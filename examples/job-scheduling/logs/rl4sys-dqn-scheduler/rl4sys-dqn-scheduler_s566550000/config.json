{
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	25600,
    "clip_value":	100,
    "current_dir":	"/Users/tybg/Documents/GitHub/RL4Sys/examples/job-scheduling",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-scheduler",
    "gamma":	0.95,
    "kernel_dim":	8,
    "kernel_size":	128,
    "log_data_dir":	"/Users/tybg/Documents/GitHub/RL4Sys/examples/job-scheduling/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-scheduler",
        "output_dir":	"/Users/tybg/Documents/GitHub/RL4Sys/examples/job-scheduling/./logs/rl4sys-dqn-scheduler/rl4sys-dqn-scheduler_s566550000"
    },
    "q_lr":	0.001,
    "seed":	566550000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x118803910>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	25600,
            "_clip_value":	100,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	8,
            "_kernel_size":	128,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=1024, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Dropout(p=0.5, inplace=False)\n    (7): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=1024, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Dropout(p=0.5, inplace=False)\n  (7): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=1024, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0291, -0.0174,  0.0306, -0.0037,  0.0280,  0.0182,  0.0276, -0.0013,\n         0.0270,  0.0135,  0.0034, -0.0190,  0.0263,  0.0072, -0.0120, -0.0124,\n        -0.0043,  0.0189, -0.0269,  0.0023,  0.0025, -0.0184, -0.0021,  0.0259,\n         0.0121,  0.0051, -0.0145, -0.0024, -0.0283,  0.0262, -0.0216,  0.0207],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0145,  0.0096,  0.0280,  ...,  0.0161,  0.0057, -0.0296],\n        [-0.0303, -0.0282,  0.0178,  ...,  0.0209,  0.0157,  0.0188],\n        [ 0.0250,  0.0276,  0.0204,  ...,  0.0270, -0.0087,  0.0296],\n        ...,\n        [-0.0309, -0.0182, -0.0111,  ...,  0.0060,  0.0028, -0.0093],\n        [-0.0246, -0.0296,  0.0031,  ..., -0.0212, -0.0259, -0.0052],\n        [ 0.0051, -0.0269, -0.0288,  ...,  0.0137, -0.0192, -0.0144]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	1024,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0201, -0.0922,  0.0124,  0.0530,  0.1276,  0.0044, -0.1293,  0.0748,\n         0.1252,  0.0712,  0.0808,  0.0662, -0.0810,  0.0656,  0.0604,  0.0452],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 3.0830e-02, -1.6182e-01, -1.2514e-01,  2.2272e-02, -2.1060e-02,\n         -5.5628e-02, -8.9638e-02,  1.0467e-01, -1.1672e-01,  7.9938e-02,\n         -5.2533e-02,  1.0006e-01, -3.5000e-02, -1.4956e-01, -9.8928e-02,\n          1.2455e-02,  1.0873e-01,  1.5330e-01,  9.4946e-02,  2.2118e-02,\n          2.5548e-02,  1.2862e-01,  4.4906e-02,  5.9589e-02,  1.3901e-01,\n         -1.5317e-01, -1.3561e-02, -1.2294e-01, -1.1747e-01,  3.1371e-02,\n         -8.5769e-02,  7.7525e-03],\n        [ 4.3001e-02, -1.4234e-01, -1.4347e-01,  1.6673e-01,  4.6652e-02,\n          1.5011e-01,  3.5028e-02, -7.7431e-02,  1.7038e-01,  8.4614e-02,\n         -1.3342e-01, -4.6233e-02,  1.0238e-01,  7.3044e-02,  6.9920e-02,\n         -1.5162e-01, -5.8249e-03, -3.6358e-04,  9.6287e-02,  8.1182e-02,\n         -8.7521e-02,  3.4010e-02, -1.4702e-01, -1.7183e-01,  9.6669e-02,\n          1.0749e-01, -1.7058e-01,  4.7233e-02,  1.0975e-02,  1.5592e-01,\n         -1.2994e-01, -3.4132e-03],\n        [ 6.9267e-02,  3.2898e-02,  1.7384e-01, -6.8139e-03, -5.8011e-02,\n          8.2750e-02, -1.3864e-01,  7.3181e-02,  5.1471e-02, -4.1312e-02,\n         -8.9638e-02, -5.4381e-03,  1.5772e-01,  5.3890e-02, -1.7500e-01,\n         -5.4034e-02, -1.3429e-02,  1.3064e-01, -1.1135e-01,  1.6287e-01,\n          4.4033e-04,  1.8801e-02, -9.3235e-02,  5.7317e-02,  1.5475e-01,\n          4.9905e-02, -1.6626e-01, -1.1385e-01,  1.4607e-01, -8.8375e-02,\n         -6.9409e-02,  5.0926e-02],\n        [ 1.1297e-01, -2.5287e-02,  4.7312e-02, -9.4872e-02, -7.1561e-02,\n          2.2583e-02,  3.0468e-03,  3.7529e-02,  1.3367e-01,  1.2245e-01,\n         -1.7073e-01, -3.1482e-02, -1.6312e-01,  1.2097e-01,  7.9570e-03,\n         -1.9907e-02,  9.3087e-02, -6.9153e-03, -1.2251e-01,  6.4714e-03,\n          1.1159e-01,  9.8577e-02, -7.8362e-02,  1.3946e-01, -8.1386e-02,\n         -1.0874e-05,  7.2516e-02,  3.7685e-03,  9.8676e-02,  7.3898e-03,\n          3.5521e-02,  1.3579e-01],\n        [-8.4874e-02,  1.4523e-01,  1.5041e-01, -1.2128e-01,  3.4807e-02,\n          1.3023e-01,  1.1170e-01,  1.1971e-02, -9.5115e-02,  3.1005e-02,\n          9.2572e-02, -1.2513e-01, -2.9360e-02,  1.1911e-01, -5.8062e-02,\n         -1.1659e-01, -4.1113e-02,  5.9732e-02, -7.5460e-02, -1.5962e-01,\n          5.5413e-03,  2.8111e-02,  7.5973e-02, -3.6060e-02,  8.9707e-02,\n         -1.3431e-01,  1.5787e-01,  4.3749e-02,  5.2947e-02, -9.2599e-02,\n          1.5637e-01,  7.3701e-02],\n        [-1.4906e-01,  1.3823e-02, -1.3728e-01,  7.1206e-03,  9.4957e-04,\n         -7.3372e-02,  9.8188e-03,  1.2173e-02, -3.3438e-02, -3.3407e-02,\n          1.2531e-01, -6.2633e-02, -1.5617e-01,  3.6146e-02,  1.6639e-01,\n          1.3569e-01, -1.1949e-01, -1.3992e-01, -1.4904e-02, -8.3878e-02,\n          1.3764e-01, -1.7147e-01, -8.1570e-02,  3.6636e-04, -5.2467e-02,\n          2.8310e-03,  4.6224e-02, -1.7015e-01,  3.8626e-02, -2.7440e-02,\n         -1.3000e-01, -1.4044e-01],\n        [ 1.1944e-01,  1.1485e-01,  7.7015e-02,  3.2738e-02, -8.4564e-02,\n         -1.5277e-01, -3.1082e-02, -5.7313e-02,  1.4012e-01,  5.5544e-02,\n         -1.6073e-01,  5.5762e-02, -6.8825e-02, -9.9228e-03,  1.0896e-01,\n          2.3462e-02,  1.4261e-01,  4.2934e-02,  1.0599e-01,  1.0380e-01,\n         -2.3047e-02,  1.6932e-01, -5.0963e-02,  1.5014e-01, -7.6896e-02,\n         -7.7414e-03, -1.2847e-01,  1.8149e-02,  1.0858e-01, -9.2427e-02,\n         -3.5130e-02,  1.6243e-01],\n        [ 5.2898e-02, -1.4861e-02, -5.4497e-02, -1.9164e-03,  1.6796e-01,\n         -1.0036e-01, -1.3689e-01,  1.5884e-01, -4.4929e-02, -4.6559e-02,\n          1.1776e-01,  2.0540e-02,  1.3035e-01, -1.0047e-01, -5.0801e-02,\n          1.0305e-01, -1.3968e-01, -1.1194e-01,  5.3235e-02, -1.0161e-01,\n         -1.6600e-01,  7.1892e-04,  5.0083e-02,  1.0760e-01,  1.6277e-01,\n         -1.4766e-01,  3.4548e-02,  5.3760e-02, -8.7889e-02,  1.4726e-01,\n         -2.9263e-02, -1.2371e-01],\n        [-9.0053e-02,  1.0417e-01,  7.8056e-02,  6.6362e-02, -1.2994e-01,\n          1.5792e-02,  6.0525e-02, -8.3258e-02,  1.6982e-01,  1.0010e-01,\n         -1.3794e-01, -3.2581e-02,  1.1277e-01,  2.9529e-02, -3.3299e-02,\n         -6.5042e-02,  1.6779e-01,  6.2494e-02,  2.0881e-02,  6.3383e-02,\n         -1.6426e-01,  1.0392e-01, -7.1043e-03,  8.6452e-02,  7.6403e-02,\n          5.5360e-02, -7.8703e-02, -1.6032e-02,  1.2194e-01, -4.2239e-02,\n          2.1467e-02, -9.1790e-02],\n        [ 2.8713e-04,  6.1003e-02,  1.1689e-01, -3.1909e-02, -1.5457e-01,\n         -4.0843e-02, -8.8248e-02,  5.8909e-02,  7.4410e-03,  6.2828e-03,\n          5.7503e-02, -2.9239e-02,  4.1668e-02, -1.5565e-01,  1.3933e-01,\n         -1.7145e-01, -6.6260e-02, -1.9531e-02,  7.0318e-02, -4.1653e-03,\n          9.9104e-02,  5.9389e-02,  1.4444e-01, -1.3381e-01, -1.4101e-01,\n          1.0938e-01, -2.1106e-02,  2.7238e-02, -7.3344e-03,  7.4667e-02,\n         -2.0598e-02,  1.0969e-02],\n        [ 1.1396e-01, -1.4076e-01, -8.0995e-03, -8.2006e-02,  1.0615e-01,\n         -8.6384e-02,  5.3910e-03, -4.3847e-02, -1.5484e-02,  1.2934e-01,\n         -4.3128e-02, -2.5374e-02,  6.0270e-02, -6.6990e-02,  1.6991e-02,\n         -6.9782e-02,  9.4534e-02,  5.0544e-02, -1.5366e-01,  1.4680e-01,\n          5.6466e-02,  1.2863e-01, -4.1064e-02, -1.1403e-01, -3.3335e-02,\n         -1.6104e-01, -1.1674e-01,  7.4337e-03, -7.7219e-02, -1.3017e-01,\n         -1.3950e-01,  1.7020e-01],\n        [ 4.8572e-02, -1.3593e-01,  6.0862e-02, -5.3658e-02,  4.7515e-02,\n         -4.1702e-02,  6.7071e-02, -1.1020e-01,  1.2535e-01,  8.4749e-02,\n         -7.7892e-03, -1.9075e-02,  3.5838e-02,  1.7058e-01, -7.1316e-02,\n         -7.4776e-02, -4.6000e-02,  2.5859e-02,  3.8455e-02,  3.8790e-02,\n         -8.3641e-03, -1.6523e-01, -6.6263e-02,  4.7394e-02, -1.4686e-01,\n         -1.2066e-01,  8.7001e-02,  1.4986e-01,  1.5649e-01,  5.7452e-02,\n         -4.9433e-02,  7.0452e-02],\n        [-1.5680e-01,  9.5657e-02,  2.9405e-03,  5.5605e-02,  2.9989e-02,\n          1.4592e-01,  1.3286e-01, -1.7358e-01,  1.4215e-01, -1.0302e-01,\n         -5.7892e-02,  1.1073e-01, -1.4710e-01, -8.9579e-02,  7.0128e-02,\n          8.1678e-02, -7.9246e-02,  1.1131e-01,  1.3832e-01, -3.2036e-02,\n          1.8384e-02, -4.4716e-02, -8.3815e-02,  2.7975e-02, -1.0222e-01,\n         -1.8434e-02, -1.4572e-01,  1.7458e-01, -5.8307e-02, -5.2969e-02,\n         -6.3144e-02, -2.8998e-02],\n        [ 1.1827e-01, -1.7483e-01,  1.3032e-01,  8.3111e-02,  1.1867e-01,\n         -6.6339e-02,  1.0341e-01, -7.2710e-02, -2.8278e-02,  5.5554e-02,\n          3.7606e-02,  7.1955e-02, -1.1416e-01, -9.9237e-02, -3.6246e-02,\n          1.3854e-02,  9.2359e-02, -9.9327e-02,  1.2062e-01,  1.6229e-01,\n          6.4146e-02, -1.1877e-02, -1.5259e-02,  1.2202e-01,  1.3885e-01,\n          1.0638e-01, -6.9494e-02, -1.3233e-01,  4.9995e-02,  3.3528e-02,\n         -8.0540e-02, -1.0839e-01],\n        [ 8.4460e-02,  1.7027e-01,  8.3549e-02,  5.1747e-02,  2.9064e-02,\n         -1.0156e-01,  6.9642e-02, -1.1045e-01, -1.7446e-01,  7.9412e-02,\n          6.9849e-02, -6.1098e-02,  1.6911e-01,  4.7183e-02,  1.5551e-01,\n         -5.1125e-02, -1.8852e-02,  6.7714e-02,  1.7588e-01,  1.0291e-01,\n         -1.6995e-01,  5.3019e-02,  5.9352e-02, -4.0805e-02,  1.4723e-02,\n         -1.4744e-01, -5.5689e-02, -1.4807e-01,  1.3538e-01, -8.7167e-02,\n         -1.3040e-01,  8.1035e-03],\n        [ 5.6260e-02,  5.8676e-02, -3.3305e-02, -1.6663e-01, -3.6022e-02,\n         -6.1895e-03, -1.2537e-02,  5.8982e-02,  1.8967e-02, -7.9980e-02,\n         -1.1545e-01,  8.4388e-02,  1.6600e-02, -1.2076e-01,  1.4688e-01,\n         -1.0624e-01,  7.2068e-02,  1.6822e-01, -1.1245e-01, -3.1230e-02,\n         -1.1079e-01, -1.7351e-01,  7.7585e-02,  9.7734e-02, -9.0805e-02,\n          5.6875e-02, -8.1930e-02, -1.5689e-01, -1.3054e-01,  1.4247e-01,\n         -6.0294e-02, -9.2279e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0884, -0.1127, -0.1186,  0.0618,  0.1575, -0.0658, -0.1394,  0.1016],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2225,  0.1028, -0.1298,  0.0145, -0.0941, -0.2286,  0.1475,  0.2098,\n          0.0384, -0.0325, -0.1842, -0.0204, -0.2478, -0.0440,  0.1160,  0.0602],\n        [ 0.0993,  0.0154,  0.1571, -0.1428, -0.1763, -0.1179,  0.1199,  0.1492,\n          0.0439,  0.1060,  0.0138,  0.0406, -0.0101,  0.1263,  0.1831, -0.2495],\n        [-0.0255, -0.1850, -0.1205, -0.1334,  0.1921,  0.2426,  0.0434,  0.2120,\n         -0.2037, -0.1497,  0.1717,  0.1185,  0.2479, -0.1307,  0.2194, -0.1218],\n        [-0.0801,  0.2490,  0.2345,  0.1010,  0.2025,  0.1649,  0.1428, -0.0344,\n          0.1387, -0.0862,  0.0935,  0.1191, -0.0216,  0.0303,  0.1920,  0.0944],\n        [ 0.1478, -0.0773,  0.0262,  0.1885,  0.1430, -0.0769, -0.0164,  0.2261,\n         -0.1701, -0.1986,  0.1049, -0.0710, -0.1403, -0.0378, -0.1276, -0.0329],\n        [ 0.0875,  0.0800, -0.0690, -0.1738,  0.1154,  0.1209,  0.1046,  0.1507,\n         -0.1257,  0.0510,  0.0158,  0.1224, -0.0692, -0.2099,  0.0464, -0.1207],\n        [ 0.0095, -0.0593,  0.1142, -0.2218, -0.0681, -0.2311, -0.2195, -0.2223,\n          0.2246,  0.0808, -0.0929,  0.0905, -0.0794,  0.0505,  0.0797, -0.2471],\n        [ 0.0971, -0.0739,  0.0489,  0.2316,  0.2126,  0.0392,  0.2495,  0.1265,\n         -0.0931, -0.1932,  0.0357, -0.0720, -0.2469,  0.0067, -0.0561, -0.1773]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Dropout(p=0.5, inplace=False)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "p":	0.5,
                                            "training":	true
                                        }
                                    },
                                    "7":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3185], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2708,  0.2894,  0.1536, -0.2004,  0.0926,  0.0923,  0.1394, -0.0128]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	128,
                    "kernel_size":	8,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.001,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.001,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0145,  0.0096,  0.0280,  ...,  0.0161,  0.0057, -0.0296],\n        [-0.0303, -0.0282,  0.0178,  ...,  0.0209,  0.0157,  0.0188],\n        [ 0.0250,  0.0276,  0.0204,  ...,  0.0270, -0.0087,  0.0296],\n        ...,\n        [-0.0309, -0.0182, -0.0111,  ...,  0.0060,  0.0028, -0.0093],\n        [-0.0246, -0.0296,  0.0031,  ..., -0.0212, -0.0259, -0.0052],\n        [ 0.0051, -0.0269, -0.0288,  ...,  0.0137, -0.0192, -0.0144]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0291, -0.0174,  0.0306, -0.0037,  0.0280,  0.0182,  0.0276, -0.0013,\n         0.0270,  0.0135,  0.0034, -0.0190,  0.0263,  0.0072, -0.0120, -0.0124,\n        -0.0043,  0.0189, -0.0269,  0.0023,  0.0025, -0.0184, -0.0021,  0.0259,\n         0.0121,  0.0051, -0.0145, -0.0024, -0.0283,  0.0262, -0.0216,  0.0207],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 3.0830e-02, -1.6182e-01, -1.2514e-01,  2.2272e-02, -2.1060e-02,\n         -5.5628e-02, -8.9638e-02,  1.0467e-01, -1.1672e-01,  7.9938e-02,\n         -5.2533e-02,  1.0006e-01, -3.5000e-02, -1.4956e-01, -9.8928e-02,\n          1.2455e-02,  1.0873e-01,  1.5330e-01,  9.4946e-02,  2.2118e-02,\n          2.5548e-02,  1.2862e-01,  4.4906e-02,  5.9589e-02,  1.3901e-01,\n         -1.5317e-01, -1.3561e-02, -1.2294e-01, -1.1747e-01,  3.1371e-02,\n         -8.5769e-02,  7.7525e-03],\n        [ 4.3001e-02, -1.4234e-01, -1.4347e-01,  1.6673e-01,  4.6652e-02,\n          1.5011e-01,  3.5028e-02, -7.7431e-02,  1.7038e-01,  8.4614e-02,\n         -1.3342e-01, -4.6233e-02,  1.0238e-01,  7.3044e-02,  6.9920e-02,\n         -1.5162e-01, -5.8249e-03, -3.6358e-04,  9.6287e-02,  8.1182e-02,\n         -8.7521e-02,  3.4010e-02, -1.4702e-01, -1.7183e-01,  9.6669e-02,\n          1.0749e-01, -1.7058e-01,  4.7233e-02,  1.0975e-02,  1.5592e-01,\n         -1.2994e-01, -3.4132e-03],\n        [ 6.9267e-02,  3.2898e-02,  1.7384e-01, -6.8139e-03, -5.8011e-02,\n          8.2750e-02, -1.3864e-01,  7.3181e-02,  5.1471e-02, -4.1312e-02,\n         -8.9638e-02, -5.4381e-03,  1.5772e-01,  5.3890e-02, -1.7500e-01,\n         -5.4034e-02, -1.3429e-02,  1.3064e-01, -1.1135e-01,  1.6287e-01,\n          4.4033e-04,  1.8801e-02, -9.3235e-02,  5.7317e-02,  1.5475e-01,\n          4.9905e-02, -1.6626e-01, -1.1385e-01,  1.4607e-01, -8.8375e-02,\n         -6.9409e-02,  5.0926e-02],\n        [ 1.1297e-01, -2.5287e-02,  4.7312e-02, -9.4872e-02, -7.1561e-02,\n          2.2583e-02,  3.0468e-03,  3.7529e-02,  1.3367e-01,  1.2245e-01,\n         -1.7073e-01, -3.1482e-02, -1.6312e-01,  1.2097e-01,  7.9570e-03,\n         -1.9907e-02,  9.3087e-02, -6.9153e-03, -1.2251e-01,  6.4714e-03,\n          1.1159e-01,  9.8577e-02, -7.8362e-02,  1.3946e-01, -8.1386e-02,\n         -1.0874e-05,  7.2516e-02,  3.7685e-03,  9.8676e-02,  7.3898e-03,\n          3.5521e-02,  1.3579e-01],\n        [-8.4874e-02,  1.4523e-01,  1.5041e-01, -1.2128e-01,  3.4807e-02,\n          1.3023e-01,  1.1170e-01,  1.1971e-02, -9.5115e-02,  3.1005e-02,\n          9.2572e-02, -1.2513e-01, -2.9360e-02,  1.1911e-01, -5.8062e-02,\n         -1.1659e-01, -4.1113e-02,  5.9732e-02, -7.5460e-02, -1.5962e-01,\n          5.5413e-03,  2.8111e-02,  7.5973e-02, -3.6060e-02,  8.9707e-02,\n         -1.3431e-01,  1.5787e-01,  4.3749e-02,  5.2947e-02, -9.2599e-02,\n          1.5637e-01,  7.3701e-02],\n        [-1.4906e-01,  1.3823e-02, -1.3728e-01,  7.1206e-03,  9.4957e-04,\n         -7.3372e-02,  9.8188e-03,  1.2173e-02, -3.3438e-02, -3.3407e-02,\n          1.2531e-01, -6.2633e-02, -1.5617e-01,  3.6146e-02,  1.6639e-01,\n          1.3569e-01, -1.1949e-01, -1.3992e-01, -1.4904e-02, -8.3878e-02,\n          1.3764e-01, -1.7147e-01, -8.1570e-02,  3.6636e-04, -5.2467e-02,\n          2.8310e-03,  4.6224e-02, -1.7015e-01,  3.8626e-02, -2.7440e-02,\n         -1.3000e-01, -1.4044e-01],\n        [ 1.1944e-01,  1.1485e-01,  7.7015e-02,  3.2738e-02, -8.4564e-02,\n         -1.5277e-01, -3.1082e-02, -5.7313e-02,  1.4012e-01,  5.5544e-02,\n         -1.6073e-01,  5.5762e-02, -6.8825e-02, -9.9228e-03,  1.0896e-01,\n          2.3462e-02,  1.4261e-01,  4.2934e-02,  1.0599e-01,  1.0380e-01,\n         -2.3047e-02,  1.6932e-01, -5.0963e-02,  1.5014e-01, -7.6896e-02,\n         -7.7414e-03, -1.2847e-01,  1.8149e-02,  1.0858e-01, -9.2427e-02,\n         -3.5130e-02,  1.6243e-01],\n        [ 5.2898e-02, -1.4861e-02, -5.4497e-02, -1.9164e-03,  1.6796e-01,\n         -1.0036e-01, -1.3689e-01,  1.5884e-01, -4.4929e-02, -4.6559e-02,\n          1.1776e-01,  2.0540e-02,  1.3035e-01, -1.0047e-01, -5.0801e-02,\n          1.0305e-01, -1.3968e-01, -1.1194e-01,  5.3235e-02, -1.0161e-01,\n         -1.6600e-01,  7.1892e-04,  5.0083e-02,  1.0760e-01,  1.6277e-01,\n         -1.4766e-01,  3.4548e-02,  5.3760e-02, -8.7889e-02,  1.4726e-01,\n         -2.9263e-02, -1.2371e-01],\n        [-9.0053e-02,  1.0417e-01,  7.8056e-02,  6.6362e-02, -1.2994e-01,\n          1.5792e-02,  6.0525e-02, -8.3258e-02,  1.6982e-01,  1.0010e-01,\n         -1.3794e-01, -3.2581e-02,  1.1277e-01,  2.9529e-02, -3.3299e-02,\n         -6.5042e-02,  1.6779e-01,  6.2494e-02,  2.0881e-02,  6.3383e-02,\n         -1.6426e-01,  1.0392e-01, -7.1043e-03,  8.6452e-02,  7.6403e-02,\n          5.5360e-02, -7.8703e-02, -1.6032e-02,  1.2194e-01, -4.2239e-02,\n          2.1467e-02, -9.1790e-02],\n        [ 2.8713e-04,  6.1003e-02,  1.1689e-01, -3.1909e-02, -1.5457e-01,\n         -4.0843e-02, -8.8248e-02,  5.8909e-02,  7.4410e-03,  6.2828e-03,\n          5.7503e-02, -2.9239e-02,  4.1668e-02, -1.5565e-01,  1.3933e-01,\n         -1.7145e-01, -6.6260e-02, -1.9531e-02,  7.0318e-02, -4.1653e-03,\n          9.9104e-02,  5.9389e-02,  1.4444e-01, -1.3381e-01, -1.4101e-01,\n          1.0938e-01, -2.1106e-02,  2.7238e-02, -7.3344e-03,  7.4667e-02,\n         -2.0598e-02,  1.0969e-02],\n        [ 1.1396e-01, -1.4076e-01, -8.0995e-03, -8.2006e-02,  1.0615e-01,\n         -8.6384e-02,  5.3910e-03, -4.3847e-02, -1.5484e-02,  1.2934e-01,\n         -4.3128e-02, -2.5374e-02,  6.0270e-02, -6.6990e-02,  1.6991e-02,\n         -6.9782e-02,  9.4534e-02,  5.0544e-02, -1.5366e-01,  1.4680e-01,\n          5.6466e-02,  1.2863e-01, -4.1064e-02, -1.1403e-01, -3.3335e-02,\n         -1.6104e-01, -1.1674e-01,  7.4337e-03, -7.7219e-02, -1.3017e-01,\n         -1.3950e-01,  1.7020e-01],\n        [ 4.8572e-02, -1.3593e-01,  6.0862e-02, -5.3658e-02,  4.7515e-02,\n         -4.1702e-02,  6.7071e-02, -1.1020e-01,  1.2535e-01,  8.4749e-02,\n         -7.7892e-03, -1.9075e-02,  3.5838e-02,  1.7058e-01, -7.1316e-02,\n         -7.4776e-02, -4.6000e-02,  2.5859e-02,  3.8455e-02,  3.8790e-02,\n         -8.3641e-03, -1.6523e-01, -6.6263e-02,  4.7394e-02, -1.4686e-01,\n         -1.2066e-01,  8.7001e-02,  1.4986e-01,  1.5649e-01,  5.7452e-02,\n         -4.9433e-02,  7.0452e-02],\n        [-1.5680e-01,  9.5657e-02,  2.9405e-03,  5.5605e-02,  2.9989e-02,\n          1.4592e-01,  1.3286e-01, -1.7358e-01,  1.4215e-01, -1.0302e-01,\n         -5.7892e-02,  1.1073e-01, -1.4710e-01, -8.9579e-02,  7.0128e-02,\n          8.1678e-02, -7.9246e-02,  1.1131e-01,  1.3832e-01, -3.2036e-02,\n          1.8384e-02, -4.4716e-02, -8.3815e-02,  2.7975e-02, -1.0222e-01,\n         -1.8434e-02, -1.4572e-01,  1.7458e-01, -5.8307e-02, -5.2969e-02,\n         -6.3144e-02, -2.8998e-02],\n        [ 1.1827e-01, -1.7483e-01,  1.3032e-01,  8.3111e-02,  1.1867e-01,\n         -6.6339e-02,  1.0341e-01, -7.2710e-02, -2.8278e-02,  5.5554e-02,\n          3.7606e-02,  7.1955e-02, -1.1416e-01, -9.9237e-02, -3.6246e-02,\n          1.3854e-02,  9.2359e-02, -9.9327e-02,  1.2062e-01,  1.6229e-01,\n          6.4146e-02, -1.1877e-02, -1.5259e-02,  1.2202e-01,  1.3885e-01,\n          1.0638e-01, -6.9494e-02, -1.3233e-01,  4.9995e-02,  3.3528e-02,\n         -8.0540e-02, -1.0839e-01],\n        [ 8.4460e-02,  1.7027e-01,  8.3549e-02,  5.1747e-02,  2.9064e-02,\n         -1.0156e-01,  6.9642e-02, -1.1045e-01, -1.7446e-01,  7.9412e-02,\n          6.9849e-02, -6.1098e-02,  1.6911e-01,  4.7183e-02,  1.5551e-01,\n         -5.1125e-02, -1.8852e-02,  6.7714e-02,  1.7588e-01,  1.0291e-01,\n         -1.6995e-01,  5.3019e-02,  5.9352e-02, -4.0805e-02,  1.4723e-02,\n         -1.4744e-01, -5.5689e-02, -1.4807e-01,  1.3538e-01, -8.7167e-02,\n         -1.3040e-01,  8.1035e-03],\n        [ 5.6260e-02,  5.8676e-02, -3.3305e-02, -1.6663e-01, -3.6022e-02,\n         -6.1895e-03, -1.2537e-02,  5.8982e-02,  1.8967e-02, -7.9980e-02,\n         -1.1545e-01,  8.4388e-02,  1.6600e-02, -1.2076e-01,  1.4688e-01,\n         -1.0624e-01,  7.2068e-02,  1.6822e-01, -1.1245e-01, -3.1230e-02,\n         -1.1079e-01, -1.7351e-01,  7.7585e-02,  9.7734e-02, -9.0805e-02,\n          5.6875e-02, -8.1930e-02, -1.5689e-01, -1.3054e-01,  1.4247e-01,\n         -6.0294e-02, -9.2279e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0201, -0.0922,  0.0124,  0.0530,  0.1276,  0.0044, -0.1293,  0.0748,\n         0.1252,  0.0712,  0.0808,  0.0662, -0.0810,  0.0656,  0.0604,  0.0452],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2225,  0.1028, -0.1298,  0.0145, -0.0941, -0.2286,  0.1475,  0.2098,\n          0.0384, -0.0325, -0.1842, -0.0204, -0.2478, -0.0440,  0.1160,  0.0602],\n        [ 0.0993,  0.0154,  0.1571, -0.1428, -0.1763, -0.1179,  0.1199,  0.1492,\n          0.0439,  0.1060,  0.0138,  0.0406, -0.0101,  0.1263,  0.1831, -0.2495],\n        [-0.0255, -0.1850, -0.1205, -0.1334,  0.1921,  0.2426,  0.0434,  0.2120,\n         -0.2037, -0.1497,  0.1717,  0.1185,  0.2479, -0.1307,  0.2194, -0.1218],\n        [-0.0801,  0.2490,  0.2345,  0.1010,  0.2025,  0.1649,  0.1428, -0.0344,\n          0.1387, -0.0862,  0.0935,  0.1191, -0.0216,  0.0303,  0.1920,  0.0944],\n        [ 0.1478, -0.0773,  0.0262,  0.1885,  0.1430, -0.0769, -0.0164,  0.2261,\n         -0.1701, -0.1986,  0.1049, -0.0710, -0.1403, -0.0378, -0.1276, -0.0329],\n        [ 0.0875,  0.0800, -0.0690, -0.1738,  0.1154,  0.1209,  0.1046,  0.1507,\n         -0.1257,  0.0510,  0.0158,  0.1224, -0.0692, -0.2099,  0.0464, -0.1207],\n        [ 0.0095, -0.0593,  0.1142, -0.2218, -0.0681, -0.2311, -0.2195, -0.2223,\n          0.2246,  0.0808, -0.0929,  0.0905, -0.0794,  0.0505,  0.0797, -0.2471],\n        [ 0.0971, -0.0739,  0.0489,  0.2316,  0.2126,  0.0392,  0.2495,  0.1265,\n         -0.0931, -0.1932,  0.0357, -0.0720, -0.2469,  0.0067, -0.0561, -0.1773]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0884, -0.1127, -0.1186,  0.0618,  0.1575, -0.0658, -0.1394,  0.1016],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2708,  0.2894,  0.1536, -0.2004,  0.0926,  0.0923,  0.1394, -0.0128]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3185], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x13e0c1c90>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	25600,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "max_size":	25600,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	0.005,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x16a320250>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-scheduler",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/tybg/Documents/GitHub/RL4Sys/examples/job-scheduling/./logs/rl4sys-dqn-scheduler/rl4sys-dqn-scheduler_s566550000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/tybg/Documents/GitHub/RL4Sys/examples/job-scheduling/./logs/rl4sys-dqn-scheduler/rl4sys-dqn-scheduler_s566550000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	0.005,
    "traj_per_epoch":	3
}