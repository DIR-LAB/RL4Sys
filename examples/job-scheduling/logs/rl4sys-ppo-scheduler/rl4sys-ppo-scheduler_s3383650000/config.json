{
    "buf_size":	25600,
    "clip_ratio":	0.2,
    "current_dir":	"/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling",
    "exp_name":	"rl4sys-ppo-scheduler",
    "gamma":	0.99,
    "kernel_dim":	8,
    "kernel_size":	128,
    "lam":	0.97,
    "log_data_dir":	"/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-scheduler",
        "output_dir":	"/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling/./logs/rl4sys-ppo-scheduler/rl4sys-ppo-scheduler_s3383650000"
    },
    "pi_lr":	0.0003,
    "seed":	3383650000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x7f95a5c0a140>":	{
            "_clip_ratio":	0.2,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (dense1): Linear(in_features=8, out_features=32, bias=True)\n    (dense2): Linear(in_features=32, out_features=16, bias=True)\n    (dense3): Linear(in_features=16, out_features=8, bias=True)\n    (dense4): Linear(in_features=8, out_features=1, bias=True)\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=1024, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (dense1): Linear(in_features=8, out_features=32, bias=True)\n  (dense2): Linear(in_features=32, out_features=16, bias=True)\n  (dense3): Linear(in_features=16, out_features=8, bias=True)\n  (dense4): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "dense1":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1560, -0.2921, -0.0224, -0.3473, -0.1116,  0.0241, -0.1478, -0.1765,\n         0.2992, -0.3246,  0.1763, -0.1203, -0.2425, -0.0311, -0.0618,  0.3343,\n         0.3194,  0.1294, -0.0955,  0.3333,  0.2079,  0.3032,  0.2093, -0.0912,\n        -0.3262, -0.3278,  0.0119, -0.0978, -0.2570, -0.0337, -0.2190, -0.1171],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2476, -0.1886,  0.1159,  0.2788, -0.2146, -0.1047, -0.1808, -0.0807],\n        [ 0.1164, -0.1042,  0.2132, -0.1614, -0.1816, -0.2258, -0.2342, -0.3223],\n        [-0.1791,  0.0248,  0.3012,  0.2631, -0.0790,  0.1213, -0.3041,  0.2020],\n        [-0.1366, -0.2400,  0.2920, -0.1741,  0.2378,  0.3380, -0.0983,  0.2516],\n        [ 0.1310,  0.2997,  0.2402, -0.1553,  0.1394, -0.2134,  0.1758, -0.0332],\n        [ 0.0737,  0.1087,  0.2097,  0.0361, -0.1592, -0.1052, -0.1542, -0.2552],\n        [-0.3467,  0.1932,  0.0674, -0.2378,  0.0642, -0.0976, -0.3375,  0.1941],\n        [-0.2893,  0.3084,  0.1483, -0.1608, -0.2318,  0.0016, -0.0204, -0.1978],\n        [-0.0023,  0.2411,  0.0254,  0.2281,  0.0319, -0.2739,  0.2272, -0.2319],\n        [ 0.0503,  0.1930,  0.2253,  0.2996, -0.2607, -0.0163, -0.0807,  0.3245],\n        [ 0.0841,  0.0854,  0.1956,  0.3346, -0.0114,  0.3450,  0.1022,  0.1345],\n        [-0.2447, -0.2782, -0.2740, -0.2688, -0.1258, -0.0339, -0.2890,  0.0787],\n        [ 0.2741,  0.2703, -0.2080, -0.0006, -0.2270, -0.2071, -0.1116,  0.2419],\n        [ 0.3014, -0.0783,  0.2513, -0.0963, -0.3001,  0.1074,  0.0257, -0.2635],\n        [ 0.3530,  0.1266, -0.0053, -0.2225, -0.3397,  0.2496,  0.3021, -0.1853],\n        [ 0.1812, -0.0571, -0.2680, -0.2880,  0.3156, -0.3302, -0.0707, -0.3354],\n        [ 0.0754,  0.1559,  0.1687, -0.3187, -0.2312,  0.0096, -0.3247,  0.1829],\n        [-0.1625,  0.1277,  0.2001, -0.2544, -0.0322,  0.1732,  0.0669, -0.0868],\n        [-0.2382,  0.3287,  0.0228, -0.1747,  0.0625, -0.1339, -0.1452, -0.0473],\n        [-0.2649,  0.2240,  0.0787,  0.3452, -0.2458, -0.0872,  0.0414, -0.2538],\n        [-0.3131,  0.1855,  0.0593,  0.0256,  0.2553, -0.1571,  0.1281,  0.0729],\n        [ 0.1654,  0.2026, -0.1493, -0.0590,  0.3484, -0.0116,  0.0082, -0.0838],\n        [ 0.1964,  0.1982, -0.1448, -0.3454, -0.1230,  0.0236, -0.1380, -0.2526],\n        [-0.0833,  0.2897, -0.0269, -0.0638,  0.0716,  0.1648,  0.0170,  0.1988],\n        [-0.1306, -0.3291,  0.2243, -0.2659, -0.2095, -0.2883, -0.2058,  0.1504],\n        [ 0.0805,  0.0785,  0.0769, -0.3382,  0.2470,  0.0102, -0.2384, -0.0265],\n        [ 0.2072,  0.2458, -0.0880, -0.1773,  0.3183, -0.0374,  0.0054, -0.3299],\n        [ 0.2407, -0.1898,  0.1732, -0.2651, -0.1932, -0.2607, -0.0359, -0.2519],\n        [ 0.2062, -0.2462, -0.2475,  0.0191,  0.2663, -0.0645,  0.3498, -0.3344],\n        [ 0.1129, -0.0958,  0.3192,  0.2618, -0.2136,  0.1680, -0.0975, -0.2491],\n        [-0.0774,  0.0244, -0.0298, -0.1872,  0.3474,  0.2479, -0.2563, -0.2847],\n        [ 0.1289, -0.2055,  0.2488, -0.3420,  0.2000,  0.2884,  0.2988,  0.0040]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "dense2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0185, -0.0557, -0.0546, -0.0736, -0.1601,  0.1395,  0.0269,  0.0100,\n         0.0873, -0.1194, -0.0040,  0.0262, -0.0495,  0.0339, -0.0765, -0.0290],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 4.1647e-02,  1.6035e-01, -2.1305e-02,  8.4870e-02, -1.5885e-01,\n          1.4578e-01, -3.9774e-04,  6.7317e-02,  1.4131e-01,  4.9132e-02,\n         -7.0562e-02, -9.2011e-02,  1.7660e-01, -1.2955e-01, -1.6784e-01,\n         -1.3769e-01, -5.5908e-02,  1.5237e-02, -1.6925e-01,  1.1554e-01,\n          1.4272e-01,  1.5525e-01, -1.7459e-02, -4.8790e-02,  9.1112e-02,\n         -1.8258e-02,  6.1978e-02, -1.0943e-02, -1.3667e-01,  9.9537e-02,\n          5.4558e-03,  1.0324e-01],\n        [-3.9383e-02, -3.6017e-02,  3.3358e-02, -6.7613e-02, -1.1140e-02,\n         -1.2868e-01, -6.1677e-02,  1.7649e-01,  4.3806e-02, -9.8097e-02,\n         -3.9718e-02,  1.6668e-01, -4.5951e-02, -1.1965e-01, -8.4595e-04,\n          1.3980e-04,  2.2322e-02, -3.9571e-02,  4.3613e-02,  1.4647e-01,\n          1.7082e-02, -7.7736e-02,  1.1343e-01,  8.9823e-02, -1.6228e-01,\n         -1.7285e-01, -5.3562e-02, -1.3685e-01, -1.5494e-01, -1.0740e-01,\n          1.4125e-01, -1.7577e-01],\n        [-1.5539e-01,  5.4190e-02, -4.8708e-02, -1.1247e-02, -9.4360e-02,\n          1.7077e-01, -1.4753e-01,  1.6786e-01, -7.0694e-02, -1.5351e-01,\n         -1.3582e-01, -2.5551e-02,  3.7494e-02,  1.3079e-01,  1.6636e-01,\n         -4.4788e-02, -4.1857e-02,  8.7537e-04,  1.4121e-01,  2.2743e-02,\n          1.2428e-02, -1.4949e-01, -4.3265e-02, -2.7895e-02,  3.4472e-02,\n          5.2597e-02, -1.0431e-01,  1.0872e-01,  1.0768e-01,  7.2897e-02,\n          6.0149e-02,  1.1456e-01],\n        [ 3.9772e-02, -1.1931e-01, -6.6175e-02,  1.4103e-01,  5.6880e-02,\n          2.6731e-03, -1.7592e-01,  7.0164e-02,  8.7307e-02,  2.7082e-02,\n          6.7795e-02,  2.6595e-03, -6.5901e-02, -8.4725e-02, -1.3532e-01,\n          1.2781e-01, -8.3171e-02, -1.3306e-01, -1.6699e-02, -4.7624e-02,\n          1.4620e-01, -5.4856e-02,  1.5607e-01, -1.1362e-01, -9.1148e-02,\n          4.6241e-02,  1.3238e-02,  1.0971e-01, -1.3246e-01, -1.5036e-01,\n         -6.9379e-02,  1.1378e-02],\n        [-1.9516e-02,  1.5732e-01,  1.6062e-01, -1.5930e-01,  7.1281e-02,\n          1.2395e-02,  5.7842e-02,  8.1062e-02,  3.5221e-02,  5.3110e-02,\n         -9.9947e-02, -1.3843e-01,  1.7244e-01, -7.7786e-03,  2.2631e-02,\n          4.3751e-04, -3.9968e-02,  1.5417e-01,  8.1748e-02, -1.4580e-01,\n         -9.6466e-02,  1.1633e-01,  1.7711e-02,  1.3484e-01,  3.0379e-02,\n         -8.5216e-02, -6.2080e-02, -2.4941e-02, -3.0998e-02,  1.3378e-01,\n         -7.2126e-02, -1.5094e-01],\n        [ 3.7834e-02, -6.8592e-02,  1.1424e-01,  1.2787e-01,  1.7347e-01,\n          9.6012e-02,  5.9530e-02,  1.4952e-01, -6.5617e-02, -9.9903e-02,\n          2.3210e-02, -1.0026e-01,  2.6904e-02, -5.5537e-02, -2.6461e-03,\n          5.3050e-02,  1.3919e-01, -1.3249e-01, -7.8293e-03,  7.4893e-02,\n         -5.9665e-02,  1.4133e-01, -3.4742e-02,  1.6011e-01, -3.1486e-02,\n          1.7043e-01, -1.1220e-01,  1.7184e-01, -2.6014e-02, -1.3655e-01,\n          1.3428e-01,  7.7826e-03],\n        [-1.6753e-01,  4.2632e-05, -1.1375e-01,  4.2070e-02,  1.0189e-01,\n         -5.4275e-02,  1.1735e-01,  4.4455e-02,  6.2150e-02, -1.2221e-01,\n         -1.0520e-01,  6.0462e-02,  1.0114e-03, -1.5387e-01, -8.9577e-02,\n          7.5433e-02, -6.9638e-02,  1.3783e-01,  2.8586e-02,  1.6751e-02,\n          1.0632e-02,  6.1348e-02, -1.8170e-02, -1.1703e-01, -1.3351e-01,\n          1.6860e-01, -5.6484e-02, -1.6982e-01, -1.1162e-01, -7.5076e-02,\n         -3.1818e-02,  2.9705e-02],\n        [ 1.4348e-01,  8.8364e-03, -1.4615e-01,  8.0357e-02, -3.0535e-02,\n         -2.6287e-02, -1.0529e-01, -9.7311e-02,  1.4671e-01, -6.5521e-02,\n         -1.3353e-01,  1.3367e-01, -1.5778e-01, -6.2489e-03,  5.4058e-02,\n          1.3790e-01, -2.8493e-02, -1.4677e-01, -6.2032e-02, -3.1786e-02,\n          1.1499e-01,  8.7319e-02, -1.0422e-01,  1.6259e-01,  6.8474e-02,\n          1.4768e-01,  3.7146e-02,  1.3068e-02,  1.2677e-01,  4.7550e-03,\n          1.0220e-01,  4.6152e-02],\n        [-4.4950e-02,  1.1988e-01,  4.7209e-02,  1.0178e-01, -6.2769e-02,\n          1.8937e-02,  5.2356e-02, -9.5389e-02,  2.6316e-02,  1.5999e-01,\n          1.2802e-01, -4.9265e-02,  1.3405e-01, -1.1158e-02,  9.0329e-02,\n          1.3028e-01,  1.7609e-01,  7.1621e-02,  1.0086e-01, -1.1305e-01,\n         -7.5436e-02,  1.1302e-01, -1.9524e-02, -9.0030e-02, -9.8985e-02,\n          1.3191e-01, -1.6764e-01,  2.3178e-02,  1.2921e-01,  6.0553e-02,\n         -9.4373e-02, -2.7628e-02],\n        [ 4.3625e-02,  1.5712e-01,  3.8892e-02,  1.4972e-01,  1.4142e-01,\n          6.8838e-03, -6.1014e-02,  1.5543e-01,  1.0873e-02,  9.7147e-02,\n          1.3568e-01,  6.4948e-03, -1.3613e-01,  1.3898e-02, -1.0039e-01,\n          8.1286e-02,  1.1721e-01, -1.2172e-01, -2.1361e-02,  1.6942e-01,\n         -4.4073e-02, -1.2329e-01, -1.7062e-01,  2.5269e-02, -1.7343e-01,\n          1.7563e-01, -1.8479e-02,  7.3145e-02,  1.2453e-01,  6.3337e-02,\n          1.5879e-01, -4.8315e-02],\n        [ 1.0483e-01, -7.3237e-02, -5.4846e-02,  8.8853e-02,  7.4899e-02,\n          1.4784e-01,  2.8238e-02,  5.3977e-02,  1.1641e-01, -3.3653e-02,\n          1.7160e-01, -1.2864e-01,  8.7438e-02, -1.3128e-01,  6.6025e-02,\n          1.0833e-01, -1.9750e-02,  1.3347e-01,  6.2635e-02,  4.1853e-02,\n          6.2816e-02,  1.2863e-01,  6.4069e-02,  1.7465e-01, -1.3649e-01,\n          2.5337e-02, -1.6409e-01,  2.8257e-02, -1.3135e-01, -1.1293e-01,\n         -2.6723e-02, -1.5576e-01],\n        [ 1.6640e-01,  4.6438e-02, -1.2149e-01,  4.8235e-02,  1.7672e-01,\n         -1.2288e-01, -7.5178e-02, -1.5706e-01,  3.9111e-02, -9.1310e-02,\n         -9.3300e-02, -1.6414e-01, -1.5143e-01,  2.1757e-02, -1.6243e-01,\n         -1.6200e-01,  7.2986e-02,  9.2668e-03,  1.0308e-01,  7.0374e-02,\n          1.1716e-01,  6.6706e-02,  1.0612e-02,  1.7212e-01,  1.4103e-01,\n         -7.1639e-02, -3.9920e-02,  1.4492e-01,  2.6792e-02,  5.9701e-02,\n          1.1798e-01,  1.4504e-02],\n        [ 5.8086e-02,  4.0380e-02, -6.4925e-02, -1.5740e-01, -1.8329e-03,\n         -1.6764e-01,  1.6965e-01, -7.4000e-03, -1.3025e-01, -4.8647e-02,\n          5.0247e-02, -6.7325e-02,  3.8936e-02, -1.0820e-01,  1.4755e-01,\n          8.8428e-02,  1.1984e-01,  4.7830e-03, -1.2126e-01,  1.5404e-01,\n         -2.3783e-02, -9.5248e-02,  1.6648e-01,  1.6692e-01, -6.8821e-02,\n          5.1506e-02,  1.3561e-01, -4.0604e-02,  5.5772e-02,  3.0859e-03,\n          7.4898e-02, -3.9311e-02],\n        [ 1.4107e-01, -1.1026e-01, -3.7201e-02,  4.7706e-02, -4.0596e-02,\n         -1.7494e-02, -1.7037e-01, -5.8887e-02, -7.5702e-02, -5.4088e-02,\n          1.2009e-01,  1.2632e-01,  1.4620e-01,  6.1895e-03,  1.5141e-01,\n         -4.8470e-02, -7.1953e-02, -5.6317e-02, -4.4159e-02,  1.2148e-01,\n         -1.2938e-01, -7.3015e-03, -1.6849e-01,  1.1341e-01,  5.8158e-02,\n          1.6725e-01,  4.1735e-02,  6.0755e-02,  1.9178e-02,  1.2584e-01,\n         -8.5909e-02,  1.6140e-01],\n        [-5.1169e-02,  3.4692e-03, -1.6195e-01,  1.6685e-01,  7.7186e-02,\n          1.5028e-01,  3.1161e-02, -9.5775e-02, -1.6804e-01,  3.1146e-02,\n          1.4299e-01,  1.1310e-01, -1.7054e-01, -4.8454e-02, -5.4319e-02,\n          8.4432e-02, -1.0037e-01,  1.3182e-01,  1.2710e-01, -6.8022e-02,\n         -3.3820e-02,  8.1155e-02,  9.2616e-03, -1.0127e-01,  2.9118e-02,\n          7.6212e-02, -4.1506e-02, -2.9196e-02, -8.3120e-02, -1.6789e-01,\n         -1.9139e-02, -1.4155e-02],\n        [-2.1653e-02,  1.2940e-01, -1.7199e-01, -3.0341e-02, -4.7298e-03,\n         -8.9336e-02,  5.9661e-02, -8.9739e-04,  1.3552e-01, -1.6857e-01,\n         -1.1854e-01, -1.4167e-01, -1.5219e-01,  7.5525e-03,  4.7610e-02,\n         -1.3641e-01, -2.6688e-02,  7.0043e-02, -7.3405e-02,  1.3670e-01,\n          1.1290e-01,  3.6697e-02,  1.1468e-01,  2.2403e-02,  5.4533e-02,\n         -5.5878e-02, -5.1196e-02, -6.5312e-02,  1.2508e-01, -9.5876e-02,\n          2.5232e-03,  2.9205e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "dense3":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0122,  0.1044, -0.2005,  0.0488, -0.1448, -0.0233,  0.0681,  0.2210],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2305,  0.1134,  0.0400, -0.1390,  0.1672,  0.1402,  0.1459, -0.1162,\n         -0.1345,  0.0915, -0.0117,  0.1699, -0.1190,  0.1223,  0.1063,  0.2036],\n        [-0.0790,  0.1889,  0.2368,  0.0800,  0.1789,  0.0166, -0.1984, -0.0087,\n          0.2182, -0.1606, -0.1777,  0.0348, -0.0689, -0.1849, -0.0024,  0.0657],\n        [ 0.1111, -0.0968, -0.1220, -0.1153,  0.1227,  0.1040, -0.1669,  0.1323,\n         -0.0439, -0.1446, -0.1760, -0.0547, -0.2057, -0.1583, -0.1270, -0.2296],\n        [-0.1448, -0.0880, -0.0074, -0.1546,  0.1458, -0.0040, -0.1301, -0.1842,\n          0.0649,  0.2384,  0.2277, -0.1271,  0.1442,  0.1486, -0.1967, -0.2265],\n        [ 0.1014,  0.1305, -0.0186, -0.0381,  0.2354,  0.0375, -0.2418,  0.1348,\n         -0.0737,  0.2390,  0.2364, -0.0281,  0.1485,  0.1461,  0.0306, -0.2313],\n        [-0.1727, -0.1876,  0.1079,  0.1510,  0.1759,  0.2048, -0.1739,  0.1792,\n          0.1330, -0.2282,  0.0113,  0.2120,  0.2217, -0.1458,  0.0105,  0.0051],\n        [-0.0589, -0.2294, -0.0722,  0.0384,  0.1857, -0.2001,  0.1787,  0.0051,\n         -0.1616, -0.0752,  0.2453, -0.0688, -0.0588, -0.0864, -0.2070,  0.2289],\n        [ 0.1107,  0.0620,  0.2166, -0.2153, -0.0198, -0.0039, -0.1417, -0.2159,\n          0.0478,  0.2219,  0.1035, -0.1144, -0.1828, -0.1962,  0.0679,  0.0385]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "dense4":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0450], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0246,  0.1908,  0.3296, -0.2382, -0.2666,  0.2573, -0.3195, -0.2657]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "kernel_dim":	8,
                                "kernel_size":	128,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=1024, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=1024, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=1024, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-2.6524e-02, -3.2746e-04, -2.4051e-02, -2.5097e-02,  5.1652e-03,\n         1.2711e-02,  8.4117e-04, -1.6363e-02, -2.0060e-02,  3.1130e-02,\n         7.3638e-03,  2.3555e-02,  8.7640e-03, -7.8843e-03, -7.1668e-03,\n        -1.8598e-02,  1.7395e-02,  2.0071e-02, -3.1173e-02, -7.7787e-03,\n         2.2320e-03, -1.5629e-02,  1.4206e-02, -2.0300e-02,  2.4506e-02,\n        -1.7868e-02,  2.0543e-02, -8.5423e-03, -6.3393e-05,  1.1546e-02,\n        -2.3652e-02, -1.6507e-02], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0268,  0.0055, -0.0152,  ..., -0.0124,  0.0171, -0.0233],\n        [ 0.0094,  0.0234,  0.0260,  ...,  0.0076, -0.0257, -0.0182],\n        [ 0.0270,  0.0088, -0.0282,  ...,  0.0039,  0.0084,  0.0168],\n        ...,\n        [ 0.0255, -0.0194, -0.0021,  ..., -0.0252, -0.0150,  0.0185],\n        [-0.0045, -0.0265,  0.0309,  ..., -0.0050,  0.0273, -0.0179],\n        [ 0.0120,  0.0230, -0.0114,  ...,  0.0186, -0.0268,  0.0271]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	1024,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1608,  0.1637, -0.0232, -0.0420,  0.0050,  0.0407, -0.0919,  0.1632,\n        -0.0663, -0.0110, -0.1597,  0.0773,  0.0694,  0.0878,  0.1546, -0.0584],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 9.7794e-02,  1.5208e-01, -1.3775e-01,  1.4504e-01, -1.4282e-01,\n         -3.5963e-02,  1.3008e-01,  3.8280e-02, -5.2539e-02, -1.3265e-01,\n         -1.3608e-02, -1.4107e-01,  1.4034e-01, -8.7892e-02, -1.7365e-01,\n          1.0245e-01,  4.2052e-02, -4.3972e-02,  1.7421e-03,  4.9779e-02,\n          4.1438e-02, -1.3759e-01,  8.1018e-02, -2.2271e-03,  1.4969e-01,\n         -1.7589e-01, -2.5393e-02,  1.5195e-01,  5.0336e-02, -1.9349e-02,\n          6.3909e-02,  1.7404e-02],\n        [-1.0396e-01,  2.7618e-02, -6.6561e-02,  1.1719e-01, -4.6799e-02,\n          2.8357e-02, -2.8377e-02, -5.6475e-02, -3.0590e-02, -1.2480e-01,\n          3.3299e-02, -9.9071e-02, -8.2902e-02,  8.7268e-02, -3.7530e-02,\n          1.6867e-01,  1.4618e-01,  8.5021e-02, -3.9079e-03,  1.3624e-01,\n          1.7149e-01,  3.6595e-03, -1.1561e-01,  1.3909e-01, -1.7254e-02,\n          6.9265e-02, -1.4981e-01,  5.9257e-02, -1.4726e-02,  6.0793e-02,\n         -5.9069e-02, -1.0079e-01],\n        [-1.2614e-01,  1.3369e-01, -1.4640e-01, -4.2076e-02,  4.3656e-02,\n          1.0766e-01,  4.6622e-02, -1.5644e-01,  1.6261e-01,  4.9555e-02,\n          7.2820e-02, -1.3570e-01, -6.9629e-02, -6.7757e-02, -1.1710e-01,\n         -6.7087e-02, -9.5283e-02, -1.0483e-01, -1.8998e-02,  4.4994e-02,\n          1.4700e-01,  1.5551e-01,  6.6997e-03,  2.1516e-02,  1.1263e-01,\n         -6.9555e-04,  1.0694e-01,  7.7948e-02, -7.4191e-02,  1.6025e-01,\n          1.8605e-02, -1.1111e-01],\n        [ 1.3882e-01, -6.7094e-02, -9.5622e-02, -6.7081e-02, -6.0496e-02,\n         -9.2986e-02, -1.0620e-02,  4.5788e-03,  8.0851e-02, -1.3865e-01,\n          1.1988e-01, -1.5705e-01, -8.1861e-02,  9.7948e-03,  1.2201e-01,\n         -1.2066e-01,  1.0285e-01, -1.2623e-01,  1.0931e-01,  7.9000e-02,\n          1.1762e-01,  1.7327e-01,  5.3089e-02, -9.8514e-02,  1.1732e-01,\n         -7.9398e-02, -4.2618e-03,  1.4815e-01, -9.9365e-02, -1.1905e-01,\n          1.1710e-01,  5.0178e-02],\n        [-1.2884e-01, -5.4574e-02, -3.9981e-02,  6.7325e-02,  2.5765e-02,\n         -2.9759e-02, -1.4343e-01, -1.4666e-01,  4.3951e-02, -3.4215e-02,\n         -8.9262e-02, -3.7181e-02, -1.1671e-02, -8.8175e-02,  6.3734e-02,\n          1.1786e-02, -1.4464e-01,  1.6779e-01, -2.3996e-02,  1.1767e-01,\n         -9.2730e-02,  1.4731e-01,  6.9035e-02,  1.9003e-02,  6.9007e-02,\n         -1.5186e-01,  1.4474e-01,  1.3723e-01, -5.5794e-02, -3.7001e-02,\n          1.3982e-01, -1.4760e-01],\n        [ 1.6853e-01, -9.9095e-02, -8.0528e-02, -1.0777e-02,  1.0795e-02,\n          7.3910e-02, -5.6132e-02, -5.5759e-02, -9.7950e-02,  5.3793e-02,\n         -1.2972e-01, -1.0353e-01,  7.6633e-02,  8.9488e-02,  1.1286e-01,\n         -1.2751e-01,  1.4635e-01, -1.1829e-01,  1.3305e-01,  1.7674e-01,\n         -1.3877e-01, -8.6639e-02,  6.3643e-02, -1.2526e-01, -1.4399e-01,\n          1.4677e-01,  1.1793e-01, -1.6254e-01,  7.0708e-02,  1.7528e-01,\n         -5.0591e-04, -1.5476e-01],\n        [-1.2872e-01,  1.1990e-03, -5.1346e-02,  1.6491e-01,  3.0828e-02,\n         -5.0980e-02,  8.7348e-02,  1.5348e-01,  7.6503e-02, -2.4183e-02,\n         -8.1637e-02, -6.1647e-02, -6.9638e-02, -7.5008e-02, -1.0620e-01,\n         -1.0652e-01, -3.3691e-02, -9.0300e-02,  6.9386e-02,  1.3274e-01,\n          1.3190e-01, -4.2617e-02,  5.1600e-02,  1.2270e-01, -1.3758e-01,\n          1.7281e-01, -5.0092e-03,  1.0153e-01, -3.8104e-02,  1.4305e-03,\n         -1.1610e-01,  1.1332e-02],\n        [-1.5410e-02,  1.3949e-01, -1.9999e-02,  3.6308e-02,  5.8211e-02,\n         -1.3315e-01,  7.4597e-02,  3.8237e-02,  6.4056e-02,  1.5401e-01,\n          4.6219e-02,  9.5342e-03, -9.0099e-03, -6.3926e-02, -1.6307e-01,\n          1.3796e-01,  1.2892e-01,  5.7929e-02,  1.6411e-01,  7.6310e-02,\n          6.7774e-02, -1.0729e-01, -9.6507e-02, -4.6825e-02,  1.0124e-01,\n         -1.6025e-01,  1.2059e-01, -1.6373e-01,  1.1301e-01,  6.9614e-02,\n          1.1992e-01,  1.6452e-01],\n        [ 1.6623e-01,  9.8014e-02, -2.5450e-02, -1.3645e-01,  2.8750e-02,\n          1.6872e-01,  5.8751e-03,  1.4937e-01,  1.4463e-01, -2.4773e-02,\n         -6.9113e-02,  5.5044e-02, -1.7168e-01,  1.5935e-02,  1.5719e-01,\n         -1.2077e-01,  1.5062e-01,  1.3908e-01,  1.7020e-01,  1.0340e-01,\n         -3.9134e-02, -1.4274e-01, -1.7600e-01, -1.5649e-01,  1.0581e-01,\n         -1.5008e-01, -1.8567e-02, -1.3510e-01,  2.4813e-02,  1.1785e-01,\n         -3.6379e-02,  6.4221e-02],\n        [ 8.3358e-02,  4.9502e-02,  5.7297e-02,  6.9451e-02,  2.9784e-02,\n         -5.0499e-02, -3.2812e-03,  6.1142e-02,  6.0711e-02,  5.7506e-02,\n          8.3422e-02, -1.1757e-01, -9.6999e-02, -7.7698e-02,  7.7458e-03,\n          1.7665e-01, -7.3873e-02,  3.5346e-02, -3.0172e-02, -2.6065e-02,\n          8.3751e-02, -6.4340e-02,  2.4358e-02,  1.6662e-01,  1.7545e-01,\n         -1.1232e-01,  9.2348e-02, -5.1958e-02, -5.2196e-02,  1.0991e-01,\n         -1.3614e-01, -1.5349e-01],\n        [ 9.0108e-02,  1.2901e-01,  1.4482e-01, -1.2822e-01,  9.7382e-02,\n         -7.6161e-02, -1.2533e-01, -4.7606e-02, -1.1249e-02,  3.4725e-02,\n         -7.1165e-03, -9.7920e-02,  1.0047e-01,  1.3653e-01, -3.7353e-02,\n          1.2068e-01, -1.7247e-01,  1.6898e-01,  1.0059e-01,  3.8982e-02,\n         -2.0147e-03,  1.4894e-01, -1.7114e-01, -1.1145e-01, -1.1892e-01,\n         -9.8825e-02, -9.2503e-02,  9.7811e-03,  1.7077e-01,  1.8988e-02,\n         -1.7574e-01, -7.6814e-02],\n        [-2.1166e-02, -1.1559e-02,  1.2646e-01,  1.5783e-01,  4.8350e-02,\n         -1.2449e-02, -1.3630e-01, -1.7611e-01,  9.5571e-02,  3.2429e-02,\n         -7.4512e-02, -8.4564e-02, -1.6748e-01, -3.8511e-02,  1.4794e-03,\n          2.6918e-02,  1.2053e-01,  1.0576e-01,  8.5330e-02, -1.3701e-01,\n          1.4750e-02,  1.6855e-01,  1.6348e-01, -1.5295e-01, -3.4297e-03,\n         -1.7150e-01,  3.4115e-02, -1.6426e-01, -4.2432e-02,  1.4354e-01,\n          1.2138e-01,  9.0711e-02],\n        [-2.3134e-03,  1.4554e-01, -1.0049e-01,  1.0086e-01, -9.4590e-02,\n         -2.2997e-02,  1.1834e-01, -1.7329e-02,  1.4900e-01, -7.8208e-02,\n         -1.6834e-01,  3.6105e-02, -8.9362e-02, -1.6744e-01, -8.0712e-02,\n          9.5961e-02, -1.6384e-01, -5.6840e-02, -8.8068e-02,  1.6244e-01,\n          1.7613e-01, -1.0684e-02, -1.7014e-01,  4.5004e-03,  1.4411e-01,\n          3.6583e-02,  6.7129e-02, -1.5835e-01, -1.1038e-01,  6.3437e-02,\n         -2.5650e-02,  3.5425e-03],\n        [-2.7552e-02, -4.2606e-02, -1.5928e-01, -8.4393e-02, -1.6985e-01,\n         -1.3582e-01, -1.2262e-01,  9.7753e-02,  1.6289e-01,  6.0507e-02,\n         -4.8029e-02, -7.7112e-02, -1.7947e-02,  1.5076e-01,  1.0131e-01,\n          5.1513e-03, -1.1787e-01, -1.5196e-01,  1.7474e-01,  1.4630e-01,\n         -4.1173e-02, -1.6931e-02, -1.6005e-01,  6.7925e-02, -5.0200e-02,\n          8.7517e-02,  1.6180e-01, -4.1837e-02,  1.7630e-01,  3.4539e-02,\n         -9.8511e-02, -4.7933e-02],\n        [ 2.2178e-02,  2.0116e-02,  1.0430e-01,  1.2856e-01, -1.8386e-02,\n          3.8701e-02, -9.4662e-02,  1.1448e-01,  7.5358e-02, -1.3126e-01,\n          4.1239e-03,  9.9264e-02,  7.0162e-02,  1.6948e-01, -7.8539e-03,\n          3.7932e-06,  1.7348e-01, -7.1111e-02, -8.8217e-02,  6.0758e-02,\n         -1.6751e-01,  5.7362e-02, -1.0533e-01, -9.4425e-02,  5.1138e-02,\n         -1.2348e-01,  8.7097e-02, -1.7381e-01, -2.6998e-02,  5.9534e-02,\n         -1.4124e-01, -1.7074e-01],\n        [ 9.7067e-02,  4.5399e-02,  1.3678e-01,  2.2794e-02,  1.0633e-01,\n         -1.4194e-01,  1.1189e-01, -1.1401e-01, -4.9016e-02, -1.0058e-01,\n          8.1032e-02, -3.8216e-02, -8.2229e-02,  1.4403e-01, -1.0759e-01,\n         -1.0574e-01, -1.5317e-01, -2.8725e-02, -4.1362e-03,  3.2115e-02,\n          8.3424e-02,  1.7451e-01, -1.3688e-02,  1.3221e-01, -5.1602e-02,\n         -1.7555e-01, -1.1932e-01,  1.6387e-01, -3.8277e-02,  8.0032e-02,\n          7.0142e-03,  1.6911e-03]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2195,  0.0457, -0.1132,  0.1258,  0.0295,  0.0300, -0.0475,  0.2490],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.2421,  0.1539,  0.1716,  0.0776,  0.1043, -0.1855,  0.2477,  0.2444,\n         -0.0244,  0.0780,  0.0097,  0.1128,  0.2304,  0.1607, -0.1072,  0.1442],\n        [ 0.2279, -0.0397, -0.0918, -0.2431,  0.1234, -0.2049,  0.2207,  0.1832,\n          0.2427, -0.1059, -0.2159, -0.0370, -0.0821, -0.0523,  0.1900, -0.1147],\n        [-0.0183, -0.1777, -0.2050,  0.0754, -0.0191, -0.1912,  0.1534, -0.1864,\n          0.0740, -0.2023,  0.0863, -0.0858,  0.2462, -0.1635,  0.0856,  0.2463],\n        [-0.1852, -0.0067,  0.1431, -0.1741, -0.1828,  0.1274, -0.2466,  0.1592,\n          0.0197, -0.0909,  0.1606,  0.0044,  0.2151, -0.2335, -0.1368, -0.0733],\n        [-0.0083, -0.0287, -0.0185, -0.0618,  0.1453,  0.2108, -0.0404, -0.0739,\n         -0.2156,  0.0108, -0.1416,  0.2321, -0.0166,  0.1689, -0.1127, -0.1443],\n        [ 0.0672,  0.2437,  0.0656, -0.0532,  0.1839, -0.1138,  0.0544,  0.1985,\n          0.2108,  0.0732, -0.0356,  0.1828, -0.2036, -0.0952,  0.0815, -0.1785],\n        [ 0.1008, -0.0528,  0.2345, -0.0093, -0.0108,  0.0699,  0.0815,  0.1652,\n         -0.0140, -0.0552,  0.0047,  0.0408,  0.0284, -0.0931, -0.1128, -0.0583],\n        [ 0.2321, -0.0273, -0.0570, -0.0588, -0.1551, -0.0489,  0.2327, -0.1495,\n         -0.2427,  0.2344, -0.1480, -0.1953,  0.0629,  0.1337,  0.1102,  0.0851]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0453], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.3276,  0.3331, -0.1958, -0.2211, -0.2092, -0.0618, -0.1672, -0.1116]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    1024,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	1024,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "flatten_obs_dim":	1024,
                    "kernel_dim":	8,
                    "kernel_size":	128,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2476, -0.1886,  0.1159,  0.2788, -0.2146, -0.1047, -0.1808, -0.0807],\n        [ 0.1164, -0.1042,  0.2132, -0.1614, -0.1816, -0.2258, -0.2342, -0.3223],\n        [-0.1791,  0.0248,  0.3012,  0.2631, -0.0790,  0.1213, -0.3041,  0.2020],\n        [-0.1366, -0.2400,  0.2920, -0.1741,  0.2378,  0.3380, -0.0983,  0.2516],\n        [ 0.1310,  0.2997,  0.2402, -0.1553,  0.1394, -0.2134,  0.1758, -0.0332],\n        [ 0.0737,  0.1087,  0.2097,  0.0361, -0.1592, -0.1052, -0.1542, -0.2552],\n        [-0.3467,  0.1932,  0.0674, -0.2378,  0.0642, -0.0976, -0.3375,  0.1941],\n        [-0.2893,  0.3084,  0.1483, -0.1608, -0.2318,  0.0016, -0.0204, -0.1978],\n        [-0.0023,  0.2411,  0.0254,  0.2281,  0.0319, -0.2739,  0.2272, -0.2319],\n        [ 0.0503,  0.1930,  0.2253,  0.2996, -0.2607, -0.0163, -0.0807,  0.3245],\n        [ 0.0841,  0.0854,  0.1956,  0.3346, -0.0114,  0.3450,  0.1022,  0.1345],\n        [-0.2447, -0.2782, -0.2740, -0.2688, -0.1258, -0.0339, -0.2890,  0.0787],\n        [ 0.2741,  0.2703, -0.2080, -0.0006, -0.2270, -0.2071, -0.1116,  0.2419],\n        [ 0.3014, -0.0783,  0.2513, -0.0963, -0.3001,  0.1074,  0.0257, -0.2635],\n        [ 0.3530,  0.1266, -0.0053, -0.2225, -0.3397,  0.2496,  0.3021, -0.1853],\n        [ 0.1812, -0.0571, -0.2680, -0.2880,  0.3156, -0.3302, -0.0707, -0.3354],\n        [ 0.0754,  0.1559,  0.1687, -0.3187, -0.2312,  0.0096, -0.3247,  0.1829],\n        [-0.1625,  0.1277,  0.2001, -0.2544, -0.0322,  0.1732,  0.0669, -0.0868],\n        [-0.2382,  0.3287,  0.0228, -0.1747,  0.0625, -0.1339, -0.1452, -0.0473],\n        [-0.2649,  0.2240,  0.0787,  0.3452, -0.2458, -0.0872,  0.0414, -0.2538],\n        [-0.3131,  0.1855,  0.0593,  0.0256,  0.2553, -0.1571,  0.1281,  0.0729],\n        [ 0.1654,  0.2026, -0.1493, -0.0590,  0.3484, -0.0116,  0.0082, -0.0838],\n        [ 0.1964,  0.1982, -0.1448, -0.3454, -0.1230,  0.0236, -0.1380, -0.2526],\n        [-0.0833,  0.2897, -0.0269, -0.0638,  0.0716,  0.1648,  0.0170,  0.1988],\n        [-0.1306, -0.3291,  0.2243, -0.2659, -0.2095, -0.2883, -0.2058,  0.1504],\n        [ 0.0805,  0.0785,  0.0769, -0.3382,  0.2470,  0.0102, -0.2384, -0.0265],\n        [ 0.2072,  0.2458, -0.0880, -0.1773,  0.3183, -0.0374,  0.0054, -0.3299],\n        [ 0.2407, -0.1898,  0.1732, -0.2651, -0.1932, -0.2607, -0.0359, -0.2519],\n        [ 0.2062, -0.2462, -0.2475,  0.0191,  0.2663, -0.0645,  0.3498, -0.3344],\n        [ 0.1129, -0.0958,  0.3192,  0.2618, -0.2136,  0.1680, -0.0975, -0.2491],\n        [-0.0774,  0.0244, -0.0298, -0.1872,  0.3474,  0.2479, -0.2563, -0.2847],\n        [ 0.1289, -0.2055,  0.2488, -0.3420,  0.2000,  0.2884,  0.2988,  0.0040]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1560, -0.2921, -0.0224, -0.3473, -0.1116,  0.0241, -0.1478, -0.1765,\n         0.2992, -0.3246,  0.1763, -0.1203, -0.2425, -0.0311, -0.0618,  0.3343,\n         0.3194,  0.1294, -0.0955,  0.3333,  0.2079,  0.3032,  0.2093, -0.0912,\n        -0.3262, -0.3278,  0.0119, -0.0978, -0.2570, -0.0337, -0.2190, -0.1171],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 4.1647e-02,  1.6035e-01, -2.1305e-02,  8.4870e-02, -1.5885e-01,\n          1.4578e-01, -3.9774e-04,  6.7317e-02,  1.4131e-01,  4.9132e-02,\n         -7.0562e-02, -9.2011e-02,  1.7660e-01, -1.2955e-01, -1.6784e-01,\n         -1.3769e-01, -5.5908e-02,  1.5237e-02, -1.6925e-01,  1.1554e-01,\n          1.4272e-01,  1.5525e-01, -1.7459e-02, -4.8790e-02,  9.1112e-02,\n         -1.8258e-02,  6.1978e-02, -1.0943e-02, -1.3667e-01,  9.9537e-02,\n          5.4558e-03,  1.0324e-01],\n        [-3.9383e-02, -3.6017e-02,  3.3358e-02, -6.7613e-02, -1.1140e-02,\n         -1.2868e-01, -6.1677e-02,  1.7649e-01,  4.3806e-02, -9.8097e-02,\n         -3.9718e-02,  1.6668e-01, -4.5951e-02, -1.1965e-01, -8.4595e-04,\n          1.3980e-04,  2.2322e-02, -3.9571e-02,  4.3613e-02,  1.4647e-01,\n          1.7082e-02, -7.7736e-02,  1.1343e-01,  8.9823e-02, -1.6228e-01,\n         -1.7285e-01, -5.3562e-02, -1.3685e-01, -1.5494e-01, -1.0740e-01,\n          1.4125e-01, -1.7577e-01],\n        [-1.5539e-01,  5.4190e-02, -4.8708e-02, -1.1247e-02, -9.4360e-02,\n          1.7077e-01, -1.4753e-01,  1.6786e-01, -7.0694e-02, -1.5351e-01,\n         -1.3582e-01, -2.5551e-02,  3.7494e-02,  1.3079e-01,  1.6636e-01,\n         -4.4788e-02, -4.1857e-02,  8.7537e-04,  1.4121e-01,  2.2743e-02,\n          1.2428e-02, -1.4949e-01, -4.3265e-02, -2.7895e-02,  3.4472e-02,\n          5.2597e-02, -1.0431e-01,  1.0872e-01,  1.0768e-01,  7.2897e-02,\n          6.0149e-02,  1.1456e-01],\n        [ 3.9772e-02, -1.1931e-01, -6.6175e-02,  1.4103e-01,  5.6880e-02,\n          2.6731e-03, -1.7592e-01,  7.0164e-02,  8.7307e-02,  2.7082e-02,\n          6.7795e-02,  2.6595e-03, -6.5901e-02, -8.4725e-02, -1.3532e-01,\n          1.2781e-01, -8.3171e-02, -1.3306e-01, -1.6699e-02, -4.7624e-02,\n          1.4620e-01, -5.4856e-02,  1.5607e-01, -1.1362e-01, -9.1148e-02,\n          4.6241e-02,  1.3238e-02,  1.0971e-01, -1.3246e-01, -1.5036e-01,\n         -6.9379e-02,  1.1378e-02],\n        [-1.9516e-02,  1.5732e-01,  1.6062e-01, -1.5930e-01,  7.1281e-02,\n          1.2395e-02,  5.7842e-02,  8.1062e-02,  3.5221e-02,  5.3110e-02,\n         -9.9947e-02, -1.3843e-01,  1.7244e-01, -7.7786e-03,  2.2631e-02,\n          4.3751e-04, -3.9968e-02,  1.5417e-01,  8.1748e-02, -1.4580e-01,\n         -9.6466e-02,  1.1633e-01,  1.7711e-02,  1.3484e-01,  3.0379e-02,\n         -8.5216e-02, -6.2080e-02, -2.4941e-02, -3.0998e-02,  1.3378e-01,\n         -7.2126e-02, -1.5094e-01],\n        [ 3.7834e-02, -6.8592e-02,  1.1424e-01,  1.2787e-01,  1.7347e-01,\n          9.6012e-02,  5.9530e-02,  1.4952e-01, -6.5617e-02, -9.9903e-02,\n          2.3210e-02, -1.0026e-01,  2.6904e-02, -5.5537e-02, -2.6461e-03,\n          5.3050e-02,  1.3919e-01, -1.3249e-01, -7.8293e-03,  7.4893e-02,\n         -5.9665e-02,  1.4133e-01, -3.4742e-02,  1.6011e-01, -3.1486e-02,\n          1.7043e-01, -1.1220e-01,  1.7184e-01, -2.6014e-02, -1.3655e-01,\n          1.3428e-01,  7.7826e-03],\n        [-1.6753e-01,  4.2632e-05, -1.1375e-01,  4.2070e-02,  1.0189e-01,\n         -5.4275e-02,  1.1735e-01,  4.4455e-02,  6.2150e-02, -1.2221e-01,\n         -1.0520e-01,  6.0462e-02,  1.0114e-03, -1.5387e-01, -8.9577e-02,\n          7.5433e-02, -6.9638e-02,  1.3783e-01,  2.8586e-02,  1.6751e-02,\n          1.0632e-02,  6.1348e-02, -1.8170e-02, -1.1703e-01, -1.3351e-01,\n          1.6860e-01, -5.6484e-02, -1.6982e-01, -1.1162e-01, -7.5076e-02,\n         -3.1818e-02,  2.9705e-02],\n        [ 1.4348e-01,  8.8364e-03, -1.4615e-01,  8.0357e-02, -3.0535e-02,\n         -2.6287e-02, -1.0529e-01, -9.7311e-02,  1.4671e-01, -6.5521e-02,\n         -1.3353e-01,  1.3367e-01, -1.5778e-01, -6.2489e-03,  5.4058e-02,\n          1.3790e-01, -2.8493e-02, -1.4677e-01, -6.2032e-02, -3.1786e-02,\n          1.1499e-01,  8.7319e-02, -1.0422e-01,  1.6259e-01,  6.8474e-02,\n          1.4768e-01,  3.7146e-02,  1.3068e-02,  1.2677e-01,  4.7550e-03,\n          1.0220e-01,  4.6152e-02],\n        [-4.4950e-02,  1.1988e-01,  4.7209e-02,  1.0178e-01, -6.2769e-02,\n          1.8937e-02,  5.2356e-02, -9.5389e-02,  2.6316e-02,  1.5999e-01,\n          1.2802e-01, -4.9265e-02,  1.3405e-01, -1.1158e-02,  9.0329e-02,\n          1.3028e-01,  1.7609e-01,  7.1621e-02,  1.0086e-01, -1.1305e-01,\n         -7.5436e-02,  1.1302e-01, -1.9524e-02, -9.0030e-02, -9.8985e-02,\n          1.3191e-01, -1.6764e-01,  2.3178e-02,  1.2921e-01,  6.0553e-02,\n         -9.4373e-02, -2.7628e-02],\n        [ 4.3625e-02,  1.5712e-01,  3.8892e-02,  1.4972e-01,  1.4142e-01,\n          6.8838e-03, -6.1014e-02,  1.5543e-01,  1.0873e-02,  9.7147e-02,\n          1.3568e-01,  6.4948e-03, -1.3613e-01,  1.3898e-02, -1.0039e-01,\n          8.1286e-02,  1.1721e-01, -1.2172e-01, -2.1361e-02,  1.6942e-01,\n         -4.4073e-02, -1.2329e-01, -1.7062e-01,  2.5269e-02, -1.7343e-01,\n          1.7563e-01, -1.8479e-02,  7.3145e-02,  1.2453e-01,  6.3337e-02,\n          1.5879e-01, -4.8315e-02],\n        [ 1.0483e-01, -7.3237e-02, -5.4846e-02,  8.8853e-02,  7.4899e-02,\n          1.4784e-01,  2.8238e-02,  5.3977e-02,  1.1641e-01, -3.3653e-02,\n          1.7160e-01, -1.2864e-01,  8.7438e-02, -1.3128e-01,  6.6025e-02,\n          1.0833e-01, -1.9750e-02,  1.3347e-01,  6.2635e-02,  4.1853e-02,\n          6.2816e-02,  1.2863e-01,  6.4069e-02,  1.7465e-01, -1.3649e-01,\n          2.5337e-02, -1.6409e-01,  2.8257e-02, -1.3135e-01, -1.1293e-01,\n         -2.6723e-02, -1.5576e-01],\n        [ 1.6640e-01,  4.6438e-02, -1.2149e-01,  4.8235e-02,  1.7672e-01,\n         -1.2288e-01, -7.5178e-02, -1.5706e-01,  3.9111e-02, -9.1310e-02,\n         -9.3300e-02, -1.6414e-01, -1.5143e-01,  2.1757e-02, -1.6243e-01,\n         -1.6200e-01,  7.2986e-02,  9.2668e-03,  1.0308e-01,  7.0374e-02,\n          1.1716e-01,  6.6706e-02,  1.0612e-02,  1.7212e-01,  1.4103e-01,\n         -7.1639e-02, -3.9920e-02,  1.4492e-01,  2.6792e-02,  5.9701e-02,\n          1.1798e-01,  1.4504e-02],\n        [ 5.8086e-02,  4.0380e-02, -6.4925e-02, -1.5740e-01, -1.8329e-03,\n         -1.6764e-01,  1.6965e-01, -7.4000e-03, -1.3025e-01, -4.8647e-02,\n          5.0247e-02, -6.7325e-02,  3.8936e-02, -1.0820e-01,  1.4755e-01,\n          8.8428e-02,  1.1984e-01,  4.7830e-03, -1.2126e-01,  1.5404e-01,\n         -2.3783e-02, -9.5248e-02,  1.6648e-01,  1.6692e-01, -6.8821e-02,\n          5.1506e-02,  1.3561e-01, -4.0604e-02,  5.5772e-02,  3.0859e-03,\n          7.4898e-02, -3.9311e-02],\n        [ 1.4107e-01, -1.1026e-01, -3.7201e-02,  4.7706e-02, -4.0596e-02,\n         -1.7494e-02, -1.7037e-01, -5.8887e-02, -7.5702e-02, -5.4088e-02,\n          1.2009e-01,  1.2632e-01,  1.4620e-01,  6.1895e-03,  1.5141e-01,\n         -4.8470e-02, -7.1953e-02, -5.6317e-02, -4.4159e-02,  1.2148e-01,\n         -1.2938e-01, -7.3015e-03, -1.6849e-01,  1.1341e-01,  5.8158e-02,\n          1.6725e-01,  4.1735e-02,  6.0755e-02,  1.9178e-02,  1.2584e-01,\n         -8.5909e-02,  1.6140e-01],\n        [-5.1169e-02,  3.4692e-03, -1.6195e-01,  1.6685e-01,  7.7186e-02,\n          1.5028e-01,  3.1161e-02, -9.5775e-02, -1.6804e-01,  3.1146e-02,\n          1.4299e-01,  1.1310e-01, -1.7054e-01, -4.8454e-02, -5.4319e-02,\n          8.4432e-02, -1.0037e-01,  1.3182e-01,  1.2710e-01, -6.8022e-02,\n         -3.3820e-02,  8.1155e-02,  9.2616e-03, -1.0127e-01,  2.9118e-02,\n          7.6212e-02, -4.1506e-02, -2.9196e-02, -8.3120e-02, -1.6789e-01,\n         -1.9139e-02, -1.4155e-02],\n        [-2.1653e-02,  1.2940e-01, -1.7199e-01, -3.0341e-02, -4.7298e-03,\n         -8.9336e-02,  5.9661e-02, -8.9739e-04,  1.3552e-01, -1.6857e-01,\n         -1.1854e-01, -1.4167e-01, -1.5219e-01,  7.5525e-03,  4.7610e-02,\n         -1.3641e-01, -2.6688e-02,  7.0043e-02, -7.3405e-02,  1.3670e-01,\n          1.1290e-01,  3.6697e-02,  1.1468e-01,  2.2403e-02,  5.4533e-02,\n         -5.5878e-02, -5.1196e-02, -6.5312e-02,  1.2508e-01, -9.5876e-02,\n          2.5232e-03,  2.9205e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0185, -0.0557, -0.0546, -0.0736, -0.1601,  0.1395,  0.0269,  0.0100,\n         0.0873, -0.1194, -0.0040,  0.0262, -0.0495,  0.0339, -0.0765, -0.0290],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2305,  0.1134,  0.0400, -0.1390,  0.1672,  0.1402,  0.1459, -0.1162,\n         -0.1345,  0.0915, -0.0117,  0.1699, -0.1190,  0.1223,  0.1063,  0.2036],\n        [-0.0790,  0.1889,  0.2368,  0.0800,  0.1789,  0.0166, -0.1984, -0.0087,\n          0.2182, -0.1606, -0.1777,  0.0348, -0.0689, -0.1849, -0.0024,  0.0657],\n        [ 0.1111, -0.0968, -0.1220, -0.1153,  0.1227,  0.1040, -0.1669,  0.1323,\n         -0.0439, -0.1446, -0.1760, -0.0547, -0.2057, -0.1583, -0.1270, -0.2296],\n        [-0.1448, -0.0880, -0.0074, -0.1546,  0.1458, -0.0040, -0.1301, -0.1842,\n          0.0649,  0.2384,  0.2277, -0.1271,  0.1442,  0.1486, -0.1967, -0.2265],\n        [ 0.1014,  0.1305, -0.0186, -0.0381,  0.2354,  0.0375, -0.2418,  0.1348,\n         -0.0737,  0.2390,  0.2364, -0.0281,  0.1485,  0.1461,  0.0306, -0.2313],\n        [-0.1727, -0.1876,  0.1079,  0.1510,  0.1759,  0.2048, -0.1739,  0.1792,\n          0.1330, -0.2282,  0.0113,  0.2120,  0.2217, -0.1458,  0.0105,  0.0051],\n        [-0.0589, -0.2294, -0.0722,  0.0384,  0.1857, -0.2001,  0.1787,  0.0051,\n         -0.1616, -0.0752,  0.2453, -0.0688, -0.0588, -0.0864, -0.2070,  0.2289],\n        [ 0.1107,  0.0620,  0.2166, -0.2153, -0.0198, -0.0039, -0.1417, -0.2159,\n          0.0478,  0.2219,  0.1035, -0.1144, -0.1828, -0.1962,  0.0679,  0.0385]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0122,  0.1044, -0.2005,  0.0488, -0.1448, -0.0233,  0.0681,  0.2210],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0246,  0.1908,  0.3296, -0.2382, -0.2666,  0.2573, -0.3195, -0.2657]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0450], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x7f95a5c0a200>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	25600,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "max_size":	25600,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	80,
            "_train_v_iters":	80,
            "_traj_per_epoch":	3,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.001,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.001,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0268,  0.0055, -0.0152,  ..., -0.0124,  0.0171, -0.0233],\n        [ 0.0094,  0.0234,  0.0260,  ...,  0.0076, -0.0257, -0.0182],\n        [ 0.0270,  0.0088, -0.0282,  ...,  0.0039,  0.0084,  0.0168],\n        ...,\n        [ 0.0255, -0.0194, -0.0021,  ..., -0.0252, -0.0150,  0.0185],\n        [-0.0045, -0.0265,  0.0309,  ..., -0.0050,  0.0273, -0.0179],\n        [ 0.0120,  0.0230, -0.0114,  ...,  0.0186, -0.0268,  0.0271]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-2.6524e-02, -3.2746e-04, -2.4051e-02, -2.5097e-02,  5.1652e-03,\n         1.2711e-02,  8.4117e-04, -1.6363e-02, -2.0060e-02,  3.1130e-02,\n         7.3638e-03,  2.3555e-02,  8.7640e-03, -7.8843e-03, -7.1668e-03,\n        -1.8598e-02,  1.7395e-02,  2.0071e-02, -3.1173e-02, -7.7787e-03,\n         2.2320e-03, -1.5629e-02,  1.4206e-02, -2.0300e-02,  2.4506e-02,\n        -1.7868e-02,  2.0543e-02, -8.5423e-03, -6.3393e-05,  1.1546e-02,\n        -2.3652e-02, -1.6507e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 9.7794e-02,  1.5208e-01, -1.3775e-01,  1.4504e-01, -1.4282e-01,\n         -3.5963e-02,  1.3008e-01,  3.8280e-02, -5.2539e-02, -1.3265e-01,\n         -1.3608e-02, -1.4107e-01,  1.4034e-01, -8.7892e-02, -1.7365e-01,\n          1.0245e-01,  4.2052e-02, -4.3972e-02,  1.7421e-03,  4.9779e-02,\n          4.1438e-02, -1.3759e-01,  8.1018e-02, -2.2271e-03,  1.4969e-01,\n         -1.7589e-01, -2.5393e-02,  1.5195e-01,  5.0336e-02, -1.9349e-02,\n          6.3909e-02,  1.7404e-02],\n        [-1.0396e-01,  2.7618e-02, -6.6561e-02,  1.1719e-01, -4.6799e-02,\n          2.8357e-02, -2.8377e-02, -5.6475e-02, -3.0590e-02, -1.2480e-01,\n          3.3299e-02, -9.9071e-02, -8.2902e-02,  8.7268e-02, -3.7530e-02,\n          1.6867e-01,  1.4618e-01,  8.5021e-02, -3.9079e-03,  1.3624e-01,\n          1.7149e-01,  3.6595e-03, -1.1561e-01,  1.3909e-01, -1.7254e-02,\n          6.9265e-02, -1.4981e-01,  5.9257e-02, -1.4726e-02,  6.0793e-02,\n         -5.9069e-02, -1.0079e-01],\n        [-1.2614e-01,  1.3369e-01, -1.4640e-01, -4.2076e-02,  4.3656e-02,\n          1.0766e-01,  4.6622e-02, -1.5644e-01,  1.6261e-01,  4.9555e-02,\n          7.2820e-02, -1.3570e-01, -6.9629e-02, -6.7757e-02, -1.1710e-01,\n         -6.7087e-02, -9.5283e-02, -1.0483e-01, -1.8998e-02,  4.4994e-02,\n          1.4700e-01,  1.5551e-01,  6.6997e-03,  2.1516e-02,  1.1263e-01,\n         -6.9555e-04,  1.0694e-01,  7.7948e-02, -7.4191e-02,  1.6025e-01,\n          1.8605e-02, -1.1111e-01],\n        [ 1.3882e-01, -6.7094e-02, -9.5622e-02, -6.7081e-02, -6.0496e-02,\n         -9.2986e-02, -1.0620e-02,  4.5788e-03,  8.0851e-02, -1.3865e-01,\n          1.1988e-01, -1.5705e-01, -8.1861e-02,  9.7948e-03,  1.2201e-01,\n         -1.2066e-01,  1.0285e-01, -1.2623e-01,  1.0931e-01,  7.9000e-02,\n          1.1762e-01,  1.7327e-01,  5.3089e-02, -9.8514e-02,  1.1732e-01,\n         -7.9398e-02, -4.2618e-03,  1.4815e-01, -9.9365e-02, -1.1905e-01,\n          1.1710e-01,  5.0178e-02],\n        [-1.2884e-01, -5.4574e-02, -3.9981e-02,  6.7325e-02,  2.5765e-02,\n         -2.9759e-02, -1.4343e-01, -1.4666e-01,  4.3951e-02, -3.4215e-02,\n         -8.9262e-02, -3.7181e-02, -1.1671e-02, -8.8175e-02,  6.3734e-02,\n          1.1786e-02, -1.4464e-01,  1.6779e-01, -2.3996e-02,  1.1767e-01,\n         -9.2730e-02,  1.4731e-01,  6.9035e-02,  1.9003e-02,  6.9007e-02,\n         -1.5186e-01,  1.4474e-01,  1.3723e-01, -5.5794e-02, -3.7001e-02,\n          1.3982e-01, -1.4760e-01],\n        [ 1.6853e-01, -9.9095e-02, -8.0528e-02, -1.0777e-02,  1.0795e-02,\n          7.3910e-02, -5.6132e-02, -5.5759e-02, -9.7950e-02,  5.3793e-02,\n         -1.2972e-01, -1.0353e-01,  7.6633e-02,  8.9488e-02,  1.1286e-01,\n         -1.2751e-01,  1.4635e-01, -1.1829e-01,  1.3305e-01,  1.7674e-01,\n         -1.3877e-01, -8.6639e-02,  6.3643e-02, -1.2526e-01, -1.4399e-01,\n          1.4677e-01,  1.1793e-01, -1.6254e-01,  7.0708e-02,  1.7528e-01,\n         -5.0591e-04, -1.5476e-01],\n        [-1.2872e-01,  1.1990e-03, -5.1346e-02,  1.6491e-01,  3.0828e-02,\n         -5.0980e-02,  8.7348e-02,  1.5348e-01,  7.6503e-02, -2.4183e-02,\n         -8.1637e-02, -6.1647e-02, -6.9638e-02, -7.5008e-02, -1.0620e-01,\n         -1.0652e-01, -3.3691e-02, -9.0300e-02,  6.9386e-02,  1.3274e-01,\n          1.3190e-01, -4.2617e-02,  5.1600e-02,  1.2270e-01, -1.3758e-01,\n          1.7281e-01, -5.0092e-03,  1.0153e-01, -3.8104e-02,  1.4305e-03,\n         -1.1610e-01,  1.1332e-02],\n        [-1.5410e-02,  1.3949e-01, -1.9999e-02,  3.6308e-02,  5.8211e-02,\n         -1.3315e-01,  7.4597e-02,  3.8237e-02,  6.4056e-02,  1.5401e-01,\n          4.6219e-02,  9.5342e-03, -9.0099e-03, -6.3926e-02, -1.6307e-01,\n          1.3796e-01,  1.2892e-01,  5.7929e-02,  1.6411e-01,  7.6310e-02,\n          6.7774e-02, -1.0729e-01, -9.6507e-02, -4.6825e-02,  1.0124e-01,\n         -1.6025e-01,  1.2059e-01, -1.6373e-01,  1.1301e-01,  6.9614e-02,\n          1.1992e-01,  1.6452e-01],\n        [ 1.6623e-01,  9.8014e-02, -2.5450e-02, -1.3645e-01,  2.8750e-02,\n          1.6872e-01,  5.8751e-03,  1.4937e-01,  1.4463e-01, -2.4773e-02,\n         -6.9113e-02,  5.5044e-02, -1.7168e-01,  1.5935e-02,  1.5719e-01,\n         -1.2077e-01,  1.5062e-01,  1.3908e-01,  1.7020e-01,  1.0340e-01,\n         -3.9134e-02, -1.4274e-01, -1.7600e-01, -1.5649e-01,  1.0581e-01,\n         -1.5008e-01, -1.8567e-02, -1.3510e-01,  2.4813e-02,  1.1785e-01,\n         -3.6379e-02,  6.4221e-02],\n        [ 8.3358e-02,  4.9502e-02,  5.7297e-02,  6.9451e-02,  2.9784e-02,\n         -5.0499e-02, -3.2812e-03,  6.1142e-02,  6.0711e-02,  5.7506e-02,\n          8.3422e-02, -1.1757e-01, -9.6999e-02, -7.7698e-02,  7.7458e-03,\n          1.7665e-01, -7.3873e-02,  3.5346e-02, -3.0172e-02, -2.6065e-02,\n          8.3751e-02, -6.4340e-02,  2.4358e-02,  1.6662e-01,  1.7545e-01,\n         -1.1232e-01,  9.2348e-02, -5.1958e-02, -5.2196e-02,  1.0991e-01,\n         -1.3614e-01, -1.5349e-01],\n        [ 9.0108e-02,  1.2901e-01,  1.4482e-01, -1.2822e-01,  9.7382e-02,\n         -7.6161e-02, -1.2533e-01, -4.7606e-02, -1.1249e-02,  3.4725e-02,\n         -7.1165e-03, -9.7920e-02,  1.0047e-01,  1.3653e-01, -3.7353e-02,\n          1.2068e-01, -1.7247e-01,  1.6898e-01,  1.0059e-01,  3.8982e-02,\n         -2.0147e-03,  1.4894e-01, -1.7114e-01, -1.1145e-01, -1.1892e-01,\n         -9.8825e-02, -9.2503e-02,  9.7811e-03,  1.7077e-01,  1.8988e-02,\n         -1.7574e-01, -7.6814e-02],\n        [-2.1166e-02, -1.1559e-02,  1.2646e-01,  1.5783e-01,  4.8350e-02,\n         -1.2449e-02, -1.3630e-01, -1.7611e-01,  9.5571e-02,  3.2429e-02,\n         -7.4512e-02, -8.4564e-02, -1.6748e-01, -3.8511e-02,  1.4794e-03,\n          2.6918e-02,  1.2053e-01,  1.0576e-01,  8.5330e-02, -1.3701e-01,\n          1.4750e-02,  1.6855e-01,  1.6348e-01, -1.5295e-01, -3.4297e-03,\n         -1.7150e-01,  3.4115e-02, -1.6426e-01, -4.2432e-02,  1.4354e-01,\n          1.2138e-01,  9.0711e-02],\n        [-2.3134e-03,  1.4554e-01, -1.0049e-01,  1.0086e-01, -9.4590e-02,\n         -2.2997e-02,  1.1834e-01, -1.7329e-02,  1.4900e-01, -7.8208e-02,\n         -1.6834e-01,  3.6105e-02, -8.9362e-02, -1.6744e-01, -8.0712e-02,\n          9.5961e-02, -1.6384e-01, -5.6840e-02, -8.8068e-02,  1.6244e-01,\n          1.7613e-01, -1.0684e-02, -1.7014e-01,  4.5004e-03,  1.4411e-01,\n          3.6583e-02,  6.7129e-02, -1.5835e-01, -1.1038e-01,  6.3437e-02,\n         -2.5650e-02,  3.5425e-03],\n        [-2.7552e-02, -4.2606e-02, -1.5928e-01, -8.4393e-02, -1.6985e-01,\n         -1.3582e-01, -1.2262e-01,  9.7753e-02,  1.6289e-01,  6.0507e-02,\n         -4.8029e-02, -7.7112e-02, -1.7947e-02,  1.5076e-01,  1.0131e-01,\n          5.1513e-03, -1.1787e-01, -1.5196e-01,  1.7474e-01,  1.4630e-01,\n         -4.1173e-02, -1.6931e-02, -1.6005e-01,  6.7925e-02, -5.0200e-02,\n          8.7517e-02,  1.6180e-01, -4.1837e-02,  1.7630e-01,  3.4539e-02,\n         -9.8511e-02, -4.7933e-02],\n        [ 2.2178e-02,  2.0116e-02,  1.0430e-01,  1.2856e-01, -1.8386e-02,\n          3.8701e-02, -9.4662e-02,  1.1448e-01,  7.5358e-02, -1.3126e-01,\n          4.1239e-03,  9.9264e-02,  7.0162e-02,  1.6948e-01, -7.8539e-03,\n          3.7932e-06,  1.7348e-01, -7.1111e-02, -8.8217e-02,  6.0758e-02,\n         -1.6751e-01,  5.7362e-02, -1.0533e-01, -9.4425e-02,  5.1138e-02,\n         -1.2348e-01,  8.7097e-02, -1.7381e-01, -2.6998e-02,  5.9534e-02,\n         -1.4124e-01, -1.7074e-01],\n        [ 9.7067e-02,  4.5399e-02,  1.3678e-01,  2.2794e-02,  1.0633e-01,\n         -1.4194e-01,  1.1189e-01, -1.1401e-01, -4.9016e-02, -1.0058e-01,\n          8.1032e-02, -3.8216e-02, -8.2229e-02,  1.4403e-01, -1.0759e-01,\n         -1.0574e-01, -1.5317e-01, -2.8725e-02, -4.1362e-03,  3.2115e-02,\n          8.3424e-02,  1.7451e-01, -1.3688e-02,  1.3221e-01, -5.1602e-02,\n         -1.7555e-01, -1.1932e-01,  1.6387e-01, -3.8277e-02,  8.0032e-02,\n          7.0142e-03,  1.6911e-03]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1608,  0.1637, -0.0232, -0.0420,  0.0050,  0.0407, -0.0919,  0.1632,\n        -0.0663, -0.0110, -0.1597,  0.0773,  0.0694,  0.0878,  0.1546, -0.0584],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2421,  0.1539,  0.1716,  0.0776,  0.1043, -0.1855,  0.2477,  0.2444,\n         -0.0244,  0.0780,  0.0097,  0.1128,  0.2304,  0.1607, -0.1072,  0.1442],\n        [ 0.2279, -0.0397, -0.0918, -0.2431,  0.1234, -0.2049,  0.2207,  0.1832,\n          0.2427, -0.1059, -0.2159, -0.0370, -0.0821, -0.0523,  0.1900, -0.1147],\n        [-0.0183, -0.1777, -0.2050,  0.0754, -0.0191, -0.1912,  0.1534, -0.1864,\n          0.0740, -0.2023,  0.0863, -0.0858,  0.2462, -0.1635,  0.0856,  0.2463],\n        [-0.1852, -0.0067,  0.1431, -0.1741, -0.1828,  0.1274, -0.2466,  0.1592,\n          0.0197, -0.0909,  0.1606,  0.0044,  0.2151, -0.2335, -0.1368, -0.0733],\n        [-0.0083, -0.0287, -0.0185, -0.0618,  0.1453,  0.2108, -0.0404, -0.0739,\n         -0.2156,  0.0108, -0.1416,  0.2321, -0.0166,  0.1689, -0.1127, -0.1443],\n        [ 0.0672,  0.2437,  0.0656, -0.0532,  0.1839, -0.1138,  0.0544,  0.1985,\n          0.2108,  0.0732, -0.0356,  0.1828, -0.2036, -0.0952,  0.0815, -0.1785],\n        [ 0.1008, -0.0528,  0.2345, -0.0093, -0.0108,  0.0699,  0.0815,  0.1652,\n         -0.0140, -0.0552,  0.0047,  0.0408,  0.0284, -0.0931, -0.1128, -0.0583],\n        [ 0.2321, -0.0273, -0.0570, -0.0588, -0.1551, -0.0489,  0.2327, -0.1495,\n         -0.2427,  0.2344, -0.1480, -0.1953,  0.0629,  0.1337,  0.1102,  0.0851]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2195,  0.0457, -0.1132,  0.1258,  0.0295,  0.0300, -0.0475,  0.2490],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3276,  0.3331, -0.1958, -0.2211, -0.2092, -0.0618, -0.1672, -0.1116]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0453], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7f95a5c0a020>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-scheduler",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling/./logs/rl4sys-ppo-scheduler/rl4sys-ppo-scheduler_s3383650000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling/./logs/rl4sys-ppo-scheduler/rl4sys-ppo-scheduler_s3383650000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	80,
    "train_v_iters":	80,
    "traj_per_epoch":	3,
    "vf_lr":	0.001
}