{
    "buf_size":	25600,
    "clip_ratio":	0.2,
    "current_dir":	"/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling",
    "exp_name":	"rl4sys-ppo-scheduler",
    "gamma":	0.99,
    "kernel_dim":	8,
    "kernel_size":	128,
    "lam":	0.97,
    "log_data_dir":	"/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-scheduler",
        "output_dir":	"/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling/./logs/rl4sys-ppo-scheduler/rl4sys-ppo-scheduler_s3387240000"
    },
    "pi_lr":	0.0003,
    "seed":	3387240000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x7f41e593df30>":	{
            "_clip_ratio":	0.2,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (dense1): Linear(in_features=8, out_features=32, bias=True)\n    (dense2): Linear(in_features=32, out_features=16, bias=True)\n    (dense3): Linear(in_features=16, out_features=8, bias=True)\n    (dense4): Linear(in_features=8, out_features=1, bias=True)\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=1024, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_pre_hooks":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (dense1): Linear(in_features=8, out_features=32, bias=True)\n  (dense2): Linear(in_features=32, out_features=16, bias=True)\n  (dense3): Linear(in_features=16, out_features=8, bias=True)\n  (dense4): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "dense1":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1004, -0.0445,  0.2165, -0.2823,  0.2697,  0.3224, -0.0542,  0.2300,\n        -0.3472,  0.0404, -0.0632,  0.0642, -0.1888, -0.3299,  0.0519,  0.3040,\n         0.2200,  0.2781,  0.2021,  0.1405, -0.1403, -0.1343,  0.3507, -0.1909,\n        -0.3451,  0.1489,  0.2242,  0.1792,  0.0797, -0.0419,  0.1739,  0.1414],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1937, -0.0761,  0.0513, -0.1674,  0.1910,  0.0083, -0.2362,  0.0298],\n        [-0.1489, -0.3042,  0.1026,  0.1107, -0.1617, -0.2796,  0.2509,  0.2663],\n        [ 0.0551, -0.2806,  0.1373, -0.1020, -0.1289, -0.3032, -0.1272, -0.3463],\n        [-0.0895,  0.2685, -0.1057, -0.3451,  0.0797,  0.0926,  0.0513, -0.2580],\n        [-0.1385, -0.1395,  0.3354, -0.1550,  0.3492,  0.1642, -0.1290,  0.2905],\n        [-0.2393,  0.2441, -0.3215, -0.0020, -0.2311, -0.2526, -0.0552, -0.0618],\n        [ 0.1013,  0.1785, -0.3238,  0.1585,  0.0649,  0.3272,  0.0899,  0.3368],\n        [ 0.1883,  0.2304, -0.1905, -0.1798,  0.1686,  0.2774,  0.1229,  0.3417],\n        [ 0.1506,  0.1883, -0.2429,  0.0304, -0.0955,  0.2669,  0.1548,  0.1922],\n        [-0.1655,  0.2379, -0.1667, -0.2182, -0.0553, -0.1692,  0.0405,  0.1805],\n        [ 0.1350,  0.0980, -0.1050,  0.0143,  0.3219,  0.1859,  0.2231,  0.1958],\n        [ 0.0246,  0.2678, -0.0352, -0.2847,  0.0881,  0.1216,  0.3483,  0.1488],\n        [-0.0708,  0.0490, -0.3403, -0.1733, -0.2129, -0.2616, -0.1048,  0.3514],\n        [-0.2496, -0.2526,  0.2979,  0.2427,  0.0864, -0.1705,  0.1636,  0.1587],\n        [ 0.0836,  0.2536,  0.0188,  0.3317,  0.2943, -0.1212, -0.2804, -0.3452],\n        [-0.0770, -0.2687, -0.3110,  0.0388,  0.0910,  0.1868, -0.0796, -0.0476],\n        [-0.1318, -0.2556,  0.2400, -0.3441, -0.0026, -0.0043,  0.1676, -0.0469],\n        [ 0.0517,  0.0968, -0.0021, -0.0141, -0.0656, -0.2991,  0.2266, -0.2575],\n        [ 0.2066,  0.3291, -0.1897, -0.2776,  0.0062, -0.1612, -0.0815, -0.0712],\n        [-0.0409,  0.1987,  0.0579, -0.1968, -0.1162, -0.3512, -0.1660, -0.0321],\n        [ 0.0455, -0.0175, -0.1648,  0.0976,  0.0356,  0.0631, -0.0456,  0.2730],\n        [ 0.0096,  0.1022,  0.1195,  0.1413, -0.2166,  0.2929, -0.1225,  0.0073],\n        [ 0.0191,  0.1306,  0.1367,  0.1691, -0.1174,  0.0170,  0.2291,  0.3529],\n        [-0.3201, -0.1992, -0.3365, -0.0309,  0.1575,  0.2596, -0.1077, -0.0979],\n        [ 0.2349,  0.0897, -0.0659, -0.0486,  0.0859, -0.2762,  0.2123, -0.1556],\n        [-0.2515, -0.2538,  0.1004, -0.0331, -0.1914,  0.1519,  0.0785, -0.3277],\n        [-0.2636,  0.1127,  0.2270, -0.1657,  0.2221,  0.2161, -0.3077, -0.2029],\n        [ 0.2477,  0.2966,  0.3398, -0.0090,  0.0313, -0.3378, -0.1064,  0.0154],\n        [-0.0240, -0.3035,  0.2979,  0.1160,  0.3323, -0.2350, -0.1001,  0.3482],\n        [ 0.0684,  0.0077,  0.1482,  0.1625, -0.2053, -0.1067,  0.2525,  0.0339],\n        [ 0.0477,  0.2966, -0.2220, -0.1684, -0.0737,  0.2898, -0.2598, -0.3193],\n        [-0.1764,  0.3330, -0.0712,  0.1590,  0.3285,  0.0292,  0.2107, -0.3376]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "dense2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0284, -0.1097, -0.0476, -0.0596, -0.0977, -0.1135,  0.0347, -0.1566,\n        -0.1375,  0.0500,  0.1052, -0.0327, -0.1061, -0.0668, -0.1645, -0.0938],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-6.9675e-03, -1.0034e-01, -1.2372e-01,  1.2000e-01,  1.2646e-01,\n         -6.4586e-02, -5.9865e-02,  1.1854e-01, -1.2928e-01,  1.1652e-01,\n         -1.3285e-01, -1.6592e-01,  1.5080e-01, -9.3838e-03,  8.7217e-02,\n          3.4868e-02,  3.1747e-02, -7.4076e-02,  1.3765e-01,  7.8382e-03,\n          1.4980e-01,  6.6800e-02,  1.0802e-01, -6.0992e-02, -2.1457e-02,\n         -8.8617e-02,  6.6078e-02, -1.4805e-01,  1.5169e-01,  1.2289e-01,\n         -1.1421e-01, -2.6533e-02],\n        [-1.2195e-01,  1.4272e-02,  9.7213e-02, -1.1462e-01, -5.8891e-02,\n         -1.5603e-01, -7.8982e-02, -1.4330e-01, -5.1053e-02, -1.1530e-01,\n          4.7670e-02, -6.0658e-04,  4.8459e-02,  7.6774e-02,  1.2705e-01,\n         -6.9725e-02, -9.6155e-02,  7.0194e-02,  1.4435e-01, -1.0067e-01,\n         -1.6855e-01,  3.6870e-02, -1.2024e-01, -6.4387e-02,  1.4649e-01,\n         -2.0104e-02,  9.6109e-02,  4.1861e-02, -3.6360e-02, -2.3378e-02,\n         -1.0899e-01,  9.1716e-02],\n        [-4.3602e-03, -1.2698e-01,  9.2132e-02,  5.7824e-02, -1.0304e-01,\n          5.3771e-03,  1.7519e-01,  1.3815e-01, -9.0678e-02, -1.5280e-01,\n          7.1428e-02, -8.2667e-02, -2.0860e-02, -3.3671e-02,  8.2118e-02,\n          7.6663e-02, -1.3770e-01, -1.5874e-01,  2.5257e-02,  1.5406e-01,\n          1.5652e-03, -1.6243e-01,  9.6955e-02, -8.4278e-02, -6.3565e-02,\n         -1.1490e-01,  2.2238e-02,  8.5016e-02, -1.1969e-01,  9.6496e-02,\n         -9.0382e-02, -1.0654e-01],\n        [-1.3166e-02,  4.0509e-02,  1.6517e-01, -8.9593e-02, -6.3024e-02,\n         -6.2889e-02,  2.9136e-02,  1.1190e-01,  9.9236e-02,  1.2155e-01,\n         -1.6976e-01,  3.2996e-02, -1.4077e-01,  4.0700e-02,  1.7208e-02,\n         -5.9591e-02, -1.4679e-01,  1.7066e-01,  6.6258e-02,  1.4147e-01,\n          1.2755e-01,  4.9942e-02,  4.6951e-02,  1.2413e-01, -1.7231e-01,\n          9.4166e-02, -6.6174e-02,  1.6792e-01, -4.6263e-02,  1.2570e-01,\n          7.9099e-03,  1.7410e-01],\n        [ 5.5714e-02, -8.6511e-02, -1.7635e-01,  6.4132e-03,  1.0488e-01,\n          1.5430e-03,  1.5315e-01,  1.6404e-02,  1.1056e-01, -1.6184e-01,\n         -1.0630e-01, -9.8978e-02,  1.7084e-01,  1.8931e-02,  6.9309e-02,\n          1.0267e-02,  8.1819e-02,  1.2532e-01, -1.4460e-01,  3.5785e-02,\n          1.1177e-01,  1.6558e-02,  3.9909e-02, -8.3839e-02, -1.1147e-01,\n          7.4958e-02, -7.2828e-02, -2.6730e-02,  1.6838e-02,  5.2683e-02,\n          3.7623e-02, -1.7425e-01],\n        [ 1.3140e-01,  1.0711e-01,  3.9130e-02, -1.0171e-01, -1.2385e-02,\n          5.7801e-02, -1.0679e-01, -4.9821e-02, -6.4209e-02, -8.7100e-03,\n          1.2426e-02,  7.9198e-02, -1.8753e-02,  9.2054e-02, -1.3102e-01,\n          8.9422e-02, -1.6864e-01,  8.7499e-04, -5.5456e-03,  5.2718e-02,\n          7.7625e-02, -5.3244e-02, -1.2143e-01,  7.1178e-02,  8.4364e-03,\n          3.4981e-02,  1.1550e-01, -4.0976e-02, -9.6812e-02,  7.2476e-02,\n         -1.2487e-01,  1.7045e-01],\n        [ 1.5468e-01,  1.0023e-01, -7.7134e-02, -1.1212e-01,  1.6365e-01,\n          7.0778e-02,  1.0259e-01, -1.4991e-01, -3.4858e-02,  2.1376e-02,\n         -3.5020e-02,  7.5488e-02, -1.4290e-01, -7.8608e-02,  9.9928e-02,\n          9.3238e-03,  1.7080e-01,  1.4192e-01, -1.4359e-01, -1.4290e-01,\n          5.7243e-02, -3.5154e-03, -1.7142e-02,  1.6562e-01, -1.2622e-01,\n          7.7778e-02, -9.6702e-02, -4.3008e-02,  1.2155e-01,  1.0994e-01,\n          1.5995e-01, -1.0497e-01],\n        [-1.0093e-02,  1.6319e-01,  1.4856e-01, -1.3882e-01,  1.7234e-01,\n          2.6040e-02,  6.8604e-02, -1.0208e-01,  5.1876e-02,  8.4196e-02,\n          1.1329e-01, -9.4033e-02,  6.2972e-02, -4.2794e-02, -1.6682e-01,\n         -2.4125e-02,  8.6522e-02,  1.0841e-02,  1.3606e-01, -1.1838e-01,\n         -1.5912e-01, -1.5843e-01,  1.0179e-01,  1.7622e-04, -1.1483e-01,\n          1.7224e-01, -2.1632e-02,  1.3678e-01, -1.2137e-01,  1.0702e-01,\n          6.9412e-02,  1.4906e-01],\n        [-2.7142e-02,  1.3744e-01,  4.1725e-02, -1.5987e-01, -5.9596e-04,\n         -6.2665e-02, -1.3787e-03,  7.0284e-02, -1.6747e-01, -3.7372e-02,\n          8.8829e-03, -1.5084e-01, -6.0199e-02, -1.3248e-01, -1.3851e-01,\n          8.0238e-02,  1.4791e-01, -8.5728e-02, -1.2871e-01,  5.1409e-02,\n          2.6201e-02, -1.9731e-02,  9.4479e-02,  7.0204e-02, -5.1371e-02,\n          5.8044e-02,  1.6302e-01,  4.6196e-02,  1.4875e-01, -1.2467e-01,\n         -1.3000e-01, -4.8086e-02],\n        [ 1.9705e-02,  3.6379e-02, -1.3879e-01,  5.8901e-02, -1.2821e-01,\n         -4.2995e-02, -1.5689e-01, -1.5953e-01,  7.4963e-02, -1.7324e-01,\n         -8.1276e-02,  1.6957e-01, -8.0814e-02,  1.6059e-01,  7.4632e-02,\n          9.4171e-02,  9.4284e-02, -1.4353e-01, -1.4770e-01, -9.6643e-02,\n          2.4654e-02, -5.1928e-02, -1.0213e-01,  2.2779e-02, -1.4148e-01,\n         -3.8773e-02, -3.8107e-02, -1.4908e-01,  2.4226e-03, -1.1440e-01,\n          5.3897e-02,  8.4678e-02],\n        [ 1.1372e-01, -1.3865e-01,  9.6416e-02, -1.2586e-01, -4.7046e-02,\n         -3.4046e-02,  4.9299e-02,  1.2860e-01,  9.2210e-02, -2.6247e-02,\n         -1.5734e-01, -1.2204e-01, -8.5152e-02, -1.4394e-01,  1.6626e-01,\n          4.5986e-02, -1.4540e-01,  4.9285e-02,  8.5447e-03,  1.5150e-01,\n          5.6145e-03,  1.3045e-02,  1.4175e-01,  7.0968e-02,  1.1737e-01,\n          1.1114e-02, -1.7380e-01, -6.0730e-02,  1.3469e-01,  1.1629e-01,\n          8.6670e-03,  6.6469e-02],\n        [ 1.0156e-01,  3.6921e-02,  1.3775e-01, -1.5093e-01, -1.3638e-02,\n          1.6935e-01, -1.0499e-01,  2.6178e-02,  3.2718e-02, -4.0552e-02,\n         -8.1838e-02,  1.7498e-01, -5.7838e-02,  5.3655e-02, -3.3793e-03,\n          8.3355e-03,  9.3997e-02, -1.2700e-01, -1.2463e-01,  7.4834e-03,\n         -1.4046e-02,  1.2899e-01,  1.5140e-01, -6.5798e-02,  1.7262e-01,\n          1.7860e-02, -2.4032e-02, -9.8721e-04,  1.3987e-01, -1.3078e-01,\n         -7.1347e-02, -1.6625e-01],\n        [-8.9214e-02, -1.4432e-01,  1.6689e-01, -1.3650e-01, -1.4753e-01,\n         -1.5622e-01,  2.9875e-02,  3.9735e-02,  2.0352e-02,  1.2162e-01,\n          1.2787e-01, -1.7196e-01,  1.8418e-02,  1.1606e-02, -1.3468e-01,\n         -8.4652e-02,  1.0658e-01, -1.7573e-01, -2.9638e-02,  7.2466e-02,\n         -2.6707e-02, -3.8463e-02, -1.4238e-01,  4.3954e-02,  1.4119e-01,\n         -8.4762e-02,  1.7896e-02,  7.1951e-02,  5.0366e-02,  1.5903e-01,\n         -8.1092e-02,  4.1790e-02],\n        [ 1.1826e-01, -6.8503e-03,  1.1698e-01, -2.3458e-03,  1.2016e-01,\n          1.5599e-01, -3.0163e-02,  1.6082e-01, -5.3310e-03,  7.4766e-02,\n          1.7062e-01,  1.3360e-01,  2.7667e-02,  3.3007e-02,  9.6966e-02,\n         -4.6328e-02,  6.4569e-02,  7.6589e-02, -1.3973e-01, -1.7045e-02,\n         -7.3050e-02,  4.4242e-02, -6.4035e-02, -1.6064e-02,  1.2307e-01,\n          1.2695e-01,  7.3289e-02,  9.3357e-03, -1.1127e-01, -1.3962e-02,\n         -1.2681e-01, -6.6032e-02],\n        [-4.0028e-02, -1.7204e-01,  3.8520e-02,  1.2787e-01, -1.0386e-01,\n         -1.3406e-01,  1.6379e-01, -8.5537e-02,  2.0070e-02,  9.3217e-02,\n         -6.9406e-02,  1.6415e-01,  4.1143e-02, -9.0022e-02,  5.7693e-02,\n         -7.6161e-02,  9.1295e-02, -1.5241e-01, -1.2158e-01, -3.6043e-02,\n          5.5158e-02,  1.6997e-01, -9.3956e-02, -1.7352e-01, -8.1805e-03,\n          1.7079e-01,  1.5531e-01, -2.8440e-02,  1.0187e-01, -5.6266e-02,\n         -5.1897e-03, -1.0054e-01],\n        [-8.8262e-02, -1.4349e-01, -3.7514e-02,  1.4612e-01,  7.3513e-02,\n          7.5693e-02,  1.1558e-01,  4.4634e-04, -1.6338e-01,  1.3167e-01,\n          1.1664e-01, -1.0058e-01, -8.8249e-02,  6.0340e-02,  1.4826e-01,\n         -4.7454e-02, -2.5199e-02,  1.3973e-01, -4.9615e-02,  3.3538e-02,\n          9.1008e-02, -1.5435e-01, -1.6284e-02,  1.4288e-01,  1.5520e-01,\n          1.3542e-01, -3.6001e-03,  7.7136e-02,  2.0780e-02, -1.6530e-01,\n         -8.3083e-02, -1.4133e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "dense3":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1574, -0.2421, -0.1212,  0.1337, -0.2337, -0.0570, -0.1596,  0.0010],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0208,  0.2103, -0.0766,  0.0566, -0.2458, -0.1499,  0.0829, -0.0629,\n         -0.1615, -0.2363, -0.1936, -0.0527,  0.1312,  0.1353,  0.0770,  0.1729],\n        [ 0.1307,  0.0374,  0.1092,  0.2223, -0.1769, -0.1784,  0.2246, -0.2125,\n         -0.0956, -0.1380, -0.0190,  0.1671,  0.1288, -0.0636,  0.2178,  0.1484],\n        [-0.0632, -0.1860,  0.1934,  0.2030,  0.1560, -0.1966, -0.2262, -0.1401,\n         -0.1706,  0.1939, -0.1117, -0.2037,  0.1936,  0.1051,  0.1375, -0.0680],\n        [-0.1599,  0.2090,  0.0902, -0.1616,  0.0402, -0.1000,  0.2239, -0.2326,\n          0.2370, -0.2259, -0.2106, -0.0713, -0.1571, -0.1724, -0.1826, -0.2199],\n        [ 0.1296, -0.0834,  0.2419, -0.0422,  0.0061,  0.2475,  0.0745,  0.2000,\n         -0.1501, -0.0044, -0.2004, -0.0368, -0.1275, -0.0152, -0.1885, -0.2382],\n        [ 0.2143,  0.0409, -0.1665, -0.1321,  0.2212,  0.2234, -0.0850, -0.1793,\n          0.2332, -0.1263, -0.0717,  0.1271, -0.2062,  0.2173, -0.1357,  0.2147],\n        [-0.0642,  0.0693, -0.2374, -0.2211, -0.0629,  0.1464,  0.1726, -0.2384,\n         -0.1630,  0.1168, -0.1181, -0.2167, -0.1128,  0.2187, -0.0201,  0.2386],\n        [ 0.1407,  0.0716, -0.1853, -0.1566, -0.0825,  0.1406, -0.1162,  0.1249,\n         -0.0549,  0.1563, -0.2459, -0.2393, -0.1615, -0.0708,  0.1866,  0.1105]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "dense4":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2410], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1355, -0.2792,  0.0587,  0.0442, -0.3026, -0.1550, -0.0919,  0.2816]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "kernel_dim":	8,
                                "kernel_size":	128,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=1024, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_pre_hooks":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=1024, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_pre_hooks":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=1024, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0255, -0.0045,  0.0179, -0.0292, -0.0027, -0.0174, -0.0151,  0.0187,\n        -0.0095,  0.0098, -0.0260,  0.0309, -0.0284, -0.0225,  0.0267,  0.0024,\n         0.0039, -0.0200, -0.0140, -0.0110, -0.0264,  0.0257,  0.0256, -0.0241,\n        -0.0101,  0.0244,  0.0147,  0.0136, -0.0195, -0.0171,  0.0058, -0.0050],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0235,  0.0023,  0.0150,  ..., -0.0055, -0.0232,  0.0134],\n        [ 0.0209, -0.0281, -0.0287,  ..., -0.0009, -0.0051,  0.0120],\n        [ 0.0312, -0.0082,  0.0105,  ...,  0.0252,  0.0144,  0.0085],\n        ...,\n        [ 0.0115, -0.0192,  0.0296,  ..., -0.0142,  0.0255,  0.0004],\n        [-0.0073,  0.0046, -0.0140,  ...,  0.0307, -0.0294, -0.0196],\n        [ 0.0010, -0.0236, -0.0237,  ...,  0.0270, -0.0104,  0.0312]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	1024,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0327, -0.0221,  0.0555,  0.0136, -0.1392, -0.0432,  0.0434,  0.1150,\n         0.1765, -0.0877, -0.0306,  0.1004,  0.0841,  0.0218,  0.0600,  0.1198],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0218,  0.1398, -0.0659, -0.1351,  0.0493, -0.1382,  0.1461, -0.1644,\n          0.1366, -0.1059, -0.0909, -0.0434,  0.0484, -0.1659,  0.0385, -0.1095,\n          0.1351,  0.1198,  0.1758,  0.0691,  0.1257,  0.0508,  0.1355, -0.0409,\n          0.0407, -0.1217,  0.1479,  0.1328,  0.1429, -0.1752, -0.1072,  0.0803],\n        [ 0.0498, -0.1044,  0.0719,  0.0607, -0.0922, -0.0226, -0.0228, -0.0589,\n         -0.0292, -0.0452, -0.1047,  0.0497,  0.1229,  0.1448, -0.1309, -0.1100,\n          0.0094,  0.0604,  0.0770,  0.0873, -0.0325, -0.0535, -0.0996,  0.0813,\n          0.0424,  0.1181, -0.0847, -0.1002,  0.0998,  0.0100,  0.1509, -0.0727],\n        [ 0.1643,  0.0798,  0.0868,  0.1074,  0.1462, -0.0857, -0.0367,  0.1019,\n         -0.1360, -0.1067, -0.0799,  0.1352,  0.0453, -0.0985,  0.0744, -0.0291,\n         -0.0123, -0.1173, -0.1681, -0.0473,  0.1305,  0.0636,  0.0368, -0.0324,\n          0.0460, -0.0717, -0.1237, -0.1548,  0.1073, -0.1742, -0.1180,  0.0827],\n        [ 0.1124,  0.0990, -0.0907,  0.0688, -0.0132, -0.1013, -0.1590,  0.0458,\n         -0.1252,  0.0040, -0.0190,  0.1224, -0.1458,  0.0666, -0.0505,  0.0933,\n          0.1479,  0.1706,  0.1749, -0.0257, -0.0389, -0.0977,  0.0012,  0.1012,\n          0.0372, -0.0961, -0.1497, -0.1279, -0.1182, -0.1496, -0.0228, -0.1150],\n        [ 0.0925, -0.0630, -0.0217,  0.0257, -0.1363, -0.0245, -0.1703,  0.0193,\n         -0.1498,  0.0257, -0.1667,  0.0729, -0.0914,  0.1398, -0.0139,  0.1668,\n          0.0609,  0.1534, -0.1032, -0.1229, -0.0771, -0.1348, -0.0429,  0.1698,\n         -0.1440,  0.0112, -0.1027, -0.0136,  0.1688,  0.0599, -0.0831,  0.0211],\n        [ 0.0612,  0.0424,  0.1118, -0.0972,  0.0781, -0.1078, -0.0507, -0.1274,\n         -0.1638,  0.1614,  0.0430,  0.1274, -0.1518, -0.1411, -0.0649,  0.0814,\n         -0.0147, -0.0722,  0.0823,  0.0754, -0.0123,  0.0520, -0.0912,  0.0789,\n          0.0627, -0.1687, -0.1276, -0.0516, -0.0990,  0.0134, -0.0512, -0.1695],\n        [-0.0856,  0.0379, -0.1338, -0.1622, -0.0874,  0.0734,  0.1148,  0.0978,\n         -0.0317, -0.0859, -0.0681,  0.0816, -0.1055,  0.1066,  0.0402,  0.0682,\n         -0.0103, -0.0685,  0.1668, -0.1122, -0.0572, -0.1630, -0.0773,  0.0168,\n         -0.0633,  0.0188,  0.0087, -0.1584,  0.0974, -0.0663,  0.1332, -0.1732],\n        [ 0.0257,  0.0193,  0.0353,  0.1226, -0.0030, -0.1261,  0.0851, -0.0771,\n         -0.1673,  0.1620,  0.1290,  0.0381,  0.0568, -0.0516, -0.0849,  0.1510,\n          0.0753,  0.1461, -0.1545,  0.0139,  0.0600, -0.1056, -0.1518,  0.0413,\n         -0.0776,  0.0965,  0.1655,  0.0793, -0.0976,  0.1251,  0.1206, -0.0204],\n        [ 0.1059, -0.1091,  0.0493, -0.1614,  0.0818,  0.0080,  0.1676, -0.0955,\n          0.0036, -0.0646, -0.1363, -0.1720,  0.1643,  0.1294, -0.0409, -0.1321,\n          0.1340,  0.0997,  0.0993, -0.1126,  0.0054,  0.1400,  0.1424, -0.0655,\n         -0.1084, -0.1510,  0.1156,  0.1759,  0.1225,  0.0847, -0.0930, -0.1048],\n        [-0.0189,  0.0198,  0.0678,  0.1253, -0.0004,  0.1289, -0.1733,  0.0770,\n          0.1619,  0.1701,  0.0887,  0.0452, -0.1525,  0.1079,  0.0598,  0.0966,\n         -0.0017,  0.0388,  0.1400,  0.0059,  0.0868, -0.1149, -0.1333, -0.0500,\n         -0.1449,  0.1273,  0.0495,  0.0475,  0.0253, -0.0365,  0.1474, -0.0254],\n        [-0.1437,  0.0569,  0.1282, -0.0395,  0.0170,  0.1096, -0.0535,  0.0580,\n         -0.0071,  0.1036, -0.0831,  0.0534, -0.1231,  0.1558,  0.1638,  0.1541,\n          0.0557, -0.0516,  0.0834,  0.0325,  0.0313,  0.0682, -0.1160, -0.0067,\n          0.0724, -0.1213,  0.1041,  0.1419,  0.1180,  0.0060,  0.0647, -0.0345],\n        [ 0.1427,  0.1541, -0.0145,  0.0584,  0.1279, -0.0743, -0.0438,  0.0904,\n         -0.0224,  0.1030, -0.0770,  0.1427,  0.1719,  0.1366, -0.0872,  0.0813,\n         -0.0268,  0.0926,  0.1609, -0.0655,  0.1135,  0.1052,  0.0215,  0.0111,\n         -0.1745, -0.0735, -0.0356, -0.1061, -0.0092,  0.1599, -0.1120,  0.1517],\n        [ 0.0282,  0.1075, -0.1375, -0.1231,  0.1755,  0.0546,  0.1172,  0.1195,\n          0.1135,  0.1218,  0.1017, -0.0862,  0.1584, -0.1139, -0.1492,  0.0480,\n          0.1139,  0.1126, -0.0599,  0.0853, -0.0943, -0.0886, -0.0542,  0.0046,\n          0.0009,  0.1347, -0.0608,  0.0006,  0.1702,  0.1489,  0.0649,  0.1077],\n        [-0.0011, -0.0968,  0.0908,  0.1555,  0.0151, -0.1558, -0.1426,  0.1095,\n          0.0226,  0.0552, -0.1708, -0.1474, -0.0478, -0.0863, -0.0518,  0.1229,\n          0.0247,  0.0983,  0.0908, -0.1468, -0.0810,  0.0058,  0.0376,  0.0611,\n          0.1127, -0.0043,  0.0217,  0.0062, -0.0120,  0.0172, -0.1056,  0.1241],\n        [-0.0290, -0.1209, -0.1056,  0.0947, -0.1685,  0.0479, -0.0251, -0.0290,\n         -0.1677,  0.0302,  0.1650,  0.1373, -0.1596, -0.0670, -0.0525,  0.0042,\n          0.1118, -0.0422, -0.1742, -0.1745, -0.0879,  0.1382, -0.0673,  0.0029,\n         -0.1729,  0.0436, -0.1211, -0.0815,  0.0680, -0.1426, -0.1096, -0.1018],\n        [-0.0710, -0.0200, -0.0979,  0.0569, -0.1596,  0.1375, -0.1302, -0.1237,\n         -0.0303,  0.1512, -0.0412, -0.1078, -0.0818, -0.0063, -0.0672, -0.0894,\n         -0.0344, -0.1628, -0.0467, -0.1474, -0.1625,  0.0074,  0.1522,  0.0595,\n          0.1200,  0.0871, -0.1456, -0.0446,  0.1664,  0.0281, -0.1711, -0.0208]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1352,  0.2039, -0.0581,  0.0398, -0.0506, -0.1976, -0.0268,  0.0960],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1219, -0.2114,  0.2162, -0.2345, -0.1742, -0.1379, -0.0824, -0.1620,\n          0.1129,  0.1963, -0.0643, -0.1576,  0.0698, -0.0950, -0.0066,  0.0245],\n        [-0.1518, -0.0750,  0.1915,  0.0400, -0.2212,  0.1343,  0.2344,  0.0848,\n          0.0947,  0.0447,  0.1922, -0.2120, -0.2376,  0.2341, -0.0250,  0.2430],\n        [-0.1646,  0.2458,  0.1861,  0.0913,  0.1862, -0.1252, -0.1613,  0.1447,\n         -0.0078,  0.1216, -0.0682,  0.2382,  0.0766, -0.1198, -0.2240,  0.0132],\n        [-0.1267,  0.1187, -0.1619,  0.1448,  0.0729,  0.2064, -0.1232,  0.1480,\n         -0.0038,  0.0292, -0.0667, -0.2151, -0.1968, -0.2432,  0.0610, -0.2313],\n        [ 0.1940, -0.2127, -0.1898, -0.1897,  0.2051, -0.1905, -0.1514, -0.1934,\n         -0.0138,  0.0582, -0.1239, -0.0251,  0.1582,  0.2323,  0.2022, -0.0101],\n        [ 0.1164,  0.2431, -0.0838, -0.2132,  0.0966, -0.0386,  0.2310, -0.0928,\n         -0.1115, -0.2380,  0.1506,  0.0956,  0.1332,  0.1573, -0.2421,  0.2054],\n        [ 0.0338,  0.0045, -0.2255, -0.0089, -0.1923, -0.1180,  0.1720, -0.0398,\n          0.0852, -0.1176, -0.2086, -0.0101, -0.1067, -0.1051,  0.2237,  0.0305],\n        [ 0.2416,  0.0701, -0.2195,  0.1381,  0.0897,  0.2061, -0.1398,  0.2391,\n          0.1389, -0.0263,  0.1526,  0.1902, -0.2384,  0.2086,  0.0450,  0.0067]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([0.2557], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.2603, -0.0083, -0.2551, -0.1652, -0.0998, -0.2703, -0.2733, -0.1665]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    1024,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	1024,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "flatten_obs_dim":	1024,
                    "kernel_dim":	8,
                    "kernel_size":	128,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1937, -0.0761,  0.0513, -0.1674,  0.1910,  0.0083, -0.2362,  0.0298],\n        [-0.1489, -0.3042,  0.1026,  0.1107, -0.1617, -0.2796,  0.2509,  0.2663],\n        [ 0.0551, -0.2806,  0.1373, -0.1020, -0.1289, -0.3032, -0.1272, -0.3463],\n        [-0.0895,  0.2685, -0.1057, -0.3451,  0.0797,  0.0926,  0.0513, -0.2580],\n        [-0.1385, -0.1395,  0.3354, -0.1550,  0.3492,  0.1642, -0.1290,  0.2905],\n        [-0.2393,  0.2441, -0.3215, -0.0020, -0.2311, -0.2526, -0.0552, -0.0618],\n        [ 0.1013,  0.1785, -0.3238,  0.1585,  0.0649,  0.3272,  0.0899,  0.3368],\n        [ 0.1883,  0.2304, -0.1905, -0.1798,  0.1686,  0.2774,  0.1229,  0.3417],\n        [ 0.1506,  0.1883, -0.2429,  0.0304, -0.0955,  0.2669,  0.1548,  0.1922],\n        [-0.1655,  0.2379, -0.1667, -0.2182, -0.0553, -0.1692,  0.0405,  0.1805],\n        [ 0.1350,  0.0980, -0.1050,  0.0143,  0.3219,  0.1859,  0.2231,  0.1958],\n        [ 0.0246,  0.2678, -0.0352, -0.2847,  0.0881,  0.1216,  0.3483,  0.1488],\n        [-0.0708,  0.0490, -0.3403, -0.1733, -0.2129, -0.2616, -0.1048,  0.3514],\n        [-0.2496, -0.2526,  0.2979,  0.2427,  0.0864, -0.1705,  0.1636,  0.1587],\n        [ 0.0836,  0.2536,  0.0188,  0.3317,  0.2943, -0.1212, -0.2804, -0.3452],\n        [-0.0770, -0.2687, -0.3110,  0.0388,  0.0910,  0.1868, -0.0796, -0.0476],\n        [-0.1318, -0.2556,  0.2400, -0.3441, -0.0026, -0.0043,  0.1676, -0.0469],\n        [ 0.0517,  0.0968, -0.0021, -0.0141, -0.0656, -0.2991,  0.2266, -0.2575],\n        [ 0.2066,  0.3291, -0.1897, -0.2776,  0.0062, -0.1612, -0.0815, -0.0712],\n        [-0.0409,  0.1987,  0.0579, -0.1968, -0.1162, -0.3512, -0.1660, -0.0321],\n        [ 0.0455, -0.0175, -0.1648,  0.0976,  0.0356,  0.0631, -0.0456,  0.2730],\n        [ 0.0096,  0.1022,  0.1195,  0.1413, -0.2166,  0.2929, -0.1225,  0.0073],\n        [ 0.0191,  0.1306,  0.1367,  0.1691, -0.1174,  0.0170,  0.2291,  0.3529],\n        [-0.3201, -0.1992, -0.3365, -0.0309,  0.1575,  0.2596, -0.1077, -0.0979],\n        [ 0.2349,  0.0897, -0.0659, -0.0486,  0.0859, -0.2762,  0.2123, -0.1556],\n        [-0.2515, -0.2538,  0.1004, -0.0331, -0.1914,  0.1519,  0.0785, -0.3277],\n        [-0.2636,  0.1127,  0.2270, -0.1657,  0.2221,  0.2161, -0.3077, -0.2029],\n        [ 0.2477,  0.2966,  0.3398, -0.0090,  0.0313, -0.3378, -0.1064,  0.0154],\n        [-0.0240, -0.3035,  0.2979,  0.1160,  0.3323, -0.2350, -0.1001,  0.3482],\n        [ 0.0684,  0.0077,  0.1482,  0.1625, -0.2053, -0.1067,  0.2525,  0.0339],\n        [ 0.0477,  0.2966, -0.2220, -0.1684, -0.0737,  0.2898, -0.2598, -0.3193],\n        [-0.1764,  0.3330, -0.0712,  0.1590,  0.3285,  0.0292,  0.2107, -0.3376]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1004, -0.0445,  0.2165, -0.2823,  0.2697,  0.3224, -0.0542,  0.2300,\n        -0.3472,  0.0404, -0.0632,  0.0642, -0.1888, -0.3299,  0.0519,  0.3040,\n         0.2200,  0.2781,  0.2021,  0.1405, -0.1403, -0.1343,  0.3507, -0.1909,\n        -0.3451,  0.1489,  0.2242,  0.1792,  0.0797, -0.0419,  0.1739,  0.1414],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-6.9675e-03, -1.0034e-01, -1.2372e-01,  1.2000e-01,  1.2646e-01,\n         -6.4586e-02, -5.9865e-02,  1.1854e-01, -1.2928e-01,  1.1652e-01,\n         -1.3285e-01, -1.6592e-01,  1.5080e-01, -9.3838e-03,  8.7217e-02,\n          3.4868e-02,  3.1747e-02, -7.4076e-02,  1.3765e-01,  7.8382e-03,\n          1.4980e-01,  6.6800e-02,  1.0802e-01, -6.0992e-02, -2.1457e-02,\n         -8.8617e-02,  6.6078e-02, -1.4805e-01,  1.5169e-01,  1.2289e-01,\n         -1.1421e-01, -2.6533e-02],\n        [-1.2195e-01,  1.4272e-02,  9.7213e-02, -1.1462e-01, -5.8891e-02,\n         -1.5603e-01, -7.8982e-02, -1.4330e-01, -5.1053e-02, -1.1530e-01,\n          4.7670e-02, -6.0658e-04,  4.8459e-02,  7.6774e-02,  1.2705e-01,\n         -6.9725e-02, -9.6155e-02,  7.0194e-02,  1.4435e-01, -1.0067e-01,\n         -1.6855e-01,  3.6870e-02, -1.2024e-01, -6.4387e-02,  1.4649e-01,\n         -2.0104e-02,  9.6109e-02,  4.1861e-02, -3.6360e-02, -2.3378e-02,\n         -1.0899e-01,  9.1716e-02],\n        [-4.3602e-03, -1.2698e-01,  9.2132e-02,  5.7824e-02, -1.0304e-01,\n          5.3771e-03,  1.7519e-01,  1.3815e-01, -9.0678e-02, -1.5280e-01,\n          7.1428e-02, -8.2667e-02, -2.0860e-02, -3.3671e-02,  8.2118e-02,\n          7.6663e-02, -1.3770e-01, -1.5874e-01,  2.5257e-02,  1.5406e-01,\n          1.5652e-03, -1.6243e-01,  9.6955e-02, -8.4278e-02, -6.3565e-02,\n         -1.1490e-01,  2.2238e-02,  8.5016e-02, -1.1969e-01,  9.6496e-02,\n         -9.0382e-02, -1.0654e-01],\n        [-1.3166e-02,  4.0509e-02,  1.6517e-01, -8.9593e-02, -6.3024e-02,\n         -6.2889e-02,  2.9136e-02,  1.1190e-01,  9.9236e-02,  1.2155e-01,\n         -1.6976e-01,  3.2996e-02, -1.4077e-01,  4.0700e-02,  1.7208e-02,\n         -5.9591e-02, -1.4679e-01,  1.7066e-01,  6.6258e-02,  1.4147e-01,\n          1.2755e-01,  4.9942e-02,  4.6951e-02,  1.2413e-01, -1.7231e-01,\n          9.4166e-02, -6.6174e-02,  1.6792e-01, -4.6263e-02,  1.2570e-01,\n          7.9099e-03,  1.7410e-01],\n        [ 5.5714e-02, -8.6511e-02, -1.7635e-01,  6.4132e-03,  1.0488e-01,\n          1.5430e-03,  1.5315e-01,  1.6404e-02,  1.1056e-01, -1.6184e-01,\n         -1.0630e-01, -9.8978e-02,  1.7084e-01,  1.8931e-02,  6.9309e-02,\n          1.0267e-02,  8.1819e-02,  1.2532e-01, -1.4460e-01,  3.5785e-02,\n          1.1177e-01,  1.6558e-02,  3.9909e-02, -8.3839e-02, -1.1147e-01,\n          7.4958e-02, -7.2828e-02, -2.6730e-02,  1.6838e-02,  5.2683e-02,\n          3.7623e-02, -1.7425e-01],\n        [ 1.3140e-01,  1.0711e-01,  3.9130e-02, -1.0171e-01, -1.2385e-02,\n          5.7801e-02, -1.0679e-01, -4.9821e-02, -6.4209e-02, -8.7100e-03,\n          1.2426e-02,  7.9198e-02, -1.8753e-02,  9.2054e-02, -1.3102e-01,\n          8.9422e-02, -1.6864e-01,  8.7499e-04, -5.5456e-03,  5.2718e-02,\n          7.7625e-02, -5.3244e-02, -1.2143e-01,  7.1178e-02,  8.4364e-03,\n          3.4981e-02,  1.1550e-01, -4.0976e-02, -9.6812e-02,  7.2476e-02,\n         -1.2487e-01,  1.7045e-01],\n        [ 1.5468e-01,  1.0023e-01, -7.7134e-02, -1.1212e-01,  1.6365e-01,\n          7.0778e-02,  1.0259e-01, -1.4991e-01, -3.4858e-02,  2.1376e-02,\n         -3.5020e-02,  7.5488e-02, -1.4290e-01, -7.8608e-02,  9.9928e-02,\n          9.3238e-03,  1.7080e-01,  1.4192e-01, -1.4359e-01, -1.4290e-01,\n          5.7243e-02, -3.5154e-03, -1.7142e-02,  1.6562e-01, -1.2622e-01,\n          7.7778e-02, -9.6702e-02, -4.3008e-02,  1.2155e-01,  1.0994e-01,\n          1.5995e-01, -1.0497e-01],\n        [-1.0093e-02,  1.6319e-01,  1.4856e-01, -1.3882e-01,  1.7234e-01,\n          2.6040e-02,  6.8604e-02, -1.0208e-01,  5.1876e-02,  8.4196e-02,\n          1.1329e-01, -9.4033e-02,  6.2972e-02, -4.2794e-02, -1.6682e-01,\n         -2.4125e-02,  8.6522e-02,  1.0841e-02,  1.3606e-01, -1.1838e-01,\n         -1.5912e-01, -1.5843e-01,  1.0179e-01,  1.7622e-04, -1.1483e-01,\n          1.7224e-01, -2.1632e-02,  1.3678e-01, -1.2137e-01,  1.0702e-01,\n          6.9412e-02,  1.4906e-01],\n        [-2.7142e-02,  1.3744e-01,  4.1725e-02, -1.5987e-01, -5.9596e-04,\n         -6.2665e-02, -1.3787e-03,  7.0284e-02, -1.6747e-01, -3.7372e-02,\n          8.8829e-03, -1.5084e-01, -6.0199e-02, -1.3248e-01, -1.3851e-01,\n          8.0238e-02,  1.4791e-01, -8.5728e-02, -1.2871e-01,  5.1409e-02,\n          2.6201e-02, -1.9731e-02,  9.4479e-02,  7.0204e-02, -5.1371e-02,\n          5.8044e-02,  1.6302e-01,  4.6196e-02,  1.4875e-01, -1.2467e-01,\n         -1.3000e-01, -4.8086e-02],\n        [ 1.9705e-02,  3.6379e-02, -1.3879e-01,  5.8901e-02, -1.2821e-01,\n         -4.2995e-02, -1.5689e-01, -1.5953e-01,  7.4963e-02, -1.7324e-01,\n         -8.1276e-02,  1.6957e-01, -8.0814e-02,  1.6059e-01,  7.4632e-02,\n          9.4171e-02,  9.4284e-02, -1.4353e-01, -1.4770e-01, -9.6643e-02,\n          2.4654e-02, -5.1928e-02, -1.0213e-01,  2.2779e-02, -1.4148e-01,\n         -3.8773e-02, -3.8107e-02, -1.4908e-01,  2.4226e-03, -1.1440e-01,\n          5.3897e-02,  8.4678e-02],\n        [ 1.1372e-01, -1.3865e-01,  9.6416e-02, -1.2586e-01, -4.7046e-02,\n         -3.4046e-02,  4.9299e-02,  1.2860e-01,  9.2210e-02, -2.6247e-02,\n         -1.5734e-01, -1.2204e-01, -8.5152e-02, -1.4394e-01,  1.6626e-01,\n          4.5986e-02, -1.4540e-01,  4.9285e-02,  8.5447e-03,  1.5150e-01,\n          5.6145e-03,  1.3045e-02,  1.4175e-01,  7.0968e-02,  1.1737e-01,\n          1.1114e-02, -1.7380e-01, -6.0730e-02,  1.3469e-01,  1.1629e-01,\n          8.6670e-03,  6.6469e-02],\n        [ 1.0156e-01,  3.6921e-02,  1.3775e-01, -1.5093e-01, -1.3638e-02,\n          1.6935e-01, -1.0499e-01,  2.6178e-02,  3.2718e-02, -4.0552e-02,\n         -8.1838e-02,  1.7498e-01, -5.7838e-02,  5.3655e-02, -3.3793e-03,\n          8.3355e-03,  9.3997e-02, -1.2700e-01, -1.2463e-01,  7.4834e-03,\n         -1.4046e-02,  1.2899e-01,  1.5140e-01, -6.5798e-02,  1.7262e-01,\n          1.7860e-02, -2.4032e-02, -9.8721e-04,  1.3987e-01, -1.3078e-01,\n         -7.1347e-02, -1.6625e-01],\n        [-8.9214e-02, -1.4432e-01,  1.6689e-01, -1.3650e-01, -1.4753e-01,\n         -1.5622e-01,  2.9875e-02,  3.9735e-02,  2.0352e-02,  1.2162e-01,\n          1.2787e-01, -1.7196e-01,  1.8418e-02,  1.1606e-02, -1.3468e-01,\n         -8.4652e-02,  1.0658e-01, -1.7573e-01, -2.9638e-02,  7.2466e-02,\n         -2.6707e-02, -3.8463e-02, -1.4238e-01,  4.3954e-02,  1.4119e-01,\n         -8.4762e-02,  1.7896e-02,  7.1951e-02,  5.0366e-02,  1.5903e-01,\n         -8.1092e-02,  4.1790e-02],\n        [ 1.1826e-01, -6.8503e-03,  1.1698e-01, -2.3458e-03,  1.2016e-01,\n          1.5599e-01, -3.0163e-02,  1.6082e-01, -5.3310e-03,  7.4766e-02,\n          1.7062e-01,  1.3360e-01,  2.7667e-02,  3.3007e-02,  9.6966e-02,\n         -4.6328e-02,  6.4569e-02,  7.6589e-02, -1.3973e-01, -1.7045e-02,\n         -7.3050e-02,  4.4242e-02, -6.4035e-02, -1.6064e-02,  1.2307e-01,\n          1.2695e-01,  7.3289e-02,  9.3357e-03, -1.1127e-01, -1.3962e-02,\n         -1.2681e-01, -6.6032e-02],\n        [-4.0028e-02, -1.7204e-01,  3.8520e-02,  1.2787e-01, -1.0386e-01,\n         -1.3406e-01,  1.6379e-01, -8.5537e-02,  2.0070e-02,  9.3217e-02,\n         -6.9406e-02,  1.6415e-01,  4.1143e-02, -9.0022e-02,  5.7693e-02,\n         -7.6161e-02,  9.1295e-02, -1.5241e-01, -1.2158e-01, -3.6043e-02,\n          5.5158e-02,  1.6997e-01, -9.3956e-02, -1.7352e-01, -8.1805e-03,\n          1.7079e-01,  1.5531e-01, -2.8440e-02,  1.0187e-01, -5.6266e-02,\n         -5.1897e-03, -1.0054e-01],\n        [-8.8262e-02, -1.4349e-01, -3.7514e-02,  1.4612e-01,  7.3513e-02,\n          7.5693e-02,  1.1558e-01,  4.4634e-04, -1.6338e-01,  1.3167e-01,\n          1.1664e-01, -1.0058e-01, -8.8249e-02,  6.0340e-02,  1.4826e-01,\n         -4.7454e-02, -2.5199e-02,  1.3973e-01, -4.9615e-02,  3.3538e-02,\n          9.1008e-02, -1.5435e-01, -1.6284e-02,  1.4288e-01,  1.5520e-01,\n          1.3542e-01, -3.6001e-03,  7.7136e-02,  2.0780e-02, -1.6530e-01,\n         -8.3083e-02, -1.4133e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0284, -0.1097, -0.0476, -0.0596, -0.0977, -0.1135,  0.0347, -0.1566,\n        -0.1375,  0.0500,  0.1052, -0.0327, -0.1061, -0.0668, -0.1645, -0.0938],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0208,  0.2103, -0.0766,  0.0566, -0.2458, -0.1499,  0.0829, -0.0629,\n         -0.1615, -0.2363, -0.1936, -0.0527,  0.1312,  0.1353,  0.0770,  0.1729],\n        [ 0.1307,  0.0374,  0.1092,  0.2223, -0.1769, -0.1784,  0.2246, -0.2125,\n         -0.0956, -0.1380, -0.0190,  0.1671,  0.1288, -0.0636,  0.2178,  0.1484],\n        [-0.0632, -0.1860,  0.1934,  0.2030,  0.1560, -0.1966, -0.2262, -0.1401,\n         -0.1706,  0.1939, -0.1117, -0.2037,  0.1936,  0.1051,  0.1375, -0.0680],\n        [-0.1599,  0.2090,  0.0902, -0.1616,  0.0402, -0.1000,  0.2239, -0.2326,\n          0.2370, -0.2259, -0.2106, -0.0713, -0.1571, -0.1724, -0.1826, -0.2199],\n        [ 0.1296, -0.0834,  0.2419, -0.0422,  0.0061,  0.2475,  0.0745,  0.2000,\n         -0.1501, -0.0044, -0.2004, -0.0368, -0.1275, -0.0152, -0.1885, -0.2382],\n        [ 0.2143,  0.0409, -0.1665, -0.1321,  0.2212,  0.2234, -0.0850, -0.1793,\n          0.2332, -0.1263, -0.0717,  0.1271, -0.2062,  0.2173, -0.1357,  0.2147],\n        [-0.0642,  0.0693, -0.2374, -0.2211, -0.0629,  0.1464,  0.1726, -0.2384,\n         -0.1630,  0.1168, -0.1181, -0.2167, -0.1128,  0.2187, -0.0201,  0.2386],\n        [ 0.1407,  0.0716, -0.1853, -0.1566, -0.0825,  0.1406, -0.1162,  0.1249,\n         -0.0549,  0.1563, -0.2459, -0.2393, -0.1615, -0.0708,  0.1866,  0.1105]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1574, -0.2421, -0.1212,  0.1337, -0.2337, -0.0570, -0.1596,  0.0010],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1355, -0.2792,  0.0587,  0.0442, -0.3026, -0.1550, -0.0919,  0.2816]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2410], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x7f41e593dff0>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	25600,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "max_size":	25600,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	80,
            "_train_v_iters":	80,
            "_traj_per_epoch":	3,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    eps: 1e-08\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "eps":	1e-08,
                        "lr":	0.001,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "eps":	1e-08,
                            "lr":	0.001,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0235,  0.0023,  0.0150,  ..., -0.0055, -0.0232,  0.0134],\n        [ 0.0209, -0.0281, -0.0287,  ..., -0.0009, -0.0051,  0.0120],\n        [ 0.0312, -0.0082,  0.0105,  ...,  0.0252,  0.0144,  0.0085],\n        ...,\n        [ 0.0115, -0.0192,  0.0296,  ..., -0.0142,  0.0255,  0.0004],\n        [-0.0073,  0.0046, -0.0140,  ...,  0.0307, -0.0294, -0.0196],\n        [ 0.0010, -0.0236, -0.0237,  ...,  0.0270, -0.0104,  0.0312]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0255, -0.0045,  0.0179, -0.0292, -0.0027, -0.0174, -0.0151,  0.0187,\n        -0.0095,  0.0098, -0.0260,  0.0309, -0.0284, -0.0225,  0.0267,  0.0024,\n         0.0039, -0.0200, -0.0140, -0.0110, -0.0264,  0.0257,  0.0256, -0.0241,\n        -0.0101,  0.0244,  0.0147,  0.0136, -0.0195, -0.0171,  0.0058, -0.0050],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0218,  0.1398, -0.0659, -0.1351,  0.0493, -0.1382,  0.1461, -0.1644,\n          0.1366, -0.1059, -0.0909, -0.0434,  0.0484, -0.1659,  0.0385, -0.1095,\n          0.1351,  0.1198,  0.1758,  0.0691,  0.1257,  0.0508,  0.1355, -0.0409,\n          0.0407, -0.1217,  0.1479,  0.1328,  0.1429, -0.1752, -0.1072,  0.0803],\n        [ 0.0498, -0.1044,  0.0719,  0.0607, -0.0922, -0.0226, -0.0228, -0.0589,\n         -0.0292, -0.0452, -0.1047,  0.0497,  0.1229,  0.1448, -0.1309, -0.1100,\n          0.0094,  0.0604,  0.0770,  0.0873, -0.0325, -0.0535, -0.0996,  0.0813,\n          0.0424,  0.1181, -0.0847, -0.1002,  0.0998,  0.0100,  0.1509, -0.0727],\n        [ 0.1643,  0.0798,  0.0868,  0.1074,  0.1462, -0.0857, -0.0367,  0.1019,\n         -0.1360, -0.1067, -0.0799,  0.1352,  0.0453, -0.0985,  0.0744, -0.0291,\n         -0.0123, -0.1173, -0.1681, -0.0473,  0.1305,  0.0636,  0.0368, -0.0324,\n          0.0460, -0.0717, -0.1237, -0.1548,  0.1073, -0.1742, -0.1180,  0.0827],\n        [ 0.1124,  0.0990, -0.0907,  0.0688, -0.0132, -0.1013, -0.1590,  0.0458,\n         -0.1252,  0.0040, -0.0190,  0.1224, -0.1458,  0.0666, -0.0505,  0.0933,\n          0.1479,  0.1706,  0.1749, -0.0257, -0.0389, -0.0977,  0.0012,  0.1012,\n          0.0372, -0.0961, -0.1497, -0.1279, -0.1182, -0.1496, -0.0228, -0.1150],\n        [ 0.0925, -0.0630, -0.0217,  0.0257, -0.1363, -0.0245, -0.1703,  0.0193,\n         -0.1498,  0.0257, -0.1667,  0.0729, -0.0914,  0.1398, -0.0139,  0.1668,\n          0.0609,  0.1534, -0.1032, -0.1229, -0.0771, -0.1348, -0.0429,  0.1698,\n         -0.1440,  0.0112, -0.1027, -0.0136,  0.1688,  0.0599, -0.0831,  0.0211],\n        [ 0.0612,  0.0424,  0.1118, -0.0972,  0.0781, -0.1078, -0.0507, -0.1274,\n         -0.1638,  0.1614,  0.0430,  0.1274, -0.1518, -0.1411, -0.0649,  0.0814,\n         -0.0147, -0.0722,  0.0823,  0.0754, -0.0123,  0.0520, -0.0912,  0.0789,\n          0.0627, -0.1687, -0.1276, -0.0516, -0.0990,  0.0134, -0.0512, -0.1695],\n        [-0.0856,  0.0379, -0.1338, -0.1622, -0.0874,  0.0734,  0.1148,  0.0978,\n         -0.0317, -0.0859, -0.0681,  0.0816, -0.1055,  0.1066,  0.0402,  0.0682,\n         -0.0103, -0.0685,  0.1668, -0.1122, -0.0572, -0.1630, -0.0773,  0.0168,\n         -0.0633,  0.0188,  0.0087, -0.1584,  0.0974, -0.0663,  0.1332, -0.1732],\n        [ 0.0257,  0.0193,  0.0353,  0.1226, -0.0030, -0.1261,  0.0851, -0.0771,\n         -0.1673,  0.1620,  0.1290,  0.0381,  0.0568, -0.0516, -0.0849,  0.1510,\n          0.0753,  0.1461, -0.1545,  0.0139,  0.0600, -0.1056, -0.1518,  0.0413,\n         -0.0776,  0.0965,  0.1655,  0.0793, -0.0976,  0.1251,  0.1206, -0.0204],\n        [ 0.1059, -0.1091,  0.0493, -0.1614,  0.0818,  0.0080,  0.1676, -0.0955,\n          0.0036, -0.0646, -0.1363, -0.1720,  0.1643,  0.1294, -0.0409, -0.1321,\n          0.1340,  0.0997,  0.0993, -0.1126,  0.0054,  0.1400,  0.1424, -0.0655,\n         -0.1084, -0.1510,  0.1156,  0.1759,  0.1225,  0.0847, -0.0930, -0.1048],\n        [-0.0189,  0.0198,  0.0678,  0.1253, -0.0004,  0.1289, -0.1733,  0.0770,\n          0.1619,  0.1701,  0.0887,  0.0452, -0.1525,  0.1079,  0.0598,  0.0966,\n         -0.0017,  0.0388,  0.1400,  0.0059,  0.0868, -0.1149, -0.1333, -0.0500,\n         -0.1449,  0.1273,  0.0495,  0.0475,  0.0253, -0.0365,  0.1474, -0.0254],\n        [-0.1437,  0.0569,  0.1282, -0.0395,  0.0170,  0.1096, -0.0535,  0.0580,\n         -0.0071,  0.1036, -0.0831,  0.0534, -0.1231,  0.1558,  0.1638,  0.1541,\n          0.0557, -0.0516,  0.0834,  0.0325,  0.0313,  0.0682, -0.1160, -0.0067,\n          0.0724, -0.1213,  0.1041,  0.1419,  0.1180,  0.0060,  0.0647, -0.0345],\n        [ 0.1427,  0.1541, -0.0145,  0.0584,  0.1279, -0.0743, -0.0438,  0.0904,\n         -0.0224,  0.1030, -0.0770,  0.1427,  0.1719,  0.1366, -0.0872,  0.0813,\n         -0.0268,  0.0926,  0.1609, -0.0655,  0.1135,  0.1052,  0.0215,  0.0111,\n         -0.1745, -0.0735, -0.0356, -0.1061, -0.0092,  0.1599, -0.1120,  0.1517],\n        [ 0.0282,  0.1075, -0.1375, -0.1231,  0.1755,  0.0546,  0.1172,  0.1195,\n          0.1135,  0.1218,  0.1017, -0.0862,  0.1584, -0.1139, -0.1492,  0.0480,\n          0.1139,  0.1126, -0.0599,  0.0853, -0.0943, -0.0886, -0.0542,  0.0046,\n          0.0009,  0.1347, -0.0608,  0.0006,  0.1702,  0.1489,  0.0649,  0.1077],\n        [-0.0011, -0.0968,  0.0908,  0.1555,  0.0151, -0.1558, -0.1426,  0.1095,\n          0.0226,  0.0552, -0.1708, -0.1474, -0.0478, -0.0863, -0.0518,  0.1229,\n          0.0247,  0.0983,  0.0908, -0.1468, -0.0810,  0.0058,  0.0376,  0.0611,\n          0.1127, -0.0043,  0.0217,  0.0062, -0.0120,  0.0172, -0.1056,  0.1241],\n        [-0.0290, -0.1209, -0.1056,  0.0947, -0.1685,  0.0479, -0.0251, -0.0290,\n         -0.1677,  0.0302,  0.1650,  0.1373, -0.1596, -0.0670, -0.0525,  0.0042,\n          0.1118, -0.0422, -0.1742, -0.1745, -0.0879,  0.1382, -0.0673,  0.0029,\n         -0.1729,  0.0436, -0.1211, -0.0815,  0.0680, -0.1426, -0.1096, -0.1018],\n        [-0.0710, -0.0200, -0.0979,  0.0569, -0.1596,  0.1375, -0.1302, -0.1237,\n         -0.0303,  0.1512, -0.0412, -0.1078, -0.0818, -0.0063, -0.0672, -0.0894,\n         -0.0344, -0.1628, -0.0467, -0.1474, -0.1625,  0.0074,  0.1522,  0.0595,\n          0.1200,  0.0871, -0.1456, -0.0446,  0.1664,  0.0281, -0.1711, -0.0208]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0327, -0.0221,  0.0555,  0.0136, -0.1392, -0.0432,  0.0434,  0.1150,\n         0.1765, -0.0877, -0.0306,  0.1004,  0.0841,  0.0218,  0.0600,  0.1198],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1219, -0.2114,  0.2162, -0.2345, -0.1742, -0.1379, -0.0824, -0.1620,\n          0.1129,  0.1963, -0.0643, -0.1576,  0.0698, -0.0950, -0.0066,  0.0245],\n        [-0.1518, -0.0750,  0.1915,  0.0400, -0.2212,  0.1343,  0.2344,  0.0848,\n          0.0947,  0.0447,  0.1922, -0.2120, -0.2376,  0.2341, -0.0250,  0.2430],\n        [-0.1646,  0.2458,  0.1861,  0.0913,  0.1862, -0.1252, -0.1613,  0.1447,\n         -0.0078,  0.1216, -0.0682,  0.2382,  0.0766, -0.1198, -0.2240,  0.0132],\n        [-0.1267,  0.1187, -0.1619,  0.1448,  0.0729,  0.2064, -0.1232,  0.1480,\n         -0.0038,  0.0292, -0.0667, -0.2151, -0.1968, -0.2432,  0.0610, -0.2313],\n        [ 0.1940, -0.2127, -0.1898, -0.1897,  0.2051, -0.1905, -0.1514, -0.1934,\n         -0.0138,  0.0582, -0.1239, -0.0251,  0.1582,  0.2323,  0.2022, -0.0101],\n        [ 0.1164,  0.2431, -0.0838, -0.2132,  0.0966, -0.0386,  0.2310, -0.0928,\n         -0.1115, -0.2380,  0.1506,  0.0956,  0.1332,  0.1573, -0.2421,  0.2054],\n        [ 0.0338,  0.0045, -0.2255, -0.0089, -0.1923, -0.1180,  0.1720, -0.0398,\n          0.0852, -0.1176, -0.2086, -0.0101, -0.1067, -0.1051,  0.2237,  0.0305],\n        [ 0.2416,  0.0701, -0.2195,  0.1381,  0.0897,  0.2061, -0.1398,  0.2391,\n          0.1389, -0.0263,  0.1526,  0.1902, -0.2384,  0.2086,  0.0450,  0.0067]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1352,  0.2039, -0.0581,  0.0398, -0.0506, -0.1976, -0.0268,  0.0960],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2603, -0.0083, -0.2551, -0.1652, -0.0998, -0.2703, -0.2733, -0.1665]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2557], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7f41e593de10>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-scheduler",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling/./logs/rl4sys-ppo-scheduler/rl4sys-ppo-scheduler_s3387240000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/jeffw/stuff/RL4Sys/New/examples/job-scheduling/./logs/rl4sys-ppo-scheduler/rl4sys-ppo-scheduler_s3387240000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	80,
    "train_v_iters":	80,
    "traj_per_epoch":	3,
    "vf_lr":	0.001
}