{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	0,
    "batch_size":	256,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1014610000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0003,
    "sample_decay":	0.5,
    "seed":	1014610000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7354557d3610>":	{
            "_act_dim":	4,
            "_aux_batch_size":	0,
            "_batch_size":	256,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2505, -0.0944, -0.3220, -0.0950,  0.1612,  0.1248,  0.0784, -0.0298,\n         0.0653,  0.2377,  0.1810,  0.0800, -0.2708,  0.1249,  0.0619,  0.0252,\n        -0.2356,  0.3177, -0.1807, -0.1507,  0.1862, -0.1019, -0.2196,  0.1606,\n        -0.0376,  0.3531, -0.1748, -0.1768,  0.0684,  0.0171, -0.3472,  0.1618],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1839, -0.2419,  0.1858,  0.2161, -0.2166,  0.3107, -0.3276, -0.2924],\n        [ 0.2126, -0.2682,  0.1797, -0.2353, -0.2961, -0.3419,  0.1941, -0.1473],\n        [ 0.0944, -0.3268,  0.0579,  0.2485, -0.0942, -0.3249, -0.2248,  0.2633],\n        [ 0.1375,  0.0719, -0.2728, -0.0942,  0.0221, -0.0672,  0.2315,  0.1314],\n        [ 0.3297, -0.2244, -0.0623,  0.0120,  0.1872, -0.0006,  0.1600,  0.3178],\n        [-0.0277,  0.3461, -0.2830, -0.1141, -0.0720,  0.0150,  0.3516,  0.1258],\n        [-0.3185, -0.3038,  0.2865,  0.1721, -0.0242,  0.3291, -0.1956,  0.1315],\n        [ 0.1178, -0.1836, -0.1855,  0.1602,  0.2454,  0.2097, -0.1509, -0.2417],\n        [-0.0829, -0.2010, -0.2738, -0.0277,  0.2029, -0.3408, -0.2382,  0.0200],\n        [ 0.0586,  0.3344, -0.1030, -0.3079, -0.0979,  0.1216,  0.1712, -0.3133],\n        [-0.1912, -0.2491,  0.0126, -0.0858, -0.1320, -0.3025, -0.0448, -0.3280],\n        [ 0.0981,  0.2892,  0.2200,  0.2070, -0.0291,  0.2230,  0.1091, -0.2449],\n        [-0.2827,  0.2807,  0.1449, -0.0902,  0.0103, -0.0244,  0.0769,  0.0965],\n        [-0.1984, -0.2506, -0.3291, -0.1379,  0.1527, -0.3499,  0.0911,  0.0355],\n        [-0.1164, -0.2200,  0.2938, -0.2194, -0.2208,  0.2926, -0.1644,  0.2979],\n        [-0.0872,  0.0899,  0.3152,  0.1011,  0.0513, -0.2910,  0.3166,  0.1983],\n        [ 0.2407,  0.3141, -0.2810, -0.2950, -0.3115,  0.0097, -0.1306, -0.0742],\n        [ 0.1744,  0.1613,  0.0228, -0.1567,  0.2296,  0.0940,  0.3122,  0.3254],\n        [-0.1235,  0.1239, -0.1515,  0.1596, -0.2804, -0.3353, -0.0269,  0.2680],\n        [ 0.0342, -0.2226,  0.2118,  0.3473,  0.3050, -0.1762,  0.2842, -0.3216],\n        [ 0.3261,  0.3497,  0.3041,  0.0263, -0.1138,  0.2268, -0.1550, -0.1234],\n        [ 0.0259,  0.2061, -0.2656,  0.0578,  0.1714, -0.1546,  0.2652, -0.0025],\n        [ 0.2587,  0.2647, -0.3247,  0.3100,  0.3480, -0.0901, -0.3157, -0.2588],\n        [-0.3458,  0.2259,  0.0876, -0.0624,  0.2739, -0.0660,  0.0795, -0.0225],\n        [ 0.2512, -0.3232,  0.2599, -0.1772, -0.1182, -0.2579,  0.0995,  0.0544],\n        [-0.0053, -0.3046,  0.1945,  0.0727, -0.0477, -0.1936,  0.2489, -0.2636],\n        [-0.0857, -0.1832,  0.2361,  0.2414,  0.0095,  0.2641, -0.0274, -0.1081],\n        [-0.3112,  0.1883, -0.1102, -0.1301,  0.0598,  0.1125, -0.3121,  0.1391],\n        [-0.3494,  0.2540,  0.0241, -0.0427,  0.0811, -0.0174, -0.0225, -0.1828],\n        [-0.1103,  0.1874,  0.0231, -0.0488, -0.3066,  0.1093, -0.2916,  0.0985],\n        [ 0.1608,  0.1905, -0.0136,  0.1981, -0.3215, -0.0984, -0.3476, -0.0243],\n        [ 0.0548, -0.2040, -0.1393, -0.2388, -0.1145, -0.0492,  0.1713, -0.3060]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1501, -0.0261,  0.1587,  0.0801, -0.0887,  0.0559, -0.1261, -0.1547,\n         0.1559,  0.0543, -0.1450, -0.0639, -0.1166, -0.0182, -0.0832, -0.0888],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.6636e-01,  7.0784e-02,  1.4578e-01, -1.2967e-01, -9.4297e-03,\n          1.4373e-01,  7.6925e-02, -1.5155e-01, -1.7126e-01, -1.3506e-01,\n          1.1042e-01,  1.0904e-02, -1.0088e-01, -1.4177e-02,  8.4127e-02,\n         -6.1534e-06, -1.7151e-01, -8.4242e-02, -1.1183e-01,  1.2153e-01,\n          6.8098e-02, -6.9268e-02,  1.5797e-02,  1.6117e-02,  9.6759e-02,\n          1.3490e-01, -1.3425e-01, -1.5769e-01, -1.6384e-01,  5.6242e-02,\n          6.6303e-02, -1.0101e-01],\n        [-1.1126e-01, -1.4659e-01,  9.3987e-02,  1.5896e-01, -9.8917e-02,\n         -1.5333e-02,  2.8168e-03,  6.6836e-02,  1.3693e-01, -3.7093e-02,\n          1.6520e-01,  1.0439e-02, -1.6497e-01,  9.4471e-02, -1.5413e-01,\n          5.2228e-02,  1.6844e-01,  4.9272e-02,  2.1473e-02, -1.4819e-02,\n         -1.3534e-01,  1.7202e-02, -1.1947e-01,  1.6700e-01, -1.5279e-01,\n          3.2588e-02, -1.5524e-01,  4.3621e-02, -2.3196e-02,  1.8399e-02,\n         -9.4689e-02, -1.6104e-02],\n        [-9.8159e-02,  7.4497e-02,  6.7817e-02, -4.9688e-02, -6.1924e-02,\n         -4.6108e-02,  1.6256e-01,  8.5619e-03, -9.3515e-02, -4.0408e-03,\n          1.7215e-01,  2.6553e-02, -1.1636e-01, -6.7692e-02,  1.4559e-03,\n          1.9898e-02, -7.6716e-02, -4.2839e-02, -1.6705e-01,  9.0487e-02,\n         -4.3218e-02,  1.1687e-01,  7.1521e-02,  6.5249e-02, -1.5148e-01,\n         -5.2543e-02,  5.5330e-02,  6.8240e-02,  1.9637e-02, -3.7688e-03,\n          1.5659e-01, -1.9538e-03],\n        [ 1.7325e-01, -1.5065e-01, -8.0923e-02,  1.9958e-02, -1.0413e-01,\n          1.6733e-01, -1.6691e-01, -1.3161e-02,  2.2573e-02, -4.7095e-02,\n          1.5947e-01, -1.4234e-01, -1.7000e-01, -3.8969e-02,  8.9968e-02,\n          1.2522e-01,  1.4261e-02,  7.0270e-02, -1.0338e-01,  1.0516e-01,\n          1.6869e-01, -7.5320e-03,  9.8199e-03, -4.6554e-02,  1.6874e-01,\n          1.5549e-01, -1.0087e-01, -3.8376e-02,  6.7722e-02, -1.7644e-01,\n         -1.3367e-01,  1.3726e-01],\n        [-1.5254e-01,  9.9060e-02, -1.6231e-03, -1.2738e-02,  1.3756e-01,\n          3.5390e-02,  1.3172e-01,  1.1140e-01,  1.4399e-01,  1.2733e-01,\n         -1.7157e-01, -1.0884e-01, -1.1605e-01, -1.4266e-01,  1.1863e-01,\n          6.1669e-02, -1.0975e-01,  2.4602e-02,  1.3561e-01, -5.0454e-02,\n         -1.0992e-01, -6.3556e-02,  1.0434e-01,  2.2203e-02, -1.1950e-01,\n          1.4942e-01, -1.6267e-01, -1.6438e-01, -6.7434e-02, -1.4646e-01,\n          1.5140e-02, -1.0230e-01],\n        [ 1.3040e-01,  5.0096e-02, -1.2908e-01,  2.0476e-02, -4.5494e-02,\n         -2.7145e-02, -4.1459e-02,  7.2237e-02, -1.3626e-01,  1.2262e-01,\n         -2.0294e-02,  1.1732e-02, -1.3525e-01,  1.2938e-01, -4.5749e-02,\n          1.7048e-01, -6.3888e-02, -7.9747e-02,  1.0498e-02,  1.5871e-01,\n          1.2405e-02,  1.1659e-01,  5.5070e-02,  6.1075e-02, -2.5264e-02,\n          1.1243e-01,  3.0850e-02, -1.7308e-01,  1.1202e-01, -1.0930e-01,\n          7.4203e-02,  1.2892e-01],\n        [-4.5415e-02, -3.3306e-02,  8.4462e-02, -1.1161e-01,  1.4559e-01,\n          1.3430e-01,  2.1213e-02, -9.9885e-02, -8.1530e-02,  3.4552e-02,\n         -4.1020e-02, -1.4179e-01, -1.5668e-01, -2.0000e-02,  1.0457e-01,\n         -1.3969e-01,  1.1480e-01,  3.0043e-02,  7.0294e-02, -1.5101e-01,\n          1.4074e-01, -9.8734e-03, -2.2842e-02, -1.1546e-01, -1.0746e-01,\n          1.1789e-01, -1.2504e-01, -1.1550e-01, -1.1748e-02, -4.5450e-03,\n         -8.0671e-02,  5.8245e-02],\n        [-9.4748e-02,  7.4044e-02,  1.6417e-01, -4.4834e-02,  7.3919e-02,\n          6.7949e-02,  9.7163e-02, -1.2498e-01,  1.4981e-01, -1.5744e-01,\n         -7.1025e-02,  1.7291e-01, -1.6174e-02, -1.6114e-01, -1.4522e-01,\n          1.0141e-01,  1.5932e-01, -1.1645e-01,  2.4743e-02, -4.4643e-03,\n         -1.7421e-01, -9.0191e-02, -1.3379e-01,  4.3648e-02,  1.0123e-01,\n          1.0689e-01, -1.5086e-01,  3.2062e-02, -3.4386e-03,  4.0525e-02,\n          9.4973e-02, -1.4284e-01],\n        [ 1.0371e-01, -1.7106e-01, -1.2746e-01,  8.7558e-02,  8.5838e-02,\n          1.7760e-03, -1.3275e-01,  2.9289e-02, -1.4875e-01,  3.2738e-02,\n          1.1627e-02, -1.3743e-01,  1.0017e-01, -4.2257e-02,  1.2868e-01,\n          1.9191e-02,  9.3196e-02,  9.8268e-02, -1.4410e-01, -4.7627e-02,\n         -9.9230e-02,  1.1555e-01,  1.6462e-01,  1.3181e-01,  1.1756e-01,\n          1.6177e-03,  7.2569e-02,  1.7323e-01,  1.6774e-02,  2.8328e-02,\n         -1.4825e-02, -1.5074e-01],\n        [-1.1360e-01, -5.3348e-03,  4.2313e-04,  4.6718e-02,  1.0604e-01,\n          1.0840e-01,  8.1966e-03,  6.9124e-03, -1.5566e-01,  7.8210e-02,\n          2.5340e-03, -1.7460e-01, -1.3669e-01,  1.6972e-01,  4.6154e-02,\n         -3.0138e-02, -1.7124e-01,  1.4827e-02,  1.4210e-01, -1.7266e-01,\n          1.3572e-03, -5.0357e-02, -1.4500e-01, -3.8659e-02, -1.4271e-01,\n          1.6429e-01, -1.5688e-01,  1.0414e-01,  3.5918e-02, -8.6522e-03,\n         -2.5733e-02, -7.6076e-02],\n        [ 3.8759e-02,  4.7507e-02,  1.3625e-01, -7.5650e-02,  1.4682e-01,\n         -3.8322e-02,  1.4841e-01, -4.3100e-02, -6.6200e-03,  1.1549e-01,\n          1.0892e-01,  4.4729e-02,  6.5128e-03, -5.9024e-02, -6.1070e-03,\n         -3.4915e-02,  5.0813e-03, -1.4966e-01,  8.0001e-02,  8.4308e-02,\n         -2.6981e-02, -1.1715e-01,  5.6144e-02, -9.8001e-02,  3.1976e-03,\n          1.1442e-01,  6.0544e-02, -5.7511e-02, -6.0402e-02,  1.4716e-01,\n          3.8765e-02,  9.7999e-02],\n        [ 1.3721e-01, -1.7664e-01,  6.8487e-02,  7.8302e-02,  1.1566e-01,\n          3.4536e-02,  7.5704e-02,  1.0079e-01,  8.5367e-02, -8.4909e-02,\n          1.3048e-01, -1.2459e-01, -1.7360e-01,  5.2336e-02,  1.5308e-01,\n         -1.6581e-02, -1.2698e-01,  1.9479e-03,  1.2351e-02, -1.6157e-01,\n         -1.5809e-01, -1.0734e-01,  6.6355e-02, -3.3071e-02, -4.3126e-02,\n         -2.1870e-02, -1.1021e-01, -7.5209e-02,  2.1160e-02, -1.3893e-01,\n         -1.4085e-01,  1.5453e-01],\n        [-1.3547e-01, -1.2165e-01, -1.8484e-02, -9.9787e-02, -1.5340e-01,\n          6.0240e-02,  1.3692e-01,  1.0419e-01, -3.4174e-02, -9.8187e-02,\n         -1.7534e-01, -8.8617e-02,  1.6434e-01, -4.7025e-02, -1.6787e-01,\n         -1.0283e-01,  5.4234e-02, -6.0390e-02,  5.7623e-02,  1.6383e-01,\n         -5.7855e-02,  1.1968e-01, -1.1857e-01, -1.6805e-01, -8.0898e-02,\n         -1.5464e-01, -5.2437e-02,  7.8830e-02, -1.5110e-01,  1.5913e-01,\n         -2.9841e-02, -3.5321e-02],\n        [-1.3116e-01, -1.1142e-02, -3.4791e-02, -1.6821e-01, -4.4456e-02,\n         -1.1064e-01, -9.1449e-02,  7.3164e-02, -1.6919e-01,  9.7820e-02,\n          1.4097e-01, -5.9615e-02,  1.1289e-01, -4.0462e-02, -4.3332e-02,\n          1.7572e-02, -1.0607e-01, -9.7520e-02, -1.7371e-01, -6.9246e-02,\n         -1.6751e-01, -1.3171e-01, -6.0671e-02,  1.0314e-01,  1.5702e-01,\n         -1.2357e-01, -4.5033e-02, -6.0019e-02, -1.2914e-01, -9.8530e-02,\n          1.5022e-02,  3.3981e-02],\n        [-5.9427e-02,  4.5982e-02, -1.5627e-01, -2.0307e-02,  1.2578e-01,\n          1.3976e-01,  1.2118e-01,  4.7313e-02,  1.0311e-01,  1.1774e-01,\n         -1.6122e-01, -1.6580e-01,  6.6068e-02, -8.8734e-02,  1.0181e-01,\n         -8.1259e-02,  1.6786e-01, -8.1443e-02, -1.2110e-01,  9.9124e-02,\n          3.4741e-02,  7.0273e-02,  1.5271e-01, -3.5209e-02,  1.3237e-02,\n          3.3047e-02, -4.1688e-02, -4.3852e-02, -1.1726e-01,  1.2921e-01,\n          4.7110e-02,  4.3507e-02],\n        [-1.3948e-02,  2.4343e-03,  4.0404e-02,  1.5984e-03,  8.4276e-02,\n          7.6105e-02, -1.8575e-02, -6.2040e-02,  3.4721e-03, -8.8838e-02,\n         -1.2950e-02,  1.5339e-01,  9.2106e-02, -1.0219e-01, -4.5357e-02,\n          1.0140e-01,  1.6951e-01,  1.0876e-01, -7.5804e-02,  1.2891e-02,\n          1.3000e-01,  4.2289e-02, -1.6279e-01,  9.7179e-02, -1.1951e-01,\n          1.1746e-01,  6.4261e-02,  1.1431e-01,  5.6060e-02,  1.7360e-01,\n          1.6426e-01, -1.2778e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1163, -0.0837, -0.1893,  0.0867, -0.0699, -0.2007,  0.0877,  0.1016],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0826, -0.1904,  0.0669,  0.2149, -0.1627, -0.1449,  0.1280, -0.1543,\n         -0.1317, -0.0078, -0.1276,  0.0518,  0.2374,  0.1947, -0.1425,  0.2443],\n        [-0.1749,  0.2300, -0.1782,  0.2217,  0.0682,  0.1372, -0.2000,  0.0225,\n         -0.0721, -0.0089, -0.2468, -0.0573, -0.2001,  0.1133, -0.0600,  0.1656],\n        [ 0.0694, -0.1232,  0.2435,  0.0615, -0.0575, -0.1779,  0.0468, -0.2467,\n         -0.1637, -0.0068, -0.2314,  0.2284,  0.1509,  0.0055,  0.1952, -0.1893],\n        [ 0.0123, -0.1453, -0.0760, -0.2397, -0.1654, -0.1146,  0.0789,  0.1772,\n          0.0539,  0.0136, -0.0481,  0.0810, -0.2329,  0.0082, -0.0037, -0.2471],\n        [-0.2298, -0.1826,  0.1506,  0.0242, -0.2031,  0.1170,  0.1640, -0.1128,\n         -0.1315, -0.1054,  0.0933, -0.1022, -0.2491,  0.2076,  0.1399, -0.1474],\n        [ 0.1091,  0.0356,  0.1150,  0.1114,  0.1658,  0.1294, -0.0416,  0.1744,\n          0.0391, -0.1388,  0.2014, -0.2092, -0.0346,  0.0844,  0.2312, -0.0174],\n        [ 0.0877, -0.1373, -0.0628, -0.2449, -0.1895,  0.1814, -0.1087, -0.2015,\n         -0.1645,  0.0846,  0.0606,  0.1342, -0.1573, -0.1134, -0.1222,  0.1515],\n        [-0.1723,  0.1576, -0.0675,  0.1169, -0.0968, -0.0849, -0.0046, -0.0884,\n          0.0817,  0.2159, -0.0626,  0.1602, -0.0951, -0.1340,  0.0735, -0.0573]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1473, -0.0187,  0.2164, -0.1318], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2162, -0.3135,  0.1250, -0.2941,  0.2916,  0.1406, -0.0661,  0.1625],\n        [ 0.1035, -0.2701, -0.1916,  0.1299,  0.2267,  0.1920, -0.3412,  0.3483],\n        [-0.1090, -0.0469, -0.1422, -0.0544, -0.0474,  0.0719,  0.2492,  0.2878],\n        [-0.1093,  0.2929,  0.2206,  0.2802,  0.0370,  0.1415, -0.1612, -0.2033]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1839, -0.2419,  0.1858,  0.2161, -0.2166,  0.3107, -0.3276, -0.2924],\n        [ 0.2126, -0.2682,  0.1797, -0.2353, -0.2961, -0.3419,  0.1941, -0.1473],\n        [ 0.0944, -0.3268,  0.0579,  0.2485, -0.0942, -0.3249, -0.2248,  0.2633],\n        [ 0.1375,  0.0719, -0.2728, -0.0942,  0.0221, -0.0672,  0.2315,  0.1314],\n        [ 0.3297, -0.2244, -0.0623,  0.0120,  0.1872, -0.0006,  0.1600,  0.3178],\n        [-0.0277,  0.3461, -0.2830, -0.1141, -0.0720,  0.0150,  0.3516,  0.1258],\n        [-0.3185, -0.3038,  0.2865,  0.1721, -0.0242,  0.3291, -0.1956,  0.1315],\n        [ 0.1178, -0.1836, -0.1855,  0.1602,  0.2454,  0.2097, -0.1509, -0.2417],\n        [-0.0829, -0.2010, -0.2738, -0.0277,  0.2029, -0.3408, -0.2382,  0.0200],\n        [ 0.0586,  0.3344, -0.1030, -0.3079, -0.0979,  0.1216,  0.1712, -0.3133],\n        [-0.1912, -0.2491,  0.0126, -0.0858, -0.1320, -0.3025, -0.0448, -0.3280],\n        [ 0.0981,  0.2892,  0.2200,  0.2070, -0.0291,  0.2230,  0.1091, -0.2449],\n        [-0.2827,  0.2807,  0.1449, -0.0902,  0.0103, -0.0244,  0.0769,  0.0965],\n        [-0.1984, -0.2506, -0.3291, -0.1379,  0.1527, -0.3499,  0.0911,  0.0355],\n        [-0.1164, -0.2200,  0.2938, -0.2194, -0.2208,  0.2926, -0.1644,  0.2979],\n        [-0.0872,  0.0899,  0.3152,  0.1011,  0.0513, -0.2910,  0.3166,  0.1983],\n        [ 0.2407,  0.3141, -0.2810, -0.2950, -0.3115,  0.0097, -0.1306, -0.0742],\n        [ 0.1744,  0.1613,  0.0228, -0.1567,  0.2296,  0.0940,  0.3122,  0.3254],\n        [-0.1235,  0.1239, -0.1515,  0.1596, -0.2804, -0.3353, -0.0269,  0.2680],\n        [ 0.0342, -0.2226,  0.2118,  0.3473,  0.3050, -0.1762,  0.2842, -0.3216],\n        [ 0.3261,  0.3497,  0.3041,  0.0263, -0.1138,  0.2268, -0.1550, -0.1234],\n        [ 0.0259,  0.2061, -0.2656,  0.0578,  0.1714, -0.1546,  0.2652, -0.0025],\n        [ 0.2587,  0.2647, -0.3247,  0.3100,  0.3480, -0.0901, -0.3157, -0.2588],\n        [-0.3458,  0.2259,  0.0876, -0.0624,  0.2739, -0.0660,  0.0795, -0.0225],\n        [ 0.2512, -0.3232,  0.2599, -0.1772, -0.1182, -0.2579,  0.0995,  0.0544],\n        [-0.0053, -0.3046,  0.1945,  0.0727, -0.0477, -0.1936,  0.2489, -0.2636],\n        [-0.0857, -0.1832,  0.2361,  0.2414,  0.0095,  0.2641, -0.0274, -0.1081],\n        [-0.3112,  0.1883, -0.1102, -0.1301,  0.0598,  0.1125, -0.3121,  0.1391],\n        [-0.3494,  0.2540,  0.0241, -0.0427,  0.0811, -0.0174, -0.0225, -0.1828],\n        [-0.1103,  0.1874,  0.0231, -0.0488, -0.3066,  0.1093, -0.2916,  0.0985],\n        [ 0.1608,  0.1905, -0.0136,  0.1981, -0.3215, -0.0984, -0.3476, -0.0243],\n        [ 0.0548, -0.2040, -0.1393, -0.2388, -0.1145, -0.0492,  0.1713, -0.3060]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2505, -0.0944, -0.3220, -0.0950,  0.1612,  0.1248,  0.0784, -0.0298,\n         0.0653,  0.2377,  0.1810,  0.0800, -0.2708,  0.1249,  0.0619,  0.0252,\n        -0.2356,  0.3177, -0.1807, -0.1507,  0.1862, -0.1019, -0.2196,  0.1606,\n        -0.0376,  0.3531, -0.1748, -0.1768,  0.0684,  0.0171, -0.3472,  0.1618],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.6636e-01,  7.0784e-02,  1.4578e-01, -1.2967e-01, -9.4297e-03,\n          1.4373e-01,  7.6925e-02, -1.5155e-01, -1.7126e-01, -1.3506e-01,\n          1.1042e-01,  1.0904e-02, -1.0088e-01, -1.4177e-02,  8.4127e-02,\n         -6.1534e-06, -1.7151e-01, -8.4242e-02, -1.1183e-01,  1.2153e-01,\n          6.8098e-02, -6.9268e-02,  1.5797e-02,  1.6117e-02,  9.6759e-02,\n          1.3490e-01, -1.3425e-01, -1.5769e-01, -1.6384e-01,  5.6242e-02,\n          6.6303e-02, -1.0101e-01],\n        [-1.1126e-01, -1.4659e-01,  9.3987e-02,  1.5896e-01, -9.8917e-02,\n         -1.5333e-02,  2.8168e-03,  6.6836e-02,  1.3693e-01, -3.7093e-02,\n          1.6520e-01,  1.0439e-02, -1.6497e-01,  9.4471e-02, -1.5413e-01,\n          5.2228e-02,  1.6844e-01,  4.9272e-02,  2.1473e-02, -1.4819e-02,\n         -1.3534e-01,  1.7202e-02, -1.1947e-01,  1.6700e-01, -1.5279e-01,\n          3.2588e-02, -1.5524e-01,  4.3621e-02, -2.3196e-02,  1.8399e-02,\n         -9.4689e-02, -1.6104e-02],\n        [-9.8159e-02,  7.4497e-02,  6.7817e-02, -4.9688e-02, -6.1924e-02,\n         -4.6108e-02,  1.6256e-01,  8.5619e-03, -9.3515e-02, -4.0408e-03,\n          1.7215e-01,  2.6553e-02, -1.1636e-01, -6.7692e-02,  1.4559e-03,\n          1.9898e-02, -7.6716e-02, -4.2839e-02, -1.6705e-01,  9.0487e-02,\n         -4.3218e-02,  1.1687e-01,  7.1521e-02,  6.5249e-02, -1.5148e-01,\n         -5.2543e-02,  5.5330e-02,  6.8240e-02,  1.9637e-02, -3.7688e-03,\n          1.5659e-01, -1.9538e-03],\n        [ 1.7325e-01, -1.5065e-01, -8.0923e-02,  1.9958e-02, -1.0413e-01,\n          1.6733e-01, -1.6691e-01, -1.3161e-02,  2.2573e-02, -4.7095e-02,\n          1.5947e-01, -1.4234e-01, -1.7000e-01, -3.8969e-02,  8.9968e-02,\n          1.2522e-01,  1.4261e-02,  7.0270e-02, -1.0338e-01,  1.0516e-01,\n          1.6869e-01, -7.5320e-03,  9.8199e-03, -4.6554e-02,  1.6874e-01,\n          1.5549e-01, -1.0087e-01, -3.8376e-02,  6.7722e-02, -1.7644e-01,\n         -1.3367e-01,  1.3726e-01],\n        [-1.5254e-01,  9.9060e-02, -1.6231e-03, -1.2738e-02,  1.3756e-01,\n          3.5390e-02,  1.3172e-01,  1.1140e-01,  1.4399e-01,  1.2733e-01,\n         -1.7157e-01, -1.0884e-01, -1.1605e-01, -1.4266e-01,  1.1863e-01,\n          6.1669e-02, -1.0975e-01,  2.4602e-02,  1.3561e-01, -5.0454e-02,\n         -1.0992e-01, -6.3556e-02,  1.0434e-01,  2.2203e-02, -1.1950e-01,\n          1.4942e-01, -1.6267e-01, -1.6438e-01, -6.7434e-02, -1.4646e-01,\n          1.5140e-02, -1.0230e-01],\n        [ 1.3040e-01,  5.0096e-02, -1.2908e-01,  2.0476e-02, -4.5494e-02,\n         -2.7145e-02, -4.1459e-02,  7.2237e-02, -1.3626e-01,  1.2262e-01,\n         -2.0294e-02,  1.1732e-02, -1.3525e-01,  1.2938e-01, -4.5749e-02,\n          1.7048e-01, -6.3888e-02, -7.9747e-02,  1.0498e-02,  1.5871e-01,\n          1.2405e-02,  1.1659e-01,  5.5070e-02,  6.1075e-02, -2.5264e-02,\n          1.1243e-01,  3.0850e-02, -1.7308e-01,  1.1202e-01, -1.0930e-01,\n          7.4203e-02,  1.2892e-01],\n        [-4.5415e-02, -3.3306e-02,  8.4462e-02, -1.1161e-01,  1.4559e-01,\n          1.3430e-01,  2.1213e-02, -9.9885e-02, -8.1530e-02,  3.4552e-02,\n         -4.1020e-02, -1.4179e-01, -1.5668e-01, -2.0000e-02,  1.0457e-01,\n         -1.3969e-01,  1.1480e-01,  3.0043e-02,  7.0294e-02, -1.5101e-01,\n          1.4074e-01, -9.8734e-03, -2.2842e-02, -1.1546e-01, -1.0746e-01,\n          1.1789e-01, -1.2504e-01, -1.1550e-01, -1.1748e-02, -4.5450e-03,\n         -8.0671e-02,  5.8245e-02],\n        [-9.4748e-02,  7.4044e-02,  1.6417e-01, -4.4834e-02,  7.3919e-02,\n          6.7949e-02,  9.7163e-02, -1.2498e-01,  1.4981e-01, -1.5744e-01,\n         -7.1025e-02,  1.7291e-01, -1.6174e-02, -1.6114e-01, -1.4522e-01,\n          1.0141e-01,  1.5932e-01, -1.1645e-01,  2.4743e-02, -4.4643e-03,\n         -1.7421e-01, -9.0191e-02, -1.3379e-01,  4.3648e-02,  1.0123e-01,\n          1.0689e-01, -1.5086e-01,  3.2062e-02, -3.4386e-03,  4.0525e-02,\n          9.4973e-02, -1.4284e-01],\n        [ 1.0371e-01, -1.7106e-01, -1.2746e-01,  8.7558e-02,  8.5838e-02,\n          1.7760e-03, -1.3275e-01,  2.9289e-02, -1.4875e-01,  3.2738e-02,\n          1.1627e-02, -1.3743e-01,  1.0017e-01, -4.2257e-02,  1.2868e-01,\n          1.9191e-02,  9.3196e-02,  9.8268e-02, -1.4410e-01, -4.7627e-02,\n         -9.9230e-02,  1.1555e-01,  1.6462e-01,  1.3181e-01,  1.1756e-01,\n          1.6177e-03,  7.2569e-02,  1.7323e-01,  1.6774e-02,  2.8328e-02,\n         -1.4825e-02, -1.5074e-01],\n        [-1.1360e-01, -5.3348e-03,  4.2313e-04,  4.6718e-02,  1.0604e-01,\n          1.0840e-01,  8.1966e-03,  6.9124e-03, -1.5566e-01,  7.8210e-02,\n          2.5340e-03, -1.7460e-01, -1.3669e-01,  1.6972e-01,  4.6154e-02,\n         -3.0138e-02, -1.7124e-01,  1.4827e-02,  1.4210e-01, -1.7266e-01,\n          1.3572e-03, -5.0357e-02, -1.4500e-01, -3.8659e-02, -1.4271e-01,\n          1.6429e-01, -1.5688e-01,  1.0414e-01,  3.5918e-02, -8.6522e-03,\n         -2.5733e-02, -7.6076e-02],\n        [ 3.8759e-02,  4.7507e-02,  1.3625e-01, -7.5650e-02,  1.4682e-01,\n         -3.8322e-02,  1.4841e-01, -4.3100e-02, -6.6200e-03,  1.1549e-01,\n          1.0892e-01,  4.4729e-02,  6.5128e-03, -5.9024e-02, -6.1070e-03,\n         -3.4915e-02,  5.0813e-03, -1.4966e-01,  8.0001e-02,  8.4308e-02,\n         -2.6981e-02, -1.1715e-01,  5.6144e-02, -9.8001e-02,  3.1976e-03,\n          1.1442e-01,  6.0544e-02, -5.7511e-02, -6.0402e-02,  1.4716e-01,\n          3.8765e-02,  9.7999e-02],\n        [ 1.3721e-01, -1.7664e-01,  6.8487e-02,  7.8302e-02,  1.1566e-01,\n          3.4536e-02,  7.5704e-02,  1.0079e-01,  8.5367e-02, -8.4909e-02,\n          1.3048e-01, -1.2459e-01, -1.7360e-01,  5.2336e-02,  1.5308e-01,\n         -1.6581e-02, -1.2698e-01,  1.9479e-03,  1.2351e-02, -1.6157e-01,\n         -1.5809e-01, -1.0734e-01,  6.6355e-02, -3.3071e-02, -4.3126e-02,\n         -2.1870e-02, -1.1021e-01, -7.5209e-02,  2.1160e-02, -1.3893e-01,\n         -1.4085e-01,  1.5453e-01],\n        [-1.3547e-01, -1.2165e-01, -1.8484e-02, -9.9787e-02, -1.5340e-01,\n          6.0240e-02,  1.3692e-01,  1.0419e-01, -3.4174e-02, -9.8187e-02,\n         -1.7534e-01, -8.8617e-02,  1.6434e-01, -4.7025e-02, -1.6787e-01,\n         -1.0283e-01,  5.4234e-02, -6.0390e-02,  5.7623e-02,  1.6383e-01,\n         -5.7855e-02,  1.1968e-01, -1.1857e-01, -1.6805e-01, -8.0898e-02,\n         -1.5464e-01, -5.2437e-02,  7.8830e-02, -1.5110e-01,  1.5913e-01,\n         -2.9841e-02, -3.5321e-02],\n        [-1.3116e-01, -1.1142e-02, -3.4791e-02, -1.6821e-01, -4.4456e-02,\n         -1.1064e-01, -9.1449e-02,  7.3164e-02, -1.6919e-01,  9.7820e-02,\n          1.4097e-01, -5.9615e-02,  1.1289e-01, -4.0462e-02, -4.3332e-02,\n          1.7572e-02, -1.0607e-01, -9.7520e-02, -1.7371e-01, -6.9246e-02,\n         -1.6751e-01, -1.3171e-01, -6.0671e-02,  1.0314e-01,  1.5702e-01,\n         -1.2357e-01, -4.5033e-02, -6.0019e-02, -1.2914e-01, -9.8530e-02,\n          1.5022e-02,  3.3981e-02],\n        [-5.9427e-02,  4.5982e-02, -1.5627e-01, -2.0307e-02,  1.2578e-01,\n          1.3976e-01,  1.2118e-01,  4.7313e-02,  1.0311e-01,  1.1774e-01,\n         -1.6122e-01, -1.6580e-01,  6.6068e-02, -8.8734e-02,  1.0181e-01,\n         -8.1259e-02,  1.6786e-01, -8.1443e-02, -1.2110e-01,  9.9124e-02,\n          3.4741e-02,  7.0273e-02,  1.5271e-01, -3.5209e-02,  1.3237e-02,\n          3.3047e-02, -4.1688e-02, -4.3852e-02, -1.1726e-01,  1.2921e-01,\n          4.7110e-02,  4.3507e-02],\n        [-1.3948e-02,  2.4343e-03,  4.0404e-02,  1.5984e-03,  8.4276e-02,\n          7.6105e-02, -1.8575e-02, -6.2040e-02,  3.4721e-03, -8.8838e-02,\n         -1.2950e-02,  1.5339e-01,  9.2106e-02, -1.0219e-01, -4.5357e-02,\n          1.0140e-01,  1.6951e-01,  1.0876e-01, -7.5804e-02,  1.2891e-02,\n          1.3000e-01,  4.2289e-02, -1.6279e-01,  9.7179e-02, -1.1951e-01,\n          1.1746e-01,  6.4261e-02,  1.1431e-01,  5.6060e-02,  1.7360e-01,\n          1.6426e-01, -1.2778e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1501, -0.0261,  0.1587,  0.0801, -0.0887,  0.0559, -0.1261, -0.1547,\n         0.1559,  0.0543, -0.1450, -0.0639, -0.1166, -0.0182, -0.0832, -0.0888],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0826, -0.1904,  0.0669,  0.2149, -0.1627, -0.1449,  0.1280, -0.1543,\n         -0.1317, -0.0078, -0.1276,  0.0518,  0.2374,  0.1947, -0.1425,  0.2443],\n        [-0.1749,  0.2300, -0.1782,  0.2217,  0.0682,  0.1372, -0.2000,  0.0225,\n         -0.0721, -0.0089, -0.2468, -0.0573, -0.2001,  0.1133, -0.0600,  0.1656],\n        [ 0.0694, -0.1232,  0.2435,  0.0615, -0.0575, -0.1779,  0.0468, -0.2467,\n         -0.1637, -0.0068, -0.2314,  0.2284,  0.1509,  0.0055,  0.1952, -0.1893],\n        [ 0.0123, -0.1453, -0.0760, -0.2397, -0.1654, -0.1146,  0.0789,  0.1772,\n          0.0539,  0.0136, -0.0481,  0.0810, -0.2329,  0.0082, -0.0037, -0.2471],\n        [-0.2298, -0.1826,  0.1506,  0.0242, -0.2031,  0.1170,  0.1640, -0.1128,\n         -0.1315, -0.1054,  0.0933, -0.1022, -0.2491,  0.2076,  0.1399, -0.1474],\n        [ 0.1091,  0.0356,  0.1150,  0.1114,  0.1658,  0.1294, -0.0416,  0.1744,\n          0.0391, -0.1388,  0.2014, -0.2092, -0.0346,  0.0844,  0.2312, -0.0174],\n        [ 0.0877, -0.1373, -0.0628, -0.2449, -0.1895,  0.1814, -0.1087, -0.2015,\n         -0.1645,  0.0846,  0.0606,  0.1342, -0.1573, -0.1134, -0.1222,  0.1515],\n        [-0.1723,  0.1576, -0.0675,  0.1169, -0.0968, -0.0849, -0.0046, -0.0884,\n          0.0817,  0.2159, -0.0626,  0.1602, -0.0951, -0.1340,  0.0735, -0.0573]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1163, -0.0837, -0.1893,  0.0867, -0.0699, -0.2007,  0.0877,  0.1016],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2162, -0.3135,  0.1250, -0.2941,  0.2916,  0.1406, -0.0661,  0.1625],\n        [ 0.1035, -0.2701, -0.1916,  0.1299,  0.2267,  0.1920, -0.3412,  0.3483],\n        [-0.1090, -0.0469, -0.1422, -0.0544, -0.0474,  0.0719,  0.2492,  0.2878],\n        [-0.1093,  0.2929,  0.2206,  0.2802,  0.0370,  0.1415, -0.1612, -0.2033]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1473, -0.0187,  0.2164, -0.1318], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x735457dfa2d0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x735455634590>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2505, -0.0944, -0.3220, -0.0950,  0.1612,  0.1248,  0.0784, -0.0298,\n         0.0653,  0.2377,  0.1810,  0.0800, -0.2708,  0.1249,  0.0619,  0.0252,\n        -0.2356,  0.3177, -0.1807, -0.1507,  0.1862, -0.1019, -0.2196,  0.1606,\n        -0.0376,  0.3531, -0.1748, -0.1768,  0.0684,  0.0171, -0.3472,  0.1618],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1839, -0.2419,  0.1858,  0.2161, -0.2166,  0.3107, -0.3276, -0.2924],\n        [ 0.2126, -0.2682,  0.1797, -0.2353, -0.2961, -0.3419,  0.1941, -0.1473],\n        [ 0.0944, -0.3268,  0.0579,  0.2485, -0.0942, -0.3249, -0.2248,  0.2633],\n        [ 0.1375,  0.0719, -0.2728, -0.0942,  0.0221, -0.0672,  0.2315,  0.1314],\n        [ 0.3297, -0.2244, -0.0623,  0.0120,  0.1872, -0.0006,  0.1600,  0.3178],\n        [-0.0277,  0.3461, -0.2830, -0.1141, -0.0720,  0.0150,  0.3516,  0.1258],\n        [-0.3185, -0.3038,  0.2865,  0.1721, -0.0242,  0.3291, -0.1956,  0.1315],\n        [ 0.1178, -0.1836, -0.1855,  0.1602,  0.2454,  0.2097, -0.1509, -0.2417],\n        [-0.0829, -0.2010, -0.2738, -0.0277,  0.2029, -0.3408, -0.2382,  0.0200],\n        [ 0.0586,  0.3344, -0.1030, -0.3079, -0.0979,  0.1216,  0.1712, -0.3133],\n        [-0.1912, -0.2491,  0.0126, -0.0858, -0.1320, -0.3025, -0.0448, -0.3280],\n        [ 0.0981,  0.2892,  0.2200,  0.2070, -0.0291,  0.2230,  0.1091, -0.2449],\n        [-0.2827,  0.2807,  0.1449, -0.0902,  0.0103, -0.0244,  0.0769,  0.0965],\n        [-0.1984, -0.2506, -0.3291, -0.1379,  0.1527, -0.3499,  0.0911,  0.0355],\n        [-0.1164, -0.2200,  0.2938, -0.2194, -0.2208,  0.2926, -0.1644,  0.2979],\n        [-0.0872,  0.0899,  0.3152,  0.1011,  0.0513, -0.2910,  0.3166,  0.1983],\n        [ 0.2407,  0.3141, -0.2810, -0.2950, -0.3115,  0.0097, -0.1306, -0.0742],\n        [ 0.1744,  0.1613,  0.0228, -0.1567,  0.2296,  0.0940,  0.3122,  0.3254],\n        [-0.1235,  0.1239, -0.1515,  0.1596, -0.2804, -0.3353, -0.0269,  0.2680],\n        [ 0.0342, -0.2226,  0.2118,  0.3473,  0.3050, -0.1762,  0.2842, -0.3216],\n        [ 0.3261,  0.3497,  0.3041,  0.0263, -0.1138,  0.2268, -0.1550, -0.1234],\n        [ 0.0259,  0.2061, -0.2656,  0.0578,  0.1714, -0.1546,  0.2652, -0.0025],\n        [ 0.2587,  0.2647, -0.3247,  0.3100,  0.3480, -0.0901, -0.3157, -0.2588],\n        [-0.3458,  0.2259,  0.0876, -0.0624,  0.2739, -0.0660,  0.0795, -0.0225],\n        [ 0.2512, -0.3232,  0.2599, -0.1772, -0.1182, -0.2579,  0.0995,  0.0544],\n        [-0.0053, -0.3046,  0.1945,  0.0727, -0.0477, -0.1936,  0.2489, -0.2636],\n        [-0.0857, -0.1832,  0.2361,  0.2414,  0.0095,  0.2641, -0.0274, -0.1081],\n        [-0.3112,  0.1883, -0.1102, -0.1301,  0.0598,  0.1125, -0.3121,  0.1391],\n        [-0.3494,  0.2540,  0.0241, -0.0427,  0.0811, -0.0174, -0.0225, -0.1828],\n        [-0.1103,  0.1874,  0.0231, -0.0488, -0.3066,  0.1093, -0.2916,  0.0985],\n        [ 0.1608,  0.1905, -0.0136,  0.1981, -0.3215, -0.0984, -0.3476, -0.0243],\n        [ 0.0548, -0.2040, -0.1393, -0.2388, -0.1145, -0.0492,  0.1713, -0.3060]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1501, -0.0261,  0.1587,  0.0801, -0.0887,  0.0559, -0.1261, -0.1547,\n         0.1559,  0.0543, -0.1450, -0.0639, -0.1166, -0.0182, -0.0832, -0.0888],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.6636e-01,  7.0784e-02,  1.4578e-01, -1.2967e-01, -9.4297e-03,\n          1.4373e-01,  7.6925e-02, -1.5155e-01, -1.7126e-01, -1.3506e-01,\n          1.1042e-01,  1.0904e-02, -1.0088e-01, -1.4177e-02,  8.4127e-02,\n         -6.1534e-06, -1.7151e-01, -8.4242e-02, -1.1183e-01,  1.2153e-01,\n          6.8098e-02, -6.9268e-02,  1.5797e-02,  1.6117e-02,  9.6759e-02,\n          1.3490e-01, -1.3425e-01, -1.5769e-01, -1.6384e-01,  5.6242e-02,\n          6.6303e-02, -1.0101e-01],\n        [-1.1126e-01, -1.4659e-01,  9.3987e-02,  1.5896e-01, -9.8917e-02,\n         -1.5333e-02,  2.8168e-03,  6.6836e-02,  1.3693e-01, -3.7093e-02,\n          1.6520e-01,  1.0439e-02, -1.6497e-01,  9.4471e-02, -1.5413e-01,\n          5.2228e-02,  1.6844e-01,  4.9272e-02,  2.1473e-02, -1.4819e-02,\n         -1.3534e-01,  1.7202e-02, -1.1947e-01,  1.6700e-01, -1.5279e-01,\n          3.2588e-02, -1.5524e-01,  4.3621e-02, -2.3196e-02,  1.8399e-02,\n         -9.4689e-02, -1.6104e-02],\n        [-9.8159e-02,  7.4497e-02,  6.7817e-02, -4.9688e-02, -6.1924e-02,\n         -4.6108e-02,  1.6256e-01,  8.5619e-03, -9.3515e-02, -4.0408e-03,\n          1.7215e-01,  2.6553e-02, -1.1636e-01, -6.7692e-02,  1.4559e-03,\n          1.9898e-02, -7.6716e-02, -4.2839e-02, -1.6705e-01,  9.0487e-02,\n         -4.3218e-02,  1.1687e-01,  7.1521e-02,  6.5249e-02, -1.5148e-01,\n         -5.2543e-02,  5.5330e-02,  6.8240e-02,  1.9637e-02, -3.7688e-03,\n          1.5659e-01, -1.9538e-03],\n        [ 1.7325e-01, -1.5065e-01, -8.0923e-02,  1.9958e-02, -1.0413e-01,\n          1.6733e-01, -1.6691e-01, -1.3161e-02,  2.2573e-02, -4.7095e-02,\n          1.5947e-01, -1.4234e-01, -1.7000e-01, -3.8969e-02,  8.9968e-02,\n          1.2522e-01,  1.4261e-02,  7.0270e-02, -1.0338e-01,  1.0516e-01,\n          1.6869e-01, -7.5320e-03,  9.8199e-03, -4.6554e-02,  1.6874e-01,\n          1.5549e-01, -1.0087e-01, -3.8376e-02,  6.7722e-02, -1.7644e-01,\n         -1.3367e-01,  1.3726e-01],\n        [-1.5254e-01,  9.9060e-02, -1.6231e-03, -1.2738e-02,  1.3756e-01,\n          3.5390e-02,  1.3172e-01,  1.1140e-01,  1.4399e-01,  1.2733e-01,\n         -1.7157e-01, -1.0884e-01, -1.1605e-01, -1.4266e-01,  1.1863e-01,\n          6.1669e-02, -1.0975e-01,  2.4602e-02,  1.3561e-01, -5.0454e-02,\n         -1.0992e-01, -6.3556e-02,  1.0434e-01,  2.2203e-02, -1.1950e-01,\n          1.4942e-01, -1.6267e-01, -1.6438e-01, -6.7434e-02, -1.4646e-01,\n          1.5140e-02, -1.0230e-01],\n        [ 1.3040e-01,  5.0096e-02, -1.2908e-01,  2.0476e-02, -4.5494e-02,\n         -2.7145e-02, -4.1459e-02,  7.2237e-02, -1.3626e-01,  1.2262e-01,\n         -2.0294e-02,  1.1732e-02, -1.3525e-01,  1.2938e-01, -4.5749e-02,\n          1.7048e-01, -6.3888e-02, -7.9747e-02,  1.0498e-02,  1.5871e-01,\n          1.2405e-02,  1.1659e-01,  5.5070e-02,  6.1075e-02, -2.5264e-02,\n          1.1243e-01,  3.0850e-02, -1.7308e-01,  1.1202e-01, -1.0930e-01,\n          7.4203e-02,  1.2892e-01],\n        [-4.5415e-02, -3.3306e-02,  8.4462e-02, -1.1161e-01,  1.4559e-01,\n          1.3430e-01,  2.1213e-02, -9.9885e-02, -8.1530e-02,  3.4552e-02,\n         -4.1020e-02, -1.4179e-01, -1.5668e-01, -2.0000e-02,  1.0457e-01,\n         -1.3969e-01,  1.1480e-01,  3.0043e-02,  7.0294e-02, -1.5101e-01,\n          1.4074e-01, -9.8734e-03, -2.2842e-02, -1.1546e-01, -1.0746e-01,\n          1.1789e-01, -1.2504e-01, -1.1550e-01, -1.1748e-02, -4.5450e-03,\n         -8.0671e-02,  5.8245e-02],\n        [-9.4748e-02,  7.4044e-02,  1.6417e-01, -4.4834e-02,  7.3919e-02,\n          6.7949e-02,  9.7163e-02, -1.2498e-01,  1.4981e-01, -1.5744e-01,\n         -7.1025e-02,  1.7291e-01, -1.6174e-02, -1.6114e-01, -1.4522e-01,\n          1.0141e-01,  1.5932e-01, -1.1645e-01,  2.4743e-02, -4.4643e-03,\n         -1.7421e-01, -9.0191e-02, -1.3379e-01,  4.3648e-02,  1.0123e-01,\n          1.0689e-01, -1.5086e-01,  3.2062e-02, -3.4386e-03,  4.0525e-02,\n          9.4973e-02, -1.4284e-01],\n        [ 1.0371e-01, -1.7106e-01, -1.2746e-01,  8.7558e-02,  8.5838e-02,\n          1.7760e-03, -1.3275e-01,  2.9289e-02, -1.4875e-01,  3.2738e-02,\n          1.1627e-02, -1.3743e-01,  1.0017e-01, -4.2257e-02,  1.2868e-01,\n          1.9191e-02,  9.3196e-02,  9.8268e-02, -1.4410e-01, -4.7627e-02,\n         -9.9230e-02,  1.1555e-01,  1.6462e-01,  1.3181e-01,  1.1756e-01,\n          1.6177e-03,  7.2569e-02,  1.7323e-01,  1.6774e-02,  2.8328e-02,\n         -1.4825e-02, -1.5074e-01],\n        [-1.1360e-01, -5.3348e-03,  4.2313e-04,  4.6718e-02,  1.0604e-01,\n          1.0840e-01,  8.1966e-03,  6.9124e-03, -1.5566e-01,  7.8210e-02,\n          2.5340e-03, -1.7460e-01, -1.3669e-01,  1.6972e-01,  4.6154e-02,\n         -3.0138e-02, -1.7124e-01,  1.4827e-02,  1.4210e-01, -1.7266e-01,\n          1.3572e-03, -5.0357e-02, -1.4500e-01, -3.8659e-02, -1.4271e-01,\n          1.6429e-01, -1.5688e-01,  1.0414e-01,  3.5918e-02, -8.6522e-03,\n         -2.5733e-02, -7.6076e-02],\n        [ 3.8759e-02,  4.7507e-02,  1.3625e-01, -7.5650e-02,  1.4682e-01,\n         -3.8322e-02,  1.4841e-01, -4.3100e-02, -6.6200e-03,  1.1549e-01,\n          1.0892e-01,  4.4729e-02,  6.5128e-03, -5.9024e-02, -6.1070e-03,\n         -3.4915e-02,  5.0813e-03, -1.4966e-01,  8.0001e-02,  8.4308e-02,\n         -2.6981e-02, -1.1715e-01,  5.6144e-02, -9.8001e-02,  3.1976e-03,\n          1.1442e-01,  6.0544e-02, -5.7511e-02, -6.0402e-02,  1.4716e-01,\n          3.8765e-02,  9.7999e-02],\n        [ 1.3721e-01, -1.7664e-01,  6.8487e-02,  7.8302e-02,  1.1566e-01,\n          3.4536e-02,  7.5704e-02,  1.0079e-01,  8.5367e-02, -8.4909e-02,\n          1.3048e-01, -1.2459e-01, -1.7360e-01,  5.2336e-02,  1.5308e-01,\n         -1.6581e-02, -1.2698e-01,  1.9479e-03,  1.2351e-02, -1.6157e-01,\n         -1.5809e-01, -1.0734e-01,  6.6355e-02, -3.3071e-02, -4.3126e-02,\n         -2.1870e-02, -1.1021e-01, -7.5209e-02,  2.1160e-02, -1.3893e-01,\n         -1.4085e-01,  1.5453e-01],\n        [-1.3547e-01, -1.2165e-01, -1.8484e-02, -9.9787e-02, -1.5340e-01,\n          6.0240e-02,  1.3692e-01,  1.0419e-01, -3.4174e-02, -9.8187e-02,\n         -1.7534e-01, -8.8617e-02,  1.6434e-01, -4.7025e-02, -1.6787e-01,\n         -1.0283e-01,  5.4234e-02, -6.0390e-02,  5.7623e-02,  1.6383e-01,\n         -5.7855e-02,  1.1968e-01, -1.1857e-01, -1.6805e-01, -8.0898e-02,\n         -1.5464e-01, -5.2437e-02,  7.8830e-02, -1.5110e-01,  1.5913e-01,\n         -2.9841e-02, -3.5321e-02],\n        [-1.3116e-01, -1.1142e-02, -3.4791e-02, -1.6821e-01, -4.4456e-02,\n         -1.1064e-01, -9.1449e-02,  7.3164e-02, -1.6919e-01,  9.7820e-02,\n          1.4097e-01, -5.9615e-02,  1.1289e-01, -4.0462e-02, -4.3332e-02,\n          1.7572e-02, -1.0607e-01, -9.7520e-02, -1.7371e-01, -6.9246e-02,\n         -1.6751e-01, -1.3171e-01, -6.0671e-02,  1.0314e-01,  1.5702e-01,\n         -1.2357e-01, -4.5033e-02, -6.0019e-02, -1.2914e-01, -9.8530e-02,\n          1.5022e-02,  3.3981e-02],\n        [-5.9427e-02,  4.5982e-02, -1.5627e-01, -2.0307e-02,  1.2578e-01,\n          1.3976e-01,  1.2118e-01,  4.7313e-02,  1.0311e-01,  1.1774e-01,\n         -1.6122e-01, -1.6580e-01,  6.6068e-02, -8.8734e-02,  1.0181e-01,\n         -8.1259e-02,  1.6786e-01, -8.1443e-02, -1.2110e-01,  9.9124e-02,\n          3.4741e-02,  7.0273e-02,  1.5271e-01, -3.5209e-02,  1.3237e-02,\n          3.3047e-02, -4.1688e-02, -4.3852e-02, -1.1726e-01,  1.2921e-01,\n          4.7110e-02,  4.3507e-02],\n        [-1.3948e-02,  2.4343e-03,  4.0404e-02,  1.5984e-03,  8.4276e-02,\n          7.6105e-02, -1.8575e-02, -6.2040e-02,  3.4721e-03, -8.8838e-02,\n         -1.2950e-02,  1.5339e-01,  9.2106e-02, -1.0219e-01, -4.5357e-02,\n          1.0140e-01,  1.6951e-01,  1.0876e-01, -7.5804e-02,  1.2891e-02,\n          1.3000e-01,  4.2289e-02, -1.6279e-01,  9.7179e-02, -1.1951e-01,\n          1.1746e-01,  6.4261e-02,  1.1431e-01,  5.6060e-02,  1.7360e-01,\n          1.6426e-01, -1.2778e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1163, -0.0837, -0.1893,  0.0867, -0.0699, -0.2007,  0.0877,  0.1016],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0826, -0.1904,  0.0669,  0.2149, -0.1627, -0.1449,  0.1280, -0.1543,\n         -0.1317, -0.0078, -0.1276,  0.0518,  0.2374,  0.1947, -0.1425,  0.2443],\n        [-0.1749,  0.2300, -0.1782,  0.2217,  0.0682,  0.1372, -0.2000,  0.0225,\n         -0.0721, -0.0089, -0.2468, -0.0573, -0.2001,  0.1133, -0.0600,  0.1656],\n        [ 0.0694, -0.1232,  0.2435,  0.0615, -0.0575, -0.1779,  0.0468, -0.2467,\n         -0.1637, -0.0068, -0.2314,  0.2284,  0.1509,  0.0055,  0.1952, -0.1893],\n        [ 0.0123, -0.1453, -0.0760, -0.2397, -0.1654, -0.1146,  0.0789,  0.1772,\n          0.0539,  0.0136, -0.0481,  0.0810, -0.2329,  0.0082, -0.0037, -0.2471],\n        [-0.2298, -0.1826,  0.1506,  0.0242, -0.2031,  0.1170,  0.1640, -0.1128,\n         -0.1315, -0.1054,  0.0933, -0.1022, -0.2491,  0.2076,  0.1399, -0.1474],\n        [ 0.1091,  0.0356,  0.1150,  0.1114,  0.1658,  0.1294, -0.0416,  0.1744,\n          0.0391, -0.1388,  0.2014, -0.2092, -0.0346,  0.0844,  0.2312, -0.0174],\n        [ 0.0877, -0.1373, -0.0628, -0.2449, -0.1895,  0.1814, -0.1087, -0.2015,\n         -0.1645,  0.0846,  0.0606,  0.1342, -0.1573, -0.1134, -0.1222,  0.1515],\n        [-0.1723,  0.1576, -0.0675,  0.1169, -0.0968, -0.0849, -0.0046, -0.0884,\n          0.0817,  0.2159, -0.0626,  0.1602, -0.0951, -0.1340,  0.0735, -0.0573]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1473, -0.0187,  0.2164, -0.1318], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2162, -0.3135,  0.1250, -0.2941,  0.2916,  0.1406, -0.0661,  0.1625],\n        [ 0.1035, -0.2701, -0.1916,  0.1299,  0.2267,  0.1920, -0.3412,  0.3483],\n        [-0.1090, -0.0469, -0.1422, -0.0544, -0.0474,  0.0719,  0.2492,  0.2878],\n        [-0.1093,  0.2929,  0.2206,  0.2802,  0.0370,  0.1415, -0.1612, -0.2033]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	16,
            "_traj_per_epoch":	8,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x73545546c490>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1014610000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1014610000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	16,
    "traj_per_epoch":	8
}