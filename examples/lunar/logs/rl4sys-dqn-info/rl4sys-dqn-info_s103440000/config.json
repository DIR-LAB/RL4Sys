{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s103440000"
    },
    "q_lr":	0.0005,
    "seed":	103440000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000001ED1018D0C0>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1723, -0.2881, -0.0656, -0.1615, -0.1229,  0.1950, -0.2280, -0.1102,\n         0.0369, -0.2891,  0.1613, -0.2968, -0.0372, -0.0574, -0.2690, -0.1839,\n        -0.1872,  0.0196, -0.0717,  0.2218, -0.2692,  0.0939, -0.0541,  0.1613,\n        -0.0487, -0.0337,  0.3474,  0.2123, -0.3476, -0.3315,  0.2431, -0.3017],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1811,  0.1596,  0.2616, -0.1912, -0.0950, -0.1338, -0.0055, -0.1565],\n        [-0.2956, -0.1062,  0.2735, -0.1400,  0.3198, -0.2057, -0.2711,  0.0907],\n        [ 0.2961,  0.1266,  0.2512, -0.2132, -0.1566, -0.0873, -0.3002,  0.3279],\n        [ 0.1849, -0.0937,  0.2127, -0.0116, -0.1183, -0.1971,  0.1692,  0.1876],\n        [-0.2391, -0.2490, -0.0328, -0.0183,  0.2697, -0.3321, -0.1003,  0.1018],\n        [ 0.1340,  0.0013, -0.3399, -0.0794, -0.1650,  0.3185, -0.0386, -0.0709],\n        [-0.2067,  0.0435,  0.1442, -0.0794, -0.3193, -0.2344,  0.1555,  0.1180],\n        [ 0.1852, -0.0048,  0.2340,  0.2270, -0.3316, -0.1080, -0.2016, -0.2624],\n        [-0.1482,  0.2167,  0.1966, -0.2757, -0.1544, -0.0977, -0.1507,  0.0398],\n        [ 0.0870,  0.3253, -0.1436, -0.0888, -0.3350, -0.2730,  0.1434,  0.0672],\n        [ 0.0707, -0.2646, -0.2077, -0.2790,  0.1123, -0.1816, -0.0842, -0.2163],\n        [-0.1052, -0.3419, -0.2769, -0.1861, -0.2006,  0.2583, -0.0525,  0.1013],\n        [ 0.2232, -0.0257,  0.2891,  0.3241,  0.2375, -0.3265,  0.0919,  0.1709],\n        [ 0.1490,  0.0346, -0.2805, -0.0512, -0.2422,  0.1099,  0.2865, -0.1038],\n        [ 0.2891, -0.0371,  0.0817,  0.2124,  0.0679, -0.0305, -0.3378,  0.1755],\n        [ 0.2345,  0.1275,  0.0164,  0.3279, -0.3370, -0.3511,  0.3086, -0.2200],\n        [-0.0861,  0.3254, -0.0025, -0.0174,  0.1646, -0.0972, -0.3214, -0.1662],\n        [ 0.1768, -0.2781,  0.2204,  0.0162,  0.1273, -0.1894, -0.0634,  0.2551],\n        [-0.0611, -0.1619,  0.1655, -0.0712, -0.2448,  0.0018, -0.0714,  0.2305],\n        [-0.0005,  0.3370, -0.2077, -0.0037,  0.3227, -0.1729,  0.2542,  0.0903],\n        [ 0.2469, -0.2781,  0.1719,  0.2802,  0.3134, -0.0649, -0.3490,  0.0271],\n        [ 0.3231, -0.3264,  0.2087,  0.0887, -0.0855,  0.2461, -0.1832, -0.1675],\n        [-0.1929, -0.2978, -0.0775, -0.1172, -0.3175,  0.2663, -0.0782, -0.1221],\n        [-0.1725,  0.1446, -0.0302,  0.2747,  0.2722, -0.3033,  0.2914, -0.0985],\n        [ 0.0158,  0.2308,  0.2454,  0.1771,  0.3430,  0.3526, -0.1878,  0.3504],\n        [ 0.1486, -0.0934,  0.1690, -0.0948,  0.0663, -0.2947, -0.0209, -0.0670],\n        [ 0.0780, -0.3310, -0.0730,  0.0724, -0.2908, -0.3350, -0.0173,  0.1268],\n        [-0.1637,  0.0683, -0.1371,  0.3211, -0.2483,  0.1398, -0.2811,  0.2418],\n        [ 0.1003, -0.3409,  0.1382,  0.1172,  0.0738,  0.2485, -0.0393, -0.0910],\n        [-0.0043, -0.3363, -0.0799, -0.3300,  0.0756,  0.2166,  0.1605, -0.1232],\n        [ 0.0155,  0.2772, -0.0621,  0.2323, -0.1161, -0.2544,  0.2584,  0.1035],\n        [-0.2774, -0.1407, -0.0514,  0.1315, -0.0986,  0.3256, -0.0561,  0.1367]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0021,  0.0947,  0.1430,  0.0309, -0.1249, -0.0912,  0.0356, -0.0778,\n         0.1180, -0.1131, -0.1522, -0.0253, -0.0603,  0.0194, -0.0664, -0.0618],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 2.8894e-02,  6.0583e-03,  1.0189e-01,  1.5871e-01,  3.3321e-03,\n         -1.1386e-01, -1.5875e-01,  1.4453e-02, -1.4701e-02, -2.3735e-02,\n          2.5030e-02, -1.3136e-01, -3.8285e-02, -3.3857e-02,  2.7574e-02,\n          1.0169e-01,  8.1244e-02, -4.8734e-02,  3.1215e-02, -1.7552e-01,\n          1.3039e-01,  1.4191e-01,  9.9928e-02,  1.7494e-02,  6.3145e-02,\n          9.1369e-02, -6.2082e-02, -1.1777e-01, -8.1430e-02, -1.0025e-01,\n          7.9560e-02, -4.0955e-02],\n        [ 5.6146e-02, -1.7722e-02,  7.0643e-02, -2.4647e-03,  8.6823e-02,\n         -1.3346e-01, -2.7073e-02, -2.1350e-02, -1.5093e-01, -9.0051e-02,\n         -1.6797e-01,  6.3330e-02,  1.5883e-01, -1.1543e-01,  1.0385e-02,\n          1.0057e-01, -1.6640e-01, -1.4426e-01,  1.2590e-02, -3.4516e-02,\n         -1.3109e-02,  1.2312e-01, -6.1059e-02,  7.7965e-02,  1.1624e-01,\n          3.6697e-02, -4.6498e-03, -1.3447e-02, -1.0849e-01,  2.1487e-02,\n         -7.7040e-02, -1.4472e-01],\n        [-1.5873e-01,  1.6453e-01, -1.0604e-01, -4.7558e-02, -1.4432e-01,\n          1.2279e-01,  6.4189e-02, -1.1628e-01,  8.6915e-02, -9.6884e-02,\n          1.7364e-01,  1.5015e-01,  4.5009e-02, -4.2255e-02,  1.0385e-01,\n         -1.3910e-01,  1.3072e-01,  2.8669e-02, -8.5640e-02, -9.5237e-02,\n          1.1776e-01,  5.2780e-02,  1.4915e-01, -1.7792e-02, -2.6816e-02,\n          8.0044e-02, -3.0015e-02,  7.4634e-02, -2.9197e-02, -5.9554e-02,\n         -1.6713e-01,  8.4963e-02],\n        [ 1.2851e-01,  8.4459e-02, -1.0876e-01,  6.0919e-02, -1.1423e-01,\n         -6.7373e-02, -1.4318e-01,  9.4980e-02, -1.5184e-01, -4.5362e-02,\n          9.3264e-02, -8.5098e-02,  1.2103e-03, -1.6369e-01,  4.8079e-03,\n          3.7768e-02, -4.4268e-02, -1.7231e-01,  1.4486e-01, -1.3613e-01,\n          1.6081e-01, -9.0034e-04, -1.5178e-01,  1.1460e-01,  4.7948e-02,\n         -6.3068e-02, -1.3686e-01,  5.3006e-02, -1.0339e-02,  3.5041e-02,\n          1.2351e-01, -1.2210e-02],\n        [-1.6708e-01,  9.6412e-03,  5.3492e-02,  8.5333e-02, -5.6106e-02,\n          1.1254e-01,  1.2213e-02, -4.1262e-02, -8.2574e-02, -4.0387e-02,\n          1.5718e-01, -1.6724e-01,  1.1981e-01, -5.2142e-02, -1.0766e-01,\n          7.7978e-02, -1.6444e-01, -2.4171e-02, -4.2228e-03, -2.1530e-02,\n          1.1439e-01, -6.9819e-02, -7.9213e-03, -2.2865e-02,  9.4830e-02,\n          8.1084e-02,  1.1213e-01,  1.1284e-01, -7.6242e-02,  1.2358e-02,\n          7.1178e-02, -1.0141e-01],\n        [-1.5226e-04, -1.6064e-01, -8.5113e-02,  1.4108e-01, -1.3713e-01,\n         -1.2906e-01, -1.2314e-01,  8.9559e-03, -8.8568e-03,  1.0882e-01,\n         -1.8082e-02, -1.4523e-01,  9.5793e-02, -2.6890e-02,  6.1154e-02,\n          1.5870e-02,  1.2917e-01,  1.2579e-01,  2.9560e-02, -6.0767e-03,\n         -1.3116e-02,  3.5723e-02, -1.5446e-02, -3.9707e-02, -2.4942e-02,\n         -1.1980e-01, -1.6314e-01, -2.8738e-02,  1.1925e-01,  1.5449e-01,\n          6.4100e-02,  1.4552e-01],\n        [ 7.9194e-02, -1.3108e-01, -2.8507e-02, -2.2025e-02, -1.1454e-01,\n          1.7491e-01,  2.5350e-02, -1.4549e-01,  1.4288e-01, -5.6911e-02,\n          1.2864e-01,  1.5922e-01, -8.1074e-02,  9.2439e-03,  3.2618e-02,\n          9.3588e-02, -1.4249e-01, -1.2217e-02, -9.4874e-02, -6.7508e-02,\n         -5.1001e-02,  1.5058e-01,  1.5890e-01,  1.4094e-01,  2.8271e-02,\n         -4.2760e-02,  1.2579e-01,  1.4215e-01,  1.0332e-01,  1.7894e-02,\n         -2.7083e-02,  4.0875e-03],\n        [-1.1701e-01, -9.8353e-02,  4.3510e-02, -1.0522e-01, -1.5343e-01,\n          1.3195e-01, -1.1021e-01,  1.2735e-01, -1.2232e-01,  1.6626e-02,\n         -9.6387e-02, -9.3065e-02, -1.7154e-01, -2.9311e-02, -1.2591e-01,\n         -6.8228e-02, -5.3593e-02, -9.2577e-02, -1.6406e-01, -1.2756e-01,\n          4.3840e-02,  8.9559e-02, -9.2849e-02, -1.7049e-01, -1.3597e-01,\n          8.4994e-02,  9.6409e-02,  1.0396e-01,  2.8404e-02, -7.5650e-03,\n         -1.0553e-01,  1.3792e-01],\n        [ 1.1067e-01,  1.6609e-01,  1.4479e-01,  9.9690e-02, -1.3767e-01,\n         -7.7817e-02, -9.7943e-02, -1.1309e-01, -5.8071e-03, -1.2887e-01,\n          5.0780e-02,  2.6458e-02,  3.3253e-02, -2.1254e-02, -8.1986e-02,\n         -7.8410e-02,  8.7232e-03, -1.6160e-01,  1.6932e-01, -1.2974e-01,\n          4.2788e-02, -3.4098e-02,  3.0826e-02, -1.2073e-02,  4.1675e-02,\n          4.1094e-02,  1.3837e-01,  5.6171e-02, -7.5344e-02, -1.1931e-01,\n         -2.4827e-02,  1.0952e-01],\n        [-1.7308e-01, -6.1506e-02,  1.0183e-02, -3.0855e-02, -1.0979e-01,\n         -7.1850e-02,  5.3056e-02,  1.3131e-01, -3.6501e-02, -7.8095e-02,\n          1.2715e-01, -2.8633e-02,  6.5476e-05,  3.5935e-02,  8.8792e-02,\n         -6.6768e-02, -3.8305e-02, -4.7609e-02, -1.1339e-01, -2.8134e-02,\n          1.0628e-01, -1.3497e-02,  5.0628e-02,  4.6187e-02,  1.7323e-01,\n         -6.8534e-02, -1.6316e-01,  1.1681e-01,  9.7512e-02,  3.8005e-02,\n         -1.6115e-01,  1.6222e-02],\n        [-6.6172e-03, -2.6197e-02,  1.9474e-02,  1.4808e-01, -4.6038e-02,\n          1.7565e-01, -2.2684e-02, -3.1895e-02, -2.0490e-02,  1.4899e-01,\n          2.4882e-02,  6.9396e-02, -1.5831e-02,  1.0274e-01, -7.4435e-02,\n         -3.2630e-02, -1.2460e-01, -1.0132e-01, -8.3259e-02,  1.4521e-01,\n         -6.1459e-02,  9.1932e-02,  1.7328e-01,  1.3115e-01,  1.3096e-02,\n          9.2746e-02, -3.0480e-02, -2.2634e-02, -1.4979e-01, -1.1679e-01,\n         -3.8557e-03, -8.5929e-02],\n        [ 9.0901e-02,  1.0360e-01,  9.1190e-03, -1.7363e-01, -2.0445e-02,\n         -4.2594e-02, -8.0077e-02,  3.2121e-02, -3.0731e-02,  8.5453e-02,\n         -1.5821e-03,  1.7148e-01,  3.1238e-02,  1.6852e-02,  8.4864e-02,\n          6.7500e-02, -7.9376e-02, -3.4042e-02,  5.0613e-02, -5.8117e-02,\n         -1.2975e-01, -1.2738e-01,  4.1145e-02,  9.8920e-02,  1.4067e-01,\n         -5.1043e-02, -8.6391e-02,  1.6684e-01,  6.3710e-02, -1.6877e-01,\n          8.1589e-02, -1.5389e-01],\n        [-1.3977e-01,  1.6771e-01, -1.5621e-01,  1.0020e-01,  1.0113e-01,\n         -1.4968e-01, -1.3598e-01, -1.2001e-01,  1.7573e-01,  6.8719e-02,\n         -8.6301e-03, -4.1562e-02, -8.2338e-03, -1.1958e-01,  4.5053e-02,\n         -5.2897e-02,  1.0437e-01,  1.3507e-01,  1.4689e-02,  1.0254e-01,\n         -1.3471e-02, -1.5380e-01, -1.0902e-01, -2.0764e-02,  5.5973e-02,\n          1.6332e-01, -4.2827e-02, -8.6714e-02, -4.0314e-02,  6.8781e-02,\n         -8.3160e-02,  1.7307e-01],\n        [-1.3633e-01, -7.5528e-02,  7.3385e-02,  1.5429e-01, -6.7003e-02,\n         -4.7145e-02, -8.7176e-02,  1.2641e-01,  1.6267e-01, -1.8550e-02,\n         -2.1566e-02, -1.6782e-01, -8.6689e-02,  1.2847e-01,  1.0892e-01,\n          1.5273e-01, -1.5926e-01,  1.4637e-01, -1.2801e-01, -1.4067e-01,\n         -3.8914e-02,  7.5896e-02, -1.5751e-01,  3.5857e-02, -8.0124e-02,\n          9.0879e-02, -2.0890e-02,  1.6616e-01, -1.9195e-02,  1.1151e-01,\n          1.1684e-01,  5.1404e-02],\n        [-8.1523e-02,  1.4758e-01, -3.5993e-02, -1.2367e-01, -7.5649e-02,\n         -9.4245e-02, -2.2626e-02, -1.4929e-01, -1.8540e-02, -8.2705e-02,\n          2.8614e-02, -1.8944e-02,  6.2847e-02, -8.2215e-03, -1.6555e-01,\n          1.2716e-01,  1.6207e-01, -1.2632e-01, -9.4036e-02, -1.3643e-01,\n         -7.6264e-02,  1.5648e-01,  3.7053e-02,  1.4775e-02,  1.6983e-01,\n         -1.7293e-01, -1.0200e-01,  7.9697e-02,  1.6408e-01, -6.3630e-02,\n         -2.5835e-02,  1.6503e-01],\n        [ 3.8896e-02, -9.3226e-04,  1.7189e-01, -5.3760e-02, -1.3808e-01,\n          1.2455e-01,  1.5512e-01,  1.3641e-01, -4.2360e-02, -4.4300e-03,\n         -1.0957e-01,  1.2691e-01,  4.0543e-02, -1.3464e-01, -1.2959e-01,\n         -1.2162e-01, -3.8057e-02, -1.0108e-01, -1.3193e-01, -1.0437e-01,\n         -8.9722e-02, -5.7884e-02, -5.3540e-03, -4.7751e-04,  1.4600e-01,\n         -1.5625e-01,  1.4237e-01, -5.5929e-02, -1.1082e-01, -7.9902e-02,\n          1.3746e-01, -1.6048e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0835, -0.0623,  0.1745, -0.1618,  0.1932,  0.0390, -0.2216,  0.0999],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0287,  0.0502, -0.1378,  0.2293, -0.2192, -0.1980, -0.1637,  0.0961,\n          0.0910,  0.0486, -0.0649, -0.1217,  0.2226,  0.0230,  0.1233, -0.1884],\n        [-0.0754,  0.2197,  0.0529, -0.1427,  0.1523, -0.1020, -0.1933,  0.0371,\n         -0.1912, -0.0978,  0.1345, -0.0229, -0.1336, -0.2064,  0.1009, -0.2254],\n        [-0.1871,  0.0227,  0.0653,  0.2148, -0.1938, -0.2394, -0.2185,  0.0677,\n          0.1994,  0.0342, -0.0956,  0.1351, -0.2050,  0.2325, -0.1076,  0.1341],\n        [ 0.1373, -0.0874, -0.0184, -0.0381,  0.1924,  0.0601, -0.0487, -0.1150,\n          0.1230, -0.2472, -0.0981,  0.0070, -0.1573, -0.0296, -0.1465, -0.0020],\n        [ 0.0429, -0.2064, -0.0242, -0.1651, -0.0259,  0.1417,  0.1984, -0.0519,\n          0.0552,  0.0213, -0.2254,  0.0419,  0.1871, -0.2109,  0.1732, -0.2113],\n        [ 0.1644,  0.1615,  0.1159, -0.1522, -0.2364, -0.1396,  0.1181,  0.0976,\n          0.0321, -0.0653,  0.0275, -0.0670, -0.1488, -0.1230,  0.0130,  0.0854],\n        [-0.2156,  0.0226,  0.0111, -0.0694, -0.1803,  0.0420, -0.1668, -0.0052,\n          0.1206, -0.0564, -0.0142, -0.0588, -0.0430, -0.1233,  0.0984, -0.1250],\n        [ 0.0225, -0.1707,  0.0999,  0.1051, -0.0830, -0.0529,  0.1984,  0.1331,\n          0.2209, -0.1415, -0.2443,  0.1176, -0.0731, -0.0426,  0.0838,  0.0538]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0771], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2942,  0.3211, -0.3427, -0.1541, -0.2281, -0.1665,  0.2821, -0.1693]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1811,  0.1596,  0.2616, -0.1912, -0.0950, -0.1338, -0.0055, -0.1565],\n        [-0.2956, -0.1062,  0.2735, -0.1400,  0.3198, -0.2057, -0.2711,  0.0907],\n        [ 0.2961,  0.1266,  0.2512, -0.2132, -0.1566, -0.0873, -0.3002,  0.3279],\n        [ 0.1849, -0.0937,  0.2127, -0.0116, -0.1183, -0.1971,  0.1692,  0.1876],\n        [-0.2391, -0.2490, -0.0328, -0.0183,  0.2697, -0.3321, -0.1003,  0.1018],\n        [ 0.1340,  0.0013, -0.3399, -0.0794, -0.1650,  0.3185, -0.0386, -0.0709],\n        [-0.2067,  0.0435,  0.1442, -0.0794, -0.3193, -0.2344,  0.1555,  0.1180],\n        [ 0.1852, -0.0048,  0.2340,  0.2270, -0.3316, -0.1080, -0.2016, -0.2624],\n        [-0.1482,  0.2167,  0.1966, -0.2757, -0.1544, -0.0977, -0.1507,  0.0398],\n        [ 0.0870,  0.3253, -0.1436, -0.0888, -0.3350, -0.2730,  0.1434,  0.0672],\n        [ 0.0707, -0.2646, -0.2077, -0.2790,  0.1123, -0.1816, -0.0842, -0.2163],\n        [-0.1052, -0.3419, -0.2769, -0.1861, -0.2006,  0.2583, -0.0525,  0.1013],\n        [ 0.2232, -0.0257,  0.2891,  0.3241,  0.2375, -0.3265,  0.0919,  0.1709],\n        [ 0.1490,  0.0346, -0.2805, -0.0512, -0.2422,  0.1099,  0.2865, -0.1038],\n        [ 0.2891, -0.0371,  0.0817,  0.2124,  0.0679, -0.0305, -0.3378,  0.1755],\n        [ 0.2345,  0.1275,  0.0164,  0.3279, -0.3370, -0.3511,  0.3086, -0.2200],\n        [-0.0861,  0.3254, -0.0025, -0.0174,  0.1646, -0.0972, -0.3214, -0.1662],\n        [ 0.1768, -0.2781,  0.2204,  0.0162,  0.1273, -0.1894, -0.0634,  0.2551],\n        [-0.0611, -0.1619,  0.1655, -0.0712, -0.2448,  0.0018, -0.0714,  0.2305],\n        [-0.0005,  0.3370, -0.2077, -0.0037,  0.3227, -0.1729,  0.2542,  0.0903],\n        [ 0.2469, -0.2781,  0.1719,  0.2802,  0.3134, -0.0649, -0.3490,  0.0271],\n        [ 0.3231, -0.3264,  0.2087,  0.0887, -0.0855,  0.2461, -0.1832, -0.1675],\n        [-0.1929, -0.2978, -0.0775, -0.1172, -0.3175,  0.2663, -0.0782, -0.1221],\n        [-0.1725,  0.1446, -0.0302,  0.2747,  0.2722, -0.3033,  0.2914, -0.0985],\n        [ 0.0158,  0.2308,  0.2454,  0.1771,  0.3430,  0.3526, -0.1878,  0.3504],\n        [ 0.1486, -0.0934,  0.1690, -0.0948,  0.0663, -0.2947, -0.0209, -0.0670],\n        [ 0.0780, -0.3310, -0.0730,  0.0724, -0.2908, -0.3350, -0.0173,  0.1268],\n        [-0.1637,  0.0683, -0.1371,  0.3211, -0.2483,  0.1398, -0.2811,  0.2418],\n        [ 0.1003, -0.3409,  0.1382,  0.1172,  0.0738,  0.2485, -0.0393, -0.0910],\n        [-0.0043, -0.3363, -0.0799, -0.3300,  0.0756,  0.2166,  0.1605, -0.1232],\n        [ 0.0155,  0.2772, -0.0621,  0.2323, -0.1161, -0.2544,  0.2584,  0.1035],\n        [-0.2774, -0.1407, -0.0514,  0.1315, -0.0986,  0.3256, -0.0561,  0.1367]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1723, -0.2881, -0.0656, -0.1615, -0.1229,  0.1950, -0.2280, -0.1102,\n         0.0369, -0.2891,  0.1613, -0.2968, -0.0372, -0.0574, -0.2690, -0.1839,\n        -0.1872,  0.0196, -0.0717,  0.2218, -0.2692,  0.0939, -0.0541,  0.1613,\n        -0.0487, -0.0337,  0.3474,  0.2123, -0.3476, -0.3315,  0.2431, -0.3017],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 2.8894e-02,  6.0583e-03,  1.0189e-01,  1.5871e-01,  3.3321e-03,\n         -1.1386e-01, -1.5875e-01,  1.4453e-02, -1.4701e-02, -2.3735e-02,\n          2.5030e-02, -1.3136e-01, -3.8285e-02, -3.3857e-02,  2.7574e-02,\n          1.0169e-01,  8.1244e-02, -4.8734e-02,  3.1215e-02, -1.7552e-01,\n          1.3039e-01,  1.4191e-01,  9.9928e-02,  1.7494e-02,  6.3145e-02,\n          9.1369e-02, -6.2082e-02, -1.1777e-01, -8.1430e-02, -1.0025e-01,\n          7.9560e-02, -4.0955e-02],\n        [ 5.6146e-02, -1.7722e-02,  7.0643e-02, -2.4647e-03,  8.6823e-02,\n         -1.3346e-01, -2.7073e-02, -2.1350e-02, -1.5093e-01, -9.0051e-02,\n         -1.6797e-01,  6.3330e-02,  1.5883e-01, -1.1543e-01,  1.0385e-02,\n          1.0057e-01, -1.6640e-01, -1.4426e-01,  1.2590e-02, -3.4516e-02,\n         -1.3109e-02,  1.2312e-01, -6.1059e-02,  7.7965e-02,  1.1624e-01,\n          3.6697e-02, -4.6498e-03, -1.3447e-02, -1.0849e-01,  2.1487e-02,\n         -7.7040e-02, -1.4472e-01],\n        [-1.5873e-01,  1.6453e-01, -1.0604e-01, -4.7558e-02, -1.4432e-01,\n          1.2279e-01,  6.4189e-02, -1.1628e-01,  8.6915e-02, -9.6884e-02,\n          1.7364e-01,  1.5015e-01,  4.5009e-02, -4.2255e-02,  1.0385e-01,\n         -1.3910e-01,  1.3072e-01,  2.8669e-02, -8.5640e-02, -9.5237e-02,\n          1.1776e-01,  5.2780e-02,  1.4915e-01, -1.7792e-02, -2.6816e-02,\n          8.0044e-02, -3.0015e-02,  7.4634e-02, -2.9197e-02, -5.9554e-02,\n         -1.6713e-01,  8.4963e-02],\n        [ 1.2851e-01,  8.4459e-02, -1.0876e-01,  6.0919e-02, -1.1423e-01,\n         -6.7373e-02, -1.4318e-01,  9.4980e-02, -1.5184e-01, -4.5362e-02,\n          9.3264e-02, -8.5098e-02,  1.2103e-03, -1.6369e-01,  4.8079e-03,\n          3.7768e-02, -4.4268e-02, -1.7231e-01,  1.4486e-01, -1.3613e-01,\n          1.6081e-01, -9.0034e-04, -1.5178e-01,  1.1460e-01,  4.7948e-02,\n         -6.3068e-02, -1.3686e-01,  5.3006e-02, -1.0339e-02,  3.5041e-02,\n          1.2351e-01, -1.2210e-02],\n        [-1.6708e-01,  9.6412e-03,  5.3492e-02,  8.5333e-02, -5.6106e-02,\n          1.1254e-01,  1.2213e-02, -4.1262e-02, -8.2574e-02, -4.0387e-02,\n          1.5718e-01, -1.6724e-01,  1.1981e-01, -5.2142e-02, -1.0766e-01,\n          7.7978e-02, -1.6444e-01, -2.4171e-02, -4.2228e-03, -2.1530e-02,\n          1.1439e-01, -6.9819e-02, -7.9213e-03, -2.2865e-02,  9.4830e-02,\n          8.1084e-02,  1.1213e-01,  1.1284e-01, -7.6242e-02,  1.2358e-02,\n          7.1178e-02, -1.0141e-01],\n        [-1.5226e-04, -1.6064e-01, -8.5113e-02,  1.4108e-01, -1.3713e-01,\n         -1.2906e-01, -1.2314e-01,  8.9559e-03, -8.8568e-03,  1.0882e-01,\n         -1.8082e-02, -1.4523e-01,  9.5793e-02, -2.6890e-02,  6.1154e-02,\n          1.5870e-02,  1.2917e-01,  1.2579e-01,  2.9560e-02, -6.0767e-03,\n         -1.3116e-02,  3.5723e-02, -1.5446e-02, -3.9707e-02, -2.4942e-02,\n         -1.1980e-01, -1.6314e-01, -2.8738e-02,  1.1925e-01,  1.5449e-01,\n          6.4100e-02,  1.4552e-01],\n        [ 7.9194e-02, -1.3108e-01, -2.8507e-02, -2.2025e-02, -1.1454e-01,\n          1.7491e-01,  2.5350e-02, -1.4549e-01,  1.4288e-01, -5.6911e-02,\n          1.2864e-01,  1.5922e-01, -8.1074e-02,  9.2439e-03,  3.2618e-02,\n          9.3588e-02, -1.4249e-01, -1.2217e-02, -9.4874e-02, -6.7508e-02,\n         -5.1001e-02,  1.5058e-01,  1.5890e-01,  1.4094e-01,  2.8271e-02,\n         -4.2760e-02,  1.2579e-01,  1.4215e-01,  1.0332e-01,  1.7894e-02,\n         -2.7083e-02,  4.0875e-03],\n        [-1.1701e-01, -9.8353e-02,  4.3510e-02, -1.0522e-01, -1.5343e-01,\n          1.3195e-01, -1.1021e-01,  1.2735e-01, -1.2232e-01,  1.6626e-02,\n         -9.6387e-02, -9.3065e-02, -1.7154e-01, -2.9311e-02, -1.2591e-01,\n         -6.8228e-02, -5.3593e-02, -9.2577e-02, -1.6406e-01, -1.2756e-01,\n          4.3840e-02,  8.9559e-02, -9.2849e-02, -1.7049e-01, -1.3597e-01,\n          8.4994e-02,  9.6409e-02,  1.0396e-01,  2.8404e-02, -7.5650e-03,\n         -1.0553e-01,  1.3792e-01],\n        [ 1.1067e-01,  1.6609e-01,  1.4479e-01,  9.9690e-02, -1.3767e-01,\n         -7.7817e-02, -9.7943e-02, -1.1309e-01, -5.8071e-03, -1.2887e-01,\n          5.0780e-02,  2.6458e-02,  3.3253e-02, -2.1254e-02, -8.1986e-02,\n         -7.8410e-02,  8.7232e-03, -1.6160e-01,  1.6932e-01, -1.2974e-01,\n          4.2788e-02, -3.4098e-02,  3.0826e-02, -1.2073e-02,  4.1675e-02,\n          4.1094e-02,  1.3837e-01,  5.6171e-02, -7.5344e-02, -1.1931e-01,\n         -2.4827e-02,  1.0952e-01],\n        [-1.7308e-01, -6.1506e-02,  1.0183e-02, -3.0855e-02, -1.0979e-01,\n         -7.1850e-02,  5.3056e-02,  1.3131e-01, -3.6501e-02, -7.8095e-02,\n          1.2715e-01, -2.8633e-02,  6.5476e-05,  3.5935e-02,  8.8792e-02,\n         -6.6768e-02, -3.8305e-02, -4.7609e-02, -1.1339e-01, -2.8134e-02,\n          1.0628e-01, -1.3497e-02,  5.0628e-02,  4.6187e-02,  1.7323e-01,\n         -6.8534e-02, -1.6316e-01,  1.1681e-01,  9.7512e-02,  3.8005e-02,\n         -1.6115e-01,  1.6222e-02],\n        [-6.6172e-03, -2.6197e-02,  1.9474e-02,  1.4808e-01, -4.6038e-02,\n          1.7565e-01, -2.2684e-02, -3.1895e-02, -2.0490e-02,  1.4899e-01,\n          2.4882e-02,  6.9396e-02, -1.5831e-02,  1.0274e-01, -7.4435e-02,\n         -3.2630e-02, -1.2460e-01, -1.0132e-01, -8.3259e-02,  1.4521e-01,\n         -6.1459e-02,  9.1932e-02,  1.7328e-01,  1.3115e-01,  1.3096e-02,\n          9.2746e-02, -3.0480e-02, -2.2634e-02, -1.4979e-01, -1.1679e-01,\n         -3.8557e-03, -8.5929e-02],\n        [ 9.0901e-02,  1.0360e-01,  9.1190e-03, -1.7363e-01, -2.0445e-02,\n         -4.2594e-02, -8.0077e-02,  3.2121e-02, -3.0731e-02,  8.5453e-02,\n         -1.5821e-03,  1.7148e-01,  3.1238e-02,  1.6852e-02,  8.4864e-02,\n          6.7500e-02, -7.9376e-02, -3.4042e-02,  5.0613e-02, -5.8117e-02,\n         -1.2975e-01, -1.2738e-01,  4.1145e-02,  9.8920e-02,  1.4067e-01,\n         -5.1043e-02, -8.6391e-02,  1.6684e-01,  6.3710e-02, -1.6877e-01,\n          8.1589e-02, -1.5389e-01],\n        [-1.3977e-01,  1.6771e-01, -1.5621e-01,  1.0020e-01,  1.0113e-01,\n         -1.4968e-01, -1.3598e-01, -1.2001e-01,  1.7573e-01,  6.8719e-02,\n         -8.6301e-03, -4.1562e-02, -8.2338e-03, -1.1958e-01,  4.5053e-02,\n         -5.2897e-02,  1.0437e-01,  1.3507e-01,  1.4689e-02,  1.0254e-01,\n         -1.3471e-02, -1.5380e-01, -1.0902e-01, -2.0764e-02,  5.5973e-02,\n          1.6332e-01, -4.2827e-02, -8.6714e-02, -4.0314e-02,  6.8781e-02,\n         -8.3160e-02,  1.7307e-01],\n        [-1.3633e-01, -7.5528e-02,  7.3385e-02,  1.5429e-01, -6.7003e-02,\n         -4.7145e-02, -8.7176e-02,  1.2641e-01,  1.6267e-01, -1.8550e-02,\n         -2.1566e-02, -1.6782e-01, -8.6689e-02,  1.2847e-01,  1.0892e-01,\n          1.5273e-01, -1.5926e-01,  1.4637e-01, -1.2801e-01, -1.4067e-01,\n         -3.8914e-02,  7.5896e-02, -1.5751e-01,  3.5857e-02, -8.0124e-02,\n          9.0879e-02, -2.0890e-02,  1.6616e-01, -1.9195e-02,  1.1151e-01,\n          1.1684e-01,  5.1404e-02],\n        [-8.1523e-02,  1.4758e-01, -3.5993e-02, -1.2367e-01, -7.5649e-02,\n         -9.4245e-02, -2.2626e-02, -1.4929e-01, -1.8540e-02, -8.2705e-02,\n          2.8614e-02, -1.8944e-02,  6.2847e-02, -8.2215e-03, -1.6555e-01,\n          1.2716e-01,  1.6207e-01, -1.2632e-01, -9.4036e-02, -1.3643e-01,\n         -7.6264e-02,  1.5648e-01,  3.7053e-02,  1.4775e-02,  1.6983e-01,\n         -1.7293e-01, -1.0200e-01,  7.9697e-02,  1.6408e-01, -6.3630e-02,\n         -2.5835e-02,  1.6503e-01],\n        [ 3.8896e-02, -9.3226e-04,  1.7189e-01, -5.3760e-02, -1.3808e-01,\n          1.2455e-01,  1.5512e-01,  1.3641e-01, -4.2360e-02, -4.4300e-03,\n         -1.0957e-01,  1.2691e-01,  4.0543e-02, -1.3464e-01, -1.2959e-01,\n         -1.2162e-01, -3.8057e-02, -1.0108e-01, -1.3193e-01, -1.0437e-01,\n         -8.9722e-02, -5.7884e-02, -5.3540e-03, -4.7751e-04,  1.4600e-01,\n         -1.5625e-01,  1.4237e-01, -5.5929e-02, -1.1082e-01, -7.9902e-02,\n          1.3746e-01, -1.6048e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0021,  0.0947,  0.1430,  0.0309, -0.1249, -0.0912,  0.0356, -0.0778,\n         0.1180, -0.1131, -0.1522, -0.0253, -0.0603,  0.0194, -0.0664, -0.0618],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0287,  0.0502, -0.1378,  0.2293, -0.2192, -0.1980, -0.1637,  0.0961,\n          0.0910,  0.0486, -0.0649, -0.1217,  0.2226,  0.0230,  0.1233, -0.1884],\n        [-0.0754,  0.2197,  0.0529, -0.1427,  0.1523, -0.1020, -0.1933,  0.0371,\n         -0.1912, -0.0978,  0.1345, -0.0229, -0.1336, -0.2064,  0.1009, -0.2254],\n        [-0.1871,  0.0227,  0.0653,  0.2148, -0.1938, -0.2394, -0.2185,  0.0677,\n          0.1994,  0.0342, -0.0956,  0.1351, -0.2050,  0.2325, -0.1076,  0.1341],\n        [ 0.1373, -0.0874, -0.0184, -0.0381,  0.1924,  0.0601, -0.0487, -0.1150,\n          0.1230, -0.2472, -0.0981,  0.0070, -0.1573, -0.0296, -0.1465, -0.0020],\n        [ 0.0429, -0.2064, -0.0242, -0.1651, -0.0259,  0.1417,  0.1984, -0.0519,\n          0.0552,  0.0213, -0.2254,  0.0419,  0.1871, -0.2109,  0.1732, -0.2113],\n        [ 0.1644,  0.1615,  0.1159, -0.1522, -0.2364, -0.1396,  0.1181,  0.0976,\n          0.0321, -0.0653,  0.0275, -0.0670, -0.1488, -0.1230,  0.0130,  0.0854],\n        [-0.2156,  0.0226,  0.0111, -0.0694, -0.1803,  0.0420, -0.1668, -0.0052,\n          0.1206, -0.0564, -0.0142, -0.0588, -0.0430, -0.1233,  0.0984, -0.1250],\n        [ 0.0225, -0.1707,  0.0999,  0.1051, -0.0830, -0.0529,  0.1984,  0.1331,\n          0.2209, -0.1415, -0.2443,  0.1176, -0.0731, -0.0426,  0.0838,  0.0538]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0835, -0.0623,  0.1745, -0.1618,  0.1932,  0.0390, -0.2216,  0.0999],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2942,  0.3211, -0.3427, -0.1541, -0.2281, -0.1665,  0.2821, -0.1693]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0771], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000001ED47B622F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001ED1018D2A0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s103440000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s103440000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}