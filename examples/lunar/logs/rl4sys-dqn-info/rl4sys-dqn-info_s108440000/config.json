{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.15,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s108440000"
    },
    "q_lr":	0.003,
    "seed":	108440000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x70b928d58d90>":	{
            "_act_dim":	4,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.15,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0282,  0.3129,  0.2245, -0.2522,  0.1648,  0.2699, -0.0361,  0.3111,\n        -0.1799,  0.1846, -0.0380, -0.3233, -0.1440,  0.1939,  0.2189, -0.2331,\n         0.0197, -0.1613, -0.3147, -0.1113, -0.0771, -0.1687, -0.2945,  0.0784,\n         0.0822, -0.0759,  0.2932, -0.2876,  0.0206, -0.0921, -0.1261, -0.0210],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1547, -0.3468,  0.1023,  0.1652, -0.0555, -0.3020,  0.3146, -0.1692],\n        [ 0.1808,  0.1003, -0.1127, -0.1288,  0.1030, -0.2364, -0.0711, -0.2612],\n        [ 0.0145,  0.0975,  0.2639,  0.2649,  0.1673,  0.2792, -0.1043,  0.2944],\n        [ 0.2664,  0.1920,  0.3108, -0.2739, -0.1285,  0.0366,  0.3085, -0.2206],\n        [ 0.3498, -0.2231, -0.1221, -0.1347,  0.1979, -0.0888, -0.1194,  0.2537],\n        [ 0.1689,  0.2425, -0.2184, -0.0213,  0.3406, -0.2184,  0.0106, -0.2571],\n        [-0.2698,  0.2580, -0.2147,  0.1340,  0.2304, -0.1221,  0.0463, -0.2313],\n        [ 0.0673,  0.1591, -0.2958, -0.1122,  0.2099,  0.0312,  0.2573,  0.1946],\n        [ 0.1216,  0.2699, -0.0285, -0.1687,  0.2923,  0.1183, -0.3200,  0.2009],\n        [ 0.1428,  0.1754,  0.2348, -0.1840, -0.0617, -0.1060,  0.0993, -0.0421],\n        [ 0.1304, -0.0890,  0.0660,  0.3126,  0.2505,  0.1937,  0.3109, -0.0046],\n        [ 0.0120,  0.1652,  0.1614, -0.3285, -0.1760,  0.1783,  0.0203, -0.0294],\n        [-0.3485,  0.0521,  0.2474, -0.3158,  0.1638, -0.1582, -0.1812, -0.3450],\n        [-0.0895, -0.1713, -0.3021,  0.1497,  0.2864,  0.0403, -0.1942, -0.1884],\n        [-0.0176, -0.0300, -0.3207, -0.0844,  0.0828,  0.1085, -0.1628,  0.0670],\n        [ 0.1515, -0.3224,  0.3045,  0.0392, -0.2043, -0.1360,  0.3411,  0.1643],\n        [-0.3125, -0.2105,  0.2720,  0.0441, -0.1735,  0.1737, -0.3465,  0.0676],\n        [ 0.3089, -0.0321,  0.1986,  0.3527,  0.0755,  0.3433,  0.0920,  0.1992],\n        [ 0.1786,  0.1251, -0.3493, -0.0249, -0.1700,  0.1060, -0.2494, -0.3488],\n        [-0.2889,  0.3297, -0.0600,  0.0575, -0.0333, -0.0675, -0.0686,  0.1134],\n        [ 0.1381,  0.2453,  0.3468, -0.0006, -0.3420, -0.3095,  0.2449, -0.2900],\n        [-0.2899, -0.1219, -0.2935, -0.0917,  0.0105, -0.1186, -0.0818,  0.0688],\n        [-0.3512, -0.0078, -0.0692, -0.3247, -0.3346, -0.2184,  0.0525, -0.1956],\n        [-0.2947,  0.2535, -0.0462, -0.0093,  0.1075,  0.0238, -0.1194,  0.2491],\n        [-0.1034,  0.3088, -0.0020, -0.0545, -0.2657, -0.1935, -0.0955,  0.2574],\n        [-0.0424,  0.2319,  0.2423,  0.1681, -0.0479,  0.0249, -0.0218, -0.0381],\n        [-0.0169, -0.1960,  0.1212,  0.1950, -0.3063,  0.0538, -0.0751, -0.3198],\n        [-0.2433, -0.2570, -0.3402,  0.1970, -0.2516, -0.0668, -0.2483, -0.1846],\n        [ 0.2671, -0.0296, -0.1514,  0.2805,  0.1755, -0.1165, -0.0038, -0.1695],\n        [-0.2748,  0.0285,  0.1696, -0.0326,  0.2206,  0.1272, -0.0729,  0.3380],\n        [ 0.0978, -0.2191,  0.2458, -0.3444,  0.1086, -0.2445, -0.0595, -0.1463],\n        [ 0.3412,  0.0467, -0.0430,  0.2548,  0.2573, -0.2271,  0.0732,  0.2436]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0775,  0.0602,  0.1184, -0.1120, -0.0648, -0.1453,  0.1191,  0.0844,\n        -0.0887,  0.0989, -0.0604, -0.0556,  0.0227, -0.1457, -0.0189,  0.1504],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.5551e-02, -1.7558e-01, -1.5141e-03, -2.4750e-02,  1.5181e-01,\n         -1.4498e-01,  1.5610e-01,  1.0655e-01, -1.2687e-01, -2.7989e-02,\n         -9.8399e-02,  8.8503e-02,  5.5179e-02,  1.4099e-01, -1.0678e-01,\n          1.8044e-02, -1.9419e-02,  6.8222e-02, -1.9482e-02,  1.0970e-01,\n          1.0029e-01, -9.6481e-02,  3.1692e-03, -7.3905e-02,  9.2595e-02,\n          6.6406e-02, -1.7342e-01, -3.4561e-03,  8.0179e-02, -4.2396e-02,\n         -1.8120e-02, -1.1500e-01],\n        [-1.5593e-01, -6.6504e-02,  1.3892e-02,  7.5627e-02, -5.4132e-02,\n          1.1364e-01,  8.4151e-02,  3.3795e-02,  1.0318e-01,  1.4602e-01,\n         -1.3866e-01, -7.6802e-02,  8.8371e-02,  3.3701e-02,  2.8752e-02,\n          1.2198e-02,  3.7604e-02, -9.3766e-02,  1.5412e-02,  1.3205e-01,\n         -3.7403e-02, -1.0037e-01, -1.4243e-01,  6.9894e-03, -5.3972e-02,\n         -1.5140e-01, -1.1557e-01, -1.3315e-01,  7.7680e-02, -1.2321e-01,\n         -3.2232e-02, -5.1189e-02],\n        [-1.6248e-01, -8.9336e-02,  7.7326e-02,  1.0677e-01,  7.1928e-02,\n         -1.0800e-01,  1.4354e-01, -8.1853e-02, -1.6901e-01,  1.0597e-01,\n         -1.1418e-01,  2.1334e-02,  1.0933e-01,  5.9734e-02, -4.7464e-02,\n         -6.2175e-02,  5.9596e-05, -1.1199e-01,  1.5093e-01, -7.6606e-02,\n          8.8410e-02,  1.1973e-01, -8.3578e-03, -9.7959e-02, -7.9412e-02,\n          1.4864e-01,  1.1494e-01,  2.2113e-02,  1.2966e-02, -9.0299e-02,\n          4.6458e-02,  1.3206e-01],\n        [-1.4173e-01, -8.3998e-02, -5.0848e-02, -4.1741e-02, -3.6534e-02,\n         -1.4265e-01, -5.0526e-02, -8.1755e-03,  4.2043e-02, -4.0238e-02,\n         -1.5881e-02,  6.8225e-02,  1.4822e-01, -1.4085e-01,  9.3526e-02,\n         -7.0502e-02,  1.7203e-01,  1.5872e-01,  9.8379e-04, -1.1609e-01,\n          1.5710e-01, -1.0921e-01, -5.7525e-02, -2.6965e-02,  1.3995e-01,\n         -6.4500e-02, -1.5126e-01,  1.2435e-01, -1.2478e-01,  1.1217e-01,\n         -2.5169e-02,  1.3424e-02],\n        [ 1.5856e-01,  1.2029e-01,  1.7638e-01,  1.3932e-01, -1.8033e-02,\n         -1.4700e-01, -8.5266e-02,  9.2234e-02, -1.3778e-01, -1.2518e-01,\n          1.0727e-01, -1.1459e-01,  3.0137e-02,  2.3630e-02,  2.6013e-02,\n         -1.0205e-01, -1.5789e-02,  3.6426e-02,  8.3951e-02, -1.5389e-01,\n          1.0374e-01, -1.5988e-01, -8.5222e-02, -4.8894e-02,  1.3901e-01,\n          4.3313e-02, -1.1332e-01, -1.2802e-01,  2.1190e-02, -8.8617e-02,\n          2.7120e-02, -7.9124e-02],\n        [ 1.6816e-01,  1.9758e-02, -1.5818e-01,  1.0089e-01,  1.9038e-02,\n          1.1535e-01, -6.5592e-02, -9.7538e-02, -1.6566e-01, -6.3315e-02,\n         -1.1565e-01, -6.0330e-02, -7.0130e-02,  9.9635e-02, -7.3743e-03,\n          1.3698e-01,  1.7978e-02,  1.2536e-01,  7.3786e-02, -1.4048e-01,\n          6.3370e-02,  4.9252e-02, -4.6241e-02,  1.6680e-01, -4.8337e-02,\n          4.2423e-02, -8.3096e-02, -1.3718e-01, -3.8510e-02,  6.7098e-03,\n          5.6389e-02,  6.3777e-02],\n        [ 1.1089e-01, -8.3974e-02,  2.1993e-02, -6.5853e-02,  1.7046e-01,\n          1.7266e-02,  7.5407e-02,  3.2030e-02,  9.7847e-02, -7.3975e-02,\n         -2.8482e-02,  1.1422e-01, -1.0105e-01, -1.0840e-01,  1.0574e-01,\n         -2.0297e-02,  1.1538e-01,  6.0914e-02, -8.3413e-02, -8.4203e-02,\n         -6.9105e-02,  1.0242e-01, -1.3830e-01,  1.4546e-01,  1.0639e-01,\n          4.1176e-02, -9.7142e-04, -1.4355e-01, -1.2071e-01,  1.3296e-01,\n          3.6558e-02,  1.7118e-01],\n        [ 1.0819e-01,  2.7963e-02,  5.1971e-02,  4.5465e-02, -3.7751e-02,\n         -3.6882e-02, -5.8761e-02, -1.2401e-01, -1.8932e-03,  4.9127e-02,\n         -1.2511e-01, -5.8871e-02, -1.0642e-01,  5.6475e-02, -1.1941e-01,\n          1.0621e-01, -8.4610e-02, -1.5289e-01,  7.6484e-02,  1.1016e-01,\n         -5.5968e-03, -1.3986e-01,  1.7408e-01, -1.5165e-01,  1.2171e-01,\n          1.3564e-01,  8.8301e-03,  6.4990e-02,  1.0979e-01,  1.4974e-01,\n          1.6399e-01,  7.4331e-02],\n        [-5.7119e-02,  4.1067e-03, -1.1297e-01, -7.7266e-02, -1.7153e-01,\n          6.9286e-02, -6.1079e-02,  1.6144e-01, -1.0712e-01,  8.5549e-03,\n          1.0290e-01,  1.6280e-01, -2.3446e-02,  1.6676e-01, -2.9327e-02,\n         -1.2056e-01, -1.7141e-01, -1.6080e-01,  1.5378e-01, -7.6872e-04,\n          3.5237e-02, -8.4361e-02,  1.8212e-02,  1.3067e-01,  1.0638e-01,\n         -1.5683e-01, -5.5228e-02,  1.0547e-01,  9.3358e-02,  4.6584e-02,\n          9.8812e-02, -1.3268e-01],\n        [-7.7958e-02,  2.3354e-03, -1.4173e-02, -9.5046e-02, -7.5663e-02,\n          1.6842e-01,  1.0598e-01, -1.3742e-01, -5.4051e-02,  1.2734e-01,\n         -3.0962e-02,  9.1361e-02, -3.2844e-02,  4.3386e-02, -3.5103e-02,\n         -7.7048e-02,  1.0163e-01,  1.0497e-02, -1.3778e-01,  1.5015e-01,\n          8.6810e-02, -1.5636e-01, -1.2372e-01, -1.2501e-01, -1.7131e-01,\n          1.4484e-01, -7.5273e-02, -5.2072e-02,  1.7150e-01,  5.8181e-02,\n         -2.7216e-02, -7.0056e-02],\n        [-1.5680e-01, -1.1165e-01, -7.1419e-02, -1.0500e-01, -1.1215e-01,\n          8.8604e-03,  7.0837e-02, -2.7770e-02,  6.7765e-02,  1.3560e-01,\n          1.6200e-01, -7.1522e-02,  1.3782e-01,  1.1106e-01,  1.5013e-01,\n          3.0460e-02,  1.4279e-02,  1.9474e-02,  7.2567e-02, -1.1203e-01,\n         -1.1022e-01, -2.8656e-02,  5.8032e-02, -1.5715e-01, -4.2979e-02,\n          1.5019e-01, -5.1783e-02, -7.0285e-02, -6.9396e-02,  1.7573e-01,\n          5.3148e-02, -5.1112e-02],\n        [-1.7123e-01,  1.3864e-01, -1.4182e-01,  1.3195e-01, -9.6332e-02,\n          7.4888e-02, -9.9712e-02, -1.4035e-01,  1.1207e-01, -8.7290e-02,\n         -1.1647e-01,  9.9260e-02,  3.8479e-02,  1.3910e-01, -1.4906e-02,\n         -1.2478e-02, -3.3016e-02,  1.7348e-01,  1.5432e-02, -1.7238e-01,\n          1.1005e-01,  7.3439e-02,  2.0808e-02,  1.0561e-01,  1.5770e-01,\n         -4.8109e-02,  1.1213e-01,  1.5134e-01,  1.1518e-02, -3.5625e-04,\n          1.1959e-02, -1.0001e-01],\n        [ 2.7576e-02, -9.7683e-02,  1.7595e-01, -1.7234e-01,  4.7964e-02,\n         -1.5316e-01, -1.1299e-01,  1.0991e-01,  8.2521e-02, -2.5934e-03,\n          1.7656e-01,  1.6022e-01, -7.1290e-02, -6.0912e-02,  7.1111e-02,\n         -7.7137e-02,  1.1336e-03, -1.6494e-01, -4.1214e-02,  1.3176e-01,\n          1.0915e-01,  8.0128e-02,  1.6531e-01, -3.7671e-02,  9.8970e-02,\n          7.4943e-02,  1.3958e-01, -1.7439e-01,  1.2850e-01, -1.6898e-01,\n          7.3849e-02,  1.7643e-02],\n        [ 4.7363e-02,  1.3316e-01, -1.5226e-01, -1.6433e-01, -4.4369e-02,\n          1.3799e-01, -1.6886e-02, -6.3777e-02,  1.4730e-01, -1.6102e-01,\n         -3.7387e-02, -8.7830e-02, -4.0627e-02, -1.2097e-01,  1.5909e-01,\n          9.3035e-02, -3.0104e-02, -7.8207e-02, -1.7579e-01, -3.7046e-02,\n          1.0131e-01,  5.4369e-02, -1.4586e-01, -1.1425e-01,  1.6235e-01,\n          3.8904e-02,  9.9550e-02,  3.5554e-02,  9.5190e-02,  7.5239e-02,\n          8.9906e-02,  6.9041e-02],\n        [-9.4849e-02,  1.0138e-01, -4.0837e-02,  1.1002e-01, -9.3520e-02,\n         -6.2895e-02, -6.6367e-02, -1.5196e-02,  1.2063e-01,  1.5545e-01,\n         -1.2769e-01,  8.3486e-02,  1.6552e-01,  1.0002e-01, -1.5296e-02,\n         -3.4353e-02, -1.5214e-02, -1.7699e-02,  7.0523e-03, -2.4233e-03,\n         -1.0062e-01, -7.7158e-02,  1.7619e-01,  1.3449e-01,  1.2846e-01,\n          1.5405e-03,  1.6481e-01,  5.5958e-02,  2.7074e-02,  7.4830e-03,\n          1.2496e-01,  9.9883e-02],\n        [ 8.6181e-02,  3.4108e-02, -1.1803e-01, -1.2927e-01,  1.0042e-01,\n          1.6460e-01, -4.8237e-02, -1.7117e-02, -8.7496e-02,  1.6236e-01,\n         -6.8307e-02, -5.2327e-02,  1.4988e-01, -5.6540e-02,  4.4736e-02,\n         -1.2535e-01,  1.0986e-01, -8.4749e-02, -1.7629e-01,  9.1596e-02,\n          2.8016e-02,  1.2660e-02,  9.2063e-02,  1.6361e-01, -1.4008e-01,\n         -1.6083e-01,  1.0985e-01, -9.6380e-02, -3.8035e-02,  1.0992e-01,\n         -1.0861e-01,  3.4887e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1431,  0.1480,  0.2439,  0.0848, -0.0855,  0.1354, -0.1655,  0.0400],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0423, -0.0026, -0.2446,  0.2110,  0.2425,  0.0871, -0.1851,  0.0137,\n          0.0521,  0.2363, -0.0682, -0.2307,  0.1212,  0.2031,  0.1931,  0.2079],\n        [ 0.1417,  0.0639, -0.2412, -0.1892,  0.0959, -0.1615, -0.0617,  0.0884,\n          0.0321, -0.0796,  0.2378,  0.1256, -0.0110,  0.1791, -0.0069, -0.1744],\n        [ 0.1748,  0.0389,  0.1979, -0.1641,  0.2067,  0.0665, -0.0163, -0.0360,\n          0.1703,  0.1165,  0.2222, -0.0729,  0.1527,  0.1744, -0.1957, -0.1616],\n        [-0.1611,  0.2050,  0.0963, -0.0219, -0.0017,  0.2388, -0.1735, -0.0410,\n         -0.1062, -0.1854,  0.1957, -0.1669, -0.0937,  0.1649, -0.1596, -0.0777],\n        [-0.1955, -0.1983,  0.2345,  0.1924, -0.1856,  0.0565,  0.2065, -0.2181,\n          0.1044,  0.2001, -0.0776,  0.1743,  0.0295,  0.1024,  0.0125, -0.0597],\n        [ 0.0517,  0.1124, -0.1250,  0.1834, -0.0860,  0.0542,  0.0389, -0.0181,\n         -0.1098, -0.0752, -0.1672,  0.1153, -0.1851, -0.1397,  0.1606,  0.2093],\n        [ 0.1053,  0.0591, -0.0725, -0.1914, -0.1477,  0.1952,  0.0202, -0.2226,\n          0.0870, -0.1377,  0.1384,  0.1839, -0.0625,  0.0599,  0.0792,  0.0295],\n        [ 0.2207,  0.1280,  0.0878, -0.1149,  0.1309,  0.0317,  0.1900, -0.1903,\n         -0.2356,  0.2130, -0.0102,  0.0320, -0.2383,  0.2222, -0.1873, -0.0201]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3068, -0.2108,  0.1943, -0.1195], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3519,  0.2851,  0.0680, -0.1354, -0.1400, -0.1441, -0.3335,  0.1410],\n        [-0.3134, -0.1224, -0.2885, -0.3456,  0.1713,  0.0362, -0.0878,  0.2425],\n        [ 0.0780,  0.3128, -0.2250, -0.0261, -0.2584,  0.0994,  0.1662,  0.0817],\n        [-0.1927, -0.1621,  0.0701,  0.0605,  0.0770, -0.3149, -0.0128, -0.0541]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.003\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#RMSprop.zero_grad",
                    "defaults":	{
                        "alpha":	0.99,
                        "capturable":	false,
                        "centered":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "momentum":	0,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "alpha":	0.99,
                            "capturable":	false,
                            "centered":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "momentum":	0,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1547, -0.3468,  0.1023,  0.1652, -0.0555, -0.3020,  0.3146, -0.1692],\n        [ 0.1808,  0.1003, -0.1127, -0.1288,  0.1030, -0.2364, -0.0711, -0.2612],\n        [ 0.0145,  0.0975,  0.2639,  0.2649,  0.1673,  0.2792, -0.1043,  0.2944],\n        [ 0.2664,  0.1920,  0.3108, -0.2739, -0.1285,  0.0366,  0.3085, -0.2206],\n        [ 0.3498, -0.2231, -0.1221, -0.1347,  0.1979, -0.0888, -0.1194,  0.2537],\n        [ 0.1689,  0.2425, -0.2184, -0.0213,  0.3406, -0.2184,  0.0106, -0.2571],\n        [-0.2698,  0.2580, -0.2147,  0.1340,  0.2304, -0.1221,  0.0463, -0.2313],\n        [ 0.0673,  0.1591, -0.2958, -0.1122,  0.2099,  0.0312,  0.2573,  0.1946],\n        [ 0.1216,  0.2699, -0.0285, -0.1687,  0.2923,  0.1183, -0.3200,  0.2009],\n        [ 0.1428,  0.1754,  0.2348, -0.1840, -0.0617, -0.1060,  0.0993, -0.0421],\n        [ 0.1304, -0.0890,  0.0660,  0.3126,  0.2505,  0.1937,  0.3109, -0.0046],\n        [ 0.0120,  0.1652,  0.1614, -0.3285, -0.1760,  0.1783,  0.0203, -0.0294],\n        [-0.3485,  0.0521,  0.2474, -0.3158,  0.1638, -0.1582, -0.1812, -0.3450],\n        [-0.0895, -0.1713, -0.3021,  0.1497,  0.2864,  0.0403, -0.1942, -0.1884],\n        [-0.0176, -0.0300, -0.3207, -0.0844,  0.0828,  0.1085, -0.1628,  0.0670],\n        [ 0.1515, -0.3224,  0.3045,  0.0392, -0.2043, -0.1360,  0.3411,  0.1643],\n        [-0.3125, -0.2105,  0.2720,  0.0441, -0.1735,  0.1737, -0.3465,  0.0676],\n        [ 0.3089, -0.0321,  0.1986,  0.3527,  0.0755,  0.3433,  0.0920,  0.1992],\n        [ 0.1786,  0.1251, -0.3493, -0.0249, -0.1700,  0.1060, -0.2494, -0.3488],\n        [-0.2889,  0.3297, -0.0600,  0.0575, -0.0333, -0.0675, -0.0686,  0.1134],\n        [ 0.1381,  0.2453,  0.3468, -0.0006, -0.3420, -0.3095,  0.2449, -0.2900],\n        [-0.2899, -0.1219, -0.2935, -0.0917,  0.0105, -0.1186, -0.0818,  0.0688],\n        [-0.3512, -0.0078, -0.0692, -0.3247, -0.3346, -0.2184,  0.0525, -0.1956],\n        [-0.2947,  0.2535, -0.0462, -0.0093,  0.1075,  0.0238, -0.1194,  0.2491],\n        [-0.1034,  0.3088, -0.0020, -0.0545, -0.2657, -0.1935, -0.0955,  0.2574],\n        [-0.0424,  0.2319,  0.2423,  0.1681, -0.0479,  0.0249, -0.0218, -0.0381],\n        [-0.0169, -0.1960,  0.1212,  0.1950, -0.3063,  0.0538, -0.0751, -0.3198],\n        [-0.2433, -0.2570, -0.3402,  0.1970, -0.2516, -0.0668, -0.2483, -0.1846],\n        [ 0.2671, -0.0296, -0.1514,  0.2805,  0.1755, -0.1165, -0.0038, -0.1695],\n        [-0.2748,  0.0285,  0.1696, -0.0326,  0.2206,  0.1272, -0.0729,  0.3380],\n        [ 0.0978, -0.2191,  0.2458, -0.3444,  0.1086, -0.2445, -0.0595, -0.1463],\n        [ 0.3412,  0.0467, -0.0430,  0.2548,  0.2573, -0.2271,  0.0732,  0.2436]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0282,  0.3129,  0.2245, -0.2522,  0.1648,  0.2699, -0.0361,  0.3111,\n        -0.1799,  0.1846, -0.0380, -0.3233, -0.1440,  0.1939,  0.2189, -0.2331,\n         0.0197, -0.1613, -0.3147, -0.1113, -0.0771, -0.1687, -0.2945,  0.0784,\n         0.0822, -0.0759,  0.2932, -0.2876,  0.0206, -0.0921, -0.1261, -0.0210],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-8.5551e-02, -1.7558e-01, -1.5141e-03, -2.4750e-02,  1.5181e-01,\n         -1.4498e-01,  1.5610e-01,  1.0655e-01, -1.2687e-01, -2.7989e-02,\n         -9.8399e-02,  8.8503e-02,  5.5179e-02,  1.4099e-01, -1.0678e-01,\n          1.8044e-02, -1.9419e-02,  6.8222e-02, -1.9482e-02,  1.0970e-01,\n          1.0029e-01, -9.6481e-02,  3.1692e-03, -7.3905e-02,  9.2595e-02,\n          6.6406e-02, -1.7342e-01, -3.4561e-03,  8.0179e-02, -4.2396e-02,\n         -1.8120e-02, -1.1500e-01],\n        [-1.5593e-01, -6.6504e-02,  1.3892e-02,  7.5627e-02, -5.4132e-02,\n          1.1364e-01,  8.4151e-02,  3.3795e-02,  1.0318e-01,  1.4602e-01,\n         -1.3866e-01, -7.6802e-02,  8.8371e-02,  3.3701e-02,  2.8752e-02,\n          1.2198e-02,  3.7604e-02, -9.3766e-02,  1.5412e-02,  1.3205e-01,\n         -3.7403e-02, -1.0037e-01, -1.4243e-01,  6.9894e-03, -5.3972e-02,\n         -1.5140e-01, -1.1557e-01, -1.3315e-01,  7.7680e-02, -1.2321e-01,\n         -3.2232e-02, -5.1189e-02],\n        [-1.6248e-01, -8.9336e-02,  7.7326e-02,  1.0677e-01,  7.1928e-02,\n         -1.0800e-01,  1.4354e-01, -8.1853e-02, -1.6901e-01,  1.0597e-01,\n         -1.1418e-01,  2.1334e-02,  1.0933e-01,  5.9734e-02, -4.7464e-02,\n         -6.2175e-02,  5.9596e-05, -1.1199e-01,  1.5093e-01, -7.6606e-02,\n          8.8410e-02,  1.1973e-01, -8.3578e-03, -9.7959e-02, -7.9412e-02,\n          1.4864e-01,  1.1494e-01,  2.2113e-02,  1.2966e-02, -9.0299e-02,\n          4.6458e-02,  1.3206e-01],\n        [-1.4173e-01, -8.3998e-02, -5.0848e-02, -4.1741e-02, -3.6534e-02,\n         -1.4265e-01, -5.0526e-02, -8.1755e-03,  4.2043e-02, -4.0238e-02,\n         -1.5881e-02,  6.8225e-02,  1.4822e-01, -1.4085e-01,  9.3526e-02,\n         -7.0502e-02,  1.7203e-01,  1.5872e-01,  9.8379e-04, -1.1609e-01,\n          1.5710e-01, -1.0921e-01, -5.7525e-02, -2.6965e-02,  1.3995e-01,\n         -6.4500e-02, -1.5126e-01,  1.2435e-01, -1.2478e-01,  1.1217e-01,\n         -2.5169e-02,  1.3424e-02],\n        [ 1.5856e-01,  1.2029e-01,  1.7638e-01,  1.3932e-01, -1.8033e-02,\n         -1.4700e-01, -8.5266e-02,  9.2234e-02, -1.3778e-01, -1.2518e-01,\n          1.0727e-01, -1.1459e-01,  3.0137e-02,  2.3630e-02,  2.6013e-02,\n         -1.0205e-01, -1.5789e-02,  3.6426e-02,  8.3951e-02, -1.5389e-01,\n          1.0374e-01, -1.5988e-01, -8.5222e-02, -4.8894e-02,  1.3901e-01,\n          4.3313e-02, -1.1332e-01, -1.2802e-01,  2.1190e-02, -8.8617e-02,\n          2.7120e-02, -7.9124e-02],\n        [ 1.6816e-01,  1.9758e-02, -1.5818e-01,  1.0089e-01,  1.9038e-02,\n          1.1535e-01, -6.5592e-02, -9.7538e-02, -1.6566e-01, -6.3315e-02,\n         -1.1565e-01, -6.0330e-02, -7.0130e-02,  9.9635e-02, -7.3743e-03,\n          1.3698e-01,  1.7978e-02,  1.2536e-01,  7.3786e-02, -1.4048e-01,\n          6.3370e-02,  4.9252e-02, -4.6241e-02,  1.6680e-01, -4.8337e-02,\n          4.2423e-02, -8.3096e-02, -1.3718e-01, -3.8510e-02,  6.7098e-03,\n          5.6389e-02,  6.3777e-02],\n        [ 1.1089e-01, -8.3974e-02,  2.1993e-02, -6.5853e-02,  1.7046e-01,\n          1.7266e-02,  7.5407e-02,  3.2030e-02,  9.7847e-02, -7.3975e-02,\n         -2.8482e-02,  1.1422e-01, -1.0105e-01, -1.0840e-01,  1.0574e-01,\n         -2.0297e-02,  1.1538e-01,  6.0914e-02, -8.3413e-02, -8.4203e-02,\n         -6.9105e-02,  1.0242e-01, -1.3830e-01,  1.4546e-01,  1.0639e-01,\n          4.1176e-02, -9.7142e-04, -1.4355e-01, -1.2071e-01,  1.3296e-01,\n          3.6558e-02,  1.7118e-01],\n        [ 1.0819e-01,  2.7963e-02,  5.1971e-02,  4.5465e-02, -3.7751e-02,\n         -3.6882e-02, -5.8761e-02, -1.2401e-01, -1.8932e-03,  4.9127e-02,\n         -1.2511e-01, -5.8871e-02, -1.0642e-01,  5.6475e-02, -1.1941e-01,\n          1.0621e-01, -8.4610e-02, -1.5289e-01,  7.6484e-02,  1.1016e-01,\n         -5.5968e-03, -1.3986e-01,  1.7408e-01, -1.5165e-01,  1.2171e-01,\n          1.3564e-01,  8.8301e-03,  6.4990e-02,  1.0979e-01,  1.4974e-01,\n          1.6399e-01,  7.4331e-02],\n        [-5.7119e-02,  4.1067e-03, -1.1297e-01, -7.7266e-02, -1.7153e-01,\n          6.9286e-02, -6.1079e-02,  1.6144e-01, -1.0712e-01,  8.5549e-03,\n          1.0290e-01,  1.6280e-01, -2.3446e-02,  1.6676e-01, -2.9327e-02,\n         -1.2056e-01, -1.7141e-01, -1.6080e-01,  1.5378e-01, -7.6872e-04,\n          3.5237e-02, -8.4361e-02,  1.8212e-02,  1.3067e-01,  1.0638e-01,\n         -1.5683e-01, -5.5228e-02,  1.0547e-01,  9.3358e-02,  4.6584e-02,\n          9.8812e-02, -1.3268e-01],\n        [-7.7958e-02,  2.3354e-03, -1.4173e-02, -9.5046e-02, -7.5663e-02,\n          1.6842e-01,  1.0598e-01, -1.3742e-01, -5.4051e-02,  1.2734e-01,\n         -3.0962e-02,  9.1361e-02, -3.2844e-02,  4.3386e-02, -3.5103e-02,\n         -7.7048e-02,  1.0163e-01,  1.0497e-02, -1.3778e-01,  1.5015e-01,\n          8.6810e-02, -1.5636e-01, -1.2372e-01, -1.2501e-01, -1.7131e-01,\n          1.4484e-01, -7.5273e-02, -5.2072e-02,  1.7150e-01,  5.8181e-02,\n         -2.7216e-02, -7.0056e-02],\n        [-1.5680e-01, -1.1165e-01, -7.1419e-02, -1.0500e-01, -1.1215e-01,\n          8.8604e-03,  7.0837e-02, -2.7770e-02,  6.7765e-02,  1.3560e-01,\n          1.6200e-01, -7.1522e-02,  1.3782e-01,  1.1106e-01,  1.5013e-01,\n          3.0460e-02,  1.4279e-02,  1.9474e-02,  7.2567e-02, -1.1203e-01,\n         -1.1022e-01, -2.8656e-02,  5.8032e-02, -1.5715e-01, -4.2979e-02,\n          1.5019e-01, -5.1783e-02, -7.0285e-02, -6.9396e-02,  1.7573e-01,\n          5.3148e-02, -5.1112e-02],\n        [-1.7123e-01,  1.3864e-01, -1.4182e-01,  1.3195e-01, -9.6332e-02,\n          7.4888e-02, -9.9712e-02, -1.4035e-01,  1.1207e-01, -8.7290e-02,\n         -1.1647e-01,  9.9260e-02,  3.8479e-02,  1.3910e-01, -1.4906e-02,\n         -1.2478e-02, -3.3016e-02,  1.7348e-01,  1.5432e-02, -1.7238e-01,\n          1.1005e-01,  7.3439e-02,  2.0808e-02,  1.0561e-01,  1.5770e-01,\n         -4.8109e-02,  1.1213e-01,  1.5134e-01,  1.1518e-02, -3.5625e-04,\n          1.1959e-02, -1.0001e-01],\n        [ 2.7576e-02, -9.7683e-02,  1.7595e-01, -1.7234e-01,  4.7964e-02,\n         -1.5316e-01, -1.1299e-01,  1.0991e-01,  8.2521e-02, -2.5934e-03,\n          1.7656e-01,  1.6022e-01, -7.1290e-02, -6.0912e-02,  7.1111e-02,\n         -7.7137e-02,  1.1336e-03, -1.6494e-01, -4.1214e-02,  1.3176e-01,\n          1.0915e-01,  8.0128e-02,  1.6531e-01, -3.7671e-02,  9.8970e-02,\n          7.4943e-02,  1.3958e-01, -1.7439e-01,  1.2850e-01, -1.6898e-01,\n          7.3849e-02,  1.7643e-02],\n        [ 4.7363e-02,  1.3316e-01, -1.5226e-01, -1.6433e-01, -4.4369e-02,\n          1.3799e-01, -1.6886e-02, -6.3777e-02,  1.4730e-01, -1.6102e-01,\n         -3.7387e-02, -8.7830e-02, -4.0627e-02, -1.2097e-01,  1.5909e-01,\n          9.3035e-02, -3.0104e-02, -7.8207e-02, -1.7579e-01, -3.7046e-02,\n          1.0131e-01,  5.4369e-02, -1.4586e-01, -1.1425e-01,  1.6235e-01,\n          3.8904e-02,  9.9550e-02,  3.5554e-02,  9.5190e-02,  7.5239e-02,\n          8.9906e-02,  6.9041e-02],\n        [-9.4849e-02,  1.0138e-01, -4.0837e-02,  1.1002e-01, -9.3520e-02,\n         -6.2895e-02, -6.6367e-02, -1.5196e-02,  1.2063e-01,  1.5545e-01,\n         -1.2769e-01,  8.3486e-02,  1.6552e-01,  1.0002e-01, -1.5296e-02,\n         -3.4353e-02, -1.5214e-02, -1.7699e-02,  7.0523e-03, -2.4233e-03,\n         -1.0062e-01, -7.7158e-02,  1.7619e-01,  1.3449e-01,  1.2846e-01,\n          1.5405e-03,  1.6481e-01,  5.5958e-02,  2.7074e-02,  7.4830e-03,\n          1.2496e-01,  9.9883e-02],\n        [ 8.6181e-02,  3.4108e-02, -1.1803e-01, -1.2927e-01,  1.0042e-01,\n          1.6460e-01, -4.8237e-02, -1.7117e-02, -8.7496e-02,  1.6236e-01,\n         -6.8307e-02, -5.2327e-02,  1.4988e-01, -5.6540e-02,  4.4736e-02,\n         -1.2535e-01,  1.0986e-01, -8.4749e-02, -1.7629e-01,  9.1596e-02,\n          2.8016e-02,  1.2660e-02,  9.2063e-02,  1.6361e-01, -1.4008e-01,\n         -1.6083e-01,  1.0985e-01, -9.6380e-02, -3.8035e-02,  1.0992e-01,\n         -1.0861e-01,  3.4887e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0775,  0.0602,  0.1184, -0.1120, -0.0648, -0.1453,  0.1191,  0.0844,\n        -0.0887,  0.0989, -0.0604, -0.0556,  0.0227, -0.1457, -0.0189,  0.1504],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0423, -0.0026, -0.2446,  0.2110,  0.2425,  0.0871, -0.1851,  0.0137,\n          0.0521,  0.2363, -0.0682, -0.2307,  0.1212,  0.2031,  0.1931,  0.2079],\n        [ 0.1417,  0.0639, -0.2412, -0.1892,  0.0959, -0.1615, -0.0617,  0.0884,\n          0.0321, -0.0796,  0.2378,  0.1256, -0.0110,  0.1791, -0.0069, -0.1744],\n        [ 0.1748,  0.0389,  0.1979, -0.1641,  0.2067,  0.0665, -0.0163, -0.0360,\n          0.1703,  0.1165,  0.2222, -0.0729,  0.1527,  0.1744, -0.1957, -0.1616],\n        [-0.1611,  0.2050,  0.0963, -0.0219, -0.0017,  0.2388, -0.1735, -0.0410,\n         -0.1062, -0.1854,  0.1957, -0.1669, -0.0937,  0.1649, -0.1596, -0.0777],\n        [-0.1955, -0.1983,  0.2345,  0.1924, -0.1856,  0.0565,  0.2065, -0.2181,\n          0.1044,  0.2001, -0.0776,  0.1743,  0.0295,  0.1024,  0.0125, -0.0597],\n        [ 0.0517,  0.1124, -0.1250,  0.1834, -0.0860,  0.0542,  0.0389, -0.0181,\n         -0.1098, -0.0752, -0.1672,  0.1153, -0.1851, -0.1397,  0.1606,  0.2093],\n        [ 0.1053,  0.0591, -0.0725, -0.1914, -0.1477,  0.1952,  0.0202, -0.2226,\n          0.0870, -0.1377,  0.1384,  0.1839, -0.0625,  0.0599,  0.0792,  0.0295],\n        [ 0.2207,  0.1280,  0.0878, -0.1149,  0.1309,  0.0317,  0.1900, -0.1903,\n         -0.2356,  0.2130, -0.0102,  0.0320, -0.2383,  0.2222, -0.1873, -0.0201]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1431,  0.1480,  0.2439,  0.0848, -0.0855,  0.1354, -0.1655,  0.0400],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3519,  0.2851,  0.0680, -0.1354, -0.1400, -0.1441, -0.3335,  0.1410],\n        [-0.3134, -0.1224, -0.2885, -0.3456,  0.1713,  0.0362, -0.0878,  0.2425],\n        [ 0.0780,  0.3128, -0.2250, -0.0261, -0.2584,  0.0994,  0.1662,  0.0817],\n        [-0.1927, -0.1621,  0.0701,  0.0605,  0.0770, -0.3149, -0.0128, -0.0541]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3068, -0.2108,  0.1943, -0.1195], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.stale_replay_buffer.StaleReplayBuffer object at 0x70b92792e550>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0282,  0.3129,  0.2245, -0.2522,  0.1648,  0.2699, -0.0361,  0.3111,\n        -0.1799,  0.1846, -0.0380, -0.3233, -0.1440,  0.1939,  0.2189, -0.2331,\n         0.0197, -0.1613, -0.3147, -0.1113, -0.0771, -0.1687, -0.2945,  0.0784,\n         0.0822, -0.0759,  0.2932, -0.2876,  0.0206, -0.0921, -0.1261, -0.0210],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1547, -0.3468,  0.1023,  0.1652, -0.0555, -0.3020,  0.3146, -0.1692],\n        [ 0.1808,  0.1003, -0.1127, -0.1288,  0.1030, -0.2364, -0.0711, -0.2612],\n        [ 0.0145,  0.0975,  0.2639,  0.2649,  0.1673,  0.2792, -0.1043,  0.2944],\n        [ 0.2664,  0.1920,  0.3108, -0.2739, -0.1285,  0.0366,  0.3085, -0.2206],\n        [ 0.3498, -0.2231, -0.1221, -0.1347,  0.1979, -0.0888, -0.1194,  0.2537],\n        [ 0.1689,  0.2425, -0.2184, -0.0213,  0.3406, -0.2184,  0.0106, -0.2571],\n        [-0.2698,  0.2580, -0.2147,  0.1340,  0.2304, -0.1221,  0.0463, -0.2313],\n        [ 0.0673,  0.1591, -0.2958, -0.1122,  0.2099,  0.0312,  0.2573,  0.1946],\n        [ 0.1216,  0.2699, -0.0285, -0.1687,  0.2923,  0.1183, -0.3200,  0.2009],\n        [ 0.1428,  0.1754,  0.2348, -0.1840, -0.0617, -0.1060,  0.0993, -0.0421],\n        [ 0.1304, -0.0890,  0.0660,  0.3126,  0.2505,  0.1937,  0.3109, -0.0046],\n        [ 0.0120,  0.1652,  0.1614, -0.3285, -0.1760,  0.1783,  0.0203, -0.0294],\n        [-0.3485,  0.0521,  0.2474, -0.3158,  0.1638, -0.1582, -0.1812, -0.3450],\n        [-0.0895, -0.1713, -0.3021,  0.1497,  0.2864,  0.0403, -0.1942, -0.1884],\n        [-0.0176, -0.0300, -0.3207, -0.0844,  0.0828,  0.1085, -0.1628,  0.0670],\n        [ 0.1515, -0.3224,  0.3045,  0.0392, -0.2043, -0.1360,  0.3411,  0.1643],\n        [-0.3125, -0.2105,  0.2720,  0.0441, -0.1735,  0.1737, -0.3465,  0.0676],\n        [ 0.3089, -0.0321,  0.1986,  0.3527,  0.0755,  0.3433,  0.0920,  0.1992],\n        [ 0.1786,  0.1251, -0.3493, -0.0249, -0.1700,  0.1060, -0.2494, -0.3488],\n        [-0.2889,  0.3297, -0.0600,  0.0575, -0.0333, -0.0675, -0.0686,  0.1134],\n        [ 0.1381,  0.2453,  0.3468, -0.0006, -0.3420, -0.3095,  0.2449, -0.2900],\n        [-0.2899, -0.1219, -0.2935, -0.0917,  0.0105, -0.1186, -0.0818,  0.0688],\n        [-0.3512, -0.0078, -0.0692, -0.3247, -0.3346, -0.2184,  0.0525, -0.1956],\n        [-0.2947,  0.2535, -0.0462, -0.0093,  0.1075,  0.0238, -0.1194,  0.2491],\n        [-0.1034,  0.3088, -0.0020, -0.0545, -0.2657, -0.1935, -0.0955,  0.2574],\n        [-0.0424,  0.2319,  0.2423,  0.1681, -0.0479,  0.0249, -0.0218, -0.0381],\n        [-0.0169, -0.1960,  0.1212,  0.1950, -0.3063,  0.0538, -0.0751, -0.3198],\n        [-0.2433, -0.2570, -0.3402,  0.1970, -0.2516, -0.0668, -0.2483, -0.1846],\n        [ 0.2671, -0.0296, -0.1514,  0.2805,  0.1755, -0.1165, -0.0038, -0.1695],\n        [-0.2748,  0.0285,  0.1696, -0.0326,  0.2206,  0.1272, -0.0729,  0.3380],\n        [ 0.0978, -0.2191,  0.2458, -0.3444,  0.1086, -0.2445, -0.0595, -0.1463],\n        [ 0.3412,  0.0467, -0.0430,  0.2548,  0.2573, -0.2271,  0.0732,  0.2436]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0775,  0.0602,  0.1184, -0.1120, -0.0648, -0.1453,  0.1191,  0.0844,\n        -0.0887,  0.0989, -0.0604, -0.0556,  0.0227, -0.1457, -0.0189,  0.1504],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.5551e-02, -1.7558e-01, -1.5141e-03, -2.4750e-02,  1.5181e-01,\n         -1.4498e-01,  1.5610e-01,  1.0655e-01, -1.2687e-01, -2.7989e-02,\n         -9.8399e-02,  8.8503e-02,  5.5179e-02,  1.4099e-01, -1.0678e-01,\n          1.8044e-02, -1.9419e-02,  6.8222e-02, -1.9482e-02,  1.0970e-01,\n          1.0029e-01, -9.6481e-02,  3.1692e-03, -7.3905e-02,  9.2595e-02,\n          6.6406e-02, -1.7342e-01, -3.4561e-03,  8.0179e-02, -4.2396e-02,\n         -1.8120e-02, -1.1500e-01],\n        [-1.5593e-01, -6.6504e-02,  1.3892e-02,  7.5627e-02, -5.4132e-02,\n          1.1364e-01,  8.4151e-02,  3.3795e-02,  1.0318e-01,  1.4602e-01,\n         -1.3866e-01, -7.6802e-02,  8.8371e-02,  3.3701e-02,  2.8752e-02,\n          1.2198e-02,  3.7604e-02, -9.3766e-02,  1.5412e-02,  1.3205e-01,\n         -3.7403e-02, -1.0037e-01, -1.4243e-01,  6.9894e-03, -5.3972e-02,\n         -1.5140e-01, -1.1557e-01, -1.3315e-01,  7.7680e-02, -1.2321e-01,\n         -3.2232e-02, -5.1189e-02],\n        [-1.6248e-01, -8.9336e-02,  7.7326e-02,  1.0677e-01,  7.1928e-02,\n         -1.0800e-01,  1.4354e-01, -8.1853e-02, -1.6901e-01,  1.0597e-01,\n         -1.1418e-01,  2.1334e-02,  1.0933e-01,  5.9734e-02, -4.7464e-02,\n         -6.2175e-02,  5.9596e-05, -1.1199e-01,  1.5093e-01, -7.6606e-02,\n          8.8410e-02,  1.1973e-01, -8.3578e-03, -9.7959e-02, -7.9412e-02,\n          1.4864e-01,  1.1494e-01,  2.2113e-02,  1.2966e-02, -9.0299e-02,\n          4.6458e-02,  1.3206e-01],\n        [-1.4173e-01, -8.3998e-02, -5.0848e-02, -4.1741e-02, -3.6534e-02,\n         -1.4265e-01, -5.0526e-02, -8.1755e-03,  4.2043e-02, -4.0238e-02,\n         -1.5881e-02,  6.8225e-02,  1.4822e-01, -1.4085e-01,  9.3526e-02,\n         -7.0502e-02,  1.7203e-01,  1.5872e-01,  9.8379e-04, -1.1609e-01,\n          1.5710e-01, -1.0921e-01, -5.7525e-02, -2.6965e-02,  1.3995e-01,\n         -6.4500e-02, -1.5126e-01,  1.2435e-01, -1.2478e-01,  1.1217e-01,\n         -2.5169e-02,  1.3424e-02],\n        [ 1.5856e-01,  1.2029e-01,  1.7638e-01,  1.3932e-01, -1.8033e-02,\n         -1.4700e-01, -8.5266e-02,  9.2234e-02, -1.3778e-01, -1.2518e-01,\n          1.0727e-01, -1.1459e-01,  3.0137e-02,  2.3630e-02,  2.6013e-02,\n         -1.0205e-01, -1.5789e-02,  3.6426e-02,  8.3951e-02, -1.5389e-01,\n          1.0374e-01, -1.5988e-01, -8.5222e-02, -4.8894e-02,  1.3901e-01,\n          4.3313e-02, -1.1332e-01, -1.2802e-01,  2.1190e-02, -8.8617e-02,\n          2.7120e-02, -7.9124e-02],\n        [ 1.6816e-01,  1.9758e-02, -1.5818e-01,  1.0089e-01,  1.9038e-02,\n          1.1535e-01, -6.5592e-02, -9.7538e-02, -1.6566e-01, -6.3315e-02,\n         -1.1565e-01, -6.0330e-02, -7.0130e-02,  9.9635e-02, -7.3743e-03,\n          1.3698e-01,  1.7978e-02,  1.2536e-01,  7.3786e-02, -1.4048e-01,\n          6.3370e-02,  4.9252e-02, -4.6241e-02,  1.6680e-01, -4.8337e-02,\n          4.2423e-02, -8.3096e-02, -1.3718e-01, -3.8510e-02,  6.7098e-03,\n          5.6389e-02,  6.3777e-02],\n        [ 1.1089e-01, -8.3974e-02,  2.1993e-02, -6.5853e-02,  1.7046e-01,\n          1.7266e-02,  7.5407e-02,  3.2030e-02,  9.7847e-02, -7.3975e-02,\n         -2.8482e-02,  1.1422e-01, -1.0105e-01, -1.0840e-01,  1.0574e-01,\n         -2.0297e-02,  1.1538e-01,  6.0914e-02, -8.3413e-02, -8.4203e-02,\n         -6.9105e-02,  1.0242e-01, -1.3830e-01,  1.4546e-01,  1.0639e-01,\n          4.1176e-02, -9.7142e-04, -1.4355e-01, -1.2071e-01,  1.3296e-01,\n          3.6558e-02,  1.7118e-01],\n        [ 1.0819e-01,  2.7963e-02,  5.1971e-02,  4.5465e-02, -3.7751e-02,\n         -3.6882e-02, -5.8761e-02, -1.2401e-01, -1.8932e-03,  4.9127e-02,\n         -1.2511e-01, -5.8871e-02, -1.0642e-01,  5.6475e-02, -1.1941e-01,\n          1.0621e-01, -8.4610e-02, -1.5289e-01,  7.6484e-02,  1.1016e-01,\n         -5.5968e-03, -1.3986e-01,  1.7408e-01, -1.5165e-01,  1.2171e-01,\n          1.3564e-01,  8.8301e-03,  6.4990e-02,  1.0979e-01,  1.4974e-01,\n          1.6399e-01,  7.4331e-02],\n        [-5.7119e-02,  4.1067e-03, -1.1297e-01, -7.7266e-02, -1.7153e-01,\n          6.9286e-02, -6.1079e-02,  1.6144e-01, -1.0712e-01,  8.5549e-03,\n          1.0290e-01,  1.6280e-01, -2.3446e-02,  1.6676e-01, -2.9327e-02,\n         -1.2056e-01, -1.7141e-01, -1.6080e-01,  1.5378e-01, -7.6872e-04,\n          3.5237e-02, -8.4361e-02,  1.8212e-02,  1.3067e-01,  1.0638e-01,\n         -1.5683e-01, -5.5228e-02,  1.0547e-01,  9.3358e-02,  4.6584e-02,\n          9.8812e-02, -1.3268e-01],\n        [-7.7958e-02,  2.3354e-03, -1.4173e-02, -9.5046e-02, -7.5663e-02,\n          1.6842e-01,  1.0598e-01, -1.3742e-01, -5.4051e-02,  1.2734e-01,\n         -3.0962e-02,  9.1361e-02, -3.2844e-02,  4.3386e-02, -3.5103e-02,\n         -7.7048e-02,  1.0163e-01,  1.0497e-02, -1.3778e-01,  1.5015e-01,\n          8.6810e-02, -1.5636e-01, -1.2372e-01, -1.2501e-01, -1.7131e-01,\n          1.4484e-01, -7.5273e-02, -5.2072e-02,  1.7150e-01,  5.8181e-02,\n         -2.7216e-02, -7.0056e-02],\n        [-1.5680e-01, -1.1165e-01, -7.1419e-02, -1.0500e-01, -1.1215e-01,\n          8.8604e-03,  7.0837e-02, -2.7770e-02,  6.7765e-02,  1.3560e-01,\n          1.6200e-01, -7.1522e-02,  1.3782e-01,  1.1106e-01,  1.5013e-01,\n          3.0460e-02,  1.4279e-02,  1.9474e-02,  7.2567e-02, -1.1203e-01,\n         -1.1022e-01, -2.8656e-02,  5.8032e-02, -1.5715e-01, -4.2979e-02,\n          1.5019e-01, -5.1783e-02, -7.0285e-02, -6.9396e-02,  1.7573e-01,\n          5.3148e-02, -5.1112e-02],\n        [-1.7123e-01,  1.3864e-01, -1.4182e-01,  1.3195e-01, -9.6332e-02,\n          7.4888e-02, -9.9712e-02, -1.4035e-01,  1.1207e-01, -8.7290e-02,\n         -1.1647e-01,  9.9260e-02,  3.8479e-02,  1.3910e-01, -1.4906e-02,\n         -1.2478e-02, -3.3016e-02,  1.7348e-01,  1.5432e-02, -1.7238e-01,\n          1.1005e-01,  7.3439e-02,  2.0808e-02,  1.0561e-01,  1.5770e-01,\n         -4.8109e-02,  1.1213e-01,  1.5134e-01,  1.1518e-02, -3.5625e-04,\n          1.1959e-02, -1.0001e-01],\n        [ 2.7576e-02, -9.7683e-02,  1.7595e-01, -1.7234e-01,  4.7964e-02,\n         -1.5316e-01, -1.1299e-01,  1.0991e-01,  8.2521e-02, -2.5934e-03,\n          1.7656e-01,  1.6022e-01, -7.1290e-02, -6.0912e-02,  7.1111e-02,\n         -7.7137e-02,  1.1336e-03, -1.6494e-01, -4.1214e-02,  1.3176e-01,\n          1.0915e-01,  8.0128e-02,  1.6531e-01, -3.7671e-02,  9.8970e-02,\n          7.4943e-02,  1.3958e-01, -1.7439e-01,  1.2850e-01, -1.6898e-01,\n          7.3849e-02,  1.7643e-02],\n        [ 4.7363e-02,  1.3316e-01, -1.5226e-01, -1.6433e-01, -4.4369e-02,\n          1.3799e-01, -1.6886e-02, -6.3777e-02,  1.4730e-01, -1.6102e-01,\n         -3.7387e-02, -8.7830e-02, -4.0627e-02, -1.2097e-01,  1.5909e-01,\n          9.3035e-02, -3.0104e-02, -7.8207e-02, -1.7579e-01, -3.7046e-02,\n          1.0131e-01,  5.4369e-02, -1.4586e-01, -1.1425e-01,  1.6235e-01,\n          3.8904e-02,  9.9550e-02,  3.5554e-02,  9.5190e-02,  7.5239e-02,\n          8.9906e-02,  6.9041e-02],\n        [-9.4849e-02,  1.0138e-01, -4.0837e-02,  1.1002e-01, -9.3520e-02,\n         -6.2895e-02, -6.6367e-02, -1.5196e-02,  1.2063e-01,  1.5545e-01,\n         -1.2769e-01,  8.3486e-02,  1.6552e-01,  1.0002e-01, -1.5296e-02,\n         -3.4353e-02, -1.5214e-02, -1.7699e-02,  7.0523e-03, -2.4233e-03,\n         -1.0062e-01, -7.7158e-02,  1.7619e-01,  1.3449e-01,  1.2846e-01,\n          1.5405e-03,  1.6481e-01,  5.5958e-02,  2.7074e-02,  7.4830e-03,\n          1.2496e-01,  9.9883e-02],\n        [ 8.6181e-02,  3.4108e-02, -1.1803e-01, -1.2927e-01,  1.0042e-01,\n          1.6460e-01, -4.8237e-02, -1.7117e-02, -8.7496e-02,  1.6236e-01,\n         -6.8307e-02, -5.2327e-02,  1.4988e-01, -5.6540e-02,  4.4736e-02,\n         -1.2535e-01,  1.0986e-01, -8.4749e-02, -1.7629e-01,  9.1596e-02,\n          2.8016e-02,  1.2660e-02,  9.2063e-02,  1.6361e-01, -1.4008e-01,\n         -1.6083e-01,  1.0985e-01, -9.6380e-02, -3.8035e-02,  1.0992e-01,\n         -1.0861e-01,  3.4887e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1431,  0.1480,  0.2439,  0.0848, -0.0855,  0.1354, -0.1655,  0.0400],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0423, -0.0026, -0.2446,  0.2110,  0.2425,  0.0871, -0.1851,  0.0137,\n          0.0521,  0.2363, -0.0682, -0.2307,  0.1212,  0.2031,  0.1931,  0.2079],\n        [ 0.1417,  0.0639, -0.2412, -0.1892,  0.0959, -0.1615, -0.0617,  0.0884,\n          0.0321, -0.0796,  0.2378,  0.1256, -0.0110,  0.1791, -0.0069, -0.1744],\n        [ 0.1748,  0.0389,  0.1979, -0.1641,  0.2067,  0.0665, -0.0163, -0.0360,\n          0.1703,  0.1165,  0.2222, -0.0729,  0.1527,  0.1744, -0.1957, -0.1616],\n        [-0.1611,  0.2050,  0.0963, -0.0219, -0.0017,  0.2388, -0.1735, -0.0410,\n         -0.1062, -0.1854,  0.1957, -0.1669, -0.0937,  0.1649, -0.1596, -0.0777],\n        [-0.1955, -0.1983,  0.2345,  0.1924, -0.1856,  0.0565,  0.2065, -0.2181,\n          0.1044,  0.2001, -0.0776,  0.1743,  0.0295,  0.1024,  0.0125, -0.0597],\n        [ 0.0517,  0.1124, -0.1250,  0.1834, -0.0860,  0.0542,  0.0389, -0.0181,\n         -0.1098, -0.0752, -0.1672,  0.1153, -0.1851, -0.1397,  0.1606,  0.2093],\n        [ 0.1053,  0.0591, -0.0725, -0.1914, -0.1477,  0.1952,  0.0202, -0.2226,\n          0.0870, -0.1377,  0.1384,  0.1839, -0.0625,  0.0599,  0.0792,  0.0295],\n        [ 0.2207,  0.1280,  0.0878, -0.1149,  0.1309,  0.0317,  0.1900, -0.1903,\n         -0.2356,  0.2130, -0.0102,  0.0320, -0.2383,  0.2222, -0.1873, -0.0201]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3068, -0.2108,  0.1943, -0.1195], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3519,  0.2851,  0.0680, -0.1354, -0.1400, -0.1441, -0.3335,  0.1410],\n        [-0.3134, -0.1224, -0.2885, -0.3456,  0.1713,  0.0362, -0.0878,  0.2425],\n        [ 0.0780,  0.3128, -0.2250, -0.0261, -0.2584,  0.0994,  0.1662,  0.0817],\n        [-0.1927, -0.1621,  0.0701,  0.0605,  0.0770, -0.3149, -0.0128, -0.0541]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x70b929796d10>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s108440000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s108440000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}