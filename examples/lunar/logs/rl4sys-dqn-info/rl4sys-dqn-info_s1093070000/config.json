{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	0,
    "batch_size":	128,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1093070000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0003,
    "sample_decay":	0.5,
    "seed":	1093070000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x785fb56bc490>":	{
            "_act_dim":	4,
            "_aux_batch_size":	0,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1390,  0.3151,  0.2286,  0.1602, -0.2861,  0.2616,  0.0820, -0.1438,\n        -0.0019, -0.2864, -0.1906, -0.1095,  0.2001,  0.1339,  0.3237,  0.0623,\n         0.3431, -0.2035, -0.0350, -0.3036,  0.2496, -0.0991,  0.0412,  0.3262,\n         0.2010, -0.3399, -0.1951, -0.0380, -0.2682,  0.0029,  0.1833,  0.2110],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2003,  0.0350,  0.2895, -0.0429, -0.2205,  0.1461, -0.2177, -0.2717],\n        [-0.0218, -0.2777, -0.2710,  0.0172, -0.0105, -0.2464, -0.0464, -0.3203],\n        [-0.2070,  0.2304, -0.3074,  0.2988, -0.2048,  0.2215,  0.0598, -0.0326],\n        [ 0.0837, -0.2057,  0.3475, -0.2715,  0.2706,  0.2477,  0.1831, -0.0261],\n        [-0.1379,  0.3424, -0.2045, -0.0850,  0.1933,  0.1226,  0.2589,  0.1632],\n        [ 0.0127,  0.2968,  0.2229,  0.1313,  0.2074, -0.2807, -0.0838, -0.1866],\n        [-0.2353,  0.2923,  0.3339,  0.1804,  0.2227,  0.1676, -0.2705,  0.2594],\n        [ 0.1243, -0.2096, -0.2730, -0.2323, -0.0648, -0.2074,  0.0871, -0.2348],\n        [ 0.2627, -0.0351, -0.1389, -0.0775,  0.2765,  0.0345, -0.1101, -0.0932],\n        [-0.2197,  0.0814,  0.2861,  0.0410, -0.3134, -0.1449,  0.3312,  0.0582],\n        [ 0.0921,  0.1784,  0.3442, -0.1207, -0.0304, -0.0112,  0.0616, -0.2744],\n        [-0.0074,  0.1911,  0.1288,  0.0649,  0.0131,  0.2283,  0.2248,  0.2623],\n        [-0.1217, -0.1141,  0.0522,  0.2043, -0.2114, -0.1170,  0.1984,  0.3443],\n        [ 0.1475, -0.0650, -0.1933, -0.0711,  0.0891, -0.2353, -0.0245, -0.0525],\n        [ 0.2200, -0.1848,  0.3430, -0.1738,  0.3507,  0.0561,  0.3424, -0.0493],\n        [-0.2239,  0.2317, -0.1113,  0.2354,  0.3252,  0.2420,  0.1149,  0.0542],\n        [-0.2373,  0.2435,  0.2828, -0.1811,  0.2904,  0.2286, -0.1967,  0.0623],\n        [-0.0641, -0.0632,  0.2537,  0.0118,  0.1329, -0.0587, -0.1488,  0.0553],\n        [-0.2745,  0.0248, -0.0810,  0.0989,  0.0018, -0.0061, -0.2709, -0.0550],\n        [-0.2147, -0.0138, -0.1818, -0.2284, -0.1611, -0.1758,  0.1047, -0.2038],\n        [ 0.1407,  0.1200, -0.1816,  0.0321, -0.1910,  0.1267,  0.3038,  0.2291],\n        [-0.1764, -0.0463,  0.1279,  0.2215, -0.1018, -0.1231, -0.3391,  0.0277],\n        [ 0.2034, -0.2966, -0.3317, -0.0471,  0.2384,  0.1594, -0.1089,  0.1449],\n        [-0.2413,  0.2140,  0.2100,  0.1213,  0.0743,  0.0218, -0.2523,  0.2756],\n        [-0.1230,  0.2547,  0.0666,  0.2728, -0.1525,  0.1914,  0.2144, -0.3450],\n        [-0.0904,  0.2223,  0.0783,  0.0647, -0.0030, -0.0760, -0.1538, -0.3231],\n        [-0.0186,  0.1177,  0.3113, -0.0375, -0.0971,  0.3525, -0.3471, -0.2417],\n        [ 0.2743,  0.0376, -0.1387, -0.1404,  0.1896, -0.3524, -0.1160,  0.3331],\n        [ 0.0307, -0.3440, -0.0968, -0.3499,  0.1870,  0.1516, -0.2347,  0.2530],\n        [ 0.0025, -0.1248, -0.0114,  0.2966,  0.3230,  0.1418,  0.1692, -0.1406],\n        [ 0.2661,  0.2158, -0.1991, -0.1787, -0.2701, -0.1761, -0.1301,  0.2241],\n        [-0.0734,  0.1716, -0.2888, -0.0243, -0.2067,  0.2985,  0.1296,  0.1657]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1644,  0.1510, -0.1732,  0.0738, -0.0970, -0.0649, -0.0071, -0.0459,\n         0.1147, -0.1020, -0.0856,  0.1720, -0.0402,  0.1128, -0.1272,  0.0194],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.6345e-02,  7.1130e-02,  7.9006e-02, -5.3059e-02,  1.0771e-01,\n         -1.6688e-01, -7.3354e-02, -1.4269e-01, -6.3460e-02, -7.5627e-02,\n         -4.9404e-02,  1.3250e-01,  3.8161e-02, -1.4195e-03, -1.1070e-01,\n         -4.1001e-02, -9.3537e-02,  7.5912e-02, -1.3189e-01,  2.1620e-03,\n         -8.2154e-02, -1.5528e-01,  1.4041e-01,  9.6176e-02,  8.3749e-02,\n          1.1481e-01, -3.0307e-02, -2.8159e-02, -1.2351e-01,  1.7513e-02,\n          3.2813e-03, -1.7317e-01],\n        [ 1.5149e-02, -1.5674e-01,  4.7181e-02, -8.3463e-02, -7.4950e-02,\n          2.2978e-02, -1.2728e-01, -7.7874e-02,  9.0436e-02,  1.6526e-01,\n          9.6110e-02,  9.9109e-02, -1.6572e-01, -1.5518e-01, -1.7056e-01,\n         -8.3910e-02, -2.2831e-02,  9.2800e-02, -8.6447e-02, -1.5374e-01,\n         -1.3871e-01,  1.4116e-01, -3.2394e-03,  6.6047e-02,  1.5916e-01,\n         -1.7252e-01,  7.4448e-02,  1.1804e-01, -1.7508e-01, -6.0605e-02,\n         -4.1057e-02,  2.0806e-02],\n        [ 1.2745e-01,  5.8373e-05,  1.6696e-02,  1.1554e-01, -1.4709e-01,\n          1.7727e-02, -4.4270e-02,  1.0124e-01, -1.2628e-02,  1.6917e-01,\n         -1.0046e-01,  2.4940e-02,  1.2094e-02, -9.0444e-02, -9.8100e-02,\n         -1.3891e-01,  1.3540e-01, -8.4982e-02, -1.6711e-01, -3.0273e-02,\n         -3.4974e-02,  8.1156e-02, -1.4331e-01, -1.3836e-01, -2.6310e-02,\n          1.6284e-01,  1.6975e-01,  1.5144e-01,  1.5590e-01,  1.7159e-01,\n         -3.5357e-02,  7.7170e-02],\n        [-8.3710e-02, -1.4074e-01,  1.0388e-01, -1.1640e-02,  1.2997e-01,\n          6.5026e-03,  1.3142e-01, -6.0021e-02, -9.2076e-02,  2.5921e-02,\n          4.7879e-02, -3.8140e-02,  2.2364e-03, -1.5669e-02, -1.3096e-01,\n          1.0792e-01, -1.2605e-01,  8.4940e-02, -1.6381e-01,  1.0281e-01,\n          3.2300e-02, -3.3427e-02, -1.0571e-01, -1.0846e-02, -1.1051e-01,\n          5.4654e-02,  1.1987e-01,  1.1625e-01,  1.0860e-01, -3.1165e-02,\n         -4.5462e-02,  8.5062e-02],\n        [ 4.6119e-02, -8.3386e-02, -9.7523e-02, -4.3965e-04, -7.5798e-02,\n          1.4007e-02,  1.1477e-01,  5.1321e-02,  1.3689e-01,  1.4899e-01,\n          1.1565e-01,  9.4316e-02, -1.4475e-01, -1.2092e-01, -4.0718e-02,\n         -1.3509e-01, -3.4571e-02, -1.6129e-01,  7.7844e-02, -1.6258e-01,\n         -1.7131e-01, -1.1900e-01, -7.6073e-02,  4.3218e-02, -1.3899e-01,\n          2.1227e-03,  7.0182e-02, -1.1100e-02,  1.6076e-02, -7.8744e-02,\n         -1.6509e-01,  1.4460e-01],\n        [ 1.7524e-01,  7.7843e-02, -5.6927e-02, -1.6689e-01,  4.2223e-02,\n          1.0797e-01, -1.5560e-01,  4.4281e-03, -1.8185e-02,  1.6765e-01,\n          2.5075e-02, -7.6489e-02, -9.2173e-02,  1.1317e-01,  1.7304e-01,\n          1.5030e-01,  1.0998e-01,  1.0505e-01,  2.2746e-02,  8.4681e-02,\n         -4.8439e-03, -9.9015e-02,  1.5649e-01,  1.6459e-01,  8.6536e-02,\n         -1.7630e-01,  3.2541e-02,  1.5391e-01,  1.3617e-01, -5.4160e-02,\n         -1.7151e-01,  2.9425e-02],\n        [-2.8626e-04, -1.5688e-01,  1.4157e-01, -3.4590e-02,  1.4038e-01,\n         -1.9977e-02, -7.4565e-02, -1.7327e-01,  2.1712e-02, -8.6345e-02,\n         -1.2310e-01,  7.2466e-02, -1.7462e-01,  7.3234e-02, -1.6425e-01,\n          8.0234e-02, -1.5543e-01,  6.6996e-02, -9.0367e-02,  1.5753e-01,\n          1.2800e-01,  1.2374e-01, -1.5201e-01,  8.2670e-02, -7.3817e-02,\n         -1.6443e-01,  7.8915e-02, -6.3836e-02, -4.6009e-02, -1.8414e-02,\n         -1.0590e-02,  5.4416e-02],\n        [ 5.9271e-02, -6.0129e-02, -9.7739e-02,  4.4334e-02, -1.2525e-01,\n          8.1264e-02,  3.0269e-02,  6.6527e-02,  1.6310e-01,  1.7643e-01,\n         -1.0101e-01, -6.1482e-02, -1.2491e-01,  2.2781e-02,  3.1229e-02,\n         -1.1672e-01, -1.6446e-01,  7.4604e-02, -7.8839e-03,  1.4413e-01,\n         -7.5377e-02, -2.4187e-02, -9.6474e-02,  1.3864e-01,  3.0222e-02,\n          4.1498e-02,  1.6709e-01,  4.7572e-03,  1.6930e-01, -9.3319e-02,\n          6.0080e-02,  4.3490e-02],\n        [ 4.2051e-02,  3.9934e-02,  2.2424e-03, -7.5580e-02, -4.8357e-02,\n         -8.5929e-02,  1.0934e-01, -3.1714e-02, -1.7190e-01,  1.6535e-01,\n         -9.7825e-02,  1.1553e-01, -6.0937e-02,  9.8724e-02, -1.6472e-01,\n          1.4458e-01,  5.4216e-02, -7.5481e-02, -8.0342e-04, -1.6788e-01,\n          4.2159e-02, -1.0652e-02,  4.3951e-02,  5.4314e-02,  1.5033e-01,\n          2.0768e-02, -6.5868e-03, -8.7784e-02,  6.0554e-02,  5.9880e-02,\n          1.5496e-01,  1.6238e-01],\n        [ 1.5576e-01,  3.0631e-02,  7.5313e-02,  4.4623e-02, -1.1203e-01,\n          1.3854e-01, -1.5817e-01, -1.1246e-01,  1.7789e-02,  1.2099e-01,\n         -1.7636e-01, -1.5036e-01, -1.4232e-01, -9.9428e-02,  7.3761e-02,\n          1.1779e-01, -5.4363e-02, -1.9980e-02,  8.4830e-02, -1.3826e-01,\n          1.6820e-01, -1.3155e-01,  5.1004e-02, -1.7485e-01, -7.2740e-02,\n          1.5435e-01, -8.6825e-02, -8.4878e-02, -1.1691e-01,  3.8444e-02,\n         -1.4837e-01, -1.2391e-01],\n        [-6.0990e-02,  2.2683e-02, -7.4800e-02, -5.4434e-02,  6.0294e-02,\n         -1.6666e-01,  3.1998e-02, -2.7144e-02,  5.3493e-02,  1.1697e-01,\n          7.1451e-02,  6.1861e-02, -1.6759e-01, -5.2952e-02, -1.6994e-01,\n          9.5034e-02, -1.6308e-01, -1.4363e-01, -1.1051e-01,  8.0255e-02,\n          5.6286e-02, -1.5214e-01, -5.5274e-02, -1.2325e-01,  8.6222e-02,\n          1.6056e-01,  2.2977e-02, -1.4543e-01,  1.4122e-02,  9.6344e-02,\n          1.6868e-02,  5.3863e-02],\n        [ 1.6586e-01,  1.1508e-01,  5.2712e-02, -4.1541e-03,  1.1556e-01,\n         -3.0146e-02, -4.6206e-03,  1.0474e-01, -1.0176e-01, -1.5437e-01,\n         -1.3202e-01, -1.2402e-01,  9.9958e-02, -1.0103e-01,  1.7128e-01,\n         -1.5634e-01,  1.5789e-01,  1.6687e-01,  7.7710e-02,  5.0375e-02,\n          9.9464e-02,  1.4981e-01,  1.6545e-01,  1.6191e-01, -1.5538e-01,\n         -3.3198e-02, -8.7079e-02,  3.9732e-02, -1.6508e-01, -4.0622e-02,\n          4.8861e-03, -3.5143e-02],\n        [ 9.2530e-02,  1.1632e-01,  1.2445e-01,  5.5839e-02, -2.8643e-02,\n          1.6257e-02, -1.0640e-01,  9.7418e-02,  1.6529e-01, -8.0148e-02,\n         -1.1664e-01,  9.8258e-03,  1.1920e-01,  1.6473e-01,  5.1830e-02,\n          1.0549e-01, -4.8633e-02,  1.1692e-01, -8.4197e-02, -1.2477e-01,\n          4.1366e-02,  5.9196e-03, -5.1192e-02,  4.3639e-02, -9.4733e-02,\n          9.3011e-02, -1.6194e-01,  4.1936e-02, -2.9684e-02, -1.5241e-01,\n          1.6175e-01, -6.4804e-02],\n        [ 1.6203e-01, -1.2870e-02, -1.5130e-01,  1.6633e-01,  2.9591e-02,\n          3.2044e-02,  2.4046e-02,  8.0030e-02, -6.9667e-02,  7.1144e-02,\n          3.9385e-02,  9.0963e-02, -7.9491e-02,  9.2712e-02, -6.6474e-02,\n         -7.7215e-02,  1.6523e-01,  6.5363e-02,  1.5337e-01, -1.1968e-01,\n          1.1463e-01,  4.6758e-02,  9.1726e-02,  1.5294e-01, -1.4311e-01,\n          6.7675e-02, -1.0069e-01,  1.7532e-01,  6.8044e-02,  1.2000e-01,\n          1.4698e-02,  1.5289e-01],\n        [-4.3527e-02,  4.1251e-02,  1.6507e-01,  1.6917e-01, -4.9481e-02,\n         -4.1914e-02,  1.3383e-01, -2.4744e-02, -1.7085e-01,  1.0836e-01,\n          7.8505e-02, -1.1077e-01,  2.2939e-02, -3.7813e-02, -9.6505e-03,\n          1.7196e-01, -8.4869e-02, -5.1226e-02,  1.4353e-01,  7.0876e-02,\n          1.1891e-01,  2.4482e-02, -5.3724e-02,  6.8743e-03,  3.4476e-02,\n         -1.1527e-02, -1.4070e-01, -3.7935e-02, -1.2685e-01,  1.1623e-01,\n         -1.0943e-01, -1.7165e-01],\n        [ 1.2597e-01, -1.0748e-01, -1.0118e-01,  5.1190e-02, -2.4968e-02,\n          1.7035e-01,  4.0292e-02, -2.2313e-02, -2.3739e-02, -1.2229e-01,\n         -5.6159e-02,  1.4062e-01,  1.4232e-01, -3.6249e-02,  6.1847e-02,\n         -1.7563e-01,  1.5950e-01,  5.1853e-02, -4.8404e-02, -1.1163e-01,\n         -3.0916e-03, -1.1005e-01,  8.4629e-02,  3.0865e-02,  1.1764e-01,\n          2.4398e-02, -4.2364e-02, -3.0394e-02, -1.4105e-01,  7.8541e-02,\n         -8.9265e-02, -6.5254e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1443, -0.0256, -0.0938,  0.0391, -0.1464, -0.1744, -0.2029,  0.1487],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2140, -0.0080, -0.0031, -0.0958, -0.0299, -0.1695,  0.0029, -0.0410,\n         -0.1059,  0.0733,  0.1568, -0.0973, -0.1854,  0.1409, -0.1839,  0.1559],\n        [-0.1246, -0.0175,  0.1625, -0.2123, -0.0214,  0.0402, -0.1055, -0.1796,\n         -0.0356,  0.1703, -0.2056,  0.0073, -0.1259, -0.2301, -0.2376,  0.1309],\n        [ 0.2025, -0.1281,  0.2191, -0.0650, -0.0546, -0.0814,  0.0006,  0.0868,\n          0.0513, -0.1540, -0.0382, -0.0121,  0.2462,  0.1315, -0.2098, -0.1268],\n        [ 0.2012, -0.1770,  0.0340, -0.2429, -0.1132, -0.0028, -0.0723,  0.2483,\n         -0.2435,  0.0036, -0.1803, -0.2039,  0.1579,  0.0382, -0.0685,  0.0865],\n        [-0.0350, -0.1840,  0.1787,  0.1690, -0.1793, -0.2084, -0.0980, -0.0726,\n         -0.1599, -0.0514,  0.0770, -0.0455, -0.1798,  0.1642,  0.0993, -0.1950],\n        [-0.0070, -0.0664, -0.0059,  0.1142,  0.1197,  0.1048, -0.1457, -0.1622,\n          0.0788, -0.0546,  0.0027,  0.1039, -0.0293, -0.2258, -0.2431,  0.0467],\n        [ 0.0408, -0.0069,  0.1076, -0.1370,  0.1062, -0.1328, -0.1239, -0.0256,\n         -0.1563, -0.1598,  0.1867, -0.1949,  0.1531, -0.0245, -0.0528, -0.0803],\n        [ 0.1444, -0.1044,  0.0082,  0.1941, -0.1220, -0.2371,  0.0331,  0.0959,\n         -0.0171, -0.0838, -0.0213, -0.0856, -0.1993, -0.1478, -0.2405,  0.1542]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2408,  0.0873,  0.1576,  0.0127], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1224,  0.2606,  0.1227, -0.0725, -0.1411,  0.1579, -0.2598,  0.1254],\n        [-0.2629,  0.1786,  0.0326,  0.2744, -0.3084, -0.2755,  0.2882,  0.1568],\n        [-0.2010, -0.2559,  0.3171,  0.0666,  0.3397, -0.1217, -0.0546, -0.3136],\n        [ 0.2284, -0.0624,  0.0687,  0.3351,  0.3006,  0.3335, -0.2132,  0.2604]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2003,  0.0350,  0.2895, -0.0429, -0.2205,  0.1461, -0.2177, -0.2717],\n        [-0.0218, -0.2777, -0.2710,  0.0172, -0.0105, -0.2464, -0.0464, -0.3203],\n        [-0.2070,  0.2304, -0.3074,  0.2988, -0.2048,  0.2215,  0.0598, -0.0326],\n        [ 0.0837, -0.2057,  0.3475, -0.2715,  0.2706,  0.2477,  0.1831, -0.0261],\n        [-0.1379,  0.3424, -0.2045, -0.0850,  0.1933,  0.1226,  0.2589,  0.1632],\n        [ 0.0127,  0.2968,  0.2229,  0.1313,  0.2074, -0.2807, -0.0838, -0.1866],\n        [-0.2353,  0.2923,  0.3339,  0.1804,  0.2227,  0.1676, -0.2705,  0.2594],\n        [ 0.1243, -0.2096, -0.2730, -0.2323, -0.0648, -0.2074,  0.0871, -0.2348],\n        [ 0.2627, -0.0351, -0.1389, -0.0775,  0.2765,  0.0345, -0.1101, -0.0932],\n        [-0.2197,  0.0814,  0.2861,  0.0410, -0.3134, -0.1449,  0.3312,  0.0582],\n        [ 0.0921,  0.1784,  0.3442, -0.1207, -0.0304, -0.0112,  0.0616, -0.2744],\n        [-0.0074,  0.1911,  0.1288,  0.0649,  0.0131,  0.2283,  0.2248,  0.2623],\n        [-0.1217, -0.1141,  0.0522,  0.2043, -0.2114, -0.1170,  0.1984,  0.3443],\n        [ 0.1475, -0.0650, -0.1933, -0.0711,  0.0891, -0.2353, -0.0245, -0.0525],\n        [ 0.2200, -0.1848,  0.3430, -0.1738,  0.3507,  0.0561,  0.3424, -0.0493],\n        [-0.2239,  0.2317, -0.1113,  0.2354,  0.3252,  0.2420,  0.1149,  0.0542],\n        [-0.2373,  0.2435,  0.2828, -0.1811,  0.2904,  0.2286, -0.1967,  0.0623],\n        [-0.0641, -0.0632,  0.2537,  0.0118,  0.1329, -0.0587, -0.1488,  0.0553],\n        [-0.2745,  0.0248, -0.0810,  0.0989,  0.0018, -0.0061, -0.2709, -0.0550],\n        [-0.2147, -0.0138, -0.1818, -0.2284, -0.1611, -0.1758,  0.1047, -0.2038],\n        [ 0.1407,  0.1200, -0.1816,  0.0321, -0.1910,  0.1267,  0.3038,  0.2291],\n        [-0.1764, -0.0463,  0.1279,  0.2215, -0.1018, -0.1231, -0.3391,  0.0277],\n        [ 0.2034, -0.2966, -0.3317, -0.0471,  0.2384,  0.1594, -0.1089,  0.1449],\n        [-0.2413,  0.2140,  0.2100,  0.1213,  0.0743,  0.0218, -0.2523,  0.2756],\n        [-0.1230,  0.2547,  0.0666,  0.2728, -0.1525,  0.1914,  0.2144, -0.3450],\n        [-0.0904,  0.2223,  0.0783,  0.0647, -0.0030, -0.0760, -0.1538, -0.3231],\n        [-0.0186,  0.1177,  0.3113, -0.0375, -0.0971,  0.3525, -0.3471, -0.2417],\n        [ 0.2743,  0.0376, -0.1387, -0.1404,  0.1896, -0.3524, -0.1160,  0.3331],\n        [ 0.0307, -0.3440, -0.0968, -0.3499,  0.1870,  0.1516, -0.2347,  0.2530],\n        [ 0.0025, -0.1248, -0.0114,  0.2966,  0.3230,  0.1418,  0.1692, -0.1406],\n        [ 0.2661,  0.2158, -0.1991, -0.1787, -0.2701, -0.1761, -0.1301,  0.2241],\n        [-0.0734,  0.1716, -0.2888, -0.0243, -0.2067,  0.2985,  0.1296,  0.1657]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1390,  0.3151,  0.2286,  0.1602, -0.2861,  0.2616,  0.0820, -0.1438,\n        -0.0019, -0.2864, -0.1906, -0.1095,  0.2001,  0.1339,  0.3237,  0.0623,\n         0.3431, -0.2035, -0.0350, -0.3036,  0.2496, -0.0991,  0.0412,  0.3262,\n         0.2010, -0.3399, -0.1951, -0.0380, -0.2682,  0.0029,  0.1833,  0.2110],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-8.6345e-02,  7.1130e-02,  7.9006e-02, -5.3059e-02,  1.0771e-01,\n         -1.6688e-01, -7.3354e-02, -1.4269e-01, -6.3460e-02, -7.5627e-02,\n         -4.9404e-02,  1.3250e-01,  3.8161e-02, -1.4195e-03, -1.1070e-01,\n         -4.1001e-02, -9.3537e-02,  7.5912e-02, -1.3189e-01,  2.1620e-03,\n         -8.2154e-02, -1.5528e-01,  1.4041e-01,  9.6176e-02,  8.3749e-02,\n          1.1481e-01, -3.0307e-02, -2.8159e-02, -1.2351e-01,  1.7513e-02,\n          3.2813e-03, -1.7317e-01],\n        [ 1.5149e-02, -1.5674e-01,  4.7181e-02, -8.3463e-02, -7.4950e-02,\n          2.2978e-02, -1.2728e-01, -7.7874e-02,  9.0436e-02,  1.6526e-01,\n          9.6110e-02,  9.9109e-02, -1.6572e-01, -1.5518e-01, -1.7056e-01,\n         -8.3910e-02, -2.2831e-02,  9.2800e-02, -8.6447e-02, -1.5374e-01,\n         -1.3871e-01,  1.4116e-01, -3.2394e-03,  6.6047e-02,  1.5916e-01,\n         -1.7252e-01,  7.4448e-02,  1.1804e-01, -1.7508e-01, -6.0605e-02,\n         -4.1057e-02,  2.0806e-02],\n        [ 1.2745e-01,  5.8373e-05,  1.6696e-02,  1.1554e-01, -1.4709e-01,\n          1.7727e-02, -4.4270e-02,  1.0124e-01, -1.2628e-02,  1.6917e-01,\n         -1.0046e-01,  2.4940e-02,  1.2094e-02, -9.0444e-02, -9.8100e-02,\n         -1.3891e-01,  1.3540e-01, -8.4982e-02, -1.6711e-01, -3.0273e-02,\n         -3.4974e-02,  8.1156e-02, -1.4331e-01, -1.3836e-01, -2.6310e-02,\n          1.6284e-01,  1.6975e-01,  1.5144e-01,  1.5590e-01,  1.7159e-01,\n         -3.5357e-02,  7.7170e-02],\n        [-8.3710e-02, -1.4074e-01,  1.0388e-01, -1.1640e-02,  1.2997e-01,\n          6.5026e-03,  1.3142e-01, -6.0021e-02, -9.2076e-02,  2.5921e-02,\n          4.7879e-02, -3.8140e-02,  2.2364e-03, -1.5669e-02, -1.3096e-01,\n          1.0792e-01, -1.2605e-01,  8.4940e-02, -1.6381e-01,  1.0281e-01,\n          3.2300e-02, -3.3427e-02, -1.0571e-01, -1.0846e-02, -1.1051e-01,\n          5.4654e-02,  1.1987e-01,  1.1625e-01,  1.0860e-01, -3.1165e-02,\n         -4.5462e-02,  8.5062e-02],\n        [ 4.6119e-02, -8.3386e-02, -9.7523e-02, -4.3965e-04, -7.5798e-02,\n          1.4007e-02,  1.1477e-01,  5.1321e-02,  1.3689e-01,  1.4899e-01,\n          1.1565e-01,  9.4316e-02, -1.4475e-01, -1.2092e-01, -4.0718e-02,\n         -1.3509e-01, -3.4571e-02, -1.6129e-01,  7.7844e-02, -1.6258e-01,\n         -1.7131e-01, -1.1900e-01, -7.6073e-02,  4.3218e-02, -1.3899e-01,\n          2.1227e-03,  7.0182e-02, -1.1100e-02,  1.6076e-02, -7.8744e-02,\n         -1.6509e-01,  1.4460e-01],\n        [ 1.7524e-01,  7.7843e-02, -5.6927e-02, -1.6689e-01,  4.2223e-02,\n          1.0797e-01, -1.5560e-01,  4.4281e-03, -1.8185e-02,  1.6765e-01,\n          2.5075e-02, -7.6489e-02, -9.2173e-02,  1.1317e-01,  1.7304e-01,\n          1.5030e-01,  1.0998e-01,  1.0505e-01,  2.2746e-02,  8.4681e-02,\n         -4.8439e-03, -9.9015e-02,  1.5649e-01,  1.6459e-01,  8.6536e-02,\n         -1.7630e-01,  3.2541e-02,  1.5391e-01,  1.3617e-01, -5.4160e-02,\n         -1.7151e-01,  2.9425e-02],\n        [-2.8626e-04, -1.5688e-01,  1.4157e-01, -3.4590e-02,  1.4038e-01,\n         -1.9977e-02, -7.4565e-02, -1.7327e-01,  2.1712e-02, -8.6345e-02,\n         -1.2310e-01,  7.2466e-02, -1.7462e-01,  7.3234e-02, -1.6425e-01,\n          8.0234e-02, -1.5543e-01,  6.6996e-02, -9.0367e-02,  1.5753e-01,\n          1.2800e-01,  1.2374e-01, -1.5201e-01,  8.2670e-02, -7.3817e-02,\n         -1.6443e-01,  7.8915e-02, -6.3836e-02, -4.6009e-02, -1.8414e-02,\n         -1.0590e-02,  5.4416e-02],\n        [ 5.9271e-02, -6.0129e-02, -9.7739e-02,  4.4334e-02, -1.2525e-01,\n          8.1264e-02,  3.0269e-02,  6.6527e-02,  1.6310e-01,  1.7643e-01,\n         -1.0101e-01, -6.1482e-02, -1.2491e-01,  2.2781e-02,  3.1229e-02,\n         -1.1672e-01, -1.6446e-01,  7.4604e-02, -7.8839e-03,  1.4413e-01,\n         -7.5377e-02, -2.4187e-02, -9.6474e-02,  1.3864e-01,  3.0222e-02,\n          4.1498e-02,  1.6709e-01,  4.7572e-03,  1.6930e-01, -9.3319e-02,\n          6.0080e-02,  4.3490e-02],\n        [ 4.2051e-02,  3.9934e-02,  2.2424e-03, -7.5580e-02, -4.8357e-02,\n         -8.5929e-02,  1.0934e-01, -3.1714e-02, -1.7190e-01,  1.6535e-01,\n         -9.7825e-02,  1.1553e-01, -6.0937e-02,  9.8724e-02, -1.6472e-01,\n          1.4458e-01,  5.4216e-02, -7.5481e-02, -8.0342e-04, -1.6788e-01,\n          4.2159e-02, -1.0652e-02,  4.3951e-02,  5.4314e-02,  1.5033e-01,\n          2.0768e-02, -6.5868e-03, -8.7784e-02,  6.0554e-02,  5.9880e-02,\n          1.5496e-01,  1.6238e-01],\n        [ 1.5576e-01,  3.0631e-02,  7.5313e-02,  4.4623e-02, -1.1203e-01,\n          1.3854e-01, -1.5817e-01, -1.1246e-01,  1.7789e-02,  1.2099e-01,\n         -1.7636e-01, -1.5036e-01, -1.4232e-01, -9.9428e-02,  7.3761e-02,\n          1.1779e-01, -5.4363e-02, -1.9980e-02,  8.4830e-02, -1.3826e-01,\n          1.6820e-01, -1.3155e-01,  5.1004e-02, -1.7485e-01, -7.2740e-02,\n          1.5435e-01, -8.6825e-02, -8.4878e-02, -1.1691e-01,  3.8444e-02,\n         -1.4837e-01, -1.2391e-01],\n        [-6.0990e-02,  2.2683e-02, -7.4800e-02, -5.4434e-02,  6.0294e-02,\n         -1.6666e-01,  3.1998e-02, -2.7144e-02,  5.3493e-02,  1.1697e-01,\n          7.1451e-02,  6.1861e-02, -1.6759e-01, -5.2952e-02, -1.6994e-01,\n          9.5034e-02, -1.6308e-01, -1.4363e-01, -1.1051e-01,  8.0255e-02,\n          5.6286e-02, -1.5214e-01, -5.5274e-02, -1.2325e-01,  8.6222e-02,\n          1.6056e-01,  2.2977e-02, -1.4543e-01,  1.4122e-02,  9.6344e-02,\n          1.6868e-02,  5.3863e-02],\n        [ 1.6586e-01,  1.1508e-01,  5.2712e-02, -4.1541e-03,  1.1556e-01,\n         -3.0146e-02, -4.6206e-03,  1.0474e-01, -1.0176e-01, -1.5437e-01,\n         -1.3202e-01, -1.2402e-01,  9.9958e-02, -1.0103e-01,  1.7128e-01,\n         -1.5634e-01,  1.5789e-01,  1.6687e-01,  7.7710e-02,  5.0375e-02,\n          9.9464e-02,  1.4981e-01,  1.6545e-01,  1.6191e-01, -1.5538e-01,\n         -3.3198e-02, -8.7079e-02,  3.9732e-02, -1.6508e-01, -4.0622e-02,\n          4.8861e-03, -3.5143e-02],\n        [ 9.2530e-02,  1.1632e-01,  1.2445e-01,  5.5839e-02, -2.8643e-02,\n          1.6257e-02, -1.0640e-01,  9.7418e-02,  1.6529e-01, -8.0148e-02,\n         -1.1664e-01,  9.8258e-03,  1.1920e-01,  1.6473e-01,  5.1830e-02,\n          1.0549e-01, -4.8633e-02,  1.1692e-01, -8.4197e-02, -1.2477e-01,\n          4.1366e-02,  5.9196e-03, -5.1192e-02,  4.3639e-02, -9.4733e-02,\n          9.3011e-02, -1.6194e-01,  4.1936e-02, -2.9684e-02, -1.5241e-01,\n          1.6175e-01, -6.4804e-02],\n        [ 1.6203e-01, -1.2870e-02, -1.5130e-01,  1.6633e-01,  2.9591e-02,\n          3.2044e-02,  2.4046e-02,  8.0030e-02, -6.9667e-02,  7.1144e-02,\n          3.9385e-02,  9.0963e-02, -7.9491e-02,  9.2712e-02, -6.6474e-02,\n         -7.7215e-02,  1.6523e-01,  6.5363e-02,  1.5337e-01, -1.1968e-01,\n          1.1463e-01,  4.6758e-02,  9.1726e-02,  1.5294e-01, -1.4311e-01,\n          6.7675e-02, -1.0069e-01,  1.7532e-01,  6.8044e-02,  1.2000e-01,\n          1.4698e-02,  1.5289e-01],\n        [-4.3527e-02,  4.1251e-02,  1.6507e-01,  1.6917e-01, -4.9481e-02,\n         -4.1914e-02,  1.3383e-01, -2.4744e-02, -1.7085e-01,  1.0836e-01,\n          7.8505e-02, -1.1077e-01,  2.2939e-02, -3.7813e-02, -9.6505e-03,\n          1.7196e-01, -8.4869e-02, -5.1226e-02,  1.4353e-01,  7.0876e-02,\n          1.1891e-01,  2.4482e-02, -5.3724e-02,  6.8743e-03,  3.4476e-02,\n         -1.1527e-02, -1.4070e-01, -3.7935e-02, -1.2685e-01,  1.1623e-01,\n         -1.0943e-01, -1.7165e-01],\n        [ 1.2597e-01, -1.0748e-01, -1.0118e-01,  5.1190e-02, -2.4968e-02,\n          1.7035e-01,  4.0292e-02, -2.2313e-02, -2.3739e-02, -1.2229e-01,\n         -5.6159e-02,  1.4062e-01,  1.4232e-01, -3.6249e-02,  6.1847e-02,\n         -1.7563e-01,  1.5950e-01,  5.1853e-02, -4.8404e-02, -1.1163e-01,\n         -3.0916e-03, -1.1005e-01,  8.4629e-02,  3.0865e-02,  1.1764e-01,\n          2.4398e-02, -4.2364e-02, -3.0394e-02, -1.4105e-01,  7.8541e-02,\n         -8.9265e-02, -6.5254e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1644,  0.1510, -0.1732,  0.0738, -0.0970, -0.0649, -0.0071, -0.0459,\n         0.1147, -0.1020, -0.0856,  0.1720, -0.0402,  0.1128, -0.1272,  0.0194],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2140, -0.0080, -0.0031, -0.0958, -0.0299, -0.1695,  0.0029, -0.0410,\n         -0.1059,  0.0733,  0.1568, -0.0973, -0.1854,  0.1409, -0.1839,  0.1559],\n        [-0.1246, -0.0175,  0.1625, -0.2123, -0.0214,  0.0402, -0.1055, -0.1796,\n         -0.0356,  0.1703, -0.2056,  0.0073, -0.1259, -0.2301, -0.2376,  0.1309],\n        [ 0.2025, -0.1281,  0.2191, -0.0650, -0.0546, -0.0814,  0.0006,  0.0868,\n          0.0513, -0.1540, -0.0382, -0.0121,  0.2462,  0.1315, -0.2098, -0.1268],\n        [ 0.2012, -0.1770,  0.0340, -0.2429, -0.1132, -0.0028, -0.0723,  0.2483,\n         -0.2435,  0.0036, -0.1803, -0.2039,  0.1579,  0.0382, -0.0685,  0.0865],\n        [-0.0350, -0.1840,  0.1787,  0.1690, -0.1793, -0.2084, -0.0980, -0.0726,\n         -0.1599, -0.0514,  0.0770, -0.0455, -0.1798,  0.1642,  0.0993, -0.1950],\n        [-0.0070, -0.0664, -0.0059,  0.1142,  0.1197,  0.1048, -0.1457, -0.1622,\n          0.0788, -0.0546,  0.0027,  0.1039, -0.0293, -0.2258, -0.2431,  0.0467],\n        [ 0.0408, -0.0069,  0.1076, -0.1370,  0.1062, -0.1328, -0.1239, -0.0256,\n         -0.1563, -0.1598,  0.1867, -0.1949,  0.1531, -0.0245, -0.0528, -0.0803],\n        [ 0.1444, -0.1044,  0.0082,  0.1941, -0.1220, -0.2371,  0.0331,  0.0959,\n         -0.0171, -0.0838, -0.0213, -0.0856, -0.1993, -0.1478, -0.2405,  0.1542]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1443, -0.0256, -0.0938,  0.0391, -0.1464, -0.1744, -0.2029,  0.1487],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1224,  0.2606,  0.1227, -0.0725, -0.1411,  0.1579, -0.2598,  0.1254],\n        [-0.2629,  0.1786,  0.0326,  0.2744, -0.3084, -0.2755,  0.2882,  0.1568],\n        [-0.2010, -0.2559,  0.3171,  0.0666,  0.3397, -0.1217, -0.0546, -0.3136],\n        [ 0.2284, -0.0624,  0.0687,  0.3351,  0.3006,  0.3335, -0.2132,  0.2604]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2408,  0.0873,  0.1576,  0.0127], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x78602d5d8210>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x785fb4bc2450>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1390,  0.3151,  0.2286,  0.1602, -0.2861,  0.2616,  0.0820, -0.1438,\n        -0.0019, -0.2864, -0.1906, -0.1095,  0.2001,  0.1339,  0.3237,  0.0623,\n         0.3431, -0.2035, -0.0350, -0.3036,  0.2496, -0.0991,  0.0412,  0.3262,\n         0.2010, -0.3399, -0.1951, -0.0380, -0.2682,  0.0029,  0.1833,  0.2110],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2003,  0.0350,  0.2895, -0.0429, -0.2205,  0.1461, -0.2177, -0.2717],\n        [-0.0218, -0.2777, -0.2710,  0.0172, -0.0105, -0.2464, -0.0464, -0.3203],\n        [-0.2070,  0.2304, -0.3074,  0.2988, -0.2048,  0.2215,  0.0598, -0.0326],\n        [ 0.0837, -0.2057,  0.3475, -0.2715,  0.2706,  0.2477,  0.1831, -0.0261],\n        [-0.1379,  0.3424, -0.2045, -0.0850,  0.1933,  0.1226,  0.2589,  0.1632],\n        [ 0.0127,  0.2968,  0.2229,  0.1313,  0.2074, -0.2807, -0.0838, -0.1866],\n        [-0.2353,  0.2923,  0.3339,  0.1804,  0.2227,  0.1676, -0.2705,  0.2594],\n        [ 0.1243, -0.2096, -0.2730, -0.2323, -0.0648, -0.2074,  0.0871, -0.2348],\n        [ 0.2627, -0.0351, -0.1389, -0.0775,  0.2765,  0.0345, -0.1101, -0.0932],\n        [-0.2197,  0.0814,  0.2861,  0.0410, -0.3134, -0.1449,  0.3312,  0.0582],\n        [ 0.0921,  0.1784,  0.3442, -0.1207, -0.0304, -0.0112,  0.0616, -0.2744],\n        [-0.0074,  0.1911,  0.1288,  0.0649,  0.0131,  0.2283,  0.2248,  0.2623],\n        [-0.1217, -0.1141,  0.0522,  0.2043, -0.2114, -0.1170,  0.1984,  0.3443],\n        [ 0.1475, -0.0650, -0.1933, -0.0711,  0.0891, -0.2353, -0.0245, -0.0525],\n        [ 0.2200, -0.1848,  0.3430, -0.1738,  0.3507,  0.0561,  0.3424, -0.0493],\n        [-0.2239,  0.2317, -0.1113,  0.2354,  0.3252,  0.2420,  0.1149,  0.0542],\n        [-0.2373,  0.2435,  0.2828, -0.1811,  0.2904,  0.2286, -0.1967,  0.0623],\n        [-0.0641, -0.0632,  0.2537,  0.0118,  0.1329, -0.0587, -0.1488,  0.0553],\n        [-0.2745,  0.0248, -0.0810,  0.0989,  0.0018, -0.0061, -0.2709, -0.0550],\n        [-0.2147, -0.0138, -0.1818, -0.2284, -0.1611, -0.1758,  0.1047, -0.2038],\n        [ 0.1407,  0.1200, -0.1816,  0.0321, -0.1910,  0.1267,  0.3038,  0.2291],\n        [-0.1764, -0.0463,  0.1279,  0.2215, -0.1018, -0.1231, -0.3391,  0.0277],\n        [ 0.2034, -0.2966, -0.3317, -0.0471,  0.2384,  0.1594, -0.1089,  0.1449],\n        [-0.2413,  0.2140,  0.2100,  0.1213,  0.0743,  0.0218, -0.2523,  0.2756],\n        [-0.1230,  0.2547,  0.0666,  0.2728, -0.1525,  0.1914,  0.2144, -0.3450],\n        [-0.0904,  0.2223,  0.0783,  0.0647, -0.0030, -0.0760, -0.1538, -0.3231],\n        [-0.0186,  0.1177,  0.3113, -0.0375, -0.0971,  0.3525, -0.3471, -0.2417],\n        [ 0.2743,  0.0376, -0.1387, -0.1404,  0.1896, -0.3524, -0.1160,  0.3331],\n        [ 0.0307, -0.3440, -0.0968, -0.3499,  0.1870,  0.1516, -0.2347,  0.2530],\n        [ 0.0025, -0.1248, -0.0114,  0.2966,  0.3230,  0.1418,  0.1692, -0.1406],\n        [ 0.2661,  0.2158, -0.1991, -0.1787, -0.2701, -0.1761, -0.1301,  0.2241],\n        [-0.0734,  0.1716, -0.2888, -0.0243, -0.2067,  0.2985,  0.1296,  0.1657]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1644,  0.1510, -0.1732,  0.0738, -0.0970, -0.0649, -0.0071, -0.0459,\n         0.1147, -0.1020, -0.0856,  0.1720, -0.0402,  0.1128, -0.1272,  0.0194],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.6345e-02,  7.1130e-02,  7.9006e-02, -5.3059e-02,  1.0771e-01,\n         -1.6688e-01, -7.3354e-02, -1.4269e-01, -6.3460e-02, -7.5627e-02,\n         -4.9404e-02,  1.3250e-01,  3.8161e-02, -1.4195e-03, -1.1070e-01,\n         -4.1001e-02, -9.3537e-02,  7.5912e-02, -1.3189e-01,  2.1620e-03,\n         -8.2154e-02, -1.5528e-01,  1.4041e-01,  9.6176e-02,  8.3749e-02,\n          1.1481e-01, -3.0307e-02, -2.8159e-02, -1.2351e-01,  1.7513e-02,\n          3.2813e-03, -1.7317e-01],\n        [ 1.5149e-02, -1.5674e-01,  4.7181e-02, -8.3463e-02, -7.4950e-02,\n          2.2978e-02, -1.2728e-01, -7.7874e-02,  9.0436e-02,  1.6526e-01,\n          9.6110e-02,  9.9109e-02, -1.6572e-01, -1.5518e-01, -1.7056e-01,\n         -8.3910e-02, -2.2831e-02,  9.2800e-02, -8.6447e-02, -1.5374e-01,\n         -1.3871e-01,  1.4116e-01, -3.2394e-03,  6.6047e-02,  1.5916e-01,\n         -1.7252e-01,  7.4448e-02,  1.1804e-01, -1.7508e-01, -6.0605e-02,\n         -4.1057e-02,  2.0806e-02],\n        [ 1.2745e-01,  5.8373e-05,  1.6696e-02,  1.1554e-01, -1.4709e-01,\n          1.7727e-02, -4.4270e-02,  1.0124e-01, -1.2628e-02,  1.6917e-01,\n         -1.0046e-01,  2.4940e-02,  1.2094e-02, -9.0444e-02, -9.8100e-02,\n         -1.3891e-01,  1.3540e-01, -8.4982e-02, -1.6711e-01, -3.0273e-02,\n         -3.4974e-02,  8.1156e-02, -1.4331e-01, -1.3836e-01, -2.6310e-02,\n          1.6284e-01,  1.6975e-01,  1.5144e-01,  1.5590e-01,  1.7159e-01,\n         -3.5357e-02,  7.7170e-02],\n        [-8.3710e-02, -1.4074e-01,  1.0388e-01, -1.1640e-02,  1.2997e-01,\n          6.5026e-03,  1.3142e-01, -6.0021e-02, -9.2076e-02,  2.5921e-02,\n          4.7879e-02, -3.8140e-02,  2.2364e-03, -1.5669e-02, -1.3096e-01,\n          1.0792e-01, -1.2605e-01,  8.4940e-02, -1.6381e-01,  1.0281e-01,\n          3.2300e-02, -3.3427e-02, -1.0571e-01, -1.0846e-02, -1.1051e-01,\n          5.4654e-02,  1.1987e-01,  1.1625e-01,  1.0860e-01, -3.1165e-02,\n         -4.5462e-02,  8.5062e-02],\n        [ 4.6119e-02, -8.3386e-02, -9.7523e-02, -4.3965e-04, -7.5798e-02,\n          1.4007e-02,  1.1477e-01,  5.1321e-02,  1.3689e-01,  1.4899e-01,\n          1.1565e-01,  9.4316e-02, -1.4475e-01, -1.2092e-01, -4.0718e-02,\n         -1.3509e-01, -3.4571e-02, -1.6129e-01,  7.7844e-02, -1.6258e-01,\n         -1.7131e-01, -1.1900e-01, -7.6073e-02,  4.3218e-02, -1.3899e-01,\n          2.1227e-03,  7.0182e-02, -1.1100e-02,  1.6076e-02, -7.8744e-02,\n         -1.6509e-01,  1.4460e-01],\n        [ 1.7524e-01,  7.7843e-02, -5.6927e-02, -1.6689e-01,  4.2223e-02,\n          1.0797e-01, -1.5560e-01,  4.4281e-03, -1.8185e-02,  1.6765e-01,\n          2.5075e-02, -7.6489e-02, -9.2173e-02,  1.1317e-01,  1.7304e-01,\n          1.5030e-01,  1.0998e-01,  1.0505e-01,  2.2746e-02,  8.4681e-02,\n         -4.8439e-03, -9.9015e-02,  1.5649e-01,  1.6459e-01,  8.6536e-02,\n         -1.7630e-01,  3.2541e-02,  1.5391e-01,  1.3617e-01, -5.4160e-02,\n         -1.7151e-01,  2.9425e-02],\n        [-2.8626e-04, -1.5688e-01,  1.4157e-01, -3.4590e-02,  1.4038e-01,\n         -1.9977e-02, -7.4565e-02, -1.7327e-01,  2.1712e-02, -8.6345e-02,\n         -1.2310e-01,  7.2466e-02, -1.7462e-01,  7.3234e-02, -1.6425e-01,\n          8.0234e-02, -1.5543e-01,  6.6996e-02, -9.0367e-02,  1.5753e-01,\n          1.2800e-01,  1.2374e-01, -1.5201e-01,  8.2670e-02, -7.3817e-02,\n         -1.6443e-01,  7.8915e-02, -6.3836e-02, -4.6009e-02, -1.8414e-02,\n         -1.0590e-02,  5.4416e-02],\n        [ 5.9271e-02, -6.0129e-02, -9.7739e-02,  4.4334e-02, -1.2525e-01,\n          8.1264e-02,  3.0269e-02,  6.6527e-02,  1.6310e-01,  1.7643e-01,\n         -1.0101e-01, -6.1482e-02, -1.2491e-01,  2.2781e-02,  3.1229e-02,\n         -1.1672e-01, -1.6446e-01,  7.4604e-02, -7.8839e-03,  1.4413e-01,\n         -7.5377e-02, -2.4187e-02, -9.6474e-02,  1.3864e-01,  3.0222e-02,\n          4.1498e-02,  1.6709e-01,  4.7572e-03,  1.6930e-01, -9.3319e-02,\n          6.0080e-02,  4.3490e-02],\n        [ 4.2051e-02,  3.9934e-02,  2.2424e-03, -7.5580e-02, -4.8357e-02,\n         -8.5929e-02,  1.0934e-01, -3.1714e-02, -1.7190e-01,  1.6535e-01,\n         -9.7825e-02,  1.1553e-01, -6.0937e-02,  9.8724e-02, -1.6472e-01,\n          1.4458e-01,  5.4216e-02, -7.5481e-02, -8.0342e-04, -1.6788e-01,\n          4.2159e-02, -1.0652e-02,  4.3951e-02,  5.4314e-02,  1.5033e-01,\n          2.0768e-02, -6.5868e-03, -8.7784e-02,  6.0554e-02,  5.9880e-02,\n          1.5496e-01,  1.6238e-01],\n        [ 1.5576e-01,  3.0631e-02,  7.5313e-02,  4.4623e-02, -1.1203e-01,\n          1.3854e-01, -1.5817e-01, -1.1246e-01,  1.7789e-02,  1.2099e-01,\n         -1.7636e-01, -1.5036e-01, -1.4232e-01, -9.9428e-02,  7.3761e-02,\n          1.1779e-01, -5.4363e-02, -1.9980e-02,  8.4830e-02, -1.3826e-01,\n          1.6820e-01, -1.3155e-01,  5.1004e-02, -1.7485e-01, -7.2740e-02,\n          1.5435e-01, -8.6825e-02, -8.4878e-02, -1.1691e-01,  3.8444e-02,\n         -1.4837e-01, -1.2391e-01],\n        [-6.0990e-02,  2.2683e-02, -7.4800e-02, -5.4434e-02,  6.0294e-02,\n         -1.6666e-01,  3.1998e-02, -2.7144e-02,  5.3493e-02,  1.1697e-01,\n          7.1451e-02,  6.1861e-02, -1.6759e-01, -5.2952e-02, -1.6994e-01,\n          9.5034e-02, -1.6308e-01, -1.4363e-01, -1.1051e-01,  8.0255e-02,\n          5.6286e-02, -1.5214e-01, -5.5274e-02, -1.2325e-01,  8.6222e-02,\n          1.6056e-01,  2.2977e-02, -1.4543e-01,  1.4122e-02,  9.6344e-02,\n          1.6868e-02,  5.3863e-02],\n        [ 1.6586e-01,  1.1508e-01,  5.2712e-02, -4.1541e-03,  1.1556e-01,\n         -3.0146e-02, -4.6206e-03,  1.0474e-01, -1.0176e-01, -1.5437e-01,\n         -1.3202e-01, -1.2402e-01,  9.9958e-02, -1.0103e-01,  1.7128e-01,\n         -1.5634e-01,  1.5789e-01,  1.6687e-01,  7.7710e-02,  5.0375e-02,\n          9.9464e-02,  1.4981e-01,  1.6545e-01,  1.6191e-01, -1.5538e-01,\n         -3.3198e-02, -8.7079e-02,  3.9732e-02, -1.6508e-01, -4.0622e-02,\n          4.8861e-03, -3.5143e-02],\n        [ 9.2530e-02,  1.1632e-01,  1.2445e-01,  5.5839e-02, -2.8643e-02,\n          1.6257e-02, -1.0640e-01,  9.7418e-02,  1.6529e-01, -8.0148e-02,\n         -1.1664e-01,  9.8258e-03,  1.1920e-01,  1.6473e-01,  5.1830e-02,\n          1.0549e-01, -4.8633e-02,  1.1692e-01, -8.4197e-02, -1.2477e-01,\n          4.1366e-02,  5.9196e-03, -5.1192e-02,  4.3639e-02, -9.4733e-02,\n          9.3011e-02, -1.6194e-01,  4.1936e-02, -2.9684e-02, -1.5241e-01,\n          1.6175e-01, -6.4804e-02],\n        [ 1.6203e-01, -1.2870e-02, -1.5130e-01,  1.6633e-01,  2.9591e-02,\n          3.2044e-02,  2.4046e-02,  8.0030e-02, -6.9667e-02,  7.1144e-02,\n          3.9385e-02,  9.0963e-02, -7.9491e-02,  9.2712e-02, -6.6474e-02,\n         -7.7215e-02,  1.6523e-01,  6.5363e-02,  1.5337e-01, -1.1968e-01,\n          1.1463e-01,  4.6758e-02,  9.1726e-02,  1.5294e-01, -1.4311e-01,\n          6.7675e-02, -1.0069e-01,  1.7532e-01,  6.8044e-02,  1.2000e-01,\n          1.4698e-02,  1.5289e-01],\n        [-4.3527e-02,  4.1251e-02,  1.6507e-01,  1.6917e-01, -4.9481e-02,\n         -4.1914e-02,  1.3383e-01, -2.4744e-02, -1.7085e-01,  1.0836e-01,\n          7.8505e-02, -1.1077e-01,  2.2939e-02, -3.7813e-02, -9.6505e-03,\n          1.7196e-01, -8.4869e-02, -5.1226e-02,  1.4353e-01,  7.0876e-02,\n          1.1891e-01,  2.4482e-02, -5.3724e-02,  6.8743e-03,  3.4476e-02,\n         -1.1527e-02, -1.4070e-01, -3.7935e-02, -1.2685e-01,  1.1623e-01,\n         -1.0943e-01, -1.7165e-01],\n        [ 1.2597e-01, -1.0748e-01, -1.0118e-01,  5.1190e-02, -2.4968e-02,\n          1.7035e-01,  4.0292e-02, -2.2313e-02, -2.3739e-02, -1.2229e-01,\n         -5.6159e-02,  1.4062e-01,  1.4232e-01, -3.6249e-02,  6.1847e-02,\n         -1.7563e-01,  1.5950e-01,  5.1853e-02, -4.8404e-02, -1.1163e-01,\n         -3.0916e-03, -1.1005e-01,  8.4629e-02,  3.0865e-02,  1.1764e-01,\n          2.4398e-02, -4.2364e-02, -3.0394e-02, -1.4105e-01,  7.8541e-02,\n         -8.9265e-02, -6.5254e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1443, -0.0256, -0.0938,  0.0391, -0.1464, -0.1744, -0.2029,  0.1487],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2140, -0.0080, -0.0031, -0.0958, -0.0299, -0.1695,  0.0029, -0.0410,\n         -0.1059,  0.0733,  0.1568, -0.0973, -0.1854,  0.1409, -0.1839,  0.1559],\n        [-0.1246, -0.0175,  0.1625, -0.2123, -0.0214,  0.0402, -0.1055, -0.1796,\n         -0.0356,  0.1703, -0.2056,  0.0073, -0.1259, -0.2301, -0.2376,  0.1309],\n        [ 0.2025, -0.1281,  0.2191, -0.0650, -0.0546, -0.0814,  0.0006,  0.0868,\n          0.0513, -0.1540, -0.0382, -0.0121,  0.2462,  0.1315, -0.2098, -0.1268],\n        [ 0.2012, -0.1770,  0.0340, -0.2429, -0.1132, -0.0028, -0.0723,  0.2483,\n         -0.2435,  0.0036, -0.1803, -0.2039,  0.1579,  0.0382, -0.0685,  0.0865],\n        [-0.0350, -0.1840,  0.1787,  0.1690, -0.1793, -0.2084, -0.0980, -0.0726,\n         -0.1599, -0.0514,  0.0770, -0.0455, -0.1798,  0.1642,  0.0993, -0.1950],\n        [-0.0070, -0.0664, -0.0059,  0.1142,  0.1197,  0.1048, -0.1457, -0.1622,\n          0.0788, -0.0546,  0.0027,  0.1039, -0.0293, -0.2258, -0.2431,  0.0467],\n        [ 0.0408, -0.0069,  0.1076, -0.1370,  0.1062, -0.1328, -0.1239, -0.0256,\n         -0.1563, -0.1598,  0.1867, -0.1949,  0.1531, -0.0245, -0.0528, -0.0803],\n        [ 0.1444, -0.1044,  0.0082,  0.1941, -0.1220, -0.2371,  0.0331,  0.0959,\n         -0.0171, -0.0838, -0.0213, -0.0856, -0.1993, -0.1478, -0.2405,  0.1542]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2408,  0.0873,  0.1576,  0.0127], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1224,  0.2606,  0.1227, -0.0725, -0.1411,  0.1579, -0.2598,  0.1254],\n        [-0.2629,  0.1786,  0.0326,  0.2744, -0.3084, -0.2755,  0.2882,  0.1568],\n        [-0.2010, -0.2559,  0.3171,  0.0666,  0.3397, -0.1217, -0.0546, -0.3136],\n        [ 0.2284, -0.0624,  0.0687,  0.3351,  0.3006,  0.3335, -0.2132,  0.2604]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	32,
            "_traj_per_epoch":	16,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x785fb27ec9d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1093070000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1093070000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	32,
    "traj_per_epoch":	16
}