{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	0,
    "batch_size":	128,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0006,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1119700000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0005,
    "sample_decay":	0.5,
    "seed":	1119700000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x71c1bdcf0950>":	{
            "_act_dim":	4,
            "_aux_batch_size":	0,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0006,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0006,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2841,  0.2864,  0.2084,  0.1660,  0.2307, -0.0157,  0.3173,  0.1989,\n        -0.1347, -0.0458, -0.1275,  0.0523, -0.2407, -0.0304,  0.3313, -0.3218,\n         0.0327, -0.1641, -0.1481,  0.0004, -0.2366,  0.0611,  0.3424,  0.0739,\n         0.2411, -0.2542, -0.3030,  0.2645, -0.1141, -0.3082, -0.0431,  0.0903],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3362,  0.0213, -0.1705, -0.2650,  0.3284, -0.2424, -0.2713, -0.0876],\n        [-0.1345,  0.3024, -0.2725, -0.0839,  0.0135, -0.2701, -0.0802, -0.1604],\n        [-0.2933, -0.2562, -0.1602,  0.1077, -0.2461, -0.2212,  0.1050, -0.0817],\n        [ 0.1538,  0.1663,  0.3347,  0.2674,  0.1091, -0.2815, -0.1147,  0.2761],\n        [-0.1011,  0.0021, -0.2857,  0.2147, -0.3087, -0.0039,  0.1533,  0.1879],\n        [ 0.1398,  0.3116,  0.2069, -0.0757, -0.0940, -0.2558, -0.3087, -0.2730],\n        [-0.0075, -0.0309,  0.0233, -0.0806,  0.0326, -0.3463, -0.0083, -0.2378],\n        [-0.0681,  0.1207, -0.2915,  0.1988,  0.2511, -0.2873,  0.2727, -0.1529],\n        [-0.2691,  0.3156,  0.1814, -0.1105, -0.1091, -0.0795, -0.2617, -0.0676],\n        [ 0.0487,  0.1703, -0.2576, -0.2990, -0.2557, -0.1491, -0.1459,  0.3362],\n        [ 0.2410, -0.2933, -0.2333, -0.2045,  0.0829,  0.2220,  0.0083, -0.0245],\n        [ 0.1244,  0.0732, -0.0944,  0.3143, -0.2836,  0.1530,  0.0302, -0.2191],\n        [ 0.1477,  0.1605,  0.1486, -0.0978, -0.0102,  0.3229, -0.0760,  0.0097],\n        [ 0.2275, -0.2333,  0.2514, -0.1112,  0.3487, -0.0408, -0.1744, -0.0579],\n        [ 0.1505, -0.2614,  0.1934,  0.1191,  0.0572,  0.2031, -0.3427, -0.2886],\n        [-0.2720,  0.0459, -0.2780,  0.2830, -0.0560,  0.0406, -0.2717, -0.2350],\n        [ 0.0634, -0.0425, -0.1906,  0.2742,  0.3219,  0.3006, -0.3188,  0.2000],\n        [-0.1346,  0.2748, -0.0708,  0.0997,  0.0057, -0.1793,  0.2132,  0.0579],\n        [ 0.0168, -0.2055,  0.3120,  0.1986, -0.0798, -0.1807, -0.2088,  0.2479],\n        [ 0.2433,  0.2090, -0.2864,  0.0727,  0.1716,  0.2137, -0.0213,  0.2578],\n        [ 0.1406,  0.1596,  0.0333, -0.1946, -0.3274, -0.3289,  0.3337, -0.2813],\n        [ 0.1589, -0.1028, -0.1107,  0.2033, -0.1034,  0.1333,  0.2960, -0.2452],\n        [-0.0025, -0.1727, -0.1165, -0.1966,  0.3034,  0.2599, -0.1062, -0.1195],\n        [-0.1626,  0.3043,  0.3335,  0.3428, -0.2516,  0.2957,  0.0834, -0.2111],\n        [ 0.2874,  0.3079,  0.2515,  0.2780, -0.1812, -0.0832,  0.1450,  0.0626],\n        [-0.3277, -0.1747,  0.2743,  0.0074, -0.0495,  0.0583, -0.2847,  0.0519],\n        [ 0.0256,  0.2860, -0.2448,  0.2289, -0.2901,  0.3164, -0.1033, -0.0351],\n        [ 0.0792, -0.2323, -0.0195, -0.0907, -0.2744,  0.2114,  0.0314,  0.3093],\n        [-0.1868, -0.0627,  0.2472, -0.0072, -0.1178, -0.1545,  0.2726,  0.2158],\n        [ 0.0968,  0.2551,  0.1526,  0.3508, -0.3134,  0.1289, -0.2105,  0.2554],\n        [ 0.3221,  0.1619, -0.0874, -0.3446, -0.2845, -0.1014,  0.1986, -0.3505],\n        [ 0.3117, -0.1953, -0.0033, -0.1022,  0.0436, -0.0925, -0.2843,  0.1348]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0212, -0.0980,  0.0691,  0.0672, -0.1152, -0.1603, -0.0191,  0.0205,\n        -0.0607,  0.1299,  0.1762, -0.1516,  0.1130, -0.0955,  0.0842, -0.0388],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 4.3484e-02, -1.5718e-01, -1.1366e-01,  8.6112e-02,  9.0850e-03,\n          1.3293e-01, -1.1126e-01,  1.2447e-01, -6.8356e-02, -1.5392e-01,\n          1.4166e-02, -1.0945e-01,  1.4868e-01, -8.3206e-02, -5.6498e-03,\n         -4.1910e-02,  9.6337e-02,  1.4934e-01,  2.8263e-02, -1.5537e-01,\n         -1.5991e-02,  8.3385e-03,  6.4664e-03, -1.0772e-02, -5.4276e-02,\n         -1.6665e-01,  2.3119e-02, -2.1880e-02,  1.4406e-01, -4.8776e-02,\n          1.6018e-01, -7.7487e-02],\n        [ 3.7671e-02,  9.4955e-02,  1.2056e-01,  1.7767e-02,  1.6019e-01,\n          1.6354e-01, -4.2362e-02,  1.1883e-01,  1.4289e-01,  8.7126e-02,\n         -1.5064e-01, -1.5783e-01,  8.6839e-02, -6.6484e-02, -1.3787e-02,\n          1.0857e-01, -1.2722e-01,  7.9596e-02,  3.8681e-02,  3.9871e-05,\n          1.1476e-01,  5.9352e-02, -2.9442e-02,  1.3741e-01, -1.3608e-01,\n         -7.0429e-02, -1.7460e-01, -1.1231e-01,  9.2262e-02, -1.0396e-01,\n          6.5828e-02,  7.7264e-02],\n        [ 4.8495e-02,  8.6397e-03, -1.4324e-01, -5.3034e-02,  1.4076e-01,\n         -8.7040e-02,  1.7509e-01,  1.2220e-01, -9.7386e-02,  8.6906e-02,\n          7.5181e-03, -1.2347e-01,  6.7243e-02, -8.7050e-02,  1.6795e-01,\n         -7.3622e-02,  1.1795e-01,  1.2263e-01, -7.7885e-02,  1.2885e-01,\n          1.2225e-01, -1.5431e-02, -7.1185e-03,  4.3357e-02, -8.0196e-02,\n         -9.8158e-02,  1.3621e-01,  9.6491e-02, -1.4583e-01, -3.8539e-04,\n          3.9833e-02,  1.5903e-01],\n        [ 8.9924e-02, -7.7825e-02,  5.6075e-02,  7.2419e-02, -3.9011e-02,\n         -6.9996e-02, -1.5361e-01,  6.9288e-02,  6.5025e-02,  5.4839e-02,\n         -9.8961e-02, -2.2400e-02, -1.7395e-01, -7.2387e-02, -2.7358e-02,\n          7.7806e-02,  1.7398e-01,  3.3542e-02,  6.4885e-02, -1.6710e-01,\n          1.6217e-02, -9.1022e-02,  8.3477e-02, -1.8580e-02, -4.3486e-03,\n         -2.0257e-02,  9.9760e-02, -5.0598e-02, -1.2848e-01,  1.7584e-01,\n          5.6050e-02, -1.2614e-01],\n        [-1.3799e-01, -1.4259e-01,  7.9476e-02,  1.8208e-02,  9.5651e-02,\n          2.5617e-02, -1.5949e-01,  1.4969e-01,  6.2252e-02, -7.8867e-02,\n         -6.0514e-02,  1.1607e-03, -3.3710e-02, -4.7088e-02, -1.1452e-01,\n          1.6194e-01, -7.6572e-02,  4.3778e-02,  8.3579e-02, -1.7388e-01,\n          3.2148e-02, -1.0196e-01, -1.4528e-01, -1.0761e-01, -4.3520e-02,\n         -1.2144e-01, -3.8790e-02, -1.3902e-02, -5.9239e-02,  9.0877e-02,\n         -4.8785e-02, -6.3768e-02],\n        [-1.3475e-03,  5.4911e-02, -1.2269e-01, -1.3196e-02,  2.8030e-02,\n         -1.9293e-02,  1.1510e-01, -1.1619e-01, -4.2001e-02, -9.3543e-02,\n          8.3886e-02, -4.7891e-02,  2.5941e-02, -1.4716e-01, -4.4048e-03,\n          1.0082e-01, -1.6738e-01,  1.4971e-01,  1.1865e-01, -1.3165e-01,\n         -1.5832e-01, -1.0691e-01, -3.3351e-02, -3.5904e-03,  1.2046e-01,\n          1.6988e-01,  1.2868e-01,  9.7289e-02,  4.9581e-02,  1.7976e-02,\n         -7.7814e-02, -1.0169e-01],\n        [ 5.7100e-02,  2.6911e-02,  1.4727e-01, -1.6772e-01,  6.6060e-02,\n          8.2244e-02, -2.2551e-02, -1.5879e-01,  1.7272e-01, -1.4604e-01,\n          1.1849e-01,  1.4713e-01, -1.7516e-01,  5.7498e-02,  1.3914e-01,\n         -1.1982e-01,  1.0901e-02,  7.0098e-02, -1.7787e-02, -6.5303e-02,\n          3.7005e-02, -9.4432e-02, -7.9931e-02, -1.8560e-02,  7.7241e-02,\n         -5.3936e-03,  4.3197e-02, -1.1553e-01, -5.7723e-02,  6.0105e-02,\n         -1.3380e-01, -1.2440e-01],\n        [ 5.6370e-02, -1.1903e-01,  1.0797e-01,  2.1158e-02, -5.5800e-02,\n         -1.0309e-01, -6.8360e-02, -5.9837e-02, -1.6056e-01,  1.5022e-01,\n          1.6010e-01,  4.1223e-02,  1.3126e-02, -5.7184e-02,  1.7135e-01,\n          9.0582e-02,  1.3297e-01,  6.9352e-02,  2.8435e-02,  1.0681e-01,\n          7.9458e-02,  5.2727e-02, -3.1185e-02, -1.2831e-01,  9.2504e-02,\n         -1.1822e-01,  1.7481e-01, -9.0421e-02, -2.6624e-02, -1.4509e-01,\n         -5.0600e-02, -2.9849e-02],\n        [-5.1351e-02, -1.2823e-01,  5.4316e-02,  1.1155e-01, -7.5462e-02,\n         -5.9463e-02, -3.1388e-02,  1.1678e-01, -1.1900e-01, -1.0571e-01,\n          1.0247e-02,  1.0262e-01,  8.1302e-02,  3.3627e-02,  9.8298e-02,\n         -1.2807e-01, -1.0410e-02,  1.5567e-02, -1.0441e-01, -6.2700e-02,\n          1.2542e-01, -5.3210e-02,  1.3202e-01, -9.7232e-02,  6.0913e-02,\n          1.1769e-01, -1.2104e-01, -8.6566e-02, -8.7451e-02,  6.4022e-02,\n         -5.3551e-02,  1.6822e-01],\n        [-6.5695e-02, -4.3233e-02, -1.0780e-01,  3.8305e-02, -7.6646e-02,\n         -8.4903e-03, -2.7655e-02,  1.1920e-01, -8.8538e-02, -6.2690e-02,\n          1.4579e-02, -7.1238e-02, -1.6511e-01,  8.2407e-02,  1.7218e-01,\n         -1.3617e-01, -9.6654e-02, -1.2419e-02,  1.5051e-02,  3.8661e-02,\n         -4.3613e-02,  1.3161e-01, -1.4998e-01,  7.5045e-03, -8.4728e-02,\n          3.6361e-02, -1.3780e-01, -8.1326e-02,  4.3170e-02,  1.0763e-01,\n          1.0511e-01, -1.7454e-01],\n        [-1.3183e-01,  1.7361e-01, -1.7762e-02,  1.5168e-01,  1.2481e-01,\n          6.5820e-02,  5.3320e-03,  2.6218e-02,  1.6126e-01,  7.4919e-02,\n          6.3050e-02,  8.3850e-02, -1.5070e-01, -9.2561e-02,  8.2255e-02,\n         -1.7336e-01, -6.1968e-02, -5.9864e-02, -1.7093e-01,  1.8487e-02,\n         -1.6714e-01, -2.4823e-02, -1.0925e-01, -1.5875e-01, -1.0669e-01,\n          7.4955e-02, -5.9704e-02, -1.6219e-01, -1.7158e-01,  6.8341e-03,\n         -1.7329e-01,  9.0561e-02],\n        [ 3.6964e-03,  3.1634e-02, -8.1368e-02,  1.4000e-01, -1.7113e-01,\n          7.2839e-02, -6.0243e-03,  4.2445e-02,  1.6389e-01,  1.5788e-01,\n         -3.6595e-02, -1.5842e-01, -1.5370e-01,  1.7229e-01, -5.0268e-02,\n         -5.0184e-02,  1.3088e-01, -1.9642e-02, -1.6048e-01, -9.3962e-02,\n         -1.1600e-01,  1.0201e-01, -7.8637e-02,  3.7107e-02,  5.1018e-02,\n         -1.6905e-01,  1.1105e-01, -2.4979e-03,  6.6760e-02,  1.2263e-01,\n         -2.9110e-02,  1.7333e-01],\n        [-4.9462e-03,  2.2293e-02,  1.0248e-01, -1.9926e-02,  2.9732e-04,\n         -1.6249e-01, -1.6913e-01,  1.7049e-01,  1.1934e-01, -7.6997e-02,\n         -4.6682e-02, -1.5447e-01, -1.7129e-01,  1.4570e-02,  2.6882e-02,\n          1.3857e-01,  6.2906e-02, -1.2500e-01,  4.1565e-03,  1.0253e-01,\n         -1.2915e-02, -4.7212e-02,  1.0965e-01, -5.3510e-02,  1.0549e-02,\n         -6.0238e-02, -5.1052e-02,  1.1115e-01,  1.6403e-01,  8.1036e-02,\n          1.6678e-01,  3.5885e-02],\n        [-1.1363e-01,  4.1001e-02,  1.3017e-01, -2.1425e-02,  6.9504e-02,\n         -1.3044e-01, -1.4676e-01, -2.1103e-04, -7.1782e-02, -4.7176e-02,\n          3.9760e-02, -1.2393e-01,  1.1026e-01,  9.4690e-02,  2.5542e-03,\n          1.4949e-01,  5.5323e-02, -1.0966e-02,  5.3529e-02,  1.2067e-01,\n          9.8564e-02,  1.7090e-01,  1.4810e-01, -7.6046e-02, -1.6156e-01,\n         -1.7033e-01, -1.4121e-02, -1.6900e-01, -7.8944e-02,  1.0485e-01,\n         -7.8541e-02,  8.8775e-03],\n        [-1.1814e-01, -7.8885e-02, -1.5593e-01,  1.1883e-01, -7.9675e-02,\n          1.3393e-01, -1.2971e-02, -1.5099e-01, -1.4197e-01, -1.4052e-01,\n          9.4413e-02,  6.1668e-02,  1.1704e-02, -1.7007e-01,  6.9391e-02,\n          1.6561e-01,  1.2337e-01,  1.6515e-01, -1.4946e-01, -1.6484e-03,\n         -1.3683e-01,  4.6479e-02,  1.4007e-01,  8.6214e-02,  7.3214e-02,\n          6.9589e-02, -2.4173e-02,  7.1100e-02, -1.7264e-02,  4.7920e-02,\n         -5.5484e-02, -8.4744e-02],\n        [-8.2258e-02, -8.8936e-02, -6.7594e-02, -3.5126e-02,  1.6927e-01,\n         -3.1457e-02,  8.3488e-02,  6.1867e-02,  7.8313e-02, -1.5089e-01,\n          1.4288e-01,  4.6655e-02,  2.6813e-02, -3.8711e-02,  1.5978e-01,\n         -3.5790e-02, -3.9061e-02,  1.2637e-01, -1.5113e-01,  2.7121e-02,\n         -1.5190e-01, -4.7226e-02, -3.8236e-04,  1.4679e-01, -1.3960e-01,\n         -1.3973e-01, -8.6619e-02, -1.1731e-02,  1.4037e-01,  6.8327e-02,\n          1.3361e-01,  1.1584e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2466,  0.1567,  0.1104,  0.1657, -0.1378, -0.1497,  0.1232,  0.0951],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0181, -0.1871, -0.0556, -0.1813,  0.0351, -0.2031,  0.2102,  0.0936,\n         -0.2117, -0.1225,  0.1575,  0.1988,  0.0585, -0.1286,  0.2194,  0.0853],\n        [-0.0577, -0.0201, -0.1677, -0.1815, -0.0660, -0.0372,  0.1289,  0.2427,\n          0.0643,  0.0799, -0.2498, -0.2311,  0.1950,  0.1547, -0.2112, -0.2191],\n        [ 0.1878,  0.1283,  0.2354, -0.0546,  0.0113, -0.1711, -0.2264, -0.1314,\n         -0.0736,  0.0430, -0.1008, -0.2431, -0.1821, -0.1979,  0.1826,  0.1391],\n        [-0.0655,  0.2212,  0.0704, -0.1896,  0.1002, -0.1451,  0.1174,  0.2294,\n          0.0321,  0.2178, -0.0974, -0.0526,  0.0592,  0.0724,  0.2406, -0.0452],\n        [-0.0034, -0.0045,  0.1524, -0.1558,  0.0548, -0.0426,  0.1758, -0.0997,\n          0.2003,  0.0577, -0.2492,  0.1515, -0.2009, -0.1197, -0.0648,  0.2194],\n        [-0.1519,  0.1201, -0.0824, -0.1488,  0.1481, -0.1749,  0.0375, -0.0320,\n         -0.2264,  0.0153, -0.0923,  0.1754, -0.1057,  0.1551, -0.1192, -0.1481],\n        [-0.1534,  0.1246, -0.1052,  0.1279, -0.1142, -0.0984, -0.0519,  0.1585,\n         -0.1450, -0.1296, -0.1332,  0.0889,  0.1961, -0.1711, -0.2394, -0.0290],\n        [ 0.1426, -0.0770, -0.1656,  0.0661,  0.0619, -0.2132,  0.1969, -0.0086,\n          0.2055,  0.1950,  0.2236,  0.0253,  0.1928, -0.1503, -0.1735, -0.2451]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0888, -0.2454,  0.1532, -0.2151], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0886,  0.3061,  0.2504, -0.2650, -0.2593,  0.0941,  0.0479, -0.0719],\n        [-0.0015,  0.1291,  0.2508,  0.2573, -0.3035,  0.1625,  0.2690,  0.3137],\n        [ 0.3477,  0.2170,  0.0650,  0.0852, -0.0020, -0.0467,  0.3352,  0.2019],\n        [-0.1249, -0.2637, -0.0966, -0.1039,  0.1513,  0.1311,  0.1404, -0.0185]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.3362,  0.0213, -0.1705, -0.2650,  0.3284, -0.2424, -0.2713, -0.0876],\n        [-0.1345,  0.3024, -0.2725, -0.0839,  0.0135, -0.2701, -0.0802, -0.1604],\n        [-0.2933, -0.2562, -0.1602,  0.1077, -0.2461, -0.2212,  0.1050, -0.0817],\n        [ 0.1538,  0.1663,  0.3347,  0.2674,  0.1091, -0.2815, -0.1147,  0.2761],\n        [-0.1011,  0.0021, -0.2857,  0.2147, -0.3087, -0.0039,  0.1533,  0.1879],\n        [ 0.1398,  0.3116,  0.2069, -0.0757, -0.0940, -0.2558, -0.3087, -0.2730],\n        [-0.0075, -0.0309,  0.0233, -0.0806,  0.0326, -0.3463, -0.0083, -0.2378],\n        [-0.0681,  0.1207, -0.2915,  0.1988,  0.2511, -0.2873,  0.2727, -0.1529],\n        [-0.2691,  0.3156,  0.1814, -0.1105, -0.1091, -0.0795, -0.2617, -0.0676],\n        [ 0.0487,  0.1703, -0.2576, -0.2990, -0.2557, -0.1491, -0.1459,  0.3362],\n        [ 0.2410, -0.2933, -0.2333, -0.2045,  0.0829,  0.2220,  0.0083, -0.0245],\n        [ 0.1244,  0.0732, -0.0944,  0.3143, -0.2836,  0.1530,  0.0302, -0.2191],\n        [ 0.1477,  0.1605,  0.1486, -0.0978, -0.0102,  0.3229, -0.0760,  0.0097],\n        [ 0.2275, -0.2333,  0.2514, -0.1112,  0.3487, -0.0408, -0.1744, -0.0579],\n        [ 0.1505, -0.2614,  0.1934,  0.1191,  0.0572,  0.2031, -0.3427, -0.2886],\n        [-0.2720,  0.0459, -0.2780,  0.2830, -0.0560,  0.0406, -0.2717, -0.2350],\n        [ 0.0634, -0.0425, -0.1906,  0.2742,  0.3219,  0.3006, -0.3188,  0.2000],\n        [-0.1346,  0.2748, -0.0708,  0.0997,  0.0057, -0.1793,  0.2132,  0.0579],\n        [ 0.0168, -0.2055,  0.3120,  0.1986, -0.0798, -0.1807, -0.2088,  0.2479],\n        [ 0.2433,  0.2090, -0.2864,  0.0727,  0.1716,  0.2137, -0.0213,  0.2578],\n        [ 0.1406,  0.1596,  0.0333, -0.1946, -0.3274, -0.3289,  0.3337, -0.2813],\n        [ 0.1589, -0.1028, -0.1107,  0.2033, -0.1034,  0.1333,  0.2960, -0.2452],\n        [-0.0025, -0.1727, -0.1165, -0.1966,  0.3034,  0.2599, -0.1062, -0.1195],\n        [-0.1626,  0.3043,  0.3335,  0.3428, -0.2516,  0.2957,  0.0834, -0.2111],\n        [ 0.2874,  0.3079,  0.2515,  0.2780, -0.1812, -0.0832,  0.1450,  0.0626],\n        [-0.3277, -0.1747,  0.2743,  0.0074, -0.0495,  0.0583, -0.2847,  0.0519],\n        [ 0.0256,  0.2860, -0.2448,  0.2289, -0.2901,  0.3164, -0.1033, -0.0351],\n        [ 0.0792, -0.2323, -0.0195, -0.0907, -0.2744,  0.2114,  0.0314,  0.3093],\n        [-0.1868, -0.0627,  0.2472, -0.0072, -0.1178, -0.1545,  0.2726,  0.2158],\n        [ 0.0968,  0.2551,  0.1526,  0.3508, -0.3134,  0.1289, -0.2105,  0.2554],\n        [ 0.3221,  0.1619, -0.0874, -0.3446, -0.2845, -0.1014,  0.1986, -0.3505],\n        [ 0.3117, -0.1953, -0.0033, -0.1022,  0.0436, -0.0925, -0.2843,  0.1348]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2841,  0.2864,  0.2084,  0.1660,  0.2307, -0.0157,  0.3173,  0.1989,\n        -0.1347, -0.0458, -0.1275,  0.0523, -0.2407, -0.0304,  0.3313, -0.3218,\n         0.0327, -0.1641, -0.1481,  0.0004, -0.2366,  0.0611,  0.3424,  0.0739,\n         0.2411, -0.2542, -0.3030,  0.2645, -0.1141, -0.3082, -0.0431,  0.0903],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 4.3484e-02, -1.5718e-01, -1.1366e-01,  8.6112e-02,  9.0850e-03,\n          1.3293e-01, -1.1126e-01,  1.2447e-01, -6.8356e-02, -1.5392e-01,\n          1.4166e-02, -1.0945e-01,  1.4868e-01, -8.3206e-02, -5.6498e-03,\n         -4.1910e-02,  9.6337e-02,  1.4934e-01,  2.8263e-02, -1.5537e-01,\n         -1.5991e-02,  8.3385e-03,  6.4664e-03, -1.0772e-02, -5.4276e-02,\n         -1.6665e-01,  2.3119e-02, -2.1880e-02,  1.4406e-01, -4.8776e-02,\n          1.6018e-01, -7.7487e-02],\n        [ 3.7671e-02,  9.4955e-02,  1.2056e-01,  1.7767e-02,  1.6019e-01,\n          1.6354e-01, -4.2362e-02,  1.1883e-01,  1.4289e-01,  8.7126e-02,\n         -1.5064e-01, -1.5783e-01,  8.6839e-02, -6.6484e-02, -1.3787e-02,\n          1.0857e-01, -1.2722e-01,  7.9596e-02,  3.8681e-02,  3.9871e-05,\n          1.1476e-01,  5.9352e-02, -2.9442e-02,  1.3741e-01, -1.3608e-01,\n         -7.0429e-02, -1.7460e-01, -1.1231e-01,  9.2262e-02, -1.0396e-01,\n          6.5828e-02,  7.7264e-02],\n        [ 4.8495e-02,  8.6397e-03, -1.4324e-01, -5.3034e-02,  1.4076e-01,\n         -8.7040e-02,  1.7509e-01,  1.2220e-01, -9.7386e-02,  8.6906e-02,\n          7.5181e-03, -1.2347e-01,  6.7243e-02, -8.7050e-02,  1.6795e-01,\n         -7.3622e-02,  1.1795e-01,  1.2263e-01, -7.7885e-02,  1.2885e-01,\n          1.2225e-01, -1.5431e-02, -7.1185e-03,  4.3357e-02, -8.0196e-02,\n         -9.8158e-02,  1.3621e-01,  9.6491e-02, -1.4583e-01, -3.8539e-04,\n          3.9833e-02,  1.5903e-01],\n        [ 8.9924e-02, -7.7825e-02,  5.6075e-02,  7.2419e-02, -3.9011e-02,\n         -6.9996e-02, -1.5361e-01,  6.9288e-02,  6.5025e-02,  5.4839e-02,\n         -9.8961e-02, -2.2400e-02, -1.7395e-01, -7.2387e-02, -2.7358e-02,\n          7.7806e-02,  1.7398e-01,  3.3542e-02,  6.4885e-02, -1.6710e-01,\n          1.6217e-02, -9.1022e-02,  8.3477e-02, -1.8580e-02, -4.3486e-03,\n         -2.0257e-02,  9.9760e-02, -5.0598e-02, -1.2848e-01,  1.7584e-01,\n          5.6050e-02, -1.2614e-01],\n        [-1.3799e-01, -1.4259e-01,  7.9476e-02,  1.8208e-02,  9.5651e-02,\n          2.5617e-02, -1.5949e-01,  1.4969e-01,  6.2252e-02, -7.8867e-02,\n         -6.0514e-02,  1.1607e-03, -3.3710e-02, -4.7088e-02, -1.1452e-01,\n          1.6194e-01, -7.6572e-02,  4.3778e-02,  8.3579e-02, -1.7388e-01,\n          3.2148e-02, -1.0196e-01, -1.4528e-01, -1.0761e-01, -4.3520e-02,\n         -1.2144e-01, -3.8790e-02, -1.3902e-02, -5.9239e-02,  9.0877e-02,\n         -4.8785e-02, -6.3768e-02],\n        [-1.3475e-03,  5.4911e-02, -1.2269e-01, -1.3196e-02,  2.8030e-02,\n         -1.9293e-02,  1.1510e-01, -1.1619e-01, -4.2001e-02, -9.3543e-02,\n          8.3886e-02, -4.7891e-02,  2.5941e-02, -1.4716e-01, -4.4048e-03,\n          1.0082e-01, -1.6738e-01,  1.4971e-01,  1.1865e-01, -1.3165e-01,\n         -1.5832e-01, -1.0691e-01, -3.3351e-02, -3.5904e-03,  1.2046e-01,\n          1.6988e-01,  1.2868e-01,  9.7289e-02,  4.9581e-02,  1.7976e-02,\n         -7.7814e-02, -1.0169e-01],\n        [ 5.7100e-02,  2.6911e-02,  1.4727e-01, -1.6772e-01,  6.6060e-02,\n          8.2244e-02, -2.2551e-02, -1.5879e-01,  1.7272e-01, -1.4604e-01,\n          1.1849e-01,  1.4713e-01, -1.7516e-01,  5.7498e-02,  1.3914e-01,\n         -1.1982e-01,  1.0901e-02,  7.0098e-02, -1.7787e-02, -6.5303e-02,\n          3.7005e-02, -9.4432e-02, -7.9931e-02, -1.8560e-02,  7.7241e-02,\n         -5.3936e-03,  4.3197e-02, -1.1553e-01, -5.7723e-02,  6.0105e-02,\n         -1.3380e-01, -1.2440e-01],\n        [ 5.6370e-02, -1.1903e-01,  1.0797e-01,  2.1158e-02, -5.5800e-02,\n         -1.0309e-01, -6.8360e-02, -5.9837e-02, -1.6056e-01,  1.5022e-01,\n          1.6010e-01,  4.1223e-02,  1.3126e-02, -5.7184e-02,  1.7135e-01,\n          9.0582e-02,  1.3297e-01,  6.9352e-02,  2.8435e-02,  1.0681e-01,\n          7.9458e-02,  5.2727e-02, -3.1185e-02, -1.2831e-01,  9.2504e-02,\n         -1.1822e-01,  1.7481e-01, -9.0421e-02, -2.6624e-02, -1.4509e-01,\n         -5.0600e-02, -2.9849e-02],\n        [-5.1351e-02, -1.2823e-01,  5.4316e-02,  1.1155e-01, -7.5462e-02,\n         -5.9463e-02, -3.1388e-02,  1.1678e-01, -1.1900e-01, -1.0571e-01,\n          1.0247e-02,  1.0262e-01,  8.1302e-02,  3.3627e-02,  9.8298e-02,\n         -1.2807e-01, -1.0410e-02,  1.5567e-02, -1.0441e-01, -6.2700e-02,\n          1.2542e-01, -5.3210e-02,  1.3202e-01, -9.7232e-02,  6.0913e-02,\n          1.1769e-01, -1.2104e-01, -8.6566e-02, -8.7451e-02,  6.4022e-02,\n         -5.3551e-02,  1.6822e-01],\n        [-6.5695e-02, -4.3233e-02, -1.0780e-01,  3.8305e-02, -7.6646e-02,\n         -8.4903e-03, -2.7655e-02,  1.1920e-01, -8.8538e-02, -6.2690e-02,\n          1.4579e-02, -7.1238e-02, -1.6511e-01,  8.2407e-02,  1.7218e-01,\n         -1.3617e-01, -9.6654e-02, -1.2419e-02,  1.5051e-02,  3.8661e-02,\n         -4.3613e-02,  1.3161e-01, -1.4998e-01,  7.5045e-03, -8.4728e-02,\n          3.6361e-02, -1.3780e-01, -8.1326e-02,  4.3170e-02,  1.0763e-01,\n          1.0511e-01, -1.7454e-01],\n        [-1.3183e-01,  1.7361e-01, -1.7762e-02,  1.5168e-01,  1.2481e-01,\n          6.5820e-02,  5.3320e-03,  2.6218e-02,  1.6126e-01,  7.4919e-02,\n          6.3050e-02,  8.3850e-02, -1.5070e-01, -9.2561e-02,  8.2255e-02,\n         -1.7336e-01, -6.1968e-02, -5.9864e-02, -1.7093e-01,  1.8487e-02,\n         -1.6714e-01, -2.4823e-02, -1.0925e-01, -1.5875e-01, -1.0669e-01,\n          7.4955e-02, -5.9704e-02, -1.6219e-01, -1.7158e-01,  6.8341e-03,\n         -1.7329e-01,  9.0561e-02],\n        [ 3.6964e-03,  3.1634e-02, -8.1368e-02,  1.4000e-01, -1.7113e-01,\n          7.2839e-02, -6.0243e-03,  4.2445e-02,  1.6389e-01,  1.5788e-01,\n         -3.6595e-02, -1.5842e-01, -1.5370e-01,  1.7229e-01, -5.0268e-02,\n         -5.0184e-02,  1.3088e-01, -1.9642e-02, -1.6048e-01, -9.3962e-02,\n         -1.1600e-01,  1.0201e-01, -7.8637e-02,  3.7107e-02,  5.1018e-02,\n         -1.6905e-01,  1.1105e-01, -2.4979e-03,  6.6760e-02,  1.2263e-01,\n         -2.9110e-02,  1.7333e-01],\n        [-4.9462e-03,  2.2293e-02,  1.0248e-01, -1.9926e-02,  2.9732e-04,\n         -1.6249e-01, -1.6913e-01,  1.7049e-01,  1.1934e-01, -7.6997e-02,\n         -4.6682e-02, -1.5447e-01, -1.7129e-01,  1.4570e-02,  2.6882e-02,\n          1.3857e-01,  6.2906e-02, -1.2500e-01,  4.1565e-03,  1.0253e-01,\n         -1.2915e-02, -4.7212e-02,  1.0965e-01, -5.3510e-02,  1.0549e-02,\n         -6.0238e-02, -5.1052e-02,  1.1115e-01,  1.6403e-01,  8.1036e-02,\n          1.6678e-01,  3.5885e-02],\n        [-1.1363e-01,  4.1001e-02,  1.3017e-01, -2.1425e-02,  6.9504e-02,\n         -1.3044e-01, -1.4676e-01, -2.1103e-04, -7.1782e-02, -4.7176e-02,\n          3.9760e-02, -1.2393e-01,  1.1026e-01,  9.4690e-02,  2.5542e-03,\n          1.4949e-01,  5.5323e-02, -1.0966e-02,  5.3529e-02,  1.2067e-01,\n          9.8564e-02,  1.7090e-01,  1.4810e-01, -7.6046e-02, -1.6156e-01,\n         -1.7033e-01, -1.4121e-02, -1.6900e-01, -7.8944e-02,  1.0485e-01,\n         -7.8541e-02,  8.8775e-03],\n        [-1.1814e-01, -7.8885e-02, -1.5593e-01,  1.1883e-01, -7.9675e-02,\n          1.3393e-01, -1.2971e-02, -1.5099e-01, -1.4197e-01, -1.4052e-01,\n          9.4413e-02,  6.1668e-02,  1.1704e-02, -1.7007e-01,  6.9391e-02,\n          1.6561e-01,  1.2337e-01,  1.6515e-01, -1.4946e-01, -1.6484e-03,\n         -1.3683e-01,  4.6479e-02,  1.4007e-01,  8.6214e-02,  7.3214e-02,\n          6.9589e-02, -2.4173e-02,  7.1100e-02, -1.7264e-02,  4.7920e-02,\n         -5.5484e-02, -8.4744e-02],\n        [-8.2258e-02, -8.8936e-02, -6.7594e-02, -3.5126e-02,  1.6927e-01,\n         -3.1457e-02,  8.3488e-02,  6.1867e-02,  7.8313e-02, -1.5089e-01,\n          1.4288e-01,  4.6655e-02,  2.6813e-02, -3.8711e-02,  1.5978e-01,\n         -3.5790e-02, -3.9061e-02,  1.2637e-01, -1.5113e-01,  2.7121e-02,\n         -1.5190e-01, -4.7226e-02, -3.8236e-04,  1.4679e-01, -1.3960e-01,\n         -1.3973e-01, -8.6619e-02, -1.1731e-02,  1.4037e-01,  6.8327e-02,\n          1.3361e-01,  1.1584e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0212, -0.0980,  0.0691,  0.0672, -0.1152, -0.1603, -0.0191,  0.0205,\n        -0.0607,  0.1299,  0.1762, -0.1516,  0.1130, -0.0955,  0.0842, -0.0388],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0181, -0.1871, -0.0556, -0.1813,  0.0351, -0.2031,  0.2102,  0.0936,\n         -0.2117, -0.1225,  0.1575,  0.1988,  0.0585, -0.1286,  0.2194,  0.0853],\n        [-0.0577, -0.0201, -0.1677, -0.1815, -0.0660, -0.0372,  0.1289,  0.2427,\n          0.0643,  0.0799, -0.2498, -0.2311,  0.1950,  0.1547, -0.2112, -0.2191],\n        [ 0.1878,  0.1283,  0.2354, -0.0546,  0.0113, -0.1711, -0.2264, -0.1314,\n         -0.0736,  0.0430, -0.1008, -0.2431, -0.1821, -0.1979,  0.1826,  0.1391],\n        [-0.0655,  0.2212,  0.0704, -0.1896,  0.1002, -0.1451,  0.1174,  0.2294,\n          0.0321,  0.2178, -0.0974, -0.0526,  0.0592,  0.0724,  0.2406, -0.0452],\n        [-0.0034, -0.0045,  0.1524, -0.1558,  0.0548, -0.0426,  0.1758, -0.0997,\n          0.2003,  0.0577, -0.2492,  0.1515, -0.2009, -0.1197, -0.0648,  0.2194],\n        [-0.1519,  0.1201, -0.0824, -0.1488,  0.1481, -0.1749,  0.0375, -0.0320,\n         -0.2264,  0.0153, -0.0923,  0.1754, -0.1057,  0.1551, -0.1192, -0.1481],\n        [-0.1534,  0.1246, -0.1052,  0.1279, -0.1142, -0.0984, -0.0519,  0.1585,\n         -0.1450, -0.1296, -0.1332,  0.0889,  0.1961, -0.1711, -0.2394, -0.0290],\n        [ 0.1426, -0.0770, -0.1656,  0.0661,  0.0619, -0.2132,  0.1969, -0.0086,\n          0.2055,  0.1950,  0.2236,  0.0253,  0.1928, -0.1503, -0.1735, -0.2451]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2466,  0.1567,  0.1104,  0.1657, -0.1378, -0.1497,  0.1232,  0.0951],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0886,  0.3061,  0.2504, -0.2650, -0.2593,  0.0941,  0.0479, -0.0719],\n        [-0.0015,  0.1291,  0.2508,  0.2573, -0.3035,  0.1625,  0.2690,  0.3137],\n        [ 0.3477,  0.2170,  0.0650,  0.0852, -0.0020, -0.0467,  0.3352,  0.2019],\n        [-0.1249, -0.2637, -0.0966, -0.1039,  0.1513,  0.1311,  0.1404, -0.0185]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0888, -0.2454,  0.1532, -0.2151], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x71c1bc722050>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x71c2365c1e50>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0006,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2841,  0.2864,  0.2084,  0.1660,  0.2307, -0.0157,  0.3173,  0.1989,\n        -0.1347, -0.0458, -0.1275,  0.0523, -0.2407, -0.0304,  0.3313, -0.3218,\n         0.0327, -0.1641, -0.1481,  0.0004, -0.2366,  0.0611,  0.3424,  0.0739,\n         0.2411, -0.2542, -0.3030,  0.2645, -0.1141, -0.3082, -0.0431,  0.0903],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3362,  0.0213, -0.1705, -0.2650,  0.3284, -0.2424, -0.2713, -0.0876],\n        [-0.1345,  0.3024, -0.2725, -0.0839,  0.0135, -0.2701, -0.0802, -0.1604],\n        [-0.2933, -0.2562, -0.1602,  0.1077, -0.2461, -0.2212,  0.1050, -0.0817],\n        [ 0.1538,  0.1663,  0.3347,  0.2674,  0.1091, -0.2815, -0.1147,  0.2761],\n        [-0.1011,  0.0021, -0.2857,  0.2147, -0.3087, -0.0039,  0.1533,  0.1879],\n        [ 0.1398,  0.3116,  0.2069, -0.0757, -0.0940, -0.2558, -0.3087, -0.2730],\n        [-0.0075, -0.0309,  0.0233, -0.0806,  0.0326, -0.3463, -0.0083, -0.2378],\n        [-0.0681,  0.1207, -0.2915,  0.1988,  0.2511, -0.2873,  0.2727, -0.1529],\n        [-0.2691,  0.3156,  0.1814, -0.1105, -0.1091, -0.0795, -0.2617, -0.0676],\n        [ 0.0487,  0.1703, -0.2576, -0.2990, -0.2557, -0.1491, -0.1459,  0.3362],\n        [ 0.2410, -0.2933, -0.2333, -0.2045,  0.0829,  0.2220,  0.0083, -0.0245],\n        [ 0.1244,  0.0732, -0.0944,  0.3143, -0.2836,  0.1530,  0.0302, -0.2191],\n        [ 0.1477,  0.1605,  0.1486, -0.0978, -0.0102,  0.3229, -0.0760,  0.0097],\n        [ 0.2275, -0.2333,  0.2514, -0.1112,  0.3487, -0.0408, -0.1744, -0.0579],\n        [ 0.1505, -0.2614,  0.1934,  0.1191,  0.0572,  0.2031, -0.3427, -0.2886],\n        [-0.2720,  0.0459, -0.2780,  0.2830, -0.0560,  0.0406, -0.2717, -0.2350],\n        [ 0.0634, -0.0425, -0.1906,  0.2742,  0.3219,  0.3006, -0.3188,  0.2000],\n        [-0.1346,  0.2748, -0.0708,  0.0997,  0.0057, -0.1793,  0.2132,  0.0579],\n        [ 0.0168, -0.2055,  0.3120,  0.1986, -0.0798, -0.1807, -0.2088,  0.2479],\n        [ 0.2433,  0.2090, -0.2864,  0.0727,  0.1716,  0.2137, -0.0213,  0.2578],\n        [ 0.1406,  0.1596,  0.0333, -0.1946, -0.3274, -0.3289,  0.3337, -0.2813],\n        [ 0.1589, -0.1028, -0.1107,  0.2033, -0.1034,  0.1333,  0.2960, -0.2452],\n        [-0.0025, -0.1727, -0.1165, -0.1966,  0.3034,  0.2599, -0.1062, -0.1195],\n        [-0.1626,  0.3043,  0.3335,  0.3428, -0.2516,  0.2957,  0.0834, -0.2111],\n        [ 0.2874,  0.3079,  0.2515,  0.2780, -0.1812, -0.0832,  0.1450,  0.0626],\n        [-0.3277, -0.1747,  0.2743,  0.0074, -0.0495,  0.0583, -0.2847,  0.0519],\n        [ 0.0256,  0.2860, -0.2448,  0.2289, -0.2901,  0.3164, -0.1033, -0.0351],\n        [ 0.0792, -0.2323, -0.0195, -0.0907, -0.2744,  0.2114,  0.0314,  0.3093],\n        [-0.1868, -0.0627,  0.2472, -0.0072, -0.1178, -0.1545,  0.2726,  0.2158],\n        [ 0.0968,  0.2551,  0.1526,  0.3508, -0.3134,  0.1289, -0.2105,  0.2554],\n        [ 0.3221,  0.1619, -0.0874, -0.3446, -0.2845, -0.1014,  0.1986, -0.3505],\n        [ 0.3117, -0.1953, -0.0033, -0.1022,  0.0436, -0.0925, -0.2843,  0.1348]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0212, -0.0980,  0.0691,  0.0672, -0.1152, -0.1603, -0.0191,  0.0205,\n        -0.0607,  0.1299,  0.1762, -0.1516,  0.1130, -0.0955,  0.0842, -0.0388],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 4.3484e-02, -1.5718e-01, -1.1366e-01,  8.6112e-02,  9.0850e-03,\n          1.3293e-01, -1.1126e-01,  1.2447e-01, -6.8356e-02, -1.5392e-01,\n          1.4166e-02, -1.0945e-01,  1.4868e-01, -8.3206e-02, -5.6498e-03,\n         -4.1910e-02,  9.6337e-02,  1.4934e-01,  2.8263e-02, -1.5537e-01,\n         -1.5991e-02,  8.3385e-03,  6.4664e-03, -1.0772e-02, -5.4276e-02,\n         -1.6665e-01,  2.3119e-02, -2.1880e-02,  1.4406e-01, -4.8776e-02,\n          1.6018e-01, -7.7487e-02],\n        [ 3.7671e-02,  9.4955e-02,  1.2056e-01,  1.7767e-02,  1.6019e-01,\n          1.6354e-01, -4.2362e-02,  1.1883e-01,  1.4289e-01,  8.7126e-02,\n         -1.5064e-01, -1.5783e-01,  8.6839e-02, -6.6484e-02, -1.3787e-02,\n          1.0857e-01, -1.2722e-01,  7.9596e-02,  3.8681e-02,  3.9871e-05,\n          1.1476e-01,  5.9352e-02, -2.9442e-02,  1.3741e-01, -1.3608e-01,\n         -7.0429e-02, -1.7460e-01, -1.1231e-01,  9.2262e-02, -1.0396e-01,\n          6.5828e-02,  7.7264e-02],\n        [ 4.8495e-02,  8.6397e-03, -1.4324e-01, -5.3034e-02,  1.4076e-01,\n         -8.7040e-02,  1.7509e-01,  1.2220e-01, -9.7386e-02,  8.6906e-02,\n          7.5181e-03, -1.2347e-01,  6.7243e-02, -8.7050e-02,  1.6795e-01,\n         -7.3622e-02,  1.1795e-01,  1.2263e-01, -7.7885e-02,  1.2885e-01,\n          1.2225e-01, -1.5431e-02, -7.1185e-03,  4.3357e-02, -8.0196e-02,\n         -9.8158e-02,  1.3621e-01,  9.6491e-02, -1.4583e-01, -3.8539e-04,\n          3.9833e-02,  1.5903e-01],\n        [ 8.9924e-02, -7.7825e-02,  5.6075e-02,  7.2419e-02, -3.9011e-02,\n         -6.9996e-02, -1.5361e-01,  6.9288e-02,  6.5025e-02,  5.4839e-02,\n         -9.8961e-02, -2.2400e-02, -1.7395e-01, -7.2387e-02, -2.7358e-02,\n          7.7806e-02,  1.7398e-01,  3.3542e-02,  6.4885e-02, -1.6710e-01,\n          1.6217e-02, -9.1022e-02,  8.3477e-02, -1.8580e-02, -4.3486e-03,\n         -2.0257e-02,  9.9760e-02, -5.0598e-02, -1.2848e-01,  1.7584e-01,\n          5.6050e-02, -1.2614e-01],\n        [-1.3799e-01, -1.4259e-01,  7.9476e-02,  1.8208e-02,  9.5651e-02,\n          2.5617e-02, -1.5949e-01,  1.4969e-01,  6.2252e-02, -7.8867e-02,\n         -6.0514e-02,  1.1607e-03, -3.3710e-02, -4.7088e-02, -1.1452e-01,\n          1.6194e-01, -7.6572e-02,  4.3778e-02,  8.3579e-02, -1.7388e-01,\n          3.2148e-02, -1.0196e-01, -1.4528e-01, -1.0761e-01, -4.3520e-02,\n         -1.2144e-01, -3.8790e-02, -1.3902e-02, -5.9239e-02,  9.0877e-02,\n         -4.8785e-02, -6.3768e-02],\n        [-1.3475e-03,  5.4911e-02, -1.2269e-01, -1.3196e-02,  2.8030e-02,\n         -1.9293e-02,  1.1510e-01, -1.1619e-01, -4.2001e-02, -9.3543e-02,\n          8.3886e-02, -4.7891e-02,  2.5941e-02, -1.4716e-01, -4.4048e-03,\n          1.0082e-01, -1.6738e-01,  1.4971e-01,  1.1865e-01, -1.3165e-01,\n         -1.5832e-01, -1.0691e-01, -3.3351e-02, -3.5904e-03,  1.2046e-01,\n          1.6988e-01,  1.2868e-01,  9.7289e-02,  4.9581e-02,  1.7976e-02,\n         -7.7814e-02, -1.0169e-01],\n        [ 5.7100e-02,  2.6911e-02,  1.4727e-01, -1.6772e-01,  6.6060e-02,\n          8.2244e-02, -2.2551e-02, -1.5879e-01,  1.7272e-01, -1.4604e-01,\n          1.1849e-01,  1.4713e-01, -1.7516e-01,  5.7498e-02,  1.3914e-01,\n         -1.1982e-01,  1.0901e-02,  7.0098e-02, -1.7787e-02, -6.5303e-02,\n          3.7005e-02, -9.4432e-02, -7.9931e-02, -1.8560e-02,  7.7241e-02,\n         -5.3936e-03,  4.3197e-02, -1.1553e-01, -5.7723e-02,  6.0105e-02,\n         -1.3380e-01, -1.2440e-01],\n        [ 5.6370e-02, -1.1903e-01,  1.0797e-01,  2.1158e-02, -5.5800e-02,\n         -1.0309e-01, -6.8360e-02, -5.9837e-02, -1.6056e-01,  1.5022e-01,\n          1.6010e-01,  4.1223e-02,  1.3126e-02, -5.7184e-02,  1.7135e-01,\n          9.0582e-02,  1.3297e-01,  6.9352e-02,  2.8435e-02,  1.0681e-01,\n          7.9458e-02,  5.2727e-02, -3.1185e-02, -1.2831e-01,  9.2504e-02,\n         -1.1822e-01,  1.7481e-01, -9.0421e-02, -2.6624e-02, -1.4509e-01,\n         -5.0600e-02, -2.9849e-02],\n        [-5.1351e-02, -1.2823e-01,  5.4316e-02,  1.1155e-01, -7.5462e-02,\n         -5.9463e-02, -3.1388e-02,  1.1678e-01, -1.1900e-01, -1.0571e-01,\n          1.0247e-02,  1.0262e-01,  8.1302e-02,  3.3627e-02,  9.8298e-02,\n         -1.2807e-01, -1.0410e-02,  1.5567e-02, -1.0441e-01, -6.2700e-02,\n          1.2542e-01, -5.3210e-02,  1.3202e-01, -9.7232e-02,  6.0913e-02,\n          1.1769e-01, -1.2104e-01, -8.6566e-02, -8.7451e-02,  6.4022e-02,\n         -5.3551e-02,  1.6822e-01],\n        [-6.5695e-02, -4.3233e-02, -1.0780e-01,  3.8305e-02, -7.6646e-02,\n         -8.4903e-03, -2.7655e-02,  1.1920e-01, -8.8538e-02, -6.2690e-02,\n          1.4579e-02, -7.1238e-02, -1.6511e-01,  8.2407e-02,  1.7218e-01,\n         -1.3617e-01, -9.6654e-02, -1.2419e-02,  1.5051e-02,  3.8661e-02,\n         -4.3613e-02,  1.3161e-01, -1.4998e-01,  7.5045e-03, -8.4728e-02,\n          3.6361e-02, -1.3780e-01, -8.1326e-02,  4.3170e-02,  1.0763e-01,\n          1.0511e-01, -1.7454e-01],\n        [-1.3183e-01,  1.7361e-01, -1.7762e-02,  1.5168e-01,  1.2481e-01,\n          6.5820e-02,  5.3320e-03,  2.6218e-02,  1.6126e-01,  7.4919e-02,\n          6.3050e-02,  8.3850e-02, -1.5070e-01, -9.2561e-02,  8.2255e-02,\n         -1.7336e-01, -6.1968e-02, -5.9864e-02, -1.7093e-01,  1.8487e-02,\n         -1.6714e-01, -2.4823e-02, -1.0925e-01, -1.5875e-01, -1.0669e-01,\n          7.4955e-02, -5.9704e-02, -1.6219e-01, -1.7158e-01,  6.8341e-03,\n         -1.7329e-01,  9.0561e-02],\n        [ 3.6964e-03,  3.1634e-02, -8.1368e-02,  1.4000e-01, -1.7113e-01,\n          7.2839e-02, -6.0243e-03,  4.2445e-02,  1.6389e-01,  1.5788e-01,\n         -3.6595e-02, -1.5842e-01, -1.5370e-01,  1.7229e-01, -5.0268e-02,\n         -5.0184e-02,  1.3088e-01, -1.9642e-02, -1.6048e-01, -9.3962e-02,\n         -1.1600e-01,  1.0201e-01, -7.8637e-02,  3.7107e-02,  5.1018e-02,\n         -1.6905e-01,  1.1105e-01, -2.4979e-03,  6.6760e-02,  1.2263e-01,\n         -2.9110e-02,  1.7333e-01],\n        [-4.9462e-03,  2.2293e-02,  1.0248e-01, -1.9926e-02,  2.9732e-04,\n         -1.6249e-01, -1.6913e-01,  1.7049e-01,  1.1934e-01, -7.6997e-02,\n         -4.6682e-02, -1.5447e-01, -1.7129e-01,  1.4570e-02,  2.6882e-02,\n          1.3857e-01,  6.2906e-02, -1.2500e-01,  4.1565e-03,  1.0253e-01,\n         -1.2915e-02, -4.7212e-02,  1.0965e-01, -5.3510e-02,  1.0549e-02,\n         -6.0238e-02, -5.1052e-02,  1.1115e-01,  1.6403e-01,  8.1036e-02,\n          1.6678e-01,  3.5885e-02],\n        [-1.1363e-01,  4.1001e-02,  1.3017e-01, -2.1425e-02,  6.9504e-02,\n         -1.3044e-01, -1.4676e-01, -2.1103e-04, -7.1782e-02, -4.7176e-02,\n          3.9760e-02, -1.2393e-01,  1.1026e-01,  9.4690e-02,  2.5542e-03,\n          1.4949e-01,  5.5323e-02, -1.0966e-02,  5.3529e-02,  1.2067e-01,\n          9.8564e-02,  1.7090e-01,  1.4810e-01, -7.6046e-02, -1.6156e-01,\n         -1.7033e-01, -1.4121e-02, -1.6900e-01, -7.8944e-02,  1.0485e-01,\n         -7.8541e-02,  8.8775e-03],\n        [-1.1814e-01, -7.8885e-02, -1.5593e-01,  1.1883e-01, -7.9675e-02,\n          1.3393e-01, -1.2971e-02, -1.5099e-01, -1.4197e-01, -1.4052e-01,\n          9.4413e-02,  6.1668e-02,  1.1704e-02, -1.7007e-01,  6.9391e-02,\n          1.6561e-01,  1.2337e-01,  1.6515e-01, -1.4946e-01, -1.6484e-03,\n         -1.3683e-01,  4.6479e-02,  1.4007e-01,  8.6214e-02,  7.3214e-02,\n          6.9589e-02, -2.4173e-02,  7.1100e-02, -1.7264e-02,  4.7920e-02,\n         -5.5484e-02, -8.4744e-02],\n        [-8.2258e-02, -8.8936e-02, -6.7594e-02, -3.5126e-02,  1.6927e-01,\n         -3.1457e-02,  8.3488e-02,  6.1867e-02,  7.8313e-02, -1.5089e-01,\n          1.4288e-01,  4.6655e-02,  2.6813e-02, -3.8711e-02,  1.5978e-01,\n         -3.5790e-02, -3.9061e-02,  1.2637e-01, -1.5113e-01,  2.7121e-02,\n         -1.5190e-01, -4.7226e-02, -3.8236e-04,  1.4679e-01, -1.3960e-01,\n         -1.3973e-01, -8.6619e-02, -1.1731e-02,  1.4037e-01,  6.8327e-02,\n          1.3361e-01,  1.1584e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2466,  0.1567,  0.1104,  0.1657, -0.1378, -0.1497,  0.1232,  0.0951],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0181, -0.1871, -0.0556, -0.1813,  0.0351, -0.2031,  0.2102,  0.0936,\n         -0.2117, -0.1225,  0.1575,  0.1988,  0.0585, -0.1286,  0.2194,  0.0853],\n        [-0.0577, -0.0201, -0.1677, -0.1815, -0.0660, -0.0372,  0.1289,  0.2427,\n          0.0643,  0.0799, -0.2498, -0.2311,  0.1950,  0.1547, -0.2112, -0.2191],\n        [ 0.1878,  0.1283,  0.2354, -0.0546,  0.0113, -0.1711, -0.2264, -0.1314,\n         -0.0736,  0.0430, -0.1008, -0.2431, -0.1821, -0.1979,  0.1826,  0.1391],\n        [-0.0655,  0.2212,  0.0704, -0.1896,  0.1002, -0.1451,  0.1174,  0.2294,\n          0.0321,  0.2178, -0.0974, -0.0526,  0.0592,  0.0724,  0.2406, -0.0452],\n        [-0.0034, -0.0045,  0.1524, -0.1558,  0.0548, -0.0426,  0.1758, -0.0997,\n          0.2003,  0.0577, -0.2492,  0.1515, -0.2009, -0.1197, -0.0648,  0.2194],\n        [-0.1519,  0.1201, -0.0824, -0.1488,  0.1481, -0.1749,  0.0375, -0.0320,\n         -0.2264,  0.0153, -0.0923,  0.1754, -0.1057,  0.1551, -0.1192, -0.1481],\n        [-0.1534,  0.1246, -0.1052,  0.1279, -0.1142, -0.0984, -0.0519,  0.1585,\n         -0.1450, -0.1296, -0.1332,  0.0889,  0.1961, -0.1711, -0.2394, -0.0290],\n        [ 0.1426, -0.0770, -0.1656,  0.0661,  0.0619, -0.2132,  0.1969, -0.0086,\n          0.2055,  0.1950,  0.2236,  0.0253,  0.1928, -0.1503, -0.1735, -0.2451]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0888, -0.2454,  0.1532, -0.2151], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0886,  0.3061,  0.2504, -0.2650, -0.2593,  0.0941,  0.0479, -0.0719],\n        [-0.0015,  0.1291,  0.2508,  0.2573, -0.3035,  0.1625,  0.2690,  0.3137],\n        [ 0.3477,  0.2170,  0.0650,  0.0852, -0.0020, -0.0467,  0.3352,  0.2019],\n        [-0.1249, -0.2637, -0.0966, -0.1039,  0.1513,  0.1311,  0.1404, -0.0185]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	32,
            "_traj_per_epoch":	16,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x71c1bb5c4b10>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1119700000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1119700000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	32,
    "traj_per_epoch":	16
}