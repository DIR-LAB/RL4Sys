{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	0,
    "batch_size":	128,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0006,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1123970000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0005,
    "sample_decay":	0.5,
    "seed":	1123970000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7ae22983c790>":	{
            "_act_dim":	4,
            "_aux_batch_size":	0,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0006,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0006,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0676, -0.3486, -0.0593,  0.0970,  0.0820,  0.2375,  0.1316,  0.2348,\n         0.3331,  0.0713, -0.2736, -0.0394,  0.3266, -0.3039, -0.3499, -0.3399,\n        -0.1501, -0.1035,  0.3235,  0.3103,  0.1581,  0.3211, -0.3040,  0.0641,\n         0.0402, -0.0964, -0.0957,  0.2780,  0.1238,  0.2524,  0.1566, -0.1715],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0028,  0.3049,  0.1754, -0.1305,  0.2429, -0.3430,  0.2806, -0.1237],\n        [-0.3201,  0.1226,  0.3467,  0.0211, -0.2755,  0.0212,  0.1279,  0.1235],\n        [ 0.2188,  0.1496, -0.1794,  0.0707, -0.1077,  0.1245, -0.1024, -0.2490],\n        [ 0.0248,  0.0299, -0.2000,  0.1199,  0.0766,  0.3255,  0.1184, -0.2435],\n        [ 0.3224,  0.3109, -0.1000, -0.0686,  0.0337, -0.2501,  0.0247,  0.0139],\n        [-0.3417,  0.0362, -0.3024, -0.2771,  0.1334,  0.3241, -0.2784, -0.1094],\n        [-0.3408,  0.0149,  0.0800,  0.0371, -0.1439,  0.0365,  0.0869,  0.0445],\n        [ 0.2857,  0.0097, -0.1435, -0.2868, -0.3381,  0.0028, -0.0775, -0.0808],\n        [-0.2944,  0.1573, -0.3318,  0.2562, -0.0437,  0.2321,  0.1147,  0.0714],\n        [ 0.1132, -0.2423, -0.1800, -0.2154,  0.1425, -0.1574, -0.1059, -0.2251],\n        [ 0.0949, -0.1268, -0.2304,  0.0148, -0.3383, -0.2857, -0.0559, -0.3288],\n        [ 0.2008, -0.1353, -0.1732,  0.0058, -0.3152, -0.3162, -0.1347,  0.1679],\n        [-0.0398, -0.2569,  0.0177,  0.1483, -0.0432, -0.0607, -0.1286, -0.0239],\n        [-0.3326, -0.2455,  0.2768, -0.3081, -0.3025,  0.2705, -0.0066, -0.0855],\n        [ 0.3473,  0.0499,  0.2179,  0.2482, -0.0367, -0.1200,  0.0484,  0.0737],\n        [-0.1884, -0.1792, -0.2991,  0.0020, -0.1895,  0.2297,  0.2100,  0.0803],\n        [-0.1420, -0.3010,  0.1839, -0.0777, -0.3269, -0.1921, -0.3018,  0.0091],\n        [ 0.0023,  0.2955, -0.1986, -0.2620, -0.0237,  0.2307,  0.1506, -0.3469],\n        [ 0.2409, -0.1181, -0.0096, -0.1276,  0.2068,  0.1792, -0.0468,  0.3499],\n        [-0.2929, -0.1544, -0.1553, -0.1716,  0.0971, -0.2317, -0.0512,  0.3072],\n        [-0.1638, -0.1809,  0.2203,  0.3388, -0.0418,  0.2648, -0.0639, -0.1487],\n        [ 0.1330,  0.1193, -0.0561,  0.1431,  0.2064, -0.2783, -0.2352, -0.0064],\n        [ 0.0549, -0.3437, -0.2321,  0.1291,  0.0927,  0.1595,  0.1879, -0.2511],\n        [ 0.2148,  0.2350, -0.1029,  0.0615, -0.2124, -0.0257,  0.1272,  0.2813],\n        [-0.1996, -0.3521,  0.3040,  0.1850, -0.0310, -0.0393,  0.0295, -0.2656],\n        [-0.2207,  0.2388,  0.1511,  0.2066, -0.2996, -0.0789, -0.0563, -0.0657],\n        [ 0.1718, -0.2676,  0.2000,  0.1461,  0.0338,  0.1235,  0.0890, -0.2293],\n        [-0.2380, -0.2235, -0.2995,  0.2448, -0.2062,  0.1286,  0.0161,  0.0151],\n        [-0.1817, -0.1082, -0.1983,  0.1801,  0.1759, -0.2242, -0.2976,  0.2631],\n        [-0.1000, -0.3369,  0.3366, -0.1914,  0.1922, -0.2306, -0.1259, -0.2700],\n        [ 0.1481, -0.1677,  0.2253, -0.3464, -0.1454, -0.0517,  0.1746,  0.3473],\n        [ 0.0618, -0.2731, -0.0794, -0.3080,  0.2786,  0.3413,  0.2405,  0.3191]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0480, -0.0595,  0.0184,  0.0702,  0.0221,  0.0694, -0.0335,  0.1570,\n        -0.0089,  0.1540, -0.0715, -0.1758,  0.1095, -0.1526,  0.0395, -0.1194],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 3.8560e-02,  1.6886e-01, -2.6417e-02,  4.4944e-02,  6.6199e-02,\n          1.3509e-01, -8.4777e-02, -4.9686e-02,  8.7770e-02, -3.0531e-02,\n         -2.9215e-02, -1.7347e-01, -5.4777e-03, -4.8045e-02, -1.1834e-01,\n          1.1452e-02,  4.3568e-02,  1.6904e-01, -3.4750e-02, -3.4548e-02,\n         -8.7290e-02, -1.3755e-01,  9.6568e-02,  1.6486e-01, -3.8485e-02,\n         -5.7266e-02, -1.0285e-02, -1.0619e-01,  1.5157e-01,  5.3509e-02,\n         -6.4158e-02, -1.7495e-01],\n        [-1.7239e-01, -1.4363e-01,  7.1167e-02, -2.1830e-02,  7.0936e-02,\n         -1.0356e-01,  5.4676e-02, -1.0931e-01, -5.4239e-02, -6.1898e-02,\n         -9.8469e-03, -1.3320e-01,  1.2572e-01, -7.2488e-02, -8.1135e-03,\n          1.5094e-01, -1.4006e-01,  6.1605e-02,  1.3446e-02, -2.3378e-02,\n         -1.5377e-01, -5.2284e-02,  1.6071e-01,  7.9021e-02,  1.3266e-01,\n          1.2579e-01,  1.3675e-01, -9.6382e-02, -1.6736e-01,  1.4071e-01,\n          1.7755e-02, -9.2966e-02],\n        [ 4.5999e-02, -1.0493e-01,  1.4009e-02,  7.7842e-02, -2.5680e-02,\n         -1.0349e-01,  1.4603e-01, -7.9011e-02,  1.0000e-02,  4.7037e-02,\n          1.6629e-01, -1.2717e-01,  3.0922e-02, -4.7802e-02,  2.5091e-02,\n         -2.4215e-02,  1.4411e-01, -2.0538e-02,  5.7125e-02,  1.0300e-01,\n         -1.9548e-02, -5.3772e-02, -1.5408e-01,  8.8283e-02,  7.0149e-02,\n          1.1437e-01, -1.1532e-01, -7.4347e-05, -1.1635e-01, -1.5287e-02,\n         -1.7133e-01, -1.4993e-01],\n        [-1.7283e-01,  1.0942e-01,  1.4573e-01,  1.1696e-01, -7.2628e-02,\n          6.0533e-02, -4.7350e-02, -9.2258e-02, -9.9983e-02, -1.5660e-01,\n          3.3743e-03, -3.9506e-02,  7.2261e-02,  8.9336e-02,  1.6486e-01,\n          9.5046e-03,  3.5726e-02,  1.7303e-01,  7.9982e-02, -1.0996e-02,\n          1.0954e-01,  7.5778e-02, -6.3695e-02,  3.7531e-02,  7.4075e-04,\n          4.2019e-02,  1.5463e-01,  6.8183e-02,  1.2657e-01,  1.6884e-01,\n         -1.5113e-01, -3.7085e-02],\n        [-9.4863e-02, -4.5834e-02,  1.2944e-01, -1.4290e-01,  1.4202e-01,\n         -6.5729e-02, -1.0742e-01,  1.2278e-01, -5.8510e-02,  1.2403e-01,\n         -6.2280e-02, -1.6400e-01,  1.6180e-01, -1.7175e-01, -1.8915e-02,\n          4.4848e-04, -2.6061e-02, -1.3638e-01, -2.7620e-02,  4.5398e-02,\n         -7.5280e-02,  1.1031e-01,  8.7592e-02, -1.2332e-01, -8.6134e-02,\n          1.3634e-01, -1.5945e-01,  5.5427e-02, -1.6071e-01, -3.8551e-02,\n          6.7864e-02,  1.4356e-01],\n        [ 1.2812e-02, -1.6209e-01, -1.3922e-01,  1.1064e-01, -3.1787e-02,\n         -1.5914e-01, -1.6367e-01,  1.2635e-01,  1.5610e-01, -2.5644e-02,\n          3.1773e-02, -1.0146e-01,  4.5458e-02,  1.4566e-01, -3.4089e-02,\n         -1.4977e-03,  1.3415e-01,  1.2514e-01,  6.0342e-02, -2.6775e-02,\n         -8.2333e-02, -6.8696e-02,  4.1717e-02,  1.5013e-01, -9.2227e-02,\n         -1.6716e-01, -1.1577e-01,  4.4705e-02,  1.1304e-03, -1.2924e-01,\n         -1.4824e-01,  1.3953e-01],\n        [-1.7778e-03,  4.3102e-02, -3.0246e-03,  1.0073e-01,  7.9334e-02,\n         -9.4552e-02, -2.5855e-02, -9.1130e-02, -3.0929e-02,  1.4645e-01,\n         -1.6955e-01,  1.4495e-01,  8.8188e-03, -1.5754e-01, -9.2913e-02,\n         -2.8811e-02,  2.4291e-02, -1.1889e-01,  5.8572e-03, -4.9254e-02,\n         -9.0067e-02,  1.1036e-01, -1.1055e-01,  9.6468e-02,  1.5618e-01,\n         -1.5277e-01,  1.5460e-01, -4.3520e-02,  9.4129e-02, -9.2358e-02,\n         -8.8435e-02,  1.1436e-01],\n        [-1.2667e-01,  6.3286e-02,  1.4347e-01, -1.5807e-01, -1.2048e-01,\n         -1.7014e-01, -8.5332e-02,  8.2262e-02, -9.3592e-02,  7.2343e-02,\n          1.4156e-02, -1.4258e-01, -2.8041e-02, -1.2479e-01,  9.7586e-02,\n         -1.3910e-01,  1.5340e-01, -6.1625e-02, -6.6108e-02, -1.6958e-01,\n         -1.7043e-01, -1.1399e-01, -1.1206e-01,  1.0681e-01,  5.0868e-02,\n         -2.5366e-02,  9.9558e-02, -1.2010e-01, -1.0948e-01,  2.9061e-03,\n         -1.3127e-01, -1.7435e-01],\n        [ 1.4674e-01,  1.4786e-01,  9.0350e-02,  1.4925e-01,  3.5108e-02,\n         -1.0295e-01, -8.5674e-02,  1.2196e-01, -1.1980e-01, -3.1259e-02,\n          3.2998e-02,  1.6960e-01,  4.3474e-02,  9.9108e-02,  8.2373e-03,\n          1.2902e-01,  1.5442e-01, -1.2999e-01,  1.0407e-01, -6.6253e-02,\n          1.6451e-01,  2.1861e-02,  1.3433e-01, -1.0912e-01, -1.7034e-01,\n         -1.6579e-01, -7.0632e-03,  1.1006e-01, -1.0055e-01,  1.3679e-02,\n         -1.6109e-02,  4.7247e-02],\n        [-1.4961e-01,  4.8407e-02, -4.5215e-02,  1.0599e-01, -1.0056e-01,\n         -5.4134e-03, -9.4831e-02, -1.0268e-02, -1.7373e-01, -1.0383e-01,\n         -1.0759e-01, -1.0116e-01, -6.8142e-02,  1.5800e-01,  7.3643e-02,\n          7.1266e-02, -9.3172e-02,  8.6899e-02, -5.1099e-03,  4.5079e-02,\n         -2.0861e-03, -1.4317e-01,  1.6544e-01, -1.6781e-01,  8.1342e-02,\n         -1.0145e-01, -6.6485e-02,  7.6975e-02,  8.9475e-02, -1.3302e-01,\n         -8.6679e-02, -7.9441e-02],\n        [ 1.7198e-01, -1.7422e-01,  6.8435e-02,  7.3964e-02, -1.3871e-01,\n          1.1193e-02, -1.3973e-01, -2.8123e-02,  9.0774e-02,  7.5066e-02,\n          4.9940e-02,  1.7407e-01, -2.1543e-02, -1.5057e-01, -1.3513e-01,\n         -6.9558e-02,  2.9476e-02,  3.1473e-02, -8.5807e-02,  1.7413e-01,\n          1.1194e-01, -6.0056e-02,  1.0768e-01, -6.2411e-03,  9.5795e-02,\n         -1.2329e-01,  4.6146e-02,  1.5470e-01, -8.1177e-02,  1.4061e-01,\n          9.6281e-02,  6.8617e-02],\n        [-4.5277e-02, -1.1503e-03,  1.6033e-01,  1.2251e-01, -1.5151e-01,\n          1.4210e-01,  1.5712e-01,  1.5621e-01,  1.3454e-01, -8.5813e-02,\n         -7.8311e-02,  6.5227e-02,  1.4808e-01,  1.4662e-01, -2.5732e-02,\n          5.1122e-02,  1.6336e-01, -1.0325e-01,  3.4171e-02, -8.1498e-02,\n         -9.9877e-02, -1.8129e-02, -8.0622e-02, -4.2798e-02,  9.4290e-02,\n         -1.4442e-01, -1.5546e-01, -4.4556e-02, -8.0001e-02,  6.8925e-02,\n         -8.0862e-02, -8.8472e-02],\n        [ 5.7391e-02,  9.1696e-02, -1.1168e-01, -1.6506e-02, -1.0313e-02,\n          1.3501e-01, -9.1856e-02,  9.5302e-02, -1.1173e-01, -1.1602e-01,\n          3.0617e-02, -2.5081e-02,  8.7514e-03, -1.0358e-01, -9.8330e-02,\n         -1.0578e-01, -6.6598e-02, -1.5051e-01,  1.4770e-03, -1.1783e-01,\n         -3.2370e-02,  8.9849e-02, -2.0097e-02, -1.1741e-01, -3.6483e-02,\n          1.3254e-01,  1.5942e-02, -1.2451e-01,  1.1896e-02,  1.1266e-01,\n          1.4422e-01,  4.2290e-02],\n        [-5.9696e-02, -5.6196e-02, -1.2780e-01,  2.3931e-02, -2.9082e-02,\n         -4.0119e-02,  1.6847e-01,  1.3768e-01,  9.3685e-02,  1.7677e-01,\n         -1.0912e-01, -1.0014e-01, -9.9776e-02,  2.9599e-02,  2.1532e-02,\n         -6.1607e-02,  1.0709e-01, -1.9388e-02,  1.2434e-01, -6.4603e-02,\n         -3.5737e-02, -1.0668e-01, -1.0415e-01, -1.1284e-01, -1.1393e-01,\n         -1.1864e-01,  1.1725e-02, -1.9748e-02, -9.9135e-02, -4.6959e-02,\n         -5.1646e-03,  1.5688e-01],\n        [-1.4976e-01, -1.6213e-01,  1.4516e-01, -1.1787e-01, -1.2454e-01,\n         -1.2391e-01, -1.4330e-01, -1.3198e-02, -1.0156e-01, -2.9143e-02,\n         -6.5653e-02,  9.3928e-02,  9.8146e-02,  1.6581e-01, -5.7999e-02,\n         -6.0059e-02, -1.7623e-01, -1.3848e-01,  9.5296e-02, -1.5287e-02,\n          7.0647e-02, -4.8085e-02,  1.4854e-01, -7.7054e-02,  1.0035e-01,\n          1.7085e-01, -5.0722e-02, -2.6204e-02,  1.2716e-01, -1.6741e-01,\n          6.1646e-02, -4.7788e-02],\n        [ 8.9780e-02, -1.0597e-01,  1.3031e-01, -4.8335e-02,  9.1085e-02,\n          9.3573e-02,  1.3197e-01, -9.6112e-02,  9.7533e-02, -1.2618e-01,\n          1.3034e-01, -7.1690e-02,  1.7016e-01, -2.8283e-03,  6.1544e-02,\n          4.4482e-02,  9.5811e-02, -6.9374e-02, -5.5283e-03, -1.0677e-01,\n          1.0418e-01,  1.6799e-01, -6.9946e-02,  2.3848e-02, -1.4239e-01,\n          4.4042e-02,  1.0928e-01, -3.8518e-02,  1.2072e-01, -1.3776e-01,\n         -1.3692e-01,  6.7633e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1821,  0.2223,  0.0634, -0.1041, -0.1706,  0.1387,  0.0825, -0.0604],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1042,  0.1351, -0.0436,  0.2439, -0.0580, -0.2187,  0.0595,  0.1316,\n          0.0100, -0.1807, -0.1055, -0.0944,  0.2415, -0.1435,  0.2145, -0.1810],\n        [-0.1157, -0.0745,  0.1234,  0.1644,  0.2016,  0.0904, -0.2456,  0.2409,\n          0.1312, -0.0843,  0.0539, -0.0702,  0.2106, -0.0133, -0.0806,  0.0575],\n        [-0.2009, -0.1750, -0.1833, -0.0764,  0.2136,  0.2292,  0.0821,  0.2386,\n          0.0338,  0.0961,  0.0031, -0.1980,  0.1556, -0.0247,  0.0241, -0.2088],\n        [-0.0221, -0.2387,  0.1750, -0.1811, -0.1323, -0.2045, -0.2365,  0.2187,\n         -0.2196,  0.2470, -0.2239,  0.2278, -0.2364,  0.1815,  0.0259, -0.1609],\n        [-0.0323, -0.0988, -0.0245,  0.1138,  0.1802,  0.1346, -0.2425,  0.2471,\n         -0.0675,  0.1067, -0.0360, -0.0220, -0.2143, -0.0438, -0.1031, -0.1945],\n        [ 0.0388,  0.2410, -0.0875, -0.1622,  0.1306,  0.0193, -0.1047,  0.2367,\n          0.1399, -0.0852,  0.1014,  0.2058,  0.1179, -0.0213,  0.1136,  0.0018],\n        [ 0.0274,  0.1878, -0.0176,  0.0860,  0.1900, -0.0581,  0.1252, -0.2286,\n          0.0136, -0.2342,  0.1803, -0.0249, -0.1907,  0.0130, -0.2050, -0.2103],\n        [-0.1897,  0.0237,  0.1118, -0.1667,  0.0004,  0.2366, -0.0813, -0.2138,\n          0.0229, -0.1066, -0.0656, -0.0321, -0.0346, -0.1806,  0.2451,  0.1061]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2996,  0.0419, -0.2374, -0.2879], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3386, -0.1316,  0.0396,  0.0087, -0.2388, -0.1577, -0.1676,  0.1854],\n        [-0.3499,  0.3161, -0.0023,  0.2012, -0.3156, -0.2695, -0.0374, -0.1485],\n        [-0.1315,  0.0013,  0.1231, -0.0156, -0.2721,  0.1056,  0.1672, -0.1783],\n        [ 0.2189, -0.0779, -0.2574, -0.3444, -0.2322,  0.0025, -0.3383, -0.1666]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0028,  0.3049,  0.1754, -0.1305,  0.2429, -0.3430,  0.2806, -0.1237],\n        [-0.3201,  0.1226,  0.3467,  0.0211, -0.2755,  0.0212,  0.1279,  0.1235],\n        [ 0.2188,  0.1496, -0.1794,  0.0707, -0.1077,  0.1245, -0.1024, -0.2490],\n        [ 0.0248,  0.0299, -0.2000,  0.1199,  0.0766,  0.3255,  0.1184, -0.2435],\n        [ 0.3224,  0.3109, -0.1000, -0.0686,  0.0337, -0.2501,  0.0247,  0.0139],\n        [-0.3417,  0.0362, -0.3024, -0.2771,  0.1334,  0.3241, -0.2784, -0.1094],\n        [-0.3408,  0.0149,  0.0800,  0.0371, -0.1439,  0.0365,  0.0869,  0.0445],\n        [ 0.2857,  0.0097, -0.1435, -0.2868, -0.3381,  0.0028, -0.0775, -0.0808],\n        [-0.2944,  0.1573, -0.3318,  0.2562, -0.0437,  0.2321,  0.1147,  0.0714],\n        [ 0.1132, -0.2423, -0.1800, -0.2154,  0.1425, -0.1574, -0.1059, -0.2251],\n        [ 0.0949, -0.1268, -0.2304,  0.0148, -0.3383, -0.2857, -0.0559, -0.3288],\n        [ 0.2008, -0.1353, -0.1732,  0.0058, -0.3152, -0.3162, -0.1347,  0.1679],\n        [-0.0398, -0.2569,  0.0177,  0.1483, -0.0432, -0.0607, -0.1286, -0.0239],\n        [-0.3326, -0.2455,  0.2768, -0.3081, -0.3025,  0.2705, -0.0066, -0.0855],\n        [ 0.3473,  0.0499,  0.2179,  0.2482, -0.0367, -0.1200,  0.0484,  0.0737],\n        [-0.1884, -0.1792, -0.2991,  0.0020, -0.1895,  0.2297,  0.2100,  0.0803],\n        [-0.1420, -0.3010,  0.1839, -0.0777, -0.3269, -0.1921, -0.3018,  0.0091],\n        [ 0.0023,  0.2955, -0.1986, -0.2620, -0.0237,  0.2307,  0.1506, -0.3469],\n        [ 0.2409, -0.1181, -0.0096, -0.1276,  0.2068,  0.1792, -0.0468,  0.3499],\n        [-0.2929, -0.1544, -0.1553, -0.1716,  0.0971, -0.2317, -0.0512,  0.3072],\n        [-0.1638, -0.1809,  0.2203,  0.3388, -0.0418,  0.2648, -0.0639, -0.1487],\n        [ 0.1330,  0.1193, -0.0561,  0.1431,  0.2064, -0.2783, -0.2352, -0.0064],\n        [ 0.0549, -0.3437, -0.2321,  0.1291,  0.0927,  0.1595,  0.1879, -0.2511],\n        [ 0.2148,  0.2350, -0.1029,  0.0615, -0.2124, -0.0257,  0.1272,  0.2813],\n        [-0.1996, -0.3521,  0.3040,  0.1850, -0.0310, -0.0393,  0.0295, -0.2656],\n        [-0.2207,  0.2388,  0.1511,  0.2066, -0.2996, -0.0789, -0.0563, -0.0657],\n        [ 0.1718, -0.2676,  0.2000,  0.1461,  0.0338,  0.1235,  0.0890, -0.2293],\n        [-0.2380, -0.2235, -0.2995,  0.2448, -0.2062,  0.1286,  0.0161,  0.0151],\n        [-0.1817, -0.1082, -0.1983,  0.1801,  0.1759, -0.2242, -0.2976,  0.2631],\n        [-0.1000, -0.3369,  0.3366, -0.1914,  0.1922, -0.2306, -0.1259, -0.2700],\n        [ 0.1481, -0.1677,  0.2253, -0.3464, -0.1454, -0.0517,  0.1746,  0.3473],\n        [ 0.0618, -0.2731, -0.0794, -0.3080,  0.2786,  0.3413,  0.2405,  0.3191]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0676, -0.3486, -0.0593,  0.0970,  0.0820,  0.2375,  0.1316,  0.2348,\n         0.3331,  0.0713, -0.2736, -0.0394,  0.3266, -0.3039, -0.3499, -0.3399,\n        -0.1501, -0.1035,  0.3235,  0.3103,  0.1581,  0.3211, -0.3040,  0.0641,\n         0.0402, -0.0964, -0.0957,  0.2780,  0.1238,  0.2524,  0.1566, -0.1715],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 3.8560e-02,  1.6886e-01, -2.6417e-02,  4.4944e-02,  6.6199e-02,\n          1.3509e-01, -8.4777e-02, -4.9686e-02,  8.7770e-02, -3.0531e-02,\n         -2.9215e-02, -1.7347e-01, -5.4777e-03, -4.8045e-02, -1.1834e-01,\n          1.1452e-02,  4.3568e-02,  1.6904e-01, -3.4750e-02, -3.4548e-02,\n         -8.7290e-02, -1.3755e-01,  9.6568e-02,  1.6486e-01, -3.8485e-02,\n         -5.7266e-02, -1.0285e-02, -1.0619e-01,  1.5157e-01,  5.3509e-02,\n         -6.4158e-02, -1.7495e-01],\n        [-1.7239e-01, -1.4363e-01,  7.1167e-02, -2.1830e-02,  7.0936e-02,\n         -1.0356e-01,  5.4676e-02, -1.0931e-01, -5.4239e-02, -6.1898e-02,\n         -9.8469e-03, -1.3320e-01,  1.2572e-01, -7.2488e-02, -8.1135e-03,\n          1.5094e-01, -1.4006e-01,  6.1605e-02,  1.3446e-02, -2.3378e-02,\n         -1.5377e-01, -5.2284e-02,  1.6071e-01,  7.9021e-02,  1.3266e-01,\n          1.2579e-01,  1.3675e-01, -9.6382e-02, -1.6736e-01,  1.4071e-01,\n          1.7755e-02, -9.2966e-02],\n        [ 4.5999e-02, -1.0493e-01,  1.4009e-02,  7.7842e-02, -2.5680e-02,\n         -1.0349e-01,  1.4603e-01, -7.9011e-02,  1.0000e-02,  4.7037e-02,\n          1.6629e-01, -1.2717e-01,  3.0922e-02, -4.7802e-02,  2.5091e-02,\n         -2.4215e-02,  1.4411e-01, -2.0538e-02,  5.7125e-02,  1.0300e-01,\n         -1.9548e-02, -5.3772e-02, -1.5408e-01,  8.8283e-02,  7.0149e-02,\n          1.1437e-01, -1.1532e-01, -7.4347e-05, -1.1635e-01, -1.5287e-02,\n         -1.7133e-01, -1.4993e-01],\n        [-1.7283e-01,  1.0942e-01,  1.4573e-01,  1.1696e-01, -7.2628e-02,\n          6.0533e-02, -4.7350e-02, -9.2258e-02, -9.9983e-02, -1.5660e-01,\n          3.3743e-03, -3.9506e-02,  7.2261e-02,  8.9336e-02,  1.6486e-01,\n          9.5046e-03,  3.5726e-02,  1.7303e-01,  7.9982e-02, -1.0996e-02,\n          1.0954e-01,  7.5778e-02, -6.3695e-02,  3.7531e-02,  7.4075e-04,\n          4.2019e-02,  1.5463e-01,  6.8183e-02,  1.2657e-01,  1.6884e-01,\n         -1.5113e-01, -3.7085e-02],\n        [-9.4863e-02, -4.5834e-02,  1.2944e-01, -1.4290e-01,  1.4202e-01,\n         -6.5729e-02, -1.0742e-01,  1.2278e-01, -5.8510e-02,  1.2403e-01,\n         -6.2280e-02, -1.6400e-01,  1.6180e-01, -1.7175e-01, -1.8915e-02,\n          4.4848e-04, -2.6061e-02, -1.3638e-01, -2.7620e-02,  4.5398e-02,\n         -7.5280e-02,  1.1031e-01,  8.7592e-02, -1.2332e-01, -8.6134e-02,\n          1.3634e-01, -1.5945e-01,  5.5427e-02, -1.6071e-01, -3.8551e-02,\n          6.7864e-02,  1.4356e-01],\n        [ 1.2812e-02, -1.6209e-01, -1.3922e-01,  1.1064e-01, -3.1787e-02,\n         -1.5914e-01, -1.6367e-01,  1.2635e-01,  1.5610e-01, -2.5644e-02,\n          3.1773e-02, -1.0146e-01,  4.5458e-02,  1.4566e-01, -3.4089e-02,\n         -1.4977e-03,  1.3415e-01,  1.2514e-01,  6.0342e-02, -2.6775e-02,\n         -8.2333e-02, -6.8696e-02,  4.1717e-02,  1.5013e-01, -9.2227e-02,\n         -1.6716e-01, -1.1577e-01,  4.4705e-02,  1.1304e-03, -1.2924e-01,\n         -1.4824e-01,  1.3953e-01],\n        [-1.7778e-03,  4.3102e-02, -3.0246e-03,  1.0073e-01,  7.9334e-02,\n         -9.4552e-02, -2.5855e-02, -9.1130e-02, -3.0929e-02,  1.4645e-01,\n         -1.6955e-01,  1.4495e-01,  8.8188e-03, -1.5754e-01, -9.2913e-02,\n         -2.8811e-02,  2.4291e-02, -1.1889e-01,  5.8572e-03, -4.9254e-02,\n         -9.0067e-02,  1.1036e-01, -1.1055e-01,  9.6468e-02,  1.5618e-01,\n         -1.5277e-01,  1.5460e-01, -4.3520e-02,  9.4129e-02, -9.2358e-02,\n         -8.8435e-02,  1.1436e-01],\n        [-1.2667e-01,  6.3286e-02,  1.4347e-01, -1.5807e-01, -1.2048e-01,\n         -1.7014e-01, -8.5332e-02,  8.2262e-02, -9.3592e-02,  7.2343e-02,\n          1.4156e-02, -1.4258e-01, -2.8041e-02, -1.2479e-01,  9.7586e-02,\n         -1.3910e-01,  1.5340e-01, -6.1625e-02, -6.6108e-02, -1.6958e-01,\n         -1.7043e-01, -1.1399e-01, -1.1206e-01,  1.0681e-01,  5.0868e-02,\n         -2.5366e-02,  9.9558e-02, -1.2010e-01, -1.0948e-01,  2.9061e-03,\n         -1.3127e-01, -1.7435e-01],\n        [ 1.4674e-01,  1.4786e-01,  9.0350e-02,  1.4925e-01,  3.5108e-02,\n         -1.0295e-01, -8.5674e-02,  1.2196e-01, -1.1980e-01, -3.1259e-02,\n          3.2998e-02,  1.6960e-01,  4.3474e-02,  9.9108e-02,  8.2373e-03,\n          1.2902e-01,  1.5442e-01, -1.2999e-01,  1.0407e-01, -6.6253e-02,\n          1.6451e-01,  2.1861e-02,  1.3433e-01, -1.0912e-01, -1.7034e-01,\n         -1.6579e-01, -7.0632e-03,  1.1006e-01, -1.0055e-01,  1.3679e-02,\n         -1.6109e-02,  4.7247e-02],\n        [-1.4961e-01,  4.8407e-02, -4.5215e-02,  1.0599e-01, -1.0056e-01,\n         -5.4134e-03, -9.4831e-02, -1.0268e-02, -1.7373e-01, -1.0383e-01,\n         -1.0759e-01, -1.0116e-01, -6.8142e-02,  1.5800e-01,  7.3643e-02,\n          7.1266e-02, -9.3172e-02,  8.6899e-02, -5.1099e-03,  4.5079e-02,\n         -2.0861e-03, -1.4317e-01,  1.6544e-01, -1.6781e-01,  8.1342e-02,\n         -1.0145e-01, -6.6485e-02,  7.6975e-02,  8.9475e-02, -1.3302e-01,\n         -8.6679e-02, -7.9441e-02],\n        [ 1.7198e-01, -1.7422e-01,  6.8435e-02,  7.3964e-02, -1.3871e-01,\n          1.1193e-02, -1.3973e-01, -2.8123e-02,  9.0774e-02,  7.5066e-02,\n          4.9940e-02,  1.7407e-01, -2.1543e-02, -1.5057e-01, -1.3513e-01,\n         -6.9558e-02,  2.9476e-02,  3.1473e-02, -8.5807e-02,  1.7413e-01,\n          1.1194e-01, -6.0056e-02,  1.0768e-01, -6.2411e-03,  9.5795e-02,\n         -1.2329e-01,  4.6146e-02,  1.5470e-01, -8.1177e-02,  1.4061e-01,\n          9.6281e-02,  6.8617e-02],\n        [-4.5277e-02, -1.1503e-03,  1.6033e-01,  1.2251e-01, -1.5151e-01,\n          1.4210e-01,  1.5712e-01,  1.5621e-01,  1.3454e-01, -8.5813e-02,\n         -7.8311e-02,  6.5227e-02,  1.4808e-01,  1.4662e-01, -2.5732e-02,\n          5.1122e-02,  1.6336e-01, -1.0325e-01,  3.4171e-02, -8.1498e-02,\n         -9.9877e-02, -1.8129e-02, -8.0622e-02, -4.2798e-02,  9.4290e-02,\n         -1.4442e-01, -1.5546e-01, -4.4556e-02, -8.0001e-02,  6.8925e-02,\n         -8.0862e-02, -8.8472e-02],\n        [ 5.7391e-02,  9.1696e-02, -1.1168e-01, -1.6506e-02, -1.0313e-02,\n          1.3501e-01, -9.1856e-02,  9.5302e-02, -1.1173e-01, -1.1602e-01,\n          3.0617e-02, -2.5081e-02,  8.7514e-03, -1.0358e-01, -9.8330e-02,\n         -1.0578e-01, -6.6598e-02, -1.5051e-01,  1.4770e-03, -1.1783e-01,\n         -3.2370e-02,  8.9849e-02, -2.0097e-02, -1.1741e-01, -3.6483e-02,\n          1.3254e-01,  1.5942e-02, -1.2451e-01,  1.1896e-02,  1.1266e-01,\n          1.4422e-01,  4.2290e-02],\n        [-5.9696e-02, -5.6196e-02, -1.2780e-01,  2.3931e-02, -2.9082e-02,\n         -4.0119e-02,  1.6847e-01,  1.3768e-01,  9.3685e-02,  1.7677e-01,\n         -1.0912e-01, -1.0014e-01, -9.9776e-02,  2.9599e-02,  2.1532e-02,\n         -6.1607e-02,  1.0709e-01, -1.9388e-02,  1.2434e-01, -6.4603e-02,\n         -3.5737e-02, -1.0668e-01, -1.0415e-01, -1.1284e-01, -1.1393e-01,\n         -1.1864e-01,  1.1725e-02, -1.9748e-02, -9.9135e-02, -4.6959e-02,\n         -5.1646e-03,  1.5688e-01],\n        [-1.4976e-01, -1.6213e-01,  1.4516e-01, -1.1787e-01, -1.2454e-01,\n         -1.2391e-01, -1.4330e-01, -1.3198e-02, -1.0156e-01, -2.9143e-02,\n         -6.5653e-02,  9.3928e-02,  9.8146e-02,  1.6581e-01, -5.7999e-02,\n         -6.0059e-02, -1.7623e-01, -1.3848e-01,  9.5296e-02, -1.5287e-02,\n          7.0647e-02, -4.8085e-02,  1.4854e-01, -7.7054e-02,  1.0035e-01,\n          1.7085e-01, -5.0722e-02, -2.6204e-02,  1.2716e-01, -1.6741e-01,\n          6.1646e-02, -4.7788e-02],\n        [ 8.9780e-02, -1.0597e-01,  1.3031e-01, -4.8335e-02,  9.1085e-02,\n          9.3573e-02,  1.3197e-01, -9.6112e-02,  9.7533e-02, -1.2618e-01,\n          1.3034e-01, -7.1690e-02,  1.7016e-01, -2.8283e-03,  6.1544e-02,\n          4.4482e-02,  9.5811e-02, -6.9374e-02, -5.5283e-03, -1.0677e-01,\n          1.0418e-01,  1.6799e-01, -6.9946e-02,  2.3848e-02, -1.4239e-01,\n          4.4042e-02,  1.0928e-01, -3.8518e-02,  1.2072e-01, -1.3776e-01,\n         -1.3692e-01,  6.7633e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0480, -0.0595,  0.0184,  0.0702,  0.0221,  0.0694, -0.0335,  0.1570,\n        -0.0089,  0.1540, -0.0715, -0.1758,  0.1095, -0.1526,  0.0395, -0.1194],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1042,  0.1351, -0.0436,  0.2439, -0.0580, -0.2187,  0.0595,  0.1316,\n          0.0100, -0.1807, -0.1055, -0.0944,  0.2415, -0.1435,  0.2145, -0.1810],\n        [-0.1157, -0.0745,  0.1234,  0.1644,  0.2016,  0.0904, -0.2456,  0.2409,\n          0.1312, -0.0843,  0.0539, -0.0702,  0.2106, -0.0133, -0.0806,  0.0575],\n        [-0.2009, -0.1750, -0.1833, -0.0764,  0.2136,  0.2292,  0.0821,  0.2386,\n          0.0338,  0.0961,  0.0031, -0.1980,  0.1556, -0.0247,  0.0241, -0.2088],\n        [-0.0221, -0.2387,  0.1750, -0.1811, -0.1323, -0.2045, -0.2365,  0.2187,\n         -0.2196,  0.2470, -0.2239,  0.2278, -0.2364,  0.1815,  0.0259, -0.1609],\n        [-0.0323, -0.0988, -0.0245,  0.1138,  0.1802,  0.1346, -0.2425,  0.2471,\n         -0.0675,  0.1067, -0.0360, -0.0220, -0.2143, -0.0438, -0.1031, -0.1945],\n        [ 0.0388,  0.2410, -0.0875, -0.1622,  0.1306,  0.0193, -0.1047,  0.2367,\n          0.1399, -0.0852,  0.1014,  0.2058,  0.1179, -0.0213,  0.1136,  0.0018],\n        [ 0.0274,  0.1878, -0.0176,  0.0860,  0.1900, -0.0581,  0.1252, -0.2286,\n          0.0136, -0.2342,  0.1803, -0.0249, -0.1907,  0.0130, -0.2050, -0.2103],\n        [-0.1897,  0.0237,  0.1118, -0.1667,  0.0004,  0.2366, -0.0813, -0.2138,\n          0.0229, -0.1066, -0.0656, -0.0321, -0.0346, -0.1806,  0.2451,  0.1061]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1821,  0.2223,  0.0634, -0.1041, -0.1706,  0.1387,  0.0825, -0.0604],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3386, -0.1316,  0.0396,  0.0087, -0.2388, -0.1577, -0.1676,  0.1854],\n        [-0.3499,  0.3161, -0.0023,  0.2012, -0.3156, -0.2695, -0.0374, -0.1485],\n        [-0.1315,  0.0013,  0.1231, -0.0156, -0.2721,  0.1056,  0.1672, -0.1783],\n        [ 0.2189, -0.0779, -0.2574, -0.3444, -0.2322,  0.0025, -0.3383, -0.1666]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2996,  0.0419, -0.2374, -0.2879], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7ae2ad50bd50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x7ae2275f3e90>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0006,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0676, -0.3486, -0.0593,  0.0970,  0.0820,  0.2375,  0.1316,  0.2348,\n         0.3331,  0.0713, -0.2736, -0.0394,  0.3266, -0.3039, -0.3499, -0.3399,\n        -0.1501, -0.1035,  0.3235,  0.3103,  0.1581,  0.3211, -0.3040,  0.0641,\n         0.0402, -0.0964, -0.0957,  0.2780,  0.1238,  0.2524,  0.1566, -0.1715],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0028,  0.3049,  0.1754, -0.1305,  0.2429, -0.3430,  0.2806, -0.1237],\n        [-0.3201,  0.1226,  0.3467,  0.0211, -0.2755,  0.0212,  0.1279,  0.1235],\n        [ 0.2188,  0.1496, -0.1794,  0.0707, -0.1077,  0.1245, -0.1024, -0.2490],\n        [ 0.0248,  0.0299, -0.2000,  0.1199,  0.0766,  0.3255,  0.1184, -0.2435],\n        [ 0.3224,  0.3109, -0.1000, -0.0686,  0.0337, -0.2501,  0.0247,  0.0139],\n        [-0.3417,  0.0362, -0.3024, -0.2771,  0.1334,  0.3241, -0.2784, -0.1094],\n        [-0.3408,  0.0149,  0.0800,  0.0371, -0.1439,  0.0365,  0.0869,  0.0445],\n        [ 0.2857,  0.0097, -0.1435, -0.2868, -0.3381,  0.0028, -0.0775, -0.0808],\n        [-0.2944,  0.1573, -0.3318,  0.2562, -0.0437,  0.2321,  0.1147,  0.0714],\n        [ 0.1132, -0.2423, -0.1800, -0.2154,  0.1425, -0.1574, -0.1059, -0.2251],\n        [ 0.0949, -0.1268, -0.2304,  0.0148, -0.3383, -0.2857, -0.0559, -0.3288],\n        [ 0.2008, -0.1353, -0.1732,  0.0058, -0.3152, -0.3162, -0.1347,  0.1679],\n        [-0.0398, -0.2569,  0.0177,  0.1483, -0.0432, -0.0607, -0.1286, -0.0239],\n        [-0.3326, -0.2455,  0.2768, -0.3081, -0.3025,  0.2705, -0.0066, -0.0855],\n        [ 0.3473,  0.0499,  0.2179,  0.2482, -0.0367, -0.1200,  0.0484,  0.0737],\n        [-0.1884, -0.1792, -0.2991,  0.0020, -0.1895,  0.2297,  0.2100,  0.0803],\n        [-0.1420, -0.3010,  0.1839, -0.0777, -0.3269, -0.1921, -0.3018,  0.0091],\n        [ 0.0023,  0.2955, -0.1986, -0.2620, -0.0237,  0.2307,  0.1506, -0.3469],\n        [ 0.2409, -0.1181, -0.0096, -0.1276,  0.2068,  0.1792, -0.0468,  0.3499],\n        [-0.2929, -0.1544, -0.1553, -0.1716,  0.0971, -0.2317, -0.0512,  0.3072],\n        [-0.1638, -0.1809,  0.2203,  0.3388, -0.0418,  0.2648, -0.0639, -0.1487],\n        [ 0.1330,  0.1193, -0.0561,  0.1431,  0.2064, -0.2783, -0.2352, -0.0064],\n        [ 0.0549, -0.3437, -0.2321,  0.1291,  0.0927,  0.1595,  0.1879, -0.2511],\n        [ 0.2148,  0.2350, -0.1029,  0.0615, -0.2124, -0.0257,  0.1272,  0.2813],\n        [-0.1996, -0.3521,  0.3040,  0.1850, -0.0310, -0.0393,  0.0295, -0.2656],\n        [-0.2207,  0.2388,  0.1511,  0.2066, -0.2996, -0.0789, -0.0563, -0.0657],\n        [ 0.1718, -0.2676,  0.2000,  0.1461,  0.0338,  0.1235,  0.0890, -0.2293],\n        [-0.2380, -0.2235, -0.2995,  0.2448, -0.2062,  0.1286,  0.0161,  0.0151],\n        [-0.1817, -0.1082, -0.1983,  0.1801,  0.1759, -0.2242, -0.2976,  0.2631],\n        [-0.1000, -0.3369,  0.3366, -0.1914,  0.1922, -0.2306, -0.1259, -0.2700],\n        [ 0.1481, -0.1677,  0.2253, -0.3464, -0.1454, -0.0517,  0.1746,  0.3473],\n        [ 0.0618, -0.2731, -0.0794, -0.3080,  0.2786,  0.3413,  0.2405,  0.3191]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0480, -0.0595,  0.0184,  0.0702,  0.0221,  0.0694, -0.0335,  0.1570,\n        -0.0089,  0.1540, -0.0715, -0.1758,  0.1095, -0.1526,  0.0395, -0.1194],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 3.8560e-02,  1.6886e-01, -2.6417e-02,  4.4944e-02,  6.6199e-02,\n          1.3509e-01, -8.4777e-02, -4.9686e-02,  8.7770e-02, -3.0531e-02,\n         -2.9215e-02, -1.7347e-01, -5.4777e-03, -4.8045e-02, -1.1834e-01,\n          1.1452e-02,  4.3568e-02,  1.6904e-01, -3.4750e-02, -3.4548e-02,\n         -8.7290e-02, -1.3755e-01,  9.6568e-02,  1.6486e-01, -3.8485e-02,\n         -5.7266e-02, -1.0285e-02, -1.0619e-01,  1.5157e-01,  5.3509e-02,\n         -6.4158e-02, -1.7495e-01],\n        [-1.7239e-01, -1.4363e-01,  7.1167e-02, -2.1830e-02,  7.0936e-02,\n         -1.0356e-01,  5.4676e-02, -1.0931e-01, -5.4239e-02, -6.1898e-02,\n         -9.8469e-03, -1.3320e-01,  1.2572e-01, -7.2488e-02, -8.1135e-03,\n          1.5094e-01, -1.4006e-01,  6.1605e-02,  1.3446e-02, -2.3378e-02,\n         -1.5377e-01, -5.2284e-02,  1.6071e-01,  7.9021e-02,  1.3266e-01,\n          1.2579e-01,  1.3675e-01, -9.6382e-02, -1.6736e-01,  1.4071e-01,\n          1.7755e-02, -9.2966e-02],\n        [ 4.5999e-02, -1.0493e-01,  1.4009e-02,  7.7842e-02, -2.5680e-02,\n         -1.0349e-01,  1.4603e-01, -7.9011e-02,  1.0000e-02,  4.7037e-02,\n          1.6629e-01, -1.2717e-01,  3.0922e-02, -4.7802e-02,  2.5091e-02,\n         -2.4215e-02,  1.4411e-01, -2.0538e-02,  5.7125e-02,  1.0300e-01,\n         -1.9548e-02, -5.3772e-02, -1.5408e-01,  8.8283e-02,  7.0149e-02,\n          1.1437e-01, -1.1532e-01, -7.4347e-05, -1.1635e-01, -1.5287e-02,\n         -1.7133e-01, -1.4993e-01],\n        [-1.7283e-01,  1.0942e-01,  1.4573e-01,  1.1696e-01, -7.2628e-02,\n          6.0533e-02, -4.7350e-02, -9.2258e-02, -9.9983e-02, -1.5660e-01,\n          3.3743e-03, -3.9506e-02,  7.2261e-02,  8.9336e-02,  1.6486e-01,\n          9.5046e-03,  3.5726e-02,  1.7303e-01,  7.9982e-02, -1.0996e-02,\n          1.0954e-01,  7.5778e-02, -6.3695e-02,  3.7531e-02,  7.4075e-04,\n          4.2019e-02,  1.5463e-01,  6.8183e-02,  1.2657e-01,  1.6884e-01,\n         -1.5113e-01, -3.7085e-02],\n        [-9.4863e-02, -4.5834e-02,  1.2944e-01, -1.4290e-01,  1.4202e-01,\n         -6.5729e-02, -1.0742e-01,  1.2278e-01, -5.8510e-02,  1.2403e-01,\n         -6.2280e-02, -1.6400e-01,  1.6180e-01, -1.7175e-01, -1.8915e-02,\n          4.4848e-04, -2.6061e-02, -1.3638e-01, -2.7620e-02,  4.5398e-02,\n         -7.5280e-02,  1.1031e-01,  8.7592e-02, -1.2332e-01, -8.6134e-02,\n          1.3634e-01, -1.5945e-01,  5.5427e-02, -1.6071e-01, -3.8551e-02,\n          6.7864e-02,  1.4356e-01],\n        [ 1.2812e-02, -1.6209e-01, -1.3922e-01,  1.1064e-01, -3.1787e-02,\n         -1.5914e-01, -1.6367e-01,  1.2635e-01,  1.5610e-01, -2.5644e-02,\n          3.1773e-02, -1.0146e-01,  4.5458e-02,  1.4566e-01, -3.4089e-02,\n         -1.4977e-03,  1.3415e-01,  1.2514e-01,  6.0342e-02, -2.6775e-02,\n         -8.2333e-02, -6.8696e-02,  4.1717e-02,  1.5013e-01, -9.2227e-02,\n         -1.6716e-01, -1.1577e-01,  4.4705e-02,  1.1304e-03, -1.2924e-01,\n         -1.4824e-01,  1.3953e-01],\n        [-1.7778e-03,  4.3102e-02, -3.0246e-03,  1.0073e-01,  7.9334e-02,\n         -9.4552e-02, -2.5855e-02, -9.1130e-02, -3.0929e-02,  1.4645e-01,\n         -1.6955e-01,  1.4495e-01,  8.8188e-03, -1.5754e-01, -9.2913e-02,\n         -2.8811e-02,  2.4291e-02, -1.1889e-01,  5.8572e-03, -4.9254e-02,\n         -9.0067e-02,  1.1036e-01, -1.1055e-01,  9.6468e-02,  1.5618e-01,\n         -1.5277e-01,  1.5460e-01, -4.3520e-02,  9.4129e-02, -9.2358e-02,\n         -8.8435e-02,  1.1436e-01],\n        [-1.2667e-01,  6.3286e-02,  1.4347e-01, -1.5807e-01, -1.2048e-01,\n         -1.7014e-01, -8.5332e-02,  8.2262e-02, -9.3592e-02,  7.2343e-02,\n          1.4156e-02, -1.4258e-01, -2.8041e-02, -1.2479e-01,  9.7586e-02,\n         -1.3910e-01,  1.5340e-01, -6.1625e-02, -6.6108e-02, -1.6958e-01,\n         -1.7043e-01, -1.1399e-01, -1.1206e-01,  1.0681e-01,  5.0868e-02,\n         -2.5366e-02,  9.9558e-02, -1.2010e-01, -1.0948e-01,  2.9061e-03,\n         -1.3127e-01, -1.7435e-01],\n        [ 1.4674e-01,  1.4786e-01,  9.0350e-02,  1.4925e-01,  3.5108e-02,\n         -1.0295e-01, -8.5674e-02,  1.2196e-01, -1.1980e-01, -3.1259e-02,\n          3.2998e-02,  1.6960e-01,  4.3474e-02,  9.9108e-02,  8.2373e-03,\n          1.2902e-01,  1.5442e-01, -1.2999e-01,  1.0407e-01, -6.6253e-02,\n          1.6451e-01,  2.1861e-02,  1.3433e-01, -1.0912e-01, -1.7034e-01,\n         -1.6579e-01, -7.0632e-03,  1.1006e-01, -1.0055e-01,  1.3679e-02,\n         -1.6109e-02,  4.7247e-02],\n        [-1.4961e-01,  4.8407e-02, -4.5215e-02,  1.0599e-01, -1.0056e-01,\n         -5.4134e-03, -9.4831e-02, -1.0268e-02, -1.7373e-01, -1.0383e-01,\n         -1.0759e-01, -1.0116e-01, -6.8142e-02,  1.5800e-01,  7.3643e-02,\n          7.1266e-02, -9.3172e-02,  8.6899e-02, -5.1099e-03,  4.5079e-02,\n         -2.0861e-03, -1.4317e-01,  1.6544e-01, -1.6781e-01,  8.1342e-02,\n         -1.0145e-01, -6.6485e-02,  7.6975e-02,  8.9475e-02, -1.3302e-01,\n         -8.6679e-02, -7.9441e-02],\n        [ 1.7198e-01, -1.7422e-01,  6.8435e-02,  7.3964e-02, -1.3871e-01,\n          1.1193e-02, -1.3973e-01, -2.8123e-02,  9.0774e-02,  7.5066e-02,\n          4.9940e-02,  1.7407e-01, -2.1543e-02, -1.5057e-01, -1.3513e-01,\n         -6.9558e-02,  2.9476e-02,  3.1473e-02, -8.5807e-02,  1.7413e-01,\n          1.1194e-01, -6.0056e-02,  1.0768e-01, -6.2411e-03,  9.5795e-02,\n         -1.2329e-01,  4.6146e-02,  1.5470e-01, -8.1177e-02,  1.4061e-01,\n          9.6281e-02,  6.8617e-02],\n        [-4.5277e-02, -1.1503e-03,  1.6033e-01,  1.2251e-01, -1.5151e-01,\n          1.4210e-01,  1.5712e-01,  1.5621e-01,  1.3454e-01, -8.5813e-02,\n         -7.8311e-02,  6.5227e-02,  1.4808e-01,  1.4662e-01, -2.5732e-02,\n          5.1122e-02,  1.6336e-01, -1.0325e-01,  3.4171e-02, -8.1498e-02,\n         -9.9877e-02, -1.8129e-02, -8.0622e-02, -4.2798e-02,  9.4290e-02,\n         -1.4442e-01, -1.5546e-01, -4.4556e-02, -8.0001e-02,  6.8925e-02,\n         -8.0862e-02, -8.8472e-02],\n        [ 5.7391e-02,  9.1696e-02, -1.1168e-01, -1.6506e-02, -1.0313e-02,\n          1.3501e-01, -9.1856e-02,  9.5302e-02, -1.1173e-01, -1.1602e-01,\n          3.0617e-02, -2.5081e-02,  8.7514e-03, -1.0358e-01, -9.8330e-02,\n         -1.0578e-01, -6.6598e-02, -1.5051e-01,  1.4770e-03, -1.1783e-01,\n         -3.2370e-02,  8.9849e-02, -2.0097e-02, -1.1741e-01, -3.6483e-02,\n          1.3254e-01,  1.5942e-02, -1.2451e-01,  1.1896e-02,  1.1266e-01,\n          1.4422e-01,  4.2290e-02],\n        [-5.9696e-02, -5.6196e-02, -1.2780e-01,  2.3931e-02, -2.9082e-02,\n         -4.0119e-02,  1.6847e-01,  1.3768e-01,  9.3685e-02,  1.7677e-01,\n         -1.0912e-01, -1.0014e-01, -9.9776e-02,  2.9599e-02,  2.1532e-02,\n         -6.1607e-02,  1.0709e-01, -1.9388e-02,  1.2434e-01, -6.4603e-02,\n         -3.5737e-02, -1.0668e-01, -1.0415e-01, -1.1284e-01, -1.1393e-01,\n         -1.1864e-01,  1.1725e-02, -1.9748e-02, -9.9135e-02, -4.6959e-02,\n         -5.1646e-03,  1.5688e-01],\n        [-1.4976e-01, -1.6213e-01,  1.4516e-01, -1.1787e-01, -1.2454e-01,\n         -1.2391e-01, -1.4330e-01, -1.3198e-02, -1.0156e-01, -2.9143e-02,\n         -6.5653e-02,  9.3928e-02,  9.8146e-02,  1.6581e-01, -5.7999e-02,\n         -6.0059e-02, -1.7623e-01, -1.3848e-01,  9.5296e-02, -1.5287e-02,\n          7.0647e-02, -4.8085e-02,  1.4854e-01, -7.7054e-02,  1.0035e-01,\n          1.7085e-01, -5.0722e-02, -2.6204e-02,  1.2716e-01, -1.6741e-01,\n          6.1646e-02, -4.7788e-02],\n        [ 8.9780e-02, -1.0597e-01,  1.3031e-01, -4.8335e-02,  9.1085e-02,\n          9.3573e-02,  1.3197e-01, -9.6112e-02,  9.7533e-02, -1.2618e-01,\n          1.3034e-01, -7.1690e-02,  1.7016e-01, -2.8283e-03,  6.1544e-02,\n          4.4482e-02,  9.5811e-02, -6.9374e-02, -5.5283e-03, -1.0677e-01,\n          1.0418e-01,  1.6799e-01, -6.9946e-02,  2.3848e-02, -1.4239e-01,\n          4.4042e-02,  1.0928e-01, -3.8518e-02,  1.2072e-01, -1.3776e-01,\n         -1.3692e-01,  6.7633e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1821,  0.2223,  0.0634, -0.1041, -0.1706,  0.1387,  0.0825, -0.0604],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1042,  0.1351, -0.0436,  0.2439, -0.0580, -0.2187,  0.0595,  0.1316,\n          0.0100, -0.1807, -0.1055, -0.0944,  0.2415, -0.1435,  0.2145, -0.1810],\n        [-0.1157, -0.0745,  0.1234,  0.1644,  0.2016,  0.0904, -0.2456,  0.2409,\n          0.1312, -0.0843,  0.0539, -0.0702,  0.2106, -0.0133, -0.0806,  0.0575],\n        [-0.2009, -0.1750, -0.1833, -0.0764,  0.2136,  0.2292,  0.0821,  0.2386,\n          0.0338,  0.0961,  0.0031, -0.1980,  0.1556, -0.0247,  0.0241, -0.2088],\n        [-0.0221, -0.2387,  0.1750, -0.1811, -0.1323, -0.2045, -0.2365,  0.2187,\n         -0.2196,  0.2470, -0.2239,  0.2278, -0.2364,  0.1815,  0.0259, -0.1609],\n        [-0.0323, -0.0988, -0.0245,  0.1138,  0.1802,  0.1346, -0.2425,  0.2471,\n         -0.0675,  0.1067, -0.0360, -0.0220, -0.2143, -0.0438, -0.1031, -0.1945],\n        [ 0.0388,  0.2410, -0.0875, -0.1622,  0.1306,  0.0193, -0.1047,  0.2367,\n          0.1399, -0.0852,  0.1014,  0.2058,  0.1179, -0.0213,  0.1136,  0.0018],\n        [ 0.0274,  0.1878, -0.0176,  0.0860,  0.1900, -0.0581,  0.1252, -0.2286,\n          0.0136, -0.2342,  0.1803, -0.0249, -0.1907,  0.0130, -0.2050, -0.2103],\n        [-0.1897,  0.0237,  0.1118, -0.1667,  0.0004,  0.2366, -0.0813, -0.2138,\n          0.0229, -0.1066, -0.0656, -0.0321, -0.0346, -0.1806,  0.2451,  0.1061]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2996,  0.0419, -0.2374, -0.2879], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3386, -0.1316,  0.0396,  0.0087, -0.2388, -0.1577, -0.1676,  0.1854],\n        [-0.3499,  0.3161, -0.0023,  0.2012, -0.3156, -0.2695, -0.0374, -0.1485],\n        [-0.1315,  0.0013,  0.1231, -0.0156, -0.2721,  0.1056,  0.1672, -0.1783],\n        [ 0.2189, -0.0779, -0.2574, -0.3444, -0.2322,  0.0025, -0.3383, -0.1666]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	1,
            "_train_update_freq":	32,
            "_traj_per_epoch":	16,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7ae225a1d750>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1123970000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s1123970000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	1,
    "train_update_freq":	32,
    "traj_per_epoch":	16
}