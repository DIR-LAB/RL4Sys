{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s131130000"
    },
    "q_lr":	0.0005,
    "seed":	131130000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x17c22a3b0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 1.9240e-01,  2.0055e-01, -1.8670e-01, -1.9639e-01,  2.4146e-04,\n         7.3741e-02,  2.8947e-01,  3.1730e-01, -1.8892e-02,  1.9233e-01,\n         3.5008e-01,  2.6455e-02,  2.9911e-02,  9.4050e-02, -3.5140e-01,\n         1.9773e-01, -2.1997e-01, -1.7071e-01, -1.4049e-01, -3.2413e-01,\n         1.1930e-01, -3.3211e-02, -2.2526e-01, -3.3143e-01,  3.9640e-02,\n         5.3934e-02,  2.7623e-01, -1.9070e-01, -2.9609e-01, -3.6965e-02,\n         2.6658e-01, -3.8132e-02], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2616,  0.1155,  0.2661,  0.2580, -0.1312,  0.2548, -0.0106, -0.3285],\n        [ 0.1680,  0.2764, -0.2619, -0.2887,  0.1912,  0.3190, -0.1032,  0.1595],\n        [-0.1754,  0.1484, -0.3022, -0.0217, -0.1354,  0.3344,  0.0590, -0.0223],\n        [ 0.2931, -0.1608, -0.3527, -0.0679,  0.2683, -0.3077, -0.0979,  0.1037],\n        [-0.1029,  0.3423,  0.3387,  0.1139,  0.0190,  0.3466, -0.2083, -0.0493],\n        [-0.3273, -0.2054,  0.2345, -0.2084, -0.2190, -0.3472, -0.0969, -0.0228],\n        [ 0.1922, -0.2569, -0.2858,  0.0696, -0.1754,  0.1266,  0.1018,  0.3123],\n        [-0.2767,  0.2062, -0.0892, -0.3102, -0.2702,  0.0904, -0.2317, -0.2201],\n        [-0.0254,  0.3045,  0.2377, -0.2263, -0.2884,  0.2604, -0.0060, -0.1160],\n        [-0.0692, -0.0400, -0.0514,  0.0248,  0.1541,  0.0197,  0.3087, -0.3340],\n        [ 0.0962, -0.1553, -0.0657,  0.1677,  0.0587,  0.0223, -0.3364,  0.0678],\n        [-0.2104, -0.2335,  0.1475,  0.1783,  0.2400, -0.2657,  0.1201,  0.3056],\n        [-0.2480,  0.0857,  0.2226, -0.2375, -0.3061, -0.2477,  0.1600,  0.1859],\n        [ 0.0859, -0.1429,  0.0215, -0.1127,  0.1606, -0.2514, -0.0785,  0.2399],\n        [ 0.0803, -0.0790,  0.0842,  0.1595, -0.0643, -0.2055,  0.0021, -0.1463],\n        [ 0.3322, -0.0288, -0.1141,  0.2762, -0.2496,  0.1259, -0.2294, -0.1531],\n        [-0.1978,  0.3091, -0.1163,  0.3083,  0.0977,  0.1104,  0.3382, -0.2166],\n        [ 0.3468, -0.2796, -0.2379,  0.0997,  0.2622, -0.3150, -0.1402,  0.2596],\n        [-0.1379,  0.2679,  0.1513,  0.1843,  0.1767,  0.2193, -0.1550, -0.2814],\n        [ 0.0243,  0.0659, -0.2628, -0.2390, -0.1731,  0.1824, -0.2489, -0.2617],\n        [ 0.0230,  0.2558, -0.0400,  0.1858, -0.2454,  0.3534, -0.1663,  0.3008],\n        [-0.2810, -0.3008, -0.0959, -0.2795, -0.1571, -0.2328,  0.0497,  0.1706],\n        [-0.1052, -0.0323,  0.0648,  0.1348,  0.2648, -0.1822, -0.2661,  0.0092],\n        [ 0.1562, -0.1318, -0.3221,  0.1935, -0.2509,  0.3047,  0.2281, -0.1003],\n        [-0.2795,  0.1854,  0.0668,  0.3068, -0.2060, -0.3226, -0.1963, -0.1313],\n        [-0.3529,  0.3479,  0.3296, -0.1837, -0.2330,  0.2792,  0.2859,  0.0858],\n        [ 0.0875, -0.2767, -0.1425,  0.0324, -0.2665,  0.0399,  0.3093, -0.1331],\n        [-0.1091, -0.1749,  0.1622, -0.3440,  0.0059,  0.2885, -0.2330, -0.2643],\n        [ 0.0318,  0.3228,  0.0859,  0.0859, -0.1648, -0.3459,  0.1949,  0.2128],\n        [ 0.1004,  0.2411, -0.3055, -0.3223,  0.1115,  0.2978, -0.0604,  0.1069],\n        [-0.0301,  0.2338, -0.2965,  0.3415,  0.3165,  0.1133,  0.2075, -0.1343],\n        [-0.0818,  0.0437, -0.3033, -0.1196,  0.2257,  0.0322, -0.0888,  0.2448]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1736, -0.0608, -0.0132,  0.0794,  0.1063,  0.1544, -0.0186, -0.0110,\n        -0.1307,  0.1681, -0.0466, -0.1543, -0.1461, -0.0899,  0.0101, -0.0904],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 8.6611e-02,  7.8201e-02,  4.1277e-02,  3.2838e-02, -1.4374e-02,\n          6.4161e-03,  1.3377e-01, -5.3053e-02,  1.5418e-01,  1.2837e-02,\n          1.0794e-01, -1.5446e-01, -1.2520e-01, -9.2112e-02,  8.9429e-02,\n         -1.2695e-01, -1.2286e-01,  1.6076e-01,  9.9211e-02, -1.3312e-01,\n         -1.3187e-01, -6.4586e-02, -8.2836e-02, -7.5816e-02,  1.7029e-01,\n          3.9393e-02,  1.3371e-01,  5.4882e-03, -2.7362e-02, -8.3163e-02,\n         -8.9831e-02, -1.0292e-01],\n        [-9.9433e-02,  7.6601e-03, -5.9184e-02,  1.3752e-01,  1.2442e-01,\n          1.0064e-01, -1.3913e-01, -1.1732e-01,  9.7669e-03, -9.8955e-02,\n          1.6675e-01,  5.1232e-02, -1.7413e-01,  2.6627e-02, -9.4594e-02,\n          4.8197e-02, -9.8262e-02, -1.4911e-01,  1.4560e-01, -1.7115e-01,\n         -1.4259e-01, -1.8935e-02,  1.0588e-02, -7.3870e-02,  1.0717e-01,\n         -9.7806e-02,  5.0828e-02,  1.7515e-01, -1.5486e-01,  1.4859e-01,\n          8.8550e-02, -1.0919e-01],\n        [ 1.0970e-01, -9.1806e-02, -1.3004e-01, -5.6736e-02,  4.1861e-02,\n          7.6189e-03, -6.4452e-02,  1.5617e-01, -1.5173e-01,  9.3774e-02,\n          7.9039e-03,  1.3422e-01, -7.7325e-02,  4.9418e-02,  6.9449e-02,\n          6.8548e-02,  1.0432e-02,  3.6464e-03, -9.6771e-02,  5.4854e-02,\n          2.9499e-02,  1.0351e-01, -1.5313e-01,  8.7525e-02, -1.1676e-01,\n          2.2284e-02, -3.9546e-02,  2.9781e-02, -2.9196e-02, -9.6559e-02,\n         -1.1449e-01,  1.0682e-01],\n        [ 8.7363e-02,  1.2831e-01,  2.0116e-02,  1.7322e-01,  7.5032e-03,\n         -9.1473e-02, -1.7404e-01, -6.2425e-03, -1.5447e-01, -2.9442e-02,\n          5.1200e-03,  7.9978e-02,  4.5219e-02, -4.6229e-03, -5.1798e-02,\n          5.5459e-03, -1.4679e-01, -8.5950e-02, -1.5541e-01,  9.1110e-02,\n          1.2726e-01, -8.2890e-02,  2.1620e-02,  1.3998e-01, -1.3983e-01,\n         -1.2272e-01, -7.0529e-02, -6.5743e-02, -8.3668e-02, -2.6670e-02,\n          1.2276e-01, -1.3910e-01],\n        [ 9.9451e-02,  1.0203e-01,  6.4037e-02, -2.2224e-02, -8.9236e-03,\n         -1.2608e-01, -4.5495e-03,  1.2460e-01, -2.2810e-02, -6.5105e-02,\n          1.4328e-01, -7.4637e-02, -1.1085e-01, -1.2692e-01, -8.0957e-02,\n         -1.4839e-01, -1.1836e-01, -1.2752e-01,  7.8765e-02, -1.7641e-04,\n         -1.4405e-02,  7.2792e-03, -2.7539e-02,  1.6090e-01,  1.2655e-01,\n         -1.2265e-01, -6.0331e-02,  6.7394e-02,  1.4988e-01, -1.3900e-02,\n          8.6775e-02,  1.3701e-01],\n        [-1.4588e-01,  2.5435e-03, -6.7632e-02, -8.4965e-02,  1.0226e-01,\n          6.0009e-02, -6.1690e-02, -3.5949e-02, -9.2328e-02,  9.9018e-02,\n         -1.4077e-01,  2.6129e-02,  8.1153e-02,  1.3947e-01,  1.2386e-01,\n          1.5867e-01, -8.6666e-02,  1.6951e-01, -1.5355e-01, -1.6298e-01,\n          1.2119e-01, -7.7740e-03, -1.5850e-01, -3.0799e-02,  7.7927e-02,\n         -1.3992e-01,  3.4627e-02, -6.2818e-03,  1.5526e-01, -9.2611e-02,\n          1.5492e-01, -9.5410e-02],\n        [-6.4120e-02,  1.1209e-01,  1.6203e-01, -7.8878e-02, -1.1037e-01,\n         -2.1803e-02,  1.2543e-01, -3.7821e-02,  5.0641e-02, -4.6467e-02,\n         -7.2591e-02, -1.6138e-01, -1.7455e-01,  1.0634e-01, -1.5424e-01,\n         -8.1518e-02, -3.0562e-02, -1.5103e-01,  1.9558e-02,  4.3030e-02,\n          7.3042e-02, -3.9515e-02, -1.7476e-01,  1.6267e-01, -1.1237e-01,\n          1.6542e-01, -1.6029e-01, -5.4237e-02,  1.5341e-01,  1.9926e-02,\n          7.6459e-02, -1.6327e-01],\n        [-1.0286e-01,  1.5602e-01, -1.2963e-01,  1.7669e-01,  1.4328e-01,\n         -2.5977e-02, -1.1166e-01, -4.1758e-02, -1.2962e-01,  1.0958e-01,\n         -1.4714e-01,  1.1763e-01, -1.2303e-01,  1.0030e-01, -1.2914e-01,\n         -1.5833e-01,  2.3538e-02, -9.8424e-02, -1.4069e-01,  1.5535e-01,\n         -1.3344e-01, -8.1377e-02,  6.6709e-02,  1.5023e-01, -3.5884e-02,\n          1.0423e-01, -5.7815e-02, -1.7425e-01,  1.6749e-01,  3.8179e-02,\n         -1.5108e-01,  2.3565e-02],\n        [-8.8642e-02,  1.1349e-01, -1.1509e-01,  6.5212e-03,  1.0357e-01,\n          1.4623e-02,  1.2706e-01,  2.5378e-02, -1.7650e-01,  6.9905e-02,\n          1.4525e-01, -9.4016e-03, -9.4908e-02,  1.4506e-01,  4.0810e-02,\n          7.1367e-02,  9.6356e-02, -4.9218e-02,  5.1999e-02, -1.0225e-01,\n         -1.2989e-01,  5.6758e-02,  1.2099e-01,  4.0166e-02, -1.0795e-01,\n          5.3989e-02,  1.6192e-01,  1.7075e-01,  1.0271e-01,  1.4922e-02,\n         -9.6264e-02, -3.5189e-02],\n        [-5.0781e-02,  7.4621e-02, -6.7816e-02,  1.3920e-01, -1.7329e-01,\n          1.1530e-01,  7.6238e-02, -1.1104e-01,  1.3153e-01,  1.3650e-01,\n         -7.7587e-02, -1.0138e-01,  1.7108e-02,  1.0454e-01,  1.7610e-01,\n         -9.5688e-02,  6.0527e-02,  1.6160e-01,  5.1730e-02, -8.0170e-02,\n          5.7518e-02,  7.8072e-02, -1.3205e-01,  3.5164e-02, -1.7878e-02,\n          1.4764e-01, -1.1351e-01, -1.6400e-01, -1.0208e-01, -1.4022e-01,\n          7.6591e-03, -1.2560e-01],\n        [-1.1075e-01, -1.2373e-01,  1.5359e-01, -1.4498e-01, -6.9986e-02,\n         -1.6008e-01, -9.2502e-02, -1.6168e-01,  8.2846e-02,  1.0512e-01,\n          7.1551e-02, -1.4374e-01, -7.1147e-02, -1.3913e-01,  3.2874e-02,\n         -1.5775e-01,  1.0863e-03,  3.4910e-02,  1.0449e-02, -1.0328e-01,\n         -1.1055e-01,  1.4546e-01,  8.3666e-02,  1.0320e-01,  6.3148e-02,\n         -1.1457e-01,  1.0029e-01, -1.5339e-01, -1.9288e-02, -1.5859e-01,\n         -1.1248e-02,  1.1274e-01],\n        [-9.7344e-02, -4.3935e-02,  1.7955e-02, -1.4717e-01, -3.1158e-02,\n          9.4238e-02, -1.4524e-01,  1.5406e-01,  6.6423e-02, -1.0390e-02,\n          8.9091e-02, -1.7177e-01, -1.5977e-01,  7.4083e-02, -1.4067e-01,\n         -1.6872e-01,  1.8434e-02, -8.9528e-02,  9.8878e-02, -1.4904e-01,\n         -1.7279e-01, -6.0473e-02,  1.4163e-01, -9.8889e-02,  6.6622e-02,\n         -1.4529e-01,  4.3430e-02, -8.3541e-02, -8.1348e-02, -1.1191e-01,\n          6.0699e-02, -1.3190e-01],\n        [ 1.1314e-01,  3.8237e-02,  1.4921e-01, -1.4082e-01,  3.1423e-02,\n         -1.7655e-01,  1.6686e-01, -1.2946e-01,  1.4363e-01, -1.0934e-02,\n         -9.0426e-02, -1.3558e-01, -1.3949e-01,  8.8943e-02,  9.1437e-02,\n         -8.8612e-02, -1.7983e-02, -4.0288e-02,  8.8555e-03,  1.2373e-01,\n          1.7459e-01,  1.7103e-01, -3.5634e-02, -2.5016e-02, -3.2233e-02,\n          1.7277e-01,  1.7366e-01, -1.7061e-02,  1.0217e-02,  1.4365e-01,\n          1.3821e-01,  5.8020e-02],\n        [-1.2131e-01, -1.6482e-01,  3.1162e-02, -1.2064e-01,  5.2236e-02,\n          1.5712e-01, -6.6647e-02, -9.7080e-02, -1.3533e-01,  2.7033e-02,\n          1.6963e-02, -1.6072e-01,  1.5866e-01, -3.9250e-02,  6.2615e-02,\n         -1.4696e-02,  2.5718e-02,  6.9735e-03, -1.4024e-01,  1.3825e-01,\n         -1.5136e-01, -2.3738e-02,  8.0283e-03, -1.6385e-01, -1.4271e-01,\n          9.9037e-03, -1.3765e-01,  7.7195e-02,  1.7108e-03,  4.6541e-02,\n         -1.1911e-01,  5.6471e-02],\n        [ 1.4073e-01, -1.0717e-01,  7.7730e-02, -5.8569e-02,  9.6240e-02,\n          1.0207e-01,  1.4140e-01, -1.2805e-01,  1.1823e-01,  8.2572e-02,\n         -1.4702e-02, -9.8107e-02, -2.7028e-02,  7.6490e-02,  5.9901e-03,\n         -1.5204e-01,  3.0336e-02,  1.4787e-01,  8.5872e-02, -9.1709e-02,\n         -1.2762e-01,  4.5248e-03, -4.3380e-02, -1.2723e-01, -1.3041e-01,\n         -1.4801e-01,  1.5132e-01,  1.4926e-03, -6.3542e-02,  3.8310e-03,\n         -1.8093e-02, -3.5925e-03],\n        [ 1.6989e-01, -2.1031e-02, -1.0738e-01, -6.7090e-02,  6.4497e-02,\n         -9.9577e-02, -7.9509e-02, -1.2244e-01, -4.9135e-02, -4.8189e-02,\n          1.2114e-01,  6.0012e-02, -8.2291e-02,  1.2225e-01, -1.3945e-01,\n         -4.5781e-02, -7.3279e-02,  4.8775e-02,  1.7599e-01,  7.0739e-02,\n          6.7430e-02, -1.6775e-01,  1.5725e-01,  7.8081e-02, -1.0472e-01,\n         -1.2472e-01,  1.2443e-01,  1.0249e-03, -8.3938e-02, -3.5490e-02,\n          9.0537e-02, -1.1200e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0873,  0.1693, -0.2351,  0.1141,  0.1490, -0.2065, -0.1639,  0.0839],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2451,  0.2353,  0.1268,  0.0458,  0.0255, -0.0122, -0.1035, -0.2055,\n         -0.2136, -0.1412,  0.2173,  0.1842,  0.1625,  0.0892, -0.1551, -0.0119],\n        [-0.1226, -0.0267, -0.2136, -0.0663, -0.1578,  0.0759,  0.1757,  0.0963,\n          0.1618,  0.1863,  0.2033,  0.0814, -0.0226, -0.0681, -0.0105, -0.1573],\n        [ 0.1762,  0.1696,  0.0392,  0.0235,  0.1255,  0.0851, -0.1454, -0.0024,\n         -0.1724,  0.2249,  0.1490,  0.0172,  0.0160,  0.1768,  0.1810, -0.0333],\n        [ 0.0937, -0.1173,  0.0279,  0.1058,  0.2459,  0.0646,  0.1244, -0.0837,\n          0.1221,  0.0033,  0.0075, -0.0304, -0.0674, -0.1838, -0.2406, -0.0694],\n        [-0.0578,  0.2259,  0.1963, -0.0520, -0.0203,  0.0119,  0.1329, -0.0838,\n          0.2452,  0.0018,  0.1603, -0.0271,  0.0206, -0.1897,  0.0094, -0.1151],\n        [ 0.1592, -0.0508,  0.2136,  0.0954, -0.1844, -0.1135, -0.2479,  0.1045,\n          0.0842,  0.1022, -0.0374,  0.0379,  0.2402, -0.1060,  0.0232,  0.0269],\n        [ 0.1090,  0.1596, -0.0475, -0.1738,  0.0064, -0.1025,  0.0456,  0.1688,\n          0.0745, -0.0352, -0.0155, -0.1083, -0.0910, -0.0220, -0.1234, -0.1890],\n        [ 0.0503,  0.0856, -0.1508,  0.0040,  0.1805, -0.1748,  0.0522, -0.0582,\n         -0.0284, -0.1412,  0.1949, -0.1378, -0.2126, -0.0379, -0.0387,  0.2231]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1574], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2222, -0.0191, -0.2979, -0.2155, -0.3340,  0.2815,  0.0374,  0.3445]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2616,  0.1155,  0.2661,  0.2580, -0.1312,  0.2548, -0.0106, -0.3285],\n        [ 0.1680,  0.2764, -0.2619, -0.2887,  0.1912,  0.3190, -0.1032,  0.1595],\n        [-0.1754,  0.1484, -0.3022, -0.0217, -0.1354,  0.3344,  0.0590, -0.0223],\n        [ 0.2931, -0.1608, -0.3527, -0.0679,  0.2683, -0.3077, -0.0979,  0.1037],\n        [-0.1029,  0.3423,  0.3387,  0.1139,  0.0190,  0.3466, -0.2083, -0.0493],\n        [-0.3273, -0.2054,  0.2345, -0.2084, -0.2190, -0.3472, -0.0969, -0.0228],\n        [ 0.1922, -0.2569, -0.2858,  0.0696, -0.1754,  0.1266,  0.1018,  0.3123],\n        [-0.2767,  0.2062, -0.0892, -0.3102, -0.2702,  0.0904, -0.2317, -0.2201],\n        [-0.0254,  0.3045,  0.2377, -0.2263, -0.2884,  0.2604, -0.0060, -0.1160],\n        [-0.0692, -0.0400, -0.0514,  0.0248,  0.1541,  0.0197,  0.3087, -0.3340],\n        [ 0.0962, -0.1553, -0.0657,  0.1677,  0.0587,  0.0223, -0.3364,  0.0678],\n        [-0.2104, -0.2335,  0.1475,  0.1783,  0.2400, -0.2657,  0.1201,  0.3056],\n        [-0.2480,  0.0857,  0.2226, -0.2375, -0.3061, -0.2477,  0.1600,  0.1859],\n        [ 0.0859, -0.1429,  0.0215, -0.1127,  0.1606, -0.2514, -0.0785,  0.2399],\n        [ 0.0803, -0.0790,  0.0842,  0.1595, -0.0643, -0.2055,  0.0021, -0.1463],\n        [ 0.3322, -0.0288, -0.1141,  0.2762, -0.2496,  0.1259, -0.2294, -0.1531],\n        [-0.1978,  0.3091, -0.1163,  0.3083,  0.0977,  0.1104,  0.3382, -0.2166],\n        [ 0.3468, -0.2796, -0.2379,  0.0997,  0.2622, -0.3150, -0.1402,  0.2596],\n        [-0.1379,  0.2679,  0.1513,  0.1843,  0.1767,  0.2193, -0.1550, -0.2814],\n        [ 0.0243,  0.0659, -0.2628, -0.2390, -0.1731,  0.1824, -0.2489, -0.2617],\n        [ 0.0230,  0.2558, -0.0400,  0.1858, -0.2454,  0.3534, -0.1663,  0.3008],\n        [-0.2810, -0.3008, -0.0959, -0.2795, -0.1571, -0.2328,  0.0497,  0.1706],\n        [-0.1052, -0.0323,  0.0648,  0.1348,  0.2648, -0.1822, -0.2661,  0.0092],\n        [ 0.1562, -0.1318, -0.3221,  0.1935, -0.2509,  0.3047,  0.2281, -0.1003],\n        [-0.2795,  0.1854,  0.0668,  0.3068, -0.2060, -0.3226, -0.1963, -0.1313],\n        [-0.3529,  0.3479,  0.3296, -0.1837, -0.2330,  0.2792,  0.2859,  0.0858],\n        [ 0.0875, -0.2767, -0.1425,  0.0324, -0.2665,  0.0399,  0.3093, -0.1331],\n        [-0.1091, -0.1749,  0.1622, -0.3440,  0.0059,  0.2885, -0.2330, -0.2643],\n        [ 0.0318,  0.3228,  0.0859,  0.0859, -0.1648, -0.3459,  0.1949,  0.2128],\n        [ 0.1004,  0.2411, -0.3055, -0.3223,  0.1115,  0.2978, -0.0604,  0.1069],\n        [-0.0301,  0.2338, -0.2965,  0.3415,  0.3165,  0.1133,  0.2075, -0.1343],\n        [-0.0818,  0.0437, -0.3033, -0.1196,  0.2257,  0.0322, -0.0888,  0.2448]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 1.9240e-01,  2.0055e-01, -1.8670e-01, -1.9639e-01,  2.4146e-04,\n         7.3741e-02,  2.8947e-01,  3.1730e-01, -1.8892e-02,  1.9233e-01,\n         3.5008e-01,  2.6455e-02,  2.9911e-02,  9.4050e-02, -3.5140e-01,\n         1.9773e-01, -2.1997e-01, -1.7071e-01, -1.4049e-01, -3.2413e-01,\n         1.1930e-01, -3.3211e-02, -2.2526e-01, -3.3143e-01,  3.9640e-02,\n         5.3934e-02,  2.7623e-01, -1.9070e-01, -2.9609e-01, -3.6965e-02,\n         2.6658e-01, -3.8132e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 8.6611e-02,  7.8201e-02,  4.1277e-02,  3.2838e-02, -1.4374e-02,\n          6.4161e-03,  1.3377e-01, -5.3053e-02,  1.5418e-01,  1.2837e-02,\n          1.0794e-01, -1.5446e-01, -1.2520e-01, -9.2112e-02,  8.9429e-02,\n         -1.2695e-01, -1.2286e-01,  1.6076e-01,  9.9211e-02, -1.3312e-01,\n         -1.3187e-01, -6.4586e-02, -8.2836e-02, -7.5816e-02,  1.7029e-01,\n          3.9393e-02,  1.3371e-01,  5.4882e-03, -2.7362e-02, -8.3163e-02,\n         -8.9831e-02, -1.0292e-01],\n        [-9.9433e-02,  7.6601e-03, -5.9184e-02,  1.3752e-01,  1.2442e-01,\n          1.0064e-01, -1.3913e-01, -1.1732e-01,  9.7669e-03, -9.8955e-02,\n          1.6675e-01,  5.1232e-02, -1.7413e-01,  2.6627e-02, -9.4594e-02,\n          4.8197e-02, -9.8262e-02, -1.4911e-01,  1.4560e-01, -1.7115e-01,\n         -1.4259e-01, -1.8935e-02,  1.0588e-02, -7.3870e-02,  1.0717e-01,\n         -9.7806e-02,  5.0828e-02,  1.7515e-01, -1.5486e-01,  1.4859e-01,\n          8.8550e-02, -1.0919e-01],\n        [ 1.0970e-01, -9.1806e-02, -1.3004e-01, -5.6736e-02,  4.1861e-02,\n          7.6189e-03, -6.4452e-02,  1.5617e-01, -1.5173e-01,  9.3774e-02,\n          7.9039e-03,  1.3422e-01, -7.7325e-02,  4.9418e-02,  6.9449e-02,\n          6.8548e-02,  1.0432e-02,  3.6464e-03, -9.6771e-02,  5.4854e-02,\n          2.9499e-02,  1.0351e-01, -1.5313e-01,  8.7525e-02, -1.1676e-01,\n          2.2284e-02, -3.9546e-02,  2.9781e-02, -2.9196e-02, -9.6559e-02,\n         -1.1449e-01,  1.0682e-01],\n        [ 8.7363e-02,  1.2831e-01,  2.0116e-02,  1.7322e-01,  7.5032e-03,\n         -9.1473e-02, -1.7404e-01, -6.2425e-03, -1.5447e-01, -2.9442e-02,\n          5.1200e-03,  7.9978e-02,  4.5219e-02, -4.6229e-03, -5.1798e-02,\n          5.5459e-03, -1.4679e-01, -8.5950e-02, -1.5541e-01,  9.1110e-02,\n          1.2726e-01, -8.2890e-02,  2.1620e-02,  1.3998e-01, -1.3983e-01,\n         -1.2272e-01, -7.0529e-02, -6.5743e-02, -8.3668e-02, -2.6670e-02,\n          1.2276e-01, -1.3910e-01],\n        [ 9.9451e-02,  1.0203e-01,  6.4037e-02, -2.2224e-02, -8.9236e-03,\n         -1.2608e-01, -4.5495e-03,  1.2460e-01, -2.2810e-02, -6.5105e-02,\n          1.4328e-01, -7.4637e-02, -1.1085e-01, -1.2692e-01, -8.0957e-02,\n         -1.4839e-01, -1.1836e-01, -1.2752e-01,  7.8765e-02, -1.7641e-04,\n         -1.4405e-02,  7.2792e-03, -2.7539e-02,  1.6090e-01,  1.2655e-01,\n         -1.2265e-01, -6.0331e-02,  6.7394e-02,  1.4988e-01, -1.3900e-02,\n          8.6775e-02,  1.3701e-01],\n        [-1.4588e-01,  2.5435e-03, -6.7632e-02, -8.4965e-02,  1.0226e-01,\n          6.0009e-02, -6.1690e-02, -3.5949e-02, -9.2328e-02,  9.9018e-02,\n         -1.4077e-01,  2.6129e-02,  8.1153e-02,  1.3947e-01,  1.2386e-01,\n          1.5867e-01, -8.6666e-02,  1.6951e-01, -1.5355e-01, -1.6298e-01,\n          1.2119e-01, -7.7740e-03, -1.5850e-01, -3.0799e-02,  7.7927e-02,\n         -1.3992e-01,  3.4627e-02, -6.2818e-03,  1.5526e-01, -9.2611e-02,\n          1.5492e-01, -9.5410e-02],\n        [-6.4120e-02,  1.1209e-01,  1.6203e-01, -7.8878e-02, -1.1037e-01,\n         -2.1803e-02,  1.2543e-01, -3.7821e-02,  5.0641e-02, -4.6467e-02,\n         -7.2591e-02, -1.6138e-01, -1.7455e-01,  1.0634e-01, -1.5424e-01,\n         -8.1518e-02, -3.0562e-02, -1.5103e-01,  1.9558e-02,  4.3030e-02,\n          7.3042e-02, -3.9515e-02, -1.7476e-01,  1.6267e-01, -1.1237e-01,\n          1.6542e-01, -1.6029e-01, -5.4237e-02,  1.5341e-01,  1.9926e-02,\n          7.6459e-02, -1.6327e-01],\n        [-1.0286e-01,  1.5602e-01, -1.2963e-01,  1.7669e-01,  1.4328e-01,\n         -2.5977e-02, -1.1166e-01, -4.1758e-02, -1.2962e-01,  1.0958e-01,\n         -1.4714e-01,  1.1763e-01, -1.2303e-01,  1.0030e-01, -1.2914e-01,\n         -1.5833e-01,  2.3538e-02, -9.8424e-02, -1.4069e-01,  1.5535e-01,\n         -1.3344e-01, -8.1377e-02,  6.6709e-02,  1.5023e-01, -3.5884e-02,\n          1.0423e-01, -5.7815e-02, -1.7425e-01,  1.6749e-01,  3.8179e-02,\n         -1.5108e-01,  2.3565e-02],\n        [-8.8642e-02,  1.1349e-01, -1.1509e-01,  6.5212e-03,  1.0357e-01,\n          1.4623e-02,  1.2706e-01,  2.5378e-02, -1.7650e-01,  6.9905e-02,\n          1.4525e-01, -9.4016e-03, -9.4908e-02,  1.4506e-01,  4.0810e-02,\n          7.1367e-02,  9.6356e-02, -4.9218e-02,  5.1999e-02, -1.0225e-01,\n         -1.2989e-01,  5.6758e-02,  1.2099e-01,  4.0166e-02, -1.0795e-01,\n          5.3989e-02,  1.6192e-01,  1.7075e-01,  1.0271e-01,  1.4922e-02,\n         -9.6264e-02, -3.5189e-02],\n        [-5.0781e-02,  7.4621e-02, -6.7816e-02,  1.3920e-01, -1.7329e-01,\n          1.1530e-01,  7.6238e-02, -1.1104e-01,  1.3153e-01,  1.3650e-01,\n         -7.7587e-02, -1.0138e-01,  1.7108e-02,  1.0454e-01,  1.7610e-01,\n         -9.5688e-02,  6.0527e-02,  1.6160e-01,  5.1730e-02, -8.0170e-02,\n          5.7518e-02,  7.8072e-02, -1.3205e-01,  3.5164e-02, -1.7878e-02,\n          1.4764e-01, -1.1351e-01, -1.6400e-01, -1.0208e-01, -1.4022e-01,\n          7.6591e-03, -1.2560e-01],\n        [-1.1075e-01, -1.2373e-01,  1.5359e-01, -1.4498e-01, -6.9986e-02,\n         -1.6008e-01, -9.2502e-02, -1.6168e-01,  8.2846e-02,  1.0512e-01,\n          7.1551e-02, -1.4374e-01, -7.1147e-02, -1.3913e-01,  3.2874e-02,\n         -1.5775e-01,  1.0863e-03,  3.4910e-02,  1.0449e-02, -1.0328e-01,\n         -1.1055e-01,  1.4546e-01,  8.3666e-02,  1.0320e-01,  6.3148e-02,\n         -1.1457e-01,  1.0029e-01, -1.5339e-01, -1.9288e-02, -1.5859e-01,\n         -1.1248e-02,  1.1274e-01],\n        [-9.7344e-02, -4.3935e-02,  1.7955e-02, -1.4717e-01, -3.1158e-02,\n          9.4238e-02, -1.4524e-01,  1.5406e-01,  6.6423e-02, -1.0390e-02,\n          8.9091e-02, -1.7177e-01, -1.5977e-01,  7.4083e-02, -1.4067e-01,\n         -1.6872e-01,  1.8434e-02, -8.9528e-02,  9.8878e-02, -1.4904e-01,\n         -1.7279e-01, -6.0473e-02,  1.4163e-01, -9.8889e-02,  6.6622e-02,\n         -1.4529e-01,  4.3430e-02, -8.3541e-02, -8.1348e-02, -1.1191e-01,\n          6.0699e-02, -1.3190e-01],\n        [ 1.1314e-01,  3.8237e-02,  1.4921e-01, -1.4082e-01,  3.1423e-02,\n         -1.7655e-01,  1.6686e-01, -1.2946e-01,  1.4363e-01, -1.0934e-02,\n         -9.0426e-02, -1.3558e-01, -1.3949e-01,  8.8943e-02,  9.1437e-02,\n         -8.8612e-02, -1.7983e-02, -4.0288e-02,  8.8555e-03,  1.2373e-01,\n          1.7459e-01,  1.7103e-01, -3.5634e-02, -2.5016e-02, -3.2233e-02,\n          1.7277e-01,  1.7366e-01, -1.7061e-02,  1.0217e-02,  1.4365e-01,\n          1.3821e-01,  5.8020e-02],\n        [-1.2131e-01, -1.6482e-01,  3.1162e-02, -1.2064e-01,  5.2236e-02,\n          1.5712e-01, -6.6647e-02, -9.7080e-02, -1.3533e-01,  2.7033e-02,\n          1.6963e-02, -1.6072e-01,  1.5866e-01, -3.9250e-02,  6.2615e-02,\n         -1.4696e-02,  2.5718e-02,  6.9735e-03, -1.4024e-01,  1.3825e-01,\n         -1.5136e-01, -2.3738e-02,  8.0283e-03, -1.6385e-01, -1.4271e-01,\n          9.9037e-03, -1.3765e-01,  7.7195e-02,  1.7108e-03,  4.6541e-02,\n         -1.1911e-01,  5.6471e-02],\n        [ 1.4073e-01, -1.0717e-01,  7.7730e-02, -5.8569e-02,  9.6240e-02,\n          1.0207e-01,  1.4140e-01, -1.2805e-01,  1.1823e-01,  8.2572e-02,\n         -1.4702e-02, -9.8107e-02, -2.7028e-02,  7.6490e-02,  5.9901e-03,\n         -1.5204e-01,  3.0336e-02,  1.4787e-01,  8.5872e-02, -9.1709e-02,\n         -1.2762e-01,  4.5248e-03, -4.3380e-02, -1.2723e-01, -1.3041e-01,\n         -1.4801e-01,  1.5132e-01,  1.4926e-03, -6.3542e-02,  3.8310e-03,\n         -1.8093e-02, -3.5925e-03],\n        [ 1.6989e-01, -2.1031e-02, -1.0738e-01, -6.7090e-02,  6.4497e-02,\n         -9.9577e-02, -7.9509e-02, -1.2244e-01, -4.9135e-02, -4.8189e-02,\n          1.2114e-01,  6.0012e-02, -8.2291e-02,  1.2225e-01, -1.3945e-01,\n         -4.5781e-02, -7.3279e-02,  4.8775e-02,  1.7599e-01,  7.0739e-02,\n          6.7430e-02, -1.6775e-01,  1.5725e-01,  7.8081e-02, -1.0472e-01,\n         -1.2472e-01,  1.2443e-01,  1.0249e-03, -8.3938e-02, -3.5490e-02,\n          9.0537e-02, -1.1200e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1736, -0.0608, -0.0132,  0.0794,  0.1063,  0.1544, -0.0186, -0.0110,\n        -0.1307,  0.1681, -0.0466, -0.1543, -0.1461, -0.0899,  0.0101, -0.0904],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2451,  0.2353,  0.1268,  0.0458,  0.0255, -0.0122, -0.1035, -0.2055,\n         -0.2136, -0.1412,  0.2173,  0.1842,  0.1625,  0.0892, -0.1551, -0.0119],\n        [-0.1226, -0.0267, -0.2136, -0.0663, -0.1578,  0.0759,  0.1757,  0.0963,\n          0.1618,  0.1863,  0.2033,  0.0814, -0.0226, -0.0681, -0.0105, -0.1573],\n        [ 0.1762,  0.1696,  0.0392,  0.0235,  0.1255,  0.0851, -0.1454, -0.0024,\n         -0.1724,  0.2249,  0.1490,  0.0172,  0.0160,  0.1768,  0.1810, -0.0333],\n        [ 0.0937, -0.1173,  0.0279,  0.1058,  0.2459,  0.0646,  0.1244, -0.0837,\n          0.1221,  0.0033,  0.0075, -0.0304, -0.0674, -0.1838, -0.2406, -0.0694],\n        [-0.0578,  0.2259,  0.1963, -0.0520, -0.0203,  0.0119,  0.1329, -0.0838,\n          0.2452,  0.0018,  0.1603, -0.0271,  0.0206, -0.1897,  0.0094, -0.1151],\n        [ 0.1592, -0.0508,  0.2136,  0.0954, -0.1844, -0.1135, -0.2479,  0.1045,\n          0.0842,  0.1022, -0.0374,  0.0379,  0.2402, -0.1060,  0.0232,  0.0269],\n        [ 0.1090,  0.1596, -0.0475, -0.1738,  0.0064, -0.1025,  0.0456,  0.1688,\n          0.0745, -0.0352, -0.0155, -0.1083, -0.0910, -0.0220, -0.1234, -0.1890],\n        [ 0.0503,  0.0856, -0.1508,  0.0040,  0.1805, -0.1748,  0.0522, -0.0582,\n         -0.0284, -0.1412,  0.1949, -0.1378, -0.2126, -0.0379, -0.0387,  0.2231]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0873,  0.1693, -0.2351,  0.1141,  0.1490, -0.2065, -0.1639,  0.0839],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2222, -0.0191, -0.2979, -0.2155, -0.3340,  0.2815,  0.0374,  0.3445]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1574], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x1032cbe80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x17c22a560>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s131130000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s131130000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}