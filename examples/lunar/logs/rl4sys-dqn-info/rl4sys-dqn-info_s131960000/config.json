{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s131960000"
    },
    "q_lr":	0.0005,
    "seed":	131960000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x3068d63b0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 1.2058e-01, -2.1669e-01, -1.0418e-01, -8.5956e-02,  2.0304e-01,\n         1.6191e-01, -2.1941e-01,  1.7515e-02, -3.1748e-01, -1.8800e-01,\n        -2.4584e-01,  2.1453e-01,  1.4879e-01, -1.2042e-03, -2.0722e-01,\n         6.1932e-02,  3.5094e-02, -4.4795e-02, -4.8839e-02,  1.8752e-01,\n        -1.4523e-02, -7.1651e-02,  2.9788e-02, -3.0138e-01,  1.3737e-02,\n        -1.2929e-01,  9.8841e-02,  1.3247e-04,  3.3807e-01,  3.5152e-01,\n        -9.4590e-03,  4.4478e-04], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 2.0034e-01, -1.9385e-01, -1.7386e-01,  2.7334e-01,  2.9830e-01,\n         -1.9512e-01, -4.9318e-02, -3.5128e-01],\n        [-1.2602e-01,  3.6176e-03,  6.4967e-02,  2.1927e-01,  3.0329e-01,\n         -9.6196e-02, -2.9706e-01, -2.7890e-01],\n        [-2.7208e-01,  3.3777e-01, -2.7131e-01, -1.5728e-01, -2.4323e-01,\n          2.4120e-01, -1.5875e-01, -1.7410e-01],\n        [ 5.5062e-03,  1.3623e-01, -2.4944e-02,  3.1906e-01, -2.4982e-01,\n         -1.2080e-01, -6.8262e-02,  2.4897e-01],\n        [-2.9815e-01, -6.5904e-02, -1.5295e-01,  3.3720e-01,  6.1002e-03,\n          3.1327e-01,  3.3643e-01,  1.7459e-01],\n        [-1.6230e-01, -2.0120e-01,  1.9765e-01,  3.4896e-01, -3.1588e-01,\n          2.4476e-02,  5.3741e-02, -9.5940e-02],\n        [-8.4945e-02,  3.2091e-01, -2.2303e-01, -2.0373e-01, -5.2500e-03,\n          3.0739e-01, -1.7227e-01,  9.5927e-02],\n        [-5.8505e-02, -1.5144e-01,  3.0740e-01,  2.1546e-01,  1.1461e-01,\n          1.1964e-01,  1.5876e-01, -3.1516e-01],\n        [-1.7820e-01,  2.3959e-01,  1.2225e-01,  2.9377e-01, -2.7654e-01,\n          7.5187e-02, -1.6982e-01,  1.5411e-01],\n        [-2.8416e-01, -2.0169e-01, -3.8210e-02, -7.4537e-02,  2.4536e-01,\n          3.3624e-01,  1.5908e-01,  2.8641e-01],\n        [-1.3874e-01, -5.3484e-02, -2.4219e-02, -2.1323e-02, -1.3092e-01,\n          2.5772e-01,  1.9160e-01,  2.6643e-02],\n        [-2.9409e-01,  2.1467e-01, -2.1256e-01, -4.5817e-02,  1.6369e-01,\n          6.4013e-02, -7.2336e-02,  3.0676e-02],\n        [ 7.3374e-02,  5.9823e-02, -4.5566e-02, -5.4450e-02,  3.3635e-01,\n         -1.8858e-01, -1.4313e-02,  3.4802e-01],\n        [-1.6532e-01, -3.9980e-02, -1.7333e-01, -1.1155e-02,  3.3391e-01,\n          1.1740e-01,  3.3866e-01, -1.2692e-01],\n        [-4.7989e-02, -6.0814e-02, -3.2156e-01, -4.3105e-02, -1.8313e-01,\n         -1.8736e-01, -3.1616e-01, -1.5480e-01],\n        [ 8.3695e-02,  3.0180e-01,  7.7458e-02, -5.5606e-02, -1.8241e-01,\n          4.9403e-02, -2.2962e-02, -3.5322e-01],\n        [-2.0594e-01, -2.2758e-01, -2.1806e-01,  2.2224e-01, -1.1332e-01,\n          1.3660e-01,  2.7009e-01,  2.2836e-01],\n        [ 1.5000e-01,  1.7171e-01,  1.0965e-01,  2.8549e-01, -9.7671e-02,\n          1.2873e-01,  2.6482e-01, -1.5254e-01],\n        [ 7.9711e-02, -1.6929e-01,  7.7400e-02,  8.7182e-02,  2.8375e-01,\n          2.7993e-02, -9.1865e-02,  5.1666e-02],\n        [-7.0727e-02,  1.0221e-01, -1.6487e-01, -2.1442e-01,  3.3386e-01,\n          2.3806e-01, -2.1268e-01,  1.9925e-01],\n        [ 3.8337e-02,  9.5454e-02,  5.7380e-02,  4.0145e-03,  2.1952e-01,\n         -6.6292e-02,  2.4863e-01,  2.2644e-01],\n        [ 3.4626e-01,  9.6182e-02, -2.3990e-02, -3.4314e-01,  1.8973e-01,\n         -2.1779e-01,  3.0374e-01, -2.2305e-01],\n        [ 7.7760e-02, -2.9166e-02,  9.3083e-02,  1.9126e-01, -2.5004e-01,\n          2.1953e-01,  5.4681e-02,  1.9503e-01],\n        [-1.9687e-02, -3.3037e-01, -2.4782e-04,  8.7376e-02,  1.7374e-01,\n         -1.9679e-01, -3.4050e-01, -1.6408e-01],\n        [ 3.4797e-01, -2.0657e-01,  2.2450e-01,  3.5337e-01,  2.3719e-02,\n          2.0490e-01,  1.8764e-01, -9.7692e-02],\n        [-2.7794e-01, -3.4044e-01,  1.5394e-01,  4.4175e-02,  1.0480e-01,\n         -1.3136e-01, -1.3436e-01, -2.8738e-01],\n        [ 3.3445e-01, -1.9835e-01,  2.7425e-01, -3.3465e-01,  2.7723e-01,\n         -3.1366e-01,  5.3437e-02, -2.5713e-01],\n        [ 2.5028e-01, -2.3505e-01,  6.8617e-02,  7.6686e-02, -7.0726e-02,\n         -7.2201e-02,  1.2294e-01, -1.9402e-01],\n        [ 3.7695e-02, -2.6216e-01, -1.4541e-01,  2.4739e-01,  2.6310e-01,\n          1.0567e-01, -4.5728e-03,  1.9732e-01],\n        [-3.0626e-01, -1.2502e-01, -4.0056e-02, -1.0454e-01, -1.2683e-02,\n         -2.3062e-01, -1.6010e-01,  9.4313e-02],\n        [ 2.5934e-01,  3.2925e-01, -9.8783e-02,  1.6055e-01, -2.3505e-01,\n          1.5574e-01, -1.6057e-01, -1.9098e-01],\n        [-2.0498e-01, -3.8736e-02,  2.3974e-01,  2.4801e-01,  3.2340e-01,\n         -2.2671e-01, -8.0440e-02, -3.4487e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1515, -0.0316, -0.1687, -0.0778,  0.0591,  0.1716, -0.0443, -0.1504,\n        -0.1501,  0.0857, -0.0710, -0.1682,  0.1045,  0.0838, -0.1747, -0.0982],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-6.5604e-02, -5.2484e-02,  1.6687e-01,  6.2830e-02, -7.1184e-03,\n         -1.5873e-02, -1.3830e-01, -5.1606e-02,  8.5592e-02,  4.6470e-02,\n          1.6162e-02, -1.3098e-01, -6.9625e-02, -8.3637e-02, -8.9897e-02,\n         -1.5285e-01,  1.0896e-01,  6.4355e-02,  5.6366e-02,  1.4069e-01,\n         -2.4644e-02,  1.4048e-01, -3.8163e-02, -1.1176e-01,  8.1713e-02,\n         -3.8508e-02,  6.2907e-02,  1.7299e-01,  1.3306e-01,  1.6047e-01,\n         -1.1386e-01, -3.9037e-02],\n        [-1.2744e-01,  5.6076e-03,  8.3889e-02, -1.3278e-02, -1.3704e-01,\n         -9.0482e-02,  2.2594e-02,  1.6137e-01, -7.1581e-02,  1.4406e-04,\n          1.2303e-01,  1.0590e-01,  6.8817e-02,  9.2087e-02,  4.5848e-02,\n         -1.7343e-01, -8.7304e-02, -4.4352e-02,  1.1659e-01,  8.8527e-02,\n          8.5485e-02,  8.7703e-02, -6.0650e-02, -9.4391e-02,  9.7448e-02,\n         -8.9033e-02,  1.4993e-01,  1.7419e-01,  9.2244e-02, -7.9551e-02,\n         -1.1759e-01,  3.9437e-03],\n        [ 6.8287e-02,  1.3553e-01,  1.0869e-01,  9.1277e-02,  1.1923e-01,\n          6.8108e-02,  3.9338e-02, -1.0921e-02,  1.3625e-01, -7.8087e-02,\n          3.2555e-02, -8.9273e-02, -8.0089e-02,  5.3359e-02,  1.3450e-01,\n         -3.7695e-02,  1.5612e-01,  1.1309e-01, -1.4361e-01, -1.0205e-01,\n          4.5997e-02, -9.3647e-02,  3.9551e-02,  5.4341e-02,  1.4952e-01,\n          3.4068e-02, -2.2513e-02, -1.4058e-01,  1.0747e-02, -2.1858e-02,\n         -1.7355e-01, -3.5422e-02],\n        [ 3.3182e-02, -5.1680e-02,  1.9516e-02,  1.2502e-01, -7.0573e-02,\n         -3.1200e-02,  8.1950e-02, -9.7996e-02, -1.4222e-01,  1.3960e-01,\n          4.8926e-02, -1.4215e-02, -1.2475e-01,  2.3344e-02,  5.9827e-02,\n          7.7167e-02, -1.5922e-01, -1.6733e-01, -1.3163e-01,  1.4213e-01,\n          1.5911e-01,  7.6382e-03, -1.1488e-02,  4.9095e-02,  5.3667e-02,\n          1.1488e-01, -4.5494e-02, -1.8702e-02, -1.1956e-02, -1.1240e-02,\n          1.2930e-01,  8.3392e-02],\n        [-1.2399e-01,  1.7032e-01, -8.2854e-02, -1.7018e-01, -1.3417e-01,\n         -9.7497e-02, -6.9372e-02,  1.1903e-01, -1.7364e-01, -1.3409e-01,\n          8.7388e-02,  6.6198e-04, -2.1753e-02, -1.2769e-01, -3.8988e-03,\n         -2.3480e-03,  1.1983e-01, -3.9066e-02,  4.0787e-03,  1.3216e-01,\n          4.5939e-02, -1.5735e-01,  1.2763e-01, -1.2054e-01, -6.7300e-02,\n         -1.2993e-01, -5.1001e-02, -6.9745e-02,  1.4849e-01, -1.0828e-01,\n          1.2074e-01, -3.9114e-02],\n        [-1.2559e-01,  1.6544e-02, -9.5606e-02,  3.8967e-02, -6.2516e-02,\n          1.6897e-01, -5.8811e-02, -2.5116e-02, -5.2229e-02, -8.9595e-02,\n         -9.9164e-02,  1.7181e-01, -3.5030e-02,  1.7318e-01, -3.0202e-02,\n          1.5775e-01, -1.4950e-02, -8.1951e-02,  1.4454e-01, -1.4915e-01,\n         -1.0232e-01,  1.6061e-01,  3.9151e-02,  1.1644e-01,  1.7493e-03,\n         -9.2127e-02,  9.3049e-02, -1.1244e-01, -3.5455e-02, -1.7604e-01,\n         -2.9062e-02, -1.0788e-01],\n        [-3.2445e-02,  4.2206e-03,  1.4426e-01,  1.2812e-01,  1.3290e-01,\n         -1.3415e-01,  1.4667e-01,  3.4835e-02, -3.9581e-02, -1.5826e-01,\n          1.4095e-01, -2.6799e-02, -1.1431e-02,  7.5292e-02,  3.9058e-02,\n         -1.3448e-01,  2.5727e-02,  8.6182e-02, -8.4200e-02,  9.4299e-02,\n          7.7791e-02,  1.5858e-01, -1.6231e-02, -1.6456e-01, -1.5716e-02,\n          1.7446e-01,  1.5541e-01,  1.4293e-01,  1.4636e-01,  1.4609e-01,\n         -7.4173e-02, -1.0383e-01],\n        [ 7.0929e-02, -8.2777e-02,  2.9905e-03,  4.4442e-02,  1.2064e-01,\n          1.0587e-01,  9.2806e-02,  1.9524e-02, -1.5302e-01,  5.2895e-02,\n         -8.8210e-02,  1.7559e-02,  9.3320e-02, -1.3602e-01, -8.1931e-02,\n          7.2104e-02, -1.4684e-01,  1.7517e-01, -6.2629e-02,  4.2843e-02,\n         -3.9561e-02, -6.2119e-02,  2.2292e-02,  1.5386e-02, -8.0241e-04,\n          5.7326e-02,  1.2011e-01, -6.8501e-03,  1.1765e-01, -1.0851e-01,\n         -2.9637e-03, -5.6539e-02],\n        [-2.5802e-02,  3.3259e-02,  2.6779e-02, -3.8598e-02, -8.3153e-02,\n         -2.9668e-02, -2.3980e-02, -9.7806e-02, -1.2535e-02, -7.3604e-02,\n          4.8801e-02,  7.8806e-02,  1.1505e-02,  5.3109e-03,  2.2700e-02,\n         -1.6000e-01, -1.2844e-01,  1.1805e-01, -6.7128e-02,  8.2744e-02,\n         -1.0689e-01,  1.9275e-02,  1.3349e-01, -1.3735e-01,  1.1322e-01,\n         -7.5032e-02, -6.6721e-02,  8.9071e-02, -1.3560e-01, -4.9894e-02,\n         -9.2772e-02, -5.0794e-02],\n        [ 3.0585e-02, -1.2895e-01,  3.7107e-02,  1.2109e-01,  1.9049e-02,\n         -9.5930e-02,  1.6720e-01, -5.3714e-02,  7.5100e-02, -9.7035e-02,\n         -1.8575e-03,  5.2561e-02, -1.7410e-01,  5.1815e-03, -3.8010e-02,\n          1.4707e-01, -1.0238e-01, -5.5709e-02,  1.3860e-01,  4.9894e-03,\n         -8.5984e-02,  6.5437e-02, -7.8695e-02, -1.3613e-01, -7.3067e-02,\n         -1.2295e-01,  2.7655e-02, -7.8261e-02, -1.4948e-03,  7.4249e-02,\n         -1.0220e-01,  3.0849e-02],\n        [-3.0433e-02,  5.6474e-03,  2.2659e-02,  1.5892e-01,  3.1030e-02,\n         -1.5439e-01,  2.5624e-02,  2.4154e-02,  1.6491e-01,  1.7524e-01,\n         -3.8733e-02, -1.5300e-02,  1.2360e-01,  1.1103e-01,  1.5826e-03,\n         -1.7640e-01, -1.3970e-01, -4.1429e-02,  7.0857e-02,  3.8094e-02,\n          7.1767e-02, -1.2007e-01, -1.3810e-01, -7.7649e-02, -1.2239e-01,\n          1.3351e-01,  6.4942e-04, -7.8591e-02,  5.6202e-02, -1.6422e-01,\n         -1.5424e-01, -5.4815e-02],\n        [-1.4279e-01,  6.9861e-02,  1.4421e-03,  6.1561e-02, -1.0070e-01,\n         -4.4153e-02, -4.9709e-02,  1.2297e-01,  4.7822e-02, -1.3180e-01,\n         -1.6925e-02, -7.3678e-02, -1.3080e-01, -6.1306e-02, -2.9820e-02,\n         -6.1817e-02, -1.3340e-01,  4.1132e-03, -4.8535e-02,  3.2745e-02,\n          4.6043e-02, -1.5871e-02,  6.4722e-02, -1.0467e-01,  5.2724e-03,\n         -1.2666e-01, -1.5932e-01,  6.4203e-02, -7.7492e-02,  7.3191e-02,\n          3.7668e-02,  8.1300e-02],\n        [ 1.3207e-02,  1.4567e-01,  1.7223e-01,  1.3597e-03, -1.5404e-01,\n          1.1573e-01,  1.0907e-01,  1.1516e-01,  9.9147e-02,  1.5465e-01,\n          1.6627e-01, -1.6801e-01,  5.6351e-02,  4.0004e-02, -1.5234e-01,\n         -1.5332e-01,  7.2275e-02, -4.7570e-02,  6.1785e-02,  1.7640e-01,\n          1.4084e-03, -2.6128e-02, -8.0339e-02, -1.3424e-01, -3.8855e-02,\n         -4.8133e-02,  9.0855e-02, -1.0225e-01,  1.4366e-01, -1.1304e-01,\n         -9.2934e-02, -1.0513e-01],\n        [-9.3023e-02,  1.1032e-02,  6.2878e-02, -5.6595e-02, -1.3673e-01,\n         -1.4245e-01, -4.9766e-02, -1.6609e-01,  4.3021e-02, -1.4501e-01,\n         -1.5147e-01, -1.5503e-01, -4.6544e-02,  4.0186e-03,  1.0899e-01,\n         -9.9983e-02, -1.3960e-01, -1.0107e-01, -3.5525e-02, -4.0896e-02,\n          8.7117e-02,  3.7963e-02,  9.6486e-02, -6.8615e-02,  9.9698e-02,\n          1.7297e-01, -9.7819e-02, -2.6613e-02, -1.7197e-01, -1.8923e-02,\n          8.8739e-02, -7.6768e-02],\n        [-1.5589e-01,  6.9288e-02,  1.6958e-01,  2.7476e-02,  1.4157e-01,\n          1.6631e-01,  9.4456e-03,  1.6660e-01,  4.9198e-02, -5.6034e-02,\n          7.5870e-02,  3.4623e-02, -9.7387e-02, -9.7991e-03,  1.2301e-01,\n         -8.2595e-02, -9.7635e-02, -1.1686e-01,  3.0699e-03,  7.5912e-02,\n          6.8754e-02, -7.6349e-02,  1.7101e-01,  6.8881e-02,  1.0462e-01,\n          1.5687e-01, -9.7018e-02, -1.1751e-01,  6.5073e-02,  2.5998e-02,\n         -7.5693e-02, -6.9412e-02],\n        [ 8.4133e-02, -6.0429e-02,  5.3310e-02,  7.5307e-02,  1.5135e-01,\n          1.0878e-01,  6.6056e-02,  5.7093e-02,  1.2865e-01, -6.1371e-02,\n         -4.4438e-02,  2.2910e-02,  5.7278e-02,  4.3934e-02,  1.2271e-01,\n         -9.0084e-03, -2.6354e-02, -1.4182e-01, -1.4460e-01, -1.6465e-01,\n          4.9577e-02,  2.3369e-02,  7.0550e-02,  1.2435e-01,  1.1404e-01,\n         -1.4433e-01, -5.7346e-02,  1.0121e-01, -1.0468e-01,  3.3238e-02,\n          1.1231e-01,  5.0472e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1739,  0.2432,  0.0907, -0.1489, -0.1588,  0.0077,  0.1592,  0.0225],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1450,  0.1420, -0.1907,  0.0130,  0.0263, -0.2224,  0.0484, -0.0325,\n         -0.0265, -0.1023, -0.1422, -0.1048, -0.1266,  0.0216, -0.0685,  0.2164],\n        [-0.0576, -0.1096,  0.0511, -0.2004, -0.2265, -0.2041, -0.0556,  0.0642,\n          0.0224, -0.1746, -0.2104, -0.1495, -0.0475,  0.0517, -0.2457,  0.0621],\n        [ 0.1070, -0.1107, -0.0637, -0.2025, -0.0271, -0.1299, -0.1325, -0.2127,\n          0.1175, -0.1753,  0.1180, -0.0406, -0.2057, -0.0248,  0.1139,  0.1170],\n        [ 0.0024,  0.0144,  0.1629, -0.0061,  0.2480, -0.1591,  0.2365, -0.0848,\n          0.0436,  0.1301,  0.2281, -0.0877,  0.0554,  0.1271, -0.1671, -0.1318],\n        [-0.2313, -0.1781, -0.1382, -0.0219, -0.0786,  0.2413, -0.1808,  0.2435,\n          0.2195, -0.0055,  0.2331, -0.1360,  0.1831, -0.1290, -0.1433,  0.0364],\n        [ 0.0223,  0.1896, -0.1529, -0.1600, -0.2228, -0.0957, -0.0140, -0.0532,\n         -0.2360, -0.0348,  0.1680, -0.1479,  0.1916,  0.1933, -0.0779, -0.1058],\n        [ 0.0198, -0.2109, -0.0494,  0.1843,  0.0411, -0.2117, -0.1151,  0.2298,\n         -0.2156,  0.2004, -0.1844,  0.2209,  0.0232,  0.0529,  0.2328,  0.1568],\n        [-0.2249,  0.1477,  0.2185,  0.1199,  0.2255,  0.1634,  0.0419,  0.2323,\n          0.0845,  0.0676,  0.0669, -0.1839, -0.1315,  0.1885, -0.1397, -0.1720]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2302], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2994, -0.0101,  0.0376,  0.3009,  0.2297, -0.1113,  0.1744, -0.1747]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 2.0034e-01, -1.9385e-01, -1.7386e-01,  2.7334e-01,  2.9830e-01,\n         -1.9512e-01, -4.9318e-02, -3.5128e-01],\n        [-1.2602e-01,  3.6176e-03,  6.4967e-02,  2.1927e-01,  3.0329e-01,\n         -9.6196e-02, -2.9706e-01, -2.7890e-01],\n        [-2.7208e-01,  3.3777e-01, -2.7131e-01, -1.5728e-01, -2.4323e-01,\n          2.4120e-01, -1.5875e-01, -1.7410e-01],\n        [ 5.5062e-03,  1.3623e-01, -2.4944e-02,  3.1906e-01, -2.4982e-01,\n         -1.2080e-01, -6.8262e-02,  2.4897e-01],\n        [-2.9815e-01, -6.5904e-02, -1.5295e-01,  3.3720e-01,  6.1002e-03,\n          3.1327e-01,  3.3643e-01,  1.7459e-01],\n        [-1.6230e-01, -2.0120e-01,  1.9765e-01,  3.4896e-01, -3.1588e-01,\n          2.4476e-02,  5.3741e-02, -9.5940e-02],\n        [-8.4945e-02,  3.2091e-01, -2.2303e-01, -2.0373e-01, -5.2500e-03,\n          3.0739e-01, -1.7227e-01,  9.5927e-02],\n        [-5.8505e-02, -1.5144e-01,  3.0740e-01,  2.1546e-01,  1.1461e-01,\n          1.1964e-01,  1.5876e-01, -3.1516e-01],\n        [-1.7820e-01,  2.3959e-01,  1.2225e-01,  2.9377e-01, -2.7654e-01,\n          7.5187e-02, -1.6982e-01,  1.5411e-01],\n        [-2.8416e-01, -2.0169e-01, -3.8210e-02, -7.4537e-02,  2.4536e-01,\n          3.3624e-01,  1.5908e-01,  2.8641e-01],\n        [-1.3874e-01, -5.3484e-02, -2.4219e-02, -2.1323e-02, -1.3092e-01,\n          2.5772e-01,  1.9160e-01,  2.6643e-02],\n        [-2.9409e-01,  2.1467e-01, -2.1256e-01, -4.5817e-02,  1.6369e-01,\n          6.4013e-02, -7.2336e-02,  3.0676e-02],\n        [ 7.3374e-02,  5.9823e-02, -4.5566e-02, -5.4450e-02,  3.3635e-01,\n         -1.8858e-01, -1.4313e-02,  3.4802e-01],\n        [-1.6532e-01, -3.9980e-02, -1.7333e-01, -1.1155e-02,  3.3391e-01,\n          1.1740e-01,  3.3866e-01, -1.2692e-01],\n        [-4.7989e-02, -6.0814e-02, -3.2156e-01, -4.3105e-02, -1.8313e-01,\n         -1.8736e-01, -3.1616e-01, -1.5480e-01],\n        [ 8.3695e-02,  3.0180e-01,  7.7458e-02, -5.5606e-02, -1.8241e-01,\n          4.9403e-02, -2.2962e-02, -3.5322e-01],\n        [-2.0594e-01, -2.2758e-01, -2.1806e-01,  2.2224e-01, -1.1332e-01,\n          1.3660e-01,  2.7009e-01,  2.2836e-01],\n        [ 1.5000e-01,  1.7171e-01,  1.0965e-01,  2.8549e-01, -9.7671e-02,\n          1.2873e-01,  2.6482e-01, -1.5254e-01],\n        [ 7.9711e-02, -1.6929e-01,  7.7400e-02,  8.7182e-02,  2.8375e-01,\n          2.7993e-02, -9.1865e-02,  5.1666e-02],\n        [-7.0727e-02,  1.0221e-01, -1.6487e-01, -2.1442e-01,  3.3386e-01,\n          2.3806e-01, -2.1268e-01,  1.9925e-01],\n        [ 3.8337e-02,  9.5454e-02,  5.7380e-02,  4.0145e-03,  2.1952e-01,\n         -6.6292e-02,  2.4863e-01,  2.2644e-01],\n        [ 3.4626e-01,  9.6182e-02, -2.3990e-02, -3.4314e-01,  1.8973e-01,\n         -2.1779e-01,  3.0374e-01, -2.2305e-01],\n        [ 7.7760e-02, -2.9166e-02,  9.3083e-02,  1.9126e-01, -2.5004e-01,\n          2.1953e-01,  5.4681e-02,  1.9503e-01],\n        [-1.9687e-02, -3.3037e-01, -2.4782e-04,  8.7376e-02,  1.7374e-01,\n         -1.9679e-01, -3.4050e-01, -1.6408e-01],\n        [ 3.4797e-01, -2.0657e-01,  2.2450e-01,  3.5337e-01,  2.3719e-02,\n          2.0490e-01,  1.8764e-01, -9.7692e-02],\n        [-2.7794e-01, -3.4044e-01,  1.5394e-01,  4.4175e-02,  1.0480e-01,\n         -1.3136e-01, -1.3436e-01, -2.8738e-01],\n        [ 3.3445e-01, -1.9835e-01,  2.7425e-01, -3.3465e-01,  2.7723e-01,\n         -3.1366e-01,  5.3437e-02, -2.5713e-01],\n        [ 2.5028e-01, -2.3505e-01,  6.8617e-02,  7.6686e-02, -7.0726e-02,\n         -7.2201e-02,  1.2294e-01, -1.9402e-01],\n        [ 3.7695e-02, -2.6216e-01, -1.4541e-01,  2.4739e-01,  2.6310e-01,\n          1.0567e-01, -4.5728e-03,  1.9732e-01],\n        [-3.0626e-01, -1.2502e-01, -4.0056e-02, -1.0454e-01, -1.2683e-02,\n         -2.3062e-01, -1.6010e-01,  9.4313e-02],\n        [ 2.5934e-01,  3.2925e-01, -9.8783e-02,  1.6055e-01, -2.3505e-01,\n          1.5574e-01, -1.6057e-01, -1.9098e-01],\n        [-2.0498e-01, -3.8736e-02,  2.3974e-01,  2.4801e-01,  3.2340e-01,\n         -2.2671e-01, -8.0440e-02, -3.4487e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 1.2058e-01, -2.1669e-01, -1.0418e-01, -8.5956e-02,  2.0304e-01,\n         1.6191e-01, -2.1941e-01,  1.7515e-02, -3.1748e-01, -1.8800e-01,\n        -2.4584e-01,  2.1453e-01,  1.4879e-01, -1.2042e-03, -2.0722e-01,\n         6.1932e-02,  3.5094e-02, -4.4795e-02, -4.8839e-02,  1.8752e-01,\n        -1.4523e-02, -7.1651e-02,  2.9788e-02, -3.0138e-01,  1.3737e-02,\n        -1.2929e-01,  9.8841e-02,  1.3247e-04,  3.3807e-01,  3.5152e-01,\n        -9.4590e-03,  4.4478e-04], requires_grad=True)",
                                "Parameter containing:\ntensor([[-6.5604e-02, -5.2484e-02,  1.6687e-01,  6.2830e-02, -7.1184e-03,\n         -1.5873e-02, -1.3830e-01, -5.1606e-02,  8.5592e-02,  4.6470e-02,\n          1.6162e-02, -1.3098e-01, -6.9625e-02, -8.3637e-02, -8.9897e-02,\n         -1.5285e-01,  1.0896e-01,  6.4355e-02,  5.6366e-02,  1.4069e-01,\n         -2.4644e-02,  1.4048e-01, -3.8163e-02, -1.1176e-01,  8.1713e-02,\n         -3.8508e-02,  6.2907e-02,  1.7299e-01,  1.3306e-01,  1.6047e-01,\n         -1.1386e-01, -3.9037e-02],\n        [-1.2744e-01,  5.6076e-03,  8.3889e-02, -1.3278e-02, -1.3704e-01,\n         -9.0482e-02,  2.2594e-02,  1.6137e-01, -7.1581e-02,  1.4406e-04,\n          1.2303e-01,  1.0590e-01,  6.8817e-02,  9.2087e-02,  4.5848e-02,\n         -1.7343e-01, -8.7304e-02, -4.4352e-02,  1.1659e-01,  8.8527e-02,\n          8.5485e-02,  8.7703e-02, -6.0650e-02, -9.4391e-02,  9.7448e-02,\n         -8.9033e-02,  1.4993e-01,  1.7419e-01,  9.2244e-02, -7.9551e-02,\n         -1.1759e-01,  3.9437e-03],\n        [ 6.8287e-02,  1.3553e-01,  1.0869e-01,  9.1277e-02,  1.1923e-01,\n          6.8108e-02,  3.9338e-02, -1.0921e-02,  1.3625e-01, -7.8087e-02,\n          3.2555e-02, -8.9273e-02, -8.0089e-02,  5.3359e-02,  1.3450e-01,\n         -3.7695e-02,  1.5612e-01,  1.1309e-01, -1.4361e-01, -1.0205e-01,\n          4.5997e-02, -9.3647e-02,  3.9551e-02,  5.4341e-02,  1.4952e-01,\n          3.4068e-02, -2.2513e-02, -1.4058e-01,  1.0747e-02, -2.1858e-02,\n         -1.7355e-01, -3.5422e-02],\n        [ 3.3182e-02, -5.1680e-02,  1.9516e-02,  1.2502e-01, -7.0573e-02,\n         -3.1200e-02,  8.1950e-02, -9.7996e-02, -1.4222e-01,  1.3960e-01,\n          4.8926e-02, -1.4215e-02, -1.2475e-01,  2.3344e-02,  5.9827e-02,\n          7.7167e-02, -1.5922e-01, -1.6733e-01, -1.3163e-01,  1.4213e-01,\n          1.5911e-01,  7.6382e-03, -1.1488e-02,  4.9095e-02,  5.3667e-02,\n          1.1488e-01, -4.5494e-02, -1.8702e-02, -1.1956e-02, -1.1240e-02,\n          1.2930e-01,  8.3392e-02],\n        [-1.2399e-01,  1.7032e-01, -8.2854e-02, -1.7018e-01, -1.3417e-01,\n         -9.7497e-02, -6.9372e-02,  1.1903e-01, -1.7364e-01, -1.3409e-01,\n          8.7388e-02,  6.6198e-04, -2.1753e-02, -1.2769e-01, -3.8988e-03,\n         -2.3480e-03,  1.1983e-01, -3.9066e-02,  4.0787e-03,  1.3216e-01,\n          4.5939e-02, -1.5735e-01,  1.2763e-01, -1.2054e-01, -6.7300e-02,\n         -1.2993e-01, -5.1001e-02, -6.9745e-02,  1.4849e-01, -1.0828e-01,\n          1.2074e-01, -3.9114e-02],\n        [-1.2559e-01,  1.6544e-02, -9.5606e-02,  3.8967e-02, -6.2516e-02,\n          1.6897e-01, -5.8811e-02, -2.5116e-02, -5.2229e-02, -8.9595e-02,\n         -9.9164e-02,  1.7181e-01, -3.5030e-02,  1.7318e-01, -3.0202e-02,\n          1.5775e-01, -1.4950e-02, -8.1951e-02,  1.4454e-01, -1.4915e-01,\n         -1.0232e-01,  1.6061e-01,  3.9151e-02,  1.1644e-01,  1.7493e-03,\n         -9.2127e-02,  9.3049e-02, -1.1244e-01, -3.5455e-02, -1.7604e-01,\n         -2.9062e-02, -1.0788e-01],\n        [-3.2445e-02,  4.2206e-03,  1.4426e-01,  1.2812e-01,  1.3290e-01,\n         -1.3415e-01,  1.4667e-01,  3.4835e-02, -3.9581e-02, -1.5826e-01,\n          1.4095e-01, -2.6799e-02, -1.1431e-02,  7.5292e-02,  3.9058e-02,\n         -1.3448e-01,  2.5727e-02,  8.6182e-02, -8.4200e-02,  9.4299e-02,\n          7.7791e-02,  1.5858e-01, -1.6231e-02, -1.6456e-01, -1.5716e-02,\n          1.7446e-01,  1.5541e-01,  1.4293e-01,  1.4636e-01,  1.4609e-01,\n         -7.4173e-02, -1.0383e-01],\n        [ 7.0929e-02, -8.2777e-02,  2.9905e-03,  4.4442e-02,  1.2064e-01,\n          1.0587e-01,  9.2806e-02,  1.9524e-02, -1.5302e-01,  5.2895e-02,\n         -8.8210e-02,  1.7559e-02,  9.3320e-02, -1.3602e-01, -8.1931e-02,\n          7.2104e-02, -1.4684e-01,  1.7517e-01, -6.2629e-02,  4.2843e-02,\n         -3.9561e-02, -6.2119e-02,  2.2292e-02,  1.5386e-02, -8.0241e-04,\n          5.7326e-02,  1.2011e-01, -6.8501e-03,  1.1765e-01, -1.0851e-01,\n         -2.9637e-03, -5.6539e-02],\n        [-2.5802e-02,  3.3259e-02,  2.6779e-02, -3.8598e-02, -8.3153e-02,\n         -2.9668e-02, -2.3980e-02, -9.7806e-02, -1.2535e-02, -7.3604e-02,\n          4.8801e-02,  7.8806e-02,  1.1505e-02,  5.3109e-03,  2.2700e-02,\n         -1.6000e-01, -1.2844e-01,  1.1805e-01, -6.7128e-02,  8.2744e-02,\n         -1.0689e-01,  1.9275e-02,  1.3349e-01, -1.3735e-01,  1.1322e-01,\n         -7.5032e-02, -6.6721e-02,  8.9071e-02, -1.3560e-01, -4.9894e-02,\n         -9.2772e-02, -5.0794e-02],\n        [ 3.0585e-02, -1.2895e-01,  3.7107e-02,  1.2109e-01,  1.9049e-02,\n         -9.5930e-02,  1.6720e-01, -5.3714e-02,  7.5100e-02, -9.7035e-02,\n         -1.8575e-03,  5.2561e-02, -1.7410e-01,  5.1815e-03, -3.8010e-02,\n          1.4707e-01, -1.0238e-01, -5.5709e-02,  1.3860e-01,  4.9894e-03,\n         -8.5984e-02,  6.5437e-02, -7.8695e-02, -1.3613e-01, -7.3067e-02,\n         -1.2295e-01,  2.7655e-02, -7.8261e-02, -1.4948e-03,  7.4249e-02,\n         -1.0220e-01,  3.0849e-02],\n        [-3.0433e-02,  5.6474e-03,  2.2659e-02,  1.5892e-01,  3.1030e-02,\n         -1.5439e-01,  2.5624e-02,  2.4154e-02,  1.6491e-01,  1.7524e-01,\n         -3.8733e-02, -1.5300e-02,  1.2360e-01,  1.1103e-01,  1.5826e-03,\n         -1.7640e-01, -1.3970e-01, -4.1429e-02,  7.0857e-02,  3.8094e-02,\n          7.1767e-02, -1.2007e-01, -1.3810e-01, -7.7649e-02, -1.2239e-01,\n          1.3351e-01,  6.4942e-04, -7.8591e-02,  5.6202e-02, -1.6422e-01,\n         -1.5424e-01, -5.4815e-02],\n        [-1.4279e-01,  6.9861e-02,  1.4421e-03,  6.1561e-02, -1.0070e-01,\n         -4.4153e-02, -4.9709e-02,  1.2297e-01,  4.7822e-02, -1.3180e-01,\n         -1.6925e-02, -7.3678e-02, -1.3080e-01, -6.1306e-02, -2.9820e-02,\n         -6.1817e-02, -1.3340e-01,  4.1132e-03, -4.8535e-02,  3.2745e-02,\n          4.6043e-02, -1.5871e-02,  6.4722e-02, -1.0467e-01,  5.2724e-03,\n         -1.2666e-01, -1.5932e-01,  6.4203e-02, -7.7492e-02,  7.3191e-02,\n          3.7668e-02,  8.1300e-02],\n        [ 1.3207e-02,  1.4567e-01,  1.7223e-01,  1.3597e-03, -1.5404e-01,\n          1.1573e-01,  1.0907e-01,  1.1516e-01,  9.9147e-02,  1.5465e-01,\n          1.6627e-01, -1.6801e-01,  5.6351e-02,  4.0004e-02, -1.5234e-01,\n         -1.5332e-01,  7.2275e-02, -4.7570e-02,  6.1785e-02,  1.7640e-01,\n          1.4084e-03, -2.6128e-02, -8.0339e-02, -1.3424e-01, -3.8855e-02,\n         -4.8133e-02,  9.0855e-02, -1.0225e-01,  1.4366e-01, -1.1304e-01,\n         -9.2934e-02, -1.0513e-01],\n        [-9.3023e-02,  1.1032e-02,  6.2878e-02, -5.6595e-02, -1.3673e-01,\n         -1.4245e-01, -4.9766e-02, -1.6609e-01,  4.3021e-02, -1.4501e-01,\n         -1.5147e-01, -1.5503e-01, -4.6544e-02,  4.0186e-03,  1.0899e-01,\n         -9.9983e-02, -1.3960e-01, -1.0107e-01, -3.5525e-02, -4.0896e-02,\n          8.7117e-02,  3.7963e-02,  9.6486e-02, -6.8615e-02,  9.9698e-02,\n          1.7297e-01, -9.7819e-02, -2.6613e-02, -1.7197e-01, -1.8923e-02,\n          8.8739e-02, -7.6768e-02],\n        [-1.5589e-01,  6.9288e-02,  1.6958e-01,  2.7476e-02,  1.4157e-01,\n          1.6631e-01,  9.4456e-03,  1.6660e-01,  4.9198e-02, -5.6034e-02,\n          7.5870e-02,  3.4623e-02, -9.7387e-02, -9.7991e-03,  1.2301e-01,\n         -8.2595e-02, -9.7635e-02, -1.1686e-01,  3.0699e-03,  7.5912e-02,\n          6.8754e-02, -7.6349e-02,  1.7101e-01,  6.8881e-02,  1.0462e-01,\n          1.5687e-01, -9.7018e-02, -1.1751e-01,  6.5073e-02,  2.5998e-02,\n         -7.5693e-02, -6.9412e-02],\n        [ 8.4133e-02, -6.0429e-02,  5.3310e-02,  7.5307e-02,  1.5135e-01,\n          1.0878e-01,  6.6056e-02,  5.7093e-02,  1.2865e-01, -6.1371e-02,\n         -4.4438e-02,  2.2910e-02,  5.7278e-02,  4.3934e-02,  1.2271e-01,\n         -9.0084e-03, -2.6354e-02, -1.4182e-01, -1.4460e-01, -1.6465e-01,\n          4.9577e-02,  2.3369e-02,  7.0550e-02,  1.2435e-01,  1.1404e-01,\n         -1.4433e-01, -5.7346e-02,  1.0121e-01, -1.0468e-01,  3.3238e-02,\n          1.1231e-01,  5.0472e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1515, -0.0316, -0.1687, -0.0778,  0.0591,  0.1716, -0.0443, -0.1504,\n        -0.1501,  0.0857, -0.0710, -0.1682,  0.1045,  0.0838, -0.1747, -0.0982],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1450,  0.1420, -0.1907,  0.0130,  0.0263, -0.2224,  0.0484, -0.0325,\n         -0.0265, -0.1023, -0.1422, -0.1048, -0.1266,  0.0216, -0.0685,  0.2164],\n        [-0.0576, -0.1096,  0.0511, -0.2004, -0.2265, -0.2041, -0.0556,  0.0642,\n          0.0224, -0.1746, -0.2104, -0.1495, -0.0475,  0.0517, -0.2457,  0.0621],\n        [ 0.1070, -0.1107, -0.0637, -0.2025, -0.0271, -0.1299, -0.1325, -0.2127,\n          0.1175, -0.1753,  0.1180, -0.0406, -0.2057, -0.0248,  0.1139,  0.1170],\n        [ 0.0024,  0.0144,  0.1629, -0.0061,  0.2480, -0.1591,  0.2365, -0.0848,\n          0.0436,  0.1301,  0.2281, -0.0877,  0.0554,  0.1271, -0.1671, -0.1318],\n        [-0.2313, -0.1781, -0.1382, -0.0219, -0.0786,  0.2413, -0.1808,  0.2435,\n          0.2195, -0.0055,  0.2331, -0.1360,  0.1831, -0.1290, -0.1433,  0.0364],\n        [ 0.0223,  0.1896, -0.1529, -0.1600, -0.2228, -0.0957, -0.0140, -0.0532,\n         -0.2360, -0.0348,  0.1680, -0.1479,  0.1916,  0.1933, -0.0779, -0.1058],\n        [ 0.0198, -0.2109, -0.0494,  0.1843,  0.0411, -0.2117, -0.1151,  0.2298,\n         -0.2156,  0.2004, -0.1844,  0.2209,  0.0232,  0.0529,  0.2328,  0.1568],\n        [-0.2249,  0.1477,  0.2185,  0.1199,  0.2255,  0.1634,  0.0419,  0.2323,\n          0.0845,  0.0676,  0.0669, -0.1839, -0.1315,  0.1885, -0.1397, -0.1720]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1739,  0.2432,  0.0907, -0.1489, -0.1588,  0.0077,  0.1592,  0.0225],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2994, -0.0101,  0.0376,  0.3009,  0.2297, -0.1113,  0.1744, -0.1747]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2302], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x105773e80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x3068d6560>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s131960000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s131960000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}