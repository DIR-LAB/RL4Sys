{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s134810000"
    },
    "q_lr":	0.0005,
    "seed":	134810000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x16d8663b0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1077, -0.1465, -0.1834,  0.1202, -0.2245,  0.1036,  0.2967, -0.0720,\n         0.1455,  0.3354,  0.1539,  0.1313, -0.3094, -0.2251,  0.0823, -0.2254,\n        -0.1418, -0.0763,  0.2614, -0.2781, -0.1141, -0.1376,  0.1692,  0.1942,\n         0.1030, -0.1301, -0.1830, -0.1799, -0.0540,  0.2782,  0.0671,  0.0343],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3418, -0.2126, -0.0372,  0.2843, -0.1991,  0.1608,  0.1110,  0.0625],\n        [ 0.1918,  0.3360,  0.0149, -0.2044, -0.1595,  0.3448,  0.3413, -0.1732],\n        [ 0.1493, -0.2687,  0.1966, -0.2072,  0.2294, -0.0733,  0.1456, -0.2351],\n        [ 0.2601,  0.0810, -0.0728, -0.1791, -0.0228,  0.1541, -0.0548, -0.1064],\n        [-0.1567,  0.0446, -0.0665, -0.0838,  0.1205, -0.3215,  0.1065, -0.1306],\n        [-0.1048,  0.3245,  0.1439, -0.1429, -0.2977,  0.2839,  0.1178, -0.0741],\n        [-0.1358,  0.2097, -0.0356,  0.2708, -0.2573,  0.0384, -0.0396,  0.0238],\n        [-0.0897, -0.0749, -0.0421,  0.2747,  0.1576,  0.3033,  0.0692, -0.0981],\n        [-0.1378,  0.2567, -0.2209, -0.1763, -0.2748,  0.0840,  0.2237, -0.1918],\n        [-0.0225, -0.2392,  0.1745,  0.2018, -0.1446,  0.2489, -0.3285,  0.2010],\n        [-0.2039, -0.1449, -0.1664,  0.1165,  0.1858,  0.2728,  0.1493,  0.0584],\n        [ 0.2104,  0.2382, -0.0357,  0.2145, -0.2012,  0.0133, -0.1501,  0.2926],\n        [-0.1281, -0.3252,  0.1438,  0.0700, -0.1871,  0.2456,  0.0736,  0.2941],\n        [ 0.2092, -0.1641, -0.2929,  0.0552, -0.0664, -0.0939,  0.1668, -0.1809],\n        [ 0.0284,  0.3375,  0.2003,  0.3480, -0.2243, -0.0491, -0.3535, -0.0852],\n        [ 0.0618,  0.1705, -0.0464, -0.2697, -0.1312,  0.2287,  0.1317, -0.2319],\n        [ 0.2299, -0.3069, -0.3203, -0.1902, -0.0871,  0.3214, -0.0516, -0.1859],\n        [-0.2566,  0.3368, -0.3408,  0.3256, -0.1087, -0.0413,  0.2581, -0.1262],\n        [ 0.1289, -0.2453,  0.1570, -0.0809, -0.0216, -0.2167, -0.1438,  0.0093],\n        [-0.3258,  0.2559,  0.0752, -0.1542,  0.3378,  0.0107,  0.3455,  0.3350],\n        [ 0.2342, -0.1625, -0.2588, -0.1994, -0.0420, -0.2721, -0.0631,  0.2363],\n        [ 0.1690,  0.1919, -0.1922,  0.1931,  0.0486,  0.2122,  0.2936,  0.1760],\n        [-0.0234,  0.1423,  0.1779, -0.2504,  0.0970, -0.0557,  0.2444, -0.0619],\n        [-0.0602, -0.0296,  0.3495, -0.2080, -0.3383, -0.1898,  0.0811,  0.2123],\n        [ 0.3004,  0.3252,  0.1016, -0.1694, -0.2364,  0.0683, -0.3511,  0.3382],\n        [-0.1151, -0.3476,  0.0020, -0.0918, -0.0459, -0.3093,  0.2319, -0.0809],\n        [ 0.2196, -0.1730,  0.2241, -0.2706,  0.1287, -0.3311, -0.0803, -0.1503],\n        [-0.1762, -0.1794, -0.2625, -0.0929, -0.2976, -0.1276, -0.0352, -0.1225],\n        [ 0.1397,  0.0066, -0.1826,  0.2053,  0.1905, -0.0216, -0.3099, -0.0780],\n        [ 0.2124,  0.1336,  0.2666, -0.3505,  0.2246, -0.1772,  0.1192, -0.2774],\n        [-0.1437,  0.1872, -0.1241, -0.1036,  0.1092,  0.3282,  0.0255, -0.0328],\n        [-0.0099,  0.0834,  0.1102,  0.3183, -0.0843,  0.0615,  0.2711,  0.2952]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1593, -0.1102, -0.0244,  0.1202,  0.0695, -0.1489, -0.1294, -0.1684,\n        -0.0653, -0.1603, -0.1330,  0.1356,  0.1617, -0.0843, -0.1364, -0.0236],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 3.2681e-02, -7.6018e-02, -5.6775e-02, -1.2865e-01,  1.4880e-01,\n         -5.0450e-02, -1.8188e-02, -9.0007e-02, -6.4244e-02,  1.5274e-01,\n          1.1198e-01, -1.7232e-02, -5.7732e-02,  1.0874e-01,  1.2916e-01,\n         -9.9228e-02,  6.0917e-02, -2.5134e-02,  1.2438e-01,  1.0814e-01,\n          2.3125e-02, -1.4115e-01, -5.3938e-02, -6.0046e-03,  1.5279e-01,\n         -1.6449e-01,  1.6335e-01, -1.5014e-01, -2.7177e-02, -1.0858e-02,\n         -1.7852e-02,  1.3239e-01],\n        [ 1.1917e-01, -1.5025e-01, -6.6513e-02, -1.1164e-01, -9.8446e-02,\n          1.4483e-01, -1.6516e-02, -9.1658e-02,  1.6590e-01, -1.0755e-01,\n         -1.3192e-01,  1.5829e-01, -1.1637e-01,  1.1763e-01,  1.1854e-01,\n          3.5022e-02,  9.3104e-02,  8.6580e-02, -4.9270e-02, -2.0995e-02,\n          8.6731e-03, -1.5564e-01, -1.1860e-01, -4.2669e-02,  1.3476e-01,\n          8.1105e-02,  7.8733e-02, -1.3734e-01,  1.0309e-01, -1.0706e-01,\n          1.2162e-01,  2.2822e-02],\n        [-2.4548e-02,  5.0928e-02, -1.7497e-01, -1.3795e-01,  7.0405e-02,\n         -1.4316e-01, -4.4243e-02,  5.6962e-02,  1.5137e-01,  1.3098e-01,\n         -1.7670e-01, -1.3254e-01,  9.8476e-02, -7.7719e-02, -7.5250e-02,\n          5.2937e-02,  9.9880e-02,  1.6599e-01,  1.1706e-04, -1.5134e-02,\n          1.5631e-01,  7.9450e-02,  6.2399e-02,  1.4548e-01, -8.1426e-02,\n          3.5446e-02,  1.7082e-01,  2.8917e-02, -5.7733e-02,  8.2330e-02,\n         -3.7414e-02,  1.3337e-01],\n        [ 1.1484e-01,  7.9728e-02,  7.9648e-02, -1.1872e-01, -8.6891e-02,\n          4.5154e-02, -7.2717e-02, -1.6508e-02,  1.0113e-01, -5.1423e-02,\n          1.4253e-01, -1.4354e-01,  1.0676e-01, -9.6035e-02, -1.3860e-01,\n         -5.5435e-02, -1.4538e-01, -1.5438e-02,  3.6248e-02,  2.4026e-02,\n         -1.6664e-01,  1.2947e-01, -1.5569e-01,  6.3151e-02,  7.0421e-02,\n         -1.0374e-01, -8.5907e-02, -4.4399e-02, -5.0520e-02, -1.6077e-01,\n          1.1278e-01, -4.0305e-02],\n        [-3.4077e-02, -1.0462e-01, -1.5118e-01, -1.0944e-01, -8.9779e-02,\n         -7.2889e-02, -1.5836e-01,  1.5997e-01,  9.1486e-02,  1.6276e-01,\n          8.5427e-02, -7.3329e-02, -1.3323e-01, -1.3200e-01, -8.2024e-02,\n         -4.3266e-02,  1.4292e-01,  1.2035e-02, -6.2135e-02, -5.2314e-02,\n         -1.1220e-01, -8.8839e-03, -7.6576e-02,  1.1518e-01, -1.5471e-01,\n         -1.7575e-01, -1.3013e-01,  8.8476e-02, -5.3343e-02, -5.5096e-03,\n          1.5162e-01,  1.7508e-01],\n        [-7.4748e-02, -1.3280e-01,  2.9636e-02,  1.2451e-01, -1.5355e-02,\n          1.1181e-01, -1.7071e-01,  2.4972e-03, -1.2375e-01, -2.6551e-02,\n         -1.0824e-01, -7.8903e-02,  1.3963e-01, -3.7913e-02,  3.1179e-02,\n         -3.2282e-02,  1.0511e-01, -4.6502e-02,  1.1166e-01, -3.6056e-02,\n          9.8033e-02,  8.6927e-02,  7.0789e-02,  1.0994e-01,  4.8108e-02,\n         -6.2289e-02, -1.2822e-01,  1.7050e-01,  1.6368e-01,  6.9183e-02,\n         -6.2854e-02,  1.0972e-01],\n        [ 1.2439e-01, -1.6268e-01,  5.4270e-02, -1.2977e-01, -1.5409e-01,\n         -1.3673e-01,  2.0020e-02, -1.7672e-01, -1.3632e-01,  1.2737e-01,\n          1.0595e-01, -2.1546e-02, -3.6036e-02, -6.4803e-02,  1.5228e-01,\n          1.0729e-01,  5.7926e-02,  1.3426e-01, -7.2457e-02, -4.1846e-02,\n         -3.7384e-02, -5.1644e-02,  3.5218e-02,  6.9287e-02,  2.7234e-02,\n         -8.3279e-02, -4.3626e-02, -9.7073e-02, -3.4337e-02, -1.9624e-02,\n          1.5912e-02, -5.1096e-02],\n        [-1.7203e-01, -9.1751e-02,  8.6131e-02, -1.4820e-01, -1.6125e-02,\n          5.8755e-02,  1.0711e-01, -6.1834e-02,  9.0335e-02, -1.1006e-01,\n          3.7569e-02, -2.2030e-02, -1.3259e-01,  2.6716e-03,  1.1014e-01,\n          1.3324e-02, -1.0938e-02, -1.6467e-01,  6.3057e-02, -1.4712e-01,\n         -4.0247e-02,  1.0523e-01, -1.1048e-02,  8.3060e-02,  2.1156e-02,\n          1.4360e-01, -3.0081e-02,  9.5661e-02,  4.2689e-02, -9.8423e-02,\n          1.1106e-01, -2.9221e-02],\n        [-1.7396e-01, -4.6508e-02,  1.0226e-01,  1.6322e-01, -1.1551e-01,\n         -3.5102e-02,  1.3759e-01,  8.1027e-02,  3.6656e-02,  1.7115e-01,\n         -1.2862e-02, -1.1198e-02, -5.5479e-02,  1.1202e-01,  8.7844e-02,\n          1.0537e-01, -1.7414e-01, -1.1846e-01, -1.7019e-01, -1.4304e-01,\n         -1.3475e-01, -1.2373e-01,  1.4023e-01, -1.3997e-01,  1.1566e-02,\n          5.7757e-02, -4.4428e-02, -1.0559e-01, -1.4063e-01,  5.0969e-02,\n          1.1892e-02,  1.4582e-01],\n        [-4.0380e-02,  1.4210e-01, -1.6482e-01,  7.8146e-02, -1.5311e-01,\n          1.1536e-01,  1.1091e-01,  7.3346e-02,  2.9662e-02, -8.3285e-03,\n         -1.3269e-01,  3.0785e-02,  1.1781e-01,  1.0593e-01, -1.6370e-01,\n         -1.3701e-01, -7.0177e-02, -7.3228e-03, -6.3502e-02, -2.2633e-02,\n         -5.9391e-02,  4.7440e-02, -1.1873e-01,  4.8310e-03,  3.7626e-02,\n          1.7530e-01,  4.5984e-02, -7.5319e-02,  2.1245e-02,  1.5462e-01,\n         -1.3611e-01,  3.6698e-03],\n        [ 9.1819e-02,  1.1938e-01,  1.0006e-01, -8.3603e-02, -3.9671e-02,\n          6.3768e-05,  1.1022e-01,  5.4805e-02,  7.8527e-02,  1.0405e-01,\n         -1.5769e-01,  6.6007e-02, -1.3147e-01,  1.4200e-01,  1.1349e-01,\n         -4.5604e-02,  6.4886e-02,  1.3382e-01,  5.2855e-02,  1.2691e-01,\n         -1.8643e-02,  3.2471e-02,  1.1694e-02, -7.4368e-02,  1.4843e-01,\n          1.2083e-01,  8.3236e-02, -6.7079e-03,  1.5742e-01, -6.3797e-02,\n          4.4284e-02, -6.6870e-02],\n        [ 7.0082e-02,  7.2116e-02,  7.1158e-02, -2.6240e-02, -1.0632e-01,\n          1.4664e-01,  1.5918e-01,  1.5228e-01, -1.4796e-01,  1.2819e-02,\n          2.1628e-02, -8.1942e-02,  1.1368e-01,  1.3246e-01,  9.5070e-02,\n          7.2493e-02,  6.5683e-02,  1.3421e-01, -1.6219e-01,  3.8108e-02,\n          1.6888e-01,  1.5299e-01, -7.2817e-02,  4.8623e-02,  1.5989e-01,\n         -5.4750e-02,  9.6487e-04, -1.5093e-01,  8.7865e-02, -7.2097e-02,\n          1.7219e-01,  3.7374e-02],\n        [ 1.4321e-01, -1.7516e-01, -2.0140e-02,  1.4488e-01,  7.0745e-02,\n          9.0034e-03, -3.9291e-02,  4.3850e-02,  1.0680e-02, -1.5083e-01,\n         -1.7423e-01,  1.3909e-01,  1.7464e-01,  1.0028e-01, -1.8452e-02,\n         -2.2991e-03, -1.6755e-01, -1.3526e-01, -1.2355e-01,  1.1244e-01,\n         -5.3980e-02, -7.6902e-03, -8.2626e-02, -1.5699e-01,  3.1606e-04,\n          1.9493e-02,  9.9463e-02,  3.6542e-02,  1.5538e-01,  9.5513e-02,\n          1.5687e-01,  2.6618e-03],\n        [-3.1406e-02, -1.0877e-01,  1.2786e-01,  8.4199e-02, -1.0236e-01,\n          5.8344e-02,  1.7520e-01, -1.7551e-01, -3.3158e-02, -8.4531e-02,\n          1.5157e-01,  1.7584e-01, -1.2613e-01, -3.7514e-02, -1.2577e-01,\n         -1.6330e-01,  1.1173e-01, -5.5809e-02, -3.5743e-02,  1.1936e-01,\n         -3.3114e-02,  2.5257e-02, -1.0031e-01,  4.5453e-02, -1.4199e-01,\n          1.9723e-02,  1.6787e-01,  9.9842e-02, -1.4829e-01, -1.2970e-01,\n          2.3279e-02, -8.3518e-03],\n        [ 5.9045e-02, -7.5203e-02,  1.1560e-01, -3.9175e-02,  1.2898e-01,\n          1.1352e-01, -6.6017e-02, -1.4848e-01, -2.8888e-02, -1.2670e-02,\n          7.4155e-02,  5.8842e-02,  2.7669e-02, -9.0344e-02, -2.3391e-02,\n         -1.2960e-01,  1.4622e-02,  5.8644e-02, -6.9446e-03,  1.6094e-01,\n          1.0223e-01, -3.8093e-02,  1.1221e-01,  6.8753e-02, -6.3301e-02,\n          1.4204e-01,  1.0520e-01, -5.0466e-02,  1.5347e-01, -2.0248e-02,\n          7.9843e-02, -1.3971e-01],\n        [ 2.8020e-02,  7.0329e-02,  7.0672e-02, -1.0533e-02, -1.7677e-01,\n          3.9312e-03, -8.2435e-02,  6.0252e-02,  1.5411e-01, -1.1825e-01,\n          1.1728e-01,  7.6054e-02,  6.4055e-02, -9.0029e-02,  1.3731e-01,\n          1.4522e-01,  1.3665e-01,  1.3466e-01,  1.8394e-02,  1.5317e-01,\n         -1.3901e-01,  1.0363e-02,  3.9998e-02, -9.4180e-02, -3.4163e-02,\n          7.2239e-02, -1.0332e-01,  4.2380e-02,  9.7455e-02,  5.4658e-02,\n         -1.3552e-02, -1.2695e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0923,  0.1516,  0.0983,  0.2210,  0.0260,  0.1033,  0.2415, -0.0657],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0776, -0.1900,  0.1370, -0.1346, -0.1838, -0.1784, -0.0287, -0.1960,\n          0.0370, -0.2276, -0.0478,  0.0093,  0.1914,  0.0062, -0.0601, -0.0049],\n        [ 0.2015, -0.0862,  0.1965,  0.1885, -0.1115,  0.2418,  0.2155, -0.1396,\n         -0.1859, -0.1452,  0.2476, -0.2168,  0.0164,  0.0045,  0.1108,  0.1655],\n        [-0.0479,  0.1081,  0.2498, -0.2356, -0.2161, -0.0553, -0.2002,  0.0853,\n          0.0248,  0.1933, -0.2371,  0.1490,  0.2307,  0.0768,  0.2097, -0.1217],\n        [-0.2482, -0.0662,  0.2224,  0.1319,  0.0197,  0.0563, -0.2095, -0.1526,\n          0.0135, -0.1614, -0.0575, -0.2193, -0.0381,  0.2453,  0.0885, -0.1653],\n        [-0.0210, -0.2321, -0.0130,  0.2362,  0.0032,  0.0075, -0.1527,  0.0102,\n         -0.0962, -0.1176, -0.2147, -0.0283,  0.0539, -0.1920, -0.1453, -0.2036],\n        [ 0.1236, -0.0618,  0.1274, -0.1091,  0.1677,  0.1846,  0.1656, -0.1874,\n          0.1554, -0.0640, -0.1694,  0.1945,  0.2112,  0.1687, -0.0263, -0.0874],\n        [ 0.1885, -0.0573,  0.1678,  0.0718, -0.0583,  0.0849,  0.0675, -0.1878,\n          0.0442, -0.0119, -0.1940,  0.2060, -0.1897,  0.1742, -0.0503, -0.1442],\n        [ 0.0089,  0.0272,  0.0229, -0.1532, -0.0579,  0.0566,  0.1566,  0.1099,\n          0.0956,  0.2099, -0.1058, -0.1922, -0.0300,  0.1259,  0.2359,  0.1133]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3221], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3359, -0.3502,  0.0087, -0.0491,  0.2514,  0.2199,  0.3365,  0.0449]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.3418, -0.2126, -0.0372,  0.2843, -0.1991,  0.1608,  0.1110,  0.0625],\n        [ 0.1918,  0.3360,  0.0149, -0.2044, -0.1595,  0.3448,  0.3413, -0.1732],\n        [ 0.1493, -0.2687,  0.1966, -0.2072,  0.2294, -0.0733,  0.1456, -0.2351],\n        [ 0.2601,  0.0810, -0.0728, -0.1791, -0.0228,  0.1541, -0.0548, -0.1064],\n        [-0.1567,  0.0446, -0.0665, -0.0838,  0.1205, -0.3215,  0.1065, -0.1306],\n        [-0.1048,  0.3245,  0.1439, -0.1429, -0.2977,  0.2839,  0.1178, -0.0741],\n        [-0.1358,  0.2097, -0.0356,  0.2708, -0.2573,  0.0384, -0.0396,  0.0238],\n        [-0.0897, -0.0749, -0.0421,  0.2747,  0.1576,  0.3033,  0.0692, -0.0981],\n        [-0.1378,  0.2567, -0.2209, -0.1763, -0.2748,  0.0840,  0.2237, -0.1918],\n        [-0.0225, -0.2392,  0.1745,  0.2018, -0.1446,  0.2489, -0.3285,  0.2010],\n        [-0.2039, -0.1449, -0.1664,  0.1165,  0.1858,  0.2728,  0.1493,  0.0584],\n        [ 0.2104,  0.2382, -0.0357,  0.2145, -0.2012,  0.0133, -0.1501,  0.2926],\n        [-0.1281, -0.3252,  0.1438,  0.0700, -0.1871,  0.2456,  0.0736,  0.2941],\n        [ 0.2092, -0.1641, -0.2929,  0.0552, -0.0664, -0.0939,  0.1668, -0.1809],\n        [ 0.0284,  0.3375,  0.2003,  0.3480, -0.2243, -0.0491, -0.3535, -0.0852],\n        [ 0.0618,  0.1705, -0.0464, -0.2697, -0.1312,  0.2287,  0.1317, -0.2319],\n        [ 0.2299, -0.3069, -0.3203, -0.1902, -0.0871,  0.3214, -0.0516, -0.1859],\n        [-0.2566,  0.3368, -0.3408,  0.3256, -0.1087, -0.0413,  0.2581, -0.1262],\n        [ 0.1289, -0.2453,  0.1570, -0.0809, -0.0216, -0.2167, -0.1438,  0.0093],\n        [-0.3258,  0.2559,  0.0752, -0.1542,  0.3378,  0.0107,  0.3455,  0.3350],\n        [ 0.2342, -0.1625, -0.2588, -0.1994, -0.0420, -0.2721, -0.0631,  0.2363],\n        [ 0.1690,  0.1919, -0.1922,  0.1931,  0.0486,  0.2122,  0.2936,  0.1760],\n        [-0.0234,  0.1423,  0.1779, -0.2504,  0.0970, -0.0557,  0.2444, -0.0619],\n        [-0.0602, -0.0296,  0.3495, -0.2080, -0.3383, -0.1898,  0.0811,  0.2123],\n        [ 0.3004,  0.3252,  0.1016, -0.1694, -0.2364,  0.0683, -0.3511,  0.3382],\n        [-0.1151, -0.3476,  0.0020, -0.0918, -0.0459, -0.3093,  0.2319, -0.0809],\n        [ 0.2196, -0.1730,  0.2241, -0.2706,  0.1287, -0.3311, -0.0803, -0.1503],\n        [-0.1762, -0.1794, -0.2625, -0.0929, -0.2976, -0.1276, -0.0352, -0.1225],\n        [ 0.1397,  0.0066, -0.1826,  0.2053,  0.1905, -0.0216, -0.3099, -0.0780],\n        [ 0.2124,  0.1336,  0.2666, -0.3505,  0.2246, -0.1772,  0.1192, -0.2774],\n        [-0.1437,  0.1872, -0.1241, -0.1036,  0.1092,  0.3282,  0.0255, -0.0328],\n        [-0.0099,  0.0834,  0.1102,  0.3183, -0.0843,  0.0615,  0.2711,  0.2952]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1077, -0.1465, -0.1834,  0.1202, -0.2245,  0.1036,  0.2967, -0.0720,\n         0.1455,  0.3354,  0.1539,  0.1313, -0.3094, -0.2251,  0.0823, -0.2254,\n        -0.1418, -0.0763,  0.2614, -0.2781, -0.1141, -0.1376,  0.1692,  0.1942,\n         0.1030, -0.1301, -0.1830, -0.1799, -0.0540,  0.2782,  0.0671,  0.0343],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 3.2681e-02, -7.6018e-02, -5.6775e-02, -1.2865e-01,  1.4880e-01,\n         -5.0450e-02, -1.8188e-02, -9.0007e-02, -6.4244e-02,  1.5274e-01,\n          1.1198e-01, -1.7232e-02, -5.7732e-02,  1.0874e-01,  1.2916e-01,\n         -9.9228e-02,  6.0917e-02, -2.5134e-02,  1.2438e-01,  1.0814e-01,\n          2.3125e-02, -1.4115e-01, -5.3938e-02, -6.0046e-03,  1.5279e-01,\n         -1.6449e-01,  1.6335e-01, -1.5014e-01, -2.7177e-02, -1.0858e-02,\n         -1.7852e-02,  1.3239e-01],\n        [ 1.1917e-01, -1.5025e-01, -6.6513e-02, -1.1164e-01, -9.8446e-02,\n          1.4483e-01, -1.6516e-02, -9.1658e-02,  1.6590e-01, -1.0755e-01,\n         -1.3192e-01,  1.5829e-01, -1.1637e-01,  1.1763e-01,  1.1854e-01,\n          3.5022e-02,  9.3104e-02,  8.6580e-02, -4.9270e-02, -2.0995e-02,\n          8.6731e-03, -1.5564e-01, -1.1860e-01, -4.2669e-02,  1.3476e-01,\n          8.1105e-02,  7.8733e-02, -1.3734e-01,  1.0309e-01, -1.0706e-01,\n          1.2162e-01,  2.2822e-02],\n        [-2.4548e-02,  5.0928e-02, -1.7497e-01, -1.3795e-01,  7.0405e-02,\n         -1.4316e-01, -4.4243e-02,  5.6962e-02,  1.5137e-01,  1.3098e-01,\n         -1.7670e-01, -1.3254e-01,  9.8476e-02, -7.7719e-02, -7.5250e-02,\n          5.2937e-02,  9.9880e-02,  1.6599e-01,  1.1706e-04, -1.5134e-02,\n          1.5631e-01,  7.9450e-02,  6.2399e-02,  1.4548e-01, -8.1426e-02,\n          3.5446e-02,  1.7082e-01,  2.8917e-02, -5.7733e-02,  8.2330e-02,\n         -3.7414e-02,  1.3337e-01],\n        [ 1.1484e-01,  7.9728e-02,  7.9648e-02, -1.1872e-01, -8.6891e-02,\n          4.5154e-02, -7.2717e-02, -1.6508e-02,  1.0113e-01, -5.1423e-02,\n          1.4253e-01, -1.4354e-01,  1.0676e-01, -9.6035e-02, -1.3860e-01,\n         -5.5435e-02, -1.4538e-01, -1.5438e-02,  3.6248e-02,  2.4026e-02,\n         -1.6664e-01,  1.2947e-01, -1.5569e-01,  6.3151e-02,  7.0421e-02,\n         -1.0374e-01, -8.5907e-02, -4.4399e-02, -5.0520e-02, -1.6077e-01,\n          1.1278e-01, -4.0305e-02],\n        [-3.4077e-02, -1.0462e-01, -1.5118e-01, -1.0944e-01, -8.9779e-02,\n         -7.2889e-02, -1.5836e-01,  1.5997e-01,  9.1486e-02,  1.6276e-01,\n          8.5427e-02, -7.3329e-02, -1.3323e-01, -1.3200e-01, -8.2024e-02,\n         -4.3266e-02,  1.4292e-01,  1.2035e-02, -6.2135e-02, -5.2314e-02,\n         -1.1220e-01, -8.8839e-03, -7.6576e-02,  1.1518e-01, -1.5471e-01,\n         -1.7575e-01, -1.3013e-01,  8.8476e-02, -5.3343e-02, -5.5096e-03,\n          1.5162e-01,  1.7508e-01],\n        [-7.4748e-02, -1.3280e-01,  2.9636e-02,  1.2451e-01, -1.5355e-02,\n          1.1181e-01, -1.7071e-01,  2.4972e-03, -1.2375e-01, -2.6551e-02,\n         -1.0824e-01, -7.8903e-02,  1.3963e-01, -3.7913e-02,  3.1179e-02,\n         -3.2282e-02,  1.0511e-01, -4.6502e-02,  1.1166e-01, -3.6056e-02,\n          9.8033e-02,  8.6927e-02,  7.0789e-02,  1.0994e-01,  4.8108e-02,\n         -6.2289e-02, -1.2822e-01,  1.7050e-01,  1.6368e-01,  6.9183e-02,\n         -6.2854e-02,  1.0972e-01],\n        [ 1.2439e-01, -1.6268e-01,  5.4270e-02, -1.2977e-01, -1.5409e-01,\n         -1.3673e-01,  2.0020e-02, -1.7672e-01, -1.3632e-01,  1.2737e-01,\n          1.0595e-01, -2.1546e-02, -3.6036e-02, -6.4803e-02,  1.5228e-01,\n          1.0729e-01,  5.7926e-02,  1.3426e-01, -7.2457e-02, -4.1846e-02,\n         -3.7384e-02, -5.1644e-02,  3.5218e-02,  6.9287e-02,  2.7234e-02,\n         -8.3279e-02, -4.3626e-02, -9.7073e-02, -3.4337e-02, -1.9624e-02,\n          1.5912e-02, -5.1096e-02],\n        [-1.7203e-01, -9.1751e-02,  8.6131e-02, -1.4820e-01, -1.6125e-02,\n          5.8755e-02,  1.0711e-01, -6.1834e-02,  9.0335e-02, -1.1006e-01,\n          3.7569e-02, -2.2030e-02, -1.3259e-01,  2.6716e-03,  1.1014e-01,\n          1.3324e-02, -1.0938e-02, -1.6467e-01,  6.3057e-02, -1.4712e-01,\n         -4.0247e-02,  1.0523e-01, -1.1048e-02,  8.3060e-02,  2.1156e-02,\n          1.4360e-01, -3.0081e-02,  9.5661e-02,  4.2689e-02, -9.8423e-02,\n          1.1106e-01, -2.9221e-02],\n        [-1.7396e-01, -4.6508e-02,  1.0226e-01,  1.6322e-01, -1.1551e-01,\n         -3.5102e-02,  1.3759e-01,  8.1027e-02,  3.6656e-02,  1.7115e-01,\n         -1.2862e-02, -1.1198e-02, -5.5479e-02,  1.1202e-01,  8.7844e-02,\n          1.0537e-01, -1.7414e-01, -1.1846e-01, -1.7019e-01, -1.4304e-01,\n         -1.3475e-01, -1.2373e-01,  1.4023e-01, -1.3997e-01,  1.1566e-02,\n          5.7757e-02, -4.4428e-02, -1.0559e-01, -1.4063e-01,  5.0969e-02,\n          1.1892e-02,  1.4582e-01],\n        [-4.0380e-02,  1.4210e-01, -1.6482e-01,  7.8146e-02, -1.5311e-01,\n          1.1536e-01,  1.1091e-01,  7.3346e-02,  2.9662e-02, -8.3285e-03,\n         -1.3269e-01,  3.0785e-02,  1.1781e-01,  1.0593e-01, -1.6370e-01,\n         -1.3701e-01, -7.0177e-02, -7.3228e-03, -6.3502e-02, -2.2633e-02,\n         -5.9391e-02,  4.7440e-02, -1.1873e-01,  4.8310e-03,  3.7626e-02,\n          1.7530e-01,  4.5984e-02, -7.5319e-02,  2.1245e-02,  1.5462e-01,\n         -1.3611e-01,  3.6698e-03],\n        [ 9.1819e-02,  1.1938e-01,  1.0006e-01, -8.3603e-02, -3.9671e-02,\n          6.3768e-05,  1.1022e-01,  5.4805e-02,  7.8527e-02,  1.0405e-01,\n         -1.5769e-01,  6.6007e-02, -1.3147e-01,  1.4200e-01,  1.1349e-01,\n         -4.5604e-02,  6.4886e-02,  1.3382e-01,  5.2855e-02,  1.2691e-01,\n         -1.8643e-02,  3.2471e-02,  1.1694e-02, -7.4368e-02,  1.4843e-01,\n          1.2083e-01,  8.3236e-02, -6.7079e-03,  1.5742e-01, -6.3797e-02,\n          4.4284e-02, -6.6870e-02],\n        [ 7.0082e-02,  7.2116e-02,  7.1158e-02, -2.6240e-02, -1.0632e-01,\n          1.4664e-01,  1.5918e-01,  1.5228e-01, -1.4796e-01,  1.2819e-02,\n          2.1628e-02, -8.1942e-02,  1.1368e-01,  1.3246e-01,  9.5070e-02,\n          7.2493e-02,  6.5683e-02,  1.3421e-01, -1.6219e-01,  3.8108e-02,\n          1.6888e-01,  1.5299e-01, -7.2817e-02,  4.8623e-02,  1.5989e-01,\n         -5.4750e-02,  9.6487e-04, -1.5093e-01,  8.7865e-02, -7.2097e-02,\n          1.7219e-01,  3.7374e-02],\n        [ 1.4321e-01, -1.7516e-01, -2.0140e-02,  1.4488e-01,  7.0745e-02,\n          9.0034e-03, -3.9291e-02,  4.3850e-02,  1.0680e-02, -1.5083e-01,\n         -1.7423e-01,  1.3909e-01,  1.7464e-01,  1.0028e-01, -1.8452e-02,\n         -2.2991e-03, -1.6755e-01, -1.3526e-01, -1.2355e-01,  1.1244e-01,\n         -5.3980e-02, -7.6902e-03, -8.2626e-02, -1.5699e-01,  3.1606e-04,\n          1.9493e-02,  9.9463e-02,  3.6542e-02,  1.5538e-01,  9.5513e-02,\n          1.5687e-01,  2.6618e-03],\n        [-3.1406e-02, -1.0877e-01,  1.2786e-01,  8.4199e-02, -1.0236e-01,\n          5.8344e-02,  1.7520e-01, -1.7551e-01, -3.3158e-02, -8.4531e-02,\n          1.5157e-01,  1.7584e-01, -1.2613e-01, -3.7514e-02, -1.2577e-01,\n         -1.6330e-01,  1.1173e-01, -5.5809e-02, -3.5743e-02,  1.1936e-01,\n         -3.3114e-02,  2.5257e-02, -1.0031e-01,  4.5453e-02, -1.4199e-01,\n          1.9723e-02,  1.6787e-01,  9.9842e-02, -1.4829e-01, -1.2970e-01,\n          2.3279e-02, -8.3518e-03],\n        [ 5.9045e-02, -7.5203e-02,  1.1560e-01, -3.9175e-02,  1.2898e-01,\n          1.1352e-01, -6.6017e-02, -1.4848e-01, -2.8888e-02, -1.2670e-02,\n          7.4155e-02,  5.8842e-02,  2.7669e-02, -9.0344e-02, -2.3391e-02,\n         -1.2960e-01,  1.4622e-02,  5.8644e-02, -6.9446e-03,  1.6094e-01,\n          1.0223e-01, -3.8093e-02,  1.1221e-01,  6.8753e-02, -6.3301e-02,\n          1.4204e-01,  1.0520e-01, -5.0466e-02,  1.5347e-01, -2.0248e-02,\n          7.9843e-02, -1.3971e-01],\n        [ 2.8020e-02,  7.0329e-02,  7.0672e-02, -1.0533e-02, -1.7677e-01,\n          3.9312e-03, -8.2435e-02,  6.0252e-02,  1.5411e-01, -1.1825e-01,\n          1.1728e-01,  7.6054e-02,  6.4055e-02, -9.0029e-02,  1.3731e-01,\n          1.4522e-01,  1.3665e-01,  1.3466e-01,  1.8394e-02,  1.5317e-01,\n         -1.3901e-01,  1.0363e-02,  3.9998e-02, -9.4180e-02, -3.4163e-02,\n          7.2239e-02, -1.0332e-01,  4.2380e-02,  9.7455e-02,  5.4658e-02,\n         -1.3552e-02, -1.2695e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1593, -0.1102, -0.0244,  0.1202,  0.0695, -0.1489, -0.1294, -0.1684,\n        -0.0653, -0.1603, -0.1330,  0.1356,  0.1617, -0.0843, -0.1364, -0.0236],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0776, -0.1900,  0.1370, -0.1346, -0.1838, -0.1784, -0.0287, -0.1960,\n          0.0370, -0.2276, -0.0478,  0.0093,  0.1914,  0.0062, -0.0601, -0.0049],\n        [ 0.2015, -0.0862,  0.1965,  0.1885, -0.1115,  0.2418,  0.2155, -0.1396,\n         -0.1859, -0.1452,  0.2476, -0.2168,  0.0164,  0.0045,  0.1108,  0.1655],\n        [-0.0479,  0.1081,  0.2498, -0.2356, -0.2161, -0.0553, -0.2002,  0.0853,\n          0.0248,  0.1933, -0.2371,  0.1490,  0.2307,  0.0768,  0.2097, -0.1217],\n        [-0.2482, -0.0662,  0.2224,  0.1319,  0.0197,  0.0563, -0.2095, -0.1526,\n          0.0135, -0.1614, -0.0575, -0.2193, -0.0381,  0.2453,  0.0885, -0.1653],\n        [-0.0210, -0.2321, -0.0130,  0.2362,  0.0032,  0.0075, -0.1527,  0.0102,\n         -0.0962, -0.1176, -0.2147, -0.0283,  0.0539, -0.1920, -0.1453, -0.2036],\n        [ 0.1236, -0.0618,  0.1274, -0.1091,  0.1677,  0.1846,  0.1656, -0.1874,\n          0.1554, -0.0640, -0.1694,  0.1945,  0.2112,  0.1687, -0.0263, -0.0874],\n        [ 0.1885, -0.0573,  0.1678,  0.0718, -0.0583,  0.0849,  0.0675, -0.1878,\n          0.0442, -0.0119, -0.1940,  0.2060, -0.1897,  0.1742, -0.0503, -0.1442],\n        [ 0.0089,  0.0272,  0.0229, -0.1532, -0.0579,  0.0566,  0.1566,  0.1099,\n          0.0956,  0.2099, -0.1058, -0.1922, -0.0300,  0.1259,  0.2359,  0.1133]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0923,  0.1516,  0.0983,  0.2210,  0.0260,  0.1033,  0.2415, -0.0657],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3359, -0.3502,  0.0087, -0.0491,  0.2514,  0.2199,  0.3365,  0.0449]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3221], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x10581be80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x16d866560>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s134810000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s134810000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}