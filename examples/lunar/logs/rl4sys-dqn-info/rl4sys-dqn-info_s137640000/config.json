{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.01,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s137640000"
    },
    "max_sample_age":	-1,
    "q_lr":	0.003,
    "seed":	137640000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x75a4849a5cd0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.01,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1266,  0.0543, -0.0325,  0.1982, -0.2789, -0.2790, -0.0606, -0.1696,\n        -0.2118,  0.2516,  0.2934, -0.2599, -0.1549,  0.1277, -0.0951,  0.1527,\n        -0.1942,  0.2765, -0.0917, -0.3357,  0.2901, -0.1385, -0.1499,  0.1526,\n         0.1630,  0.3403,  0.1453, -0.0530, -0.1137, -0.1543, -0.0934, -0.0403,\n         0.2034,  0.1430, -0.2940, -0.1414,  0.2084,  0.1319,  0.1636, -0.0562,\n         0.1070,  0.0281,  0.1098, -0.1058,  0.2432,  0.0469,  0.0102, -0.2668,\n        -0.0778, -0.2056, -0.0266,  0.2060, -0.1160, -0.1234,  0.0292,  0.2542,\n        -0.2752,  0.1901,  0.0202,  0.0739,  0.0120, -0.1605,  0.3004,  0.1394,\n         0.2572,  0.1485,  0.0340, -0.1841,  0.1545, -0.0810,  0.3413,  0.2244,\n         0.2069,  0.2175, -0.1133, -0.3006,  0.3333, -0.3203, -0.2266,  0.1876,\n        -0.1868, -0.2408,  0.1716, -0.3258,  0.1774, -0.0379,  0.0048, -0.3119,\n        -0.3522,  0.0759,  0.1236, -0.2525, -0.1564, -0.0576,  0.2717, -0.1156,\n         0.2277, -0.2398, -0.1120,  0.0511, -0.1991,  0.2511, -0.0538, -0.0711,\n         0.3295, -0.3473, -0.0352, -0.3412, -0.1754,  0.0420, -0.3224,  0.2067,\n         0.1580, -0.1837, -0.1228,  0.2046,  0.3227, -0.2876,  0.2902,  0.3382,\n         0.0095, -0.0325,  0.2945,  0.1938, -0.0841, -0.1275, -0.1556,  0.2184,\n        -0.0524,  0.3075, -0.3450,  0.0957,  0.0141, -0.1208,  0.3005,  0.2570,\n        -0.0661, -0.1200,  0.3496,  0.3110, -0.0183, -0.0284, -0.3003, -0.2853,\n        -0.1570,  0.1284,  0.1111, -0.2579, -0.1017, -0.0023,  0.2892, -0.2693,\n         0.1504, -0.1782,  0.2400,  0.0263, -0.2866, -0.1981,  0.1913,  0.3488,\n         0.1552,  0.0726, -0.1474, -0.2944,  0.1922, -0.1305, -0.2080,  0.2103,\n        -0.2419, -0.0469, -0.0964,  0.1837, -0.3005,  0.2201, -0.1593, -0.1888,\n        -0.0254, -0.1318, -0.2474,  0.2839,  0.3450,  0.3144, -0.0018, -0.2279,\n         0.2389, -0.2562,  0.1337, -0.2808, -0.0811, -0.1338,  0.2403,  0.0642,\n         0.2872, -0.2082, -0.0763,  0.2879, -0.1262,  0.2007, -0.2207, -0.0371,\n        -0.0361, -0.1755, -0.0075,  0.2127,  0.2557, -0.2819,  0.1574,  0.1793,\n        -0.1486, -0.2249,  0.2770, -0.0023, -0.1830, -0.3223, -0.0225, -0.3171,\n         0.2417, -0.2232,  0.2263,  0.0362, -0.0297, -0.0241,  0.1379, -0.3416,\n         0.0585, -0.2127,  0.3509,  0.2267, -0.2967,  0.2632,  0.2248, -0.0601,\n         0.0343,  0.3327,  0.0958, -0.0039,  0.3309,  0.1306,  0.1459,  0.3375,\n        -0.1058,  0.1720, -0.2859, -0.1707, -0.0808,  0.0343, -0.1398,  0.3326,\n        -0.0698,  0.0462,  0.0832,  0.1615, -0.0871, -0.2279,  0.3194,  0.1397,\n        -0.0781, -0.1814, -0.0244,  0.2014,  0.2273,  0.0787, -0.0849,  0.1677,\n        -0.0695,  0.1279,  0.2211, -0.3310, -0.2293,  0.2893,  0.0616, -0.1721,\n        -0.1946,  0.0626,  0.0337,  0.2101, -0.2386,  0.0542,  0.2443, -0.0614,\n        -0.0880, -0.1670,  0.1412,  0.0369,  0.0536, -0.2107,  0.1500, -0.2217,\n        -0.0262,  0.2402, -0.1748,  0.1122, -0.0805,  0.1903,  0.2429, -0.0454,\n        -0.1229, -0.0416,  0.1275,  0.2158, -0.2072,  0.0352,  0.2696,  0.1661,\n         0.1704, -0.0072,  0.2752,  0.1662, -0.1921,  0.0825,  0.2894,  0.2321,\n        -0.1663, -0.1272,  0.1849, -0.2347,  0.3116, -0.3003, -0.0547,  0.0399,\n         0.2244,  0.3089,  0.1374,  0.0621,  0.0386, -0.2733,  0.1728,  0.3451,\n         0.1391,  0.2141, -0.0328,  0.0414, -0.1327,  0.2122,  0.1728, -0.1295,\n        -0.1443,  0.0145, -0.0191, -0.3493, -0.1714, -0.1363, -0.0694, -0.0260,\n         0.2461, -0.1002, -0.0575,  0.0261,  0.0374, -0.1402,  0.1343,  0.2530,\n         0.2904,  0.1928,  0.0565,  0.1940,  0.1219,  0.2505, -0.2613, -0.3013,\n        -0.0563,  0.1798, -0.3145, -0.1527, -0.1633, -0.3134,  0.0912, -0.1898,\n        -0.0382,  0.0020,  0.1108,  0.1872,  0.0792, -0.1274,  0.0351,  0.0585,\n         0.1468,  0.1536, -0.2820,  0.1918,  0.2775, -0.0806, -0.2238,  0.1614,\n        -0.1320,  0.1849,  0.1372, -0.1721, -0.2878, -0.2786, -0.1507,  0.0789,\n         0.2543,  0.1770,  0.3468, -0.2874,  0.3256, -0.0711, -0.3242, -0.3515],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2920, -0.2102,  0.1500,  ...,  0.3485, -0.1347,  0.1857],\n        [ 0.1371, -0.3032, -0.2757,  ...,  0.0615,  0.3211,  0.1992],\n        [ 0.0711,  0.3098,  0.2594,  ...,  0.1982,  0.0833, -0.0551],\n        ...,\n        [-0.0476, -0.1288,  0.2342,  ..., -0.3290, -0.2061,  0.0585],\n        [-0.0070,  0.3060, -0.2343,  ..., -0.2630,  0.1900,  0.1841],\n        [-0.2782,  0.0396,  0.0048,  ...,  0.3313,  0.2845,  0.3345]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-2.8335e-02,  4.0146e-02,  4.6623e-02, -2.4218e-02,  3.8929e-02,\n         2.0560e-02,  4.5623e-02, -2.0382e-02, -1.3761e-02,  2.1803e-02,\n        -7.8767e-03, -4.5187e-02, -2.9800e-02, -2.9179e-02,  3.6295e-03,\n        -3.7153e-02, -9.3450e-03, -4.9228e-02,  3.4514e-02,  4.9111e-02,\n        -4.8864e-02,  9.2347e-03,  4.9365e-03, -2.7585e-03,  1.1693e-02,\n         1.1689e-02, -1.3438e-02,  3.4792e-02,  1.8445e-02, -1.0028e-02,\n         1.9210e-03,  3.2663e-03, -1.3806e-02, -1.5579e-02,  1.0229e-02,\n        -6.9184e-03, -3.0079e-02,  3.5755e-02, -6.4908e-03, -3.3897e-02,\n         1.3427e-02,  2.0021e-02, -9.9615e-03, -4.1397e-02,  2.8447e-02,\n         1.6822e-02, -4.0187e-02, -3.8386e-02,  3.4461e-02,  1.0609e-02,\n         4.4090e-02,  4.9889e-03,  3.7224e-02, -1.5111e-02, -3.6091e-02,\n         1.9742e-02, -1.4880e-02,  1.6571e-02,  4.6741e-02, -8.9630e-03,\n         6.9234e-03, -2.8471e-02,  4.3450e-02,  2.2517e-02,  4.7550e-02,\n        -4.4007e-02,  1.3449e-02, -1.7948e-02, -3.6548e-03, -3.6496e-02,\n         1.4093e-02, -1.0826e-03,  4.1372e-02,  2.4396e-02, -4.5836e-03,\n        -1.4132e-02,  1.7721e-02,  3.4710e-03,  3.4719e-02,  2.4094e-02,\n         4.2053e-02,  2.0902e-02, -2.1965e-02,  4.7506e-02, -4.8690e-02,\n        -1.3170e-02, -6.5846e-04, -3.4554e-02, -6.9142e-03,  4.8726e-02,\n         2.6553e-02, -1.9765e-03,  1.8080e-02,  4.6477e-02,  4.5328e-02,\n        -3.3595e-02, -4.3408e-02,  2.8661e-02,  2.0844e-02,  1.6894e-02,\n         3.3272e-02, -3.7443e-02,  3.5904e-02, -1.1419e-02,  2.7682e-02,\n        -1.2969e-02, -4.5540e-02,  2.4859e-03,  4.8296e-02,  2.7891e-02,\n         2.7846e-02,  4.9520e-02, -3.8172e-02, -4.8287e-03, -3.0253e-02,\n        -3.7504e-02,  4.4506e-02, -4.4249e-02, -2.5641e-02, -3.4344e-02,\n         3.4014e-02,  4.7347e-02,  3.0628e-02,  3.3235e-02, -2.1925e-02,\n         6.2003e-03,  4.6982e-02,  4.3738e-02, -3.0819e-02,  3.3625e-02,\n        -6.4074e-03,  4.3013e-02,  1.6874e-03,  8.5313e-03,  1.8127e-02,\n        -3.5164e-02, -2.4969e-02,  1.9345e-02,  2.0490e-02, -4.8327e-02,\n         4.8487e-02, -1.5167e-02, -4.8732e-02, -4.3753e-03, -2.3384e-02,\n        -1.8340e-02,  4.9397e-02, -3.0679e-03, -4.5943e-02,  3.8075e-02,\n        -1.2001e-02, -2.7459e-02, -1.5370e-02, -2.1561e-02,  3.0691e-02,\n        -2.4845e-02,  4.1577e-02, -1.4829e-02,  4.4272e-02,  4.2516e-02,\n         3.0994e-02, -1.1523e-02,  2.5143e-02,  1.8101e-02,  4.0065e-03,\n        -4.2013e-02, -1.6690e-02,  4.5988e-02,  3.0805e-02, -3.2775e-02,\n         1.7100e-02, -1.7751e-03, -2.6971e-02, -9.9104e-03,  1.6034e-02,\n        -1.4082e-02, -3.2233e-02, -4.2866e-02,  2.0764e-03,  2.4157e-03,\n         7.7585e-03,  8.9808e-03,  1.9347e-03, -4.9543e-02,  1.4615e-02,\n        -2.0387e-02,  1.9342e-02,  3.2797e-02, -1.9746e-02,  1.0368e-02,\n        -9.8511e-03,  2.4345e-02, -3.1295e-02,  4.5445e-02,  1.8603e-02,\n         2.5707e-02, -4.8029e-02, -3.9452e-02,  1.5323e-02,  1.2417e-02,\n        -4.1844e-03,  4.3187e-02,  9.6313e-04,  9.4668e-03, -2.9895e-02,\n         4.7640e-02, -4.1494e-02, -1.5022e-02,  3.6620e-02, -2.2799e-02,\n         9.7493e-03,  7.9921e-03, -1.7700e-02, -2.6859e-03,  1.3204e-02,\n         4.8540e-02,  3.7660e-02,  8.8232e-03,  8.0623e-03,  4.1854e-03,\n        -3.9410e-02, -4.0357e-02,  2.6810e-02,  4.7943e-02,  3.1580e-02,\n        -1.2080e-02,  2.9153e-02,  2.6448e-02,  1.6723e-02, -2.5418e-02,\n        -4.3971e-02, -3.1146e-02,  2.8148e-03, -3.8422e-02,  3.8429e-02,\n         3.7243e-02,  3.4284e-02,  3.4245e-02,  4.4721e-02,  4.4678e-02,\n        -9.8947e-03,  1.2984e-03, -2.3353e-02, -4.6098e-02,  4.6173e-02,\n         2.2799e-02, -1.0860e-02,  4.0930e-02, -3.7970e-02, -4.4093e-02,\n         3.7362e-02, -5.4385e-03, -3.8852e-04, -1.3631e-03,  2.9148e-02,\n         4.7213e-02,  7.0163e-03,  2.2377e-02, -6.8871e-03, -1.4241e-02,\n        -9.4721e-03, -3.1200e-02,  3.0118e-02, -2.7970e-02, -9.7065e-03,\n        -1.8669e-02, -1.1825e-02, -2.4918e-02,  7.7998e-03,  1.7545e-02,\n         3.7381e-02, -4.2611e-03,  1.5217e-02, -4.5601e-02, -3.8892e-02,\n         1.9003e-04, -2.6262e-02,  1.0129e-03,  3.1200e-02,  3.2470e-02,\n         1.0995e-02,  2.9696e-02,  4.1440e-02,  9.3807e-03,  2.5414e-02,\n        -1.7131e-02,  2.7714e-02,  4.8443e-02, -1.2444e-02, -3.5683e-02,\n        -1.6803e-05,  3.1590e-02, -2.8186e-02, -4.3093e-02, -3.0726e-02,\n         1.0759e-02, -4.4649e-02, -2.0332e-02, -8.6480e-05, -3.5390e-02],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-3.3485e-02,  3.2954e-04,  9.7334e-03,  ..., -4.7827e-02,\n         -2.9997e-02, -2.3288e-03],\n        [ 3.4024e-02,  3.0217e-02,  2.3028e-02,  ...,  2.2907e-02,\n         -6.4450e-03,  4.7669e-02],\n        [-4.2486e-02, -3.9959e-03, -4.3477e-02,  ..., -1.6339e-02,\n          1.3202e-02, -1.9434e-02],\n        ...,\n        [ 4.2887e-02,  2.8574e-05, -2.0912e-02,  ..., -3.3034e-02,\n          2.9165e-02,  4.2921e-02],\n        [ 3.1202e-02, -1.4567e-02, -7.6371e-03,  ..., -2.4069e-02,\n         -4.2383e-02, -5.0594e-03],\n        [ 3.6028e-02,  4.6573e-02,  2.3044e-02,  ..., -4.5284e-02,\n          4.0679e-02,  9.4514e-03]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0571,  0.0307,  0.0411,  0.0181], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0277,  0.0106,  0.0164,  ..., -0.0202, -0.0036,  0.0498],\n        [ 0.0015,  0.0045, -0.0105,  ..., -0.0080, -0.0444, -0.0077],\n        [-0.0166, -0.0459,  0.0105,  ..., -0.0393,  0.0418,  0.0132],\n        [-0.0157, -0.0178, -0.0465,  ...,  0.0314, -0.0531,  0.0490]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2920, -0.2102,  0.1500,  ...,  0.3485, -0.1347,  0.1857],\n        [ 0.1371, -0.3032, -0.2757,  ...,  0.0615,  0.3211,  0.1992],\n        [ 0.0711,  0.3098,  0.2594,  ...,  0.1982,  0.0833, -0.0551],\n        ...,\n        [-0.0476, -0.1288,  0.2342,  ..., -0.3290, -0.2061,  0.0585],\n        [-0.0070,  0.3060, -0.2343,  ..., -0.2630,  0.1900,  0.1841],\n        [-0.2782,  0.0396,  0.0048,  ...,  0.3313,  0.2845,  0.3345]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1266,  0.0543, -0.0325,  0.1982, -0.2789, -0.2790, -0.0606, -0.1696,\n        -0.2118,  0.2516,  0.2934, -0.2599, -0.1549,  0.1277, -0.0951,  0.1527,\n        -0.1942,  0.2765, -0.0917, -0.3357,  0.2901, -0.1385, -0.1499,  0.1526,\n         0.1630,  0.3403,  0.1453, -0.0530, -0.1137, -0.1543, -0.0934, -0.0403,\n         0.2034,  0.1430, -0.2940, -0.1414,  0.2084,  0.1319,  0.1636, -0.0562,\n         0.1070,  0.0281,  0.1098, -0.1058,  0.2432,  0.0469,  0.0102, -0.2668,\n        -0.0778, -0.2056, -0.0266,  0.2060, -0.1160, -0.1234,  0.0292,  0.2542,\n        -0.2752,  0.1901,  0.0202,  0.0739,  0.0120, -0.1605,  0.3004,  0.1394,\n         0.2572,  0.1485,  0.0340, -0.1841,  0.1545, -0.0810,  0.3413,  0.2244,\n         0.2069,  0.2175, -0.1133, -0.3006,  0.3333, -0.3203, -0.2266,  0.1876,\n        -0.1868, -0.2408,  0.1716, -0.3258,  0.1774, -0.0379,  0.0048, -0.3119,\n        -0.3522,  0.0759,  0.1236, -0.2525, -0.1564, -0.0576,  0.2717, -0.1156,\n         0.2277, -0.2398, -0.1120,  0.0511, -0.1991,  0.2511, -0.0538, -0.0711,\n         0.3295, -0.3473, -0.0352, -0.3412, -0.1754,  0.0420, -0.3224,  0.2067,\n         0.1580, -0.1837, -0.1228,  0.2046,  0.3227, -0.2876,  0.2902,  0.3382,\n         0.0095, -0.0325,  0.2945,  0.1938, -0.0841, -0.1275, -0.1556,  0.2184,\n        -0.0524,  0.3075, -0.3450,  0.0957,  0.0141, -0.1208,  0.3005,  0.2570,\n        -0.0661, -0.1200,  0.3496,  0.3110, -0.0183, -0.0284, -0.3003, -0.2853,\n        -0.1570,  0.1284,  0.1111, -0.2579, -0.1017, -0.0023,  0.2892, -0.2693,\n         0.1504, -0.1782,  0.2400,  0.0263, -0.2866, -0.1981,  0.1913,  0.3488,\n         0.1552,  0.0726, -0.1474, -0.2944,  0.1922, -0.1305, -0.2080,  0.2103,\n        -0.2419, -0.0469, -0.0964,  0.1837, -0.3005,  0.2201, -0.1593, -0.1888,\n        -0.0254, -0.1318, -0.2474,  0.2839,  0.3450,  0.3144, -0.0018, -0.2279,\n         0.2389, -0.2562,  0.1337, -0.2808, -0.0811, -0.1338,  0.2403,  0.0642,\n         0.2872, -0.2082, -0.0763,  0.2879, -0.1262,  0.2007, -0.2207, -0.0371,\n        -0.0361, -0.1755, -0.0075,  0.2127,  0.2557, -0.2819,  0.1574,  0.1793,\n        -0.1486, -0.2249,  0.2770, -0.0023, -0.1830, -0.3223, -0.0225, -0.3171,\n         0.2417, -0.2232,  0.2263,  0.0362, -0.0297, -0.0241,  0.1379, -0.3416,\n         0.0585, -0.2127,  0.3509,  0.2267, -0.2967,  0.2632,  0.2248, -0.0601,\n         0.0343,  0.3327,  0.0958, -0.0039,  0.3309,  0.1306,  0.1459,  0.3375,\n        -0.1058,  0.1720, -0.2859, -0.1707, -0.0808,  0.0343, -0.1398,  0.3326,\n        -0.0698,  0.0462,  0.0832,  0.1615, -0.0871, -0.2279,  0.3194,  0.1397,\n        -0.0781, -0.1814, -0.0244,  0.2014,  0.2273,  0.0787, -0.0849,  0.1677,\n        -0.0695,  0.1279,  0.2211, -0.3310, -0.2293,  0.2893,  0.0616, -0.1721,\n        -0.1946,  0.0626,  0.0337,  0.2101, -0.2386,  0.0542,  0.2443, -0.0614,\n        -0.0880, -0.1670,  0.1412,  0.0369,  0.0536, -0.2107,  0.1500, -0.2217,\n        -0.0262,  0.2402, -0.1748,  0.1122, -0.0805,  0.1903,  0.2429, -0.0454,\n        -0.1229, -0.0416,  0.1275,  0.2158, -0.2072,  0.0352,  0.2696,  0.1661,\n         0.1704, -0.0072,  0.2752,  0.1662, -0.1921,  0.0825,  0.2894,  0.2321,\n        -0.1663, -0.1272,  0.1849, -0.2347,  0.3116, -0.3003, -0.0547,  0.0399,\n         0.2244,  0.3089,  0.1374,  0.0621,  0.0386, -0.2733,  0.1728,  0.3451,\n         0.1391,  0.2141, -0.0328,  0.0414, -0.1327,  0.2122,  0.1728, -0.1295,\n        -0.1443,  0.0145, -0.0191, -0.3493, -0.1714, -0.1363, -0.0694, -0.0260,\n         0.2461, -0.1002, -0.0575,  0.0261,  0.0374, -0.1402,  0.1343,  0.2530,\n         0.2904,  0.1928,  0.0565,  0.1940,  0.1219,  0.2505, -0.2613, -0.3013,\n        -0.0563,  0.1798, -0.3145, -0.1527, -0.1633, -0.3134,  0.0912, -0.1898,\n        -0.0382,  0.0020,  0.1108,  0.1872,  0.0792, -0.1274,  0.0351,  0.0585,\n         0.1468,  0.1536, -0.2820,  0.1918,  0.2775, -0.0806, -0.2238,  0.1614,\n        -0.1320,  0.1849,  0.1372, -0.1721, -0.2878, -0.2786, -0.1507,  0.0789,\n         0.2543,  0.1770,  0.3468, -0.2874,  0.3256, -0.0711, -0.3242, -0.3515],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-3.3485e-02,  3.2954e-04,  9.7334e-03,  ..., -4.7827e-02,\n         -2.9997e-02, -2.3288e-03],\n        [ 3.4024e-02,  3.0217e-02,  2.3028e-02,  ...,  2.2907e-02,\n         -6.4450e-03,  4.7669e-02],\n        [-4.2486e-02, -3.9959e-03, -4.3477e-02,  ..., -1.6339e-02,\n          1.3202e-02, -1.9434e-02],\n        ...,\n        [ 4.2887e-02,  2.8574e-05, -2.0912e-02,  ..., -3.3034e-02,\n          2.9165e-02,  4.2921e-02],\n        [ 3.1202e-02, -1.4567e-02, -7.6371e-03,  ..., -2.4069e-02,\n         -4.2383e-02, -5.0594e-03],\n        [ 3.6028e-02,  4.6573e-02,  2.3044e-02,  ..., -4.5284e-02,\n          4.0679e-02,  9.4514e-03]], requires_grad=True)",
                                "Parameter containing:\ntensor([-2.8335e-02,  4.0146e-02,  4.6623e-02, -2.4218e-02,  3.8929e-02,\n         2.0560e-02,  4.5623e-02, -2.0382e-02, -1.3761e-02,  2.1803e-02,\n        -7.8767e-03, -4.5187e-02, -2.9800e-02, -2.9179e-02,  3.6295e-03,\n        -3.7153e-02, -9.3450e-03, -4.9228e-02,  3.4514e-02,  4.9111e-02,\n        -4.8864e-02,  9.2347e-03,  4.9365e-03, -2.7585e-03,  1.1693e-02,\n         1.1689e-02, -1.3438e-02,  3.4792e-02,  1.8445e-02, -1.0028e-02,\n         1.9210e-03,  3.2663e-03, -1.3806e-02, -1.5579e-02,  1.0229e-02,\n        -6.9184e-03, -3.0079e-02,  3.5755e-02, -6.4908e-03, -3.3897e-02,\n         1.3427e-02,  2.0021e-02, -9.9615e-03, -4.1397e-02,  2.8447e-02,\n         1.6822e-02, -4.0187e-02, -3.8386e-02,  3.4461e-02,  1.0609e-02,\n         4.4090e-02,  4.9889e-03,  3.7224e-02, -1.5111e-02, -3.6091e-02,\n         1.9742e-02, -1.4880e-02,  1.6571e-02,  4.6741e-02, -8.9630e-03,\n         6.9234e-03, -2.8471e-02,  4.3450e-02,  2.2517e-02,  4.7550e-02,\n        -4.4007e-02,  1.3449e-02, -1.7948e-02, -3.6548e-03, -3.6496e-02,\n         1.4093e-02, -1.0826e-03,  4.1372e-02,  2.4396e-02, -4.5836e-03,\n        -1.4132e-02,  1.7721e-02,  3.4710e-03,  3.4719e-02,  2.4094e-02,\n         4.2053e-02,  2.0902e-02, -2.1965e-02,  4.7506e-02, -4.8690e-02,\n        -1.3170e-02, -6.5846e-04, -3.4554e-02, -6.9142e-03,  4.8726e-02,\n         2.6553e-02, -1.9765e-03,  1.8080e-02,  4.6477e-02,  4.5328e-02,\n        -3.3595e-02, -4.3408e-02,  2.8661e-02,  2.0844e-02,  1.6894e-02,\n         3.3272e-02, -3.7443e-02,  3.5904e-02, -1.1419e-02,  2.7682e-02,\n        -1.2969e-02, -4.5540e-02,  2.4859e-03,  4.8296e-02,  2.7891e-02,\n         2.7846e-02,  4.9520e-02, -3.8172e-02, -4.8287e-03, -3.0253e-02,\n        -3.7504e-02,  4.4506e-02, -4.4249e-02, -2.5641e-02, -3.4344e-02,\n         3.4014e-02,  4.7347e-02,  3.0628e-02,  3.3235e-02, -2.1925e-02,\n         6.2003e-03,  4.6982e-02,  4.3738e-02, -3.0819e-02,  3.3625e-02,\n        -6.4074e-03,  4.3013e-02,  1.6874e-03,  8.5313e-03,  1.8127e-02,\n        -3.5164e-02, -2.4969e-02,  1.9345e-02,  2.0490e-02, -4.8327e-02,\n         4.8487e-02, -1.5167e-02, -4.8732e-02, -4.3753e-03, -2.3384e-02,\n        -1.8340e-02,  4.9397e-02, -3.0679e-03, -4.5943e-02,  3.8075e-02,\n        -1.2001e-02, -2.7459e-02, -1.5370e-02, -2.1561e-02,  3.0691e-02,\n        -2.4845e-02,  4.1577e-02, -1.4829e-02,  4.4272e-02,  4.2516e-02,\n         3.0994e-02, -1.1523e-02,  2.5143e-02,  1.8101e-02,  4.0065e-03,\n        -4.2013e-02, -1.6690e-02,  4.5988e-02,  3.0805e-02, -3.2775e-02,\n         1.7100e-02, -1.7751e-03, -2.6971e-02, -9.9104e-03,  1.6034e-02,\n        -1.4082e-02, -3.2233e-02, -4.2866e-02,  2.0764e-03,  2.4157e-03,\n         7.7585e-03,  8.9808e-03,  1.9347e-03, -4.9543e-02,  1.4615e-02,\n        -2.0387e-02,  1.9342e-02,  3.2797e-02, -1.9746e-02,  1.0368e-02,\n        -9.8511e-03,  2.4345e-02, -3.1295e-02,  4.5445e-02,  1.8603e-02,\n         2.5707e-02, -4.8029e-02, -3.9452e-02,  1.5323e-02,  1.2417e-02,\n        -4.1844e-03,  4.3187e-02,  9.6313e-04,  9.4668e-03, -2.9895e-02,\n         4.7640e-02, -4.1494e-02, -1.5022e-02,  3.6620e-02, -2.2799e-02,\n         9.7493e-03,  7.9921e-03, -1.7700e-02, -2.6859e-03,  1.3204e-02,\n         4.8540e-02,  3.7660e-02,  8.8232e-03,  8.0623e-03,  4.1854e-03,\n        -3.9410e-02, -4.0357e-02,  2.6810e-02,  4.7943e-02,  3.1580e-02,\n        -1.2080e-02,  2.9153e-02,  2.6448e-02,  1.6723e-02, -2.5418e-02,\n        -4.3971e-02, -3.1146e-02,  2.8148e-03, -3.8422e-02,  3.8429e-02,\n         3.7243e-02,  3.4284e-02,  3.4245e-02,  4.4721e-02,  4.4678e-02,\n        -9.8947e-03,  1.2984e-03, -2.3353e-02, -4.6098e-02,  4.6173e-02,\n         2.2799e-02, -1.0860e-02,  4.0930e-02, -3.7970e-02, -4.4093e-02,\n         3.7362e-02, -5.4385e-03, -3.8852e-04, -1.3631e-03,  2.9148e-02,\n         4.7213e-02,  7.0163e-03,  2.2377e-02, -6.8871e-03, -1.4241e-02,\n        -9.4721e-03, -3.1200e-02,  3.0118e-02, -2.7970e-02, -9.7065e-03,\n        -1.8669e-02, -1.1825e-02, -2.4918e-02,  7.7998e-03,  1.7545e-02,\n         3.7381e-02, -4.2611e-03,  1.5217e-02, -4.5601e-02, -3.8892e-02,\n         1.9003e-04, -2.6262e-02,  1.0129e-03,  3.1200e-02,  3.2470e-02,\n         1.0995e-02,  2.9696e-02,  4.1440e-02,  9.3807e-03,  2.5414e-02,\n        -1.7131e-02,  2.7714e-02,  4.8443e-02, -1.2444e-02, -3.5683e-02,\n        -1.6803e-05,  3.1590e-02, -2.8186e-02, -4.3093e-02, -3.0726e-02,\n         1.0759e-02, -4.4649e-02, -2.0332e-02, -8.6480e-05, -3.5390e-02],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0277,  0.0106,  0.0164,  ..., -0.0202, -0.0036,  0.0498],\n        [ 0.0015,  0.0045, -0.0105,  ..., -0.0080, -0.0444, -0.0077],\n        [-0.0166, -0.0459,  0.0105,  ..., -0.0393,  0.0418,  0.0132],\n        [-0.0157, -0.0178, -0.0465,  ...,  0.0314, -0.0531,  0.0490]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0571,  0.0307,  0.0411,  0.0181], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x75a5056e2490>":	{
                    "capacity":	50000,
                    "current_segment":	0,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	50000,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1266,  0.0543, -0.0325,  0.1982, -0.2789, -0.2790, -0.0606, -0.1696,\n        -0.2118,  0.2516,  0.2934, -0.2599, -0.1549,  0.1277, -0.0951,  0.1527,\n        -0.1942,  0.2765, -0.0917, -0.3357,  0.2901, -0.1385, -0.1499,  0.1526,\n         0.1630,  0.3403,  0.1453, -0.0530, -0.1137, -0.1543, -0.0934, -0.0403,\n         0.2034,  0.1430, -0.2940, -0.1414,  0.2084,  0.1319,  0.1636, -0.0562,\n         0.1070,  0.0281,  0.1098, -0.1058,  0.2432,  0.0469,  0.0102, -0.2668,\n        -0.0778, -0.2056, -0.0266,  0.2060, -0.1160, -0.1234,  0.0292,  0.2542,\n        -0.2752,  0.1901,  0.0202,  0.0739,  0.0120, -0.1605,  0.3004,  0.1394,\n         0.2572,  0.1485,  0.0340, -0.1841,  0.1545, -0.0810,  0.3413,  0.2244,\n         0.2069,  0.2175, -0.1133, -0.3006,  0.3333, -0.3203, -0.2266,  0.1876,\n        -0.1868, -0.2408,  0.1716, -0.3258,  0.1774, -0.0379,  0.0048, -0.3119,\n        -0.3522,  0.0759,  0.1236, -0.2525, -0.1564, -0.0576,  0.2717, -0.1156,\n         0.2277, -0.2398, -0.1120,  0.0511, -0.1991,  0.2511, -0.0538, -0.0711,\n         0.3295, -0.3473, -0.0352, -0.3412, -0.1754,  0.0420, -0.3224,  0.2067,\n         0.1580, -0.1837, -0.1228,  0.2046,  0.3227, -0.2876,  0.2902,  0.3382,\n         0.0095, -0.0325,  0.2945,  0.1938, -0.0841, -0.1275, -0.1556,  0.2184,\n        -0.0524,  0.3075, -0.3450,  0.0957,  0.0141, -0.1208,  0.3005,  0.2570,\n        -0.0661, -0.1200,  0.3496,  0.3110, -0.0183, -0.0284, -0.3003, -0.2853,\n        -0.1570,  0.1284,  0.1111, -0.2579, -0.1017, -0.0023,  0.2892, -0.2693,\n         0.1504, -0.1782,  0.2400,  0.0263, -0.2866, -0.1981,  0.1913,  0.3488,\n         0.1552,  0.0726, -0.1474, -0.2944,  0.1922, -0.1305, -0.2080,  0.2103,\n        -0.2419, -0.0469, -0.0964,  0.1837, -0.3005,  0.2201, -0.1593, -0.1888,\n        -0.0254, -0.1318, -0.2474,  0.2839,  0.3450,  0.3144, -0.0018, -0.2279,\n         0.2389, -0.2562,  0.1337, -0.2808, -0.0811, -0.1338,  0.2403,  0.0642,\n         0.2872, -0.2082, -0.0763,  0.2879, -0.1262,  0.2007, -0.2207, -0.0371,\n        -0.0361, -0.1755, -0.0075,  0.2127,  0.2557, -0.2819,  0.1574,  0.1793,\n        -0.1486, -0.2249,  0.2770, -0.0023, -0.1830, -0.3223, -0.0225, -0.3171,\n         0.2417, -0.2232,  0.2263,  0.0362, -0.0297, -0.0241,  0.1379, -0.3416,\n         0.0585, -0.2127,  0.3509,  0.2267, -0.2967,  0.2632,  0.2248, -0.0601,\n         0.0343,  0.3327,  0.0958, -0.0039,  0.3309,  0.1306,  0.1459,  0.3375,\n        -0.1058,  0.1720, -0.2859, -0.1707, -0.0808,  0.0343, -0.1398,  0.3326,\n        -0.0698,  0.0462,  0.0832,  0.1615, -0.0871, -0.2279,  0.3194,  0.1397,\n        -0.0781, -0.1814, -0.0244,  0.2014,  0.2273,  0.0787, -0.0849,  0.1677,\n        -0.0695,  0.1279,  0.2211, -0.3310, -0.2293,  0.2893,  0.0616, -0.1721,\n        -0.1946,  0.0626,  0.0337,  0.2101, -0.2386,  0.0542,  0.2443, -0.0614,\n        -0.0880, -0.1670,  0.1412,  0.0369,  0.0536, -0.2107,  0.1500, -0.2217,\n        -0.0262,  0.2402, -0.1748,  0.1122, -0.0805,  0.1903,  0.2429, -0.0454,\n        -0.1229, -0.0416,  0.1275,  0.2158, -0.2072,  0.0352,  0.2696,  0.1661,\n         0.1704, -0.0072,  0.2752,  0.1662, -0.1921,  0.0825,  0.2894,  0.2321,\n        -0.1663, -0.1272,  0.1849, -0.2347,  0.3116, -0.3003, -0.0547,  0.0399,\n         0.2244,  0.3089,  0.1374,  0.0621,  0.0386, -0.2733,  0.1728,  0.3451,\n         0.1391,  0.2141, -0.0328,  0.0414, -0.1327,  0.2122,  0.1728, -0.1295,\n        -0.1443,  0.0145, -0.0191, -0.3493, -0.1714, -0.1363, -0.0694, -0.0260,\n         0.2461, -0.1002, -0.0575,  0.0261,  0.0374, -0.1402,  0.1343,  0.2530,\n         0.2904,  0.1928,  0.0565,  0.1940,  0.1219,  0.2505, -0.2613, -0.3013,\n        -0.0563,  0.1798, -0.3145, -0.1527, -0.1633, -0.3134,  0.0912, -0.1898,\n        -0.0382,  0.0020,  0.1108,  0.1872,  0.0792, -0.1274,  0.0351,  0.0585,\n         0.1468,  0.1536, -0.2820,  0.1918,  0.2775, -0.0806, -0.2238,  0.1614,\n        -0.1320,  0.1849,  0.1372, -0.1721, -0.2878, -0.2786, -0.1507,  0.0789,\n         0.2543,  0.1770,  0.3468, -0.2874,  0.3256, -0.0711, -0.3242, -0.3515],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2920, -0.2102,  0.1500,  ...,  0.3485, -0.1347,  0.1857],\n        [ 0.1371, -0.3032, -0.2757,  ...,  0.0615,  0.3211,  0.1992],\n        [ 0.0711,  0.3098,  0.2594,  ...,  0.1982,  0.0833, -0.0551],\n        ...,\n        [-0.0476, -0.1288,  0.2342,  ..., -0.3290, -0.2061,  0.0585],\n        [-0.0070,  0.3060, -0.2343,  ..., -0.2630,  0.1900,  0.1841],\n        [-0.2782,  0.0396,  0.0048,  ...,  0.3313,  0.2845,  0.3345]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-2.8335e-02,  4.0146e-02,  4.6623e-02, -2.4218e-02,  3.8929e-02,\n         2.0560e-02,  4.5623e-02, -2.0382e-02, -1.3761e-02,  2.1803e-02,\n        -7.8767e-03, -4.5187e-02, -2.9800e-02, -2.9179e-02,  3.6295e-03,\n        -3.7153e-02, -9.3450e-03, -4.9228e-02,  3.4514e-02,  4.9111e-02,\n        -4.8864e-02,  9.2347e-03,  4.9365e-03, -2.7585e-03,  1.1693e-02,\n         1.1689e-02, -1.3438e-02,  3.4792e-02,  1.8445e-02, -1.0028e-02,\n         1.9210e-03,  3.2663e-03, -1.3806e-02, -1.5579e-02,  1.0229e-02,\n        -6.9184e-03, -3.0079e-02,  3.5755e-02, -6.4908e-03, -3.3897e-02,\n         1.3427e-02,  2.0021e-02, -9.9615e-03, -4.1397e-02,  2.8447e-02,\n         1.6822e-02, -4.0187e-02, -3.8386e-02,  3.4461e-02,  1.0609e-02,\n         4.4090e-02,  4.9889e-03,  3.7224e-02, -1.5111e-02, -3.6091e-02,\n         1.9742e-02, -1.4880e-02,  1.6571e-02,  4.6741e-02, -8.9630e-03,\n         6.9234e-03, -2.8471e-02,  4.3450e-02,  2.2517e-02,  4.7550e-02,\n        -4.4007e-02,  1.3449e-02, -1.7948e-02, -3.6548e-03, -3.6496e-02,\n         1.4093e-02, -1.0826e-03,  4.1372e-02,  2.4396e-02, -4.5836e-03,\n        -1.4132e-02,  1.7721e-02,  3.4710e-03,  3.4719e-02,  2.4094e-02,\n         4.2053e-02,  2.0902e-02, -2.1965e-02,  4.7506e-02, -4.8690e-02,\n        -1.3170e-02, -6.5846e-04, -3.4554e-02, -6.9142e-03,  4.8726e-02,\n         2.6553e-02, -1.9765e-03,  1.8080e-02,  4.6477e-02,  4.5328e-02,\n        -3.3595e-02, -4.3408e-02,  2.8661e-02,  2.0844e-02,  1.6894e-02,\n         3.3272e-02, -3.7443e-02,  3.5904e-02, -1.1419e-02,  2.7682e-02,\n        -1.2969e-02, -4.5540e-02,  2.4859e-03,  4.8296e-02,  2.7891e-02,\n         2.7846e-02,  4.9520e-02, -3.8172e-02, -4.8287e-03, -3.0253e-02,\n        -3.7504e-02,  4.4506e-02, -4.4249e-02, -2.5641e-02, -3.4344e-02,\n         3.4014e-02,  4.7347e-02,  3.0628e-02,  3.3235e-02, -2.1925e-02,\n         6.2003e-03,  4.6982e-02,  4.3738e-02, -3.0819e-02,  3.3625e-02,\n        -6.4074e-03,  4.3013e-02,  1.6874e-03,  8.5313e-03,  1.8127e-02,\n        -3.5164e-02, -2.4969e-02,  1.9345e-02,  2.0490e-02, -4.8327e-02,\n         4.8487e-02, -1.5167e-02, -4.8732e-02, -4.3753e-03, -2.3384e-02,\n        -1.8340e-02,  4.9397e-02, -3.0679e-03, -4.5943e-02,  3.8075e-02,\n        -1.2001e-02, -2.7459e-02, -1.5370e-02, -2.1561e-02,  3.0691e-02,\n        -2.4845e-02,  4.1577e-02, -1.4829e-02,  4.4272e-02,  4.2516e-02,\n         3.0994e-02, -1.1523e-02,  2.5143e-02,  1.8101e-02,  4.0065e-03,\n        -4.2013e-02, -1.6690e-02,  4.5988e-02,  3.0805e-02, -3.2775e-02,\n         1.7100e-02, -1.7751e-03, -2.6971e-02, -9.9104e-03,  1.6034e-02,\n        -1.4082e-02, -3.2233e-02, -4.2866e-02,  2.0764e-03,  2.4157e-03,\n         7.7585e-03,  8.9808e-03,  1.9347e-03, -4.9543e-02,  1.4615e-02,\n        -2.0387e-02,  1.9342e-02,  3.2797e-02, -1.9746e-02,  1.0368e-02,\n        -9.8511e-03,  2.4345e-02, -3.1295e-02,  4.5445e-02,  1.8603e-02,\n         2.5707e-02, -4.8029e-02, -3.9452e-02,  1.5323e-02,  1.2417e-02,\n        -4.1844e-03,  4.3187e-02,  9.6313e-04,  9.4668e-03, -2.9895e-02,\n         4.7640e-02, -4.1494e-02, -1.5022e-02,  3.6620e-02, -2.2799e-02,\n         9.7493e-03,  7.9921e-03, -1.7700e-02, -2.6859e-03,  1.3204e-02,\n         4.8540e-02,  3.7660e-02,  8.8232e-03,  8.0623e-03,  4.1854e-03,\n        -3.9410e-02, -4.0357e-02,  2.6810e-02,  4.7943e-02,  3.1580e-02,\n        -1.2080e-02,  2.9153e-02,  2.6448e-02,  1.6723e-02, -2.5418e-02,\n        -4.3971e-02, -3.1146e-02,  2.8148e-03, -3.8422e-02,  3.8429e-02,\n         3.7243e-02,  3.4284e-02,  3.4245e-02,  4.4721e-02,  4.4678e-02,\n        -9.8947e-03,  1.2984e-03, -2.3353e-02, -4.6098e-02,  4.6173e-02,\n         2.2799e-02, -1.0860e-02,  4.0930e-02, -3.7970e-02, -4.4093e-02,\n         3.7362e-02, -5.4385e-03, -3.8852e-04, -1.3631e-03,  2.9148e-02,\n         4.7213e-02,  7.0163e-03,  2.2377e-02, -6.8871e-03, -1.4241e-02,\n        -9.4721e-03, -3.1200e-02,  3.0118e-02, -2.7970e-02, -9.7065e-03,\n        -1.8669e-02, -1.1825e-02, -2.4918e-02,  7.7998e-03,  1.7545e-02,\n         3.7381e-02, -4.2611e-03,  1.5217e-02, -4.5601e-02, -3.8892e-02,\n         1.9003e-04, -2.6262e-02,  1.0129e-03,  3.1200e-02,  3.2470e-02,\n         1.0995e-02,  2.9696e-02,  4.1440e-02,  9.3807e-03,  2.5414e-02,\n        -1.7131e-02,  2.7714e-02,  4.8443e-02, -1.2444e-02, -3.5683e-02,\n        -1.6803e-05,  3.1590e-02, -2.8186e-02, -4.3093e-02, -3.0726e-02,\n         1.0759e-02, -4.4649e-02, -2.0332e-02, -8.6480e-05, -3.5390e-02],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-3.3485e-02,  3.2954e-04,  9.7334e-03,  ..., -4.7827e-02,\n         -2.9997e-02, -2.3288e-03],\n        [ 3.4024e-02,  3.0217e-02,  2.3028e-02,  ...,  2.2907e-02,\n         -6.4450e-03,  4.7669e-02],\n        [-4.2486e-02, -3.9959e-03, -4.3477e-02,  ..., -1.6339e-02,\n          1.3202e-02, -1.9434e-02],\n        ...,\n        [ 4.2887e-02,  2.8574e-05, -2.0912e-02,  ..., -3.3034e-02,\n          2.9165e-02,  4.2921e-02],\n        [ 3.1202e-02, -1.4567e-02, -7.6371e-03,  ..., -2.4069e-02,\n         -4.2383e-02, -5.0594e-03],\n        [ 3.6028e-02,  4.6573e-02,  2.3044e-02,  ..., -4.5284e-02,\n          4.0679e-02,  9.4514e-03]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0571,  0.0307,  0.0411,  0.0181], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0277,  0.0106,  0.0164,  ..., -0.0202, -0.0036,  0.0498],\n        [ 0.0015,  0.0045, -0.0105,  ..., -0.0080, -0.0444, -0.0077],\n        [-0.0166, -0.0459,  0.0105,  ..., -0.0393,  0.0418,  0.0132],\n        [-0.0157, -0.0178, -0.0465,  ...,  0.0314, -0.0531,  0.0490]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x75a47afff050>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s137640000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s137640000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}