{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.01,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s139790000"
    },
    "max_sample_age":	-1,
    "q_lr":	0.003,
    "seed":	139790000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x759fe6d66910>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.01,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1532, -0.0396,  0.0241, -0.2217,  0.3531, -0.2824,  0.2896,  0.2685,\n        -0.0164,  0.2007,  0.1488,  0.2333,  0.3324,  0.1764, -0.0186,  0.0325,\n         0.2008,  0.1235, -0.0632,  0.1734,  0.2950, -0.0209,  0.2913, -0.3296,\n         0.2505, -0.3474,  0.1445, -0.2306, -0.3023,  0.0332,  0.0203,  0.1914,\n         0.3096,  0.1515, -0.0894,  0.2288,  0.0941,  0.2296,  0.3135, -0.2155,\n        -0.2878, -0.3029,  0.1631, -0.3337,  0.0190,  0.0074,  0.3208, -0.0685,\n        -0.1926,  0.2272,  0.1014,  0.0610, -0.1674, -0.1214, -0.2973, -0.2212,\n         0.0014, -0.2004,  0.1370, -0.2841,  0.3233, -0.0196,  0.0479, -0.3237,\n        -0.2911,  0.1550,  0.2604,  0.2611,  0.0705, -0.2185, -0.0582,  0.1977,\n        -0.2866, -0.1625, -0.2261, -0.0633,  0.1753, -0.2425,  0.1405, -0.0648,\n         0.2498, -0.1606, -0.2542,  0.1235, -0.0661, -0.0370, -0.1877,  0.2357,\n        -0.0189, -0.0038, -0.0065, -0.1213, -0.2836,  0.3177,  0.3110, -0.1024,\n         0.2255, -0.0946, -0.0216, -0.0333, -0.0744, -0.0349,  0.0084, -0.1897,\n        -0.0597, -0.3380, -0.2175,  0.0173, -0.1213,  0.2134,  0.2956,  0.1575,\n         0.2899, -0.1668,  0.2775,  0.1397, -0.2849,  0.2546, -0.1639, -0.0013,\n         0.1019,  0.1045,  0.2259, -0.3470,  0.2840,  0.0353,  0.3141,  0.0259,\n        -0.0596, -0.0815,  0.0910, -0.2788,  0.0308,  0.3083,  0.2371,  0.0555,\n        -0.0719,  0.2754,  0.0444, -0.2205, -0.2079, -0.0712,  0.1509, -0.0773,\n        -0.0996,  0.1714, -0.0754, -0.2255,  0.1982,  0.2101,  0.1676,  0.3039,\n         0.1336,  0.3162, -0.0721, -0.1338, -0.1837,  0.1157, -0.0389, -0.1380,\n         0.3332,  0.0974, -0.2418,  0.1442,  0.2486,  0.0461,  0.0824, -0.2584,\n         0.0487, -0.0170, -0.2382, -0.2737, -0.1201,  0.1057,  0.2790, -0.2167,\n         0.0120, -0.2555,  0.2917,  0.3072,  0.1951, -0.0111, -0.0578,  0.2108,\n         0.3142,  0.1930,  0.2474, -0.1021,  0.1973, -0.2253, -0.0418,  0.2622,\n        -0.1321,  0.0677,  0.0288, -0.1740,  0.0066, -0.1158,  0.0095, -0.2966,\n         0.2182, -0.0071,  0.2772, -0.2209,  0.1692,  0.2988,  0.0661,  0.3044,\n        -0.0670, -0.2269, -0.0215,  0.1173,  0.1454, -0.1894,  0.2025,  0.2920,\n        -0.0962,  0.0363,  0.2559,  0.0481, -0.2615,  0.1837, -0.0268, -0.2724,\n         0.2718,  0.2788,  0.1132,  0.1449, -0.2618,  0.2671, -0.0883,  0.0296,\n        -0.2349, -0.2164,  0.1433,  0.2200, -0.3180,  0.3090, -0.1288,  0.0799,\n        -0.0919,  0.1754, -0.0198, -0.3337, -0.0816, -0.2886,  0.0349, -0.2761,\n         0.2227,  0.2774,  0.0855,  0.0612,  0.3089,  0.1936,  0.3148,  0.2789,\n        -0.1635, -0.2783,  0.2678,  0.3311,  0.0435,  0.2770,  0.1566, -0.1370,\n        -0.0348, -0.2429, -0.0194,  0.0363,  0.2930, -0.1032,  0.2268, -0.2427,\n        -0.1961,  0.0146, -0.2882,  0.3267, -0.1578,  0.3154, -0.0110,  0.0452,\n         0.0923, -0.3254,  0.1873, -0.2280,  0.0973,  0.1776,  0.0256, -0.3434,\n         0.2789, -0.0621, -0.0307, -0.3152,  0.1954,  0.2337,  0.2787, -0.1158,\n        -0.0064,  0.1173, -0.0395, -0.2834, -0.1611, -0.0476, -0.2005, -0.1565,\n         0.0076, -0.0175,  0.1066,  0.0470, -0.1412, -0.1093, -0.1101, -0.1991,\n         0.0386,  0.1588,  0.1875, -0.2639,  0.0958,  0.0462, -0.0184,  0.1096,\n        -0.1398, -0.1430, -0.0468,  0.1555, -0.1243, -0.1809, -0.1355,  0.1691,\n        -0.3307, -0.2182,  0.1905, -0.2324,  0.3399,  0.0936,  0.1362,  0.2390,\n         0.1684,  0.1491,  0.1631, -0.3067,  0.3171,  0.1814,  0.3351, -0.0330,\n         0.2666,  0.1184, -0.1135,  0.2720,  0.0162,  0.0251,  0.2567, -0.3253,\n        -0.2014,  0.0323, -0.3143,  0.0962, -0.3312,  0.0976,  0.3038,  0.1928,\n        -0.1789, -0.2413,  0.1067, -0.0310, -0.2238,  0.1727, -0.1536,  0.1286,\n        -0.1820, -0.2447,  0.2206, -0.3341, -0.0425, -0.1343,  0.0994,  0.2376,\n         0.1880,  0.2079, -0.2405,  0.2716, -0.3128, -0.2965,  0.1483,  0.1366,\n         0.0881, -0.0536, -0.0043,  0.2061,  0.1522, -0.0638,  0.2647,  0.0132,\n        -0.0615, -0.3386,  0.2750,  0.2101,  0.3352, -0.2475,  0.3530, -0.3445],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0892,  0.0092, -0.2864,  ...,  0.3492,  0.2678, -0.0381],\n        [ 0.1764,  0.1889, -0.2972,  ...,  0.3030,  0.3501, -0.3266],\n        [ 0.1695, -0.3006,  0.0806,  ...,  0.2522,  0.0729,  0.3144],\n        ...,\n        [-0.1378,  0.3302, -0.3300,  ..., -0.2961,  0.2275,  0.2111],\n        [ 0.1200,  0.2335,  0.1362,  ..., -0.0473,  0.0856, -0.3276],\n        [ 0.0669,  0.0343, -0.1673,  ..., -0.2385, -0.2220, -0.3238]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-3.8067e-02,  5.2800e-03,  6.0209e-03,  1.2889e-02, -3.2228e-02,\n         3.5502e-02,  3.3752e-02, -2.5035e-02,  3.7363e-02,  3.5937e-02,\n        -1.1257e-02,  3.2402e-02,  5.9585e-03, -4.8720e-02,  2.6343e-02,\n         2.4508e-02, -4.7059e-03,  9.6807e-03,  3.1709e-02, -3.1905e-02,\n         3.7386e-02, -3.8121e-02, -1.9877e-02, -3.0232e-02,  5.4470e-03,\n         3.1496e-02,  4.6865e-02,  1.6409e-02, -2.0606e-02,  2.3462e-02,\n         2.0232e-02,  1.2909e-02,  7.7267e-03,  5.6114e-03, -4.9410e-02,\n         1.3844e-02,  4.3861e-02, -3.8421e-02,  2.5628e-02,  4.2356e-03,\n         2.0067e-02,  2.7613e-02, -1.1947e-03, -2.1509e-02, -9.9699e-03,\n        -4.0532e-02, -3.0498e-02,  1.4885e-02,  3.8546e-02, -4.9549e-02,\n        -2.9556e-02, -3.3064e-02, -4.8368e-02, -3.4851e-02,  3.0575e-02,\n         4.9158e-03, -1.7978e-02, -4.8950e-02, -2.3581e-02, -8.3635e-04,\n        -1.2695e-02,  3.5477e-02,  4.8658e-02,  3.4295e-02, -4.2320e-02,\n         1.1514e-03,  4.3860e-02, -4.9815e-02,  5.6806e-03,  1.1478e-02,\n         3.9728e-02,  4.3749e-02,  1.5546e-02,  2.6394e-03,  2.9470e-02,\n         2.5059e-02, -2.8844e-02,  9.6058e-03,  4.6572e-02,  1.9924e-02,\n        -3.3357e-02, -3.0949e-02, -4.8982e-02,  3.1963e-02, -4.8907e-02,\n        -4.9141e-02, -2.1058e-02,  1.0123e-02, -1.4655e-02,  4.3661e-02,\n        -8.5079e-03,  4.3279e-02, -4.3932e-03, -8.5424e-03, -1.0913e-02,\n        -1.3451e-02, -2.7859e-02,  4.0611e-02, -4.3574e-02, -2.0840e-02,\n        -3.9675e-02, -3.5234e-02, -1.2226e-03,  4.2494e-02, -4.3234e-02,\n         2.6208e-02,  4.8957e-02, -5.6528e-03, -2.6644e-02, -3.3595e-02,\n        -3.1848e-02,  1.4493e-02, -2.0281e-02,  2.7771e-02, -5.4832e-03,\n         4.0363e-02,  4.3887e-02,  2.0774e-02, -1.4746e-02,  8.9254e-03,\n        -6.2709e-03, -2.6886e-02, -1.5509e-02, -2.1110e-02, -3.7915e-02,\n        -3.9597e-02, -4.9976e-02,  2.1859e-02, -7.8978e-03, -2.5628e-02,\n         2.4859e-03, -3.4121e-02,  1.1896e-02,  3.1802e-02,  4.5509e-02,\n        -1.4863e-02, -2.7100e-02, -1.6795e-03,  4.4245e-03,  1.4177e-02,\n        -4.1567e-02,  3.9151e-02, -2.8607e-02,  1.2924e-02,  1.4836e-02,\n        -4.0736e-02,  3.7173e-02,  1.9331e-02,  8.7384e-03, -2.6038e-03,\n         3.0787e-02, -1.7698e-02, -3.1137e-02,  3.3159e-02,  3.6545e-04,\n         3.8177e-02,  1.6235e-02, -8.2483e-03,  3.9006e-02,  3.6749e-02,\n        -3.3753e-02,  4.5718e-02,  7.4214e-03,  3.3541e-02, -3.6076e-02,\n        -4.4335e-02,  1.7222e-02, -8.7909e-03,  3.8651e-02, -1.8754e-02,\n        -4.2826e-05,  1.9092e-02, -3.9491e-03, -3.0028e-02, -3.2948e-02,\n         4.6025e-02, -1.7013e-02, -4.4829e-02,  4.6699e-02, -8.3253e-03,\n        -1.9501e-02,  2.5269e-02, -2.4874e-03, -3.1606e-02,  5.0940e-03,\n        -4.2274e-02,  4.5989e-02, -3.4082e-02,  2.1012e-02, -3.5045e-02,\n        -2.2265e-02, -1.8185e-03, -3.9192e-02,  2.8374e-03,  4.9092e-02,\n         2.6118e-02, -6.0623e-03,  4.1199e-02,  2.4388e-04, -1.2206e-02,\n        -3.9193e-02,  1.0586e-02,  3.3383e-02, -1.9093e-02, -3.9715e-02,\n         2.2894e-02, -2.3228e-02, -2.6322e-02, -4.9987e-02,  4.6147e-02,\n         1.1370e-03,  4.0621e-02,  4.7406e-02,  1.2918e-02,  3.2717e-02,\n         1.9007e-02,  3.3474e-02,  4.6239e-02,  1.7595e-02, -4.3512e-02,\n         1.2592e-02, -4.3806e-02, -3.9989e-02,  2.9501e-02,  3.0818e-02,\n        -2.5184e-02, -3.3963e-02,  2.7649e-02,  8.0095e-03,  1.8969e-02,\n         4.0649e-02,  3.1340e-02,  8.1955e-04, -3.0003e-02,  6.6707e-03,\n        -1.4703e-02,  1.6132e-02,  1.5318e-02,  2.5705e-02, -7.4475e-03,\n         1.8716e-02,  3.4270e-03,  4.2885e-02, -3.1314e-02, -1.3583e-02,\n         4.2405e-03,  6.1489e-03, -4.3748e-02, -3.1082e-02,  4.2881e-02,\n         1.2263e-02, -3.1116e-02,  3.8844e-02, -4.6515e-03,  1.2476e-02,\n         4.7093e-03, -3.0058e-02, -3.2217e-02, -3.6668e-02,  3.8330e-02,\n        -5.1169e-03, -4.1994e-02,  4.8908e-02, -1.6006e-02,  4.2665e-02,\n        -1.0519e-02, -2.6352e-02, -5.3137e-03,  2.9378e-02, -1.0968e-02,\n         3.5702e-03,  2.4141e-02,  6.2686e-03, -3.3989e-02, -3.0614e-03,\n        -4.3387e-02,  2.9227e-02, -1.3052e-02,  3.4021e-02, -8.5380e-03,\n         3.0542e-02, -8.4377e-03, -1.3235e-02, -2.1350e-02,  4.4927e-02,\n        -1.2234e-02,  8.0754e-03,  1.9310e-02,  4.1065e-02,  3.9237e-02,\n        -2.8189e-02, -4.5697e-02, -6.2964e-03,  2.1875e-02,  4.7969e-03,\n         3.5183e-02,  4.3729e-02, -2.3943e-02,  1.0262e-02,  4.7656e-02],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 3.5688e-02,  5.1328e-03, -2.0307e-05,  ...,  3.7764e-02,\n         -2.0411e-02,  1.8053e-02],\n        [-6.8034e-03, -2.7177e-02, -2.4734e-02,  ...,  4.3951e-02,\n         -2.7059e-02,  4.7503e-02],\n        [ 1.7810e-02,  1.3988e-02, -1.6738e-02,  ...,  2.1196e-03,\n         -1.3344e-02,  3.2764e-02],\n        ...,\n        [-2.2349e-02, -3.4173e-02, -4.6864e-03,  ..., -4.4232e-03,\n         -3.2651e-02, -2.8116e-02],\n        [-4.1103e-02, -3.1029e-02,  3.4274e-02,  ...,  5.5721e-03,\n          4.5246e-02,  2.9264e-02],\n        [ 4.3503e-03,  3.4308e-02,  2.4341e-02,  ...,  1.4078e-02,\n         -3.4300e-02, -3.6256e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0490, -0.0433,  0.0260, -0.0054], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0033,  0.0287, -0.0122,  ..., -0.0493, -0.0160, -0.0405],\n        [ 0.0370, -0.0506,  0.0480,  ...,  0.0324, -0.0335, -0.0349],\n        [ 0.0099, -0.0069,  0.0495,  ...,  0.0289,  0.0239, -0.0199],\n        [ 0.0127, -0.0246,  0.0405,  ...,  0.0205,  0.0530, -0.0085]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0892,  0.0092, -0.2864,  ...,  0.3492,  0.2678, -0.0381],\n        [ 0.1764,  0.1889, -0.2972,  ...,  0.3030,  0.3501, -0.3266],\n        [ 0.1695, -0.3006,  0.0806,  ...,  0.2522,  0.0729,  0.3144],\n        ...,\n        [-0.1378,  0.3302, -0.3300,  ..., -0.2961,  0.2275,  0.2111],\n        [ 0.1200,  0.2335,  0.1362,  ..., -0.0473,  0.0856, -0.3276],\n        [ 0.0669,  0.0343, -0.1673,  ..., -0.2385, -0.2220, -0.3238]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1532, -0.0396,  0.0241, -0.2217,  0.3531, -0.2824,  0.2896,  0.2685,\n        -0.0164,  0.2007,  0.1488,  0.2333,  0.3324,  0.1764, -0.0186,  0.0325,\n         0.2008,  0.1235, -0.0632,  0.1734,  0.2950, -0.0209,  0.2913, -0.3296,\n         0.2505, -0.3474,  0.1445, -0.2306, -0.3023,  0.0332,  0.0203,  0.1914,\n         0.3096,  0.1515, -0.0894,  0.2288,  0.0941,  0.2296,  0.3135, -0.2155,\n        -0.2878, -0.3029,  0.1631, -0.3337,  0.0190,  0.0074,  0.3208, -0.0685,\n        -0.1926,  0.2272,  0.1014,  0.0610, -0.1674, -0.1214, -0.2973, -0.2212,\n         0.0014, -0.2004,  0.1370, -0.2841,  0.3233, -0.0196,  0.0479, -0.3237,\n        -0.2911,  0.1550,  0.2604,  0.2611,  0.0705, -0.2185, -0.0582,  0.1977,\n        -0.2866, -0.1625, -0.2261, -0.0633,  0.1753, -0.2425,  0.1405, -0.0648,\n         0.2498, -0.1606, -0.2542,  0.1235, -0.0661, -0.0370, -0.1877,  0.2357,\n        -0.0189, -0.0038, -0.0065, -0.1213, -0.2836,  0.3177,  0.3110, -0.1024,\n         0.2255, -0.0946, -0.0216, -0.0333, -0.0744, -0.0349,  0.0084, -0.1897,\n        -0.0597, -0.3380, -0.2175,  0.0173, -0.1213,  0.2134,  0.2956,  0.1575,\n         0.2899, -0.1668,  0.2775,  0.1397, -0.2849,  0.2546, -0.1639, -0.0013,\n         0.1019,  0.1045,  0.2259, -0.3470,  0.2840,  0.0353,  0.3141,  0.0259,\n        -0.0596, -0.0815,  0.0910, -0.2788,  0.0308,  0.3083,  0.2371,  0.0555,\n        -0.0719,  0.2754,  0.0444, -0.2205, -0.2079, -0.0712,  0.1509, -0.0773,\n        -0.0996,  0.1714, -0.0754, -0.2255,  0.1982,  0.2101,  0.1676,  0.3039,\n         0.1336,  0.3162, -0.0721, -0.1338, -0.1837,  0.1157, -0.0389, -0.1380,\n         0.3332,  0.0974, -0.2418,  0.1442,  0.2486,  0.0461,  0.0824, -0.2584,\n         0.0487, -0.0170, -0.2382, -0.2737, -0.1201,  0.1057,  0.2790, -0.2167,\n         0.0120, -0.2555,  0.2917,  0.3072,  0.1951, -0.0111, -0.0578,  0.2108,\n         0.3142,  0.1930,  0.2474, -0.1021,  0.1973, -0.2253, -0.0418,  0.2622,\n        -0.1321,  0.0677,  0.0288, -0.1740,  0.0066, -0.1158,  0.0095, -0.2966,\n         0.2182, -0.0071,  0.2772, -0.2209,  0.1692,  0.2988,  0.0661,  0.3044,\n        -0.0670, -0.2269, -0.0215,  0.1173,  0.1454, -0.1894,  0.2025,  0.2920,\n        -0.0962,  0.0363,  0.2559,  0.0481, -0.2615,  0.1837, -0.0268, -0.2724,\n         0.2718,  0.2788,  0.1132,  0.1449, -0.2618,  0.2671, -0.0883,  0.0296,\n        -0.2349, -0.2164,  0.1433,  0.2200, -0.3180,  0.3090, -0.1288,  0.0799,\n        -0.0919,  0.1754, -0.0198, -0.3337, -0.0816, -0.2886,  0.0349, -0.2761,\n         0.2227,  0.2774,  0.0855,  0.0612,  0.3089,  0.1936,  0.3148,  0.2789,\n        -0.1635, -0.2783,  0.2678,  0.3311,  0.0435,  0.2770,  0.1566, -0.1370,\n        -0.0348, -0.2429, -0.0194,  0.0363,  0.2930, -0.1032,  0.2268, -0.2427,\n        -0.1961,  0.0146, -0.2882,  0.3267, -0.1578,  0.3154, -0.0110,  0.0452,\n         0.0923, -0.3254,  0.1873, -0.2280,  0.0973,  0.1776,  0.0256, -0.3434,\n         0.2789, -0.0621, -0.0307, -0.3152,  0.1954,  0.2337,  0.2787, -0.1158,\n        -0.0064,  0.1173, -0.0395, -0.2834, -0.1611, -0.0476, -0.2005, -0.1565,\n         0.0076, -0.0175,  0.1066,  0.0470, -0.1412, -0.1093, -0.1101, -0.1991,\n         0.0386,  0.1588,  0.1875, -0.2639,  0.0958,  0.0462, -0.0184,  0.1096,\n        -0.1398, -0.1430, -0.0468,  0.1555, -0.1243, -0.1809, -0.1355,  0.1691,\n        -0.3307, -0.2182,  0.1905, -0.2324,  0.3399,  0.0936,  0.1362,  0.2390,\n         0.1684,  0.1491,  0.1631, -0.3067,  0.3171,  0.1814,  0.3351, -0.0330,\n         0.2666,  0.1184, -0.1135,  0.2720,  0.0162,  0.0251,  0.2567, -0.3253,\n        -0.2014,  0.0323, -0.3143,  0.0962, -0.3312,  0.0976,  0.3038,  0.1928,\n        -0.1789, -0.2413,  0.1067, -0.0310, -0.2238,  0.1727, -0.1536,  0.1286,\n        -0.1820, -0.2447,  0.2206, -0.3341, -0.0425, -0.1343,  0.0994,  0.2376,\n         0.1880,  0.2079, -0.2405,  0.2716, -0.3128, -0.2965,  0.1483,  0.1366,\n         0.0881, -0.0536, -0.0043,  0.2061,  0.1522, -0.0638,  0.2647,  0.0132,\n        -0.0615, -0.3386,  0.2750,  0.2101,  0.3352, -0.2475,  0.3530, -0.3445],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 3.5688e-02,  5.1328e-03, -2.0307e-05,  ...,  3.7764e-02,\n         -2.0411e-02,  1.8053e-02],\n        [-6.8034e-03, -2.7177e-02, -2.4734e-02,  ...,  4.3951e-02,\n         -2.7059e-02,  4.7503e-02],\n        [ 1.7810e-02,  1.3988e-02, -1.6738e-02,  ...,  2.1196e-03,\n         -1.3344e-02,  3.2764e-02],\n        ...,\n        [-2.2349e-02, -3.4173e-02, -4.6864e-03,  ..., -4.4232e-03,\n         -3.2651e-02, -2.8116e-02],\n        [-4.1103e-02, -3.1029e-02,  3.4274e-02,  ...,  5.5721e-03,\n          4.5246e-02,  2.9264e-02],\n        [ 4.3503e-03,  3.4308e-02,  2.4341e-02,  ...,  1.4078e-02,\n         -3.4300e-02, -3.6256e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-3.8067e-02,  5.2800e-03,  6.0209e-03,  1.2889e-02, -3.2228e-02,\n         3.5502e-02,  3.3752e-02, -2.5035e-02,  3.7363e-02,  3.5937e-02,\n        -1.1257e-02,  3.2402e-02,  5.9585e-03, -4.8720e-02,  2.6343e-02,\n         2.4508e-02, -4.7059e-03,  9.6807e-03,  3.1709e-02, -3.1905e-02,\n         3.7386e-02, -3.8121e-02, -1.9877e-02, -3.0232e-02,  5.4470e-03,\n         3.1496e-02,  4.6865e-02,  1.6409e-02, -2.0606e-02,  2.3462e-02,\n         2.0232e-02,  1.2909e-02,  7.7267e-03,  5.6114e-03, -4.9410e-02,\n         1.3844e-02,  4.3861e-02, -3.8421e-02,  2.5628e-02,  4.2356e-03,\n         2.0067e-02,  2.7613e-02, -1.1947e-03, -2.1509e-02, -9.9699e-03,\n        -4.0532e-02, -3.0498e-02,  1.4885e-02,  3.8546e-02, -4.9549e-02,\n        -2.9556e-02, -3.3064e-02, -4.8368e-02, -3.4851e-02,  3.0575e-02,\n         4.9158e-03, -1.7978e-02, -4.8950e-02, -2.3581e-02, -8.3635e-04,\n        -1.2695e-02,  3.5477e-02,  4.8658e-02,  3.4295e-02, -4.2320e-02,\n         1.1514e-03,  4.3860e-02, -4.9815e-02,  5.6806e-03,  1.1478e-02,\n         3.9728e-02,  4.3749e-02,  1.5546e-02,  2.6394e-03,  2.9470e-02,\n         2.5059e-02, -2.8844e-02,  9.6058e-03,  4.6572e-02,  1.9924e-02,\n        -3.3357e-02, -3.0949e-02, -4.8982e-02,  3.1963e-02, -4.8907e-02,\n        -4.9141e-02, -2.1058e-02,  1.0123e-02, -1.4655e-02,  4.3661e-02,\n        -8.5079e-03,  4.3279e-02, -4.3932e-03, -8.5424e-03, -1.0913e-02,\n        -1.3451e-02, -2.7859e-02,  4.0611e-02, -4.3574e-02, -2.0840e-02,\n        -3.9675e-02, -3.5234e-02, -1.2226e-03,  4.2494e-02, -4.3234e-02,\n         2.6208e-02,  4.8957e-02, -5.6528e-03, -2.6644e-02, -3.3595e-02,\n        -3.1848e-02,  1.4493e-02, -2.0281e-02,  2.7771e-02, -5.4832e-03,\n         4.0363e-02,  4.3887e-02,  2.0774e-02, -1.4746e-02,  8.9254e-03,\n        -6.2709e-03, -2.6886e-02, -1.5509e-02, -2.1110e-02, -3.7915e-02,\n        -3.9597e-02, -4.9976e-02,  2.1859e-02, -7.8978e-03, -2.5628e-02,\n         2.4859e-03, -3.4121e-02,  1.1896e-02,  3.1802e-02,  4.5509e-02,\n        -1.4863e-02, -2.7100e-02, -1.6795e-03,  4.4245e-03,  1.4177e-02,\n        -4.1567e-02,  3.9151e-02, -2.8607e-02,  1.2924e-02,  1.4836e-02,\n        -4.0736e-02,  3.7173e-02,  1.9331e-02,  8.7384e-03, -2.6038e-03,\n         3.0787e-02, -1.7698e-02, -3.1137e-02,  3.3159e-02,  3.6545e-04,\n         3.8177e-02,  1.6235e-02, -8.2483e-03,  3.9006e-02,  3.6749e-02,\n        -3.3753e-02,  4.5718e-02,  7.4214e-03,  3.3541e-02, -3.6076e-02,\n        -4.4335e-02,  1.7222e-02, -8.7909e-03,  3.8651e-02, -1.8754e-02,\n        -4.2826e-05,  1.9092e-02, -3.9491e-03, -3.0028e-02, -3.2948e-02,\n         4.6025e-02, -1.7013e-02, -4.4829e-02,  4.6699e-02, -8.3253e-03,\n        -1.9501e-02,  2.5269e-02, -2.4874e-03, -3.1606e-02,  5.0940e-03,\n        -4.2274e-02,  4.5989e-02, -3.4082e-02,  2.1012e-02, -3.5045e-02,\n        -2.2265e-02, -1.8185e-03, -3.9192e-02,  2.8374e-03,  4.9092e-02,\n         2.6118e-02, -6.0623e-03,  4.1199e-02,  2.4388e-04, -1.2206e-02,\n        -3.9193e-02,  1.0586e-02,  3.3383e-02, -1.9093e-02, -3.9715e-02,\n         2.2894e-02, -2.3228e-02, -2.6322e-02, -4.9987e-02,  4.6147e-02,\n         1.1370e-03,  4.0621e-02,  4.7406e-02,  1.2918e-02,  3.2717e-02,\n         1.9007e-02,  3.3474e-02,  4.6239e-02,  1.7595e-02, -4.3512e-02,\n         1.2592e-02, -4.3806e-02, -3.9989e-02,  2.9501e-02,  3.0818e-02,\n        -2.5184e-02, -3.3963e-02,  2.7649e-02,  8.0095e-03,  1.8969e-02,\n         4.0649e-02,  3.1340e-02,  8.1955e-04, -3.0003e-02,  6.6707e-03,\n        -1.4703e-02,  1.6132e-02,  1.5318e-02,  2.5705e-02, -7.4475e-03,\n         1.8716e-02,  3.4270e-03,  4.2885e-02, -3.1314e-02, -1.3583e-02,\n         4.2405e-03,  6.1489e-03, -4.3748e-02, -3.1082e-02,  4.2881e-02,\n         1.2263e-02, -3.1116e-02,  3.8844e-02, -4.6515e-03,  1.2476e-02,\n         4.7093e-03, -3.0058e-02, -3.2217e-02, -3.6668e-02,  3.8330e-02,\n        -5.1169e-03, -4.1994e-02,  4.8908e-02, -1.6006e-02,  4.2665e-02,\n        -1.0519e-02, -2.6352e-02, -5.3137e-03,  2.9378e-02, -1.0968e-02,\n         3.5702e-03,  2.4141e-02,  6.2686e-03, -3.3989e-02, -3.0614e-03,\n        -4.3387e-02,  2.9227e-02, -1.3052e-02,  3.4021e-02, -8.5380e-03,\n         3.0542e-02, -8.4377e-03, -1.3235e-02, -2.1350e-02,  4.4927e-02,\n        -1.2234e-02,  8.0754e-03,  1.9310e-02,  4.1065e-02,  3.9237e-02,\n        -2.8189e-02, -4.5697e-02, -6.2964e-03,  2.1875e-02,  4.7969e-03,\n         3.5183e-02,  4.3729e-02, -2.3943e-02,  1.0262e-02,  4.7656e-02],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0033,  0.0287, -0.0122,  ..., -0.0493, -0.0160, -0.0405],\n        [ 0.0370, -0.0506,  0.0480,  ...,  0.0324, -0.0335, -0.0349],\n        [ 0.0099, -0.0069,  0.0495,  ...,  0.0289,  0.0239, -0.0199],\n        [ 0.0127, -0.0246,  0.0405,  ...,  0.0205,  0.0530, -0.0085]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0490, -0.0433,  0.0260, -0.0054], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x759fe6344550>":	{
                    "capacity":	50000,
                    "current_segment":	0,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	50000,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1532, -0.0396,  0.0241, -0.2217,  0.3531, -0.2824,  0.2896,  0.2685,\n        -0.0164,  0.2007,  0.1488,  0.2333,  0.3324,  0.1764, -0.0186,  0.0325,\n         0.2008,  0.1235, -0.0632,  0.1734,  0.2950, -0.0209,  0.2913, -0.3296,\n         0.2505, -0.3474,  0.1445, -0.2306, -0.3023,  0.0332,  0.0203,  0.1914,\n         0.3096,  0.1515, -0.0894,  0.2288,  0.0941,  0.2296,  0.3135, -0.2155,\n        -0.2878, -0.3029,  0.1631, -0.3337,  0.0190,  0.0074,  0.3208, -0.0685,\n        -0.1926,  0.2272,  0.1014,  0.0610, -0.1674, -0.1214, -0.2973, -0.2212,\n         0.0014, -0.2004,  0.1370, -0.2841,  0.3233, -0.0196,  0.0479, -0.3237,\n        -0.2911,  0.1550,  0.2604,  0.2611,  0.0705, -0.2185, -0.0582,  0.1977,\n        -0.2866, -0.1625, -0.2261, -0.0633,  0.1753, -0.2425,  0.1405, -0.0648,\n         0.2498, -0.1606, -0.2542,  0.1235, -0.0661, -0.0370, -0.1877,  0.2357,\n        -0.0189, -0.0038, -0.0065, -0.1213, -0.2836,  0.3177,  0.3110, -0.1024,\n         0.2255, -0.0946, -0.0216, -0.0333, -0.0744, -0.0349,  0.0084, -0.1897,\n        -0.0597, -0.3380, -0.2175,  0.0173, -0.1213,  0.2134,  0.2956,  0.1575,\n         0.2899, -0.1668,  0.2775,  0.1397, -0.2849,  0.2546, -0.1639, -0.0013,\n         0.1019,  0.1045,  0.2259, -0.3470,  0.2840,  0.0353,  0.3141,  0.0259,\n        -0.0596, -0.0815,  0.0910, -0.2788,  0.0308,  0.3083,  0.2371,  0.0555,\n        -0.0719,  0.2754,  0.0444, -0.2205, -0.2079, -0.0712,  0.1509, -0.0773,\n        -0.0996,  0.1714, -0.0754, -0.2255,  0.1982,  0.2101,  0.1676,  0.3039,\n         0.1336,  0.3162, -0.0721, -0.1338, -0.1837,  0.1157, -0.0389, -0.1380,\n         0.3332,  0.0974, -0.2418,  0.1442,  0.2486,  0.0461,  0.0824, -0.2584,\n         0.0487, -0.0170, -0.2382, -0.2737, -0.1201,  0.1057,  0.2790, -0.2167,\n         0.0120, -0.2555,  0.2917,  0.3072,  0.1951, -0.0111, -0.0578,  0.2108,\n         0.3142,  0.1930,  0.2474, -0.1021,  0.1973, -0.2253, -0.0418,  0.2622,\n        -0.1321,  0.0677,  0.0288, -0.1740,  0.0066, -0.1158,  0.0095, -0.2966,\n         0.2182, -0.0071,  0.2772, -0.2209,  0.1692,  0.2988,  0.0661,  0.3044,\n        -0.0670, -0.2269, -0.0215,  0.1173,  0.1454, -0.1894,  0.2025,  0.2920,\n        -0.0962,  0.0363,  0.2559,  0.0481, -0.2615,  0.1837, -0.0268, -0.2724,\n         0.2718,  0.2788,  0.1132,  0.1449, -0.2618,  0.2671, -0.0883,  0.0296,\n        -0.2349, -0.2164,  0.1433,  0.2200, -0.3180,  0.3090, -0.1288,  0.0799,\n        -0.0919,  0.1754, -0.0198, -0.3337, -0.0816, -0.2886,  0.0349, -0.2761,\n         0.2227,  0.2774,  0.0855,  0.0612,  0.3089,  0.1936,  0.3148,  0.2789,\n        -0.1635, -0.2783,  0.2678,  0.3311,  0.0435,  0.2770,  0.1566, -0.1370,\n        -0.0348, -0.2429, -0.0194,  0.0363,  0.2930, -0.1032,  0.2268, -0.2427,\n        -0.1961,  0.0146, -0.2882,  0.3267, -0.1578,  0.3154, -0.0110,  0.0452,\n         0.0923, -0.3254,  0.1873, -0.2280,  0.0973,  0.1776,  0.0256, -0.3434,\n         0.2789, -0.0621, -0.0307, -0.3152,  0.1954,  0.2337,  0.2787, -0.1158,\n        -0.0064,  0.1173, -0.0395, -0.2834, -0.1611, -0.0476, -0.2005, -0.1565,\n         0.0076, -0.0175,  0.1066,  0.0470, -0.1412, -0.1093, -0.1101, -0.1991,\n         0.0386,  0.1588,  0.1875, -0.2639,  0.0958,  0.0462, -0.0184,  0.1096,\n        -0.1398, -0.1430, -0.0468,  0.1555, -0.1243, -0.1809, -0.1355,  0.1691,\n        -0.3307, -0.2182,  0.1905, -0.2324,  0.3399,  0.0936,  0.1362,  0.2390,\n         0.1684,  0.1491,  0.1631, -0.3067,  0.3171,  0.1814,  0.3351, -0.0330,\n         0.2666,  0.1184, -0.1135,  0.2720,  0.0162,  0.0251,  0.2567, -0.3253,\n        -0.2014,  0.0323, -0.3143,  0.0962, -0.3312,  0.0976,  0.3038,  0.1928,\n        -0.1789, -0.2413,  0.1067, -0.0310, -0.2238,  0.1727, -0.1536,  0.1286,\n        -0.1820, -0.2447,  0.2206, -0.3341, -0.0425, -0.1343,  0.0994,  0.2376,\n         0.1880,  0.2079, -0.2405,  0.2716, -0.3128, -0.2965,  0.1483,  0.1366,\n         0.0881, -0.0536, -0.0043,  0.2061,  0.1522, -0.0638,  0.2647,  0.0132,\n        -0.0615, -0.3386,  0.2750,  0.2101,  0.3352, -0.2475,  0.3530, -0.3445],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0892,  0.0092, -0.2864,  ...,  0.3492,  0.2678, -0.0381],\n        [ 0.1764,  0.1889, -0.2972,  ...,  0.3030,  0.3501, -0.3266],\n        [ 0.1695, -0.3006,  0.0806,  ...,  0.2522,  0.0729,  0.3144],\n        ...,\n        [-0.1378,  0.3302, -0.3300,  ..., -0.2961,  0.2275,  0.2111],\n        [ 0.1200,  0.2335,  0.1362,  ..., -0.0473,  0.0856, -0.3276],\n        [ 0.0669,  0.0343, -0.1673,  ..., -0.2385, -0.2220, -0.3238]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-3.8067e-02,  5.2800e-03,  6.0209e-03,  1.2889e-02, -3.2228e-02,\n         3.5502e-02,  3.3752e-02, -2.5035e-02,  3.7363e-02,  3.5937e-02,\n        -1.1257e-02,  3.2402e-02,  5.9585e-03, -4.8720e-02,  2.6343e-02,\n         2.4508e-02, -4.7059e-03,  9.6807e-03,  3.1709e-02, -3.1905e-02,\n         3.7386e-02, -3.8121e-02, -1.9877e-02, -3.0232e-02,  5.4470e-03,\n         3.1496e-02,  4.6865e-02,  1.6409e-02, -2.0606e-02,  2.3462e-02,\n         2.0232e-02,  1.2909e-02,  7.7267e-03,  5.6114e-03, -4.9410e-02,\n         1.3844e-02,  4.3861e-02, -3.8421e-02,  2.5628e-02,  4.2356e-03,\n         2.0067e-02,  2.7613e-02, -1.1947e-03, -2.1509e-02, -9.9699e-03,\n        -4.0532e-02, -3.0498e-02,  1.4885e-02,  3.8546e-02, -4.9549e-02,\n        -2.9556e-02, -3.3064e-02, -4.8368e-02, -3.4851e-02,  3.0575e-02,\n         4.9158e-03, -1.7978e-02, -4.8950e-02, -2.3581e-02, -8.3635e-04,\n        -1.2695e-02,  3.5477e-02,  4.8658e-02,  3.4295e-02, -4.2320e-02,\n         1.1514e-03,  4.3860e-02, -4.9815e-02,  5.6806e-03,  1.1478e-02,\n         3.9728e-02,  4.3749e-02,  1.5546e-02,  2.6394e-03,  2.9470e-02,\n         2.5059e-02, -2.8844e-02,  9.6058e-03,  4.6572e-02,  1.9924e-02,\n        -3.3357e-02, -3.0949e-02, -4.8982e-02,  3.1963e-02, -4.8907e-02,\n        -4.9141e-02, -2.1058e-02,  1.0123e-02, -1.4655e-02,  4.3661e-02,\n        -8.5079e-03,  4.3279e-02, -4.3932e-03, -8.5424e-03, -1.0913e-02,\n        -1.3451e-02, -2.7859e-02,  4.0611e-02, -4.3574e-02, -2.0840e-02,\n        -3.9675e-02, -3.5234e-02, -1.2226e-03,  4.2494e-02, -4.3234e-02,\n         2.6208e-02,  4.8957e-02, -5.6528e-03, -2.6644e-02, -3.3595e-02,\n        -3.1848e-02,  1.4493e-02, -2.0281e-02,  2.7771e-02, -5.4832e-03,\n         4.0363e-02,  4.3887e-02,  2.0774e-02, -1.4746e-02,  8.9254e-03,\n        -6.2709e-03, -2.6886e-02, -1.5509e-02, -2.1110e-02, -3.7915e-02,\n        -3.9597e-02, -4.9976e-02,  2.1859e-02, -7.8978e-03, -2.5628e-02,\n         2.4859e-03, -3.4121e-02,  1.1896e-02,  3.1802e-02,  4.5509e-02,\n        -1.4863e-02, -2.7100e-02, -1.6795e-03,  4.4245e-03,  1.4177e-02,\n        -4.1567e-02,  3.9151e-02, -2.8607e-02,  1.2924e-02,  1.4836e-02,\n        -4.0736e-02,  3.7173e-02,  1.9331e-02,  8.7384e-03, -2.6038e-03,\n         3.0787e-02, -1.7698e-02, -3.1137e-02,  3.3159e-02,  3.6545e-04,\n         3.8177e-02,  1.6235e-02, -8.2483e-03,  3.9006e-02,  3.6749e-02,\n        -3.3753e-02,  4.5718e-02,  7.4214e-03,  3.3541e-02, -3.6076e-02,\n        -4.4335e-02,  1.7222e-02, -8.7909e-03,  3.8651e-02, -1.8754e-02,\n        -4.2826e-05,  1.9092e-02, -3.9491e-03, -3.0028e-02, -3.2948e-02,\n         4.6025e-02, -1.7013e-02, -4.4829e-02,  4.6699e-02, -8.3253e-03,\n        -1.9501e-02,  2.5269e-02, -2.4874e-03, -3.1606e-02,  5.0940e-03,\n        -4.2274e-02,  4.5989e-02, -3.4082e-02,  2.1012e-02, -3.5045e-02,\n        -2.2265e-02, -1.8185e-03, -3.9192e-02,  2.8374e-03,  4.9092e-02,\n         2.6118e-02, -6.0623e-03,  4.1199e-02,  2.4388e-04, -1.2206e-02,\n        -3.9193e-02,  1.0586e-02,  3.3383e-02, -1.9093e-02, -3.9715e-02,\n         2.2894e-02, -2.3228e-02, -2.6322e-02, -4.9987e-02,  4.6147e-02,\n         1.1370e-03,  4.0621e-02,  4.7406e-02,  1.2918e-02,  3.2717e-02,\n         1.9007e-02,  3.3474e-02,  4.6239e-02,  1.7595e-02, -4.3512e-02,\n         1.2592e-02, -4.3806e-02, -3.9989e-02,  2.9501e-02,  3.0818e-02,\n        -2.5184e-02, -3.3963e-02,  2.7649e-02,  8.0095e-03,  1.8969e-02,\n         4.0649e-02,  3.1340e-02,  8.1955e-04, -3.0003e-02,  6.6707e-03,\n        -1.4703e-02,  1.6132e-02,  1.5318e-02,  2.5705e-02, -7.4475e-03,\n         1.8716e-02,  3.4270e-03,  4.2885e-02, -3.1314e-02, -1.3583e-02,\n         4.2405e-03,  6.1489e-03, -4.3748e-02, -3.1082e-02,  4.2881e-02,\n         1.2263e-02, -3.1116e-02,  3.8844e-02, -4.6515e-03,  1.2476e-02,\n         4.7093e-03, -3.0058e-02, -3.2217e-02, -3.6668e-02,  3.8330e-02,\n        -5.1169e-03, -4.1994e-02,  4.8908e-02, -1.6006e-02,  4.2665e-02,\n        -1.0519e-02, -2.6352e-02, -5.3137e-03,  2.9378e-02, -1.0968e-02,\n         3.5702e-03,  2.4141e-02,  6.2686e-03, -3.3989e-02, -3.0614e-03,\n        -4.3387e-02,  2.9227e-02, -1.3052e-02,  3.4021e-02, -8.5380e-03,\n         3.0542e-02, -8.4377e-03, -1.3235e-02, -2.1350e-02,  4.4927e-02,\n        -1.2234e-02,  8.0754e-03,  1.9310e-02,  4.1065e-02,  3.9237e-02,\n        -2.8189e-02, -4.5697e-02, -6.2964e-03,  2.1875e-02,  4.7969e-03,\n         3.5183e-02,  4.3729e-02, -2.3943e-02,  1.0262e-02,  4.7656e-02],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 3.5688e-02,  5.1328e-03, -2.0307e-05,  ...,  3.7764e-02,\n         -2.0411e-02,  1.8053e-02],\n        [-6.8034e-03, -2.7177e-02, -2.4734e-02,  ...,  4.3951e-02,\n         -2.7059e-02,  4.7503e-02],\n        [ 1.7810e-02,  1.3988e-02, -1.6738e-02,  ...,  2.1196e-03,\n         -1.3344e-02,  3.2764e-02],\n        ...,\n        [-2.2349e-02, -3.4173e-02, -4.6864e-03,  ..., -4.4232e-03,\n         -3.2651e-02, -2.8116e-02],\n        [-4.1103e-02, -3.1029e-02,  3.4274e-02,  ...,  5.5721e-03,\n          4.5246e-02,  2.9264e-02],\n        [ 4.3503e-03,  3.4308e-02,  2.4341e-02,  ...,  1.4078e-02,\n         -3.4300e-02, -3.6256e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0490, -0.0433,  0.0260, -0.0054], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0033,  0.0287, -0.0122,  ..., -0.0493, -0.0160, -0.0405],\n        [ 0.0370, -0.0506,  0.0480,  ...,  0.0324, -0.0335, -0.0349],\n        [ 0.0099, -0.0069,  0.0495,  ...,  0.0289,  0.0239, -0.0199],\n        [ 0.0127, -0.0246,  0.0405,  ...,  0.0205,  0.0530, -0.0085]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x759fe8516850>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s139790000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s139790000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}