{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.01,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s144340000"
    },
    "max_sample_age":	-1,
    "q_lr":	0.003,
    "seed":	144340000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x785e7a5177d0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.01,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-6.8111e-02,  1.6352e-02,  1.0155e-01, -2.5162e-01, -4.2880e-02,\n        -1.9521e-01, -2.3209e-01, -3.9605e-02,  2.5050e-02,  9.6478e-02,\n        -2.0157e-01, -1.2898e-01,  7.3536e-02,  3.2594e-01, -3.0258e-01,\n         1.4774e-01, -1.6013e-01,  2.7585e-01, -3.4538e-01,  3.0844e-01,\n        -3.1491e-01,  1.9097e-01, -3.3167e-01, -9.9506e-02,  3.4114e-01,\n         2.6878e-01, -9.4868e-02,  8.8406e-02, -7.9495e-02, -1.7844e-01,\n         7.7571e-02,  1.0614e-01, -1.9311e-01,  4.9094e-02, -1.6799e-01,\n        -2.5274e-01,  9.7710e-02,  1.3161e-01,  8.0010e-02, -3.3618e-02,\n        -2.7607e-01, -2.2516e-01,  2.8488e-01,  6.1582e-02,  3.3217e-01,\n         2.0559e-01, -1.9301e-01,  9.8491e-02, -9.7896e-02, -1.4598e-01,\n        -3.2763e-01, -7.7259e-02,  1.0775e-01, -2.9545e-05, -2.5854e-01,\n        -1.6352e-01, -2.7722e-01,  1.5744e-01, -2.2018e-01,  2.8861e-01,\n        -2.9976e-01,  1.5539e-01, -3.2462e-01,  1.0282e-01, -3.4911e-01,\n         1.0607e-01,  3.5018e-01, -2.8405e-01,  1.9580e-01,  1.4743e-01,\n         1.8843e-01, -2.7069e-01, -2.4944e-01,  3.3777e-02,  2.6535e-01,\n         1.2716e-01,  1.9917e-02, -1.5792e-01,  1.7987e-01, -2.2123e-01,\n         9.5251e-02,  2.0210e-01,  2.6957e-01,  2.8099e-01,  1.1582e-02,\n         2.1065e-01, -1.8092e-01,  3.1380e-01, -2.1981e-01,  4.2646e-02,\n        -1.4541e-01, -2.7973e-01,  7.5582e-02,  2.1797e-01, -2.6890e-01,\n         2.1274e-01,  1.0535e-01,  8.2296e-04, -8.9825e-02, -2.0899e-02,\n         1.1182e-01, -3.1888e-01,  2.2275e-01,  1.4260e-01,  3.3150e-01,\n        -1.1227e-01, -3.0399e-01,  2.8670e-01,  1.1704e-01, -2.2298e-01,\n         3.1048e-02,  2.6241e-01,  2.8747e-01, -1.4963e-01,  3.0606e-01,\n         1.6313e-02, -2.6490e-01, -1.4491e-01,  4.1103e-02, -2.2290e-02,\n         2.6097e-01, -3.0847e-01,  9.0792e-03,  1.7387e-01, -3.2881e-01,\n         2.1807e-01, -2.1930e-01, -1.6790e-01, -3.4965e-01,  7.9417e-02,\n        -1.2659e-01,  2.4549e-01, -3.0707e-01,  1.9163e-01,  1.7452e-01,\n         1.8673e-01,  1.6125e-01, -5.9934e-02,  3.5310e-01, -3.2602e-01,\n        -1.6394e-01, -1.7487e-01,  1.6262e-01, -1.6717e-01,  3.3329e-01,\n         6.9056e-02,  6.8831e-03, -1.4567e-01, -3.2604e-01,  5.1361e-02,\n         1.7067e-02,  1.5621e-01, -7.0918e-02, -3.6548e-02, -1.9856e-01,\n        -7.9953e-02, -8.7216e-02,  3.4613e-01, -3.0303e-01,  1.4206e-01,\n        -1.6294e-01,  2.6226e-01, -2.3780e-01, -5.1249e-02,  9.6765e-02,\n         2.7218e-01, -2.7730e-01,  3.3578e-01,  1.6212e-01,  7.6350e-02,\n         1.3579e-01, -1.3551e-01,  8.5354e-02,  1.3128e-01,  2.8483e-01,\n         2.4768e-01,  2.8944e-02,  6.7513e-02, -2.0715e-01,  2.3831e-02,\n         2.8673e-01,  3.2187e-01,  2.6185e-01, -3.1578e-02, -2.2283e-01,\n         2.7190e-01, -2.2837e-01,  2.2104e-01, -2.6305e-01, -1.4588e-01,\n         6.4406e-02,  2.5827e-01, -3.0486e-01,  3.2295e-01,  2.0062e-01,\n         3.2792e-01, -7.9203e-02, -1.8175e-01, -7.9275e-02, -2.0362e-01,\n        -9.2435e-02,  1.9446e-01,  9.9854e-02, -3.4644e-01,  2.9083e-01,\n         1.2067e-01,  1.6077e-01,  5.2898e-02, -5.6971e-02, -2.0630e-01,\n        -1.5179e-01,  8.1589e-02,  3.4056e-01, -2.3106e-01, -3.4167e-01,\n        -9.4886e-02,  9.7734e-02,  2.8138e-01,  2.5054e-02,  4.8316e-02,\n         2.8071e-01,  1.0351e-01,  1.1693e-01, -3.6686e-02, -2.5094e-01,\n        -2.7264e-01,  7.5048e-02, -3.4565e-01, -1.1562e-01,  2.2645e-01,\n        -3.2191e-01,  1.9584e-01, -9.3402e-02, -8.4426e-02, -2.4299e-01,\n         6.8034e-02, -8.4358e-02, -5.4629e-02, -3.1109e-01,  1.2346e-01,\n        -2.1239e-01,  3.3493e-01,  2.8830e-01, -8.5404e-02,  5.7336e-02,\n        -2.7644e-02,  7.7092e-02, -1.4388e-02,  3.5136e-01,  2.1720e-01,\n        -1.6327e-01, -1.6905e-02, -1.5889e-01, -1.4949e-01, -2.2320e-01,\n         3.1569e-01,  3.3197e-02, -2.0336e-02, -8.2663e-02, -3.4696e-01,\n        -2.8107e-01,  1.8312e-01, -3.9501e-02, -2.7266e-01,  2.4300e-01,\n        -3.9811e-02, -3.2752e-01, -6.4167e-02,  3.1055e-01,  3.0183e-02,\n        -9.5815e-03, -2.0421e-01,  3.3207e-01,  3.5079e-02, -3.9468e-02,\n         1.2687e-03,  3.3472e-01,  1.3580e-01, -2.8986e-01,  2.0158e-01,\n        -1.2172e-01,  1.0761e-01,  3.0965e-01,  3.0414e-01,  2.8709e-01,\n         2.3426e-02, -2.3526e-01,  6.0596e-03,  3.2563e-01, -2.3793e-01,\n         1.1765e-01, -1.5693e-01, -2.6827e-01, -2.3080e-01, -2.1696e-01,\n        -9.6960e-02,  8.8873e-02,  1.9319e-01, -3.2185e-01,  2.9007e-01,\n        -1.3704e-02,  1.4941e-01, -1.3788e-01,  1.7018e-01, -1.1944e-01,\n        -3.2865e-01, -5.6292e-02,  3.1315e-01, -7.6812e-02,  6.8317e-02,\n        -3.3600e-01, -3.4226e-01, -1.9488e-01,  2.7294e-01, -2.2203e-01,\n        -4.2156e-02, -1.9223e-01, -2.1520e-01, -2.5684e-01, -3.1217e-01,\n         8.8333e-02,  3.2011e-01, -2.1758e-01,  1.6022e-01, -1.4377e-01,\n         2.0982e-01,  2.4932e-01,  1.9944e-01,  5.6471e-02, -1.5593e-01,\n        -2.3054e-01,  1.1799e-02, -2.1813e-02, -1.2419e-01, -2.8297e-01,\n        -3.2245e-01,  2.8492e-01, -3.4271e-01, -3.2504e-01,  7.2032e-02,\n        -1.3451e-01, -2.2851e-01, -3.5913e-02,  3.0275e-01,  4.7795e-05,\n        -1.6171e-01, -3.4468e-01, -9.6784e-02, -2.2255e-01, -9.0284e-02,\n         1.6710e-01,  2.2405e-01, -1.8062e-01, -4.7457e-02,  3.3028e-02,\n        -3.5263e-01, -1.6073e-01, -2.6818e-01,  2.4167e-01, -2.6605e-01,\n        -1.3430e-01, -7.9785e-02,  1.7124e-01, -1.5931e-01, -3.4989e-02,\n        -1.2546e-01, -2.3501e-01, -3.2735e-02, -2.0062e-01, -1.0127e-01,\n        -2.0663e-01,  1.2259e-01, -1.7130e-01,  9.2757e-02, -2.0524e-01,\n         2.9841e-02, -9.5776e-02, -3.1330e-01, -1.3666e-01,  1.5430e-01,\n         7.7187e-02,  4.6550e-02, -1.9514e-01, -1.7819e-01,  6.3278e-02,\n        -1.9338e-01,  2.1946e-01,  5.9382e-02, -1.3073e-01,  2.4845e-01,\n         2.3705e-01, -1.6809e-01,  3.4737e-01,  1.2629e-01, -7.9406e-02,\n         2.9447e-01, -1.3092e-01, -1.4633e-01,  3.3359e-01,  9.3281e-02],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2503,  0.3033,  0.0111,  ...,  0.0599, -0.1472,  0.0598],\n        [-0.3297,  0.0759,  0.2657,  ..., -0.2234, -0.2688, -0.3308],\n        [ 0.3330,  0.3149, -0.1859,  ..., -0.1398,  0.2227,  0.3522],\n        ...,\n        [ 0.0491, -0.3229,  0.1679,  ...,  0.2780,  0.0256, -0.1029],\n        [ 0.0917, -0.0115, -0.3004,  ..., -0.1738, -0.1891,  0.1371],\n        [ 0.0510,  0.1073, -0.2654,  ..., -0.2284,  0.3035, -0.1857]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0121,  0.0309,  0.0403,  0.0321,  0.0428, -0.0368,  0.0285,  0.0288,\n         0.0051, -0.0366, -0.0188,  0.0173,  0.0095, -0.0064,  0.0380, -0.0006,\n         0.0302,  0.0261,  0.0208, -0.0054,  0.0041,  0.0296,  0.0057, -0.0498,\n         0.0013,  0.0097, -0.0017,  0.0070, -0.0483, -0.0341, -0.0119,  0.0163,\n         0.0282,  0.0358,  0.0424, -0.0350,  0.0462,  0.0472, -0.0061, -0.0415,\n        -0.0487,  0.0054, -0.0420, -0.0210,  0.0185, -0.0329,  0.0459, -0.0151,\n         0.0236, -0.0329,  0.0003, -0.0304,  0.0079, -0.0359,  0.0442,  0.0308,\n         0.0097,  0.0085, -0.0324, -0.0188, -0.0004, -0.0051, -0.0388,  0.0188,\n        -0.0242,  0.0019, -0.0463,  0.0098, -0.0462, -0.0237, -0.0026, -0.0201,\n         0.0003,  0.0257,  0.0471,  0.0329,  0.0437,  0.0184,  0.0177, -0.0433,\n         0.0492, -0.0378,  0.0483, -0.0348,  0.0050,  0.0453,  0.0274,  0.0469,\n        -0.0105, -0.0416,  0.0500,  0.0372, -0.0091,  0.0406,  0.0367,  0.0183,\n         0.0233,  0.0231, -0.0354, -0.0189, -0.0160, -0.0317, -0.0407, -0.0190,\n        -0.0451,  0.0038,  0.0202,  0.0155,  0.0327,  0.0176, -0.0119,  0.0123,\n         0.0100, -0.0260, -0.0208,  0.0417,  0.0191, -0.0319,  0.0171,  0.0400,\n        -0.0422,  0.0110,  0.0168,  0.0494,  0.0356,  0.0174, -0.0312,  0.0153,\n         0.0011, -0.0426,  0.0472,  0.0408, -0.0029,  0.0067, -0.0288, -0.0448,\n         0.0353,  0.0187,  0.0087, -0.0371,  0.0199, -0.0082, -0.0001,  0.0053,\n        -0.0340,  0.0434, -0.0460, -0.0093,  0.0407,  0.0430, -0.0300,  0.0355,\n        -0.0297, -0.0401, -0.0247, -0.0201, -0.0299, -0.0434, -0.0322, -0.0186,\n        -0.0494, -0.0346,  0.0235,  0.0052,  0.0438,  0.0384,  0.0139, -0.0310,\n        -0.0317,  0.0296, -0.0191,  0.0137,  0.0475, -0.0465,  0.0468,  0.0334,\n         0.0163,  0.0289, -0.0099,  0.0129,  0.0252,  0.0071,  0.0293,  0.0324,\n        -0.0289,  0.0062,  0.0059, -0.0106,  0.0238,  0.0089,  0.0327, -0.0267,\n        -0.0363,  0.0350, -0.0287, -0.0284,  0.0118, -0.0180,  0.0089, -0.0443,\n         0.0350, -0.0109,  0.0430, -0.0293, -0.0042, -0.0282,  0.0367,  0.0456,\n         0.0192, -0.0253, -0.0223, -0.0232, -0.0105, -0.0100,  0.0350, -0.0375,\n         0.0382, -0.0379,  0.0107, -0.0415,  0.0441, -0.0359,  0.0394, -0.0496,\n        -0.0444, -0.0363,  0.0304,  0.0154, -0.0384, -0.0235,  0.0399,  0.0157,\n         0.0422,  0.0057, -0.0458,  0.0417, -0.0362,  0.0229,  0.0091,  0.0190,\n        -0.0193,  0.0368,  0.0003,  0.0338,  0.0285, -0.0052, -0.0312, -0.0015,\n        -0.0114,  0.0147, -0.0066,  0.0091, -0.0125,  0.0204, -0.0485, -0.0485,\n        -0.0413,  0.0034, -0.0002,  0.0330,  0.0418,  0.0108, -0.0315,  0.0110,\n         0.0009,  0.0301,  0.0131,  0.0322, -0.0382,  0.0023,  0.0432,  0.0112,\n         0.0391,  0.0288, -0.0242, -0.0438,  0.0172, -0.0243,  0.0331,  0.0100,\n        -0.0492,  0.0447, -0.0277,  0.0135, -0.0286,  0.0036,  0.0407, -0.0240,\n         0.0319, -0.0103,  0.0160,  0.0092,  0.0190, -0.0094, -0.0012, -0.0390,\n         0.0103, -0.0107, -0.0034, -0.0317], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0194, -0.0422,  0.0146,  ...,  0.0002, -0.0435, -0.0485],\n        [ 0.0436, -0.0169,  0.0372,  ...,  0.0250, -0.0068,  0.0095],\n        [-0.0349, -0.0071,  0.0051,  ...,  0.0037,  0.0019,  0.0323],\n        ...,\n        [ 0.0054,  0.0444, -0.0425,  ..., -0.0271,  0.0089,  0.0443],\n        [-0.0158,  0.0154,  0.0163,  ...,  0.0153,  0.0170,  0.0275],\n        [ 0.0331, -0.0394,  0.0220,  ..., -0.0310, -0.0196, -0.0298]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0254,  0.0550,  0.0389, -0.0017], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0360, -0.0248,  0.0336,  ...,  0.0327,  0.0461,  0.0197],\n        [-0.0202, -0.0073, -0.0482,  ..., -0.0170, -0.0237, -0.0198],\n        [ 0.0576,  0.0463, -0.0114,  ...,  0.0446, -0.0265,  0.0412],\n        [ 0.0497, -0.0176,  0.0515,  ..., -0.0412,  0.0486, -0.0355]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2503,  0.3033,  0.0111,  ...,  0.0599, -0.1472,  0.0598],\n        [-0.3297,  0.0759,  0.2657,  ..., -0.2234, -0.2688, -0.3308],\n        [ 0.3330,  0.3149, -0.1859,  ..., -0.1398,  0.2227,  0.3522],\n        ...,\n        [ 0.0491, -0.3229,  0.1679,  ...,  0.2780,  0.0256, -0.1029],\n        [ 0.0917, -0.0115, -0.3004,  ..., -0.1738, -0.1891,  0.1371],\n        [ 0.0510,  0.1073, -0.2654,  ..., -0.2284,  0.3035, -0.1857]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-6.8111e-02,  1.6352e-02,  1.0155e-01, -2.5162e-01, -4.2880e-02,\n        -1.9521e-01, -2.3209e-01, -3.9605e-02,  2.5050e-02,  9.6478e-02,\n        -2.0157e-01, -1.2898e-01,  7.3536e-02,  3.2594e-01, -3.0258e-01,\n         1.4774e-01, -1.6013e-01,  2.7585e-01, -3.4538e-01,  3.0844e-01,\n        -3.1491e-01,  1.9097e-01, -3.3167e-01, -9.9506e-02,  3.4114e-01,\n         2.6878e-01, -9.4868e-02,  8.8406e-02, -7.9495e-02, -1.7844e-01,\n         7.7571e-02,  1.0614e-01, -1.9311e-01,  4.9094e-02, -1.6799e-01,\n        -2.5274e-01,  9.7710e-02,  1.3161e-01,  8.0010e-02, -3.3618e-02,\n        -2.7607e-01, -2.2516e-01,  2.8488e-01,  6.1582e-02,  3.3217e-01,\n         2.0559e-01, -1.9301e-01,  9.8491e-02, -9.7896e-02, -1.4598e-01,\n        -3.2763e-01, -7.7259e-02,  1.0775e-01, -2.9545e-05, -2.5854e-01,\n        -1.6352e-01, -2.7722e-01,  1.5744e-01, -2.2018e-01,  2.8861e-01,\n        -2.9976e-01,  1.5539e-01, -3.2462e-01,  1.0282e-01, -3.4911e-01,\n         1.0607e-01,  3.5018e-01, -2.8405e-01,  1.9580e-01,  1.4743e-01,\n         1.8843e-01, -2.7069e-01, -2.4944e-01,  3.3777e-02,  2.6535e-01,\n         1.2716e-01,  1.9917e-02, -1.5792e-01,  1.7987e-01, -2.2123e-01,\n         9.5251e-02,  2.0210e-01,  2.6957e-01,  2.8099e-01,  1.1582e-02,\n         2.1065e-01, -1.8092e-01,  3.1380e-01, -2.1981e-01,  4.2646e-02,\n        -1.4541e-01, -2.7973e-01,  7.5582e-02,  2.1797e-01, -2.6890e-01,\n         2.1274e-01,  1.0535e-01,  8.2296e-04, -8.9825e-02, -2.0899e-02,\n         1.1182e-01, -3.1888e-01,  2.2275e-01,  1.4260e-01,  3.3150e-01,\n        -1.1227e-01, -3.0399e-01,  2.8670e-01,  1.1704e-01, -2.2298e-01,\n         3.1048e-02,  2.6241e-01,  2.8747e-01, -1.4963e-01,  3.0606e-01,\n         1.6313e-02, -2.6490e-01, -1.4491e-01,  4.1103e-02, -2.2290e-02,\n         2.6097e-01, -3.0847e-01,  9.0792e-03,  1.7387e-01, -3.2881e-01,\n         2.1807e-01, -2.1930e-01, -1.6790e-01, -3.4965e-01,  7.9417e-02,\n        -1.2659e-01,  2.4549e-01, -3.0707e-01,  1.9163e-01,  1.7452e-01,\n         1.8673e-01,  1.6125e-01, -5.9934e-02,  3.5310e-01, -3.2602e-01,\n        -1.6394e-01, -1.7487e-01,  1.6262e-01, -1.6717e-01,  3.3329e-01,\n         6.9056e-02,  6.8831e-03, -1.4567e-01, -3.2604e-01,  5.1361e-02,\n         1.7067e-02,  1.5621e-01, -7.0918e-02, -3.6548e-02, -1.9856e-01,\n        -7.9953e-02, -8.7216e-02,  3.4613e-01, -3.0303e-01,  1.4206e-01,\n        -1.6294e-01,  2.6226e-01, -2.3780e-01, -5.1249e-02,  9.6765e-02,\n         2.7218e-01, -2.7730e-01,  3.3578e-01,  1.6212e-01,  7.6350e-02,\n         1.3579e-01, -1.3551e-01,  8.5354e-02,  1.3128e-01,  2.8483e-01,\n         2.4768e-01,  2.8944e-02,  6.7513e-02, -2.0715e-01,  2.3831e-02,\n         2.8673e-01,  3.2187e-01,  2.6185e-01, -3.1578e-02, -2.2283e-01,\n         2.7190e-01, -2.2837e-01,  2.2104e-01, -2.6305e-01, -1.4588e-01,\n         6.4406e-02,  2.5827e-01, -3.0486e-01,  3.2295e-01,  2.0062e-01,\n         3.2792e-01, -7.9203e-02, -1.8175e-01, -7.9275e-02, -2.0362e-01,\n        -9.2435e-02,  1.9446e-01,  9.9854e-02, -3.4644e-01,  2.9083e-01,\n         1.2067e-01,  1.6077e-01,  5.2898e-02, -5.6971e-02, -2.0630e-01,\n        -1.5179e-01,  8.1589e-02,  3.4056e-01, -2.3106e-01, -3.4167e-01,\n        -9.4886e-02,  9.7734e-02,  2.8138e-01,  2.5054e-02,  4.8316e-02,\n         2.8071e-01,  1.0351e-01,  1.1693e-01, -3.6686e-02, -2.5094e-01,\n        -2.7264e-01,  7.5048e-02, -3.4565e-01, -1.1562e-01,  2.2645e-01,\n        -3.2191e-01,  1.9584e-01, -9.3402e-02, -8.4426e-02, -2.4299e-01,\n         6.8034e-02, -8.4358e-02, -5.4629e-02, -3.1109e-01,  1.2346e-01,\n        -2.1239e-01,  3.3493e-01,  2.8830e-01, -8.5404e-02,  5.7336e-02,\n        -2.7644e-02,  7.7092e-02, -1.4388e-02,  3.5136e-01,  2.1720e-01,\n        -1.6327e-01, -1.6905e-02, -1.5889e-01, -1.4949e-01, -2.2320e-01,\n         3.1569e-01,  3.3197e-02, -2.0336e-02, -8.2663e-02, -3.4696e-01,\n        -2.8107e-01,  1.8312e-01, -3.9501e-02, -2.7266e-01,  2.4300e-01,\n        -3.9811e-02, -3.2752e-01, -6.4167e-02,  3.1055e-01,  3.0183e-02,\n        -9.5815e-03, -2.0421e-01,  3.3207e-01,  3.5079e-02, -3.9468e-02,\n         1.2687e-03,  3.3472e-01,  1.3580e-01, -2.8986e-01,  2.0158e-01,\n        -1.2172e-01,  1.0761e-01,  3.0965e-01,  3.0414e-01,  2.8709e-01,\n         2.3426e-02, -2.3526e-01,  6.0596e-03,  3.2563e-01, -2.3793e-01,\n         1.1765e-01, -1.5693e-01, -2.6827e-01, -2.3080e-01, -2.1696e-01,\n        -9.6960e-02,  8.8873e-02,  1.9319e-01, -3.2185e-01,  2.9007e-01,\n        -1.3704e-02,  1.4941e-01, -1.3788e-01,  1.7018e-01, -1.1944e-01,\n        -3.2865e-01, -5.6292e-02,  3.1315e-01, -7.6812e-02,  6.8317e-02,\n        -3.3600e-01, -3.4226e-01, -1.9488e-01,  2.7294e-01, -2.2203e-01,\n        -4.2156e-02, -1.9223e-01, -2.1520e-01, -2.5684e-01, -3.1217e-01,\n         8.8333e-02,  3.2011e-01, -2.1758e-01,  1.6022e-01, -1.4377e-01,\n         2.0982e-01,  2.4932e-01,  1.9944e-01,  5.6471e-02, -1.5593e-01,\n        -2.3054e-01,  1.1799e-02, -2.1813e-02, -1.2419e-01, -2.8297e-01,\n        -3.2245e-01,  2.8492e-01, -3.4271e-01, -3.2504e-01,  7.2032e-02,\n        -1.3451e-01, -2.2851e-01, -3.5913e-02,  3.0275e-01,  4.7795e-05,\n        -1.6171e-01, -3.4468e-01, -9.6784e-02, -2.2255e-01, -9.0284e-02,\n         1.6710e-01,  2.2405e-01, -1.8062e-01, -4.7457e-02,  3.3028e-02,\n        -3.5263e-01, -1.6073e-01, -2.6818e-01,  2.4167e-01, -2.6605e-01,\n        -1.3430e-01, -7.9785e-02,  1.7124e-01, -1.5931e-01, -3.4989e-02,\n        -1.2546e-01, -2.3501e-01, -3.2735e-02, -2.0062e-01, -1.0127e-01,\n        -2.0663e-01,  1.2259e-01, -1.7130e-01,  9.2757e-02, -2.0524e-01,\n         2.9841e-02, -9.5776e-02, -3.1330e-01, -1.3666e-01,  1.5430e-01,\n         7.7187e-02,  4.6550e-02, -1.9514e-01, -1.7819e-01,  6.3278e-02,\n        -1.9338e-01,  2.1946e-01,  5.9382e-02, -1.3073e-01,  2.4845e-01,\n         2.3705e-01, -1.6809e-01,  3.4737e-01,  1.2629e-01, -7.9406e-02,\n         2.9447e-01, -1.3092e-01, -1.4633e-01,  3.3359e-01,  9.3281e-02],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0194, -0.0422,  0.0146,  ...,  0.0002, -0.0435, -0.0485],\n        [ 0.0436, -0.0169,  0.0372,  ...,  0.0250, -0.0068,  0.0095],\n        [-0.0349, -0.0071,  0.0051,  ...,  0.0037,  0.0019,  0.0323],\n        ...,\n        [ 0.0054,  0.0444, -0.0425,  ..., -0.0271,  0.0089,  0.0443],\n        [-0.0158,  0.0154,  0.0163,  ...,  0.0153,  0.0170,  0.0275],\n        [ 0.0331, -0.0394,  0.0220,  ..., -0.0310, -0.0196, -0.0298]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0121,  0.0309,  0.0403,  0.0321,  0.0428, -0.0368,  0.0285,  0.0288,\n         0.0051, -0.0366, -0.0188,  0.0173,  0.0095, -0.0064,  0.0380, -0.0006,\n         0.0302,  0.0261,  0.0208, -0.0054,  0.0041,  0.0296,  0.0057, -0.0498,\n         0.0013,  0.0097, -0.0017,  0.0070, -0.0483, -0.0341, -0.0119,  0.0163,\n         0.0282,  0.0358,  0.0424, -0.0350,  0.0462,  0.0472, -0.0061, -0.0415,\n        -0.0487,  0.0054, -0.0420, -0.0210,  0.0185, -0.0329,  0.0459, -0.0151,\n         0.0236, -0.0329,  0.0003, -0.0304,  0.0079, -0.0359,  0.0442,  0.0308,\n         0.0097,  0.0085, -0.0324, -0.0188, -0.0004, -0.0051, -0.0388,  0.0188,\n        -0.0242,  0.0019, -0.0463,  0.0098, -0.0462, -0.0237, -0.0026, -0.0201,\n         0.0003,  0.0257,  0.0471,  0.0329,  0.0437,  0.0184,  0.0177, -0.0433,\n         0.0492, -0.0378,  0.0483, -0.0348,  0.0050,  0.0453,  0.0274,  0.0469,\n        -0.0105, -0.0416,  0.0500,  0.0372, -0.0091,  0.0406,  0.0367,  0.0183,\n         0.0233,  0.0231, -0.0354, -0.0189, -0.0160, -0.0317, -0.0407, -0.0190,\n        -0.0451,  0.0038,  0.0202,  0.0155,  0.0327,  0.0176, -0.0119,  0.0123,\n         0.0100, -0.0260, -0.0208,  0.0417,  0.0191, -0.0319,  0.0171,  0.0400,\n        -0.0422,  0.0110,  0.0168,  0.0494,  0.0356,  0.0174, -0.0312,  0.0153,\n         0.0011, -0.0426,  0.0472,  0.0408, -0.0029,  0.0067, -0.0288, -0.0448,\n         0.0353,  0.0187,  0.0087, -0.0371,  0.0199, -0.0082, -0.0001,  0.0053,\n        -0.0340,  0.0434, -0.0460, -0.0093,  0.0407,  0.0430, -0.0300,  0.0355,\n        -0.0297, -0.0401, -0.0247, -0.0201, -0.0299, -0.0434, -0.0322, -0.0186,\n        -0.0494, -0.0346,  0.0235,  0.0052,  0.0438,  0.0384,  0.0139, -0.0310,\n        -0.0317,  0.0296, -0.0191,  0.0137,  0.0475, -0.0465,  0.0468,  0.0334,\n         0.0163,  0.0289, -0.0099,  0.0129,  0.0252,  0.0071,  0.0293,  0.0324,\n        -0.0289,  0.0062,  0.0059, -0.0106,  0.0238,  0.0089,  0.0327, -0.0267,\n        -0.0363,  0.0350, -0.0287, -0.0284,  0.0118, -0.0180,  0.0089, -0.0443,\n         0.0350, -0.0109,  0.0430, -0.0293, -0.0042, -0.0282,  0.0367,  0.0456,\n         0.0192, -0.0253, -0.0223, -0.0232, -0.0105, -0.0100,  0.0350, -0.0375,\n         0.0382, -0.0379,  0.0107, -0.0415,  0.0441, -0.0359,  0.0394, -0.0496,\n        -0.0444, -0.0363,  0.0304,  0.0154, -0.0384, -0.0235,  0.0399,  0.0157,\n         0.0422,  0.0057, -0.0458,  0.0417, -0.0362,  0.0229,  0.0091,  0.0190,\n        -0.0193,  0.0368,  0.0003,  0.0338,  0.0285, -0.0052, -0.0312, -0.0015,\n        -0.0114,  0.0147, -0.0066,  0.0091, -0.0125,  0.0204, -0.0485, -0.0485,\n        -0.0413,  0.0034, -0.0002,  0.0330,  0.0418,  0.0108, -0.0315,  0.0110,\n         0.0009,  0.0301,  0.0131,  0.0322, -0.0382,  0.0023,  0.0432,  0.0112,\n         0.0391,  0.0288, -0.0242, -0.0438,  0.0172, -0.0243,  0.0331,  0.0100,\n        -0.0492,  0.0447, -0.0277,  0.0135, -0.0286,  0.0036,  0.0407, -0.0240,\n         0.0319, -0.0103,  0.0160,  0.0092,  0.0190, -0.0094, -0.0012, -0.0390,\n         0.0103, -0.0107, -0.0034, -0.0317], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0360, -0.0248,  0.0336,  ...,  0.0327,  0.0461,  0.0197],\n        [-0.0202, -0.0073, -0.0482,  ..., -0.0170, -0.0237, -0.0198],\n        [ 0.0576,  0.0463, -0.0114,  ...,  0.0446, -0.0265,  0.0412],\n        [ 0.0497, -0.0176,  0.0515,  ..., -0.0412,  0.0486, -0.0355]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0254,  0.0550,  0.0389, -0.0017], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x785ef2fe6510>":	{
                    "capacity":	50000,
                    "current_segment":	0,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	50000,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-6.8111e-02,  1.6352e-02,  1.0155e-01, -2.5162e-01, -4.2880e-02,\n        -1.9521e-01, -2.3209e-01, -3.9605e-02,  2.5050e-02,  9.6478e-02,\n        -2.0157e-01, -1.2898e-01,  7.3536e-02,  3.2594e-01, -3.0258e-01,\n         1.4774e-01, -1.6013e-01,  2.7585e-01, -3.4538e-01,  3.0844e-01,\n        -3.1491e-01,  1.9097e-01, -3.3167e-01, -9.9506e-02,  3.4114e-01,\n         2.6878e-01, -9.4868e-02,  8.8406e-02, -7.9495e-02, -1.7844e-01,\n         7.7571e-02,  1.0614e-01, -1.9311e-01,  4.9094e-02, -1.6799e-01,\n        -2.5274e-01,  9.7710e-02,  1.3161e-01,  8.0010e-02, -3.3618e-02,\n        -2.7607e-01, -2.2516e-01,  2.8488e-01,  6.1582e-02,  3.3217e-01,\n         2.0559e-01, -1.9301e-01,  9.8491e-02, -9.7896e-02, -1.4598e-01,\n        -3.2763e-01, -7.7259e-02,  1.0775e-01, -2.9545e-05, -2.5854e-01,\n        -1.6352e-01, -2.7722e-01,  1.5744e-01, -2.2018e-01,  2.8861e-01,\n        -2.9976e-01,  1.5539e-01, -3.2462e-01,  1.0282e-01, -3.4911e-01,\n         1.0607e-01,  3.5018e-01, -2.8405e-01,  1.9580e-01,  1.4743e-01,\n         1.8843e-01, -2.7069e-01, -2.4944e-01,  3.3777e-02,  2.6535e-01,\n         1.2716e-01,  1.9917e-02, -1.5792e-01,  1.7987e-01, -2.2123e-01,\n         9.5251e-02,  2.0210e-01,  2.6957e-01,  2.8099e-01,  1.1582e-02,\n         2.1065e-01, -1.8092e-01,  3.1380e-01, -2.1981e-01,  4.2646e-02,\n        -1.4541e-01, -2.7973e-01,  7.5582e-02,  2.1797e-01, -2.6890e-01,\n         2.1274e-01,  1.0535e-01,  8.2296e-04, -8.9825e-02, -2.0899e-02,\n         1.1182e-01, -3.1888e-01,  2.2275e-01,  1.4260e-01,  3.3150e-01,\n        -1.1227e-01, -3.0399e-01,  2.8670e-01,  1.1704e-01, -2.2298e-01,\n         3.1048e-02,  2.6241e-01,  2.8747e-01, -1.4963e-01,  3.0606e-01,\n         1.6313e-02, -2.6490e-01, -1.4491e-01,  4.1103e-02, -2.2290e-02,\n         2.6097e-01, -3.0847e-01,  9.0792e-03,  1.7387e-01, -3.2881e-01,\n         2.1807e-01, -2.1930e-01, -1.6790e-01, -3.4965e-01,  7.9417e-02,\n        -1.2659e-01,  2.4549e-01, -3.0707e-01,  1.9163e-01,  1.7452e-01,\n         1.8673e-01,  1.6125e-01, -5.9934e-02,  3.5310e-01, -3.2602e-01,\n        -1.6394e-01, -1.7487e-01,  1.6262e-01, -1.6717e-01,  3.3329e-01,\n         6.9056e-02,  6.8831e-03, -1.4567e-01, -3.2604e-01,  5.1361e-02,\n         1.7067e-02,  1.5621e-01, -7.0918e-02, -3.6548e-02, -1.9856e-01,\n        -7.9953e-02, -8.7216e-02,  3.4613e-01, -3.0303e-01,  1.4206e-01,\n        -1.6294e-01,  2.6226e-01, -2.3780e-01, -5.1249e-02,  9.6765e-02,\n         2.7218e-01, -2.7730e-01,  3.3578e-01,  1.6212e-01,  7.6350e-02,\n         1.3579e-01, -1.3551e-01,  8.5354e-02,  1.3128e-01,  2.8483e-01,\n         2.4768e-01,  2.8944e-02,  6.7513e-02, -2.0715e-01,  2.3831e-02,\n         2.8673e-01,  3.2187e-01,  2.6185e-01, -3.1578e-02, -2.2283e-01,\n         2.7190e-01, -2.2837e-01,  2.2104e-01, -2.6305e-01, -1.4588e-01,\n         6.4406e-02,  2.5827e-01, -3.0486e-01,  3.2295e-01,  2.0062e-01,\n         3.2792e-01, -7.9203e-02, -1.8175e-01, -7.9275e-02, -2.0362e-01,\n        -9.2435e-02,  1.9446e-01,  9.9854e-02, -3.4644e-01,  2.9083e-01,\n         1.2067e-01,  1.6077e-01,  5.2898e-02, -5.6971e-02, -2.0630e-01,\n        -1.5179e-01,  8.1589e-02,  3.4056e-01, -2.3106e-01, -3.4167e-01,\n        -9.4886e-02,  9.7734e-02,  2.8138e-01,  2.5054e-02,  4.8316e-02,\n         2.8071e-01,  1.0351e-01,  1.1693e-01, -3.6686e-02, -2.5094e-01,\n        -2.7264e-01,  7.5048e-02, -3.4565e-01, -1.1562e-01,  2.2645e-01,\n        -3.2191e-01,  1.9584e-01, -9.3402e-02, -8.4426e-02, -2.4299e-01,\n         6.8034e-02, -8.4358e-02, -5.4629e-02, -3.1109e-01,  1.2346e-01,\n        -2.1239e-01,  3.3493e-01,  2.8830e-01, -8.5404e-02,  5.7336e-02,\n        -2.7644e-02,  7.7092e-02, -1.4388e-02,  3.5136e-01,  2.1720e-01,\n        -1.6327e-01, -1.6905e-02, -1.5889e-01, -1.4949e-01, -2.2320e-01,\n         3.1569e-01,  3.3197e-02, -2.0336e-02, -8.2663e-02, -3.4696e-01,\n        -2.8107e-01,  1.8312e-01, -3.9501e-02, -2.7266e-01,  2.4300e-01,\n        -3.9811e-02, -3.2752e-01, -6.4167e-02,  3.1055e-01,  3.0183e-02,\n        -9.5815e-03, -2.0421e-01,  3.3207e-01,  3.5079e-02, -3.9468e-02,\n         1.2687e-03,  3.3472e-01,  1.3580e-01, -2.8986e-01,  2.0158e-01,\n        -1.2172e-01,  1.0761e-01,  3.0965e-01,  3.0414e-01,  2.8709e-01,\n         2.3426e-02, -2.3526e-01,  6.0596e-03,  3.2563e-01, -2.3793e-01,\n         1.1765e-01, -1.5693e-01, -2.6827e-01, -2.3080e-01, -2.1696e-01,\n        -9.6960e-02,  8.8873e-02,  1.9319e-01, -3.2185e-01,  2.9007e-01,\n        -1.3704e-02,  1.4941e-01, -1.3788e-01,  1.7018e-01, -1.1944e-01,\n        -3.2865e-01, -5.6292e-02,  3.1315e-01, -7.6812e-02,  6.8317e-02,\n        -3.3600e-01, -3.4226e-01, -1.9488e-01,  2.7294e-01, -2.2203e-01,\n        -4.2156e-02, -1.9223e-01, -2.1520e-01, -2.5684e-01, -3.1217e-01,\n         8.8333e-02,  3.2011e-01, -2.1758e-01,  1.6022e-01, -1.4377e-01,\n         2.0982e-01,  2.4932e-01,  1.9944e-01,  5.6471e-02, -1.5593e-01,\n        -2.3054e-01,  1.1799e-02, -2.1813e-02, -1.2419e-01, -2.8297e-01,\n        -3.2245e-01,  2.8492e-01, -3.4271e-01, -3.2504e-01,  7.2032e-02,\n        -1.3451e-01, -2.2851e-01, -3.5913e-02,  3.0275e-01,  4.7795e-05,\n        -1.6171e-01, -3.4468e-01, -9.6784e-02, -2.2255e-01, -9.0284e-02,\n         1.6710e-01,  2.2405e-01, -1.8062e-01, -4.7457e-02,  3.3028e-02,\n        -3.5263e-01, -1.6073e-01, -2.6818e-01,  2.4167e-01, -2.6605e-01,\n        -1.3430e-01, -7.9785e-02,  1.7124e-01, -1.5931e-01, -3.4989e-02,\n        -1.2546e-01, -2.3501e-01, -3.2735e-02, -2.0062e-01, -1.0127e-01,\n        -2.0663e-01,  1.2259e-01, -1.7130e-01,  9.2757e-02, -2.0524e-01,\n         2.9841e-02, -9.5776e-02, -3.1330e-01, -1.3666e-01,  1.5430e-01,\n         7.7187e-02,  4.6550e-02, -1.9514e-01, -1.7819e-01,  6.3278e-02,\n        -1.9338e-01,  2.1946e-01,  5.9382e-02, -1.3073e-01,  2.4845e-01,\n         2.3705e-01, -1.6809e-01,  3.4737e-01,  1.2629e-01, -7.9406e-02,\n         2.9447e-01, -1.3092e-01, -1.4633e-01,  3.3359e-01,  9.3281e-02],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2503,  0.3033,  0.0111,  ...,  0.0599, -0.1472,  0.0598],\n        [-0.3297,  0.0759,  0.2657,  ..., -0.2234, -0.2688, -0.3308],\n        [ 0.3330,  0.3149, -0.1859,  ..., -0.1398,  0.2227,  0.3522],\n        ...,\n        [ 0.0491, -0.3229,  0.1679,  ...,  0.2780,  0.0256, -0.1029],\n        [ 0.0917, -0.0115, -0.3004,  ..., -0.1738, -0.1891,  0.1371],\n        [ 0.0510,  0.1073, -0.2654,  ..., -0.2284,  0.3035, -0.1857]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0121,  0.0309,  0.0403,  0.0321,  0.0428, -0.0368,  0.0285,  0.0288,\n         0.0051, -0.0366, -0.0188,  0.0173,  0.0095, -0.0064,  0.0380, -0.0006,\n         0.0302,  0.0261,  0.0208, -0.0054,  0.0041,  0.0296,  0.0057, -0.0498,\n         0.0013,  0.0097, -0.0017,  0.0070, -0.0483, -0.0341, -0.0119,  0.0163,\n         0.0282,  0.0358,  0.0424, -0.0350,  0.0462,  0.0472, -0.0061, -0.0415,\n        -0.0487,  0.0054, -0.0420, -0.0210,  0.0185, -0.0329,  0.0459, -0.0151,\n         0.0236, -0.0329,  0.0003, -0.0304,  0.0079, -0.0359,  0.0442,  0.0308,\n         0.0097,  0.0085, -0.0324, -0.0188, -0.0004, -0.0051, -0.0388,  0.0188,\n        -0.0242,  0.0019, -0.0463,  0.0098, -0.0462, -0.0237, -0.0026, -0.0201,\n         0.0003,  0.0257,  0.0471,  0.0329,  0.0437,  0.0184,  0.0177, -0.0433,\n         0.0492, -0.0378,  0.0483, -0.0348,  0.0050,  0.0453,  0.0274,  0.0469,\n        -0.0105, -0.0416,  0.0500,  0.0372, -0.0091,  0.0406,  0.0367,  0.0183,\n         0.0233,  0.0231, -0.0354, -0.0189, -0.0160, -0.0317, -0.0407, -0.0190,\n        -0.0451,  0.0038,  0.0202,  0.0155,  0.0327,  0.0176, -0.0119,  0.0123,\n         0.0100, -0.0260, -0.0208,  0.0417,  0.0191, -0.0319,  0.0171,  0.0400,\n        -0.0422,  0.0110,  0.0168,  0.0494,  0.0356,  0.0174, -0.0312,  0.0153,\n         0.0011, -0.0426,  0.0472,  0.0408, -0.0029,  0.0067, -0.0288, -0.0448,\n         0.0353,  0.0187,  0.0087, -0.0371,  0.0199, -0.0082, -0.0001,  0.0053,\n        -0.0340,  0.0434, -0.0460, -0.0093,  0.0407,  0.0430, -0.0300,  0.0355,\n        -0.0297, -0.0401, -0.0247, -0.0201, -0.0299, -0.0434, -0.0322, -0.0186,\n        -0.0494, -0.0346,  0.0235,  0.0052,  0.0438,  0.0384,  0.0139, -0.0310,\n        -0.0317,  0.0296, -0.0191,  0.0137,  0.0475, -0.0465,  0.0468,  0.0334,\n         0.0163,  0.0289, -0.0099,  0.0129,  0.0252,  0.0071,  0.0293,  0.0324,\n        -0.0289,  0.0062,  0.0059, -0.0106,  0.0238,  0.0089,  0.0327, -0.0267,\n        -0.0363,  0.0350, -0.0287, -0.0284,  0.0118, -0.0180,  0.0089, -0.0443,\n         0.0350, -0.0109,  0.0430, -0.0293, -0.0042, -0.0282,  0.0367,  0.0456,\n         0.0192, -0.0253, -0.0223, -0.0232, -0.0105, -0.0100,  0.0350, -0.0375,\n         0.0382, -0.0379,  0.0107, -0.0415,  0.0441, -0.0359,  0.0394, -0.0496,\n        -0.0444, -0.0363,  0.0304,  0.0154, -0.0384, -0.0235,  0.0399,  0.0157,\n         0.0422,  0.0057, -0.0458,  0.0417, -0.0362,  0.0229,  0.0091,  0.0190,\n        -0.0193,  0.0368,  0.0003,  0.0338,  0.0285, -0.0052, -0.0312, -0.0015,\n        -0.0114,  0.0147, -0.0066,  0.0091, -0.0125,  0.0204, -0.0485, -0.0485,\n        -0.0413,  0.0034, -0.0002,  0.0330,  0.0418,  0.0108, -0.0315,  0.0110,\n         0.0009,  0.0301,  0.0131,  0.0322, -0.0382,  0.0023,  0.0432,  0.0112,\n         0.0391,  0.0288, -0.0242, -0.0438,  0.0172, -0.0243,  0.0331,  0.0100,\n        -0.0492,  0.0447, -0.0277,  0.0135, -0.0286,  0.0036,  0.0407, -0.0240,\n         0.0319, -0.0103,  0.0160,  0.0092,  0.0190, -0.0094, -0.0012, -0.0390,\n         0.0103, -0.0107, -0.0034, -0.0317], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0194, -0.0422,  0.0146,  ...,  0.0002, -0.0435, -0.0485],\n        [ 0.0436, -0.0169,  0.0372,  ...,  0.0250, -0.0068,  0.0095],\n        [-0.0349, -0.0071,  0.0051,  ...,  0.0037,  0.0019,  0.0323],\n        ...,\n        [ 0.0054,  0.0444, -0.0425,  ..., -0.0271,  0.0089,  0.0443],\n        [-0.0158,  0.0154,  0.0163,  ...,  0.0153,  0.0170,  0.0275],\n        [ 0.0331, -0.0394,  0.0220,  ..., -0.0310, -0.0196, -0.0298]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0254,  0.0550,  0.0389, -0.0017], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0360, -0.0248,  0.0336,  ...,  0.0327,  0.0461,  0.0197],\n        [-0.0202, -0.0073, -0.0482,  ..., -0.0170, -0.0237, -0.0198],\n        [ 0.0576,  0.0463, -0.0114,  ...,  0.0446, -0.0265,  0.0412],\n        [ 0.0497, -0.0176,  0.0515,  ..., -0.0412,  0.0486, -0.0355]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x785e723d19d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s144340000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s144340000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}