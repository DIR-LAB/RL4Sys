{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s145120000"
    },
    "q_lr":	0.0005,
    "seed":	145120000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x303dee3b0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2566,  0.3493,  0.3226, -0.1083, -0.1045, -0.0248,  0.1249,  0.3449,\n         0.1499,  0.1257,  0.0143, -0.2473,  0.1351,  0.0709,  0.0357, -0.0397,\n        -0.2901,  0.2556, -0.2632,  0.3423, -0.3009, -0.3037, -0.3252, -0.1539,\n         0.0190, -0.1421,  0.0981, -0.0542, -0.3104, -0.0015, -0.0931, -0.1093],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0708, -0.0543,  0.2200, -0.0115, -0.2670, -0.1947,  0.1980,  0.0406],\n        [ 0.2836,  0.3182, -0.2209, -0.3477, -0.0460,  0.2508,  0.3340, -0.1519],\n        [ 0.2652,  0.2562, -0.1001,  0.2614, -0.2087,  0.0529, -0.1998,  0.3512],\n        [ 0.2049, -0.1198,  0.0855,  0.1361, -0.3466, -0.1295, -0.2141,  0.2968],\n        [ 0.0662,  0.2548, -0.1244, -0.3092, -0.2175, -0.0435, -0.1939, -0.2937],\n        [ 0.1243, -0.3273, -0.0682, -0.1307,  0.0576,  0.2783, -0.0974,  0.2384],\n        [ 0.0177, -0.3399, -0.1019,  0.3389,  0.0764,  0.2038,  0.2220,  0.2852],\n        [-0.2436, -0.0450,  0.2635,  0.3164,  0.3404,  0.0364, -0.3397, -0.1575],\n        [ 0.1636,  0.0449,  0.0004, -0.2496, -0.2218,  0.1381,  0.0432, -0.2287],\n        [-0.0061,  0.1340,  0.2959,  0.1970,  0.2443,  0.1276, -0.0104, -0.0392],\n        [-0.2446,  0.0999, -0.3413,  0.0217, -0.0438, -0.1083, -0.1717, -0.3261],\n        [-0.1001,  0.2703,  0.1842,  0.2235, -0.2912, -0.2735,  0.2795, -0.2791],\n        [-0.1417, -0.2924,  0.1393,  0.2800,  0.3086, -0.0670,  0.0421, -0.1245],\n        [ 0.1801,  0.2063,  0.3289, -0.2011,  0.1608,  0.0940, -0.3342,  0.0649],\n        [-0.2943,  0.3419,  0.1846,  0.1020, -0.1386, -0.1256, -0.0362,  0.3347],\n        [ 0.1453,  0.2558, -0.0502,  0.2195, -0.3041,  0.1215, -0.2970, -0.3056],\n        [ 0.0303, -0.2059, -0.1510,  0.0135, -0.3011,  0.2352, -0.2078, -0.0818],\n        [ 0.2947,  0.0394, -0.0046,  0.3113,  0.1153, -0.0926, -0.1300, -0.0570],\n        [-0.2774, -0.2157, -0.0825, -0.2448,  0.0889,  0.1010,  0.2798, -0.1144],\n        [ 0.1459,  0.2125, -0.3270,  0.0496, -0.0835, -0.3211, -0.1059,  0.2000],\n        [-0.0985,  0.0411,  0.1104,  0.1764,  0.2073,  0.1758,  0.1508,  0.2562],\n        [ 0.1195,  0.1167,  0.2280, -0.2120,  0.3449,  0.1411, -0.2748, -0.1187],\n        [-0.1475,  0.0692, -0.0571, -0.1156,  0.2013, -0.0261, -0.1295,  0.0734],\n        [ 0.1021,  0.2749,  0.0762, -0.0312,  0.3377, -0.2505,  0.0942, -0.1674],\n        [ 0.0994, -0.3359, -0.3376, -0.0400, -0.2236,  0.1113, -0.0411, -0.3235],\n        [-0.3419, -0.0246, -0.0346,  0.1786,  0.3265,  0.0887,  0.2156,  0.2680],\n        [-0.2861,  0.2117,  0.3481, -0.1691,  0.2003,  0.1315,  0.2405, -0.0058],\n        [-0.2151, -0.0719, -0.2856, -0.1767, -0.3260,  0.1931, -0.3288,  0.0028],\n        [-0.1515,  0.2168, -0.1593,  0.0666, -0.0609,  0.1275,  0.2054, -0.2449],\n        [ 0.1130,  0.3123, -0.1605,  0.0909, -0.2399,  0.3149,  0.0492,  0.1291],\n        [-0.2154, -0.2191, -0.2637,  0.2047, -0.2044, -0.0391,  0.1599, -0.1708],\n        [ 0.2871,  0.2437, -0.3346, -0.1482,  0.0187,  0.3204, -0.3105,  0.0239]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0766,  0.1532,  0.1475,  0.0283,  0.1536, -0.1574,  0.0650, -0.1650,\n        -0.0303, -0.0250,  0.0097, -0.0386, -0.1102, -0.0303, -0.0777,  0.0714],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0953e-01, -2.6909e-02,  5.8590e-02, -1.2572e-01,  7.0090e-02,\n         -7.9293e-02, -4.0232e-02, -1.5427e-01, -1.2412e-01,  1.1567e-01,\n         -6.6073e-02, -8.8868e-02,  9.4858e-02, -1.8936e-02,  6.9239e-02,\n          1.5630e-01, -7.8978e-02,  3.3809e-02, -9.2306e-02, -1.6451e-01,\n         -7.1730e-02,  1.7527e-01,  1.3820e-03,  1.0580e-01, -8.4571e-02,\n          3.9819e-02, -1.2398e-01, -1.4249e-02, -6.8427e-02,  3.0602e-02,\n         -1.4397e-01,  8.9275e-02],\n        [-4.0961e-02,  1.2662e-01, -1.3500e-01,  1.0515e-01, -2.5216e-02,\n         -5.7587e-03,  1.2296e-01,  1.6676e-01, -1.7256e-01, -4.7854e-02,\n          7.6496e-03,  1.0141e-01, -1.0490e-01,  1.2853e-01,  1.4266e-01,\n         -1.7391e-01,  1.2222e-01, -5.2689e-02, -4.3150e-02,  3.9694e-02,\n         -9.9904e-02,  7.1038e-02,  1.1554e-01,  1.7443e-01,  1.6903e-01,\n          1.9307e-02, -1.4342e-01, -8.8368e-02,  4.9371e-02,  1.0773e-01,\n         -8.6562e-02, -7.5080e-02],\n        [ 1.1276e-01, -1.0895e-01,  9.7019e-02,  7.6786e-02, -6.5425e-03,\n         -1.3678e-01, -1.6694e-01, -6.3120e-02, -1.0568e-01,  1.2387e-01,\n         -5.3008e-02,  1.6114e-01,  1.0218e-01,  7.3255e-02,  1.1528e-01,\n         -1.6182e-01, -5.4570e-02,  1.4202e-01,  1.6492e-01, -1.1905e-02,\n          9.4022e-02, -3.8324e-02,  1.6529e-01, -4.0250e-02, -1.1373e-02,\n         -1.2090e-01,  3.8354e-02, -1.5375e-01, -7.0431e-02,  4.5207e-02,\n         -1.3024e-01,  1.6473e-01],\n        [-6.1839e-02,  9.0030e-02,  2.0036e-02, -3.2605e-02,  6.6618e-02,\n         -1.5083e-01, -1.4489e-01, -1.7017e-01, -1.2192e-01, -1.3364e-01,\n          8.5192e-02,  1.6589e-01, -1.0161e-01, -1.7382e-01,  1.2910e-01,\n          1.4257e-02, -3.7078e-02, -1.1623e-02,  1.8990e-02, -1.2678e-01,\n         -3.7714e-02, -6.2908e-02, -1.5232e-02, -7.6205e-02,  1.4367e-01,\n         -9.5401e-02,  1.2461e-01, -1.6261e-01, -4.2570e-02,  1.3079e-02,\n         -9.6707e-03, -1.0758e-01],\n        [ 9.9781e-02,  3.9226e-02, -1.8624e-02,  1.3436e-01,  1.3484e-01,\n         -7.2352e-02,  6.5159e-02, -1.4063e-01, -8.5086e-02, -2.4991e-02,\n         -1.2371e-02,  1.5787e-01,  3.7001e-02,  6.8077e-02, -7.6546e-02,\n          6.9467e-02,  1.5581e-01, -8.6144e-02,  1.0063e-01, -1.3160e-01,\n          1.3873e-01, -1.0663e-01,  1.1358e-01, -1.3301e-01,  8.2628e-02,\n         -5.8999e-02, -7.8892e-02, -4.2782e-02,  1.0313e-02,  3.4413e-02,\n          7.6417e-02, -7.7434e-03],\n        [ 6.2846e-02,  1.6048e-01,  3.2008e-02, -1.0127e-01, -3.6109e-03,\n         -1.0574e-01, -1.5157e-01,  8.4484e-02, -8.5713e-02, -1.1593e-01,\n          6.8059e-02,  1.3730e-03,  1.5591e-01, -1.0799e-01, -9.9412e-02,\n         -1.0330e-01, -8.5049e-02, -1.1510e-01,  3.6209e-02,  1.7505e-01,\n         -1.0175e-01, -1.3592e-01, -2.0794e-02,  1.5488e-01,  1.4697e-01,\n          1.0647e-02, -8.6129e-02, -1.4364e-02, -3.4448e-02,  1.6370e-01,\n          1.3564e-01, -1.2767e-01],\n        [ 7.6162e-02, -1.2681e-01,  6.7616e-02, -6.5235e-02,  2.4576e-02,\n          1.0775e-01,  1.3551e-01,  1.2480e-01, -1.7359e-01,  1.4053e-01,\n          7.8062e-02,  1.0320e-01, -6.6022e-02,  1.1489e-01, -1.0064e-01,\n          8.3208e-02,  3.5259e-02, -1.3501e-02,  1.2423e-01,  8.2409e-02,\n         -1.7451e-01, -9.5233e-02, -1.5277e-01,  1.3006e-01, -1.5816e-02,\n          4.4083e-03,  1.7306e-01, -7.1310e-02,  1.2967e-01,  4.9470e-02,\n         -1.2725e-01,  4.7240e-02],\n        [ 1.9324e-02, -9.1072e-02,  8.3334e-02,  8.7281e-02,  7.5516e-02,\n         -1.2511e-01, -1.3692e-01,  9.2941e-02, -8.1326e-02,  6.4711e-02,\n         -7.8299e-02, -1.5372e-01, -1.6500e-01, -7.2536e-02, -5.6938e-02,\n         -1.6984e-01,  1.7335e-01, -1.2001e-01,  7.5654e-02, -6.2098e-02,\n          5.6919e-02, -1.6910e-01,  1.0846e-01,  9.8155e-02,  4.8549e-02,\n          7.7256e-02,  7.7337e-03,  1.7478e-01, -1.1315e-01,  1.7828e-02,\n         -7.7289e-02, -3.5786e-02],\n        [ 1.4104e-01,  1.7597e-01,  5.3519e-03, -4.8908e-02,  9.2966e-02,\n          1.1471e-01, -5.9542e-02,  2.1957e-02,  5.0503e-02, -1.4720e-01,\n          1.3144e-01,  1.3561e-01, -1.0943e-01,  6.1580e-02,  1.0817e-01,\n          6.2631e-02, -1.3276e-01, -8.8534e-02,  1.6848e-01,  9.9370e-02,\n          7.2126e-02,  4.2357e-02,  1.5592e-01, -8.5581e-02, -5.4800e-02,\n          3.3088e-02, -6.2336e-02,  6.5112e-02,  7.1871e-02, -4.8893e-02,\n         -9.1601e-02,  2.6889e-02],\n        [ 6.8977e-02,  6.4467e-02, -4.3259e-02, -5.1179e-02, -1.7151e-01,\n          3.9510e-03,  4.9500e-02,  5.5933e-02, -1.0536e-01, -3.0075e-02,\n          3.4139e-02, -1.0858e-01, -7.1916e-02,  1.0930e-01, -1.4764e-01,\n          1.6041e-01, -1.1170e-01,  1.3301e-01,  1.4210e-01,  1.1994e-01,\n         -1.8292e-02, -6.5367e-02,  1.5519e-01, -1.4963e-01, -3.9527e-02,\n         -3.7057e-02, -1.1151e-02, -2.3821e-02,  9.7645e-02, -9.8757e-02,\n         -1.6570e-01, -1.5630e-01],\n        [ 5.8150e-02,  7.7260e-02, -1.4070e-01,  1.6122e-02, -3.8802e-02,\n          8.3775e-02,  1.6129e-02,  5.0560e-02,  1.1929e-01,  1.4521e-01,\n         -5.2336e-02,  5.8511e-02,  9.3451e-03, -1.2787e-01,  1.5215e-01,\n         -4.0847e-02, -1.4350e-01, -5.0434e-02,  1.4811e-01, -1.3860e-01,\n         -6.1005e-02,  4.4725e-02,  7.3759e-02,  1.2973e-01,  5.7787e-02,\n          5.6054e-02,  4.0601e-02, -3.0480e-02,  1.3083e-01, -1.4748e-01,\n          9.3062e-02,  1.6944e-02],\n        [-1.7053e-01,  4.4332e-03, -1.4460e-01, -1.6753e-02,  2.1915e-02,\n         -1.1087e-01, -6.6921e-02, -1.7323e-01,  7.2708e-02, -8.6232e-02,\n          5.1068e-02, -4.8314e-02,  3.8335e-02, -1.8614e-02, -5.7568e-02,\n          6.5659e-02, -1.4640e-01,  3.4565e-02, -1.0416e-01,  1.6038e-01,\n          4.9740e-02, -7.3215e-02,  5.1996e-02,  9.5213e-02,  1.5101e-01,\n          1.1754e-01,  1.0525e-01,  5.2434e-02,  5.6240e-02,  1.2367e-01,\n         -1.7214e-01,  4.2451e-02],\n        [-1.0376e-01,  7.5038e-03,  1.3159e-01,  1.4372e-01,  7.6560e-02,\n          9.0649e-03,  1.6110e-01,  1.5634e-01, -3.8718e-02, -9.8537e-02,\n          1.4801e-01, -9.4940e-02, -1.6937e-01,  1.3344e-01, -5.2866e-02,\n         -1.2726e-01, -1.6445e-01, -1.7411e-01,  3.6091e-02,  5.9217e-02,\n         -9.0735e-02,  1.2415e-01,  1.1873e-01,  1.6012e-01,  1.7359e-01,\n          2.7280e-02,  1.7286e-01,  1.0024e-01, -1.7309e-01, -1.7511e-01,\n         -1.9957e-02, -2.8687e-02],\n        [-7.4322e-02, -7.0474e-02,  3.3559e-02, -8.1476e-02,  7.9874e-02,\n         -1.6887e-01,  1.1016e-01,  1.4482e-01,  1.1790e-01,  1.0434e-01,\n         -9.8440e-02,  6.0743e-02, -6.1740e-03,  1.3136e-01,  4.2205e-02,\n         -4.9908e-02, -9.3374e-02, -3.3675e-02, -1.7061e-01,  1.1160e-01,\n          6.7181e-02, -1.1192e-01, -1.2055e-01,  7.8226e-03, -5.7212e-02,\n         -1.4017e-01, -4.5821e-02,  4.7754e-03,  5.2243e-03,  1.2099e-01,\n          3.8886e-02,  1.3112e-01],\n        [ 7.3931e-02,  1.7602e-01,  1.2048e-01, -1.5418e-01, -2.4663e-02,\n          1.3273e-01,  5.9797e-02,  3.1136e-02, -1.0400e-01, -1.6328e-01,\n         -8.5027e-02,  8.8905e-02,  5.0865e-02,  1.1228e-01, -1.4441e-01,\n         -1.2676e-01, -1.2657e-02,  2.4918e-02,  1.6137e-01, -9.7656e-02,\n         -3.5820e-02, -6.6875e-02, -4.1667e-02, -3.8618e-02, -1.0350e-01,\n         -4.8627e-02,  1.5185e-01, -7.0344e-03,  1.5445e-01,  1.0584e-01,\n          1.1746e-01,  1.2251e-01],\n        [ 1.7001e-01,  1.4909e-01, -6.8450e-02, -1.3585e-01,  9.9068e-02,\n         -3.6529e-02, -5.2756e-02,  1.0298e-01,  1.5967e-01, -1.3856e-01,\n         -1.4252e-01, -1.1276e-01, -2.5557e-02,  9.0226e-02, -1.6688e-01,\n         -2.0706e-02,  1.5659e-01,  2.2894e-03,  5.3786e-02, -7.3757e-07,\n          1.4550e-01, -6.5327e-02, -4.5788e-04,  3.6361e-02, -1.0841e-01,\n         -8.0751e-02,  1.3549e-02, -2.8663e-02, -9.7599e-02, -3.8060e-02,\n          1.3293e-01, -1.3717e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0713, -0.1966,  0.1987,  0.0815,  0.2485, -0.0170,  0.0176,  0.0673],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0706,  0.2462,  0.1220,  0.0331,  0.1478,  0.2141,  0.0500, -0.0059,\n         -0.2240,  0.0795, -0.0281, -0.0751,  0.1318,  0.2261,  0.0397, -0.1953],\n        [ 0.1992, -0.1859, -0.1904, -0.2062, -0.1984, -0.1330,  0.1776, -0.0085,\n          0.0553, -0.0657, -0.0872,  0.1826,  0.1702, -0.2468, -0.0900, -0.1821],\n        [-0.1991, -0.0792, -0.1751,  0.2062, -0.0190, -0.0978,  0.0140,  0.1519,\n         -0.0967,  0.1641, -0.0673,  0.1294, -0.0435, -0.1428, -0.0979, -0.1089],\n        [ 0.0649,  0.1384,  0.1988,  0.0811, -0.2481,  0.0271,  0.2038, -0.0162,\n         -0.0696,  0.0584,  0.1355,  0.0355,  0.2128,  0.0553, -0.1355,  0.0459],\n        [ 0.1983, -0.1938, -0.1392, -0.1751, -0.0259, -0.1029,  0.2414, -0.1778,\n          0.0421, -0.0263,  0.0590,  0.1655,  0.1456, -0.1912, -0.0116, -0.0777],\n        [ 0.1708,  0.2389, -0.2228,  0.1637, -0.2197,  0.1090,  0.1216, -0.1119,\n         -0.2259, -0.0616,  0.1115, -0.1568, -0.0712,  0.1699,  0.2040,  0.0762],\n        [-0.2173,  0.1047, -0.1239,  0.0957, -0.2089, -0.1207, -0.1809, -0.0475,\n          0.0961, -0.0004,  0.1459,  0.0259, -0.0769,  0.2162, -0.0246,  0.1096],\n        [ 0.0764, -0.0349,  0.1845, -0.0084,  0.0362,  0.0858, -0.1548, -0.1739,\n          0.0037, -0.1523, -0.1623,  0.0105,  0.1530,  0.0604, -0.0128, -0.0522]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2970], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1971,  0.0524,  0.0005,  0.3385, -0.3497, -0.2893, -0.0965, -0.2125]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0708, -0.0543,  0.2200, -0.0115, -0.2670, -0.1947,  0.1980,  0.0406],\n        [ 0.2836,  0.3182, -0.2209, -0.3477, -0.0460,  0.2508,  0.3340, -0.1519],\n        [ 0.2652,  0.2562, -0.1001,  0.2614, -0.2087,  0.0529, -0.1998,  0.3512],\n        [ 0.2049, -0.1198,  0.0855,  0.1361, -0.3466, -0.1295, -0.2141,  0.2968],\n        [ 0.0662,  0.2548, -0.1244, -0.3092, -0.2175, -0.0435, -0.1939, -0.2937],\n        [ 0.1243, -0.3273, -0.0682, -0.1307,  0.0576,  0.2783, -0.0974,  0.2384],\n        [ 0.0177, -0.3399, -0.1019,  0.3389,  0.0764,  0.2038,  0.2220,  0.2852],\n        [-0.2436, -0.0450,  0.2635,  0.3164,  0.3404,  0.0364, -0.3397, -0.1575],\n        [ 0.1636,  0.0449,  0.0004, -0.2496, -0.2218,  0.1381,  0.0432, -0.2287],\n        [-0.0061,  0.1340,  0.2959,  0.1970,  0.2443,  0.1276, -0.0104, -0.0392],\n        [-0.2446,  0.0999, -0.3413,  0.0217, -0.0438, -0.1083, -0.1717, -0.3261],\n        [-0.1001,  0.2703,  0.1842,  0.2235, -0.2912, -0.2735,  0.2795, -0.2791],\n        [-0.1417, -0.2924,  0.1393,  0.2800,  0.3086, -0.0670,  0.0421, -0.1245],\n        [ 0.1801,  0.2063,  0.3289, -0.2011,  0.1608,  0.0940, -0.3342,  0.0649],\n        [-0.2943,  0.3419,  0.1846,  0.1020, -0.1386, -0.1256, -0.0362,  0.3347],\n        [ 0.1453,  0.2558, -0.0502,  0.2195, -0.3041,  0.1215, -0.2970, -0.3056],\n        [ 0.0303, -0.2059, -0.1510,  0.0135, -0.3011,  0.2352, -0.2078, -0.0818],\n        [ 0.2947,  0.0394, -0.0046,  0.3113,  0.1153, -0.0926, -0.1300, -0.0570],\n        [-0.2774, -0.2157, -0.0825, -0.2448,  0.0889,  0.1010,  0.2798, -0.1144],\n        [ 0.1459,  0.2125, -0.3270,  0.0496, -0.0835, -0.3211, -0.1059,  0.2000],\n        [-0.0985,  0.0411,  0.1104,  0.1764,  0.2073,  0.1758,  0.1508,  0.2562],\n        [ 0.1195,  0.1167,  0.2280, -0.2120,  0.3449,  0.1411, -0.2748, -0.1187],\n        [-0.1475,  0.0692, -0.0571, -0.1156,  0.2013, -0.0261, -0.1295,  0.0734],\n        [ 0.1021,  0.2749,  0.0762, -0.0312,  0.3377, -0.2505,  0.0942, -0.1674],\n        [ 0.0994, -0.3359, -0.3376, -0.0400, -0.2236,  0.1113, -0.0411, -0.3235],\n        [-0.3419, -0.0246, -0.0346,  0.1786,  0.3265,  0.0887,  0.2156,  0.2680],\n        [-0.2861,  0.2117,  0.3481, -0.1691,  0.2003,  0.1315,  0.2405, -0.0058],\n        [-0.2151, -0.0719, -0.2856, -0.1767, -0.3260,  0.1931, -0.3288,  0.0028],\n        [-0.1515,  0.2168, -0.1593,  0.0666, -0.0609,  0.1275,  0.2054, -0.2449],\n        [ 0.1130,  0.3123, -0.1605,  0.0909, -0.2399,  0.3149,  0.0492,  0.1291],\n        [-0.2154, -0.2191, -0.2637,  0.2047, -0.2044, -0.0391,  0.1599, -0.1708],\n        [ 0.2871,  0.2437, -0.3346, -0.1482,  0.0187,  0.3204, -0.3105,  0.0239]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2566,  0.3493,  0.3226, -0.1083, -0.1045, -0.0248,  0.1249,  0.3449,\n         0.1499,  0.1257,  0.0143, -0.2473,  0.1351,  0.0709,  0.0357, -0.0397,\n        -0.2901,  0.2556, -0.2632,  0.3423, -0.3009, -0.3037, -0.3252, -0.1539,\n         0.0190, -0.1421,  0.0981, -0.0542, -0.3104, -0.0015, -0.0931, -0.1093],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.0953e-01, -2.6909e-02,  5.8590e-02, -1.2572e-01,  7.0090e-02,\n         -7.9293e-02, -4.0232e-02, -1.5427e-01, -1.2412e-01,  1.1567e-01,\n         -6.6073e-02, -8.8868e-02,  9.4858e-02, -1.8936e-02,  6.9239e-02,\n          1.5630e-01, -7.8978e-02,  3.3809e-02, -9.2306e-02, -1.6451e-01,\n         -7.1730e-02,  1.7527e-01,  1.3820e-03,  1.0580e-01, -8.4571e-02,\n          3.9819e-02, -1.2398e-01, -1.4249e-02, -6.8427e-02,  3.0602e-02,\n         -1.4397e-01,  8.9275e-02],\n        [-4.0961e-02,  1.2662e-01, -1.3500e-01,  1.0515e-01, -2.5216e-02,\n         -5.7587e-03,  1.2296e-01,  1.6676e-01, -1.7256e-01, -4.7854e-02,\n          7.6496e-03,  1.0141e-01, -1.0490e-01,  1.2853e-01,  1.4266e-01,\n         -1.7391e-01,  1.2222e-01, -5.2689e-02, -4.3150e-02,  3.9694e-02,\n         -9.9904e-02,  7.1038e-02,  1.1554e-01,  1.7443e-01,  1.6903e-01,\n          1.9307e-02, -1.4342e-01, -8.8368e-02,  4.9371e-02,  1.0773e-01,\n         -8.6562e-02, -7.5080e-02],\n        [ 1.1276e-01, -1.0895e-01,  9.7019e-02,  7.6786e-02, -6.5425e-03,\n         -1.3678e-01, -1.6694e-01, -6.3120e-02, -1.0568e-01,  1.2387e-01,\n         -5.3008e-02,  1.6114e-01,  1.0218e-01,  7.3255e-02,  1.1528e-01,\n         -1.6182e-01, -5.4570e-02,  1.4202e-01,  1.6492e-01, -1.1905e-02,\n          9.4022e-02, -3.8324e-02,  1.6529e-01, -4.0250e-02, -1.1373e-02,\n         -1.2090e-01,  3.8354e-02, -1.5375e-01, -7.0431e-02,  4.5207e-02,\n         -1.3024e-01,  1.6473e-01],\n        [-6.1839e-02,  9.0030e-02,  2.0036e-02, -3.2605e-02,  6.6618e-02,\n         -1.5083e-01, -1.4489e-01, -1.7017e-01, -1.2192e-01, -1.3364e-01,\n          8.5192e-02,  1.6589e-01, -1.0161e-01, -1.7382e-01,  1.2910e-01,\n          1.4257e-02, -3.7078e-02, -1.1623e-02,  1.8990e-02, -1.2678e-01,\n         -3.7714e-02, -6.2908e-02, -1.5232e-02, -7.6205e-02,  1.4367e-01,\n         -9.5401e-02,  1.2461e-01, -1.6261e-01, -4.2570e-02,  1.3079e-02,\n         -9.6707e-03, -1.0758e-01],\n        [ 9.9781e-02,  3.9226e-02, -1.8624e-02,  1.3436e-01,  1.3484e-01,\n         -7.2352e-02,  6.5159e-02, -1.4063e-01, -8.5086e-02, -2.4991e-02,\n         -1.2371e-02,  1.5787e-01,  3.7001e-02,  6.8077e-02, -7.6546e-02,\n          6.9467e-02,  1.5581e-01, -8.6144e-02,  1.0063e-01, -1.3160e-01,\n          1.3873e-01, -1.0663e-01,  1.1358e-01, -1.3301e-01,  8.2628e-02,\n         -5.8999e-02, -7.8892e-02, -4.2782e-02,  1.0313e-02,  3.4413e-02,\n          7.6417e-02, -7.7434e-03],\n        [ 6.2846e-02,  1.6048e-01,  3.2008e-02, -1.0127e-01, -3.6109e-03,\n         -1.0574e-01, -1.5157e-01,  8.4484e-02, -8.5713e-02, -1.1593e-01,\n          6.8059e-02,  1.3730e-03,  1.5591e-01, -1.0799e-01, -9.9412e-02,\n         -1.0330e-01, -8.5049e-02, -1.1510e-01,  3.6209e-02,  1.7505e-01,\n         -1.0175e-01, -1.3592e-01, -2.0794e-02,  1.5488e-01,  1.4697e-01,\n          1.0647e-02, -8.6129e-02, -1.4364e-02, -3.4448e-02,  1.6370e-01,\n          1.3564e-01, -1.2767e-01],\n        [ 7.6162e-02, -1.2681e-01,  6.7616e-02, -6.5235e-02,  2.4576e-02,\n          1.0775e-01,  1.3551e-01,  1.2480e-01, -1.7359e-01,  1.4053e-01,\n          7.8062e-02,  1.0320e-01, -6.6022e-02,  1.1489e-01, -1.0064e-01,\n          8.3208e-02,  3.5259e-02, -1.3501e-02,  1.2423e-01,  8.2409e-02,\n         -1.7451e-01, -9.5233e-02, -1.5277e-01,  1.3006e-01, -1.5816e-02,\n          4.4083e-03,  1.7306e-01, -7.1310e-02,  1.2967e-01,  4.9470e-02,\n         -1.2725e-01,  4.7240e-02],\n        [ 1.9324e-02, -9.1072e-02,  8.3334e-02,  8.7281e-02,  7.5516e-02,\n         -1.2511e-01, -1.3692e-01,  9.2941e-02, -8.1326e-02,  6.4711e-02,\n         -7.8299e-02, -1.5372e-01, -1.6500e-01, -7.2536e-02, -5.6938e-02,\n         -1.6984e-01,  1.7335e-01, -1.2001e-01,  7.5654e-02, -6.2098e-02,\n          5.6919e-02, -1.6910e-01,  1.0846e-01,  9.8155e-02,  4.8549e-02,\n          7.7256e-02,  7.7337e-03,  1.7478e-01, -1.1315e-01,  1.7828e-02,\n         -7.7289e-02, -3.5786e-02],\n        [ 1.4104e-01,  1.7597e-01,  5.3519e-03, -4.8908e-02,  9.2966e-02,\n          1.1471e-01, -5.9542e-02,  2.1957e-02,  5.0503e-02, -1.4720e-01,\n          1.3144e-01,  1.3561e-01, -1.0943e-01,  6.1580e-02,  1.0817e-01,\n          6.2631e-02, -1.3276e-01, -8.8534e-02,  1.6848e-01,  9.9370e-02,\n          7.2126e-02,  4.2357e-02,  1.5592e-01, -8.5581e-02, -5.4800e-02,\n          3.3088e-02, -6.2336e-02,  6.5112e-02,  7.1871e-02, -4.8893e-02,\n         -9.1601e-02,  2.6889e-02],\n        [ 6.8977e-02,  6.4467e-02, -4.3259e-02, -5.1179e-02, -1.7151e-01,\n          3.9510e-03,  4.9500e-02,  5.5933e-02, -1.0536e-01, -3.0075e-02,\n          3.4139e-02, -1.0858e-01, -7.1916e-02,  1.0930e-01, -1.4764e-01,\n          1.6041e-01, -1.1170e-01,  1.3301e-01,  1.4210e-01,  1.1994e-01,\n         -1.8292e-02, -6.5367e-02,  1.5519e-01, -1.4963e-01, -3.9527e-02,\n         -3.7057e-02, -1.1151e-02, -2.3821e-02,  9.7645e-02, -9.8757e-02,\n         -1.6570e-01, -1.5630e-01],\n        [ 5.8150e-02,  7.7260e-02, -1.4070e-01,  1.6122e-02, -3.8802e-02,\n          8.3775e-02,  1.6129e-02,  5.0560e-02,  1.1929e-01,  1.4521e-01,\n         -5.2336e-02,  5.8511e-02,  9.3451e-03, -1.2787e-01,  1.5215e-01,\n         -4.0847e-02, -1.4350e-01, -5.0434e-02,  1.4811e-01, -1.3860e-01,\n         -6.1005e-02,  4.4725e-02,  7.3759e-02,  1.2973e-01,  5.7787e-02,\n          5.6054e-02,  4.0601e-02, -3.0480e-02,  1.3083e-01, -1.4748e-01,\n          9.3062e-02,  1.6944e-02],\n        [-1.7053e-01,  4.4332e-03, -1.4460e-01, -1.6753e-02,  2.1915e-02,\n         -1.1087e-01, -6.6921e-02, -1.7323e-01,  7.2708e-02, -8.6232e-02,\n          5.1068e-02, -4.8314e-02,  3.8335e-02, -1.8614e-02, -5.7568e-02,\n          6.5659e-02, -1.4640e-01,  3.4565e-02, -1.0416e-01,  1.6038e-01,\n          4.9740e-02, -7.3215e-02,  5.1996e-02,  9.5213e-02,  1.5101e-01,\n          1.1754e-01,  1.0525e-01,  5.2434e-02,  5.6240e-02,  1.2367e-01,\n         -1.7214e-01,  4.2451e-02],\n        [-1.0376e-01,  7.5038e-03,  1.3159e-01,  1.4372e-01,  7.6560e-02,\n          9.0649e-03,  1.6110e-01,  1.5634e-01, -3.8718e-02, -9.8537e-02,\n          1.4801e-01, -9.4940e-02, -1.6937e-01,  1.3344e-01, -5.2866e-02,\n         -1.2726e-01, -1.6445e-01, -1.7411e-01,  3.6091e-02,  5.9217e-02,\n         -9.0735e-02,  1.2415e-01,  1.1873e-01,  1.6012e-01,  1.7359e-01,\n          2.7280e-02,  1.7286e-01,  1.0024e-01, -1.7309e-01, -1.7511e-01,\n         -1.9957e-02, -2.8687e-02],\n        [-7.4322e-02, -7.0474e-02,  3.3559e-02, -8.1476e-02,  7.9874e-02,\n         -1.6887e-01,  1.1016e-01,  1.4482e-01,  1.1790e-01,  1.0434e-01,\n         -9.8440e-02,  6.0743e-02, -6.1740e-03,  1.3136e-01,  4.2205e-02,\n         -4.9908e-02, -9.3374e-02, -3.3675e-02, -1.7061e-01,  1.1160e-01,\n          6.7181e-02, -1.1192e-01, -1.2055e-01,  7.8226e-03, -5.7212e-02,\n         -1.4017e-01, -4.5821e-02,  4.7754e-03,  5.2243e-03,  1.2099e-01,\n          3.8886e-02,  1.3112e-01],\n        [ 7.3931e-02,  1.7602e-01,  1.2048e-01, -1.5418e-01, -2.4663e-02,\n          1.3273e-01,  5.9797e-02,  3.1136e-02, -1.0400e-01, -1.6328e-01,\n         -8.5027e-02,  8.8905e-02,  5.0865e-02,  1.1228e-01, -1.4441e-01,\n         -1.2676e-01, -1.2657e-02,  2.4918e-02,  1.6137e-01, -9.7656e-02,\n         -3.5820e-02, -6.6875e-02, -4.1667e-02, -3.8618e-02, -1.0350e-01,\n         -4.8627e-02,  1.5185e-01, -7.0344e-03,  1.5445e-01,  1.0584e-01,\n          1.1746e-01,  1.2251e-01],\n        [ 1.7001e-01,  1.4909e-01, -6.8450e-02, -1.3585e-01,  9.9068e-02,\n         -3.6529e-02, -5.2756e-02,  1.0298e-01,  1.5967e-01, -1.3856e-01,\n         -1.4252e-01, -1.1276e-01, -2.5557e-02,  9.0226e-02, -1.6688e-01,\n         -2.0706e-02,  1.5659e-01,  2.2894e-03,  5.3786e-02, -7.3757e-07,\n          1.4550e-01, -6.5327e-02, -4.5788e-04,  3.6361e-02, -1.0841e-01,\n         -8.0751e-02,  1.3549e-02, -2.8663e-02, -9.7599e-02, -3.8060e-02,\n          1.3293e-01, -1.3717e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0766,  0.1532,  0.1475,  0.0283,  0.1536, -0.1574,  0.0650, -0.1650,\n        -0.0303, -0.0250,  0.0097, -0.0386, -0.1102, -0.0303, -0.0777,  0.0714],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0706,  0.2462,  0.1220,  0.0331,  0.1478,  0.2141,  0.0500, -0.0059,\n         -0.2240,  0.0795, -0.0281, -0.0751,  0.1318,  0.2261,  0.0397, -0.1953],\n        [ 0.1992, -0.1859, -0.1904, -0.2062, -0.1984, -0.1330,  0.1776, -0.0085,\n          0.0553, -0.0657, -0.0872,  0.1826,  0.1702, -0.2468, -0.0900, -0.1821],\n        [-0.1991, -0.0792, -0.1751,  0.2062, -0.0190, -0.0978,  0.0140,  0.1519,\n         -0.0967,  0.1641, -0.0673,  0.1294, -0.0435, -0.1428, -0.0979, -0.1089],\n        [ 0.0649,  0.1384,  0.1988,  0.0811, -0.2481,  0.0271,  0.2038, -0.0162,\n         -0.0696,  0.0584,  0.1355,  0.0355,  0.2128,  0.0553, -0.1355,  0.0459],\n        [ 0.1983, -0.1938, -0.1392, -0.1751, -0.0259, -0.1029,  0.2414, -0.1778,\n          0.0421, -0.0263,  0.0590,  0.1655,  0.1456, -0.1912, -0.0116, -0.0777],\n        [ 0.1708,  0.2389, -0.2228,  0.1637, -0.2197,  0.1090,  0.1216, -0.1119,\n         -0.2259, -0.0616,  0.1115, -0.1568, -0.0712,  0.1699,  0.2040,  0.0762],\n        [-0.2173,  0.1047, -0.1239,  0.0957, -0.2089, -0.1207, -0.1809, -0.0475,\n          0.0961, -0.0004,  0.1459,  0.0259, -0.0769,  0.2162, -0.0246,  0.1096],\n        [ 0.0764, -0.0349,  0.1845, -0.0084,  0.0362,  0.0858, -0.1548, -0.1739,\n          0.0037, -0.1523, -0.1623,  0.0105,  0.1530,  0.0604, -0.0128, -0.0522]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0713, -0.1966,  0.1987,  0.0815,  0.2485, -0.0170,  0.0176,  0.0673],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1971,  0.0524,  0.0005,  0.3385, -0.3497, -0.2893, -0.0965, -0.2125]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2970], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x105e33e80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x303dee560>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s145120000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s145120000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}