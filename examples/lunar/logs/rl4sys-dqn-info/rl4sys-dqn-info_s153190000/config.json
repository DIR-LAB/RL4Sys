{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.15,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s153190000"
    },
    "q_lr":	0.003,
    "seed":	153190000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x72b324da45d0>":	{
            "_act_dim":	4,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.15,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 5.6656e-02, -2.5621e-01,  2.0310e-01,  1.8873e-04, -8.1007e-02,\n         2.5713e-01,  1.1184e-01, -2.2602e-01,  2.5845e-01, -8.1426e-02,\n        -2.7486e-01, -2.0897e-02, -1.1830e-01, -6.7379e-02, -5.8103e-02,\n         2.8858e-01,  1.2204e-01,  2.3172e-01, -2.5932e-01, -1.7627e-01,\n        -3.5842e-02, -2.3175e-01, -2.7611e-02,  7.5739e-02,  1.6304e-01,\n         3.3388e-01,  2.9028e-01,  3.1384e-01, -1.3899e-01,  1.9051e-01,\n        -1.9216e-01,  3.9544e-02], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.0239e-01,  4.8001e-02,  5.5733e-02,  1.7118e-01,  2.7304e-01,\n          2.5082e-01, -7.5891e-02,  5.6566e-02],\n        [ 2.0925e-01,  2.8530e-01, -2.0931e-02, -3.4229e-01, -1.5540e-01,\n         -3.1239e-01, -3.2547e-01,  2.5730e-02],\n        [ 2.2032e-01, -6.6840e-02,  1.2293e-01,  1.9470e-01,  2.0524e-01,\n         -1.4066e-01,  2.5933e-01,  1.8601e-03],\n        [-1.3964e-01,  1.2694e-01,  2.6148e-01, -1.9680e-01, -2.8012e-02,\n         -1.6493e-01,  3.4040e-01, -1.0341e-01],\n        [ 1.2562e-01, -2.5365e-01,  3.0998e-02, -1.3913e-01, -1.8646e-01,\n          1.1308e-01,  1.0069e-01,  1.5288e-01],\n        [ 3.5335e-01, -2.6374e-01,  7.7744e-02,  2.8405e-01,  2.1918e-01,\n         -1.5593e-01,  3.3334e-01,  3.4068e-01],\n        [-8.4057e-02,  2.7521e-01,  3.7211e-02,  2.2442e-01,  5.9713e-02,\n          7.0674e-02,  1.9696e-01,  2.1455e-01],\n        [ 3.5109e-01, -8.0250e-02, -2.7386e-02,  1.6704e-01,  4.6972e-02,\n          2.0791e-01, -2.6832e-01, -1.0810e-01],\n        [-6.1665e-02, -1.3444e-01, -2.7556e-01, -1.4919e-01,  2.6803e-03,\n         -2.4095e-01,  3.1912e-01,  3.1890e-01],\n        [ 1.6284e-01,  2.1540e-01, -8.0799e-02, -1.1634e-01,  2.2150e-01,\n          3.4717e-01, -3.1105e-01, -2.5648e-01],\n        [ 1.0557e-01, -1.7173e-01,  3.4598e-01,  9.1037e-02, -2.9667e-01,\n          1.4149e-01,  8.6106e-05, -3.1256e-01],\n        [ 3.1497e-02, -3.1282e-01, -5.3711e-02,  1.9476e-01, -2.7716e-02,\n         -2.4644e-02, -8.3480e-02,  3.3667e-01],\n        [-9.8506e-02,  1.0260e-01, -1.7078e-01,  2.1236e-01, -4.4722e-02,\n         -3.2984e-01, -1.9712e-01,  6.9833e-02],\n        [-3.4428e-02, -1.3073e-01,  8.4262e-02, -1.1067e-01, -2.3761e-01,\n         -2.0621e-01, -3.2227e-02, -7.3517e-02],\n        [-1.3837e-02,  9.4458e-02,  3.1391e-01,  2.6133e-01, -2.3642e-01,\n         -1.7984e-01,  1.7688e-01,  3.3201e-01],\n        [ 6.5722e-02, -3.5723e-02,  1.3811e-01,  7.2784e-02, -1.8768e-03,\n         -2.0155e-01,  2.8191e-01, -7.9749e-02],\n        [-3.5987e-02,  1.6519e-01, -1.2796e-01, -1.8105e-01,  1.6211e-01,\n         -8.9251e-02, -2.6405e-01, -3.0622e-01],\n        [ 2.9173e-01,  7.9714e-02,  1.9878e-01, -2.6583e-01, -3.1264e-02,\n         -3.0801e-01, -2.6741e-01,  2.0911e-01],\n        [ 8.6756e-02,  1.9527e-01, -3.0845e-01, -3.0825e-01,  1.0556e-01,\n          2.7380e-01,  1.3197e-01, -1.9914e-01],\n        [ 2.6273e-02,  3.5237e-01, -1.4147e-01, -3.0172e-01,  1.5428e-01,\n         -1.8120e-01, -3.1302e-01,  2.7317e-01],\n        [-8.3396e-02,  1.4462e-01,  1.2190e-01,  3.3217e-01, -2.2180e-02,\n          3.5271e-01, -2.0609e-01, -3.3788e-01],\n        [-6.6514e-02, -6.3542e-02, -1.7036e-01, -1.3152e-01,  3.0381e-01,\n          4.9847e-02, -3.0058e-02, -1.5130e-02],\n        [ 6.7932e-02,  4.8913e-02, -2.1324e-02, -1.1283e-01, -2.7442e-01,\n         -2.2247e-01, -7.9722e-02,  3.3361e-01],\n        [-2.1253e-01, -7.6148e-02, -3.4716e-02, -2.0019e-01,  1.5930e-01,\n          9.6067e-02,  3.2209e-01,  2.6194e-01],\n        [ 1.8727e-01,  2.2264e-01,  1.4441e-01,  2.7638e-01, -1.6334e-01,\n         -3.2860e-01, -2.1337e-01, -2.3713e-01],\n        [-7.9374e-02, -2.3655e-01,  4.6138e-02,  3.4181e-01, -7.2724e-02,\n         -1.0149e-01, -1.6005e-01,  3.3834e-01],\n        [-1.4138e-01,  3.0818e-01, -5.9834e-02,  1.8406e-01,  2.7522e-01,\n         -1.9822e-01,  2.7740e-01,  2.1553e-01],\n        [ 4.5047e-02,  1.2901e-01,  1.8898e-01, -1.3089e-01, -2.7277e-01,\n         -1.3600e-01, -2.9531e-01,  3.5687e-02],\n        [ 1.6566e-01, -3.2278e-01, -8.5914e-02, -3.3846e-01,  1.0633e-01,\n          2.5091e-01,  1.8752e-01, -5.3548e-03],\n        [-3.0209e-01, -1.8384e-01, -9.3478e-02, -1.3678e-01, -2.5873e-02,\n         -1.8744e-01,  2.4381e-01, -3.0003e-01],\n        [ 3.3456e-02,  2.6065e-01, -6.6238e-02, -3.9464e-02,  2.0901e-01,\n         -6.5824e-02,  1.0572e-02,  3.1399e-01],\n        [-3.2315e-01,  4.9940e-02,  3.4171e-01, -3.3340e-01, -2.1118e-01,\n         -9.0858e-02,  9.2650e-02,  8.1628e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0628,  0.1215,  0.1565,  0.0468,  0.0902,  0.0435,  0.0649, -0.0763,\n         0.0892,  0.1763,  0.0806,  0.0836,  0.0841, -0.0233, -0.1588,  0.0495],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-9.5718e-02, -1.5874e-01,  1.1379e-01, -8.8518e-02,  1.4705e-01,\n         -1.3921e-01, -9.6822e-02, -1.7482e-01, -1.4467e-01,  1.2631e-01,\n          3.1991e-02,  9.7704e-02, -3.5007e-02,  1.0569e-01,  1.2520e-01,\n          6.6992e-02,  8.6808e-02, -3.1070e-02,  1.4243e-02, -1.2631e-01,\n         -9.3092e-02,  1.0847e-01,  9.1417e-02, -9.4775e-02,  1.3639e-01,\n         -2.8462e-02,  1.3576e-01,  1.4620e-01, -3.4806e-02,  9.8016e-02,\n          1.2877e-01, -3.0834e-02],\n        [ 3.7486e-02,  1.5605e-02,  1.4576e-01, -1.0559e-01, -6.5306e-02,\n         -1.0690e-02,  1.4513e-02,  3.4281e-02, -5.1680e-02,  8.1601e-02,\n          1.6541e-01, -1.3371e-01,  4.5322e-02, -1.8295e-02, -4.0371e-02,\n         -3.4000e-02,  1.5672e-01, -7.6651e-02,  6.4270e-02, -3.6872e-02,\n         -9.4931e-02, -4.7712e-03,  1.3030e-02,  1.0095e-01,  2.0405e-04,\n          4.3224e-02,  9.0513e-02, -1.5608e-01,  1.4645e-01,  6.7021e-02,\n         -1.1519e-01,  6.4110e-02],\n        [-1.5613e-01, -5.5449e-02, -1.2223e-01, -1.2949e-01, -9.2346e-02,\n         -5.3372e-02, -1.6642e-01,  1.2851e-01,  1.6482e-01,  1.3308e-02,\n         -1.6991e-01, -1.7108e-02, -9.5977e-02, -9.0647e-02,  7.7638e-02,\n         -1.0756e-02, -5.3505e-02,  1.7561e-01,  1.0207e-01,  1.1957e-01,\n         -1.7392e-01,  1.4423e-01,  1.6104e-01,  9.7237e-02, -1.3045e-01,\n          1.4458e-01, -7.6160e-02, -1.7101e-01,  3.4528e-02,  1.3534e-01,\n         -1.0176e-01,  9.5549e-02],\n        [-5.8219e-02, -7.8346e-02, -9.2041e-03,  1.1159e-01,  9.8372e-02,\n          8.2841e-02, -5.6566e-02, -1.0418e-02,  6.8820e-03, -5.2219e-02,\n          3.3518e-02, -1.7129e-01, -8.0097e-03,  1.7548e-01,  1.6304e-01,\n          8.3881e-02, -6.1471e-02, -1.4844e-01, -1.0014e-01,  1.7224e-01,\n          5.0641e-03,  1.3428e-01, -7.3066e-02, -1.0671e-01, -1.0939e-01,\n         -1.4177e-01, -7.5454e-02, -1.0072e-01,  3.8192e-02, -1.6798e-01,\n         -1.3124e-01, -3.8750e-02],\n        [ 9.4132e-02, -1.0006e-01,  9.7279e-02,  1.3448e-01, -1.3021e-01,\n         -1.4950e-01,  1.2760e-01,  5.6402e-02, -1.7036e-01,  2.0681e-02,\n          4.9566e-02,  9.9387e-02, -8.4625e-02, -6.7561e-02, -1.0681e-01,\n         -4.5254e-02, -1.7476e-01,  6.1502e-03, -9.1860e-02,  1.1579e-01,\n         -3.4028e-02, -1.1396e-01, -4.1092e-02, -7.7960e-02,  2.8122e-02,\n         -4.0887e-02,  2.3267e-02, -2.8768e-02,  1.0049e-01, -1.4974e-01,\n          1.2762e-01, -1.5415e-01],\n        [ 2.8296e-02, -5.9585e-02, -7.9528e-02,  7.3133e-02, -4.4340e-02,\n          7.4174e-02,  5.9781e-02,  2.0420e-04,  1.3770e-01, -1.5529e-02,\n          5.8349e-02,  1.6734e-01,  2.6498e-02, -3.0903e-02,  2.3189e-02,\n         -4.6036e-02, -1.5850e-01, -1.1619e-01,  1.1481e-01,  1.3094e-01,\n          7.4217e-02,  1.0403e-01,  9.8629e-02, -8.7848e-02, -7.9129e-02,\n         -2.0444e-02, -7.8237e-02,  6.5373e-02,  1.3043e-01,  1.7290e-01,\n         -6.5669e-02,  1.2922e-01],\n        [ 8.8003e-02, -4.8114e-02,  1.3618e-02, -2.0628e-03, -6.3065e-02,\n         -6.5680e-02, -1.0129e-02, -1.0744e-02, -8.2608e-02, -3.5070e-02,\n          1.1669e-01,  6.2600e-02, -9.8988e-02, -8.6817e-02,  1.9045e-02,\n         -9.6990e-02, -2.4977e-02,  6.6559e-02,  1.7032e-02,  1.5964e-01,\n         -1.0044e-01, -7.4797e-02,  1.8864e-02,  7.8713e-02,  3.9920e-02,\n         -2.7796e-02, -8.2115e-02,  1.2969e-01,  7.1792e-02, -7.7667e-02,\n          1.0525e-01, -2.3132e-02],\n        [ 1.0648e-01,  1.2627e-01, -6.2068e-02, -1.0499e-01,  2.3639e-02,\n          3.2396e-02, -4.8429e-02,  2.5522e-02,  4.3706e-02, -1.4116e-01,\n         -2.8187e-02, -1.4953e-01,  1.3434e-01,  8.7410e-02,  7.6954e-02,\n          6.3579e-02, -9.2505e-02, -1.3376e-01, -2.0151e-02, -1.6208e-01,\n          1.5313e-01, -1.0442e-01,  1.6899e-01, -1.6364e-01, -1.6890e-01,\n          1.4500e-01, -1.7121e-01,  1.7157e-01, -3.6061e-03, -8.8023e-02,\n         -1.0139e-01, -1.6856e-01],\n        [-8.7937e-02,  4.2247e-02, -5.9637e-02, -1.7308e-01,  1.2912e-01,\n          1.7505e-01,  8.5085e-02, -3.7813e-02,  1.7382e-01, -1.7387e-01,\n          5.9823e-02,  6.1191e-02, -1.4007e-01,  5.5415e-02, -1.3539e-01,\n          1.6950e-01, -2.4082e-02, -7.0238e-02,  6.5380e-02, -1.6689e-01,\n         -1.0381e-01, -8.5165e-03,  1.3411e-02,  4.2535e-02, -1.6730e-01,\n          1.5750e-01, -1.4477e-01, -1.2851e-01, -1.0403e-01, -6.2816e-02,\n          3.8425e-03,  3.4005e-02],\n        [ 1.4403e-01,  9.7932e-02,  1.6743e-01, -1.4037e-01,  1.6928e-01,\n         -4.6086e-02,  9.8160e-02,  2.8112e-02,  1.1693e-02,  1.6641e-02,\n          1.5911e-01,  1.1207e-01, -6.9315e-02, -1.1431e-01,  1.0554e-01,\n         -4.1282e-02,  1.5685e-01, -1.3776e-01,  1.5775e-01, -1.5558e-01,\n          4.2453e-02, -6.1415e-03, -1.4804e-01, -4.5959e-02,  4.2062e-02,\n          1.2987e-01,  1.2505e-01, -9.6893e-02,  1.3974e-01,  6.1446e-02,\n         -9.7847e-02,  1.1149e-01],\n        [ 1.5798e-01, -5.0067e-02, -1.1296e-01, -1.3433e-01, -6.2529e-02,\n          5.6792e-02,  1.3558e-03,  1.1351e-01, -2.0736e-02,  1.7037e-01,\n          7.0362e-04,  1.0183e-01,  1.6360e-01, -1.3709e-01,  1.3587e-01,\n         -8.6420e-02, -4.6958e-02,  5.6169e-02, -1.3092e-01,  1.4846e-01,\n         -4.3875e-02, -8.1812e-02,  9.3333e-03,  1.4253e-01,  1.6714e-01,\n         -1.0074e-01,  5.3208e-02, -6.4609e-02,  4.0283e-02,  6.4273e-02,\n         -6.8117e-02,  8.0910e-03],\n        [-5.2968e-02,  1.4144e-01, -3.9717e-02,  3.7295e-02, -4.4976e-02,\n          8.8086e-02,  1.0004e-01, -3.5441e-02, -1.6690e-01, -2.1967e-02,\n         -3.6571e-03, -1.0800e-01,  1.5134e-01, -7.5133e-02, -1.3625e-01,\n         -2.9522e-02,  1.6049e-01,  1.0862e-01,  1.0390e-01,  4.0173e-02,\n          7.5166e-03, -9.6744e-02, -4.4847e-02,  8.1937e-02, -1.0289e-01,\n         -6.1996e-02,  1.7376e-01, -5.3731e-02, -3.3438e-02, -8.2527e-02,\n          1.8744e-02, -1.6414e-01],\n        [ 2.3021e-02, -5.0876e-02,  3.6679e-02,  1.4470e-01,  1.6713e-01,\n          1.5211e-01, -1.3837e-01,  6.9884e-02, -8.7108e-02,  3.6068e-02,\n          1.6972e-01,  4.6271e-02, -7.4514e-02,  7.5305e-02,  1.4068e-02,\n          2.7581e-02,  1.6590e-01,  3.3474e-03, -1.6921e-01, -1.2046e-01,\n         -1.5643e-02,  2.3350e-03,  1.6535e-01,  1.7338e-01,  1.1195e-01,\n          4.2463e-02,  2.2813e-02,  5.7443e-02, -1.6704e-01, -6.4136e-02,\n          7.5945e-02, -5.2208e-02],\n        [ 5.3436e-02,  7.6593e-02, -1.7181e-01,  7.9595e-02,  1.4779e-01,\n         -1.1334e-01, -1.6106e-01,  3.7733e-02, -3.8246e-02,  5.2151e-02,\n          1.1756e-01, -7.9664e-02,  9.0222e-02, -2.4816e-02,  1.7336e-01,\n          5.5032e-02, -6.5865e-02, -1.6010e-01,  3.3076e-02, -9.1372e-02,\n          7.7084e-02,  1.1440e-01,  1.0733e-01,  2.8053e-03, -1.4082e-01,\n          7.4260e-02,  5.0102e-02, -1.5055e-01, -1.2723e-01,  8.7703e-02,\n         -7.1273e-03, -1.5379e-01],\n        [ 7.2342e-02, -1.7602e-01,  5.3973e-02,  1.4193e-01, -1.6838e-01,\n          5.2665e-02,  5.2284e-02,  2.6843e-02,  5.7777e-02, -7.0628e-02,\n          1.6604e-01,  1.6510e-02,  1.4114e-01, -2.8837e-02, -4.0160e-02,\n         -4.8151e-02,  1.4151e-01,  8.9319e-03, -1.3577e-01,  5.7191e-02,\n          1.6622e-01,  1.8689e-02, -1.2240e-01, -1.2459e-01, -8.5338e-02,\n          1.6498e-01,  5.6712e-02,  1.0291e-01, -1.6759e-01,  3.0778e-02,\n         -1.8232e-02, -5.8634e-02],\n        [ 4.4675e-02, -1.5212e-01,  1.2624e-01, -2.9159e-02,  1.6176e-02,\n         -7.2130e-02,  1.3030e-01,  3.9850e-05,  9.7213e-02,  3.2598e-03,\n         -6.3709e-02,  1.4672e-02,  1.6707e-01,  1.2841e-01,  3.8936e-02,\n          1.6600e-01,  1.1975e-01,  7.0828e-02,  1.1359e-01,  4.7235e-02,\n         -7.6874e-02, -1.5749e-01,  4.0353e-02,  3.6621e-02, -6.7451e-02,\n          1.6171e-01, -9.9663e-02,  4.6919e-02, -6.8140e-02, -1.2115e-01,\n         -7.5335e-02, -1.1749e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1202, -0.0179, -0.1295,  0.1902,  0.1638, -0.2389,  0.0874,  0.1401],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2199, -0.0436, -0.2274, -0.1435,  0.0293, -0.0245,  0.0452, -0.2004,\n          0.1345, -0.1266, -0.1820, -0.1915, -0.1219, -0.2359, -0.2217, -0.1862],\n        [-0.0204,  0.0433, -0.0562,  0.1714, -0.1694,  0.2445,  0.1195, -0.1795,\n          0.1557,  0.1459, -0.1131, -0.2341, -0.1254, -0.1946,  0.0198,  0.0993],\n        [ 0.1390,  0.2031,  0.1727,  0.0245,  0.1313,  0.0219, -0.1646,  0.0027,\n         -0.2226,  0.2333, -0.1769, -0.0991,  0.0584,  0.1950,  0.1586, -0.0494],\n        [-0.1332,  0.1051, -0.0947,  0.0052, -0.1611, -0.1827,  0.0049, -0.0263,\n          0.1152, -0.1880, -0.0293, -0.1856, -0.1241,  0.2013, -0.2491, -0.2341],\n        [-0.1579, -0.2223, -0.0273,  0.1368, -0.1213,  0.0446, -0.2236,  0.0045,\n         -0.1424, -0.1574, -0.0054, -0.1855, -0.0316, -0.0533,  0.1082,  0.2436],\n        [-0.2460, -0.1820, -0.0026, -0.0532, -0.0387,  0.1074, -0.2158, -0.2280,\n         -0.0539,  0.0707,  0.2436,  0.1861, -0.0377,  0.0194,  0.1174, -0.1151],\n        [ 0.1099,  0.2142,  0.1502,  0.0516, -0.0668, -0.2489,  0.1474, -0.0960,\n          0.0237, -0.0886, -0.1635, -0.2371,  0.0963, -0.0206, -0.0472,  0.0155],\n        [ 0.0336, -0.1585, -0.1968, -0.0495, -0.2044,  0.0413, -0.1382,  0.0712,\n          0.1446,  0.0007,  0.0131,  0.0069, -0.0718, -0.1691, -0.0824, -0.0776]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0985,  0.3327, -0.2508,  0.2110], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1278, -0.3105, -0.2761, -0.1855,  0.2573, -0.0713,  0.2773, -0.2819],\n        [ 0.2740, -0.0646,  0.2694,  0.2609,  0.1455, -0.3224, -0.1934, -0.2870],\n        [-0.0199,  0.2402, -0.3462, -0.2496, -0.0902,  0.0452,  0.2899, -0.3262],\n        [ 0.1058,  0.0013,  0.1703, -0.1898, -0.0450, -0.0765,  0.0554, -0.0050]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.003\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#RMSprop.zero_grad",
                    "defaults":	{
                        "alpha":	0.99,
                        "capturable":	false,
                        "centered":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "momentum":	0,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "alpha":	0.99,
                            "capturable":	false,
                            "centered":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "momentum":	0,
                            "params":	[
                                "Parameter containing:\ntensor([[-2.0239e-01,  4.8001e-02,  5.5733e-02,  1.7118e-01,  2.7304e-01,\n          2.5082e-01, -7.5891e-02,  5.6566e-02],\n        [ 2.0925e-01,  2.8530e-01, -2.0931e-02, -3.4229e-01, -1.5540e-01,\n         -3.1239e-01, -3.2547e-01,  2.5730e-02],\n        [ 2.2032e-01, -6.6840e-02,  1.2293e-01,  1.9470e-01,  2.0524e-01,\n         -1.4066e-01,  2.5933e-01,  1.8601e-03],\n        [-1.3964e-01,  1.2694e-01,  2.6148e-01, -1.9680e-01, -2.8012e-02,\n         -1.6493e-01,  3.4040e-01, -1.0341e-01],\n        [ 1.2562e-01, -2.5365e-01,  3.0998e-02, -1.3913e-01, -1.8646e-01,\n          1.1308e-01,  1.0069e-01,  1.5288e-01],\n        [ 3.5335e-01, -2.6374e-01,  7.7744e-02,  2.8405e-01,  2.1918e-01,\n         -1.5593e-01,  3.3334e-01,  3.4068e-01],\n        [-8.4057e-02,  2.7521e-01,  3.7211e-02,  2.2442e-01,  5.9713e-02,\n          7.0674e-02,  1.9696e-01,  2.1455e-01],\n        [ 3.5109e-01, -8.0250e-02, -2.7386e-02,  1.6704e-01,  4.6972e-02,\n          2.0791e-01, -2.6832e-01, -1.0810e-01],\n        [-6.1665e-02, -1.3444e-01, -2.7556e-01, -1.4919e-01,  2.6803e-03,\n         -2.4095e-01,  3.1912e-01,  3.1890e-01],\n        [ 1.6284e-01,  2.1540e-01, -8.0799e-02, -1.1634e-01,  2.2150e-01,\n          3.4717e-01, -3.1105e-01, -2.5648e-01],\n        [ 1.0557e-01, -1.7173e-01,  3.4598e-01,  9.1037e-02, -2.9667e-01,\n          1.4149e-01,  8.6106e-05, -3.1256e-01],\n        [ 3.1497e-02, -3.1282e-01, -5.3711e-02,  1.9476e-01, -2.7716e-02,\n         -2.4644e-02, -8.3480e-02,  3.3667e-01],\n        [-9.8506e-02,  1.0260e-01, -1.7078e-01,  2.1236e-01, -4.4722e-02,\n         -3.2984e-01, -1.9712e-01,  6.9833e-02],\n        [-3.4428e-02, -1.3073e-01,  8.4262e-02, -1.1067e-01, -2.3761e-01,\n         -2.0621e-01, -3.2227e-02, -7.3517e-02],\n        [-1.3837e-02,  9.4458e-02,  3.1391e-01,  2.6133e-01, -2.3642e-01,\n         -1.7984e-01,  1.7688e-01,  3.3201e-01],\n        [ 6.5722e-02, -3.5723e-02,  1.3811e-01,  7.2784e-02, -1.8768e-03,\n         -2.0155e-01,  2.8191e-01, -7.9749e-02],\n        [-3.5987e-02,  1.6519e-01, -1.2796e-01, -1.8105e-01,  1.6211e-01,\n         -8.9251e-02, -2.6405e-01, -3.0622e-01],\n        [ 2.9173e-01,  7.9714e-02,  1.9878e-01, -2.6583e-01, -3.1264e-02,\n         -3.0801e-01, -2.6741e-01,  2.0911e-01],\n        [ 8.6756e-02,  1.9527e-01, -3.0845e-01, -3.0825e-01,  1.0556e-01,\n          2.7380e-01,  1.3197e-01, -1.9914e-01],\n        [ 2.6273e-02,  3.5237e-01, -1.4147e-01, -3.0172e-01,  1.5428e-01,\n         -1.8120e-01, -3.1302e-01,  2.7317e-01],\n        [-8.3396e-02,  1.4462e-01,  1.2190e-01,  3.3217e-01, -2.2180e-02,\n          3.5271e-01, -2.0609e-01, -3.3788e-01],\n        [-6.6514e-02, -6.3542e-02, -1.7036e-01, -1.3152e-01,  3.0381e-01,\n          4.9847e-02, -3.0058e-02, -1.5130e-02],\n        [ 6.7932e-02,  4.8913e-02, -2.1324e-02, -1.1283e-01, -2.7442e-01,\n         -2.2247e-01, -7.9722e-02,  3.3361e-01],\n        [-2.1253e-01, -7.6148e-02, -3.4716e-02, -2.0019e-01,  1.5930e-01,\n          9.6067e-02,  3.2209e-01,  2.6194e-01],\n        [ 1.8727e-01,  2.2264e-01,  1.4441e-01,  2.7638e-01, -1.6334e-01,\n         -3.2860e-01, -2.1337e-01, -2.3713e-01],\n        [-7.9374e-02, -2.3655e-01,  4.6138e-02,  3.4181e-01, -7.2724e-02,\n         -1.0149e-01, -1.6005e-01,  3.3834e-01],\n        [-1.4138e-01,  3.0818e-01, -5.9834e-02,  1.8406e-01,  2.7522e-01,\n         -1.9822e-01,  2.7740e-01,  2.1553e-01],\n        [ 4.5047e-02,  1.2901e-01,  1.8898e-01, -1.3089e-01, -2.7277e-01,\n         -1.3600e-01, -2.9531e-01,  3.5687e-02],\n        [ 1.6566e-01, -3.2278e-01, -8.5914e-02, -3.3846e-01,  1.0633e-01,\n          2.5091e-01,  1.8752e-01, -5.3548e-03],\n        [-3.0209e-01, -1.8384e-01, -9.3478e-02, -1.3678e-01, -2.5873e-02,\n         -1.8744e-01,  2.4381e-01, -3.0003e-01],\n        [ 3.3456e-02,  2.6065e-01, -6.6238e-02, -3.9464e-02,  2.0901e-01,\n         -6.5824e-02,  1.0572e-02,  3.1399e-01],\n        [-3.2315e-01,  4.9940e-02,  3.4171e-01, -3.3340e-01, -2.1118e-01,\n         -9.0858e-02,  9.2650e-02,  8.1628e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 5.6656e-02, -2.5621e-01,  2.0310e-01,  1.8873e-04, -8.1007e-02,\n         2.5713e-01,  1.1184e-01, -2.2602e-01,  2.5845e-01, -8.1426e-02,\n        -2.7486e-01, -2.0897e-02, -1.1830e-01, -6.7379e-02, -5.8103e-02,\n         2.8858e-01,  1.2204e-01,  2.3172e-01, -2.5932e-01, -1.7627e-01,\n        -3.5842e-02, -2.3175e-01, -2.7611e-02,  7.5739e-02,  1.6304e-01,\n         3.3388e-01,  2.9028e-01,  3.1384e-01, -1.3899e-01,  1.9051e-01,\n        -1.9216e-01,  3.9544e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[-9.5718e-02, -1.5874e-01,  1.1379e-01, -8.8518e-02,  1.4705e-01,\n         -1.3921e-01, -9.6822e-02, -1.7482e-01, -1.4467e-01,  1.2631e-01,\n          3.1991e-02,  9.7704e-02, -3.5007e-02,  1.0569e-01,  1.2520e-01,\n          6.6992e-02,  8.6808e-02, -3.1070e-02,  1.4243e-02, -1.2631e-01,\n         -9.3092e-02,  1.0847e-01,  9.1417e-02, -9.4775e-02,  1.3639e-01,\n         -2.8462e-02,  1.3576e-01,  1.4620e-01, -3.4806e-02,  9.8016e-02,\n          1.2877e-01, -3.0834e-02],\n        [ 3.7486e-02,  1.5605e-02,  1.4576e-01, -1.0559e-01, -6.5306e-02,\n         -1.0690e-02,  1.4513e-02,  3.4281e-02, -5.1680e-02,  8.1601e-02,\n          1.6541e-01, -1.3371e-01,  4.5322e-02, -1.8295e-02, -4.0371e-02,\n         -3.4000e-02,  1.5672e-01, -7.6651e-02,  6.4270e-02, -3.6872e-02,\n         -9.4931e-02, -4.7712e-03,  1.3030e-02,  1.0095e-01,  2.0405e-04,\n          4.3224e-02,  9.0513e-02, -1.5608e-01,  1.4645e-01,  6.7021e-02,\n         -1.1519e-01,  6.4110e-02],\n        [-1.5613e-01, -5.5449e-02, -1.2223e-01, -1.2949e-01, -9.2346e-02,\n         -5.3372e-02, -1.6642e-01,  1.2851e-01,  1.6482e-01,  1.3308e-02,\n         -1.6991e-01, -1.7108e-02, -9.5977e-02, -9.0647e-02,  7.7638e-02,\n         -1.0756e-02, -5.3505e-02,  1.7561e-01,  1.0207e-01,  1.1957e-01,\n         -1.7392e-01,  1.4423e-01,  1.6104e-01,  9.7237e-02, -1.3045e-01,\n          1.4458e-01, -7.6160e-02, -1.7101e-01,  3.4528e-02,  1.3534e-01,\n         -1.0176e-01,  9.5549e-02],\n        [-5.8219e-02, -7.8346e-02, -9.2041e-03,  1.1159e-01,  9.8372e-02,\n          8.2841e-02, -5.6566e-02, -1.0418e-02,  6.8820e-03, -5.2219e-02,\n          3.3518e-02, -1.7129e-01, -8.0097e-03,  1.7548e-01,  1.6304e-01,\n          8.3881e-02, -6.1471e-02, -1.4844e-01, -1.0014e-01,  1.7224e-01,\n          5.0641e-03,  1.3428e-01, -7.3066e-02, -1.0671e-01, -1.0939e-01,\n         -1.4177e-01, -7.5454e-02, -1.0072e-01,  3.8192e-02, -1.6798e-01,\n         -1.3124e-01, -3.8750e-02],\n        [ 9.4132e-02, -1.0006e-01,  9.7279e-02,  1.3448e-01, -1.3021e-01,\n         -1.4950e-01,  1.2760e-01,  5.6402e-02, -1.7036e-01,  2.0681e-02,\n          4.9566e-02,  9.9387e-02, -8.4625e-02, -6.7561e-02, -1.0681e-01,\n         -4.5254e-02, -1.7476e-01,  6.1502e-03, -9.1860e-02,  1.1579e-01,\n         -3.4028e-02, -1.1396e-01, -4.1092e-02, -7.7960e-02,  2.8122e-02,\n         -4.0887e-02,  2.3267e-02, -2.8768e-02,  1.0049e-01, -1.4974e-01,\n          1.2762e-01, -1.5415e-01],\n        [ 2.8296e-02, -5.9585e-02, -7.9528e-02,  7.3133e-02, -4.4340e-02,\n          7.4174e-02,  5.9781e-02,  2.0420e-04,  1.3770e-01, -1.5529e-02,\n          5.8349e-02,  1.6734e-01,  2.6498e-02, -3.0903e-02,  2.3189e-02,\n         -4.6036e-02, -1.5850e-01, -1.1619e-01,  1.1481e-01,  1.3094e-01,\n          7.4217e-02,  1.0403e-01,  9.8629e-02, -8.7848e-02, -7.9129e-02,\n         -2.0444e-02, -7.8237e-02,  6.5373e-02,  1.3043e-01,  1.7290e-01,\n         -6.5669e-02,  1.2922e-01],\n        [ 8.8003e-02, -4.8114e-02,  1.3618e-02, -2.0628e-03, -6.3065e-02,\n         -6.5680e-02, -1.0129e-02, -1.0744e-02, -8.2608e-02, -3.5070e-02,\n          1.1669e-01,  6.2600e-02, -9.8988e-02, -8.6817e-02,  1.9045e-02,\n         -9.6990e-02, -2.4977e-02,  6.6559e-02,  1.7032e-02,  1.5964e-01,\n         -1.0044e-01, -7.4797e-02,  1.8864e-02,  7.8713e-02,  3.9920e-02,\n         -2.7796e-02, -8.2115e-02,  1.2969e-01,  7.1792e-02, -7.7667e-02,\n          1.0525e-01, -2.3132e-02],\n        [ 1.0648e-01,  1.2627e-01, -6.2068e-02, -1.0499e-01,  2.3639e-02,\n          3.2396e-02, -4.8429e-02,  2.5522e-02,  4.3706e-02, -1.4116e-01,\n         -2.8187e-02, -1.4953e-01,  1.3434e-01,  8.7410e-02,  7.6954e-02,\n          6.3579e-02, -9.2505e-02, -1.3376e-01, -2.0151e-02, -1.6208e-01,\n          1.5313e-01, -1.0442e-01,  1.6899e-01, -1.6364e-01, -1.6890e-01,\n          1.4500e-01, -1.7121e-01,  1.7157e-01, -3.6061e-03, -8.8023e-02,\n         -1.0139e-01, -1.6856e-01],\n        [-8.7937e-02,  4.2247e-02, -5.9637e-02, -1.7308e-01,  1.2912e-01,\n          1.7505e-01,  8.5085e-02, -3.7813e-02,  1.7382e-01, -1.7387e-01,\n          5.9823e-02,  6.1191e-02, -1.4007e-01,  5.5415e-02, -1.3539e-01,\n          1.6950e-01, -2.4082e-02, -7.0238e-02,  6.5380e-02, -1.6689e-01,\n         -1.0381e-01, -8.5165e-03,  1.3411e-02,  4.2535e-02, -1.6730e-01,\n          1.5750e-01, -1.4477e-01, -1.2851e-01, -1.0403e-01, -6.2816e-02,\n          3.8425e-03,  3.4005e-02],\n        [ 1.4403e-01,  9.7932e-02,  1.6743e-01, -1.4037e-01,  1.6928e-01,\n         -4.6086e-02,  9.8160e-02,  2.8112e-02,  1.1693e-02,  1.6641e-02,\n          1.5911e-01,  1.1207e-01, -6.9315e-02, -1.1431e-01,  1.0554e-01,\n         -4.1282e-02,  1.5685e-01, -1.3776e-01,  1.5775e-01, -1.5558e-01,\n          4.2453e-02, -6.1415e-03, -1.4804e-01, -4.5959e-02,  4.2062e-02,\n          1.2987e-01,  1.2505e-01, -9.6893e-02,  1.3974e-01,  6.1446e-02,\n         -9.7847e-02,  1.1149e-01],\n        [ 1.5798e-01, -5.0067e-02, -1.1296e-01, -1.3433e-01, -6.2529e-02,\n          5.6792e-02,  1.3558e-03,  1.1351e-01, -2.0736e-02,  1.7037e-01,\n          7.0362e-04,  1.0183e-01,  1.6360e-01, -1.3709e-01,  1.3587e-01,\n         -8.6420e-02, -4.6958e-02,  5.6169e-02, -1.3092e-01,  1.4846e-01,\n         -4.3875e-02, -8.1812e-02,  9.3333e-03,  1.4253e-01,  1.6714e-01,\n         -1.0074e-01,  5.3208e-02, -6.4609e-02,  4.0283e-02,  6.4273e-02,\n         -6.8117e-02,  8.0910e-03],\n        [-5.2968e-02,  1.4144e-01, -3.9717e-02,  3.7295e-02, -4.4976e-02,\n          8.8086e-02,  1.0004e-01, -3.5441e-02, -1.6690e-01, -2.1967e-02,\n         -3.6571e-03, -1.0800e-01,  1.5134e-01, -7.5133e-02, -1.3625e-01,\n         -2.9522e-02,  1.6049e-01,  1.0862e-01,  1.0390e-01,  4.0173e-02,\n          7.5166e-03, -9.6744e-02, -4.4847e-02,  8.1937e-02, -1.0289e-01,\n         -6.1996e-02,  1.7376e-01, -5.3731e-02, -3.3438e-02, -8.2527e-02,\n          1.8744e-02, -1.6414e-01],\n        [ 2.3021e-02, -5.0876e-02,  3.6679e-02,  1.4470e-01,  1.6713e-01,\n          1.5211e-01, -1.3837e-01,  6.9884e-02, -8.7108e-02,  3.6068e-02,\n          1.6972e-01,  4.6271e-02, -7.4514e-02,  7.5305e-02,  1.4068e-02,\n          2.7581e-02,  1.6590e-01,  3.3474e-03, -1.6921e-01, -1.2046e-01,\n         -1.5643e-02,  2.3350e-03,  1.6535e-01,  1.7338e-01,  1.1195e-01,\n          4.2463e-02,  2.2813e-02,  5.7443e-02, -1.6704e-01, -6.4136e-02,\n          7.5945e-02, -5.2208e-02],\n        [ 5.3436e-02,  7.6593e-02, -1.7181e-01,  7.9595e-02,  1.4779e-01,\n         -1.1334e-01, -1.6106e-01,  3.7733e-02, -3.8246e-02,  5.2151e-02,\n          1.1756e-01, -7.9664e-02,  9.0222e-02, -2.4816e-02,  1.7336e-01,\n          5.5032e-02, -6.5865e-02, -1.6010e-01,  3.3076e-02, -9.1372e-02,\n          7.7084e-02,  1.1440e-01,  1.0733e-01,  2.8053e-03, -1.4082e-01,\n          7.4260e-02,  5.0102e-02, -1.5055e-01, -1.2723e-01,  8.7703e-02,\n         -7.1273e-03, -1.5379e-01],\n        [ 7.2342e-02, -1.7602e-01,  5.3973e-02,  1.4193e-01, -1.6838e-01,\n          5.2665e-02,  5.2284e-02,  2.6843e-02,  5.7777e-02, -7.0628e-02,\n          1.6604e-01,  1.6510e-02,  1.4114e-01, -2.8837e-02, -4.0160e-02,\n         -4.8151e-02,  1.4151e-01,  8.9319e-03, -1.3577e-01,  5.7191e-02,\n          1.6622e-01,  1.8689e-02, -1.2240e-01, -1.2459e-01, -8.5338e-02,\n          1.6498e-01,  5.6712e-02,  1.0291e-01, -1.6759e-01,  3.0778e-02,\n         -1.8232e-02, -5.8634e-02],\n        [ 4.4675e-02, -1.5212e-01,  1.2624e-01, -2.9159e-02,  1.6176e-02,\n         -7.2130e-02,  1.3030e-01,  3.9850e-05,  9.7213e-02,  3.2598e-03,\n         -6.3709e-02,  1.4672e-02,  1.6707e-01,  1.2841e-01,  3.8936e-02,\n          1.6600e-01,  1.1975e-01,  7.0828e-02,  1.1359e-01,  4.7235e-02,\n         -7.6874e-02, -1.5749e-01,  4.0353e-02,  3.6621e-02, -6.7451e-02,\n          1.6171e-01, -9.9663e-02,  4.6919e-02, -6.8140e-02, -1.2115e-01,\n         -7.5335e-02, -1.1749e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0628,  0.1215,  0.1565,  0.0468,  0.0902,  0.0435,  0.0649, -0.0763,\n         0.0892,  0.1763,  0.0806,  0.0836,  0.0841, -0.0233, -0.1588,  0.0495],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2199, -0.0436, -0.2274, -0.1435,  0.0293, -0.0245,  0.0452, -0.2004,\n          0.1345, -0.1266, -0.1820, -0.1915, -0.1219, -0.2359, -0.2217, -0.1862],\n        [-0.0204,  0.0433, -0.0562,  0.1714, -0.1694,  0.2445,  0.1195, -0.1795,\n          0.1557,  0.1459, -0.1131, -0.2341, -0.1254, -0.1946,  0.0198,  0.0993],\n        [ 0.1390,  0.2031,  0.1727,  0.0245,  0.1313,  0.0219, -0.1646,  0.0027,\n         -0.2226,  0.2333, -0.1769, -0.0991,  0.0584,  0.1950,  0.1586, -0.0494],\n        [-0.1332,  0.1051, -0.0947,  0.0052, -0.1611, -0.1827,  0.0049, -0.0263,\n          0.1152, -0.1880, -0.0293, -0.1856, -0.1241,  0.2013, -0.2491, -0.2341],\n        [-0.1579, -0.2223, -0.0273,  0.1368, -0.1213,  0.0446, -0.2236,  0.0045,\n         -0.1424, -0.1574, -0.0054, -0.1855, -0.0316, -0.0533,  0.1082,  0.2436],\n        [-0.2460, -0.1820, -0.0026, -0.0532, -0.0387,  0.1074, -0.2158, -0.2280,\n         -0.0539,  0.0707,  0.2436,  0.1861, -0.0377,  0.0194,  0.1174, -0.1151],\n        [ 0.1099,  0.2142,  0.1502,  0.0516, -0.0668, -0.2489,  0.1474, -0.0960,\n          0.0237, -0.0886, -0.1635, -0.2371,  0.0963, -0.0206, -0.0472,  0.0155],\n        [ 0.0336, -0.1585, -0.1968, -0.0495, -0.2044,  0.0413, -0.1382,  0.0712,\n          0.1446,  0.0007,  0.0131,  0.0069, -0.0718, -0.1691, -0.0824, -0.0776]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1202, -0.0179, -0.1295,  0.1902,  0.1638, -0.2389,  0.0874,  0.1401],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1278, -0.3105, -0.2761, -0.1855,  0.2573, -0.0713,  0.2773, -0.2819],\n        [ 0.2740, -0.0646,  0.2694,  0.2609,  0.1455, -0.3224, -0.1934, -0.2870],\n        [-0.0199,  0.2402, -0.3462, -0.2496, -0.0902,  0.0452,  0.2899, -0.3262],\n        [ 0.1058,  0.0013,  0.1703, -0.1898, -0.0450, -0.0765,  0.0554, -0.0050]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0985,  0.3327, -0.2508,  0.2110], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.stale_replay_buffer.StaleReplayBuffer object at 0x72b324da4c90>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 5.6656e-02, -2.5621e-01,  2.0310e-01,  1.8873e-04, -8.1007e-02,\n         2.5713e-01,  1.1184e-01, -2.2602e-01,  2.5845e-01, -8.1426e-02,\n        -2.7486e-01, -2.0897e-02, -1.1830e-01, -6.7379e-02, -5.8103e-02,\n         2.8858e-01,  1.2204e-01,  2.3172e-01, -2.5932e-01, -1.7627e-01,\n        -3.5842e-02, -2.3175e-01, -2.7611e-02,  7.5739e-02,  1.6304e-01,\n         3.3388e-01,  2.9028e-01,  3.1384e-01, -1.3899e-01,  1.9051e-01,\n        -1.9216e-01,  3.9544e-02], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.0239e-01,  4.8001e-02,  5.5733e-02,  1.7118e-01,  2.7304e-01,\n          2.5082e-01, -7.5891e-02,  5.6566e-02],\n        [ 2.0925e-01,  2.8530e-01, -2.0931e-02, -3.4229e-01, -1.5540e-01,\n         -3.1239e-01, -3.2547e-01,  2.5730e-02],\n        [ 2.2032e-01, -6.6840e-02,  1.2293e-01,  1.9470e-01,  2.0524e-01,\n         -1.4066e-01,  2.5933e-01,  1.8601e-03],\n        [-1.3964e-01,  1.2694e-01,  2.6148e-01, -1.9680e-01, -2.8012e-02,\n         -1.6493e-01,  3.4040e-01, -1.0341e-01],\n        [ 1.2562e-01, -2.5365e-01,  3.0998e-02, -1.3913e-01, -1.8646e-01,\n          1.1308e-01,  1.0069e-01,  1.5288e-01],\n        [ 3.5335e-01, -2.6374e-01,  7.7744e-02,  2.8405e-01,  2.1918e-01,\n         -1.5593e-01,  3.3334e-01,  3.4068e-01],\n        [-8.4057e-02,  2.7521e-01,  3.7211e-02,  2.2442e-01,  5.9713e-02,\n          7.0674e-02,  1.9696e-01,  2.1455e-01],\n        [ 3.5109e-01, -8.0250e-02, -2.7386e-02,  1.6704e-01,  4.6972e-02,\n          2.0791e-01, -2.6832e-01, -1.0810e-01],\n        [-6.1665e-02, -1.3444e-01, -2.7556e-01, -1.4919e-01,  2.6803e-03,\n         -2.4095e-01,  3.1912e-01,  3.1890e-01],\n        [ 1.6284e-01,  2.1540e-01, -8.0799e-02, -1.1634e-01,  2.2150e-01,\n          3.4717e-01, -3.1105e-01, -2.5648e-01],\n        [ 1.0557e-01, -1.7173e-01,  3.4598e-01,  9.1037e-02, -2.9667e-01,\n          1.4149e-01,  8.6106e-05, -3.1256e-01],\n        [ 3.1497e-02, -3.1282e-01, -5.3711e-02,  1.9476e-01, -2.7716e-02,\n         -2.4644e-02, -8.3480e-02,  3.3667e-01],\n        [-9.8506e-02,  1.0260e-01, -1.7078e-01,  2.1236e-01, -4.4722e-02,\n         -3.2984e-01, -1.9712e-01,  6.9833e-02],\n        [-3.4428e-02, -1.3073e-01,  8.4262e-02, -1.1067e-01, -2.3761e-01,\n         -2.0621e-01, -3.2227e-02, -7.3517e-02],\n        [-1.3837e-02,  9.4458e-02,  3.1391e-01,  2.6133e-01, -2.3642e-01,\n         -1.7984e-01,  1.7688e-01,  3.3201e-01],\n        [ 6.5722e-02, -3.5723e-02,  1.3811e-01,  7.2784e-02, -1.8768e-03,\n         -2.0155e-01,  2.8191e-01, -7.9749e-02],\n        [-3.5987e-02,  1.6519e-01, -1.2796e-01, -1.8105e-01,  1.6211e-01,\n         -8.9251e-02, -2.6405e-01, -3.0622e-01],\n        [ 2.9173e-01,  7.9714e-02,  1.9878e-01, -2.6583e-01, -3.1264e-02,\n         -3.0801e-01, -2.6741e-01,  2.0911e-01],\n        [ 8.6756e-02,  1.9527e-01, -3.0845e-01, -3.0825e-01,  1.0556e-01,\n          2.7380e-01,  1.3197e-01, -1.9914e-01],\n        [ 2.6273e-02,  3.5237e-01, -1.4147e-01, -3.0172e-01,  1.5428e-01,\n         -1.8120e-01, -3.1302e-01,  2.7317e-01],\n        [-8.3396e-02,  1.4462e-01,  1.2190e-01,  3.3217e-01, -2.2180e-02,\n          3.5271e-01, -2.0609e-01, -3.3788e-01],\n        [-6.6514e-02, -6.3542e-02, -1.7036e-01, -1.3152e-01,  3.0381e-01,\n          4.9847e-02, -3.0058e-02, -1.5130e-02],\n        [ 6.7932e-02,  4.8913e-02, -2.1324e-02, -1.1283e-01, -2.7442e-01,\n         -2.2247e-01, -7.9722e-02,  3.3361e-01],\n        [-2.1253e-01, -7.6148e-02, -3.4716e-02, -2.0019e-01,  1.5930e-01,\n          9.6067e-02,  3.2209e-01,  2.6194e-01],\n        [ 1.8727e-01,  2.2264e-01,  1.4441e-01,  2.7638e-01, -1.6334e-01,\n         -3.2860e-01, -2.1337e-01, -2.3713e-01],\n        [-7.9374e-02, -2.3655e-01,  4.6138e-02,  3.4181e-01, -7.2724e-02,\n         -1.0149e-01, -1.6005e-01,  3.3834e-01],\n        [-1.4138e-01,  3.0818e-01, -5.9834e-02,  1.8406e-01,  2.7522e-01,\n         -1.9822e-01,  2.7740e-01,  2.1553e-01],\n        [ 4.5047e-02,  1.2901e-01,  1.8898e-01, -1.3089e-01, -2.7277e-01,\n         -1.3600e-01, -2.9531e-01,  3.5687e-02],\n        [ 1.6566e-01, -3.2278e-01, -8.5914e-02, -3.3846e-01,  1.0633e-01,\n          2.5091e-01,  1.8752e-01, -5.3548e-03],\n        [-3.0209e-01, -1.8384e-01, -9.3478e-02, -1.3678e-01, -2.5873e-02,\n         -1.8744e-01,  2.4381e-01, -3.0003e-01],\n        [ 3.3456e-02,  2.6065e-01, -6.6238e-02, -3.9464e-02,  2.0901e-01,\n         -6.5824e-02,  1.0572e-02,  3.1399e-01],\n        [-3.2315e-01,  4.9940e-02,  3.4171e-01, -3.3340e-01, -2.1118e-01,\n         -9.0858e-02,  9.2650e-02,  8.1628e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0628,  0.1215,  0.1565,  0.0468,  0.0902,  0.0435,  0.0649, -0.0763,\n         0.0892,  0.1763,  0.0806,  0.0836,  0.0841, -0.0233, -0.1588,  0.0495],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-9.5718e-02, -1.5874e-01,  1.1379e-01, -8.8518e-02,  1.4705e-01,\n         -1.3921e-01, -9.6822e-02, -1.7482e-01, -1.4467e-01,  1.2631e-01,\n          3.1991e-02,  9.7704e-02, -3.5007e-02,  1.0569e-01,  1.2520e-01,\n          6.6992e-02,  8.6808e-02, -3.1070e-02,  1.4243e-02, -1.2631e-01,\n         -9.3092e-02,  1.0847e-01,  9.1417e-02, -9.4775e-02,  1.3639e-01,\n         -2.8462e-02,  1.3576e-01,  1.4620e-01, -3.4806e-02,  9.8016e-02,\n          1.2877e-01, -3.0834e-02],\n        [ 3.7486e-02,  1.5605e-02,  1.4576e-01, -1.0559e-01, -6.5306e-02,\n         -1.0690e-02,  1.4513e-02,  3.4281e-02, -5.1680e-02,  8.1601e-02,\n          1.6541e-01, -1.3371e-01,  4.5322e-02, -1.8295e-02, -4.0371e-02,\n         -3.4000e-02,  1.5672e-01, -7.6651e-02,  6.4270e-02, -3.6872e-02,\n         -9.4931e-02, -4.7712e-03,  1.3030e-02,  1.0095e-01,  2.0405e-04,\n          4.3224e-02,  9.0513e-02, -1.5608e-01,  1.4645e-01,  6.7021e-02,\n         -1.1519e-01,  6.4110e-02],\n        [-1.5613e-01, -5.5449e-02, -1.2223e-01, -1.2949e-01, -9.2346e-02,\n         -5.3372e-02, -1.6642e-01,  1.2851e-01,  1.6482e-01,  1.3308e-02,\n         -1.6991e-01, -1.7108e-02, -9.5977e-02, -9.0647e-02,  7.7638e-02,\n         -1.0756e-02, -5.3505e-02,  1.7561e-01,  1.0207e-01,  1.1957e-01,\n         -1.7392e-01,  1.4423e-01,  1.6104e-01,  9.7237e-02, -1.3045e-01,\n          1.4458e-01, -7.6160e-02, -1.7101e-01,  3.4528e-02,  1.3534e-01,\n         -1.0176e-01,  9.5549e-02],\n        [-5.8219e-02, -7.8346e-02, -9.2041e-03,  1.1159e-01,  9.8372e-02,\n          8.2841e-02, -5.6566e-02, -1.0418e-02,  6.8820e-03, -5.2219e-02,\n          3.3518e-02, -1.7129e-01, -8.0097e-03,  1.7548e-01,  1.6304e-01,\n          8.3881e-02, -6.1471e-02, -1.4844e-01, -1.0014e-01,  1.7224e-01,\n          5.0641e-03,  1.3428e-01, -7.3066e-02, -1.0671e-01, -1.0939e-01,\n         -1.4177e-01, -7.5454e-02, -1.0072e-01,  3.8192e-02, -1.6798e-01,\n         -1.3124e-01, -3.8750e-02],\n        [ 9.4132e-02, -1.0006e-01,  9.7279e-02,  1.3448e-01, -1.3021e-01,\n         -1.4950e-01,  1.2760e-01,  5.6402e-02, -1.7036e-01,  2.0681e-02,\n          4.9566e-02,  9.9387e-02, -8.4625e-02, -6.7561e-02, -1.0681e-01,\n         -4.5254e-02, -1.7476e-01,  6.1502e-03, -9.1860e-02,  1.1579e-01,\n         -3.4028e-02, -1.1396e-01, -4.1092e-02, -7.7960e-02,  2.8122e-02,\n         -4.0887e-02,  2.3267e-02, -2.8768e-02,  1.0049e-01, -1.4974e-01,\n          1.2762e-01, -1.5415e-01],\n        [ 2.8296e-02, -5.9585e-02, -7.9528e-02,  7.3133e-02, -4.4340e-02,\n          7.4174e-02,  5.9781e-02,  2.0420e-04,  1.3770e-01, -1.5529e-02,\n          5.8349e-02,  1.6734e-01,  2.6498e-02, -3.0903e-02,  2.3189e-02,\n         -4.6036e-02, -1.5850e-01, -1.1619e-01,  1.1481e-01,  1.3094e-01,\n          7.4217e-02,  1.0403e-01,  9.8629e-02, -8.7848e-02, -7.9129e-02,\n         -2.0444e-02, -7.8237e-02,  6.5373e-02,  1.3043e-01,  1.7290e-01,\n         -6.5669e-02,  1.2922e-01],\n        [ 8.8003e-02, -4.8114e-02,  1.3618e-02, -2.0628e-03, -6.3065e-02,\n         -6.5680e-02, -1.0129e-02, -1.0744e-02, -8.2608e-02, -3.5070e-02,\n          1.1669e-01,  6.2600e-02, -9.8988e-02, -8.6817e-02,  1.9045e-02,\n         -9.6990e-02, -2.4977e-02,  6.6559e-02,  1.7032e-02,  1.5964e-01,\n         -1.0044e-01, -7.4797e-02,  1.8864e-02,  7.8713e-02,  3.9920e-02,\n         -2.7796e-02, -8.2115e-02,  1.2969e-01,  7.1792e-02, -7.7667e-02,\n          1.0525e-01, -2.3132e-02],\n        [ 1.0648e-01,  1.2627e-01, -6.2068e-02, -1.0499e-01,  2.3639e-02,\n          3.2396e-02, -4.8429e-02,  2.5522e-02,  4.3706e-02, -1.4116e-01,\n         -2.8187e-02, -1.4953e-01,  1.3434e-01,  8.7410e-02,  7.6954e-02,\n          6.3579e-02, -9.2505e-02, -1.3376e-01, -2.0151e-02, -1.6208e-01,\n          1.5313e-01, -1.0442e-01,  1.6899e-01, -1.6364e-01, -1.6890e-01,\n          1.4500e-01, -1.7121e-01,  1.7157e-01, -3.6061e-03, -8.8023e-02,\n         -1.0139e-01, -1.6856e-01],\n        [-8.7937e-02,  4.2247e-02, -5.9637e-02, -1.7308e-01,  1.2912e-01,\n          1.7505e-01,  8.5085e-02, -3.7813e-02,  1.7382e-01, -1.7387e-01,\n          5.9823e-02,  6.1191e-02, -1.4007e-01,  5.5415e-02, -1.3539e-01,\n          1.6950e-01, -2.4082e-02, -7.0238e-02,  6.5380e-02, -1.6689e-01,\n         -1.0381e-01, -8.5165e-03,  1.3411e-02,  4.2535e-02, -1.6730e-01,\n          1.5750e-01, -1.4477e-01, -1.2851e-01, -1.0403e-01, -6.2816e-02,\n          3.8425e-03,  3.4005e-02],\n        [ 1.4403e-01,  9.7932e-02,  1.6743e-01, -1.4037e-01,  1.6928e-01,\n         -4.6086e-02,  9.8160e-02,  2.8112e-02,  1.1693e-02,  1.6641e-02,\n          1.5911e-01,  1.1207e-01, -6.9315e-02, -1.1431e-01,  1.0554e-01,\n         -4.1282e-02,  1.5685e-01, -1.3776e-01,  1.5775e-01, -1.5558e-01,\n          4.2453e-02, -6.1415e-03, -1.4804e-01, -4.5959e-02,  4.2062e-02,\n          1.2987e-01,  1.2505e-01, -9.6893e-02,  1.3974e-01,  6.1446e-02,\n         -9.7847e-02,  1.1149e-01],\n        [ 1.5798e-01, -5.0067e-02, -1.1296e-01, -1.3433e-01, -6.2529e-02,\n          5.6792e-02,  1.3558e-03,  1.1351e-01, -2.0736e-02,  1.7037e-01,\n          7.0362e-04,  1.0183e-01,  1.6360e-01, -1.3709e-01,  1.3587e-01,\n         -8.6420e-02, -4.6958e-02,  5.6169e-02, -1.3092e-01,  1.4846e-01,\n         -4.3875e-02, -8.1812e-02,  9.3333e-03,  1.4253e-01,  1.6714e-01,\n         -1.0074e-01,  5.3208e-02, -6.4609e-02,  4.0283e-02,  6.4273e-02,\n         -6.8117e-02,  8.0910e-03],\n        [-5.2968e-02,  1.4144e-01, -3.9717e-02,  3.7295e-02, -4.4976e-02,\n          8.8086e-02,  1.0004e-01, -3.5441e-02, -1.6690e-01, -2.1967e-02,\n         -3.6571e-03, -1.0800e-01,  1.5134e-01, -7.5133e-02, -1.3625e-01,\n         -2.9522e-02,  1.6049e-01,  1.0862e-01,  1.0390e-01,  4.0173e-02,\n          7.5166e-03, -9.6744e-02, -4.4847e-02,  8.1937e-02, -1.0289e-01,\n         -6.1996e-02,  1.7376e-01, -5.3731e-02, -3.3438e-02, -8.2527e-02,\n          1.8744e-02, -1.6414e-01],\n        [ 2.3021e-02, -5.0876e-02,  3.6679e-02,  1.4470e-01,  1.6713e-01,\n          1.5211e-01, -1.3837e-01,  6.9884e-02, -8.7108e-02,  3.6068e-02,\n          1.6972e-01,  4.6271e-02, -7.4514e-02,  7.5305e-02,  1.4068e-02,\n          2.7581e-02,  1.6590e-01,  3.3474e-03, -1.6921e-01, -1.2046e-01,\n         -1.5643e-02,  2.3350e-03,  1.6535e-01,  1.7338e-01,  1.1195e-01,\n          4.2463e-02,  2.2813e-02,  5.7443e-02, -1.6704e-01, -6.4136e-02,\n          7.5945e-02, -5.2208e-02],\n        [ 5.3436e-02,  7.6593e-02, -1.7181e-01,  7.9595e-02,  1.4779e-01,\n         -1.1334e-01, -1.6106e-01,  3.7733e-02, -3.8246e-02,  5.2151e-02,\n          1.1756e-01, -7.9664e-02,  9.0222e-02, -2.4816e-02,  1.7336e-01,\n          5.5032e-02, -6.5865e-02, -1.6010e-01,  3.3076e-02, -9.1372e-02,\n          7.7084e-02,  1.1440e-01,  1.0733e-01,  2.8053e-03, -1.4082e-01,\n          7.4260e-02,  5.0102e-02, -1.5055e-01, -1.2723e-01,  8.7703e-02,\n         -7.1273e-03, -1.5379e-01],\n        [ 7.2342e-02, -1.7602e-01,  5.3973e-02,  1.4193e-01, -1.6838e-01,\n          5.2665e-02,  5.2284e-02,  2.6843e-02,  5.7777e-02, -7.0628e-02,\n          1.6604e-01,  1.6510e-02,  1.4114e-01, -2.8837e-02, -4.0160e-02,\n         -4.8151e-02,  1.4151e-01,  8.9319e-03, -1.3577e-01,  5.7191e-02,\n          1.6622e-01,  1.8689e-02, -1.2240e-01, -1.2459e-01, -8.5338e-02,\n          1.6498e-01,  5.6712e-02,  1.0291e-01, -1.6759e-01,  3.0778e-02,\n         -1.8232e-02, -5.8634e-02],\n        [ 4.4675e-02, -1.5212e-01,  1.2624e-01, -2.9159e-02,  1.6176e-02,\n         -7.2130e-02,  1.3030e-01,  3.9850e-05,  9.7213e-02,  3.2598e-03,\n         -6.3709e-02,  1.4672e-02,  1.6707e-01,  1.2841e-01,  3.8936e-02,\n          1.6600e-01,  1.1975e-01,  7.0828e-02,  1.1359e-01,  4.7235e-02,\n         -7.6874e-02, -1.5749e-01,  4.0353e-02,  3.6621e-02, -6.7451e-02,\n          1.6171e-01, -9.9663e-02,  4.6919e-02, -6.8140e-02, -1.2115e-01,\n         -7.5335e-02, -1.1749e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1202, -0.0179, -0.1295,  0.1902,  0.1638, -0.2389,  0.0874,  0.1401],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2199, -0.0436, -0.2274, -0.1435,  0.0293, -0.0245,  0.0452, -0.2004,\n          0.1345, -0.1266, -0.1820, -0.1915, -0.1219, -0.2359, -0.2217, -0.1862],\n        [-0.0204,  0.0433, -0.0562,  0.1714, -0.1694,  0.2445,  0.1195, -0.1795,\n          0.1557,  0.1459, -0.1131, -0.2341, -0.1254, -0.1946,  0.0198,  0.0993],\n        [ 0.1390,  0.2031,  0.1727,  0.0245,  0.1313,  0.0219, -0.1646,  0.0027,\n         -0.2226,  0.2333, -0.1769, -0.0991,  0.0584,  0.1950,  0.1586, -0.0494],\n        [-0.1332,  0.1051, -0.0947,  0.0052, -0.1611, -0.1827,  0.0049, -0.0263,\n          0.1152, -0.1880, -0.0293, -0.1856, -0.1241,  0.2013, -0.2491, -0.2341],\n        [-0.1579, -0.2223, -0.0273,  0.1368, -0.1213,  0.0446, -0.2236,  0.0045,\n         -0.1424, -0.1574, -0.0054, -0.1855, -0.0316, -0.0533,  0.1082,  0.2436],\n        [-0.2460, -0.1820, -0.0026, -0.0532, -0.0387,  0.1074, -0.2158, -0.2280,\n         -0.0539,  0.0707,  0.2436,  0.1861, -0.0377,  0.0194,  0.1174, -0.1151],\n        [ 0.1099,  0.2142,  0.1502,  0.0516, -0.0668, -0.2489,  0.1474, -0.0960,\n          0.0237, -0.0886, -0.1635, -0.2371,  0.0963, -0.0206, -0.0472,  0.0155],\n        [ 0.0336, -0.1585, -0.1968, -0.0495, -0.2044,  0.0413, -0.1382,  0.0712,\n          0.1446,  0.0007,  0.0131,  0.0069, -0.0718, -0.1691, -0.0824, -0.0776]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0985,  0.3327, -0.2508,  0.2110], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1278, -0.3105, -0.2761, -0.1855,  0.2573, -0.0713,  0.2773, -0.2819],\n        [ 0.2740, -0.0646,  0.2694,  0.2609,  0.1455, -0.3224, -0.1934, -0.2870],\n        [-0.0199,  0.2402, -0.3462, -0.2496, -0.0902,  0.0452,  0.2899, -0.3262],\n        [ 0.1058,  0.0013,  0.1703, -0.1898, -0.0450, -0.0765,  0.0554, -0.0050]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x72b320fc4d90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s153190000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s153190000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}