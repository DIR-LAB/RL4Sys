{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.01,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s157340000"
    },
    "max_sample_age":	-1,
    "q_lr":	0.003,
    "seed":	157340000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x76da8712dd50>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.01,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1786,  0.1261,  0.3373, -0.0535, -0.1946,  0.2617, -0.0142,  0.3401,\n        -0.0443,  0.2808,  0.2740, -0.2446, -0.2882, -0.1655, -0.1256, -0.0081,\n         0.0662, -0.1114,  0.3532, -0.1763, -0.2558, -0.2396, -0.0552, -0.1033,\n         0.2280, -0.0563, -0.2577, -0.1631,  0.2672,  0.3011,  0.2315, -0.0355,\n         0.2885, -0.0717, -0.0590, -0.3041, -0.1775,  0.1574,  0.0638, -0.1411,\n         0.1307,  0.0957, -0.0085, -0.2949,  0.2632, -0.3140,  0.1164, -0.1998,\n        -0.2154, -0.0968, -0.2024, -0.2957, -0.1835,  0.1463,  0.0993, -0.0741,\n        -0.0750,  0.0706,  0.1153,  0.0156,  0.3215, -0.0911,  0.0907, -0.3420,\n        -0.1381,  0.3036,  0.1960, -0.3409,  0.1216, -0.1803, -0.2650, -0.1134,\n         0.0437, -0.0276, -0.0583, -0.2139,  0.2922, -0.3274,  0.2911, -0.1687,\n        -0.0947,  0.0453, -0.0075,  0.0311,  0.2606, -0.2986, -0.0195, -0.1006,\n         0.1129,  0.2057,  0.1456, -0.2210,  0.0858,  0.3414, -0.2030, -0.2849,\n         0.3095,  0.2882, -0.2860,  0.3489, -0.0434, -0.0400, -0.0263,  0.1188,\n         0.2784,  0.2792,  0.2946, -0.2638,  0.1642,  0.0698,  0.2346,  0.0447,\n        -0.1260, -0.1057, -0.0304,  0.1039, -0.0994, -0.0845,  0.2698, -0.0261,\n         0.1600, -0.1280,  0.1437, -0.3223,  0.0904, -0.0563,  0.1433, -0.0803,\n        -0.0849,  0.1311,  0.0238,  0.2872,  0.0189,  0.2948, -0.1837,  0.0052,\n        -0.1335,  0.1935, -0.3506,  0.0146, -0.1098,  0.2691, -0.2321, -0.2067,\n        -0.1580, -0.0010, -0.0516, -0.1557,  0.1477, -0.3182,  0.0627,  0.1545,\n        -0.2507,  0.0443, -0.1255,  0.0594, -0.1945,  0.3068, -0.0990, -0.2845,\n        -0.1107, -0.0171, -0.0480,  0.0655,  0.0152,  0.1504, -0.2593,  0.0286,\n        -0.1052,  0.1800, -0.1331, -0.1842,  0.0921, -0.1622,  0.0364, -0.0177,\n        -0.2769, -0.1736,  0.0044,  0.1600, -0.2663, -0.2682,  0.2198, -0.2758,\n         0.0511, -0.3212, -0.2076, -0.2797, -0.3243, -0.0858, -0.3057,  0.1355,\n         0.2093,  0.2015, -0.0681,  0.2703,  0.3345,  0.1062, -0.1422,  0.0846,\n         0.1614, -0.0549, -0.3125,  0.2709, -0.2731, -0.3318, -0.3237, -0.3407,\n         0.1186, -0.3190,  0.1493, -0.1887,  0.1241, -0.0766,  0.3008, -0.0796,\n         0.2498, -0.1996,  0.2814,  0.2063,  0.0999,  0.3261, -0.1141,  0.0896,\n        -0.3431,  0.2973,  0.2652, -0.1907, -0.1696, -0.1410, -0.0210, -0.0835,\n        -0.1492,  0.1729, -0.0020, -0.3410,  0.3456,  0.2401, -0.2067, -0.3300,\n         0.2483, -0.0828, -0.0381,  0.2291,  0.0157,  0.0408, -0.2757, -0.2186,\n         0.0602, -0.2918,  0.2933,  0.1550, -0.2988,  0.3381, -0.3525, -0.0837,\n         0.0523,  0.1773,  0.1969, -0.1953,  0.1378, -0.3010, -0.3313,  0.1546,\n         0.2531,  0.2154,  0.2067, -0.2946, -0.2926, -0.2990, -0.2474,  0.3493,\n        -0.0460, -0.0648, -0.0644,  0.3136,  0.0433, -0.2508, -0.0631, -0.2578,\n        -0.1921, -0.0785,  0.0206,  0.1762,  0.0401, -0.1508,  0.2700,  0.1005,\n        -0.0041,  0.1318,  0.1967,  0.0680, -0.1083, -0.0588,  0.2440,  0.3506,\n         0.2888,  0.0761,  0.2900, -0.3050,  0.3396, -0.3503,  0.2386, -0.2490,\n        -0.3042, -0.1488, -0.3322,  0.2493,  0.1767,  0.0435, -0.1255, -0.1872,\n        -0.2490, -0.1925,  0.2366,  0.3514, -0.1727,  0.0709,  0.2825,  0.1892,\n         0.2937, -0.2195,  0.0194, -0.1952,  0.1480, -0.3435,  0.1909,  0.2862,\n        -0.0143, -0.0355, -0.2455,  0.2038, -0.2826, -0.2495,  0.1076,  0.0942,\n        -0.3356,  0.0704, -0.1977,  0.3191, -0.2929, -0.1051, -0.1836,  0.2970,\n        -0.0121,  0.0276, -0.2990, -0.0156,  0.1547, -0.1260, -0.0523,  0.2766,\n         0.0271, -0.0581,  0.0125,  0.1893, -0.1305, -0.1826,  0.1044, -0.0789,\n         0.1763, -0.3305, -0.1101, -0.0480,  0.0131,  0.2154, -0.0858, -0.2627,\n        -0.2112,  0.1914,  0.1029,  0.0119, -0.0174,  0.0837,  0.2236, -0.0503,\n        -0.2526,  0.0403, -0.0067, -0.2448, -0.0944, -0.0225, -0.2228, -0.0808,\n         0.2072, -0.0758, -0.2678, -0.0335,  0.1526,  0.2956,  0.0383,  0.2096,\n         0.1469, -0.0708, -0.1366,  0.3472, -0.1633,  0.1477,  0.1885, -0.2145],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.3465, -0.0862, -0.2112,  ..., -0.0235, -0.2126,  0.2280],\n        [ 0.2615, -0.2347, -0.2926,  ...,  0.2889, -0.1768, -0.2638],\n        [-0.0018, -0.0732, -0.0808,  ..., -0.1577, -0.0405, -0.2625],\n        ...,\n        [-0.1928, -0.2928,  0.2980,  ...,  0.1302,  0.1389,  0.0167],\n        [ 0.2346, -0.0272, -0.0694,  ..., -0.2475, -0.0297, -0.2084],\n        [ 0.1360,  0.0547,  0.3396,  ...,  0.2150,  0.2512, -0.1578]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-7.7341e-03, -4.9942e-02, -4.3653e-02, -2.4545e-02, -3.1194e-02,\n        -4.7822e-02,  1.2134e-02,  1.7571e-02, -1.4736e-02,  1.4323e-03,\n        -6.7228e-03, -2.1122e-02,  2.3278e-02, -1.8761e-02,  3.3414e-02,\n         2.2998e-03, -3.5165e-02,  2.5528e-02, -1.6434e-02, -1.5567e-03,\n         1.1685e-02,  1.1992e-02,  4.4545e-04, -4.9983e-02,  1.1474e-02,\n        -3.0255e-02, -1.2255e-02,  3.0082e-02, -4.6611e-02, -1.6371e-02,\n         6.4720e-03,  4.8608e-02,  1.6252e-02,  3.3486e-02,  2.7021e-03,\n        -2.6590e-02,  1.3080e-02, -3.6118e-02, -2.4384e-02, -8.4293e-04,\n        -2.6311e-02,  2.6471e-02, -2.5485e-02,  1.7192e-02, -1.1115e-02,\n         2.0621e-02,  4.1606e-03, -3.5350e-02,  3.2626e-02,  4.4629e-03,\n         2.1319e-02,  4.9995e-02,  2.5070e-02,  1.2090e-02, -4.7681e-03,\n         2.7644e-02,  1.1967e-02, -3.8760e-02,  3.5509e-02,  2.6692e-02,\n         4.9836e-02, -1.4741e-02,  1.7023e-02, -3.9491e-02,  3.3068e-03,\n        -3.1257e-02, -3.9213e-02, -1.1557e-02, -3.2665e-02, -4.8567e-02,\n        -2.0137e-02,  2.9910e-02, -2.3487e-02, -3.6865e-02,  1.2831e-03,\n         3.7175e-02,  3.9731e-02, -2.1682e-02, -2.7742e-02, -1.7591e-02,\n        -2.6567e-02, -2.9681e-02, -2.5898e-02, -7.4629e-03, -3.5719e-02,\n         3.5949e-02, -2.8510e-02,  1.1398e-02,  3.5206e-03, -2.1609e-03,\n        -2.1121e-02,  6.6036e-03,  3.8648e-02, -8.0689e-03, -3.5368e-02,\n        -3.3924e-02, -2.5969e-02,  3.5994e-02,  8.7075e-03, -1.4651e-02,\n         2.6592e-02, -3.0776e-02,  4.0532e-02,  2.5838e-02,  2.2181e-02,\n         1.6759e-02, -1.6352e-02,  2.0478e-02,  2.7164e-02, -1.4955e-02,\n        -4.5089e-02, -1.2999e-02,  3.6555e-02, -3.5852e-02,  4.3352e-02,\n        -4.1820e-02, -1.6070e-02,  4.2954e-02,  1.9741e-02,  4.8993e-02,\n        -2.7494e-02,  1.4525e-03, -2.8174e-02, -2.0578e-02, -2.8769e-02,\n        -3.7224e-02, -4.4938e-02, -4.9526e-02,  4.8473e-03,  1.6094e-02,\n         1.0689e-03,  4.5702e-03,  2.1619e-02, -7.8504e-03, -1.1394e-02,\n         4.9443e-02,  3.8855e-02,  9.0666e-03,  3.9164e-02, -1.5379e-02,\n        -1.5936e-02,  8.0494e-03, -1.4238e-02, -2.6667e-02, -3.7969e-02,\n         2.3118e-02,  1.9891e-02, -2.1292e-02, -2.5918e-02,  4.3063e-02,\n        -4.7592e-02, -3.6329e-03, -1.9776e-02, -3.3178e-02,  2.0236e-02,\n        -7.1850e-03, -1.9133e-02,  1.3065e-02,  9.7793e-05, -4.5937e-02,\n         4.1546e-02, -1.4791e-02, -3.7314e-02,  2.8096e-02,  2.2897e-02,\n        -1.1751e-04,  2.1178e-02,  2.1684e-02,  4.3154e-02,  3.2003e-02,\n         2.0061e-02,  4.9683e-02,  4.4554e-02, -3.8720e-02,  3.6779e-02,\n        -3.7659e-03, -2.0728e-02,  1.9142e-02, -2.8506e-02, -3.9530e-02,\n         4.9118e-02, -4.7225e-02,  1.3901e-02, -3.3018e-02, -2.6062e-02,\n        -2.5596e-02, -1.0128e-03, -2.7042e-02,  1.1806e-02, -3.6419e-02,\n         1.9049e-02, -9.6157e-03, -4.8913e-02,  3.8756e-02,  2.9660e-02,\n        -2.0096e-02,  2.8027e-02,  1.4100e-02,  4.6298e-02, -3.8080e-03,\n         4.9736e-02, -1.4655e-02, -4.8762e-02, -2.6802e-02, -1.7572e-02,\n         1.5770e-02,  3.4808e-02,  2.5332e-02,  2.7053e-02,  3.3403e-02,\n        -2.3536e-03,  1.1894e-02, -3.1730e-02,  2.7668e-02, -2.9334e-03,\n         3.1238e-02, -1.0605e-02,  2.7110e-02,  4.9291e-02,  2.9141e-02,\n        -5.0377e-03,  4.6592e-02, -1.3485e-02, -2.0748e-02,  1.0499e-02,\n         1.9963e-02,  4.5268e-02,  3.1331e-02, -2.8664e-03, -1.5673e-02,\n        -4.6282e-02,  1.8146e-02,  2.6609e-02, -2.6964e-02, -9.3108e-03,\n        -3.1968e-02,  2.9079e-02, -3.2745e-02, -1.3188e-02, -3.7180e-02,\n        -4.3298e-02, -4.6736e-02, -3.7396e-02, -2.0960e-02, -1.3792e-03,\n         2.2636e-02,  4.9929e-02,  2.8361e-03,  3.4615e-02,  2.4191e-02,\n        -9.2635e-03, -7.2302e-03,  3.9027e-03, -1.7049e-02,  1.5300e-02,\n        -3.1319e-02, -2.5513e-03,  1.3207e-02,  4.2232e-02, -2.3554e-02,\n         3.1821e-02, -3.6084e-02, -3.5494e-02,  3.9272e-02,  2.5245e-02,\n         2.0475e-02,  2.9815e-02, -4.9009e-02,  4.6247e-02,  6.7880e-03,\n         4.4402e-02, -4.7308e-02,  1.8544e-02,  1.5775e-02,  3.6889e-03,\n        -4.2616e-02, -4.2512e-02, -3.2616e-02,  3.6473e-02, -2.2018e-02,\n        -4.1077e-02, -4.1081e-02, -1.7340e-02, -4.3914e-02,  6.7273e-03,\n         1.5529e-02, -2.9682e-02, -2.3989e-03,  4.8519e-02,  8.4780e-04,\n        -3.2728e-02, -5.7964e-03, -1.9042e-02,  4.1806e-02, -8.1167e-03,\n         2.9821e-02,  4.8640e-02,  1.3110e-02, -1.8842e-02,  9.8203e-03],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 4.7902e-02, -3.4875e-02,  4.2764e-02,  ...,  4.7032e-02,\n          1.9333e-03, -2.1209e-03],\n        [ 3.2098e-02, -1.0856e-02, -2.6042e-02,  ..., -1.8691e-02,\n         -8.6068e-03, -8.2673e-03],\n        [-4.7746e-02, -4.1494e-02,  3.4731e-02,  ...,  4.9297e-02,\n          3.0255e-02,  3.8571e-02],\n        ...,\n        [ 3.8697e-02, -9.1452e-03, -1.0981e-02,  ...,  4.9032e-02,\n          3.3722e-02, -2.8867e-02],\n        [-1.1792e-03, -4.0535e-02, -4.3073e-02,  ...,  2.4303e-02,\n          2.8896e-02, -2.0796e-02],\n        [ 3.5233e-02,  3.9862e-02, -2.2206e-02,  ...,  4.8846e-05,\n         -3.3097e-02, -3.8843e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0315,  0.0178, -0.0543,  0.0275], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0316,  0.0226, -0.0356,  ...,  0.0300, -0.0139,  0.0290],\n        [-0.0065, -0.0311, -0.0324,  ..., -0.0195, -0.0286,  0.0190],\n        [-0.0169,  0.0424,  0.0099,  ..., -0.0171, -0.0426, -0.0419],\n        [-0.0072, -0.0285, -0.0338,  ..., -0.0569, -0.0426, -0.0375]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.3465, -0.0862, -0.2112,  ..., -0.0235, -0.2126,  0.2280],\n        [ 0.2615, -0.2347, -0.2926,  ...,  0.2889, -0.1768, -0.2638],\n        [-0.0018, -0.0732, -0.0808,  ..., -0.1577, -0.0405, -0.2625],\n        ...,\n        [-0.1928, -0.2928,  0.2980,  ...,  0.1302,  0.1389,  0.0167],\n        [ 0.2346, -0.0272, -0.0694,  ..., -0.2475, -0.0297, -0.2084],\n        [ 0.1360,  0.0547,  0.3396,  ...,  0.2150,  0.2512, -0.1578]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1786,  0.1261,  0.3373, -0.0535, -0.1946,  0.2617, -0.0142,  0.3401,\n        -0.0443,  0.2808,  0.2740, -0.2446, -0.2882, -0.1655, -0.1256, -0.0081,\n         0.0662, -0.1114,  0.3532, -0.1763, -0.2558, -0.2396, -0.0552, -0.1033,\n         0.2280, -0.0563, -0.2577, -0.1631,  0.2672,  0.3011,  0.2315, -0.0355,\n         0.2885, -0.0717, -0.0590, -0.3041, -0.1775,  0.1574,  0.0638, -0.1411,\n         0.1307,  0.0957, -0.0085, -0.2949,  0.2632, -0.3140,  0.1164, -0.1998,\n        -0.2154, -0.0968, -0.2024, -0.2957, -0.1835,  0.1463,  0.0993, -0.0741,\n        -0.0750,  0.0706,  0.1153,  0.0156,  0.3215, -0.0911,  0.0907, -0.3420,\n        -0.1381,  0.3036,  0.1960, -0.3409,  0.1216, -0.1803, -0.2650, -0.1134,\n         0.0437, -0.0276, -0.0583, -0.2139,  0.2922, -0.3274,  0.2911, -0.1687,\n        -0.0947,  0.0453, -0.0075,  0.0311,  0.2606, -0.2986, -0.0195, -0.1006,\n         0.1129,  0.2057,  0.1456, -0.2210,  0.0858,  0.3414, -0.2030, -0.2849,\n         0.3095,  0.2882, -0.2860,  0.3489, -0.0434, -0.0400, -0.0263,  0.1188,\n         0.2784,  0.2792,  0.2946, -0.2638,  0.1642,  0.0698,  0.2346,  0.0447,\n        -0.1260, -0.1057, -0.0304,  0.1039, -0.0994, -0.0845,  0.2698, -0.0261,\n         0.1600, -0.1280,  0.1437, -0.3223,  0.0904, -0.0563,  0.1433, -0.0803,\n        -0.0849,  0.1311,  0.0238,  0.2872,  0.0189,  0.2948, -0.1837,  0.0052,\n        -0.1335,  0.1935, -0.3506,  0.0146, -0.1098,  0.2691, -0.2321, -0.2067,\n        -0.1580, -0.0010, -0.0516, -0.1557,  0.1477, -0.3182,  0.0627,  0.1545,\n        -0.2507,  0.0443, -0.1255,  0.0594, -0.1945,  0.3068, -0.0990, -0.2845,\n        -0.1107, -0.0171, -0.0480,  0.0655,  0.0152,  0.1504, -0.2593,  0.0286,\n        -0.1052,  0.1800, -0.1331, -0.1842,  0.0921, -0.1622,  0.0364, -0.0177,\n        -0.2769, -0.1736,  0.0044,  0.1600, -0.2663, -0.2682,  0.2198, -0.2758,\n         0.0511, -0.3212, -0.2076, -0.2797, -0.3243, -0.0858, -0.3057,  0.1355,\n         0.2093,  0.2015, -0.0681,  0.2703,  0.3345,  0.1062, -0.1422,  0.0846,\n         0.1614, -0.0549, -0.3125,  0.2709, -0.2731, -0.3318, -0.3237, -0.3407,\n         0.1186, -0.3190,  0.1493, -0.1887,  0.1241, -0.0766,  0.3008, -0.0796,\n         0.2498, -0.1996,  0.2814,  0.2063,  0.0999,  0.3261, -0.1141,  0.0896,\n        -0.3431,  0.2973,  0.2652, -0.1907, -0.1696, -0.1410, -0.0210, -0.0835,\n        -0.1492,  0.1729, -0.0020, -0.3410,  0.3456,  0.2401, -0.2067, -0.3300,\n         0.2483, -0.0828, -0.0381,  0.2291,  0.0157,  0.0408, -0.2757, -0.2186,\n         0.0602, -0.2918,  0.2933,  0.1550, -0.2988,  0.3381, -0.3525, -0.0837,\n         0.0523,  0.1773,  0.1969, -0.1953,  0.1378, -0.3010, -0.3313,  0.1546,\n         0.2531,  0.2154,  0.2067, -0.2946, -0.2926, -0.2990, -0.2474,  0.3493,\n        -0.0460, -0.0648, -0.0644,  0.3136,  0.0433, -0.2508, -0.0631, -0.2578,\n        -0.1921, -0.0785,  0.0206,  0.1762,  0.0401, -0.1508,  0.2700,  0.1005,\n        -0.0041,  0.1318,  0.1967,  0.0680, -0.1083, -0.0588,  0.2440,  0.3506,\n         0.2888,  0.0761,  0.2900, -0.3050,  0.3396, -0.3503,  0.2386, -0.2490,\n        -0.3042, -0.1488, -0.3322,  0.2493,  0.1767,  0.0435, -0.1255, -0.1872,\n        -0.2490, -0.1925,  0.2366,  0.3514, -0.1727,  0.0709,  0.2825,  0.1892,\n         0.2937, -0.2195,  0.0194, -0.1952,  0.1480, -0.3435,  0.1909,  0.2862,\n        -0.0143, -0.0355, -0.2455,  0.2038, -0.2826, -0.2495,  0.1076,  0.0942,\n        -0.3356,  0.0704, -0.1977,  0.3191, -0.2929, -0.1051, -0.1836,  0.2970,\n        -0.0121,  0.0276, -0.2990, -0.0156,  0.1547, -0.1260, -0.0523,  0.2766,\n         0.0271, -0.0581,  0.0125,  0.1893, -0.1305, -0.1826,  0.1044, -0.0789,\n         0.1763, -0.3305, -0.1101, -0.0480,  0.0131,  0.2154, -0.0858, -0.2627,\n        -0.2112,  0.1914,  0.1029,  0.0119, -0.0174,  0.0837,  0.2236, -0.0503,\n        -0.2526,  0.0403, -0.0067, -0.2448, -0.0944, -0.0225, -0.2228, -0.0808,\n         0.2072, -0.0758, -0.2678, -0.0335,  0.1526,  0.2956,  0.0383,  0.2096,\n         0.1469, -0.0708, -0.1366,  0.3472, -0.1633,  0.1477,  0.1885, -0.2145],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 4.7902e-02, -3.4875e-02,  4.2764e-02,  ...,  4.7032e-02,\n          1.9333e-03, -2.1209e-03],\n        [ 3.2098e-02, -1.0856e-02, -2.6042e-02,  ..., -1.8691e-02,\n         -8.6068e-03, -8.2673e-03],\n        [-4.7746e-02, -4.1494e-02,  3.4731e-02,  ...,  4.9297e-02,\n          3.0255e-02,  3.8571e-02],\n        ...,\n        [ 3.8697e-02, -9.1452e-03, -1.0981e-02,  ...,  4.9032e-02,\n          3.3722e-02, -2.8867e-02],\n        [-1.1792e-03, -4.0535e-02, -4.3073e-02,  ...,  2.4303e-02,\n          2.8896e-02, -2.0796e-02],\n        [ 3.5233e-02,  3.9862e-02, -2.2206e-02,  ...,  4.8846e-05,\n         -3.3097e-02, -3.8843e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-7.7341e-03, -4.9942e-02, -4.3653e-02, -2.4545e-02, -3.1194e-02,\n        -4.7822e-02,  1.2134e-02,  1.7571e-02, -1.4736e-02,  1.4323e-03,\n        -6.7228e-03, -2.1122e-02,  2.3278e-02, -1.8761e-02,  3.3414e-02,\n         2.2998e-03, -3.5165e-02,  2.5528e-02, -1.6434e-02, -1.5567e-03,\n         1.1685e-02,  1.1992e-02,  4.4545e-04, -4.9983e-02,  1.1474e-02,\n        -3.0255e-02, -1.2255e-02,  3.0082e-02, -4.6611e-02, -1.6371e-02,\n         6.4720e-03,  4.8608e-02,  1.6252e-02,  3.3486e-02,  2.7021e-03,\n        -2.6590e-02,  1.3080e-02, -3.6118e-02, -2.4384e-02, -8.4293e-04,\n        -2.6311e-02,  2.6471e-02, -2.5485e-02,  1.7192e-02, -1.1115e-02,\n         2.0621e-02,  4.1606e-03, -3.5350e-02,  3.2626e-02,  4.4629e-03,\n         2.1319e-02,  4.9995e-02,  2.5070e-02,  1.2090e-02, -4.7681e-03,\n         2.7644e-02,  1.1967e-02, -3.8760e-02,  3.5509e-02,  2.6692e-02,\n         4.9836e-02, -1.4741e-02,  1.7023e-02, -3.9491e-02,  3.3068e-03,\n        -3.1257e-02, -3.9213e-02, -1.1557e-02, -3.2665e-02, -4.8567e-02,\n        -2.0137e-02,  2.9910e-02, -2.3487e-02, -3.6865e-02,  1.2831e-03,\n         3.7175e-02,  3.9731e-02, -2.1682e-02, -2.7742e-02, -1.7591e-02,\n        -2.6567e-02, -2.9681e-02, -2.5898e-02, -7.4629e-03, -3.5719e-02,\n         3.5949e-02, -2.8510e-02,  1.1398e-02,  3.5206e-03, -2.1609e-03,\n        -2.1121e-02,  6.6036e-03,  3.8648e-02, -8.0689e-03, -3.5368e-02,\n        -3.3924e-02, -2.5969e-02,  3.5994e-02,  8.7075e-03, -1.4651e-02,\n         2.6592e-02, -3.0776e-02,  4.0532e-02,  2.5838e-02,  2.2181e-02,\n         1.6759e-02, -1.6352e-02,  2.0478e-02,  2.7164e-02, -1.4955e-02,\n        -4.5089e-02, -1.2999e-02,  3.6555e-02, -3.5852e-02,  4.3352e-02,\n        -4.1820e-02, -1.6070e-02,  4.2954e-02,  1.9741e-02,  4.8993e-02,\n        -2.7494e-02,  1.4525e-03, -2.8174e-02, -2.0578e-02, -2.8769e-02,\n        -3.7224e-02, -4.4938e-02, -4.9526e-02,  4.8473e-03,  1.6094e-02,\n         1.0689e-03,  4.5702e-03,  2.1619e-02, -7.8504e-03, -1.1394e-02,\n         4.9443e-02,  3.8855e-02,  9.0666e-03,  3.9164e-02, -1.5379e-02,\n        -1.5936e-02,  8.0494e-03, -1.4238e-02, -2.6667e-02, -3.7969e-02,\n         2.3118e-02,  1.9891e-02, -2.1292e-02, -2.5918e-02,  4.3063e-02,\n        -4.7592e-02, -3.6329e-03, -1.9776e-02, -3.3178e-02,  2.0236e-02,\n        -7.1850e-03, -1.9133e-02,  1.3065e-02,  9.7793e-05, -4.5937e-02,\n         4.1546e-02, -1.4791e-02, -3.7314e-02,  2.8096e-02,  2.2897e-02,\n        -1.1751e-04,  2.1178e-02,  2.1684e-02,  4.3154e-02,  3.2003e-02,\n         2.0061e-02,  4.9683e-02,  4.4554e-02, -3.8720e-02,  3.6779e-02,\n        -3.7659e-03, -2.0728e-02,  1.9142e-02, -2.8506e-02, -3.9530e-02,\n         4.9118e-02, -4.7225e-02,  1.3901e-02, -3.3018e-02, -2.6062e-02,\n        -2.5596e-02, -1.0128e-03, -2.7042e-02,  1.1806e-02, -3.6419e-02,\n         1.9049e-02, -9.6157e-03, -4.8913e-02,  3.8756e-02,  2.9660e-02,\n        -2.0096e-02,  2.8027e-02,  1.4100e-02,  4.6298e-02, -3.8080e-03,\n         4.9736e-02, -1.4655e-02, -4.8762e-02, -2.6802e-02, -1.7572e-02,\n         1.5770e-02,  3.4808e-02,  2.5332e-02,  2.7053e-02,  3.3403e-02,\n        -2.3536e-03,  1.1894e-02, -3.1730e-02,  2.7668e-02, -2.9334e-03,\n         3.1238e-02, -1.0605e-02,  2.7110e-02,  4.9291e-02,  2.9141e-02,\n        -5.0377e-03,  4.6592e-02, -1.3485e-02, -2.0748e-02,  1.0499e-02,\n         1.9963e-02,  4.5268e-02,  3.1331e-02, -2.8664e-03, -1.5673e-02,\n        -4.6282e-02,  1.8146e-02,  2.6609e-02, -2.6964e-02, -9.3108e-03,\n        -3.1968e-02,  2.9079e-02, -3.2745e-02, -1.3188e-02, -3.7180e-02,\n        -4.3298e-02, -4.6736e-02, -3.7396e-02, -2.0960e-02, -1.3792e-03,\n         2.2636e-02,  4.9929e-02,  2.8361e-03,  3.4615e-02,  2.4191e-02,\n        -9.2635e-03, -7.2302e-03,  3.9027e-03, -1.7049e-02,  1.5300e-02,\n        -3.1319e-02, -2.5513e-03,  1.3207e-02,  4.2232e-02, -2.3554e-02,\n         3.1821e-02, -3.6084e-02, -3.5494e-02,  3.9272e-02,  2.5245e-02,\n         2.0475e-02,  2.9815e-02, -4.9009e-02,  4.6247e-02,  6.7880e-03,\n         4.4402e-02, -4.7308e-02,  1.8544e-02,  1.5775e-02,  3.6889e-03,\n        -4.2616e-02, -4.2512e-02, -3.2616e-02,  3.6473e-02, -2.2018e-02,\n        -4.1077e-02, -4.1081e-02, -1.7340e-02, -4.3914e-02,  6.7273e-03,\n         1.5529e-02, -2.9682e-02, -2.3989e-03,  4.8519e-02,  8.4780e-04,\n        -3.2728e-02, -5.7964e-03, -1.9042e-02,  4.1806e-02, -8.1167e-03,\n         2.9821e-02,  4.8640e-02,  1.3110e-02, -1.8842e-02,  9.8203e-03],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0316,  0.0226, -0.0356,  ...,  0.0300, -0.0139,  0.0290],\n        [-0.0065, -0.0311, -0.0324,  ..., -0.0195, -0.0286,  0.0190],\n        [-0.0169,  0.0424,  0.0099,  ..., -0.0171, -0.0426, -0.0419],\n        [-0.0072, -0.0285, -0.0338,  ..., -0.0569, -0.0426, -0.0375]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0315,  0.0178, -0.0543,  0.0275], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x76da87bf0410>":	{
                    "capacity":	50000,
                    "current_segment":	0,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	50000,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1786,  0.1261,  0.3373, -0.0535, -0.1946,  0.2617, -0.0142,  0.3401,\n        -0.0443,  0.2808,  0.2740, -0.2446, -0.2882, -0.1655, -0.1256, -0.0081,\n         0.0662, -0.1114,  0.3532, -0.1763, -0.2558, -0.2396, -0.0552, -0.1033,\n         0.2280, -0.0563, -0.2577, -0.1631,  0.2672,  0.3011,  0.2315, -0.0355,\n         0.2885, -0.0717, -0.0590, -0.3041, -0.1775,  0.1574,  0.0638, -0.1411,\n         0.1307,  0.0957, -0.0085, -0.2949,  0.2632, -0.3140,  0.1164, -0.1998,\n        -0.2154, -0.0968, -0.2024, -0.2957, -0.1835,  0.1463,  0.0993, -0.0741,\n        -0.0750,  0.0706,  0.1153,  0.0156,  0.3215, -0.0911,  0.0907, -0.3420,\n        -0.1381,  0.3036,  0.1960, -0.3409,  0.1216, -0.1803, -0.2650, -0.1134,\n         0.0437, -0.0276, -0.0583, -0.2139,  0.2922, -0.3274,  0.2911, -0.1687,\n        -0.0947,  0.0453, -0.0075,  0.0311,  0.2606, -0.2986, -0.0195, -0.1006,\n         0.1129,  0.2057,  0.1456, -0.2210,  0.0858,  0.3414, -0.2030, -0.2849,\n         0.3095,  0.2882, -0.2860,  0.3489, -0.0434, -0.0400, -0.0263,  0.1188,\n         0.2784,  0.2792,  0.2946, -0.2638,  0.1642,  0.0698,  0.2346,  0.0447,\n        -0.1260, -0.1057, -0.0304,  0.1039, -0.0994, -0.0845,  0.2698, -0.0261,\n         0.1600, -0.1280,  0.1437, -0.3223,  0.0904, -0.0563,  0.1433, -0.0803,\n        -0.0849,  0.1311,  0.0238,  0.2872,  0.0189,  0.2948, -0.1837,  0.0052,\n        -0.1335,  0.1935, -0.3506,  0.0146, -0.1098,  0.2691, -0.2321, -0.2067,\n        -0.1580, -0.0010, -0.0516, -0.1557,  0.1477, -0.3182,  0.0627,  0.1545,\n        -0.2507,  0.0443, -0.1255,  0.0594, -0.1945,  0.3068, -0.0990, -0.2845,\n        -0.1107, -0.0171, -0.0480,  0.0655,  0.0152,  0.1504, -0.2593,  0.0286,\n        -0.1052,  0.1800, -0.1331, -0.1842,  0.0921, -0.1622,  0.0364, -0.0177,\n        -0.2769, -0.1736,  0.0044,  0.1600, -0.2663, -0.2682,  0.2198, -0.2758,\n         0.0511, -0.3212, -0.2076, -0.2797, -0.3243, -0.0858, -0.3057,  0.1355,\n         0.2093,  0.2015, -0.0681,  0.2703,  0.3345,  0.1062, -0.1422,  0.0846,\n         0.1614, -0.0549, -0.3125,  0.2709, -0.2731, -0.3318, -0.3237, -0.3407,\n         0.1186, -0.3190,  0.1493, -0.1887,  0.1241, -0.0766,  0.3008, -0.0796,\n         0.2498, -0.1996,  0.2814,  0.2063,  0.0999,  0.3261, -0.1141,  0.0896,\n        -0.3431,  0.2973,  0.2652, -0.1907, -0.1696, -0.1410, -0.0210, -0.0835,\n        -0.1492,  0.1729, -0.0020, -0.3410,  0.3456,  0.2401, -0.2067, -0.3300,\n         0.2483, -0.0828, -0.0381,  0.2291,  0.0157,  0.0408, -0.2757, -0.2186,\n         0.0602, -0.2918,  0.2933,  0.1550, -0.2988,  0.3381, -0.3525, -0.0837,\n         0.0523,  0.1773,  0.1969, -0.1953,  0.1378, -0.3010, -0.3313,  0.1546,\n         0.2531,  0.2154,  0.2067, -0.2946, -0.2926, -0.2990, -0.2474,  0.3493,\n        -0.0460, -0.0648, -0.0644,  0.3136,  0.0433, -0.2508, -0.0631, -0.2578,\n        -0.1921, -0.0785,  0.0206,  0.1762,  0.0401, -0.1508,  0.2700,  0.1005,\n        -0.0041,  0.1318,  0.1967,  0.0680, -0.1083, -0.0588,  0.2440,  0.3506,\n         0.2888,  0.0761,  0.2900, -0.3050,  0.3396, -0.3503,  0.2386, -0.2490,\n        -0.3042, -0.1488, -0.3322,  0.2493,  0.1767,  0.0435, -0.1255, -0.1872,\n        -0.2490, -0.1925,  0.2366,  0.3514, -0.1727,  0.0709,  0.2825,  0.1892,\n         0.2937, -0.2195,  0.0194, -0.1952,  0.1480, -0.3435,  0.1909,  0.2862,\n        -0.0143, -0.0355, -0.2455,  0.2038, -0.2826, -0.2495,  0.1076,  0.0942,\n        -0.3356,  0.0704, -0.1977,  0.3191, -0.2929, -0.1051, -0.1836,  0.2970,\n        -0.0121,  0.0276, -0.2990, -0.0156,  0.1547, -0.1260, -0.0523,  0.2766,\n         0.0271, -0.0581,  0.0125,  0.1893, -0.1305, -0.1826,  0.1044, -0.0789,\n         0.1763, -0.3305, -0.1101, -0.0480,  0.0131,  0.2154, -0.0858, -0.2627,\n        -0.2112,  0.1914,  0.1029,  0.0119, -0.0174,  0.0837,  0.2236, -0.0503,\n        -0.2526,  0.0403, -0.0067, -0.2448, -0.0944, -0.0225, -0.2228, -0.0808,\n         0.2072, -0.0758, -0.2678, -0.0335,  0.1526,  0.2956,  0.0383,  0.2096,\n         0.1469, -0.0708, -0.1366,  0.3472, -0.1633,  0.1477,  0.1885, -0.2145],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.3465, -0.0862, -0.2112,  ..., -0.0235, -0.2126,  0.2280],\n        [ 0.2615, -0.2347, -0.2926,  ...,  0.2889, -0.1768, -0.2638],\n        [-0.0018, -0.0732, -0.0808,  ..., -0.1577, -0.0405, -0.2625],\n        ...,\n        [-0.1928, -0.2928,  0.2980,  ...,  0.1302,  0.1389,  0.0167],\n        [ 0.2346, -0.0272, -0.0694,  ..., -0.2475, -0.0297, -0.2084],\n        [ 0.1360,  0.0547,  0.3396,  ...,  0.2150,  0.2512, -0.1578]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-7.7341e-03, -4.9942e-02, -4.3653e-02, -2.4545e-02, -3.1194e-02,\n        -4.7822e-02,  1.2134e-02,  1.7571e-02, -1.4736e-02,  1.4323e-03,\n        -6.7228e-03, -2.1122e-02,  2.3278e-02, -1.8761e-02,  3.3414e-02,\n         2.2998e-03, -3.5165e-02,  2.5528e-02, -1.6434e-02, -1.5567e-03,\n         1.1685e-02,  1.1992e-02,  4.4545e-04, -4.9983e-02,  1.1474e-02,\n        -3.0255e-02, -1.2255e-02,  3.0082e-02, -4.6611e-02, -1.6371e-02,\n         6.4720e-03,  4.8608e-02,  1.6252e-02,  3.3486e-02,  2.7021e-03,\n        -2.6590e-02,  1.3080e-02, -3.6118e-02, -2.4384e-02, -8.4293e-04,\n        -2.6311e-02,  2.6471e-02, -2.5485e-02,  1.7192e-02, -1.1115e-02,\n         2.0621e-02,  4.1606e-03, -3.5350e-02,  3.2626e-02,  4.4629e-03,\n         2.1319e-02,  4.9995e-02,  2.5070e-02,  1.2090e-02, -4.7681e-03,\n         2.7644e-02,  1.1967e-02, -3.8760e-02,  3.5509e-02,  2.6692e-02,\n         4.9836e-02, -1.4741e-02,  1.7023e-02, -3.9491e-02,  3.3068e-03,\n        -3.1257e-02, -3.9213e-02, -1.1557e-02, -3.2665e-02, -4.8567e-02,\n        -2.0137e-02,  2.9910e-02, -2.3487e-02, -3.6865e-02,  1.2831e-03,\n         3.7175e-02,  3.9731e-02, -2.1682e-02, -2.7742e-02, -1.7591e-02,\n        -2.6567e-02, -2.9681e-02, -2.5898e-02, -7.4629e-03, -3.5719e-02,\n         3.5949e-02, -2.8510e-02,  1.1398e-02,  3.5206e-03, -2.1609e-03,\n        -2.1121e-02,  6.6036e-03,  3.8648e-02, -8.0689e-03, -3.5368e-02,\n        -3.3924e-02, -2.5969e-02,  3.5994e-02,  8.7075e-03, -1.4651e-02,\n         2.6592e-02, -3.0776e-02,  4.0532e-02,  2.5838e-02,  2.2181e-02,\n         1.6759e-02, -1.6352e-02,  2.0478e-02,  2.7164e-02, -1.4955e-02,\n        -4.5089e-02, -1.2999e-02,  3.6555e-02, -3.5852e-02,  4.3352e-02,\n        -4.1820e-02, -1.6070e-02,  4.2954e-02,  1.9741e-02,  4.8993e-02,\n        -2.7494e-02,  1.4525e-03, -2.8174e-02, -2.0578e-02, -2.8769e-02,\n        -3.7224e-02, -4.4938e-02, -4.9526e-02,  4.8473e-03,  1.6094e-02,\n         1.0689e-03,  4.5702e-03,  2.1619e-02, -7.8504e-03, -1.1394e-02,\n         4.9443e-02,  3.8855e-02,  9.0666e-03,  3.9164e-02, -1.5379e-02,\n        -1.5936e-02,  8.0494e-03, -1.4238e-02, -2.6667e-02, -3.7969e-02,\n         2.3118e-02,  1.9891e-02, -2.1292e-02, -2.5918e-02,  4.3063e-02,\n        -4.7592e-02, -3.6329e-03, -1.9776e-02, -3.3178e-02,  2.0236e-02,\n        -7.1850e-03, -1.9133e-02,  1.3065e-02,  9.7793e-05, -4.5937e-02,\n         4.1546e-02, -1.4791e-02, -3.7314e-02,  2.8096e-02,  2.2897e-02,\n        -1.1751e-04,  2.1178e-02,  2.1684e-02,  4.3154e-02,  3.2003e-02,\n         2.0061e-02,  4.9683e-02,  4.4554e-02, -3.8720e-02,  3.6779e-02,\n        -3.7659e-03, -2.0728e-02,  1.9142e-02, -2.8506e-02, -3.9530e-02,\n         4.9118e-02, -4.7225e-02,  1.3901e-02, -3.3018e-02, -2.6062e-02,\n        -2.5596e-02, -1.0128e-03, -2.7042e-02,  1.1806e-02, -3.6419e-02,\n         1.9049e-02, -9.6157e-03, -4.8913e-02,  3.8756e-02,  2.9660e-02,\n        -2.0096e-02,  2.8027e-02,  1.4100e-02,  4.6298e-02, -3.8080e-03,\n         4.9736e-02, -1.4655e-02, -4.8762e-02, -2.6802e-02, -1.7572e-02,\n         1.5770e-02,  3.4808e-02,  2.5332e-02,  2.7053e-02,  3.3403e-02,\n        -2.3536e-03,  1.1894e-02, -3.1730e-02,  2.7668e-02, -2.9334e-03,\n         3.1238e-02, -1.0605e-02,  2.7110e-02,  4.9291e-02,  2.9141e-02,\n        -5.0377e-03,  4.6592e-02, -1.3485e-02, -2.0748e-02,  1.0499e-02,\n         1.9963e-02,  4.5268e-02,  3.1331e-02, -2.8664e-03, -1.5673e-02,\n        -4.6282e-02,  1.8146e-02,  2.6609e-02, -2.6964e-02, -9.3108e-03,\n        -3.1968e-02,  2.9079e-02, -3.2745e-02, -1.3188e-02, -3.7180e-02,\n        -4.3298e-02, -4.6736e-02, -3.7396e-02, -2.0960e-02, -1.3792e-03,\n         2.2636e-02,  4.9929e-02,  2.8361e-03,  3.4615e-02,  2.4191e-02,\n        -9.2635e-03, -7.2302e-03,  3.9027e-03, -1.7049e-02,  1.5300e-02,\n        -3.1319e-02, -2.5513e-03,  1.3207e-02,  4.2232e-02, -2.3554e-02,\n         3.1821e-02, -3.6084e-02, -3.5494e-02,  3.9272e-02,  2.5245e-02,\n         2.0475e-02,  2.9815e-02, -4.9009e-02,  4.6247e-02,  6.7880e-03,\n         4.4402e-02, -4.7308e-02,  1.8544e-02,  1.5775e-02,  3.6889e-03,\n        -4.2616e-02, -4.2512e-02, -3.2616e-02,  3.6473e-02, -2.2018e-02,\n        -4.1077e-02, -4.1081e-02, -1.7340e-02, -4.3914e-02,  6.7273e-03,\n         1.5529e-02, -2.9682e-02, -2.3989e-03,  4.8519e-02,  8.4780e-04,\n        -3.2728e-02, -5.7964e-03, -1.9042e-02,  4.1806e-02, -8.1167e-03,\n         2.9821e-02,  4.8640e-02,  1.3110e-02, -1.8842e-02,  9.8203e-03],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 4.7902e-02, -3.4875e-02,  4.2764e-02,  ...,  4.7032e-02,\n          1.9333e-03, -2.1209e-03],\n        [ 3.2098e-02, -1.0856e-02, -2.6042e-02,  ..., -1.8691e-02,\n         -8.6068e-03, -8.2673e-03],\n        [-4.7746e-02, -4.1494e-02,  3.4731e-02,  ...,  4.9297e-02,\n          3.0255e-02,  3.8571e-02],\n        ...,\n        [ 3.8697e-02, -9.1452e-03, -1.0981e-02,  ...,  4.9032e-02,\n          3.3722e-02, -2.8867e-02],\n        [-1.1792e-03, -4.0535e-02, -4.3073e-02,  ...,  2.4303e-02,\n          2.8896e-02, -2.0796e-02],\n        [ 3.5233e-02,  3.9862e-02, -2.2206e-02,  ...,  4.8846e-05,\n         -3.3097e-02, -3.8843e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0315,  0.0178, -0.0543,  0.0275], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0316,  0.0226, -0.0356,  ...,  0.0300, -0.0139,  0.0290],\n        [-0.0065, -0.0311, -0.0324,  ..., -0.0195, -0.0286,  0.0190],\n        [-0.0169,  0.0424,  0.0099,  ..., -0.0171, -0.0426, -0.0419],\n        [-0.0072, -0.0285, -0.0338,  ..., -0.0569, -0.0426, -0.0375]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x76da7ec04b10>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s157340000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s157340000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}