{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s160480000"
    },
    "q_lr":	0.0005,
    "seed":	160480000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x171b6e3b0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3455,  0.2208, -0.2468, -0.2194, -0.2199,  0.3269,  0.2999,  0.0732,\n         0.0012,  0.0955, -0.2421,  0.0123, -0.1365, -0.1991,  0.1741,  0.3005,\n         0.2528, -0.1710, -0.0238,  0.0458, -0.1933, -0.0079, -0.1214, -0.1456,\n        -0.3358, -0.2870, -0.0632, -0.3139,  0.0473,  0.1517, -0.0508, -0.0228],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0631,  0.0758,  0.1824, -0.0063,  0.0535,  0.0217, -0.2850,  0.3510],\n        [-0.1802,  0.1385,  0.2271,  0.0400,  0.1918,  0.2716,  0.0938,  0.1934],\n        [ 0.1645,  0.2987,  0.0909, -0.0950, -0.3532,  0.3503,  0.1133,  0.1308],\n        [ 0.2271,  0.3359,  0.1290, -0.1410, -0.2102, -0.2785, -0.1287, -0.2512],\n        [ 0.2092,  0.1787, -0.2532,  0.1803, -0.1371, -0.2613, -0.1564, -0.2873],\n        [-0.2618, -0.2010, -0.2450, -0.3172,  0.1970, -0.1952,  0.2585, -0.0228],\n        [ 0.2918, -0.1104, -0.0796, -0.0623, -0.1776, -0.1657,  0.0900,  0.1721],\n        [-0.2179, -0.2758,  0.1766,  0.1670,  0.1065,  0.0277, -0.0337, -0.1431],\n        [-0.1995,  0.2814,  0.1856, -0.0996, -0.1453,  0.1067, -0.1773,  0.1438],\n        [ 0.3025,  0.0657,  0.2053, -0.2606,  0.1751,  0.1466, -0.3092,  0.0663],\n        [-0.0164,  0.3184, -0.2021, -0.3233, -0.1084, -0.3361,  0.2315,  0.2367],\n        [ 0.0022,  0.1240, -0.1395,  0.1491, -0.2744,  0.2424,  0.0668,  0.3219],\n        [-0.3429, -0.1436, -0.2424, -0.2566, -0.3409, -0.3214, -0.0395, -0.2124],\n        [ 0.3050,  0.3235, -0.3398,  0.1106, -0.1436, -0.3091,  0.3524,  0.1366],\n        [ 0.2786,  0.1216,  0.1286, -0.1820, -0.1137, -0.1623,  0.0256, -0.2030],\n        [-0.2289, -0.2694, -0.1279,  0.1677, -0.0570,  0.0252,  0.3395,  0.2535],\n        [-0.3068,  0.0322,  0.0545,  0.0867,  0.2950,  0.0728,  0.0482,  0.3413],\n        [-0.1982,  0.3439,  0.1714,  0.1641,  0.3103, -0.0748, -0.2495, -0.2083],\n        [ 0.1035, -0.3043,  0.2367, -0.2199, -0.0831,  0.2066,  0.3454,  0.1704],\n        [ 0.1687, -0.2157,  0.1390,  0.0312,  0.3226, -0.2815, -0.0655,  0.2361],\n        [ 0.2644,  0.0615, -0.0711,  0.2510,  0.3454, -0.2616, -0.1843,  0.3327],\n        [ 0.2155, -0.2145, -0.0070, -0.1691,  0.3413, -0.2574,  0.0953, -0.1050],\n        [ 0.0950, -0.0485, -0.2716, -0.0173,  0.0861, -0.1406, -0.1815, -0.3105],\n        [-0.1003,  0.0343,  0.0593, -0.2861, -0.0022, -0.0788,  0.0626, -0.0189],\n        [ 0.1167, -0.0335,  0.2099, -0.0603, -0.1943, -0.0709,  0.1902, -0.3167],\n        [ 0.0742,  0.0963,  0.1252, -0.2998,  0.2438, -0.3275,  0.1221,  0.1132],\n        [-0.3365,  0.1725, -0.0941,  0.2459,  0.2403,  0.0789, -0.3106, -0.1842],\n        [-0.2499,  0.1392,  0.1974,  0.0153,  0.1355, -0.0199,  0.2976,  0.0712],\n        [-0.1711,  0.3450, -0.1957, -0.0604,  0.2784,  0.1898,  0.2965, -0.3167],\n        [ 0.3152, -0.3240,  0.0398,  0.1822,  0.3071, -0.1757,  0.1841, -0.0405],\n        [ 0.1095,  0.2248, -0.1226, -0.1921, -0.1861,  0.0558,  0.0258, -0.0105],\n        [ 0.1648, -0.3391,  0.3150, -0.2432,  0.0802,  0.1896, -0.0484,  0.3268]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0048,  0.0767, -0.0695, -0.0969, -0.0869,  0.1311,  0.1115, -0.1547,\n         0.1180,  0.0883,  0.0180, -0.1012, -0.0021, -0.1186,  0.1469,  0.1126],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.1412e-01,  1.5497e-01, -1.6326e-01,  8.8662e-02, -4.4109e-02,\n         -1.1888e-01,  1.4641e-01,  6.2694e-02,  1.5168e-01, -7.0855e-02,\n         -9.8582e-02, -1.6989e-01, -1.7571e-01, -1.0244e-01,  1.3143e-01,\n          1.2205e-02, -1.4300e-01,  1.1721e-01, -3.8632e-04, -4.9071e-02,\n          1.4261e-01, -4.2978e-02,  7.7065e-02,  1.0438e-01, -2.1384e-02,\n         -1.6034e-01,  6.1877e-02, -1.0387e-01,  1.7309e-01,  6.4221e-02,\n         -3.5120e-02, -1.1203e-01],\n        [-1.3544e-01, -1.6130e-01,  6.3691e-02,  9.5952e-02,  1.7118e-01,\n         -1.3379e-01,  1.0058e-01, -1.8460e-02,  1.4044e-01, -1.7609e-01,\n         -4.1209e-02, -7.2729e-02, -8.1104e-02, -1.0425e-01,  1.0767e-02,\n          1.5732e-01, -1.5483e-01,  2.7752e-03,  3.0838e-02,  1.5422e-01,\n          1.0304e-01, -1.7657e-01, -1.3175e-02, -5.6768e-02,  4.4590e-02,\n          1.3602e-01, -5.2524e-02, -3.9931e-02, -5.5170e-02,  2.0232e-02,\n         -7.4042e-02,  1.7164e-01],\n        [-2.9487e-02,  3.9454e-02, -1.7202e-01,  1.3102e-01, -1.7243e-01,\n         -1.0968e-01,  8.6662e-02,  1.2773e-01, -1.0798e-01,  6.0145e-02,\n          8.2314e-02,  1.3411e-01,  1.0571e-01,  7.6730e-04,  8.5526e-02,\n          9.0403e-02, -9.2827e-02,  9.9536e-03, -1.5774e-01,  1.0776e-01,\n          1.4442e-01,  8.8591e-02,  1.4936e-01,  1.0643e-01, -6.3004e-03,\n         -4.1757e-02,  1.8583e-02,  9.2345e-02,  6.5293e-03,  2.1078e-02,\n         -1.2691e-02,  1.4141e-01],\n        [ 6.5268e-02, -5.1516e-02,  1.9511e-03,  7.7245e-02, -1.1371e-01,\n         -1.1317e-01, -1.2135e-01,  1.8625e-02, -5.0607e-02,  1.5104e-01,\n          1.6176e-01, -2.3716e-02,  7.4082e-02, -3.7898e-02, -1.5887e-01,\n         -1.3944e-01,  2.6073e-02, -8.4204e-02,  8.0646e-02,  1.2913e-01,\n          1.5536e-02, -5.3667e-02, -7.6915e-02,  4.6193e-02, -5.1917e-02,\n          5.1877e-03,  8.0638e-02,  2.9481e-02, -1.5025e-01, -1.3167e-01,\n          1.3820e-01,  9.0475e-02],\n        [-8.3281e-02, -5.9130e-02, -6.0153e-03, -1.5402e-01, -5.8354e-02,\n          1.6508e-02, -4.6854e-02,  7.3294e-02, -7.6300e-03,  1.0094e-01,\n         -2.6166e-03, -1.7124e-01, -3.9183e-02,  7.2689e-03,  5.7205e-02,\n         -5.0661e-02,  7.4386e-02, -1.4095e-01, -6.2102e-02, -1.2188e-01,\n          4.2625e-02, -1.3296e-01,  6.6470e-02, -3.2055e-02, -1.6359e-01,\n         -1.6150e-02,  8.5976e-02,  6.2120e-02,  1.4411e-01,  1.1140e-01,\n          1.4552e-01, -9.9146e-02],\n        [-1.4280e-01, -1.1384e-01, -3.8966e-02, -1.0428e-01,  1.2604e-01,\n         -1.7246e-01, -5.6466e-02, -1.2294e-01, -1.2568e-01,  1.6383e-01,\n          2.3644e-03,  1.2394e-01,  2.6427e-02, -9.8865e-02, -2.7203e-02,\n         -1.2404e-01,  1.1343e-01, -1.7307e-01,  9.6824e-02,  6.0981e-02,\n         -1.1951e-01, -7.0854e-02, -3.7097e-03,  3.8757e-02,  3.2151e-02,\n         -7.1894e-02,  9.0826e-02,  4.6073e-02,  1.6102e-01, -8.7143e-02,\n          1.0713e-02,  4.4047e-02],\n        [-1.3397e-01,  8.3555e-02,  1.4909e-01,  4.5718e-03, -6.4370e-02,\n         -3.5903e-02, -7.3016e-02,  1.0481e-01, -1.0441e-01,  8.5695e-02,\n         -1.0822e-01,  4.2008e-03,  9.6619e-02,  1.4922e-01, -1.6497e-01,\n          2.0499e-02,  5.5183e-02,  1.3056e-01, -2.5322e-02, -1.0070e-01,\n         -2.1577e-02, -1.4017e-01, -2.6658e-03, -1.6581e-01,  9.9023e-02,\n          3.0250e-03, -4.5473e-02,  3.3406e-03,  4.0719e-02,  1.4234e-02,\n          1.2093e-01,  1.7251e-01],\n        [ 1.4052e-01,  1.4539e-01, -1.1733e-01,  1.9493e-02, -1.2221e-01,\n         -1.4551e-01,  2.4344e-02, -7.9955e-02, -1.0401e-01,  8.0435e-02,\n         -5.7105e-02,  3.3751e-02,  2.9280e-02,  1.2937e-01, -3.9760e-02,\n          1.3402e-01, -2.4071e-02, -8.5834e-03, -1.3760e-02,  1.3191e-01,\n         -3.9617e-02, -1.7267e-01,  4.5562e-02, -1.6726e-01, -8.5058e-02,\n         -1.2869e-01, -1.4430e-01, -6.4456e-02,  1.7650e-01,  1.1174e-01,\n         -9.2763e-02, -9.6203e-02],\n        [ 1.6530e-01,  1.5132e-01,  1.2226e-01,  5.9363e-02, -5.9570e-02,\n          4.7447e-03, -9.9386e-02,  6.9458e-02, -8.3329e-03, -5.8945e-02,\n          6.5624e-02,  2.2622e-02,  1.1984e-02,  1.1424e-01, -3.5165e-02,\n          2.2281e-02, -1.8651e-02, -6.1034e-02,  1.1102e-02, -1.2647e-01,\n         -2.9904e-03, -4.2846e-02, -1.0106e-01, -1.1962e-01,  1.4152e-01,\n          1.3304e-02,  2.1230e-02,  8.4990e-02, -1.2239e-01,  1.4229e-01,\n          1.2724e-01,  1.5569e-01],\n        [-1.1960e-01,  9.6549e-02,  2.5216e-02, -7.0007e-02, -9.9464e-02,\n          3.8494e-02, -1.5332e-01,  1.0812e-01, -9.4069e-02,  6.1573e-02,\n          1.3604e-01,  1.4750e-01, -1.6119e-01, -9.4100e-02, -6.1382e-02,\n          1.2346e-01, -2.3940e-02,  1.6276e-01,  1.5272e-01,  8.3548e-02,\n          5.4770e-05,  1.1746e-01,  7.7779e-02, -4.9223e-02, -1.0729e-01,\n          4.6243e-02,  1.3513e-01,  1.3135e-01, -9.5532e-02,  6.0265e-02,\n          9.4704e-04, -1.3979e-01],\n        [-1.1531e-01,  1.5069e-03, -3.4911e-02, -3.1862e-02,  1.5860e-01,\n          1.4020e-01,  4.5328e-02, -5.4320e-02,  8.7428e-02, -6.4410e-02,\n         -1.2854e-01,  1.4194e-01,  4.8004e-02,  9.7210e-03,  9.4802e-02,\n          9.0870e-02, -1.1474e-01, -1.7661e-01,  1.4881e-01,  1.0805e-01,\n         -6.1657e-02, -1.1720e-01,  3.4639e-02, -1.5871e-01,  1.1017e-01,\n          1.6411e-01,  2.1938e-02,  1.3834e-01, -8.6154e-02, -1.7580e-01,\n         -1.4325e-01,  1.2464e-01],\n        [ 7.2870e-02, -1.6010e-01, -9.0943e-02,  7.8377e-02,  2.3685e-02,\n          1.6612e-01, -1.1408e-02,  1.3356e-02,  1.1960e-01,  7.6639e-02,\n         -1.4626e-01,  1.0064e-01,  1.4610e-01,  1.3477e-01,  5.8580e-02,\n          1.6094e-01, -8.5266e-02, -1.2037e-01, -2.8693e-02, -1.6330e-01,\n         -1.2452e-01,  5.5511e-02, -4.9132e-02, -1.6438e-01,  9.1992e-02,\n         -1.0998e-01, -1.6482e-01, -2.5420e-02, -8.9763e-02,  7.8750e-03,\n          1.1445e-01,  1.1539e-01],\n        [ 2.0892e-02, -4.3188e-02, -1.1863e-01, -4.7884e-02, -2.8688e-02,\n         -3.1945e-02,  8.5890e-02, -5.0780e-02, -1.2259e-02,  3.8381e-04,\n         -1.3851e-01,  9.7530e-02, -8.5963e-02,  3.6767e-02,  8.6156e-02,\n         -1.7485e-01,  1.1911e-01, -1.1764e-01,  1.1042e-01, -7.9684e-02,\n         -1.2090e-01, -1.5718e-01, -1.3112e-01, -1.3841e-02,  8.1910e-02,\n         -1.2966e-01,  1.4195e-02, -1.1194e-01, -2.3427e-02,  8.7862e-02,\n          1.5875e-01,  4.7872e-02],\n        [-1.3659e-01, -6.2556e-02,  1.1301e-01,  1.0252e-01, -4.8768e-02,\n         -6.1050e-02,  1.6118e-01, -1.6427e-01, -6.3463e-02, -8.4789e-02,\n          5.0211e-02,  3.5505e-02, -1.1727e-01,  9.9078e-02, -1.7320e-01,\n         -1.0094e-01, -3.3475e-02,  1.4963e-01,  1.0531e-01, -3.9532e-02,\n         -7.0404e-04, -2.3769e-03,  2.1506e-02,  5.4433e-02,  1.4656e-01,\n         -1.3192e-01,  1.4283e-01, -8.4668e-02, -2.1788e-02, -1.7104e-01,\n         -8.0969e-02,  1.6739e-01],\n        [-1.0869e-02, -1.6665e-01, -9.4813e-02,  3.4133e-02,  1.7605e-01,\n         -1.4921e-01,  1.3110e-01, -1.1836e-01,  2.0938e-02,  3.7965e-02,\n          1.2861e-01,  1.4430e-01, -1.9087e-03,  9.3535e-02, -7.0197e-02,\n         -1.2176e-01, -2.4684e-02,  1.2943e-01,  2.5746e-02, -9.5483e-02,\n          4.2463e-02,  6.9259e-02,  1.5435e-01,  7.4325e-02, -4.4758e-02,\n         -1.2578e-01, -9.9505e-02, -4.0573e-02, -3.1400e-02, -3.3622e-02,\n          1.3087e-01,  1.6382e-01],\n        [ 1.2237e-01, -2.5306e-02, -3.1658e-02,  1.2514e-01,  9.8591e-02,\n          2.5503e-02,  1.5658e-01,  1.8797e-02, -3.8922e-02,  1.2326e-01,\n         -1.5478e-01, -1.3588e-02, -1.0561e-02, -3.2426e-02, -8.9975e-02,\n          1.6267e-01, -5.3832e-02,  1.5551e-01,  1.7504e-01,  9.3934e-02,\n         -1.0405e-01, -1.7159e-01, -1.5318e-01,  5.5738e-02,  5.1899e-02,\n         -1.7132e-01,  1.1500e-01,  6.0719e-02,  1.5668e-01, -1.3188e-01,\n          9.1801e-02,  1.1247e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1282,  0.0836,  0.0171, -0.1101,  0.0632,  0.1005,  0.0138,  0.1834],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.3310e-01,  2.3778e-01,  1.8773e-02, -2.0629e-01,  7.5413e-02,\n          9.0692e-02,  1.5383e-01, -1.3334e-01, -2.4049e-02, -3.3119e-02,\n          1.8251e-01, -1.5653e-01, -9.0536e-02,  1.2251e-01,  5.3669e-02,\n         -3.1916e-03],\n        [ 1.7948e-01, -2.2982e-01,  2.0687e-01, -2.0126e-01,  5.9698e-02,\n         -1.0179e-01, -3.3165e-02, -7.1557e-02,  2.2925e-01, -7.8416e-02,\n         -6.6670e-02, -1.6967e-01,  1.3045e-01, -2.3265e-01,  2.1088e-01,\n         -1.4825e-01],\n        [-3.7573e-02,  1.6147e-01, -2.0350e-01,  9.8837e-02, -3.7053e-03,\n          1.3216e-01, -1.0847e-01, -3.9088e-02, -2.8442e-02, -1.3187e-01,\n         -1.6849e-01, -1.2474e-01, -1.7494e-01,  2.4717e-02, -1.1758e-01,\n         -2.0465e-02],\n        [-1.6919e-01,  8.7707e-02,  8.8545e-02,  3.5603e-02,  1.2849e-01,\n         -6.8753e-02,  6.3175e-03, -2.4232e-04, -1.4313e-01, -1.8405e-01,\n          1.2866e-01,  9.4485e-02, -2.3156e-01, -3.8927e-02,  3.6924e-02,\n         -2.0735e-01],\n        [-6.7686e-02,  1.7743e-01,  2.7012e-02,  1.7274e-01, -2.2039e-01,\n          3.6865e-05,  2.1107e-01, -2.4235e-01,  9.8707e-02,  5.2089e-02,\n          2.0419e-01,  2.2789e-01,  2.9898e-02, -2.4974e-01, -2.2227e-01,\n          1.3968e-01],\n        [-2.3422e-01,  3.8085e-02, -1.8752e-01,  1.9514e-01, -1.5110e-01,\n         -2.1865e-01, -9.8699e-02,  3.3777e-03, -2.0858e-01, -2.4543e-01,\n         -2.3935e-01, -9.5385e-02,  1.7177e-01,  2.3504e-01, -9.7075e-02,\n          2.1194e-01],\n        [ 6.7360e-02,  8.0271e-02, -2.2464e-02, -1.0999e-01, -1.8586e-01,\n         -1.0966e-01, -4.3915e-02, -5.1718e-02, -1.0323e-01, -9.8593e-02,\n          1.3320e-02, -2.4684e-01,  4.2644e-03, -5.2245e-02,  1.9955e-01,\n         -2.2743e-01],\n        [-2.2133e-01, -2.2796e-01,  4.4824e-02,  1.4636e-01, -8.9578e-02,\n         -2.1570e-02,  2.3341e-01,  1.0701e-02, -1.3080e-01, -1.3566e-01,\n          2.4914e-02,  2.2633e-01,  8.0818e-02,  1.2845e-01,  3.9382e-02,\n         -1.3658e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2329], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0106,  0.3337,  0.2657,  0.0932, -0.0663, -0.0541, -0.2043,  0.0074]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0631,  0.0758,  0.1824, -0.0063,  0.0535,  0.0217, -0.2850,  0.3510],\n        [-0.1802,  0.1385,  0.2271,  0.0400,  0.1918,  0.2716,  0.0938,  0.1934],\n        [ 0.1645,  0.2987,  0.0909, -0.0950, -0.3532,  0.3503,  0.1133,  0.1308],\n        [ 0.2271,  0.3359,  0.1290, -0.1410, -0.2102, -0.2785, -0.1287, -0.2512],\n        [ 0.2092,  0.1787, -0.2532,  0.1803, -0.1371, -0.2613, -0.1564, -0.2873],\n        [-0.2618, -0.2010, -0.2450, -0.3172,  0.1970, -0.1952,  0.2585, -0.0228],\n        [ 0.2918, -0.1104, -0.0796, -0.0623, -0.1776, -0.1657,  0.0900,  0.1721],\n        [-0.2179, -0.2758,  0.1766,  0.1670,  0.1065,  0.0277, -0.0337, -0.1431],\n        [-0.1995,  0.2814,  0.1856, -0.0996, -0.1453,  0.1067, -0.1773,  0.1438],\n        [ 0.3025,  0.0657,  0.2053, -0.2606,  0.1751,  0.1466, -0.3092,  0.0663],\n        [-0.0164,  0.3184, -0.2021, -0.3233, -0.1084, -0.3361,  0.2315,  0.2367],\n        [ 0.0022,  0.1240, -0.1395,  0.1491, -0.2744,  0.2424,  0.0668,  0.3219],\n        [-0.3429, -0.1436, -0.2424, -0.2566, -0.3409, -0.3214, -0.0395, -0.2124],\n        [ 0.3050,  0.3235, -0.3398,  0.1106, -0.1436, -0.3091,  0.3524,  0.1366],\n        [ 0.2786,  0.1216,  0.1286, -0.1820, -0.1137, -0.1623,  0.0256, -0.2030],\n        [-0.2289, -0.2694, -0.1279,  0.1677, -0.0570,  0.0252,  0.3395,  0.2535],\n        [-0.3068,  0.0322,  0.0545,  0.0867,  0.2950,  0.0728,  0.0482,  0.3413],\n        [-0.1982,  0.3439,  0.1714,  0.1641,  0.3103, -0.0748, -0.2495, -0.2083],\n        [ 0.1035, -0.3043,  0.2367, -0.2199, -0.0831,  0.2066,  0.3454,  0.1704],\n        [ 0.1687, -0.2157,  0.1390,  0.0312,  0.3226, -0.2815, -0.0655,  0.2361],\n        [ 0.2644,  0.0615, -0.0711,  0.2510,  0.3454, -0.2616, -0.1843,  0.3327],\n        [ 0.2155, -0.2145, -0.0070, -0.1691,  0.3413, -0.2574,  0.0953, -0.1050],\n        [ 0.0950, -0.0485, -0.2716, -0.0173,  0.0861, -0.1406, -0.1815, -0.3105],\n        [-0.1003,  0.0343,  0.0593, -0.2861, -0.0022, -0.0788,  0.0626, -0.0189],\n        [ 0.1167, -0.0335,  0.2099, -0.0603, -0.1943, -0.0709,  0.1902, -0.3167],\n        [ 0.0742,  0.0963,  0.1252, -0.2998,  0.2438, -0.3275,  0.1221,  0.1132],\n        [-0.3365,  0.1725, -0.0941,  0.2459,  0.2403,  0.0789, -0.3106, -0.1842],\n        [-0.2499,  0.1392,  0.1974,  0.0153,  0.1355, -0.0199,  0.2976,  0.0712],\n        [-0.1711,  0.3450, -0.1957, -0.0604,  0.2784,  0.1898,  0.2965, -0.3167],\n        [ 0.3152, -0.3240,  0.0398,  0.1822,  0.3071, -0.1757,  0.1841, -0.0405],\n        [ 0.1095,  0.2248, -0.1226, -0.1921, -0.1861,  0.0558,  0.0258, -0.0105],\n        [ 0.1648, -0.3391,  0.3150, -0.2432,  0.0802,  0.1896, -0.0484,  0.3268]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3455,  0.2208, -0.2468, -0.2194, -0.2199,  0.3269,  0.2999,  0.0732,\n         0.0012,  0.0955, -0.2421,  0.0123, -0.1365, -0.1991,  0.1741,  0.3005,\n         0.2528, -0.1710, -0.0238,  0.0458, -0.1933, -0.0079, -0.1214, -0.1456,\n        -0.3358, -0.2870, -0.0632, -0.3139,  0.0473,  0.1517, -0.0508, -0.0228],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.1412e-01,  1.5497e-01, -1.6326e-01,  8.8662e-02, -4.4109e-02,\n         -1.1888e-01,  1.4641e-01,  6.2694e-02,  1.5168e-01, -7.0855e-02,\n         -9.8582e-02, -1.6989e-01, -1.7571e-01, -1.0244e-01,  1.3143e-01,\n          1.2205e-02, -1.4300e-01,  1.1721e-01, -3.8632e-04, -4.9071e-02,\n          1.4261e-01, -4.2978e-02,  7.7065e-02,  1.0438e-01, -2.1384e-02,\n         -1.6034e-01,  6.1877e-02, -1.0387e-01,  1.7309e-01,  6.4221e-02,\n         -3.5120e-02, -1.1203e-01],\n        [-1.3544e-01, -1.6130e-01,  6.3691e-02,  9.5952e-02,  1.7118e-01,\n         -1.3379e-01,  1.0058e-01, -1.8460e-02,  1.4044e-01, -1.7609e-01,\n         -4.1209e-02, -7.2729e-02, -8.1104e-02, -1.0425e-01,  1.0767e-02,\n          1.5732e-01, -1.5483e-01,  2.7752e-03,  3.0838e-02,  1.5422e-01,\n          1.0304e-01, -1.7657e-01, -1.3175e-02, -5.6768e-02,  4.4590e-02,\n          1.3602e-01, -5.2524e-02, -3.9931e-02, -5.5170e-02,  2.0232e-02,\n         -7.4042e-02,  1.7164e-01],\n        [-2.9487e-02,  3.9454e-02, -1.7202e-01,  1.3102e-01, -1.7243e-01,\n         -1.0968e-01,  8.6662e-02,  1.2773e-01, -1.0798e-01,  6.0145e-02,\n          8.2314e-02,  1.3411e-01,  1.0571e-01,  7.6730e-04,  8.5526e-02,\n          9.0403e-02, -9.2827e-02,  9.9536e-03, -1.5774e-01,  1.0776e-01,\n          1.4442e-01,  8.8591e-02,  1.4936e-01,  1.0643e-01, -6.3004e-03,\n         -4.1757e-02,  1.8583e-02,  9.2345e-02,  6.5293e-03,  2.1078e-02,\n         -1.2691e-02,  1.4141e-01],\n        [ 6.5268e-02, -5.1516e-02,  1.9511e-03,  7.7245e-02, -1.1371e-01,\n         -1.1317e-01, -1.2135e-01,  1.8625e-02, -5.0607e-02,  1.5104e-01,\n          1.6176e-01, -2.3716e-02,  7.4082e-02, -3.7898e-02, -1.5887e-01,\n         -1.3944e-01,  2.6073e-02, -8.4204e-02,  8.0646e-02,  1.2913e-01,\n          1.5536e-02, -5.3667e-02, -7.6915e-02,  4.6193e-02, -5.1917e-02,\n          5.1877e-03,  8.0638e-02,  2.9481e-02, -1.5025e-01, -1.3167e-01,\n          1.3820e-01,  9.0475e-02],\n        [-8.3281e-02, -5.9130e-02, -6.0153e-03, -1.5402e-01, -5.8354e-02,\n          1.6508e-02, -4.6854e-02,  7.3294e-02, -7.6300e-03,  1.0094e-01,\n         -2.6166e-03, -1.7124e-01, -3.9183e-02,  7.2689e-03,  5.7205e-02,\n         -5.0661e-02,  7.4386e-02, -1.4095e-01, -6.2102e-02, -1.2188e-01,\n          4.2625e-02, -1.3296e-01,  6.6470e-02, -3.2055e-02, -1.6359e-01,\n         -1.6150e-02,  8.5976e-02,  6.2120e-02,  1.4411e-01,  1.1140e-01,\n          1.4552e-01, -9.9146e-02],\n        [-1.4280e-01, -1.1384e-01, -3.8966e-02, -1.0428e-01,  1.2604e-01,\n         -1.7246e-01, -5.6466e-02, -1.2294e-01, -1.2568e-01,  1.6383e-01,\n          2.3644e-03,  1.2394e-01,  2.6427e-02, -9.8865e-02, -2.7203e-02,\n         -1.2404e-01,  1.1343e-01, -1.7307e-01,  9.6824e-02,  6.0981e-02,\n         -1.1951e-01, -7.0854e-02, -3.7097e-03,  3.8757e-02,  3.2151e-02,\n         -7.1894e-02,  9.0826e-02,  4.6073e-02,  1.6102e-01, -8.7143e-02,\n          1.0713e-02,  4.4047e-02],\n        [-1.3397e-01,  8.3555e-02,  1.4909e-01,  4.5718e-03, -6.4370e-02,\n         -3.5903e-02, -7.3016e-02,  1.0481e-01, -1.0441e-01,  8.5695e-02,\n         -1.0822e-01,  4.2008e-03,  9.6619e-02,  1.4922e-01, -1.6497e-01,\n          2.0499e-02,  5.5183e-02,  1.3056e-01, -2.5322e-02, -1.0070e-01,\n         -2.1577e-02, -1.4017e-01, -2.6658e-03, -1.6581e-01,  9.9023e-02,\n          3.0250e-03, -4.5473e-02,  3.3406e-03,  4.0719e-02,  1.4234e-02,\n          1.2093e-01,  1.7251e-01],\n        [ 1.4052e-01,  1.4539e-01, -1.1733e-01,  1.9493e-02, -1.2221e-01,\n         -1.4551e-01,  2.4344e-02, -7.9955e-02, -1.0401e-01,  8.0435e-02,\n         -5.7105e-02,  3.3751e-02,  2.9280e-02,  1.2937e-01, -3.9760e-02,\n          1.3402e-01, -2.4071e-02, -8.5834e-03, -1.3760e-02,  1.3191e-01,\n         -3.9617e-02, -1.7267e-01,  4.5562e-02, -1.6726e-01, -8.5058e-02,\n         -1.2869e-01, -1.4430e-01, -6.4456e-02,  1.7650e-01,  1.1174e-01,\n         -9.2763e-02, -9.6203e-02],\n        [ 1.6530e-01,  1.5132e-01,  1.2226e-01,  5.9363e-02, -5.9570e-02,\n          4.7447e-03, -9.9386e-02,  6.9458e-02, -8.3329e-03, -5.8945e-02,\n          6.5624e-02,  2.2622e-02,  1.1984e-02,  1.1424e-01, -3.5165e-02,\n          2.2281e-02, -1.8651e-02, -6.1034e-02,  1.1102e-02, -1.2647e-01,\n         -2.9904e-03, -4.2846e-02, -1.0106e-01, -1.1962e-01,  1.4152e-01,\n          1.3304e-02,  2.1230e-02,  8.4990e-02, -1.2239e-01,  1.4229e-01,\n          1.2724e-01,  1.5569e-01],\n        [-1.1960e-01,  9.6549e-02,  2.5216e-02, -7.0007e-02, -9.9464e-02,\n          3.8494e-02, -1.5332e-01,  1.0812e-01, -9.4069e-02,  6.1573e-02,\n          1.3604e-01,  1.4750e-01, -1.6119e-01, -9.4100e-02, -6.1382e-02,\n          1.2346e-01, -2.3940e-02,  1.6276e-01,  1.5272e-01,  8.3548e-02,\n          5.4770e-05,  1.1746e-01,  7.7779e-02, -4.9223e-02, -1.0729e-01,\n          4.6243e-02,  1.3513e-01,  1.3135e-01, -9.5532e-02,  6.0265e-02,\n          9.4704e-04, -1.3979e-01],\n        [-1.1531e-01,  1.5069e-03, -3.4911e-02, -3.1862e-02,  1.5860e-01,\n          1.4020e-01,  4.5328e-02, -5.4320e-02,  8.7428e-02, -6.4410e-02,\n         -1.2854e-01,  1.4194e-01,  4.8004e-02,  9.7210e-03,  9.4802e-02,\n          9.0870e-02, -1.1474e-01, -1.7661e-01,  1.4881e-01,  1.0805e-01,\n         -6.1657e-02, -1.1720e-01,  3.4639e-02, -1.5871e-01,  1.1017e-01,\n          1.6411e-01,  2.1938e-02,  1.3834e-01, -8.6154e-02, -1.7580e-01,\n         -1.4325e-01,  1.2464e-01],\n        [ 7.2870e-02, -1.6010e-01, -9.0943e-02,  7.8377e-02,  2.3685e-02,\n          1.6612e-01, -1.1408e-02,  1.3356e-02,  1.1960e-01,  7.6639e-02,\n         -1.4626e-01,  1.0064e-01,  1.4610e-01,  1.3477e-01,  5.8580e-02,\n          1.6094e-01, -8.5266e-02, -1.2037e-01, -2.8693e-02, -1.6330e-01,\n         -1.2452e-01,  5.5511e-02, -4.9132e-02, -1.6438e-01,  9.1992e-02,\n         -1.0998e-01, -1.6482e-01, -2.5420e-02, -8.9763e-02,  7.8750e-03,\n          1.1445e-01,  1.1539e-01],\n        [ 2.0892e-02, -4.3188e-02, -1.1863e-01, -4.7884e-02, -2.8688e-02,\n         -3.1945e-02,  8.5890e-02, -5.0780e-02, -1.2259e-02,  3.8381e-04,\n         -1.3851e-01,  9.7530e-02, -8.5963e-02,  3.6767e-02,  8.6156e-02,\n         -1.7485e-01,  1.1911e-01, -1.1764e-01,  1.1042e-01, -7.9684e-02,\n         -1.2090e-01, -1.5718e-01, -1.3112e-01, -1.3841e-02,  8.1910e-02,\n         -1.2966e-01,  1.4195e-02, -1.1194e-01, -2.3427e-02,  8.7862e-02,\n          1.5875e-01,  4.7872e-02],\n        [-1.3659e-01, -6.2556e-02,  1.1301e-01,  1.0252e-01, -4.8768e-02,\n         -6.1050e-02,  1.6118e-01, -1.6427e-01, -6.3463e-02, -8.4789e-02,\n          5.0211e-02,  3.5505e-02, -1.1727e-01,  9.9078e-02, -1.7320e-01,\n         -1.0094e-01, -3.3475e-02,  1.4963e-01,  1.0531e-01, -3.9532e-02,\n         -7.0404e-04, -2.3769e-03,  2.1506e-02,  5.4433e-02,  1.4656e-01,\n         -1.3192e-01,  1.4283e-01, -8.4668e-02, -2.1788e-02, -1.7104e-01,\n         -8.0969e-02,  1.6739e-01],\n        [-1.0869e-02, -1.6665e-01, -9.4813e-02,  3.4133e-02,  1.7605e-01,\n         -1.4921e-01,  1.3110e-01, -1.1836e-01,  2.0938e-02,  3.7965e-02,\n          1.2861e-01,  1.4430e-01, -1.9087e-03,  9.3535e-02, -7.0197e-02,\n         -1.2176e-01, -2.4684e-02,  1.2943e-01,  2.5746e-02, -9.5483e-02,\n          4.2463e-02,  6.9259e-02,  1.5435e-01,  7.4325e-02, -4.4758e-02,\n         -1.2578e-01, -9.9505e-02, -4.0573e-02, -3.1400e-02, -3.3622e-02,\n          1.3087e-01,  1.6382e-01],\n        [ 1.2237e-01, -2.5306e-02, -3.1658e-02,  1.2514e-01,  9.8591e-02,\n          2.5503e-02,  1.5658e-01,  1.8797e-02, -3.8922e-02,  1.2326e-01,\n         -1.5478e-01, -1.3588e-02, -1.0561e-02, -3.2426e-02, -8.9975e-02,\n          1.6267e-01, -5.3832e-02,  1.5551e-01,  1.7504e-01,  9.3934e-02,\n         -1.0405e-01, -1.7159e-01, -1.5318e-01,  5.5738e-02,  5.1899e-02,\n         -1.7132e-01,  1.1500e-01,  6.0719e-02,  1.5668e-01, -1.3188e-01,\n          9.1801e-02,  1.1247e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0048,  0.0767, -0.0695, -0.0969, -0.0869,  0.1311,  0.1115, -0.1547,\n         0.1180,  0.0883,  0.0180, -0.1012, -0.0021, -0.1186,  0.1469,  0.1126],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-2.3310e-01,  2.3778e-01,  1.8773e-02, -2.0629e-01,  7.5413e-02,\n          9.0692e-02,  1.5383e-01, -1.3334e-01, -2.4049e-02, -3.3119e-02,\n          1.8251e-01, -1.5653e-01, -9.0536e-02,  1.2251e-01,  5.3669e-02,\n         -3.1916e-03],\n        [ 1.7948e-01, -2.2982e-01,  2.0687e-01, -2.0126e-01,  5.9698e-02,\n         -1.0179e-01, -3.3165e-02, -7.1557e-02,  2.2925e-01, -7.8416e-02,\n         -6.6670e-02, -1.6967e-01,  1.3045e-01, -2.3265e-01,  2.1088e-01,\n         -1.4825e-01],\n        [-3.7573e-02,  1.6147e-01, -2.0350e-01,  9.8837e-02, -3.7053e-03,\n          1.3216e-01, -1.0847e-01, -3.9088e-02, -2.8442e-02, -1.3187e-01,\n         -1.6849e-01, -1.2474e-01, -1.7494e-01,  2.4717e-02, -1.1758e-01,\n         -2.0465e-02],\n        [-1.6919e-01,  8.7707e-02,  8.8545e-02,  3.5603e-02,  1.2849e-01,\n         -6.8753e-02,  6.3175e-03, -2.4232e-04, -1.4313e-01, -1.8405e-01,\n          1.2866e-01,  9.4485e-02, -2.3156e-01, -3.8927e-02,  3.6924e-02,\n         -2.0735e-01],\n        [-6.7686e-02,  1.7743e-01,  2.7012e-02,  1.7274e-01, -2.2039e-01,\n          3.6865e-05,  2.1107e-01, -2.4235e-01,  9.8707e-02,  5.2089e-02,\n          2.0419e-01,  2.2789e-01,  2.9898e-02, -2.4974e-01, -2.2227e-01,\n          1.3968e-01],\n        [-2.3422e-01,  3.8085e-02, -1.8752e-01,  1.9514e-01, -1.5110e-01,\n         -2.1865e-01, -9.8699e-02,  3.3777e-03, -2.0858e-01, -2.4543e-01,\n         -2.3935e-01, -9.5385e-02,  1.7177e-01,  2.3504e-01, -9.7075e-02,\n          2.1194e-01],\n        [ 6.7360e-02,  8.0271e-02, -2.2464e-02, -1.0999e-01, -1.8586e-01,\n         -1.0966e-01, -4.3915e-02, -5.1718e-02, -1.0323e-01, -9.8593e-02,\n          1.3320e-02, -2.4684e-01,  4.2644e-03, -5.2245e-02,  1.9955e-01,\n         -2.2743e-01],\n        [-2.2133e-01, -2.2796e-01,  4.4824e-02,  1.4636e-01, -8.9578e-02,\n         -2.1570e-02,  2.3341e-01,  1.0701e-02, -1.3080e-01, -1.3566e-01,\n          2.4914e-02,  2.2633e-01,  8.0818e-02,  1.2845e-01,  3.9382e-02,\n         -1.3658e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1282,  0.0836,  0.0171, -0.1101,  0.0632,  0.1005,  0.0138,  0.1834],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0106,  0.3337,  0.2657,  0.0932, -0.0663, -0.0541, -0.2043,  0.0074]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2329], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x1010ffe80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x171b6e560>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s160480000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s160480000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}