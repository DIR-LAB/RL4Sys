{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s161780000"
    },
    "q_lr":	0.0005,
    "seed":	161780000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7afb1b58d590>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=32, out_features=16, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=16, out_features=8, bias=True)\n    (9): ReLU()\n    (10): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=32, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=32, out_features=16, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=16, out_features=8, bias=True)\n  (9): ReLU()\n  (10): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0179,  0.2037, -0.1427, -0.1923,  0.0902,  0.0997,  0.2353,  0.2850,\n         0.0073, -0.1958, -0.1422, -0.3021,  0.1290,  0.3040, -0.1577, -0.1729,\n         0.2590, -0.1856, -0.2461, -0.0154, -0.1886,  0.1939, -0.1812, -0.2865,\n         0.1970,  0.2913, -0.0277,  0.0868,  0.0228,  0.1827, -0.3531,  0.3070,\n         0.2476, -0.1695,  0.1170,  0.3387,  0.0917, -0.2335,  0.3153, -0.1432,\n         0.1934, -0.2174, -0.1985, -0.0263, -0.3525, -0.1502,  0.3069, -0.0243,\n        -0.3493, -0.2037, -0.1495,  0.2471,  0.0813, -0.0885, -0.0013,  0.3383,\n         0.2120, -0.1349, -0.1617,  0.1102, -0.2021, -0.2745,  0.2393,  0.3122],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.0435e-02,  1.6516e-01, -1.5475e-01, -1.3506e-01,  5.6251e-02,\n          5.2453e-02, -5.9123e-02, -3.4224e-01],\n        [ 2.5202e-01,  4.0962e-02,  3.4342e-01,  2.2023e-01,  3.3759e-01,\n          9.5094e-03, -2.2830e-01, -2.3842e-04],\n        [ 1.3836e-01, -5.4746e-02,  2.8297e-01, -1.2856e-01,  1.0311e-01,\n          1.0395e-01,  2.6725e-01,  2.5555e-01],\n        [ 1.8699e-01, -1.8846e-01,  2.2683e-01,  5.6803e-02,  1.1584e-01,\n          1.8915e-02, -3.1792e-01, -1.4603e-01],\n        [-2.9464e-01, -2.8334e-01, -1.7586e-01, -9.1139e-02, -1.8707e-02,\n          3.1154e-01,  2.6865e-01, -1.1980e-02],\n        [-1.2221e-01,  3.4437e-01,  2.6137e-02, -3.1777e-01,  6.9204e-02,\n          1.6341e-01,  6.5642e-03,  2.8160e-01],\n        [ 5.6827e-02,  2.7375e-01, -9.5773e-02,  2.8439e-01,  3.2885e-01,\n         -1.4269e-02, -6.6514e-02, -2.4950e-01],\n        [ 2.2678e-01,  1.9648e-01,  1.8229e-01,  2.1316e-01, -3.1891e-01,\n          3.0519e-01, -3.0758e-02, -3.3663e-01],\n        [ 1.2274e-01, -2.2916e-01, -5.5106e-02,  2.6935e-01,  2.5772e-01,\n          6.3752e-02,  1.7586e-02,  1.0666e-01],\n        [-2.4280e-01,  2.5802e-01,  2.9146e-01,  2.1273e-01, -7.5707e-02,\n         -1.8861e-02, -7.0397e-02,  1.9966e-01],\n        [ 7.0538e-02,  2.9659e-01, -9.8419e-02,  3.4067e-01,  3.4335e-01,\n          2.4745e-01, -2.2380e-01, -1.2113e-01],\n        [-1.5234e-01,  5.6094e-02,  9.3237e-02,  1.0105e-02, -6.8304e-02,\n          2.8409e-02,  6.6074e-02, -2.1506e-01],\n        [ 5.9415e-02, -1.3176e-01, -2.0134e-01, -3.0099e-01,  3.3469e-01,\n         -1.7375e-01, -2.3710e-01,  3.3612e-01],\n        [-1.7377e-01, -6.4519e-02, -1.5476e-02, -2.8151e-01,  1.9013e-01,\n         -6.1427e-02, -2.8151e-01,  6.5015e-03],\n        [-2.0766e-01,  2.0108e-01,  3.4994e-01,  2.5452e-01,  1.8158e-01,\n          3.2198e-01,  2.1567e-01,  3.4973e-01],\n        [ 1.3258e-01,  1.3949e-01, -2.3397e-01, -1.8063e-01, -3.3005e-01,\n          2.5933e-01, -1.3319e-01,  2.2298e-02],\n        [ 9.9140e-02,  2.3897e-02, -2.9920e-01,  2.3407e-01,  3.3894e-01,\n         -7.7828e-02,  2.8536e-01,  1.7571e-02],\n        [ 8.7660e-02,  5.2793e-02, -3.4808e-01,  2.2777e-02,  2.6671e-01,\n         -8.8998e-02,  1.4964e-01, -1.8708e-01],\n        [-2.1362e-01,  3.3313e-01, -3.1853e-01,  1.0770e-01,  2.1296e-01,\n         -8.0241e-02, -8.0836e-02,  1.8219e-01],\n        [ 7.6354e-03, -2.6729e-01, -3.4819e-02, -2.1453e-01, -3.4911e-01,\n          1.8525e-01,  1.0280e-01, -2.4438e-01],\n        [-1.9668e-01,  2.0205e-01,  1.1653e-01, -1.2489e-01,  2.9898e-02,\n          8.9352e-02,  3.2382e-01,  1.9854e-01],\n        [-1.2752e-01, -8.7529e-03,  6.2986e-02,  1.8553e-01, -1.6177e-01,\n          1.9618e-01,  1.2883e-01, -1.9866e-01],\n        [-1.6767e-01,  3.9280e-02, -2.7622e-01,  1.7857e-01, -9.5330e-02,\n         -1.7684e-01,  3.3728e-01, -2.1567e-02],\n        [-1.0647e-01,  2.0032e-01,  1.6092e-01, -1.4726e-01,  1.6414e-01,\n         -1.0252e-01,  2.9121e-01, -2.2492e-02],\n        [-2.8454e-01,  2.2127e-01, -3.1653e-01,  3.1102e-02, -1.4538e-01,\n          2.6118e-01,  1.5366e-01, -3.3607e-01],\n        [ 1.9461e-01, -6.4715e-02, -4.1704e-02, -1.7166e-01,  1.6889e-01,\n          1.9862e-01,  5.7598e-02,  3.1304e-01],\n        [-1.5481e-01, -3.9788e-02, -2.0211e-02, -4.4944e-02,  3.5310e-01,\n          1.0161e-01,  2.4027e-01,  3.2995e-01],\n        [-2.3384e-01,  2.0317e-01,  1.2817e-01,  2.6881e-01,  8.1528e-02,\n         -1.2755e-01,  8.1470e-02,  1.1488e-02],\n        [-2.0870e-01, -7.4087e-02, -7.3325e-02, -5.4007e-02, -1.8427e-01,\n          2.8727e-01,  7.9969e-02, -1.3939e-01],\n        [-2.9269e-01,  7.5594e-02,  5.5521e-02, -2.1910e-01, -2.8995e-02,\n         -7.9217e-03,  3.5115e-01,  5.9366e-02],\n        [ 9.3653e-02,  2.9221e-01,  2.5706e-01, -5.0173e-02, -2.1591e-01,\n          1.1981e-01, -4.0326e-02,  3.1938e-01],\n        [ 3.2894e-01, -1.2670e-01, -4.7463e-03,  2.8156e-02, -1.1788e-01,\n          1.3810e-01, -2.5291e-01,  2.2326e-01],\n        [-1.8316e-01, -4.1002e-02,  3.6634e-02,  2.4082e-01,  3.2980e-01,\n         -9.1577e-03, -2.5272e-01,  1.4205e-01],\n        [ 2.8026e-01, -7.6661e-04,  2.7267e-01, -3.3969e-01,  2.3105e-01,\n          2.9082e-01, -2.1271e-01,  3.4635e-01],\n        [ 1.9978e-01,  4.0982e-02,  1.4783e-02, -1.0880e-01,  2.8570e-01,\n         -1.4669e-01, -8.3064e-02, -3.4467e-01],\n        [ 2.1374e-02,  2.2352e-01,  1.3275e-01, -2.8602e-01,  2.1002e-01,\n          2.7664e-02, -1.9711e-01,  1.9078e-01],\n        [ 3.1434e-02,  5.4699e-02, -3.4041e-01, -2.0330e-01, -2.3128e-01,\n          2.9048e-01,  1.6609e-01,  1.9392e-01],\n        [-2.5878e-01, -3.4538e-01,  1.7503e-01,  1.7706e-01, -1.7618e-01,\n         -3.2442e-01,  2.8913e-01,  1.5400e-01],\n        [-4.1862e-02,  1.8376e-01, -6.0377e-02, -1.8323e-01, -2.9668e-02,\n          1.3543e-01,  2.8396e-01, -6.7226e-02],\n        [-1.4553e-01, -8.7959e-03, -1.9921e-01,  1.8241e-01,  2.9179e-01,\n         -6.3304e-02,  2.7815e-01, -1.4630e-02],\n        [-1.6936e-01,  8.2328e-02, -3.0760e-02, -9.3416e-03, -6.7111e-02,\n          2.8866e-01,  3.2134e-01, -2.4612e-01],\n        [-1.6716e-01,  2.1037e-01, -9.1245e-03, -5.1100e-02,  3.1056e-01,\n          1.2738e-02, -1.3492e-01,  2.0217e-01],\n        [-2.3276e-01,  1.8283e-01, -1.6924e-01, -2.1733e-01, -2.3624e-01,\n         -1.4425e-02,  2.4935e-01,  2.9022e-01],\n        [ 2.2718e-01, -1.1520e-01, -1.8858e-01, -2.6733e-01, -2.6365e-01,\n          2.1217e-01, -1.8666e-01,  8.2085e-02],\n        [ 1.8983e-01, -1.1497e-01, -2.4885e-01,  3.4853e-01,  7.9713e-02,\n         -1.9642e-02, -1.3813e-01,  2.4094e-01],\n        [-2.7666e-01,  1.8517e-01, -2.1439e-01, -1.8012e-01,  1.3551e-02,\n          1.2915e-02,  2.9562e-01, -2.2031e-01],\n        [-1.3818e-01,  3.3853e-01, -8.3113e-02,  2.5537e-01, -9.3183e-02,\n         -2.4977e-01, -1.2748e-01,  3.5152e-01],\n        [-6.3841e-03, -3.1825e-01,  2.8022e-01,  2.2976e-02, -2.0979e-01,\n          2.7967e-01,  2.8291e-01,  3.0456e-01],\n        [-2.3457e-02,  1.8378e-01, -9.8195e-02, -4.7674e-02, -2.6571e-01,\n         -6.6536e-03, -2.6811e-01, -8.4680e-02],\n        [ 1.6706e-01,  1.4903e-01,  3.1483e-01,  1.0094e-01, -7.9541e-02,\n         -3.3057e-02,  5.2330e-04,  5.9623e-02],\n        [ 4.6780e-02,  1.3139e-01,  1.3002e-01,  1.5493e-01, -1.1571e-02,\n          2.8984e-02, -3.4308e-01, -2.8250e-01],\n        [ 1.3119e-01,  4.2471e-02,  8.5383e-02,  2.6244e-01, -1.9242e-01,\n         -8.3057e-02, -1.3424e-02, -2.0169e-02],\n        [-1.1328e-01, -1.6691e-01,  1.5614e-02, -2.9105e-01,  3.3360e-01,\n         -9.3722e-04,  3.7309e-03, -6.7744e-02],\n        [-3.2740e-01, -6.6637e-02, -2.7050e-02,  1.3956e-01, -8.7487e-02,\n          1.5112e-01,  2.8930e-01,  1.7637e-01],\n        [-4.5824e-03, -2.9269e-02,  1.6329e-01, -1.0052e-01,  2.2508e-02,\n          3.4738e-01,  7.9732e-02,  2.1091e-01],\n        [ 2.3490e-01,  2.1376e-01, -3.4528e-01,  1.2694e-01,  1.1171e-01,\n          3.4730e-02, -2.0836e-01,  3.1902e-01],\n        [-6.1759e-02,  5.0075e-02,  2.8380e-01,  2.1721e-01, -1.3818e-01,\n         -7.2740e-02, -5.2062e-02,  1.5037e-01],\n        [ 8.6711e-02,  2.4213e-01, -1.4442e-01, -2.3259e-01, -3.0290e-01,\n         -2.6491e-01, -1.9012e-01, -2.6294e-01],\n        [-2.7046e-01, -1.4098e-01, -9.3646e-02,  9.5501e-03, -2.9651e-01,\n          2.2696e-01,  3.3651e-01, -3.4291e-01],\n        [-1.5275e-01,  3.2784e-01,  3.5252e-01, -1.2674e-01,  1.7081e-01,\n          2.8190e-01,  4.9800e-02,  2.0754e-01],\n        [-3.6125e-02, -3.1829e-02,  3.4987e-01, -2.0447e-01,  1.3608e-01,\n          7.1674e-02, -3.5297e-01,  3.2971e-01],\n        [ 2.7278e-01,  2.8810e-01,  1.4673e-01, -1.3923e-01,  3.4873e-01,\n         -1.4616e-01, -9.0482e-02,  2.5274e-01],\n        [-9.3493e-02,  2.5536e-01,  2.0359e-01, -3.1994e-01, -2.4518e-01,\n          3.9201e-02, -7.0659e-02,  2.1291e-01],\n        [-8.5009e-02,  1.4840e-01, -1.0267e-01, -3.1588e-01,  1.4341e-02,\n         -2.4521e-02,  7.2670e-02, -1.0680e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "10":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1077], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1848, -0.0589, -0.0453,  0.0829,  0.1828,  0.1629,  0.0659,  0.3471]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=64, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-2.3873e-02, -8.0249e-02,  3.9373e-02, -1.0261e-02, -9.9259e-02,\n         9.2782e-02,  8.3089e-02, -4.0510e-02,  5.1153e-02,  3.2125e-04,\n        -9.7454e-02, -1.2498e-01,  1.0406e-01,  1.3547e-02, -8.2355e-02,\n         3.2950e-02,  9.0676e-02, -7.5515e-02,  1.0246e-01,  2.3990e-02,\n         9.7821e-02,  5.0151e-02,  2.1020e-02,  1.2408e-01,  5.4637e-02,\n        -9.9034e-02, -4.9569e-02, -1.7364e-02,  1.1882e-01,  9.5665e-05,\n        -3.9297e-02, -3.4806e-02,  1.1143e-01,  1.1370e-02, -8.4781e-02,\n         1.1783e-01,  1.1986e-01, -2.7613e-02, -4.2682e-02, -5.7944e-02,\n         1.0820e-02,  5.1297e-02,  1.3215e-03, -2.2392e-04, -5.8607e-02,\n         9.7660e-02, -1.0832e-01, -1.1020e-01, -5.0184e-02, -8.4397e-02,\n        -8.9418e-02, -2.5564e-02, -9.6378e-02,  7.4277e-02,  6.8952e-02,\n        -2.2024e-02,  6.3813e-02, -1.8772e-02, -6.5571e-02, -9.0725e-02,\n        -1.1950e-01, -7.0625e-02, -2.9541e-02,  1.0709e-01],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0237, -0.0845,  0.0803,  ...,  0.1183,  0.0734,  0.1049],\n        [-0.0785, -0.0237, -0.0348,  ...,  0.0053, -0.1206,  0.0328],\n        [-0.0430,  0.0646,  0.0134,  ...,  0.0035, -0.0529,  0.1010],\n        ...,\n        [-0.1065, -0.0175, -0.0561,  ..., -0.0394,  0.1057, -0.0985],\n        [ 0.0232, -0.0294,  0.0971,  ...,  0.0979, -0.0535,  0.0615],\n        [-0.0596,  0.0235,  0.0504,  ..., -0.0245, -0.0366,  0.0041]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=64, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0384,  0.0076,  0.0975,  0.0050,  0.0664,  0.1013, -0.0035,  0.0628,\n         0.0481,  0.0579, -0.0457,  0.1236,  0.0166, -0.0297,  0.1137, -0.1048,\n        -0.1195,  0.0693,  0.0144,  0.0348, -0.0296, -0.0466, -0.0296, -0.0288,\n         0.0153,  0.0348, -0.0424,  0.0253, -0.0662,  0.1208,  0.1194, -0.0961],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1235, -0.0909,  0.0116,  ...,  0.0880,  0.1127, -0.0362],\n        [ 0.0130,  0.0403, -0.0590,  ...,  0.0817, -0.0487, -0.1108],\n        [-0.0355, -0.0997,  0.0931,  ...,  0.0708, -0.0464,  0.1019],\n        ...,\n        [-0.0273, -0.0668,  0.0414,  ...,  0.0014,  0.1144,  0.0692],\n        [-0.1200,  0.0697, -0.0695,  ...,  0.0705,  0.0690, -0.0377],\n        [ 0.0433, -0.1048,  0.0413,  ..., -0.0444,  0.0264,  0.1134]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0973, -0.0259,  0.0872, -0.1025,  0.1174, -0.0025, -0.1375, -0.1049,\n         0.1512, -0.0004,  0.1501,  0.1384, -0.1408, -0.0992,  0.1414, -0.0346],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1258,  0.0515,  0.1453,  0.1139,  0.1167, -0.0723, -0.1660, -0.0561,\n          0.1436, -0.1764, -0.1403, -0.0164,  0.0435,  0.0527, -0.0487,  0.0224,\n         -0.1541,  0.1716,  0.0401,  0.1356, -0.1003,  0.0857,  0.1208,  0.1128,\n         -0.0017, -0.0238, -0.0002, -0.0159,  0.0967,  0.0391, -0.1090,  0.0138],\n        [-0.0359, -0.0272, -0.0746,  0.1475,  0.1322, -0.0987, -0.0114,  0.0036,\n          0.1311, -0.0548,  0.1503, -0.0235, -0.0096,  0.1233,  0.0911, -0.0374,\n          0.0009, -0.0274, -0.0582,  0.0098,  0.0386,  0.1091,  0.0998, -0.1457,\n         -0.0737, -0.1500, -0.0015,  0.1678, -0.1512, -0.0536, -0.0263, -0.0484],\n        [ 0.1598,  0.0950,  0.0020,  0.1677, -0.0153, -0.0825,  0.1760, -0.1580,\n         -0.0833,  0.1445,  0.0446, -0.0507, -0.0979, -0.0916,  0.1527, -0.0371,\n         -0.0155,  0.0438, -0.1756,  0.0418, -0.1168, -0.1280,  0.0446,  0.1035,\n          0.0081,  0.0868, -0.1275,  0.0960, -0.0274,  0.1283,  0.1017, -0.1676],\n        [ 0.0201, -0.0108,  0.1051,  0.0524, -0.0079, -0.0115,  0.1333,  0.1257,\n          0.0904, -0.0187, -0.0635, -0.0345,  0.1653, -0.1090, -0.1327, -0.0374,\n          0.0258,  0.1708,  0.1447, -0.0225, -0.1767, -0.0970,  0.1381,  0.0902,\n         -0.0359,  0.1598, -0.1175, -0.1679, -0.0753,  0.0384, -0.0914, -0.0269],\n        [ 0.1588, -0.1247,  0.0449,  0.1156,  0.1038, -0.1212, -0.0202, -0.0010,\n          0.1516, -0.0744, -0.1470,  0.1378,  0.1073, -0.1025, -0.0399, -0.0269,\n          0.1656, -0.0015, -0.0203, -0.1108, -0.0074, -0.0095, -0.1461,  0.0970,\n         -0.0784, -0.0500,  0.0969,  0.0569, -0.1028,  0.1333, -0.0050,  0.0263],\n        [-0.0958, -0.1010,  0.0453, -0.0144,  0.0846,  0.1209, -0.1117, -0.1289,\n         -0.1346,  0.1157,  0.0170,  0.0410,  0.0569, -0.1230,  0.1507, -0.0120,\n         -0.1265,  0.1483,  0.1276,  0.0572,  0.0347,  0.1013, -0.1057, -0.0305,\n          0.0804, -0.0305,  0.1128, -0.1592, -0.0177, -0.0378, -0.0695,  0.0174],\n        [-0.1644,  0.0131,  0.0129, -0.0535,  0.0570, -0.0792, -0.1072,  0.1423,\n         -0.0261,  0.1335, -0.1097,  0.0462,  0.0798,  0.0291, -0.0864, -0.1368,\n          0.0145,  0.1331,  0.1211, -0.1682,  0.1605, -0.1167, -0.0322,  0.1576,\n          0.0059, -0.1230, -0.1134, -0.0913, -0.0562, -0.0631, -0.1143, -0.1225],\n        [-0.0043,  0.1281,  0.1376, -0.0284,  0.1043, -0.0550,  0.0336,  0.1497,\n         -0.0132,  0.0590, -0.1195, -0.1723,  0.0506, -0.1180, -0.1696, -0.1737,\n          0.1440,  0.0600,  0.0205, -0.1076,  0.1241,  0.0413,  0.1444,  0.1468,\n         -0.0437,  0.0338, -0.1251,  0.0107,  0.0098, -0.1676, -0.0632,  0.1476],\n        [ 0.0811,  0.0223,  0.1572, -0.0298, -0.0236,  0.1436,  0.0165,  0.1435,\n         -0.1102, -0.0566, -0.0519,  0.0358, -0.0793,  0.0174,  0.0944, -0.1545,\n         -0.0519,  0.1484,  0.0121,  0.1178, -0.0321, -0.1340,  0.0176,  0.1159,\n         -0.1373, -0.0412, -0.1658,  0.0917, -0.1238,  0.0694,  0.1700,  0.0245],\n        [ 0.0741, -0.1332, -0.0750,  0.0760, -0.0276, -0.1644,  0.0932, -0.0203,\n         -0.1445, -0.0557,  0.0775,  0.0216,  0.1305,  0.0695, -0.0463, -0.1066,\n         -0.0283,  0.1386,  0.1453,  0.0759,  0.1591,  0.0609,  0.0573,  0.0534,\n          0.0858,  0.0615,  0.1555,  0.0723,  0.0208, -0.0039, -0.1600, -0.1526],\n        [-0.0395, -0.0958, -0.1382,  0.0576, -0.0653, -0.0138,  0.0535, -0.0857,\n         -0.0587,  0.0843,  0.1415,  0.1673, -0.1057, -0.1047,  0.1393, -0.1062,\n         -0.0149, -0.1247, -0.1760, -0.1481, -0.0383,  0.0323, -0.1739, -0.0285,\n         -0.0673,  0.0385,  0.1289,  0.0038, -0.1561,  0.1583, -0.1526, -0.0882],\n        [ 0.0051,  0.0295,  0.1504, -0.0421,  0.0335,  0.0793, -0.1075, -0.0837,\n         -0.1387, -0.0260, -0.0201,  0.0624,  0.1272, -0.1764,  0.1284,  0.0519,\n          0.0465,  0.1230, -0.0494,  0.0699, -0.1377, -0.1330, -0.0252,  0.0556,\n         -0.0393, -0.0146,  0.0052, -0.1278, -0.0830,  0.1227,  0.1517,  0.0740],\n        [-0.1639, -0.0283,  0.1492,  0.0655,  0.0328, -0.1457, -0.0498,  0.0882,\n         -0.0331,  0.0492,  0.0291,  0.1281, -0.0647, -0.0495,  0.1547, -0.0960,\n          0.0643, -0.0881, -0.0421, -0.0703, -0.0451, -0.0726, -0.0652,  0.0213,\n         -0.1447,  0.0581,  0.0173, -0.0234, -0.1236,  0.1377, -0.1124, -0.0947],\n        [-0.1447,  0.0701,  0.0933, -0.0843,  0.0830, -0.1491,  0.1634, -0.0898,\n         -0.0459, -0.0022,  0.1209,  0.0142, -0.0509,  0.1607,  0.0056,  0.0975,\n          0.0159, -0.1521,  0.1086, -0.0299,  0.1617,  0.1215, -0.1553,  0.1578,\n         -0.0744, -0.1594, -0.0212,  0.1525, -0.0196,  0.0625,  0.0141, -0.0785],\n        [ 0.0638, -0.0211,  0.1425,  0.1161, -0.0519, -0.1561, -0.1141,  0.0803,\n          0.0967,  0.1598, -0.0006,  0.1396, -0.1515, -0.1406,  0.0997, -0.0782,\n          0.0171, -0.0738,  0.0309, -0.1007,  0.0545, -0.1697, -0.1002,  0.1611,\n          0.0897, -0.1060,  0.0570,  0.0869, -0.0675,  0.0512,  0.1337, -0.0722],\n        [-0.1491, -0.0964,  0.1383, -0.1523,  0.0091, -0.0934,  0.0215, -0.1074,\n          0.1640, -0.0039, -0.0145,  0.1689, -0.1008, -0.0640, -0.1656, -0.0333,\n         -0.0732, -0.0730, -0.1604, -0.0431, -0.0271,  0.0670, -0.1297,  0.0227,\n          0.1292,  0.0624,  0.0875, -0.1314, -0.0818,  0.1110,  0.1600, -0.1102]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "7":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "8":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0586, -0.1755,  0.1370, -0.2369,  0.0690,  0.0518, -0.1605,  0.0381],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2036, -0.1916,  0.0214,  0.2388, -0.2493,  0.2222, -0.2255,  0.0756,\n         -0.0499,  0.1560,  0.2155,  0.2345,  0.0554,  0.1855, -0.2412, -0.1052],\n        [ 0.2224,  0.1643, -0.1345, -0.0058, -0.2177,  0.0368, -0.2090,  0.0260,\n         -0.1353,  0.1228,  0.0661,  0.0817,  0.1399,  0.1484,  0.1619,  0.1863],\n        [ 0.0841,  0.1098, -0.1565, -0.0749,  0.0917,  0.0321,  0.1901,  0.1879,\n          0.2484,  0.0456, -0.1782,  0.1762, -0.1163,  0.0537, -0.2454, -0.0329],\n        [ 0.2465, -0.2282,  0.1831,  0.1089, -0.1868, -0.2189, -0.0310,  0.1248,\n         -0.0549,  0.1883, -0.2354,  0.0772, -0.1843, -0.1806,  0.1147,  0.0537],\n        [ 0.0478, -0.1039,  0.2425, -0.0559, -0.1881,  0.0766, -0.1629,  0.0572,\n          0.1240, -0.0213, -0.0577, -0.2326,  0.2482, -0.0400,  0.2109,  0.0915],\n        [-0.0628,  0.1608,  0.1561, -0.0158, -0.0704, -0.0981,  0.0543, -0.0809,\n          0.0370, -0.2379,  0.0411,  0.0933, -0.0831, -0.2190,  0.1480,  0.0773],\n        [-0.1675, -0.1287, -0.0791, -0.1744, -0.1289,  0.0952, -0.1690,  0.0825,\n         -0.2214, -0.1427,  0.1839, -0.1993, -0.0480,  0.0721,  0.0642, -0.2071],\n        [-0.0048,  0.0098, -0.1544, -0.0444, -0.0976,  0.1188,  0.1734,  0.0977,\n          0.1794, -0.0025,  0.0553,  0.1297,  0.2235, -0.0240,  0.1697, -0.2281]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "9":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 1.0435e-02,  1.6516e-01, -1.5475e-01, -1.3506e-01,  5.6251e-02,\n          5.2453e-02, -5.9123e-02, -3.4224e-01],\n        [ 2.5202e-01,  4.0962e-02,  3.4342e-01,  2.2023e-01,  3.3759e-01,\n          9.5094e-03, -2.2830e-01, -2.3842e-04],\n        [ 1.3836e-01, -5.4746e-02,  2.8297e-01, -1.2856e-01,  1.0311e-01,\n          1.0395e-01,  2.6725e-01,  2.5555e-01],\n        [ 1.8699e-01, -1.8846e-01,  2.2683e-01,  5.6803e-02,  1.1584e-01,\n          1.8915e-02, -3.1792e-01, -1.4603e-01],\n        [-2.9464e-01, -2.8334e-01, -1.7586e-01, -9.1139e-02, -1.8707e-02,\n          3.1154e-01,  2.6865e-01, -1.1980e-02],\n        [-1.2221e-01,  3.4437e-01,  2.6137e-02, -3.1777e-01,  6.9204e-02,\n          1.6341e-01,  6.5642e-03,  2.8160e-01],\n        [ 5.6827e-02,  2.7375e-01, -9.5773e-02,  2.8439e-01,  3.2885e-01,\n         -1.4269e-02, -6.6514e-02, -2.4950e-01],\n        [ 2.2678e-01,  1.9648e-01,  1.8229e-01,  2.1316e-01, -3.1891e-01,\n          3.0519e-01, -3.0758e-02, -3.3663e-01],\n        [ 1.2274e-01, -2.2916e-01, -5.5106e-02,  2.6935e-01,  2.5772e-01,\n          6.3752e-02,  1.7586e-02,  1.0666e-01],\n        [-2.4280e-01,  2.5802e-01,  2.9146e-01,  2.1273e-01, -7.5707e-02,\n         -1.8861e-02, -7.0397e-02,  1.9966e-01],\n        [ 7.0538e-02,  2.9659e-01, -9.8419e-02,  3.4067e-01,  3.4335e-01,\n          2.4745e-01, -2.2380e-01, -1.2113e-01],\n        [-1.5234e-01,  5.6094e-02,  9.3237e-02,  1.0105e-02, -6.8304e-02,\n          2.8409e-02,  6.6074e-02, -2.1506e-01],\n        [ 5.9415e-02, -1.3176e-01, -2.0134e-01, -3.0099e-01,  3.3469e-01,\n         -1.7375e-01, -2.3710e-01,  3.3612e-01],\n        [-1.7377e-01, -6.4519e-02, -1.5476e-02, -2.8151e-01,  1.9013e-01,\n         -6.1427e-02, -2.8151e-01,  6.5015e-03],\n        [-2.0766e-01,  2.0108e-01,  3.4994e-01,  2.5452e-01,  1.8158e-01,\n          3.2198e-01,  2.1567e-01,  3.4973e-01],\n        [ 1.3258e-01,  1.3949e-01, -2.3397e-01, -1.8063e-01, -3.3005e-01,\n          2.5933e-01, -1.3319e-01,  2.2298e-02],\n        [ 9.9140e-02,  2.3897e-02, -2.9920e-01,  2.3407e-01,  3.3894e-01,\n         -7.7828e-02,  2.8536e-01,  1.7571e-02],\n        [ 8.7660e-02,  5.2793e-02, -3.4808e-01,  2.2777e-02,  2.6671e-01,\n         -8.8998e-02,  1.4964e-01, -1.8708e-01],\n        [-2.1362e-01,  3.3313e-01, -3.1853e-01,  1.0770e-01,  2.1296e-01,\n         -8.0241e-02, -8.0836e-02,  1.8219e-01],\n        [ 7.6354e-03, -2.6729e-01, -3.4819e-02, -2.1453e-01, -3.4911e-01,\n          1.8525e-01,  1.0280e-01, -2.4438e-01],\n        [-1.9668e-01,  2.0205e-01,  1.1653e-01, -1.2489e-01,  2.9898e-02,\n          8.9352e-02,  3.2382e-01,  1.9854e-01],\n        [-1.2752e-01, -8.7529e-03,  6.2986e-02,  1.8553e-01, -1.6177e-01,\n          1.9618e-01,  1.2883e-01, -1.9866e-01],\n        [-1.6767e-01,  3.9280e-02, -2.7622e-01,  1.7857e-01, -9.5330e-02,\n         -1.7684e-01,  3.3728e-01, -2.1567e-02],\n        [-1.0647e-01,  2.0032e-01,  1.6092e-01, -1.4726e-01,  1.6414e-01,\n         -1.0252e-01,  2.9121e-01, -2.2492e-02],\n        [-2.8454e-01,  2.2127e-01, -3.1653e-01,  3.1102e-02, -1.4538e-01,\n          2.6118e-01,  1.5366e-01, -3.3607e-01],\n        [ 1.9461e-01, -6.4715e-02, -4.1704e-02, -1.7166e-01,  1.6889e-01,\n          1.9862e-01,  5.7598e-02,  3.1304e-01],\n        [-1.5481e-01, -3.9788e-02, -2.0211e-02, -4.4944e-02,  3.5310e-01,\n          1.0161e-01,  2.4027e-01,  3.2995e-01],\n        [-2.3384e-01,  2.0317e-01,  1.2817e-01,  2.6881e-01,  8.1528e-02,\n         -1.2755e-01,  8.1470e-02,  1.1488e-02],\n        [-2.0870e-01, -7.4087e-02, -7.3325e-02, -5.4007e-02, -1.8427e-01,\n          2.8727e-01,  7.9969e-02, -1.3939e-01],\n        [-2.9269e-01,  7.5594e-02,  5.5521e-02, -2.1910e-01, -2.8995e-02,\n         -7.9217e-03,  3.5115e-01,  5.9366e-02],\n        [ 9.3653e-02,  2.9221e-01,  2.5706e-01, -5.0173e-02, -2.1591e-01,\n          1.1981e-01, -4.0326e-02,  3.1938e-01],\n        [ 3.2894e-01, -1.2670e-01, -4.7463e-03,  2.8156e-02, -1.1788e-01,\n          1.3810e-01, -2.5291e-01,  2.2326e-01],\n        [-1.8316e-01, -4.1002e-02,  3.6634e-02,  2.4082e-01,  3.2980e-01,\n         -9.1577e-03, -2.5272e-01,  1.4205e-01],\n        [ 2.8026e-01, -7.6661e-04,  2.7267e-01, -3.3969e-01,  2.3105e-01,\n          2.9082e-01, -2.1271e-01,  3.4635e-01],\n        [ 1.9978e-01,  4.0982e-02,  1.4783e-02, -1.0880e-01,  2.8570e-01,\n         -1.4669e-01, -8.3064e-02, -3.4467e-01],\n        [ 2.1374e-02,  2.2352e-01,  1.3275e-01, -2.8602e-01,  2.1002e-01,\n          2.7664e-02, -1.9711e-01,  1.9078e-01],\n        [ 3.1434e-02,  5.4699e-02, -3.4041e-01, -2.0330e-01, -2.3128e-01,\n          2.9048e-01,  1.6609e-01,  1.9392e-01],\n        [-2.5878e-01, -3.4538e-01,  1.7503e-01,  1.7706e-01, -1.7618e-01,\n         -3.2442e-01,  2.8913e-01,  1.5400e-01],\n        [-4.1862e-02,  1.8376e-01, -6.0377e-02, -1.8323e-01, -2.9668e-02,\n          1.3543e-01,  2.8396e-01, -6.7226e-02],\n        [-1.4553e-01, -8.7959e-03, -1.9921e-01,  1.8241e-01,  2.9179e-01,\n         -6.3304e-02,  2.7815e-01, -1.4630e-02],\n        [-1.6936e-01,  8.2328e-02, -3.0760e-02, -9.3416e-03, -6.7111e-02,\n          2.8866e-01,  3.2134e-01, -2.4612e-01],\n        [-1.6716e-01,  2.1037e-01, -9.1245e-03, -5.1100e-02,  3.1056e-01,\n          1.2738e-02, -1.3492e-01,  2.0217e-01],\n        [-2.3276e-01,  1.8283e-01, -1.6924e-01, -2.1733e-01, -2.3624e-01,\n         -1.4425e-02,  2.4935e-01,  2.9022e-01],\n        [ 2.2718e-01, -1.1520e-01, -1.8858e-01, -2.6733e-01, -2.6365e-01,\n          2.1217e-01, -1.8666e-01,  8.2085e-02],\n        [ 1.8983e-01, -1.1497e-01, -2.4885e-01,  3.4853e-01,  7.9713e-02,\n         -1.9642e-02, -1.3813e-01,  2.4094e-01],\n        [-2.7666e-01,  1.8517e-01, -2.1439e-01, -1.8012e-01,  1.3551e-02,\n          1.2915e-02,  2.9562e-01, -2.2031e-01],\n        [-1.3818e-01,  3.3853e-01, -8.3113e-02,  2.5537e-01, -9.3183e-02,\n         -2.4977e-01, -1.2748e-01,  3.5152e-01],\n        [-6.3841e-03, -3.1825e-01,  2.8022e-01,  2.2976e-02, -2.0979e-01,\n          2.7967e-01,  2.8291e-01,  3.0456e-01],\n        [-2.3457e-02,  1.8378e-01, -9.8195e-02, -4.7674e-02, -2.6571e-01,\n         -6.6536e-03, -2.6811e-01, -8.4680e-02],\n        [ 1.6706e-01,  1.4903e-01,  3.1483e-01,  1.0094e-01, -7.9541e-02,\n         -3.3057e-02,  5.2330e-04,  5.9623e-02],\n        [ 4.6780e-02,  1.3139e-01,  1.3002e-01,  1.5493e-01, -1.1571e-02,\n          2.8984e-02, -3.4308e-01, -2.8250e-01],\n        [ 1.3119e-01,  4.2471e-02,  8.5383e-02,  2.6244e-01, -1.9242e-01,\n         -8.3057e-02, -1.3424e-02, -2.0169e-02],\n        [-1.1328e-01, -1.6691e-01,  1.5614e-02, -2.9105e-01,  3.3360e-01,\n         -9.3722e-04,  3.7309e-03, -6.7744e-02],\n        [-3.2740e-01, -6.6637e-02, -2.7050e-02,  1.3956e-01, -8.7487e-02,\n          1.5112e-01,  2.8930e-01,  1.7637e-01],\n        [-4.5824e-03, -2.9269e-02,  1.6329e-01, -1.0052e-01,  2.2508e-02,\n          3.4738e-01,  7.9732e-02,  2.1091e-01],\n        [ 2.3490e-01,  2.1376e-01, -3.4528e-01,  1.2694e-01,  1.1171e-01,\n          3.4730e-02, -2.0836e-01,  3.1902e-01],\n        [-6.1759e-02,  5.0075e-02,  2.8380e-01,  2.1721e-01, -1.3818e-01,\n         -7.2740e-02, -5.2062e-02,  1.5037e-01],\n        [ 8.6711e-02,  2.4213e-01, -1.4442e-01, -2.3259e-01, -3.0290e-01,\n         -2.6491e-01, -1.9012e-01, -2.6294e-01],\n        [-2.7046e-01, -1.4098e-01, -9.3646e-02,  9.5501e-03, -2.9651e-01,\n          2.2696e-01,  3.3651e-01, -3.4291e-01],\n        [-1.5275e-01,  3.2784e-01,  3.5252e-01, -1.2674e-01,  1.7081e-01,\n          2.8190e-01,  4.9800e-02,  2.0754e-01],\n        [-3.6125e-02, -3.1829e-02,  3.4987e-01, -2.0447e-01,  1.3608e-01,\n          7.1674e-02, -3.5297e-01,  3.2971e-01],\n        [ 2.7278e-01,  2.8810e-01,  1.4673e-01, -1.3923e-01,  3.4873e-01,\n         -1.4616e-01, -9.0482e-02,  2.5274e-01],\n        [-9.3493e-02,  2.5536e-01,  2.0359e-01, -3.1994e-01, -2.4518e-01,\n          3.9201e-02, -7.0659e-02,  2.1291e-01],\n        [-8.5009e-02,  1.4840e-01, -1.0267e-01, -3.1588e-01,  1.4341e-02,\n         -2.4521e-02,  7.2670e-02, -1.0680e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0179,  0.2037, -0.1427, -0.1923,  0.0902,  0.0997,  0.2353,  0.2850,\n         0.0073, -0.1958, -0.1422, -0.3021,  0.1290,  0.3040, -0.1577, -0.1729,\n         0.2590, -0.1856, -0.2461, -0.0154, -0.1886,  0.1939, -0.1812, -0.2865,\n         0.1970,  0.2913, -0.0277,  0.0868,  0.0228,  0.1827, -0.3531,  0.3070,\n         0.2476, -0.1695,  0.1170,  0.3387,  0.0917, -0.2335,  0.3153, -0.1432,\n         0.1934, -0.2174, -0.1985, -0.0263, -0.3525, -0.1502,  0.3069, -0.0243,\n        -0.3493, -0.2037, -0.1495,  0.2471,  0.0813, -0.0885, -0.0013,  0.3383,\n         0.2120, -0.1349, -0.1617,  0.1102, -0.2021, -0.2745,  0.2393,  0.3122],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0237, -0.0845,  0.0803,  ...,  0.1183,  0.0734,  0.1049],\n        [-0.0785, -0.0237, -0.0348,  ...,  0.0053, -0.1206,  0.0328],\n        [-0.0430,  0.0646,  0.0134,  ...,  0.0035, -0.0529,  0.1010],\n        ...,\n        [-0.1065, -0.0175, -0.0561,  ..., -0.0394,  0.1057, -0.0985],\n        [ 0.0232, -0.0294,  0.0971,  ...,  0.0979, -0.0535,  0.0615],\n        [-0.0596,  0.0235,  0.0504,  ..., -0.0245, -0.0366,  0.0041]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-2.3873e-02, -8.0249e-02,  3.9373e-02, -1.0261e-02, -9.9259e-02,\n         9.2782e-02,  8.3089e-02, -4.0510e-02,  5.1153e-02,  3.2125e-04,\n        -9.7454e-02, -1.2498e-01,  1.0406e-01,  1.3547e-02, -8.2355e-02,\n         3.2950e-02,  9.0676e-02, -7.5515e-02,  1.0246e-01,  2.3990e-02,\n         9.7821e-02,  5.0151e-02,  2.1020e-02,  1.2408e-01,  5.4637e-02,\n        -9.9034e-02, -4.9569e-02, -1.7364e-02,  1.1882e-01,  9.5665e-05,\n        -3.9297e-02, -3.4806e-02,  1.1143e-01,  1.1370e-02, -8.4781e-02,\n         1.1783e-01,  1.1986e-01, -2.7613e-02, -4.2682e-02, -5.7944e-02,\n         1.0820e-02,  5.1297e-02,  1.3215e-03, -2.2392e-04, -5.8607e-02,\n         9.7660e-02, -1.0832e-01, -1.1020e-01, -5.0184e-02, -8.4397e-02,\n        -8.9418e-02, -2.5564e-02, -9.6378e-02,  7.4277e-02,  6.8952e-02,\n        -2.2024e-02,  6.3813e-02, -1.8772e-02, -6.5571e-02, -9.0725e-02,\n        -1.1950e-01, -7.0625e-02, -2.9541e-02,  1.0709e-01],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1235, -0.0909,  0.0116,  ...,  0.0880,  0.1127, -0.0362],\n        [ 0.0130,  0.0403, -0.0590,  ...,  0.0817, -0.0487, -0.1108],\n        [-0.0355, -0.0997,  0.0931,  ...,  0.0708, -0.0464,  0.1019],\n        ...,\n        [-0.0273, -0.0668,  0.0414,  ...,  0.0014,  0.1144,  0.0692],\n        [-0.1200,  0.0697, -0.0695,  ...,  0.0705,  0.0690, -0.0377],\n        [ 0.0433, -0.1048,  0.0413,  ..., -0.0444,  0.0264,  0.1134]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0384,  0.0076,  0.0975,  0.0050,  0.0664,  0.1013, -0.0035,  0.0628,\n         0.0481,  0.0579, -0.0457,  0.1236,  0.0166, -0.0297,  0.1137, -0.1048,\n        -0.1195,  0.0693,  0.0144,  0.0348, -0.0296, -0.0466, -0.0296, -0.0288,\n         0.0153,  0.0348, -0.0424,  0.0253, -0.0662,  0.1208,  0.1194, -0.0961],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1258,  0.0515,  0.1453,  0.1139,  0.1167, -0.0723, -0.1660, -0.0561,\n          0.1436, -0.1764, -0.1403, -0.0164,  0.0435,  0.0527, -0.0487,  0.0224,\n         -0.1541,  0.1716,  0.0401,  0.1356, -0.1003,  0.0857,  0.1208,  0.1128,\n         -0.0017, -0.0238, -0.0002, -0.0159,  0.0967,  0.0391, -0.1090,  0.0138],\n        [-0.0359, -0.0272, -0.0746,  0.1475,  0.1322, -0.0987, -0.0114,  0.0036,\n          0.1311, -0.0548,  0.1503, -0.0235, -0.0096,  0.1233,  0.0911, -0.0374,\n          0.0009, -0.0274, -0.0582,  0.0098,  0.0386,  0.1091,  0.0998, -0.1457,\n         -0.0737, -0.1500, -0.0015,  0.1678, -0.1512, -0.0536, -0.0263, -0.0484],\n        [ 0.1598,  0.0950,  0.0020,  0.1677, -0.0153, -0.0825,  0.1760, -0.1580,\n         -0.0833,  0.1445,  0.0446, -0.0507, -0.0979, -0.0916,  0.1527, -0.0371,\n         -0.0155,  0.0438, -0.1756,  0.0418, -0.1168, -0.1280,  0.0446,  0.1035,\n          0.0081,  0.0868, -0.1275,  0.0960, -0.0274,  0.1283,  0.1017, -0.1676],\n        [ 0.0201, -0.0108,  0.1051,  0.0524, -0.0079, -0.0115,  0.1333,  0.1257,\n          0.0904, -0.0187, -0.0635, -0.0345,  0.1653, -0.1090, -0.1327, -0.0374,\n          0.0258,  0.1708,  0.1447, -0.0225, -0.1767, -0.0970,  0.1381,  0.0902,\n         -0.0359,  0.1598, -0.1175, -0.1679, -0.0753,  0.0384, -0.0914, -0.0269],\n        [ 0.1588, -0.1247,  0.0449,  0.1156,  0.1038, -0.1212, -0.0202, -0.0010,\n          0.1516, -0.0744, -0.1470,  0.1378,  0.1073, -0.1025, -0.0399, -0.0269,\n          0.1656, -0.0015, -0.0203, -0.1108, -0.0074, -0.0095, -0.1461,  0.0970,\n         -0.0784, -0.0500,  0.0969,  0.0569, -0.1028,  0.1333, -0.0050,  0.0263],\n        [-0.0958, -0.1010,  0.0453, -0.0144,  0.0846,  0.1209, -0.1117, -0.1289,\n         -0.1346,  0.1157,  0.0170,  0.0410,  0.0569, -0.1230,  0.1507, -0.0120,\n         -0.1265,  0.1483,  0.1276,  0.0572,  0.0347,  0.1013, -0.1057, -0.0305,\n          0.0804, -0.0305,  0.1128, -0.1592, -0.0177, -0.0378, -0.0695,  0.0174],\n        [-0.1644,  0.0131,  0.0129, -0.0535,  0.0570, -0.0792, -0.1072,  0.1423,\n         -0.0261,  0.1335, -0.1097,  0.0462,  0.0798,  0.0291, -0.0864, -0.1368,\n          0.0145,  0.1331,  0.1211, -0.1682,  0.1605, -0.1167, -0.0322,  0.1576,\n          0.0059, -0.1230, -0.1134, -0.0913, -0.0562, -0.0631, -0.1143, -0.1225],\n        [-0.0043,  0.1281,  0.1376, -0.0284,  0.1043, -0.0550,  0.0336,  0.1497,\n         -0.0132,  0.0590, -0.1195, -0.1723,  0.0506, -0.1180, -0.1696, -0.1737,\n          0.1440,  0.0600,  0.0205, -0.1076,  0.1241,  0.0413,  0.1444,  0.1468,\n         -0.0437,  0.0338, -0.1251,  0.0107,  0.0098, -0.1676, -0.0632,  0.1476],\n        [ 0.0811,  0.0223,  0.1572, -0.0298, -0.0236,  0.1436,  0.0165,  0.1435,\n         -0.1102, -0.0566, -0.0519,  0.0358, -0.0793,  0.0174,  0.0944, -0.1545,\n         -0.0519,  0.1484,  0.0121,  0.1178, -0.0321, -0.1340,  0.0176,  0.1159,\n         -0.1373, -0.0412, -0.1658,  0.0917, -0.1238,  0.0694,  0.1700,  0.0245],\n        [ 0.0741, -0.1332, -0.0750,  0.0760, -0.0276, -0.1644,  0.0932, -0.0203,\n         -0.1445, -0.0557,  0.0775,  0.0216,  0.1305,  0.0695, -0.0463, -0.1066,\n         -0.0283,  0.1386,  0.1453,  0.0759,  0.1591,  0.0609,  0.0573,  0.0534,\n          0.0858,  0.0615,  0.1555,  0.0723,  0.0208, -0.0039, -0.1600, -0.1526],\n        [-0.0395, -0.0958, -0.1382,  0.0576, -0.0653, -0.0138,  0.0535, -0.0857,\n         -0.0587,  0.0843,  0.1415,  0.1673, -0.1057, -0.1047,  0.1393, -0.1062,\n         -0.0149, -0.1247, -0.1760, -0.1481, -0.0383,  0.0323, -0.1739, -0.0285,\n         -0.0673,  0.0385,  0.1289,  0.0038, -0.1561,  0.1583, -0.1526, -0.0882],\n        [ 0.0051,  0.0295,  0.1504, -0.0421,  0.0335,  0.0793, -0.1075, -0.0837,\n         -0.1387, -0.0260, -0.0201,  0.0624,  0.1272, -0.1764,  0.1284,  0.0519,\n          0.0465,  0.1230, -0.0494,  0.0699, -0.1377, -0.1330, -0.0252,  0.0556,\n         -0.0393, -0.0146,  0.0052, -0.1278, -0.0830,  0.1227,  0.1517,  0.0740],\n        [-0.1639, -0.0283,  0.1492,  0.0655,  0.0328, -0.1457, -0.0498,  0.0882,\n         -0.0331,  0.0492,  0.0291,  0.1281, -0.0647, -0.0495,  0.1547, -0.0960,\n          0.0643, -0.0881, -0.0421, -0.0703, -0.0451, -0.0726, -0.0652,  0.0213,\n         -0.1447,  0.0581,  0.0173, -0.0234, -0.1236,  0.1377, -0.1124, -0.0947],\n        [-0.1447,  0.0701,  0.0933, -0.0843,  0.0830, -0.1491,  0.1634, -0.0898,\n         -0.0459, -0.0022,  0.1209,  0.0142, -0.0509,  0.1607,  0.0056,  0.0975,\n          0.0159, -0.1521,  0.1086, -0.0299,  0.1617,  0.1215, -0.1553,  0.1578,\n         -0.0744, -0.1594, -0.0212,  0.1525, -0.0196,  0.0625,  0.0141, -0.0785],\n        [ 0.0638, -0.0211,  0.1425,  0.1161, -0.0519, -0.1561, -0.1141,  0.0803,\n          0.0967,  0.1598, -0.0006,  0.1396, -0.1515, -0.1406,  0.0997, -0.0782,\n          0.0171, -0.0738,  0.0309, -0.1007,  0.0545, -0.1697, -0.1002,  0.1611,\n          0.0897, -0.1060,  0.0570,  0.0869, -0.0675,  0.0512,  0.1337, -0.0722],\n        [-0.1491, -0.0964,  0.1383, -0.1523,  0.0091, -0.0934,  0.0215, -0.1074,\n          0.1640, -0.0039, -0.0145,  0.1689, -0.1008, -0.0640, -0.1656, -0.0333,\n         -0.0732, -0.0730, -0.1604, -0.0431, -0.0271,  0.0670, -0.1297,  0.0227,\n          0.1292,  0.0624,  0.0875, -0.1314, -0.0818,  0.1110,  0.1600, -0.1102]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0973, -0.0259,  0.0872, -0.1025,  0.1174, -0.0025, -0.1375, -0.1049,\n         0.1512, -0.0004,  0.1501,  0.1384, -0.1408, -0.0992,  0.1414, -0.0346],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2036, -0.1916,  0.0214,  0.2388, -0.2493,  0.2222, -0.2255,  0.0756,\n         -0.0499,  0.1560,  0.2155,  0.2345,  0.0554,  0.1855, -0.2412, -0.1052],\n        [ 0.2224,  0.1643, -0.1345, -0.0058, -0.2177,  0.0368, -0.2090,  0.0260,\n         -0.1353,  0.1228,  0.0661,  0.0817,  0.1399,  0.1484,  0.1619,  0.1863],\n        [ 0.0841,  0.1098, -0.1565, -0.0749,  0.0917,  0.0321,  0.1901,  0.1879,\n          0.2484,  0.0456, -0.1782,  0.1762, -0.1163,  0.0537, -0.2454, -0.0329],\n        [ 0.2465, -0.2282,  0.1831,  0.1089, -0.1868, -0.2189, -0.0310,  0.1248,\n         -0.0549,  0.1883, -0.2354,  0.0772, -0.1843, -0.1806,  0.1147,  0.0537],\n        [ 0.0478, -0.1039,  0.2425, -0.0559, -0.1881,  0.0766, -0.1629,  0.0572,\n          0.1240, -0.0213, -0.0577, -0.2326,  0.2482, -0.0400,  0.2109,  0.0915],\n        [-0.0628,  0.1608,  0.1561, -0.0158, -0.0704, -0.0981,  0.0543, -0.0809,\n          0.0370, -0.2379,  0.0411,  0.0933, -0.0831, -0.2190,  0.1480,  0.0773],\n        [-0.1675, -0.1287, -0.0791, -0.1744, -0.1289,  0.0952, -0.1690,  0.0825,\n         -0.2214, -0.1427,  0.1839, -0.1993, -0.0480,  0.0721,  0.0642, -0.2071],\n        [-0.0048,  0.0098, -0.1544, -0.0444, -0.0976,  0.1188,  0.1734,  0.0977,\n          0.1794, -0.0025,  0.0553,  0.1297,  0.2235, -0.0240,  0.1697, -0.2281]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0586, -0.1755,  0.1370, -0.2369,  0.0690,  0.0518, -0.1605,  0.0381],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1848, -0.0589, -0.0453,  0.0829,  0.1828,  0.1629,  0.0659,  0.3471]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1077], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7afb1cb41150>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7afb18ef3b50>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s161780000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s161780000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}