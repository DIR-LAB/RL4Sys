{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s166110000"
    },
    "q_lr":	0.0005,
    "seed":	166110000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x76f616e9ced0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=32, out_features=16, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=16, out_features=8, bias=True)\n    (9): ReLU()\n    (10): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=32, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=32, out_features=16, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=16, out_features=8, bias=True)\n  (9): ReLU()\n  (10): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2604,  0.0819,  0.0289,  0.2795,  0.3294,  0.2681,  0.1469,  0.3344,\n        -0.1782,  0.1323, -0.1781, -0.0272,  0.2711,  0.3297, -0.0456,  0.3229,\n         0.0925, -0.2777,  0.0912, -0.1390, -0.1613, -0.1027,  0.3406,  0.0315,\n        -0.2343,  0.1569, -0.0649,  0.1456, -0.1481, -0.2935, -0.1652, -0.2408,\n        -0.1390,  0.2755, -0.0382, -0.0854, -0.3511,  0.1039, -0.1561, -0.2660,\n         0.0646, -0.3426, -0.0511,  0.2766,  0.1323,  0.2946, -0.0507,  0.0213,\n         0.0662, -0.0056,  0.0356, -0.3028, -0.2014, -0.3507,  0.3498, -0.0257,\n         0.0542,  0.1810,  0.1378,  0.1446, -0.1873, -0.0878,  0.1935,  0.3332],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.4118e-01,  1.7581e-01,  8.9233e-02,  2.8873e-01, -1.7926e-01,\n         -2.7935e-01,  1.0147e-02,  1.3626e-04],\n        [ 2.9214e-01, -2.5321e-01,  8.5886e-02, -2.6543e-01, -1.9196e-01,\n          1.6761e-01, -6.7604e-02,  2.9160e-01],\n        [-1.1938e-01,  2.7161e-01,  2.6497e-01, -1.6844e-01,  1.6946e-01,\n          1.9011e-01,  3.0428e-03,  3.1669e-01],\n        [-1.7120e-01, -4.3970e-02, -1.1606e-01, -4.2526e-02,  2.4116e-01,\n          3.2959e-01, -3.2820e-01,  1.6690e-01],\n        [ 1.6812e-01, -1.9148e-01, -3.4553e-01, -2.5601e-01,  1.7772e-02,\n         -9.0312e-02,  2.6923e-01, -3.1801e-02],\n        [-3.1948e-01,  3.4681e-01, -2.0745e-01,  2.0070e-01, -2.3964e-02,\n          3.3603e-01, -6.4884e-02, -3.2170e-02],\n        [ 2.0569e-01,  1.9128e-01, -1.4327e-01,  1.7332e-01,  3.4418e-01,\n         -2.2935e-01, -2.1013e-01, -5.1526e-03],\n        [-2.5556e-01,  3.0249e-01,  1.3789e-01,  2.5531e-01,  2.7491e-01,\n          2.3111e-01, -1.3523e-01,  3.2276e-01],\n        [-1.7789e-01,  1.2959e-01,  1.2915e-01,  3.9566e-02, -1.0357e-01,\n          1.0882e-01,  1.6491e-01, -2.1672e-01],\n        [ 3.2755e-01, -8.2199e-02,  2.3103e-01, -3.4900e-01, -1.0011e-01,\n         -1.6343e-01, -1.1569e-01, -1.4918e-01],\n        [ 3.3656e-01,  2.6651e-01,  1.2808e-01,  2.0592e-01,  2.1810e-02,\n         -1.0012e-01, -1.0482e-01,  1.5846e-01],\n        [-2.0302e-01,  1.7348e-01,  8.2497e-03,  3.3122e-01,  1.2114e-01,\n          6.8268e-02,  1.9610e-01, -6.6338e-02],\n        [-3.0655e-01,  1.0199e-01, -3.0328e-01, -4.4391e-02, -2.9098e-02,\n          2.6565e-02,  1.4549e-01,  2.8048e-01],\n        [-2.7596e-01,  1.8481e-03, -3.3625e-01,  6.2109e-02,  3.0287e-01,\n         -3.1606e-01,  3.1849e-01,  2.6708e-01],\n        [ 1.6576e-01, -7.0555e-02,  1.9313e-01, -3.1898e-01,  3.0769e-01,\n         -1.1154e-01,  3.3152e-01,  2.8126e-01],\n        [-2.5143e-01, -1.1624e-01,  9.7645e-03,  3.1262e-01,  2.3346e-01,\n         -3.3871e-01, -1.8717e-01,  2.5315e-01],\n        [ 1.4996e-01,  4.2107e-02,  1.1592e-01,  1.2346e-01, -1.8672e-01,\n          1.1698e-01,  3.1636e-02,  1.2044e-01],\n        [-2.6299e-01,  2.6232e-01, -3.0388e-04, -1.5604e-01, -2.2777e-01,\n          1.8866e-01,  2.6144e-02, -8.0023e-02],\n        [ 2.3106e-01, -3.3043e-02, -1.6020e-01, -1.6025e-01,  1.0534e-01,\n         -1.6640e-01, -2.4024e-01, -1.1807e-01],\n        [ 4.8603e-02,  3.3723e-01,  5.0172e-02,  1.3734e-01, -2.6769e-01,\n          6.2285e-02,  7.1003e-02, -1.9618e-01],\n        [-5.0724e-02, -3.0914e-01,  1.5540e-01, -5.0996e-02, -4.8304e-02,\n          4.2706e-02,  2.2737e-01,  2.4437e-01],\n        [-1.4594e-01,  1.6443e-01,  2.1743e-01,  6.9682e-02,  7.7538e-03,\n         -3.3984e-01,  2.8975e-01,  1.8385e-01],\n        [-2.4857e-01, -1.4049e-01, -2.6967e-01, -5.2459e-02,  2.3781e-01,\n         -2.9777e-01, -3.2232e-02, -1.7437e-02],\n        [ 3.2176e-01, -1.8398e-01, -4.4641e-02, -9.8727e-02, -7.5022e-02,\n          6.0282e-02, -1.9681e-01, -2.0479e-01],\n        [ 2.9426e-01, -1.3473e-01,  2.0471e-01,  2.1143e-01,  3.1918e-01,\n          8.2389e-02, -3.3809e-01,  1.5290e-01],\n        [ 2.3820e-01,  2.2241e-01,  6.8240e-02,  1.5025e-01, -8.6725e-02,\n         -1.1795e-01, -2.8626e-01,  1.4499e-01],\n        [-1.5994e-01, -1.3368e-03,  1.4540e-01, -1.0995e-01,  1.7918e-03,\n         -1.2340e-01, -1.8852e-01, -2.7314e-01],\n        [-1.3388e-01, -2.3828e-01, -3.5352e-01, -2.4080e-01,  3.0950e-01,\n          1.0263e-01,  1.4282e-01, -1.1502e-01],\n        [ 2.1559e-01, -6.8109e-02, -2.0272e-01, -3.4848e-02,  1.0173e-01,\n         -8.5090e-02, -3.3707e-01, -1.4663e-01],\n        [-4.4362e-02, -2.8125e-01, -4.9923e-02,  8.5377e-02,  3.4710e-01,\n          1.1943e-01,  1.9921e-01,  1.9813e-01],\n        [ 2.5414e-01, -2.2700e-01, -2.1025e-01, -1.9344e-01,  1.0541e-01,\n          3.3112e-01,  2.4147e-01,  8.3676e-02],\n        [ 1.6681e-01,  2.1797e-01,  3.3506e-01,  7.0061e-02, -8.9004e-02,\n         -1.6243e-01, -6.4223e-02, -1.1641e-01],\n        [-2.0366e-01,  1.0217e-01, -2.2783e-01, -1.0542e-01, -1.2906e-01,\n          2.5685e-01,  6.8891e-02,  2.4838e-01],\n        [-3.1796e-01,  2.4392e-01,  3.0147e-01, -1.7254e-01,  1.7066e-01,\n         -3.2689e-01, -3.5836e-02, -3.2576e-01],\n        [ 2.4776e-01, -1.1409e-01, -3.0195e-01, -8.8580e-02, -3.3664e-01,\n         -2.9729e-01, -1.8852e-01, -3.0351e-03],\n        [ 2.4380e-01,  2.7362e-01,  1.5454e-01, -1.5583e-01,  2.3568e-01,\n          1.4588e-01, -2.4438e-01, -7.3839e-02],\n        [-4.9293e-02, -3.4437e-02, -3.4466e-01,  1.7607e-01, -2.1428e-01,\n         -1.9165e-01, -2.7204e-03,  3.0328e-01],\n        [ 3.0429e-02,  1.2736e-01,  3.3748e-01, -1.4197e-01,  3.7833e-02,\n          1.3281e-01,  2.4322e-01,  1.0808e-02],\n        [ 1.2856e-01, -6.7811e-02,  2.0139e-01,  2.5648e-02,  2.3076e-01,\n         -2.6899e-01,  1.8793e-01, -4.4883e-02],\n        [ 2.4444e-01, -1.9154e-01,  3.0553e-01,  2.8182e-01,  1.9163e-01,\n         -1.2012e-01,  1.5457e-01, -3.5166e-01],\n        [-3.2068e-01,  1.8221e-01, -1.8835e-01,  1.4308e-01, -2.9344e-01,\n         -1.8825e-01,  1.3163e-01,  6.5153e-02],\n        [-3.3494e-01, -1.0488e-01, -1.8618e-01, -2.5725e-02, -3.0525e-01,\n          9.2433e-02, -1.3260e-01, -1.2953e-01],\n        [ 4.1158e-02, -1.4051e-01, -3.2135e-01,  2.1633e-01, -2.4536e-01,\n         -9.8382e-02, -6.6061e-04,  1.3082e-01],\n        [-3.0369e-01,  1.4018e-01, -1.2840e-01, -3.5049e-01,  2.4420e-01,\n          1.4941e-01,  8.2078e-02,  3.1866e-01],\n        [-3.0011e-01, -2.6722e-01,  2.1938e-01,  3.4424e-01,  3.1556e-01,\n         -1.0880e-01, -1.0063e-02, -3.2432e-01],\n        [ 1.9344e-01,  4.4030e-02, -7.7694e-02, -2.0360e-01, -1.1971e-01,\n          1.7761e-01, -3.4288e-02, -1.7326e-01],\n        [ 2.7247e-01,  1.2954e-02,  2.7219e-01, -1.6901e-01, -1.0802e-01,\n         -8.2375e-02,  1.3721e-01,  2.6655e-01],\n        [ 1.2256e-01, -3.1046e-01, -8.3916e-02, -2.4744e-01,  2.0643e-01,\n         -1.0622e-01,  2.8151e-03,  5.6577e-02],\n        [-2.2029e-01, -3.4659e-01, -2.8022e-02, -4.7397e-02, -1.0330e-02,\n         -2.8495e-01, -2.0456e-01,  1.6385e-01],\n        [ 2.3679e-01,  2.1214e-01,  5.5136e-02, -1.1285e-01, -2.0584e-01,\n          2.0101e-01, -5.6044e-02,  1.1634e-01],\n        [ 2.5707e-01, -2.7796e-01, -1.4918e-01,  1.6904e-01, -1.7947e-01,\n          2.0131e-01, -1.7596e-01, -6.9195e-02],\n        [-2.9921e-01,  1.4712e-02,  2.6776e-01, -3.4330e-01, -1.7288e-02,\n         -2.4873e-01, -1.8781e-01,  1.7452e-02],\n        [-3.6709e-02, -1.4117e-01,  1.6268e-01,  8.1752e-04,  1.0547e-01,\n         -2.3617e-01, -2.4244e-01,  9.3716e-02],\n        [ 1.1815e-01, -2.1147e-01, -2.1047e-01,  2.8875e-01, -8.6099e-02,\n         -8.4790e-02, -3.5751e-02, -2.1941e-01],\n        [-1.0471e-01, -2.2851e-01, -1.2151e-01,  1.5344e-01, -1.9592e-01,\n         -2.6804e-01, -2.9195e-01, -9.1137e-03],\n        [ 2.3353e-01, -5.6632e-02,  2.7454e-01, -2.3341e-01, -6.7233e-02,\n         -9.8331e-02, -1.7858e-01,  1.0551e-03],\n        [ 3.1812e-02,  1.9810e-01, -3.2425e-01,  1.7499e-01,  6.5023e-02,\n         -2.7012e-02, -5.3835e-02, -1.1370e-01],\n        [-1.0933e-01, -3.1570e-01, -2.4363e-01,  3.4544e-01,  5.4781e-02,\n          3.0707e-01,  2.5971e-01, -1.2124e-01],\n        [ 3.2161e-01,  2.7982e-01,  1.0611e-01,  3.2707e-01,  1.0689e-01,\n         -9.2469e-02,  9.4767e-02, -1.1612e-01],\n        [ 6.4410e-02,  1.4028e-01, -1.5087e-01, -4.8933e-03, -3.3217e-01,\n         -2.7432e-01,  2.8908e-01,  5.5443e-02],\n        [ 2.3581e-01,  3.3049e-01, -1.4468e-01, -3.0073e-01, -3.4131e-01,\n         -1.7568e-01,  1.8368e-01,  3.3466e-01],\n        [ 1.1844e-01,  2.9651e-01,  1.2575e-01,  8.4845e-02,  1.3569e-01,\n         -1.7152e-01,  2.1382e-01, -2.7274e-01],\n        [-2.3307e-01,  1.2550e-01, -1.6053e-01,  4.6724e-04,  1.6744e-01,\n         -8.3431e-02, -2.1397e-02,  2.6125e-01],\n        [-1.4300e-01, -3.1904e-01,  1.5692e-01, -2.2048e-01, -2.2839e-01,\n         -4.2602e-02, -2.8595e-01, -5.6474e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "10":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0392], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1914,  0.0440,  0.1322,  0.1609, -0.2645,  0.0764,  0.2323, -0.2263]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=64, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0335, -0.1228,  0.0033,  0.0389, -0.0918,  0.0901, -0.0004,  0.0010,\n        -0.0941, -0.0834,  0.0224, -0.0275, -0.0751, -0.0763,  0.0460, -0.0529,\n        -0.0978, -0.0200,  0.0317, -0.0793, -0.0017, -0.0824,  0.0136, -0.0586,\n         0.0485,  0.0687,  0.0545, -0.0934, -0.0681, -0.0616,  0.0055, -0.0722,\n        -0.1048,  0.1222, -0.0467,  0.1247, -0.0426,  0.0737,  0.0181, -0.0275,\n        -0.0632,  0.1079, -0.1087,  0.1026, -0.0325,  0.0156,  0.0124,  0.0807,\n         0.1151, -0.0615, -0.0078, -0.0130, -0.0809,  0.0413, -0.0714, -0.1010,\n         0.0957, -0.0864, -0.0381, -0.0369, -0.0547,  0.0441,  0.0613, -0.0326],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0192,  0.0370, -0.0764,  ..., -0.0771,  0.1215,  0.0544],\n        [ 0.0513,  0.0620,  0.1197,  ..., -0.0623, -0.0116,  0.0432],\n        [-0.0239, -0.0721, -0.0722,  ..., -0.0895, -0.0853, -0.0279],\n        ...,\n        [-0.0130,  0.0192, -0.0578,  ..., -0.0640, -0.0777, -0.0998],\n        [ 0.0740,  0.0309, -0.0110,  ...,  0.0416, -0.0939, -0.1083],\n        [ 0.0633,  0.0371, -0.0219,  ..., -0.0838,  0.0385,  0.1120]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=64, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0226,  0.1115, -0.0605, -0.0077,  0.0926,  0.0324, -0.1088,  0.1186,\n         0.0600, -0.0473,  0.0740, -0.1171,  0.0837, -0.1138,  0.0253, -0.0912,\n        -0.1182, -0.0687, -0.0145,  0.1056, -0.0436,  0.0321,  0.0726, -0.0560,\n         0.0733,  0.1004,  0.1217, -0.1059, -0.0447, -0.0550,  0.0709, -0.1198],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0810, -0.0842, -0.1071,  ..., -0.0820,  0.0048,  0.0640],\n        [ 0.0157,  0.0015, -0.0726,  ...,  0.1056,  0.0437,  0.0179],\n        [ 0.0636, -0.1185, -0.0036,  ..., -0.1188, -0.0426,  0.0081],\n        ...,\n        [ 0.0166,  0.0817, -0.0647,  ...,  0.0068, -0.1060,  0.0402],\n        [ 0.0188,  0.1239, -0.0314,  ...,  0.0885, -0.0335, -0.0081],\n        [ 0.0061,  0.0354, -0.0734,  ...,  0.0079,  0.0009,  0.0705]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0192, -0.0519,  0.1477,  0.1540, -0.0286, -0.0147,  0.0516,  0.0624,\n         0.1368, -0.0140, -0.1581, -0.0294, -0.1151,  0.1598, -0.1005,  0.0532],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0770,  0.1399,  0.1209, -0.0830,  0.1369,  0.1660,  0.0683,  0.0992,\n         -0.0964,  0.0928,  0.0223,  0.0857, -0.1460,  0.0422,  0.1108, -0.1697,\n         -0.0607, -0.1237,  0.0235, -0.0517, -0.0519,  0.1201,  0.1662,  0.0141,\n          0.0451, -0.1417, -0.1215,  0.0534,  0.0093, -0.0728, -0.0164, -0.1647],\n        [-0.0061,  0.1377, -0.1379, -0.0594,  0.1145,  0.0347,  0.0709, -0.0994,\n          0.1706, -0.0320, -0.1605, -0.0284,  0.0108,  0.0294,  0.0726,  0.0009,\n          0.1424,  0.1664, -0.0728,  0.1707, -0.0239,  0.1604, -0.1228,  0.0100,\n         -0.1629,  0.1225,  0.1496,  0.0117, -0.0835,  0.1721, -0.0110, -0.0336],\n        [-0.0717, -0.0843,  0.0523, -0.1747,  0.1563, -0.1151, -0.0803,  0.1463,\n         -0.0639,  0.0342,  0.0325, -0.0173, -0.1083,  0.1234,  0.1662, -0.1301,\n          0.1748,  0.0477, -0.1170,  0.0721, -0.1063, -0.1407, -0.0038, -0.0353,\n          0.1094,  0.1651,  0.0740, -0.1640,  0.0929,  0.1538, -0.0106,  0.0623],\n        [-0.1170,  0.0016,  0.0060, -0.1057, -0.0654,  0.0341,  0.0807, -0.1175,\n          0.0585,  0.1045, -0.0158,  0.1107,  0.1406, -0.1377, -0.1738, -0.1430,\n          0.1032, -0.1699,  0.1581, -0.0593,  0.0142, -0.1432, -0.1247, -0.1017,\n         -0.0678,  0.1245,  0.1276, -0.0561,  0.1204, -0.1424,  0.0926,  0.0651],\n        [-0.0304,  0.0227, -0.0580, -0.1567, -0.1010,  0.0550, -0.0673,  0.1035,\n         -0.0324, -0.1472, -0.1543, -0.1257, -0.0689,  0.1402, -0.0751,  0.0758,\n         -0.0567, -0.0467,  0.0907,  0.1052, -0.0965, -0.0568, -0.0619, -0.1178,\n          0.1513,  0.0900,  0.0790,  0.0651,  0.0777, -0.0242, -0.0859, -0.1251],\n        [-0.0993,  0.0828, -0.0400,  0.0603,  0.0021,  0.1286, -0.0938, -0.0251,\n         -0.0380, -0.0675,  0.0503, -0.1177,  0.0093,  0.0731, -0.0876,  0.0039,\n          0.0242,  0.1049,  0.1106, -0.0772, -0.1047,  0.0806,  0.0455,  0.0024,\n          0.0193, -0.0929,  0.1319, -0.1147, -0.1650, -0.1433, -0.0295, -0.0355],\n        [-0.0737, -0.1141,  0.0774,  0.1129, -0.0597, -0.1151,  0.0934,  0.0035,\n          0.1123, -0.0143, -0.0320, -0.1304,  0.0180,  0.1681, -0.0151,  0.0509,\n         -0.1643,  0.1423,  0.1341, -0.0564, -0.1278,  0.0688, -0.1369, -0.1470,\n          0.1656, -0.1361,  0.1764,  0.0009,  0.0881, -0.1626, -0.0057, -0.0964],\n        [ 0.0864,  0.1280,  0.0212, -0.0183,  0.1639,  0.1524, -0.0691,  0.1530,\n         -0.0483,  0.0843, -0.0909, -0.0903, -0.0607,  0.0558,  0.0396, -0.1565,\n          0.0930,  0.0289,  0.1455,  0.1025, -0.1447, -0.0232, -0.0093, -0.0028,\n         -0.0236, -0.1712, -0.1091, -0.0015,  0.1215,  0.1504,  0.0115, -0.1050],\n        [-0.0184,  0.1151, -0.0348, -0.1456, -0.1343, -0.0751, -0.1045, -0.1276,\n          0.1212,  0.1630,  0.0794,  0.0788,  0.0939, -0.1200, -0.0423,  0.0725,\n          0.0823,  0.0184,  0.0207,  0.1528,  0.0464, -0.1748, -0.0526, -0.0545,\n          0.0613,  0.0042, -0.0733, -0.1548,  0.0848, -0.0959,  0.1300,  0.0288],\n        [-0.0364,  0.0193, -0.0598, -0.0791, -0.0863, -0.0402,  0.1275, -0.0209,\n          0.0223,  0.0798, -0.0681,  0.0859, -0.0285,  0.1271, -0.0091, -0.1135,\n         -0.0045,  0.1564, -0.0099,  0.1127, -0.1409, -0.0325,  0.0821, -0.1234,\n         -0.0689, -0.1453, -0.0481, -0.1142,  0.1734, -0.0244, -0.0412, -0.1295],\n        [-0.0425, -0.1150,  0.1741, -0.0775,  0.1455, -0.0528, -0.1185,  0.0656,\n         -0.1470,  0.0935, -0.0102,  0.1244,  0.1658, -0.1728, -0.1686,  0.1617,\n          0.1396, -0.1025, -0.0244,  0.1449, -0.0143, -0.0106, -0.1373,  0.0715,\n         -0.0939,  0.0529, -0.1146,  0.0970, -0.0362, -0.0854, -0.0077,  0.0867],\n        [ 0.0126,  0.0191,  0.0689, -0.1018, -0.1420,  0.0606, -0.1355,  0.1477,\n          0.0119,  0.0358,  0.0950,  0.0198, -0.1021,  0.0507,  0.0985,  0.1525,\n          0.1441, -0.1055, -0.0182, -0.1282,  0.0585,  0.0837,  0.1249,  0.0175,\n         -0.1042,  0.1279, -0.1487, -0.0220,  0.0351,  0.0635, -0.0778,  0.0867],\n        [ 0.0675, -0.0618, -0.1269,  0.1297, -0.0255, -0.0973, -0.0049, -0.1428,\n          0.1210, -0.0164, -0.0174, -0.0639, -0.0208,  0.0554,  0.1710,  0.0142,\n         -0.0389,  0.0453, -0.1760, -0.1494,  0.1507,  0.1062, -0.1303, -0.1132,\n          0.0903, -0.0033, -0.1657,  0.0296, -0.1017,  0.0139, -0.1724,  0.1343],\n        [-0.1296, -0.0049,  0.0270,  0.1233,  0.0431,  0.1085, -0.1259, -0.0841,\n          0.1161, -0.0152, -0.0482,  0.1164, -0.0068,  0.0707,  0.0286,  0.0704,\n         -0.1690, -0.0424,  0.1490, -0.0675,  0.1431,  0.0948,  0.0536, -0.0260,\n          0.1447, -0.0462,  0.1660,  0.0912,  0.0895,  0.1193,  0.1667,  0.0917],\n        [ 0.1007,  0.1252, -0.1363, -0.1233,  0.1017,  0.0999, -0.0376,  0.1227,\n         -0.1440, -0.0263, -0.1611, -0.1143, -0.1030, -0.0119, -0.1626, -0.1572,\n         -0.0641, -0.0271, -0.1142,  0.0964, -0.0825,  0.0463, -0.1006,  0.0297,\n         -0.0301,  0.0004, -0.0900,  0.0570,  0.1606, -0.0994,  0.0857, -0.0383],\n        [ 0.1259,  0.1061, -0.0066,  0.1015, -0.0959,  0.0029,  0.0371, -0.0137,\n         -0.0906,  0.0701, -0.0634, -0.1677, -0.1110, -0.0075, -0.0789,  0.1741,\n         -0.0035,  0.0979,  0.1071,  0.1219, -0.1319, -0.1621, -0.0915, -0.0116,\n          0.1749,  0.1664,  0.0879,  0.0964,  0.1585, -0.0061,  0.0746, -0.1453]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "7":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "8":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2084,  0.0338, -0.1178, -0.0130,  0.0796, -0.0528, -0.1471, -0.2037],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1574, -0.1500,  0.0148, -0.1180, -0.0535,  0.1528,  0.1021, -0.0975,\n         -0.1713, -0.2284, -0.1321,  0.0693, -0.0897, -0.0080, -0.1248,  0.0396],\n        [-0.1422,  0.0518, -0.0062, -0.1869,  0.0097,  0.2259, -0.1761,  0.2068,\n          0.0314, -0.1038, -0.2409, -0.1528, -0.1703,  0.1307, -0.0330,  0.0719],\n        [-0.1697, -0.1148, -0.0434,  0.0205, -0.2478,  0.0026,  0.2360, -0.2017,\n          0.2285, -0.1335,  0.0498, -0.2200,  0.0233, -0.0984, -0.2161,  0.2065],\n        [-0.0927,  0.1352, -0.1750, -0.0993, -0.2474,  0.0103,  0.0515, -0.0376,\n          0.1189, -0.1194, -0.2454,  0.0428,  0.2003, -0.1388,  0.0652, -0.0662],\n        [-0.1670,  0.0593, -0.1154,  0.1621,  0.0715,  0.1173,  0.0218, -0.2035,\n          0.0939, -0.0608, -0.0026, -0.1012, -0.2185, -0.2230,  0.0757,  0.1645],\n        [-0.0863, -0.0256,  0.0839,  0.1373, -0.0546,  0.0858, -0.0294,  0.0958,\n          0.2255,  0.2457,  0.2094,  0.1664,  0.0128,  0.1919,  0.2196,  0.1978],\n        [ 0.1421, -0.1641,  0.0648, -0.0459, -0.1153,  0.2301, -0.1554, -0.0727,\n         -0.0855, -0.1611, -0.0504, -0.2154, -0.1129, -0.1595,  0.1745,  0.0947],\n        [ 0.0591,  0.2467,  0.0034,  0.1773,  0.0345,  0.0787,  0.2241,  0.0872,\n         -0.2214, -0.1344,  0.1453,  0.2308,  0.1510, -0.0143, -0.0285, -0.0421]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "9":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-2.4118e-01,  1.7581e-01,  8.9233e-02,  2.8873e-01, -1.7926e-01,\n         -2.7935e-01,  1.0147e-02,  1.3626e-04],\n        [ 2.9214e-01, -2.5321e-01,  8.5886e-02, -2.6543e-01, -1.9196e-01,\n          1.6761e-01, -6.7604e-02,  2.9160e-01],\n        [-1.1938e-01,  2.7161e-01,  2.6497e-01, -1.6844e-01,  1.6946e-01,\n          1.9011e-01,  3.0428e-03,  3.1669e-01],\n        [-1.7120e-01, -4.3970e-02, -1.1606e-01, -4.2526e-02,  2.4116e-01,\n          3.2959e-01, -3.2820e-01,  1.6690e-01],\n        [ 1.6812e-01, -1.9148e-01, -3.4553e-01, -2.5601e-01,  1.7772e-02,\n         -9.0312e-02,  2.6923e-01, -3.1801e-02],\n        [-3.1948e-01,  3.4681e-01, -2.0745e-01,  2.0070e-01, -2.3964e-02,\n          3.3603e-01, -6.4884e-02, -3.2170e-02],\n        [ 2.0569e-01,  1.9128e-01, -1.4327e-01,  1.7332e-01,  3.4418e-01,\n         -2.2935e-01, -2.1013e-01, -5.1526e-03],\n        [-2.5556e-01,  3.0249e-01,  1.3789e-01,  2.5531e-01,  2.7491e-01,\n          2.3111e-01, -1.3523e-01,  3.2276e-01],\n        [-1.7789e-01,  1.2959e-01,  1.2915e-01,  3.9566e-02, -1.0357e-01,\n          1.0882e-01,  1.6491e-01, -2.1672e-01],\n        [ 3.2755e-01, -8.2199e-02,  2.3103e-01, -3.4900e-01, -1.0011e-01,\n         -1.6343e-01, -1.1569e-01, -1.4918e-01],\n        [ 3.3656e-01,  2.6651e-01,  1.2808e-01,  2.0592e-01,  2.1810e-02,\n         -1.0012e-01, -1.0482e-01,  1.5846e-01],\n        [-2.0302e-01,  1.7348e-01,  8.2497e-03,  3.3122e-01,  1.2114e-01,\n          6.8268e-02,  1.9610e-01, -6.6338e-02],\n        [-3.0655e-01,  1.0199e-01, -3.0328e-01, -4.4391e-02, -2.9098e-02,\n          2.6565e-02,  1.4549e-01,  2.8048e-01],\n        [-2.7596e-01,  1.8481e-03, -3.3625e-01,  6.2109e-02,  3.0287e-01,\n         -3.1606e-01,  3.1849e-01,  2.6708e-01],\n        [ 1.6576e-01, -7.0555e-02,  1.9313e-01, -3.1898e-01,  3.0769e-01,\n         -1.1154e-01,  3.3152e-01,  2.8126e-01],\n        [-2.5143e-01, -1.1624e-01,  9.7645e-03,  3.1262e-01,  2.3346e-01,\n         -3.3871e-01, -1.8717e-01,  2.5315e-01],\n        [ 1.4996e-01,  4.2107e-02,  1.1592e-01,  1.2346e-01, -1.8672e-01,\n          1.1698e-01,  3.1636e-02,  1.2044e-01],\n        [-2.6299e-01,  2.6232e-01, -3.0388e-04, -1.5604e-01, -2.2777e-01,\n          1.8866e-01,  2.6144e-02, -8.0023e-02],\n        [ 2.3106e-01, -3.3043e-02, -1.6020e-01, -1.6025e-01,  1.0534e-01,\n         -1.6640e-01, -2.4024e-01, -1.1807e-01],\n        [ 4.8603e-02,  3.3723e-01,  5.0172e-02,  1.3734e-01, -2.6769e-01,\n          6.2285e-02,  7.1003e-02, -1.9618e-01],\n        [-5.0724e-02, -3.0914e-01,  1.5540e-01, -5.0996e-02, -4.8304e-02,\n          4.2706e-02,  2.2737e-01,  2.4437e-01],\n        [-1.4594e-01,  1.6443e-01,  2.1743e-01,  6.9682e-02,  7.7538e-03,\n         -3.3984e-01,  2.8975e-01,  1.8385e-01],\n        [-2.4857e-01, -1.4049e-01, -2.6967e-01, -5.2459e-02,  2.3781e-01,\n         -2.9777e-01, -3.2232e-02, -1.7437e-02],\n        [ 3.2176e-01, -1.8398e-01, -4.4641e-02, -9.8727e-02, -7.5022e-02,\n          6.0282e-02, -1.9681e-01, -2.0479e-01],\n        [ 2.9426e-01, -1.3473e-01,  2.0471e-01,  2.1143e-01,  3.1918e-01,\n          8.2389e-02, -3.3809e-01,  1.5290e-01],\n        [ 2.3820e-01,  2.2241e-01,  6.8240e-02,  1.5025e-01, -8.6725e-02,\n         -1.1795e-01, -2.8626e-01,  1.4499e-01],\n        [-1.5994e-01, -1.3368e-03,  1.4540e-01, -1.0995e-01,  1.7918e-03,\n         -1.2340e-01, -1.8852e-01, -2.7314e-01],\n        [-1.3388e-01, -2.3828e-01, -3.5352e-01, -2.4080e-01,  3.0950e-01,\n          1.0263e-01,  1.4282e-01, -1.1502e-01],\n        [ 2.1559e-01, -6.8109e-02, -2.0272e-01, -3.4848e-02,  1.0173e-01,\n         -8.5090e-02, -3.3707e-01, -1.4663e-01],\n        [-4.4362e-02, -2.8125e-01, -4.9923e-02,  8.5377e-02,  3.4710e-01,\n          1.1943e-01,  1.9921e-01,  1.9813e-01],\n        [ 2.5414e-01, -2.2700e-01, -2.1025e-01, -1.9344e-01,  1.0541e-01,\n          3.3112e-01,  2.4147e-01,  8.3676e-02],\n        [ 1.6681e-01,  2.1797e-01,  3.3506e-01,  7.0061e-02, -8.9004e-02,\n         -1.6243e-01, -6.4223e-02, -1.1641e-01],\n        [-2.0366e-01,  1.0217e-01, -2.2783e-01, -1.0542e-01, -1.2906e-01,\n          2.5685e-01,  6.8891e-02,  2.4838e-01],\n        [-3.1796e-01,  2.4392e-01,  3.0147e-01, -1.7254e-01,  1.7066e-01,\n         -3.2689e-01, -3.5836e-02, -3.2576e-01],\n        [ 2.4776e-01, -1.1409e-01, -3.0195e-01, -8.8580e-02, -3.3664e-01,\n         -2.9729e-01, -1.8852e-01, -3.0351e-03],\n        [ 2.4380e-01,  2.7362e-01,  1.5454e-01, -1.5583e-01,  2.3568e-01,\n          1.4588e-01, -2.4438e-01, -7.3839e-02],\n        [-4.9293e-02, -3.4437e-02, -3.4466e-01,  1.7607e-01, -2.1428e-01,\n         -1.9165e-01, -2.7204e-03,  3.0328e-01],\n        [ 3.0429e-02,  1.2736e-01,  3.3748e-01, -1.4197e-01,  3.7833e-02,\n          1.3281e-01,  2.4322e-01,  1.0808e-02],\n        [ 1.2856e-01, -6.7811e-02,  2.0139e-01,  2.5648e-02,  2.3076e-01,\n         -2.6899e-01,  1.8793e-01, -4.4883e-02],\n        [ 2.4444e-01, -1.9154e-01,  3.0553e-01,  2.8182e-01,  1.9163e-01,\n         -1.2012e-01,  1.5457e-01, -3.5166e-01],\n        [-3.2068e-01,  1.8221e-01, -1.8835e-01,  1.4308e-01, -2.9344e-01,\n         -1.8825e-01,  1.3163e-01,  6.5153e-02],\n        [-3.3494e-01, -1.0488e-01, -1.8618e-01, -2.5725e-02, -3.0525e-01,\n          9.2433e-02, -1.3260e-01, -1.2953e-01],\n        [ 4.1158e-02, -1.4051e-01, -3.2135e-01,  2.1633e-01, -2.4536e-01,\n         -9.8382e-02, -6.6061e-04,  1.3082e-01],\n        [-3.0369e-01,  1.4018e-01, -1.2840e-01, -3.5049e-01,  2.4420e-01,\n          1.4941e-01,  8.2078e-02,  3.1866e-01],\n        [-3.0011e-01, -2.6722e-01,  2.1938e-01,  3.4424e-01,  3.1556e-01,\n         -1.0880e-01, -1.0063e-02, -3.2432e-01],\n        [ 1.9344e-01,  4.4030e-02, -7.7694e-02, -2.0360e-01, -1.1971e-01,\n          1.7761e-01, -3.4288e-02, -1.7326e-01],\n        [ 2.7247e-01,  1.2954e-02,  2.7219e-01, -1.6901e-01, -1.0802e-01,\n         -8.2375e-02,  1.3721e-01,  2.6655e-01],\n        [ 1.2256e-01, -3.1046e-01, -8.3916e-02, -2.4744e-01,  2.0643e-01,\n         -1.0622e-01,  2.8151e-03,  5.6577e-02],\n        [-2.2029e-01, -3.4659e-01, -2.8022e-02, -4.7397e-02, -1.0330e-02,\n         -2.8495e-01, -2.0456e-01,  1.6385e-01],\n        [ 2.3679e-01,  2.1214e-01,  5.5136e-02, -1.1285e-01, -2.0584e-01,\n          2.0101e-01, -5.6044e-02,  1.1634e-01],\n        [ 2.5707e-01, -2.7796e-01, -1.4918e-01,  1.6904e-01, -1.7947e-01,\n          2.0131e-01, -1.7596e-01, -6.9195e-02],\n        [-2.9921e-01,  1.4712e-02,  2.6776e-01, -3.4330e-01, -1.7288e-02,\n         -2.4873e-01, -1.8781e-01,  1.7452e-02],\n        [-3.6709e-02, -1.4117e-01,  1.6268e-01,  8.1752e-04,  1.0547e-01,\n         -2.3617e-01, -2.4244e-01,  9.3716e-02],\n        [ 1.1815e-01, -2.1147e-01, -2.1047e-01,  2.8875e-01, -8.6099e-02,\n         -8.4790e-02, -3.5751e-02, -2.1941e-01],\n        [-1.0471e-01, -2.2851e-01, -1.2151e-01,  1.5344e-01, -1.9592e-01,\n         -2.6804e-01, -2.9195e-01, -9.1137e-03],\n        [ 2.3353e-01, -5.6632e-02,  2.7454e-01, -2.3341e-01, -6.7233e-02,\n         -9.8331e-02, -1.7858e-01,  1.0551e-03],\n        [ 3.1812e-02,  1.9810e-01, -3.2425e-01,  1.7499e-01,  6.5023e-02,\n         -2.7012e-02, -5.3835e-02, -1.1370e-01],\n        [-1.0933e-01, -3.1570e-01, -2.4363e-01,  3.4544e-01,  5.4781e-02,\n          3.0707e-01,  2.5971e-01, -1.2124e-01],\n        [ 3.2161e-01,  2.7982e-01,  1.0611e-01,  3.2707e-01,  1.0689e-01,\n         -9.2469e-02,  9.4767e-02, -1.1612e-01],\n        [ 6.4410e-02,  1.4028e-01, -1.5087e-01, -4.8933e-03, -3.3217e-01,\n         -2.7432e-01,  2.8908e-01,  5.5443e-02],\n        [ 2.3581e-01,  3.3049e-01, -1.4468e-01, -3.0073e-01, -3.4131e-01,\n         -1.7568e-01,  1.8368e-01,  3.3466e-01],\n        [ 1.1844e-01,  2.9651e-01,  1.2575e-01,  8.4845e-02,  1.3569e-01,\n         -1.7152e-01,  2.1382e-01, -2.7274e-01],\n        [-2.3307e-01,  1.2550e-01, -1.6053e-01,  4.6724e-04,  1.6744e-01,\n         -8.3431e-02, -2.1397e-02,  2.6125e-01],\n        [-1.4300e-01, -3.1904e-01,  1.5692e-01, -2.2048e-01, -2.2839e-01,\n         -4.2602e-02, -2.8595e-01, -5.6474e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2604,  0.0819,  0.0289,  0.2795,  0.3294,  0.2681,  0.1469,  0.3344,\n        -0.1782,  0.1323, -0.1781, -0.0272,  0.2711,  0.3297, -0.0456,  0.3229,\n         0.0925, -0.2777,  0.0912, -0.1390, -0.1613, -0.1027,  0.3406,  0.0315,\n        -0.2343,  0.1569, -0.0649,  0.1456, -0.1481, -0.2935, -0.1652, -0.2408,\n        -0.1390,  0.2755, -0.0382, -0.0854, -0.3511,  0.1039, -0.1561, -0.2660,\n         0.0646, -0.3426, -0.0511,  0.2766,  0.1323,  0.2946, -0.0507,  0.0213,\n         0.0662, -0.0056,  0.0356, -0.3028, -0.2014, -0.3507,  0.3498, -0.0257,\n         0.0542,  0.1810,  0.1378,  0.1446, -0.1873, -0.0878,  0.1935,  0.3332],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0192,  0.0370, -0.0764,  ..., -0.0771,  0.1215,  0.0544],\n        [ 0.0513,  0.0620,  0.1197,  ..., -0.0623, -0.0116,  0.0432],\n        [-0.0239, -0.0721, -0.0722,  ..., -0.0895, -0.0853, -0.0279],\n        ...,\n        [-0.0130,  0.0192, -0.0578,  ..., -0.0640, -0.0777, -0.0998],\n        [ 0.0740,  0.0309, -0.0110,  ...,  0.0416, -0.0939, -0.1083],\n        [ 0.0633,  0.0371, -0.0219,  ..., -0.0838,  0.0385,  0.1120]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0335, -0.1228,  0.0033,  0.0389, -0.0918,  0.0901, -0.0004,  0.0010,\n        -0.0941, -0.0834,  0.0224, -0.0275, -0.0751, -0.0763,  0.0460, -0.0529,\n        -0.0978, -0.0200,  0.0317, -0.0793, -0.0017, -0.0824,  0.0136, -0.0586,\n         0.0485,  0.0687,  0.0545, -0.0934, -0.0681, -0.0616,  0.0055, -0.0722,\n        -0.1048,  0.1222, -0.0467,  0.1247, -0.0426,  0.0737,  0.0181, -0.0275,\n        -0.0632,  0.1079, -0.1087,  0.1026, -0.0325,  0.0156,  0.0124,  0.0807,\n         0.1151, -0.0615, -0.0078, -0.0130, -0.0809,  0.0413, -0.0714, -0.1010,\n         0.0957, -0.0864, -0.0381, -0.0369, -0.0547,  0.0441,  0.0613, -0.0326],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0810, -0.0842, -0.1071,  ..., -0.0820,  0.0048,  0.0640],\n        [ 0.0157,  0.0015, -0.0726,  ...,  0.1056,  0.0437,  0.0179],\n        [ 0.0636, -0.1185, -0.0036,  ..., -0.1188, -0.0426,  0.0081],\n        ...,\n        [ 0.0166,  0.0817, -0.0647,  ...,  0.0068, -0.1060,  0.0402],\n        [ 0.0188,  0.1239, -0.0314,  ...,  0.0885, -0.0335, -0.0081],\n        [ 0.0061,  0.0354, -0.0734,  ...,  0.0079,  0.0009,  0.0705]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0226,  0.1115, -0.0605, -0.0077,  0.0926,  0.0324, -0.1088,  0.1186,\n         0.0600, -0.0473,  0.0740, -0.1171,  0.0837, -0.1138,  0.0253, -0.0912,\n        -0.1182, -0.0687, -0.0145,  0.1056, -0.0436,  0.0321,  0.0726, -0.0560,\n         0.0733,  0.1004,  0.1217, -0.1059, -0.0447, -0.0550,  0.0709, -0.1198],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0770,  0.1399,  0.1209, -0.0830,  0.1369,  0.1660,  0.0683,  0.0992,\n         -0.0964,  0.0928,  0.0223,  0.0857, -0.1460,  0.0422,  0.1108, -0.1697,\n         -0.0607, -0.1237,  0.0235, -0.0517, -0.0519,  0.1201,  0.1662,  0.0141,\n          0.0451, -0.1417, -0.1215,  0.0534,  0.0093, -0.0728, -0.0164, -0.1647],\n        [-0.0061,  0.1377, -0.1379, -0.0594,  0.1145,  0.0347,  0.0709, -0.0994,\n          0.1706, -0.0320, -0.1605, -0.0284,  0.0108,  0.0294,  0.0726,  0.0009,\n          0.1424,  0.1664, -0.0728,  0.1707, -0.0239,  0.1604, -0.1228,  0.0100,\n         -0.1629,  0.1225,  0.1496,  0.0117, -0.0835,  0.1721, -0.0110, -0.0336],\n        [-0.0717, -0.0843,  0.0523, -0.1747,  0.1563, -0.1151, -0.0803,  0.1463,\n         -0.0639,  0.0342,  0.0325, -0.0173, -0.1083,  0.1234,  0.1662, -0.1301,\n          0.1748,  0.0477, -0.1170,  0.0721, -0.1063, -0.1407, -0.0038, -0.0353,\n          0.1094,  0.1651,  0.0740, -0.1640,  0.0929,  0.1538, -0.0106,  0.0623],\n        [-0.1170,  0.0016,  0.0060, -0.1057, -0.0654,  0.0341,  0.0807, -0.1175,\n          0.0585,  0.1045, -0.0158,  0.1107,  0.1406, -0.1377, -0.1738, -0.1430,\n          0.1032, -0.1699,  0.1581, -0.0593,  0.0142, -0.1432, -0.1247, -0.1017,\n         -0.0678,  0.1245,  0.1276, -0.0561,  0.1204, -0.1424,  0.0926,  0.0651],\n        [-0.0304,  0.0227, -0.0580, -0.1567, -0.1010,  0.0550, -0.0673,  0.1035,\n         -0.0324, -0.1472, -0.1543, -0.1257, -0.0689,  0.1402, -0.0751,  0.0758,\n         -0.0567, -0.0467,  0.0907,  0.1052, -0.0965, -0.0568, -0.0619, -0.1178,\n          0.1513,  0.0900,  0.0790,  0.0651,  0.0777, -0.0242, -0.0859, -0.1251],\n        [-0.0993,  0.0828, -0.0400,  0.0603,  0.0021,  0.1286, -0.0938, -0.0251,\n         -0.0380, -0.0675,  0.0503, -0.1177,  0.0093,  0.0731, -0.0876,  0.0039,\n          0.0242,  0.1049,  0.1106, -0.0772, -0.1047,  0.0806,  0.0455,  0.0024,\n          0.0193, -0.0929,  0.1319, -0.1147, -0.1650, -0.1433, -0.0295, -0.0355],\n        [-0.0737, -0.1141,  0.0774,  0.1129, -0.0597, -0.1151,  0.0934,  0.0035,\n          0.1123, -0.0143, -0.0320, -0.1304,  0.0180,  0.1681, -0.0151,  0.0509,\n         -0.1643,  0.1423,  0.1341, -0.0564, -0.1278,  0.0688, -0.1369, -0.1470,\n          0.1656, -0.1361,  0.1764,  0.0009,  0.0881, -0.1626, -0.0057, -0.0964],\n        [ 0.0864,  0.1280,  0.0212, -0.0183,  0.1639,  0.1524, -0.0691,  0.1530,\n         -0.0483,  0.0843, -0.0909, -0.0903, -0.0607,  0.0558,  0.0396, -0.1565,\n          0.0930,  0.0289,  0.1455,  0.1025, -0.1447, -0.0232, -0.0093, -0.0028,\n         -0.0236, -0.1712, -0.1091, -0.0015,  0.1215,  0.1504,  0.0115, -0.1050],\n        [-0.0184,  0.1151, -0.0348, -0.1456, -0.1343, -0.0751, -0.1045, -0.1276,\n          0.1212,  0.1630,  0.0794,  0.0788,  0.0939, -0.1200, -0.0423,  0.0725,\n          0.0823,  0.0184,  0.0207,  0.1528,  0.0464, -0.1748, -0.0526, -0.0545,\n          0.0613,  0.0042, -0.0733, -0.1548,  0.0848, -0.0959,  0.1300,  0.0288],\n        [-0.0364,  0.0193, -0.0598, -0.0791, -0.0863, -0.0402,  0.1275, -0.0209,\n          0.0223,  0.0798, -0.0681,  0.0859, -0.0285,  0.1271, -0.0091, -0.1135,\n         -0.0045,  0.1564, -0.0099,  0.1127, -0.1409, -0.0325,  0.0821, -0.1234,\n         -0.0689, -0.1453, -0.0481, -0.1142,  0.1734, -0.0244, -0.0412, -0.1295],\n        [-0.0425, -0.1150,  0.1741, -0.0775,  0.1455, -0.0528, -0.1185,  0.0656,\n         -0.1470,  0.0935, -0.0102,  0.1244,  0.1658, -0.1728, -0.1686,  0.1617,\n          0.1396, -0.1025, -0.0244,  0.1449, -0.0143, -0.0106, -0.1373,  0.0715,\n         -0.0939,  0.0529, -0.1146,  0.0970, -0.0362, -0.0854, -0.0077,  0.0867],\n        [ 0.0126,  0.0191,  0.0689, -0.1018, -0.1420,  0.0606, -0.1355,  0.1477,\n          0.0119,  0.0358,  0.0950,  0.0198, -0.1021,  0.0507,  0.0985,  0.1525,\n          0.1441, -0.1055, -0.0182, -0.1282,  0.0585,  0.0837,  0.1249,  0.0175,\n         -0.1042,  0.1279, -0.1487, -0.0220,  0.0351,  0.0635, -0.0778,  0.0867],\n        [ 0.0675, -0.0618, -0.1269,  0.1297, -0.0255, -0.0973, -0.0049, -0.1428,\n          0.1210, -0.0164, -0.0174, -0.0639, -0.0208,  0.0554,  0.1710,  0.0142,\n         -0.0389,  0.0453, -0.1760, -0.1494,  0.1507,  0.1062, -0.1303, -0.1132,\n          0.0903, -0.0033, -0.1657,  0.0296, -0.1017,  0.0139, -0.1724,  0.1343],\n        [-0.1296, -0.0049,  0.0270,  0.1233,  0.0431,  0.1085, -0.1259, -0.0841,\n          0.1161, -0.0152, -0.0482,  0.1164, -0.0068,  0.0707,  0.0286,  0.0704,\n         -0.1690, -0.0424,  0.1490, -0.0675,  0.1431,  0.0948,  0.0536, -0.0260,\n          0.1447, -0.0462,  0.1660,  0.0912,  0.0895,  0.1193,  0.1667,  0.0917],\n        [ 0.1007,  0.1252, -0.1363, -0.1233,  0.1017,  0.0999, -0.0376,  0.1227,\n         -0.1440, -0.0263, -0.1611, -0.1143, -0.1030, -0.0119, -0.1626, -0.1572,\n         -0.0641, -0.0271, -0.1142,  0.0964, -0.0825,  0.0463, -0.1006,  0.0297,\n         -0.0301,  0.0004, -0.0900,  0.0570,  0.1606, -0.0994,  0.0857, -0.0383],\n        [ 0.1259,  0.1061, -0.0066,  0.1015, -0.0959,  0.0029,  0.0371, -0.0137,\n         -0.0906,  0.0701, -0.0634, -0.1677, -0.1110, -0.0075, -0.0789,  0.1741,\n         -0.0035,  0.0979,  0.1071,  0.1219, -0.1319, -0.1621, -0.0915, -0.0116,\n          0.1749,  0.1664,  0.0879,  0.0964,  0.1585, -0.0061,  0.0746, -0.1453]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0192, -0.0519,  0.1477,  0.1540, -0.0286, -0.0147,  0.0516,  0.0624,\n         0.1368, -0.0140, -0.1581, -0.0294, -0.1151,  0.1598, -0.1005,  0.0532],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1574, -0.1500,  0.0148, -0.1180, -0.0535,  0.1528,  0.1021, -0.0975,\n         -0.1713, -0.2284, -0.1321,  0.0693, -0.0897, -0.0080, -0.1248,  0.0396],\n        [-0.1422,  0.0518, -0.0062, -0.1869,  0.0097,  0.2259, -0.1761,  0.2068,\n          0.0314, -0.1038, -0.2409, -0.1528, -0.1703,  0.1307, -0.0330,  0.0719],\n        [-0.1697, -0.1148, -0.0434,  0.0205, -0.2478,  0.0026,  0.2360, -0.2017,\n          0.2285, -0.1335,  0.0498, -0.2200,  0.0233, -0.0984, -0.2161,  0.2065],\n        [-0.0927,  0.1352, -0.1750, -0.0993, -0.2474,  0.0103,  0.0515, -0.0376,\n          0.1189, -0.1194, -0.2454,  0.0428,  0.2003, -0.1388,  0.0652, -0.0662],\n        [-0.1670,  0.0593, -0.1154,  0.1621,  0.0715,  0.1173,  0.0218, -0.2035,\n          0.0939, -0.0608, -0.0026, -0.1012, -0.2185, -0.2230,  0.0757,  0.1645],\n        [-0.0863, -0.0256,  0.0839,  0.1373, -0.0546,  0.0858, -0.0294,  0.0958,\n          0.2255,  0.2457,  0.2094,  0.1664,  0.0128,  0.1919,  0.2196,  0.1978],\n        [ 0.1421, -0.1641,  0.0648, -0.0459, -0.1153,  0.2301, -0.1554, -0.0727,\n         -0.0855, -0.1611, -0.0504, -0.2154, -0.1129, -0.1595,  0.1745,  0.0947],\n        [ 0.0591,  0.2467,  0.0034,  0.1773,  0.0345,  0.0787,  0.2241,  0.0872,\n         -0.2214, -0.1344,  0.1453,  0.2308,  0.1510, -0.0143, -0.0285, -0.0421]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2084,  0.0338, -0.1178, -0.0130,  0.0796, -0.0528, -0.1471, -0.2037],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1914,  0.0440,  0.1322,  0.1609, -0.2645,  0.0764,  0.2323, -0.2263]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0392], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x76f618ee0910>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x76f6151f0b50>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s166110000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s166110000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}