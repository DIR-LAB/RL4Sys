{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s168610000"
    },
    "q_lr":	0.0005,
    "seed":	168610000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x1728163e0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3342, -0.3343,  0.3528, -0.1485,  0.2352,  0.2462,  0.0467, -0.3076,\n         0.3406,  0.1340,  0.2736,  0.0611,  0.3169,  0.1077, -0.1140,  0.0352,\n        -0.0235,  0.3287, -0.0735,  0.1381, -0.3195, -0.1804,  0.1136, -0.2255,\n         0.1218, -0.2349,  0.0141, -0.3260,  0.1921, -0.1442,  0.1302, -0.0573],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1949,  0.0618,  0.0997, -0.0471,  0.2141, -0.2730,  0.1780,  0.1011],\n        [-0.3398, -0.0216, -0.2526, -0.1900, -0.1030,  0.2633, -0.2069,  0.2962],\n        [-0.0178,  0.0133, -0.2252, -0.1277,  0.1597,  0.2860, -0.1749,  0.1165],\n        [ 0.0773, -0.0663, -0.3129,  0.0242,  0.2749,  0.0556, -0.0315,  0.3053],\n        [-0.1014, -0.0811, -0.2166,  0.0488, -0.2929,  0.0436, -0.2248,  0.1729],\n        [-0.0401,  0.1440, -0.0806, -0.2812,  0.1690,  0.1173, -0.1654, -0.1596],\n        [-0.3348, -0.2673,  0.0644, -0.0152, -0.0995, -0.1255,  0.1538,  0.2989],\n        [-0.2928, -0.0155,  0.2062, -0.3028,  0.1327,  0.2304, -0.0743,  0.0913],\n        [ 0.1807,  0.1405, -0.0479, -0.0094,  0.3025,  0.0178, -0.0403, -0.1390],\n        [-0.3218,  0.0074, -0.0090, -0.3061,  0.1538,  0.0542,  0.2294,  0.2167],\n        [ 0.1800,  0.1360, -0.0061,  0.1493,  0.0823,  0.1014, -0.1914, -0.3237],\n        [ 0.0588, -0.2176,  0.3396,  0.1535, -0.0477,  0.2151, -0.1357,  0.2677],\n        [ 0.1262,  0.2687,  0.1642, -0.0981, -0.0777,  0.0469,  0.1007, -0.1364],\n        [-0.0591,  0.1785, -0.1513, -0.2333, -0.0142,  0.1282, -0.2222, -0.1734],\n        [ 0.2358, -0.2645,  0.1733, -0.1115,  0.1569, -0.2326,  0.0615, -0.3503],\n        [ 0.0043,  0.3327, -0.0890, -0.3002, -0.0385,  0.1972, -0.2179,  0.3070],\n        [ 0.0689,  0.2507, -0.1459,  0.2449, -0.3048, -0.0422,  0.0147,  0.3131],\n        [-0.3353, -0.1075,  0.1196, -0.3085,  0.2853, -0.1734,  0.1950,  0.0747],\n        [ 0.1982,  0.1027, -0.0814,  0.1245,  0.2976,  0.0705, -0.1724,  0.1957],\n        [ 0.2728,  0.1247,  0.3192, -0.0289, -0.1977,  0.1174, -0.0131, -0.2226],\n        [ 0.2752, -0.3216,  0.1286, -0.2174, -0.0846,  0.1366, -0.0303, -0.2180],\n        [ 0.3487,  0.1560, -0.0304,  0.0315,  0.2414,  0.1468,  0.1763, -0.0221],\n        [-0.1707, -0.2296,  0.0644,  0.3288, -0.1785,  0.1108,  0.2828,  0.1409],\n        [ 0.2647,  0.3022,  0.0549,  0.2026,  0.1737, -0.1171,  0.0607, -0.0271],\n        [ 0.3398, -0.2143, -0.1131,  0.1069,  0.2799, -0.1062, -0.2729,  0.0201],\n        [ 0.0124,  0.2138, -0.0059, -0.1544, -0.0178, -0.0230, -0.2275,  0.0428],\n        [ 0.2647,  0.1180, -0.2979, -0.1566,  0.1111, -0.0445,  0.2625,  0.1189],\n        [-0.1905,  0.0824, -0.3484,  0.1107,  0.0486,  0.3196, -0.3411,  0.2545],\n        [-0.1285, -0.3229,  0.1306,  0.3298, -0.0596, -0.3255,  0.3432,  0.2436],\n        [ 0.0528,  0.3176,  0.1965,  0.0583, -0.1139, -0.1307,  0.2167,  0.1156],\n        [ 0.0293,  0.3532,  0.3055,  0.1195, -0.1648,  0.3408,  0.1219, -0.3047],\n        [-0.0327,  0.2474, -0.2140, -0.2138, -0.1052, -0.0118, -0.1705, -0.2171]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0228, -0.0750, -0.0204, -0.0653, -0.1416, -0.0571, -0.1186, -0.1233,\n        -0.0553, -0.1176, -0.0294, -0.0835, -0.1713,  0.0495, -0.0398, -0.0753],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 6.2962e-02, -1.1086e-01, -7.9292e-02, -1.2035e-01, -7.4954e-02,\n         -1.0761e-01,  6.0654e-02, -1.4705e-01,  1.1285e-02,  1.0904e-01,\n         -1.0965e-01,  5.9359e-02, -1.6434e-02,  5.7581e-02, -5.3654e-02,\n         -1.0369e-01, -8.2613e-02,  1.1474e-01, -9.6848e-02, -1.5551e-02,\n         -8.1555e-02, -1.6844e-01,  8.3938e-03,  7.9690e-02, -7.1397e-02,\n          1.3923e-01, -1.0969e-01, -1.7248e-02, -6.4897e-02,  3.4893e-02,\n          1.2172e-02,  7.4474e-02],\n        [ 1.1564e-01, -9.1725e-02, -5.1957e-02, -1.0619e-01,  6.2119e-03,\n         -2.9680e-02, -2.8938e-02,  4.8100e-02,  1.9697e-02,  1.6208e-02,\n         -1.2487e-01, -1.0640e-01,  5.4911e-03, -5.3673e-02,  1.3284e-01,\n          3.3582e-02, -1.4947e-01,  8.2485e-02,  1.7317e-01,  9.9660e-03,\n         -1.0934e-02,  7.2865e-03, -1.2540e-01,  1.4222e-01, -1.6220e-01,\n         -8.0604e-02, -7.2968e-02,  1.4144e-01, -1.3648e-01,  5.2797e-02,\n          8.4550e-02,  1.4565e-01],\n        [-8.1137e-02, -1.5571e-01, -1.1395e-01, -1.5096e-01, -1.6591e-01,\n          4.4779e-02, -9.7735e-02,  4.2826e-02,  5.6925e-02,  7.0637e-02,\n          5.7860e-02,  1.6386e-01, -1.2672e-01, -9.0392e-02,  3.0539e-02,\n         -9.3169e-02,  1.3288e-01,  8.1713e-02, -1.4309e-02,  1.3279e-01,\n         -1.0694e-01,  1.3491e-02,  2.7671e-02, -3.9188e-02,  1.4412e-01,\n          6.0029e-02, -4.5468e-02, -1.5319e-01, -2.7021e-02, -9.8204e-02,\n          4.5737e-02, -6.3565e-02],\n        [-3.2873e-02,  1.2229e-01,  1.4152e-01,  9.4792e-02,  2.5565e-02,\n         -1.1999e-01,  1.6715e-01,  7.8855e-02,  4.3387e-02,  1.6272e-01,\n         -1.0859e-01,  7.1244e-02,  1.1020e-01,  1.7298e-01,  8.4022e-02,\n          2.5062e-02, -5.5285e-02,  1.2759e-02,  2.7766e-02, -1.0049e-01,\n         -1.5337e-01,  2.8150e-02, -3.4012e-02, -1.0887e-01,  1.1531e-01,\n          1.2140e-01,  7.0461e-02, -2.7230e-02,  1.3861e-01, -1.2938e-01,\n         -1.5098e-02, -1.7594e-02],\n        [ 9.7931e-02, -1.1275e-01,  1.5569e-01,  1.4557e-01, -6.4782e-02,\n         -4.8355e-04,  3.3522e-02, -9.9520e-02, -1.5466e-01, -3.5438e-02,\n          3.9573e-02,  3.2015e-02, -6.0950e-02,  5.8553e-02,  1.5684e-01,\n         -9.5152e-02, -4.9056e-02, -6.7563e-03,  4.8647e-02,  1.6461e-01,\n          9.6035e-02,  8.2042e-02, -3.4199e-02, -7.7559e-04, -4.6129e-02,\n          7.9622e-02,  2.0943e-03,  4.0769e-02,  1.5005e-01,  1.1190e-01,\n         -8.9149e-02,  8.0278e-02],\n        [ 7.4196e-02,  1.5796e-01, -1.2949e-01,  1.1823e-01,  6.8635e-02,\n          1.1560e-01,  7.3587e-02, -1.5188e-01, -8.4915e-02, -1.6783e-01,\n         -1.6961e-01,  1.0624e-01, -1.6915e-01, -1.5546e-01,  7.1480e-02,\n          5.9082e-02, -2.1346e-02,  8.2386e-03, -1.7393e-01, -1.3805e-01,\n          1.5709e-01, -1.5798e-01, -2.7855e-02,  7.2824e-02,  7.9749e-02,\n          1.2762e-01, -5.2284e-02,  1.1737e-01, -6.3493e-02, -1.4210e-01,\n         -1.3805e-01, -1.6049e-01],\n        [-8.0735e-03, -1.3061e-01, -6.9409e-02, -1.5104e-01, -5.1762e-02,\n          1.0868e-01,  1.2023e-01,  7.2613e-02, -1.3244e-01,  1.4411e-01,\n          8.8691e-02, -3.3075e-02,  2.1258e-02,  1.3348e-01,  1.9677e-02,\n          1.3945e-01, -6.2892e-04, -1.1654e-01, -8.9150e-02, -2.3149e-02,\n         -1.6858e-01,  6.0604e-02, -1.3674e-01, -7.5903e-02, -8.9421e-02,\n         -1.6780e-01,  3.3566e-02,  1.4095e-01,  1.7287e-01, -4.8434e-02,\n         -4.6380e-02, -5.4902e-02],\n        [-7.7181e-03, -1.0817e-01,  1.8903e-02, -1.3598e-01, -1.6630e-01,\n         -7.4994e-03, -1.6347e-01, -1.4973e-01,  1.1146e-01, -8.4147e-02,\n          4.1460e-02,  2.9873e-02, -4.5215e-02, -6.1194e-02,  8.8643e-02,\n          8.3960e-02, -3.1330e-02,  5.1325e-02, -4.0447e-02,  8.2981e-02,\n          5.3126e-02, -3.0698e-02,  1.6357e-01, -4.0292e-02,  1.0083e-01,\n         -3.8730e-02, -9.5994e-02, -1.5382e-01,  6.2616e-02,  1.5452e-01,\n          7.9980e-02, -6.9498e-02],\n        [ 1.6813e-01, -6.3522e-02,  1.4382e-01, -1.1965e-01,  7.0841e-02,\n          9.6303e-02, -1.0744e-01,  2.7451e-03, -7.2232e-02,  3.0785e-02,\n          1.4123e-01,  9.5859e-02, -2.3943e-02,  1.5311e-02,  1.3541e-01,\n         -1.0186e-01, -5.2357e-02,  2.4423e-02, -4.3836e-02, -1.5029e-01,\n          7.4304e-02, -3.2594e-02,  1.4408e-01,  1.4134e-01,  1.3501e-01,\n         -3.7344e-02, -1.6805e-01, -1.7307e-01, -2.4290e-02, -1.1240e-01,\n          6.1300e-02,  1.1756e-01],\n        [ 3.5062e-03, -6.5948e-03, -1.5307e-01,  4.4012e-02,  1.5443e-01,\n          3.9894e-02, -1.4149e-01,  8.4508e-02,  9.4991e-02, -3.2063e-02,\n         -1.0468e-01,  3.9493e-02,  1.0764e-01,  1.4730e-01, -1.9487e-02,\n         -1.1565e-01, -1.8945e-03, -3.6684e-02, -1.3162e-01, -1.7486e-01,\n          1.4732e-02,  2.4743e-03, -3.9897e-02, -5.8800e-02, -7.9738e-02,\n         -1.6437e-02,  4.3048e-02,  8.2468e-02, -8.4238e-03,  7.2533e-02,\n         -1.9779e-02,  7.3497e-02],\n        [ 1.5074e-01, -1.6317e-01,  8.0715e-02, -9.3806e-02, -3.6708e-02,\n         -8.6508e-02, -1.9507e-02, -1.8947e-02, -6.5446e-02,  9.1595e-02,\n          8.5180e-02, -1.6842e-01, -1.0050e-01, -7.1081e-05, -1.2048e-01,\n         -4.3144e-02, -4.1060e-02,  7.6038e-02, -3.4530e-02, -3.3182e-02,\n         -5.9595e-02,  1.4704e-01,  1.6095e-01,  1.3959e-01, -4.7789e-02,\n         -1.5896e-01,  1.2357e-01, -1.3659e-01, -4.1222e-02, -6.9303e-02,\n         -3.3850e-02,  2.6160e-03],\n        [-3.0491e-02, -1.0748e-01, -8.7453e-02,  1.0744e-01, -5.5443e-02,\n          1.7092e-01, -1.5573e-01,  2.2196e-02, -1.2725e-01, -3.3675e-02,\n          9.3392e-03,  5.1522e-02,  5.3395e-02, -4.8039e-02, -9.9994e-02,\n         -1.9224e-02, -1.1045e-01, -9.9084e-03, -5.1460e-02,  1.3145e-01,\n         -9.2152e-02, -8.5060e-02, -7.6922e-02, -1.5566e-01, -1.6571e-01,\n          2.8986e-02,  3.2425e-02, -4.7024e-02,  1.5301e-01,  4.6833e-02,\n          1.5092e-01, -4.1806e-02],\n        [-1.1054e-02,  1.3575e-01,  6.3764e-02, -1.1347e-01, -3.1058e-02,\n          1.5408e-01, -1.0116e-01,  6.6374e-02, -1.6521e-01,  1.3853e-01,\n          5.8525e-02,  1.3254e-01,  1.3305e-01, -6.5284e-02, -1.3652e-01,\n         -1.7135e-01,  1.0939e-01,  1.3847e-01,  9.8543e-02, -2.7225e-02,\n          5.2148e-02, -1.4331e-01, -2.5821e-02,  5.2289e-03, -1.1936e-01,\n          1.3897e-01,  7.3737e-02,  1.4435e-01,  6.4520e-02,  1.3620e-01,\n         -1.6288e-01, -1.6045e-01],\n        [-1.2599e-01,  2.2052e-02, -3.8405e-02,  1.5524e-01, -1.6514e-01,\n          4.7667e-02,  3.0703e-02, -8.6144e-03, -1.2332e-01, -1.1921e-01,\n          1.4036e-01, -9.5977e-02, -1.7154e-01,  3.1199e-02, -9.9964e-02,\n         -2.7764e-03,  1.2640e-01,  1.8402e-03,  1.6157e-01,  8.1427e-02,\n         -1.2922e-01,  2.8736e-03,  7.6727e-02,  1.3538e-01, -3.1054e-02,\n          8.8473e-02, -7.7599e-02, -6.9446e-02, -1.7624e-01, -9.3192e-02,\n         -2.5458e-02, -1.7463e-01],\n        [ 4.4889e-02,  2.9758e-02, -8.2484e-02, -5.8179e-02,  8.3237e-02,\n          6.7803e-03, -9.2296e-02,  1.5357e-01, -3.2890e-02,  8.3080e-03,\n         -8.5906e-02, -6.6886e-02,  1.5026e-01, -1.0265e-01,  1.1909e-01,\n         -5.5671e-02, -8.1952e-02, -5.2661e-02, -7.8131e-02,  1.6950e-01,\n          3.2450e-02, -1.6689e-01,  1.0179e-01, -7.2022e-02, -6.1240e-02,\n          1.6045e-01, -3.4299e-02,  1.9802e-02,  1.6771e-02, -1.2538e-01,\n          1.2682e-01,  4.6368e-02],\n        [ 1.0285e-02, -2.4072e-02, -1.7069e-01, -8.7652e-02, -2.1482e-02,\n         -1.7283e-01, -1.7236e-01,  2.5782e-02, -2.7607e-02, -1.8107e-02,\n          5.0824e-02, -4.5422e-02,  4.6294e-02, -5.7569e-02,  6.5833e-02,\n          1.0032e-01,  1.4885e-01,  4.7608e-02, -1.1937e-01, -1.1604e-03,\n         -7.0969e-03, -6.5059e-02,  1.0524e-04,  1.2749e-01,  5.3259e-02,\n          1.0659e-01, -1.2262e-01, -7.0735e-02,  1.0457e-02,  1.1984e-01,\n          4.6068e-02,  6.0698e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1955, -0.1706, -0.2396, -0.1278,  0.2187, -0.1059,  0.0043,  0.0144],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2476,  0.2096,  0.2219, -0.0194, -0.2155, -0.0680,  0.0574, -0.0822,\n         -0.0135, -0.1468,  0.0882,  0.0407,  0.2145,  0.1790,  0.0326,  0.1599],\n        [ 0.2287, -0.2468, -0.1681, -0.0087, -0.2091, -0.1480, -0.1751,  0.0427,\n          0.1591,  0.2060,  0.2427,  0.1819,  0.1504, -0.1579,  0.1016,  0.2018],\n        [-0.0686,  0.0012, -0.0923,  0.0610, -0.0598, -0.2158,  0.2367, -0.1045,\n          0.0100,  0.1617,  0.1399,  0.0323, -0.1637, -0.2449, -0.0171, -0.1884],\n        [ 0.0918,  0.0176, -0.1797,  0.1056,  0.1680,  0.2414,  0.1204, -0.0441,\n          0.2499, -0.0958,  0.0611,  0.2262,  0.0371,  0.0559,  0.1269,  0.2402],\n        [ 0.1532, -0.0981, -0.1464,  0.1656, -0.1287,  0.0725, -0.1869,  0.0315,\n          0.0696, -0.1104,  0.1051,  0.2378, -0.0100,  0.2025,  0.0411, -0.2248],\n        [ 0.0821,  0.0462,  0.0086, -0.1252, -0.1330, -0.1837, -0.0462, -0.1535,\n          0.0645, -0.1158,  0.0384,  0.0822,  0.1282,  0.1837,  0.1175, -0.1307],\n        [-0.1652, -0.1558, -0.1967, -0.1108,  0.1071,  0.0978,  0.2383, -0.2412,\n          0.1257, -0.0507, -0.1972,  0.0774, -0.0678,  0.0644, -0.2447,  0.0405],\n        [ 0.0698, -0.2294,  0.2264,  0.2302, -0.1134, -0.0208, -0.0438,  0.2480,\n         -0.1171,  0.0097, -0.1610,  0.1609, -0.2040, -0.0470,  0.1229, -0.2099]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0691], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3228,  0.0338,  0.0814,  0.2923,  0.2950,  0.1881, -0.0054,  0.1674]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1949,  0.0618,  0.0997, -0.0471,  0.2141, -0.2730,  0.1780,  0.1011],\n        [-0.3398, -0.0216, -0.2526, -0.1900, -0.1030,  0.2633, -0.2069,  0.2962],\n        [-0.0178,  0.0133, -0.2252, -0.1277,  0.1597,  0.2860, -0.1749,  0.1165],\n        [ 0.0773, -0.0663, -0.3129,  0.0242,  0.2749,  0.0556, -0.0315,  0.3053],\n        [-0.1014, -0.0811, -0.2166,  0.0488, -0.2929,  0.0436, -0.2248,  0.1729],\n        [-0.0401,  0.1440, -0.0806, -0.2812,  0.1690,  0.1173, -0.1654, -0.1596],\n        [-0.3348, -0.2673,  0.0644, -0.0152, -0.0995, -0.1255,  0.1538,  0.2989],\n        [-0.2928, -0.0155,  0.2062, -0.3028,  0.1327,  0.2304, -0.0743,  0.0913],\n        [ 0.1807,  0.1405, -0.0479, -0.0094,  0.3025,  0.0178, -0.0403, -0.1390],\n        [-0.3218,  0.0074, -0.0090, -0.3061,  0.1538,  0.0542,  0.2294,  0.2167],\n        [ 0.1800,  0.1360, -0.0061,  0.1493,  0.0823,  0.1014, -0.1914, -0.3237],\n        [ 0.0588, -0.2176,  0.3396,  0.1535, -0.0477,  0.2151, -0.1357,  0.2677],\n        [ 0.1262,  0.2687,  0.1642, -0.0981, -0.0777,  0.0469,  0.1007, -0.1364],\n        [-0.0591,  0.1785, -0.1513, -0.2333, -0.0142,  0.1282, -0.2222, -0.1734],\n        [ 0.2358, -0.2645,  0.1733, -0.1115,  0.1569, -0.2326,  0.0615, -0.3503],\n        [ 0.0043,  0.3327, -0.0890, -0.3002, -0.0385,  0.1972, -0.2179,  0.3070],\n        [ 0.0689,  0.2507, -0.1459,  0.2449, -0.3048, -0.0422,  0.0147,  0.3131],\n        [-0.3353, -0.1075,  0.1196, -0.3085,  0.2853, -0.1734,  0.1950,  0.0747],\n        [ 0.1982,  0.1027, -0.0814,  0.1245,  0.2976,  0.0705, -0.1724,  0.1957],\n        [ 0.2728,  0.1247,  0.3192, -0.0289, -0.1977,  0.1174, -0.0131, -0.2226],\n        [ 0.2752, -0.3216,  0.1286, -0.2174, -0.0846,  0.1366, -0.0303, -0.2180],\n        [ 0.3487,  0.1560, -0.0304,  0.0315,  0.2414,  0.1468,  0.1763, -0.0221],\n        [-0.1707, -0.2296,  0.0644,  0.3288, -0.1785,  0.1108,  0.2828,  0.1409],\n        [ 0.2647,  0.3022,  0.0549,  0.2026,  0.1737, -0.1171,  0.0607, -0.0271],\n        [ 0.3398, -0.2143, -0.1131,  0.1069,  0.2799, -0.1062, -0.2729,  0.0201],\n        [ 0.0124,  0.2138, -0.0059, -0.1544, -0.0178, -0.0230, -0.2275,  0.0428],\n        [ 0.2647,  0.1180, -0.2979, -0.1566,  0.1111, -0.0445,  0.2625,  0.1189],\n        [-0.1905,  0.0824, -0.3484,  0.1107,  0.0486,  0.3196, -0.3411,  0.2545],\n        [-0.1285, -0.3229,  0.1306,  0.3298, -0.0596, -0.3255,  0.3432,  0.2436],\n        [ 0.0528,  0.3176,  0.1965,  0.0583, -0.1139, -0.1307,  0.2167,  0.1156],\n        [ 0.0293,  0.3532,  0.3055,  0.1195, -0.1648,  0.3408,  0.1219, -0.3047],\n        [-0.0327,  0.2474, -0.2140, -0.2138, -0.1052, -0.0118, -0.1705, -0.2171]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.3342, -0.3343,  0.3528, -0.1485,  0.2352,  0.2462,  0.0467, -0.3076,\n         0.3406,  0.1340,  0.2736,  0.0611,  0.3169,  0.1077, -0.1140,  0.0352,\n        -0.0235,  0.3287, -0.0735,  0.1381, -0.3195, -0.1804,  0.1136, -0.2255,\n         0.1218, -0.2349,  0.0141, -0.3260,  0.1921, -0.1442,  0.1302, -0.0573],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 6.2962e-02, -1.1086e-01, -7.9292e-02, -1.2035e-01, -7.4954e-02,\n         -1.0761e-01,  6.0654e-02, -1.4705e-01,  1.1285e-02,  1.0904e-01,\n         -1.0965e-01,  5.9359e-02, -1.6434e-02,  5.7581e-02, -5.3654e-02,\n         -1.0369e-01, -8.2613e-02,  1.1474e-01, -9.6848e-02, -1.5551e-02,\n         -8.1555e-02, -1.6844e-01,  8.3938e-03,  7.9690e-02, -7.1397e-02,\n          1.3923e-01, -1.0969e-01, -1.7248e-02, -6.4897e-02,  3.4893e-02,\n          1.2172e-02,  7.4474e-02],\n        [ 1.1564e-01, -9.1725e-02, -5.1957e-02, -1.0619e-01,  6.2119e-03,\n         -2.9680e-02, -2.8938e-02,  4.8100e-02,  1.9697e-02,  1.6208e-02,\n         -1.2487e-01, -1.0640e-01,  5.4911e-03, -5.3673e-02,  1.3284e-01,\n          3.3582e-02, -1.4947e-01,  8.2485e-02,  1.7317e-01,  9.9660e-03,\n         -1.0934e-02,  7.2865e-03, -1.2540e-01,  1.4222e-01, -1.6220e-01,\n         -8.0604e-02, -7.2968e-02,  1.4144e-01, -1.3648e-01,  5.2797e-02,\n          8.4550e-02,  1.4565e-01],\n        [-8.1137e-02, -1.5571e-01, -1.1395e-01, -1.5096e-01, -1.6591e-01,\n          4.4779e-02, -9.7735e-02,  4.2826e-02,  5.6925e-02,  7.0637e-02,\n          5.7860e-02,  1.6386e-01, -1.2672e-01, -9.0392e-02,  3.0539e-02,\n         -9.3169e-02,  1.3288e-01,  8.1713e-02, -1.4309e-02,  1.3279e-01,\n         -1.0694e-01,  1.3491e-02,  2.7671e-02, -3.9188e-02,  1.4412e-01,\n          6.0029e-02, -4.5468e-02, -1.5319e-01, -2.7021e-02, -9.8204e-02,\n          4.5737e-02, -6.3565e-02],\n        [-3.2873e-02,  1.2229e-01,  1.4152e-01,  9.4792e-02,  2.5565e-02,\n         -1.1999e-01,  1.6715e-01,  7.8855e-02,  4.3387e-02,  1.6272e-01,\n         -1.0859e-01,  7.1244e-02,  1.1020e-01,  1.7298e-01,  8.4022e-02,\n          2.5062e-02, -5.5285e-02,  1.2759e-02,  2.7766e-02, -1.0049e-01,\n         -1.5337e-01,  2.8150e-02, -3.4012e-02, -1.0887e-01,  1.1531e-01,\n          1.2140e-01,  7.0461e-02, -2.7230e-02,  1.3861e-01, -1.2938e-01,\n         -1.5098e-02, -1.7594e-02],\n        [ 9.7931e-02, -1.1275e-01,  1.5569e-01,  1.4557e-01, -6.4782e-02,\n         -4.8355e-04,  3.3522e-02, -9.9520e-02, -1.5466e-01, -3.5438e-02,\n          3.9573e-02,  3.2015e-02, -6.0950e-02,  5.8553e-02,  1.5684e-01,\n         -9.5152e-02, -4.9056e-02, -6.7563e-03,  4.8647e-02,  1.6461e-01,\n          9.6035e-02,  8.2042e-02, -3.4199e-02, -7.7559e-04, -4.6129e-02,\n          7.9622e-02,  2.0943e-03,  4.0769e-02,  1.5005e-01,  1.1190e-01,\n         -8.9149e-02,  8.0278e-02],\n        [ 7.4196e-02,  1.5796e-01, -1.2949e-01,  1.1823e-01,  6.8635e-02,\n          1.1560e-01,  7.3587e-02, -1.5188e-01, -8.4915e-02, -1.6783e-01,\n         -1.6961e-01,  1.0624e-01, -1.6915e-01, -1.5546e-01,  7.1480e-02,\n          5.9082e-02, -2.1346e-02,  8.2386e-03, -1.7393e-01, -1.3805e-01,\n          1.5709e-01, -1.5798e-01, -2.7855e-02,  7.2824e-02,  7.9749e-02,\n          1.2762e-01, -5.2284e-02,  1.1737e-01, -6.3493e-02, -1.4210e-01,\n         -1.3805e-01, -1.6049e-01],\n        [-8.0735e-03, -1.3061e-01, -6.9409e-02, -1.5104e-01, -5.1762e-02,\n          1.0868e-01,  1.2023e-01,  7.2613e-02, -1.3244e-01,  1.4411e-01,\n          8.8691e-02, -3.3075e-02,  2.1258e-02,  1.3348e-01,  1.9677e-02,\n          1.3945e-01, -6.2892e-04, -1.1654e-01, -8.9150e-02, -2.3149e-02,\n         -1.6858e-01,  6.0604e-02, -1.3674e-01, -7.5903e-02, -8.9421e-02,\n         -1.6780e-01,  3.3566e-02,  1.4095e-01,  1.7287e-01, -4.8434e-02,\n         -4.6380e-02, -5.4902e-02],\n        [-7.7181e-03, -1.0817e-01,  1.8903e-02, -1.3598e-01, -1.6630e-01,\n         -7.4994e-03, -1.6347e-01, -1.4973e-01,  1.1146e-01, -8.4147e-02,\n          4.1460e-02,  2.9873e-02, -4.5215e-02, -6.1194e-02,  8.8643e-02,\n          8.3960e-02, -3.1330e-02,  5.1325e-02, -4.0447e-02,  8.2981e-02,\n          5.3126e-02, -3.0698e-02,  1.6357e-01, -4.0292e-02,  1.0083e-01,\n         -3.8730e-02, -9.5994e-02, -1.5382e-01,  6.2616e-02,  1.5452e-01,\n          7.9980e-02, -6.9498e-02],\n        [ 1.6813e-01, -6.3522e-02,  1.4382e-01, -1.1965e-01,  7.0841e-02,\n          9.6303e-02, -1.0744e-01,  2.7451e-03, -7.2232e-02,  3.0785e-02,\n          1.4123e-01,  9.5859e-02, -2.3943e-02,  1.5311e-02,  1.3541e-01,\n         -1.0186e-01, -5.2357e-02,  2.4423e-02, -4.3836e-02, -1.5029e-01,\n          7.4304e-02, -3.2594e-02,  1.4408e-01,  1.4134e-01,  1.3501e-01,\n         -3.7344e-02, -1.6805e-01, -1.7307e-01, -2.4290e-02, -1.1240e-01,\n          6.1300e-02,  1.1756e-01],\n        [ 3.5062e-03, -6.5948e-03, -1.5307e-01,  4.4012e-02,  1.5443e-01,\n          3.9894e-02, -1.4149e-01,  8.4508e-02,  9.4991e-02, -3.2063e-02,\n         -1.0468e-01,  3.9493e-02,  1.0764e-01,  1.4730e-01, -1.9487e-02,\n         -1.1565e-01, -1.8945e-03, -3.6684e-02, -1.3162e-01, -1.7486e-01,\n          1.4732e-02,  2.4743e-03, -3.9897e-02, -5.8800e-02, -7.9738e-02,\n         -1.6437e-02,  4.3048e-02,  8.2468e-02, -8.4238e-03,  7.2533e-02,\n         -1.9779e-02,  7.3497e-02],\n        [ 1.5074e-01, -1.6317e-01,  8.0715e-02, -9.3806e-02, -3.6708e-02,\n         -8.6508e-02, -1.9507e-02, -1.8947e-02, -6.5446e-02,  9.1595e-02,\n          8.5180e-02, -1.6842e-01, -1.0050e-01, -7.1081e-05, -1.2048e-01,\n         -4.3144e-02, -4.1060e-02,  7.6038e-02, -3.4530e-02, -3.3182e-02,\n         -5.9595e-02,  1.4704e-01,  1.6095e-01,  1.3959e-01, -4.7789e-02,\n         -1.5896e-01,  1.2357e-01, -1.3659e-01, -4.1222e-02, -6.9303e-02,\n         -3.3850e-02,  2.6160e-03],\n        [-3.0491e-02, -1.0748e-01, -8.7453e-02,  1.0744e-01, -5.5443e-02,\n          1.7092e-01, -1.5573e-01,  2.2196e-02, -1.2725e-01, -3.3675e-02,\n          9.3392e-03,  5.1522e-02,  5.3395e-02, -4.8039e-02, -9.9994e-02,\n         -1.9224e-02, -1.1045e-01, -9.9084e-03, -5.1460e-02,  1.3145e-01,\n         -9.2152e-02, -8.5060e-02, -7.6922e-02, -1.5566e-01, -1.6571e-01,\n          2.8986e-02,  3.2425e-02, -4.7024e-02,  1.5301e-01,  4.6833e-02,\n          1.5092e-01, -4.1806e-02],\n        [-1.1054e-02,  1.3575e-01,  6.3764e-02, -1.1347e-01, -3.1058e-02,\n          1.5408e-01, -1.0116e-01,  6.6374e-02, -1.6521e-01,  1.3853e-01,\n          5.8525e-02,  1.3254e-01,  1.3305e-01, -6.5284e-02, -1.3652e-01,\n         -1.7135e-01,  1.0939e-01,  1.3847e-01,  9.8543e-02, -2.7225e-02,\n          5.2148e-02, -1.4331e-01, -2.5821e-02,  5.2289e-03, -1.1936e-01,\n          1.3897e-01,  7.3737e-02,  1.4435e-01,  6.4520e-02,  1.3620e-01,\n         -1.6288e-01, -1.6045e-01],\n        [-1.2599e-01,  2.2052e-02, -3.8405e-02,  1.5524e-01, -1.6514e-01,\n          4.7667e-02,  3.0703e-02, -8.6144e-03, -1.2332e-01, -1.1921e-01,\n          1.4036e-01, -9.5977e-02, -1.7154e-01,  3.1199e-02, -9.9964e-02,\n         -2.7764e-03,  1.2640e-01,  1.8402e-03,  1.6157e-01,  8.1427e-02,\n         -1.2922e-01,  2.8736e-03,  7.6727e-02,  1.3538e-01, -3.1054e-02,\n          8.8473e-02, -7.7599e-02, -6.9446e-02, -1.7624e-01, -9.3192e-02,\n         -2.5458e-02, -1.7463e-01],\n        [ 4.4889e-02,  2.9758e-02, -8.2484e-02, -5.8179e-02,  8.3237e-02,\n          6.7803e-03, -9.2296e-02,  1.5357e-01, -3.2890e-02,  8.3080e-03,\n         -8.5906e-02, -6.6886e-02,  1.5026e-01, -1.0265e-01,  1.1909e-01,\n         -5.5671e-02, -8.1952e-02, -5.2661e-02, -7.8131e-02,  1.6950e-01,\n          3.2450e-02, -1.6689e-01,  1.0179e-01, -7.2022e-02, -6.1240e-02,\n          1.6045e-01, -3.4299e-02,  1.9802e-02,  1.6771e-02, -1.2538e-01,\n          1.2682e-01,  4.6368e-02],\n        [ 1.0285e-02, -2.4072e-02, -1.7069e-01, -8.7652e-02, -2.1482e-02,\n         -1.7283e-01, -1.7236e-01,  2.5782e-02, -2.7607e-02, -1.8107e-02,\n          5.0824e-02, -4.5422e-02,  4.6294e-02, -5.7569e-02,  6.5833e-02,\n          1.0032e-01,  1.4885e-01,  4.7608e-02, -1.1937e-01, -1.1604e-03,\n         -7.0969e-03, -6.5059e-02,  1.0524e-04,  1.2749e-01,  5.3259e-02,\n          1.0659e-01, -1.2262e-01, -7.0735e-02,  1.0457e-02,  1.1984e-01,\n          4.6068e-02,  6.0698e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0228, -0.0750, -0.0204, -0.0653, -0.1416, -0.0571, -0.1186, -0.1233,\n        -0.0553, -0.1176, -0.0294, -0.0835, -0.1713,  0.0495, -0.0398, -0.0753],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2476,  0.2096,  0.2219, -0.0194, -0.2155, -0.0680,  0.0574, -0.0822,\n         -0.0135, -0.1468,  0.0882,  0.0407,  0.2145,  0.1790,  0.0326,  0.1599],\n        [ 0.2287, -0.2468, -0.1681, -0.0087, -0.2091, -0.1480, -0.1751,  0.0427,\n          0.1591,  0.2060,  0.2427,  0.1819,  0.1504, -0.1579,  0.1016,  0.2018],\n        [-0.0686,  0.0012, -0.0923,  0.0610, -0.0598, -0.2158,  0.2367, -0.1045,\n          0.0100,  0.1617,  0.1399,  0.0323, -0.1637, -0.2449, -0.0171, -0.1884],\n        [ 0.0918,  0.0176, -0.1797,  0.1056,  0.1680,  0.2414,  0.1204, -0.0441,\n          0.2499, -0.0958,  0.0611,  0.2262,  0.0371,  0.0559,  0.1269,  0.2402],\n        [ 0.1532, -0.0981, -0.1464,  0.1656, -0.1287,  0.0725, -0.1869,  0.0315,\n          0.0696, -0.1104,  0.1051,  0.2378, -0.0100,  0.2025,  0.0411, -0.2248],\n        [ 0.0821,  0.0462,  0.0086, -0.1252, -0.1330, -0.1837, -0.0462, -0.1535,\n          0.0645, -0.1158,  0.0384,  0.0822,  0.1282,  0.1837,  0.1175, -0.1307],\n        [-0.1652, -0.1558, -0.1967, -0.1108,  0.1071,  0.0978,  0.2383, -0.2412,\n          0.1257, -0.0507, -0.1972,  0.0774, -0.0678,  0.0644, -0.2447,  0.0405],\n        [ 0.0698, -0.2294,  0.2264,  0.2302, -0.1134, -0.0208, -0.0438,  0.2480,\n         -0.1171,  0.0097, -0.1610,  0.1609, -0.2040, -0.0470,  0.1229, -0.2099]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1955, -0.1706, -0.2396, -0.1278,  0.2187, -0.1059,  0.0043,  0.0144],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3228,  0.0338,  0.0814,  0.2923,  0.2950,  0.1881, -0.0054,  0.1674]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0691], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x103a5be80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x172816590>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s168610000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s168610000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}