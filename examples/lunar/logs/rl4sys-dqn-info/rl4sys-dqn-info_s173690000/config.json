{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s173690000"
    },
    "q_lr":	0.0005,
    "seed":	173690000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x1577d63b0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0291,  0.2398,  0.2872, -0.0384,  0.1952, -0.2427, -0.2518,  0.3304,\n        -0.2231, -0.1888, -0.2205,  0.2823,  0.1892,  0.2592,  0.2974,  0.0282,\n         0.1509, -0.2146, -0.2529,  0.2227, -0.0021, -0.2452, -0.3230, -0.1471,\n        -0.2215,  0.3161, -0.2999,  0.1783,  0.3114, -0.2996,  0.0186, -0.1050],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3416, -0.0777,  0.0059, -0.2563,  0.2825, -0.1096,  0.2539, -0.1650],\n        [ 0.0677, -0.2924,  0.0151, -0.1841, -0.2628,  0.2157, -0.2157, -0.0204],\n        [ 0.1835, -0.1512, -0.1033,  0.1915, -0.0391, -0.2591, -0.1037, -0.2610],\n        [ 0.0036,  0.2495, -0.1520, -0.2001, -0.2793,  0.1045, -0.1644, -0.2374],\n        [-0.2803,  0.3189,  0.0569,  0.1046, -0.0663,  0.1895,  0.1390,  0.2745],\n        [ 0.1167, -0.3496,  0.0021, -0.0211, -0.2927, -0.3286,  0.2612,  0.2586],\n        [ 0.2133,  0.0895,  0.1698, -0.2729, -0.2244, -0.3044, -0.0805, -0.2609],\n        [-0.1594,  0.0294, -0.1079,  0.1783, -0.0918,  0.0855, -0.2767, -0.0954],\n        [-0.0792, -0.2457, -0.0891, -0.2994,  0.2197,  0.0412,  0.0662, -0.2275],\n        [ 0.3076,  0.1737, -0.2542, -0.2479,  0.2670, -0.2918,  0.0256,  0.2403],\n        [ 0.2949,  0.1740, -0.0352, -0.1450,  0.1016, -0.0233, -0.1022,  0.3222],\n        [ 0.1015,  0.1918, -0.2381,  0.1243,  0.2857, -0.3020, -0.1839, -0.0318],\n        [-0.3497, -0.1364,  0.0911, -0.2935, -0.1095, -0.3288, -0.0763, -0.2086],\n        [-0.2692, -0.1318, -0.0789,  0.2662,  0.0171,  0.3218, -0.2037, -0.1662],\n        [ 0.2571,  0.0199, -0.2173, -0.1083,  0.2018,  0.3128,  0.0036,  0.2037],\n        [-0.1553,  0.0376, -0.2114, -0.3390, -0.0665, -0.1303, -0.0604, -0.3301],\n        [ 0.3358,  0.1677,  0.1435,  0.3461,  0.0472, -0.0903,  0.2615, -0.1265],\n        [-0.0171,  0.2177,  0.2427, -0.1375, -0.2560, -0.1382,  0.1734,  0.2494],\n        [-0.0939, -0.1541,  0.3427,  0.2545, -0.2734,  0.2571, -0.0096,  0.0539],\n        [ 0.1125, -0.1547,  0.2453, -0.2488, -0.2838,  0.1049,  0.2843, -0.3351],\n        [-0.0289,  0.0602,  0.0307,  0.2602,  0.0295,  0.3112, -0.0341, -0.0863],\n        [ 0.0015, -0.2110,  0.2740,  0.0470, -0.2377, -0.3174, -0.3105,  0.2460],\n        [-0.2282,  0.2325, -0.1434, -0.1906, -0.2759,  0.3145, -0.0506, -0.0246],\n        [-0.2690, -0.1180, -0.1046, -0.2203, -0.1500, -0.0792,  0.2827,  0.0651],\n        [ 0.2979,  0.2966, -0.2860,  0.0415, -0.1725, -0.2206,  0.3070,  0.0595],\n        [ 0.3437, -0.2982, -0.3343, -0.2325,  0.3284,  0.0711, -0.2827, -0.2660],\n        [-0.1964,  0.1456, -0.3324,  0.1860, -0.2043, -0.3425,  0.1167,  0.3212],\n        [-0.2648, -0.1017, -0.3215, -0.0130, -0.1947, -0.1281,  0.1118, -0.0493],\n        [ 0.2751,  0.1606,  0.1399,  0.3198,  0.3147,  0.2411, -0.0613, -0.2716],\n        [-0.0111, -0.0818,  0.0096,  0.1886,  0.0432, -0.2093,  0.1768, -0.2066],\n        [ 0.2153,  0.1403, -0.1809,  0.3388, -0.3232, -0.1102,  0.3011,  0.0690],\n        [ 0.0750,  0.3384,  0.0571, -0.1801,  0.2670, -0.3428,  0.3103, -0.3087]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1127,  0.0318, -0.1257, -0.0249, -0.0275, -0.1759,  0.0024,  0.0808,\n        -0.0123,  0.0128, -0.1268, -0.0117, -0.0312, -0.1462, -0.0252,  0.1270],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 9.0167e-02,  6.6424e-02, -1.7808e-02,  1.0642e-01,  1.2028e-01,\n         -1.4701e-01, -5.4731e-02, -9.8249e-02, -1.1785e-02,  7.6655e-03,\n         -1.4534e-01,  1.6706e-01, -1.7120e-01, -1.4209e-01,  4.8293e-02,\n          1.2047e-01, -1.1910e-01,  6.3381e-03, -7.1276e-02,  8.0422e-02,\n          2.2150e-02,  1.3596e-02,  3.2264e-02,  1.5841e-02,  8.1830e-02,\n          5.2012e-02, -8.2706e-02,  3.0198e-02,  1.6017e-01, -1.3954e-01,\n         -1.6730e-01,  1.3585e-01],\n        [-7.4518e-02, -1.1325e-03, -2.3676e-02, -1.3964e-01,  8.2628e-02,\n          1.6399e-01, -1.3171e-01, -1.2480e-01, -1.5456e-01, -9.6570e-02,\n         -1.3468e-01, -1.5655e-01,  1.2191e-01, -3.6462e-02,  4.1884e-03,\n         -6.9243e-03, -1.0865e-01, -1.4151e-02, -1.5121e-01,  1.1772e-01,\n          3.5505e-02, -4.6558e-02,  6.5994e-02, -9.2346e-02, -7.3496e-02,\n          1.1223e-01, -2.2990e-02,  1.7390e-02,  1.5043e-01,  7.7602e-02,\n          1.3972e-01,  3.7830e-02],\n        [ 1.4525e-01, -1.7340e-01, -2.8708e-02, -1.5547e-01, -1.1506e-01,\n          1.7577e-01,  4.5317e-02,  1.5666e-01, -9.7736e-02, -8.5241e-02,\n          2.6288e-02,  8.5632e-02, -2.8327e-03, -1.1530e-01,  4.3015e-02,\n         -1.3545e-01, -1.0727e-01,  1.1193e-01, -6.6107e-02, -7.5562e-02,\n         -6.5580e-05, -1.5186e-01, -1.5092e-01, -1.4121e-01, -6.0380e-02,\n         -9.9360e-02, -1.4224e-02, -1.7051e-01,  1.0786e-01,  1.5541e-01,\n         -1.8190e-02,  8.3688e-02],\n        [ 3.1394e-02,  3.2595e-02, -8.1073e-02, -1.6827e-01,  1.3570e-01,\n          1.6112e-01, -9.5704e-02,  3.3440e-02,  3.4519e-02,  6.5582e-02,\n         -1.2813e-01,  1.2877e-01,  1.9186e-02,  1.3537e-01,  2.1473e-02,\n         -2.8008e-02, -3.1125e-03, -1.4287e-01,  1.1244e-01, -9.7425e-02,\n          1.5389e-01, -8.5485e-03,  6.6616e-02, -5.5673e-02,  7.7252e-02,\n          8.3939e-02, -1.5409e-01, -1.3542e-01, -1.7423e-01,  2.0983e-04,\n         -6.4531e-02, -1.1896e-02],\n        [ 1.3434e-01,  1.7465e-01, -1.2697e-01,  8.1358e-02,  9.9932e-02,\n         -1.0503e-03, -8.0276e-02, -1.0203e-01, -1.0182e-01, -1.6759e-02,\n          1.2268e-02,  5.0103e-02,  1.6698e-01, -1.6588e-01, -1.5086e-01,\n          1.0807e-01,  6.2386e-02, -2.6820e-02,  1.0804e-01, -4.9433e-02,\n         -8.0956e-04,  1.0058e-01, -6.6140e-02,  1.6685e-01,  8.6588e-03,\n          7.3516e-02, -1.6740e-01,  6.1728e-02,  7.1111e-02,  1.6768e-01,\n          1.0822e-01, -3.6715e-02],\n        [ 1.3440e-01,  2.5760e-02,  1.8753e-02, -4.8510e-02, -4.2610e-02,\n          3.6339e-02, -1.3593e-01,  4.5017e-02,  1.4463e-01, -2.8338e-02,\n         -6.8160e-03, -8.5135e-02, -1.2794e-01, -9.8979e-02, -3.8780e-02,\n         -7.1018e-02, -1.0284e-01,  1.2098e-01,  3.8693e-02, -1.7163e-01,\n          5.8944e-02, -8.7635e-02,  1.7050e-01, -1.4096e-02, -8.0413e-02,\n          7.8809e-02, -8.4732e-02,  1.6678e-01,  9.5059e-02,  2.6789e-02,\n          4.7204e-02,  1.7080e-01],\n        [-1.3893e-01,  5.2528e-02, -1.3075e-01,  1.7202e-01, -1.1084e-01,\n         -2.2436e-02, -5.7806e-02,  9.4083e-03, -4.9268e-02, -5.0748e-02,\n         -6.3611e-03,  1.5934e-02, -5.7312e-02,  4.7903e-02,  1.6141e-01,\n          5.3419e-03, -6.7775e-02, -1.4914e-01, -9.1500e-02,  1.1533e-01,\n         -1.4489e-01,  2.2012e-02, -7.5642e-02, -2.7713e-02, -1.1266e-01,\n          9.1551e-02, -1.1478e-01,  1.2142e-01,  1.6911e-01,  1.0232e-01,\n         -1.4164e-01,  1.5481e-01],\n        [ 8.6944e-02, -1.2422e-02, -2.7797e-02,  1.3166e-02,  5.5552e-02,\n          1.5442e-01,  1.0544e-01,  1.1086e-01, -4.0140e-02, -2.7030e-02,\n         -1.7447e-01,  1.3887e-01,  9.7217e-02,  1.0459e-01, -3.7969e-02,\n          1.2438e-01, -8.8843e-03, -5.9585e-02, -1.5117e-01,  9.1347e-02,\n         -1.4570e-01, -1.6832e-01, -9.6244e-02,  1.5131e-01, -5.5523e-02,\n         -1.0652e-01,  8.7334e-02, -8.6553e-02, -1.4595e-01, -1.3968e-01,\n          1.5797e-01,  1.4268e-01],\n        [-1.6487e-02, -8.6364e-02,  5.6027e-02,  1.5944e-01, -8.8305e-02,\n          4.8591e-02,  9.8597e-02, -4.0226e-02,  1.0416e-01,  2.4758e-02,\n         -1.1187e-01,  1.2160e-01, -8.0427e-02, -3.3724e-02, -4.6723e-02,\n          2.0913e-02,  8.2830e-02,  7.3700e-02, -1.3235e-01,  2.7450e-02,\n          1.3725e-02,  7.9501e-02, -7.4311e-02,  8.1497e-02, -1.6172e-01,\n         -8.1759e-02, -7.5474e-02, -5.9542e-02,  7.3510e-02, -1.3185e-01,\n          3.0847e-04, -5.7093e-02],\n        [-1.5477e-01, -1.6214e-01, -2.5200e-02, -1.5915e-01, -1.4225e-01,\n         -6.8099e-02, -8.7160e-02,  1.2877e-01,  6.4868e-02,  8.9876e-02,\n         -9.6334e-02, -6.1353e-02, -1.8010e-02, -1.4232e-01,  9.4922e-02,\n         -1.1833e-01, -6.1181e-02, -8.9708e-03,  6.6028e-02, -1.3392e-01,\n          1.4010e-01,  1.2862e-01, -2.3563e-02, -6.2968e-02,  6.1375e-02,\n         -3.0704e-02, -1.5931e-01,  1.6179e-01,  1.5923e-01, -6.5717e-03,\n         -1.1559e-01, -1.1737e-01],\n        [-5.7842e-02, -5.0360e-02, -1.2515e-01, -2.9891e-02,  9.1149e-02,\n          2.4704e-03,  3.9939e-02,  1.9662e-02, -2.6336e-02,  1.5963e-01,\n         -1.4807e-02, -1.2077e-01,  7.1721e-02, -6.2134e-02, -1.2468e-01,\n          9.0498e-02, -1.4348e-01,  1.3991e-01,  1.6241e-01, -7.9298e-02,\n          1.4159e-01,  8.8673e-02,  3.2431e-02, -1.7209e-01,  4.3752e-02,\n          6.0672e-04,  4.8860e-02,  1.5180e-01, -1.2172e-01, -2.5862e-02,\n          5.3846e-02, -7.4623e-02],\n        [ 6.1490e-02, -1.1443e-01, -2.0794e-02,  1.6781e-03, -3.7700e-02,\n          2.6779e-02,  1.7287e-01,  3.5500e-02,  1.7364e-01,  1.8715e-02,\n          9.8468e-02,  1.6522e-01,  4.3730e-02,  1.7200e-01, -1.3264e-01,\n         -1.0361e-01,  1.5399e-01,  1.4931e-01,  5.7580e-02, -1.1270e-01,\n          1.5130e-01,  2.2545e-02,  2.4873e-03, -1.5852e-01,  1.0400e-03,\n         -1.1402e-01,  1.3198e-01, -1.2756e-01,  1.7513e-03,  6.5633e-02,\n          9.4022e-02,  1.6029e-01],\n        [-1.3041e-01, -1.6100e-01, -2.6122e-02,  1.0375e-02, -2.8528e-02,\n          3.2213e-02,  6.6032e-02,  7.1346e-02,  1.5576e-01, -1.2560e-01,\n         -1.6550e-01,  2.9943e-02, -1.5947e-01,  4.0398e-03, -1.2366e-01,\n         -1.4869e-02,  1.4905e-01, -6.0337e-02,  8.8971e-02,  5.8010e-02,\n         -2.1639e-02,  1.4973e-01,  3.2771e-02,  4.6562e-02, -1.0371e-01,\n         -1.7345e-01, -8.6027e-02,  1.7148e-01, -4.1322e-02,  1.7204e-01,\n          1.6760e-01,  1.1318e-02],\n        [-6.2778e-02, -5.9552e-02,  9.2179e-02, -4.8042e-02,  1.7159e-01,\n          1.5297e-01,  1.1765e-01,  2.3001e-02, -8.6348e-02,  1.2316e-01,\n          9.5151e-02, -3.1595e-02, -1.3354e-01,  1.7592e-01,  1.0233e-01,\n          1.2339e-01, -6.1794e-02, -5.0455e-02, -7.1711e-02,  6.0645e-02,\n          1.1196e-02, -1.1668e-01, -1.7536e-01,  4.9025e-02,  5.4676e-02,\n          1.0306e-01, -3.6130e-02,  2.3039e-02,  1.7032e-01,  1.7263e-02,\n         -4.4890e-02,  3.8036e-02],\n        [ 8.7882e-02, -8.4420e-02,  1.3097e-01, -2.8701e-02, -5.6413e-02,\n         -5.7959e-02, -5.1781e-02,  1.4962e-01, -7.6196e-03,  1.1615e-01,\n          1.7019e-01, -6.4505e-02, -1.4639e-01, -8.6233e-02,  1.8001e-02,\n         -1.5521e-01, -4.0422e-02,  9.2486e-02, -1.3315e-01, -3.5494e-02,\n          1.3399e-01,  1.5497e-01,  1.4923e-01,  1.3478e-01,  1.3982e-01,\n         -1.4586e-01, -4.4249e-02,  1.4920e-01,  1.2646e-01,  1.7523e-01,\n          1.2657e-02, -1.6519e-01],\n        [ 7.3101e-02,  6.1479e-02, -7.8673e-02,  7.1370e-02, -1.0303e-01,\n          1.6109e-01,  2.0938e-02, -1.2948e-01,  1.2121e-01, -2.5088e-02,\n         -1.4242e-01,  1.6006e-01, -1.1116e-01,  1.4216e-01,  1.6154e-01,\n          1.4828e-01,  1.8737e-02,  1.3888e-01,  1.0198e-01,  9.3089e-02,\n          6.8025e-02, -3.5840e-02, -1.4991e-01,  2.6492e-03, -8.9739e-02,\n          1.0980e-01,  1.3510e-01,  4.8985e-02,  8.6802e-02, -6.3754e-03,\n          2.8440e-02, -1.5092e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0812, -0.1787,  0.1508, -0.1782, -0.2179, -0.0405, -0.1607,  0.2326],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2132, -0.2076, -0.0347,  0.2264,  0.0741, -0.0735, -0.1317, -0.1424,\n          0.0434, -0.0657, -0.1131,  0.2297,  0.0436, -0.1790, -0.1749, -0.2418],\n        [-0.0013,  0.0809, -0.1799, -0.0205, -0.0211,  0.2293,  0.1820,  0.1026,\n          0.0125, -0.2222,  0.1973,  0.0432, -0.1857,  0.1967, -0.0298, -0.1794],\n        [-0.0326, -0.2212,  0.0201,  0.0490,  0.0128, -0.1395,  0.2041, -0.0477,\n         -0.1734, -0.1586, -0.0847,  0.1297, -0.0338,  0.0258,  0.2389,  0.1606],\n        [-0.1694, -0.1663,  0.1966,  0.1397,  0.2367, -0.1795,  0.0189, -0.0250,\n         -0.1739,  0.0707, -0.1902, -0.0061, -0.2355, -0.0414, -0.0975, -0.0015],\n        [ 0.1774,  0.1903, -0.1365, -0.1788, -0.1429,  0.1652, -0.1139,  0.1607,\n          0.0849, -0.2244, -0.1598,  0.0887, -0.1587, -0.1087,  0.0134, -0.0572],\n        [-0.1909, -0.1575,  0.2223,  0.0625,  0.1078,  0.2291, -0.1702, -0.0407,\n          0.1085, -0.2448, -0.2196, -0.1939, -0.0350, -0.0596,  0.1226,  0.1277],\n        [-0.0237, -0.1773, -0.1016, -0.1271,  0.1886,  0.0915, -0.2308, -0.0251,\n          0.1276, -0.0330, -0.0172, -0.1816,  0.0680,  0.1438, -0.1439,  0.1810],\n        [-0.1104,  0.2087,  0.1500, -0.1861, -0.0316, -0.2251, -0.0588,  0.2184,\n         -0.1206, -0.0852, -0.0454, -0.1090, -0.0946,  0.2288, -0.1857, -0.1947]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1833], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3103,  0.2690,  0.0335, -0.1188,  0.0747,  0.1494, -0.2881,  0.1054]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.3416, -0.0777,  0.0059, -0.2563,  0.2825, -0.1096,  0.2539, -0.1650],\n        [ 0.0677, -0.2924,  0.0151, -0.1841, -0.2628,  0.2157, -0.2157, -0.0204],\n        [ 0.1835, -0.1512, -0.1033,  0.1915, -0.0391, -0.2591, -0.1037, -0.2610],\n        [ 0.0036,  0.2495, -0.1520, -0.2001, -0.2793,  0.1045, -0.1644, -0.2374],\n        [-0.2803,  0.3189,  0.0569,  0.1046, -0.0663,  0.1895,  0.1390,  0.2745],\n        [ 0.1167, -0.3496,  0.0021, -0.0211, -0.2927, -0.3286,  0.2612,  0.2586],\n        [ 0.2133,  0.0895,  0.1698, -0.2729, -0.2244, -0.3044, -0.0805, -0.2609],\n        [-0.1594,  0.0294, -0.1079,  0.1783, -0.0918,  0.0855, -0.2767, -0.0954],\n        [-0.0792, -0.2457, -0.0891, -0.2994,  0.2197,  0.0412,  0.0662, -0.2275],\n        [ 0.3076,  0.1737, -0.2542, -0.2479,  0.2670, -0.2918,  0.0256,  0.2403],\n        [ 0.2949,  0.1740, -0.0352, -0.1450,  0.1016, -0.0233, -0.1022,  0.3222],\n        [ 0.1015,  0.1918, -0.2381,  0.1243,  0.2857, -0.3020, -0.1839, -0.0318],\n        [-0.3497, -0.1364,  0.0911, -0.2935, -0.1095, -0.3288, -0.0763, -0.2086],\n        [-0.2692, -0.1318, -0.0789,  0.2662,  0.0171,  0.3218, -0.2037, -0.1662],\n        [ 0.2571,  0.0199, -0.2173, -0.1083,  0.2018,  0.3128,  0.0036,  0.2037],\n        [-0.1553,  0.0376, -0.2114, -0.3390, -0.0665, -0.1303, -0.0604, -0.3301],\n        [ 0.3358,  0.1677,  0.1435,  0.3461,  0.0472, -0.0903,  0.2615, -0.1265],\n        [-0.0171,  0.2177,  0.2427, -0.1375, -0.2560, -0.1382,  0.1734,  0.2494],\n        [-0.0939, -0.1541,  0.3427,  0.2545, -0.2734,  0.2571, -0.0096,  0.0539],\n        [ 0.1125, -0.1547,  0.2453, -0.2488, -0.2838,  0.1049,  0.2843, -0.3351],\n        [-0.0289,  0.0602,  0.0307,  0.2602,  0.0295,  0.3112, -0.0341, -0.0863],\n        [ 0.0015, -0.2110,  0.2740,  0.0470, -0.2377, -0.3174, -0.3105,  0.2460],\n        [-0.2282,  0.2325, -0.1434, -0.1906, -0.2759,  0.3145, -0.0506, -0.0246],\n        [-0.2690, -0.1180, -0.1046, -0.2203, -0.1500, -0.0792,  0.2827,  0.0651],\n        [ 0.2979,  0.2966, -0.2860,  0.0415, -0.1725, -0.2206,  0.3070,  0.0595],\n        [ 0.3437, -0.2982, -0.3343, -0.2325,  0.3284,  0.0711, -0.2827, -0.2660],\n        [-0.1964,  0.1456, -0.3324,  0.1860, -0.2043, -0.3425,  0.1167,  0.3212],\n        [-0.2648, -0.1017, -0.3215, -0.0130, -0.1947, -0.1281,  0.1118, -0.0493],\n        [ 0.2751,  0.1606,  0.1399,  0.3198,  0.3147,  0.2411, -0.0613, -0.2716],\n        [-0.0111, -0.0818,  0.0096,  0.1886,  0.0432, -0.2093,  0.1768, -0.2066],\n        [ 0.2153,  0.1403, -0.1809,  0.3388, -0.3232, -0.1102,  0.3011,  0.0690],\n        [ 0.0750,  0.3384,  0.0571, -0.1801,  0.2670, -0.3428,  0.3103, -0.3087]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0291,  0.2398,  0.2872, -0.0384,  0.1952, -0.2427, -0.2518,  0.3304,\n        -0.2231, -0.1888, -0.2205,  0.2823,  0.1892,  0.2592,  0.2974,  0.0282,\n         0.1509, -0.2146, -0.2529,  0.2227, -0.0021, -0.2452, -0.3230, -0.1471,\n        -0.2215,  0.3161, -0.2999,  0.1783,  0.3114, -0.2996,  0.0186, -0.1050],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 9.0167e-02,  6.6424e-02, -1.7808e-02,  1.0642e-01,  1.2028e-01,\n         -1.4701e-01, -5.4731e-02, -9.8249e-02, -1.1785e-02,  7.6655e-03,\n         -1.4534e-01,  1.6706e-01, -1.7120e-01, -1.4209e-01,  4.8293e-02,\n          1.2047e-01, -1.1910e-01,  6.3381e-03, -7.1276e-02,  8.0422e-02,\n          2.2150e-02,  1.3596e-02,  3.2264e-02,  1.5841e-02,  8.1830e-02,\n          5.2012e-02, -8.2706e-02,  3.0198e-02,  1.6017e-01, -1.3954e-01,\n         -1.6730e-01,  1.3585e-01],\n        [-7.4518e-02, -1.1325e-03, -2.3676e-02, -1.3964e-01,  8.2628e-02,\n          1.6399e-01, -1.3171e-01, -1.2480e-01, -1.5456e-01, -9.6570e-02,\n         -1.3468e-01, -1.5655e-01,  1.2191e-01, -3.6462e-02,  4.1884e-03,\n         -6.9243e-03, -1.0865e-01, -1.4151e-02, -1.5121e-01,  1.1772e-01,\n          3.5505e-02, -4.6558e-02,  6.5994e-02, -9.2346e-02, -7.3496e-02,\n          1.1223e-01, -2.2990e-02,  1.7390e-02,  1.5043e-01,  7.7602e-02,\n          1.3972e-01,  3.7830e-02],\n        [ 1.4525e-01, -1.7340e-01, -2.8708e-02, -1.5547e-01, -1.1506e-01,\n          1.7577e-01,  4.5317e-02,  1.5666e-01, -9.7736e-02, -8.5241e-02,\n          2.6288e-02,  8.5632e-02, -2.8327e-03, -1.1530e-01,  4.3015e-02,\n         -1.3545e-01, -1.0727e-01,  1.1193e-01, -6.6107e-02, -7.5562e-02,\n         -6.5580e-05, -1.5186e-01, -1.5092e-01, -1.4121e-01, -6.0380e-02,\n         -9.9360e-02, -1.4224e-02, -1.7051e-01,  1.0786e-01,  1.5541e-01,\n         -1.8190e-02,  8.3688e-02],\n        [ 3.1394e-02,  3.2595e-02, -8.1073e-02, -1.6827e-01,  1.3570e-01,\n          1.6112e-01, -9.5704e-02,  3.3440e-02,  3.4519e-02,  6.5582e-02,\n         -1.2813e-01,  1.2877e-01,  1.9186e-02,  1.3537e-01,  2.1473e-02,\n         -2.8008e-02, -3.1125e-03, -1.4287e-01,  1.1244e-01, -9.7425e-02,\n          1.5389e-01, -8.5485e-03,  6.6616e-02, -5.5673e-02,  7.7252e-02,\n          8.3939e-02, -1.5409e-01, -1.3542e-01, -1.7423e-01,  2.0983e-04,\n         -6.4531e-02, -1.1896e-02],\n        [ 1.3434e-01,  1.7465e-01, -1.2697e-01,  8.1358e-02,  9.9932e-02,\n         -1.0503e-03, -8.0276e-02, -1.0203e-01, -1.0182e-01, -1.6759e-02,\n          1.2268e-02,  5.0103e-02,  1.6698e-01, -1.6588e-01, -1.5086e-01,\n          1.0807e-01,  6.2386e-02, -2.6820e-02,  1.0804e-01, -4.9433e-02,\n         -8.0956e-04,  1.0058e-01, -6.6140e-02,  1.6685e-01,  8.6588e-03,\n          7.3516e-02, -1.6740e-01,  6.1728e-02,  7.1111e-02,  1.6768e-01,\n          1.0822e-01, -3.6715e-02],\n        [ 1.3440e-01,  2.5760e-02,  1.8753e-02, -4.8510e-02, -4.2610e-02,\n          3.6339e-02, -1.3593e-01,  4.5017e-02,  1.4463e-01, -2.8338e-02,\n         -6.8160e-03, -8.5135e-02, -1.2794e-01, -9.8979e-02, -3.8780e-02,\n         -7.1018e-02, -1.0284e-01,  1.2098e-01,  3.8693e-02, -1.7163e-01,\n          5.8944e-02, -8.7635e-02,  1.7050e-01, -1.4096e-02, -8.0413e-02,\n          7.8809e-02, -8.4732e-02,  1.6678e-01,  9.5059e-02,  2.6789e-02,\n          4.7204e-02,  1.7080e-01],\n        [-1.3893e-01,  5.2528e-02, -1.3075e-01,  1.7202e-01, -1.1084e-01,\n         -2.2436e-02, -5.7806e-02,  9.4083e-03, -4.9268e-02, -5.0748e-02,\n         -6.3611e-03,  1.5934e-02, -5.7312e-02,  4.7903e-02,  1.6141e-01,\n          5.3419e-03, -6.7775e-02, -1.4914e-01, -9.1500e-02,  1.1533e-01,\n         -1.4489e-01,  2.2012e-02, -7.5642e-02, -2.7713e-02, -1.1266e-01,\n          9.1551e-02, -1.1478e-01,  1.2142e-01,  1.6911e-01,  1.0232e-01,\n         -1.4164e-01,  1.5481e-01],\n        [ 8.6944e-02, -1.2422e-02, -2.7797e-02,  1.3166e-02,  5.5552e-02,\n          1.5442e-01,  1.0544e-01,  1.1086e-01, -4.0140e-02, -2.7030e-02,\n         -1.7447e-01,  1.3887e-01,  9.7217e-02,  1.0459e-01, -3.7969e-02,\n          1.2438e-01, -8.8843e-03, -5.9585e-02, -1.5117e-01,  9.1347e-02,\n         -1.4570e-01, -1.6832e-01, -9.6244e-02,  1.5131e-01, -5.5523e-02,\n         -1.0652e-01,  8.7334e-02, -8.6553e-02, -1.4595e-01, -1.3968e-01,\n          1.5797e-01,  1.4268e-01],\n        [-1.6487e-02, -8.6364e-02,  5.6027e-02,  1.5944e-01, -8.8305e-02,\n          4.8591e-02,  9.8597e-02, -4.0226e-02,  1.0416e-01,  2.4758e-02,\n         -1.1187e-01,  1.2160e-01, -8.0427e-02, -3.3724e-02, -4.6723e-02,\n          2.0913e-02,  8.2830e-02,  7.3700e-02, -1.3235e-01,  2.7450e-02,\n          1.3725e-02,  7.9501e-02, -7.4311e-02,  8.1497e-02, -1.6172e-01,\n         -8.1759e-02, -7.5474e-02, -5.9542e-02,  7.3510e-02, -1.3185e-01,\n          3.0847e-04, -5.7093e-02],\n        [-1.5477e-01, -1.6214e-01, -2.5200e-02, -1.5915e-01, -1.4225e-01,\n         -6.8099e-02, -8.7160e-02,  1.2877e-01,  6.4868e-02,  8.9876e-02,\n         -9.6334e-02, -6.1353e-02, -1.8010e-02, -1.4232e-01,  9.4922e-02,\n         -1.1833e-01, -6.1181e-02, -8.9708e-03,  6.6028e-02, -1.3392e-01,\n          1.4010e-01,  1.2862e-01, -2.3563e-02, -6.2968e-02,  6.1375e-02,\n         -3.0704e-02, -1.5931e-01,  1.6179e-01,  1.5923e-01, -6.5717e-03,\n         -1.1559e-01, -1.1737e-01],\n        [-5.7842e-02, -5.0360e-02, -1.2515e-01, -2.9891e-02,  9.1149e-02,\n          2.4704e-03,  3.9939e-02,  1.9662e-02, -2.6336e-02,  1.5963e-01,\n         -1.4807e-02, -1.2077e-01,  7.1721e-02, -6.2134e-02, -1.2468e-01,\n          9.0498e-02, -1.4348e-01,  1.3991e-01,  1.6241e-01, -7.9298e-02,\n          1.4159e-01,  8.8673e-02,  3.2431e-02, -1.7209e-01,  4.3752e-02,\n          6.0672e-04,  4.8860e-02,  1.5180e-01, -1.2172e-01, -2.5862e-02,\n          5.3846e-02, -7.4623e-02],\n        [ 6.1490e-02, -1.1443e-01, -2.0794e-02,  1.6781e-03, -3.7700e-02,\n          2.6779e-02,  1.7287e-01,  3.5500e-02,  1.7364e-01,  1.8715e-02,\n          9.8468e-02,  1.6522e-01,  4.3730e-02,  1.7200e-01, -1.3264e-01,\n         -1.0361e-01,  1.5399e-01,  1.4931e-01,  5.7580e-02, -1.1270e-01,\n          1.5130e-01,  2.2545e-02,  2.4873e-03, -1.5852e-01,  1.0400e-03,\n         -1.1402e-01,  1.3198e-01, -1.2756e-01,  1.7513e-03,  6.5633e-02,\n          9.4022e-02,  1.6029e-01],\n        [-1.3041e-01, -1.6100e-01, -2.6122e-02,  1.0375e-02, -2.8528e-02,\n          3.2213e-02,  6.6032e-02,  7.1346e-02,  1.5576e-01, -1.2560e-01,\n         -1.6550e-01,  2.9943e-02, -1.5947e-01,  4.0398e-03, -1.2366e-01,\n         -1.4869e-02,  1.4905e-01, -6.0337e-02,  8.8971e-02,  5.8010e-02,\n         -2.1639e-02,  1.4973e-01,  3.2771e-02,  4.6562e-02, -1.0371e-01,\n         -1.7345e-01, -8.6027e-02,  1.7148e-01, -4.1322e-02,  1.7204e-01,\n          1.6760e-01,  1.1318e-02],\n        [-6.2778e-02, -5.9552e-02,  9.2179e-02, -4.8042e-02,  1.7159e-01,\n          1.5297e-01,  1.1765e-01,  2.3001e-02, -8.6348e-02,  1.2316e-01,\n          9.5151e-02, -3.1595e-02, -1.3354e-01,  1.7592e-01,  1.0233e-01,\n          1.2339e-01, -6.1794e-02, -5.0455e-02, -7.1711e-02,  6.0645e-02,\n          1.1196e-02, -1.1668e-01, -1.7536e-01,  4.9025e-02,  5.4676e-02,\n          1.0306e-01, -3.6130e-02,  2.3039e-02,  1.7032e-01,  1.7263e-02,\n         -4.4890e-02,  3.8036e-02],\n        [ 8.7882e-02, -8.4420e-02,  1.3097e-01, -2.8701e-02, -5.6413e-02,\n         -5.7959e-02, -5.1781e-02,  1.4962e-01, -7.6196e-03,  1.1615e-01,\n          1.7019e-01, -6.4505e-02, -1.4639e-01, -8.6233e-02,  1.8001e-02,\n         -1.5521e-01, -4.0422e-02,  9.2486e-02, -1.3315e-01, -3.5494e-02,\n          1.3399e-01,  1.5497e-01,  1.4923e-01,  1.3478e-01,  1.3982e-01,\n         -1.4586e-01, -4.4249e-02,  1.4920e-01,  1.2646e-01,  1.7523e-01,\n          1.2657e-02, -1.6519e-01],\n        [ 7.3101e-02,  6.1479e-02, -7.8673e-02,  7.1370e-02, -1.0303e-01,\n          1.6109e-01,  2.0938e-02, -1.2948e-01,  1.2121e-01, -2.5088e-02,\n         -1.4242e-01,  1.6006e-01, -1.1116e-01,  1.4216e-01,  1.6154e-01,\n          1.4828e-01,  1.8737e-02,  1.3888e-01,  1.0198e-01,  9.3089e-02,\n          6.8025e-02, -3.5840e-02, -1.4991e-01,  2.6492e-03, -8.9739e-02,\n          1.0980e-01,  1.3510e-01,  4.8985e-02,  8.6802e-02, -6.3754e-03,\n          2.8440e-02, -1.5092e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1127,  0.0318, -0.1257, -0.0249, -0.0275, -0.1759,  0.0024,  0.0808,\n        -0.0123,  0.0128, -0.1268, -0.0117, -0.0312, -0.1462, -0.0252,  0.1270],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2132, -0.2076, -0.0347,  0.2264,  0.0741, -0.0735, -0.1317, -0.1424,\n          0.0434, -0.0657, -0.1131,  0.2297,  0.0436, -0.1790, -0.1749, -0.2418],\n        [-0.0013,  0.0809, -0.1799, -0.0205, -0.0211,  0.2293,  0.1820,  0.1026,\n          0.0125, -0.2222,  0.1973,  0.0432, -0.1857,  0.1967, -0.0298, -0.1794],\n        [-0.0326, -0.2212,  0.0201,  0.0490,  0.0128, -0.1395,  0.2041, -0.0477,\n         -0.1734, -0.1586, -0.0847,  0.1297, -0.0338,  0.0258,  0.2389,  0.1606],\n        [-0.1694, -0.1663,  0.1966,  0.1397,  0.2367, -0.1795,  0.0189, -0.0250,\n         -0.1739,  0.0707, -0.1902, -0.0061, -0.2355, -0.0414, -0.0975, -0.0015],\n        [ 0.1774,  0.1903, -0.1365, -0.1788, -0.1429,  0.1652, -0.1139,  0.1607,\n          0.0849, -0.2244, -0.1598,  0.0887, -0.1587, -0.1087,  0.0134, -0.0572],\n        [-0.1909, -0.1575,  0.2223,  0.0625,  0.1078,  0.2291, -0.1702, -0.0407,\n          0.1085, -0.2448, -0.2196, -0.1939, -0.0350, -0.0596,  0.1226,  0.1277],\n        [-0.0237, -0.1773, -0.1016, -0.1271,  0.1886,  0.0915, -0.2308, -0.0251,\n          0.1276, -0.0330, -0.0172, -0.1816,  0.0680,  0.1438, -0.1439,  0.1810],\n        [-0.1104,  0.2087,  0.1500, -0.1861, -0.0316, -0.2251, -0.0588,  0.2184,\n         -0.1206, -0.0852, -0.0454, -0.1090, -0.0946,  0.2288, -0.1857, -0.1947]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0812, -0.1787,  0.1508, -0.1782, -0.2179, -0.0405, -0.1607,  0.2326],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3103,  0.2690,  0.0335, -0.1188,  0.0747,  0.1494, -0.2881,  0.1054]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1833], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x101b1be80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x1577d6560>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s173690000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s173690000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}