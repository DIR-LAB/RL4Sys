{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s176940000"
    },
    "q_lr":	0.0005,
    "seed":	176940000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7c1fd6c26ed0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=32, out_features=16, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=16, out_features=8, bias=True)\n    (9): ReLU()\n    (10): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=32, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=32, out_features=16, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=16, out_features=8, bias=True)\n  (9): ReLU()\n  (10): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1691,  0.2995, -0.2579, -0.2618,  0.1731, -0.2120, -0.0236, -0.2409,\n         0.3422,  0.0129,  0.3296, -0.1140, -0.1780,  0.1770, -0.0750, -0.2774,\n        -0.2185,  0.1052,  0.0398, -0.2478, -0.1419,  0.2616, -0.1522, -0.2452,\n         0.0373,  0.2304, -0.2703,  0.2676,  0.1629, -0.1630,  0.0167, -0.2473,\n        -0.0745,  0.2267, -0.0490, -0.3125,  0.3422,  0.3288,  0.0681, -0.0935,\n        -0.0860, -0.0888, -0.2716, -0.1279,  0.2170,  0.1714,  0.1159, -0.0150,\n         0.2598, -0.2310,  0.1232,  0.3453,  0.2562,  0.1418, -0.1386, -0.1796,\n         0.2362,  0.1089, -0.1935,  0.2787, -0.0161,  0.0910, -0.0055, -0.3256],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0289, -0.2043,  0.0287, -0.3306,  0.0098,  0.2074, -0.0272,  0.0497],\n        [-0.0700,  0.0958,  0.2372, -0.2059, -0.1120, -0.2779,  0.0661,  0.2549],\n        [-0.1357, -0.2483,  0.1911,  0.1973,  0.2066,  0.0500, -0.0797,  0.2095],\n        [-0.0494, -0.1069, -0.3123, -0.0280, -0.2867, -0.0776,  0.0236, -0.3039],\n        [ 0.2412, -0.0666,  0.1895,  0.0844, -0.2576, -0.1504, -0.1251, -0.3354],\n        [ 0.2350,  0.2693, -0.2823, -0.3459,  0.2903,  0.1464, -0.2129,  0.2734],\n        [ 0.2499,  0.0572,  0.0636,  0.2813,  0.3246,  0.1612, -0.1481, -0.3291],\n        [ 0.0262,  0.1638, -0.3448,  0.3452, -0.1623,  0.0589,  0.0721, -0.3130],\n        [ 0.3222, -0.3166, -0.2358, -0.2087, -0.1188, -0.1040, -0.2898, -0.0963],\n        [-0.1465, -0.2319,  0.2401, -0.0845,  0.1053, -0.1528,  0.0314, -0.2263],\n        [-0.1094,  0.1138,  0.3066, -0.0082, -0.0810,  0.0032, -0.1522,  0.2809],\n        [-0.0310,  0.3046, -0.2469, -0.0284, -0.0027,  0.2406, -0.0041, -0.0395],\n        [-0.2517,  0.0904,  0.3339, -0.3515, -0.2459, -0.0333,  0.0735, -0.0281],\n        [ 0.3510, -0.3107, -0.0503,  0.2776,  0.1622, -0.0955, -0.1895, -0.2338],\n        [-0.3093, -0.2592,  0.2984, -0.1809,  0.0881, -0.0356, -0.2672,  0.1450],\n        [ 0.0031, -0.1420,  0.0709, -0.1931, -0.1868,  0.1837, -0.2063,  0.1359],\n        [ 0.2967,  0.0443, -0.1512, -0.1137,  0.2858,  0.2538,  0.1707, -0.0057],\n        [-0.3380, -0.0592,  0.0630, -0.3369, -0.3058, -0.0878,  0.0859,  0.2518],\n        [ 0.0622,  0.0826,  0.1827, -0.1478, -0.0618, -0.2976, -0.1024, -0.1712],\n        [-0.2020, -0.2244, -0.2051,  0.1968, -0.0585,  0.3079, -0.3368, -0.1453],\n        [ 0.1831, -0.0415,  0.2864,  0.2254, -0.0644,  0.0717, -0.0258,  0.3459],\n        [-0.1491, -0.1767, -0.1166, -0.2419,  0.2248, -0.2058,  0.0774, -0.3322],\n        [-0.2451, -0.3375, -0.0412,  0.1129, -0.1412, -0.2410, -0.1752, -0.2342],\n        [-0.2222,  0.0013,  0.0671,  0.3266,  0.2491, -0.3176,  0.1346, -0.2226],\n        [ 0.2051, -0.2196, -0.3091,  0.0284,  0.2492, -0.1328, -0.1577,  0.3487],\n        [-0.0614,  0.1026, -0.2210,  0.0156,  0.3245, -0.2343, -0.2865, -0.2566],\n        [ 0.1081,  0.3144,  0.1456, -0.2718, -0.0228, -0.1137, -0.1158,  0.1169],\n        [ 0.2530, -0.2517, -0.0031,  0.0904, -0.2387, -0.3436,  0.2796, -0.3159],\n        [-0.0476, -0.2982, -0.0951, -0.2148,  0.0881, -0.0932, -0.2836, -0.1345],\n        [ 0.2679, -0.1401,  0.2538,  0.0988, -0.1254,  0.1538,  0.3232,  0.0559],\n        [-0.2104,  0.1350, -0.2724, -0.2894,  0.3166,  0.1164,  0.0351,  0.1989],\n        [ 0.0458, -0.2802,  0.0177, -0.2873, -0.1474,  0.0478, -0.2248, -0.0887],\n        [ 0.1867,  0.1417,  0.3488,  0.1524,  0.1576,  0.3073,  0.0584,  0.2177],\n        [ 0.0341,  0.0547, -0.3276,  0.3345, -0.0948,  0.1935, -0.0778, -0.1580],\n        [-0.1983, -0.2065,  0.2872, -0.1545, -0.3307, -0.2283, -0.0008, -0.2872],\n        [ 0.0181,  0.2507,  0.0881,  0.1632, -0.1221,  0.2552, -0.2600, -0.1567],\n        [-0.0433,  0.1907,  0.0202,  0.0937,  0.1485, -0.1003, -0.0222,  0.1314],\n        [ 0.1665,  0.1213,  0.1742, -0.3389, -0.2016,  0.1331, -0.0445, -0.0787],\n        [-0.2790,  0.1541,  0.0771,  0.1057, -0.3211, -0.2035, -0.1561, -0.1129],\n        [-0.0696, -0.0296,  0.0750, -0.0217, -0.1070, -0.3020,  0.2558, -0.3351],\n        [-0.1679,  0.2440, -0.0364, -0.0632,  0.0808,  0.1078, -0.0865,  0.1549],\n        [-0.1363, -0.2896,  0.0210,  0.2837,  0.2094, -0.0362, -0.1770, -0.2907],\n        [-0.2244,  0.0642, -0.2104,  0.0207,  0.2463, -0.1595, -0.2888,  0.1776],\n        [-0.2456,  0.0177, -0.1994, -0.2126, -0.0596, -0.3384,  0.2748,  0.0039],\n        [ 0.0699,  0.3082,  0.2929,  0.1331, -0.2441, -0.3125, -0.2638, -0.2065],\n        [-0.0163, -0.2817, -0.3013,  0.1294,  0.1217, -0.0472,  0.1109,  0.1114],\n        [-0.1963,  0.0255,  0.2592, -0.2523,  0.0574,  0.0596,  0.1970, -0.0635],\n        [-0.2354, -0.0476, -0.1622, -0.0584, -0.0923, -0.0593,  0.2484, -0.0277],\n        [ 0.2690,  0.0901,  0.1109, -0.0089,  0.0358,  0.3236, -0.2455, -0.1150],\n        [ 0.0565, -0.0126,  0.2517, -0.0668, -0.1334,  0.2881, -0.2054,  0.0409],\n        [ 0.2732,  0.2296, -0.3281,  0.3453, -0.1751, -0.0409, -0.2628,  0.2674],\n        [ 0.0185, -0.3064, -0.2385, -0.0871,  0.0255,  0.0971, -0.2658,  0.2402],\n        [-0.1993, -0.0206,  0.0485, -0.0733, -0.0321, -0.1137, -0.1328, -0.1579],\n        [-0.0390,  0.2684,  0.0338,  0.2635, -0.1253,  0.2230,  0.0688, -0.1630],\n        [ 0.0997,  0.2018, -0.1325, -0.0089,  0.1648,  0.1068,  0.1455, -0.2808],\n        [-0.0341, -0.1528, -0.2015, -0.2467, -0.0832, -0.2359, -0.2769,  0.2854],\n        [ 0.2247, -0.1647,  0.2536,  0.3485, -0.0219, -0.2274,  0.2575, -0.2259],\n        [ 0.2809,  0.1542,  0.3378,  0.3020,  0.1148,  0.2626, -0.2830, -0.0405],\n        [ 0.2758,  0.0744, -0.0541,  0.0455, -0.2572,  0.1629,  0.1405, -0.3439],\n        [-0.0068,  0.2210, -0.3006, -0.1692,  0.0596,  0.2911,  0.0107,  0.1721],\n        [-0.1863,  0.1561,  0.3520, -0.0572,  0.0945, -0.3346, -0.2754,  0.0775],\n        [ 0.3233,  0.0252,  0.0389, -0.1201,  0.3183, -0.0708,  0.0771,  0.1965],\n        [ 0.3033,  0.0229,  0.2075, -0.1444,  0.0674, -0.3454,  0.0537,  0.3512],\n        [-0.3235, -0.0463,  0.1964,  0.2879,  0.2676,  0.2986, -0.1119, -0.2143]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "10":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0549], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2154, -0.0233,  0.2288, -0.0779, -0.1659, -0.1573,  0.1045, -0.3401]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=64, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0036, -0.0943,  0.0625,  0.0865,  0.0717,  0.1150, -0.0398, -0.0285,\n        -0.0878, -0.0361, -0.0538,  0.0514,  0.0755, -0.0452, -0.0427, -0.0570,\n         0.0238,  0.1050,  0.1094,  0.0106,  0.0832, -0.0997, -0.0875, -0.0174,\n        -0.0153,  0.0086,  0.1022,  0.0368,  0.0289,  0.0177,  0.0651,  0.1157,\n         0.1127, -0.1152, -0.1007,  0.0843, -0.0030,  0.0496, -0.0439, -0.1008,\n         0.1068,  0.1012, -0.0216, -0.0512,  0.0549, -0.1082,  0.0223, -0.0717,\n        -0.0858, -0.0049,  0.0373, -0.0293,  0.0637,  0.0688, -0.0637,  0.1079,\n        -0.0896,  0.1202,  0.0693,  0.0254, -0.0074,  0.0719, -0.0714, -0.1174],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1037,  0.0556,  0.0274,  ..., -0.0167,  0.0688,  0.1184],\n        [ 0.0849,  0.0052,  0.0206,  ..., -0.0785,  0.0703, -0.1201],\n        [ 0.1050, -0.1036,  0.1014,  ..., -0.0968, -0.0915,  0.0128],\n        ...,\n        [ 0.0927, -0.1043,  0.0703,  ...,  0.1027, -0.0646, -0.0007],\n        [-0.0286, -0.0690, -0.0846,  ...,  0.0749,  0.1052,  0.0717],\n        [-0.1106,  0.0560, -0.0709,  ...,  0.1018, -0.0225, -0.0716]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=64, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0967, -0.0704, -0.1215,  0.0311,  0.1151,  0.0287, -0.0633,  0.1102,\n        -0.0084, -0.0151,  0.1101, -0.0163, -0.0077,  0.1153,  0.0148, -0.0252,\n         0.0582,  0.0531,  0.1075, -0.0312,  0.0150, -0.1092, -0.1218,  0.0821,\n        -0.1062, -0.1132, -0.0224,  0.0499,  0.1059,  0.0479,  0.1091, -0.1141],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1017,  0.1188,  0.0551,  ..., -0.0708, -0.0959,  0.1075],\n        [ 0.0598,  0.0472,  0.0473,  ...,  0.1041,  0.0437,  0.0716],\n        [-0.0720,  0.1072,  0.0780,  ..., -0.0752,  0.1051,  0.0173],\n        ...,\n        [-0.0827,  0.0746,  0.0464,  ...,  0.0688,  0.1064,  0.1228],\n        [-0.0787,  0.0297,  0.0279,  ...,  0.0142, -0.0988, -0.1011],\n        [ 0.1151,  0.0141, -0.0504,  ..., -0.0478, -0.0653,  0.1249]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0151,  0.1341, -0.0573,  0.0192, -0.0530, -0.0873,  0.1162,  0.0690,\n         0.1244,  0.0021, -0.0719,  0.0802, -0.0076,  0.0693,  0.1644, -0.0265],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.6102e-01, -8.5128e-02, -1.4146e-01,  1.1576e-01, -1.4104e-01,\n          8.1585e-02,  1.6268e-01, -1.0131e-02, -1.5354e-01,  1.1959e-01,\n          4.7865e-02, -7.8579e-02,  1.1384e-01,  5.6196e-02,  1.0405e-01,\n         -2.1318e-02,  1.5867e-01,  1.4729e-01, -5.4797e-02,  1.3362e-01,\n          1.2449e-01,  1.6333e-02, -1.4675e-01,  1.0291e-01,  1.3337e-01,\n         -1.6544e-01, -7.8864e-02,  1.5861e-01, -8.1729e-02, -1.0031e-02,\n          3.5659e-02,  6.8321e-02],\n        [ 1.2107e-01, -1.2837e-01,  1.3051e-02, -2.6906e-02,  2.2059e-02,\n         -1.2434e-02,  4.0989e-02, -4.1357e-04, -1.4030e-01, -9.7626e-02,\n          3.1038e-02, -1.1354e-01, -1.2185e-01, -1.6321e-02, -9.1561e-02,\n         -2.9486e-02,  1.0228e-02, -7.0043e-02, -1.7591e-01, -1.4113e-01,\n         -7.7869e-02, -4.8024e-02,  3.3914e-02,  1.3086e-01,  2.7061e-03,\n          4.6681e-02, -9.7119e-02,  6.5355e-02,  3.4926e-02, -6.6792e-02,\n          1.2716e-01, -1.1520e-01],\n        [-1.2439e-01,  6.5371e-03, -8.8702e-02,  4.2135e-02,  5.8033e-02,\n          7.8149e-02, -4.6778e-02, -1.0139e-01,  7.9358e-03,  7.3419e-02,\n         -8.4522e-02, -2.8006e-02, -1.3717e-01,  9.2691e-02, -5.8037e-02,\n          1.8156e-02,  1.3460e-01,  1.4806e-01, -6.8590e-02,  6.0753e-02,\n          1.7670e-02,  8.2748e-02,  1.5695e-01, -1.2630e-01,  1.3516e-01,\n          9.8902e-02, -1.5824e-02,  7.3368e-02, -1.5895e-01, -1.1966e-01,\n          1.4138e-01,  1.6368e-01],\n        [-1.4914e-01,  1.3242e-01,  5.6171e-02, -9.4913e-02, -1.5815e-01,\n          2.5463e-03, -3.8561e-02,  6.0975e-02,  9.5443e-02,  3.9990e-02,\n         -1.2347e-01, -1.7536e-01, -7.3538e-02,  1.5548e-01,  6.9916e-02,\n         -1.4570e-01,  1.1682e-01,  3.0477e-02, -1.4826e-01,  1.4935e-01,\n          1.3317e-01, -3.9681e-02, -1.6204e-01, -4.8679e-02,  8.3227e-03,\n          9.9586e-02, -1.7574e-01, -1.2170e-01,  1.7138e-01, -1.7011e-01,\n          1.3179e-01, -1.6334e-01],\n        [-5.7064e-02,  3.2236e-02, -5.3891e-02, -8.4216e-02,  9.6715e-02,\n         -1.5308e-01, -4.8110e-02,  1.3089e-01,  1.4904e-01,  1.7356e-01,\n          1.2311e-01, -9.8504e-02,  1.6989e-01, -1.2586e-01, -1.6716e-01,\n         -4.1032e-02,  1.6711e-01, -3.5111e-02,  2.0148e-02,  4.4008e-02,\n         -6.0436e-02, -1.6191e-01, -8.1963e-02,  8.7027e-02,  1.0782e-01,\n         -1.4005e-01,  6.8367e-02,  1.7384e-01,  7.4313e-02, -1.1070e-01,\n          1.3779e-01,  1.0716e-01],\n        [ 1.2388e-01,  4.2650e-02, -1.2996e-01, -1.3211e-01,  5.9071e-02,\n         -1.2162e-01, -2.2094e-02, -3.1455e-02,  1.5281e-01, -4.1899e-02,\n         -6.5235e-03, -2.2083e-02,  6.4172e-02,  1.6018e-02,  1.7246e-01,\n         -1.0868e-01,  1.6852e-01, -1.7125e-01,  4.2212e-02, -1.1433e-01,\n          4.7961e-02, -2.5480e-02,  1.1554e-01, -6.7807e-02,  9.0763e-02,\n          1.7262e-01,  9.1345e-02, -1.3493e-01,  9.4345e-02, -2.1565e-03,\n          9.0417e-02, -1.7560e-01],\n        [ 5.4982e-02,  1.2371e-01, -5.2490e-02, -9.3821e-02,  1.2163e-01,\n          2.4831e-02,  7.3669e-03, -4.3109e-02, -1.4406e-03,  4.2379e-02,\n          9.7484e-02, -5.5610e-02,  7.7796e-03,  6.8417e-02, -1.2181e-01,\n         -1.4496e-01, -1.1940e-01, -1.4865e-01,  6.0092e-02, -1.1006e-02,\n         -1.0867e-01,  7.8871e-02, -1.7455e-01, -6.7783e-02,  8.6316e-02,\n         -9.6772e-02, -1.3211e-01, -1.5924e-01,  1.3776e-01,  1.3778e-01,\n          8.5189e-02, -1.1009e-01],\n        [-1.4948e-01,  7.9783e-03,  1.3164e-01,  1.6655e-01, -5.7005e-02,\n          3.2566e-02, -1.2218e-01, -8.1818e-02,  9.0852e-02, -5.5586e-02,\n          4.0791e-02,  1.1037e-01,  5.8936e-02, -1.4574e-01,  7.4858e-02,\n          1.6887e-01,  1.4075e-01, -7.9721e-02,  6.1482e-02,  1.4031e-01,\n         -1.3822e-02, -1.8103e-02,  1.6997e-01,  1.3622e-01,  1.4493e-02,\n          2.4609e-02,  1.2983e-01, -9.8186e-02, -1.3268e-02,  1.5415e-02,\n         -1.6590e-01,  1.6161e-01],\n        [-1.7635e-01,  1.0890e-01, -1.5940e-01,  1.2017e-01,  1.7246e-01,\n         -5.7913e-02,  1.6667e-02,  7.4663e-02,  8.3386e-02, -1.6698e-02,\n          1.5160e-01, -5.5654e-02, -1.5233e-01,  6.6518e-02, -1.0695e-02,\n         -1.2398e-01, -1.4147e-01,  4.3688e-02,  6.7815e-02,  1.1150e-01,\n         -1.5875e-01, -3.2091e-02,  5.6387e-02, -1.1998e-01,  7.1168e-02,\n          8.4674e-02,  5.9262e-02,  6.2117e-02, -1.1058e-01,  1.4913e-01,\n          1.7587e-01,  9.1560e-02],\n        [-3.8708e-02,  9.7961e-02,  1.4253e-01,  3.8318e-02,  1.2123e-01,\n          1.3085e-01,  1.5058e-01,  9.8299e-02, -2.4044e-02,  3.9801e-02,\n         -1.4869e-01,  1.0271e-01, -1.7636e-01, -3.4440e-02,  1.0374e-01,\n         -9.3660e-02, -3.1666e-02,  7.6243e-02, -1.7269e-01, -1.1595e-01,\n         -9.1061e-02,  8.6446e-02,  9.2057e-02,  1.0290e-01,  1.9604e-02,\n         -7.8075e-02, -1.1950e-01, -1.1292e-01, -9.5715e-02, -1.7341e-01,\n         -8.1562e-02, -1.6452e-01],\n        [-8.6976e-02,  1.0868e-01, -8.0166e-02, -6.2649e-02,  7.9136e-02,\n          5.7169e-02, -1.3157e-01, -1.6406e-01, -4.2155e-02, -1.1484e-01,\n          6.2046e-02,  3.6450e-02,  5.8515e-02, -5.8005e-02, -1.5625e-01,\n         -1.1284e-01, -2.0288e-02,  1.6490e-01,  3.1116e-02, -8.0293e-02,\n          6.3535e-02, -1.3516e-01, -1.3555e-01,  6.6034e-02, -8.7015e-02,\n         -1.2947e-01, -1.1634e-01, -1.6924e-01, -1.1324e-01, -1.6969e-01,\n         -1.1083e-02,  1.0520e-01],\n        [ 1.1499e-01, -1.0191e-01, -1.3018e-01, -1.7392e-01,  1.2169e-01,\n          7.4562e-02,  9.2718e-03,  6.9774e-05,  1.4941e-01, -4.8803e-02,\n         -1.4966e-01, -5.3488e-02, -1.7106e-02, -6.2621e-02,  8.1446e-02,\n         -1.2075e-01, -1.7564e-01, -2.9163e-02, -6.1563e-02, -7.0347e-02,\n          4.5411e-02, -1.0803e-02,  1.4712e-01,  8.9295e-02,  4.5568e-03,\n          1.1600e-01,  2.6068e-02, -1.2461e-01, -1.0597e-01,  4.1388e-02,\n         -1.3751e-01,  2.7379e-02],\n        [-1.1643e-02,  1.0427e-01, -1.1839e-01, -1.5426e-01,  1.3410e-01,\n         -9.8479e-02,  1.7472e-01,  7.6972e-02, -4.1890e-02,  1.6342e-01,\n          1.0015e-01,  9.9274e-02,  7.4606e-02, -1.5460e-01,  1.7601e-01,\n          1.2593e-01, -1.7001e-01, -1.5836e-01,  6.5371e-02, -1.7148e-01,\n         -1.7567e-01,  1.5591e-01, -9.9452e-02, -6.5568e-04,  7.9244e-02,\n         -7.6385e-02, -7.7621e-02,  6.7093e-02, -1.4539e-01, -1.3061e-01,\n          9.2603e-02, -5.2606e-02],\n        [-1.5918e-01, -6.2766e-02, -1.0337e-01,  5.2917e-04,  1.4822e-01,\n          1.5079e-01,  3.2050e-02, -1.3876e-01, -1.3807e-01,  9.6158e-02,\n         -2.0966e-02,  3.2998e-02, -7.9421e-02,  1.1739e-01, -1.1723e-01,\n         -2.2148e-02, -7.5558e-02, -1.1349e-03, -1.2381e-01,  2.4169e-02,\n          6.7654e-02,  1.2341e-01,  1.3333e-01, -1.0557e-01, -6.1676e-02,\n         -6.7219e-02, -1.0826e-01,  1.3570e-01, -1.6039e-01, -1.1179e-02,\n         -1.1119e-01,  1.5390e-01],\n        [-1.3188e-01, -5.0337e-03,  1.0684e-01,  6.5375e-02,  3.7497e-02,\n          8.4907e-02,  4.4785e-02, -8.7047e-02, -1.4718e-01,  1.7600e-01,\n         -2.7796e-02,  1.0720e-01, -3.7091e-02, -7.8026e-02, -1.5146e-01,\n          1.0112e-01,  5.3219e-02, -4.3035e-02,  1.0867e-01, -2.9741e-02,\n          7.6039e-02, -5.2252e-02,  4.5434e-02,  1.8849e-03,  1.2901e-01,\n         -6.7135e-02, -1.0772e-01, -1.3041e-01,  1.1294e-01, -2.4583e-02,\n         -5.7941e-02,  1.2762e-01],\n        [ 9.5493e-02,  1.5672e-01,  2.5035e-02, -1.1271e-01, -2.5014e-02,\n          4.2627e-02, -2.3148e-02, -1.0742e-01,  8.0076e-02, -1.5385e-01,\n         -7.5079e-02, -1.2183e-02,  6.3549e-02,  9.7931e-02, -1.9736e-02,\n         -1.1853e-01, -1.0277e-01,  1.7455e-01,  8.5560e-02, -6.8724e-02,\n          1.6503e-01, -7.9256e-02,  1.0981e-01,  8.6079e-02,  3.8020e-02,\n          3.7887e-02,  1.0565e-01, -1.1694e-01, -3.5191e-02, -1.0221e-01,\n         -1.0987e-02, -1.4688e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "7":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "8":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0376,  0.2372,  0.2292, -0.0909,  0.0911, -0.0512, -0.1439, -0.0729],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1807,  0.0761, -0.1847,  0.2303,  0.0370,  0.0638,  0.0072,  0.1700,\n          0.1541,  0.0318, -0.2217,  0.1252, -0.1118,  0.1162, -0.1247, -0.1982],\n        [ 0.0080,  0.2137, -0.2041,  0.0533, -0.2422,  0.0492, -0.2255, -0.1696,\n         -0.0427, -0.1892, -0.1044,  0.2202, -0.1194,  0.0025,  0.0678,  0.0739],\n        [-0.1026, -0.2243,  0.1716, -0.1631,  0.1844,  0.2034,  0.0113, -0.0427,\n         -0.1025,  0.2125, -0.0222,  0.1006,  0.0665,  0.1030,  0.2475,  0.0861],\n        [-0.0850, -0.1070, -0.0193, -0.1713,  0.0896,  0.1437, -0.2359,  0.1467,\n          0.1097,  0.0482, -0.0381, -0.0463, -0.0967,  0.1609, -0.2242,  0.1803],\n        [ 0.2342,  0.1336,  0.2379, -0.0797, -0.2283,  0.2049,  0.0575, -0.0417,\n         -0.0569,  0.2327, -0.2475, -0.0303, -0.1499,  0.1547, -0.0900, -0.1795],\n        [-0.2010,  0.1488, -0.0454, -0.1065,  0.0072,  0.2346,  0.0388, -0.1455,\n          0.0293, -0.2092,  0.1791, -0.0957,  0.1827,  0.1437, -0.2301,  0.0242],\n        [-0.0914,  0.1448, -0.2055,  0.1099,  0.0789, -0.2475,  0.1079, -0.1441,\n         -0.0538, -0.1224, -0.2335, -0.0760, -0.2321, -0.0378, -0.1249,  0.1415],\n        [ 0.2453, -0.1735, -0.1260,  0.0209,  0.1965, -0.1730,  0.1799, -0.0839,\n          0.1659, -0.0786,  0.1205,  0.0438, -0.0311,  0.2083, -0.0764,  0.1575]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "9":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0289, -0.2043,  0.0287, -0.3306,  0.0098,  0.2074, -0.0272,  0.0497],\n        [-0.0700,  0.0958,  0.2372, -0.2059, -0.1120, -0.2779,  0.0661,  0.2549],\n        [-0.1357, -0.2483,  0.1911,  0.1973,  0.2066,  0.0500, -0.0797,  0.2095],\n        [-0.0494, -0.1069, -0.3123, -0.0280, -0.2867, -0.0776,  0.0236, -0.3039],\n        [ 0.2412, -0.0666,  0.1895,  0.0844, -0.2576, -0.1504, -0.1251, -0.3354],\n        [ 0.2350,  0.2693, -0.2823, -0.3459,  0.2903,  0.1464, -0.2129,  0.2734],\n        [ 0.2499,  0.0572,  0.0636,  0.2813,  0.3246,  0.1612, -0.1481, -0.3291],\n        [ 0.0262,  0.1638, -0.3448,  0.3452, -0.1623,  0.0589,  0.0721, -0.3130],\n        [ 0.3222, -0.3166, -0.2358, -0.2087, -0.1188, -0.1040, -0.2898, -0.0963],\n        [-0.1465, -0.2319,  0.2401, -0.0845,  0.1053, -0.1528,  0.0314, -0.2263],\n        [-0.1094,  0.1138,  0.3066, -0.0082, -0.0810,  0.0032, -0.1522,  0.2809],\n        [-0.0310,  0.3046, -0.2469, -0.0284, -0.0027,  0.2406, -0.0041, -0.0395],\n        [-0.2517,  0.0904,  0.3339, -0.3515, -0.2459, -0.0333,  0.0735, -0.0281],\n        [ 0.3510, -0.3107, -0.0503,  0.2776,  0.1622, -0.0955, -0.1895, -0.2338],\n        [-0.3093, -0.2592,  0.2984, -0.1809,  0.0881, -0.0356, -0.2672,  0.1450],\n        [ 0.0031, -0.1420,  0.0709, -0.1931, -0.1868,  0.1837, -0.2063,  0.1359],\n        [ 0.2967,  0.0443, -0.1512, -0.1137,  0.2858,  0.2538,  0.1707, -0.0057],\n        [-0.3380, -0.0592,  0.0630, -0.3369, -0.3058, -0.0878,  0.0859,  0.2518],\n        [ 0.0622,  0.0826,  0.1827, -0.1478, -0.0618, -0.2976, -0.1024, -0.1712],\n        [-0.2020, -0.2244, -0.2051,  0.1968, -0.0585,  0.3079, -0.3368, -0.1453],\n        [ 0.1831, -0.0415,  0.2864,  0.2254, -0.0644,  0.0717, -0.0258,  0.3459],\n        [-0.1491, -0.1767, -0.1166, -0.2419,  0.2248, -0.2058,  0.0774, -0.3322],\n        [-0.2451, -0.3375, -0.0412,  0.1129, -0.1412, -0.2410, -0.1752, -0.2342],\n        [-0.2222,  0.0013,  0.0671,  0.3266,  0.2491, -0.3176,  0.1346, -0.2226],\n        [ 0.2051, -0.2196, -0.3091,  0.0284,  0.2492, -0.1328, -0.1577,  0.3487],\n        [-0.0614,  0.1026, -0.2210,  0.0156,  0.3245, -0.2343, -0.2865, -0.2566],\n        [ 0.1081,  0.3144,  0.1456, -0.2718, -0.0228, -0.1137, -0.1158,  0.1169],\n        [ 0.2530, -0.2517, -0.0031,  0.0904, -0.2387, -0.3436,  0.2796, -0.3159],\n        [-0.0476, -0.2982, -0.0951, -0.2148,  0.0881, -0.0932, -0.2836, -0.1345],\n        [ 0.2679, -0.1401,  0.2538,  0.0988, -0.1254,  0.1538,  0.3232,  0.0559],\n        [-0.2104,  0.1350, -0.2724, -0.2894,  0.3166,  0.1164,  0.0351,  0.1989],\n        [ 0.0458, -0.2802,  0.0177, -0.2873, -0.1474,  0.0478, -0.2248, -0.0887],\n        [ 0.1867,  0.1417,  0.3488,  0.1524,  0.1576,  0.3073,  0.0584,  0.2177],\n        [ 0.0341,  0.0547, -0.3276,  0.3345, -0.0948,  0.1935, -0.0778, -0.1580],\n        [-0.1983, -0.2065,  0.2872, -0.1545, -0.3307, -0.2283, -0.0008, -0.2872],\n        [ 0.0181,  0.2507,  0.0881,  0.1632, -0.1221,  0.2552, -0.2600, -0.1567],\n        [-0.0433,  0.1907,  0.0202,  0.0937,  0.1485, -0.1003, -0.0222,  0.1314],\n        [ 0.1665,  0.1213,  0.1742, -0.3389, -0.2016,  0.1331, -0.0445, -0.0787],\n        [-0.2790,  0.1541,  0.0771,  0.1057, -0.3211, -0.2035, -0.1561, -0.1129],\n        [-0.0696, -0.0296,  0.0750, -0.0217, -0.1070, -0.3020,  0.2558, -0.3351],\n        [-0.1679,  0.2440, -0.0364, -0.0632,  0.0808,  0.1078, -0.0865,  0.1549],\n        [-0.1363, -0.2896,  0.0210,  0.2837,  0.2094, -0.0362, -0.1770, -0.2907],\n        [-0.2244,  0.0642, -0.2104,  0.0207,  0.2463, -0.1595, -0.2888,  0.1776],\n        [-0.2456,  0.0177, -0.1994, -0.2126, -0.0596, -0.3384,  0.2748,  0.0039],\n        [ 0.0699,  0.3082,  0.2929,  0.1331, -0.2441, -0.3125, -0.2638, -0.2065],\n        [-0.0163, -0.2817, -0.3013,  0.1294,  0.1217, -0.0472,  0.1109,  0.1114],\n        [-0.1963,  0.0255,  0.2592, -0.2523,  0.0574,  0.0596,  0.1970, -0.0635],\n        [-0.2354, -0.0476, -0.1622, -0.0584, -0.0923, -0.0593,  0.2484, -0.0277],\n        [ 0.2690,  0.0901,  0.1109, -0.0089,  0.0358,  0.3236, -0.2455, -0.1150],\n        [ 0.0565, -0.0126,  0.2517, -0.0668, -0.1334,  0.2881, -0.2054,  0.0409],\n        [ 0.2732,  0.2296, -0.3281,  0.3453, -0.1751, -0.0409, -0.2628,  0.2674],\n        [ 0.0185, -0.3064, -0.2385, -0.0871,  0.0255,  0.0971, -0.2658,  0.2402],\n        [-0.1993, -0.0206,  0.0485, -0.0733, -0.0321, -0.1137, -0.1328, -0.1579],\n        [-0.0390,  0.2684,  0.0338,  0.2635, -0.1253,  0.2230,  0.0688, -0.1630],\n        [ 0.0997,  0.2018, -0.1325, -0.0089,  0.1648,  0.1068,  0.1455, -0.2808],\n        [-0.0341, -0.1528, -0.2015, -0.2467, -0.0832, -0.2359, -0.2769,  0.2854],\n        [ 0.2247, -0.1647,  0.2536,  0.3485, -0.0219, -0.2274,  0.2575, -0.2259],\n        [ 0.2809,  0.1542,  0.3378,  0.3020,  0.1148,  0.2626, -0.2830, -0.0405],\n        [ 0.2758,  0.0744, -0.0541,  0.0455, -0.2572,  0.1629,  0.1405, -0.3439],\n        [-0.0068,  0.2210, -0.3006, -0.1692,  0.0596,  0.2911,  0.0107,  0.1721],\n        [-0.1863,  0.1561,  0.3520, -0.0572,  0.0945, -0.3346, -0.2754,  0.0775],\n        [ 0.3233,  0.0252,  0.0389, -0.1201,  0.3183, -0.0708,  0.0771,  0.1965],\n        [ 0.3033,  0.0229,  0.2075, -0.1444,  0.0674, -0.3454,  0.0537,  0.3512],\n        [-0.3235, -0.0463,  0.1964,  0.2879,  0.2676,  0.2986, -0.1119, -0.2143]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1691,  0.2995, -0.2579, -0.2618,  0.1731, -0.2120, -0.0236, -0.2409,\n         0.3422,  0.0129,  0.3296, -0.1140, -0.1780,  0.1770, -0.0750, -0.2774,\n        -0.2185,  0.1052,  0.0398, -0.2478, -0.1419,  0.2616, -0.1522, -0.2452,\n         0.0373,  0.2304, -0.2703,  0.2676,  0.1629, -0.1630,  0.0167, -0.2473,\n        -0.0745,  0.2267, -0.0490, -0.3125,  0.3422,  0.3288,  0.0681, -0.0935,\n        -0.0860, -0.0888, -0.2716, -0.1279,  0.2170,  0.1714,  0.1159, -0.0150,\n         0.2598, -0.2310,  0.1232,  0.3453,  0.2562,  0.1418, -0.1386, -0.1796,\n         0.2362,  0.1089, -0.1935,  0.2787, -0.0161,  0.0910, -0.0055, -0.3256],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1037,  0.0556,  0.0274,  ..., -0.0167,  0.0688,  0.1184],\n        [ 0.0849,  0.0052,  0.0206,  ..., -0.0785,  0.0703, -0.1201],\n        [ 0.1050, -0.1036,  0.1014,  ..., -0.0968, -0.0915,  0.0128],\n        ...,\n        [ 0.0927, -0.1043,  0.0703,  ...,  0.1027, -0.0646, -0.0007],\n        [-0.0286, -0.0690, -0.0846,  ...,  0.0749,  0.1052,  0.0717],\n        [-0.1106,  0.0560, -0.0709,  ...,  0.1018, -0.0225, -0.0716]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0036, -0.0943,  0.0625,  0.0865,  0.0717,  0.1150, -0.0398, -0.0285,\n        -0.0878, -0.0361, -0.0538,  0.0514,  0.0755, -0.0452, -0.0427, -0.0570,\n         0.0238,  0.1050,  0.1094,  0.0106,  0.0832, -0.0997, -0.0875, -0.0174,\n        -0.0153,  0.0086,  0.1022,  0.0368,  0.0289,  0.0177,  0.0651,  0.1157,\n         0.1127, -0.1152, -0.1007,  0.0843, -0.0030,  0.0496, -0.0439, -0.1008,\n         0.1068,  0.1012, -0.0216, -0.0512,  0.0549, -0.1082,  0.0223, -0.0717,\n        -0.0858, -0.0049,  0.0373, -0.0293,  0.0637,  0.0688, -0.0637,  0.1079,\n        -0.0896,  0.1202,  0.0693,  0.0254, -0.0074,  0.0719, -0.0714, -0.1174],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1017,  0.1188,  0.0551,  ..., -0.0708, -0.0959,  0.1075],\n        [ 0.0598,  0.0472,  0.0473,  ...,  0.1041,  0.0437,  0.0716],\n        [-0.0720,  0.1072,  0.0780,  ..., -0.0752,  0.1051,  0.0173],\n        ...,\n        [-0.0827,  0.0746,  0.0464,  ...,  0.0688,  0.1064,  0.1228],\n        [-0.0787,  0.0297,  0.0279,  ...,  0.0142, -0.0988, -0.1011],\n        [ 0.1151,  0.0141, -0.0504,  ..., -0.0478, -0.0653,  0.1249]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0967, -0.0704, -0.1215,  0.0311,  0.1151,  0.0287, -0.0633,  0.1102,\n        -0.0084, -0.0151,  0.1101, -0.0163, -0.0077,  0.1153,  0.0148, -0.0252,\n         0.0582,  0.0531,  0.1075, -0.0312,  0.0150, -0.1092, -0.1218,  0.0821,\n        -0.1062, -0.1132, -0.0224,  0.0499,  0.1059,  0.0479,  0.1091, -0.1141],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.6102e-01, -8.5128e-02, -1.4146e-01,  1.1576e-01, -1.4104e-01,\n          8.1585e-02,  1.6268e-01, -1.0131e-02, -1.5354e-01,  1.1959e-01,\n          4.7865e-02, -7.8579e-02,  1.1384e-01,  5.6196e-02,  1.0405e-01,\n         -2.1318e-02,  1.5867e-01,  1.4729e-01, -5.4797e-02,  1.3362e-01,\n          1.2449e-01,  1.6333e-02, -1.4675e-01,  1.0291e-01,  1.3337e-01,\n         -1.6544e-01, -7.8864e-02,  1.5861e-01, -8.1729e-02, -1.0031e-02,\n          3.5659e-02,  6.8321e-02],\n        [ 1.2107e-01, -1.2837e-01,  1.3051e-02, -2.6906e-02,  2.2059e-02,\n         -1.2434e-02,  4.0989e-02, -4.1357e-04, -1.4030e-01, -9.7626e-02,\n          3.1038e-02, -1.1354e-01, -1.2185e-01, -1.6321e-02, -9.1561e-02,\n         -2.9486e-02,  1.0228e-02, -7.0043e-02, -1.7591e-01, -1.4113e-01,\n         -7.7869e-02, -4.8024e-02,  3.3914e-02,  1.3086e-01,  2.7061e-03,\n          4.6681e-02, -9.7119e-02,  6.5355e-02,  3.4926e-02, -6.6792e-02,\n          1.2716e-01, -1.1520e-01],\n        [-1.2439e-01,  6.5371e-03, -8.8702e-02,  4.2135e-02,  5.8033e-02,\n          7.8149e-02, -4.6778e-02, -1.0139e-01,  7.9358e-03,  7.3419e-02,\n         -8.4522e-02, -2.8006e-02, -1.3717e-01,  9.2691e-02, -5.8037e-02,\n          1.8156e-02,  1.3460e-01,  1.4806e-01, -6.8590e-02,  6.0753e-02,\n          1.7670e-02,  8.2748e-02,  1.5695e-01, -1.2630e-01,  1.3516e-01,\n          9.8902e-02, -1.5824e-02,  7.3368e-02, -1.5895e-01, -1.1966e-01,\n          1.4138e-01,  1.6368e-01],\n        [-1.4914e-01,  1.3242e-01,  5.6171e-02, -9.4913e-02, -1.5815e-01,\n          2.5463e-03, -3.8561e-02,  6.0975e-02,  9.5443e-02,  3.9990e-02,\n         -1.2347e-01, -1.7536e-01, -7.3538e-02,  1.5548e-01,  6.9916e-02,\n         -1.4570e-01,  1.1682e-01,  3.0477e-02, -1.4826e-01,  1.4935e-01,\n          1.3317e-01, -3.9681e-02, -1.6204e-01, -4.8679e-02,  8.3227e-03,\n          9.9586e-02, -1.7574e-01, -1.2170e-01,  1.7138e-01, -1.7011e-01,\n          1.3179e-01, -1.6334e-01],\n        [-5.7064e-02,  3.2236e-02, -5.3891e-02, -8.4216e-02,  9.6715e-02,\n         -1.5308e-01, -4.8110e-02,  1.3089e-01,  1.4904e-01,  1.7356e-01,\n          1.2311e-01, -9.8504e-02,  1.6989e-01, -1.2586e-01, -1.6716e-01,\n         -4.1032e-02,  1.6711e-01, -3.5111e-02,  2.0148e-02,  4.4008e-02,\n         -6.0436e-02, -1.6191e-01, -8.1963e-02,  8.7027e-02,  1.0782e-01,\n         -1.4005e-01,  6.8367e-02,  1.7384e-01,  7.4313e-02, -1.1070e-01,\n          1.3779e-01,  1.0716e-01],\n        [ 1.2388e-01,  4.2650e-02, -1.2996e-01, -1.3211e-01,  5.9071e-02,\n         -1.2162e-01, -2.2094e-02, -3.1455e-02,  1.5281e-01, -4.1899e-02,\n         -6.5235e-03, -2.2083e-02,  6.4172e-02,  1.6018e-02,  1.7246e-01,\n         -1.0868e-01,  1.6852e-01, -1.7125e-01,  4.2212e-02, -1.1433e-01,\n          4.7961e-02, -2.5480e-02,  1.1554e-01, -6.7807e-02,  9.0763e-02,\n          1.7262e-01,  9.1345e-02, -1.3493e-01,  9.4345e-02, -2.1565e-03,\n          9.0417e-02, -1.7560e-01],\n        [ 5.4982e-02,  1.2371e-01, -5.2490e-02, -9.3821e-02,  1.2163e-01,\n          2.4831e-02,  7.3669e-03, -4.3109e-02, -1.4406e-03,  4.2379e-02,\n          9.7484e-02, -5.5610e-02,  7.7796e-03,  6.8417e-02, -1.2181e-01,\n         -1.4496e-01, -1.1940e-01, -1.4865e-01,  6.0092e-02, -1.1006e-02,\n         -1.0867e-01,  7.8871e-02, -1.7455e-01, -6.7783e-02,  8.6316e-02,\n         -9.6772e-02, -1.3211e-01, -1.5924e-01,  1.3776e-01,  1.3778e-01,\n          8.5189e-02, -1.1009e-01],\n        [-1.4948e-01,  7.9783e-03,  1.3164e-01,  1.6655e-01, -5.7005e-02,\n          3.2566e-02, -1.2218e-01, -8.1818e-02,  9.0852e-02, -5.5586e-02,\n          4.0791e-02,  1.1037e-01,  5.8936e-02, -1.4574e-01,  7.4858e-02,\n          1.6887e-01,  1.4075e-01, -7.9721e-02,  6.1482e-02,  1.4031e-01,\n         -1.3822e-02, -1.8103e-02,  1.6997e-01,  1.3622e-01,  1.4493e-02,\n          2.4609e-02,  1.2983e-01, -9.8186e-02, -1.3268e-02,  1.5415e-02,\n         -1.6590e-01,  1.6161e-01],\n        [-1.7635e-01,  1.0890e-01, -1.5940e-01,  1.2017e-01,  1.7246e-01,\n         -5.7913e-02,  1.6667e-02,  7.4663e-02,  8.3386e-02, -1.6698e-02,\n          1.5160e-01, -5.5654e-02, -1.5233e-01,  6.6518e-02, -1.0695e-02,\n         -1.2398e-01, -1.4147e-01,  4.3688e-02,  6.7815e-02,  1.1150e-01,\n         -1.5875e-01, -3.2091e-02,  5.6387e-02, -1.1998e-01,  7.1168e-02,\n          8.4674e-02,  5.9262e-02,  6.2117e-02, -1.1058e-01,  1.4913e-01,\n          1.7587e-01,  9.1560e-02],\n        [-3.8708e-02,  9.7961e-02,  1.4253e-01,  3.8318e-02,  1.2123e-01,\n          1.3085e-01,  1.5058e-01,  9.8299e-02, -2.4044e-02,  3.9801e-02,\n         -1.4869e-01,  1.0271e-01, -1.7636e-01, -3.4440e-02,  1.0374e-01,\n         -9.3660e-02, -3.1666e-02,  7.6243e-02, -1.7269e-01, -1.1595e-01,\n         -9.1061e-02,  8.6446e-02,  9.2057e-02,  1.0290e-01,  1.9604e-02,\n         -7.8075e-02, -1.1950e-01, -1.1292e-01, -9.5715e-02, -1.7341e-01,\n         -8.1562e-02, -1.6452e-01],\n        [-8.6976e-02,  1.0868e-01, -8.0166e-02, -6.2649e-02,  7.9136e-02,\n          5.7169e-02, -1.3157e-01, -1.6406e-01, -4.2155e-02, -1.1484e-01,\n          6.2046e-02,  3.6450e-02,  5.8515e-02, -5.8005e-02, -1.5625e-01,\n         -1.1284e-01, -2.0288e-02,  1.6490e-01,  3.1116e-02, -8.0293e-02,\n          6.3535e-02, -1.3516e-01, -1.3555e-01,  6.6034e-02, -8.7015e-02,\n         -1.2947e-01, -1.1634e-01, -1.6924e-01, -1.1324e-01, -1.6969e-01,\n         -1.1083e-02,  1.0520e-01],\n        [ 1.1499e-01, -1.0191e-01, -1.3018e-01, -1.7392e-01,  1.2169e-01,\n          7.4562e-02,  9.2718e-03,  6.9774e-05,  1.4941e-01, -4.8803e-02,\n         -1.4966e-01, -5.3488e-02, -1.7106e-02, -6.2621e-02,  8.1446e-02,\n         -1.2075e-01, -1.7564e-01, -2.9163e-02, -6.1563e-02, -7.0347e-02,\n          4.5411e-02, -1.0803e-02,  1.4712e-01,  8.9295e-02,  4.5568e-03,\n          1.1600e-01,  2.6068e-02, -1.2461e-01, -1.0597e-01,  4.1388e-02,\n         -1.3751e-01,  2.7379e-02],\n        [-1.1643e-02,  1.0427e-01, -1.1839e-01, -1.5426e-01,  1.3410e-01,\n         -9.8479e-02,  1.7472e-01,  7.6972e-02, -4.1890e-02,  1.6342e-01,\n          1.0015e-01,  9.9274e-02,  7.4606e-02, -1.5460e-01,  1.7601e-01,\n          1.2593e-01, -1.7001e-01, -1.5836e-01,  6.5371e-02, -1.7148e-01,\n         -1.7567e-01,  1.5591e-01, -9.9452e-02, -6.5568e-04,  7.9244e-02,\n         -7.6385e-02, -7.7621e-02,  6.7093e-02, -1.4539e-01, -1.3061e-01,\n          9.2603e-02, -5.2606e-02],\n        [-1.5918e-01, -6.2766e-02, -1.0337e-01,  5.2917e-04,  1.4822e-01,\n          1.5079e-01,  3.2050e-02, -1.3876e-01, -1.3807e-01,  9.6158e-02,\n         -2.0966e-02,  3.2998e-02, -7.9421e-02,  1.1739e-01, -1.1723e-01,\n         -2.2148e-02, -7.5558e-02, -1.1349e-03, -1.2381e-01,  2.4169e-02,\n          6.7654e-02,  1.2341e-01,  1.3333e-01, -1.0557e-01, -6.1676e-02,\n         -6.7219e-02, -1.0826e-01,  1.3570e-01, -1.6039e-01, -1.1179e-02,\n         -1.1119e-01,  1.5390e-01],\n        [-1.3188e-01, -5.0337e-03,  1.0684e-01,  6.5375e-02,  3.7497e-02,\n          8.4907e-02,  4.4785e-02, -8.7047e-02, -1.4718e-01,  1.7600e-01,\n         -2.7796e-02,  1.0720e-01, -3.7091e-02, -7.8026e-02, -1.5146e-01,\n          1.0112e-01,  5.3219e-02, -4.3035e-02,  1.0867e-01, -2.9741e-02,\n          7.6039e-02, -5.2252e-02,  4.5434e-02,  1.8849e-03,  1.2901e-01,\n         -6.7135e-02, -1.0772e-01, -1.3041e-01,  1.1294e-01, -2.4583e-02,\n         -5.7941e-02,  1.2762e-01],\n        [ 9.5493e-02,  1.5672e-01,  2.5035e-02, -1.1271e-01, -2.5014e-02,\n          4.2627e-02, -2.3148e-02, -1.0742e-01,  8.0076e-02, -1.5385e-01,\n         -7.5079e-02, -1.2183e-02,  6.3549e-02,  9.7931e-02, -1.9736e-02,\n         -1.1853e-01, -1.0277e-01,  1.7455e-01,  8.5560e-02, -6.8724e-02,\n          1.6503e-01, -7.9256e-02,  1.0981e-01,  8.6079e-02,  3.8020e-02,\n          3.7887e-02,  1.0565e-01, -1.1694e-01, -3.5191e-02, -1.0221e-01,\n         -1.0987e-02, -1.4688e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0151,  0.1341, -0.0573,  0.0192, -0.0530, -0.0873,  0.1162,  0.0690,\n         0.1244,  0.0021, -0.0719,  0.0802, -0.0076,  0.0693,  0.1644, -0.0265],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1807,  0.0761, -0.1847,  0.2303,  0.0370,  0.0638,  0.0072,  0.1700,\n          0.1541,  0.0318, -0.2217,  0.1252, -0.1118,  0.1162, -0.1247, -0.1982],\n        [ 0.0080,  0.2137, -0.2041,  0.0533, -0.2422,  0.0492, -0.2255, -0.1696,\n         -0.0427, -0.1892, -0.1044,  0.2202, -0.1194,  0.0025,  0.0678,  0.0739],\n        [-0.1026, -0.2243,  0.1716, -0.1631,  0.1844,  0.2034,  0.0113, -0.0427,\n         -0.1025,  0.2125, -0.0222,  0.1006,  0.0665,  0.1030,  0.2475,  0.0861],\n        [-0.0850, -0.1070, -0.0193, -0.1713,  0.0896,  0.1437, -0.2359,  0.1467,\n          0.1097,  0.0482, -0.0381, -0.0463, -0.0967,  0.1609, -0.2242,  0.1803],\n        [ 0.2342,  0.1336,  0.2379, -0.0797, -0.2283,  0.2049,  0.0575, -0.0417,\n         -0.0569,  0.2327, -0.2475, -0.0303, -0.1499,  0.1547, -0.0900, -0.1795],\n        [-0.2010,  0.1488, -0.0454, -0.1065,  0.0072,  0.2346,  0.0388, -0.1455,\n          0.0293, -0.2092,  0.1791, -0.0957,  0.1827,  0.1437, -0.2301,  0.0242],\n        [-0.0914,  0.1448, -0.2055,  0.1099,  0.0789, -0.2475,  0.1079, -0.1441,\n         -0.0538, -0.1224, -0.2335, -0.0760, -0.2321, -0.0378, -0.1249,  0.1415],\n        [ 0.2453, -0.1735, -0.1260,  0.0209,  0.1965, -0.1730,  0.1799, -0.0839,\n          0.1659, -0.0786,  0.1205,  0.0438, -0.0311,  0.2083, -0.0764,  0.1575]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0376,  0.2372,  0.2292, -0.0909,  0.0911, -0.0512, -0.1439, -0.0729],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2154, -0.0233,  0.2288, -0.0779, -0.1659, -0.1573,  0.1045, -0.3401]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0549], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7c1fd85adb50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7c1fcd508f10>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s176940000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s176940000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}