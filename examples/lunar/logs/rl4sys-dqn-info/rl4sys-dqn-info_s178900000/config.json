{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s178900000"
    },
    "q_lr":	0.0005,
    "seed":	178900000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x3067d63e0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1086,  0.0765, -0.2870, -0.2063, -0.3267, -0.2180,  0.0437,  0.3535,\n         0.2130,  0.3283, -0.3131, -0.1970,  0.0814,  0.3333,  0.3058, -0.0744,\n         0.1223, -0.1462, -0.3503, -0.3420,  0.2786,  0.2646, -0.1399, -0.0346,\n         0.0368,  0.1083, -0.3167,  0.1517, -0.2282,  0.1915,  0.2727, -0.1729],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3424, -0.1928, -0.1136,  0.2016,  0.1335, -0.1343, -0.2881,  0.2263],\n        [ 0.1997, -0.2779, -0.1653,  0.2161, -0.0023, -0.0182,  0.3351,  0.1141],\n        [-0.3201, -0.2949,  0.2020,  0.2981, -0.3166,  0.3020, -0.3154, -0.0661],\n        [-0.1197, -0.0011,  0.0499,  0.1187, -0.1822, -0.3060, -0.0786, -0.0415],\n        [ 0.0266, -0.0319, -0.1857,  0.0308, -0.3077, -0.0212, -0.3143, -0.1669],\n        [-0.2290,  0.1585,  0.0892, -0.2236,  0.0967, -0.2209,  0.1108, -0.2134],\n        [ 0.1561,  0.2825, -0.2721,  0.2347,  0.3409,  0.1167, -0.2793,  0.0168],\n        [ 0.2194,  0.3031, -0.2666,  0.2768, -0.2449, -0.0767,  0.0927, -0.0063],\n        [ 0.1052, -0.2312, -0.1700, -0.1591, -0.0237, -0.3086, -0.0056,  0.2501],\n        [ 0.0647, -0.0358, -0.3331,  0.3130,  0.3076, -0.2894,  0.2376,  0.3496],\n        [ 0.2447, -0.0066, -0.2017,  0.2040, -0.1084,  0.0900,  0.2789, -0.0033],\n        [ 0.3021, -0.1006,  0.0243,  0.2758,  0.1365,  0.0672, -0.0367,  0.2750],\n        [ 0.2569,  0.0360,  0.1584,  0.2157, -0.2699, -0.0257, -0.2485,  0.2918],\n        [-0.1486, -0.2915,  0.1023,  0.2885, -0.0428,  0.1604, -0.2004, -0.1308],\n        [ 0.0972,  0.2156,  0.3124, -0.2202, -0.2299,  0.0475, -0.3059, -0.0440],\n        [-0.0915, -0.3379,  0.1952,  0.2317, -0.1992,  0.3155,  0.2281,  0.2574],\n        [ 0.1308, -0.1388, -0.0039, -0.0984, -0.0598,  0.1311, -0.2134, -0.0784],\n        [-0.0780,  0.0573,  0.1946, -0.3058, -0.0336,  0.0299,  0.1207, -0.2754],\n        [-0.0262,  0.0075, -0.3316,  0.0696,  0.2755,  0.2958, -0.3385,  0.1388],\n        [ 0.3265,  0.0723, -0.2334,  0.2271,  0.1201,  0.2043,  0.0307,  0.2887],\n        [ 0.1897, -0.1817, -0.1519, -0.1482,  0.0629, -0.2913,  0.3200,  0.3202],\n        [ 0.2292, -0.1426, -0.1410,  0.0998, -0.2521, -0.2938,  0.3369, -0.1032],\n        [ 0.1914,  0.0185, -0.0540,  0.0308, -0.0792,  0.2568, -0.2424, -0.0807],\n        [ 0.1464,  0.0201,  0.2170, -0.1723, -0.1638,  0.1933, -0.1365,  0.2092],\n        [ 0.3422,  0.3161,  0.0346,  0.0082, -0.3204,  0.0670,  0.1444, -0.0969],\n        [ 0.1025, -0.0601, -0.1908,  0.0144,  0.0427,  0.0086,  0.2278,  0.2341],\n        [ 0.2269, -0.0603, -0.3490,  0.0763,  0.2559, -0.3416, -0.0544, -0.0759],\n        [-0.2659, -0.1433,  0.2681, -0.1205,  0.0685, -0.0937,  0.2675,  0.2140],\n        [-0.0512, -0.0746,  0.2547,  0.0763, -0.0994,  0.1544,  0.1460, -0.3001],\n        [ 0.1451,  0.1014, -0.1015,  0.0705,  0.3054, -0.2391,  0.2888, -0.0147],\n        [-0.2416,  0.2795, -0.1062,  0.0889,  0.2398,  0.0854, -0.0036, -0.2274],\n        [ 0.2632,  0.1971,  0.0760,  0.2420,  0.2366, -0.3212,  0.0126,  0.0836]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1096, -0.1413,  0.0993,  0.1366,  0.1136, -0.1308,  0.0292,  0.1217,\n        -0.0194,  0.1726,  0.1444,  0.1288, -0.0719, -0.1406, -0.0289, -0.0116],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.3858e-02,  2.8769e-02, -1.0532e-01,  6.8004e-02, -8.1696e-02,\n         -4.7126e-02,  1.0509e-01, -6.4183e-02,  7.5480e-02, -1.3090e-01,\n          1.0041e-01,  1.7692e-02,  3.4155e-02, -4.0651e-02,  1.2413e-01,\n         -9.8685e-02,  1.3138e-01, -1.7156e-02,  1.2508e-02,  1.3117e-01,\n          1.4409e-01,  1.6918e-01,  4.5395e-02,  1.1649e-01,  1.6294e-01,\n         -3.1561e-02, -3.8669e-02, -4.4707e-02,  1.6885e-01,  1.6777e-01,\n          1.5765e-01,  1.2363e-01],\n        [-1.1658e-01,  1.3319e-01, -1.6922e-01, -5.0921e-02, -1.1883e-01,\n          1.2206e-01,  1.7011e-01, -1.5310e-01,  3.9430e-02, -3.5090e-02,\n          1.6496e-01, -1.3299e-02,  3.0668e-04, -1.7242e-01,  1.1047e-01,\n          1.1475e-01,  1.6598e-01, -1.7183e-02, -3.4604e-02, -1.4786e-01,\n          9.2769e-04,  2.6349e-02,  1.7663e-01, -1.2894e-01, -3.0411e-02,\n         -1.5164e-01, -6.5844e-02,  5.7129e-02,  9.5447e-02,  1.4082e-01,\n         -1.7285e-01,  1.1299e-01],\n        [-1.7215e-01, -5.4806e-02,  1.3972e-01,  1.9824e-02, -1.3114e-02,\n         -1.4507e-01,  6.0764e-02, -4.7686e-03, -5.4301e-02,  1.3545e-01,\n          7.1964e-02,  7.2819e-02,  1.4769e-01, -1.3031e-01, -1.2112e-01,\n          1.6962e-02,  1.4248e-01,  1.7038e-01,  1.5628e-01, -8.6206e-02,\n         -1.2154e-01,  9.6267e-02,  1.3998e-01,  9.0828e-02, -1.3441e-01,\n          1.0775e-01, -5.2815e-02, -1.6375e-01,  1.4960e-01,  1.1883e-01,\n         -5.6933e-02,  9.8040e-02],\n        [ 6.6729e-02, -1.6598e-01,  9.0947e-02, -1.1715e-01,  1.6589e-01,\n         -7.8676e-02, -4.3984e-02, -4.2046e-02,  8.2051e-02, -1.3547e-01,\n         -1.5078e-01,  1.1471e-02,  1.4318e-01, -1.2453e-01,  8.7687e-02,\n          3.1300e-02,  1.4676e-01,  6.2764e-02,  1.5376e-01,  1.0901e-01,\n         -1.2214e-01,  7.5049e-02,  9.3634e-03, -1.2409e-01,  6.5383e-02,\n         -9.8912e-02, -8.7783e-02,  8.2411e-02,  3.7105e-02, -1.2584e-01,\n         -1.6647e-01,  1.7550e-01],\n        [ 1.0687e-02,  5.5012e-02, -1.2265e-02, -3.1477e-02, -2.7466e-02,\n          8.7528e-02, -1.5655e-01,  1.3596e-01, -1.9197e-02,  1.8735e-02,\n          1.2854e-02, -1.0406e-01, -1.9621e-02,  7.5627e-02, -3.7539e-02,\n         -7.4918e-02, -1.3899e-02, -1.1176e-01, -8.9676e-02, -6.1170e-02,\n         -1.4519e-01, -1.8097e-02,  1.1212e-01, -3.2629e-02,  1.0429e-01,\n         -1.1023e-01,  1.6418e-01,  1.1422e-01,  1.2601e-01, -1.0645e-01,\n         -3.0588e-02,  7.5437e-02],\n        [ 1.4838e-01, -3.4732e-02,  9.1971e-02, -1.5932e-01, -1.6087e-01,\n         -5.9283e-02, -1.7187e-01,  4.2480e-02, -1.7560e-01, -2.8522e-02,\n          3.3806e-02, -8.5329e-02,  1.2637e-01, -1.0549e-01,  4.9772e-02,\n         -2.8859e-02,  1.4413e-01,  9.7040e-02, -3.1096e-02, -1.1150e-01,\n          1.6231e-01,  1.0180e-02,  1.1109e-01, -5.7569e-02,  3.1468e-02,\n         -1.5176e-01,  8.7412e-02, -1.7045e-01,  7.6279e-02, -1.5356e-01,\n         -2.7565e-02,  1.0022e-01],\n        [ 1.1326e-01,  2.4613e-02,  8.3892e-02, -1.5199e-01,  1.7253e-01,\n         -1.4465e-01, -8.3054e-02, -4.0628e-02, -7.7943e-02, -1.4907e-01,\n          1.5949e-01,  9.1242e-02, -1.7670e-01, -9.7928e-03,  1.3358e-01,\n          1.2390e-01,  8.4529e-02, -1.7096e-01,  6.1161e-02,  3.4271e-02,\n         -1.7860e-02, -4.2339e-02,  1.9896e-02, -2.2917e-02,  1.0736e-01,\n          1.4481e-01,  7.7640e-02, -4.1462e-02,  1.2858e-01, -1.1009e-01,\n         -4.9923e-02, -1.6202e-01],\n        [-5.1780e-03,  8.4365e-02, -7.4143e-02,  3.5616e-02, -1.5752e-01,\n         -1.6922e-01, -1.5336e-01,  5.1366e-02, -6.0258e-02, -1.5058e-01,\n         -4.4717e-02, -1.6301e-01, -1.1818e-01, -1.2073e-01, -1.1842e-01,\n         -3.0541e-02, -1.4360e-01, -1.5189e-01, -1.7372e-02, -1.1155e-01,\n         -6.0724e-03, -1.6523e-01,  1.3469e-01, -2.9034e-03, -3.7726e-02,\n         -1.2080e-01,  3.9854e-02,  6.3545e-02,  6.3084e-02,  1.3552e-01,\n          1.0275e-01, -6.2431e-02],\n        [-7.9964e-02, -6.0496e-03,  1.0695e-02,  2.8004e-03,  5.5013e-02,\n         -7.8012e-03,  9.3192e-02, -5.2743e-02, -5.6950e-02,  7.2399e-02,\n         -8.9707e-02,  8.2605e-02,  1.3272e-01,  4.3502e-02, -1.1100e-01,\n         -1.2577e-01,  1.1085e-01, -9.3639e-02,  3.8984e-02, -4.5070e-02,\n         -6.9481e-02, -7.1674e-02,  1.1321e-01,  8.9881e-02, -1.4443e-01,\n         -7.8421e-02,  1.0490e-01, -1.1961e-01,  9.4332e-02,  5.9674e-03,\n         -8.6507e-02, -2.3471e-02],\n        [-2.1334e-02,  7.2489e-02,  4.3622e-02,  1.0121e-01,  9.9998e-02,\n          1.1784e-01, -5.1945e-02, -9.0086e-02, -4.7999e-02, -6.5140e-02,\n         -2.0860e-02,  1.1943e-01, -1.0664e-01, -1.5188e-01, -1.6975e-01,\n          1.3337e-01,  9.2889e-02, -9.3323e-02,  1.7197e-01,  1.5680e-02,\n          1.4903e-01,  1.4881e-01, -1.1270e-01, -1.3793e-02,  4.0247e-02,\n          8.1936e-02,  3.3534e-02,  1.1194e-01,  4.4210e-02,  5.7862e-03,\n          1.7259e-01,  4.2948e-03],\n        [-1.3589e-01, -1.9009e-02, -1.7321e-02,  1.0884e-01, -1.1968e-01,\n          8.1261e-02,  1.5687e-01, -1.2108e-01, -1.5895e-01, -7.6814e-02,\n         -2.9374e-02, -1.5134e-01,  3.8872e-02,  1.2909e-01,  8.6723e-02,\n         -1.4707e-01,  1.3808e-01, -2.2948e-02, -1.3037e-01, -1.0565e-02,\n          2.1610e-02,  1.3508e-01,  4.8660e-02, -7.9041e-02,  8.3623e-02,\n         -6.6695e-02, -2.3102e-02, -1.2381e-01,  1.1958e-01,  7.8641e-02,\n         -2.7666e-03, -1.7066e-01],\n        [ 2.7457e-02,  7.9108e-02,  5.9076e-02, -1.3149e-01, -8.3763e-02,\n          7.3230e-02, -1.5616e-01, -7.2458e-02, -1.1457e-01, -1.7319e-01,\n          1.3192e-01,  7.9530e-02,  8.5771e-02,  1.4127e-01,  4.3656e-02,\n          1.8750e-02,  9.8243e-03, -1.3519e-01,  2.8890e-02,  1.7348e-04,\n          1.7203e-01,  4.0551e-02, -1.4534e-01,  9.9770e-02,  9.1962e-02,\n          1.0770e-01, -1.7198e-01, -1.0582e-01, -4.4971e-02, -1.2221e-01,\n         -4.1483e-02,  6.8251e-02],\n        [ 1.5011e-01,  1.2460e-01, -9.1300e-02,  1.1802e-01, -7.3035e-02,\n         -1.5890e-01,  9.5472e-02,  3.5984e-02, -1.1820e-01,  4.3946e-02,\n          1.6312e-01,  3.2930e-02, -1.5617e-01, -1.0857e-01, -1.4591e-02,\n         -1.4170e-01, -1.7538e-01, -1.4255e-01,  1.3842e-01,  1.8940e-02,\n         -5.0816e-02, -3.0519e-02, -3.7108e-02,  6.6931e-02, -3.3151e-02,\n         -2.5611e-02, -1.1662e-01, -8.6989e-02,  7.4077e-02, -8.2705e-02,\n         -7.2156e-02, -3.8398e-03],\n        [ 1.5113e-01,  1.4095e-01, -3.1366e-02, -1.3263e-02,  1.6777e-01,\n         -5.7441e-02, -6.5416e-02,  5.4147e-02, -4.5313e-02,  6.2050e-02,\n         -1.5002e-01, -8.0583e-02, -7.3670e-02,  1.7223e-01,  9.9121e-02,\n          9.0945e-02,  1.1021e-01,  4.0876e-02, -7.7200e-03,  1.0629e-01,\n         -1.7029e-01,  1.5317e-01,  1.3586e-01, -1.4736e-01,  7.2794e-02,\n         -1.6165e-01,  9.2481e-02, -1.4734e-01,  1.5122e-01,  5.1003e-02,\n          1.3159e-01,  7.3850e-02],\n        [ 1.7063e-01, -3.4779e-02, -1.1437e-01, -5.7682e-02,  8.6295e-02,\n          5.8337e-02,  1.0480e-01,  1.1538e-02,  4.1144e-02, -1.3250e-01,\n         -3.9470e-02,  4.7344e-02,  1.7611e-01,  2.6865e-02, -2.2238e-02,\n         -1.1675e-01,  7.1366e-02,  7.6466e-02,  6.0280e-02, -1.5882e-01,\n         -5.4551e-02,  1.7499e-01, -6.7160e-03,  1.0360e-01,  1.0347e-01,\n         -8.9669e-02,  1.6361e-01,  1.6398e-01,  1.7023e-01, -5.8415e-02,\n         -6.1183e-02,  1.3166e-01],\n        [-1.1613e-02, -7.8040e-03, -1.5002e-01, -8.0750e-03,  1.4556e-02,\n         -8.1966e-02,  1.4771e-01, -2.0430e-02, -9.0475e-02, -1.3143e-01,\n         -1.0439e-01, -1.6598e-01,  3.0961e-02, -1.0090e-01,  8.0855e-02,\n         -1.0209e-01, -8.2357e-03, -3.2755e-02,  2.2238e-02, -1.2590e-01,\n          1.5942e-01,  7.7298e-02, -1.0963e-01,  4.6870e-02,  7.7675e-02,\n         -3.2312e-02,  1.6327e-01,  1.4333e-01,  8.6747e-02,  5.4595e-02,\n         -1.2019e-01,  7.0607e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0516, -0.1687,  0.1847,  0.0734,  0.0358,  0.1230,  0.1595,  0.0163],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1572,  0.0906, -0.0297, -0.0097,  0.2299, -0.0401, -0.1146,  0.2041,\n          0.0733,  0.1446, -0.0137, -0.2158, -0.1702, -0.1155,  0.1598,  0.0518],\n        [-0.1181,  0.0010, -0.0249, -0.0282, -0.1872,  0.0712,  0.0639,  0.1920,\n          0.1923, -0.0860, -0.0021,  0.1077, -0.1668, -0.1062,  0.0311, -0.1167],\n        [ 0.0396,  0.0224, -0.2454,  0.1606,  0.0644,  0.2223, -0.0862,  0.1734,\n         -0.2357,  0.0402, -0.1656,  0.2141,  0.2209, -0.0853, -0.1327, -0.1988],\n        [ 0.1216, -0.1870, -0.0649,  0.1272,  0.1195, -0.2461, -0.1966,  0.1312,\n          0.1591, -0.1555, -0.0149, -0.0376,  0.2323, -0.1773, -0.0847, -0.0493],\n        [ 0.1003, -0.2118, -0.0240,  0.1838, -0.2043,  0.2492,  0.0294, -0.0153,\n         -0.1240,  0.2162,  0.1912,  0.0545,  0.1196,  0.1683,  0.2024, -0.1809],\n        [-0.0222,  0.0803, -0.0820,  0.2145, -0.0370, -0.1669, -0.0630, -0.0551,\n         -0.1520, -0.0347,  0.2443,  0.0672, -0.2403, -0.1866, -0.1516,  0.0891],\n        [ 0.1909,  0.1222, -0.1356, -0.0288, -0.2286,  0.1859, -0.1510, -0.1647,\n          0.1395,  0.0468,  0.0637,  0.1492, -0.1373, -0.1157, -0.1257,  0.2290],\n        [-0.0428, -0.1124, -0.2080, -0.2432, -0.1393,  0.2411, -0.0929,  0.0504,\n          0.0605,  0.1620, -0.0488, -0.1253,  0.1147,  0.1752, -0.1460,  0.0284]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.3251], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0531,  0.2232,  0.3205, -0.0245,  0.2808,  0.3110, -0.0029,  0.3251]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.3424, -0.1928, -0.1136,  0.2016,  0.1335, -0.1343, -0.2881,  0.2263],\n        [ 0.1997, -0.2779, -0.1653,  0.2161, -0.0023, -0.0182,  0.3351,  0.1141],\n        [-0.3201, -0.2949,  0.2020,  0.2981, -0.3166,  0.3020, -0.3154, -0.0661],\n        [-0.1197, -0.0011,  0.0499,  0.1187, -0.1822, -0.3060, -0.0786, -0.0415],\n        [ 0.0266, -0.0319, -0.1857,  0.0308, -0.3077, -0.0212, -0.3143, -0.1669],\n        [-0.2290,  0.1585,  0.0892, -0.2236,  0.0967, -0.2209,  0.1108, -0.2134],\n        [ 0.1561,  0.2825, -0.2721,  0.2347,  0.3409,  0.1167, -0.2793,  0.0168],\n        [ 0.2194,  0.3031, -0.2666,  0.2768, -0.2449, -0.0767,  0.0927, -0.0063],\n        [ 0.1052, -0.2312, -0.1700, -0.1591, -0.0237, -0.3086, -0.0056,  0.2501],\n        [ 0.0647, -0.0358, -0.3331,  0.3130,  0.3076, -0.2894,  0.2376,  0.3496],\n        [ 0.2447, -0.0066, -0.2017,  0.2040, -0.1084,  0.0900,  0.2789, -0.0033],\n        [ 0.3021, -0.1006,  0.0243,  0.2758,  0.1365,  0.0672, -0.0367,  0.2750],\n        [ 0.2569,  0.0360,  0.1584,  0.2157, -0.2699, -0.0257, -0.2485,  0.2918],\n        [-0.1486, -0.2915,  0.1023,  0.2885, -0.0428,  0.1604, -0.2004, -0.1308],\n        [ 0.0972,  0.2156,  0.3124, -0.2202, -0.2299,  0.0475, -0.3059, -0.0440],\n        [-0.0915, -0.3379,  0.1952,  0.2317, -0.1992,  0.3155,  0.2281,  0.2574],\n        [ 0.1308, -0.1388, -0.0039, -0.0984, -0.0598,  0.1311, -0.2134, -0.0784],\n        [-0.0780,  0.0573,  0.1946, -0.3058, -0.0336,  0.0299,  0.1207, -0.2754],\n        [-0.0262,  0.0075, -0.3316,  0.0696,  0.2755,  0.2958, -0.3385,  0.1388],\n        [ 0.3265,  0.0723, -0.2334,  0.2271,  0.1201,  0.2043,  0.0307,  0.2887],\n        [ 0.1897, -0.1817, -0.1519, -0.1482,  0.0629, -0.2913,  0.3200,  0.3202],\n        [ 0.2292, -0.1426, -0.1410,  0.0998, -0.2521, -0.2938,  0.3369, -0.1032],\n        [ 0.1914,  0.0185, -0.0540,  0.0308, -0.0792,  0.2568, -0.2424, -0.0807],\n        [ 0.1464,  0.0201,  0.2170, -0.1723, -0.1638,  0.1933, -0.1365,  0.2092],\n        [ 0.3422,  0.3161,  0.0346,  0.0082, -0.3204,  0.0670,  0.1444, -0.0969],\n        [ 0.1025, -0.0601, -0.1908,  0.0144,  0.0427,  0.0086,  0.2278,  0.2341],\n        [ 0.2269, -0.0603, -0.3490,  0.0763,  0.2559, -0.3416, -0.0544, -0.0759],\n        [-0.2659, -0.1433,  0.2681, -0.1205,  0.0685, -0.0937,  0.2675,  0.2140],\n        [-0.0512, -0.0746,  0.2547,  0.0763, -0.0994,  0.1544,  0.1460, -0.3001],\n        [ 0.1451,  0.1014, -0.1015,  0.0705,  0.3054, -0.2391,  0.2888, -0.0147],\n        [-0.2416,  0.2795, -0.1062,  0.0889,  0.2398,  0.0854, -0.0036, -0.2274],\n        [ 0.2632,  0.1971,  0.0760,  0.2420,  0.2366, -0.3212,  0.0126,  0.0836]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1086,  0.0765, -0.2870, -0.2063, -0.3267, -0.2180,  0.0437,  0.3535,\n         0.2130,  0.3283, -0.3131, -0.1970,  0.0814,  0.3333,  0.3058, -0.0744,\n         0.1223, -0.1462, -0.3503, -0.3420,  0.2786,  0.2646, -0.1399, -0.0346,\n         0.0368,  0.1083, -0.3167,  0.1517, -0.2282,  0.1915,  0.2727, -0.1729],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-3.3858e-02,  2.8769e-02, -1.0532e-01,  6.8004e-02, -8.1696e-02,\n         -4.7126e-02,  1.0509e-01, -6.4183e-02,  7.5480e-02, -1.3090e-01,\n          1.0041e-01,  1.7692e-02,  3.4155e-02, -4.0651e-02,  1.2413e-01,\n         -9.8685e-02,  1.3138e-01, -1.7156e-02,  1.2508e-02,  1.3117e-01,\n          1.4409e-01,  1.6918e-01,  4.5395e-02,  1.1649e-01,  1.6294e-01,\n         -3.1561e-02, -3.8669e-02, -4.4707e-02,  1.6885e-01,  1.6777e-01,\n          1.5765e-01,  1.2363e-01],\n        [-1.1658e-01,  1.3319e-01, -1.6922e-01, -5.0921e-02, -1.1883e-01,\n          1.2206e-01,  1.7011e-01, -1.5310e-01,  3.9430e-02, -3.5090e-02,\n          1.6496e-01, -1.3299e-02,  3.0668e-04, -1.7242e-01,  1.1047e-01,\n          1.1475e-01,  1.6598e-01, -1.7183e-02, -3.4604e-02, -1.4786e-01,\n          9.2769e-04,  2.6349e-02,  1.7663e-01, -1.2894e-01, -3.0411e-02,\n         -1.5164e-01, -6.5844e-02,  5.7129e-02,  9.5447e-02,  1.4082e-01,\n         -1.7285e-01,  1.1299e-01],\n        [-1.7215e-01, -5.4806e-02,  1.3972e-01,  1.9824e-02, -1.3114e-02,\n         -1.4507e-01,  6.0764e-02, -4.7686e-03, -5.4301e-02,  1.3545e-01,\n          7.1964e-02,  7.2819e-02,  1.4769e-01, -1.3031e-01, -1.2112e-01,\n          1.6962e-02,  1.4248e-01,  1.7038e-01,  1.5628e-01, -8.6206e-02,\n         -1.2154e-01,  9.6267e-02,  1.3998e-01,  9.0828e-02, -1.3441e-01,\n          1.0775e-01, -5.2815e-02, -1.6375e-01,  1.4960e-01,  1.1883e-01,\n         -5.6933e-02,  9.8040e-02],\n        [ 6.6729e-02, -1.6598e-01,  9.0947e-02, -1.1715e-01,  1.6589e-01,\n         -7.8676e-02, -4.3984e-02, -4.2046e-02,  8.2051e-02, -1.3547e-01,\n         -1.5078e-01,  1.1471e-02,  1.4318e-01, -1.2453e-01,  8.7687e-02,\n          3.1300e-02,  1.4676e-01,  6.2764e-02,  1.5376e-01,  1.0901e-01,\n         -1.2214e-01,  7.5049e-02,  9.3634e-03, -1.2409e-01,  6.5383e-02,\n         -9.8912e-02, -8.7783e-02,  8.2411e-02,  3.7105e-02, -1.2584e-01,\n         -1.6647e-01,  1.7550e-01],\n        [ 1.0687e-02,  5.5012e-02, -1.2265e-02, -3.1477e-02, -2.7466e-02,\n          8.7528e-02, -1.5655e-01,  1.3596e-01, -1.9197e-02,  1.8735e-02,\n          1.2854e-02, -1.0406e-01, -1.9621e-02,  7.5627e-02, -3.7539e-02,\n         -7.4918e-02, -1.3899e-02, -1.1176e-01, -8.9676e-02, -6.1170e-02,\n         -1.4519e-01, -1.8097e-02,  1.1212e-01, -3.2629e-02,  1.0429e-01,\n         -1.1023e-01,  1.6418e-01,  1.1422e-01,  1.2601e-01, -1.0645e-01,\n         -3.0588e-02,  7.5437e-02],\n        [ 1.4838e-01, -3.4732e-02,  9.1971e-02, -1.5932e-01, -1.6087e-01,\n         -5.9283e-02, -1.7187e-01,  4.2480e-02, -1.7560e-01, -2.8522e-02,\n          3.3806e-02, -8.5329e-02,  1.2637e-01, -1.0549e-01,  4.9772e-02,\n         -2.8859e-02,  1.4413e-01,  9.7040e-02, -3.1096e-02, -1.1150e-01,\n          1.6231e-01,  1.0180e-02,  1.1109e-01, -5.7569e-02,  3.1468e-02,\n         -1.5176e-01,  8.7412e-02, -1.7045e-01,  7.6279e-02, -1.5356e-01,\n         -2.7565e-02,  1.0022e-01],\n        [ 1.1326e-01,  2.4613e-02,  8.3892e-02, -1.5199e-01,  1.7253e-01,\n         -1.4465e-01, -8.3054e-02, -4.0628e-02, -7.7943e-02, -1.4907e-01,\n          1.5949e-01,  9.1242e-02, -1.7670e-01, -9.7928e-03,  1.3358e-01,\n          1.2390e-01,  8.4529e-02, -1.7096e-01,  6.1161e-02,  3.4271e-02,\n         -1.7860e-02, -4.2339e-02,  1.9896e-02, -2.2917e-02,  1.0736e-01,\n          1.4481e-01,  7.7640e-02, -4.1462e-02,  1.2858e-01, -1.1009e-01,\n         -4.9923e-02, -1.6202e-01],\n        [-5.1780e-03,  8.4365e-02, -7.4143e-02,  3.5616e-02, -1.5752e-01,\n         -1.6922e-01, -1.5336e-01,  5.1366e-02, -6.0258e-02, -1.5058e-01,\n         -4.4717e-02, -1.6301e-01, -1.1818e-01, -1.2073e-01, -1.1842e-01,\n         -3.0541e-02, -1.4360e-01, -1.5189e-01, -1.7372e-02, -1.1155e-01,\n         -6.0724e-03, -1.6523e-01,  1.3469e-01, -2.9034e-03, -3.7726e-02,\n         -1.2080e-01,  3.9854e-02,  6.3545e-02,  6.3084e-02,  1.3552e-01,\n          1.0275e-01, -6.2431e-02],\n        [-7.9964e-02, -6.0496e-03,  1.0695e-02,  2.8004e-03,  5.5013e-02,\n         -7.8012e-03,  9.3192e-02, -5.2743e-02, -5.6950e-02,  7.2399e-02,\n         -8.9707e-02,  8.2605e-02,  1.3272e-01,  4.3502e-02, -1.1100e-01,\n         -1.2577e-01,  1.1085e-01, -9.3639e-02,  3.8984e-02, -4.5070e-02,\n         -6.9481e-02, -7.1674e-02,  1.1321e-01,  8.9881e-02, -1.4443e-01,\n         -7.8421e-02,  1.0490e-01, -1.1961e-01,  9.4332e-02,  5.9674e-03,\n         -8.6507e-02, -2.3471e-02],\n        [-2.1334e-02,  7.2489e-02,  4.3622e-02,  1.0121e-01,  9.9998e-02,\n          1.1784e-01, -5.1945e-02, -9.0086e-02, -4.7999e-02, -6.5140e-02,\n         -2.0860e-02,  1.1943e-01, -1.0664e-01, -1.5188e-01, -1.6975e-01,\n          1.3337e-01,  9.2889e-02, -9.3323e-02,  1.7197e-01,  1.5680e-02,\n          1.4903e-01,  1.4881e-01, -1.1270e-01, -1.3793e-02,  4.0247e-02,\n          8.1936e-02,  3.3534e-02,  1.1194e-01,  4.4210e-02,  5.7862e-03,\n          1.7259e-01,  4.2948e-03],\n        [-1.3589e-01, -1.9009e-02, -1.7321e-02,  1.0884e-01, -1.1968e-01,\n          8.1261e-02,  1.5687e-01, -1.2108e-01, -1.5895e-01, -7.6814e-02,\n         -2.9374e-02, -1.5134e-01,  3.8872e-02,  1.2909e-01,  8.6723e-02,\n         -1.4707e-01,  1.3808e-01, -2.2948e-02, -1.3037e-01, -1.0565e-02,\n          2.1610e-02,  1.3508e-01,  4.8660e-02, -7.9041e-02,  8.3623e-02,\n         -6.6695e-02, -2.3102e-02, -1.2381e-01,  1.1958e-01,  7.8641e-02,\n         -2.7666e-03, -1.7066e-01],\n        [ 2.7457e-02,  7.9108e-02,  5.9076e-02, -1.3149e-01, -8.3763e-02,\n          7.3230e-02, -1.5616e-01, -7.2458e-02, -1.1457e-01, -1.7319e-01,\n          1.3192e-01,  7.9530e-02,  8.5771e-02,  1.4127e-01,  4.3656e-02,\n          1.8750e-02,  9.8243e-03, -1.3519e-01,  2.8890e-02,  1.7348e-04,\n          1.7203e-01,  4.0551e-02, -1.4534e-01,  9.9770e-02,  9.1962e-02,\n          1.0770e-01, -1.7198e-01, -1.0582e-01, -4.4971e-02, -1.2221e-01,\n         -4.1483e-02,  6.8251e-02],\n        [ 1.5011e-01,  1.2460e-01, -9.1300e-02,  1.1802e-01, -7.3035e-02,\n         -1.5890e-01,  9.5472e-02,  3.5984e-02, -1.1820e-01,  4.3946e-02,\n          1.6312e-01,  3.2930e-02, -1.5617e-01, -1.0857e-01, -1.4591e-02,\n         -1.4170e-01, -1.7538e-01, -1.4255e-01,  1.3842e-01,  1.8940e-02,\n         -5.0816e-02, -3.0519e-02, -3.7108e-02,  6.6931e-02, -3.3151e-02,\n         -2.5611e-02, -1.1662e-01, -8.6989e-02,  7.4077e-02, -8.2705e-02,\n         -7.2156e-02, -3.8398e-03],\n        [ 1.5113e-01,  1.4095e-01, -3.1366e-02, -1.3263e-02,  1.6777e-01,\n         -5.7441e-02, -6.5416e-02,  5.4147e-02, -4.5313e-02,  6.2050e-02,\n         -1.5002e-01, -8.0583e-02, -7.3670e-02,  1.7223e-01,  9.9121e-02,\n          9.0945e-02,  1.1021e-01,  4.0876e-02, -7.7200e-03,  1.0629e-01,\n         -1.7029e-01,  1.5317e-01,  1.3586e-01, -1.4736e-01,  7.2794e-02,\n         -1.6165e-01,  9.2481e-02, -1.4734e-01,  1.5122e-01,  5.1003e-02,\n          1.3159e-01,  7.3850e-02],\n        [ 1.7063e-01, -3.4779e-02, -1.1437e-01, -5.7682e-02,  8.6295e-02,\n          5.8337e-02,  1.0480e-01,  1.1538e-02,  4.1144e-02, -1.3250e-01,\n         -3.9470e-02,  4.7344e-02,  1.7611e-01,  2.6865e-02, -2.2238e-02,\n         -1.1675e-01,  7.1366e-02,  7.6466e-02,  6.0280e-02, -1.5882e-01,\n         -5.4551e-02,  1.7499e-01, -6.7160e-03,  1.0360e-01,  1.0347e-01,\n         -8.9669e-02,  1.6361e-01,  1.6398e-01,  1.7023e-01, -5.8415e-02,\n         -6.1183e-02,  1.3166e-01],\n        [-1.1613e-02, -7.8040e-03, -1.5002e-01, -8.0750e-03,  1.4556e-02,\n         -8.1966e-02,  1.4771e-01, -2.0430e-02, -9.0475e-02, -1.3143e-01,\n         -1.0439e-01, -1.6598e-01,  3.0961e-02, -1.0090e-01,  8.0855e-02,\n         -1.0209e-01, -8.2357e-03, -3.2755e-02,  2.2238e-02, -1.2590e-01,\n          1.5942e-01,  7.7298e-02, -1.0963e-01,  4.6870e-02,  7.7675e-02,\n         -3.2312e-02,  1.6327e-01,  1.4333e-01,  8.6747e-02,  5.4595e-02,\n         -1.2019e-01,  7.0607e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1096, -0.1413,  0.0993,  0.1366,  0.1136, -0.1308,  0.0292,  0.1217,\n        -0.0194,  0.1726,  0.1444,  0.1288, -0.0719, -0.1406, -0.0289, -0.0116],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1572,  0.0906, -0.0297, -0.0097,  0.2299, -0.0401, -0.1146,  0.2041,\n          0.0733,  0.1446, -0.0137, -0.2158, -0.1702, -0.1155,  0.1598,  0.0518],\n        [-0.1181,  0.0010, -0.0249, -0.0282, -0.1872,  0.0712,  0.0639,  0.1920,\n          0.1923, -0.0860, -0.0021,  0.1077, -0.1668, -0.1062,  0.0311, -0.1167],\n        [ 0.0396,  0.0224, -0.2454,  0.1606,  0.0644,  0.2223, -0.0862,  0.1734,\n         -0.2357,  0.0402, -0.1656,  0.2141,  0.2209, -0.0853, -0.1327, -0.1988],\n        [ 0.1216, -0.1870, -0.0649,  0.1272,  0.1195, -0.2461, -0.1966,  0.1312,\n          0.1591, -0.1555, -0.0149, -0.0376,  0.2323, -0.1773, -0.0847, -0.0493],\n        [ 0.1003, -0.2118, -0.0240,  0.1838, -0.2043,  0.2492,  0.0294, -0.0153,\n         -0.1240,  0.2162,  0.1912,  0.0545,  0.1196,  0.1683,  0.2024, -0.1809],\n        [-0.0222,  0.0803, -0.0820,  0.2145, -0.0370, -0.1669, -0.0630, -0.0551,\n         -0.1520, -0.0347,  0.2443,  0.0672, -0.2403, -0.1866, -0.1516,  0.0891],\n        [ 0.1909,  0.1222, -0.1356, -0.0288, -0.2286,  0.1859, -0.1510, -0.1647,\n          0.1395,  0.0468,  0.0637,  0.1492, -0.1373, -0.1157, -0.1257,  0.2290],\n        [-0.0428, -0.1124, -0.2080, -0.2432, -0.1393,  0.2411, -0.0929,  0.0504,\n          0.0605,  0.1620, -0.0488, -0.1253,  0.1147,  0.1752, -0.1460,  0.0284]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0516, -0.1687,  0.1847,  0.0734,  0.0358,  0.1230,  0.1595,  0.0163],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0531,  0.2232,  0.3205, -0.0245,  0.2808,  0.3110, -0.0029,  0.3251]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.3251], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x11771be80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x3067d6590>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s178900000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s178900000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}