{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s180310000"
    },
    "q_lr":	0.0005,
    "seed":	180310000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7e62593e5510>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=32, out_features=16, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=16, out_features=8, bias=True)\n    (9): ReLU()\n    (10): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=32, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=32, out_features=16, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=16, out_features=8, bias=True)\n  (9): ReLU()\n  (10): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-3.2616e-01, -5.6886e-02,  1.6651e-01, -6.5059e-02, -1.6460e-01,\n        -4.3738e-02,  2.8844e-01,  7.2061e-02,  2.6188e-01, -1.1699e-01,\n         2.4542e-01,  7.8197e-02, -3.3883e-01,  2.6263e-01,  2.2203e-01,\n        -8.6443e-02,  2.3866e-01, -4.2169e-02,  2.9325e-01, -1.2025e-01,\n         9.5744e-02, -2.9280e-02,  2.0441e-05, -1.5986e-01, -1.9098e-01,\n         3.2475e-01, -3.4897e-01, -3.1455e-01, -1.6389e-02, -1.8786e-01,\n        -5.9864e-02,  4.6363e-02,  3.2002e-01,  2.7711e-01,  2.7138e-01,\n        -1.3966e-01, -3.0241e-01,  6.9881e-02,  8.1109e-02, -1.3019e-01,\n        -1.0660e-01, -1.0453e-02, -2.8131e-01,  3.3030e-01, -2.4696e-01,\n        -2.9001e-02, -1.9623e-01,  3.4760e-01, -1.7245e-01, -1.8809e-01,\n        -8.3976e-02,  6.9564e-02, -3.1987e-01,  1.2843e-01, -2.3163e-02,\n         3.1046e-01, -1.7992e-01, -2.7775e-01,  2.1499e-01, -1.7620e-01,\n        -1.3464e-01,  2.9908e-02,  2.8292e-01, -4.4094e-02],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.6338e-01, -2.5477e-01, -1.0195e-01,  2.1448e-01,  8.0360e-02,\n         -1.9363e-01,  3.0949e-01,  1.4321e-01],\n        [-2.1611e-01, -1.4350e-02,  3.2673e-01,  3.2015e-01,  1.2254e-02,\n          2.1923e-01,  7.7929e-02,  2.2081e-01],\n        [-1.5732e-01, -1.4647e-01, -3.2528e-01, -1.9237e-01, -2.0621e-01,\n         -3.2793e-03, -2.0202e-01, -1.3429e-01],\n        [-2.3803e-01,  2.6990e-01,  1.0056e-01,  1.4273e-01, -3.4659e-01,\n          1.8246e-01,  1.2447e-01,  3.3022e-01],\n        [ 3.3797e-02, -2.1080e-02, -1.6234e-01,  1.7153e-02,  2.8772e-01,\n          7.8705e-02, -1.8310e-01,  1.3444e-01],\n        [-2.2815e-01,  1.1480e-01,  4.2314e-02, -1.5926e-01,  3.1699e-01,\n          2.1934e-01, -9.5153e-02,  3.4707e-01],\n        [ 3.3835e-01,  1.4112e-01, -8.3809e-02,  1.7921e-01, -1.7694e-01,\n         -2.9662e-02, -2.4561e-01,  2.9128e-01],\n        [ 2.6119e-01, -5.4627e-04, -2.1473e-01,  6.9508e-02,  1.4129e-01,\n         -1.7142e-01,  1.3847e-01, -1.0917e-01],\n        [-2.5204e-01, -3.4796e-01, -2.4394e-01,  5.4165e-02, -2.2867e-02,\n          1.9777e-01,  9.8927e-02,  2.2380e-01],\n        [-9.9008e-02,  2.8402e-01, -9.2227e-02,  4.7630e-02,  2.6886e-02,\n         -1.5870e-02, -5.9214e-03,  1.2185e-01],\n        [-1.3469e-01, -2.3043e-01,  9.3251e-02, -1.3525e-01,  3.1884e-01,\n          8.4315e-03,  2.0071e-01, -2.5273e-01],\n        [-1.7664e-01,  3.5068e-01,  2.1852e-01, -5.0458e-02,  1.1868e-01,\n         -1.6537e-01, -3.2960e-01, -1.0473e-01],\n        [-1.4736e-01,  2.0787e-02,  7.3604e-02, -2.4879e-01,  1.0741e-01,\n          3.5069e-01, -1.8089e-02, -9.3378e-02],\n        [ 1.2218e-01,  3.0824e-01, -1.6623e-01,  2.3361e-01,  8.5625e-02,\n         -6.5159e-03, -3.0340e-01,  1.2278e-01],\n        [ 1.2926e-01,  3.3735e-01,  3.4407e-01, -2.7552e-01,  3.3462e-01,\n         -3.4097e-01, -1.4978e-01,  2.7389e-01],\n        [-1.2551e-01, -2.5905e-01, -2.7068e-01,  3.7864e-02, -3.8943e-02,\n          2.6106e-01,  1.5372e-02, -2.0174e-02],\n        [-1.9492e-02, -2.9172e-01,  3.7149e-02, -1.8764e-02, -8.2248e-02,\n          4.9597e-02, -1.5555e-01,  3.0205e-01],\n        [ 1.1867e-01, -2.7667e-01, -3.3725e-01,  2.9453e-03,  3.2935e-01,\n         -2.3125e-01,  1.2025e-01,  1.0896e-01],\n        [ 1.5416e-01, -3.3332e-01, -2.4076e-01,  2.2151e-01,  3.9851e-02,\n         -2.4614e-01,  2.6446e-01, -1.6976e-02],\n        [ 3.2969e-02,  3.2554e-01,  3.0052e-02,  1.9162e-02, -3.0390e-01,\n          1.7637e-01,  4.7434e-02, -2.3043e-01],\n        [ 6.4156e-02, -2.8786e-01,  3.3802e-01,  2.9429e-01, -6.6659e-02,\n          1.5231e-01, -2.9716e-01,  1.1588e-01],\n        [ 2.8370e-01,  2.6209e-01, -1.2617e-01,  3.3536e-02, -6.0507e-02,\n          1.9679e-01,  3.1433e-01,  2.4487e-01],\n        [ 1.9885e-01,  1.8097e-01, -4.9303e-04,  2.6389e-01, -1.1736e-01,\n          1.8779e-01, -1.1046e-01, -6.4663e-02],\n        [ 2.7358e-01, -1.4845e-01, -1.6642e-01, -3.0481e-01,  5.9202e-03,\n         -2.9158e-01, -2.0689e-01, -2.3000e-01],\n        [-1.5363e-01,  2.2306e-01, -2.8381e-01, -1.6765e-01, -4.7401e-02,\n         -4.0631e-02, -3.2535e-01,  6.1592e-02],\n        [-3.3951e-01, -4.9011e-02,  2.0157e-01,  3.0331e-01, -1.7008e-01,\n         -1.2238e-01,  1.7983e-01, -3.2962e-01],\n        [-6.3934e-02, -1.3267e-01, -1.9569e-01, -1.9193e-01,  6.8038e-02,\n         -2.1926e-01, -3.5347e-01,  1.9508e-01],\n        [-2.0100e-01, -2.7881e-01,  1.3066e-01,  7.5162e-03, -2.2013e-01,\n         -3.4617e-01,  2.5302e-01,  1.2170e-01],\n        [ 2.3656e-01, -5.3688e-02, -2.1687e-01, -1.0802e-01,  3.2814e-01,\n          3.5077e-01,  2.3423e-01,  2.2895e-01],\n        [-3.1470e-01, -1.5655e-01,  2.1398e-01,  3.4800e-01,  1.3379e-02,\n          3.3017e-01, -3.6253e-02,  6.1391e-02],\n        [ 1.0247e-01, -4.0490e-02, -4.2780e-02, -2.7900e-01, -3.1059e-01,\n          2.4515e-01, -3.4616e-01, -5.7991e-02],\n        [-1.2515e-02,  2.3761e-01, -1.3548e-01,  7.3332e-02, -2.5225e-01,\n         -4.6145e-02,  1.3103e-01, -1.8046e-01],\n        [ 1.9068e-01, -3.0858e-01,  1.1957e-01, -4.0129e-02,  2.7947e-01,\n          1.8082e-01,  3.2039e-01, -1.1138e-01],\n        [ 3.2325e-01, -1.8756e-01, -3.0419e-01,  5.7200e-02,  3.2263e-01,\n         -2.4605e-01,  7.1436e-02, -1.1792e-01],\n        [-2.6632e-01, -1.9710e-01, -2.3564e-01,  2.9370e-01,  2.9851e-01,\n         -2.4172e-01,  3.0048e-02, -1.6052e-01],\n        [-3.4838e-02, -3.2352e-01, -1.2978e-01,  3.1247e-01,  2.6040e-01,\n          6.7245e-02,  1.5596e-01, -1.2250e-01],\n        [ 1.6264e-01,  1.1450e-01, -2.9402e-01,  6.4999e-02, -2.3230e-01,\n          2.8423e-01, -2.8135e-01,  1.1491e-01],\n        [ 4.4831e-02,  2.1691e-01,  3.0790e-01,  2.4156e-01,  1.3100e-01,\n          2.7060e-01, -2.2120e-02, -6.0345e-03],\n        [-2.6740e-01, -1.1468e-01,  5.6172e-02,  3.1028e-01, -2.8147e-01,\n         -3.5117e-01, -8.8069e-02, -1.7238e-01],\n        [ 2.8783e-01, -2.5419e-01,  3.3955e-01, -2.3902e-01,  1.4703e-01,\n         -2.3923e-02,  7.9277e-02, -2.8657e-01],\n        [-5.1220e-02, -9.8498e-02,  1.9472e-01, -2.8564e-01,  7.6881e-02,\n          2.5233e-01,  3.4728e-01,  1.7063e-01],\n        [ 3.4626e-01, -1.3989e-01,  1.8258e-02,  6.3863e-02,  3.4216e-01,\n         -2.8055e-01, -9.4788e-02, -1.5587e-01],\n        [-1.0381e-01,  2.9180e-01,  8.9747e-02,  2.2337e-01,  1.7310e-02,\n          4.7804e-02, -2.7772e-01,  3.5138e-01],\n        [ 2.0362e-01, -8.9239e-02, -2.6162e-01,  2.0706e-01,  2.5605e-01,\n         -2.9908e-01,  1.6149e-01,  3.1041e-01],\n        [ 2.1842e-01,  1.6925e-01,  1.3186e-01,  5.2209e-02,  2.3301e-01,\n          1.9479e-01,  6.2364e-02, -1.8548e-01],\n        [-8.2956e-02, -1.7393e-01, -2.3178e-01,  2.8093e-01, -3.3063e-01,\n         -7.2506e-03, -4.7325e-02,  6.8069e-02],\n        [-1.1688e-01, -1.7941e-01, -1.1328e-01, -6.7121e-02, -1.2396e-01,\n          1.2982e-01,  2.4391e-02,  1.6656e-01],\n        [-1.1698e-01, -1.8924e-01,  1.8752e-01, -2.9895e-01, -2.4129e-01,\n          3.2166e-01, -2.5047e-01,  3.5854e-02],\n        [ 3.1545e-01, -2.0109e-01, -6.3655e-02,  9.4536e-03,  2.4984e-02,\n          2.2371e-01,  2.7653e-01, -8.2915e-02],\n        [ 1.5063e-01,  9.8180e-02,  2.4724e-01,  2.1116e-04, -1.6475e-01,\n          2.2569e-01, -1.5704e-01, -3.1165e-01],\n        [ 1.8730e-01,  3.1660e-01, -3.2182e-01,  7.1873e-03,  2.7173e-01,\n          2.4332e-02, -2.4761e-01, -6.9793e-02],\n        [-9.8125e-02,  2.3256e-01, -3.3997e-01,  2.4382e-01, -1.2562e-01,\n         -2.4890e-01,  6.6221e-02,  1.7551e-01],\n        [-2.8921e-01,  1.1080e-01, -2.7819e-01,  6.3259e-02, -2.4889e-01,\n          8.8328e-02,  7.9351e-02, -1.4745e-01],\n        [-2.8643e-01,  1.8629e-01, -3.3549e-02, -1.0263e-01, -2.4533e-01,\n          2.7033e-01, -4.7308e-02, -2.2887e-01],\n        [-2.3665e-01,  2.6882e-01,  2.4857e-01, -9.1079e-02, -2.5134e-01,\n          1.9461e-01,  2.2289e-01, -2.6607e-01],\n        [ 1.6310e-01,  9.0285e-02, -1.9600e-01,  7.5464e-02,  2.2425e-02,\n          2.1314e-01,  2.0873e-01, -1.4806e-01],\n        [-3.3027e-01,  6.0239e-02,  3.4077e-01,  5.2826e-02, -2.9462e-01,\n         -3.3613e-01, -1.8851e-01,  1.1862e-01],\n        [-2.4098e-01,  3.1717e-01, -2.3302e-01, -2.4067e-01, -8.0679e-02,\n         -7.5850e-02, -1.2632e-01,  1.6679e-02],\n        [ 1.8263e-01,  2.6701e-01, -2.9065e-01,  2.2932e-01,  3.3216e-03,\n         -1.4952e-01, -5.2640e-02, -5.7685e-02],\n        [ 1.4082e-01,  8.9513e-02,  1.6899e-01,  2.8928e-01,  2.7911e-01,\n          3.4215e-01,  1.8752e-01,  5.7003e-02],\n        [-2.4711e-01,  2.9251e-01,  1.6806e-01,  6.4060e-02,  1.4340e-01,\n         -2.3572e-01, -3.0761e-01,  1.8973e-01],\n        [ 2.2935e-01,  2.4429e-01, -3.2079e-03, -1.0523e-01,  1.9784e-01,\n          9.0421e-03,  4.6979e-02, -3.1945e-01],\n        [-1.5995e-01,  5.6591e-02,  2.3148e-01,  3.0972e-01,  1.2637e-01,\n         -1.4810e-01,  1.3401e-01, -3.2169e-01],\n        [-1.5658e-01, -4.2762e-02, -5.1437e-03, -1.6129e-01, -4.5308e-02,\n         -8.2236e-02, -9.8041e-02,  3.5184e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "10":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2524], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3044,  0.2803,  0.2767, -0.2503, -0.0409, -0.2742,  0.1325, -0.2777]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=64, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0085, -0.0384,  0.0201,  0.0381,  0.0165, -0.0345,  0.0449,  0.0208,\n         0.1027,  0.0660, -0.1112,  0.0475,  0.0431, -0.0317, -0.0141,  0.1037,\n         0.0270,  0.0809,  0.0599,  0.0768, -0.0619, -0.1103, -0.0556,  0.0219,\n         0.0921, -0.0067,  0.0453,  0.0171, -0.0273, -0.0772, -0.1247, -0.0357,\n        -0.0462, -0.0702, -0.0031, -0.0940, -0.0241,  0.0539, -0.1059, -0.0848,\n        -0.0068, -0.0269, -0.0116, -0.0542, -0.0498,  0.0556,  0.0702, -0.1238,\n         0.0635, -0.1173, -0.0718, -0.1106, -0.1205,  0.1030, -0.1192, -0.0822,\n        -0.1102,  0.0304,  0.0876,  0.0346, -0.0805,  0.0491, -0.1222,  0.0099],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1246, -0.0274, -0.0061,  ..., -0.1174,  0.0708, -0.0612],\n        [ 0.1245, -0.0741, -0.0490,  ..., -0.1196,  0.0968, -0.0217],\n        [-0.0908,  0.1025, -0.1167,  ..., -0.0616,  0.0764, -0.0126],\n        ...,\n        [ 0.0968,  0.0406, -0.1179,  ...,  0.0457, -0.0946, -0.0958],\n        [-0.0569, -0.0396, -0.0310,  ..., -0.0158, -0.0572,  0.0474],\n        [ 0.0361,  0.1246, -0.1164,  ...,  0.0639,  0.0530,  0.1169]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=64, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1123, -0.0793,  0.1046, -0.0029,  0.0359,  0.0958, -0.0687, -0.0179,\n         0.1006,  0.0504, -0.1073,  0.0624,  0.0267,  0.0175,  0.1160,  0.0725,\n        -0.1090, -0.0814, -0.0109,  0.0312, -0.0412, -0.0355, -0.0010,  0.0210,\n        -0.0065,  0.0103, -0.1032,  0.0258,  0.0953, -0.0645, -0.0884, -0.0382],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0145,  0.0780,  0.1229,  ...,  0.0101, -0.0850,  0.0292],\n        [-0.0587,  0.0204,  0.0411,  ..., -0.0539, -0.1085, -0.1166],\n        [-0.0244,  0.0427,  0.0454,  ..., -0.0313, -0.0263,  0.0491],\n        ...,\n        [-0.0958, -0.0849,  0.0375,  ...,  0.0245,  0.0521,  0.0050],\n        [ 0.0523, -0.0045, -0.1054,  ..., -0.1065, -0.0512, -0.1248],\n        [-0.0683,  0.0439,  0.0416,  ..., -0.0206,  0.0807, -0.0251]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1302,  0.1492,  0.1760,  0.1331, -0.0282, -0.0303,  0.0013, -0.1472,\n         0.1631,  0.0751,  0.0644, -0.1632,  0.1621,  0.1421,  0.1723,  0.0263],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.5956e-02,  1.1147e-01, -8.4412e-02, -4.5755e-03, -1.6173e-01,\n         -1.6873e-02,  7.2736e-02, -1.4553e-01,  1.2028e-01, -8.7122e-02,\n         -1.6081e-01, -1.2397e-01, -3.2149e-02,  1.1772e-01,  4.3381e-02,\n          2.8891e-02,  9.1582e-02,  6.2870e-02, -9.6223e-02, -9.2371e-02,\n         -1.3442e-01,  1.0987e-01, -4.8419e-02, -9.5404e-02, -8.8407e-02,\n          1.2480e-01, -1.3390e-02,  6.8911e-02, -9.1312e-02,  1.3571e-01,\n          3.2108e-02, -1.5276e-01],\n        [ 1.7418e-01,  1.4230e-01, -1.0969e-01, -1.7374e-01, -1.1665e-01,\n          1.3477e-01, -1.2185e-01, -1.2665e-01,  2.5025e-03, -4.1708e-02,\n         -1.1838e-01, -1.2901e-02,  6.7079e-02,  1.4848e-01, -1.2085e-01,\n         -1.0309e-01, -1.9839e-02, -6.9307e-02,  1.0602e-01,  1.5233e-01,\n          1.1525e-01, -1.0543e-01,  1.0476e-01,  2.4209e-03, -5.1728e-02,\n         -4.5878e-02, -7.7432e-02, -9.4387e-02, -7.8305e-02,  1.3836e-01,\n          7.0265e-02,  3.2300e-02],\n        [-1.7537e-01,  1.5021e-01,  1.2979e-01,  7.5470e-02,  1.6243e-01,\n          6.3153e-02,  1.6008e-01,  1.4521e-02,  1.1173e-01,  1.2884e-01,\n         -1.7562e-01,  3.2483e-02,  1.5481e-02,  1.0120e-02,  1.0546e-01,\n          1.1116e-01, -1.6451e-01,  1.7491e-01, -1.1512e-01, -8.7101e-02,\n         -5.4674e-02,  4.1941e-02, -1.1837e-01, -1.4970e-01, -1.9892e-02,\n          5.8556e-02, -6.2661e-02, -1.1813e-02,  6.5693e-03, -2.2355e-02,\n         -1.2033e-01, -1.6181e-01],\n        [ 6.9581e-03, -3.1123e-03,  1.4621e-01, -4.8100e-02,  1.1659e-01,\n         -2.2150e-02, -1.5058e-01,  6.7795e-02, -1.3778e-01, -7.6234e-02,\n         -7.1460e-05,  1.5981e-01,  6.0934e-02,  1.0122e-02, -2.4576e-02,\n          6.2980e-02, -1.3789e-01, -1.4991e-01, -1.4327e-01,  1.6057e-01,\n         -1.6066e-01, -1.6234e-02,  1.3410e-01,  4.0393e-02, -1.2145e-01,\n         -1.4417e-01, -1.1329e-01,  1.1066e-01, -7.9744e-02, -1.4233e-01,\n          3.2638e-02, -7.4631e-02],\n        [ 1.1534e-02, -1.0635e-01,  1.9795e-02,  1.5643e-01,  5.6342e-02,\n         -1.1900e-01,  1.4754e-02,  5.6475e-02, -1.1356e-01,  8.9467e-02,\n          5.4965e-02,  8.2326e-02, -4.6573e-03, -6.9005e-02, -7.6876e-02,\n          3.6406e-02,  5.6902e-02,  7.8599e-02, -6.3010e-02,  1.1592e-02,\n          5.3338e-02, -2.9593e-02,  3.2678e-02, -2.2963e-02, -1.4985e-01,\n         -2.8280e-02,  3.8330e-02,  1.1846e-01,  2.2985e-02,  1.0648e-01,\n         -9.0336e-02, -1.0052e-01],\n        [-1.6046e-01,  1.4907e-01,  3.8502e-03, -1.2104e-01,  1.4068e-01,\n          1.3095e-01,  1.6042e-01, -1.1355e-01, -5.3799e-03,  4.6895e-02,\n          1.7484e-01,  8.9499e-02,  1.4103e-01,  1.1697e-01, -1.2974e-01,\n         -7.7905e-02,  1.4247e-02,  1.1017e-01,  4.2758e-02, -1.7264e-01,\n          1.4433e-01,  3.0197e-02,  1.6613e-01, -1.6573e-01,  3.9758e-02,\n          8.4897e-02, -9.4701e-02, -1.0088e-01,  1.1323e-01,  1.5616e-01,\n          7.1225e-02, -1.1138e-01],\n        [ 6.3311e-02,  1.6427e-01, -1.7321e-01,  1.6868e-01,  1.0217e-01,\n         -1.2567e-01,  8.2979e-02,  4.2991e-02, -1.2450e-01,  3.4794e-02,\n         -1.2035e-01, -7.8844e-02, -7.1058e-02,  9.9657e-03, -8.4068e-02,\n          4.6301e-02, -4.0864e-02,  8.8124e-02,  2.8821e-02,  1.7738e-02,\n          9.7740e-02, -1.5279e-01,  1.0778e-01, -1.7631e-01,  1.4697e-01,\n         -1.5094e-01, -4.6223e-02,  1.2399e-01,  9.9060e-02,  2.8364e-02,\n          5.4216e-03, -5.2968e-03],\n        [-8.0236e-02, -1.1531e-01, -1.7295e-01,  9.4021e-02,  4.5310e-02,\n          1.4631e-01, -1.7284e-01, -6.8090e-02,  1.7055e-01, -5.0783e-02,\n          3.9754e-03,  1.1667e-01, -9.1705e-02, -5.0367e-02, -9.5074e-02,\n         -3.2424e-02, -8.7329e-02, -1.3106e-01, -2.0385e-02,  5.0350e-02,\n          1.0108e-01, -1.6535e-01,  2.0946e-02,  6.5808e-02,  8.8632e-02,\n         -2.5599e-02,  3.4125e-02,  1.4957e-01,  1.0207e-01,  5.0267e-02,\n          1.5482e-01, -1.2763e-01],\n        [-1.4806e-01, -1.4575e-01,  3.8041e-02, -8.5971e-03,  7.3658e-02,\n         -7.5005e-02, -1.4730e-01, -1.2068e-01,  4.2221e-02, -2.1215e-02,\n          9.7055e-02, -5.1646e-02,  2.9932e-03,  1.4412e-01, -6.4829e-03,\n         -2.7836e-02, -5.6123e-02, -6.6212e-02,  2.5540e-03,  1.0181e-01,\n         -6.8779e-02,  1.3700e-01, -1.4986e-01, -1.6596e-03,  2.9790e-02,\n         -1.1741e-03, -2.1415e-02, -1.6993e-01,  1.7477e-01,  2.3730e-02,\n         -1.2379e-01,  1.0216e-01],\n        [ 1.1199e-01, -1.3307e-01, -6.6006e-02, -3.5592e-02, -1.3791e-01,\n         -1.4757e-01, -1.4895e-01,  1.6672e-01, -7.6621e-03, -1.6226e-01,\n          5.7063e-02, -1.7451e-02,  5.3001e-02,  4.5565e-02, -5.0825e-02,\n          5.8940e-02,  6.0491e-02, -9.9885e-02, -1.7179e-01,  2.4604e-03,\n          8.1275e-02,  1.4892e-01, -1.6051e-01, -1.0144e-02, -1.5554e-01,\n         -1.5161e-01, -7.0320e-02,  6.9498e-02,  1.1990e-01, -1.8456e-02,\n          3.5974e-02, -9.3641e-03],\n        [-4.4013e-02,  1.4422e-01, -1.0235e-02,  1.0687e-01, -1.1575e-01,\n          7.9519e-02,  1.9506e-02,  1.5067e-01, -1.5451e-01,  5.7950e-02,\n         -1.4399e-01,  1.8017e-02,  1.1966e-01,  3.9283e-02,  1.3477e-01,\n          7.5038e-02,  9.7867e-02,  5.7574e-02, -1.6558e-01,  1.5264e-01,\n          7.1676e-02, -5.5660e-02,  1.0594e-04,  6.7285e-02, -1.3790e-01,\n          6.4960e-02, -8.9568e-02, -7.7004e-02,  8.7584e-02,  1.0247e-01,\n          1.7369e-01,  1.1615e-01],\n        [ 1.3498e-01,  2.0453e-02,  8.9103e-02,  4.0730e-02,  1.2632e-02,\n         -8.5183e-02, -5.9953e-03,  1.7219e-01, -4.9996e-02, -1.7524e-01,\n         -8.1430e-02,  8.0099e-02,  1.0660e-02, -5.8366e-02,  1.2463e-01,\n          5.3301e-03, -1.5143e-01,  2.5409e-02, -1.7476e-01, -4.8904e-02,\n          1.6290e-01,  8.5202e-02,  2.4690e-02, -1.2291e-01, -9.7226e-04,\n          8.7581e-02,  6.0869e-02,  1.7579e-01,  1.3785e-01,  1.4643e-01,\n          1.4041e-01, -3.6677e-02],\n        [-1.2867e-01,  7.6378e-02, -6.6325e-02,  7.9773e-02, -1.9418e-02,\n         -1.1838e-01, -1.1633e-02, -3.9845e-02,  6.5052e-02, -9.5717e-02,\n         -1.7016e-01,  4.8164e-02,  3.8558e-02, -1.6494e-01, -1.4557e-01,\n          3.7579e-02,  1.1812e-01, -2.8167e-02,  7.6819e-02,  4.1322e-02,\n         -9.9810e-02, -1.4616e-01,  1.4642e-01,  3.5210e-02,  1.1368e-01,\n          1.2594e-01, -2.5032e-02, -3.8450e-02,  3.5624e-02, -6.1444e-02,\n         -1.0396e-01, -9.4254e-02],\n        [-1.5122e-01,  1.3778e-01, -4.6990e-02,  1.3801e-01, -4.7815e-02,\n         -6.4804e-02,  5.7900e-02,  6.0444e-02, -8.5919e-02, -7.0767e-02,\n          1.3067e-01,  2.1626e-02, -1.5641e-01,  3.9014e-02, -8.3942e-02,\n          1.4700e-02,  3.8611e-02,  3.6934e-02, -1.1405e-01, -4.8827e-02,\n         -1.7271e-01,  4.1816e-02, -1.6163e-01,  1.2857e-01,  1.2503e-01,\n         -3.6856e-02, -7.7315e-02,  1.5566e-01, -1.5763e-01, -5.2735e-02,\n          6.7441e-02,  9.2095e-02],\n        [-4.9394e-02, -1.0078e-01, -1.2849e-01,  1.8697e-02, -1.1266e-01,\n         -4.4491e-02, -1.0750e-01, -1.1483e-01,  1.2395e-01, -1.1542e-01,\n          2.9979e-02, -1.0653e-01,  7.3824e-02, -8.9337e-02,  6.5132e-02,\n         -1.3295e-01,  3.8492e-02,  7.0065e-02,  3.6066e-03, -1.5038e-02,\n          1.7475e-01,  1.4888e-01,  6.0757e-02,  1.5943e-01,  2.7939e-02,\n         -3.1983e-02,  8.2537e-02,  1.7524e-02,  1.6334e-01,  1.2914e-01,\n         -4.5501e-02, -9.0899e-02],\n        [ 1.4448e-01,  1.0687e-01,  9.5797e-02, -8.9906e-02, -1.4605e-01,\n          4.5961e-02, -9.8611e-02,  1.0045e-01, -8.6376e-02, -8.0927e-02,\n          1.3325e-01, -1.4054e-01,  9.0148e-03,  1.6846e-01, -1.5439e-01,\n          3.9751e-02, -1.4537e-01, -4.2542e-02, -1.3281e-01, -1.3916e-01,\n          1.1704e-01, -1.2551e-01,  3.5272e-02,  1.7256e-01,  5.0884e-02,\n         -3.0260e-03,  1.6978e-02,  9.3314e-02,  4.5768e-02, -7.6394e-02,\n         -1.4497e-01,  1.1031e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "7":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "8":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1312, -0.2368,  0.0488,  0.0126, -0.0114, -0.1338, -0.0756, -0.1421],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0910,  0.2414, -0.2449, -0.0663,  0.0585, -0.2142,  0.1366, -0.0034,\n          0.1240, -0.0976,  0.1038,  0.2102, -0.0502, -0.1310,  0.0856, -0.2065],\n        [-0.0769, -0.0755,  0.1853,  0.1811, -0.2384,  0.0663, -0.1258,  0.1299,\n          0.1205,  0.0823, -0.1115,  0.0091, -0.0776, -0.2451,  0.2234,  0.0749],\n        [ 0.0477, -0.2066, -0.0062, -0.2499,  0.1267, -0.2225, -0.1047, -0.1924,\n          0.2229,  0.1383, -0.2365, -0.1492, -0.2155, -0.0240,  0.1022,  0.1564],\n        [ 0.1042, -0.1535,  0.1884,  0.0926, -0.1874, -0.2394,  0.2163,  0.0160,\n          0.0686, -0.0149,  0.0067,  0.0309,  0.2147, -0.1105, -0.1451,  0.0692],\n        [ 0.2216, -0.2037, -0.0544, -0.0168, -0.0549, -0.1242, -0.1021,  0.2168,\n         -0.2480,  0.1162, -0.1687,  0.0134, -0.0875,  0.1124,  0.0856,  0.2140],\n        [-0.1081,  0.0829,  0.1794,  0.0450, -0.0399, -0.1637, -0.0269,  0.1536,\n          0.1393,  0.1037, -0.0821,  0.1238, -0.0480,  0.2402,  0.1760,  0.1438],\n        [-0.2257,  0.1886, -0.1512,  0.0197, -0.1545, -0.0212, -0.1629, -0.2318,\n         -0.0600,  0.0955,  0.1661,  0.0024,  0.0555, -0.2018, -0.0545,  0.1404],\n        [ 0.1581,  0.0257,  0.1356,  0.1352,  0.1663,  0.1260,  0.0408, -0.1951,\n          0.1792,  0.0691, -0.0453, -0.0628, -0.0467, -0.2010,  0.2330, -0.1699]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "9":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-1.6338e-01, -2.5477e-01, -1.0195e-01,  2.1448e-01,  8.0360e-02,\n         -1.9363e-01,  3.0949e-01,  1.4321e-01],\n        [-2.1611e-01, -1.4350e-02,  3.2673e-01,  3.2015e-01,  1.2254e-02,\n          2.1923e-01,  7.7929e-02,  2.2081e-01],\n        [-1.5732e-01, -1.4647e-01, -3.2528e-01, -1.9237e-01, -2.0621e-01,\n         -3.2793e-03, -2.0202e-01, -1.3429e-01],\n        [-2.3803e-01,  2.6990e-01,  1.0056e-01,  1.4273e-01, -3.4659e-01,\n          1.8246e-01,  1.2447e-01,  3.3022e-01],\n        [ 3.3797e-02, -2.1080e-02, -1.6234e-01,  1.7153e-02,  2.8772e-01,\n          7.8705e-02, -1.8310e-01,  1.3444e-01],\n        [-2.2815e-01,  1.1480e-01,  4.2314e-02, -1.5926e-01,  3.1699e-01,\n          2.1934e-01, -9.5153e-02,  3.4707e-01],\n        [ 3.3835e-01,  1.4112e-01, -8.3809e-02,  1.7921e-01, -1.7694e-01,\n         -2.9662e-02, -2.4561e-01,  2.9128e-01],\n        [ 2.6119e-01, -5.4627e-04, -2.1473e-01,  6.9508e-02,  1.4129e-01,\n         -1.7142e-01,  1.3847e-01, -1.0917e-01],\n        [-2.5204e-01, -3.4796e-01, -2.4394e-01,  5.4165e-02, -2.2867e-02,\n          1.9777e-01,  9.8927e-02,  2.2380e-01],\n        [-9.9008e-02,  2.8402e-01, -9.2227e-02,  4.7630e-02,  2.6886e-02,\n         -1.5870e-02, -5.9214e-03,  1.2185e-01],\n        [-1.3469e-01, -2.3043e-01,  9.3251e-02, -1.3525e-01,  3.1884e-01,\n          8.4315e-03,  2.0071e-01, -2.5273e-01],\n        [-1.7664e-01,  3.5068e-01,  2.1852e-01, -5.0458e-02,  1.1868e-01,\n         -1.6537e-01, -3.2960e-01, -1.0473e-01],\n        [-1.4736e-01,  2.0787e-02,  7.3604e-02, -2.4879e-01,  1.0741e-01,\n          3.5069e-01, -1.8089e-02, -9.3378e-02],\n        [ 1.2218e-01,  3.0824e-01, -1.6623e-01,  2.3361e-01,  8.5625e-02,\n         -6.5159e-03, -3.0340e-01,  1.2278e-01],\n        [ 1.2926e-01,  3.3735e-01,  3.4407e-01, -2.7552e-01,  3.3462e-01,\n         -3.4097e-01, -1.4978e-01,  2.7389e-01],\n        [-1.2551e-01, -2.5905e-01, -2.7068e-01,  3.7864e-02, -3.8943e-02,\n          2.6106e-01,  1.5372e-02, -2.0174e-02],\n        [-1.9492e-02, -2.9172e-01,  3.7149e-02, -1.8764e-02, -8.2248e-02,\n          4.9597e-02, -1.5555e-01,  3.0205e-01],\n        [ 1.1867e-01, -2.7667e-01, -3.3725e-01,  2.9453e-03,  3.2935e-01,\n         -2.3125e-01,  1.2025e-01,  1.0896e-01],\n        [ 1.5416e-01, -3.3332e-01, -2.4076e-01,  2.2151e-01,  3.9851e-02,\n         -2.4614e-01,  2.6446e-01, -1.6976e-02],\n        [ 3.2969e-02,  3.2554e-01,  3.0052e-02,  1.9162e-02, -3.0390e-01,\n          1.7637e-01,  4.7434e-02, -2.3043e-01],\n        [ 6.4156e-02, -2.8786e-01,  3.3802e-01,  2.9429e-01, -6.6659e-02,\n          1.5231e-01, -2.9716e-01,  1.1588e-01],\n        [ 2.8370e-01,  2.6209e-01, -1.2617e-01,  3.3536e-02, -6.0507e-02,\n          1.9679e-01,  3.1433e-01,  2.4487e-01],\n        [ 1.9885e-01,  1.8097e-01, -4.9303e-04,  2.6389e-01, -1.1736e-01,\n          1.8779e-01, -1.1046e-01, -6.4663e-02],\n        [ 2.7358e-01, -1.4845e-01, -1.6642e-01, -3.0481e-01,  5.9202e-03,\n         -2.9158e-01, -2.0689e-01, -2.3000e-01],\n        [-1.5363e-01,  2.2306e-01, -2.8381e-01, -1.6765e-01, -4.7401e-02,\n         -4.0631e-02, -3.2535e-01,  6.1592e-02],\n        [-3.3951e-01, -4.9011e-02,  2.0157e-01,  3.0331e-01, -1.7008e-01,\n         -1.2238e-01,  1.7983e-01, -3.2962e-01],\n        [-6.3934e-02, -1.3267e-01, -1.9569e-01, -1.9193e-01,  6.8038e-02,\n         -2.1926e-01, -3.5347e-01,  1.9508e-01],\n        [-2.0100e-01, -2.7881e-01,  1.3066e-01,  7.5162e-03, -2.2013e-01,\n         -3.4617e-01,  2.5302e-01,  1.2170e-01],\n        [ 2.3656e-01, -5.3688e-02, -2.1687e-01, -1.0802e-01,  3.2814e-01,\n          3.5077e-01,  2.3423e-01,  2.2895e-01],\n        [-3.1470e-01, -1.5655e-01,  2.1398e-01,  3.4800e-01,  1.3379e-02,\n          3.3017e-01, -3.6253e-02,  6.1391e-02],\n        [ 1.0247e-01, -4.0490e-02, -4.2780e-02, -2.7900e-01, -3.1059e-01,\n          2.4515e-01, -3.4616e-01, -5.7991e-02],\n        [-1.2515e-02,  2.3761e-01, -1.3548e-01,  7.3332e-02, -2.5225e-01,\n         -4.6145e-02,  1.3103e-01, -1.8046e-01],\n        [ 1.9068e-01, -3.0858e-01,  1.1957e-01, -4.0129e-02,  2.7947e-01,\n          1.8082e-01,  3.2039e-01, -1.1138e-01],\n        [ 3.2325e-01, -1.8756e-01, -3.0419e-01,  5.7200e-02,  3.2263e-01,\n         -2.4605e-01,  7.1436e-02, -1.1792e-01],\n        [-2.6632e-01, -1.9710e-01, -2.3564e-01,  2.9370e-01,  2.9851e-01,\n         -2.4172e-01,  3.0048e-02, -1.6052e-01],\n        [-3.4838e-02, -3.2352e-01, -1.2978e-01,  3.1247e-01,  2.6040e-01,\n          6.7245e-02,  1.5596e-01, -1.2250e-01],\n        [ 1.6264e-01,  1.1450e-01, -2.9402e-01,  6.4999e-02, -2.3230e-01,\n          2.8423e-01, -2.8135e-01,  1.1491e-01],\n        [ 4.4831e-02,  2.1691e-01,  3.0790e-01,  2.4156e-01,  1.3100e-01,\n          2.7060e-01, -2.2120e-02, -6.0345e-03],\n        [-2.6740e-01, -1.1468e-01,  5.6172e-02,  3.1028e-01, -2.8147e-01,\n         -3.5117e-01, -8.8069e-02, -1.7238e-01],\n        [ 2.8783e-01, -2.5419e-01,  3.3955e-01, -2.3902e-01,  1.4703e-01,\n         -2.3923e-02,  7.9277e-02, -2.8657e-01],\n        [-5.1220e-02, -9.8498e-02,  1.9472e-01, -2.8564e-01,  7.6881e-02,\n          2.5233e-01,  3.4728e-01,  1.7063e-01],\n        [ 3.4626e-01, -1.3989e-01,  1.8258e-02,  6.3863e-02,  3.4216e-01,\n         -2.8055e-01, -9.4788e-02, -1.5587e-01],\n        [-1.0381e-01,  2.9180e-01,  8.9747e-02,  2.2337e-01,  1.7310e-02,\n          4.7804e-02, -2.7772e-01,  3.5138e-01],\n        [ 2.0362e-01, -8.9239e-02, -2.6162e-01,  2.0706e-01,  2.5605e-01,\n         -2.9908e-01,  1.6149e-01,  3.1041e-01],\n        [ 2.1842e-01,  1.6925e-01,  1.3186e-01,  5.2209e-02,  2.3301e-01,\n          1.9479e-01,  6.2364e-02, -1.8548e-01],\n        [-8.2956e-02, -1.7393e-01, -2.3178e-01,  2.8093e-01, -3.3063e-01,\n         -7.2506e-03, -4.7325e-02,  6.8069e-02],\n        [-1.1688e-01, -1.7941e-01, -1.1328e-01, -6.7121e-02, -1.2396e-01,\n          1.2982e-01,  2.4391e-02,  1.6656e-01],\n        [-1.1698e-01, -1.8924e-01,  1.8752e-01, -2.9895e-01, -2.4129e-01,\n          3.2166e-01, -2.5047e-01,  3.5854e-02],\n        [ 3.1545e-01, -2.0109e-01, -6.3655e-02,  9.4536e-03,  2.4984e-02,\n          2.2371e-01,  2.7653e-01, -8.2915e-02],\n        [ 1.5063e-01,  9.8180e-02,  2.4724e-01,  2.1116e-04, -1.6475e-01,\n          2.2569e-01, -1.5704e-01, -3.1165e-01],\n        [ 1.8730e-01,  3.1660e-01, -3.2182e-01,  7.1873e-03,  2.7173e-01,\n          2.4332e-02, -2.4761e-01, -6.9793e-02],\n        [-9.8125e-02,  2.3256e-01, -3.3997e-01,  2.4382e-01, -1.2562e-01,\n         -2.4890e-01,  6.6221e-02,  1.7551e-01],\n        [-2.8921e-01,  1.1080e-01, -2.7819e-01,  6.3259e-02, -2.4889e-01,\n          8.8328e-02,  7.9351e-02, -1.4745e-01],\n        [-2.8643e-01,  1.8629e-01, -3.3549e-02, -1.0263e-01, -2.4533e-01,\n          2.7033e-01, -4.7308e-02, -2.2887e-01],\n        [-2.3665e-01,  2.6882e-01,  2.4857e-01, -9.1079e-02, -2.5134e-01,\n          1.9461e-01,  2.2289e-01, -2.6607e-01],\n        [ 1.6310e-01,  9.0285e-02, -1.9600e-01,  7.5464e-02,  2.2425e-02,\n          2.1314e-01,  2.0873e-01, -1.4806e-01],\n        [-3.3027e-01,  6.0239e-02,  3.4077e-01,  5.2826e-02, -2.9462e-01,\n         -3.3613e-01, -1.8851e-01,  1.1862e-01],\n        [-2.4098e-01,  3.1717e-01, -2.3302e-01, -2.4067e-01, -8.0679e-02,\n         -7.5850e-02, -1.2632e-01,  1.6679e-02],\n        [ 1.8263e-01,  2.6701e-01, -2.9065e-01,  2.2932e-01,  3.3216e-03,\n         -1.4952e-01, -5.2640e-02, -5.7685e-02],\n        [ 1.4082e-01,  8.9513e-02,  1.6899e-01,  2.8928e-01,  2.7911e-01,\n          3.4215e-01,  1.8752e-01,  5.7003e-02],\n        [-2.4711e-01,  2.9251e-01,  1.6806e-01,  6.4060e-02,  1.4340e-01,\n         -2.3572e-01, -3.0761e-01,  1.8973e-01],\n        [ 2.2935e-01,  2.4429e-01, -3.2079e-03, -1.0523e-01,  1.9784e-01,\n          9.0421e-03,  4.6979e-02, -3.1945e-01],\n        [-1.5995e-01,  5.6591e-02,  2.3148e-01,  3.0972e-01,  1.2637e-01,\n         -1.4810e-01,  1.3401e-01, -3.2169e-01],\n        [-1.5658e-01, -4.2762e-02, -5.1437e-03, -1.6129e-01, -4.5308e-02,\n         -8.2236e-02, -9.8041e-02,  3.5184e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-3.2616e-01, -5.6886e-02,  1.6651e-01, -6.5059e-02, -1.6460e-01,\n        -4.3738e-02,  2.8844e-01,  7.2061e-02,  2.6188e-01, -1.1699e-01,\n         2.4542e-01,  7.8197e-02, -3.3883e-01,  2.6263e-01,  2.2203e-01,\n        -8.6443e-02,  2.3866e-01, -4.2169e-02,  2.9325e-01, -1.2025e-01,\n         9.5744e-02, -2.9280e-02,  2.0441e-05, -1.5986e-01, -1.9098e-01,\n         3.2475e-01, -3.4897e-01, -3.1455e-01, -1.6389e-02, -1.8786e-01,\n        -5.9864e-02,  4.6363e-02,  3.2002e-01,  2.7711e-01,  2.7138e-01,\n        -1.3966e-01, -3.0241e-01,  6.9881e-02,  8.1109e-02, -1.3019e-01,\n        -1.0660e-01, -1.0453e-02, -2.8131e-01,  3.3030e-01, -2.4696e-01,\n        -2.9001e-02, -1.9623e-01,  3.4760e-01, -1.7245e-01, -1.8809e-01,\n        -8.3976e-02,  6.9564e-02, -3.1987e-01,  1.2843e-01, -2.3163e-02,\n         3.1046e-01, -1.7992e-01, -2.7775e-01,  2.1499e-01, -1.7620e-01,\n        -1.3464e-01,  2.9908e-02,  2.8292e-01, -4.4094e-02],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1246, -0.0274, -0.0061,  ..., -0.1174,  0.0708, -0.0612],\n        [ 0.1245, -0.0741, -0.0490,  ..., -0.1196,  0.0968, -0.0217],\n        [-0.0908,  0.1025, -0.1167,  ..., -0.0616,  0.0764, -0.0126],\n        ...,\n        [ 0.0968,  0.0406, -0.1179,  ...,  0.0457, -0.0946, -0.0958],\n        [-0.0569, -0.0396, -0.0310,  ..., -0.0158, -0.0572,  0.0474],\n        [ 0.0361,  0.1246, -0.1164,  ...,  0.0639,  0.0530,  0.1169]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0085, -0.0384,  0.0201,  0.0381,  0.0165, -0.0345,  0.0449,  0.0208,\n         0.1027,  0.0660, -0.1112,  0.0475,  0.0431, -0.0317, -0.0141,  0.1037,\n         0.0270,  0.0809,  0.0599,  0.0768, -0.0619, -0.1103, -0.0556,  0.0219,\n         0.0921, -0.0067,  0.0453,  0.0171, -0.0273, -0.0772, -0.1247, -0.0357,\n        -0.0462, -0.0702, -0.0031, -0.0940, -0.0241,  0.0539, -0.1059, -0.0848,\n        -0.0068, -0.0269, -0.0116, -0.0542, -0.0498,  0.0556,  0.0702, -0.1238,\n         0.0635, -0.1173, -0.0718, -0.1106, -0.1205,  0.1030, -0.1192, -0.0822,\n        -0.1102,  0.0304,  0.0876,  0.0346, -0.0805,  0.0491, -0.1222,  0.0099],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0145,  0.0780,  0.1229,  ...,  0.0101, -0.0850,  0.0292],\n        [-0.0587,  0.0204,  0.0411,  ..., -0.0539, -0.1085, -0.1166],\n        [-0.0244,  0.0427,  0.0454,  ..., -0.0313, -0.0263,  0.0491],\n        ...,\n        [-0.0958, -0.0849,  0.0375,  ...,  0.0245,  0.0521,  0.0050],\n        [ 0.0523, -0.0045, -0.1054,  ..., -0.1065, -0.0512, -0.1248],\n        [-0.0683,  0.0439,  0.0416,  ..., -0.0206,  0.0807, -0.0251]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1123, -0.0793,  0.1046, -0.0029,  0.0359,  0.0958, -0.0687, -0.0179,\n         0.1006,  0.0504, -0.1073,  0.0624,  0.0267,  0.0175,  0.1160,  0.0725,\n        -0.1090, -0.0814, -0.0109,  0.0312, -0.0412, -0.0355, -0.0010,  0.0210,\n        -0.0065,  0.0103, -0.1032,  0.0258,  0.0953, -0.0645, -0.0884, -0.0382],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.5956e-02,  1.1147e-01, -8.4412e-02, -4.5755e-03, -1.6173e-01,\n         -1.6873e-02,  7.2736e-02, -1.4553e-01,  1.2028e-01, -8.7122e-02,\n         -1.6081e-01, -1.2397e-01, -3.2149e-02,  1.1772e-01,  4.3381e-02,\n          2.8891e-02,  9.1582e-02,  6.2870e-02, -9.6223e-02, -9.2371e-02,\n         -1.3442e-01,  1.0987e-01, -4.8419e-02, -9.5404e-02, -8.8407e-02,\n          1.2480e-01, -1.3390e-02,  6.8911e-02, -9.1312e-02,  1.3571e-01,\n          3.2108e-02, -1.5276e-01],\n        [ 1.7418e-01,  1.4230e-01, -1.0969e-01, -1.7374e-01, -1.1665e-01,\n          1.3477e-01, -1.2185e-01, -1.2665e-01,  2.5025e-03, -4.1708e-02,\n         -1.1838e-01, -1.2901e-02,  6.7079e-02,  1.4848e-01, -1.2085e-01,\n         -1.0309e-01, -1.9839e-02, -6.9307e-02,  1.0602e-01,  1.5233e-01,\n          1.1525e-01, -1.0543e-01,  1.0476e-01,  2.4209e-03, -5.1728e-02,\n         -4.5878e-02, -7.7432e-02, -9.4387e-02, -7.8305e-02,  1.3836e-01,\n          7.0265e-02,  3.2300e-02],\n        [-1.7537e-01,  1.5021e-01,  1.2979e-01,  7.5470e-02,  1.6243e-01,\n          6.3153e-02,  1.6008e-01,  1.4521e-02,  1.1173e-01,  1.2884e-01,\n         -1.7562e-01,  3.2483e-02,  1.5481e-02,  1.0120e-02,  1.0546e-01,\n          1.1116e-01, -1.6451e-01,  1.7491e-01, -1.1512e-01, -8.7101e-02,\n         -5.4674e-02,  4.1941e-02, -1.1837e-01, -1.4970e-01, -1.9892e-02,\n          5.8556e-02, -6.2661e-02, -1.1813e-02,  6.5693e-03, -2.2355e-02,\n         -1.2033e-01, -1.6181e-01],\n        [ 6.9581e-03, -3.1123e-03,  1.4621e-01, -4.8100e-02,  1.1659e-01,\n         -2.2150e-02, -1.5058e-01,  6.7795e-02, -1.3778e-01, -7.6234e-02,\n         -7.1460e-05,  1.5981e-01,  6.0934e-02,  1.0122e-02, -2.4576e-02,\n          6.2980e-02, -1.3789e-01, -1.4991e-01, -1.4327e-01,  1.6057e-01,\n         -1.6066e-01, -1.6234e-02,  1.3410e-01,  4.0393e-02, -1.2145e-01,\n         -1.4417e-01, -1.1329e-01,  1.1066e-01, -7.9744e-02, -1.4233e-01,\n          3.2638e-02, -7.4631e-02],\n        [ 1.1534e-02, -1.0635e-01,  1.9795e-02,  1.5643e-01,  5.6342e-02,\n         -1.1900e-01,  1.4754e-02,  5.6475e-02, -1.1356e-01,  8.9467e-02,\n          5.4965e-02,  8.2326e-02, -4.6573e-03, -6.9005e-02, -7.6876e-02,\n          3.6406e-02,  5.6902e-02,  7.8599e-02, -6.3010e-02,  1.1592e-02,\n          5.3338e-02, -2.9593e-02,  3.2678e-02, -2.2963e-02, -1.4985e-01,\n         -2.8280e-02,  3.8330e-02,  1.1846e-01,  2.2985e-02,  1.0648e-01,\n         -9.0336e-02, -1.0052e-01],\n        [-1.6046e-01,  1.4907e-01,  3.8502e-03, -1.2104e-01,  1.4068e-01,\n          1.3095e-01,  1.6042e-01, -1.1355e-01, -5.3799e-03,  4.6895e-02,\n          1.7484e-01,  8.9499e-02,  1.4103e-01,  1.1697e-01, -1.2974e-01,\n         -7.7905e-02,  1.4247e-02,  1.1017e-01,  4.2758e-02, -1.7264e-01,\n          1.4433e-01,  3.0197e-02,  1.6613e-01, -1.6573e-01,  3.9758e-02,\n          8.4897e-02, -9.4701e-02, -1.0088e-01,  1.1323e-01,  1.5616e-01,\n          7.1225e-02, -1.1138e-01],\n        [ 6.3311e-02,  1.6427e-01, -1.7321e-01,  1.6868e-01,  1.0217e-01,\n         -1.2567e-01,  8.2979e-02,  4.2991e-02, -1.2450e-01,  3.4794e-02,\n         -1.2035e-01, -7.8844e-02, -7.1058e-02,  9.9657e-03, -8.4068e-02,\n          4.6301e-02, -4.0864e-02,  8.8124e-02,  2.8821e-02,  1.7738e-02,\n          9.7740e-02, -1.5279e-01,  1.0778e-01, -1.7631e-01,  1.4697e-01,\n         -1.5094e-01, -4.6223e-02,  1.2399e-01,  9.9060e-02,  2.8364e-02,\n          5.4216e-03, -5.2968e-03],\n        [-8.0236e-02, -1.1531e-01, -1.7295e-01,  9.4021e-02,  4.5310e-02,\n          1.4631e-01, -1.7284e-01, -6.8090e-02,  1.7055e-01, -5.0783e-02,\n          3.9754e-03,  1.1667e-01, -9.1705e-02, -5.0367e-02, -9.5074e-02,\n         -3.2424e-02, -8.7329e-02, -1.3106e-01, -2.0385e-02,  5.0350e-02,\n          1.0108e-01, -1.6535e-01,  2.0946e-02,  6.5808e-02,  8.8632e-02,\n         -2.5599e-02,  3.4125e-02,  1.4957e-01,  1.0207e-01,  5.0267e-02,\n          1.5482e-01, -1.2763e-01],\n        [-1.4806e-01, -1.4575e-01,  3.8041e-02, -8.5971e-03,  7.3658e-02,\n         -7.5005e-02, -1.4730e-01, -1.2068e-01,  4.2221e-02, -2.1215e-02,\n          9.7055e-02, -5.1646e-02,  2.9932e-03,  1.4412e-01, -6.4829e-03,\n         -2.7836e-02, -5.6123e-02, -6.6212e-02,  2.5540e-03,  1.0181e-01,\n         -6.8779e-02,  1.3700e-01, -1.4986e-01, -1.6596e-03,  2.9790e-02,\n         -1.1741e-03, -2.1415e-02, -1.6993e-01,  1.7477e-01,  2.3730e-02,\n         -1.2379e-01,  1.0216e-01],\n        [ 1.1199e-01, -1.3307e-01, -6.6006e-02, -3.5592e-02, -1.3791e-01,\n         -1.4757e-01, -1.4895e-01,  1.6672e-01, -7.6621e-03, -1.6226e-01,\n          5.7063e-02, -1.7451e-02,  5.3001e-02,  4.5565e-02, -5.0825e-02,\n          5.8940e-02,  6.0491e-02, -9.9885e-02, -1.7179e-01,  2.4604e-03,\n          8.1275e-02,  1.4892e-01, -1.6051e-01, -1.0144e-02, -1.5554e-01,\n         -1.5161e-01, -7.0320e-02,  6.9498e-02,  1.1990e-01, -1.8456e-02,\n          3.5974e-02, -9.3641e-03],\n        [-4.4013e-02,  1.4422e-01, -1.0235e-02,  1.0687e-01, -1.1575e-01,\n          7.9519e-02,  1.9506e-02,  1.5067e-01, -1.5451e-01,  5.7950e-02,\n         -1.4399e-01,  1.8017e-02,  1.1966e-01,  3.9283e-02,  1.3477e-01,\n          7.5038e-02,  9.7867e-02,  5.7574e-02, -1.6558e-01,  1.5264e-01,\n          7.1676e-02, -5.5660e-02,  1.0594e-04,  6.7285e-02, -1.3790e-01,\n          6.4960e-02, -8.9568e-02, -7.7004e-02,  8.7584e-02,  1.0247e-01,\n          1.7369e-01,  1.1615e-01],\n        [ 1.3498e-01,  2.0453e-02,  8.9103e-02,  4.0730e-02,  1.2632e-02,\n         -8.5183e-02, -5.9953e-03,  1.7219e-01, -4.9996e-02, -1.7524e-01,\n         -8.1430e-02,  8.0099e-02,  1.0660e-02, -5.8366e-02,  1.2463e-01,\n          5.3301e-03, -1.5143e-01,  2.5409e-02, -1.7476e-01, -4.8904e-02,\n          1.6290e-01,  8.5202e-02,  2.4690e-02, -1.2291e-01, -9.7226e-04,\n          8.7581e-02,  6.0869e-02,  1.7579e-01,  1.3785e-01,  1.4643e-01,\n          1.4041e-01, -3.6677e-02],\n        [-1.2867e-01,  7.6378e-02, -6.6325e-02,  7.9773e-02, -1.9418e-02,\n         -1.1838e-01, -1.1633e-02, -3.9845e-02,  6.5052e-02, -9.5717e-02,\n         -1.7016e-01,  4.8164e-02,  3.8558e-02, -1.6494e-01, -1.4557e-01,\n          3.7579e-02,  1.1812e-01, -2.8167e-02,  7.6819e-02,  4.1322e-02,\n         -9.9810e-02, -1.4616e-01,  1.4642e-01,  3.5210e-02,  1.1368e-01,\n          1.2594e-01, -2.5032e-02, -3.8450e-02,  3.5624e-02, -6.1444e-02,\n         -1.0396e-01, -9.4254e-02],\n        [-1.5122e-01,  1.3778e-01, -4.6990e-02,  1.3801e-01, -4.7815e-02,\n         -6.4804e-02,  5.7900e-02,  6.0444e-02, -8.5919e-02, -7.0767e-02,\n          1.3067e-01,  2.1626e-02, -1.5641e-01,  3.9014e-02, -8.3942e-02,\n          1.4700e-02,  3.8611e-02,  3.6934e-02, -1.1405e-01, -4.8827e-02,\n         -1.7271e-01,  4.1816e-02, -1.6163e-01,  1.2857e-01,  1.2503e-01,\n         -3.6856e-02, -7.7315e-02,  1.5566e-01, -1.5763e-01, -5.2735e-02,\n          6.7441e-02,  9.2095e-02],\n        [-4.9394e-02, -1.0078e-01, -1.2849e-01,  1.8697e-02, -1.1266e-01,\n         -4.4491e-02, -1.0750e-01, -1.1483e-01,  1.2395e-01, -1.1542e-01,\n          2.9979e-02, -1.0653e-01,  7.3824e-02, -8.9337e-02,  6.5132e-02,\n         -1.3295e-01,  3.8492e-02,  7.0065e-02,  3.6066e-03, -1.5038e-02,\n          1.7475e-01,  1.4888e-01,  6.0757e-02,  1.5943e-01,  2.7939e-02,\n         -3.1983e-02,  8.2537e-02,  1.7524e-02,  1.6334e-01,  1.2914e-01,\n         -4.5501e-02, -9.0899e-02],\n        [ 1.4448e-01,  1.0687e-01,  9.5797e-02, -8.9906e-02, -1.4605e-01,\n          4.5961e-02, -9.8611e-02,  1.0045e-01, -8.6376e-02, -8.0927e-02,\n          1.3325e-01, -1.4054e-01,  9.0148e-03,  1.6846e-01, -1.5439e-01,\n          3.9751e-02, -1.4537e-01, -4.2542e-02, -1.3281e-01, -1.3916e-01,\n          1.1704e-01, -1.2551e-01,  3.5272e-02,  1.7256e-01,  5.0884e-02,\n         -3.0260e-03,  1.6978e-02,  9.3314e-02,  4.5768e-02, -7.6394e-02,\n         -1.4497e-01,  1.1031e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1302,  0.1492,  0.1760,  0.1331, -0.0282, -0.0303,  0.0013, -0.1472,\n         0.1631,  0.0751,  0.0644, -0.1632,  0.1621,  0.1421,  0.1723,  0.0263],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0910,  0.2414, -0.2449, -0.0663,  0.0585, -0.2142,  0.1366, -0.0034,\n          0.1240, -0.0976,  0.1038,  0.2102, -0.0502, -0.1310,  0.0856, -0.2065],\n        [-0.0769, -0.0755,  0.1853,  0.1811, -0.2384,  0.0663, -0.1258,  0.1299,\n          0.1205,  0.0823, -0.1115,  0.0091, -0.0776, -0.2451,  0.2234,  0.0749],\n        [ 0.0477, -0.2066, -0.0062, -0.2499,  0.1267, -0.2225, -0.1047, -0.1924,\n          0.2229,  0.1383, -0.2365, -0.1492, -0.2155, -0.0240,  0.1022,  0.1564],\n        [ 0.1042, -0.1535,  0.1884,  0.0926, -0.1874, -0.2394,  0.2163,  0.0160,\n          0.0686, -0.0149,  0.0067,  0.0309,  0.2147, -0.1105, -0.1451,  0.0692],\n        [ 0.2216, -0.2037, -0.0544, -0.0168, -0.0549, -0.1242, -0.1021,  0.2168,\n         -0.2480,  0.1162, -0.1687,  0.0134, -0.0875,  0.1124,  0.0856,  0.2140],\n        [-0.1081,  0.0829,  0.1794,  0.0450, -0.0399, -0.1637, -0.0269,  0.1536,\n          0.1393,  0.1037, -0.0821,  0.1238, -0.0480,  0.2402,  0.1760,  0.1438],\n        [-0.2257,  0.1886, -0.1512,  0.0197, -0.1545, -0.0212, -0.1629, -0.2318,\n         -0.0600,  0.0955,  0.1661,  0.0024,  0.0555, -0.2018, -0.0545,  0.1404],\n        [ 0.1581,  0.0257,  0.1356,  0.1352,  0.1663,  0.1260,  0.0408, -0.1951,\n          0.1792,  0.0691, -0.0453, -0.0628, -0.0467, -0.2010,  0.2330, -0.1699]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1312, -0.2368,  0.0488,  0.0126, -0.0114, -0.1338, -0.0756, -0.1421],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3044,  0.2803,  0.2767, -0.2503, -0.0409, -0.2742,  0.1325, -0.2777]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2524], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7e625aaa5190>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7e62572e0750>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s180310000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s180310000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}