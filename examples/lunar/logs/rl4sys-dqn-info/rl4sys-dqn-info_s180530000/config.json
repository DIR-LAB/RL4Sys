{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s180530000"
    },
    "q_lr":	0.0005,
    "seed":	180530000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x16ac4e3e0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0352,  0.1469, -0.3258, -0.1375,  0.2541,  0.0670,  0.0614,  0.1532,\n         0.2184, -0.1192,  0.3383,  0.2805, -0.1141, -0.3454, -0.0601,  0.0382,\n         0.2075, -0.0536, -0.1328,  0.2232,  0.2345, -0.3272,  0.2631, -0.1553,\n         0.2632, -0.0667, -0.2175, -0.0520, -0.3041, -0.1216, -0.1737, -0.0126],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.1576e-01, -3.1884e-02, -8.0676e-02,  1.2485e-01, -2.2159e-01,\n         -2.5679e-01,  2.2602e-02, -1.0743e-01],\n        [ 3.2917e-01, -1.6423e-01, -3.2012e-01,  3.0615e-03,  1.2856e-01,\n         -9.5251e-02,  2.4748e-01, -1.5581e-02],\n        [-1.6735e-01, -1.1923e-02,  1.5144e-01,  1.9164e-01, -3.5335e-01,\n         -4.2791e-02, -1.0785e-01,  1.6267e-01],\n        [ 1.9999e-01,  3.2056e-01,  1.5225e-01,  1.0534e-01,  2.8073e-01,\n         -1.1527e-01,  1.5535e-02,  9.6562e-03],\n        [-2.0363e-01, -7.0004e-02,  2.2088e-01,  2.4797e-01,  2.2201e-01,\n          1.3453e-01,  2.5368e-01, -2.0424e-01],\n        [ 1.3269e-01,  2.3389e-01,  1.0312e-01,  6.7661e-03,  2.6912e-01,\n         -1.7168e-01,  6.8448e-02, -1.7976e-01],\n        [ 7.8296e-03,  3.3781e-01,  1.3976e-01, -3.1555e-01, -2.2130e-01,\n         -1.4482e-01,  2.7214e-01, -3.1793e-02],\n        [ 2.1531e-01,  2.4369e-01, -9.2363e-02, -5.4835e-02,  3.2388e-01,\n          7.9953e-03, -1.5949e-01,  9.7490e-02],\n        [-6.6990e-02, -2.0767e-02, -6.1805e-02,  3.4040e-01, -2.5670e-01,\n         -1.1996e-01, -2.5421e-01, -1.8119e-01],\n        [ 1.7406e-01, -3.4114e-01,  3.1532e-01,  1.5855e-01, -3.1137e-01,\n          6.1814e-02,  2.4652e-02, -9.7185e-02],\n        [ 3.4185e-01,  9.8783e-02, -2.8368e-01,  2.9159e-01,  1.8835e-01,\n         -1.9944e-02,  3.5349e-01,  1.8097e-01],\n        [-3.4706e-01, -3.0873e-01,  2.2524e-01,  3.4366e-01, -1.9670e-01,\n         -4.1296e-02,  2.5046e-01, -7.6229e-02],\n        [-2.6855e-01,  6.9673e-02,  1.3812e-01, -9.5927e-02,  6.2981e-02,\n         -2.7030e-01, -3.3574e-01,  4.6291e-02],\n        [ 1.6201e-02,  1.6965e-01,  2.9902e-01, -2.9115e-01, -2.6342e-01,\n          3.5141e-01, -2.8041e-01,  3.1989e-01],\n        [-1.2515e-01,  3.2122e-01,  1.7376e-01, -1.4143e-01, -1.8982e-01,\n         -4.8088e-02, -1.1905e-01, -3.3745e-01],\n        [-4.8811e-02,  2.3757e-01,  2.3109e-01,  2.8303e-01,  1.0075e-02,\n          1.1228e-01,  2.8320e-01, -2.8916e-01],\n        [-1.3179e-01, -1.6584e-01,  3.3828e-01,  1.1103e-01, -2.2984e-01,\n         -4.2669e-02,  2.3722e-01, -1.4449e-01],\n        [-2.1268e-01,  2.9869e-01, -8.5081e-02, -1.1858e-02, -9.9626e-02,\n         -1.7151e-01, -2.2172e-03, -4.4871e-02],\n        [-2.3346e-01,  2.1153e-01,  1.4549e-01,  2.9097e-01, -6.5120e-03,\n          2.9877e-01,  2.0789e-01,  2.1288e-01],\n        [ 3.2225e-02,  2.0696e-01,  1.7003e-01,  1.4310e-01, -2.2938e-01,\n          7.2128e-02,  9.2724e-02, -1.5571e-01],\n        [-9.2970e-02, -3.1082e-01,  2.4414e-01, -3.0361e-02,  2.5916e-01,\n          2.8654e-02,  3.6247e-02,  2.7242e-01],\n        [-1.5075e-01, -2.8663e-01,  2.9162e-01, -1.6627e-01, -1.8645e-01,\n         -2.6091e-01,  3.0181e-01,  3.3407e-01],\n        [-3.4303e-02,  2.0719e-01, -1.8254e-01,  1.2411e-01,  3.0040e-01,\n         -7.8215e-02,  3.0681e-01,  2.5075e-01],\n        [ 2.7256e-01,  1.8932e-01,  3.4094e-01, -2.7974e-01,  1.0959e-01,\n         -4.7281e-02, -2.4226e-01, -9.5003e-02],\n        [ 1.2773e-01,  7.6209e-02, -3.0629e-01, -4.8061e-02,  1.2208e-01,\n         -1.5624e-01,  1.9850e-02, -1.6792e-01],\n        [ 2.1478e-02,  2.6907e-01, -1.4342e-01,  3.1279e-01, -3.3146e-01,\n         -2.1179e-01,  3.1347e-01, -1.9539e-04],\n        [ 1.4470e-01, -2.8225e-01,  1.0283e-01,  2.7648e-02, -3.6611e-02,\n         -3.4326e-01, -1.7013e-03, -3.6672e-02],\n        [ 8.0403e-02,  2.3952e-01, -1.8181e-01, -1.6934e-01, -1.7764e-01,\n         -1.1588e-01, -3.3019e-01, -1.1502e-01],\n        [ 5.1947e-02, -4.6680e-02,  6.4443e-03,  1.0955e-02, -1.4496e-01,\n         -3.0636e-01, -3.3989e-01, -1.3364e-01],\n        [ 2.7020e-02,  1.1915e-01, -2.0784e-02, -6.7808e-02, -1.7593e-02,\n         -2.9482e-01,  1.5815e-01,  1.2543e-01],\n        [ 3.3121e-02, -1.0256e-01, -2.9155e-01,  1.9152e-01,  3.3292e-01,\n         -2.1081e-01, -5.8512e-02,  6.7047e-02],\n        [ 1.8190e-01,  7.4127e-02, -3.2398e-01, -3.0104e-03,  5.8436e-02,\n          2.1882e-01,  2.5477e-01,  3.1300e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1307,  0.0590, -0.1302, -0.0043, -0.0766, -0.0328,  0.1624, -0.0481,\n        -0.1666,  0.0406, -0.0087,  0.1131, -0.1510, -0.0134, -0.0795,  0.1197],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.4053e-01,  1.0765e-01,  1.0035e-01,  1.5591e-01, -5.4845e-02,\n         -7.1010e-02,  1.7182e-01, -1.1956e-01,  1.1310e-01, -1.0655e-01,\n         -9.0682e-02, -1.3988e-01, -5.0848e-02, -1.6977e-01,  1.3267e-02,\n         -1.1359e-01, -9.1720e-02,  3.5507e-02, -9.5452e-02,  1.0633e-01,\n          1.5824e-01,  1.3010e-01, -1.0547e-01,  1.7676e-01, -1.1031e-01,\n          1.5062e-01,  8.8502e-02, -9.9440e-03, -1.0119e-01, -1.5824e-01,\n         -3.4694e-02, -1.1069e-01],\n        [-1.0923e-01, -1.4228e-01,  1.1309e-01, -5.0891e-02,  7.9055e-02,\n         -1.2619e-01,  1.0893e-01,  3.1997e-02, -2.9663e-02,  8.6133e-02,\n         -1.6077e-02, -1.4446e-01, -1.3572e-02,  1.0381e-02, -1.0007e-01,\n          1.8854e-02,  4.4912e-02,  1.5778e-01, -4.6886e-02, -1.6976e-01,\n          1.3757e-01, -1.3508e-01,  8.1556e-02, -7.2295e-02,  3.7263e-02,\n         -1.7302e-01,  7.0747e-02,  2.9835e-02,  4.3238e-02,  5.2003e-02,\n          1.5389e-01, -1.3202e-01],\n        [-7.1808e-02,  1.7461e-01,  1.7382e-01,  1.6054e-01, -9.6229e-02,\n          1.3874e-01, -1.7528e-01, -1.3971e-02, -1.5346e-01, -8.7734e-02,\n          3.3550e-02, -9.9599e-02, -6.2751e-03, -1.3023e-01,  1.0464e-01,\n          1.6300e-01, -9.7469e-02, -1.0159e-01,  1.4004e-01, -1.0009e-01,\n          5.8771e-02,  1.3011e-02, -1.2958e-01, -3.1353e-02,  1.0103e-01,\n         -8.3338e-02, -9.3399e-03,  5.0011e-02, -1.2108e-02,  1.7649e-01,\n         -7.9874e-02,  3.3334e-02],\n        [-1.7329e-01, -1.6069e-01,  8.5158e-02, -2.3218e-02, -1.5197e-01,\n         -1.3079e-01,  6.7412e-02, -1.3727e-01, -5.1561e-02, -3.0982e-02,\n          1.9063e-02, -1.0416e-01,  3.3741e-03, -1.3558e-01,  1.3406e-01,\n          6.1120e-02, -1.4769e-01,  1.6959e-01,  6.4136e-02,  4.1356e-02,\n          1.4969e-01,  1.1250e-01, -6.6011e-02,  3.0622e-02, -5.5370e-02,\n          1.1986e-01,  1.3721e-01,  7.1003e-02,  7.0051e-02, -1.1817e-01,\n          1.6009e-01,  1.2879e-01],\n        [-7.9308e-02, -1.7673e-01,  7.8308e-02, -1.6709e-01,  7.2491e-02,\n          1.5577e-01, -9.9319e-02,  5.4789e-02,  8.9660e-02, -2.6083e-02,\n         -1.6612e-01,  1.2267e-01, -1.6156e-01,  2.0649e-02, -1.1619e-01,\n         -5.0487e-03, -1.4282e-03, -4.5685e-02,  9.5438e-02,  1.4552e-01,\n         -1.2857e-01, -8.3410e-03, -3.9549e-02, -1.2783e-02, -5.3831e-02,\n         -1.7673e-01, -5.4061e-02,  9.2549e-02,  2.8174e-02, -4.9163e-03,\n          1.3501e-01, -5.3976e-02],\n        [ 1.7282e-02, -4.3849e-02,  7.1634e-02, -1.4152e-01,  1.0982e-01,\n         -7.3110e-02,  1.3751e-01,  1.4306e-01, -1.3833e-01, -6.0783e-02,\n          8.8712e-02, -5.4047e-02,  8.6192e-02, -9.8665e-02,  1.5757e-01,\n          8.8525e-02,  2.0506e-02, -1.2686e-01, -1.2710e-01, -5.5039e-02,\n         -1.3216e-02, -1.5885e-01,  1.0257e-01, -1.7181e-01, -3.1786e-02,\n          5.7615e-02,  1.7370e-01, -9.8355e-02, -1.2865e-01, -1.6706e-01,\n         -1.5110e-01,  1.4872e-01],\n        [-1.9152e-02, -1.0906e-01,  1.0051e-03, -1.9859e-02, -1.7070e-01,\n          6.3130e-02,  9.4468e-02, -9.6592e-02,  2.8210e-02, -7.9372e-02,\n          1.5915e-01, -1.6780e-01, -1.4947e-01,  1.4846e-01, -3.3320e-02,\n         -3.8464e-02,  1.6038e-01, -9.2667e-02, -2.3222e-02,  1.7230e-01,\n         -1.0123e-01,  1.2833e-02,  2.2287e-02,  7.7667e-02,  3.4802e-02,\n         -1.4806e-01,  6.8090e-02,  1.3785e-01,  1.7139e-01,  4.6980e-02,\n          1.3583e-01, -9.3628e-02],\n        [-1.0727e-01, -1.1326e-02,  5.4293e-02,  9.9007e-02, -1.4958e-01,\n          6.9659e-02, -4.0374e-03,  5.8753e-02,  5.4833e-02,  1.1110e-03,\n         -1.1236e-01, -7.0564e-02, -4.7100e-02, -1.5875e-01,  1.7436e-01,\n          1.4378e-01,  1.4823e-01,  1.0386e-01, -3.8033e-02,  1.6926e-01,\n         -9.8621e-02,  2.1215e-02, -2.4376e-02, -1.2672e-01,  1.3899e-01,\n          7.7653e-02, -9.9548e-02, -1.4236e-02, -1.6508e-01,  1.9309e-02,\n          1.7532e-01, -9.9994e-02],\n        [-1.3625e-01,  1.5398e-01,  3.0208e-03, -1.4224e-01, -5.9666e-03,\n         -1.3878e-01,  1.0427e-01,  9.8460e-02, -1.7761e-02, -3.4314e-02,\n          5.1432e-02,  1.4814e-01,  3.9610e-02,  1.6128e-01,  4.0223e-02,\n          9.8578e-02,  7.3362e-02, -1.2101e-01,  7.6444e-03,  2.2719e-02,\n         -1.0716e-01,  1.5870e-01, -1.3307e-02, -1.2403e-01,  1.4405e-01,\n         -1.2756e-01, -1.4140e-01,  1.6338e-01, -8.3228e-02,  1.3640e-01,\n         -1.6385e-01, -7.0318e-02],\n        [ 7.6430e-02,  7.6146e-02,  1.8130e-02,  1.6698e-01, -1.6340e-01,\n         -7.4352e-02,  3.3461e-02,  1.2605e-01, -1.4853e-01, -7.2946e-02,\n          8.0761e-02,  1.3270e-01,  2.0828e-02,  1.1337e-02,  8.2797e-02,\n         -8.6798e-02,  4.3022e-02,  1.2902e-01, -3.3021e-02,  6.9039e-02,\n          1.6975e-01,  8.6192e-02, -1.7675e-01,  1.3002e-01, -1.5319e-01,\n         -1.2768e-01, -5.7987e-02, -7.0933e-02, -3.1508e-02, -1.2383e-01,\n          1.4987e-01,  9.3680e-02],\n        [ 1.3988e-02,  9.0992e-02,  1.0088e-01, -1.3796e-01, -8.5481e-02,\n         -3.0821e-02, -1.3454e-01,  9.0026e-02,  1.6461e-01, -1.1067e-01,\n          1.6132e-01,  2.4187e-02,  2.2452e-02, -1.4169e-01, -4.8117e-02,\n          1.4089e-02, -1.6065e-01,  6.6376e-02,  2.2632e-02, -1.3609e-01,\n          7.5695e-02,  2.7705e-03,  8.9977e-02,  1.1839e-01, -1.0337e-01,\n         -1.0248e-01,  3.8270e-02, -6.7104e-02,  1.8566e-02,  4.3876e-02,\n          1.4997e-01,  1.5442e-01],\n        [-1.4797e-01, -5.8304e-02,  4.2190e-02, -1.3723e-01, -1.5374e-01,\n          1.1023e-01, -6.0492e-02,  1.9855e-02,  7.1640e-02,  7.9678e-02,\n          8.3859e-02, -3.0575e-02, -1.2372e-01, -1.1617e-01, -1.7182e-01,\n          7.9526e-02, -1.2109e-04,  1.2483e-01, -9.3802e-04, -2.3402e-02,\n          8.5239e-02,  2.7072e-02,  2.1575e-02,  5.3059e-02, -5.9389e-02,\n         -5.3725e-02, -9.0690e-02,  1.3333e-01, -1.4345e-01, -4.6119e-02,\n         -6.3128e-02,  3.7910e-03],\n        [ 9.0102e-02, -1.2197e-01,  8.3289e-02,  7.8684e-03, -2.2161e-03,\n          2.7171e-02,  5.6931e-02,  2.3437e-02,  1.2462e-01,  1.1686e-01,\n         -1.4728e-01,  3.7807e-02, -1.7166e-01,  1.2005e-01,  7.1370e-02,\n          1.0137e-01, -1.2282e-01,  1.2317e-01, -4.2860e-02,  1.7234e-01,\n         -1.3577e-01, -1.3316e-01,  1.4201e-01,  1.5141e-01, -1.0979e-02,\n          1.3905e-01,  1.4085e-01,  3.0196e-02, -9.0419e-02, -2.2854e-02,\n          3.4779e-02,  1.0452e-01],\n        [-4.2689e-02, -1.3874e-01, -7.9986e-02,  1.2479e-01,  2.8717e-02,\n          1.2399e-01,  1.4877e-01, -1.2027e-01, -6.4486e-02,  2.2843e-02,\n          8.2055e-02,  4.8359e-02, -1.0561e-01, -3.4038e-02, -7.9954e-02,\n          2.3543e-02, -1.7640e-01, -8.5762e-02,  5.4661e-02,  4.5044e-02,\n         -4.9619e-02,  4.8716e-02,  5.2728e-02, -3.3773e-02,  1.4320e-01,\n          1.6736e-01, -9.1924e-04, -4.7581e-02, -5.6397e-02,  1.2241e-01,\n          3.0090e-02,  2.0188e-02],\n        [-2.2310e-04, -1.5971e-01, -9.6108e-02, -5.6988e-02, -6.4008e-02,\n         -3.9182e-02, -1.0674e-01, -1.0989e-02, -2.7891e-02, -8.3654e-02,\n          9.7527e-02, -7.4768e-02, -2.8078e-02, -4.5801e-02,  1.4384e-01,\n         -1.4683e-01, -1.0502e-01, -1.5467e-01,  5.9948e-02,  8.8606e-02,\n         -1.5294e-01,  1.7030e-02, -9.0759e-03, -1.3906e-02, -8.4457e-02,\n          1.0532e-01,  1.6001e-01,  9.3857e-02, -2.3646e-02, -1.6450e-01,\n          1.1577e-01, -2.8458e-02],\n        [ 3.0314e-03,  3.4983e-02, -8.5013e-02,  1.0201e-01, -1.6968e-01,\n          1.4206e-01,  9.0216e-02,  1.3130e-01, -1.1929e-01, -6.2976e-02,\n         -3.0935e-03,  1.4081e-01,  1.4626e-01, -2.9495e-02,  6.4559e-02,\n          1.2725e-01,  7.2093e-02,  1.4685e-01,  3.8613e-02, -2.4944e-02,\n         -1.5748e-01, -1.0012e-01, -1.0007e-01, -5.0272e-02,  3.9050e-02,\n          1.1750e-01,  6.5722e-02,  1.5017e-01, -1.6406e-01,  4.6943e-03,\n          1.2344e-01, -9.3775e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0818,  0.0783,  0.2335, -0.0143, -0.0861, -0.1004, -0.2022, -0.2308],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.4860e-01,  2.2262e-01,  6.3728e-02,  9.8102e-02,  2.2664e-01,\n          1.8608e-01, -1.9943e-01,  2.3064e-01, -2.1745e-01,  1.3269e-01,\n         -1.8085e-01,  9.8335e-02, -2.1838e-01,  1.0507e-01,  9.5451e-02,\n          1.0889e-01],\n        [ 2.2642e-01,  7.8300e-02, -2.2453e-01, -1.6781e-01, -1.9200e-01,\n          1.9845e-01,  1.0993e-01,  4.7704e-02,  3.8931e-02,  1.5286e-01,\n          2.7707e-02,  1.3913e-01, -6.6678e-02,  1.5663e-01,  6.9296e-02,\n          5.1018e-02],\n        [ 4.9503e-02, -9.2557e-02,  8.2478e-02,  6.5142e-02,  1.9548e-01,\n          2.3928e-01, -1.7736e-01, -1.5671e-02, -2.3065e-02, -1.3536e-01,\n         -1.7628e-01, -6.9320e-02,  1.1780e-01,  1.7624e-01,  8.9789e-02,\n          9.9729e-02],\n        [-1.2364e-01,  3.9811e-02,  1.3422e-02, -1.9706e-01, -2.0764e-01,\n         -1.1496e-01, -1.6490e-02,  1.9941e-01, -7.8410e-02, -1.7074e-01,\n          1.9691e-01,  4.4769e-02,  1.7886e-01,  8.8740e-02,  1.6333e-01,\n          2.1655e-01],\n        [ 1.5509e-01,  2.0230e-01, -8.9798e-02,  7.7674e-02,  1.5011e-01,\n          4.8548e-03, -2.4528e-01,  2.3147e-01, -2.2681e-01,  8.3004e-02,\n         -2.0258e-01, -8.9929e-02,  1.1258e-01,  2.2251e-01, -9.8907e-02,\n          1.0871e-01],\n        [-4.6241e-02, -9.6096e-02, -2.4947e-01,  2.4511e-01, -6.0828e-02,\n          8.7618e-02, -7.8321e-05, -7.3640e-02, -9.8971e-02,  9.9631e-03,\n         -7.9414e-02,  4.3578e-02,  1.3098e-01, -5.5716e-02,  2.4349e-01,\n          1.2463e-01],\n        [ 1.7769e-01,  1.4841e-01,  1.3114e-01, -2.3589e-01,  6.3578e-02,\n          1.5513e-01,  1.5196e-01,  1.8173e-01,  3.8303e-03, -1.8071e-01,\n          1.8870e-01, -1.7548e-01,  1.1814e-01, -6.5700e-02,  1.3013e-01,\n         -9.9545e-02],\n        [ 2.1331e-01,  1.5626e-01,  5.4617e-02,  1.1249e-01, -1.1310e-01,\n          2.4677e-02,  2.2888e-01,  1.6674e-01,  2.2807e-02,  4.6975e-02,\n         -2.3692e-01,  7.6210e-02,  1.8196e-01, -1.6989e-02, -2.4109e-01,\n          2.2621e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1800], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2453,  0.2193, -0.1564, -0.0255,  0.1944,  0.0623, -0.0633, -0.0857]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-3.1576e-01, -3.1884e-02, -8.0676e-02,  1.2485e-01, -2.2159e-01,\n         -2.5679e-01,  2.2602e-02, -1.0743e-01],\n        [ 3.2917e-01, -1.6423e-01, -3.2012e-01,  3.0615e-03,  1.2856e-01,\n         -9.5251e-02,  2.4748e-01, -1.5581e-02],\n        [-1.6735e-01, -1.1923e-02,  1.5144e-01,  1.9164e-01, -3.5335e-01,\n         -4.2791e-02, -1.0785e-01,  1.6267e-01],\n        [ 1.9999e-01,  3.2056e-01,  1.5225e-01,  1.0534e-01,  2.8073e-01,\n         -1.1527e-01,  1.5535e-02,  9.6562e-03],\n        [-2.0363e-01, -7.0004e-02,  2.2088e-01,  2.4797e-01,  2.2201e-01,\n          1.3453e-01,  2.5368e-01, -2.0424e-01],\n        [ 1.3269e-01,  2.3389e-01,  1.0312e-01,  6.7661e-03,  2.6912e-01,\n         -1.7168e-01,  6.8448e-02, -1.7976e-01],\n        [ 7.8296e-03,  3.3781e-01,  1.3976e-01, -3.1555e-01, -2.2130e-01,\n         -1.4482e-01,  2.7214e-01, -3.1793e-02],\n        [ 2.1531e-01,  2.4369e-01, -9.2363e-02, -5.4835e-02,  3.2388e-01,\n          7.9953e-03, -1.5949e-01,  9.7490e-02],\n        [-6.6990e-02, -2.0767e-02, -6.1805e-02,  3.4040e-01, -2.5670e-01,\n         -1.1996e-01, -2.5421e-01, -1.8119e-01],\n        [ 1.7406e-01, -3.4114e-01,  3.1532e-01,  1.5855e-01, -3.1137e-01,\n          6.1814e-02,  2.4652e-02, -9.7185e-02],\n        [ 3.4185e-01,  9.8783e-02, -2.8368e-01,  2.9159e-01,  1.8835e-01,\n         -1.9944e-02,  3.5349e-01,  1.8097e-01],\n        [-3.4706e-01, -3.0873e-01,  2.2524e-01,  3.4366e-01, -1.9670e-01,\n         -4.1296e-02,  2.5046e-01, -7.6229e-02],\n        [-2.6855e-01,  6.9673e-02,  1.3812e-01, -9.5927e-02,  6.2981e-02,\n         -2.7030e-01, -3.3574e-01,  4.6291e-02],\n        [ 1.6201e-02,  1.6965e-01,  2.9902e-01, -2.9115e-01, -2.6342e-01,\n          3.5141e-01, -2.8041e-01,  3.1989e-01],\n        [-1.2515e-01,  3.2122e-01,  1.7376e-01, -1.4143e-01, -1.8982e-01,\n         -4.8088e-02, -1.1905e-01, -3.3745e-01],\n        [-4.8811e-02,  2.3757e-01,  2.3109e-01,  2.8303e-01,  1.0075e-02,\n          1.1228e-01,  2.8320e-01, -2.8916e-01],\n        [-1.3179e-01, -1.6584e-01,  3.3828e-01,  1.1103e-01, -2.2984e-01,\n         -4.2669e-02,  2.3722e-01, -1.4449e-01],\n        [-2.1268e-01,  2.9869e-01, -8.5081e-02, -1.1858e-02, -9.9626e-02,\n         -1.7151e-01, -2.2172e-03, -4.4871e-02],\n        [-2.3346e-01,  2.1153e-01,  1.4549e-01,  2.9097e-01, -6.5120e-03,\n          2.9877e-01,  2.0789e-01,  2.1288e-01],\n        [ 3.2225e-02,  2.0696e-01,  1.7003e-01,  1.4310e-01, -2.2938e-01,\n          7.2128e-02,  9.2724e-02, -1.5571e-01],\n        [-9.2970e-02, -3.1082e-01,  2.4414e-01, -3.0361e-02,  2.5916e-01,\n          2.8654e-02,  3.6247e-02,  2.7242e-01],\n        [-1.5075e-01, -2.8663e-01,  2.9162e-01, -1.6627e-01, -1.8645e-01,\n         -2.6091e-01,  3.0181e-01,  3.3407e-01],\n        [-3.4303e-02,  2.0719e-01, -1.8254e-01,  1.2411e-01,  3.0040e-01,\n         -7.8215e-02,  3.0681e-01,  2.5075e-01],\n        [ 2.7256e-01,  1.8932e-01,  3.4094e-01, -2.7974e-01,  1.0959e-01,\n         -4.7281e-02, -2.4226e-01, -9.5003e-02],\n        [ 1.2773e-01,  7.6209e-02, -3.0629e-01, -4.8061e-02,  1.2208e-01,\n         -1.5624e-01,  1.9850e-02, -1.6792e-01],\n        [ 2.1478e-02,  2.6907e-01, -1.4342e-01,  3.1279e-01, -3.3146e-01,\n         -2.1179e-01,  3.1347e-01, -1.9539e-04],\n        [ 1.4470e-01, -2.8225e-01,  1.0283e-01,  2.7648e-02, -3.6611e-02,\n         -3.4326e-01, -1.7013e-03, -3.6672e-02],\n        [ 8.0403e-02,  2.3952e-01, -1.8181e-01, -1.6934e-01, -1.7764e-01,\n         -1.1588e-01, -3.3019e-01, -1.1502e-01],\n        [ 5.1947e-02, -4.6680e-02,  6.4443e-03,  1.0955e-02, -1.4496e-01,\n         -3.0636e-01, -3.3989e-01, -1.3364e-01],\n        [ 2.7020e-02,  1.1915e-01, -2.0784e-02, -6.7808e-02, -1.7593e-02,\n         -2.9482e-01,  1.5815e-01,  1.2543e-01],\n        [ 3.3121e-02, -1.0256e-01, -2.9155e-01,  1.9152e-01,  3.3292e-01,\n         -2.1081e-01, -5.8512e-02,  6.7047e-02],\n        [ 1.8190e-01,  7.4127e-02, -3.2398e-01, -3.0104e-03,  5.8436e-02,\n          2.1882e-01,  2.5477e-01,  3.1300e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0352,  0.1469, -0.3258, -0.1375,  0.2541,  0.0670,  0.0614,  0.1532,\n         0.2184, -0.1192,  0.3383,  0.2805, -0.1141, -0.3454, -0.0601,  0.0382,\n         0.2075, -0.0536, -0.1328,  0.2232,  0.2345, -0.3272,  0.2631, -0.1553,\n         0.2632, -0.0667, -0.2175, -0.0520, -0.3041, -0.1216, -0.1737, -0.0126],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.4053e-01,  1.0765e-01,  1.0035e-01,  1.5591e-01, -5.4845e-02,\n         -7.1010e-02,  1.7182e-01, -1.1956e-01,  1.1310e-01, -1.0655e-01,\n         -9.0682e-02, -1.3988e-01, -5.0848e-02, -1.6977e-01,  1.3267e-02,\n         -1.1359e-01, -9.1720e-02,  3.5507e-02, -9.5452e-02,  1.0633e-01,\n          1.5824e-01,  1.3010e-01, -1.0547e-01,  1.7676e-01, -1.1031e-01,\n          1.5062e-01,  8.8502e-02, -9.9440e-03, -1.0119e-01, -1.5824e-01,\n         -3.4694e-02, -1.1069e-01],\n        [-1.0923e-01, -1.4228e-01,  1.1309e-01, -5.0891e-02,  7.9055e-02,\n         -1.2619e-01,  1.0893e-01,  3.1997e-02, -2.9663e-02,  8.6133e-02,\n         -1.6077e-02, -1.4446e-01, -1.3572e-02,  1.0381e-02, -1.0007e-01,\n          1.8854e-02,  4.4912e-02,  1.5778e-01, -4.6886e-02, -1.6976e-01,\n          1.3757e-01, -1.3508e-01,  8.1556e-02, -7.2295e-02,  3.7263e-02,\n         -1.7302e-01,  7.0747e-02,  2.9835e-02,  4.3238e-02,  5.2003e-02,\n          1.5389e-01, -1.3202e-01],\n        [-7.1808e-02,  1.7461e-01,  1.7382e-01,  1.6054e-01, -9.6229e-02,\n          1.3874e-01, -1.7528e-01, -1.3971e-02, -1.5346e-01, -8.7734e-02,\n          3.3550e-02, -9.9599e-02, -6.2751e-03, -1.3023e-01,  1.0464e-01,\n          1.6300e-01, -9.7469e-02, -1.0159e-01,  1.4004e-01, -1.0009e-01,\n          5.8771e-02,  1.3011e-02, -1.2958e-01, -3.1353e-02,  1.0103e-01,\n         -8.3338e-02, -9.3399e-03,  5.0011e-02, -1.2108e-02,  1.7649e-01,\n         -7.9874e-02,  3.3334e-02],\n        [-1.7329e-01, -1.6069e-01,  8.5158e-02, -2.3218e-02, -1.5197e-01,\n         -1.3079e-01,  6.7412e-02, -1.3727e-01, -5.1561e-02, -3.0982e-02,\n          1.9063e-02, -1.0416e-01,  3.3741e-03, -1.3558e-01,  1.3406e-01,\n          6.1120e-02, -1.4769e-01,  1.6959e-01,  6.4136e-02,  4.1356e-02,\n          1.4969e-01,  1.1250e-01, -6.6011e-02,  3.0622e-02, -5.5370e-02,\n          1.1986e-01,  1.3721e-01,  7.1003e-02,  7.0051e-02, -1.1817e-01,\n          1.6009e-01,  1.2879e-01],\n        [-7.9308e-02, -1.7673e-01,  7.8308e-02, -1.6709e-01,  7.2491e-02,\n          1.5577e-01, -9.9319e-02,  5.4789e-02,  8.9660e-02, -2.6083e-02,\n         -1.6612e-01,  1.2267e-01, -1.6156e-01,  2.0649e-02, -1.1619e-01,\n         -5.0487e-03, -1.4282e-03, -4.5685e-02,  9.5438e-02,  1.4552e-01,\n         -1.2857e-01, -8.3410e-03, -3.9549e-02, -1.2783e-02, -5.3831e-02,\n         -1.7673e-01, -5.4061e-02,  9.2549e-02,  2.8174e-02, -4.9163e-03,\n          1.3501e-01, -5.3976e-02],\n        [ 1.7282e-02, -4.3849e-02,  7.1634e-02, -1.4152e-01,  1.0982e-01,\n         -7.3110e-02,  1.3751e-01,  1.4306e-01, -1.3833e-01, -6.0783e-02,\n          8.8712e-02, -5.4047e-02,  8.6192e-02, -9.8665e-02,  1.5757e-01,\n          8.8525e-02,  2.0506e-02, -1.2686e-01, -1.2710e-01, -5.5039e-02,\n         -1.3216e-02, -1.5885e-01,  1.0257e-01, -1.7181e-01, -3.1786e-02,\n          5.7615e-02,  1.7370e-01, -9.8355e-02, -1.2865e-01, -1.6706e-01,\n         -1.5110e-01,  1.4872e-01],\n        [-1.9152e-02, -1.0906e-01,  1.0051e-03, -1.9859e-02, -1.7070e-01,\n          6.3130e-02,  9.4468e-02, -9.6592e-02,  2.8210e-02, -7.9372e-02,\n          1.5915e-01, -1.6780e-01, -1.4947e-01,  1.4846e-01, -3.3320e-02,\n         -3.8464e-02,  1.6038e-01, -9.2667e-02, -2.3222e-02,  1.7230e-01,\n         -1.0123e-01,  1.2833e-02,  2.2287e-02,  7.7667e-02,  3.4802e-02,\n         -1.4806e-01,  6.8090e-02,  1.3785e-01,  1.7139e-01,  4.6980e-02,\n          1.3583e-01, -9.3628e-02],\n        [-1.0727e-01, -1.1326e-02,  5.4293e-02,  9.9007e-02, -1.4958e-01,\n          6.9659e-02, -4.0374e-03,  5.8753e-02,  5.4833e-02,  1.1110e-03,\n         -1.1236e-01, -7.0564e-02, -4.7100e-02, -1.5875e-01,  1.7436e-01,\n          1.4378e-01,  1.4823e-01,  1.0386e-01, -3.8033e-02,  1.6926e-01,\n         -9.8621e-02,  2.1215e-02, -2.4376e-02, -1.2672e-01,  1.3899e-01,\n          7.7653e-02, -9.9548e-02, -1.4236e-02, -1.6508e-01,  1.9309e-02,\n          1.7532e-01, -9.9994e-02],\n        [-1.3625e-01,  1.5398e-01,  3.0208e-03, -1.4224e-01, -5.9666e-03,\n         -1.3878e-01,  1.0427e-01,  9.8460e-02, -1.7761e-02, -3.4314e-02,\n          5.1432e-02,  1.4814e-01,  3.9610e-02,  1.6128e-01,  4.0223e-02,\n          9.8578e-02,  7.3362e-02, -1.2101e-01,  7.6444e-03,  2.2719e-02,\n         -1.0716e-01,  1.5870e-01, -1.3307e-02, -1.2403e-01,  1.4405e-01,\n         -1.2756e-01, -1.4140e-01,  1.6338e-01, -8.3228e-02,  1.3640e-01,\n         -1.6385e-01, -7.0318e-02],\n        [ 7.6430e-02,  7.6146e-02,  1.8130e-02,  1.6698e-01, -1.6340e-01,\n         -7.4352e-02,  3.3461e-02,  1.2605e-01, -1.4853e-01, -7.2946e-02,\n          8.0761e-02,  1.3270e-01,  2.0828e-02,  1.1337e-02,  8.2797e-02,\n         -8.6798e-02,  4.3022e-02,  1.2902e-01, -3.3021e-02,  6.9039e-02,\n          1.6975e-01,  8.6192e-02, -1.7675e-01,  1.3002e-01, -1.5319e-01,\n         -1.2768e-01, -5.7987e-02, -7.0933e-02, -3.1508e-02, -1.2383e-01,\n          1.4987e-01,  9.3680e-02],\n        [ 1.3988e-02,  9.0992e-02,  1.0088e-01, -1.3796e-01, -8.5481e-02,\n         -3.0821e-02, -1.3454e-01,  9.0026e-02,  1.6461e-01, -1.1067e-01,\n          1.6132e-01,  2.4187e-02,  2.2452e-02, -1.4169e-01, -4.8117e-02,\n          1.4089e-02, -1.6065e-01,  6.6376e-02,  2.2632e-02, -1.3609e-01,\n          7.5695e-02,  2.7705e-03,  8.9977e-02,  1.1839e-01, -1.0337e-01,\n         -1.0248e-01,  3.8270e-02, -6.7104e-02,  1.8566e-02,  4.3876e-02,\n          1.4997e-01,  1.5442e-01],\n        [-1.4797e-01, -5.8304e-02,  4.2190e-02, -1.3723e-01, -1.5374e-01,\n          1.1023e-01, -6.0492e-02,  1.9855e-02,  7.1640e-02,  7.9678e-02,\n          8.3859e-02, -3.0575e-02, -1.2372e-01, -1.1617e-01, -1.7182e-01,\n          7.9526e-02, -1.2109e-04,  1.2483e-01, -9.3802e-04, -2.3402e-02,\n          8.5239e-02,  2.7072e-02,  2.1575e-02,  5.3059e-02, -5.9389e-02,\n         -5.3725e-02, -9.0690e-02,  1.3333e-01, -1.4345e-01, -4.6119e-02,\n         -6.3128e-02,  3.7910e-03],\n        [ 9.0102e-02, -1.2197e-01,  8.3289e-02,  7.8684e-03, -2.2161e-03,\n          2.7171e-02,  5.6931e-02,  2.3437e-02,  1.2462e-01,  1.1686e-01,\n         -1.4728e-01,  3.7807e-02, -1.7166e-01,  1.2005e-01,  7.1370e-02,\n          1.0137e-01, -1.2282e-01,  1.2317e-01, -4.2860e-02,  1.7234e-01,\n         -1.3577e-01, -1.3316e-01,  1.4201e-01,  1.5141e-01, -1.0979e-02,\n          1.3905e-01,  1.4085e-01,  3.0196e-02, -9.0419e-02, -2.2854e-02,\n          3.4779e-02,  1.0452e-01],\n        [-4.2689e-02, -1.3874e-01, -7.9986e-02,  1.2479e-01,  2.8717e-02,\n          1.2399e-01,  1.4877e-01, -1.2027e-01, -6.4486e-02,  2.2843e-02,\n          8.2055e-02,  4.8359e-02, -1.0561e-01, -3.4038e-02, -7.9954e-02,\n          2.3543e-02, -1.7640e-01, -8.5762e-02,  5.4661e-02,  4.5044e-02,\n         -4.9619e-02,  4.8716e-02,  5.2728e-02, -3.3773e-02,  1.4320e-01,\n          1.6736e-01, -9.1924e-04, -4.7581e-02, -5.6397e-02,  1.2241e-01,\n          3.0090e-02,  2.0188e-02],\n        [-2.2310e-04, -1.5971e-01, -9.6108e-02, -5.6988e-02, -6.4008e-02,\n         -3.9182e-02, -1.0674e-01, -1.0989e-02, -2.7891e-02, -8.3654e-02,\n          9.7527e-02, -7.4768e-02, -2.8078e-02, -4.5801e-02,  1.4384e-01,\n         -1.4683e-01, -1.0502e-01, -1.5467e-01,  5.9948e-02,  8.8606e-02,\n         -1.5294e-01,  1.7030e-02, -9.0759e-03, -1.3906e-02, -8.4457e-02,\n          1.0532e-01,  1.6001e-01,  9.3857e-02, -2.3646e-02, -1.6450e-01,\n          1.1577e-01, -2.8458e-02],\n        [ 3.0314e-03,  3.4983e-02, -8.5013e-02,  1.0201e-01, -1.6968e-01,\n          1.4206e-01,  9.0216e-02,  1.3130e-01, -1.1929e-01, -6.2976e-02,\n         -3.0935e-03,  1.4081e-01,  1.4626e-01, -2.9495e-02,  6.4559e-02,\n          1.2725e-01,  7.2093e-02,  1.4685e-01,  3.8613e-02, -2.4944e-02,\n         -1.5748e-01, -1.0012e-01, -1.0007e-01, -5.0272e-02,  3.9050e-02,\n          1.1750e-01,  6.5722e-02,  1.5017e-01, -1.6406e-01,  4.6943e-03,\n          1.2344e-01, -9.3775e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1307,  0.0590, -0.1302, -0.0043, -0.0766, -0.0328,  0.1624, -0.0481,\n        -0.1666,  0.0406, -0.0087,  0.1131, -0.1510, -0.0134, -0.0795,  0.1197],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-2.4860e-01,  2.2262e-01,  6.3728e-02,  9.8102e-02,  2.2664e-01,\n          1.8608e-01, -1.9943e-01,  2.3064e-01, -2.1745e-01,  1.3269e-01,\n         -1.8085e-01,  9.8335e-02, -2.1838e-01,  1.0507e-01,  9.5451e-02,\n          1.0889e-01],\n        [ 2.2642e-01,  7.8300e-02, -2.2453e-01, -1.6781e-01, -1.9200e-01,\n          1.9845e-01,  1.0993e-01,  4.7704e-02,  3.8931e-02,  1.5286e-01,\n          2.7707e-02,  1.3913e-01, -6.6678e-02,  1.5663e-01,  6.9296e-02,\n          5.1018e-02],\n        [ 4.9503e-02, -9.2557e-02,  8.2478e-02,  6.5142e-02,  1.9548e-01,\n          2.3928e-01, -1.7736e-01, -1.5671e-02, -2.3065e-02, -1.3536e-01,\n         -1.7628e-01, -6.9320e-02,  1.1780e-01,  1.7624e-01,  8.9789e-02,\n          9.9729e-02],\n        [-1.2364e-01,  3.9811e-02,  1.3422e-02, -1.9706e-01, -2.0764e-01,\n         -1.1496e-01, -1.6490e-02,  1.9941e-01, -7.8410e-02, -1.7074e-01,\n          1.9691e-01,  4.4769e-02,  1.7886e-01,  8.8740e-02,  1.6333e-01,\n          2.1655e-01],\n        [ 1.5509e-01,  2.0230e-01, -8.9798e-02,  7.7674e-02,  1.5011e-01,\n          4.8548e-03, -2.4528e-01,  2.3147e-01, -2.2681e-01,  8.3004e-02,\n         -2.0258e-01, -8.9929e-02,  1.1258e-01,  2.2251e-01, -9.8907e-02,\n          1.0871e-01],\n        [-4.6241e-02, -9.6096e-02, -2.4947e-01,  2.4511e-01, -6.0828e-02,\n          8.7618e-02, -7.8321e-05, -7.3640e-02, -9.8971e-02,  9.9631e-03,\n         -7.9414e-02,  4.3578e-02,  1.3098e-01, -5.5716e-02,  2.4349e-01,\n          1.2463e-01],\n        [ 1.7769e-01,  1.4841e-01,  1.3114e-01, -2.3589e-01,  6.3578e-02,\n          1.5513e-01,  1.5196e-01,  1.8173e-01,  3.8303e-03, -1.8071e-01,\n          1.8870e-01, -1.7548e-01,  1.1814e-01, -6.5700e-02,  1.3013e-01,\n         -9.9545e-02],\n        [ 2.1331e-01,  1.5626e-01,  5.4617e-02,  1.1249e-01, -1.1310e-01,\n          2.4677e-02,  2.2888e-01,  1.6674e-01,  2.2807e-02,  4.6975e-02,\n         -2.3692e-01,  7.6210e-02,  1.8196e-01, -1.6989e-02, -2.4109e-01,\n          2.2621e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0818,  0.0783,  0.2335, -0.0143, -0.0861, -0.1004, -0.2022, -0.2308],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2453,  0.2193, -0.1564, -0.0255,  0.1944,  0.0623, -0.0633, -0.0857]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1800], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x1035afe80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x16ac4e590>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s180530000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s180530000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}