{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s184280000"
    },
    "q_lr":	0.0005,
    "seed":	184280000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000001C5CB6AD090>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0415,  0.2094,  0.2568,  0.3376,  0.0821,  0.2399,  0.1184, -0.1340,\n         0.1268, -0.1260,  0.3233, -0.0882,  0.0648,  0.2996, -0.2945, -0.2270,\n         0.1940, -0.3173, -0.2839,  0.2638, -0.1621, -0.0762, -0.1350,  0.0054,\n         0.1615,  0.2258,  0.2687,  0.2360, -0.1789, -0.0026, -0.1395, -0.1962],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.5961e-02,  9.2515e-02, -2.6739e-01, -3.3717e-01,  3.0071e-01,\n         -2.3818e-01, -7.5130e-03,  3.4405e-01],\n        [ 1.8778e-01, -8.7924e-02, -5.1601e-02, -2.2489e-01, -2.6321e-01,\n         -2.4182e-01, -1.1997e-01, -1.3794e-01],\n        [-9.0623e-02,  3.1667e-01,  1.4735e-01, -1.9036e-01, -2.3816e-01,\n          3.0978e-01, -4.3979e-03, -9.4879e-02],\n        [ 2.7314e-01, -1.7669e-01,  3.1645e-01,  1.3590e-01, -1.0779e-01,\n          3.3477e-01, -2.4767e-01,  1.8879e-01],\n        [ 1.7581e-01,  3.4062e-01, -2.6525e-01, -2.6172e-01, -2.3768e-01,\n          3.0750e-01, -4.6153e-02,  3.3096e-01],\n        [ 2.0115e-01, -2.0507e-01,  1.4355e-01,  2.0276e-01,  1.5989e-01,\n          2.6937e-01, -1.5460e-01, -2.7792e-01],\n        [ 1.1686e-01, -2.8566e-01, -4.6860e-02, -1.1976e-01,  3.4334e-02,\n          1.6805e-01,  1.6864e-01,  8.4695e-02],\n        [ 2.7650e-01,  1.2097e-01,  1.1906e-01, -2.3590e-01, -3.0516e-01,\n          9.1093e-02,  3.4408e-01,  3.2383e-01],\n        [ 2.5617e-01,  1.6094e-02, -8.7026e-02,  6.9539e-02,  3.1517e-01,\n         -1.7660e-01,  3.4721e-01,  1.3180e-01],\n        [ 1.1138e-01, -1.7602e-01, -1.8337e-01, -1.1436e-01,  1.9317e-01,\n          2.3856e-01, -3.0991e-01,  1.5555e-01],\n        [ 2.3984e-01,  4.6793e-02, -3.1378e-01,  2.9336e-02, -3.7566e-02,\n          9.1239e-03, -2.9636e-01, -7.8712e-02],\n        [-2.7860e-01,  2.2420e-01,  2.8202e-01, -2.9079e-01,  2.8629e-01,\n         -2.9405e-01, -1.7904e-02,  2.9750e-01],\n        [-2.2203e-01, -5.6330e-02, -2.7730e-01,  1.5467e-01, -2.0445e-02,\n          2.9146e-01,  3.3948e-04, -1.5950e-01],\n        [-4.4054e-02, -2.5346e-01, -3.0242e-01,  1.7853e-01, -2.6200e-01,\n          2.7808e-01,  1.6049e-01,  4.8267e-02],\n        [-1.1221e-01,  3.4750e-01,  3.2288e-01,  3.2923e-01, -1.1367e-01,\n          6.8868e-02, -8.8971e-03,  2.7718e-01],\n        [ 2.7231e-01,  2.1820e-01,  1.6042e-01,  1.5547e-01, -1.5968e-02,\n          1.1163e-01, -2.6090e-01, -2.4271e-01],\n        [-1.9708e-01, -2.9278e-01,  6.9187e-02,  2.1690e-01, -2.3001e-01,\n          3.3261e-01,  3.2836e-01, -1.1229e-01],\n        [-2.7566e-01,  8.7619e-02,  1.5378e-01,  3.9270e-02, -1.2986e-01,\n         -3.4353e-01, -2.3993e-01,  1.9999e-02],\n        [-3.9887e-02,  1.6460e-01, -1.2763e-01,  3.0797e-01, -2.4984e-01,\n         -6.8799e-02, -1.2039e-01,  1.5247e-01],\n        [-1.4743e-02, -1.6378e-01, -5.3352e-02, -2.0058e-02, -1.5739e-02,\n          2.2165e-01, -9.7135e-02, -1.0573e-01],\n        [-3.7875e-02,  1.1136e-02, -2.9921e-01, -4.3051e-02, -3.4202e-01,\n         -2.2898e-01, -1.0912e-01,  3.4557e-01],\n        [-6.4435e-03,  2.5799e-01,  2.6673e-01, -1.6606e-02,  3.4515e-01,\n         -1.8061e-01,  1.1260e-01,  3.3215e-01],\n        [ 4.8375e-02, -1.1353e-01, -2.5837e-01,  1.4825e-02,  2.8137e-01,\n          3.2610e-01, -1.2000e-02, -3.3351e-01],\n        [-1.8289e-02,  3.2853e-01,  3.1102e-01,  1.2248e-01,  6.3575e-02,\n          1.4421e-01, -2.1732e-01,  1.3179e-01],\n        [-1.7858e-01, -1.9453e-01,  1.3048e-01,  8.7143e-02,  2.1909e-02,\n         -1.4433e-01, -8.9940e-02,  3.3063e-01],\n        [-4.4387e-02,  3.4504e-01, -1.0371e-01,  6.5190e-02, -1.9308e-01,\n          3.1361e-01, -2.6725e-01, -3.2592e-01],\n        [-3.0169e-01, -3.9083e-02, -2.2273e-01, -1.1866e-01,  1.7452e-01,\n          6.9585e-02, -2.4654e-01,  2.5653e-01],\n        [ 4.8489e-03, -1.4261e-01, -2.0363e-01, -3.2612e-01,  6.2480e-02,\n          2.8373e-01, -2.4775e-01, -2.8074e-01],\n        [ 1.5579e-01, -5.3216e-02, -2.5084e-01,  3.1504e-01,  1.8605e-02,\n         -1.3174e-01, -5.6167e-02,  1.6552e-01],\n        [ 9.8954e-02,  8.5155e-02,  8.4394e-02, -3.2758e-01, -3.0633e-02,\n          1.5198e-01, -1.5591e-01, -2.3977e-03],\n        [-2.8749e-01, -6.1824e-02,  9.0777e-02,  3.0268e-01,  6.1304e-03,\n          3.3628e-01, -5.4540e-02,  9.3709e-03],\n        [ 1.6783e-01, -2.9026e-01,  2.1896e-01, -1.7804e-02, -2.5688e-01,\n          2.2915e-01, -5.6405e-02, -2.6104e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0903,  0.0519, -0.0592, -0.1250, -0.1142, -0.0104,  0.0613,  0.1076,\n        -0.0954,  0.1533,  0.0260,  0.0295, -0.0836,  0.1121,  0.0380,  0.1457],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 5.8400e-02, -7.7493e-02, -9.2432e-02,  6.4562e-02, -1.0139e-01,\n         -3.7020e-02, -4.4576e-02,  1.4087e-01, -1.2851e-01, -6.8322e-02,\n         -4.7150e-02,  8.8888e-02,  1.0959e-01,  1.2047e-01,  6.7420e-02,\n         -1.5433e-01,  1.1661e-01,  7.3403e-02,  4.8295e-02, -5.0183e-02,\n          9.0541e-02, -8.2117e-02,  9.8345e-02, -4.4113e-03,  1.1535e-01,\n          1.1695e-01,  1.3531e-01, -4.9352e-02, -3.8795e-02,  1.6616e-01,\n          1.6331e-02,  1.3801e-01],\n        [ 1.3607e-02,  1.1024e-01,  2.6141e-02, -1.3893e-02,  3.7954e-02,\n          3.4978e-02,  1.6340e-01,  6.3065e-02,  8.6048e-02, -6.7577e-02,\n         -1.5027e-01, -1.7094e-02, -3.5694e-02,  1.7445e-01,  1.1635e-01,\n          3.8186e-02,  1.1710e-01,  6.0390e-02, -7.5589e-03,  1.0005e-01,\n         -1.5636e-01,  4.2355e-03, -1.5775e-01,  3.2691e-02,  4.1696e-02,\n          1.4697e-01, -1.7532e-01, -1.0482e-01,  1.4824e-02,  1.7632e-01,\n         -1.7569e-01,  1.1957e-01],\n        [-8.6117e-02,  1.8693e-02,  6.8770e-04,  1.0403e-01, -3.9245e-02,\n          8.1567e-02,  1.6268e-01, -5.6286e-02,  6.1689e-02,  1.1595e-01,\n         -1.6140e-01, -1.4452e-01,  1.7339e-01, -1.0574e-01,  4.8838e-02,\n         -1.1470e-01, -4.4699e-02, -1.4415e-01,  6.2715e-02,  7.1594e-02,\n          8.0146e-02, -1.2893e-01, -5.6509e-02,  4.0492e-02, -1.9048e-02,\n         -9.1209e-02, -1.7480e-01,  4.4684e-02, -6.3270e-02,  1.4248e-01,\n         -4.0837e-03, -1.5854e-01],\n        [ 1.4411e-01,  3.4679e-02,  4.1135e-02,  3.5485e-02, -1.4938e-01,\n          1.7363e-02, -1.2159e-01, -5.4739e-02, -8.9900e-02,  1.7590e-01,\n         -5.5330e-02,  9.1692e-02,  3.1336e-02,  1.8660e-03,  1.0211e-01,\n          1.7596e-01,  4.9366e-02, -9.2866e-02, -4.5488e-03,  1.5698e-01,\n         -7.1936e-03,  1.2209e-01,  8.3012e-02, -1.0424e-01, -1.5585e-01,\n          1.1775e-01, -4.7986e-03,  9.3868e-02,  1.3410e-01, -5.6343e-02,\n          1.7173e-01, -4.0911e-02],\n        [ 2.0052e-02, -1.5500e-01, -5.2173e-02,  1.4385e-02,  6.5079e-02,\n          8.6390e-02, -5.7880e-02,  2.9530e-02, -1.1725e-01,  1.0237e-01,\n          1.5324e-01,  3.3741e-02,  1.6089e-01, -4.0559e-02, -1.2117e-02,\n         -8.5355e-02, -1.0955e-01,  6.0618e-02,  7.2038e-02, -5.4939e-02,\n         -2.1328e-02,  1.7404e-01, -6.7969e-03, -1.2332e-01,  1.6689e-01,\n          1.4138e-01, -1.7175e-01,  3.9071e-03,  7.7164e-03, -7.8594e-02,\n          8.0555e-02,  1.1314e-01],\n        [-5.2030e-02,  1.6135e-01,  1.4025e-01,  8.3568e-02,  1.6147e-01,\n         -1.6337e-01,  8.8847e-02, -1.6317e-01, -3.5493e-02, -1.4749e-01,\n          1.0110e-01,  1.3098e-01, -8.8654e-02,  1.6587e-01, -7.5206e-03,\n          5.7939e-02, -2.1958e-02,  1.4169e-01,  9.7904e-03,  6.6917e-02,\n         -7.6083e-02,  8.9574e-02,  1.7263e-01,  1.4421e-01, -7.8342e-02,\n         -5.3751e-02, -3.7835e-02,  7.5894e-02, -1.0691e-01, -1.5277e-01,\n         -1.1281e-01, -6.5183e-02],\n        [ 1.4158e-01,  1.5972e-01, -4.2090e-03,  5.4664e-02, -1.5920e-01,\n         -1.5152e-01, -1.0514e-01,  5.7128e-02,  1.5403e-01,  6.3643e-03,\n         -1.6538e-01, -6.6875e-02,  4.4055e-02, -8.3240e-02, -3.8984e-02,\n         -1.0337e-01, -3.6817e-02,  5.7646e-02,  1.0955e-01,  1.5263e-01,\n          6.0060e-02, -1.3160e-01, -1.6939e-01, -1.9071e-03, -6.5604e-02,\n         -1.6118e-01, -1.2017e-01,  6.0824e-02, -5.6952e-02, -1.1501e-01,\n         -8.0202e-02, -5.7714e-02],\n        [-6.8976e-02,  1.4343e-01,  1.7592e-01, -1.3439e-01,  2.3100e-02,\n          9.7203e-02, -1.7681e-03, -1.4469e-01, -9.4907e-02,  9.6737e-02,\n          5.1561e-02,  1.4377e-01,  2.0444e-02, -2.8862e-02, -1.5860e-01,\n         -9.9513e-02,  2.6038e-03,  1.6648e-01, -3.6258e-02, -7.2637e-02,\n          6.3847e-02, -1.0925e-01, -5.1255e-02, -2.7922e-02,  5.9185e-02,\n         -1.5875e-01, -1.2133e-01, -1.2659e-01,  2.4511e-02,  1.4263e-01,\n          9.9283e-03,  1.8679e-02],\n        [ 1.4992e-01,  7.8531e-02, -1.0759e-01, -1.6090e-01,  2.4780e-02,\n         -1.2570e-01, -6.3782e-02,  1.4777e-01, -1.5126e-01,  3.4476e-02,\n          1.3849e-01, -1.3840e-01, -6.0884e-02,  1.0915e-02, -1.5170e-01,\n          6.7100e-02, -1.5142e-01,  1.2183e-01,  2.1659e-02, -1.0456e-01,\n          1.3264e-01, -1.4465e-01, -1.1561e-01,  1.0193e-01,  5.8170e-02,\n         -1.5206e-01,  8.6501e-05, -1.4712e-01, -1.1950e-01,  1.4111e-01,\n         -1.5172e-02, -1.2137e-01],\n        [-2.0061e-02, -2.0625e-02,  1.5939e-01,  5.0444e-02, -2.1875e-02,\n          1.0798e-03, -2.2221e-02, -1.5533e-01, -2.9924e-02, -6.7558e-02,\n         -7.5419e-02, -1.5441e-01, -1.4534e-01,  1.0504e-01,  1.5975e-02,\n         -1.0950e-01,  5.2474e-02, -4.7456e-02,  1.4218e-02, -5.3333e-02,\n         -3.0970e-02, -5.4391e-02, -6.7218e-02,  1.3895e-01,  1.6975e-01,\n          1.2966e-01, -1.0116e-01,  4.7741e-02,  1.5667e-01,  2.3566e-02,\n          4.1172e-02, -1.4164e-01],\n        [ 3.8404e-02,  6.3643e-02,  7.7547e-02, -1.1628e-01, -1.5842e-01,\n         -5.8376e-02, -6.8698e-02, -8.0155e-02,  9.7216e-02, -3.6851e-05,\n         -6.6887e-02, -9.3513e-02,  8.5799e-03, -1.7163e-01, -8.7623e-02,\n          1.3399e-01, -5.4985e-02,  7.9098e-02,  7.8788e-02, -7.1719e-02,\n          1.2307e-01, -9.3975e-02,  1.6388e-01,  1.0563e-01,  1.4278e-01,\n         -5.4452e-02,  9.2350e-02,  6.6267e-02,  1.3441e-02,  3.0114e-04,\n          1.3443e-01, -7.1007e-02],\n        [ 4.2095e-02,  1.4241e-01, -8.1756e-02,  1.4094e-01,  1.0648e-01,\n          1.0870e-01, -1.3494e-01, -1.6019e-01,  1.2031e-01,  8.3821e-02,\n          8.3353e-02,  1.5647e-01,  1.1650e-02, -1.4377e-01, -6.7776e-02,\n          1.4828e-01,  7.4164e-02, -9.5684e-02,  7.3764e-02,  1.3236e-01,\n          1.8748e-02,  1.6249e-01, -1.1195e-01, -4.3870e-02, -1.1083e-01,\n          8.8378e-02,  1.2001e-02,  6.2994e-03, -1.1426e-01,  1.3057e-01,\n          1.3151e-01, -1.6484e-01],\n        [ 1.6009e-01,  8.6201e-02,  1.0314e-01, -1.4456e-01,  1.6210e-01,\n          3.2370e-02,  1.5982e-01,  3.2551e-02,  1.3014e-01,  9.5496e-02,\n          5.1727e-02, -8.3792e-04, -1.2572e-01, -6.4643e-02, -9.4265e-02,\n         -1.4338e-01, -1.4230e-01, -5.8485e-02,  5.8984e-02, -3.5629e-02,\n          2.2649e-02, -4.4282e-02,  4.1204e-02,  7.5713e-02,  9.8380e-02,\n          1.4378e-02, -3.4044e-03,  1.0630e-01, -7.3577e-02, -3.6924e-02,\n         -1.3173e-01, -5.6444e-02],\n        [ 6.5685e-02,  5.9984e-02,  7.4366e-02, -6.4401e-02, -5.1452e-02,\n          1.3710e-01,  1.7308e-01, -4.4980e-02,  3.0538e-02,  6.9348e-02,\n         -4.4753e-02,  8.0335e-02,  1.7527e-01,  1.0075e-01,  1.2530e-01,\n          3.9561e-02, -1.0505e-01,  4.2713e-02,  1.4676e-01, -7.5507e-02,\n         -1.2181e-01,  1.6515e-01,  9.4953e-02,  1.0244e-01,  1.7145e-01,\n         -1.9804e-02, -7.2367e-02, -7.8692e-02, -1.9711e-02, -1.4471e-01,\n         -1.6041e-01, -1.5715e-01],\n        [-1.2112e-01,  1.5341e-01, -1.7107e-01,  1.5684e-01,  6.9688e-04,\n          1.4013e-01,  6.1670e-02, -1.6215e-01, -1.7189e-01,  7.6003e-02,\n          1.2412e-01, -9.6800e-02,  1.3208e-01, -8.2236e-02,  3.8833e-02,\n         -1.4326e-01,  4.3166e-02, -2.8498e-02, -1.4524e-01, -6.8596e-02,\n         -1.5448e-01, -1.0675e-04,  1.5235e-01, -1.0620e-01, -1.1104e-01,\n         -6.3754e-02, -5.0011e-02,  1.7573e-01, -2.3287e-02,  1.0309e-01,\n          1.8393e-02,  9.6321e-02],\n        [-6.1157e-02, -1.2138e-01, -5.6278e-02, -4.0672e-02, -6.6837e-02,\n         -1.7570e-01,  6.8364e-02, -2.5337e-03,  1.0927e-01,  3.0734e-03,\n         -7.7376e-03, -6.0888e-02, -1.0307e-01,  1.5159e-01,  9.1348e-02,\n         -3.5000e-02, -1.6437e-01,  4.7276e-03,  1.4133e-01, -9.2266e-02,\n          1.3142e-01, -5.3147e-02, -1.7598e-01, -8.1075e-02, -5.2079e-02,\n         -1.4579e-01, -6.1311e-02, -1.2262e-01, -9.0952e-02, -2.0830e-03,\n         -4.2199e-03,  6.2900e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1393, -0.0744,  0.0927,  0.0445,  0.2209,  0.1114,  0.1871, -0.1654],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1934,  0.0417,  0.1811,  0.0918,  0.0508,  0.0416, -0.2109, -0.1072,\n         -0.2241,  0.0301,  0.2269,  0.1685, -0.1539, -0.1897,  0.1760,  0.1606],\n        [ 0.2237, -0.0337, -0.1181, -0.1264,  0.1780, -0.1829,  0.0713,  0.2452,\n         -0.0239,  0.1839,  0.2188, -0.2451,  0.1277, -0.2009,  0.0931,  0.2290],\n        [-0.0070, -0.0988, -0.0818, -0.2158,  0.2072, -0.0947,  0.0921,  0.1879,\n          0.1650, -0.1591,  0.1306, -0.2227, -0.2485,  0.0042, -0.2265, -0.1552],\n        [ 0.0277,  0.1322,  0.1419, -0.2268, -0.0903,  0.2349, -0.2247,  0.2121,\n          0.2205,  0.2200,  0.0412, -0.0113,  0.1557, -0.1504,  0.2168,  0.1497],\n        [ 0.2304, -0.1050, -0.2452, -0.0961, -0.1588,  0.0464,  0.1823,  0.1374,\n          0.0775, -0.2012,  0.1555, -0.2101,  0.0691, -0.0122, -0.0868, -0.1376],\n        [-0.0153, -0.1138, -0.1304, -0.1951,  0.0774,  0.1871, -0.2096, -0.2453,\n         -0.1128, -0.1492,  0.0643,  0.2080,  0.1688,  0.1244,  0.1404,  0.0387],\n        [ 0.1286,  0.1351,  0.0623, -0.0667, -0.1120, -0.0484, -0.1670,  0.2260,\n         -0.1785,  0.1105,  0.2123,  0.2265, -0.2346, -0.0669,  0.0791, -0.0503],\n        [ 0.0520,  0.1745,  0.1135,  0.1629, -0.1476, -0.2029,  0.1591,  0.0443,\n          0.0032, -0.0072,  0.0114,  0.2130,  0.1438,  0.1366,  0.0165,  0.2295]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1774], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3496, -0.1829, -0.2651,  0.1106,  0.2793,  0.1291,  0.2478, -0.2335]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-8.5961e-02,  9.2515e-02, -2.6739e-01, -3.3717e-01,  3.0071e-01,\n         -2.3818e-01, -7.5130e-03,  3.4405e-01],\n        [ 1.8778e-01, -8.7924e-02, -5.1601e-02, -2.2489e-01, -2.6321e-01,\n         -2.4182e-01, -1.1997e-01, -1.3794e-01],\n        [-9.0623e-02,  3.1667e-01,  1.4735e-01, -1.9036e-01, -2.3816e-01,\n          3.0978e-01, -4.3979e-03, -9.4879e-02],\n        [ 2.7314e-01, -1.7669e-01,  3.1645e-01,  1.3590e-01, -1.0779e-01,\n          3.3477e-01, -2.4767e-01,  1.8879e-01],\n        [ 1.7581e-01,  3.4062e-01, -2.6525e-01, -2.6172e-01, -2.3768e-01,\n          3.0750e-01, -4.6153e-02,  3.3096e-01],\n        [ 2.0115e-01, -2.0507e-01,  1.4355e-01,  2.0276e-01,  1.5989e-01,\n          2.6937e-01, -1.5460e-01, -2.7792e-01],\n        [ 1.1686e-01, -2.8566e-01, -4.6860e-02, -1.1976e-01,  3.4334e-02,\n          1.6805e-01,  1.6864e-01,  8.4695e-02],\n        [ 2.7650e-01,  1.2097e-01,  1.1906e-01, -2.3590e-01, -3.0516e-01,\n          9.1093e-02,  3.4408e-01,  3.2383e-01],\n        [ 2.5617e-01,  1.6094e-02, -8.7026e-02,  6.9539e-02,  3.1517e-01,\n         -1.7660e-01,  3.4721e-01,  1.3180e-01],\n        [ 1.1138e-01, -1.7602e-01, -1.8337e-01, -1.1436e-01,  1.9317e-01,\n          2.3856e-01, -3.0991e-01,  1.5555e-01],\n        [ 2.3984e-01,  4.6793e-02, -3.1378e-01,  2.9336e-02, -3.7566e-02,\n          9.1239e-03, -2.9636e-01, -7.8712e-02],\n        [-2.7860e-01,  2.2420e-01,  2.8202e-01, -2.9079e-01,  2.8629e-01,\n         -2.9405e-01, -1.7904e-02,  2.9750e-01],\n        [-2.2203e-01, -5.6330e-02, -2.7730e-01,  1.5467e-01, -2.0445e-02,\n          2.9146e-01,  3.3948e-04, -1.5950e-01],\n        [-4.4054e-02, -2.5346e-01, -3.0242e-01,  1.7853e-01, -2.6200e-01,\n          2.7808e-01,  1.6049e-01,  4.8267e-02],\n        [-1.1221e-01,  3.4750e-01,  3.2288e-01,  3.2923e-01, -1.1367e-01,\n          6.8868e-02, -8.8971e-03,  2.7718e-01],\n        [ 2.7231e-01,  2.1820e-01,  1.6042e-01,  1.5547e-01, -1.5968e-02,\n          1.1163e-01, -2.6090e-01, -2.4271e-01],\n        [-1.9708e-01, -2.9278e-01,  6.9187e-02,  2.1690e-01, -2.3001e-01,\n          3.3261e-01,  3.2836e-01, -1.1229e-01],\n        [-2.7566e-01,  8.7619e-02,  1.5378e-01,  3.9270e-02, -1.2986e-01,\n         -3.4353e-01, -2.3993e-01,  1.9999e-02],\n        [-3.9887e-02,  1.6460e-01, -1.2763e-01,  3.0797e-01, -2.4984e-01,\n         -6.8799e-02, -1.2039e-01,  1.5247e-01],\n        [-1.4743e-02, -1.6378e-01, -5.3352e-02, -2.0058e-02, -1.5739e-02,\n          2.2165e-01, -9.7135e-02, -1.0573e-01],\n        [-3.7875e-02,  1.1136e-02, -2.9921e-01, -4.3051e-02, -3.4202e-01,\n         -2.2898e-01, -1.0912e-01,  3.4557e-01],\n        [-6.4435e-03,  2.5799e-01,  2.6673e-01, -1.6606e-02,  3.4515e-01,\n         -1.8061e-01,  1.1260e-01,  3.3215e-01],\n        [ 4.8375e-02, -1.1353e-01, -2.5837e-01,  1.4825e-02,  2.8137e-01,\n          3.2610e-01, -1.2000e-02, -3.3351e-01],\n        [-1.8289e-02,  3.2853e-01,  3.1102e-01,  1.2248e-01,  6.3575e-02,\n          1.4421e-01, -2.1732e-01,  1.3179e-01],\n        [-1.7858e-01, -1.9453e-01,  1.3048e-01,  8.7143e-02,  2.1909e-02,\n         -1.4433e-01, -8.9940e-02,  3.3063e-01],\n        [-4.4387e-02,  3.4504e-01, -1.0371e-01,  6.5190e-02, -1.9308e-01,\n          3.1361e-01, -2.6725e-01, -3.2592e-01],\n        [-3.0169e-01, -3.9083e-02, -2.2273e-01, -1.1866e-01,  1.7452e-01,\n          6.9585e-02, -2.4654e-01,  2.5653e-01],\n        [ 4.8489e-03, -1.4261e-01, -2.0363e-01, -3.2612e-01,  6.2480e-02,\n          2.8373e-01, -2.4775e-01, -2.8074e-01],\n        [ 1.5579e-01, -5.3216e-02, -2.5084e-01,  3.1504e-01,  1.8605e-02,\n         -1.3174e-01, -5.6167e-02,  1.6552e-01],\n        [ 9.8954e-02,  8.5155e-02,  8.4394e-02, -3.2758e-01, -3.0633e-02,\n          1.5198e-01, -1.5591e-01, -2.3977e-03],\n        [-2.8749e-01, -6.1824e-02,  9.0777e-02,  3.0268e-01,  6.1304e-03,\n          3.3628e-01, -5.4540e-02,  9.3709e-03],\n        [ 1.6783e-01, -2.9026e-01,  2.1896e-01, -1.7804e-02, -2.5688e-01,\n          2.2915e-01, -5.6405e-02, -2.6104e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0415,  0.2094,  0.2568,  0.3376,  0.0821,  0.2399,  0.1184, -0.1340,\n         0.1268, -0.1260,  0.3233, -0.0882,  0.0648,  0.2996, -0.2945, -0.2270,\n         0.1940, -0.3173, -0.2839,  0.2638, -0.1621, -0.0762, -0.1350,  0.0054,\n         0.1615,  0.2258,  0.2687,  0.2360, -0.1789, -0.0026, -0.1395, -0.1962],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 5.8400e-02, -7.7493e-02, -9.2432e-02,  6.4562e-02, -1.0139e-01,\n         -3.7020e-02, -4.4576e-02,  1.4087e-01, -1.2851e-01, -6.8322e-02,\n         -4.7150e-02,  8.8888e-02,  1.0959e-01,  1.2047e-01,  6.7420e-02,\n         -1.5433e-01,  1.1661e-01,  7.3403e-02,  4.8295e-02, -5.0183e-02,\n          9.0541e-02, -8.2117e-02,  9.8345e-02, -4.4113e-03,  1.1535e-01,\n          1.1695e-01,  1.3531e-01, -4.9352e-02, -3.8795e-02,  1.6616e-01,\n          1.6331e-02,  1.3801e-01],\n        [ 1.3607e-02,  1.1024e-01,  2.6141e-02, -1.3893e-02,  3.7954e-02,\n          3.4978e-02,  1.6340e-01,  6.3065e-02,  8.6048e-02, -6.7577e-02,\n         -1.5027e-01, -1.7094e-02, -3.5694e-02,  1.7445e-01,  1.1635e-01,\n          3.8186e-02,  1.1710e-01,  6.0390e-02, -7.5589e-03,  1.0005e-01,\n         -1.5636e-01,  4.2355e-03, -1.5775e-01,  3.2691e-02,  4.1696e-02,\n          1.4697e-01, -1.7532e-01, -1.0482e-01,  1.4824e-02,  1.7632e-01,\n         -1.7569e-01,  1.1957e-01],\n        [-8.6117e-02,  1.8693e-02,  6.8770e-04,  1.0403e-01, -3.9245e-02,\n          8.1567e-02,  1.6268e-01, -5.6286e-02,  6.1689e-02,  1.1595e-01,\n         -1.6140e-01, -1.4452e-01,  1.7339e-01, -1.0574e-01,  4.8838e-02,\n         -1.1470e-01, -4.4699e-02, -1.4415e-01,  6.2715e-02,  7.1594e-02,\n          8.0146e-02, -1.2893e-01, -5.6509e-02,  4.0492e-02, -1.9048e-02,\n         -9.1209e-02, -1.7480e-01,  4.4684e-02, -6.3270e-02,  1.4248e-01,\n         -4.0837e-03, -1.5854e-01],\n        [ 1.4411e-01,  3.4679e-02,  4.1135e-02,  3.5485e-02, -1.4938e-01,\n          1.7363e-02, -1.2159e-01, -5.4739e-02, -8.9900e-02,  1.7590e-01,\n         -5.5330e-02,  9.1692e-02,  3.1336e-02,  1.8660e-03,  1.0211e-01,\n          1.7596e-01,  4.9366e-02, -9.2866e-02, -4.5488e-03,  1.5698e-01,\n         -7.1936e-03,  1.2209e-01,  8.3012e-02, -1.0424e-01, -1.5585e-01,\n          1.1775e-01, -4.7986e-03,  9.3868e-02,  1.3410e-01, -5.6343e-02,\n          1.7173e-01, -4.0911e-02],\n        [ 2.0052e-02, -1.5500e-01, -5.2173e-02,  1.4385e-02,  6.5079e-02,\n          8.6390e-02, -5.7880e-02,  2.9530e-02, -1.1725e-01,  1.0237e-01,\n          1.5324e-01,  3.3741e-02,  1.6089e-01, -4.0559e-02, -1.2117e-02,\n         -8.5355e-02, -1.0955e-01,  6.0618e-02,  7.2038e-02, -5.4939e-02,\n         -2.1328e-02,  1.7404e-01, -6.7969e-03, -1.2332e-01,  1.6689e-01,\n          1.4138e-01, -1.7175e-01,  3.9071e-03,  7.7164e-03, -7.8594e-02,\n          8.0555e-02,  1.1314e-01],\n        [-5.2030e-02,  1.6135e-01,  1.4025e-01,  8.3568e-02,  1.6147e-01,\n         -1.6337e-01,  8.8847e-02, -1.6317e-01, -3.5493e-02, -1.4749e-01,\n          1.0110e-01,  1.3098e-01, -8.8654e-02,  1.6587e-01, -7.5206e-03,\n          5.7939e-02, -2.1958e-02,  1.4169e-01,  9.7904e-03,  6.6917e-02,\n         -7.6083e-02,  8.9574e-02,  1.7263e-01,  1.4421e-01, -7.8342e-02,\n         -5.3751e-02, -3.7835e-02,  7.5894e-02, -1.0691e-01, -1.5277e-01,\n         -1.1281e-01, -6.5183e-02],\n        [ 1.4158e-01,  1.5972e-01, -4.2090e-03,  5.4664e-02, -1.5920e-01,\n         -1.5152e-01, -1.0514e-01,  5.7128e-02,  1.5403e-01,  6.3643e-03,\n         -1.6538e-01, -6.6875e-02,  4.4055e-02, -8.3240e-02, -3.8984e-02,\n         -1.0337e-01, -3.6817e-02,  5.7646e-02,  1.0955e-01,  1.5263e-01,\n          6.0060e-02, -1.3160e-01, -1.6939e-01, -1.9071e-03, -6.5604e-02,\n         -1.6118e-01, -1.2017e-01,  6.0824e-02, -5.6952e-02, -1.1501e-01,\n         -8.0202e-02, -5.7714e-02],\n        [-6.8976e-02,  1.4343e-01,  1.7592e-01, -1.3439e-01,  2.3100e-02,\n          9.7203e-02, -1.7681e-03, -1.4469e-01, -9.4907e-02,  9.6737e-02,\n          5.1561e-02,  1.4377e-01,  2.0444e-02, -2.8862e-02, -1.5860e-01,\n         -9.9513e-02,  2.6038e-03,  1.6648e-01, -3.6258e-02, -7.2637e-02,\n          6.3847e-02, -1.0925e-01, -5.1255e-02, -2.7922e-02,  5.9185e-02,\n         -1.5875e-01, -1.2133e-01, -1.2659e-01,  2.4511e-02,  1.4263e-01,\n          9.9283e-03,  1.8679e-02],\n        [ 1.4992e-01,  7.8531e-02, -1.0759e-01, -1.6090e-01,  2.4780e-02,\n         -1.2570e-01, -6.3782e-02,  1.4777e-01, -1.5126e-01,  3.4476e-02,\n          1.3849e-01, -1.3840e-01, -6.0884e-02,  1.0915e-02, -1.5170e-01,\n          6.7100e-02, -1.5142e-01,  1.2183e-01,  2.1659e-02, -1.0456e-01,\n          1.3264e-01, -1.4465e-01, -1.1561e-01,  1.0193e-01,  5.8170e-02,\n         -1.5206e-01,  8.6501e-05, -1.4712e-01, -1.1950e-01,  1.4111e-01,\n         -1.5172e-02, -1.2137e-01],\n        [-2.0061e-02, -2.0625e-02,  1.5939e-01,  5.0444e-02, -2.1875e-02,\n          1.0798e-03, -2.2221e-02, -1.5533e-01, -2.9924e-02, -6.7558e-02,\n         -7.5419e-02, -1.5441e-01, -1.4534e-01,  1.0504e-01,  1.5975e-02,\n         -1.0950e-01,  5.2474e-02, -4.7456e-02,  1.4218e-02, -5.3333e-02,\n         -3.0970e-02, -5.4391e-02, -6.7218e-02,  1.3895e-01,  1.6975e-01,\n          1.2966e-01, -1.0116e-01,  4.7741e-02,  1.5667e-01,  2.3566e-02,\n          4.1172e-02, -1.4164e-01],\n        [ 3.8404e-02,  6.3643e-02,  7.7547e-02, -1.1628e-01, -1.5842e-01,\n         -5.8376e-02, -6.8698e-02, -8.0155e-02,  9.7216e-02, -3.6851e-05,\n         -6.6887e-02, -9.3513e-02,  8.5799e-03, -1.7163e-01, -8.7623e-02,\n          1.3399e-01, -5.4985e-02,  7.9098e-02,  7.8788e-02, -7.1719e-02,\n          1.2307e-01, -9.3975e-02,  1.6388e-01,  1.0563e-01,  1.4278e-01,\n         -5.4452e-02,  9.2350e-02,  6.6267e-02,  1.3441e-02,  3.0114e-04,\n          1.3443e-01, -7.1007e-02],\n        [ 4.2095e-02,  1.4241e-01, -8.1756e-02,  1.4094e-01,  1.0648e-01,\n          1.0870e-01, -1.3494e-01, -1.6019e-01,  1.2031e-01,  8.3821e-02,\n          8.3353e-02,  1.5647e-01,  1.1650e-02, -1.4377e-01, -6.7776e-02,\n          1.4828e-01,  7.4164e-02, -9.5684e-02,  7.3764e-02,  1.3236e-01,\n          1.8748e-02,  1.6249e-01, -1.1195e-01, -4.3870e-02, -1.1083e-01,\n          8.8378e-02,  1.2001e-02,  6.2994e-03, -1.1426e-01,  1.3057e-01,\n          1.3151e-01, -1.6484e-01],\n        [ 1.6009e-01,  8.6201e-02,  1.0314e-01, -1.4456e-01,  1.6210e-01,\n          3.2370e-02,  1.5982e-01,  3.2551e-02,  1.3014e-01,  9.5496e-02,\n          5.1727e-02, -8.3792e-04, -1.2572e-01, -6.4643e-02, -9.4265e-02,\n         -1.4338e-01, -1.4230e-01, -5.8485e-02,  5.8984e-02, -3.5629e-02,\n          2.2649e-02, -4.4282e-02,  4.1204e-02,  7.5713e-02,  9.8380e-02,\n          1.4378e-02, -3.4044e-03,  1.0630e-01, -7.3577e-02, -3.6924e-02,\n         -1.3173e-01, -5.6444e-02],\n        [ 6.5685e-02,  5.9984e-02,  7.4366e-02, -6.4401e-02, -5.1452e-02,\n          1.3710e-01,  1.7308e-01, -4.4980e-02,  3.0538e-02,  6.9348e-02,\n         -4.4753e-02,  8.0335e-02,  1.7527e-01,  1.0075e-01,  1.2530e-01,\n          3.9561e-02, -1.0505e-01,  4.2713e-02,  1.4676e-01, -7.5507e-02,\n         -1.2181e-01,  1.6515e-01,  9.4953e-02,  1.0244e-01,  1.7145e-01,\n         -1.9804e-02, -7.2367e-02, -7.8692e-02, -1.9711e-02, -1.4471e-01,\n         -1.6041e-01, -1.5715e-01],\n        [-1.2112e-01,  1.5341e-01, -1.7107e-01,  1.5684e-01,  6.9688e-04,\n          1.4013e-01,  6.1670e-02, -1.6215e-01, -1.7189e-01,  7.6003e-02,\n          1.2412e-01, -9.6800e-02,  1.3208e-01, -8.2236e-02,  3.8833e-02,\n         -1.4326e-01,  4.3166e-02, -2.8498e-02, -1.4524e-01, -6.8596e-02,\n         -1.5448e-01, -1.0675e-04,  1.5235e-01, -1.0620e-01, -1.1104e-01,\n         -6.3754e-02, -5.0011e-02,  1.7573e-01, -2.3287e-02,  1.0309e-01,\n          1.8393e-02,  9.6321e-02],\n        [-6.1157e-02, -1.2138e-01, -5.6278e-02, -4.0672e-02, -6.6837e-02,\n         -1.7570e-01,  6.8364e-02, -2.5337e-03,  1.0927e-01,  3.0734e-03,\n         -7.7376e-03, -6.0888e-02, -1.0307e-01,  1.5159e-01,  9.1348e-02,\n         -3.5000e-02, -1.6437e-01,  4.7276e-03,  1.4133e-01, -9.2266e-02,\n          1.3142e-01, -5.3147e-02, -1.7598e-01, -8.1075e-02, -5.2079e-02,\n         -1.4579e-01, -6.1311e-02, -1.2262e-01, -9.0952e-02, -2.0830e-03,\n         -4.2199e-03,  6.2900e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0903,  0.0519, -0.0592, -0.1250, -0.1142, -0.0104,  0.0613,  0.1076,\n        -0.0954,  0.1533,  0.0260,  0.0295, -0.0836,  0.1121,  0.0380,  0.1457],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1934,  0.0417,  0.1811,  0.0918,  0.0508,  0.0416, -0.2109, -0.1072,\n         -0.2241,  0.0301,  0.2269,  0.1685, -0.1539, -0.1897,  0.1760,  0.1606],\n        [ 0.2237, -0.0337, -0.1181, -0.1264,  0.1780, -0.1829,  0.0713,  0.2452,\n         -0.0239,  0.1839,  0.2188, -0.2451,  0.1277, -0.2009,  0.0931,  0.2290],\n        [-0.0070, -0.0988, -0.0818, -0.2158,  0.2072, -0.0947,  0.0921,  0.1879,\n          0.1650, -0.1591,  0.1306, -0.2227, -0.2485,  0.0042, -0.2265, -0.1552],\n        [ 0.0277,  0.1322,  0.1419, -0.2268, -0.0903,  0.2349, -0.2247,  0.2121,\n          0.2205,  0.2200,  0.0412, -0.0113,  0.1557, -0.1504,  0.2168,  0.1497],\n        [ 0.2304, -0.1050, -0.2452, -0.0961, -0.1588,  0.0464,  0.1823,  0.1374,\n          0.0775, -0.2012,  0.1555, -0.2101,  0.0691, -0.0122, -0.0868, -0.1376],\n        [-0.0153, -0.1138, -0.1304, -0.1951,  0.0774,  0.1871, -0.2096, -0.2453,\n         -0.1128, -0.1492,  0.0643,  0.2080,  0.1688,  0.1244,  0.1404,  0.0387],\n        [ 0.1286,  0.1351,  0.0623, -0.0667, -0.1120, -0.0484, -0.1670,  0.2260,\n         -0.1785,  0.1105,  0.2123,  0.2265, -0.2346, -0.0669,  0.0791, -0.0503],\n        [ 0.0520,  0.1745,  0.1135,  0.1629, -0.1476, -0.2029,  0.1591,  0.0443,\n          0.0032, -0.0072,  0.0114,  0.2130,  0.1438,  0.1366,  0.0165,  0.2295]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1393, -0.0744,  0.0927,  0.0445,  0.2209,  0.1114,  0.1871, -0.1654],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3496, -0.1829, -0.2651,  0.1106,  0.2793,  0.1291,  0.2478, -0.2335]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1774], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000001C5FFC722F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001C5CB6AD270>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s184280000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s184280000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}