{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s184310000"
    },
    "q_lr":	0.0005,
    "seed":	184310000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x17a91a3e0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0029, -0.0436,  0.2882, -0.3064, -0.1571,  0.1085, -0.1895,  0.2737,\n         0.2476, -0.1338, -0.1043, -0.2027,  0.2358, -0.2908, -0.0513, -0.1571,\n        -0.1957,  0.3491,  0.1227, -0.1856,  0.0015,  0.2989, -0.0366, -0.0835,\n        -0.0451, -0.1467,  0.3385,  0.2197,  0.0234, -0.0195, -0.1789, -0.0841],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1615,  0.1119, -0.0811, -0.3456, -0.2980,  0.1752, -0.0875,  0.0051],\n        [ 0.1282, -0.0466, -0.3113,  0.2527, -0.3484, -0.2336,  0.2099, -0.1049],\n        [ 0.1531, -0.1614,  0.0391,  0.2022,  0.0815,  0.3093,  0.1309,  0.2500],\n        [-0.2274, -0.2891,  0.1918, -0.1537,  0.1994,  0.2676, -0.2537,  0.2140],\n        [-0.3397, -0.1838,  0.2605,  0.0494,  0.2153,  0.0891, -0.0102, -0.0371],\n        [ 0.2586, -0.1610,  0.1856,  0.1559,  0.0956,  0.1672, -0.1536, -0.0151],\n        [-0.2322, -0.1379,  0.0475,  0.0486, -0.2943,  0.2348,  0.2412,  0.3431],\n        [-0.0090, -0.2516, -0.2794,  0.2112, -0.3528,  0.1779, -0.2130, -0.2148],\n        [ 0.0139,  0.0621, -0.2678,  0.0112, -0.1443,  0.2897,  0.0807,  0.0713],\n        [ 0.2825,  0.1232, -0.2591,  0.3513, -0.0209,  0.2561,  0.1788, -0.2164],\n        [-0.3060, -0.1593,  0.0380,  0.0725, -0.1231, -0.1113,  0.0683, -0.2169],\n        [-0.0054, -0.0016,  0.0156, -0.1065, -0.1505, -0.1017, -0.0993, -0.1732],\n        [-0.3347, -0.2234,  0.1009,  0.1318,  0.2865, -0.1720, -0.1961,  0.3093],\n        [-0.1575,  0.1445,  0.2165,  0.2851,  0.1176,  0.2391, -0.2453, -0.1066],\n        [ 0.3313, -0.1012,  0.2375,  0.3158, -0.0436,  0.2488, -0.2796, -0.3404],\n        [ 0.1018, -0.2023,  0.1172, -0.0600,  0.1333, -0.3523,  0.1022,  0.2080],\n        [ 0.1451,  0.1681,  0.2635,  0.1138,  0.3452,  0.1627, -0.1084,  0.1225],\n        [-0.2163,  0.1712,  0.1275,  0.0444,  0.1411, -0.1257, -0.1194,  0.2883],\n        [ 0.0698,  0.1674, -0.3044,  0.1505,  0.2807, -0.1963,  0.0258, -0.1615],\n        [ 0.1221,  0.1631, -0.0005,  0.0902,  0.2166,  0.1634,  0.1101, -0.0042],\n        [ 0.2476,  0.3370, -0.0044,  0.2494,  0.0642, -0.0359,  0.3126, -0.0633],\n        [ 0.3008,  0.2807, -0.2975, -0.3285, -0.0574,  0.1270, -0.3107, -0.3444],\n        [-0.2073,  0.1607,  0.0254,  0.1510,  0.2156, -0.3347,  0.3488,  0.1020],\n        [ 0.3192, -0.3204, -0.0499,  0.0650,  0.0334, -0.2850,  0.0193, -0.0997],\n        [ 0.3413, -0.3476,  0.2878,  0.3284, -0.2538, -0.2238,  0.3113, -0.1209],\n        [ 0.1069,  0.3253, -0.0830,  0.1211,  0.2158,  0.1377, -0.1636, -0.0067],\n        [-0.0526, -0.0971, -0.2381,  0.3236, -0.1497, -0.1176,  0.0761,  0.2564],\n        [ 0.0581,  0.0639,  0.3265,  0.2817, -0.0207,  0.3079, -0.2283, -0.1254],\n        [ 0.1897, -0.3384, -0.0455, -0.0764, -0.0919,  0.3320, -0.0469, -0.0663],\n        [-0.0868, -0.0801,  0.1355,  0.2209, -0.2533, -0.1257,  0.0487, -0.0229],\n        [ 0.2084,  0.2959,  0.1812,  0.1630, -0.2810, -0.1074, -0.0223, -0.1250],\n        [ 0.0020,  0.0146,  0.2360, -0.3192, -0.1783,  0.0590,  0.3082,  0.0339]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0303,  0.1544, -0.0873, -0.0707,  0.0397, -0.0075,  0.0158, -0.0184,\n         0.1020, -0.0022,  0.0180, -0.1468, -0.1183, -0.0299,  0.1113, -0.1740],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.8459e-02,  5.1110e-02, -4.1989e-02,  3.1383e-02, -1.4941e-01,\n          9.1094e-02, -6.4970e-02, -1.5712e-01, -1.6120e-01, -1.2182e-01,\n         -1.1101e-01, -5.7681e-02, -5.8805e-03,  1.7254e-01,  8.5130e-02,\n         -2.7699e-02, -8.7131e-03, -8.9532e-02, -5.6764e-03,  7.9530e-02,\n         -1.3546e-01,  7.1202e-02,  8.5525e-02, -3.2780e-02,  1.0235e-01,\n         -9.5044e-02,  1.5183e-01, -1.7297e-01,  1.5212e-02,  8.4473e-03,\n          1.5407e-01,  1.5483e-02],\n        [-9.2634e-02,  1.3958e-01, -1.0458e-01, -1.1862e-01, -2.9306e-02,\n         -1.4991e-01,  4.8368e-02, -6.0036e-03, -3.5954e-02, -9.4104e-02,\n         -8.0118e-02,  1.3479e-01,  1.7663e-01, -1.0919e-01,  3.5146e-03,\n          1.5198e-01,  1.3164e-01, -4.8319e-03,  6.6145e-02,  3.7352e-02,\n          1.5767e-01,  1.5481e-01,  1.0274e-01,  1.0226e-01,  1.1315e-01,\n          1.7534e-01, -1.7470e-01,  5.2684e-02,  1.5824e-01, -1.0063e-01,\n          9.6064e-02, -1.3236e-01],\n        [-1.8751e-02,  1.7090e-01,  4.7878e-03,  8.3580e-02, -7.7951e-02,\n         -3.2319e-02,  1.5337e-01, -8.5287e-02,  2.5985e-02, -2.5095e-02,\n         -1.6846e-02, -4.9306e-02, -1.2012e-01,  1.6611e-01, -9.2561e-02,\n          1.3676e-01, -4.6059e-02, -3.4235e-03,  7.0775e-02, -5.7172e-02,\n         -7.9654e-02,  1.7014e-01,  4.5787e-03,  1.3861e-01, -1.0561e-01,\n         -8.1378e-02, -9.3925e-02, -4.9447e-02, -4.1886e-03, -6.7741e-02,\n          8.9401e-02,  1.5748e-01],\n        [-1.1401e-01,  3.3725e-02,  5.0861e-02, -8.8222e-02,  1.5182e-01,\n          5.5942e-02,  1.2914e-01,  6.7765e-02, -1.0307e-01,  3.5843e-02,\n         -7.8248e-02,  6.2109e-02, -1.5151e-01,  1.0808e-01,  8.9040e-02,\n          1.6976e-02, -1.6432e-01, -2.9023e-02, -1.4729e-01,  7.0778e-02,\n          1.0296e-01,  4.1220e-02,  1.5217e-01, -1.4489e-02, -9.4958e-02,\n         -2.5189e-02,  1.0182e-01, -1.3859e-01, -8.2720e-02,  3.5635e-02,\n          1.2312e-02,  3.9199e-03],\n        [-1.7476e-01, -1.3018e-02,  1.7632e-01,  1.4792e-01,  3.6006e-02,\n         -1.3667e-01, -1.5216e-02, -2.0549e-03, -3.0110e-02, -1.5323e-01,\n         -9.0853e-02, -9.9075e-03,  6.1690e-03, -5.9946e-02, -7.7166e-02,\n         -7.0884e-02, -7.8774e-02,  3.9256e-04, -1.2613e-01,  1.0663e-02,\n          1.6872e-01,  4.3102e-02, -5.3140e-02, -9.5853e-02,  1.4375e-01,\n          4.5304e-02, -9.7717e-02,  1.3247e-01,  1.4291e-01,  1.6416e-01,\n         -1.1838e-01,  4.0667e-02],\n        [ 1.3150e-01, -1.0096e-01, -8.4134e-02, -1.2452e-01, -1.1737e-01,\n          6.7347e-02, -8.0412e-02,  9.7224e-02,  7.3870e-02,  1.1381e-01,\n          1.3181e-02, -9.7324e-02, -1.6999e-01, -9.3838e-02, -1.4149e-02,\n          1.0363e-01, -1.5398e-01,  1.6927e-01,  5.5317e-03, -1.7041e-01,\n          1.9657e-02,  9.1829e-02, -3.4892e-02, -4.1527e-02,  4.5995e-02,\n          5.7484e-02,  1.7209e-01, -8.7712e-02,  6.0409e-02, -1.1255e-01,\n          2.2400e-02,  5.7833e-02],\n        [-6.4784e-02,  9.8576e-03,  5.5353e-02, -9.3576e-02, -1.4004e-02,\n         -1.5195e-01,  1.2544e-01,  1.7436e-02, -1.5201e-01,  1.8685e-03,\n          7.9067e-02, -1.3828e-01, -1.5716e-01,  1.6377e-01, -1.5485e-01,\n          1.7397e-01, -1.0769e-01, -1.3985e-01,  1.8827e-02, -4.4866e-02,\n          5.9027e-02,  3.8385e-02,  1.1427e-01,  4.5093e-02, -1.0775e-01,\n          1.1793e-01,  2.7588e-02, -1.4932e-02, -1.2904e-01,  1.3929e-01,\n          1.4359e-01, -3.8549e-02],\n        [-5.5001e-02, -1.2761e-01,  7.5970e-02,  2.2305e-02, -1.4568e-01,\n         -8.6079e-02, -3.0262e-02,  2.8595e-02, -1.4689e-01, -1.3388e-01,\n          1.2847e-01,  2.6749e-02,  1.2937e-01,  1.4784e-01,  8.9548e-02,\n          9.5793e-02,  4.1445e-02,  1.3250e-01, -1.5616e-01, -3.7042e-02,\n          7.8822e-02, -1.2873e-01,  2.5423e-02, -3.1994e-02,  1.6244e-01,\n          6.6926e-02, -2.3001e-02,  2.0768e-02, -9.1021e-02,  1.3394e-01,\n         -1.4622e-01, -1.4968e-01],\n        [-1.0626e-01,  7.3097e-04,  9.1815e-02, -1.2766e-01,  6.1840e-02,\n          5.2339e-02,  1.7710e-02,  1.5932e-01, -5.2321e-02, -6.4722e-02,\n          1.6066e-02,  1.3281e-01,  1.0399e-01, -7.4660e-02, -1.6395e-01,\n          8.8123e-02,  1.5149e-01,  1.3322e-01, -4.2181e-02, -7.3665e-02,\n          1.3394e-01,  1.1205e-01,  2.4807e-02, -8.1069e-02,  1.6280e-01,\n          1.3467e-01,  1.4533e-01,  1.4360e-01, -3.5070e-02,  3.7426e-02,\n         -6.4540e-02, -2.3012e-02],\n        [ 1.2740e-01,  1.7397e-01, -5.0072e-02,  1.6885e-01,  4.7952e-02,\n          9.9522e-03, -5.1682e-02, -8.9125e-02, -8.8678e-02,  3.7781e-03,\n         -4.0988e-02,  1.1237e-01,  9.9246e-02, -1.6078e-01,  1.3124e-01,\n          3.0537e-02,  5.8227e-02, -6.8027e-03,  5.5418e-02, -1.6445e-01,\n          6.8031e-02,  2.3225e-02, -1.3879e-01, -2.7135e-02,  1.0845e-01,\n         -7.9826e-02,  1.2337e-01,  1.6055e-01, -8.9218e-02, -1.6574e-01,\n          1.3738e-02, -2.8784e-02],\n        [ 1.5135e-01,  7.1444e-02,  5.7516e-02,  7.3066e-03,  1.3092e-01,\n          3.0560e-02,  3.1263e-02, -3.0901e-02, -1.3166e-02, -9.9402e-02,\n          5.4633e-02, -7.1629e-02,  7.9343e-02, -1.1208e-01, -1.2699e-01,\n         -2.1623e-02, -1.7498e-01,  3.5154e-03, -4.1159e-02,  9.1197e-02,\n         -5.2101e-02, -7.1964e-02,  2.2014e-02,  2.1157e-02,  1.2967e-02,\n          8.4087e-02, -1.5884e-01,  3.4352e-02,  1.4901e-01, -1.5538e-01,\n         -7.7043e-03,  7.3139e-02],\n        [ 1.6027e-01,  4.1217e-02,  5.1492e-02, -9.5809e-03, -7.9090e-02,\n         -1.5994e-02, -7.1253e-02,  1.0748e-01, -1.2140e-01,  1.8424e-02,\n          1.3666e-02, -4.5062e-02,  1.4538e-01,  9.2201e-02,  8.4207e-02,\n          1.4515e-02,  1.0596e-02,  1.5670e-01,  3.6638e-02, -1.4021e-01,\n          1.2232e-01,  3.8411e-02,  1.3957e-01, -5.3707e-02, -1.3026e-01,\n         -2.3679e-02, -1.7469e-01, -6.9361e-02, -1.3450e-01,  1.7633e-01,\n         -5.7212e-02, -1.6412e-01],\n        [-4.6129e-02, -9.1531e-02, -1.0221e-01, -1.6237e-01,  1.7398e-01,\n          4.7001e-03,  6.4871e-02, -5.6148e-02, -5.3759e-02,  8.4137e-02,\n         -1.0631e-01,  3.4149e-02,  1.2916e-01,  8.4276e-02,  9.1280e-02,\n          1.0780e-01, -3.5478e-02,  5.8755e-02,  1.0094e-01,  1.6670e-01,\n         -2.2501e-02,  1.8270e-02, -1.0460e-01, -1.0680e-02, -1.1110e-02,\n         -3.2014e-02,  9.4699e-02, -1.1702e-01,  8.8271e-02, -1.5024e-02,\n          9.3505e-02,  1.4500e-01],\n        [ 1.4117e-01,  9.9192e-02, -7.6772e-02,  1.0683e-02,  1.1817e-01,\n         -2.6967e-02,  1.0333e-01, -1.0538e-01,  1.5149e-01,  5.0743e-02,\n         -8.0937e-03, -7.2451e-02, -2.9149e-02,  1.5229e-01,  1.6659e-01,\n         -1.5746e-01,  1.6331e-02,  1.6822e-01,  5.8025e-02,  1.2444e-01,\n          2.2448e-02,  2.9081e-02, -6.5566e-02,  8.3434e-02, -2.5963e-02,\n         -1.3117e-01, -1.1698e-01, -1.2962e-01,  2.4036e-02,  2.8807e-05,\n         -1.4291e-01,  1.2217e-01],\n        [ 1.6694e-01, -1.9247e-02, -2.8752e-02, -1.1329e-01, -2.3164e-02,\n         -1.0089e-01,  7.1161e-02,  8.7363e-02,  7.0368e-02,  6.8348e-02,\n          1.1050e-01, -1.0349e-01, -4.4710e-02,  1.6147e-02,  7.7356e-02,\n         -1.5652e-01,  1.5754e-01,  7.0340e-02, -1.0735e-01,  2.0065e-02,\n          9.4632e-02,  9.5405e-02,  1.0576e-01, -2.1657e-02, -1.1450e-01,\n         -1.1635e-01, -8.4049e-02, -3.6993e-02,  1.6903e-01, -5.5941e-02,\n          6.4805e-02, -1.2136e-01],\n        [-1.2952e-01, -1.0587e-01,  8.1734e-02, -1.7631e-01, -1.3751e-01,\n         -1.2485e-01,  3.6752e-02,  1.3465e-01,  1.0320e-02, -1.4829e-01,\n          3.8661e-02, -1.4418e-01, -1.4189e-01,  3.2044e-02,  2.9750e-02,\n          1.5008e-01,  3.4579e-02,  9.5591e-02,  1.4490e-01, -8.0054e-02,\n         -1.3879e-01,  7.7366e-02,  5.6175e-02,  1.0061e-02, -1.3310e-01,\n          1.4978e-01,  1.6576e-01, -5.5111e-02,  7.0145e-02,  8.4182e-02,\n         -5.7895e-02, -8.7556e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0373,  0.2074, -0.2215,  0.0202,  0.1319, -0.2137,  0.2068,  0.0914],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1326, -0.2125,  0.1300,  0.1421,  0.2271,  0.1610,  0.1440,  0.1343,\n         -0.1592, -0.2458, -0.2022, -0.1164,  0.1574, -0.0168, -0.0564, -0.1819],\n        [-0.1461, -0.1361,  0.0317,  0.0838,  0.2421, -0.0116, -0.0080,  0.0122,\n          0.0970, -0.1649, -0.0252, -0.1691, -0.2344, -0.0370,  0.0109, -0.0452],\n        [ 0.1572, -0.2001,  0.1692,  0.1321,  0.0400,  0.1986,  0.0176,  0.0984,\n         -0.1679,  0.0290, -0.1781, -0.0681,  0.2423, -0.0202, -0.0603, -0.2296],\n        [-0.1661,  0.0374,  0.2132,  0.2387, -0.0741,  0.1565,  0.1768,  0.1658,\n         -0.2274, -0.2146, -0.0984, -0.2045,  0.1268, -0.0451,  0.0150,  0.1529],\n        [ 0.0262,  0.0493,  0.0621,  0.0993,  0.0143, -0.1665, -0.1677,  0.0347,\n         -0.0667,  0.0665,  0.2499, -0.0085,  0.0032, -0.1771, -0.2477, -0.0329],\n        [-0.2456,  0.1580, -0.1257,  0.1987, -0.0699,  0.2185, -0.1048,  0.0086,\n          0.1774, -0.1613,  0.0720, -0.2288, -0.2204,  0.1242, -0.0107, -0.1208],\n        [ 0.1141, -0.0988,  0.0254,  0.1246, -0.2299,  0.0853,  0.0716,  0.1604,\n         -0.1938, -0.1015,  0.0267, -0.0735, -0.0585, -0.1744,  0.1169,  0.2310],\n        [ 0.1883,  0.1759,  0.0186,  0.0587, -0.0146,  0.0259,  0.0874,  0.1361,\n         -0.0266, -0.0675,  0.0285,  0.1126,  0.1751, -0.2402,  0.0490,  0.0448]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0554], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2971, -0.0694, -0.2936,  0.2924, -0.2651, -0.0149,  0.0707,  0.2161]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1615,  0.1119, -0.0811, -0.3456, -0.2980,  0.1752, -0.0875,  0.0051],\n        [ 0.1282, -0.0466, -0.3113,  0.2527, -0.3484, -0.2336,  0.2099, -0.1049],\n        [ 0.1531, -0.1614,  0.0391,  0.2022,  0.0815,  0.3093,  0.1309,  0.2500],\n        [-0.2274, -0.2891,  0.1918, -0.1537,  0.1994,  0.2676, -0.2537,  0.2140],\n        [-0.3397, -0.1838,  0.2605,  0.0494,  0.2153,  0.0891, -0.0102, -0.0371],\n        [ 0.2586, -0.1610,  0.1856,  0.1559,  0.0956,  0.1672, -0.1536, -0.0151],\n        [-0.2322, -0.1379,  0.0475,  0.0486, -0.2943,  0.2348,  0.2412,  0.3431],\n        [-0.0090, -0.2516, -0.2794,  0.2112, -0.3528,  0.1779, -0.2130, -0.2148],\n        [ 0.0139,  0.0621, -0.2678,  0.0112, -0.1443,  0.2897,  0.0807,  0.0713],\n        [ 0.2825,  0.1232, -0.2591,  0.3513, -0.0209,  0.2561,  0.1788, -0.2164],\n        [-0.3060, -0.1593,  0.0380,  0.0725, -0.1231, -0.1113,  0.0683, -0.2169],\n        [-0.0054, -0.0016,  0.0156, -0.1065, -0.1505, -0.1017, -0.0993, -0.1732],\n        [-0.3347, -0.2234,  0.1009,  0.1318,  0.2865, -0.1720, -0.1961,  0.3093],\n        [-0.1575,  0.1445,  0.2165,  0.2851,  0.1176,  0.2391, -0.2453, -0.1066],\n        [ 0.3313, -0.1012,  0.2375,  0.3158, -0.0436,  0.2488, -0.2796, -0.3404],\n        [ 0.1018, -0.2023,  0.1172, -0.0600,  0.1333, -0.3523,  0.1022,  0.2080],\n        [ 0.1451,  0.1681,  0.2635,  0.1138,  0.3452,  0.1627, -0.1084,  0.1225],\n        [-0.2163,  0.1712,  0.1275,  0.0444,  0.1411, -0.1257, -0.1194,  0.2883],\n        [ 0.0698,  0.1674, -0.3044,  0.1505,  0.2807, -0.1963,  0.0258, -0.1615],\n        [ 0.1221,  0.1631, -0.0005,  0.0902,  0.2166,  0.1634,  0.1101, -0.0042],\n        [ 0.2476,  0.3370, -0.0044,  0.2494,  0.0642, -0.0359,  0.3126, -0.0633],\n        [ 0.3008,  0.2807, -0.2975, -0.3285, -0.0574,  0.1270, -0.3107, -0.3444],\n        [-0.2073,  0.1607,  0.0254,  0.1510,  0.2156, -0.3347,  0.3488,  0.1020],\n        [ 0.3192, -0.3204, -0.0499,  0.0650,  0.0334, -0.2850,  0.0193, -0.0997],\n        [ 0.3413, -0.3476,  0.2878,  0.3284, -0.2538, -0.2238,  0.3113, -0.1209],\n        [ 0.1069,  0.3253, -0.0830,  0.1211,  0.2158,  0.1377, -0.1636, -0.0067],\n        [-0.0526, -0.0971, -0.2381,  0.3236, -0.1497, -0.1176,  0.0761,  0.2564],\n        [ 0.0581,  0.0639,  0.3265,  0.2817, -0.0207,  0.3079, -0.2283, -0.1254],\n        [ 0.1897, -0.3384, -0.0455, -0.0764, -0.0919,  0.3320, -0.0469, -0.0663],\n        [-0.0868, -0.0801,  0.1355,  0.2209, -0.2533, -0.1257,  0.0487, -0.0229],\n        [ 0.2084,  0.2959,  0.1812,  0.1630, -0.2810, -0.1074, -0.0223, -0.1250],\n        [ 0.0020,  0.0146,  0.2360, -0.3192, -0.1783,  0.0590,  0.3082,  0.0339]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0029, -0.0436,  0.2882, -0.3064, -0.1571,  0.1085, -0.1895,  0.2737,\n         0.2476, -0.1338, -0.1043, -0.2027,  0.2358, -0.2908, -0.0513, -0.1571,\n        -0.1957,  0.3491,  0.1227, -0.1856,  0.0015,  0.2989, -0.0366, -0.0835,\n        -0.0451, -0.1467,  0.3385,  0.2197,  0.0234, -0.0195, -0.1789, -0.0841],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.8459e-02,  5.1110e-02, -4.1989e-02,  3.1383e-02, -1.4941e-01,\n          9.1094e-02, -6.4970e-02, -1.5712e-01, -1.6120e-01, -1.2182e-01,\n         -1.1101e-01, -5.7681e-02, -5.8805e-03,  1.7254e-01,  8.5130e-02,\n         -2.7699e-02, -8.7131e-03, -8.9532e-02, -5.6764e-03,  7.9530e-02,\n         -1.3546e-01,  7.1202e-02,  8.5525e-02, -3.2780e-02,  1.0235e-01,\n         -9.5044e-02,  1.5183e-01, -1.7297e-01,  1.5212e-02,  8.4473e-03,\n          1.5407e-01,  1.5483e-02],\n        [-9.2634e-02,  1.3958e-01, -1.0458e-01, -1.1862e-01, -2.9306e-02,\n         -1.4991e-01,  4.8368e-02, -6.0036e-03, -3.5954e-02, -9.4104e-02,\n         -8.0118e-02,  1.3479e-01,  1.7663e-01, -1.0919e-01,  3.5146e-03,\n          1.5198e-01,  1.3164e-01, -4.8319e-03,  6.6145e-02,  3.7352e-02,\n          1.5767e-01,  1.5481e-01,  1.0274e-01,  1.0226e-01,  1.1315e-01,\n          1.7534e-01, -1.7470e-01,  5.2684e-02,  1.5824e-01, -1.0063e-01,\n          9.6064e-02, -1.3236e-01],\n        [-1.8751e-02,  1.7090e-01,  4.7878e-03,  8.3580e-02, -7.7951e-02,\n         -3.2319e-02,  1.5337e-01, -8.5287e-02,  2.5985e-02, -2.5095e-02,\n         -1.6846e-02, -4.9306e-02, -1.2012e-01,  1.6611e-01, -9.2561e-02,\n          1.3676e-01, -4.6059e-02, -3.4235e-03,  7.0775e-02, -5.7172e-02,\n         -7.9654e-02,  1.7014e-01,  4.5787e-03,  1.3861e-01, -1.0561e-01,\n         -8.1378e-02, -9.3925e-02, -4.9447e-02, -4.1886e-03, -6.7741e-02,\n          8.9401e-02,  1.5748e-01],\n        [-1.1401e-01,  3.3725e-02,  5.0861e-02, -8.8222e-02,  1.5182e-01,\n          5.5942e-02,  1.2914e-01,  6.7765e-02, -1.0307e-01,  3.5843e-02,\n         -7.8248e-02,  6.2109e-02, -1.5151e-01,  1.0808e-01,  8.9040e-02,\n          1.6976e-02, -1.6432e-01, -2.9023e-02, -1.4729e-01,  7.0778e-02,\n          1.0296e-01,  4.1220e-02,  1.5217e-01, -1.4489e-02, -9.4958e-02,\n         -2.5189e-02,  1.0182e-01, -1.3859e-01, -8.2720e-02,  3.5635e-02,\n          1.2312e-02,  3.9199e-03],\n        [-1.7476e-01, -1.3018e-02,  1.7632e-01,  1.4792e-01,  3.6006e-02,\n         -1.3667e-01, -1.5216e-02, -2.0549e-03, -3.0110e-02, -1.5323e-01,\n         -9.0853e-02, -9.9075e-03,  6.1690e-03, -5.9946e-02, -7.7166e-02,\n         -7.0884e-02, -7.8774e-02,  3.9256e-04, -1.2613e-01,  1.0663e-02,\n          1.6872e-01,  4.3102e-02, -5.3140e-02, -9.5853e-02,  1.4375e-01,\n          4.5304e-02, -9.7717e-02,  1.3247e-01,  1.4291e-01,  1.6416e-01,\n         -1.1838e-01,  4.0667e-02],\n        [ 1.3150e-01, -1.0096e-01, -8.4134e-02, -1.2452e-01, -1.1737e-01,\n          6.7347e-02, -8.0412e-02,  9.7224e-02,  7.3870e-02,  1.1381e-01,\n          1.3181e-02, -9.7324e-02, -1.6999e-01, -9.3838e-02, -1.4149e-02,\n          1.0363e-01, -1.5398e-01,  1.6927e-01,  5.5317e-03, -1.7041e-01,\n          1.9657e-02,  9.1829e-02, -3.4892e-02, -4.1527e-02,  4.5995e-02,\n          5.7484e-02,  1.7209e-01, -8.7712e-02,  6.0409e-02, -1.1255e-01,\n          2.2400e-02,  5.7833e-02],\n        [-6.4784e-02,  9.8576e-03,  5.5353e-02, -9.3576e-02, -1.4004e-02,\n         -1.5195e-01,  1.2544e-01,  1.7436e-02, -1.5201e-01,  1.8685e-03,\n          7.9067e-02, -1.3828e-01, -1.5716e-01,  1.6377e-01, -1.5485e-01,\n          1.7397e-01, -1.0769e-01, -1.3985e-01,  1.8827e-02, -4.4866e-02,\n          5.9027e-02,  3.8385e-02,  1.1427e-01,  4.5093e-02, -1.0775e-01,\n          1.1793e-01,  2.7588e-02, -1.4932e-02, -1.2904e-01,  1.3929e-01,\n          1.4359e-01, -3.8549e-02],\n        [-5.5001e-02, -1.2761e-01,  7.5970e-02,  2.2305e-02, -1.4568e-01,\n         -8.6079e-02, -3.0262e-02,  2.8595e-02, -1.4689e-01, -1.3388e-01,\n          1.2847e-01,  2.6749e-02,  1.2937e-01,  1.4784e-01,  8.9548e-02,\n          9.5793e-02,  4.1445e-02,  1.3250e-01, -1.5616e-01, -3.7042e-02,\n          7.8822e-02, -1.2873e-01,  2.5423e-02, -3.1994e-02,  1.6244e-01,\n          6.6926e-02, -2.3001e-02,  2.0768e-02, -9.1021e-02,  1.3394e-01,\n         -1.4622e-01, -1.4968e-01],\n        [-1.0626e-01,  7.3097e-04,  9.1815e-02, -1.2766e-01,  6.1840e-02,\n          5.2339e-02,  1.7710e-02,  1.5932e-01, -5.2321e-02, -6.4722e-02,\n          1.6066e-02,  1.3281e-01,  1.0399e-01, -7.4660e-02, -1.6395e-01,\n          8.8123e-02,  1.5149e-01,  1.3322e-01, -4.2181e-02, -7.3665e-02,\n          1.3394e-01,  1.1205e-01,  2.4807e-02, -8.1069e-02,  1.6280e-01,\n          1.3467e-01,  1.4533e-01,  1.4360e-01, -3.5070e-02,  3.7426e-02,\n         -6.4540e-02, -2.3012e-02],\n        [ 1.2740e-01,  1.7397e-01, -5.0072e-02,  1.6885e-01,  4.7952e-02,\n          9.9522e-03, -5.1682e-02, -8.9125e-02, -8.8678e-02,  3.7781e-03,\n         -4.0988e-02,  1.1237e-01,  9.9246e-02, -1.6078e-01,  1.3124e-01,\n          3.0537e-02,  5.8227e-02, -6.8027e-03,  5.5418e-02, -1.6445e-01,\n          6.8031e-02,  2.3225e-02, -1.3879e-01, -2.7135e-02,  1.0845e-01,\n         -7.9826e-02,  1.2337e-01,  1.6055e-01, -8.9218e-02, -1.6574e-01,\n          1.3738e-02, -2.8784e-02],\n        [ 1.5135e-01,  7.1444e-02,  5.7516e-02,  7.3066e-03,  1.3092e-01,\n          3.0560e-02,  3.1263e-02, -3.0901e-02, -1.3166e-02, -9.9402e-02,\n          5.4633e-02, -7.1629e-02,  7.9343e-02, -1.1208e-01, -1.2699e-01,\n         -2.1623e-02, -1.7498e-01,  3.5154e-03, -4.1159e-02,  9.1197e-02,\n         -5.2101e-02, -7.1964e-02,  2.2014e-02,  2.1157e-02,  1.2967e-02,\n          8.4087e-02, -1.5884e-01,  3.4352e-02,  1.4901e-01, -1.5538e-01,\n         -7.7043e-03,  7.3139e-02],\n        [ 1.6027e-01,  4.1217e-02,  5.1492e-02, -9.5809e-03, -7.9090e-02,\n         -1.5994e-02, -7.1253e-02,  1.0748e-01, -1.2140e-01,  1.8424e-02,\n          1.3666e-02, -4.5062e-02,  1.4538e-01,  9.2201e-02,  8.4207e-02,\n          1.4515e-02,  1.0596e-02,  1.5670e-01,  3.6638e-02, -1.4021e-01,\n          1.2232e-01,  3.8411e-02,  1.3957e-01, -5.3707e-02, -1.3026e-01,\n         -2.3679e-02, -1.7469e-01, -6.9361e-02, -1.3450e-01,  1.7633e-01,\n         -5.7212e-02, -1.6412e-01],\n        [-4.6129e-02, -9.1531e-02, -1.0221e-01, -1.6237e-01,  1.7398e-01,\n          4.7001e-03,  6.4871e-02, -5.6148e-02, -5.3759e-02,  8.4137e-02,\n         -1.0631e-01,  3.4149e-02,  1.2916e-01,  8.4276e-02,  9.1280e-02,\n          1.0780e-01, -3.5478e-02,  5.8755e-02,  1.0094e-01,  1.6670e-01,\n         -2.2501e-02,  1.8270e-02, -1.0460e-01, -1.0680e-02, -1.1110e-02,\n         -3.2014e-02,  9.4699e-02, -1.1702e-01,  8.8271e-02, -1.5024e-02,\n          9.3505e-02,  1.4500e-01],\n        [ 1.4117e-01,  9.9192e-02, -7.6772e-02,  1.0683e-02,  1.1817e-01,\n         -2.6967e-02,  1.0333e-01, -1.0538e-01,  1.5149e-01,  5.0743e-02,\n         -8.0937e-03, -7.2451e-02, -2.9149e-02,  1.5229e-01,  1.6659e-01,\n         -1.5746e-01,  1.6331e-02,  1.6822e-01,  5.8025e-02,  1.2444e-01,\n          2.2448e-02,  2.9081e-02, -6.5566e-02,  8.3434e-02, -2.5963e-02,\n         -1.3117e-01, -1.1698e-01, -1.2962e-01,  2.4036e-02,  2.8807e-05,\n         -1.4291e-01,  1.2217e-01],\n        [ 1.6694e-01, -1.9247e-02, -2.8752e-02, -1.1329e-01, -2.3164e-02,\n         -1.0089e-01,  7.1161e-02,  8.7363e-02,  7.0368e-02,  6.8348e-02,\n          1.1050e-01, -1.0349e-01, -4.4710e-02,  1.6147e-02,  7.7356e-02,\n         -1.5652e-01,  1.5754e-01,  7.0340e-02, -1.0735e-01,  2.0065e-02,\n          9.4632e-02,  9.5405e-02,  1.0576e-01, -2.1657e-02, -1.1450e-01,\n         -1.1635e-01, -8.4049e-02, -3.6993e-02,  1.6903e-01, -5.5941e-02,\n          6.4805e-02, -1.2136e-01],\n        [-1.2952e-01, -1.0587e-01,  8.1734e-02, -1.7631e-01, -1.3751e-01,\n         -1.2485e-01,  3.6752e-02,  1.3465e-01,  1.0320e-02, -1.4829e-01,\n          3.8661e-02, -1.4418e-01, -1.4189e-01,  3.2044e-02,  2.9750e-02,\n          1.5008e-01,  3.4579e-02,  9.5591e-02,  1.4490e-01, -8.0054e-02,\n         -1.3879e-01,  7.7366e-02,  5.6175e-02,  1.0061e-02, -1.3310e-01,\n          1.4978e-01,  1.6576e-01, -5.5111e-02,  7.0145e-02,  8.4182e-02,\n         -5.7895e-02, -8.7556e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0303,  0.1544, -0.0873, -0.0707,  0.0397, -0.0075,  0.0158, -0.0184,\n         0.1020, -0.0022,  0.0180, -0.1468, -0.1183, -0.0299,  0.1113, -0.1740],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1326, -0.2125,  0.1300,  0.1421,  0.2271,  0.1610,  0.1440,  0.1343,\n         -0.1592, -0.2458, -0.2022, -0.1164,  0.1574, -0.0168, -0.0564, -0.1819],\n        [-0.1461, -0.1361,  0.0317,  0.0838,  0.2421, -0.0116, -0.0080,  0.0122,\n          0.0970, -0.1649, -0.0252, -0.1691, -0.2344, -0.0370,  0.0109, -0.0452],\n        [ 0.1572, -0.2001,  0.1692,  0.1321,  0.0400,  0.1986,  0.0176,  0.0984,\n         -0.1679,  0.0290, -0.1781, -0.0681,  0.2423, -0.0202, -0.0603, -0.2296],\n        [-0.1661,  0.0374,  0.2132,  0.2387, -0.0741,  0.1565,  0.1768,  0.1658,\n         -0.2274, -0.2146, -0.0984, -0.2045,  0.1268, -0.0451,  0.0150,  0.1529],\n        [ 0.0262,  0.0493,  0.0621,  0.0993,  0.0143, -0.1665, -0.1677,  0.0347,\n         -0.0667,  0.0665,  0.2499, -0.0085,  0.0032, -0.1771, -0.2477, -0.0329],\n        [-0.2456,  0.1580, -0.1257,  0.1987, -0.0699,  0.2185, -0.1048,  0.0086,\n          0.1774, -0.1613,  0.0720, -0.2288, -0.2204,  0.1242, -0.0107, -0.1208],\n        [ 0.1141, -0.0988,  0.0254,  0.1246, -0.2299,  0.0853,  0.0716,  0.1604,\n         -0.1938, -0.1015,  0.0267, -0.0735, -0.0585, -0.1744,  0.1169,  0.2310],\n        [ 0.1883,  0.1759,  0.0186,  0.0587, -0.0146,  0.0259,  0.0874,  0.1361,\n         -0.0266, -0.0675,  0.0285,  0.1126,  0.1751, -0.2402,  0.0490,  0.0448]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0373,  0.2074, -0.2215,  0.0202,  0.1319, -0.2137,  0.2068,  0.0914],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2971, -0.0694, -0.2936,  0.2924, -0.2651, -0.0149,  0.0707,  0.2161]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0554], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x1039f3e80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x17a91a590>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s184310000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s184310000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}