{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s184920000"
    },
    "q_lr":	0.0005,
    "seed":	184920000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x30300e3e0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0568, -0.3411,  0.3065,  0.2158, -0.3512,  0.3150,  0.0384, -0.2788,\n        -0.1486,  0.1569,  0.0949,  0.2420,  0.3380,  0.1549, -0.0520,  0.1139,\n        -0.2806,  0.2903,  0.2162, -0.0043,  0.0083,  0.2611,  0.0016,  0.2445,\n         0.2117, -0.0371,  0.2342,  0.0745, -0.0812, -0.1601,  0.1800, -0.1797],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 2.4488e-01,  3.4899e-01, -1.0877e-02, -9.9497e-02,  1.5042e-01,\n         -2.6682e-01,  2.3463e-02, -3.2838e-01],\n        [ 2.1709e-01, -3.3592e-01,  9.9849e-02,  1.4359e-01, -2.0588e-01,\n          3.5317e-01,  1.5341e-02, -1.7570e-01],\n        [ 1.8718e-01,  3.0239e-01,  1.5343e-01,  1.8360e-02,  2.5509e-01,\n          5.2510e-02, -2.1330e-02, -2.9117e-01],\n        [-5.8697e-02, -7.3650e-02, -1.1439e-01, -1.8080e-01, -1.0523e-01,\n          2.6622e-01,  6.4895e-02, -1.3779e-01],\n        [ 2.1054e-01,  2.4120e-01, -1.6231e-01, -9.2057e-02, -1.6174e-01,\n         -6.3539e-02,  2.2520e-01, -7.7104e-02],\n        [ 1.7001e-01,  2.1637e-01, -1.1521e-01,  3.3475e-01, -2.9451e-01,\n         -2.7541e-01, -1.9196e-01,  3.2989e-01],\n        [-1.8010e-01,  1.3520e-01,  3.1567e-01,  1.9388e-01, -3.1053e-03,\n          4.3639e-02, -2.3343e-01,  1.0735e-01],\n        [ 2.3601e-01,  2.3782e-02, -1.0089e-01, -1.6519e-01,  2.0145e-01,\n         -9.2841e-02,  4.6030e-02,  2.6266e-01],\n        [-5.9518e-02,  1.1716e-01,  2.4767e-01,  1.5257e-02, -3.4839e-04,\n          1.6935e-01, -1.4886e-01,  1.3290e-01],\n        [-1.6840e-02,  4.7876e-02,  1.5918e-01,  1.7558e-01, -1.7998e-01,\n         -9.9615e-02,  2.0951e-01, -7.6434e-02],\n        [ 2.1056e-01, -2.6403e-01, -1.8708e-01, -2.5073e-01, -1.6358e-01,\n          6.8327e-03, -2.2257e-02,  4.9814e-02],\n        [ 2.3644e-02,  2.3847e-01,  3.4911e-01, -3.5349e-01, -2.0612e-01,\n         -3.3116e-01, -3.3679e-01, -1.1654e-01],\n        [ 3.4944e-01, -3.4508e-01,  5.9158e-02, -3.3283e-01,  5.9167e-02,\n         -7.0621e-02,  1.3829e-01, -1.6790e-01],\n        [ 1.4868e-01,  1.5780e-01, -2.0462e-01, -1.6432e-01,  1.8310e-01,\n          9.3949e-02, -1.5272e-02,  2.8185e-01],\n        [-1.8563e-01,  1.0451e-01, -3.3987e-01, -2.0477e-01,  3.4342e-01,\n         -6.6117e-02, -3.3201e-01,  8.9705e-02],\n        [-1.6308e-01,  5.7692e-02, -1.5946e-01, -1.5439e-01,  2.1225e-01,\n          1.0893e-01, -1.0254e-01,  2.6754e-01],\n        [ 1.1609e-02, -2.3112e-01, -2.9362e-01, -2.3819e-01,  3.0987e-01,\n         -2.3961e-01, -1.1501e-02, -1.6177e-01],\n        [-3.2615e-01,  2.7010e-01, -1.1693e-01,  3.1434e-01,  1.6677e-01,\n          2.1996e-01, -1.5815e-01, -1.8920e-01],\n        [-4.7072e-02, -2.7979e-01, -2.6981e-01,  2.2977e-02, -1.9695e-01,\n         -2.2607e-01,  2.0223e-01, -2.2090e-01],\n        [-6.5456e-02, -3.3753e-03,  2.7175e-01, -3.1393e-01, -1.9699e-01,\n         -2.5706e-01, -1.1576e-01,  1.1880e-01],\n        [-1.6364e-01, -1.8441e-01,  1.8494e-01, -3.4043e-01,  2.7286e-01,\n         -2.8045e-01,  3.1011e-01, -2.5877e-01],\n        [ 2.6989e-02,  2.2430e-01, -1.2792e-01, -2.1391e-01, -5.6950e-02,\n          3.0244e-01,  1.5955e-01, -1.7577e-01],\n        [-1.8204e-01, -1.1858e-01,  3.0571e-01, -8.6241e-02,  3.3885e-01,\n         -6.0671e-02, -1.5511e-01,  1.8244e-01],\n        [-1.1282e-01, -8.5054e-02,  7.7467e-02,  9.1263e-03,  9.7518e-03,\n         -6.0804e-02,  1.0932e-01, -1.3969e-01],\n        [ 2.9320e-01, -1.7821e-02,  3.3688e-01,  2.1497e-01, -1.6824e-02,\n          3.0888e-01, -4.7314e-02, -1.6360e-01],\n        [ 2.1878e-01,  3.4241e-01,  1.6223e-01, -3.4891e-02,  3.3780e-01,\n          1.7133e-01, -1.5957e-01, -2.5509e-01],\n        [ 2.2365e-01, -3.0953e-01, -2.7909e-01,  2.1631e-01,  2.2317e-02,\n          1.0843e-01, -2.7984e-01,  2.7281e-01],\n        [-1.6761e-01, -2.6666e-01,  4.0783e-02, -1.7596e-01, -1.3980e-01,\n          1.2704e-01,  2.5110e-01,  6.8420e-02],\n        [-2.9415e-01, -1.7548e-02, -1.6116e-01,  3.2237e-01,  1.4921e-01,\n          4.9744e-02,  2.7566e-01, -1.6226e-01],\n        [-2.7435e-01, -6.2019e-02,  2.7749e-01, -1.3755e-01, -1.8451e-01,\n         -1.8144e-01,  3.3668e-01,  1.2933e-01],\n        [ 1.3978e-01, -2.7111e-01, -7.8643e-02,  1.4576e-01,  1.9057e-01,\n         -4.2173e-02,  3.3439e-01, -3.1258e-01],\n        [-2.3081e-01, -2.2903e-01, -4.4949e-02, -4.3885e-03, -1.7188e-01,\n         -2.7703e-01,  2.4322e-01, -3.1509e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1526, -0.0567, -0.1065,  0.1436,  0.0012, -0.0292,  0.1030,  0.0337,\n         0.0758, -0.0955, -0.1448,  0.0109,  0.1002, -0.1567, -0.0149, -0.0059],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.5589e-02,  1.1934e-01,  9.0498e-02, -9.1005e-02,  2.8755e-02,\n         -1.4890e-01,  9.1317e-02, -7.9022e-02, -1.0582e-02,  3.2627e-02,\n         -2.2429e-02,  1.5158e-01, -4.3207e-02, -3.9715e-02, -2.6577e-02,\n          9.5598e-02,  5.0803e-02,  3.8576e-02, -2.5047e-02,  1.1708e-01,\n         -3.0650e-03,  3.2499e-04,  2.3447e-02,  1.3734e-01,  1.1983e-01,\n         -1.6960e-01,  1.3678e-01,  5.3121e-02,  1.2888e-01, -6.0782e-02,\n          1.4174e-01, -1.0028e-01],\n        [ 7.2415e-02,  1.2854e-01,  8.5951e-02, -1.5491e-01,  1.6137e-01,\n         -3.0528e-02, -6.2283e-02, -1.1389e-01, -7.5680e-02, -1.3531e-01,\n         -8.1199e-03,  1.0777e-01, -1.6876e-01, -1.4785e-01,  1.2715e-01,\n          4.5611e-02,  1.0026e-01,  8.0029e-02, -2.8594e-02,  1.1077e-01,\n          7.5974e-02,  7.7656e-02,  9.2777e-02, -1.4465e-01, -3.3865e-02,\n          1.6086e-01,  3.4826e-02, -6.1616e-02, -1.6245e-01,  1.5794e-01,\n          1.0758e-02,  6.8248e-02],\n        [ 5.3227e-02, -9.0960e-02, -1.2670e-01,  8.6599e-02,  1.6912e-01,\n          5.0585e-02, -1.6973e-01,  8.2438e-02,  4.4753e-02, -4.6798e-02,\n          1.7133e-01, -7.5053e-02,  1.4580e-01, -1.5796e-01,  6.5541e-02,\n         -1.4540e-01,  1.0653e-01, -1.1597e-01,  1.3991e-01,  6.0009e-02,\n         -1.3040e-01, -4.8675e-02, -8.2924e-02, -1.2624e-01,  1.5091e-01,\n          9.1388e-02,  5.3814e-02, -2.0263e-02, -1.1893e-01,  7.1095e-02,\n          3.7242e-02, -1.6856e-01],\n        [ 1.4956e-01,  1.6785e-01,  7.2681e-02, -1.4681e-01, -1.2353e-01,\n          9.1096e-02, -8.9353e-02, -1.5486e-01, -1.9257e-02, -1.0298e-01,\n         -5.5475e-02, -2.0426e-02,  9.2576e-02,  8.7207e-02, -1.2154e-02,\n          1.6360e-01, -5.3431e-03,  1.6943e-01, -1.0178e-01, -1.3790e-02,\n         -7.0388e-02, -1.4998e-01, -5.1155e-02, -6.1257e-02, -7.3458e-03,\n         -1.4076e-01,  2.3940e-02, -1.0230e-01, -8.0611e-02, -3.6505e-02,\n          1.0011e-01, -1.5041e-01],\n        [ 1.7162e-01,  1.3476e-01, -1.3366e-01, -3.2873e-02,  5.2076e-02,\n          3.6343e-02,  7.3423e-02, -9.9376e-02, -1.3214e-01, -2.6896e-02,\n          1.3995e-01,  1.1896e-01, -1.0684e-01, -5.5797e-02, -1.1471e-01,\n         -4.2974e-02,  1.1499e-01, -1.3354e-01,  6.8563e-02,  1.1737e-01,\n          1.4471e-01,  1.6204e-01, -1.0501e-01,  9.1889e-02, -1.5652e-01,\n          7.9491e-02, -1.0624e-01,  9.8400e-02, -3.6771e-02, -1.5481e-01,\n          1.0437e-01,  1.5932e-01],\n        [-1.6628e-01, -1.3777e-01,  1.4486e-01, -1.2817e-01, -1.3025e-03,\n          1.0268e-01,  1.4132e-01,  1.3800e-01, -1.6990e-01,  1.4539e-01,\n          1.1527e-01,  8.4840e-02,  2.5403e-02, -5.6552e-02,  4.4611e-02,\n         -1.0274e-01, -1.6661e-02,  1.6575e-01,  9.9542e-02,  3.1716e-02,\n          6.5212e-02,  9.2892e-02, -1.2137e-01,  2.1948e-02,  5.0492e-02,\n          1.4829e-01, -4.1314e-04, -3.6683e-02, -9.7181e-02,  3.7191e-02,\n          1.4903e-01,  4.0733e-02],\n        [-5.8092e-02,  1.0285e-01,  1.6218e-01, -1.4101e-01, -6.5766e-02,\n          1.3099e-01, -1.4732e-01, -1.3221e-01,  1.0951e-01,  3.7485e-03,\n          8.6270e-02,  1.1287e-02, -4.8362e-02,  4.7793e-02,  1.5923e-01,\n          2.0831e-02, -3.1535e-02,  7.3634e-02, -1.5335e-01,  1.6785e-01,\n         -1.2931e-01, -1.7198e-01, -1.7639e-01,  1.2561e-02, -2.5978e-02,\n         -4.1059e-02, -3.9665e-02,  1.3104e-01, -1.1607e-01,  1.2578e-01,\n          4.3890e-03, -8.8497e-02],\n        [-1.5748e-01,  1.6027e-01,  7.9888e-02,  5.3548e-03, -9.1318e-02,\n          2.5276e-02,  5.8655e-03,  7.5299e-02,  5.4346e-03,  3.3463e-02,\n         -2.7191e-03,  8.8351e-02,  8.5941e-02,  1.6225e-01,  9.9086e-02,\n         -1.3872e-01,  1.5436e-01,  1.3511e-01, -9.1458e-02, -1.5958e-01,\n          1.6759e-01, -1.3604e-01,  1.2626e-02, -1.0953e-01, -8.9133e-02,\n         -9.5809e-02, -2.4246e-02, -1.1782e-01, -1.0160e-01, -1.4802e-01,\n          1.2919e-01,  7.3811e-02],\n        [ 1.4047e-01,  6.6845e-02, -1.5961e-01, -4.6183e-03,  1.0425e-01,\n          1.5061e-01,  1.0058e-01, -6.1494e-02, -8.2604e-03, -1.3248e-01,\n          4.6687e-02, -1.1448e-01,  8.7734e-03, -1.4001e-01,  7.4950e-02,\n         -5.9222e-02,  6.6829e-03,  1.3429e-01, -1.7565e-01,  9.8052e-02,\n         -1.0598e-01, -6.0367e-02,  3.0657e-02, -9.1076e-02,  7.6515e-02,\n         -3.0620e-02, -2.5403e-02,  4.6884e-02,  1.0014e-02,  7.9764e-02,\n         -4.6351e-02, -1.6537e-01],\n        [-3.8803e-02, -7.4390e-02, -1.1411e-01,  1.3720e-01,  1.0470e-01,\n         -8.6557e-02, -2.6089e-02, -9.7992e-03, -4.4786e-02,  1.5260e-01,\n         -1.5269e-01,  1.5827e-01, -1.3424e-01,  1.7071e-01, -1.6355e-01,\n          1.5711e-01,  7.9493e-02,  3.4976e-02, -1.7199e-01, -1.1040e-01,\n         -1.7041e-01,  3.0975e-02,  2.6842e-02,  1.2895e-01, -1.5353e-02,\n         -1.3625e-01,  2.9722e-02,  1.7191e-01, -9.0944e-02, -1.4491e-01,\n         -1.2892e-01, -1.1712e-01],\n        [ 8.8564e-02,  3.0399e-02, -1.2635e-01, -5.2552e-02,  1.0100e-01,\n         -7.4215e-02, -7.6603e-02,  6.9470e-02, -6.3732e-02, -1.7081e-01,\n          6.7135e-02,  8.6652e-02, -7.8740e-02, -5.0395e-02, -1.7317e-01,\n          7.8204e-02,  1.7050e-01, -4.8096e-02,  3.3431e-03,  6.6128e-02,\n         -1.5052e-01,  1.1789e-01, -1.4308e-01,  6.8469e-02,  1.4189e-01,\n          5.4393e-02, -1.7156e-01,  3.1196e-02,  7.6731e-02, -1.1578e-02,\n          9.0267e-02, -1.6591e-01],\n        [-3.2607e-02, -1.0885e-01, -1.7228e-01, -7.1513e-02, -8.0142e-03,\n         -8.4965e-02,  1.3501e-01, -1.3009e-01,  1.4085e-02, -5.3304e-02,\n          1.3371e-01, -6.0707e-02, -1.7505e-01,  2.7268e-02, -1.5261e-02,\n          1.3356e-01, -1.6886e-01, -1.7532e-01,  1.3733e-01,  1.6114e-01,\n         -8.8969e-02,  1.6673e-01, -4.7743e-02,  6.9167e-02,  2.6522e-02,\n         -1.5997e-01,  5.9953e-02,  6.6886e-02, -4.5106e-02,  8.4265e-03,\n         -3.2325e-03, -1.6689e-01],\n        [-9.8598e-02,  5.2141e-02,  5.6807e-02, -1.0786e-01, -5.6104e-02,\n         -3.4937e-02, -1.5036e-01,  9.5348e-02,  1.7123e-01,  4.0744e-02,\n         -1.4042e-01, -1.0539e-01, -1.2998e-01,  3.0485e-02, -7.7563e-02,\n         -1.7999e-02, -6.3328e-02,  1.8292e-02,  8.8462e-02,  9.3478e-02,\n          6.2998e-02, -6.6027e-02,  1.6695e-01,  1.5972e-01, -1.3021e-01,\n         -1.4991e-01,  7.1828e-02, -2.2466e-03,  8.0763e-02,  2.4445e-06,\n          1.7555e-01,  1.4922e-01],\n        [ 8.2238e-02, -1.3149e-01,  8.7406e-02, -1.7464e-01,  1.0924e-02,\n         -8.1022e-02, -1.5011e-01, -1.2583e-02,  1.0462e-01, -1.6128e-01,\n          1.0638e-01, -1.2404e-01, -4.7245e-03, -1.0124e-01, -3.7034e-02,\n          1.2687e-01, -9.4055e-02,  1.1414e-01, -3.4211e-02,  6.6369e-02,\n         -1.6484e-01,  6.4144e-02,  6.8689e-02,  6.1724e-02, -1.2570e-01,\n         -1.7069e-01, -1.6733e-01, -2.7425e-03, -7.1310e-02,  9.2118e-02,\n         -1.7094e-01, -3.0322e-02],\n        [-1.4678e-01, -3.5834e-03,  7.8780e-02, -3.5508e-02, -1.6811e-02,\n         -1.7583e-01,  1.5891e-01,  4.4192e-02,  9.0453e-02,  4.7024e-03,\n         -7.3294e-02,  1.6020e-01, -8.5782e-02,  3.0344e-02, -1.5481e-01,\n          5.7321e-02, -1.4681e-01,  1.5541e-01,  5.0293e-02,  1.2951e-01,\n          1.0980e-01, -5.9731e-02,  5.4594e-02, -3.9851e-02, -1.3769e-01,\n         -2.4415e-02, -1.4695e-01, -1.3610e-01, -9.0565e-02, -1.1351e-01,\n         -1.0795e-01, -1.9934e-02],\n        [ 3.5327e-02,  1.4014e-01, -1.3560e-01,  1.2978e-01, -1.6277e-01,\n         -1.1427e-01, -1.0586e-02,  1.6292e-01,  6.0734e-03,  1.5061e-02,\n          3.6422e-02, -7.3511e-03, -1.6378e-01,  8.6371e-02,  6.7631e-02,\n         -5.8105e-02,  3.5592e-03,  1.7427e-01,  4.8416e-02,  1.2994e-01,\n          6.9957e-02,  9.9750e-02,  1.5269e-01, -7.1752e-02, -1.2448e-02,\n          1.2613e-01,  5.2142e-02, -1.6611e-01, -1.2308e-02,  4.1621e-02,\n          8.7941e-02,  1.0841e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2119,  0.0868, -0.0714,  0.2214, -0.0576, -0.0754, -0.0750, -0.2381],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1476, -0.2435, -0.0367, -0.1854,  0.0585,  0.0799, -0.0462, -0.0334,\n          0.0676, -0.1608,  0.1449,  0.2155,  0.0899, -0.0661, -0.0256, -0.2069],\n        [ 0.1316, -0.1843, -0.0249,  0.1124,  0.1553,  0.2397,  0.0459, -0.2461,\n         -0.0218, -0.0379, -0.2443,  0.1026,  0.0152, -0.0318,  0.0053,  0.2115],\n        [-0.1993,  0.2146,  0.0202, -0.0415, -0.1212, -0.0425,  0.1573, -0.0255,\n         -0.0146,  0.2042,  0.2002, -0.1220, -0.1695,  0.0240, -0.2210, -0.1280],\n        [ 0.2277, -0.1575,  0.0420, -0.0802,  0.1495,  0.2011, -0.2069, -0.1761,\n          0.0488, -0.2433, -0.2461, -0.0141, -0.2155, -0.2258,  0.2006,  0.1048],\n        [-0.0768,  0.2308, -0.2229, -0.1469,  0.0070, -0.2210,  0.0172,  0.2249,\n         -0.1723,  0.1584, -0.0593, -0.0697, -0.1271, -0.1130, -0.2118,  0.0945],\n        [-0.2429, -0.0709, -0.1429, -0.0511,  0.1531, -0.0019,  0.1719,  0.2039,\n          0.1932, -0.1027,  0.2210,  0.2290, -0.2142,  0.1944,  0.1475, -0.1117],\n        [ 0.0046, -0.0546,  0.0090,  0.1052,  0.2042,  0.1662, -0.0565,  0.0559,\n         -0.0257, -0.2039, -0.1996,  0.0271, -0.2109,  0.2351,  0.1965,  0.2272],\n        [-0.1358,  0.0762, -0.2433, -0.1998,  0.0464,  0.1418,  0.0318,  0.1710,\n         -0.0198, -0.0128,  0.1027, -0.1846,  0.2406, -0.0837, -0.1128,  0.2368]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1824], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3153,  0.1312,  0.2239,  0.2989, -0.2698,  0.2607, -0.0419, -0.1175]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 2.4488e-01,  3.4899e-01, -1.0877e-02, -9.9497e-02,  1.5042e-01,\n         -2.6682e-01,  2.3463e-02, -3.2838e-01],\n        [ 2.1709e-01, -3.3592e-01,  9.9849e-02,  1.4359e-01, -2.0588e-01,\n          3.5317e-01,  1.5341e-02, -1.7570e-01],\n        [ 1.8718e-01,  3.0239e-01,  1.5343e-01,  1.8360e-02,  2.5509e-01,\n          5.2510e-02, -2.1330e-02, -2.9117e-01],\n        [-5.8697e-02, -7.3650e-02, -1.1439e-01, -1.8080e-01, -1.0523e-01,\n          2.6622e-01,  6.4895e-02, -1.3779e-01],\n        [ 2.1054e-01,  2.4120e-01, -1.6231e-01, -9.2057e-02, -1.6174e-01,\n         -6.3539e-02,  2.2520e-01, -7.7104e-02],\n        [ 1.7001e-01,  2.1637e-01, -1.1521e-01,  3.3475e-01, -2.9451e-01,\n         -2.7541e-01, -1.9196e-01,  3.2989e-01],\n        [-1.8010e-01,  1.3520e-01,  3.1567e-01,  1.9388e-01, -3.1053e-03,\n          4.3639e-02, -2.3343e-01,  1.0735e-01],\n        [ 2.3601e-01,  2.3782e-02, -1.0089e-01, -1.6519e-01,  2.0145e-01,\n         -9.2841e-02,  4.6030e-02,  2.6266e-01],\n        [-5.9518e-02,  1.1716e-01,  2.4767e-01,  1.5257e-02, -3.4839e-04,\n          1.6935e-01, -1.4886e-01,  1.3290e-01],\n        [-1.6840e-02,  4.7876e-02,  1.5918e-01,  1.7558e-01, -1.7998e-01,\n         -9.9615e-02,  2.0951e-01, -7.6434e-02],\n        [ 2.1056e-01, -2.6403e-01, -1.8708e-01, -2.5073e-01, -1.6358e-01,\n          6.8327e-03, -2.2257e-02,  4.9814e-02],\n        [ 2.3644e-02,  2.3847e-01,  3.4911e-01, -3.5349e-01, -2.0612e-01,\n         -3.3116e-01, -3.3679e-01, -1.1654e-01],\n        [ 3.4944e-01, -3.4508e-01,  5.9158e-02, -3.3283e-01,  5.9167e-02,\n         -7.0621e-02,  1.3829e-01, -1.6790e-01],\n        [ 1.4868e-01,  1.5780e-01, -2.0462e-01, -1.6432e-01,  1.8310e-01,\n          9.3949e-02, -1.5272e-02,  2.8185e-01],\n        [-1.8563e-01,  1.0451e-01, -3.3987e-01, -2.0477e-01,  3.4342e-01,\n         -6.6117e-02, -3.3201e-01,  8.9705e-02],\n        [-1.6308e-01,  5.7692e-02, -1.5946e-01, -1.5439e-01,  2.1225e-01,\n          1.0893e-01, -1.0254e-01,  2.6754e-01],\n        [ 1.1609e-02, -2.3112e-01, -2.9362e-01, -2.3819e-01,  3.0987e-01,\n         -2.3961e-01, -1.1501e-02, -1.6177e-01],\n        [-3.2615e-01,  2.7010e-01, -1.1693e-01,  3.1434e-01,  1.6677e-01,\n          2.1996e-01, -1.5815e-01, -1.8920e-01],\n        [-4.7072e-02, -2.7979e-01, -2.6981e-01,  2.2977e-02, -1.9695e-01,\n         -2.2607e-01,  2.0223e-01, -2.2090e-01],\n        [-6.5456e-02, -3.3753e-03,  2.7175e-01, -3.1393e-01, -1.9699e-01,\n         -2.5706e-01, -1.1576e-01,  1.1880e-01],\n        [-1.6364e-01, -1.8441e-01,  1.8494e-01, -3.4043e-01,  2.7286e-01,\n         -2.8045e-01,  3.1011e-01, -2.5877e-01],\n        [ 2.6989e-02,  2.2430e-01, -1.2792e-01, -2.1391e-01, -5.6950e-02,\n          3.0244e-01,  1.5955e-01, -1.7577e-01],\n        [-1.8204e-01, -1.1858e-01,  3.0571e-01, -8.6241e-02,  3.3885e-01,\n         -6.0671e-02, -1.5511e-01,  1.8244e-01],\n        [-1.1282e-01, -8.5054e-02,  7.7467e-02,  9.1263e-03,  9.7518e-03,\n         -6.0804e-02,  1.0932e-01, -1.3969e-01],\n        [ 2.9320e-01, -1.7821e-02,  3.3688e-01,  2.1497e-01, -1.6824e-02,\n          3.0888e-01, -4.7314e-02, -1.6360e-01],\n        [ 2.1878e-01,  3.4241e-01,  1.6223e-01, -3.4891e-02,  3.3780e-01,\n          1.7133e-01, -1.5957e-01, -2.5509e-01],\n        [ 2.2365e-01, -3.0953e-01, -2.7909e-01,  2.1631e-01,  2.2317e-02,\n          1.0843e-01, -2.7984e-01,  2.7281e-01],\n        [-1.6761e-01, -2.6666e-01,  4.0783e-02, -1.7596e-01, -1.3980e-01,\n          1.2704e-01,  2.5110e-01,  6.8420e-02],\n        [-2.9415e-01, -1.7548e-02, -1.6116e-01,  3.2237e-01,  1.4921e-01,\n          4.9744e-02,  2.7566e-01, -1.6226e-01],\n        [-2.7435e-01, -6.2019e-02,  2.7749e-01, -1.3755e-01, -1.8451e-01,\n         -1.8144e-01,  3.3668e-01,  1.2933e-01],\n        [ 1.3978e-01, -2.7111e-01, -7.8643e-02,  1.4576e-01,  1.9057e-01,\n         -4.2173e-02,  3.3439e-01, -3.1258e-01],\n        [-2.3081e-01, -2.2903e-01, -4.4949e-02, -4.3885e-03, -1.7188e-01,\n         -2.7703e-01,  2.4322e-01, -3.1509e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0568, -0.3411,  0.3065,  0.2158, -0.3512,  0.3150,  0.0384, -0.2788,\n        -0.1486,  0.1569,  0.0949,  0.2420,  0.3380,  0.1549, -0.0520,  0.1139,\n        -0.2806,  0.2903,  0.2162, -0.0043,  0.0083,  0.2611,  0.0016,  0.2445,\n         0.2117, -0.0371,  0.2342,  0.0745, -0.0812, -0.1601,  0.1800, -0.1797],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-8.5589e-02,  1.1934e-01,  9.0498e-02, -9.1005e-02,  2.8755e-02,\n         -1.4890e-01,  9.1317e-02, -7.9022e-02, -1.0582e-02,  3.2627e-02,\n         -2.2429e-02,  1.5158e-01, -4.3207e-02, -3.9715e-02, -2.6577e-02,\n          9.5598e-02,  5.0803e-02,  3.8576e-02, -2.5047e-02,  1.1708e-01,\n         -3.0650e-03,  3.2499e-04,  2.3447e-02,  1.3734e-01,  1.1983e-01,\n         -1.6960e-01,  1.3678e-01,  5.3121e-02,  1.2888e-01, -6.0782e-02,\n          1.4174e-01, -1.0028e-01],\n        [ 7.2415e-02,  1.2854e-01,  8.5951e-02, -1.5491e-01,  1.6137e-01,\n         -3.0528e-02, -6.2283e-02, -1.1389e-01, -7.5680e-02, -1.3531e-01,\n         -8.1199e-03,  1.0777e-01, -1.6876e-01, -1.4785e-01,  1.2715e-01,\n          4.5611e-02,  1.0026e-01,  8.0029e-02, -2.8594e-02,  1.1077e-01,\n          7.5974e-02,  7.7656e-02,  9.2777e-02, -1.4465e-01, -3.3865e-02,\n          1.6086e-01,  3.4826e-02, -6.1616e-02, -1.6245e-01,  1.5794e-01,\n          1.0758e-02,  6.8248e-02],\n        [ 5.3227e-02, -9.0960e-02, -1.2670e-01,  8.6599e-02,  1.6912e-01,\n          5.0585e-02, -1.6973e-01,  8.2438e-02,  4.4753e-02, -4.6798e-02,\n          1.7133e-01, -7.5053e-02,  1.4580e-01, -1.5796e-01,  6.5541e-02,\n         -1.4540e-01,  1.0653e-01, -1.1597e-01,  1.3991e-01,  6.0009e-02,\n         -1.3040e-01, -4.8675e-02, -8.2924e-02, -1.2624e-01,  1.5091e-01,\n          9.1388e-02,  5.3814e-02, -2.0263e-02, -1.1893e-01,  7.1095e-02,\n          3.7242e-02, -1.6856e-01],\n        [ 1.4956e-01,  1.6785e-01,  7.2681e-02, -1.4681e-01, -1.2353e-01,\n          9.1096e-02, -8.9353e-02, -1.5486e-01, -1.9257e-02, -1.0298e-01,\n         -5.5475e-02, -2.0426e-02,  9.2576e-02,  8.7207e-02, -1.2154e-02,\n          1.6360e-01, -5.3431e-03,  1.6943e-01, -1.0178e-01, -1.3790e-02,\n         -7.0388e-02, -1.4998e-01, -5.1155e-02, -6.1257e-02, -7.3458e-03,\n         -1.4076e-01,  2.3940e-02, -1.0230e-01, -8.0611e-02, -3.6505e-02,\n          1.0011e-01, -1.5041e-01],\n        [ 1.7162e-01,  1.3476e-01, -1.3366e-01, -3.2873e-02,  5.2076e-02,\n          3.6343e-02,  7.3423e-02, -9.9376e-02, -1.3214e-01, -2.6896e-02,\n          1.3995e-01,  1.1896e-01, -1.0684e-01, -5.5797e-02, -1.1471e-01,\n         -4.2974e-02,  1.1499e-01, -1.3354e-01,  6.8563e-02,  1.1737e-01,\n          1.4471e-01,  1.6204e-01, -1.0501e-01,  9.1889e-02, -1.5652e-01,\n          7.9491e-02, -1.0624e-01,  9.8400e-02, -3.6771e-02, -1.5481e-01,\n          1.0437e-01,  1.5932e-01],\n        [-1.6628e-01, -1.3777e-01,  1.4486e-01, -1.2817e-01, -1.3025e-03,\n          1.0268e-01,  1.4132e-01,  1.3800e-01, -1.6990e-01,  1.4539e-01,\n          1.1527e-01,  8.4840e-02,  2.5403e-02, -5.6552e-02,  4.4611e-02,\n         -1.0274e-01, -1.6661e-02,  1.6575e-01,  9.9542e-02,  3.1716e-02,\n          6.5212e-02,  9.2892e-02, -1.2137e-01,  2.1948e-02,  5.0492e-02,\n          1.4829e-01, -4.1314e-04, -3.6683e-02, -9.7181e-02,  3.7191e-02,\n          1.4903e-01,  4.0733e-02],\n        [-5.8092e-02,  1.0285e-01,  1.6218e-01, -1.4101e-01, -6.5766e-02,\n          1.3099e-01, -1.4732e-01, -1.3221e-01,  1.0951e-01,  3.7485e-03,\n          8.6270e-02,  1.1287e-02, -4.8362e-02,  4.7793e-02,  1.5923e-01,\n          2.0831e-02, -3.1535e-02,  7.3634e-02, -1.5335e-01,  1.6785e-01,\n         -1.2931e-01, -1.7198e-01, -1.7639e-01,  1.2561e-02, -2.5978e-02,\n         -4.1059e-02, -3.9665e-02,  1.3104e-01, -1.1607e-01,  1.2578e-01,\n          4.3890e-03, -8.8497e-02],\n        [-1.5748e-01,  1.6027e-01,  7.9888e-02,  5.3548e-03, -9.1318e-02,\n          2.5276e-02,  5.8655e-03,  7.5299e-02,  5.4346e-03,  3.3463e-02,\n         -2.7191e-03,  8.8351e-02,  8.5941e-02,  1.6225e-01,  9.9086e-02,\n         -1.3872e-01,  1.5436e-01,  1.3511e-01, -9.1458e-02, -1.5958e-01,\n          1.6759e-01, -1.3604e-01,  1.2626e-02, -1.0953e-01, -8.9133e-02,\n         -9.5809e-02, -2.4246e-02, -1.1782e-01, -1.0160e-01, -1.4802e-01,\n          1.2919e-01,  7.3811e-02],\n        [ 1.4047e-01,  6.6845e-02, -1.5961e-01, -4.6183e-03,  1.0425e-01,\n          1.5061e-01,  1.0058e-01, -6.1494e-02, -8.2604e-03, -1.3248e-01,\n          4.6687e-02, -1.1448e-01,  8.7734e-03, -1.4001e-01,  7.4950e-02,\n         -5.9222e-02,  6.6829e-03,  1.3429e-01, -1.7565e-01,  9.8052e-02,\n         -1.0598e-01, -6.0367e-02,  3.0657e-02, -9.1076e-02,  7.6515e-02,\n         -3.0620e-02, -2.5403e-02,  4.6884e-02,  1.0014e-02,  7.9764e-02,\n         -4.6351e-02, -1.6537e-01],\n        [-3.8803e-02, -7.4390e-02, -1.1411e-01,  1.3720e-01,  1.0470e-01,\n         -8.6557e-02, -2.6089e-02, -9.7992e-03, -4.4786e-02,  1.5260e-01,\n         -1.5269e-01,  1.5827e-01, -1.3424e-01,  1.7071e-01, -1.6355e-01,\n          1.5711e-01,  7.9493e-02,  3.4976e-02, -1.7199e-01, -1.1040e-01,\n         -1.7041e-01,  3.0975e-02,  2.6842e-02,  1.2895e-01, -1.5353e-02,\n         -1.3625e-01,  2.9722e-02,  1.7191e-01, -9.0944e-02, -1.4491e-01,\n         -1.2892e-01, -1.1712e-01],\n        [ 8.8564e-02,  3.0399e-02, -1.2635e-01, -5.2552e-02,  1.0100e-01,\n         -7.4215e-02, -7.6603e-02,  6.9470e-02, -6.3732e-02, -1.7081e-01,\n          6.7135e-02,  8.6652e-02, -7.8740e-02, -5.0395e-02, -1.7317e-01,\n          7.8204e-02,  1.7050e-01, -4.8096e-02,  3.3431e-03,  6.6128e-02,\n         -1.5052e-01,  1.1789e-01, -1.4308e-01,  6.8469e-02,  1.4189e-01,\n          5.4393e-02, -1.7156e-01,  3.1196e-02,  7.6731e-02, -1.1578e-02,\n          9.0267e-02, -1.6591e-01],\n        [-3.2607e-02, -1.0885e-01, -1.7228e-01, -7.1513e-02, -8.0142e-03,\n         -8.4965e-02,  1.3501e-01, -1.3009e-01,  1.4085e-02, -5.3304e-02,\n          1.3371e-01, -6.0707e-02, -1.7505e-01,  2.7268e-02, -1.5261e-02,\n          1.3356e-01, -1.6886e-01, -1.7532e-01,  1.3733e-01,  1.6114e-01,\n         -8.8969e-02,  1.6673e-01, -4.7743e-02,  6.9167e-02,  2.6522e-02,\n         -1.5997e-01,  5.9953e-02,  6.6886e-02, -4.5106e-02,  8.4265e-03,\n         -3.2325e-03, -1.6689e-01],\n        [-9.8598e-02,  5.2141e-02,  5.6807e-02, -1.0786e-01, -5.6104e-02,\n         -3.4937e-02, -1.5036e-01,  9.5348e-02,  1.7123e-01,  4.0744e-02,\n         -1.4042e-01, -1.0539e-01, -1.2998e-01,  3.0485e-02, -7.7563e-02,\n         -1.7999e-02, -6.3328e-02,  1.8292e-02,  8.8462e-02,  9.3478e-02,\n          6.2998e-02, -6.6027e-02,  1.6695e-01,  1.5972e-01, -1.3021e-01,\n         -1.4991e-01,  7.1828e-02, -2.2466e-03,  8.0763e-02,  2.4445e-06,\n          1.7555e-01,  1.4922e-01],\n        [ 8.2238e-02, -1.3149e-01,  8.7406e-02, -1.7464e-01,  1.0924e-02,\n         -8.1022e-02, -1.5011e-01, -1.2583e-02,  1.0462e-01, -1.6128e-01,\n          1.0638e-01, -1.2404e-01, -4.7245e-03, -1.0124e-01, -3.7034e-02,\n          1.2687e-01, -9.4055e-02,  1.1414e-01, -3.4211e-02,  6.6369e-02,\n         -1.6484e-01,  6.4144e-02,  6.8689e-02,  6.1724e-02, -1.2570e-01,\n         -1.7069e-01, -1.6733e-01, -2.7425e-03, -7.1310e-02,  9.2118e-02,\n         -1.7094e-01, -3.0322e-02],\n        [-1.4678e-01, -3.5834e-03,  7.8780e-02, -3.5508e-02, -1.6811e-02,\n         -1.7583e-01,  1.5891e-01,  4.4192e-02,  9.0453e-02,  4.7024e-03,\n         -7.3294e-02,  1.6020e-01, -8.5782e-02,  3.0344e-02, -1.5481e-01,\n          5.7321e-02, -1.4681e-01,  1.5541e-01,  5.0293e-02,  1.2951e-01,\n          1.0980e-01, -5.9731e-02,  5.4594e-02, -3.9851e-02, -1.3769e-01,\n         -2.4415e-02, -1.4695e-01, -1.3610e-01, -9.0565e-02, -1.1351e-01,\n         -1.0795e-01, -1.9934e-02],\n        [ 3.5327e-02,  1.4014e-01, -1.3560e-01,  1.2978e-01, -1.6277e-01,\n         -1.1427e-01, -1.0586e-02,  1.6292e-01,  6.0734e-03,  1.5061e-02,\n          3.6422e-02, -7.3511e-03, -1.6378e-01,  8.6371e-02,  6.7631e-02,\n         -5.8105e-02,  3.5592e-03,  1.7427e-01,  4.8416e-02,  1.2994e-01,\n          6.9957e-02,  9.9750e-02,  1.5269e-01, -7.1752e-02, -1.2448e-02,\n          1.2613e-01,  5.2142e-02, -1.6611e-01, -1.2308e-02,  4.1621e-02,\n          8.7941e-02,  1.0841e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1526, -0.0567, -0.1065,  0.1436,  0.0012, -0.0292,  0.1030,  0.0337,\n         0.0758, -0.0955, -0.1448,  0.0109,  0.1002, -0.1567, -0.0149, -0.0059],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1476, -0.2435, -0.0367, -0.1854,  0.0585,  0.0799, -0.0462, -0.0334,\n          0.0676, -0.1608,  0.1449,  0.2155,  0.0899, -0.0661, -0.0256, -0.2069],\n        [ 0.1316, -0.1843, -0.0249,  0.1124,  0.1553,  0.2397,  0.0459, -0.2461,\n         -0.0218, -0.0379, -0.2443,  0.1026,  0.0152, -0.0318,  0.0053,  0.2115],\n        [-0.1993,  0.2146,  0.0202, -0.0415, -0.1212, -0.0425,  0.1573, -0.0255,\n         -0.0146,  0.2042,  0.2002, -0.1220, -0.1695,  0.0240, -0.2210, -0.1280],\n        [ 0.2277, -0.1575,  0.0420, -0.0802,  0.1495,  0.2011, -0.2069, -0.1761,\n          0.0488, -0.2433, -0.2461, -0.0141, -0.2155, -0.2258,  0.2006,  0.1048],\n        [-0.0768,  0.2308, -0.2229, -0.1469,  0.0070, -0.2210,  0.0172,  0.2249,\n         -0.1723,  0.1584, -0.0593, -0.0697, -0.1271, -0.1130, -0.2118,  0.0945],\n        [-0.2429, -0.0709, -0.1429, -0.0511,  0.1531, -0.0019,  0.1719,  0.2039,\n          0.1932, -0.1027,  0.2210,  0.2290, -0.2142,  0.1944,  0.1475, -0.1117],\n        [ 0.0046, -0.0546,  0.0090,  0.1052,  0.2042,  0.1662, -0.0565,  0.0559,\n         -0.0257, -0.2039, -0.1996,  0.0271, -0.2109,  0.2351,  0.1965,  0.2272],\n        [-0.1358,  0.0762, -0.2433, -0.1998,  0.0464,  0.1418,  0.0318,  0.1710,\n         -0.0198, -0.0128,  0.1027, -0.1846,  0.2406, -0.0837, -0.1128,  0.2368]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2119,  0.0868, -0.0714,  0.2214, -0.0576, -0.0754, -0.0750, -0.2381],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3153,  0.1312,  0.2239,  0.2989, -0.2698,  0.2607, -0.0419, -0.1175]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1824], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x102587e80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x30300e590>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s184920000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s184920000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}