{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s185270000"
    },
    "q_lr":	0.0005,
    "seed":	185270000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x70be59f9cd90>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=32, out_features=16, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=16, out_features=8, bias=True)\n    (9): ReLU()\n    (10): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=32, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=32, out_features=16, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=16, out_features=8, bias=True)\n  (9): ReLU()\n  (10): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0374, -0.1362,  0.2812,  0.3161, -0.0754, -0.0194, -0.1546, -0.0920,\n         0.0156, -0.3040,  0.2331, -0.3410, -0.0411, -0.1029, -0.3312, -0.0482,\n        -0.0969,  0.2682, -0.3324, -0.0273,  0.3338,  0.2887, -0.1589,  0.1743,\n        -0.1611, -0.1169, -0.1357,  0.1715, -0.2674, -0.1605,  0.3241,  0.2294,\n         0.3416, -0.0188,  0.2567, -0.1059,  0.1299,  0.2619,  0.0053, -0.1822,\n         0.2775,  0.0878,  0.0295, -0.0168,  0.2071, -0.2543, -0.3480, -0.0892,\n        -0.2661,  0.1459, -0.2554,  0.1917,  0.0408,  0.2681, -0.0101,  0.2496,\n         0.3512,  0.0007, -0.3217, -0.1825, -0.0392, -0.2831, -0.1026,  0.1099],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2265, -0.0198, -0.1033, -0.1393, -0.1041, -0.1517, -0.0735, -0.0433],\n        [-0.2451, -0.0568, -0.0250, -0.1438, -0.2922, -0.0324,  0.2420, -0.1826],\n        [-0.2490, -0.2571, -0.1373,  0.1890, -0.3250,  0.2716, -0.1164, -0.0840],\n        [ 0.0705,  0.3386,  0.0886, -0.0511, -0.1978, -0.2082,  0.0332,  0.0204],\n        [-0.1659,  0.0371,  0.3072,  0.0173,  0.3248, -0.1542,  0.0299,  0.3360],\n        [ 0.0716,  0.1528,  0.2457, -0.0917,  0.2606, -0.1715, -0.2931, -0.1748],\n        [-0.1016,  0.0408,  0.2238,  0.0419,  0.1755,  0.2852,  0.1422,  0.3207],\n        [ 0.2405, -0.3366, -0.3157,  0.0902,  0.3239, -0.0009,  0.2339,  0.0742],\n        [-0.1378,  0.2583,  0.2601,  0.0154,  0.1125, -0.3226, -0.0825,  0.0543],\n        [ 0.2376,  0.1450, -0.2156, -0.0634,  0.0323, -0.1318, -0.0623,  0.1145],\n        [-0.2188, -0.0803,  0.1331, -0.1917, -0.0724, -0.0247, -0.1153,  0.2103],\n        [ 0.3200,  0.0871, -0.3490,  0.0712, -0.1384, -0.2261,  0.0657,  0.2533],\n        [-0.1224,  0.3234,  0.1355,  0.2038, -0.0428, -0.2199,  0.0034, -0.3105],\n        [ 0.1806, -0.1971,  0.0959, -0.1641, -0.0124,  0.2695,  0.2619, -0.3099],\n        [-0.1710,  0.0665, -0.1598,  0.2862,  0.1546, -0.2204,  0.3194,  0.1575],\n        [-0.1553, -0.2933, -0.2775,  0.3403,  0.2117,  0.1446,  0.1782, -0.0791],\n        [ 0.2037, -0.1543, -0.3499,  0.1635, -0.1319,  0.0908, -0.2986, -0.3234],\n        [-0.0500, -0.2772,  0.3188,  0.2195, -0.1497,  0.2913,  0.1111, -0.1255],\n        [ 0.2959, -0.3088, -0.0432,  0.0026,  0.0931,  0.3053, -0.1758, -0.2814],\n        [ 0.1795, -0.3238,  0.1134,  0.0529, -0.0278,  0.1109,  0.2104,  0.2304],\n        [-0.2037,  0.2333, -0.3535,  0.0882, -0.2906,  0.2569, -0.1674, -0.2975],\n        [-0.0344,  0.1843,  0.3366,  0.0030, -0.0223,  0.0639, -0.0141, -0.2644],\n        [ 0.3308,  0.2734, -0.0799,  0.3397, -0.0169, -0.0073, -0.2645, -0.3487],\n        [-0.2144, -0.2092, -0.2370, -0.2821,  0.2798,  0.3482,  0.1370, -0.0012],\n        [ 0.0237, -0.2633,  0.1567,  0.0053, -0.0413, -0.1851, -0.1019,  0.3528],\n        [ 0.1286, -0.1568,  0.1278, -0.0214,  0.1669,  0.2406,  0.2822,  0.0654],\n        [ 0.2464, -0.2858, -0.1321, -0.0211,  0.2496,  0.2739, -0.1743,  0.2098],\n        [ 0.2250, -0.2087,  0.0852, -0.2650, -0.0930,  0.3003, -0.3014,  0.1633],\n        [ 0.0384,  0.3457,  0.2056, -0.1605, -0.2095, -0.3355, -0.2811, -0.3244],\n        [-0.0392, -0.0122,  0.1864, -0.2562,  0.2584, -0.2836,  0.0715,  0.3016],\n        [-0.0292,  0.1164,  0.3527, -0.1576,  0.1873, -0.2519, -0.3495, -0.0497],\n        [ 0.3325, -0.1816,  0.3295, -0.3083, -0.2543,  0.1587, -0.0169,  0.0779],\n        [ 0.3280, -0.1725, -0.2325, -0.0925, -0.2852,  0.0664,  0.0584, -0.2358],\n        [ 0.3019,  0.0550,  0.2965,  0.0030,  0.0479,  0.0698,  0.1169, -0.0317],\n        [-0.1957, -0.1238, -0.1962,  0.2967,  0.0446, -0.1857, -0.3203, -0.1157],\n        [ 0.2985, -0.2476, -0.2500, -0.0238,  0.1926, -0.1539,  0.1764, -0.2343],\n        [ 0.1219,  0.2628, -0.2786,  0.1246,  0.2555, -0.0304,  0.1545,  0.2934],\n        [ 0.2804,  0.0572, -0.2576,  0.3247, -0.1940, -0.2774,  0.1299,  0.1052],\n        [-0.0799,  0.1881, -0.1487, -0.2875,  0.1579, -0.0529,  0.0214,  0.1080],\n        [-0.3226,  0.1301,  0.0546,  0.2665,  0.3451, -0.2502,  0.1365, -0.2971],\n        [-0.0957,  0.1646, -0.0841, -0.0367, -0.2999,  0.1936, -0.1988,  0.0977],\n        [-0.2213,  0.3510,  0.0805, -0.0524, -0.0796, -0.0734, -0.2483, -0.1201],\n        [ 0.2165,  0.1410, -0.0101,  0.0736, -0.2379, -0.0424, -0.0974, -0.1869],\n        [ 0.1821, -0.0224, -0.3213, -0.1752, -0.1244,  0.2942,  0.0475,  0.2538],\n        [ 0.1169, -0.0436, -0.0177,  0.0477, -0.1664,  0.2689, -0.1341, -0.1139],\n        [-0.1522, -0.3371, -0.3317,  0.0491,  0.0097,  0.2962,  0.1100,  0.2140],\n        [-0.3347, -0.1312, -0.0989, -0.0320,  0.2686,  0.3124, -0.1709, -0.0300],\n        [ 0.1969, -0.3457,  0.3305,  0.3165,  0.2779,  0.1769,  0.2930,  0.1042],\n        [ 0.1790, -0.0435,  0.2269, -0.2786,  0.0033,  0.2601,  0.2264,  0.2228],\n        [-0.0985, -0.1931,  0.0698,  0.2641, -0.0224, -0.1368,  0.0073, -0.3169],\n        [-0.2038, -0.0094,  0.1931,  0.0766,  0.2981,  0.3176, -0.2196, -0.1856],\n        [-0.3351,  0.1018,  0.1043,  0.1267,  0.0593, -0.1588,  0.1358,  0.1848],\n        [-0.0172,  0.1121, -0.2223,  0.0013, -0.0873,  0.2521, -0.3272,  0.2269],\n        [-0.2570,  0.1659,  0.3127,  0.3136,  0.2147, -0.0835,  0.0511, -0.0060],\n        [ 0.0153, -0.2405, -0.1677, -0.2347,  0.2804,  0.1095, -0.3301,  0.1616],\n        [-0.2760, -0.3341, -0.2084, -0.0739, -0.1023, -0.2154,  0.1017,  0.0994],\n        [ 0.1436,  0.2805,  0.0490, -0.1240, -0.2948,  0.2371, -0.2692, -0.0686],\n        [-0.3137, -0.0135, -0.2733, -0.3535,  0.1104, -0.1332,  0.1513, -0.2928],\n        [-0.0365, -0.2012, -0.1737, -0.0978, -0.1311,  0.1551,  0.3385, -0.3248],\n        [ 0.2209, -0.1121, -0.1226, -0.0440,  0.1531, -0.1572,  0.2242, -0.2037],\n        [ 0.0116,  0.3387,  0.0220, -0.1609, -0.1506, -0.3205,  0.3051,  0.0888],\n        [-0.1063,  0.3491, -0.1913, -0.2303,  0.1355, -0.1843, -0.2174,  0.1552],\n        [ 0.3172, -0.1309,  0.2828, -0.3348,  0.1597,  0.0542,  0.1136,  0.3281],\n        [ 0.0045, -0.1506,  0.0696,  0.0677, -0.2483, -0.2411, -0.2037, -0.0800]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "10":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1897], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1703,  0.2783, -0.2810, -0.1586,  0.0885,  0.0836, -0.0083, -0.1307]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=64, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0343, -0.0525,  0.0452,  0.0237,  0.0127,  0.0636,  0.0913,  0.1067,\n        -0.1097,  0.0004,  0.0088,  0.0330,  0.0940,  0.0514, -0.0925,  0.0115,\n        -0.0313, -0.0006, -0.0770, -0.0535,  0.0404,  0.0113,  0.0551, -0.0114,\n        -0.0392, -0.0075,  0.0117, -0.0815, -0.0998,  0.0638, -0.1183,  0.0598,\n         0.0811, -0.0024, -0.0821, -0.0690, -0.0330,  0.0835,  0.0635,  0.0993,\n         0.0322,  0.0926, -0.0434, -0.0450,  0.0414,  0.0712,  0.0552, -0.0586,\n         0.1140, -0.0292, -0.0953, -0.0236, -0.1096, -0.1222, -0.0516, -0.1104,\n         0.0952,  0.1192,  0.0477, -0.1049, -0.1177, -0.1168, -0.0025, -0.0062],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0316,  0.0997,  0.1223,  ..., -0.0548,  0.1060, -0.0226],\n        [-0.0222,  0.0053, -0.0990,  ..., -0.0387,  0.0526,  0.0297],\n        [-0.0238, -0.0223, -0.1080,  ...,  0.0634, -0.0484,  0.0382],\n        ...,\n        [ 0.1029,  0.0127,  0.0262,  ..., -0.0488, -0.0699, -0.0949],\n        [-0.0880,  0.0901,  0.0421,  ...,  0.0012,  0.1211, -0.0212],\n        [ 0.0320, -0.1116,  0.0096,  ..., -0.0890,  0.1026, -0.1103]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=64, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1106, -0.0020, -0.0389,  0.0336,  0.1176, -0.0291, -0.0611,  0.0483,\n         0.0523, -0.0161,  0.0743, -0.0647,  0.0323, -0.1178,  0.0189,  0.0948,\n        -0.1035,  0.0957, -0.1195, -0.1234, -0.1134, -0.0736, -0.0681,  0.1028,\n         0.0657,  0.0980, -0.0608,  0.0510, -0.1177, -0.0747, -0.1087, -0.0465],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0963,  0.0636,  0.0992,  ..., -0.0027, -0.1066, -0.0424],\n        [ 0.0606, -0.0683,  0.1122,  ..., -0.0815,  0.1068, -0.0231],\n        [-0.0562, -0.1125, -0.0915,  ...,  0.1098,  0.0385,  0.0770],\n        ...,\n        [ 0.0065,  0.0965,  0.0690,  ...,  0.0785,  0.1066, -0.0894],\n        [-0.0737,  0.0537, -0.0677,  ...,  0.1097, -0.0437,  0.0456],\n        [-0.0085, -0.1206,  0.0545,  ..., -0.1039,  0.0277, -0.0741]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1237, -0.0708,  0.0414,  0.1535, -0.1383,  0.0239, -0.1757,  0.0292,\n        -0.0365, -0.1581, -0.0309,  0.1601,  0.0737,  0.0595, -0.1388,  0.1460],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0103e-01,  1.3044e-01,  2.1441e-02, -4.4961e-02,  1.6067e-01,\n         -3.8866e-02, -2.8370e-02,  1.2057e-01, -1.1911e-01,  1.0437e-01,\n          3.9831e-02,  9.3676e-02, -1.5182e-01,  5.9657e-02,  7.6728e-02,\n         -5.3329e-02, -7.7273e-03,  1.7600e-01, -8.2391e-02, -2.8836e-02,\n         -3.8694e-02,  6.2439e-02,  8.6302e-02, -1.3421e-01, -1.0031e-01,\n         -1.0523e-02,  1.0332e-02, -8.5625e-02,  1.0190e-01,  8.0566e-02,\n          6.6741e-02,  7.8269e-02],\n        [ 1.3762e-02, -2.2304e-02,  1.1586e-01, -1.7278e-01,  3.8611e-02,\n          4.6521e-02, -7.0306e-03,  1.4322e-01, -1.3057e-01,  1.5248e-01,\n          1.3917e-01,  1.5458e-01, -4.3837e-02,  1.3806e-01,  5.2045e-02,\n         -1.7006e-01,  1.1784e-01, -1.6323e-01,  9.6609e-03, -6.2013e-02,\n         -4.7914e-02,  2.1879e-02,  1.6954e-01, -1.4265e-01,  6.6472e-02,\n          6.6532e-02,  1.5483e-01,  1.5771e-02,  1.2768e-01, -5.8863e-02,\n         -1.9344e-02,  1.2750e-01],\n        [-9.4913e-02,  1.7587e-01,  1.9909e-02, -8.0661e-02, -1.0868e-01,\n          9.9175e-02,  9.2989e-02, -1.4130e-01, -1.5815e-01, -2.9503e-07,\n         -3.3944e-02, -4.5190e-02, -1.6930e-01, -1.7593e-01, -9.5471e-02,\n         -7.4307e-02, -1.8922e-02,  5.1783e-02, -1.0376e-01, -1.4988e-01,\n         -1.1126e-02, -1.3055e-01, -1.4815e-01,  1.3285e-01, -5.9135e-02,\n          3.3885e-03, -1.1909e-01, -7.1326e-02,  1.4889e-01, -4.0584e-02,\n         -3.6682e-02, -1.2092e-01],\n        [ 3.6574e-02, -5.3938e-03,  1.7196e-01,  6.6899e-02,  1.3019e-01,\n          1.7572e-01,  1.1952e-01, -1.1186e-01, -1.3650e-02,  1.0814e-01,\n         -9.8342e-02,  1.5544e-01, -3.8964e-02,  6.1110e-02, -6.8167e-02,\n          1.6623e-01,  2.2224e-02,  1.1206e-01, -1.1009e-01, -9.3859e-03,\n          1.0064e-01, -1.4741e-01, -6.7351e-02,  1.1584e-01, -3.0706e-02,\n          4.7404e-02, -1.1732e-01,  4.5935e-02,  1.5101e-01,  6.9566e-02,\n         -1.2233e-01,  1.2690e-01],\n        [-9.2696e-03,  6.4805e-02,  9.7023e-03,  5.2360e-02, -8.9422e-02,\n         -1.6009e-01, -3.5275e-02,  1.3592e-01,  9.6468e-02,  2.8256e-02,\n         -8.7407e-02, -4.2621e-02,  1.2210e-02, -1.1344e-01,  4.3983e-02,\n          4.3575e-02, -9.9209e-04, -1.7287e-01, -6.5547e-02, -3.3157e-02,\n         -1.6209e-01, -1.5774e-01, -5.3458e-02, -2.1195e-03,  1.4338e-01,\n          5.3545e-02, -1.7516e-01, -1.6309e-01, -2.5928e-02,  3.7207e-02,\n         -8.0693e-02, -4.4303e-02],\n        [-1.4885e-01,  1.4110e-01,  1.4640e-01,  1.0536e-01,  1.0098e-01,\n         -7.4270e-02, -2.7253e-02, -2.9176e-02,  2.5915e-02,  7.7355e-02,\n         -1.0056e-04, -1.2963e-01,  4.2566e-02, -6.2533e-02,  3.2308e-02,\n          1.7411e-01, -5.5302e-02,  9.2802e-02, -5.8408e-02,  1.1260e-01,\n          1.5700e-01,  1.5141e-01, -1.0327e-02, -1.6697e-01,  1.3191e-02,\n          4.0974e-02,  1.2252e-01,  1.6357e-02, -5.8011e-02, -1.2850e-01,\n          1.1348e-01, -1.4001e-01],\n        [ 4.0685e-02,  2.4295e-03,  4.1343e-02, -1.6383e-02,  9.0169e-02,\n         -1.0170e-01,  1.4514e-01, -1.6726e-01, -1.1104e-01, -6.0736e-02,\n         -1.0053e-01,  1.0726e-01, -5.2287e-02,  9.7274e-02, -3.3491e-02,\n          9.8996e-03,  1.1460e-01, -1.5992e-01, -1.2851e-01,  8.2465e-02,\n          1.9672e-02,  5.6513e-02, -1.2552e-01,  3.7188e-02,  1.3739e-01,\n         -1.0271e-02,  1.2409e-01, -1.7308e-01,  5.4228e-02,  4.6457e-02,\n          5.6062e-02,  1.0836e-01],\n        [ 1.6763e-01, -7.3261e-02, -1.6678e-01,  5.0633e-02, -1.1385e-01,\n          5.3242e-02,  3.3491e-03,  1.2365e-01, -1.4588e-01, -1.6995e-01,\n          1.4871e-01, -1.2073e-01,  1.1859e-01,  1.2914e-01,  5.2313e-02,\n         -1.5629e-01, -1.7528e-02,  1.1265e-01, -6.0255e-02,  1.7536e-01,\n         -1.3970e-01,  1.3881e-01, -1.7483e-01, -2.6130e-02, -1.0562e-01,\n          9.3960e-03,  6.2633e-02,  4.3839e-02, -1.6581e-01, -1.7290e-01,\n          1.6696e-01, -1.2800e-01],\n        [ 1.6346e-01,  1.2823e-01, -1.5921e-01,  9.4238e-02, -1.9057e-02,\n         -1.5900e-01,  3.1200e-02, -4.1231e-02, -8.0442e-02,  3.2750e-02,\n         -1.0384e-01, -1.1537e-01, -9.2242e-02,  7.0441e-02, -3.1371e-02,\n         -1.0743e-01,  1.4583e-01,  4.7433e-02, -4.3031e-03, -2.6328e-02,\n         -1.2429e-01,  7.3315e-02,  1.2533e-01, -1.5360e-01,  9.1619e-02,\n         -1.6254e-01,  1.5371e-01, -1.4573e-01, -1.2190e-01,  1.4770e-01,\n         -1.5545e-01,  4.6542e-02],\n        [ 2.8854e-02, -1.6545e-01,  9.7410e-02, -1.3002e-01,  6.9684e-03,\n          7.7898e-02, -1.1073e-02,  1.6769e-01,  1.0238e-01, -6.3717e-02,\n         -1.6442e-01,  1.7403e-01, -7.7956e-02,  1.2504e-01,  3.8363e-02,\n         -1.9901e-03, -5.8007e-02,  8.8853e-02, -6.6489e-02,  1.1524e-02,\n          1.6475e-01, -8.1253e-02, -5.7948e-02,  1.1892e-01,  1.2521e-01,\n          1.3722e-01, -8.7516e-03,  1.0693e-01,  1.0011e-01, -7.0299e-02,\n         -1.4563e-01,  7.6046e-02],\n        [-9.9561e-02, -7.6067e-02, -8.2460e-02, -2.3403e-02, -1.6923e-01,\n          2.2483e-02,  1.2814e-02,  4.0016e-02,  4.4124e-02, -1.4038e-01,\n          1.5982e-01, -4.6964e-03,  4.7042e-02, -4.6159e-02, -8.2396e-03,\n          1.4262e-01, -4.7813e-02, -4.9447e-02, -5.1775e-02, -1.2348e-01,\n         -6.0562e-02,  6.8634e-02,  2.2589e-02,  4.7713e-02, -1.7087e-01,\n         -5.5466e-02, -1.5792e-01,  1.2372e-01, -1.1079e-01,  1.5470e-02,\n          1.5156e-01, -1.2559e-01],\n        [-1.7539e-01,  5.4746e-02,  1.3667e-02,  3.4855e-02, -1.1714e-01,\n          1.2875e-01, -4.0467e-02,  1.2339e-02,  1.7608e-01, -6.9184e-02,\n         -5.5471e-02,  4.7595e-02, -9.4965e-02, -2.5008e-02,  5.2595e-04,\n         -7.4348e-02,  3.3223e-02, -3.8691e-02, -1.6224e-01,  1.3361e-01,\n          1.2509e-01,  3.0419e-02, -1.3213e-01, -4.5709e-02, -1.2062e-01,\n          6.7443e-02, -1.1728e-01,  1.1971e-01,  8.5466e-02, -1.9701e-02,\n          1.4655e-01,  5.9635e-02],\n        [ 5.6317e-02, -1.3195e-01, -1.5144e-01,  1.6338e-01,  2.0635e-02,\n          1.3833e-02, -8.3196e-02, -7.5694e-02,  6.9188e-02,  8.5950e-02,\n          8.2537e-02, -1.0958e-01, -1.0028e-01,  1.6971e-01,  5.0574e-02,\n          8.0770e-02, -1.1800e-01,  2.8916e-02,  1.0139e-01,  1.0487e-01,\n          6.0979e-02,  8.6959e-02,  3.2206e-02,  9.6946e-02, -1.4418e-01,\n          1.6252e-01, -1.4241e-01, -9.6905e-02, -1.0654e-01,  1.6338e-01,\n          7.3340e-02, -1.7154e-01],\n        [ 1.2767e-01,  1.3975e-01, -8.6244e-02, -3.6881e-02, -1.6988e-01,\n         -2.6605e-02, -8.6876e-03, -5.8464e-02, -7.3747e-02,  7.4437e-02,\n         -1.2225e-02, -7.2475e-02, -7.8471e-02,  7.2451e-02, -6.2929e-02,\n          1.5665e-01, -1.0649e-01, -1.0771e-01,  6.2302e-02,  6.4150e-02,\n          8.7657e-02,  1.3408e-01,  8.6472e-02,  6.5170e-02,  1.0774e-01,\n          1.6147e-01,  1.0730e-01,  6.9266e-02,  1.6365e-01,  6.8378e-02,\n         -6.0933e-02, -1.0195e-01],\n        [ 7.7835e-02,  2.8441e-02,  5.4429e-02,  1.0237e-01,  1.1044e-01,\n          1.5581e-01,  9.3556e-02, -5.3081e-02,  1.3764e-01, -1.2539e-01,\n         -6.3537e-02,  7.4913e-02, -1.4848e-01,  4.5687e-02,  1.6187e-01,\n         -1.6058e-01, -1.0902e-01, -5.2994e-02, -9.1078e-02,  1.3232e-01,\n         -6.1189e-02,  1.5170e-02,  8.2260e-02,  8.0174e-02, -1.2911e-01,\n          1.7562e-01,  1.0623e-01, -1.6548e-01, -9.8150e-02,  2.6964e-02,\n         -2.5024e-02,  1.5448e-01],\n        [-1.4986e-01,  6.0753e-02,  4.5547e-02, -6.4023e-02,  1.0477e-01,\n         -1.5712e-03, -6.2100e-03,  5.0939e-03, -1.5228e-01,  1.3768e-01,\n          9.5254e-02, -5.8790e-02, -1.0545e-01, -3.5562e-03, -1.2066e-01,\n          1.3096e-01, -4.6077e-03, -1.6340e-01,  5.1689e-02, -4.7426e-02,\n         -6.8733e-02,  1.0424e-01, -1.5949e-01, -2.4109e-02,  1.0839e-01,\n          7.6810e-02,  9.4483e-02,  1.5576e-01,  2.9681e-02,  7.2787e-02,\n         -1.7128e-01, -1.8017e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "7":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "8":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0627, -0.1810,  0.0436,  0.1364, -0.0733,  0.1768,  0.0848,  0.2398],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1478, -0.0347,  0.1203,  0.1795, -0.0132, -0.0831,  0.1210,  0.1112,\n          0.0863,  0.0444, -0.1940,  0.0008,  0.1770,  0.1102,  0.2331, -0.2335],\n        [ 0.1264, -0.0415,  0.1380,  0.2352, -0.0969, -0.1986, -0.1870, -0.0100,\n          0.1026, -0.0612,  0.0938, -0.1196,  0.0230,  0.0533, -0.0380, -0.1771],\n        [-0.1321, -0.1000,  0.1790, -0.1432, -0.2169,  0.1224,  0.0379,  0.0856,\n         -0.0541, -0.1163, -0.1754,  0.1552, -0.0644,  0.0172,  0.2144,  0.1898],\n        [ 0.1269,  0.1698,  0.1593, -0.1780,  0.1633, -0.0268, -0.2481, -0.0730,\n         -0.0653, -0.0831, -0.1528, -0.1308,  0.1825,  0.1584, -0.2459, -0.2369],\n        [-0.0019, -0.1058,  0.1805,  0.0426, -0.0391, -0.0408,  0.0232,  0.1333,\n         -0.1862,  0.2285, -0.0460, -0.0312, -0.0424,  0.2244, -0.0666, -0.1754],\n        [ 0.1433,  0.1770,  0.0535,  0.0664, -0.0554,  0.0005,  0.2132,  0.0097,\n          0.1168, -0.2144, -0.2260, -0.1644, -0.0315, -0.1700, -0.0993,  0.0218],\n        [-0.0541,  0.1533,  0.0854, -0.2259, -0.0220,  0.0322, -0.1195, -0.1128,\n         -0.2281, -0.2126,  0.0701, -0.1840,  0.2086, -0.2008,  0.2285,  0.1332],\n        [ 0.1376, -0.0878, -0.1574,  0.1474, -0.1687,  0.1683, -0.0573, -0.0853,\n         -0.1920, -0.1556,  0.1913,  0.1870, -0.2477, -0.2288, -0.1557, -0.0579]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "9":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2265, -0.0198, -0.1033, -0.1393, -0.1041, -0.1517, -0.0735, -0.0433],\n        [-0.2451, -0.0568, -0.0250, -0.1438, -0.2922, -0.0324,  0.2420, -0.1826],\n        [-0.2490, -0.2571, -0.1373,  0.1890, -0.3250,  0.2716, -0.1164, -0.0840],\n        [ 0.0705,  0.3386,  0.0886, -0.0511, -0.1978, -0.2082,  0.0332,  0.0204],\n        [-0.1659,  0.0371,  0.3072,  0.0173,  0.3248, -0.1542,  0.0299,  0.3360],\n        [ 0.0716,  0.1528,  0.2457, -0.0917,  0.2606, -0.1715, -0.2931, -0.1748],\n        [-0.1016,  0.0408,  0.2238,  0.0419,  0.1755,  0.2852,  0.1422,  0.3207],\n        [ 0.2405, -0.3366, -0.3157,  0.0902,  0.3239, -0.0009,  0.2339,  0.0742],\n        [-0.1378,  0.2583,  0.2601,  0.0154,  0.1125, -0.3226, -0.0825,  0.0543],\n        [ 0.2376,  0.1450, -0.2156, -0.0634,  0.0323, -0.1318, -0.0623,  0.1145],\n        [-0.2188, -0.0803,  0.1331, -0.1917, -0.0724, -0.0247, -0.1153,  0.2103],\n        [ 0.3200,  0.0871, -0.3490,  0.0712, -0.1384, -0.2261,  0.0657,  0.2533],\n        [-0.1224,  0.3234,  0.1355,  0.2038, -0.0428, -0.2199,  0.0034, -0.3105],\n        [ 0.1806, -0.1971,  0.0959, -0.1641, -0.0124,  0.2695,  0.2619, -0.3099],\n        [-0.1710,  0.0665, -0.1598,  0.2862,  0.1546, -0.2204,  0.3194,  0.1575],\n        [-0.1553, -0.2933, -0.2775,  0.3403,  0.2117,  0.1446,  0.1782, -0.0791],\n        [ 0.2037, -0.1543, -0.3499,  0.1635, -0.1319,  0.0908, -0.2986, -0.3234],\n        [-0.0500, -0.2772,  0.3188,  0.2195, -0.1497,  0.2913,  0.1111, -0.1255],\n        [ 0.2959, -0.3088, -0.0432,  0.0026,  0.0931,  0.3053, -0.1758, -0.2814],\n        [ 0.1795, -0.3238,  0.1134,  0.0529, -0.0278,  0.1109,  0.2104,  0.2304],\n        [-0.2037,  0.2333, -0.3535,  0.0882, -0.2906,  0.2569, -0.1674, -0.2975],\n        [-0.0344,  0.1843,  0.3366,  0.0030, -0.0223,  0.0639, -0.0141, -0.2644],\n        [ 0.3308,  0.2734, -0.0799,  0.3397, -0.0169, -0.0073, -0.2645, -0.3487],\n        [-0.2144, -0.2092, -0.2370, -0.2821,  0.2798,  0.3482,  0.1370, -0.0012],\n        [ 0.0237, -0.2633,  0.1567,  0.0053, -0.0413, -0.1851, -0.1019,  0.3528],\n        [ 0.1286, -0.1568,  0.1278, -0.0214,  0.1669,  0.2406,  0.2822,  0.0654],\n        [ 0.2464, -0.2858, -0.1321, -0.0211,  0.2496,  0.2739, -0.1743,  0.2098],\n        [ 0.2250, -0.2087,  0.0852, -0.2650, -0.0930,  0.3003, -0.3014,  0.1633],\n        [ 0.0384,  0.3457,  0.2056, -0.1605, -0.2095, -0.3355, -0.2811, -0.3244],\n        [-0.0392, -0.0122,  0.1864, -0.2562,  0.2584, -0.2836,  0.0715,  0.3016],\n        [-0.0292,  0.1164,  0.3527, -0.1576,  0.1873, -0.2519, -0.3495, -0.0497],\n        [ 0.3325, -0.1816,  0.3295, -0.3083, -0.2543,  0.1587, -0.0169,  0.0779],\n        [ 0.3280, -0.1725, -0.2325, -0.0925, -0.2852,  0.0664,  0.0584, -0.2358],\n        [ 0.3019,  0.0550,  0.2965,  0.0030,  0.0479,  0.0698,  0.1169, -0.0317],\n        [-0.1957, -0.1238, -0.1962,  0.2967,  0.0446, -0.1857, -0.3203, -0.1157],\n        [ 0.2985, -0.2476, -0.2500, -0.0238,  0.1926, -0.1539,  0.1764, -0.2343],\n        [ 0.1219,  0.2628, -0.2786,  0.1246,  0.2555, -0.0304,  0.1545,  0.2934],\n        [ 0.2804,  0.0572, -0.2576,  0.3247, -0.1940, -0.2774,  0.1299,  0.1052],\n        [-0.0799,  0.1881, -0.1487, -0.2875,  0.1579, -0.0529,  0.0214,  0.1080],\n        [-0.3226,  0.1301,  0.0546,  0.2665,  0.3451, -0.2502,  0.1365, -0.2971],\n        [-0.0957,  0.1646, -0.0841, -0.0367, -0.2999,  0.1936, -0.1988,  0.0977],\n        [-0.2213,  0.3510,  0.0805, -0.0524, -0.0796, -0.0734, -0.2483, -0.1201],\n        [ 0.2165,  0.1410, -0.0101,  0.0736, -0.2379, -0.0424, -0.0974, -0.1869],\n        [ 0.1821, -0.0224, -0.3213, -0.1752, -0.1244,  0.2942,  0.0475,  0.2538],\n        [ 0.1169, -0.0436, -0.0177,  0.0477, -0.1664,  0.2689, -0.1341, -0.1139],\n        [-0.1522, -0.3371, -0.3317,  0.0491,  0.0097,  0.2962,  0.1100,  0.2140],\n        [-0.3347, -0.1312, -0.0989, -0.0320,  0.2686,  0.3124, -0.1709, -0.0300],\n        [ 0.1969, -0.3457,  0.3305,  0.3165,  0.2779,  0.1769,  0.2930,  0.1042],\n        [ 0.1790, -0.0435,  0.2269, -0.2786,  0.0033,  0.2601,  0.2264,  0.2228],\n        [-0.0985, -0.1931,  0.0698,  0.2641, -0.0224, -0.1368,  0.0073, -0.3169],\n        [-0.2038, -0.0094,  0.1931,  0.0766,  0.2981,  0.3176, -0.2196, -0.1856],\n        [-0.3351,  0.1018,  0.1043,  0.1267,  0.0593, -0.1588,  0.1358,  0.1848],\n        [-0.0172,  0.1121, -0.2223,  0.0013, -0.0873,  0.2521, -0.3272,  0.2269],\n        [-0.2570,  0.1659,  0.3127,  0.3136,  0.2147, -0.0835,  0.0511, -0.0060],\n        [ 0.0153, -0.2405, -0.1677, -0.2347,  0.2804,  0.1095, -0.3301,  0.1616],\n        [-0.2760, -0.3341, -0.2084, -0.0739, -0.1023, -0.2154,  0.1017,  0.0994],\n        [ 0.1436,  0.2805,  0.0490, -0.1240, -0.2948,  0.2371, -0.2692, -0.0686],\n        [-0.3137, -0.0135, -0.2733, -0.3535,  0.1104, -0.1332,  0.1513, -0.2928],\n        [-0.0365, -0.2012, -0.1737, -0.0978, -0.1311,  0.1551,  0.3385, -0.3248],\n        [ 0.2209, -0.1121, -0.1226, -0.0440,  0.1531, -0.1572,  0.2242, -0.2037],\n        [ 0.0116,  0.3387,  0.0220, -0.1609, -0.1506, -0.3205,  0.3051,  0.0888],\n        [-0.1063,  0.3491, -0.1913, -0.2303,  0.1355, -0.1843, -0.2174,  0.1552],\n        [ 0.3172, -0.1309,  0.2828, -0.3348,  0.1597,  0.0542,  0.1136,  0.3281],\n        [ 0.0045, -0.1506,  0.0696,  0.0677, -0.2483, -0.2411, -0.2037, -0.0800]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0374, -0.1362,  0.2812,  0.3161, -0.0754, -0.0194, -0.1546, -0.0920,\n         0.0156, -0.3040,  0.2331, -0.3410, -0.0411, -0.1029, -0.3312, -0.0482,\n        -0.0969,  0.2682, -0.3324, -0.0273,  0.3338,  0.2887, -0.1589,  0.1743,\n        -0.1611, -0.1169, -0.1357,  0.1715, -0.2674, -0.1605,  0.3241,  0.2294,\n         0.3416, -0.0188,  0.2567, -0.1059,  0.1299,  0.2619,  0.0053, -0.1822,\n         0.2775,  0.0878,  0.0295, -0.0168,  0.2071, -0.2543, -0.3480, -0.0892,\n        -0.2661,  0.1459, -0.2554,  0.1917,  0.0408,  0.2681, -0.0101,  0.2496,\n         0.3512,  0.0007, -0.3217, -0.1825, -0.0392, -0.2831, -0.1026,  0.1099],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0316,  0.0997,  0.1223,  ..., -0.0548,  0.1060, -0.0226],\n        [-0.0222,  0.0053, -0.0990,  ..., -0.0387,  0.0526,  0.0297],\n        [-0.0238, -0.0223, -0.1080,  ...,  0.0634, -0.0484,  0.0382],\n        ...,\n        [ 0.1029,  0.0127,  0.0262,  ..., -0.0488, -0.0699, -0.0949],\n        [-0.0880,  0.0901,  0.0421,  ...,  0.0012,  0.1211, -0.0212],\n        [ 0.0320, -0.1116,  0.0096,  ..., -0.0890,  0.1026, -0.1103]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0343, -0.0525,  0.0452,  0.0237,  0.0127,  0.0636,  0.0913,  0.1067,\n        -0.1097,  0.0004,  0.0088,  0.0330,  0.0940,  0.0514, -0.0925,  0.0115,\n        -0.0313, -0.0006, -0.0770, -0.0535,  0.0404,  0.0113,  0.0551, -0.0114,\n        -0.0392, -0.0075,  0.0117, -0.0815, -0.0998,  0.0638, -0.1183,  0.0598,\n         0.0811, -0.0024, -0.0821, -0.0690, -0.0330,  0.0835,  0.0635,  0.0993,\n         0.0322,  0.0926, -0.0434, -0.0450,  0.0414,  0.0712,  0.0552, -0.0586,\n         0.1140, -0.0292, -0.0953, -0.0236, -0.1096, -0.1222, -0.0516, -0.1104,\n         0.0952,  0.1192,  0.0477, -0.1049, -0.1177, -0.1168, -0.0025, -0.0062],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0963,  0.0636,  0.0992,  ..., -0.0027, -0.1066, -0.0424],\n        [ 0.0606, -0.0683,  0.1122,  ..., -0.0815,  0.1068, -0.0231],\n        [-0.0562, -0.1125, -0.0915,  ...,  0.1098,  0.0385,  0.0770],\n        ...,\n        [ 0.0065,  0.0965,  0.0690,  ...,  0.0785,  0.1066, -0.0894],\n        [-0.0737,  0.0537, -0.0677,  ...,  0.1097, -0.0437,  0.0456],\n        [-0.0085, -0.1206,  0.0545,  ..., -0.1039,  0.0277, -0.0741]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1106, -0.0020, -0.0389,  0.0336,  0.1176, -0.0291, -0.0611,  0.0483,\n         0.0523, -0.0161,  0.0743, -0.0647,  0.0323, -0.1178,  0.0189,  0.0948,\n        -0.1035,  0.0957, -0.1195, -0.1234, -0.1134, -0.0736, -0.0681,  0.1028,\n         0.0657,  0.0980, -0.0608,  0.0510, -0.1177, -0.0747, -0.1087, -0.0465],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.0103e-01,  1.3044e-01,  2.1441e-02, -4.4961e-02,  1.6067e-01,\n         -3.8866e-02, -2.8370e-02,  1.2057e-01, -1.1911e-01,  1.0437e-01,\n          3.9831e-02,  9.3676e-02, -1.5182e-01,  5.9657e-02,  7.6728e-02,\n         -5.3329e-02, -7.7273e-03,  1.7600e-01, -8.2391e-02, -2.8836e-02,\n         -3.8694e-02,  6.2439e-02,  8.6302e-02, -1.3421e-01, -1.0031e-01,\n         -1.0523e-02,  1.0332e-02, -8.5625e-02,  1.0190e-01,  8.0566e-02,\n          6.6741e-02,  7.8269e-02],\n        [ 1.3762e-02, -2.2304e-02,  1.1586e-01, -1.7278e-01,  3.8611e-02,\n          4.6521e-02, -7.0306e-03,  1.4322e-01, -1.3057e-01,  1.5248e-01,\n          1.3917e-01,  1.5458e-01, -4.3837e-02,  1.3806e-01,  5.2045e-02,\n         -1.7006e-01,  1.1784e-01, -1.6323e-01,  9.6609e-03, -6.2013e-02,\n         -4.7914e-02,  2.1879e-02,  1.6954e-01, -1.4265e-01,  6.6472e-02,\n          6.6532e-02,  1.5483e-01,  1.5771e-02,  1.2768e-01, -5.8863e-02,\n         -1.9344e-02,  1.2750e-01],\n        [-9.4913e-02,  1.7587e-01,  1.9909e-02, -8.0661e-02, -1.0868e-01,\n          9.9175e-02,  9.2989e-02, -1.4130e-01, -1.5815e-01, -2.9503e-07,\n         -3.3944e-02, -4.5190e-02, -1.6930e-01, -1.7593e-01, -9.5471e-02,\n         -7.4307e-02, -1.8922e-02,  5.1783e-02, -1.0376e-01, -1.4988e-01,\n         -1.1126e-02, -1.3055e-01, -1.4815e-01,  1.3285e-01, -5.9135e-02,\n          3.3885e-03, -1.1909e-01, -7.1326e-02,  1.4889e-01, -4.0584e-02,\n         -3.6682e-02, -1.2092e-01],\n        [ 3.6574e-02, -5.3938e-03,  1.7196e-01,  6.6899e-02,  1.3019e-01,\n          1.7572e-01,  1.1952e-01, -1.1186e-01, -1.3650e-02,  1.0814e-01,\n         -9.8342e-02,  1.5544e-01, -3.8964e-02,  6.1110e-02, -6.8167e-02,\n          1.6623e-01,  2.2224e-02,  1.1206e-01, -1.1009e-01, -9.3859e-03,\n          1.0064e-01, -1.4741e-01, -6.7351e-02,  1.1584e-01, -3.0706e-02,\n          4.7404e-02, -1.1732e-01,  4.5935e-02,  1.5101e-01,  6.9566e-02,\n         -1.2233e-01,  1.2690e-01],\n        [-9.2696e-03,  6.4805e-02,  9.7023e-03,  5.2360e-02, -8.9422e-02,\n         -1.6009e-01, -3.5275e-02,  1.3592e-01,  9.6468e-02,  2.8256e-02,\n         -8.7407e-02, -4.2621e-02,  1.2210e-02, -1.1344e-01,  4.3983e-02,\n          4.3575e-02, -9.9209e-04, -1.7287e-01, -6.5547e-02, -3.3157e-02,\n         -1.6209e-01, -1.5774e-01, -5.3458e-02, -2.1195e-03,  1.4338e-01,\n          5.3545e-02, -1.7516e-01, -1.6309e-01, -2.5928e-02,  3.7207e-02,\n         -8.0693e-02, -4.4303e-02],\n        [-1.4885e-01,  1.4110e-01,  1.4640e-01,  1.0536e-01,  1.0098e-01,\n         -7.4270e-02, -2.7253e-02, -2.9176e-02,  2.5915e-02,  7.7355e-02,\n         -1.0056e-04, -1.2963e-01,  4.2566e-02, -6.2533e-02,  3.2308e-02,\n          1.7411e-01, -5.5302e-02,  9.2802e-02, -5.8408e-02,  1.1260e-01,\n          1.5700e-01,  1.5141e-01, -1.0327e-02, -1.6697e-01,  1.3191e-02,\n          4.0974e-02,  1.2252e-01,  1.6357e-02, -5.8011e-02, -1.2850e-01,\n          1.1348e-01, -1.4001e-01],\n        [ 4.0685e-02,  2.4295e-03,  4.1343e-02, -1.6383e-02,  9.0169e-02,\n         -1.0170e-01,  1.4514e-01, -1.6726e-01, -1.1104e-01, -6.0736e-02,\n         -1.0053e-01,  1.0726e-01, -5.2287e-02,  9.7274e-02, -3.3491e-02,\n          9.8996e-03,  1.1460e-01, -1.5992e-01, -1.2851e-01,  8.2465e-02,\n          1.9672e-02,  5.6513e-02, -1.2552e-01,  3.7188e-02,  1.3739e-01,\n         -1.0271e-02,  1.2409e-01, -1.7308e-01,  5.4228e-02,  4.6457e-02,\n          5.6062e-02,  1.0836e-01],\n        [ 1.6763e-01, -7.3261e-02, -1.6678e-01,  5.0633e-02, -1.1385e-01,\n          5.3242e-02,  3.3491e-03,  1.2365e-01, -1.4588e-01, -1.6995e-01,\n          1.4871e-01, -1.2073e-01,  1.1859e-01,  1.2914e-01,  5.2313e-02,\n         -1.5629e-01, -1.7528e-02,  1.1265e-01, -6.0255e-02,  1.7536e-01,\n         -1.3970e-01,  1.3881e-01, -1.7483e-01, -2.6130e-02, -1.0562e-01,\n          9.3960e-03,  6.2633e-02,  4.3839e-02, -1.6581e-01, -1.7290e-01,\n          1.6696e-01, -1.2800e-01],\n        [ 1.6346e-01,  1.2823e-01, -1.5921e-01,  9.4238e-02, -1.9057e-02,\n         -1.5900e-01,  3.1200e-02, -4.1231e-02, -8.0442e-02,  3.2750e-02,\n         -1.0384e-01, -1.1537e-01, -9.2242e-02,  7.0441e-02, -3.1371e-02,\n         -1.0743e-01,  1.4583e-01,  4.7433e-02, -4.3031e-03, -2.6328e-02,\n         -1.2429e-01,  7.3315e-02,  1.2533e-01, -1.5360e-01,  9.1619e-02,\n         -1.6254e-01,  1.5371e-01, -1.4573e-01, -1.2190e-01,  1.4770e-01,\n         -1.5545e-01,  4.6542e-02],\n        [ 2.8854e-02, -1.6545e-01,  9.7410e-02, -1.3002e-01,  6.9684e-03,\n          7.7898e-02, -1.1073e-02,  1.6769e-01,  1.0238e-01, -6.3717e-02,\n         -1.6442e-01,  1.7403e-01, -7.7956e-02,  1.2504e-01,  3.8363e-02,\n         -1.9901e-03, -5.8007e-02,  8.8853e-02, -6.6489e-02,  1.1524e-02,\n          1.6475e-01, -8.1253e-02, -5.7948e-02,  1.1892e-01,  1.2521e-01,\n          1.3722e-01, -8.7516e-03,  1.0693e-01,  1.0011e-01, -7.0299e-02,\n         -1.4563e-01,  7.6046e-02],\n        [-9.9561e-02, -7.6067e-02, -8.2460e-02, -2.3403e-02, -1.6923e-01,\n          2.2483e-02,  1.2814e-02,  4.0016e-02,  4.4124e-02, -1.4038e-01,\n          1.5982e-01, -4.6964e-03,  4.7042e-02, -4.6159e-02, -8.2396e-03,\n          1.4262e-01, -4.7813e-02, -4.9447e-02, -5.1775e-02, -1.2348e-01,\n         -6.0562e-02,  6.8634e-02,  2.2589e-02,  4.7713e-02, -1.7087e-01,\n         -5.5466e-02, -1.5792e-01,  1.2372e-01, -1.1079e-01,  1.5470e-02,\n          1.5156e-01, -1.2559e-01],\n        [-1.7539e-01,  5.4746e-02,  1.3667e-02,  3.4855e-02, -1.1714e-01,\n          1.2875e-01, -4.0467e-02,  1.2339e-02,  1.7608e-01, -6.9184e-02,\n         -5.5471e-02,  4.7595e-02, -9.4965e-02, -2.5008e-02,  5.2595e-04,\n         -7.4348e-02,  3.3223e-02, -3.8691e-02, -1.6224e-01,  1.3361e-01,\n          1.2509e-01,  3.0419e-02, -1.3213e-01, -4.5709e-02, -1.2062e-01,\n          6.7443e-02, -1.1728e-01,  1.1971e-01,  8.5466e-02, -1.9701e-02,\n          1.4655e-01,  5.9635e-02],\n        [ 5.6317e-02, -1.3195e-01, -1.5144e-01,  1.6338e-01,  2.0635e-02,\n          1.3833e-02, -8.3196e-02, -7.5694e-02,  6.9188e-02,  8.5950e-02,\n          8.2537e-02, -1.0958e-01, -1.0028e-01,  1.6971e-01,  5.0574e-02,\n          8.0770e-02, -1.1800e-01,  2.8916e-02,  1.0139e-01,  1.0487e-01,\n          6.0979e-02,  8.6959e-02,  3.2206e-02,  9.6946e-02, -1.4418e-01,\n          1.6252e-01, -1.4241e-01, -9.6905e-02, -1.0654e-01,  1.6338e-01,\n          7.3340e-02, -1.7154e-01],\n        [ 1.2767e-01,  1.3975e-01, -8.6244e-02, -3.6881e-02, -1.6988e-01,\n         -2.6605e-02, -8.6876e-03, -5.8464e-02, -7.3747e-02,  7.4437e-02,\n         -1.2225e-02, -7.2475e-02, -7.8471e-02,  7.2451e-02, -6.2929e-02,\n          1.5665e-01, -1.0649e-01, -1.0771e-01,  6.2302e-02,  6.4150e-02,\n          8.7657e-02,  1.3408e-01,  8.6472e-02,  6.5170e-02,  1.0774e-01,\n          1.6147e-01,  1.0730e-01,  6.9266e-02,  1.6365e-01,  6.8378e-02,\n         -6.0933e-02, -1.0195e-01],\n        [ 7.7835e-02,  2.8441e-02,  5.4429e-02,  1.0237e-01,  1.1044e-01,\n          1.5581e-01,  9.3556e-02, -5.3081e-02,  1.3764e-01, -1.2539e-01,\n         -6.3537e-02,  7.4913e-02, -1.4848e-01,  4.5687e-02,  1.6187e-01,\n         -1.6058e-01, -1.0902e-01, -5.2994e-02, -9.1078e-02,  1.3232e-01,\n         -6.1189e-02,  1.5170e-02,  8.2260e-02,  8.0174e-02, -1.2911e-01,\n          1.7562e-01,  1.0623e-01, -1.6548e-01, -9.8150e-02,  2.6964e-02,\n         -2.5024e-02,  1.5448e-01],\n        [-1.4986e-01,  6.0753e-02,  4.5547e-02, -6.4023e-02,  1.0477e-01,\n         -1.5712e-03, -6.2100e-03,  5.0939e-03, -1.5228e-01,  1.3768e-01,\n          9.5254e-02, -5.8790e-02, -1.0545e-01, -3.5562e-03, -1.2066e-01,\n          1.3096e-01, -4.6077e-03, -1.6340e-01,  5.1689e-02, -4.7426e-02,\n         -6.8733e-02,  1.0424e-01, -1.5949e-01, -2.4109e-02,  1.0839e-01,\n          7.6810e-02,  9.4483e-02,  1.5576e-01,  2.9681e-02,  7.2787e-02,\n         -1.7128e-01, -1.8017e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1237, -0.0708,  0.0414,  0.1535, -0.1383,  0.0239, -0.1757,  0.0292,\n        -0.0365, -0.1581, -0.0309,  0.1601,  0.0737,  0.0595, -0.1388,  0.1460],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1478, -0.0347,  0.1203,  0.1795, -0.0132, -0.0831,  0.1210,  0.1112,\n          0.0863,  0.0444, -0.1940,  0.0008,  0.1770,  0.1102,  0.2331, -0.2335],\n        [ 0.1264, -0.0415,  0.1380,  0.2352, -0.0969, -0.1986, -0.1870, -0.0100,\n          0.1026, -0.0612,  0.0938, -0.1196,  0.0230,  0.0533, -0.0380, -0.1771],\n        [-0.1321, -0.1000,  0.1790, -0.1432, -0.2169,  0.1224,  0.0379,  0.0856,\n         -0.0541, -0.1163, -0.1754,  0.1552, -0.0644,  0.0172,  0.2144,  0.1898],\n        [ 0.1269,  0.1698,  0.1593, -0.1780,  0.1633, -0.0268, -0.2481, -0.0730,\n         -0.0653, -0.0831, -0.1528, -0.1308,  0.1825,  0.1584, -0.2459, -0.2369],\n        [-0.0019, -0.1058,  0.1805,  0.0426, -0.0391, -0.0408,  0.0232,  0.1333,\n         -0.1862,  0.2285, -0.0460, -0.0312, -0.0424,  0.2244, -0.0666, -0.1754],\n        [ 0.1433,  0.1770,  0.0535,  0.0664, -0.0554,  0.0005,  0.2132,  0.0097,\n          0.1168, -0.2144, -0.2260, -0.1644, -0.0315, -0.1700, -0.0993,  0.0218],\n        [-0.0541,  0.1533,  0.0854, -0.2259, -0.0220,  0.0322, -0.1195, -0.1128,\n         -0.2281, -0.2126,  0.0701, -0.1840,  0.2086, -0.2008,  0.2285,  0.1332],\n        [ 0.1376, -0.0878, -0.1574,  0.1474, -0.1687,  0.1683, -0.0573, -0.0853,\n         -0.1920, -0.1556,  0.1913,  0.1870, -0.2477, -0.2288, -0.1557, -0.0579]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0627, -0.1810,  0.0436,  0.1364, -0.0733,  0.1768,  0.0848,  0.2398],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1703,  0.2783, -0.2810, -0.1586,  0.0885,  0.0836, -0.0083, -0.1307]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1897], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x70bedb91e550>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x70be57994d10>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s185270000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s185270000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}