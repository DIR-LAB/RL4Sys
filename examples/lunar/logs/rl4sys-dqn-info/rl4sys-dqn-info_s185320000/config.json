{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	64,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s185320000"
    },
    "q_lr":	0.001,
    "seed":	185320000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x00000218D1AD9150>":	{
            "_act_dim":	1,
            "_batch_size":	64,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2325,  0.0236, -0.3265,  0.0601,  0.1187,  0.0184,  0.0844,  0.2045,\n         0.1023, -0.1708, -0.2322, -0.3501,  0.0453, -0.0258, -0.1737, -0.2741,\n        -0.0809,  0.2914, -0.0744, -0.3087, -0.2964,  0.2774,  0.3474,  0.0705,\n         0.2862,  0.2647, -0.2510,  0.2387, -0.0457, -0.0498,  0.1038,  0.0851],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0395, -0.0820, -0.2982, -0.2540, -0.0699, -0.0168, -0.1761, -0.1445],\n        [ 0.0677,  0.0338,  0.0055, -0.1563,  0.2802,  0.2658,  0.3142, -0.0443],\n        [-0.2639, -0.2102, -0.0497, -0.3252,  0.0208,  0.2737,  0.3207,  0.1457],\n        [ 0.1770,  0.0461, -0.3064,  0.3081,  0.2563,  0.1929, -0.3467,  0.1782],\n        [-0.2962,  0.0189,  0.2618, -0.0097,  0.1954, -0.3067,  0.1300,  0.0129],\n        [ 0.3457, -0.2278, -0.0023,  0.2183, -0.1320,  0.0043,  0.0286,  0.1780],\n        [-0.0671, -0.3101, -0.0272,  0.2155,  0.2595,  0.1834,  0.3012,  0.3403],\n        [ 0.1968, -0.2580, -0.2876,  0.2718, -0.3362,  0.2638, -0.1399, -0.0538],\n        [ 0.1867, -0.0262, -0.2009,  0.2125,  0.2028, -0.1032,  0.3081, -0.2023],\n        [ 0.0987, -0.0780, -0.2819,  0.1004,  0.3427, -0.1547,  0.1711, -0.2835],\n        [-0.0906, -0.3398,  0.1353, -0.2522,  0.1098, -0.2706, -0.1026,  0.1445],\n        [-0.2222,  0.0868, -0.2566,  0.0060, -0.0204, -0.1647, -0.0896,  0.0428],\n        [ 0.3078,  0.1264,  0.0255,  0.2352, -0.2103, -0.1032, -0.1661, -0.2583],\n        [-0.1749,  0.1640, -0.0622,  0.0829, -0.2814, -0.1597,  0.2376, -0.1932],\n        [-0.1594, -0.1359,  0.1775,  0.1849,  0.2879,  0.2739, -0.1885,  0.1050],\n        [ 0.2204,  0.1986,  0.2126,  0.2962, -0.0123, -0.2932,  0.2911,  0.1150],\n        [ 0.3159,  0.2808, -0.1518, -0.0075,  0.1452, -0.3011,  0.3473,  0.3030],\n        [-0.0571,  0.1822,  0.2730, -0.2921, -0.0607, -0.2953, -0.1146, -0.0287],\n        [-0.3013, -0.1319, -0.1541, -0.3443, -0.3276, -0.2809, -0.1079,  0.1433],\n        [ 0.3225, -0.1463,  0.0472, -0.0591,  0.2107, -0.1971,  0.1427, -0.0035],\n        [ 0.1317,  0.0694,  0.3510,  0.2290, -0.0343,  0.0915,  0.0851, -0.2873],\n        [-0.1629, -0.2270,  0.1709, -0.3309,  0.2982, -0.1475, -0.2088,  0.1374],\n        [ 0.0644, -0.1770, -0.0539, -0.1849,  0.3079,  0.1294,  0.0178, -0.2967],\n        [ 0.1324, -0.0475,  0.1255,  0.0205, -0.0340, -0.1246, -0.1547,  0.2874],\n        [-0.1650,  0.0843,  0.1404,  0.3278, -0.0385,  0.1513,  0.0101,  0.2741],\n        [ 0.0339, -0.0954,  0.3530, -0.0253,  0.0770,  0.2056, -0.0446, -0.3160],\n        [-0.1376,  0.1052, -0.2498,  0.0704,  0.2306, -0.0417,  0.0521, -0.1952],\n        [ 0.1535, -0.0255, -0.1180, -0.2459,  0.1515, -0.1101, -0.2630, -0.0633],\n        [ 0.3432, -0.3266, -0.1261,  0.2556,  0.2783,  0.0655, -0.1683,  0.3122],\n        [ 0.1582,  0.1113,  0.0066, -0.1186, -0.2934,  0.1265, -0.3476, -0.0921],\n        [ 0.2570,  0.2262, -0.1528,  0.2756,  0.0056, -0.3267, -0.3081,  0.1170],\n        [-0.0389, -0.2117, -0.2164,  0.1530,  0.2178,  0.0899, -0.2236, -0.0477]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0893,  0.1044, -0.1167,  0.1464, -0.1070,  0.1442,  0.1085, -0.1643,\n        -0.0099,  0.0454, -0.0472, -0.0944, -0.1485, -0.0161,  0.0539,  0.0341],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.8376e-02,  4.7873e-02,  6.4840e-02, -4.5469e-02, -2.5359e-02,\n          4.4779e-02, -3.3715e-02, -3.8026e-02, -1.0223e-01,  6.1730e-02,\n          5.7411e-03,  1.7674e-01, -3.6891e-02,  8.8193e-02,  1.9300e-02,\n          1.1334e-02,  1.5929e-01, -1.3123e-01, -1.3869e-01, -8.2986e-03,\n         -1.6585e-01,  1.2635e-01,  8.6916e-02, -6.1977e-02, -8.3730e-03,\n         -3.1145e-02,  2.0092e-03,  1.4261e-01, -9.3841e-02, -2.8974e-02,\n          1.5644e-01,  1.2266e-01],\n        [-2.4523e-02, -5.7890e-03, -1.2267e-01, -1.0215e-01,  1.3333e-01,\n          1.2840e-01, -9.6205e-02, -7.5122e-02,  1.5649e-01, -1.7443e-01,\n         -1.5852e-01, -2.2216e-02,  1.1016e-02, -1.5061e-01,  9.7007e-02,\n         -1.2046e-01,  1.4958e-01,  9.9527e-02,  1.1224e-01, -6.4203e-03,\n         -1.6791e-01,  1.6780e-01, -2.8980e-02, -7.0426e-02,  9.8668e-02,\n          1.3801e-01, -8.4402e-02,  8.2197e-02,  7.2971e-03,  1.4027e-01,\n          1.7229e-01,  9.2855e-03],\n        [ 6.9520e-02, -7.2440e-02, -1.6971e-01,  8.4847e-02, -2.1404e-02,\n         -8.7165e-02,  5.4123e-02,  1.7000e-01, -1.5379e-01, -5.1702e-02,\n         -5.6669e-02, -8.1652e-02,  8.1116e-02, -1.2465e-01,  1.3903e-01,\n         -1.4836e-01, -3.7066e-02,  9.0366e-02,  1.6823e-01,  6.0999e-02,\n         -1.1758e-01, -8.4157e-02,  1.4905e-01,  3.9591e-02, -2.2970e-04,\n          1.5474e-01, -7.6151e-02,  9.8828e-02,  9.5826e-02, -1.4119e-01,\n          1.2594e-01, -4.5224e-02],\n        [ 7.5908e-02, -1.5567e-01, -4.9446e-02, -1.5726e-01,  6.1799e-03,\n         -1.1105e-01,  1.3937e-01,  1.4218e-02, -1.5104e-01, -1.1705e-01,\n         -3.9418e-02,  1.3262e-02,  5.8359e-02, -3.2736e-02,  6.2079e-02,\n          9.7599e-02, -1.4697e-01, -8.4249e-02,  1.6050e-01, -3.2830e-02,\n         -1.1109e-02, -6.9944e-02, -3.3794e-02, -5.7124e-02,  1.2692e-01,\n         -6.4964e-02,  1.1979e-01,  4.6170e-02, -1.0954e-01, -9.0335e-02,\n          1.4698e-01, -1.2229e-01],\n        [-1.3685e-02, -1.4980e-01,  5.1350e-02,  1.4679e-01,  1.5476e-02,\n          1.7408e-02, -1.3850e-01, -5.8735e-02, -6.4514e-02,  6.7928e-04,\n         -8.3884e-02, -1.0126e-01, -1.8951e-03, -2.3347e-02, -1.0118e-01,\n          1.1165e-01,  1.5034e-01, -1.3502e-02,  6.7037e-02,  7.6409e-03,\n         -1.5856e-01, -1.4749e-02,  5.7057e-02, -1.0658e-01, -4.7343e-02,\n         -1.7464e-01, -1.4679e-01,  9.6310e-02,  9.0244e-02, -9.2242e-02,\n         -2.8224e-02, -2.6041e-02],\n        [ 5.4640e-02,  4.9076e-02,  3.1271e-02, -4.7030e-02,  6.4143e-02,\n          9.2265e-02,  2.4706e-02, -1.5325e-01, -1.5582e-01,  7.5420e-02,\n         -1.7234e-01,  6.1980e-02,  5.8878e-03, -7.2565e-02,  1.0295e-01,\n          1.1151e-01, -5.6537e-02, -2.2153e-02,  1.2697e-01,  3.7373e-02,\n         -1.1526e-01,  1.7284e-01,  1.2869e-01, -9.5631e-02, -9.5339e-02,\n         -1.0113e-01, -4.2613e-02, -1.5346e-01,  1.0241e-01,  2.3525e-02,\n         -1.5068e-01,  2.9257e-02],\n        [-1.4443e-01, -6.6674e-03,  1.0253e-01, -8.8623e-02,  1.5204e-01,\n         -1.3431e-01,  2.7223e-02,  8.6246e-03, -9.2197e-02,  1.3608e-01,\n          4.1372e-02,  3.6574e-02, -1.9298e-02, -1.4424e-01, -1.6699e-01,\n          1.6374e-01, -1.1241e-01,  5.2006e-02, -2.5628e-03,  4.1597e-02,\n          1.1044e-01, -8.4190e-04,  4.6026e-02,  1.0538e-01,  5.6413e-02,\n          1.1301e-01,  5.5462e-05, -1.2177e-01,  1.1571e-01, -1.7175e-01,\n          1.7234e-01, -1.1500e-02],\n        [ 9.5082e-02,  1.0111e-01, -1.7305e-01, -1.3143e-01, -4.8919e-02,\n         -1.4656e-01, -1.4169e-01,  4.7099e-02,  1.6412e-01, -1.3289e-01,\n          1.0092e-01, -1.0954e-01, -1.2304e-02, -8.3851e-02, -8.2439e-02,\n          9.2191e-02, -9.7528e-02,  4.1545e-02, -3.2183e-02, -4.3222e-02,\n          1.4214e-01,  6.1655e-03,  1.4966e-01, -1.0357e-02, -1.4152e-01,\n          4.6794e-02,  1.8970e-02,  1.4389e-01, -2.5343e-02, -2.5917e-02,\n         -4.0159e-02,  1.3322e-01],\n        [-1.7657e-01,  8.9049e-02,  2.8392e-02, -4.3020e-02,  1.6514e-01,\n         -3.6593e-02, -9.2003e-02,  3.1359e-03, -4.2045e-02, -1.0610e-02,\n          7.1485e-03,  1.1150e-01, -1.5381e-01, -7.6781e-03, -1.4293e-01,\n          1.7407e-01, -6.6183e-02, -5.1280e-02,  1.5806e-01, -1.3010e-01,\n          7.6294e-02, -1.4716e-01, -8.5624e-02,  2.4198e-02,  1.7286e-01,\n          1.1654e-01, -2.9314e-03,  3.5565e-02,  6.6343e-02,  1.4669e-01,\n         -1.4828e-02,  1.2623e-01],\n        [ 6.9448e-02,  1.5744e-01, -4.3824e-02,  2.6461e-03, -1.1106e-01,\n          3.7359e-02,  6.8180e-02, -1.4351e-01,  1.4966e-01, -2.0222e-02,\n          1.2895e-01, -3.5323e-02,  1.5647e-01, -9.1040e-02, -1.4705e-01,\n         -3.0390e-02,  1.3319e-01, -6.7186e-02,  1.2279e-01, -4.3182e-02,\n         -3.7307e-02, -8.8041e-02, -5.6598e-02, -1.0870e-02, -9.2769e-02,\n         -1.1429e-01, -1.4144e-01,  1.5677e-01,  3.3412e-02, -1.3346e-01,\n         -7.6147e-02,  3.6122e-02],\n        [-1.3289e-01, -1.5675e-01, -7.8298e-02, -4.6496e-02,  1.1435e-01,\n          1.4837e-01, -1.0923e-01, -7.0406e-02, -1.6213e-01,  5.6018e-02,\n          9.4018e-02, -1.4478e-01, -4.6446e-02, -1.0979e-01,  1.6432e-01,\n          5.2375e-02,  3.8028e-02, -7.0264e-02, -5.3968e-02,  2.5586e-02,\n         -1.5559e-02, -1.1763e-01,  1.1900e-01, -1.1335e-01, -1.2166e-01,\n          4.5605e-02,  1.0749e-01,  9.4165e-02, -5.6393e-02, -1.5736e-01,\n          7.3648e-02,  1.4879e-01],\n        [ 4.2024e-02,  1.6107e-01,  1.2511e-02, -1.3676e-01, -8.7942e-02,\n         -4.7955e-02,  1.6565e-01,  2.4229e-02,  1.0758e-01,  1.6233e-01,\n         -1.7233e-01, -1.9037e-02, -1.1456e-01, -6.3248e-02, -1.0200e-02,\n         -5.3164e-03, -1.4180e-01, -3.6768e-02, -2.7467e-02,  9.6098e-02,\n         -1.2291e-01, -6.4653e-02, -1.3381e-01, -4.2279e-02,  2.6332e-02,\n          7.5631e-03, -5.2790e-02,  1.0745e-01,  3.5254e-02, -1.1044e-01,\n         -6.6146e-02,  1.3002e-01],\n        [-6.7484e-02, -1.6262e-01,  7.6181e-02, -4.5097e-02, -1.5820e-01,\n          1.0914e-01,  1.1535e-01,  1.1885e-01,  1.2701e-01,  1.6587e-01,\n          6.9054e-02, -1.2962e-01, -1.4198e-02,  1.7305e-01,  5.7027e-02,\n         -2.8181e-02,  1.7631e-01, -1.2326e-01, -5.1214e-02,  1.4658e-01,\n         -8.5884e-02, -1.1273e-01,  4.8951e-02,  4.6988e-02,  5.4381e-02,\n          1.3363e-01,  1.6902e-02, -2.6017e-02, -6.1035e-02,  7.2567e-02,\n          1.1359e-01,  1.6317e-01],\n        [-2.6796e-02,  6.7940e-02,  1.4698e-01, -8.3741e-02,  8.6319e-02,\n         -2.6921e-02, -1.2751e-01, -3.8776e-02, -1.2086e-01, -1.0010e-01,\n         -1.2246e-01,  6.3218e-02,  1.2305e-03,  1.2735e-01, -5.3858e-02,\n         -7.4342e-02,  1.5533e-01, -1.3899e-01,  3.5609e-02,  1.1658e-01,\n         -1.2304e-01,  1.6520e-01, -4.7626e-02, -1.2583e-01,  8.4426e-02,\n          3.9601e-02,  2.7929e-02, -7.4791e-02, -1.7301e-01, -4.9010e-02,\n         -9.9295e-02, -8.4655e-02],\n        [-8.5975e-02, -1.3705e-01,  1.4230e-01, -1.1919e-01,  1.7192e-01,\n         -6.3314e-02,  5.4110e-02, -1.3736e-01, -1.4640e-01, -3.8244e-02,\n          5.3126e-04, -3.1436e-02, -1.0916e-01,  9.1474e-03,  1.6869e-01,\n          1.0156e-03, -3.6362e-03,  5.9246e-04,  1.5367e-01,  1.6182e-01,\n          2.0763e-02, -1.0761e-01, -7.4609e-02,  1.6124e-02,  1.6208e-01,\n          3.1407e-03,  1.0740e-01, -1.5497e-02, -9.8784e-02,  6.1585e-02,\n          1.6895e-01,  6.0963e-02],\n        [ 2.1485e-02,  7.5693e-02,  1.1873e-01, -1.6929e-01,  8.2379e-02,\n         -6.8267e-02,  1.7229e-01,  1.2498e-01, -1.4869e-01, -4.8854e-02,\n         -1.2785e-02,  1.6448e-01,  7.6258e-02,  1.0449e-01, -1.0907e-01,\n         -3.5940e-02,  1.2773e-01,  3.2286e-02, -1.3219e-01,  2.4689e-02,\n          4.8904e-02,  1.7414e-01,  4.9775e-03,  8.6995e-02,  1.1789e-01,\n         -1.1176e-01,  1.2409e-01,  7.3214e-02, -1.9226e-02,  1.4476e-01,\n          2.9335e-02, -1.5860e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2451,  0.0975,  0.0171,  0.2125, -0.2295,  0.0151,  0.0066, -0.0672],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0939,  0.0430,  0.0756, -0.1519, -0.2365, -0.1734,  0.0883,  0.1071,\n         -0.0526, -0.2226, -0.1134,  0.0177,  0.1859, -0.1491, -0.0146, -0.1153],\n        [ 0.2313, -0.0738, -0.1909,  0.2453,  0.2145,  0.1236, -0.0330, -0.1774,\n          0.1117, -0.1544,  0.0874, -0.1457,  0.2168, -0.1710, -0.2296, -0.2171],\n        [-0.0604, -0.0345, -0.1931,  0.2492,  0.2332,  0.2161, -0.1546, -0.1278,\n         -0.2422, -0.1354, -0.2216,  0.1726,  0.1409,  0.0196,  0.2357, -0.0986],\n        [-0.0202,  0.2203,  0.1758, -0.0906,  0.0813,  0.0642,  0.1219,  0.2130,\n          0.0355, -0.0056,  0.0205, -0.0392,  0.0066, -0.1421, -0.0135, -0.2254],\n        [ 0.0528,  0.0360, -0.2100, -0.1133,  0.0032,  0.1468,  0.1677,  0.0429,\n         -0.1801,  0.0299,  0.0706,  0.0063, -0.2407,  0.0327,  0.0093,  0.1271],\n        [-0.2275, -0.1605,  0.2280, -0.2142, -0.0509,  0.0032, -0.2465,  0.0881,\n         -0.2004,  0.1837, -0.2254, -0.1340,  0.0505,  0.1021, -0.0725, -0.1775],\n        [ 0.2434,  0.1713,  0.1725, -0.1755, -0.1422, -0.0073, -0.0608,  0.1472,\n         -0.0675,  0.1305, -0.0604,  0.0425,  0.0639, -0.0289,  0.1380,  0.2426],\n        [-0.1893,  0.1694,  0.1457,  0.1598,  0.1484, -0.1817, -0.1963,  0.1515,\n          0.1526,  0.0008,  0.2397,  0.0702, -0.1443, -0.0937,  0.0122,  0.0231]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0376], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0122,  0.1384,  0.1091,  0.0645,  0.1231, -0.1031,  0.0745,  0.0576]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.001,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.001,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0395, -0.0820, -0.2982, -0.2540, -0.0699, -0.0168, -0.1761, -0.1445],\n        [ 0.0677,  0.0338,  0.0055, -0.1563,  0.2802,  0.2658,  0.3142, -0.0443],\n        [-0.2639, -0.2102, -0.0497, -0.3252,  0.0208,  0.2737,  0.3207,  0.1457],\n        [ 0.1770,  0.0461, -0.3064,  0.3081,  0.2563,  0.1929, -0.3467,  0.1782],\n        [-0.2962,  0.0189,  0.2618, -0.0097,  0.1954, -0.3067,  0.1300,  0.0129],\n        [ 0.3457, -0.2278, -0.0023,  0.2183, -0.1320,  0.0043,  0.0286,  0.1780],\n        [-0.0671, -0.3101, -0.0272,  0.2155,  0.2595,  0.1834,  0.3012,  0.3403],\n        [ 0.1968, -0.2580, -0.2876,  0.2718, -0.3362,  0.2638, -0.1399, -0.0538],\n        [ 0.1867, -0.0262, -0.2009,  0.2125,  0.2028, -0.1032,  0.3081, -0.2023],\n        [ 0.0987, -0.0780, -0.2819,  0.1004,  0.3427, -0.1547,  0.1711, -0.2835],\n        [-0.0906, -0.3398,  0.1353, -0.2522,  0.1098, -0.2706, -0.1026,  0.1445],\n        [-0.2222,  0.0868, -0.2566,  0.0060, -0.0204, -0.1647, -0.0896,  0.0428],\n        [ 0.3078,  0.1264,  0.0255,  0.2352, -0.2103, -0.1032, -0.1661, -0.2583],\n        [-0.1749,  0.1640, -0.0622,  0.0829, -0.2814, -0.1597,  0.2376, -0.1932],\n        [-0.1594, -0.1359,  0.1775,  0.1849,  0.2879,  0.2739, -0.1885,  0.1050],\n        [ 0.2204,  0.1986,  0.2126,  0.2962, -0.0123, -0.2932,  0.2911,  0.1150],\n        [ 0.3159,  0.2808, -0.1518, -0.0075,  0.1452, -0.3011,  0.3473,  0.3030],\n        [-0.0571,  0.1822,  0.2730, -0.2921, -0.0607, -0.2953, -0.1146, -0.0287],\n        [-0.3013, -0.1319, -0.1541, -0.3443, -0.3276, -0.2809, -0.1079,  0.1433],\n        [ 0.3225, -0.1463,  0.0472, -0.0591,  0.2107, -0.1971,  0.1427, -0.0035],\n        [ 0.1317,  0.0694,  0.3510,  0.2290, -0.0343,  0.0915,  0.0851, -0.2873],\n        [-0.1629, -0.2270,  0.1709, -0.3309,  0.2982, -0.1475, -0.2088,  0.1374],\n        [ 0.0644, -0.1770, -0.0539, -0.1849,  0.3079,  0.1294,  0.0178, -0.2967],\n        [ 0.1324, -0.0475,  0.1255,  0.0205, -0.0340, -0.1246, -0.1547,  0.2874],\n        [-0.1650,  0.0843,  0.1404,  0.3278, -0.0385,  0.1513,  0.0101,  0.2741],\n        [ 0.0339, -0.0954,  0.3530, -0.0253,  0.0770,  0.2056, -0.0446, -0.3160],\n        [-0.1376,  0.1052, -0.2498,  0.0704,  0.2306, -0.0417,  0.0521, -0.1952],\n        [ 0.1535, -0.0255, -0.1180, -0.2459,  0.1515, -0.1101, -0.2630, -0.0633],\n        [ 0.3432, -0.3266, -0.1261,  0.2556,  0.2783,  0.0655, -0.1683,  0.3122],\n        [ 0.1582,  0.1113,  0.0066, -0.1186, -0.2934,  0.1265, -0.3476, -0.0921],\n        [ 0.2570,  0.2262, -0.1528,  0.2756,  0.0056, -0.3267, -0.3081,  0.1170],\n        [-0.0389, -0.2117, -0.2164,  0.1530,  0.2178,  0.0899, -0.2236, -0.0477]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2325,  0.0236, -0.3265,  0.0601,  0.1187,  0.0184,  0.0844,  0.2045,\n         0.1023, -0.1708, -0.2322, -0.3501,  0.0453, -0.0258, -0.1737, -0.2741,\n        -0.0809,  0.2914, -0.0744, -0.3087, -0.2964,  0.2774,  0.3474,  0.0705,\n         0.2862,  0.2647, -0.2510,  0.2387, -0.0457, -0.0498,  0.1038,  0.0851],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-2.8376e-02,  4.7873e-02,  6.4840e-02, -4.5469e-02, -2.5359e-02,\n          4.4779e-02, -3.3715e-02, -3.8026e-02, -1.0223e-01,  6.1730e-02,\n          5.7411e-03,  1.7674e-01, -3.6891e-02,  8.8193e-02,  1.9300e-02,\n          1.1334e-02,  1.5929e-01, -1.3123e-01, -1.3869e-01, -8.2986e-03,\n         -1.6585e-01,  1.2635e-01,  8.6916e-02, -6.1977e-02, -8.3730e-03,\n         -3.1145e-02,  2.0092e-03,  1.4261e-01, -9.3841e-02, -2.8974e-02,\n          1.5644e-01,  1.2266e-01],\n        [-2.4523e-02, -5.7890e-03, -1.2267e-01, -1.0215e-01,  1.3333e-01,\n          1.2840e-01, -9.6205e-02, -7.5122e-02,  1.5649e-01, -1.7443e-01,\n         -1.5852e-01, -2.2216e-02,  1.1016e-02, -1.5061e-01,  9.7007e-02,\n         -1.2046e-01,  1.4958e-01,  9.9527e-02,  1.1224e-01, -6.4203e-03,\n         -1.6791e-01,  1.6780e-01, -2.8980e-02, -7.0426e-02,  9.8668e-02,\n          1.3801e-01, -8.4402e-02,  8.2197e-02,  7.2971e-03,  1.4027e-01,\n          1.7229e-01,  9.2855e-03],\n        [ 6.9520e-02, -7.2440e-02, -1.6971e-01,  8.4847e-02, -2.1404e-02,\n         -8.7165e-02,  5.4123e-02,  1.7000e-01, -1.5379e-01, -5.1702e-02,\n         -5.6669e-02, -8.1652e-02,  8.1116e-02, -1.2465e-01,  1.3903e-01,\n         -1.4836e-01, -3.7066e-02,  9.0366e-02,  1.6823e-01,  6.0999e-02,\n         -1.1758e-01, -8.4157e-02,  1.4905e-01,  3.9591e-02, -2.2970e-04,\n          1.5474e-01, -7.6151e-02,  9.8828e-02,  9.5826e-02, -1.4119e-01,\n          1.2594e-01, -4.5224e-02],\n        [ 7.5908e-02, -1.5567e-01, -4.9446e-02, -1.5726e-01,  6.1799e-03,\n         -1.1105e-01,  1.3937e-01,  1.4218e-02, -1.5104e-01, -1.1705e-01,\n         -3.9418e-02,  1.3262e-02,  5.8359e-02, -3.2736e-02,  6.2079e-02,\n          9.7599e-02, -1.4697e-01, -8.4249e-02,  1.6050e-01, -3.2830e-02,\n         -1.1109e-02, -6.9944e-02, -3.3794e-02, -5.7124e-02,  1.2692e-01,\n         -6.4964e-02,  1.1979e-01,  4.6170e-02, -1.0954e-01, -9.0335e-02,\n          1.4698e-01, -1.2229e-01],\n        [-1.3685e-02, -1.4980e-01,  5.1350e-02,  1.4679e-01,  1.5476e-02,\n          1.7408e-02, -1.3850e-01, -5.8735e-02, -6.4514e-02,  6.7928e-04,\n         -8.3884e-02, -1.0126e-01, -1.8951e-03, -2.3347e-02, -1.0118e-01,\n          1.1165e-01,  1.5034e-01, -1.3502e-02,  6.7037e-02,  7.6409e-03,\n         -1.5856e-01, -1.4749e-02,  5.7057e-02, -1.0658e-01, -4.7343e-02,\n         -1.7464e-01, -1.4679e-01,  9.6310e-02,  9.0244e-02, -9.2242e-02,\n         -2.8224e-02, -2.6041e-02],\n        [ 5.4640e-02,  4.9076e-02,  3.1271e-02, -4.7030e-02,  6.4143e-02,\n          9.2265e-02,  2.4706e-02, -1.5325e-01, -1.5582e-01,  7.5420e-02,\n         -1.7234e-01,  6.1980e-02,  5.8878e-03, -7.2565e-02,  1.0295e-01,\n          1.1151e-01, -5.6537e-02, -2.2153e-02,  1.2697e-01,  3.7373e-02,\n         -1.1526e-01,  1.7284e-01,  1.2869e-01, -9.5631e-02, -9.5339e-02,\n         -1.0113e-01, -4.2613e-02, -1.5346e-01,  1.0241e-01,  2.3525e-02,\n         -1.5068e-01,  2.9257e-02],\n        [-1.4443e-01, -6.6674e-03,  1.0253e-01, -8.8623e-02,  1.5204e-01,\n         -1.3431e-01,  2.7223e-02,  8.6246e-03, -9.2197e-02,  1.3608e-01,\n          4.1372e-02,  3.6574e-02, -1.9298e-02, -1.4424e-01, -1.6699e-01,\n          1.6374e-01, -1.1241e-01,  5.2006e-02, -2.5628e-03,  4.1597e-02,\n          1.1044e-01, -8.4190e-04,  4.6026e-02,  1.0538e-01,  5.6413e-02,\n          1.1301e-01,  5.5462e-05, -1.2177e-01,  1.1571e-01, -1.7175e-01,\n          1.7234e-01, -1.1500e-02],\n        [ 9.5082e-02,  1.0111e-01, -1.7305e-01, -1.3143e-01, -4.8919e-02,\n         -1.4656e-01, -1.4169e-01,  4.7099e-02,  1.6412e-01, -1.3289e-01,\n          1.0092e-01, -1.0954e-01, -1.2304e-02, -8.3851e-02, -8.2439e-02,\n          9.2191e-02, -9.7528e-02,  4.1545e-02, -3.2183e-02, -4.3222e-02,\n          1.4214e-01,  6.1655e-03,  1.4966e-01, -1.0357e-02, -1.4152e-01,\n          4.6794e-02,  1.8970e-02,  1.4389e-01, -2.5343e-02, -2.5917e-02,\n         -4.0159e-02,  1.3322e-01],\n        [-1.7657e-01,  8.9049e-02,  2.8392e-02, -4.3020e-02,  1.6514e-01,\n         -3.6593e-02, -9.2003e-02,  3.1359e-03, -4.2045e-02, -1.0610e-02,\n          7.1485e-03,  1.1150e-01, -1.5381e-01, -7.6781e-03, -1.4293e-01,\n          1.7407e-01, -6.6183e-02, -5.1280e-02,  1.5806e-01, -1.3010e-01,\n          7.6294e-02, -1.4716e-01, -8.5624e-02,  2.4198e-02,  1.7286e-01,\n          1.1654e-01, -2.9314e-03,  3.5565e-02,  6.6343e-02,  1.4669e-01,\n         -1.4828e-02,  1.2623e-01],\n        [ 6.9448e-02,  1.5744e-01, -4.3824e-02,  2.6461e-03, -1.1106e-01,\n          3.7359e-02,  6.8180e-02, -1.4351e-01,  1.4966e-01, -2.0222e-02,\n          1.2895e-01, -3.5323e-02,  1.5647e-01, -9.1040e-02, -1.4705e-01,\n         -3.0390e-02,  1.3319e-01, -6.7186e-02,  1.2279e-01, -4.3182e-02,\n         -3.7307e-02, -8.8041e-02, -5.6598e-02, -1.0870e-02, -9.2769e-02,\n         -1.1429e-01, -1.4144e-01,  1.5677e-01,  3.3412e-02, -1.3346e-01,\n         -7.6147e-02,  3.6122e-02],\n        [-1.3289e-01, -1.5675e-01, -7.8298e-02, -4.6496e-02,  1.1435e-01,\n          1.4837e-01, -1.0923e-01, -7.0406e-02, -1.6213e-01,  5.6018e-02,\n          9.4018e-02, -1.4478e-01, -4.6446e-02, -1.0979e-01,  1.6432e-01,\n          5.2375e-02,  3.8028e-02, -7.0264e-02, -5.3968e-02,  2.5586e-02,\n         -1.5559e-02, -1.1763e-01,  1.1900e-01, -1.1335e-01, -1.2166e-01,\n          4.5605e-02,  1.0749e-01,  9.4165e-02, -5.6393e-02, -1.5736e-01,\n          7.3648e-02,  1.4879e-01],\n        [ 4.2024e-02,  1.6107e-01,  1.2511e-02, -1.3676e-01, -8.7942e-02,\n         -4.7955e-02,  1.6565e-01,  2.4229e-02,  1.0758e-01,  1.6233e-01,\n         -1.7233e-01, -1.9037e-02, -1.1456e-01, -6.3248e-02, -1.0200e-02,\n         -5.3164e-03, -1.4180e-01, -3.6768e-02, -2.7467e-02,  9.6098e-02,\n         -1.2291e-01, -6.4653e-02, -1.3381e-01, -4.2279e-02,  2.6332e-02,\n          7.5631e-03, -5.2790e-02,  1.0745e-01,  3.5254e-02, -1.1044e-01,\n         -6.6146e-02,  1.3002e-01],\n        [-6.7484e-02, -1.6262e-01,  7.6181e-02, -4.5097e-02, -1.5820e-01,\n          1.0914e-01,  1.1535e-01,  1.1885e-01,  1.2701e-01,  1.6587e-01,\n          6.9054e-02, -1.2962e-01, -1.4198e-02,  1.7305e-01,  5.7027e-02,\n         -2.8181e-02,  1.7631e-01, -1.2326e-01, -5.1214e-02,  1.4658e-01,\n         -8.5884e-02, -1.1273e-01,  4.8951e-02,  4.6988e-02,  5.4381e-02,\n          1.3363e-01,  1.6902e-02, -2.6017e-02, -6.1035e-02,  7.2567e-02,\n          1.1359e-01,  1.6317e-01],\n        [-2.6796e-02,  6.7940e-02,  1.4698e-01, -8.3741e-02,  8.6319e-02,\n         -2.6921e-02, -1.2751e-01, -3.8776e-02, -1.2086e-01, -1.0010e-01,\n         -1.2246e-01,  6.3218e-02,  1.2305e-03,  1.2735e-01, -5.3858e-02,\n         -7.4342e-02,  1.5533e-01, -1.3899e-01,  3.5609e-02,  1.1658e-01,\n         -1.2304e-01,  1.6520e-01, -4.7626e-02, -1.2583e-01,  8.4426e-02,\n          3.9601e-02,  2.7929e-02, -7.4791e-02, -1.7301e-01, -4.9010e-02,\n         -9.9295e-02, -8.4655e-02],\n        [-8.5975e-02, -1.3705e-01,  1.4230e-01, -1.1919e-01,  1.7192e-01,\n         -6.3314e-02,  5.4110e-02, -1.3736e-01, -1.4640e-01, -3.8244e-02,\n          5.3126e-04, -3.1436e-02, -1.0916e-01,  9.1474e-03,  1.6869e-01,\n          1.0156e-03, -3.6362e-03,  5.9246e-04,  1.5367e-01,  1.6182e-01,\n          2.0763e-02, -1.0761e-01, -7.4609e-02,  1.6124e-02,  1.6208e-01,\n          3.1407e-03,  1.0740e-01, -1.5497e-02, -9.8784e-02,  6.1585e-02,\n          1.6895e-01,  6.0963e-02],\n        [ 2.1485e-02,  7.5693e-02,  1.1873e-01, -1.6929e-01,  8.2379e-02,\n         -6.8267e-02,  1.7229e-01,  1.2498e-01, -1.4869e-01, -4.8854e-02,\n         -1.2785e-02,  1.6448e-01,  7.6258e-02,  1.0449e-01, -1.0907e-01,\n         -3.5940e-02,  1.2773e-01,  3.2286e-02, -1.3219e-01,  2.4689e-02,\n          4.8904e-02,  1.7414e-01,  4.9775e-03,  8.6995e-02,  1.1789e-01,\n         -1.1176e-01,  1.2409e-01,  7.3214e-02, -1.9226e-02,  1.4476e-01,\n          2.9335e-02, -1.5860e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0893,  0.1044, -0.1167,  0.1464, -0.1070,  0.1442,  0.1085, -0.1643,\n        -0.0099,  0.0454, -0.0472, -0.0944, -0.1485, -0.0161,  0.0539,  0.0341],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0939,  0.0430,  0.0756, -0.1519, -0.2365, -0.1734,  0.0883,  0.1071,\n         -0.0526, -0.2226, -0.1134,  0.0177,  0.1859, -0.1491, -0.0146, -0.1153],\n        [ 0.2313, -0.0738, -0.1909,  0.2453,  0.2145,  0.1236, -0.0330, -0.1774,\n          0.1117, -0.1544,  0.0874, -0.1457,  0.2168, -0.1710, -0.2296, -0.2171],\n        [-0.0604, -0.0345, -0.1931,  0.2492,  0.2332,  0.2161, -0.1546, -0.1278,\n         -0.2422, -0.1354, -0.2216,  0.1726,  0.1409,  0.0196,  0.2357, -0.0986],\n        [-0.0202,  0.2203,  0.1758, -0.0906,  0.0813,  0.0642,  0.1219,  0.2130,\n          0.0355, -0.0056,  0.0205, -0.0392,  0.0066, -0.1421, -0.0135, -0.2254],\n        [ 0.0528,  0.0360, -0.2100, -0.1133,  0.0032,  0.1468,  0.1677,  0.0429,\n         -0.1801,  0.0299,  0.0706,  0.0063, -0.2407,  0.0327,  0.0093,  0.1271],\n        [-0.2275, -0.1605,  0.2280, -0.2142, -0.0509,  0.0032, -0.2465,  0.0881,\n         -0.2004,  0.1837, -0.2254, -0.1340,  0.0505,  0.1021, -0.0725, -0.1775],\n        [ 0.2434,  0.1713,  0.1725, -0.1755, -0.1422, -0.0073, -0.0608,  0.1472,\n         -0.0675,  0.1305, -0.0604,  0.0425,  0.0639, -0.0289,  0.1380,  0.2426],\n        [-0.1893,  0.1694,  0.1457,  0.1598,  0.1484, -0.1817, -0.1963,  0.1515,\n          0.1526,  0.0008,  0.2397,  0.0702, -0.1443, -0.0937,  0.0122,  0.0231]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2451,  0.0975,  0.0171,  0.2125, -0.2295,  0.0151,  0.0066, -0.0672],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0122,  0.1384,  0.1091,  0.0645,  0.1231, -0.1031,  0.0745,  0.0576]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0376], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x00000218FFD26320>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	10,
            "_train_update_freq":	1,
            "_traj_per_epoch":	64,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x00000218D1AD8CA0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s185320000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s185320000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2325,  0.0236, -0.3265,  0.0601,  0.1187,  0.0184,  0.0844,  0.2045,\n         0.1023, -0.1708, -0.2322, -0.3501,  0.0453, -0.0258, -0.1737, -0.2741,\n        -0.0809,  0.2914, -0.0744, -0.3087, -0.2964,  0.2774,  0.3474,  0.0705,\n         0.2862,  0.2647, -0.2510,  0.2387, -0.0457, -0.0498,  0.1038,  0.0851],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0395, -0.0820, -0.2982, -0.2540, -0.0699, -0.0168, -0.1761, -0.1445],\n        [ 0.0677,  0.0338,  0.0055, -0.1563,  0.2802,  0.2658,  0.3142, -0.0443],\n        [-0.2639, -0.2102, -0.0497, -0.3252,  0.0208,  0.2737,  0.3207,  0.1457],\n        [ 0.1770,  0.0461, -0.3064,  0.3081,  0.2563,  0.1929, -0.3467,  0.1782],\n        [-0.2962,  0.0189,  0.2618, -0.0097,  0.1954, -0.3067,  0.1300,  0.0129],\n        [ 0.3457, -0.2278, -0.0023,  0.2183, -0.1320,  0.0043,  0.0286,  0.1780],\n        [-0.0671, -0.3101, -0.0272,  0.2155,  0.2595,  0.1834,  0.3012,  0.3403],\n        [ 0.1968, -0.2580, -0.2876,  0.2718, -0.3362,  0.2638, -0.1399, -0.0538],\n        [ 0.1867, -0.0262, -0.2009,  0.2125,  0.2028, -0.1032,  0.3081, -0.2023],\n        [ 0.0987, -0.0780, -0.2819,  0.1004,  0.3427, -0.1547,  0.1711, -0.2835],\n        [-0.0906, -0.3398,  0.1353, -0.2522,  0.1098, -0.2706, -0.1026,  0.1445],\n        [-0.2222,  0.0868, -0.2566,  0.0060, -0.0204, -0.1647, -0.0896,  0.0428],\n        [ 0.3078,  0.1264,  0.0255,  0.2352, -0.2103, -0.1032, -0.1661, -0.2583],\n        [-0.1749,  0.1640, -0.0622,  0.0829, -0.2814, -0.1597,  0.2376, -0.1932],\n        [-0.1594, -0.1359,  0.1775,  0.1849,  0.2879,  0.2739, -0.1885,  0.1050],\n        [ 0.2204,  0.1986,  0.2126,  0.2962, -0.0123, -0.2932,  0.2911,  0.1150],\n        [ 0.3159,  0.2808, -0.1518, -0.0075,  0.1452, -0.3011,  0.3473,  0.3030],\n        [-0.0571,  0.1822,  0.2730, -0.2921, -0.0607, -0.2953, -0.1146, -0.0287],\n        [-0.3013, -0.1319, -0.1541, -0.3443, -0.3276, -0.2809, -0.1079,  0.1433],\n        [ 0.3225, -0.1463,  0.0472, -0.0591,  0.2107, -0.1971,  0.1427, -0.0035],\n        [ 0.1317,  0.0694,  0.3510,  0.2290, -0.0343,  0.0915,  0.0851, -0.2873],\n        [-0.1629, -0.2270,  0.1709, -0.3309,  0.2982, -0.1475, -0.2088,  0.1374],\n        [ 0.0644, -0.1770, -0.0539, -0.1849,  0.3079,  0.1294,  0.0178, -0.2967],\n        [ 0.1324, -0.0475,  0.1255,  0.0205, -0.0340, -0.1246, -0.1547,  0.2874],\n        [-0.1650,  0.0843,  0.1404,  0.3278, -0.0385,  0.1513,  0.0101,  0.2741],\n        [ 0.0339, -0.0954,  0.3530, -0.0253,  0.0770,  0.2056, -0.0446, -0.3160],\n        [-0.1376,  0.1052, -0.2498,  0.0704,  0.2306, -0.0417,  0.0521, -0.1952],\n        [ 0.1535, -0.0255, -0.1180, -0.2459,  0.1515, -0.1101, -0.2630, -0.0633],\n        [ 0.3432, -0.3266, -0.1261,  0.2556,  0.2783,  0.0655, -0.1683,  0.3122],\n        [ 0.1582,  0.1113,  0.0066, -0.1186, -0.2934,  0.1265, -0.3476, -0.0921],\n        [ 0.2570,  0.2262, -0.1528,  0.2756,  0.0056, -0.3267, -0.3081,  0.1170],\n        [-0.0389, -0.2117, -0.2164,  0.1530,  0.2178,  0.0899, -0.2236, -0.0477]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0893,  0.1044, -0.1167,  0.1464, -0.1070,  0.1442,  0.1085, -0.1643,\n        -0.0099,  0.0454, -0.0472, -0.0944, -0.1485, -0.0161,  0.0539,  0.0341],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.8376e-02,  4.7873e-02,  6.4840e-02, -4.5469e-02, -2.5359e-02,\n          4.4779e-02, -3.3715e-02, -3.8026e-02, -1.0223e-01,  6.1730e-02,\n          5.7411e-03,  1.7674e-01, -3.6891e-02,  8.8193e-02,  1.9300e-02,\n          1.1334e-02,  1.5929e-01, -1.3123e-01, -1.3869e-01, -8.2986e-03,\n         -1.6585e-01,  1.2635e-01,  8.6916e-02, -6.1977e-02, -8.3730e-03,\n         -3.1145e-02,  2.0092e-03,  1.4261e-01, -9.3841e-02, -2.8974e-02,\n          1.5644e-01,  1.2266e-01],\n        [-2.4523e-02, -5.7890e-03, -1.2267e-01, -1.0215e-01,  1.3333e-01,\n          1.2840e-01, -9.6205e-02, -7.5122e-02,  1.5649e-01, -1.7443e-01,\n         -1.5852e-01, -2.2216e-02,  1.1016e-02, -1.5061e-01,  9.7007e-02,\n         -1.2046e-01,  1.4958e-01,  9.9527e-02,  1.1224e-01, -6.4203e-03,\n         -1.6791e-01,  1.6780e-01, -2.8980e-02, -7.0426e-02,  9.8668e-02,\n          1.3801e-01, -8.4402e-02,  8.2197e-02,  7.2971e-03,  1.4027e-01,\n          1.7229e-01,  9.2855e-03],\n        [ 6.9520e-02, -7.2440e-02, -1.6971e-01,  8.4847e-02, -2.1404e-02,\n         -8.7165e-02,  5.4123e-02,  1.7000e-01, -1.5379e-01, -5.1702e-02,\n         -5.6669e-02, -8.1652e-02,  8.1116e-02, -1.2465e-01,  1.3903e-01,\n         -1.4836e-01, -3.7066e-02,  9.0366e-02,  1.6823e-01,  6.0999e-02,\n         -1.1758e-01, -8.4157e-02,  1.4905e-01,  3.9591e-02, -2.2970e-04,\n          1.5474e-01, -7.6151e-02,  9.8828e-02,  9.5826e-02, -1.4119e-01,\n          1.2594e-01, -4.5224e-02],\n        [ 7.5908e-02, -1.5567e-01, -4.9446e-02, -1.5726e-01,  6.1799e-03,\n         -1.1105e-01,  1.3937e-01,  1.4218e-02, -1.5104e-01, -1.1705e-01,\n         -3.9418e-02,  1.3262e-02,  5.8359e-02, -3.2736e-02,  6.2079e-02,\n          9.7599e-02, -1.4697e-01, -8.4249e-02,  1.6050e-01, -3.2830e-02,\n         -1.1109e-02, -6.9944e-02, -3.3794e-02, -5.7124e-02,  1.2692e-01,\n         -6.4964e-02,  1.1979e-01,  4.6170e-02, -1.0954e-01, -9.0335e-02,\n          1.4698e-01, -1.2229e-01],\n        [-1.3685e-02, -1.4980e-01,  5.1350e-02,  1.4679e-01,  1.5476e-02,\n          1.7408e-02, -1.3850e-01, -5.8735e-02, -6.4514e-02,  6.7928e-04,\n         -8.3884e-02, -1.0126e-01, -1.8951e-03, -2.3347e-02, -1.0118e-01,\n          1.1165e-01,  1.5034e-01, -1.3502e-02,  6.7037e-02,  7.6409e-03,\n         -1.5856e-01, -1.4749e-02,  5.7057e-02, -1.0658e-01, -4.7343e-02,\n         -1.7464e-01, -1.4679e-01,  9.6310e-02,  9.0244e-02, -9.2242e-02,\n         -2.8224e-02, -2.6041e-02],\n        [ 5.4640e-02,  4.9076e-02,  3.1271e-02, -4.7030e-02,  6.4143e-02,\n          9.2265e-02,  2.4706e-02, -1.5325e-01, -1.5582e-01,  7.5420e-02,\n         -1.7234e-01,  6.1980e-02,  5.8878e-03, -7.2565e-02,  1.0295e-01,\n          1.1151e-01, -5.6537e-02, -2.2153e-02,  1.2697e-01,  3.7373e-02,\n         -1.1526e-01,  1.7284e-01,  1.2869e-01, -9.5631e-02, -9.5339e-02,\n         -1.0113e-01, -4.2613e-02, -1.5346e-01,  1.0241e-01,  2.3525e-02,\n         -1.5068e-01,  2.9257e-02],\n        [-1.4443e-01, -6.6674e-03,  1.0253e-01, -8.8623e-02,  1.5204e-01,\n         -1.3431e-01,  2.7223e-02,  8.6246e-03, -9.2197e-02,  1.3608e-01,\n          4.1372e-02,  3.6574e-02, -1.9298e-02, -1.4424e-01, -1.6699e-01,\n          1.6374e-01, -1.1241e-01,  5.2006e-02, -2.5628e-03,  4.1597e-02,\n          1.1044e-01, -8.4190e-04,  4.6026e-02,  1.0538e-01,  5.6413e-02,\n          1.1301e-01,  5.5462e-05, -1.2177e-01,  1.1571e-01, -1.7175e-01,\n          1.7234e-01, -1.1500e-02],\n        [ 9.5082e-02,  1.0111e-01, -1.7305e-01, -1.3143e-01, -4.8919e-02,\n         -1.4656e-01, -1.4169e-01,  4.7099e-02,  1.6412e-01, -1.3289e-01,\n          1.0092e-01, -1.0954e-01, -1.2304e-02, -8.3851e-02, -8.2439e-02,\n          9.2191e-02, -9.7528e-02,  4.1545e-02, -3.2183e-02, -4.3222e-02,\n          1.4214e-01,  6.1655e-03,  1.4966e-01, -1.0357e-02, -1.4152e-01,\n          4.6794e-02,  1.8970e-02,  1.4389e-01, -2.5343e-02, -2.5917e-02,\n         -4.0159e-02,  1.3322e-01],\n        [-1.7657e-01,  8.9049e-02,  2.8392e-02, -4.3020e-02,  1.6514e-01,\n         -3.6593e-02, -9.2003e-02,  3.1359e-03, -4.2045e-02, -1.0610e-02,\n          7.1485e-03,  1.1150e-01, -1.5381e-01, -7.6781e-03, -1.4293e-01,\n          1.7407e-01, -6.6183e-02, -5.1280e-02,  1.5806e-01, -1.3010e-01,\n          7.6294e-02, -1.4716e-01, -8.5624e-02,  2.4198e-02,  1.7286e-01,\n          1.1654e-01, -2.9314e-03,  3.5565e-02,  6.6343e-02,  1.4669e-01,\n         -1.4828e-02,  1.2623e-01],\n        [ 6.9448e-02,  1.5744e-01, -4.3824e-02,  2.6461e-03, -1.1106e-01,\n          3.7359e-02,  6.8180e-02, -1.4351e-01,  1.4966e-01, -2.0222e-02,\n          1.2895e-01, -3.5323e-02,  1.5647e-01, -9.1040e-02, -1.4705e-01,\n         -3.0390e-02,  1.3319e-01, -6.7186e-02,  1.2279e-01, -4.3182e-02,\n         -3.7307e-02, -8.8041e-02, -5.6598e-02, -1.0870e-02, -9.2769e-02,\n         -1.1429e-01, -1.4144e-01,  1.5677e-01,  3.3412e-02, -1.3346e-01,\n         -7.6147e-02,  3.6122e-02],\n        [-1.3289e-01, -1.5675e-01, -7.8298e-02, -4.6496e-02,  1.1435e-01,\n          1.4837e-01, -1.0923e-01, -7.0406e-02, -1.6213e-01,  5.6018e-02,\n          9.4018e-02, -1.4478e-01, -4.6446e-02, -1.0979e-01,  1.6432e-01,\n          5.2375e-02,  3.8028e-02, -7.0264e-02, -5.3968e-02,  2.5586e-02,\n         -1.5559e-02, -1.1763e-01,  1.1900e-01, -1.1335e-01, -1.2166e-01,\n          4.5605e-02,  1.0749e-01,  9.4165e-02, -5.6393e-02, -1.5736e-01,\n          7.3648e-02,  1.4879e-01],\n        [ 4.2024e-02,  1.6107e-01,  1.2511e-02, -1.3676e-01, -8.7942e-02,\n         -4.7955e-02,  1.6565e-01,  2.4229e-02,  1.0758e-01,  1.6233e-01,\n         -1.7233e-01, -1.9037e-02, -1.1456e-01, -6.3248e-02, -1.0200e-02,\n         -5.3164e-03, -1.4180e-01, -3.6768e-02, -2.7467e-02,  9.6098e-02,\n         -1.2291e-01, -6.4653e-02, -1.3381e-01, -4.2279e-02,  2.6332e-02,\n          7.5631e-03, -5.2790e-02,  1.0745e-01,  3.5254e-02, -1.1044e-01,\n         -6.6146e-02,  1.3002e-01],\n        [-6.7484e-02, -1.6262e-01,  7.6181e-02, -4.5097e-02, -1.5820e-01,\n          1.0914e-01,  1.1535e-01,  1.1885e-01,  1.2701e-01,  1.6587e-01,\n          6.9054e-02, -1.2962e-01, -1.4198e-02,  1.7305e-01,  5.7027e-02,\n         -2.8181e-02,  1.7631e-01, -1.2326e-01, -5.1214e-02,  1.4658e-01,\n         -8.5884e-02, -1.1273e-01,  4.8951e-02,  4.6988e-02,  5.4381e-02,\n          1.3363e-01,  1.6902e-02, -2.6017e-02, -6.1035e-02,  7.2567e-02,\n          1.1359e-01,  1.6317e-01],\n        [-2.6796e-02,  6.7940e-02,  1.4698e-01, -8.3741e-02,  8.6319e-02,\n         -2.6921e-02, -1.2751e-01, -3.8776e-02, -1.2086e-01, -1.0010e-01,\n         -1.2246e-01,  6.3218e-02,  1.2305e-03,  1.2735e-01, -5.3858e-02,\n         -7.4342e-02,  1.5533e-01, -1.3899e-01,  3.5609e-02,  1.1658e-01,\n         -1.2304e-01,  1.6520e-01, -4.7626e-02, -1.2583e-01,  8.4426e-02,\n          3.9601e-02,  2.7929e-02, -7.4791e-02, -1.7301e-01, -4.9010e-02,\n         -9.9295e-02, -8.4655e-02],\n        [-8.5975e-02, -1.3705e-01,  1.4230e-01, -1.1919e-01,  1.7192e-01,\n         -6.3314e-02,  5.4110e-02, -1.3736e-01, -1.4640e-01, -3.8244e-02,\n          5.3126e-04, -3.1436e-02, -1.0916e-01,  9.1474e-03,  1.6869e-01,\n          1.0156e-03, -3.6362e-03,  5.9246e-04,  1.5367e-01,  1.6182e-01,\n          2.0763e-02, -1.0761e-01, -7.4609e-02,  1.6124e-02,  1.6208e-01,\n          3.1407e-03,  1.0740e-01, -1.5497e-02, -9.8784e-02,  6.1585e-02,\n          1.6895e-01,  6.0963e-02],\n        [ 2.1485e-02,  7.5693e-02,  1.1873e-01, -1.6929e-01,  8.2379e-02,\n         -6.8267e-02,  1.7229e-01,  1.2498e-01, -1.4869e-01, -4.8854e-02,\n         -1.2785e-02,  1.6448e-01,  7.6258e-02,  1.0449e-01, -1.0907e-01,\n         -3.5940e-02,  1.2773e-01,  3.2286e-02, -1.3219e-01,  2.4689e-02,\n          4.8904e-02,  1.7414e-01,  4.9775e-03,  8.6995e-02,  1.1789e-01,\n         -1.1176e-01,  1.2409e-01,  7.3214e-02, -1.9226e-02,  1.4476e-01,\n          2.9335e-02, -1.5860e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2451,  0.0975,  0.0171,  0.2125, -0.2295,  0.0151,  0.0066, -0.0672],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0939,  0.0430,  0.0756, -0.1519, -0.2365, -0.1734,  0.0883,  0.1071,\n         -0.0526, -0.2226, -0.1134,  0.0177,  0.1859, -0.1491, -0.0146, -0.1153],\n        [ 0.2313, -0.0738, -0.1909,  0.2453,  0.2145,  0.1236, -0.0330, -0.1774,\n          0.1117, -0.1544,  0.0874, -0.1457,  0.2168, -0.1710, -0.2296, -0.2171],\n        [-0.0604, -0.0345, -0.1931,  0.2492,  0.2332,  0.2161, -0.1546, -0.1278,\n         -0.2422, -0.1354, -0.2216,  0.1726,  0.1409,  0.0196,  0.2357, -0.0986],\n        [-0.0202,  0.2203,  0.1758, -0.0906,  0.0813,  0.0642,  0.1219,  0.2130,\n          0.0355, -0.0056,  0.0205, -0.0392,  0.0066, -0.1421, -0.0135, -0.2254],\n        [ 0.0528,  0.0360, -0.2100, -0.1133,  0.0032,  0.1468,  0.1677,  0.0429,\n         -0.1801,  0.0299,  0.0706,  0.0063, -0.2407,  0.0327,  0.0093,  0.1271],\n        [-0.2275, -0.1605,  0.2280, -0.2142, -0.0509,  0.0032, -0.2465,  0.0881,\n         -0.2004,  0.1837, -0.2254, -0.1340,  0.0505,  0.1021, -0.0725, -0.1775],\n        [ 0.2434,  0.1713,  0.1725, -0.1755, -0.1422, -0.0073, -0.0608,  0.1472,\n         -0.0675,  0.1305, -0.0604,  0.0425,  0.0639, -0.0289,  0.1380,  0.2426],\n        [-0.1893,  0.1694,  0.1457,  0.1598,  0.1484, -0.1817, -0.1963,  0.1515,\n          0.1526,  0.0008,  0.2397,  0.0702, -0.1443, -0.0937,  0.0122,  0.0231]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0376], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0122,  0.1384,  0.1091,  0.0645,  0.1231, -0.1031,  0.0745,  0.0576]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	10,
    "train_update_freq":	1,
    "traj_per_epoch":	64
}