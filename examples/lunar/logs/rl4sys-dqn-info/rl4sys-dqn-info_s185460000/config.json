{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	5000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s185460000"
    },
    "q_lr":	0.0005,
    "seed":	185460000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x171cd63e0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2771,  0.0880, -0.1325, -0.3114,  0.0698, -0.2492, -0.1014, -0.2726,\n        -0.0715,  0.0333, -0.1625, -0.2666, -0.1575, -0.2703,  0.3418, -0.0624,\n         0.0387,  0.3291, -0.0494, -0.1924, -0.1030,  0.1394, -0.1880,  0.2368,\n         0.2772, -0.1291,  0.0904, -0.1163, -0.2528,  0.3344,  0.2138, -0.2559],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1802, -0.1113,  0.1238,  0.2691, -0.3282,  0.1005, -0.3449, -0.0295],\n        [ 0.0342,  0.3005,  0.1950, -0.1702, -0.1580, -0.2826,  0.2594,  0.2923],\n        [-0.2911, -0.0313,  0.2922, -0.1580,  0.1147,  0.2260,  0.0740,  0.2297],\n        [ 0.0647, -0.1308, -0.1126, -0.1351, -0.0237, -0.2379,  0.2734,  0.2457],\n        [ 0.1318,  0.0728, -0.2599, -0.0349, -0.0284, -0.0300,  0.0156,  0.2747],\n        [-0.3082,  0.0741, -0.3093,  0.2422, -0.1046, -0.2619, -0.1466,  0.3114],\n        [-0.2845, -0.0937, -0.0700,  0.1210,  0.0161,  0.2075, -0.0339,  0.0535],\n        [ 0.3419,  0.1405, -0.1789, -0.0313, -0.2811, -0.2085,  0.0961, -0.2112],\n        [-0.1225, -0.1405, -0.3321, -0.1102, -0.2882,  0.1835,  0.0530,  0.2966],\n        [-0.1242,  0.0135,  0.2834,  0.0955, -0.0232,  0.3462,  0.0578, -0.0073],\n        [ 0.2366,  0.1055,  0.0140, -0.0251,  0.0404, -0.0759,  0.0645, -0.2314],\n        [ 0.0319, -0.0376, -0.3029,  0.2588,  0.2158,  0.1205,  0.3139,  0.1909],\n        [-0.0096, -0.1045, -0.1001,  0.0898,  0.1607, -0.0908,  0.3076, -0.3400],\n        [ 0.0567, -0.2994, -0.2788,  0.0339, -0.2687,  0.1265, -0.1683,  0.1618],\n        [ 0.1450,  0.2757,  0.2706, -0.3493,  0.2535, -0.0147,  0.3227,  0.2678],\n        [-0.1865, -0.0432,  0.0295,  0.0124,  0.2695, -0.1426, -0.1348, -0.1353],\n        [ 0.2616, -0.0695,  0.2901, -0.2469,  0.3415,  0.1977,  0.1884,  0.0186],\n        [-0.0927,  0.2680,  0.1567, -0.2193,  0.0171, -0.3224, -0.2679, -0.0534],\n        [ 0.2702,  0.1990,  0.2496,  0.1659,  0.0674,  0.0172, -0.0487,  0.1010],\n        [ 0.0980,  0.2066, -0.3062,  0.0631,  0.3331, -0.0506, -0.0261, -0.2045],\n        [ 0.0101,  0.1084,  0.1679,  0.2734,  0.0008, -0.2586,  0.1478, -0.0755],\n        [-0.3409,  0.1623, -0.2790, -0.2270,  0.1403,  0.1841,  0.3502,  0.3344],\n        [-0.1591, -0.0881,  0.0702,  0.0585,  0.2737,  0.1340,  0.0070,  0.1404],\n        [-0.0111,  0.0170,  0.2765, -0.2672, -0.2874, -0.1827, -0.1992,  0.0721],\n        [-0.2764, -0.0482, -0.2582,  0.3309, -0.1104, -0.1133,  0.3082,  0.1293],\n        [ 0.2912, -0.2396, -0.2634,  0.2282,  0.1162,  0.3210,  0.2519, -0.0595],\n        [ 0.1195,  0.3419, -0.0423,  0.0527,  0.1468,  0.0117, -0.1938,  0.1559],\n        [ 0.3120,  0.1369,  0.1963,  0.3514, -0.0625, -0.3463, -0.2198, -0.0794],\n        [ 0.0776,  0.0205,  0.2663, -0.3090, -0.2652, -0.0365,  0.1263, -0.0220],\n        [-0.2054, -0.3140,  0.2128,  0.0853, -0.2290,  0.2909, -0.0748, -0.1046],\n        [ 0.0231, -0.2482,  0.3239,  0.1039,  0.0421, -0.1048,  0.0693,  0.3332],\n        [ 0.1601, -0.0968,  0.1195, -0.1774, -0.0854, -0.1755,  0.1305,  0.1982]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1450,  0.1192, -0.0878,  0.0579, -0.1028,  0.0409,  0.1582, -0.0843,\n         0.0735, -0.0892,  0.0944,  0.1719, -0.1588,  0.0652, -0.0595,  0.1170],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 8.5205e-02,  1.5719e-01, -6.7914e-02, -1.1285e-01, -7.3901e-02,\n         -1.4491e-01,  1.2703e-01, -1.4213e-01,  1.1365e-01,  2.9038e-02,\n          1.7275e-01,  1.5397e-01, -3.0099e-02, -1.5173e-01, -1.3849e-01,\n         -1.6344e-01,  1.6575e-01, -3.3060e-03, -2.6226e-02, -2.3514e-02,\n          1.3476e-01,  2.3602e-06, -1.2182e-01, -1.1511e-01,  1.0192e-01,\n         -2.4540e-02,  6.1958e-02, -6.4238e-02,  1.0129e-02, -2.8638e-02,\n          3.7552e-02, -1.2556e-01],\n        [ 1.4060e-01, -2.2915e-02, -1.0832e-01,  6.2226e-02, -3.5346e-02,\n         -6.8157e-02, -3.3594e-02, -2.5162e-02, -1.7146e-01,  1.4665e-01,\n         -7.2427e-03, -8.2097e-02,  6.2431e-02,  1.1082e-01, -1.6248e-01,\n         -1.3474e-01,  1.6485e-01,  3.5678e-02, -1.6261e-01,  1.3600e-01,\n         -5.2438e-03, -5.0996e-02,  1.2406e-02,  1.7314e-02, -8.4128e-03,\n         -1.1819e-01, -6.9106e-02,  1.1611e-01, -3.7516e-02, -1.4606e-01,\n          3.9709e-02, -3.9968e-02],\n        [-1.2848e-01, -1.1440e-02, -1.0154e-01, -1.6688e-01,  1.4097e-02,\n          7.8535e-02, -6.8861e-02,  1.3347e-01, -4.0730e-02,  6.5531e-02,\n         -1.1532e-01, -6.8652e-03, -1.5458e-01, -2.5864e-02,  1.1537e-01,\n         -1.5983e-01,  1.6742e-01,  2.5462e-02, -6.4114e-02, -2.3819e-02,\n          1.6571e-01,  1.3078e-01,  6.3214e-02, -2.3965e-02,  9.1589e-02,\n          5.8228e-02,  1.6640e-01,  6.3962e-02, -2.2383e-02,  1.0643e-01,\n          1.6984e-01, -1.4982e-01],\n        [ 1.1243e-02, -7.9656e-02, -1.2851e-01,  6.6187e-02, -1.4027e-01,\n          1.2944e-02,  8.3688e-03, -6.4655e-02,  1.2379e-01, -2.3059e-02,\n          3.6429e-02,  5.9819e-02, -1.3500e-01, -1.7219e-01, -1.2314e-01,\n         -7.6567e-02, -9.5353e-02,  6.7398e-02, -2.3108e-02,  3.7597e-02,\n          1.0429e-01, -1.2200e-01, -7.9710e-02, -9.8401e-02, -9.8064e-02,\n         -1.4119e-01,  1.0272e-01, -1.0140e-01, -8.7203e-02, -4.1549e-02,\n          2.6912e-02, -1.6110e-01],\n        [ 1.2320e-01, -7.6757e-02,  1.4162e-01, -1.6940e-01, -1.2437e-01,\n         -8.2113e-02,  2.6526e-02,  1.1132e-01, -1.4931e-01, -1.5722e-01,\n          7.2901e-02, -1.1688e-01,  1.0295e-01, -1.5700e-01,  6.2570e-02,\n         -1.5331e-01, -8.0669e-02,  1.4914e-01, -6.4738e-02,  9.1563e-02,\n          1.2421e-01, -5.9752e-03,  1.1527e-01,  5.4182e-02, -4.5368e-02,\n         -1.0329e-02,  8.7048e-02,  8.3175e-02, -1.2167e-01, -1.1675e-01,\n          1.1402e-01,  7.3418e-02],\n        [ 2.8827e-02,  1.5664e-01,  1.4034e-01, -1.7277e-01, -4.6527e-02,\n         -1.6883e-01,  1.7148e-01,  1.3905e-01,  6.6038e-02, -1.1283e-01,\n          1.3475e-01,  1.2383e-01,  1.1327e-01,  4.0092e-02,  1.6539e-01,\n          1.2277e-01, -1.3933e-01,  6.6036e-02, -1.2801e-01, -1.3950e-02,\n         -8.8511e-02, -1.3980e-01, -3.0170e-02, -1.1572e-01,  1.5318e-01,\n         -1.7985e-02,  5.3550e-02, -1.1513e-01, -1.4505e-02, -1.5486e-01,\n          9.9488e-02, -8.2678e-02],\n        [-9.1137e-02, -8.4580e-02,  8.7231e-02,  8.3185e-02,  8.6633e-02,\n         -1.4035e-01, -1.3876e-01,  2.3046e-02, -1.1804e-01, -1.6804e-01,\n          6.7315e-02, -1.4416e-01,  3.9125e-02, -7.5381e-02,  6.6776e-02,\n          1.2741e-01, -5.3609e-02,  4.7504e-02,  9.6045e-02, -3.3260e-02,\n          1.6216e-01,  1.2686e-01,  1.0955e-01, -1.4341e-01,  9.0377e-02,\n          9.6863e-02,  4.0194e-02, -1.0483e-01, -1.7014e-01, -5.8607e-02,\n         -6.8451e-02, -7.9039e-02],\n        [-3.3821e-02, -1.3274e-01, -1.4500e-01,  9.0740e-02,  4.3147e-02,\n          1.0539e-01, -1.3844e-01,  9.3664e-02,  1.6133e-01,  1.4501e-02,\n          2.8903e-02, -1.2378e-01, -1.1589e-01,  5.6528e-02, -1.6850e-01,\n          1.4271e-01, -6.9759e-02,  1.7361e-01,  8.2183e-02,  7.6121e-02,\n         -1.1890e-01,  1.1645e-01, -1.1742e-01,  5.7558e-02, -5.1882e-02,\n          4.1230e-02, -9.8096e-02,  9.8665e-02,  1.3153e-01,  1.1678e-01,\n         -4.9553e-02,  1.7386e-01],\n        [ 3.3525e-02, -1.3943e-01,  1.3898e-02, -1.6846e-01, -1.4648e-02,\n          6.8188e-02,  1.2240e-01,  1.2797e-01, -2.8527e-02, -9.1978e-02,\n          2.7528e-02, -1.7594e-01, -1.1864e-01, -1.1326e-01,  1.1452e-01,\n         -3.5619e-03, -1.0247e-01,  1.1516e-01, -5.1206e-02, -8.9652e-02,\n          2.9385e-02, -2.7630e-02, -8.3697e-02, -4.9394e-03, -8.6167e-02,\n         -1.6765e-01,  1.6450e-01, -9.2731e-02, -1.3916e-01, -1.4938e-01,\n         -9.1164e-02,  3.7514e-02],\n        [-8.6458e-02,  9.8701e-02, -6.6356e-02, -1.4719e-01, -5.0487e-02,\n          1.1908e-01, -9.5756e-02, -1.6809e-01,  1.1376e-01,  7.5249e-02,\n          1.6028e-01,  1.6229e-01,  3.1860e-02,  5.6963e-02, -6.2135e-02,\n         -1.4190e-01, -4.9419e-02, -1.3343e-01, -1.3325e-01, -7.0284e-02,\n          1.1091e-01,  2.0979e-02, -8.8293e-02,  9.5180e-02,  1.7388e-01,\n          1.6797e-01,  3.0077e-03, -9.5252e-02, -5.4426e-02, -9.9974e-02,\n          1.5740e-01, -5.9788e-02],\n        [-1.0669e-01, -6.4648e-02, -1.4140e-01,  9.4440e-02,  1.3178e-01,\n          8.7014e-03,  3.0476e-02,  1.6491e-01,  1.5964e-01,  3.6038e-02,\n         -3.1715e-03,  8.4956e-02, -4.9865e-02, -1.8759e-02,  7.9149e-02,\n         -1.5276e-03, -1.9295e-02,  3.4689e-02,  1.6031e-01,  1.3671e-01,\n          5.1951e-02, -1.0060e-01,  5.7674e-02, -3.3547e-02, -9.7089e-02,\n          1.3332e-01,  1.5070e-01, -3.5388e-02, -1.2999e-01,  5.6293e-02,\n         -1.4340e-01,  8.3733e-02],\n        [-1.3696e-01, -1.1218e-01,  7.4429e-02, -1.5751e-01, -1.4928e-01,\n         -6.6266e-02, -1.0924e-01, -6.5176e-02,  1.3125e-01, -3.7260e-03,\n          7.3882e-02, -2.9090e-02,  1.6902e-01,  1.1244e-01, -2.8947e-02,\n          4.8890e-02, -6.4900e-03, -1.5438e-01, -1.2713e-01,  1.4121e-01,\n         -7.5752e-02,  9.6753e-02,  7.2419e-02, -9.3635e-02,  1.0083e-01,\n          1.4174e-01,  1.2979e-01, -3.9517e-02, -1.5141e-01,  8.0148e-02,\n         -1.2970e-01,  5.4138e-02],\n        [-6.7001e-02, -1.3458e-02,  8.1527e-02,  8.2955e-02, -3.7803e-03,\n         -6.6458e-02,  3.0150e-02, -1.5355e-01,  1.3583e-01,  3.1003e-02,\n          9.0074e-02,  6.0844e-02, -1.6660e-01, -8.7545e-02,  1.6152e-01,\n         -1.6577e-01, -8.4566e-02,  1.5410e-01,  1.1197e-01,  1.5067e-01,\n          7.8690e-02,  9.3962e-02,  1.2920e-01,  7.2200e-02,  1.3280e-02,\n          3.9522e-03,  9.8518e-02, -8.8043e-02, -8.2665e-02, -5.2062e-02,\n          1.4769e-01,  9.8890e-02],\n        [-6.4417e-03, -2.3815e-02, -1.2142e-01,  1.5127e-01, -1.6475e-01,\n         -7.4019e-02,  1.1440e-01,  9.2456e-02, -8.7572e-02,  4.4415e-02,\n         -1.0102e-01,  2.6582e-02, -2.4545e-02, -1.3616e-01, -7.7921e-03,\n          3.3861e-02,  9.2600e-02, -1.1677e-01,  1.1920e-01,  1.1004e-01,\n          4.9031e-03, -2.7951e-02,  1.2065e-01, -1.5033e-01,  1.5429e-01,\n         -1.4655e-01,  1.7613e-01,  5.0412e-02,  2.7503e-02,  1.0266e-01,\n         -1.3065e-01, -1.2681e-01],\n        [ 1.6786e-01,  1.0587e-01, -7.4936e-02, -7.3036e-02, -6.2757e-02,\n          8.3878e-02, -2.9067e-02,  8.1062e-02, -9.5388e-02,  1.9369e-02,\n          6.9231e-02,  4.8228e-03,  1.6178e-01, -4.6172e-02, -6.5280e-02,\n          1.1511e-01, -4.8202e-02, -8.0951e-02, -1.3294e-01, -2.8559e-02,\n          4.0604e-02,  1.4442e-01, -1.0904e-01,  4.5886e-02,  1.0664e-01,\n         -2.6262e-02, -7.5769e-02, -3.9367e-02, -1.3231e-01,  6.2502e-02,\n         -4.2400e-02, -3.3638e-03],\n        [ 5.4206e-02,  1.2509e-01, -4.1808e-03,  1.4891e-01,  1.6948e-01,\n         -1.0605e-02,  1.2200e-02,  3.5777e-02, -4.2937e-02,  1.6594e-01,\n         -1.3204e-01,  1.6430e-01, -9.5835e-02,  1.2986e-01,  4.8992e-02,\n         -1.7327e-01, -5.0447e-02,  1.6850e-02,  1.4737e-01,  1.4842e-01,\n          1.6453e-01, -1.0188e-01, -1.2070e-01, -8.4841e-02,  1.0127e-01,\n         -4.0544e-02,  4.8353e-02, -1.3623e-01,  5.7348e-02,  7.4288e-02,\n          1.4286e-01,  9.8177e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1629, -0.1855, -0.0376,  0.1342, -0.0588,  0.0407,  0.2417,  0.1132],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0237,  0.2335,  0.2360,  0.2297, -0.1333, -0.1538,  0.2048, -0.2100,\n         -0.0966,  0.0296,  0.2300,  0.0554, -0.2470,  0.1694,  0.0766, -0.0727],\n        [-0.2133,  0.2130,  0.2441, -0.0118, -0.1217, -0.0485, -0.1166, -0.0973,\n         -0.2363, -0.0452, -0.2320,  0.0793,  0.1609, -0.0033,  0.1806,  0.0285],\n        [ 0.1522, -0.2267,  0.0830,  0.1942,  0.1730, -0.0062, -0.1168,  0.0835,\n         -0.0336, -0.1550, -0.2152, -0.1598, -0.1029, -0.1293, -0.1018,  0.1415],\n        [ 0.0166, -0.1140,  0.1173,  0.0598, -0.2485,  0.2412, -0.0931,  0.1507,\n         -0.2266,  0.1362, -0.0464,  0.0011,  0.1241,  0.0997, -0.2155, -0.0473],\n        [ 0.2060, -0.2217,  0.1188,  0.2221,  0.0870,  0.0015,  0.1276,  0.2446,\n         -0.1346,  0.0372,  0.1622, -0.0056, -0.0308,  0.2181,  0.1744,  0.0295],\n        [ 0.2332,  0.1112, -0.1505,  0.0511,  0.2084, -0.2468, -0.0117, -0.0586,\n          0.0354, -0.1783, -0.1074,  0.1203, -0.1105,  0.0260, -0.2168, -0.1530],\n        [ 0.0673,  0.1145, -0.0949, -0.1649, -0.0251, -0.1097,  0.2142,  0.2381,\n          0.1730, -0.1867,  0.2278, -0.1350,  0.1319,  0.2407, -0.1944, -0.0198],\n        [ 0.1735,  0.2182,  0.0930, -0.2166,  0.0327,  0.1506,  0.1097, -0.0060,\n         -0.1890, -0.0386, -0.0150,  0.2136,  0.1049,  0.0759, -0.1948,  0.1108]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3247], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0746, -0.2568, -0.0042,  0.3095,  0.2848,  0.0104,  0.0158, -0.1239]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1802, -0.1113,  0.1238,  0.2691, -0.3282,  0.1005, -0.3449, -0.0295],\n        [ 0.0342,  0.3005,  0.1950, -0.1702, -0.1580, -0.2826,  0.2594,  0.2923],\n        [-0.2911, -0.0313,  0.2922, -0.1580,  0.1147,  0.2260,  0.0740,  0.2297],\n        [ 0.0647, -0.1308, -0.1126, -0.1351, -0.0237, -0.2379,  0.2734,  0.2457],\n        [ 0.1318,  0.0728, -0.2599, -0.0349, -0.0284, -0.0300,  0.0156,  0.2747],\n        [-0.3082,  0.0741, -0.3093,  0.2422, -0.1046, -0.2619, -0.1466,  0.3114],\n        [-0.2845, -0.0937, -0.0700,  0.1210,  0.0161,  0.2075, -0.0339,  0.0535],\n        [ 0.3419,  0.1405, -0.1789, -0.0313, -0.2811, -0.2085,  0.0961, -0.2112],\n        [-0.1225, -0.1405, -0.3321, -0.1102, -0.2882,  0.1835,  0.0530,  0.2966],\n        [-0.1242,  0.0135,  0.2834,  0.0955, -0.0232,  0.3462,  0.0578, -0.0073],\n        [ 0.2366,  0.1055,  0.0140, -0.0251,  0.0404, -0.0759,  0.0645, -0.2314],\n        [ 0.0319, -0.0376, -0.3029,  0.2588,  0.2158,  0.1205,  0.3139,  0.1909],\n        [-0.0096, -0.1045, -0.1001,  0.0898,  0.1607, -0.0908,  0.3076, -0.3400],\n        [ 0.0567, -0.2994, -0.2788,  0.0339, -0.2687,  0.1265, -0.1683,  0.1618],\n        [ 0.1450,  0.2757,  0.2706, -0.3493,  0.2535, -0.0147,  0.3227,  0.2678],\n        [-0.1865, -0.0432,  0.0295,  0.0124,  0.2695, -0.1426, -0.1348, -0.1353],\n        [ 0.2616, -0.0695,  0.2901, -0.2469,  0.3415,  0.1977,  0.1884,  0.0186],\n        [-0.0927,  0.2680,  0.1567, -0.2193,  0.0171, -0.3224, -0.2679, -0.0534],\n        [ 0.2702,  0.1990,  0.2496,  0.1659,  0.0674,  0.0172, -0.0487,  0.1010],\n        [ 0.0980,  0.2066, -0.3062,  0.0631,  0.3331, -0.0506, -0.0261, -0.2045],\n        [ 0.0101,  0.1084,  0.1679,  0.2734,  0.0008, -0.2586,  0.1478, -0.0755],\n        [-0.3409,  0.1623, -0.2790, -0.2270,  0.1403,  0.1841,  0.3502,  0.3344],\n        [-0.1591, -0.0881,  0.0702,  0.0585,  0.2737,  0.1340,  0.0070,  0.1404],\n        [-0.0111,  0.0170,  0.2765, -0.2672, -0.2874, -0.1827, -0.1992,  0.0721],\n        [-0.2764, -0.0482, -0.2582,  0.3309, -0.1104, -0.1133,  0.3082,  0.1293],\n        [ 0.2912, -0.2396, -0.2634,  0.2282,  0.1162,  0.3210,  0.2519, -0.0595],\n        [ 0.1195,  0.3419, -0.0423,  0.0527,  0.1468,  0.0117, -0.1938,  0.1559],\n        [ 0.3120,  0.1369,  0.1963,  0.3514, -0.0625, -0.3463, -0.2198, -0.0794],\n        [ 0.0776,  0.0205,  0.2663, -0.3090, -0.2652, -0.0365,  0.1263, -0.0220],\n        [-0.2054, -0.3140,  0.2128,  0.0853, -0.2290,  0.2909, -0.0748, -0.1046],\n        [ 0.0231, -0.2482,  0.3239,  0.1039,  0.0421, -0.1048,  0.0693,  0.3332],\n        [ 0.1601, -0.0968,  0.1195, -0.1774, -0.0854, -0.1755,  0.1305,  0.1982]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2771,  0.0880, -0.1325, -0.3114,  0.0698, -0.2492, -0.1014, -0.2726,\n        -0.0715,  0.0333, -0.1625, -0.2666, -0.1575, -0.2703,  0.3418, -0.0624,\n         0.0387,  0.3291, -0.0494, -0.1924, -0.1030,  0.1394, -0.1880,  0.2368,\n         0.2772, -0.1291,  0.0904, -0.1163, -0.2528,  0.3344,  0.2138, -0.2559],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 8.5205e-02,  1.5719e-01, -6.7914e-02, -1.1285e-01, -7.3901e-02,\n         -1.4491e-01,  1.2703e-01, -1.4213e-01,  1.1365e-01,  2.9038e-02,\n          1.7275e-01,  1.5397e-01, -3.0099e-02, -1.5173e-01, -1.3849e-01,\n         -1.6344e-01,  1.6575e-01, -3.3060e-03, -2.6226e-02, -2.3514e-02,\n          1.3476e-01,  2.3602e-06, -1.2182e-01, -1.1511e-01,  1.0192e-01,\n         -2.4540e-02,  6.1958e-02, -6.4238e-02,  1.0129e-02, -2.8638e-02,\n          3.7552e-02, -1.2556e-01],\n        [ 1.4060e-01, -2.2915e-02, -1.0832e-01,  6.2226e-02, -3.5346e-02,\n         -6.8157e-02, -3.3594e-02, -2.5162e-02, -1.7146e-01,  1.4665e-01,\n         -7.2427e-03, -8.2097e-02,  6.2431e-02,  1.1082e-01, -1.6248e-01,\n         -1.3474e-01,  1.6485e-01,  3.5678e-02, -1.6261e-01,  1.3600e-01,\n         -5.2438e-03, -5.0996e-02,  1.2406e-02,  1.7314e-02, -8.4128e-03,\n         -1.1819e-01, -6.9106e-02,  1.1611e-01, -3.7516e-02, -1.4606e-01,\n          3.9709e-02, -3.9968e-02],\n        [-1.2848e-01, -1.1440e-02, -1.0154e-01, -1.6688e-01,  1.4097e-02,\n          7.8535e-02, -6.8861e-02,  1.3347e-01, -4.0730e-02,  6.5531e-02,\n         -1.1532e-01, -6.8652e-03, -1.5458e-01, -2.5864e-02,  1.1537e-01,\n         -1.5983e-01,  1.6742e-01,  2.5462e-02, -6.4114e-02, -2.3819e-02,\n          1.6571e-01,  1.3078e-01,  6.3214e-02, -2.3965e-02,  9.1589e-02,\n          5.8228e-02,  1.6640e-01,  6.3962e-02, -2.2383e-02,  1.0643e-01,\n          1.6984e-01, -1.4982e-01],\n        [ 1.1243e-02, -7.9656e-02, -1.2851e-01,  6.6187e-02, -1.4027e-01,\n          1.2944e-02,  8.3688e-03, -6.4655e-02,  1.2379e-01, -2.3059e-02,\n          3.6429e-02,  5.9819e-02, -1.3500e-01, -1.7219e-01, -1.2314e-01,\n         -7.6567e-02, -9.5353e-02,  6.7398e-02, -2.3108e-02,  3.7597e-02,\n          1.0429e-01, -1.2200e-01, -7.9710e-02, -9.8401e-02, -9.8064e-02,\n         -1.4119e-01,  1.0272e-01, -1.0140e-01, -8.7203e-02, -4.1549e-02,\n          2.6912e-02, -1.6110e-01],\n        [ 1.2320e-01, -7.6757e-02,  1.4162e-01, -1.6940e-01, -1.2437e-01,\n         -8.2113e-02,  2.6526e-02,  1.1132e-01, -1.4931e-01, -1.5722e-01,\n          7.2901e-02, -1.1688e-01,  1.0295e-01, -1.5700e-01,  6.2570e-02,\n         -1.5331e-01, -8.0669e-02,  1.4914e-01, -6.4738e-02,  9.1563e-02,\n          1.2421e-01, -5.9752e-03,  1.1527e-01,  5.4182e-02, -4.5368e-02,\n         -1.0329e-02,  8.7048e-02,  8.3175e-02, -1.2167e-01, -1.1675e-01,\n          1.1402e-01,  7.3418e-02],\n        [ 2.8827e-02,  1.5664e-01,  1.4034e-01, -1.7277e-01, -4.6527e-02,\n         -1.6883e-01,  1.7148e-01,  1.3905e-01,  6.6038e-02, -1.1283e-01,\n          1.3475e-01,  1.2383e-01,  1.1327e-01,  4.0092e-02,  1.6539e-01,\n          1.2277e-01, -1.3933e-01,  6.6036e-02, -1.2801e-01, -1.3950e-02,\n         -8.8511e-02, -1.3980e-01, -3.0170e-02, -1.1572e-01,  1.5318e-01,\n         -1.7985e-02,  5.3550e-02, -1.1513e-01, -1.4505e-02, -1.5486e-01,\n          9.9488e-02, -8.2678e-02],\n        [-9.1137e-02, -8.4580e-02,  8.7231e-02,  8.3185e-02,  8.6633e-02,\n         -1.4035e-01, -1.3876e-01,  2.3046e-02, -1.1804e-01, -1.6804e-01,\n          6.7315e-02, -1.4416e-01,  3.9125e-02, -7.5381e-02,  6.6776e-02,\n          1.2741e-01, -5.3609e-02,  4.7504e-02,  9.6045e-02, -3.3260e-02,\n          1.6216e-01,  1.2686e-01,  1.0955e-01, -1.4341e-01,  9.0377e-02,\n          9.6863e-02,  4.0194e-02, -1.0483e-01, -1.7014e-01, -5.8607e-02,\n         -6.8451e-02, -7.9039e-02],\n        [-3.3821e-02, -1.3274e-01, -1.4500e-01,  9.0740e-02,  4.3147e-02,\n          1.0539e-01, -1.3844e-01,  9.3664e-02,  1.6133e-01,  1.4501e-02,\n          2.8903e-02, -1.2378e-01, -1.1589e-01,  5.6528e-02, -1.6850e-01,\n          1.4271e-01, -6.9759e-02,  1.7361e-01,  8.2183e-02,  7.6121e-02,\n         -1.1890e-01,  1.1645e-01, -1.1742e-01,  5.7558e-02, -5.1882e-02,\n          4.1230e-02, -9.8096e-02,  9.8665e-02,  1.3153e-01,  1.1678e-01,\n         -4.9553e-02,  1.7386e-01],\n        [ 3.3525e-02, -1.3943e-01,  1.3898e-02, -1.6846e-01, -1.4648e-02,\n          6.8188e-02,  1.2240e-01,  1.2797e-01, -2.8527e-02, -9.1978e-02,\n          2.7528e-02, -1.7594e-01, -1.1864e-01, -1.1326e-01,  1.1452e-01,\n         -3.5619e-03, -1.0247e-01,  1.1516e-01, -5.1206e-02, -8.9652e-02,\n          2.9385e-02, -2.7630e-02, -8.3697e-02, -4.9394e-03, -8.6167e-02,\n         -1.6765e-01,  1.6450e-01, -9.2731e-02, -1.3916e-01, -1.4938e-01,\n         -9.1164e-02,  3.7514e-02],\n        [-8.6458e-02,  9.8701e-02, -6.6356e-02, -1.4719e-01, -5.0487e-02,\n          1.1908e-01, -9.5756e-02, -1.6809e-01,  1.1376e-01,  7.5249e-02,\n          1.6028e-01,  1.6229e-01,  3.1860e-02,  5.6963e-02, -6.2135e-02,\n         -1.4190e-01, -4.9419e-02, -1.3343e-01, -1.3325e-01, -7.0284e-02,\n          1.1091e-01,  2.0979e-02, -8.8293e-02,  9.5180e-02,  1.7388e-01,\n          1.6797e-01,  3.0077e-03, -9.5252e-02, -5.4426e-02, -9.9974e-02,\n          1.5740e-01, -5.9788e-02],\n        [-1.0669e-01, -6.4648e-02, -1.4140e-01,  9.4440e-02,  1.3178e-01,\n          8.7014e-03,  3.0476e-02,  1.6491e-01,  1.5964e-01,  3.6038e-02,\n         -3.1715e-03,  8.4956e-02, -4.9865e-02, -1.8759e-02,  7.9149e-02,\n         -1.5276e-03, -1.9295e-02,  3.4689e-02,  1.6031e-01,  1.3671e-01,\n          5.1951e-02, -1.0060e-01,  5.7674e-02, -3.3547e-02, -9.7089e-02,\n          1.3332e-01,  1.5070e-01, -3.5388e-02, -1.2999e-01,  5.6293e-02,\n         -1.4340e-01,  8.3733e-02],\n        [-1.3696e-01, -1.1218e-01,  7.4429e-02, -1.5751e-01, -1.4928e-01,\n         -6.6266e-02, -1.0924e-01, -6.5176e-02,  1.3125e-01, -3.7260e-03,\n          7.3882e-02, -2.9090e-02,  1.6902e-01,  1.1244e-01, -2.8947e-02,\n          4.8890e-02, -6.4900e-03, -1.5438e-01, -1.2713e-01,  1.4121e-01,\n         -7.5752e-02,  9.6753e-02,  7.2419e-02, -9.3635e-02,  1.0083e-01,\n          1.4174e-01,  1.2979e-01, -3.9517e-02, -1.5141e-01,  8.0148e-02,\n         -1.2970e-01,  5.4138e-02],\n        [-6.7001e-02, -1.3458e-02,  8.1527e-02,  8.2955e-02, -3.7803e-03,\n         -6.6458e-02,  3.0150e-02, -1.5355e-01,  1.3583e-01,  3.1003e-02,\n          9.0074e-02,  6.0844e-02, -1.6660e-01, -8.7545e-02,  1.6152e-01,\n         -1.6577e-01, -8.4566e-02,  1.5410e-01,  1.1197e-01,  1.5067e-01,\n          7.8690e-02,  9.3962e-02,  1.2920e-01,  7.2200e-02,  1.3280e-02,\n          3.9522e-03,  9.8518e-02, -8.8043e-02, -8.2665e-02, -5.2062e-02,\n          1.4769e-01,  9.8890e-02],\n        [-6.4417e-03, -2.3815e-02, -1.2142e-01,  1.5127e-01, -1.6475e-01,\n         -7.4019e-02,  1.1440e-01,  9.2456e-02, -8.7572e-02,  4.4415e-02,\n         -1.0102e-01,  2.6582e-02, -2.4545e-02, -1.3616e-01, -7.7921e-03,\n          3.3861e-02,  9.2600e-02, -1.1677e-01,  1.1920e-01,  1.1004e-01,\n          4.9031e-03, -2.7951e-02,  1.2065e-01, -1.5033e-01,  1.5429e-01,\n         -1.4655e-01,  1.7613e-01,  5.0412e-02,  2.7503e-02,  1.0266e-01,\n         -1.3065e-01, -1.2681e-01],\n        [ 1.6786e-01,  1.0587e-01, -7.4936e-02, -7.3036e-02, -6.2757e-02,\n          8.3878e-02, -2.9067e-02,  8.1062e-02, -9.5388e-02,  1.9369e-02,\n          6.9231e-02,  4.8228e-03,  1.6178e-01, -4.6172e-02, -6.5280e-02,\n          1.1511e-01, -4.8202e-02, -8.0951e-02, -1.3294e-01, -2.8559e-02,\n          4.0604e-02,  1.4442e-01, -1.0904e-01,  4.5886e-02,  1.0664e-01,\n         -2.6262e-02, -7.5769e-02, -3.9367e-02, -1.3231e-01,  6.2502e-02,\n         -4.2400e-02, -3.3638e-03],\n        [ 5.4206e-02,  1.2509e-01, -4.1808e-03,  1.4891e-01,  1.6948e-01,\n         -1.0605e-02,  1.2200e-02,  3.5777e-02, -4.2937e-02,  1.6594e-01,\n         -1.3204e-01,  1.6430e-01, -9.5835e-02,  1.2986e-01,  4.8992e-02,\n         -1.7327e-01, -5.0447e-02,  1.6850e-02,  1.4737e-01,  1.4842e-01,\n          1.6453e-01, -1.0188e-01, -1.2070e-01, -8.4841e-02,  1.0127e-01,\n         -4.0544e-02,  4.8353e-02, -1.3623e-01,  5.7348e-02,  7.4288e-02,\n          1.4286e-01,  9.8177e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1450,  0.1192, -0.0878,  0.0579, -0.1028,  0.0409,  0.1582, -0.0843,\n         0.0735, -0.0892,  0.0944,  0.1719, -0.1588,  0.0652, -0.0595,  0.1170],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0237,  0.2335,  0.2360,  0.2297, -0.1333, -0.1538,  0.2048, -0.2100,\n         -0.0966,  0.0296,  0.2300,  0.0554, -0.2470,  0.1694,  0.0766, -0.0727],\n        [-0.2133,  0.2130,  0.2441, -0.0118, -0.1217, -0.0485, -0.1166, -0.0973,\n         -0.2363, -0.0452, -0.2320,  0.0793,  0.1609, -0.0033,  0.1806,  0.0285],\n        [ 0.1522, -0.2267,  0.0830,  0.1942,  0.1730, -0.0062, -0.1168,  0.0835,\n         -0.0336, -0.1550, -0.2152, -0.1598, -0.1029, -0.1293, -0.1018,  0.1415],\n        [ 0.0166, -0.1140,  0.1173,  0.0598, -0.2485,  0.2412, -0.0931,  0.1507,\n         -0.2266,  0.1362, -0.0464,  0.0011,  0.1241,  0.0997, -0.2155, -0.0473],\n        [ 0.2060, -0.2217,  0.1188,  0.2221,  0.0870,  0.0015,  0.1276,  0.2446,\n         -0.1346,  0.0372,  0.1622, -0.0056, -0.0308,  0.2181,  0.1744,  0.0295],\n        [ 0.2332,  0.1112, -0.1505,  0.0511,  0.2084, -0.2468, -0.0117, -0.0586,\n          0.0354, -0.1783, -0.1074,  0.1203, -0.1105,  0.0260, -0.2168, -0.1530],\n        [ 0.0673,  0.1145, -0.0949, -0.1649, -0.0251, -0.1097,  0.2142,  0.2381,\n          0.1730, -0.1867,  0.2278, -0.1350,  0.1319,  0.2407, -0.1944, -0.0198],\n        [ 0.1735,  0.2182,  0.0930, -0.2166,  0.0327,  0.1506,  0.1097, -0.0060,\n         -0.1890, -0.0386, -0.0150,  0.2136,  0.1049,  0.0759, -0.1948,  0.1108]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1629, -0.1855, -0.0376,  0.1342, -0.0588,  0.0407,  0.2417,  0.1132],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0746, -0.2568, -0.0042,  0.3095,  0.2848,  0.0104,  0.0158, -0.1239]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3247], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x1011ffe80>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x171cd6590>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s185460000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s185460000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}