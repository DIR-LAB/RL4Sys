{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s186290000"
    },
    "q_lr":	0.0005,
    "seed":	186290000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x782311decad0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=32, out_features=16, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=16, out_features=8, bias=True)\n    (9): ReLU()\n    (10): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=32, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=32, out_features=16, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=16, out_features=8, bias=True)\n  (9): ReLU()\n  (10): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-1.4339e-01, -3.7021e-02,  1.2065e-01,  2.7791e-02,  3.4681e-01,\n         3.0483e-01,  2.2117e-01,  1.9948e-01, -1.1285e-02, -1.5281e-01,\n        -1.1816e-01, -2.1424e-01,  1.3729e-01, -1.0732e-01, -7.7847e-02,\n        -1.1619e-01,  6.2537e-02, -3.0863e-01,  1.1247e-02, -2.2469e-01,\n         2.0183e-01,  1.2618e-01,  7.9579e-03, -1.0194e-01, -1.7843e-01,\n        -1.3776e-01,  2.9970e-01, -2.0242e-01, -2.9920e-01,  1.5751e-01,\n         3.3893e-01,  3.4985e-01, -2.4213e-01, -3.0575e-01, -1.0422e-01,\n        -1.4436e-02,  4.0047e-02,  6.6215e-02,  5.4092e-02, -2.4294e-01,\n         3.1987e-01,  7.1366e-02, -1.5235e-01, -4.2600e-03,  1.4368e-02,\n         1.9752e-01, -2.0141e-01, -3.4178e-01, -3.1458e-01,  2.2404e-01,\n         1.6760e-01,  1.7383e-01, -9.1120e-02,  2.3682e-01, -1.9506e-04,\n        -1.1564e-01,  1.0740e-02, -1.5307e-01,  1.5570e-01,  3.3752e-01,\n        -3.0249e-01, -5.6245e-03,  2.8905e-01, -1.7550e-02],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3222,  0.0782,  0.1832, -0.0478, -0.2616,  0.0985, -0.1860, -0.2497],\n        [ 0.2669, -0.0612, -0.2299,  0.1491, -0.1705,  0.3508,  0.2983, -0.3400],\n        [-0.1926, -0.0727, -0.2715, -0.0150,  0.0925, -0.3015, -0.2240, -0.2098],\n        [-0.2531, -0.0353, -0.2738,  0.2113, -0.0920, -0.3259,  0.1103, -0.0093],\n        [-0.2115,  0.2895, -0.0115, -0.0177,  0.1493,  0.0004,  0.0232, -0.1094],\n        [ 0.0893, -0.0369, -0.1735, -0.3284, -0.1300,  0.0290,  0.2377,  0.1130],\n        [-0.2991,  0.1257, -0.0039, -0.1759, -0.1841, -0.1652,  0.3509,  0.2518],\n        [-0.2918, -0.2537,  0.0398, -0.0894,  0.0606, -0.3504, -0.0051,  0.2509],\n        [-0.3109, -0.1714,  0.0867,  0.3121,  0.3181,  0.0314,  0.1468,  0.0258],\n        [ 0.1771,  0.2740,  0.1439,  0.2215, -0.1236, -0.2379, -0.1041, -0.2383],\n        [ 0.1077,  0.0269,  0.1488, -0.3423,  0.1680, -0.3309, -0.1764,  0.0876],\n        [-0.2669,  0.0289, -0.2127, -0.0026,  0.0207,  0.0534,  0.1892, -0.2060],\n        [-0.0324, -0.1377, -0.3303, -0.2672,  0.2489, -0.3352,  0.1820, -0.3103],\n        [-0.0853,  0.0470,  0.1782, -0.3413,  0.2016, -0.2104,  0.2624,  0.2033],\n        [ 0.3249,  0.0979, -0.3023,  0.0146, -0.1187, -0.0361, -0.1368, -0.0181],\n        [-0.0017, -0.1355,  0.0918,  0.1822,  0.2599, -0.2821, -0.2262,  0.0962],\n        [ 0.2791, -0.3529, -0.0661,  0.2958, -0.1061,  0.0789,  0.2259, -0.0135],\n        [ 0.0226, -0.0158, -0.0967,  0.0239, -0.1815,  0.1801, -0.1331,  0.0653],\n        [ 0.1540,  0.2638,  0.2141,  0.3350,  0.1654,  0.2911, -0.0075, -0.0840],\n        [ 0.0325,  0.0727,  0.0876,  0.2989, -0.1444,  0.0330,  0.2817, -0.1415],\n        [-0.0664, -0.1030, -0.1061, -0.2879, -0.2330, -0.2770,  0.2503, -0.1711],\n        [ 0.1942, -0.2111, -0.2986, -0.3356,  0.2809, -0.0679,  0.1669, -0.0534],\n        [ 0.1641,  0.2134, -0.3402, -0.1510, -0.2328,  0.0609, -0.3362, -0.2255],\n        [-0.0348, -0.0545, -0.3475,  0.0455,  0.1533, -0.1466,  0.1486,  0.3463],\n        [ 0.1364, -0.0537, -0.2282,  0.1198, -0.0091,  0.0752,  0.0888, -0.3385],\n        [-0.1936,  0.1503,  0.0603, -0.1115,  0.0995, -0.0714, -0.0827,  0.1718],\n        [-0.1832,  0.0005, -0.1555, -0.3386,  0.3317, -0.2280, -0.1683,  0.0033],\n        [-0.0110,  0.2617,  0.3258, -0.2341,  0.3363, -0.1723, -0.0486, -0.0107],\n        [-0.0055, -0.1350, -0.0523,  0.1809,  0.0467, -0.1835,  0.3197, -0.2739],\n        [ 0.1782, -0.0481,  0.1926, -0.2439,  0.1467, -0.0795,  0.3266,  0.1289],\n        [-0.1690, -0.2000, -0.2411,  0.1225,  0.2025, -0.1255,  0.1086,  0.3272],\n        [ 0.3331, -0.2278, -0.3305, -0.1744,  0.0364,  0.0328, -0.1298,  0.2546],\n        [ 0.3452,  0.1409, -0.1481,  0.1419, -0.0301, -0.0695,  0.2558,  0.3384],\n        [ 0.2210, -0.1118, -0.1612,  0.0471, -0.1228,  0.2442, -0.1027,  0.2752],\n        [-0.3059, -0.1673, -0.3391, -0.2579,  0.3518,  0.0989,  0.1841, -0.1116],\n        [ 0.0552,  0.0780, -0.2341,  0.2720,  0.2254,  0.1841,  0.0057,  0.1286],\n        [-0.3418, -0.2977, -0.0900, -0.0938, -0.3400, -0.3457,  0.2988,  0.2291],\n        [-0.1683, -0.0069,  0.1275,  0.1322,  0.1174, -0.0370, -0.3019,  0.3153],\n        [-0.1483, -0.0729,  0.2627, -0.0237,  0.2990,  0.1075,  0.0701,  0.1658],\n        [-0.0160, -0.2181, -0.0178, -0.2140,  0.1760, -0.1543,  0.0952,  0.1551],\n        [ 0.3527, -0.2657, -0.1762, -0.2094,  0.3070, -0.2355, -0.1836,  0.2834],\n        [-0.2705,  0.0539, -0.0738, -0.0794, -0.2055,  0.3501,  0.1539,  0.1715],\n        [ 0.1889,  0.0088,  0.0027,  0.2653,  0.2915,  0.2892,  0.0620,  0.3330],\n        [ 0.2380,  0.2622, -0.0339, -0.1933,  0.1005,  0.0043,  0.0983,  0.3236],\n        [ 0.1365, -0.3176,  0.3192, -0.2923,  0.2048,  0.0770, -0.3214,  0.0882],\n        [ 0.1207,  0.0604,  0.1315,  0.2376, -0.0869, -0.3388, -0.2451, -0.0784],\n        [ 0.2496,  0.0728,  0.3204,  0.0528,  0.2121,  0.0478, -0.0427,  0.2758],\n        [ 0.1418,  0.0893, -0.0750,  0.0570, -0.1542,  0.2918, -0.1894, -0.2883],\n        [-0.0955,  0.0051, -0.2236,  0.3067, -0.2963, -0.2304, -0.1213,  0.2108],\n        [-0.3165,  0.3216, -0.2466,  0.0670,  0.2172, -0.0040, -0.0553,  0.0066],\n        [ 0.3099, -0.1613, -0.1474,  0.0914, -0.1811,  0.0235,  0.3086,  0.0552],\n        [-0.0358,  0.0838,  0.1833,  0.1218, -0.2006, -0.3247,  0.2535,  0.0800],\n        [-0.0832,  0.1028, -0.1746,  0.0841,  0.2328, -0.3070,  0.1946, -0.0792],\n        [ 0.2809, -0.1020,  0.0905,  0.1785, -0.0608, -0.2080, -0.2702,  0.3220],\n        [-0.2799, -0.1140,  0.1371, -0.1879, -0.2181,  0.1222,  0.3427, -0.1241],\n        [-0.2477,  0.3423, -0.1776,  0.3513, -0.1635,  0.2475, -0.3076, -0.0336],\n        [-0.0101, -0.1063, -0.0271,  0.2503,  0.1675, -0.0420, -0.1924,  0.0014],\n        [ 0.2953, -0.0574,  0.0680, -0.1177, -0.1971,  0.0889, -0.0715,  0.0352],\n        [-0.0240,  0.0123, -0.0310, -0.2284, -0.1829, -0.3140, -0.3329,  0.1382],\n        [ 0.1109, -0.0090, -0.3112, -0.0010,  0.1063,  0.2633,  0.2074,  0.2272],\n        [-0.3223, -0.1282, -0.1286, -0.0988,  0.0746, -0.1491, -0.0775, -0.0120],\n        [-0.3410,  0.1125,  0.3482, -0.0582, -0.2475, -0.0618,  0.0915,  0.2110],\n        [ 0.0792, -0.1699, -0.1344,  0.0711, -0.2120,  0.0723, -0.1956,  0.0770],\n        [-0.2844, -0.0764, -0.3479,  0.2233,  0.2927, -0.2444, -0.0218,  0.1269]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "10":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0855], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0643, -0.2573, -0.0329,  0.1877,  0.3439,  0.1961,  0.0711,  0.1330]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=64, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0324,  0.0255,  0.0348, -0.0449,  0.1036, -0.0976, -0.0516,  0.0023,\n        -0.0803, -0.0962, -0.0750,  0.0220, -0.0793, -0.1239, -0.0198,  0.0261,\n         0.0750,  0.0811,  0.0827, -0.0496, -0.0058,  0.0918,  0.0542,  0.0090,\n        -0.0107,  0.0789,  0.0581, -0.0982, -0.0165,  0.0641, -0.1028, -0.0766,\n         0.0698,  0.0423, -0.0187, -0.1220, -0.0011, -0.0787, -0.0659,  0.1032,\n         0.1081, -0.1167, -0.1176,  0.0359,  0.0207,  0.0428,  0.0130,  0.0923,\n        -0.1121, -0.0940, -0.1184, -0.0814,  0.0210,  0.0727,  0.1222,  0.0788,\n        -0.0731,  0.0776, -0.1209,  0.0398, -0.0919,  0.0898, -0.1075,  0.0613],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0403,  0.0506, -0.1097,  ...,  0.0314, -0.0943,  0.0964],\n        [ 0.0784, -0.0666, -0.0557,  ..., -0.0803,  0.0236,  0.0013],\n        [ 0.0238,  0.1199,  0.0737,  ..., -0.0777,  0.0596, -0.0641],\n        ...,\n        [ 0.0897,  0.0852,  0.0856,  ...,  0.0356,  0.0847,  0.0148],\n        [ 0.0919, -0.0274, -0.0903,  ..., -0.1020, -0.0135, -0.0107],\n        [ 0.1083,  0.0472, -0.1112,  ..., -0.0538,  0.0051, -0.1116]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=64, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0054,  0.0436, -0.0392, -0.0840,  0.0954,  0.0704,  0.0699, -0.0203,\n         0.0266, -0.0904, -0.0869,  0.0297,  0.0763, -0.1236,  0.0309, -0.0167,\n         0.0591, -0.0288,  0.0107,  0.1067,  0.0491, -0.0594,  0.0181,  0.0297,\n         0.1181,  0.1119, -0.0447,  0.0467, -0.0049, -0.0621, -0.1101, -0.0372],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1049, -0.0493,  0.1185,  ..., -0.0970,  0.1143,  0.0116],\n        [-0.0984,  0.0775,  0.0728,  ..., -0.0395,  0.0336,  0.0330],\n        [-0.0811,  0.1067,  0.0133,  ..., -0.0268, -0.0486, -0.0705],\n        ...,\n        [ 0.0292, -0.0946,  0.1175,  ..., -0.0040,  0.0931,  0.0514],\n        [-0.0425, -0.1141,  0.0988,  ..., -0.0700, -0.0385, -0.0458],\n        [ 0.1098, -0.0628,  0.0614,  ...,  0.0978,  0.0407,  0.0747]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0399, -0.1207,  0.1556, -0.0774,  0.0218,  0.0730,  0.1258,  0.0439,\n         0.1631, -0.1101, -0.0695, -0.1371,  0.0155, -0.1027, -0.0980,  0.0135],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.9445e-02,  7.6534e-02,  1.7368e-01, -9.6190e-02,  1.2038e-01,\n          1.5088e-01,  1.4512e-01,  1.4868e-01,  1.3194e-01, -6.6219e-03,\n          4.3360e-03, -1.0627e-01,  6.6367e-02,  1.6610e-01,  8.2316e-02,\n          2.3696e-03,  6.8050e-02,  8.9576e-02,  1.3043e-01, -9.8121e-02,\n         -7.5331e-02,  5.7656e-02, -2.7116e-02,  9.8734e-02, -5.4858e-02,\n         -1.6787e-01, -1.3650e-01,  9.2165e-02,  9.5400e-02, -2.8616e-03,\n         -1.6288e-01,  1.5005e-01],\n        [-1.0246e-01,  1.3202e-01,  2.7038e-02,  4.7329e-02, -2.2399e-02,\n         -1.7224e-01, -1.0535e-01, -1.1594e-01,  8.2038e-02,  2.4546e-02,\n         -1.4121e-01,  9.1370e-02,  1.6128e-01, -1.1279e-01, -7.9751e-02,\n          1.6549e-01, -9.8206e-02,  7.5304e-02, -1.5573e-01, -1.4266e-01,\n          1.4957e-02, -3.2674e-02, -4.3726e-02,  9.3941e-02, -9.0936e-02,\n          1.5239e-01,  5.7080e-02, -9.5301e-02, -1.1914e-01, -1.4535e-01,\n         -1.2032e-01,  2.9037e-02],\n        [-1.4755e-01, -7.9258e-02,  1.7305e-01,  3.0004e-02, -1.4191e-01,\n         -1.0274e-01, -1.1061e-01,  4.2077e-02, -1.2844e-01,  1.6303e-02,\n         -4.0450e-02, -4.3575e-02, -9.1070e-02, -3.7002e-02, -1.2601e-01,\n          5.0070e-05, -6.5802e-02,  1.2187e-01, -9.0381e-02, -9.8786e-02,\n         -5.6271e-02, -7.7091e-02,  9.8481e-02, -1.3354e-01, -1.4108e-01,\n          1.3943e-01, -4.9635e-03,  1.6874e-01,  1.6301e-01, -1.1167e-01,\n         -1.0575e-01, -6.1569e-02],\n        [-8.4227e-02,  2.9393e-02,  3.3435e-02,  3.0454e-02,  4.9279e-02,\n          1.9502e-02,  7.8499e-02,  1.4669e-01,  7.7352e-02, -1.0820e-01,\n         -1.0887e-01, -1.4088e-01, -1.1342e-01,  7.1937e-02,  9.2946e-02,\n         -1.3389e-01,  4.7260e-02,  3.8296e-02, -7.4920e-02,  1.6966e-01,\n          1.3442e-01,  1.4985e-01, -1.5627e-01, -3.1574e-02,  5.0037e-02,\n          8.1567e-02, -1.0825e-01, -7.3178e-02,  1.0773e-02,  9.5188e-02,\n          1.3370e-01, -1.0286e-01],\n        [-1.7110e-01, -6.8475e-02,  6.4956e-02,  5.8013e-02, -6.2961e-02,\n         -1.8428e-02, -2.2274e-02,  5.1129e-02, -1.4739e-01, -6.6959e-02,\n         -6.1762e-02, -1.2884e-01,  7.4788e-02,  1.2323e-01, -1.4292e-01,\n          9.3096e-02,  2.5397e-02,  1.3243e-01, -8.0715e-02,  3.0584e-02,\n          6.4528e-02, -2.2715e-02,  1.4789e-01,  5.4988e-02,  8.3215e-02,\n          2.8164e-02, -1.5814e-01, -8.3147e-02,  1.0263e-01, -1.5470e-01,\n          5.6707e-03, -1.5428e-01],\n        [-1.1978e-01,  8.9074e-03,  1.5102e-01,  1.6914e-01,  1.2140e-01,\n          1.0799e-01, -1.6009e-01, -8.0812e-02,  1.1784e-01, -4.3801e-02,\n          9.3965e-02,  1.1747e-01, -1.7612e-01, -1.1128e-02,  7.9710e-02,\n         -1.5719e-01,  1.4053e-01, -1.5823e-01,  1.4280e-01, -6.2351e-03,\n         -1.2887e-01,  1.6587e-01,  1.1618e-01, -1.2039e-02, -3.3036e-02,\n         -8.7416e-02,  7.6946e-02,  1.6793e-01,  7.1897e-02, -2.7491e-02,\n         -1.6589e-01,  2.8002e-02],\n        [-1.1788e-01, -2.0349e-02, -1.6740e-01, -2.4564e-02, -3.5628e-03,\n         -4.5861e-02, -1.4088e-03, -1.5912e-01,  1.6873e-01, -8.5183e-02,\n          3.5056e-02, -4.6254e-03, -1.6018e-01,  1.4092e-01, -1.4163e-01,\n          7.6819e-02,  1.6949e-01,  2.4390e-02,  3.9943e-02,  2.4256e-03,\n          7.7990e-02, -1.2712e-01, -1.4959e-01,  9.0331e-02, -6.5149e-02,\n         -2.3738e-02,  8.3380e-02, -3.5863e-02,  1.0199e-01, -1.7307e-01,\n          8.2083e-02,  1.3735e-01],\n        [ 1.1272e-01, -3.7242e-02,  3.0815e-02,  1.2130e-02, -8.5215e-02,\n          6.0290e-02, -1.3541e-01, -2.2314e-02,  1.6883e-01,  3.8156e-02,\n         -6.2005e-02, -1.1744e-01, -1.5197e-01, -1.9856e-02,  7.0403e-02,\n         -4.4627e-02,  2.6483e-02, -1.6801e-01, -1.3047e-01,  1.4869e-01,\n         -2.1081e-02, -8.9288e-03, -3.7092e-02, -1.4340e-01, -8.7802e-02,\n         -9.2609e-02, -1.0865e-01, -1.5306e-01, -2.2659e-02, -1.1259e-01,\n         -1.4373e-01,  1.7359e-01],\n        [ 4.1392e-02, -1.0389e-01,  1.0650e-01, -4.5945e-02, -8.3478e-02,\n          5.8740e-02,  2.9533e-02,  8.7240e-02,  6.9277e-02, -2.1269e-02,\n          7.9919e-02, -1.6354e-01,  1.0925e-01,  1.6323e-01, -5.4597e-02,\n         -1.2774e-01,  1.0882e-01, -3.0611e-02,  1.4828e-01,  1.0434e-01,\n          1.7519e-02, -1.4786e-01, -1.1479e-01,  6.1782e-02, -1.3292e-01,\n         -7.9955e-02,  1.0366e-01,  1.6798e-01, -1.3158e-01,  1.7121e-01,\n          1.0223e-01,  1.1697e-01],\n        [-2.0362e-02,  9.2530e-02,  1.2947e-01,  1.0513e-02, -1.0751e-02,\n          1.4037e-01,  3.8561e-02,  1.7328e-01, -1.1096e-01,  9.5083e-02,\n         -6.9030e-02,  1.3366e-01, -1.0278e-01, -7.4874e-02, -1.4600e-01,\n         -2.6729e-02,  2.9855e-02, -1.3476e-01,  1.7571e-01,  7.4796e-02,\n         -4.2058e-02,  1.7194e-01,  2.8415e-02,  1.5702e-01, -7.3924e-02,\n         -2.4035e-02,  2.4622e-02,  1.7266e-01,  4.1449e-02,  2.0059e-02,\n         -4.0284e-02,  1.3714e-01],\n        [ 1.2972e-01, -1.0622e-01,  8.2176e-02,  7.9999e-02,  5.6002e-02,\n          1.6449e-01,  8.4721e-02, -1.4821e-01,  1.4255e-01, -2.0688e-02,\n          1.0886e-01,  1.7498e-01, -5.3923e-02,  1.6430e-01, -1.2454e-01,\n         -1.5605e-01, -1.5021e-01, -1.3738e-01,  4.9084e-02,  1.2274e-01,\n          4.0360e-03,  6.8085e-02,  5.3818e-02, -3.0731e-02,  3.9520e-02,\n          1.6084e-01,  1.4870e-01, -8.3504e-02,  1.6368e-01, -6.6401e-02,\n          1.2294e-01, -1.4028e-02],\n        [-1.0416e-01,  7.1548e-02,  8.8310e-02, -6.8599e-02,  1.5411e-01,\n         -1.1352e-01, -1.6787e-01, -1.4425e-02, -1.5097e-01,  9.5129e-02,\n          1.2780e-01, -1.7539e-01,  3.5975e-02,  1.3033e-01, -2.3468e-02,\n         -1.4354e-01, -1.4939e-01,  2.5779e-02, -3.0876e-02, -1.6668e-01,\n         -1.3581e-02, -1.6920e-01,  8.9019e-02,  4.4593e-02,  1.2743e-01,\n         -3.1681e-02, -4.7729e-02, -1.4389e-02,  1.0169e-01,  8.7837e-02,\n         -1.5176e-01,  4.8570e-02],\n        [ 6.5327e-02, -1.1431e-01,  1.2232e-01, -8.8547e-02, -9.4389e-02,\n          9.0432e-03,  1.6426e-01, -5.7434e-02, -1.1729e-01, -1.6214e-01,\n          8.9202e-02, -1.3766e-01,  6.7432e-02, -2.8999e-02,  2.2408e-02,\n         -1.1162e-01, -6.8644e-02,  1.0015e-01,  8.8297e-02,  2.1649e-02,\n         -8.5576e-02,  2.9504e-03, -1.5813e-01,  1.4200e-01,  8.5466e-03,\n         -9.3314e-02,  9.5005e-02,  1.5369e-02,  1.4328e-01, -7.6864e-02,\n          8.4400e-02, -2.0171e-03],\n        [-5.3977e-02, -6.8076e-02, -1.5315e-01, -1.6013e-01,  6.4942e-02,\n         -5.7031e-03,  7.8327e-02, -1.2789e-01, -1.1182e-01,  8.6523e-02,\n          2.9689e-02, -1.3241e-01, -5.8752e-02, -8.7063e-02, -2.1458e-02,\n         -6.2748e-02, -1.4868e-01,  1.6828e-01, -9.8540e-02, -1.2438e-01,\n         -1.5981e-01,  9.1044e-02, -1.2729e-01,  1.4167e-01, -7.8520e-03,\n          1.7234e-01,  1.6899e-01,  5.8094e-02,  1.7486e-01,  1.1737e-02,\n         -3.5130e-02, -5.4917e-02],\n        [-9.9522e-03, -1.3221e-01, -1.2177e-01, -1.6323e-01,  3.9688e-02,\n          1.2778e-01,  9.5892e-02,  1.3534e-01, -1.7230e-01, -4.4463e-02,\n         -4.8944e-02, -4.5641e-02, -1.3843e-01, -1.7139e-01, -1.6527e-01,\n         -2.4623e-02, -1.0672e-01,  1.1750e-01, -1.3375e-01, -4.4235e-02,\n         -8.8921e-02,  1.2404e-01, -5.5464e-02, -1.1656e-01,  3.9384e-03,\n          1.1399e-01,  1.6082e-01, -5.9217e-02,  1.3091e-01,  1.3594e-01,\n          1.0365e-02, -1.3393e-01],\n        [ 4.6650e-03,  6.9835e-02, -1.6872e-01,  1.5321e-01,  3.6525e-02,\n          1.3437e-01, -4.3631e-02,  9.9797e-02,  3.9226e-02,  1.0929e-01,\n         -7.4226e-02, -7.8440e-02, -6.7009e-02,  1.1143e-01, -1.3635e-01,\n         -9.7670e-02,  1.1352e-01, -8.2298e-03, -7.2436e-02, -1.1234e-01,\n          1.3777e-01, -1.5567e-01, -3.1933e-02, -9.0576e-02, -1.0665e-01,\n          2.2708e-02,  4.5469e-02,  2.1575e-02,  1.0163e-01,  1.0326e-01,\n         -1.4905e-01,  6.5297e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "7":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "8":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1657, -0.1794,  0.2149, -0.1100,  0.1786,  0.0081,  0.0219,  0.2272],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1847, -0.0285, -0.1209, -0.1133, -0.0332,  0.2064, -0.1056, -0.0728,\n         -0.2199,  0.0576, -0.0377, -0.1931,  0.1748,  0.0868, -0.0510, -0.0253],\n        [-0.1662,  0.0222, -0.0321,  0.2307,  0.0276, -0.1561,  0.1882, -0.0030,\n         -0.0137,  0.1969, -0.1629,  0.1404,  0.0373,  0.0130, -0.2455, -0.0652],\n        [ 0.0343,  0.2012,  0.1940, -0.1676, -0.0595, -0.2106,  0.2123, -0.2181,\n          0.1833,  0.0822, -0.1977,  0.0586,  0.2380,  0.1256, -0.0639, -0.0469],\n        [-0.1475, -0.1292,  0.2012,  0.0846,  0.0891, -0.0414, -0.1306,  0.1045,\n         -0.2026, -0.1213, -0.2256,  0.1965, -0.0556,  0.0856, -0.2370, -0.1753],\n        [ 0.1272, -0.1414,  0.1756,  0.1028,  0.0230,  0.1259,  0.1061, -0.2164,\n          0.0902,  0.2215, -0.2146, -0.1900,  0.2007,  0.0391, -0.0816,  0.0093],\n        [ 0.1818, -0.1111,  0.2137,  0.1546, -0.0840,  0.0009, -0.1976, -0.0339,\n          0.2025, -0.1565,  0.2203,  0.2385, -0.0216,  0.2010, -0.1920, -0.2345],\n        [-0.0329,  0.2312, -0.0235, -0.1820,  0.1075, -0.1369, -0.0332,  0.0856,\n          0.0838, -0.1855,  0.2104,  0.0400, -0.2400, -0.1430, -0.0440, -0.1409],\n        [ 0.2102, -0.0062, -0.1105, -0.0372, -0.0738, -0.2139,  0.0263,  0.1910,\n         -0.1654,  0.0564, -0.0445, -0.1312,  0.0501,  0.2093,  0.1245, -0.2301]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "9":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.3222,  0.0782,  0.1832, -0.0478, -0.2616,  0.0985, -0.1860, -0.2497],\n        [ 0.2669, -0.0612, -0.2299,  0.1491, -0.1705,  0.3508,  0.2983, -0.3400],\n        [-0.1926, -0.0727, -0.2715, -0.0150,  0.0925, -0.3015, -0.2240, -0.2098],\n        [-0.2531, -0.0353, -0.2738,  0.2113, -0.0920, -0.3259,  0.1103, -0.0093],\n        [-0.2115,  0.2895, -0.0115, -0.0177,  0.1493,  0.0004,  0.0232, -0.1094],\n        [ 0.0893, -0.0369, -0.1735, -0.3284, -0.1300,  0.0290,  0.2377,  0.1130],\n        [-0.2991,  0.1257, -0.0039, -0.1759, -0.1841, -0.1652,  0.3509,  0.2518],\n        [-0.2918, -0.2537,  0.0398, -0.0894,  0.0606, -0.3504, -0.0051,  0.2509],\n        [-0.3109, -0.1714,  0.0867,  0.3121,  0.3181,  0.0314,  0.1468,  0.0258],\n        [ 0.1771,  0.2740,  0.1439,  0.2215, -0.1236, -0.2379, -0.1041, -0.2383],\n        [ 0.1077,  0.0269,  0.1488, -0.3423,  0.1680, -0.3309, -0.1764,  0.0876],\n        [-0.2669,  0.0289, -0.2127, -0.0026,  0.0207,  0.0534,  0.1892, -0.2060],\n        [-0.0324, -0.1377, -0.3303, -0.2672,  0.2489, -0.3352,  0.1820, -0.3103],\n        [-0.0853,  0.0470,  0.1782, -0.3413,  0.2016, -0.2104,  0.2624,  0.2033],\n        [ 0.3249,  0.0979, -0.3023,  0.0146, -0.1187, -0.0361, -0.1368, -0.0181],\n        [-0.0017, -0.1355,  0.0918,  0.1822,  0.2599, -0.2821, -0.2262,  0.0962],\n        [ 0.2791, -0.3529, -0.0661,  0.2958, -0.1061,  0.0789,  0.2259, -0.0135],\n        [ 0.0226, -0.0158, -0.0967,  0.0239, -0.1815,  0.1801, -0.1331,  0.0653],\n        [ 0.1540,  0.2638,  0.2141,  0.3350,  0.1654,  0.2911, -0.0075, -0.0840],\n        [ 0.0325,  0.0727,  0.0876,  0.2989, -0.1444,  0.0330,  0.2817, -0.1415],\n        [-0.0664, -0.1030, -0.1061, -0.2879, -0.2330, -0.2770,  0.2503, -0.1711],\n        [ 0.1942, -0.2111, -0.2986, -0.3356,  0.2809, -0.0679,  0.1669, -0.0534],\n        [ 0.1641,  0.2134, -0.3402, -0.1510, -0.2328,  0.0609, -0.3362, -0.2255],\n        [-0.0348, -0.0545, -0.3475,  0.0455,  0.1533, -0.1466,  0.1486,  0.3463],\n        [ 0.1364, -0.0537, -0.2282,  0.1198, -0.0091,  0.0752,  0.0888, -0.3385],\n        [-0.1936,  0.1503,  0.0603, -0.1115,  0.0995, -0.0714, -0.0827,  0.1718],\n        [-0.1832,  0.0005, -0.1555, -0.3386,  0.3317, -0.2280, -0.1683,  0.0033],\n        [-0.0110,  0.2617,  0.3258, -0.2341,  0.3363, -0.1723, -0.0486, -0.0107],\n        [-0.0055, -0.1350, -0.0523,  0.1809,  0.0467, -0.1835,  0.3197, -0.2739],\n        [ 0.1782, -0.0481,  0.1926, -0.2439,  0.1467, -0.0795,  0.3266,  0.1289],\n        [-0.1690, -0.2000, -0.2411,  0.1225,  0.2025, -0.1255,  0.1086,  0.3272],\n        [ 0.3331, -0.2278, -0.3305, -0.1744,  0.0364,  0.0328, -0.1298,  0.2546],\n        [ 0.3452,  0.1409, -0.1481,  0.1419, -0.0301, -0.0695,  0.2558,  0.3384],\n        [ 0.2210, -0.1118, -0.1612,  0.0471, -0.1228,  0.2442, -0.1027,  0.2752],\n        [-0.3059, -0.1673, -0.3391, -0.2579,  0.3518,  0.0989,  0.1841, -0.1116],\n        [ 0.0552,  0.0780, -0.2341,  0.2720,  0.2254,  0.1841,  0.0057,  0.1286],\n        [-0.3418, -0.2977, -0.0900, -0.0938, -0.3400, -0.3457,  0.2988,  0.2291],\n        [-0.1683, -0.0069,  0.1275,  0.1322,  0.1174, -0.0370, -0.3019,  0.3153],\n        [-0.1483, -0.0729,  0.2627, -0.0237,  0.2990,  0.1075,  0.0701,  0.1658],\n        [-0.0160, -0.2181, -0.0178, -0.2140,  0.1760, -0.1543,  0.0952,  0.1551],\n        [ 0.3527, -0.2657, -0.1762, -0.2094,  0.3070, -0.2355, -0.1836,  0.2834],\n        [-0.2705,  0.0539, -0.0738, -0.0794, -0.2055,  0.3501,  0.1539,  0.1715],\n        [ 0.1889,  0.0088,  0.0027,  0.2653,  0.2915,  0.2892,  0.0620,  0.3330],\n        [ 0.2380,  0.2622, -0.0339, -0.1933,  0.1005,  0.0043,  0.0983,  0.3236],\n        [ 0.1365, -0.3176,  0.3192, -0.2923,  0.2048,  0.0770, -0.3214,  0.0882],\n        [ 0.1207,  0.0604,  0.1315,  0.2376, -0.0869, -0.3388, -0.2451, -0.0784],\n        [ 0.2496,  0.0728,  0.3204,  0.0528,  0.2121,  0.0478, -0.0427,  0.2758],\n        [ 0.1418,  0.0893, -0.0750,  0.0570, -0.1542,  0.2918, -0.1894, -0.2883],\n        [-0.0955,  0.0051, -0.2236,  0.3067, -0.2963, -0.2304, -0.1213,  0.2108],\n        [-0.3165,  0.3216, -0.2466,  0.0670,  0.2172, -0.0040, -0.0553,  0.0066],\n        [ 0.3099, -0.1613, -0.1474,  0.0914, -0.1811,  0.0235,  0.3086,  0.0552],\n        [-0.0358,  0.0838,  0.1833,  0.1218, -0.2006, -0.3247,  0.2535,  0.0800],\n        [-0.0832,  0.1028, -0.1746,  0.0841,  0.2328, -0.3070,  0.1946, -0.0792],\n        [ 0.2809, -0.1020,  0.0905,  0.1785, -0.0608, -0.2080, -0.2702,  0.3220],\n        [-0.2799, -0.1140,  0.1371, -0.1879, -0.2181,  0.1222,  0.3427, -0.1241],\n        [-0.2477,  0.3423, -0.1776,  0.3513, -0.1635,  0.2475, -0.3076, -0.0336],\n        [-0.0101, -0.1063, -0.0271,  0.2503,  0.1675, -0.0420, -0.1924,  0.0014],\n        [ 0.2953, -0.0574,  0.0680, -0.1177, -0.1971,  0.0889, -0.0715,  0.0352],\n        [-0.0240,  0.0123, -0.0310, -0.2284, -0.1829, -0.3140, -0.3329,  0.1382],\n        [ 0.1109, -0.0090, -0.3112, -0.0010,  0.1063,  0.2633,  0.2074,  0.2272],\n        [-0.3223, -0.1282, -0.1286, -0.0988,  0.0746, -0.1491, -0.0775, -0.0120],\n        [-0.3410,  0.1125,  0.3482, -0.0582, -0.2475, -0.0618,  0.0915,  0.2110],\n        [ 0.0792, -0.1699, -0.1344,  0.0711, -0.2120,  0.0723, -0.1956,  0.0770],\n        [-0.2844, -0.0764, -0.3479,  0.2233,  0.2927, -0.2444, -0.0218,  0.1269]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-1.4339e-01, -3.7021e-02,  1.2065e-01,  2.7791e-02,  3.4681e-01,\n         3.0483e-01,  2.2117e-01,  1.9948e-01, -1.1285e-02, -1.5281e-01,\n        -1.1816e-01, -2.1424e-01,  1.3729e-01, -1.0732e-01, -7.7847e-02,\n        -1.1619e-01,  6.2537e-02, -3.0863e-01,  1.1247e-02, -2.2469e-01,\n         2.0183e-01,  1.2618e-01,  7.9579e-03, -1.0194e-01, -1.7843e-01,\n        -1.3776e-01,  2.9970e-01, -2.0242e-01, -2.9920e-01,  1.5751e-01,\n         3.3893e-01,  3.4985e-01, -2.4213e-01, -3.0575e-01, -1.0422e-01,\n        -1.4436e-02,  4.0047e-02,  6.6215e-02,  5.4092e-02, -2.4294e-01,\n         3.1987e-01,  7.1366e-02, -1.5235e-01, -4.2600e-03,  1.4368e-02,\n         1.9752e-01, -2.0141e-01, -3.4178e-01, -3.1458e-01,  2.2404e-01,\n         1.6760e-01,  1.7383e-01, -9.1120e-02,  2.3682e-01, -1.9506e-04,\n        -1.1564e-01,  1.0740e-02, -1.5307e-01,  1.5570e-01,  3.3752e-01,\n        -3.0249e-01, -5.6245e-03,  2.8905e-01, -1.7550e-02],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0403,  0.0506, -0.1097,  ...,  0.0314, -0.0943,  0.0964],\n        [ 0.0784, -0.0666, -0.0557,  ..., -0.0803,  0.0236,  0.0013],\n        [ 0.0238,  0.1199,  0.0737,  ..., -0.0777,  0.0596, -0.0641],\n        ...,\n        [ 0.0897,  0.0852,  0.0856,  ...,  0.0356,  0.0847,  0.0148],\n        [ 0.0919, -0.0274, -0.0903,  ..., -0.1020, -0.0135, -0.0107],\n        [ 0.1083,  0.0472, -0.1112,  ..., -0.0538,  0.0051, -0.1116]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0324,  0.0255,  0.0348, -0.0449,  0.1036, -0.0976, -0.0516,  0.0023,\n        -0.0803, -0.0962, -0.0750,  0.0220, -0.0793, -0.1239, -0.0198,  0.0261,\n         0.0750,  0.0811,  0.0827, -0.0496, -0.0058,  0.0918,  0.0542,  0.0090,\n        -0.0107,  0.0789,  0.0581, -0.0982, -0.0165,  0.0641, -0.1028, -0.0766,\n         0.0698,  0.0423, -0.0187, -0.1220, -0.0011, -0.0787, -0.0659,  0.1032,\n         0.1081, -0.1167, -0.1176,  0.0359,  0.0207,  0.0428,  0.0130,  0.0923,\n        -0.1121, -0.0940, -0.1184, -0.0814,  0.0210,  0.0727,  0.1222,  0.0788,\n        -0.0731,  0.0776, -0.1209,  0.0398, -0.0919,  0.0898, -0.1075,  0.0613],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1049, -0.0493,  0.1185,  ..., -0.0970,  0.1143,  0.0116],\n        [-0.0984,  0.0775,  0.0728,  ..., -0.0395,  0.0336,  0.0330],\n        [-0.0811,  0.1067,  0.0133,  ..., -0.0268, -0.0486, -0.0705],\n        ...,\n        [ 0.0292, -0.0946,  0.1175,  ..., -0.0040,  0.0931,  0.0514],\n        [-0.0425, -0.1141,  0.0988,  ..., -0.0700, -0.0385, -0.0458],\n        [ 0.1098, -0.0628,  0.0614,  ...,  0.0978,  0.0407,  0.0747]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0054,  0.0436, -0.0392, -0.0840,  0.0954,  0.0704,  0.0699, -0.0203,\n         0.0266, -0.0904, -0.0869,  0.0297,  0.0763, -0.1236,  0.0309, -0.0167,\n         0.0591, -0.0288,  0.0107,  0.1067,  0.0491, -0.0594,  0.0181,  0.0297,\n         0.1181,  0.1119, -0.0447,  0.0467, -0.0049, -0.0621, -0.1101, -0.0372],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-2.9445e-02,  7.6534e-02,  1.7368e-01, -9.6190e-02,  1.2038e-01,\n          1.5088e-01,  1.4512e-01,  1.4868e-01,  1.3194e-01, -6.6219e-03,\n          4.3360e-03, -1.0627e-01,  6.6367e-02,  1.6610e-01,  8.2316e-02,\n          2.3696e-03,  6.8050e-02,  8.9576e-02,  1.3043e-01, -9.8121e-02,\n         -7.5331e-02,  5.7656e-02, -2.7116e-02,  9.8734e-02, -5.4858e-02,\n         -1.6787e-01, -1.3650e-01,  9.2165e-02,  9.5400e-02, -2.8616e-03,\n         -1.6288e-01,  1.5005e-01],\n        [-1.0246e-01,  1.3202e-01,  2.7038e-02,  4.7329e-02, -2.2399e-02,\n         -1.7224e-01, -1.0535e-01, -1.1594e-01,  8.2038e-02,  2.4546e-02,\n         -1.4121e-01,  9.1370e-02,  1.6128e-01, -1.1279e-01, -7.9751e-02,\n          1.6549e-01, -9.8206e-02,  7.5304e-02, -1.5573e-01, -1.4266e-01,\n          1.4957e-02, -3.2674e-02, -4.3726e-02,  9.3941e-02, -9.0936e-02,\n          1.5239e-01,  5.7080e-02, -9.5301e-02, -1.1914e-01, -1.4535e-01,\n         -1.2032e-01,  2.9037e-02],\n        [-1.4755e-01, -7.9258e-02,  1.7305e-01,  3.0004e-02, -1.4191e-01,\n         -1.0274e-01, -1.1061e-01,  4.2077e-02, -1.2844e-01,  1.6303e-02,\n         -4.0450e-02, -4.3575e-02, -9.1070e-02, -3.7002e-02, -1.2601e-01,\n          5.0070e-05, -6.5802e-02,  1.2187e-01, -9.0381e-02, -9.8786e-02,\n         -5.6271e-02, -7.7091e-02,  9.8481e-02, -1.3354e-01, -1.4108e-01,\n          1.3943e-01, -4.9635e-03,  1.6874e-01,  1.6301e-01, -1.1167e-01,\n         -1.0575e-01, -6.1569e-02],\n        [-8.4227e-02,  2.9393e-02,  3.3435e-02,  3.0454e-02,  4.9279e-02,\n          1.9502e-02,  7.8499e-02,  1.4669e-01,  7.7352e-02, -1.0820e-01,\n         -1.0887e-01, -1.4088e-01, -1.1342e-01,  7.1937e-02,  9.2946e-02,\n         -1.3389e-01,  4.7260e-02,  3.8296e-02, -7.4920e-02,  1.6966e-01,\n          1.3442e-01,  1.4985e-01, -1.5627e-01, -3.1574e-02,  5.0037e-02,\n          8.1567e-02, -1.0825e-01, -7.3178e-02,  1.0773e-02,  9.5188e-02,\n          1.3370e-01, -1.0286e-01],\n        [-1.7110e-01, -6.8475e-02,  6.4956e-02,  5.8013e-02, -6.2961e-02,\n         -1.8428e-02, -2.2274e-02,  5.1129e-02, -1.4739e-01, -6.6959e-02,\n         -6.1762e-02, -1.2884e-01,  7.4788e-02,  1.2323e-01, -1.4292e-01,\n          9.3096e-02,  2.5397e-02,  1.3243e-01, -8.0715e-02,  3.0584e-02,\n          6.4528e-02, -2.2715e-02,  1.4789e-01,  5.4988e-02,  8.3215e-02,\n          2.8164e-02, -1.5814e-01, -8.3147e-02,  1.0263e-01, -1.5470e-01,\n          5.6707e-03, -1.5428e-01],\n        [-1.1978e-01,  8.9074e-03,  1.5102e-01,  1.6914e-01,  1.2140e-01,\n          1.0799e-01, -1.6009e-01, -8.0812e-02,  1.1784e-01, -4.3801e-02,\n          9.3965e-02,  1.1747e-01, -1.7612e-01, -1.1128e-02,  7.9710e-02,\n         -1.5719e-01,  1.4053e-01, -1.5823e-01,  1.4280e-01, -6.2351e-03,\n         -1.2887e-01,  1.6587e-01,  1.1618e-01, -1.2039e-02, -3.3036e-02,\n         -8.7416e-02,  7.6946e-02,  1.6793e-01,  7.1897e-02, -2.7491e-02,\n         -1.6589e-01,  2.8002e-02],\n        [-1.1788e-01, -2.0349e-02, -1.6740e-01, -2.4564e-02, -3.5628e-03,\n         -4.5861e-02, -1.4088e-03, -1.5912e-01,  1.6873e-01, -8.5183e-02,\n          3.5056e-02, -4.6254e-03, -1.6018e-01,  1.4092e-01, -1.4163e-01,\n          7.6819e-02,  1.6949e-01,  2.4390e-02,  3.9943e-02,  2.4256e-03,\n          7.7990e-02, -1.2712e-01, -1.4959e-01,  9.0331e-02, -6.5149e-02,\n         -2.3738e-02,  8.3380e-02, -3.5863e-02,  1.0199e-01, -1.7307e-01,\n          8.2083e-02,  1.3735e-01],\n        [ 1.1272e-01, -3.7242e-02,  3.0815e-02,  1.2130e-02, -8.5215e-02,\n          6.0290e-02, -1.3541e-01, -2.2314e-02,  1.6883e-01,  3.8156e-02,\n         -6.2005e-02, -1.1744e-01, -1.5197e-01, -1.9856e-02,  7.0403e-02,\n         -4.4627e-02,  2.6483e-02, -1.6801e-01, -1.3047e-01,  1.4869e-01,\n         -2.1081e-02, -8.9288e-03, -3.7092e-02, -1.4340e-01, -8.7802e-02,\n         -9.2609e-02, -1.0865e-01, -1.5306e-01, -2.2659e-02, -1.1259e-01,\n         -1.4373e-01,  1.7359e-01],\n        [ 4.1392e-02, -1.0389e-01,  1.0650e-01, -4.5945e-02, -8.3478e-02,\n          5.8740e-02,  2.9533e-02,  8.7240e-02,  6.9277e-02, -2.1269e-02,\n          7.9919e-02, -1.6354e-01,  1.0925e-01,  1.6323e-01, -5.4597e-02,\n         -1.2774e-01,  1.0882e-01, -3.0611e-02,  1.4828e-01,  1.0434e-01,\n          1.7519e-02, -1.4786e-01, -1.1479e-01,  6.1782e-02, -1.3292e-01,\n         -7.9955e-02,  1.0366e-01,  1.6798e-01, -1.3158e-01,  1.7121e-01,\n          1.0223e-01,  1.1697e-01],\n        [-2.0362e-02,  9.2530e-02,  1.2947e-01,  1.0513e-02, -1.0751e-02,\n          1.4037e-01,  3.8561e-02,  1.7328e-01, -1.1096e-01,  9.5083e-02,\n         -6.9030e-02,  1.3366e-01, -1.0278e-01, -7.4874e-02, -1.4600e-01,\n         -2.6729e-02,  2.9855e-02, -1.3476e-01,  1.7571e-01,  7.4796e-02,\n         -4.2058e-02,  1.7194e-01,  2.8415e-02,  1.5702e-01, -7.3924e-02,\n         -2.4035e-02,  2.4622e-02,  1.7266e-01,  4.1449e-02,  2.0059e-02,\n         -4.0284e-02,  1.3714e-01],\n        [ 1.2972e-01, -1.0622e-01,  8.2176e-02,  7.9999e-02,  5.6002e-02,\n          1.6449e-01,  8.4721e-02, -1.4821e-01,  1.4255e-01, -2.0688e-02,\n          1.0886e-01,  1.7498e-01, -5.3923e-02,  1.6430e-01, -1.2454e-01,\n         -1.5605e-01, -1.5021e-01, -1.3738e-01,  4.9084e-02,  1.2274e-01,\n          4.0360e-03,  6.8085e-02,  5.3818e-02, -3.0731e-02,  3.9520e-02,\n          1.6084e-01,  1.4870e-01, -8.3504e-02,  1.6368e-01, -6.6401e-02,\n          1.2294e-01, -1.4028e-02],\n        [-1.0416e-01,  7.1548e-02,  8.8310e-02, -6.8599e-02,  1.5411e-01,\n         -1.1352e-01, -1.6787e-01, -1.4425e-02, -1.5097e-01,  9.5129e-02,\n          1.2780e-01, -1.7539e-01,  3.5975e-02,  1.3033e-01, -2.3468e-02,\n         -1.4354e-01, -1.4939e-01,  2.5779e-02, -3.0876e-02, -1.6668e-01,\n         -1.3581e-02, -1.6920e-01,  8.9019e-02,  4.4593e-02,  1.2743e-01,\n         -3.1681e-02, -4.7729e-02, -1.4389e-02,  1.0169e-01,  8.7837e-02,\n         -1.5176e-01,  4.8570e-02],\n        [ 6.5327e-02, -1.1431e-01,  1.2232e-01, -8.8547e-02, -9.4389e-02,\n          9.0432e-03,  1.6426e-01, -5.7434e-02, -1.1729e-01, -1.6214e-01,\n          8.9202e-02, -1.3766e-01,  6.7432e-02, -2.8999e-02,  2.2408e-02,\n         -1.1162e-01, -6.8644e-02,  1.0015e-01,  8.8297e-02,  2.1649e-02,\n         -8.5576e-02,  2.9504e-03, -1.5813e-01,  1.4200e-01,  8.5466e-03,\n         -9.3314e-02,  9.5005e-02,  1.5369e-02,  1.4328e-01, -7.6864e-02,\n          8.4400e-02, -2.0171e-03],\n        [-5.3977e-02, -6.8076e-02, -1.5315e-01, -1.6013e-01,  6.4942e-02,\n         -5.7031e-03,  7.8327e-02, -1.2789e-01, -1.1182e-01,  8.6523e-02,\n          2.9689e-02, -1.3241e-01, -5.8752e-02, -8.7063e-02, -2.1458e-02,\n         -6.2748e-02, -1.4868e-01,  1.6828e-01, -9.8540e-02, -1.2438e-01,\n         -1.5981e-01,  9.1044e-02, -1.2729e-01,  1.4167e-01, -7.8520e-03,\n          1.7234e-01,  1.6899e-01,  5.8094e-02,  1.7486e-01,  1.1737e-02,\n         -3.5130e-02, -5.4917e-02],\n        [-9.9522e-03, -1.3221e-01, -1.2177e-01, -1.6323e-01,  3.9688e-02,\n          1.2778e-01,  9.5892e-02,  1.3534e-01, -1.7230e-01, -4.4463e-02,\n         -4.8944e-02, -4.5641e-02, -1.3843e-01, -1.7139e-01, -1.6527e-01,\n         -2.4623e-02, -1.0672e-01,  1.1750e-01, -1.3375e-01, -4.4235e-02,\n         -8.8921e-02,  1.2404e-01, -5.5464e-02, -1.1656e-01,  3.9384e-03,\n          1.1399e-01,  1.6082e-01, -5.9217e-02,  1.3091e-01,  1.3594e-01,\n          1.0365e-02, -1.3393e-01],\n        [ 4.6650e-03,  6.9835e-02, -1.6872e-01,  1.5321e-01,  3.6525e-02,\n          1.3437e-01, -4.3631e-02,  9.9797e-02,  3.9226e-02,  1.0929e-01,\n         -7.4226e-02, -7.8440e-02, -6.7009e-02,  1.1143e-01, -1.3635e-01,\n         -9.7670e-02,  1.1352e-01, -8.2298e-03, -7.2436e-02, -1.1234e-01,\n          1.3777e-01, -1.5567e-01, -3.1933e-02, -9.0576e-02, -1.0665e-01,\n          2.2708e-02,  4.5469e-02,  2.1575e-02,  1.0163e-01,  1.0326e-01,\n         -1.4905e-01,  6.5297e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0399, -0.1207,  0.1556, -0.0774,  0.0218,  0.0730,  0.1258,  0.0439,\n         0.1631, -0.1101, -0.0695, -0.1371,  0.0155, -0.1027, -0.0980,  0.0135],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1847, -0.0285, -0.1209, -0.1133, -0.0332,  0.2064, -0.1056, -0.0728,\n         -0.2199,  0.0576, -0.0377, -0.1931,  0.1748,  0.0868, -0.0510, -0.0253],\n        [-0.1662,  0.0222, -0.0321,  0.2307,  0.0276, -0.1561,  0.1882, -0.0030,\n         -0.0137,  0.1969, -0.1629,  0.1404,  0.0373,  0.0130, -0.2455, -0.0652],\n        [ 0.0343,  0.2012,  0.1940, -0.1676, -0.0595, -0.2106,  0.2123, -0.2181,\n          0.1833,  0.0822, -0.1977,  0.0586,  0.2380,  0.1256, -0.0639, -0.0469],\n        [-0.1475, -0.1292,  0.2012,  0.0846,  0.0891, -0.0414, -0.1306,  0.1045,\n         -0.2026, -0.1213, -0.2256,  0.1965, -0.0556,  0.0856, -0.2370, -0.1753],\n        [ 0.1272, -0.1414,  0.1756,  0.1028,  0.0230,  0.1259,  0.1061, -0.2164,\n          0.0902,  0.2215, -0.2146, -0.1900,  0.2007,  0.0391, -0.0816,  0.0093],\n        [ 0.1818, -0.1111,  0.2137,  0.1546, -0.0840,  0.0009, -0.1976, -0.0339,\n          0.2025, -0.1565,  0.2203,  0.2385, -0.0216,  0.2010, -0.1920, -0.2345],\n        [-0.0329,  0.2312, -0.0235, -0.1820,  0.1075, -0.1369, -0.0332,  0.0856,\n          0.0838, -0.1855,  0.2104,  0.0400, -0.2400, -0.1430, -0.0440, -0.1409],\n        [ 0.2102, -0.0062, -0.1105, -0.0372, -0.0738, -0.2139,  0.0263,  0.1910,\n         -0.1654,  0.0564, -0.0445, -0.1312,  0.0501,  0.2093,  0.1245, -0.2301]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1657, -0.1794,  0.2149, -0.1100,  0.1786,  0.0081,  0.0219,  0.2272],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0643, -0.2573, -0.0329,  0.1877,  0.3439,  0.1961,  0.0711,  0.1330]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0855], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x782312539890>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7823100ff250>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s186290000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s186290000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}