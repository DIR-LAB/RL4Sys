{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s187020000"
    },
    "q_lr":	0.0005,
    "seed":	187020000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x76b7e935e3d0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=32, out_features=16, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=16, out_features=8, bias=True)\n    (9): ReLU()\n    (10): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=64, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=64, out_features=32, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=32, out_features=16, bias=True)\n  (7): ReLU()\n  (8): Linear(in_features=16, out_features=8, bias=True)\n  (9): ReLU()\n  (10): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3360, -0.0019,  0.2161,  0.0517,  0.2204, -0.3061, -0.1881, -0.3018,\n         0.2512,  0.3166, -0.1757,  0.0918,  0.1380,  0.1309, -0.1371, -0.0248,\n        -0.2981,  0.3433, -0.3074,  0.0904, -0.0164,  0.1266, -0.1025,  0.2486,\n        -0.0940, -0.3154, -0.0628,  0.1841,  0.1957, -0.2947, -0.1459, -0.0566,\n         0.2011,  0.0952,  0.2344, -0.2928, -0.3521,  0.0199,  0.1223,  0.1625,\n         0.0618,  0.2882,  0.1502,  0.3018,  0.1542, -0.0438, -0.2063, -0.2613,\n        -0.2207, -0.0497, -0.2457, -0.1451,  0.1210, -0.0824,  0.0281,  0.0044,\n        -0.2192, -0.1821, -0.0967, -0.1442,  0.0614,  0.1776,  0.0106, -0.0777],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1213, -0.2474, -0.0423,  0.2005, -0.3293,  0.1271, -0.1751, -0.2342],\n        [ 0.3419,  0.2553,  0.0155,  0.2748, -0.2720,  0.1082, -0.0953,  0.1794],\n        [ 0.3337, -0.3079, -0.1845, -0.0737,  0.0328, -0.1334, -0.1851,  0.3525],\n        [-0.3113, -0.1122,  0.0449, -0.2860, -0.1319,  0.2223, -0.1053, -0.3055],\n        [ 0.1795,  0.0972,  0.1431, -0.2733,  0.3198, -0.2698, -0.1348,  0.2489],\n        [-0.1584, -0.2329, -0.1083,  0.2267, -0.0531, -0.0015,  0.0315, -0.3387],\n        [-0.0481,  0.0130, -0.3044,  0.0632,  0.0790,  0.0521,  0.0976, -0.3151],\n        [ 0.1829, -0.3351, -0.3505, -0.3276,  0.2138,  0.2408, -0.3020,  0.0031],\n        [ 0.1422,  0.2525, -0.2478, -0.3121,  0.0021,  0.0991, -0.0689,  0.2528],\n        [ 0.2816,  0.0245,  0.3438, -0.1640, -0.0961, -0.2914,  0.3223,  0.3474],\n        [-0.0819, -0.3106, -0.2853, -0.1055, -0.2749,  0.3190, -0.2165, -0.2279],\n        [-0.3242,  0.2712,  0.2140,  0.3432,  0.2975,  0.2650, -0.0807,  0.0910],\n        [ 0.3144, -0.1366,  0.3029, -0.3481,  0.3176,  0.3532, -0.3008, -0.2557],\n        [-0.1734,  0.3131,  0.3176, -0.1449, -0.1942, -0.0013,  0.2346, -0.1354],\n        [-0.0502, -0.2306,  0.2129,  0.1569, -0.0114,  0.1834, -0.1611, -0.0679],\n        [-0.0098, -0.1031, -0.0701,  0.1685,  0.1328, -0.0866, -0.3028,  0.2273],\n        [-0.0955, -0.2985, -0.0957, -0.3147,  0.3260, -0.0893, -0.2219,  0.2915],\n        [-0.1370, -0.0637, -0.2582,  0.0030, -0.3209, -0.2199, -0.2606,  0.1078],\n        [-0.3422,  0.0200,  0.0757,  0.3389, -0.3500,  0.1841, -0.0253, -0.3378],\n        [ 0.1396,  0.1551, -0.3315,  0.0702,  0.0853,  0.2804, -0.3099, -0.1214],\n        [ 0.0049,  0.0625, -0.0544, -0.3370, -0.0762, -0.1678, -0.0742,  0.2154],\n        [-0.2154, -0.1094,  0.1182, -0.0863,  0.1249,  0.1658,  0.0683, -0.0102],\n        [ 0.1049, -0.3340, -0.2523, -0.0815,  0.1553,  0.1442,  0.0045, -0.1934],\n        [ 0.3279, -0.0524,  0.1846, -0.0355,  0.1319, -0.0662,  0.2105,  0.1839],\n        [-0.1887, -0.0402, -0.0460, -0.3216,  0.0451, -0.2798,  0.1063,  0.1111],\n        [-0.2803,  0.3530, -0.2724, -0.1831,  0.3360,  0.0116, -0.1754,  0.3253],\n        [-0.2288, -0.3298, -0.3348, -0.2674, -0.2254,  0.2867, -0.2992, -0.3310],\n        [-0.2851, -0.0567, -0.0176, -0.2317, -0.0772, -0.1329, -0.1225, -0.2088],\n        [ 0.3457,  0.2507,  0.3023, -0.1799, -0.1974,  0.3062, -0.0953,  0.2920],\n        [ 0.3158, -0.3076,  0.3421,  0.2594,  0.3424,  0.3428,  0.0906, -0.1436],\n        [-0.3232,  0.1291,  0.2994, -0.1996, -0.2856, -0.2852,  0.1849, -0.1906],\n        [ 0.0045,  0.2011, -0.2093, -0.0385,  0.2253, -0.3384, -0.2080, -0.0203],\n        [ 0.3341,  0.2137, -0.0664,  0.0834,  0.0254, -0.1040,  0.3490, -0.3496],\n        [-0.0351, -0.1139,  0.3047,  0.1382,  0.2938,  0.0537, -0.1972, -0.0304],\n        [ 0.1944, -0.0477,  0.3410, -0.2175,  0.1793,  0.0007,  0.2050, -0.3523],\n        [ 0.2061, -0.0401, -0.3310, -0.1709, -0.2892, -0.2565, -0.2476,  0.2030],\n        [ 0.0941, -0.1840, -0.3176,  0.0856,  0.0242, -0.0952, -0.1953,  0.3328],\n        [-0.2360, -0.2048, -0.1862, -0.2603, -0.1917, -0.1743,  0.2450,  0.2236],\n        [ 0.3007, -0.3135, -0.2415,  0.1331, -0.2313,  0.0141,  0.2408,  0.2899],\n        [-0.3296, -0.0568,  0.3193,  0.1428, -0.1596, -0.1248, -0.1308, -0.1223],\n        [-0.1209,  0.3102,  0.1056, -0.0673, -0.0566, -0.2613,  0.2691, -0.2406],\n        [-0.3407, -0.2495, -0.2512,  0.1231, -0.3061, -0.2448, -0.2981,  0.1386],\n        [-0.1996, -0.1208,  0.3288,  0.1187, -0.2653, -0.2129,  0.0394,  0.1167],\n        [-0.2088,  0.0360,  0.3025,  0.2056,  0.2939,  0.3363,  0.2032, -0.0899],\n        [ 0.3529, -0.1007,  0.2326, -0.3531,  0.1007,  0.2763, -0.2741, -0.2132],\n        [-0.1384, -0.1533, -0.1615, -0.3038, -0.0811,  0.0688, -0.1391,  0.1143],\n        [-0.1509,  0.0147,  0.1530,  0.1818,  0.1914, -0.2947,  0.1361, -0.0025],\n        [ 0.3440,  0.0928, -0.1452, -0.0097,  0.2948, -0.0991,  0.0490,  0.0063],\n        [-0.0962,  0.1479,  0.3222, -0.3466, -0.1706, -0.0235,  0.3070, -0.2227],\n        [-0.1520,  0.1877,  0.1936, -0.2403,  0.1267,  0.0493,  0.2439,  0.1813],\n        [-0.1031, -0.2252, -0.0394,  0.1466,  0.1339,  0.0045, -0.0169,  0.2382],\n        [-0.2224, -0.2601,  0.2366, -0.3181,  0.2180,  0.3415, -0.2976,  0.0832],\n        [-0.2727, -0.2771,  0.1109, -0.1910, -0.0257, -0.0311,  0.3355, -0.0697],\n        [-0.3277, -0.2580,  0.2402,  0.3280, -0.1642, -0.0760,  0.0306,  0.3090],\n        [-0.2173,  0.3522,  0.2394,  0.3008,  0.1075, -0.3260, -0.3006,  0.1585],\n        [-0.1373,  0.0825, -0.0390, -0.1268, -0.2776, -0.3458,  0.0446,  0.1163],\n        [-0.2828,  0.0957, -0.1804, -0.2280,  0.1097,  0.3005, -0.1912,  0.1525],\n        [-0.0929, -0.2530, -0.1603, -0.1590, -0.2197, -0.1572,  0.1215, -0.3217],\n        [ 0.1943,  0.0097,  0.2401,  0.2216,  0.0847,  0.3437,  0.2110, -0.1903],\n        [ 0.0983, -0.0627,  0.1567,  0.0335, -0.2118,  0.1254, -0.0127,  0.3497],\n        [-0.1387,  0.2232,  0.2049, -0.1459,  0.0602, -0.0497,  0.0066,  0.0486],\n        [-0.2556,  0.3264, -0.0047,  0.1881,  0.0032,  0.3383,  0.2654, -0.2337],\n        [-0.1643,  0.2733, -0.2159,  0.0340, -0.1245, -0.2815,  0.3061, -0.0631],\n        [-0.1226,  0.1257, -0.3335,  0.2626, -0.3456,  0.2664,  0.2770,  0.2301]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "10":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1466], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3283,  0.1331,  0.1234,  0.1495, -0.0481,  0.1129, -0.1608,  0.2936]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=64, out_features=64, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0564,  0.1053, -0.0748,  0.0543, -0.0829, -0.1173,  0.0797,  0.0472,\n         0.1240,  0.1187,  0.1205, -0.0734,  0.1175, -0.0204,  0.0904,  0.0436,\n         0.0850,  0.0199,  0.0325,  0.0129, -0.0689,  0.0923, -0.0956,  0.0098,\n        -0.0722,  0.0411, -0.1206,  0.0942, -0.1045, -0.0889, -0.0577, -0.0648,\n         0.1183, -0.0059, -0.0325,  0.0479, -0.0607,  0.0094, -0.1167, -0.0064,\n        -0.1157,  0.0462, -0.0288,  0.0960,  0.1134, -0.1187,  0.0071,  0.0175,\n        -0.0353, -0.0153,  0.0671,  0.1218, -0.1080, -0.1094,  0.0199,  0.0923,\n         0.1008, -0.0692, -0.1062, -0.0176, -0.0243,  0.0805, -0.0398, -0.0611],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0942,  0.0965,  0.0657,  ..., -0.0532, -0.0190, -0.0595],\n        [-0.0465,  0.0027, -0.0498,  ...,  0.0447,  0.1221, -0.0603],\n        [-0.0511,  0.0892,  0.0142,  ..., -0.0983, -0.0868,  0.1239],\n        ...,\n        [-0.0890, -0.0362, -0.0429,  ..., -0.0140, -0.0819,  0.0141],\n        [ 0.0654, -0.0459, -0.0985,  ..., -0.1094,  0.0129,  0.1085],\n        [-0.1005, -0.0780,  0.0714,  ..., -0.0432, -0.0698,  0.0731]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	64,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=64, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0833, -0.1108,  0.1121, -0.0114,  0.0471, -0.0494,  0.0753,  0.0361,\n        -0.0911, -0.0044,  0.1047,  0.0653,  0.0552, -0.0457,  0.0458,  0.0859,\n        -0.0042, -0.0516,  0.0098,  0.0416,  0.0661, -0.1172, -0.0565, -0.0394,\n        -0.1126,  0.0303,  0.0243,  0.0837, -0.0195, -0.0560,  0.0079,  0.0638],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1054,  0.0888,  0.0213,  ..., -0.0085,  0.0188, -0.0979],\n        [ 0.1220,  0.0924,  0.0726,  ...,  0.1247,  0.0714,  0.0464],\n        [-0.0921, -0.0315,  0.0852,  ...,  0.0228, -0.1097, -0.0211],\n        ...,\n        [ 0.0533,  0.0996, -0.1038,  ..., -0.0219,  0.1006,  0.0330],\n        [-0.1238, -0.1119, -0.1115,  ...,  0.1025,  0.1052,  0.0235],\n        [-0.0937,  0.0279, -0.0545,  ...,  0.0838,  0.0407,  0.0379]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	64,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0569,  0.1038, -0.1735, -0.1516, -0.0326,  0.1340,  0.0109,  0.0494,\n         0.1376, -0.0813,  0.0628,  0.0727,  0.1620, -0.0747, -0.0841,  0.1211],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-7.9170e-02,  2.5758e-02, -2.3570e-02,  1.0172e-01, -4.9570e-02,\n          1.0944e-02,  1.7228e-01, -1.4755e-01,  1.4135e-01, -1.5157e-01,\n         -1.4146e-02, -1.6830e-02, -1.2681e-01,  1.1152e-01,  1.5426e-01,\n          1.5057e-01,  8.8704e-02, -8.1413e-02,  1.2189e-01,  4.2357e-02,\n          9.8505e-02,  1.0699e-01,  1.6491e-01, -8.4568e-02,  1.4035e-01,\n         -5.5133e-02,  1.8327e-02,  2.4116e-02, -1.6902e-01,  6.0563e-02,\n          1.0213e-01,  7.3342e-03],\n        [-1.6078e-01,  9.4167e-02,  1.6005e-01,  1.6713e-01, -8.4519e-02,\n          1.2324e-01,  1.5329e-01,  5.0624e-02, -8.6200e-03, -2.4492e-02,\n         -7.7374e-02,  2.6752e-02,  2.3086e-02,  6.5194e-02,  3.0777e-02,\n          6.4081e-03, -1.3729e-01, -5.8700e-02,  2.4142e-02,  1.2822e-01,\n         -1.7058e-01,  1.6600e-01, -4.6292e-02, -1.4336e-01, -1.5866e-02,\n          1.5956e-01, -1.7526e-01, -1.5614e-01,  3.2996e-02,  2.8764e-02,\n          3.6958e-02, -4.1192e-02],\n        [ 5.9602e-02, -1.5995e-02,  7.3244e-02,  2.3015e-02,  5.7431e-02,\n          1.2158e-01,  2.0293e-02,  4.2901e-02,  4.9671e-02, -2.8175e-04,\n          8.9074e-02,  9.8729e-05, -1.5239e-01, -7.8410e-02, -5.9143e-02,\n         -5.5649e-02,  9.7338e-02, -1.8113e-02, -1.1236e-01,  9.0100e-02,\n         -1.6565e-01,  8.4321e-02,  1.4664e-01, -1.7514e-01,  1.4423e-01,\n          4.7145e-02,  4.1487e-02,  5.6974e-02, -1.4268e-01,  1.2523e-01,\n         -1.3990e-01,  1.2333e-01],\n        [ 1.5696e-02, -8.3175e-02, -1.0005e-01, -7.5597e-04, -8.8771e-02,\n          1.3988e-01,  1.6078e-01,  1.0327e-01,  5.4675e-02,  9.5019e-03,\n          3.6100e-02, -6.0714e-02,  1.0389e-01, -1.0748e-01,  1.2874e-01,\n         -8.1537e-02, -4.2529e-02,  8.8337e-02, -4.8047e-02,  1.5415e-01,\n          3.3537e-03,  6.6518e-02, -1.0653e-01,  1.0135e-01,  2.6713e-02,\n          1.5638e-01,  1.2505e-01, -9.4827e-03, -1.7444e-01, -8.3427e-02,\n          9.7949e-02,  9.4389e-03],\n        [-5.6430e-02, -1.0966e-01, -1.6567e-01, -5.4666e-02,  5.8029e-02,\n          1.0695e-01,  1.4395e-01, -1.2788e-01,  1.1028e-01,  1.4133e-02,\n         -1.3149e-01, -9.7177e-02,  2.2848e-02, -1.1618e-01, -1.3658e-01,\n          2.9443e-02, -8.2392e-03,  5.0838e-02, -1.1927e-01, -4.4644e-02,\n         -1.2358e-02,  2.4075e-02, -1.0493e-01,  3.7123e-02, -7.0215e-02,\n         -1.5675e-01, -1.4999e-01,  1.7619e-01,  5.9430e-02, -3.9753e-02,\n          7.0361e-02,  1.3049e-02],\n        [-3.7031e-02, -1.3481e-01,  1.5884e-01,  1.7472e-02, -1.6364e-01,\n          5.2664e-02,  3.4653e-02,  6.0256e-02,  5.2858e-02,  1.3617e-01,\n         -4.1324e-02, -1.2926e-01,  1.1730e-01,  7.4818e-02, -1.4636e-01,\n         -5.3014e-02,  1.4667e-01,  1.3580e-02, -1.4137e-01, -7.5196e-02,\n          9.4278e-02,  9.5145e-02, -8.7589e-02, -3.9456e-02, -6.7684e-02,\n          1.1486e-01,  1.6682e-01, -9.3443e-02,  5.0951e-02,  2.7927e-02,\n         -6.9000e-02,  5.4418e-02],\n        [ 1.4456e-01,  5.7438e-02, -2.4172e-02,  1.2382e-02,  7.8323e-02,\n          1.5578e-01, -4.0676e-02, -5.4075e-02, -2.2099e-02,  4.9354e-02,\n         -7.4343e-02, -1.5159e-01, -1.3463e-01, -1.2676e-01,  1.2409e-01,\n         -1.1188e-01, -7.0362e-02,  8.8134e-02, -3.2139e-04,  9.7093e-02,\n         -1.1251e-01,  1.4958e-01, -1.2364e-01, -2.6023e-02, -1.4325e-01,\n         -1.7324e-01, -2.8524e-03,  5.4667e-02, -9.1452e-02, -1.2513e-01,\n          1.1190e-02, -4.7048e-02],\n        [ 1.5068e-01, -9.8204e-02,  2.4372e-02, -1.4039e-01,  1.5814e-01,\n          1.5442e-01, -5.9275e-03, -1.6517e-01, -1.3173e-01,  1.7580e-01,\n          4.7706e-02, -1.5345e-01,  1.6908e-01,  8.4091e-02, -1.6409e-01,\n          1.5239e-01, -1.6395e-01,  8.3722e-02,  1.4731e-01, -1.9799e-02,\n          9.9852e-02, -1.2761e-01,  1.7323e-01, -4.5388e-02,  8.2105e-02,\n          1.4729e-01, -9.1177e-02,  1.5911e-01,  4.0309e-02,  6.4734e-02,\n          1.3991e-02,  1.6654e-01],\n        [-1.2851e-01, -1.3028e-01,  1.6369e-02, -8.5696e-02,  6.8594e-02,\n          9.7185e-02, -1.0178e-01,  1.0605e-01, -1.5446e-01,  3.7920e-02,\n         -1.5754e-01, -1.3080e-01, -5.1330e-02,  9.3962e-02,  1.7016e-01,\n          9.7792e-02,  8.7939e-05,  2.2150e-02,  1.1704e-01, -1.2456e-01,\n         -6.4419e-02, -1.4497e-01, -7.8373e-02, -1.0284e-01, -1.0618e-01,\n          4.9447e-02,  1.3514e-01,  1.7475e-01, -9.5780e-02, -1.1101e-03,\n          1.9088e-02,  7.1700e-02],\n        [-1.6011e-01, -9.4405e-02,  2.9299e-02, -1.1847e-01, -8.6035e-02,\n          9.3410e-02, -1.2377e-01,  8.1899e-02,  1.5547e-01,  6.0591e-02,\n         -8.6522e-02,  7.3627e-02,  1.2029e-01,  1.0511e-01,  5.0102e-02,\n         -1.5825e-01,  1.4148e-01, -8.3554e-02, -4.4998e-02,  1.1345e-01,\n          8.4632e-02, -5.7932e-02,  7.9828e-02,  3.7876e-02,  3.8799e-02,\n          1.9759e-02, -5.0730e-02,  2.9747e-02,  1.4578e-01, -2.7485e-02,\n         -1.1368e-01,  8.4749e-02],\n        [ 7.5028e-03,  1.3245e-01, -1.5327e-01, -1.5287e-01, -1.3751e-01,\n         -5.6938e-02, -5.0643e-02,  4.6636e-02, -1.4503e-01, -1.3981e-01,\n          3.4144e-02, -1.7834e-02,  1.2125e-01, -8.2859e-02, -7.5395e-02,\n         -6.8728e-02, -1.3417e-01, -2.3076e-02, -1.4467e-01,  5.8683e-03,\n         -9.4573e-02,  1.4520e-02, -1.2573e-01, -7.0265e-04,  1.5276e-01,\n         -1.5965e-01,  1.1008e-02, -1.1164e-01, -2.4355e-02,  1.6986e-01,\n         -7.0088e-02, -9.2813e-02],\n        [ 1.2846e-01,  8.9836e-02, -3.8639e-02,  8.0213e-02, -4.9762e-02,\n          1.1294e-02,  1.4355e-01,  8.4360e-02,  4.4086e-02, -2.4725e-02,\n          1.0953e-01,  4.1345e-02,  4.4625e-02, -2.0202e-03,  1.6775e-01,\n          8.4788e-02,  1.0621e-01, -9.9917e-02, -1.2829e-01,  1.0969e-01,\n         -1.4531e-02, -1.3622e-01,  9.8911e-02, -6.9286e-02,  4.4771e-02,\n          1.2043e-01,  2.5417e-02,  1.6105e-01,  9.2175e-02, -6.2241e-02,\n         -1.6503e-02, -9.2128e-02],\n        [-4.0387e-02, -1.0283e-01,  1.0296e-01,  8.4583e-03,  1.7194e-01,\n         -1.5738e-01,  1.5836e-01,  1.7319e-01, -1.3191e-01,  9.6711e-02,\n         -1.7296e-01,  1.3154e-01,  1.6694e-01,  1.2556e-01, -1.5024e-01,\n          1.1883e-01,  1.0042e-01,  9.5688e-02,  9.8518e-02,  1.6058e-01,\n          2.1848e-02, -8.3919e-03, -5.1840e-02,  1.1127e-02,  1.3602e-01,\n         -1.2064e-01,  3.1543e-02,  1.5873e-01,  8.0092e-02,  1.4406e-01,\n         -6.6870e-03, -2.3206e-02],\n        [-2.0188e-02,  3.5162e-02,  1.1896e-01, -2.4052e-02,  8.3708e-02,\n          1.4482e-01, -7.3585e-03, -1.3822e-01, -1.0216e-01,  5.0596e-02,\n         -6.0265e-02,  1.3743e-01, -5.8509e-02, -1.2160e-01, -9.8990e-02,\n          1.5248e-01,  1.5550e-01, -1.1442e-01, -1.1669e-01, -1.6270e-01,\n         -4.0666e-02,  6.8569e-02,  6.8004e-02, -1.6822e-02, -2.5819e-02,\n         -3.2085e-02, -8.1852e-02, -1.6940e-01,  4.7652e-02,  1.4791e-01,\n         -7.0046e-02, -7.4302e-02],\n        [-1.0541e-01, -5.9840e-03,  1.5735e-01,  9.3777e-06,  1.2460e-02,\n          1.3355e-02,  1.6678e-01,  1.1793e-01,  1.0832e-01,  1.6576e-01,\n         -1.6007e-01, -1.3893e-01, -9.9740e-02, -4.8867e-02,  4.6387e-02,\n          9.6333e-02, -5.0046e-02, -8.7068e-02, -3.2879e-02, -1.2109e-01,\n         -1.1074e-01, -1.5123e-01, -1.0233e-01, -5.1051e-02,  1.2553e-01,\n         -1.5735e-01, -1.0581e-01,  3.1798e-03, -6.0259e-02, -1.3765e-01,\n          1.1736e-01,  1.5235e-01],\n        [-1.4263e-01,  4.0620e-02, -7.1959e-02, -1.1460e-01, -1.7230e-01,\n          1.7166e-01, -1.1164e-01,  1.2900e-01,  2.2963e-02,  1.0385e-01,\n         -6.0334e-02,  3.3855e-02,  1.4590e-01, -1.9797e-02, -4.4801e-02,\n          4.6484e-03, -6.2774e-02,  9.1695e-02,  1.7111e-01,  7.2009e-02,\n         -8.6681e-02,  1.2619e-01, -1.9880e-02,  3.0194e-02, -1.6837e-01,\n          9.3265e-02, -1.7359e-03, -7.8579e-02,  8.7519e-02, -2.5010e-02,\n         -8.1971e-02,  1.3954e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "7":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "8":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1987,  0.1996,  0.1858,  0.0052, -0.0140,  0.0352, -0.1575,  0.0758],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0229, -0.1950,  0.0194,  0.0764, -0.0451, -0.0425, -0.1554,  0.0296,\n         -0.2201,  0.0552, -0.2209, -0.0748,  0.1206,  0.0003, -0.1206,  0.1002],\n        [ 0.1918,  0.0369,  0.1007,  0.2348,  0.0978, -0.0779, -0.1940, -0.0307,\n          0.2022,  0.0751,  0.1532,  0.1355,  0.1431,  0.2475,  0.1904, -0.1484],\n        [ 0.0129, -0.0222,  0.0287,  0.0909, -0.2042, -0.0327,  0.1170, -0.0866,\n          0.2436,  0.1208, -0.1676, -0.0911,  0.0262,  0.1514,  0.2385,  0.1712],\n        [-0.1624,  0.0711,  0.2180, -0.1153,  0.1002,  0.0616,  0.0301,  0.1978,\n         -0.1388,  0.0793, -0.0127, -0.0214, -0.0054, -0.2359,  0.0068, -0.2065],\n        [ 0.1434, -0.0302,  0.2043,  0.0196, -0.0932,  0.2029,  0.1977, -0.1376,\n         -0.1063, -0.1301, -0.0480, -0.1235, -0.1022, -0.0802,  0.0632,  0.2140],\n        [ 0.2351,  0.0962,  0.2138,  0.1859, -0.1741,  0.0331, -0.2424, -0.0768,\n         -0.0728,  0.1111,  0.1355,  0.0391,  0.0416,  0.2325, -0.0425,  0.0516],\n        [ 0.0814,  0.2166, -0.0875, -0.2406,  0.0447,  0.0434,  0.1919,  0.0909,\n          0.1454, -0.1161,  0.0150, -0.1925,  0.2451,  0.1173,  0.1636,  0.2172],\n        [-0.0007,  0.1256, -0.2347,  0.0202, -0.1048, -0.2035,  0.1884,  0.0726,\n         -0.0039, -0.1314,  0.2014, -0.2197,  0.0731, -0.0830,  0.0691, -0.1426]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "9":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1213, -0.2474, -0.0423,  0.2005, -0.3293,  0.1271, -0.1751, -0.2342],\n        [ 0.3419,  0.2553,  0.0155,  0.2748, -0.2720,  0.1082, -0.0953,  0.1794],\n        [ 0.3337, -0.3079, -0.1845, -0.0737,  0.0328, -0.1334, -0.1851,  0.3525],\n        [-0.3113, -0.1122,  0.0449, -0.2860, -0.1319,  0.2223, -0.1053, -0.3055],\n        [ 0.1795,  0.0972,  0.1431, -0.2733,  0.3198, -0.2698, -0.1348,  0.2489],\n        [-0.1584, -0.2329, -0.1083,  0.2267, -0.0531, -0.0015,  0.0315, -0.3387],\n        [-0.0481,  0.0130, -0.3044,  0.0632,  0.0790,  0.0521,  0.0976, -0.3151],\n        [ 0.1829, -0.3351, -0.3505, -0.3276,  0.2138,  0.2408, -0.3020,  0.0031],\n        [ 0.1422,  0.2525, -0.2478, -0.3121,  0.0021,  0.0991, -0.0689,  0.2528],\n        [ 0.2816,  0.0245,  0.3438, -0.1640, -0.0961, -0.2914,  0.3223,  0.3474],\n        [-0.0819, -0.3106, -0.2853, -0.1055, -0.2749,  0.3190, -0.2165, -0.2279],\n        [-0.3242,  0.2712,  0.2140,  0.3432,  0.2975,  0.2650, -0.0807,  0.0910],\n        [ 0.3144, -0.1366,  0.3029, -0.3481,  0.3176,  0.3532, -0.3008, -0.2557],\n        [-0.1734,  0.3131,  0.3176, -0.1449, -0.1942, -0.0013,  0.2346, -0.1354],\n        [-0.0502, -0.2306,  0.2129,  0.1569, -0.0114,  0.1834, -0.1611, -0.0679],\n        [-0.0098, -0.1031, -0.0701,  0.1685,  0.1328, -0.0866, -0.3028,  0.2273],\n        [-0.0955, -0.2985, -0.0957, -0.3147,  0.3260, -0.0893, -0.2219,  0.2915],\n        [-0.1370, -0.0637, -0.2582,  0.0030, -0.3209, -0.2199, -0.2606,  0.1078],\n        [-0.3422,  0.0200,  0.0757,  0.3389, -0.3500,  0.1841, -0.0253, -0.3378],\n        [ 0.1396,  0.1551, -0.3315,  0.0702,  0.0853,  0.2804, -0.3099, -0.1214],\n        [ 0.0049,  0.0625, -0.0544, -0.3370, -0.0762, -0.1678, -0.0742,  0.2154],\n        [-0.2154, -0.1094,  0.1182, -0.0863,  0.1249,  0.1658,  0.0683, -0.0102],\n        [ 0.1049, -0.3340, -0.2523, -0.0815,  0.1553,  0.1442,  0.0045, -0.1934],\n        [ 0.3279, -0.0524,  0.1846, -0.0355,  0.1319, -0.0662,  0.2105,  0.1839],\n        [-0.1887, -0.0402, -0.0460, -0.3216,  0.0451, -0.2798,  0.1063,  0.1111],\n        [-0.2803,  0.3530, -0.2724, -0.1831,  0.3360,  0.0116, -0.1754,  0.3253],\n        [-0.2288, -0.3298, -0.3348, -0.2674, -0.2254,  0.2867, -0.2992, -0.3310],\n        [-0.2851, -0.0567, -0.0176, -0.2317, -0.0772, -0.1329, -0.1225, -0.2088],\n        [ 0.3457,  0.2507,  0.3023, -0.1799, -0.1974,  0.3062, -0.0953,  0.2920],\n        [ 0.3158, -0.3076,  0.3421,  0.2594,  0.3424,  0.3428,  0.0906, -0.1436],\n        [-0.3232,  0.1291,  0.2994, -0.1996, -0.2856, -0.2852,  0.1849, -0.1906],\n        [ 0.0045,  0.2011, -0.2093, -0.0385,  0.2253, -0.3384, -0.2080, -0.0203],\n        [ 0.3341,  0.2137, -0.0664,  0.0834,  0.0254, -0.1040,  0.3490, -0.3496],\n        [-0.0351, -0.1139,  0.3047,  0.1382,  0.2938,  0.0537, -0.1972, -0.0304],\n        [ 0.1944, -0.0477,  0.3410, -0.2175,  0.1793,  0.0007,  0.2050, -0.3523],\n        [ 0.2061, -0.0401, -0.3310, -0.1709, -0.2892, -0.2565, -0.2476,  0.2030],\n        [ 0.0941, -0.1840, -0.3176,  0.0856,  0.0242, -0.0952, -0.1953,  0.3328],\n        [-0.2360, -0.2048, -0.1862, -0.2603, -0.1917, -0.1743,  0.2450,  0.2236],\n        [ 0.3007, -0.3135, -0.2415,  0.1331, -0.2313,  0.0141,  0.2408,  0.2899],\n        [-0.3296, -0.0568,  0.3193,  0.1428, -0.1596, -0.1248, -0.1308, -0.1223],\n        [-0.1209,  0.3102,  0.1056, -0.0673, -0.0566, -0.2613,  0.2691, -0.2406],\n        [-0.3407, -0.2495, -0.2512,  0.1231, -0.3061, -0.2448, -0.2981,  0.1386],\n        [-0.1996, -0.1208,  0.3288,  0.1187, -0.2653, -0.2129,  0.0394,  0.1167],\n        [-0.2088,  0.0360,  0.3025,  0.2056,  0.2939,  0.3363,  0.2032, -0.0899],\n        [ 0.3529, -0.1007,  0.2326, -0.3531,  0.1007,  0.2763, -0.2741, -0.2132],\n        [-0.1384, -0.1533, -0.1615, -0.3038, -0.0811,  0.0688, -0.1391,  0.1143],\n        [-0.1509,  0.0147,  0.1530,  0.1818,  0.1914, -0.2947,  0.1361, -0.0025],\n        [ 0.3440,  0.0928, -0.1452, -0.0097,  0.2948, -0.0991,  0.0490,  0.0063],\n        [-0.0962,  0.1479,  0.3222, -0.3466, -0.1706, -0.0235,  0.3070, -0.2227],\n        [-0.1520,  0.1877,  0.1936, -0.2403,  0.1267,  0.0493,  0.2439,  0.1813],\n        [-0.1031, -0.2252, -0.0394,  0.1466,  0.1339,  0.0045, -0.0169,  0.2382],\n        [-0.2224, -0.2601,  0.2366, -0.3181,  0.2180,  0.3415, -0.2976,  0.0832],\n        [-0.2727, -0.2771,  0.1109, -0.1910, -0.0257, -0.0311,  0.3355, -0.0697],\n        [-0.3277, -0.2580,  0.2402,  0.3280, -0.1642, -0.0760,  0.0306,  0.3090],\n        [-0.2173,  0.3522,  0.2394,  0.3008,  0.1075, -0.3260, -0.3006,  0.1585],\n        [-0.1373,  0.0825, -0.0390, -0.1268, -0.2776, -0.3458,  0.0446,  0.1163],\n        [-0.2828,  0.0957, -0.1804, -0.2280,  0.1097,  0.3005, -0.1912,  0.1525],\n        [-0.0929, -0.2530, -0.1603, -0.1590, -0.2197, -0.1572,  0.1215, -0.3217],\n        [ 0.1943,  0.0097,  0.2401,  0.2216,  0.0847,  0.3437,  0.2110, -0.1903],\n        [ 0.0983, -0.0627,  0.1567,  0.0335, -0.2118,  0.1254, -0.0127,  0.3497],\n        [-0.1387,  0.2232,  0.2049, -0.1459,  0.0602, -0.0497,  0.0066,  0.0486],\n        [-0.2556,  0.3264, -0.0047,  0.1881,  0.0032,  0.3383,  0.2654, -0.2337],\n        [-0.1643,  0.2733, -0.2159,  0.0340, -0.1245, -0.2815,  0.3061, -0.0631],\n        [-0.1226,  0.1257, -0.3335,  0.2626, -0.3456,  0.2664,  0.2770,  0.2301]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.3360, -0.0019,  0.2161,  0.0517,  0.2204, -0.3061, -0.1881, -0.3018,\n         0.2512,  0.3166, -0.1757,  0.0918,  0.1380,  0.1309, -0.1371, -0.0248,\n        -0.2981,  0.3433, -0.3074,  0.0904, -0.0164,  0.1266, -0.1025,  0.2486,\n        -0.0940, -0.3154, -0.0628,  0.1841,  0.1957, -0.2947, -0.1459, -0.0566,\n         0.2011,  0.0952,  0.2344, -0.2928, -0.3521,  0.0199,  0.1223,  0.1625,\n         0.0618,  0.2882,  0.1502,  0.3018,  0.1542, -0.0438, -0.2063, -0.2613,\n        -0.2207, -0.0497, -0.2457, -0.1451,  0.1210, -0.0824,  0.0281,  0.0044,\n        -0.2192, -0.1821, -0.0967, -0.1442,  0.0614,  0.1776,  0.0106, -0.0777],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0942,  0.0965,  0.0657,  ..., -0.0532, -0.0190, -0.0595],\n        [-0.0465,  0.0027, -0.0498,  ...,  0.0447,  0.1221, -0.0603],\n        [-0.0511,  0.0892,  0.0142,  ..., -0.0983, -0.0868,  0.1239],\n        ...,\n        [-0.0890, -0.0362, -0.0429,  ..., -0.0140, -0.0819,  0.0141],\n        [ 0.0654, -0.0459, -0.0985,  ..., -0.1094,  0.0129,  0.1085],\n        [-0.1005, -0.0780,  0.0714,  ..., -0.0432, -0.0698,  0.0731]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0564,  0.1053, -0.0748,  0.0543, -0.0829, -0.1173,  0.0797,  0.0472,\n         0.1240,  0.1187,  0.1205, -0.0734,  0.1175, -0.0204,  0.0904,  0.0436,\n         0.0850,  0.0199,  0.0325,  0.0129, -0.0689,  0.0923, -0.0956,  0.0098,\n        -0.0722,  0.0411, -0.1206,  0.0942, -0.1045, -0.0889, -0.0577, -0.0648,\n         0.1183, -0.0059, -0.0325,  0.0479, -0.0607,  0.0094, -0.1167, -0.0064,\n        -0.1157,  0.0462, -0.0288,  0.0960,  0.1134, -0.1187,  0.0071,  0.0175,\n        -0.0353, -0.0153,  0.0671,  0.1218, -0.1080, -0.1094,  0.0199,  0.0923,\n         0.1008, -0.0692, -0.1062, -0.0176, -0.0243,  0.0805, -0.0398, -0.0611],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1054,  0.0888,  0.0213,  ..., -0.0085,  0.0188, -0.0979],\n        [ 0.1220,  0.0924,  0.0726,  ...,  0.1247,  0.0714,  0.0464],\n        [-0.0921, -0.0315,  0.0852,  ...,  0.0228, -0.1097, -0.0211],\n        ...,\n        [ 0.0533,  0.0996, -0.1038,  ..., -0.0219,  0.1006,  0.0330],\n        [-0.1238, -0.1119, -0.1115,  ...,  0.1025,  0.1052,  0.0235],\n        [-0.0937,  0.0279, -0.0545,  ...,  0.0838,  0.0407,  0.0379]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0833, -0.1108,  0.1121, -0.0114,  0.0471, -0.0494,  0.0753,  0.0361,\n        -0.0911, -0.0044,  0.1047,  0.0653,  0.0552, -0.0457,  0.0458,  0.0859,\n        -0.0042, -0.0516,  0.0098,  0.0416,  0.0661, -0.1172, -0.0565, -0.0394,\n        -0.1126,  0.0303,  0.0243,  0.0837, -0.0195, -0.0560,  0.0079,  0.0638],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-7.9170e-02,  2.5758e-02, -2.3570e-02,  1.0172e-01, -4.9570e-02,\n          1.0944e-02,  1.7228e-01, -1.4755e-01,  1.4135e-01, -1.5157e-01,\n         -1.4146e-02, -1.6830e-02, -1.2681e-01,  1.1152e-01,  1.5426e-01,\n          1.5057e-01,  8.8704e-02, -8.1413e-02,  1.2189e-01,  4.2357e-02,\n          9.8505e-02,  1.0699e-01,  1.6491e-01, -8.4568e-02,  1.4035e-01,\n         -5.5133e-02,  1.8327e-02,  2.4116e-02, -1.6902e-01,  6.0563e-02,\n          1.0213e-01,  7.3342e-03],\n        [-1.6078e-01,  9.4167e-02,  1.6005e-01,  1.6713e-01, -8.4519e-02,\n          1.2324e-01,  1.5329e-01,  5.0624e-02, -8.6200e-03, -2.4492e-02,\n         -7.7374e-02,  2.6752e-02,  2.3086e-02,  6.5194e-02,  3.0777e-02,\n          6.4081e-03, -1.3729e-01, -5.8700e-02,  2.4142e-02,  1.2822e-01,\n         -1.7058e-01,  1.6600e-01, -4.6292e-02, -1.4336e-01, -1.5866e-02,\n          1.5956e-01, -1.7526e-01, -1.5614e-01,  3.2996e-02,  2.8764e-02,\n          3.6958e-02, -4.1192e-02],\n        [ 5.9602e-02, -1.5995e-02,  7.3244e-02,  2.3015e-02,  5.7431e-02,\n          1.2158e-01,  2.0293e-02,  4.2901e-02,  4.9671e-02, -2.8175e-04,\n          8.9074e-02,  9.8729e-05, -1.5239e-01, -7.8410e-02, -5.9143e-02,\n         -5.5649e-02,  9.7338e-02, -1.8113e-02, -1.1236e-01,  9.0100e-02,\n         -1.6565e-01,  8.4321e-02,  1.4664e-01, -1.7514e-01,  1.4423e-01,\n          4.7145e-02,  4.1487e-02,  5.6974e-02, -1.4268e-01,  1.2523e-01,\n         -1.3990e-01,  1.2333e-01],\n        [ 1.5696e-02, -8.3175e-02, -1.0005e-01, -7.5597e-04, -8.8771e-02,\n          1.3988e-01,  1.6078e-01,  1.0327e-01,  5.4675e-02,  9.5019e-03,\n          3.6100e-02, -6.0714e-02,  1.0389e-01, -1.0748e-01,  1.2874e-01,\n         -8.1537e-02, -4.2529e-02,  8.8337e-02, -4.8047e-02,  1.5415e-01,\n          3.3537e-03,  6.6518e-02, -1.0653e-01,  1.0135e-01,  2.6713e-02,\n          1.5638e-01,  1.2505e-01, -9.4827e-03, -1.7444e-01, -8.3427e-02,\n          9.7949e-02,  9.4389e-03],\n        [-5.6430e-02, -1.0966e-01, -1.6567e-01, -5.4666e-02,  5.8029e-02,\n          1.0695e-01,  1.4395e-01, -1.2788e-01,  1.1028e-01,  1.4133e-02,\n         -1.3149e-01, -9.7177e-02,  2.2848e-02, -1.1618e-01, -1.3658e-01,\n          2.9443e-02, -8.2392e-03,  5.0838e-02, -1.1927e-01, -4.4644e-02,\n         -1.2358e-02,  2.4075e-02, -1.0493e-01,  3.7123e-02, -7.0215e-02,\n         -1.5675e-01, -1.4999e-01,  1.7619e-01,  5.9430e-02, -3.9753e-02,\n          7.0361e-02,  1.3049e-02],\n        [-3.7031e-02, -1.3481e-01,  1.5884e-01,  1.7472e-02, -1.6364e-01,\n          5.2664e-02,  3.4653e-02,  6.0256e-02,  5.2858e-02,  1.3617e-01,\n         -4.1324e-02, -1.2926e-01,  1.1730e-01,  7.4818e-02, -1.4636e-01,\n         -5.3014e-02,  1.4667e-01,  1.3580e-02, -1.4137e-01, -7.5196e-02,\n          9.4278e-02,  9.5145e-02, -8.7589e-02, -3.9456e-02, -6.7684e-02,\n          1.1486e-01,  1.6682e-01, -9.3443e-02,  5.0951e-02,  2.7927e-02,\n         -6.9000e-02,  5.4418e-02],\n        [ 1.4456e-01,  5.7438e-02, -2.4172e-02,  1.2382e-02,  7.8323e-02,\n          1.5578e-01, -4.0676e-02, -5.4075e-02, -2.2099e-02,  4.9354e-02,\n         -7.4343e-02, -1.5159e-01, -1.3463e-01, -1.2676e-01,  1.2409e-01,\n         -1.1188e-01, -7.0362e-02,  8.8134e-02, -3.2139e-04,  9.7093e-02,\n         -1.1251e-01,  1.4958e-01, -1.2364e-01, -2.6023e-02, -1.4325e-01,\n         -1.7324e-01, -2.8524e-03,  5.4667e-02, -9.1452e-02, -1.2513e-01,\n          1.1190e-02, -4.7048e-02],\n        [ 1.5068e-01, -9.8204e-02,  2.4372e-02, -1.4039e-01,  1.5814e-01,\n          1.5442e-01, -5.9275e-03, -1.6517e-01, -1.3173e-01,  1.7580e-01,\n          4.7706e-02, -1.5345e-01,  1.6908e-01,  8.4091e-02, -1.6409e-01,\n          1.5239e-01, -1.6395e-01,  8.3722e-02,  1.4731e-01, -1.9799e-02,\n          9.9852e-02, -1.2761e-01,  1.7323e-01, -4.5388e-02,  8.2105e-02,\n          1.4729e-01, -9.1177e-02,  1.5911e-01,  4.0309e-02,  6.4734e-02,\n          1.3991e-02,  1.6654e-01],\n        [-1.2851e-01, -1.3028e-01,  1.6369e-02, -8.5696e-02,  6.8594e-02,\n          9.7185e-02, -1.0178e-01,  1.0605e-01, -1.5446e-01,  3.7920e-02,\n         -1.5754e-01, -1.3080e-01, -5.1330e-02,  9.3962e-02,  1.7016e-01,\n          9.7792e-02,  8.7939e-05,  2.2150e-02,  1.1704e-01, -1.2456e-01,\n         -6.4419e-02, -1.4497e-01, -7.8373e-02, -1.0284e-01, -1.0618e-01,\n          4.9447e-02,  1.3514e-01,  1.7475e-01, -9.5780e-02, -1.1101e-03,\n          1.9088e-02,  7.1700e-02],\n        [-1.6011e-01, -9.4405e-02,  2.9299e-02, -1.1847e-01, -8.6035e-02,\n          9.3410e-02, -1.2377e-01,  8.1899e-02,  1.5547e-01,  6.0591e-02,\n         -8.6522e-02,  7.3627e-02,  1.2029e-01,  1.0511e-01,  5.0102e-02,\n         -1.5825e-01,  1.4148e-01, -8.3554e-02, -4.4998e-02,  1.1345e-01,\n          8.4632e-02, -5.7932e-02,  7.9828e-02,  3.7876e-02,  3.8799e-02,\n          1.9759e-02, -5.0730e-02,  2.9747e-02,  1.4578e-01, -2.7485e-02,\n         -1.1368e-01,  8.4749e-02],\n        [ 7.5028e-03,  1.3245e-01, -1.5327e-01, -1.5287e-01, -1.3751e-01,\n         -5.6938e-02, -5.0643e-02,  4.6636e-02, -1.4503e-01, -1.3981e-01,\n          3.4144e-02, -1.7834e-02,  1.2125e-01, -8.2859e-02, -7.5395e-02,\n         -6.8728e-02, -1.3417e-01, -2.3076e-02, -1.4467e-01,  5.8683e-03,\n         -9.4573e-02,  1.4520e-02, -1.2573e-01, -7.0265e-04,  1.5276e-01,\n         -1.5965e-01,  1.1008e-02, -1.1164e-01, -2.4355e-02,  1.6986e-01,\n         -7.0088e-02, -9.2813e-02],\n        [ 1.2846e-01,  8.9836e-02, -3.8639e-02,  8.0213e-02, -4.9762e-02,\n          1.1294e-02,  1.4355e-01,  8.4360e-02,  4.4086e-02, -2.4725e-02,\n          1.0953e-01,  4.1345e-02,  4.4625e-02, -2.0202e-03,  1.6775e-01,\n          8.4788e-02,  1.0621e-01, -9.9917e-02, -1.2829e-01,  1.0969e-01,\n         -1.4531e-02, -1.3622e-01,  9.8911e-02, -6.9286e-02,  4.4771e-02,\n          1.2043e-01,  2.5417e-02,  1.6105e-01,  9.2175e-02, -6.2241e-02,\n         -1.6503e-02, -9.2128e-02],\n        [-4.0387e-02, -1.0283e-01,  1.0296e-01,  8.4583e-03,  1.7194e-01,\n         -1.5738e-01,  1.5836e-01,  1.7319e-01, -1.3191e-01,  9.6711e-02,\n         -1.7296e-01,  1.3154e-01,  1.6694e-01,  1.2556e-01, -1.5024e-01,\n          1.1883e-01,  1.0042e-01,  9.5688e-02,  9.8518e-02,  1.6058e-01,\n          2.1848e-02, -8.3919e-03, -5.1840e-02,  1.1127e-02,  1.3602e-01,\n         -1.2064e-01,  3.1543e-02,  1.5873e-01,  8.0092e-02,  1.4406e-01,\n         -6.6870e-03, -2.3206e-02],\n        [-2.0188e-02,  3.5162e-02,  1.1896e-01, -2.4052e-02,  8.3708e-02,\n          1.4482e-01, -7.3585e-03, -1.3822e-01, -1.0216e-01,  5.0596e-02,\n         -6.0265e-02,  1.3743e-01, -5.8509e-02, -1.2160e-01, -9.8990e-02,\n          1.5248e-01,  1.5550e-01, -1.1442e-01, -1.1669e-01, -1.6270e-01,\n         -4.0666e-02,  6.8569e-02,  6.8004e-02, -1.6822e-02, -2.5819e-02,\n         -3.2085e-02, -8.1852e-02, -1.6940e-01,  4.7652e-02,  1.4791e-01,\n         -7.0046e-02, -7.4302e-02],\n        [-1.0541e-01, -5.9840e-03,  1.5735e-01,  9.3777e-06,  1.2460e-02,\n          1.3355e-02,  1.6678e-01,  1.1793e-01,  1.0832e-01,  1.6576e-01,\n         -1.6007e-01, -1.3893e-01, -9.9740e-02, -4.8867e-02,  4.6387e-02,\n          9.6333e-02, -5.0046e-02, -8.7068e-02, -3.2879e-02, -1.2109e-01,\n         -1.1074e-01, -1.5123e-01, -1.0233e-01, -5.1051e-02,  1.2553e-01,\n         -1.5735e-01, -1.0581e-01,  3.1798e-03, -6.0259e-02, -1.3765e-01,\n          1.1736e-01,  1.5235e-01],\n        [-1.4263e-01,  4.0620e-02, -7.1959e-02, -1.1460e-01, -1.7230e-01,\n          1.7166e-01, -1.1164e-01,  1.2900e-01,  2.2963e-02,  1.0385e-01,\n         -6.0334e-02,  3.3855e-02,  1.4590e-01, -1.9797e-02, -4.4801e-02,\n          4.6484e-03, -6.2774e-02,  9.1695e-02,  1.7111e-01,  7.2009e-02,\n         -8.6681e-02,  1.2619e-01, -1.9880e-02,  3.0194e-02, -1.6837e-01,\n          9.3265e-02, -1.7359e-03, -7.8579e-02,  8.7519e-02, -2.5010e-02,\n         -8.1971e-02,  1.3954e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0569,  0.1038, -0.1735, -0.1516, -0.0326,  0.1340,  0.0109,  0.0494,\n         0.1376, -0.0813,  0.0628,  0.0727,  0.1620, -0.0747, -0.0841,  0.1211],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0229, -0.1950,  0.0194,  0.0764, -0.0451, -0.0425, -0.1554,  0.0296,\n         -0.2201,  0.0552, -0.2209, -0.0748,  0.1206,  0.0003, -0.1206,  0.1002],\n        [ 0.1918,  0.0369,  0.1007,  0.2348,  0.0978, -0.0779, -0.1940, -0.0307,\n          0.2022,  0.0751,  0.1532,  0.1355,  0.1431,  0.2475,  0.1904, -0.1484],\n        [ 0.0129, -0.0222,  0.0287,  0.0909, -0.2042, -0.0327,  0.1170, -0.0866,\n          0.2436,  0.1208, -0.1676, -0.0911,  0.0262,  0.1514,  0.2385,  0.1712],\n        [-0.1624,  0.0711,  0.2180, -0.1153,  0.1002,  0.0616,  0.0301,  0.1978,\n         -0.1388,  0.0793, -0.0127, -0.0214, -0.0054, -0.2359,  0.0068, -0.2065],\n        [ 0.1434, -0.0302,  0.2043,  0.0196, -0.0932,  0.2029,  0.1977, -0.1376,\n         -0.1063, -0.1301, -0.0480, -0.1235, -0.1022, -0.0802,  0.0632,  0.2140],\n        [ 0.2351,  0.0962,  0.2138,  0.1859, -0.1741,  0.0331, -0.2424, -0.0768,\n         -0.0728,  0.1111,  0.1355,  0.0391,  0.0416,  0.2325, -0.0425,  0.0516],\n        [ 0.0814,  0.2166, -0.0875, -0.2406,  0.0447,  0.0434,  0.1919,  0.0909,\n          0.1454, -0.1161,  0.0150, -0.1925,  0.2451,  0.1173,  0.1636,  0.2172],\n        [-0.0007,  0.1256, -0.2347,  0.0202, -0.1048, -0.2035,  0.1884,  0.0726,\n         -0.0039, -0.1314,  0.2014, -0.2197,  0.0731, -0.0830,  0.0691, -0.1426]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1987,  0.1996,  0.1858,  0.0052, -0.0140,  0.0352, -0.1575,  0.0758],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3283,  0.1331,  0.1234,  0.1495, -0.0481,  0.1129, -0.1608,  0.2936]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1466], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x76b8593ca790>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x76b7e7c2ea90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s187020000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s187020000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}