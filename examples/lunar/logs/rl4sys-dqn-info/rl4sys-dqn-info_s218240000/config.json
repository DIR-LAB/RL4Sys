{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s218240000"
    },
    "q_lr":	0.0005,
    "seed":	218240000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x00000192E83DD0F0>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1947,  0.2313,  0.0776,  0.0701,  0.1300,  0.1245,  0.0542, -0.3415,\n        -0.2892,  0.0116, -0.2365, -0.0743, -0.2695, -0.1277, -0.3081, -0.3340,\n        -0.2092,  0.0481, -0.0751, -0.2303,  0.0718,  0.0823, -0.1367, -0.0984,\n         0.2886,  0.2223,  0.3471, -0.0686, -0.1498,  0.3347, -0.1740, -0.3395],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3354, -0.1718,  0.2749, -0.1507,  0.3130, -0.1589, -0.2622,  0.0445],\n        [ 0.0416,  0.3446, -0.2773,  0.3528,  0.3089,  0.0248, -0.0862, -0.2786],\n        [ 0.0009,  0.1135, -0.2582, -0.1401,  0.0520,  0.1209, -0.0641, -0.3361],\n        [ 0.1504,  0.3147, -0.1102, -0.0132, -0.1334, -0.1182,  0.0565,  0.1494],\n        [ 0.0799, -0.2094, -0.3504,  0.0219,  0.3315,  0.3262, -0.0110,  0.2458],\n        [ 0.2463, -0.1152, -0.2962,  0.0629,  0.2705, -0.1314,  0.3509, -0.2212],\n        [ 0.2282, -0.1296, -0.2190,  0.3005, -0.2442,  0.2668,  0.2643,  0.1995],\n        [-0.2627,  0.1372, -0.0888, -0.0456, -0.1784,  0.0632, -0.2378, -0.3197],\n        [-0.1326, -0.2448, -0.0260, -0.0013,  0.0799,  0.2929,  0.3039,  0.0810],\n        [ 0.0018,  0.0094,  0.2430,  0.2704,  0.0225, -0.2850,  0.1302, -0.3228],\n        [-0.1954,  0.1015,  0.0650, -0.3065, -0.0556, -0.2494,  0.1673,  0.2114],\n        [-0.0053,  0.0245,  0.3296, -0.1653,  0.1405, -0.2668, -0.2187,  0.2349],\n        [-0.0315,  0.1998, -0.2439,  0.2918, -0.1097, -0.3286, -0.3346, -0.2657],\n        [ 0.0361, -0.2403,  0.0631, -0.2366,  0.1781, -0.0986, -0.1622, -0.3376],\n        [-0.1490, -0.1091,  0.2791,  0.0225,  0.2308, -0.1506, -0.1368,  0.2830],\n        [-0.1702,  0.1929,  0.2643, -0.1367, -0.3012, -0.0689, -0.2281, -0.2552],\n        [-0.1404, -0.3329,  0.1029,  0.0010, -0.1783, -0.2320, -0.3350, -0.1374],\n        [ 0.1391,  0.1169,  0.1381,  0.1405,  0.0622, -0.1562,  0.2963,  0.1499],\n        [-0.0208,  0.2627, -0.2631,  0.0367, -0.2491,  0.0436, -0.1107, -0.3210],\n        [ 0.3105, -0.2832,  0.1255,  0.0666, -0.2119,  0.2617, -0.0353, -0.3332],\n        [ 0.0408,  0.2562, -0.1570,  0.0657, -0.2568,  0.0259, -0.2610, -0.0523],\n        [ 0.1368,  0.1431,  0.0639, -0.1310, -0.0242, -0.1333,  0.2349,  0.2844],\n        [-0.2650, -0.2227,  0.0081,  0.3504, -0.2628,  0.0826, -0.0077, -0.0625],\n        [-0.2921,  0.0229,  0.2260,  0.0762, -0.2444,  0.3362, -0.0035, -0.0104],\n        [ 0.1005,  0.3185, -0.1944,  0.3185, -0.0045, -0.2847,  0.1770, -0.1843],\n        [-0.1402,  0.2122, -0.3025, -0.1204, -0.3075, -0.2525,  0.0125,  0.0477],\n        [ 0.1680, -0.0576, -0.0568, -0.1918,  0.1042,  0.1216, -0.1753,  0.1016],\n        [-0.3399,  0.1109, -0.0731,  0.1108,  0.0456, -0.0793,  0.0202, -0.0045],\n        [-0.1908, -0.2529, -0.2586, -0.2755, -0.1959,  0.2072,  0.0273, -0.1301],\n        [ 0.1789, -0.0528, -0.1781, -0.3079, -0.0398, -0.3196,  0.1909, -0.0047],\n        [-0.1682,  0.1371, -0.1504,  0.1052, -0.3066, -0.1014, -0.2656,  0.1052],\n        [ 0.0078, -0.2736,  0.1213,  0.3189,  0.1728,  0.1191,  0.1083,  0.2517]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1002,  0.0390, -0.0817, -0.0421,  0.1569,  0.1004, -0.1757, -0.0358,\n         0.0454,  0.1439,  0.0697,  0.1667, -0.0686, -0.1514, -0.0181, -0.1695],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.6134e-02,  5.9922e-02,  1.0342e-02,  4.9280e-02,  9.9776e-02,\n          6.4450e-02,  2.3213e-02,  1.4749e-01, -2.7879e-02, -1.6341e-01,\n          3.0864e-02, -9.5538e-02, -3.5716e-02, -1.5356e-01,  1.1915e-01,\n         -2.6759e-03, -1.5728e-01, -2.3171e-02,  6.2554e-02, -1.5521e-01,\n         -7.1615e-02,  9.9546e-02,  1.4843e-01, -7.2842e-02,  1.3625e-01,\n          1.0291e-01, -3.4012e-02, -1.4400e-01, -2.6297e-02, -2.4763e-02,\n         -8.9991e-02, -1.6315e-01],\n        [ 1.3523e-01, -3.6700e-02,  4.2233e-03,  9.3597e-02, -9.3751e-02,\n          1.6161e-01, -1.1091e-01,  1.3980e-01,  5.2399e-02, -1.4403e-01,\n          7.3112e-02,  1.6420e-01, -1.4258e-01, -4.9113e-02, -6.4577e-03,\n          9.7178e-02, -4.8809e-02, -1.7418e-01, -2.5513e-02, -1.1403e-02,\n         -1.5675e-01, -9.6674e-02, -1.6467e-01, -3.8842e-02, -4.8016e-02,\n         -1.1037e-01, -6.3155e-03, -8.5382e-02, -5.1436e-02, -1.2029e-01,\n          6.6902e-02, -1.6193e-01],\n        [-1.1371e-01,  5.3313e-02,  1.0603e-01, -1.2694e-01, -1.4141e-01,\n         -1.5337e-01,  2.9809e-02, -6.9425e-02, -7.8490e-02, -2.2722e-02,\n         -5.4329e-02,  1.1550e-01,  6.5766e-02,  1.7455e-02, -3.4282e-02,\n          9.4530e-02, -1.3525e-01,  1.3415e-01,  9.1504e-02,  1.3654e-01,\n         -7.0478e-02,  2.3124e-02,  3.4172e-02, -1.4482e-01, -9.4052e-02,\n         -1.6179e-01,  1.1315e-01,  6.1312e-02, -1.7355e-01, -1.2911e-01,\n         -8.3314e-02,  1.6011e-01],\n        [ 1.1063e-01, -1.6519e-01,  1.4932e-01,  2.1563e-02, -6.9858e-02,\n          7.1177e-02,  4.9865e-02,  7.1217e-02,  1.2881e-01,  1.4513e-01,\n          1.0139e-01,  6.7149e-03,  1.7128e-01,  1.0268e-01, -1.1371e-01,\n          4.4481e-02,  1.5074e-02, -6.1243e-02, -3.7771e-02, -5.9947e-02,\n         -8.6971e-02,  1.0284e-01,  9.9141e-02,  1.0408e-01, -4.4501e-02,\n          1.2138e-01, -1.1749e-01,  1.2909e-01, -1.6989e-01,  2.9789e-02,\n         -1.4185e-01, -4.5295e-02],\n        [ 1.5474e-01,  2.6877e-02, -1.1826e-01,  1.7453e-01, -1.6852e-02,\n          1.5375e-01, -6.0633e-02, -1.2698e-01,  6.5534e-02,  1.3581e-01,\n          3.6112e-02, -2.7946e-02,  1.5186e-01, -1.3479e-01,  1.0661e-01,\n          1.2808e-01, -1.7046e-01, -5.1849e-02, -1.1906e-01,  4.6974e-02,\n          1.5988e-01, -3.9942e-02, -1.3084e-02,  1.1108e-01,  1.3350e-01,\n         -3.3237e-02, -1.3324e-01,  4.1746e-02,  3.3707e-02,  1.5865e-01,\n          1.3736e-01,  1.3142e-01],\n        [ 1.2616e-01,  8.5860e-02,  3.4532e-03,  1.4399e-01, -4.9660e-02,\n         -4.4534e-02, -1.1971e-01, -9.3368e-02, -8.6895e-02, -1.3445e-01,\n          5.6403e-02,  1.6050e-01, -1.6957e-01, -6.6985e-02,  1.2179e-01,\n         -1.5127e-01,  7.6991e-02, -4.4049e-03, -1.5168e-02,  2.6980e-02,\n          2.1204e-02,  1.4235e-01,  1.1191e-01,  9.0273e-02, -9.5180e-02,\n         -1.7529e-01,  1.7378e-01, -1.3310e-01, -8.2978e-02, -8.2297e-02,\n          1.6836e-01,  7.5716e-02],\n        [-6.4868e-02,  7.3533e-02, -1.4432e-01,  7.1628e-02,  2.4076e-02,\n          1.4603e-01, -1.6896e-01, -1.2825e-01,  1.6695e-01, -7.7804e-02,\n          7.2601e-03, -8.2901e-03, -1.6883e-01,  8.9188e-02, -1.1441e-01,\n         -4.8768e-02, -1.7552e-01,  1.3762e-01, -1.0460e-01, -1.5739e-01,\n          1.3002e-01, -5.8951e-02,  5.0927e-02,  1.4958e-01,  1.5093e-01,\n         -7.1144e-02,  4.1293e-02,  1.5984e-01, -5.9043e-02, -5.6839e-02,\n         -1.6940e-01,  1.5170e-01],\n        [-4.3035e-02,  1.6500e-01,  1.0143e-01,  8.4331e-02, -1.3481e-01,\n         -6.6549e-02, -1.2068e-01,  3.9329e-02, -1.2214e-02, -1.6473e-01,\n          1.0287e-02, -1.7567e-01,  1.4256e-04,  1.2717e-01, -1.0287e-01,\n         -1.5512e-01, -1.1364e-01, -7.9802e-02, -1.7573e-01,  5.0456e-02,\n         -1.5486e-02, -1.6174e-01,  7.0051e-03,  1.0525e-01, -4.3281e-02,\n         -4.4620e-02,  7.9647e-02,  5.9483e-02, -1.6000e-01, -6.7340e-02,\n          1.6177e-01,  7.5221e-02],\n        [-1.7390e-01,  1.7327e-01, -3.4531e-02, -1.5938e-01,  1.1385e-01,\n          4.6496e-02, -1.1487e-01,  3.2965e-02,  3.4630e-02, -1.7102e-01,\n         -3.7333e-02,  1.1103e-01,  1.6559e-01, -1.5305e-01, -1.5351e-01,\n         -3.2715e-02,  1.3343e-01,  7.1717e-02, -1.6452e-01,  8.2286e-02,\n         -4.2387e-02,  1.1224e-01,  6.2646e-02,  1.2951e-03,  1.1420e-01,\n         -1.3187e-01, -1.3132e-01,  8.1860e-02,  1.6233e-02,  1.3477e-01,\n          2.4280e-02, -3.9418e-02],\n        [ 4.3508e-02, -5.0223e-02,  1.1777e-01, -1.3626e-01,  1.3294e-01,\n         -1.0744e-01,  2.7724e-02, -6.9673e-02, -1.3746e-01,  1.6993e-03,\n         -8.7244e-02,  1.5716e-01,  1.5168e-01, -5.1032e-02,  1.1570e-01,\n         -1.3296e-01,  6.0210e-02, -6.6610e-02, -6.5687e-02,  1.2470e-01,\n         -5.5638e-02,  1.6725e-01,  1.7400e-01, -5.4669e-02,  1.2323e-01,\n          6.8276e-02, -3.6686e-02, -1.7617e-01, -4.8471e-02, -1.2750e-01,\n          1.5113e-01,  1.6876e-01],\n        [ 4.2733e-02, -1.3296e-01,  1.5213e-01, -9.9153e-02,  1.0537e-01,\n         -1.1856e-01,  1.5598e-01,  1.1793e-01, -1.5025e-01,  1.2514e-01,\n          1.0171e-02, -1.6743e-01,  1.7120e-01,  1.5901e-01, -8.7494e-02,\n          5.3292e-02,  1.4354e-01,  6.0567e-02, -1.2250e-01, -5.7700e-02,\n          7.8381e-02, -1.5276e-01, -1.0154e-01, -1.5957e-01,  1.6296e-01,\n         -8.0343e-02, -6.7004e-02,  5.1476e-02,  9.3466e-02,  4.0150e-02,\n          7.4355e-02, -1.3474e-01],\n        [-6.5475e-02,  1.3658e-01, -9.7082e-02, -1.4035e-01, -1.7337e-01,\n          1.6957e-02,  1.2777e-01, -1.6372e-01,  1.6585e-01,  1.5899e-01,\n          1.4809e-01,  1.1283e-01, -5.2816e-02, -2.9039e-03,  1.5303e-01,\n          2.3872e-02,  1.1833e-01, -4.1892e-02,  6.8199e-02, -1.4760e-01,\n         -8.0409e-02, -3.4979e-02, -1.7360e-01,  6.2031e-02, -1.1618e-01,\n         -1.6153e-01,  7.1461e-02,  1.3943e-01,  1.4543e-01, -1.3975e-01,\n         -2.7829e-03,  1.4672e-02],\n        [-5.5732e-02,  1.2992e-01,  7.6005e-02, -1.0786e-02, -1.3914e-02,\n          4.0537e-02, -5.0218e-02, -7.0527e-02,  9.5206e-02,  9.9186e-02,\n         -8.1037e-02,  1.3654e-01,  4.6955e-02,  1.5911e-01, -5.8232e-02,\n          1.4869e-01,  1.1112e-01, -1.5846e-02,  1.0714e-02, -7.0650e-02,\n          7.0027e-03, -1.3930e-01, -6.9749e-02,  1.4244e-01, -1.2741e-02,\n          1.0962e-01,  1.7336e-01,  8.2044e-02,  1.7907e-02, -1.3872e-01,\n         -6.9801e-02, -1.2998e-01],\n        [-9.6624e-02,  4.3300e-04, -5.8108e-02, -1.1011e-01,  9.0507e-03,\n         -8.8043e-02,  1.0815e-01,  1.2568e-01,  7.9541e-02, -1.4807e-01,\n          1.6030e-01,  9.7995e-02, -3.9271e-03,  8.7290e-02,  1.7327e-01,\n         -9.2590e-02,  5.1825e-02,  4.6521e-02,  4.3804e-02,  8.3433e-02,\n          1.6986e-01, -1.1480e-01,  7.8441e-02,  1.1381e-01,  1.4648e-01,\n         -5.5564e-03,  6.7023e-02,  1.7417e-01,  6.5144e-02, -1.8745e-02,\n         -1.7487e-01,  1.8034e-02],\n        [-5.2790e-02, -1.6598e-01,  5.0948e-02, -1.0871e-02, -6.8591e-02,\n         -9.3866e-02, -1.2471e-01,  1.1726e-01,  3.0193e-02,  1.2929e-01,\n          1.5753e-01, -1.6444e-01, -1.7582e-01,  8.4928e-02, -6.4900e-02,\n          4.4889e-02, -1.2691e-01,  8.4722e-02, -3.3943e-02,  8.2598e-02,\n          8.0148e-02, -1.3940e-01, -1.4701e-01,  1.0103e-01,  5.8823e-02,\n         -1.1332e-01,  8.0663e-02, -2.6355e-03, -2.6247e-02, -1.0148e-03,\n          9.7645e-02, -1.6309e-01],\n        [ 6.8954e-02,  9.3897e-02, -1.2494e-01,  4.2141e-03, -3.1188e-02,\n          9.5836e-02,  5.6179e-02,  7.3313e-02,  4.7262e-02, -1.4335e-01,\n          7.1270e-02, -1.7118e-01,  7.4084e-02, -1.6000e-01, -9.0752e-02,\n         -1.2639e-02,  1.7056e-01,  1.5003e-01,  6.4985e-02, -1.2998e-01,\n          3.2469e-02, -6.1082e-02, -1.7456e-01, -7.3716e-02, -1.3567e-01,\n          5.9263e-02, -1.0587e-01, -1.0003e-01,  1.5734e-01,  7.0821e-02,\n          2.5046e-02,  1.6388e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1136, -0.2402, -0.0179,  0.0370,  0.0894, -0.2274,  0.0965,  0.2174],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1180, -0.2295, -0.0911,  0.0357,  0.2190,  0.0481,  0.1981, -0.1198,\n         -0.0553,  0.0979, -0.2423, -0.1061, -0.0147, -0.0438,  0.2219,  0.0271],\n        [ 0.0569,  0.0436,  0.1226, -0.0193, -0.0610, -0.0878, -0.0194, -0.0553,\n          0.0260,  0.0130, -0.0770, -0.0884, -0.0431, -0.0527, -0.1792, -0.1783],\n        [ 0.0764,  0.2244, -0.1683, -0.1365,  0.0858,  0.1011,  0.2022,  0.1357,\n         -0.2186,  0.1743,  0.1127, -0.1380, -0.0029, -0.2196, -0.1645, -0.0394],\n        [-0.0346,  0.0784, -0.0319, -0.2470, -0.1542, -0.1058,  0.1082,  0.2283,\n          0.1944, -0.0101, -0.1085, -0.0879, -0.1223,  0.2202,  0.1554, -0.2274],\n        [-0.0912, -0.1079,  0.1497,  0.1531,  0.2005,  0.1651, -0.2375, -0.0544,\n         -0.2222, -0.1764,  0.0268, -0.2063,  0.1184, -0.2213,  0.1442,  0.1120],\n        [-0.1508,  0.1580,  0.0755,  0.0800, -0.1034,  0.1183, -0.2239, -0.1953,\n         -0.2225,  0.2146,  0.1374, -0.0570, -0.0701, -0.1317,  0.0953, -0.2403],\n        [ 0.1284,  0.0769,  0.0026,  0.1840, -0.2099,  0.2018,  0.1955,  0.1305,\n         -0.1485, -0.0339, -0.1078,  0.0329, -0.1071, -0.1427,  0.0139,  0.1680],\n        [-0.1951, -0.1870,  0.0089,  0.2362, -0.1761,  0.0163,  0.1127,  0.0912,\n         -0.0076, -0.1283,  0.0723, -0.1011, -0.0780,  0.2053,  0.1331, -0.1901]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1106], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0054, -0.0232, -0.2570, -0.3438, -0.1155, -0.2034, -0.0070,  0.0760]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.3354, -0.1718,  0.2749, -0.1507,  0.3130, -0.1589, -0.2622,  0.0445],\n        [ 0.0416,  0.3446, -0.2773,  0.3528,  0.3089,  0.0248, -0.0862, -0.2786],\n        [ 0.0009,  0.1135, -0.2582, -0.1401,  0.0520,  0.1209, -0.0641, -0.3361],\n        [ 0.1504,  0.3147, -0.1102, -0.0132, -0.1334, -0.1182,  0.0565,  0.1494],\n        [ 0.0799, -0.2094, -0.3504,  0.0219,  0.3315,  0.3262, -0.0110,  0.2458],\n        [ 0.2463, -0.1152, -0.2962,  0.0629,  0.2705, -0.1314,  0.3509, -0.2212],\n        [ 0.2282, -0.1296, -0.2190,  0.3005, -0.2442,  0.2668,  0.2643,  0.1995],\n        [-0.2627,  0.1372, -0.0888, -0.0456, -0.1784,  0.0632, -0.2378, -0.3197],\n        [-0.1326, -0.2448, -0.0260, -0.0013,  0.0799,  0.2929,  0.3039,  0.0810],\n        [ 0.0018,  0.0094,  0.2430,  0.2704,  0.0225, -0.2850,  0.1302, -0.3228],\n        [-0.1954,  0.1015,  0.0650, -0.3065, -0.0556, -0.2494,  0.1673,  0.2114],\n        [-0.0053,  0.0245,  0.3296, -0.1653,  0.1405, -0.2668, -0.2187,  0.2349],\n        [-0.0315,  0.1998, -0.2439,  0.2918, -0.1097, -0.3286, -0.3346, -0.2657],\n        [ 0.0361, -0.2403,  0.0631, -0.2366,  0.1781, -0.0986, -0.1622, -0.3376],\n        [-0.1490, -0.1091,  0.2791,  0.0225,  0.2308, -0.1506, -0.1368,  0.2830],\n        [-0.1702,  0.1929,  0.2643, -0.1367, -0.3012, -0.0689, -0.2281, -0.2552],\n        [-0.1404, -0.3329,  0.1029,  0.0010, -0.1783, -0.2320, -0.3350, -0.1374],\n        [ 0.1391,  0.1169,  0.1381,  0.1405,  0.0622, -0.1562,  0.2963,  0.1499],\n        [-0.0208,  0.2627, -0.2631,  0.0367, -0.2491,  0.0436, -0.1107, -0.3210],\n        [ 0.3105, -0.2832,  0.1255,  0.0666, -0.2119,  0.2617, -0.0353, -0.3332],\n        [ 0.0408,  0.2562, -0.1570,  0.0657, -0.2568,  0.0259, -0.2610, -0.0523],\n        [ 0.1368,  0.1431,  0.0639, -0.1310, -0.0242, -0.1333,  0.2349,  0.2844],\n        [-0.2650, -0.2227,  0.0081,  0.3504, -0.2628,  0.0826, -0.0077, -0.0625],\n        [-0.2921,  0.0229,  0.2260,  0.0762, -0.2444,  0.3362, -0.0035, -0.0104],\n        [ 0.1005,  0.3185, -0.1944,  0.3185, -0.0045, -0.2847,  0.1770, -0.1843],\n        [-0.1402,  0.2122, -0.3025, -0.1204, -0.3075, -0.2525,  0.0125,  0.0477],\n        [ 0.1680, -0.0576, -0.0568, -0.1918,  0.1042,  0.1216, -0.1753,  0.1016],\n        [-0.3399,  0.1109, -0.0731,  0.1108,  0.0456, -0.0793,  0.0202, -0.0045],\n        [-0.1908, -0.2529, -0.2586, -0.2755, -0.1959,  0.2072,  0.0273, -0.1301],\n        [ 0.1789, -0.0528, -0.1781, -0.3079, -0.0398, -0.3196,  0.1909, -0.0047],\n        [-0.1682,  0.1371, -0.1504,  0.1052, -0.3066, -0.1014, -0.2656,  0.1052],\n        [ 0.0078, -0.2736,  0.1213,  0.3189,  0.1728,  0.1191,  0.1083,  0.2517]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1947,  0.2313,  0.0776,  0.0701,  0.1300,  0.1245,  0.0542, -0.3415,\n        -0.2892,  0.0116, -0.2365, -0.0743, -0.2695, -0.1277, -0.3081, -0.3340,\n        -0.2092,  0.0481, -0.0751, -0.2303,  0.0718,  0.0823, -0.1367, -0.0984,\n         0.2886,  0.2223,  0.3471, -0.0686, -0.1498,  0.3347, -0.1740, -0.3395],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-8.6134e-02,  5.9922e-02,  1.0342e-02,  4.9280e-02,  9.9776e-02,\n          6.4450e-02,  2.3213e-02,  1.4749e-01, -2.7879e-02, -1.6341e-01,\n          3.0864e-02, -9.5538e-02, -3.5716e-02, -1.5356e-01,  1.1915e-01,\n         -2.6759e-03, -1.5728e-01, -2.3171e-02,  6.2554e-02, -1.5521e-01,\n         -7.1615e-02,  9.9546e-02,  1.4843e-01, -7.2842e-02,  1.3625e-01,\n          1.0291e-01, -3.4012e-02, -1.4400e-01, -2.6297e-02, -2.4763e-02,\n         -8.9991e-02, -1.6315e-01],\n        [ 1.3523e-01, -3.6700e-02,  4.2233e-03,  9.3597e-02, -9.3751e-02,\n          1.6161e-01, -1.1091e-01,  1.3980e-01,  5.2399e-02, -1.4403e-01,\n          7.3112e-02,  1.6420e-01, -1.4258e-01, -4.9113e-02, -6.4577e-03,\n          9.7178e-02, -4.8809e-02, -1.7418e-01, -2.5513e-02, -1.1403e-02,\n         -1.5675e-01, -9.6674e-02, -1.6467e-01, -3.8842e-02, -4.8016e-02,\n         -1.1037e-01, -6.3155e-03, -8.5382e-02, -5.1436e-02, -1.2029e-01,\n          6.6902e-02, -1.6193e-01],\n        [-1.1371e-01,  5.3313e-02,  1.0603e-01, -1.2694e-01, -1.4141e-01,\n         -1.5337e-01,  2.9809e-02, -6.9425e-02, -7.8490e-02, -2.2722e-02,\n         -5.4329e-02,  1.1550e-01,  6.5766e-02,  1.7455e-02, -3.4282e-02,\n          9.4530e-02, -1.3525e-01,  1.3415e-01,  9.1504e-02,  1.3654e-01,\n         -7.0478e-02,  2.3124e-02,  3.4172e-02, -1.4482e-01, -9.4052e-02,\n         -1.6179e-01,  1.1315e-01,  6.1312e-02, -1.7355e-01, -1.2911e-01,\n         -8.3314e-02,  1.6011e-01],\n        [ 1.1063e-01, -1.6519e-01,  1.4932e-01,  2.1563e-02, -6.9858e-02,\n          7.1177e-02,  4.9865e-02,  7.1217e-02,  1.2881e-01,  1.4513e-01,\n          1.0139e-01,  6.7149e-03,  1.7128e-01,  1.0268e-01, -1.1371e-01,\n          4.4481e-02,  1.5074e-02, -6.1243e-02, -3.7771e-02, -5.9947e-02,\n         -8.6971e-02,  1.0284e-01,  9.9141e-02,  1.0408e-01, -4.4501e-02,\n          1.2138e-01, -1.1749e-01,  1.2909e-01, -1.6989e-01,  2.9789e-02,\n         -1.4185e-01, -4.5295e-02],\n        [ 1.5474e-01,  2.6877e-02, -1.1826e-01,  1.7453e-01, -1.6852e-02,\n          1.5375e-01, -6.0633e-02, -1.2698e-01,  6.5534e-02,  1.3581e-01,\n          3.6112e-02, -2.7946e-02,  1.5186e-01, -1.3479e-01,  1.0661e-01,\n          1.2808e-01, -1.7046e-01, -5.1849e-02, -1.1906e-01,  4.6974e-02,\n          1.5988e-01, -3.9942e-02, -1.3084e-02,  1.1108e-01,  1.3350e-01,\n         -3.3237e-02, -1.3324e-01,  4.1746e-02,  3.3707e-02,  1.5865e-01,\n          1.3736e-01,  1.3142e-01],\n        [ 1.2616e-01,  8.5860e-02,  3.4532e-03,  1.4399e-01, -4.9660e-02,\n         -4.4534e-02, -1.1971e-01, -9.3368e-02, -8.6895e-02, -1.3445e-01,\n          5.6403e-02,  1.6050e-01, -1.6957e-01, -6.6985e-02,  1.2179e-01,\n         -1.5127e-01,  7.6991e-02, -4.4049e-03, -1.5168e-02,  2.6980e-02,\n          2.1204e-02,  1.4235e-01,  1.1191e-01,  9.0273e-02, -9.5180e-02,\n         -1.7529e-01,  1.7378e-01, -1.3310e-01, -8.2978e-02, -8.2297e-02,\n          1.6836e-01,  7.5716e-02],\n        [-6.4868e-02,  7.3533e-02, -1.4432e-01,  7.1628e-02,  2.4076e-02,\n          1.4603e-01, -1.6896e-01, -1.2825e-01,  1.6695e-01, -7.7804e-02,\n          7.2601e-03, -8.2901e-03, -1.6883e-01,  8.9188e-02, -1.1441e-01,\n         -4.8768e-02, -1.7552e-01,  1.3762e-01, -1.0460e-01, -1.5739e-01,\n          1.3002e-01, -5.8951e-02,  5.0927e-02,  1.4958e-01,  1.5093e-01,\n         -7.1144e-02,  4.1293e-02,  1.5984e-01, -5.9043e-02, -5.6839e-02,\n         -1.6940e-01,  1.5170e-01],\n        [-4.3035e-02,  1.6500e-01,  1.0143e-01,  8.4331e-02, -1.3481e-01,\n         -6.6549e-02, -1.2068e-01,  3.9329e-02, -1.2214e-02, -1.6473e-01,\n          1.0287e-02, -1.7567e-01,  1.4256e-04,  1.2717e-01, -1.0287e-01,\n         -1.5512e-01, -1.1364e-01, -7.9802e-02, -1.7573e-01,  5.0456e-02,\n         -1.5486e-02, -1.6174e-01,  7.0051e-03,  1.0525e-01, -4.3281e-02,\n         -4.4620e-02,  7.9647e-02,  5.9483e-02, -1.6000e-01, -6.7340e-02,\n          1.6177e-01,  7.5221e-02],\n        [-1.7390e-01,  1.7327e-01, -3.4531e-02, -1.5938e-01,  1.1385e-01,\n          4.6496e-02, -1.1487e-01,  3.2965e-02,  3.4630e-02, -1.7102e-01,\n         -3.7333e-02,  1.1103e-01,  1.6559e-01, -1.5305e-01, -1.5351e-01,\n         -3.2715e-02,  1.3343e-01,  7.1717e-02, -1.6452e-01,  8.2286e-02,\n         -4.2387e-02,  1.1224e-01,  6.2646e-02,  1.2951e-03,  1.1420e-01,\n         -1.3187e-01, -1.3132e-01,  8.1860e-02,  1.6233e-02,  1.3477e-01,\n          2.4280e-02, -3.9418e-02],\n        [ 4.3508e-02, -5.0223e-02,  1.1777e-01, -1.3626e-01,  1.3294e-01,\n         -1.0744e-01,  2.7724e-02, -6.9673e-02, -1.3746e-01,  1.6993e-03,\n         -8.7244e-02,  1.5716e-01,  1.5168e-01, -5.1032e-02,  1.1570e-01,\n         -1.3296e-01,  6.0210e-02, -6.6610e-02, -6.5687e-02,  1.2470e-01,\n         -5.5638e-02,  1.6725e-01,  1.7400e-01, -5.4669e-02,  1.2323e-01,\n          6.8276e-02, -3.6686e-02, -1.7617e-01, -4.8471e-02, -1.2750e-01,\n          1.5113e-01,  1.6876e-01],\n        [ 4.2733e-02, -1.3296e-01,  1.5213e-01, -9.9153e-02,  1.0537e-01,\n         -1.1856e-01,  1.5598e-01,  1.1793e-01, -1.5025e-01,  1.2514e-01,\n          1.0171e-02, -1.6743e-01,  1.7120e-01,  1.5901e-01, -8.7494e-02,\n          5.3292e-02,  1.4354e-01,  6.0567e-02, -1.2250e-01, -5.7700e-02,\n          7.8381e-02, -1.5276e-01, -1.0154e-01, -1.5957e-01,  1.6296e-01,\n         -8.0343e-02, -6.7004e-02,  5.1476e-02,  9.3466e-02,  4.0150e-02,\n          7.4355e-02, -1.3474e-01],\n        [-6.5475e-02,  1.3658e-01, -9.7082e-02, -1.4035e-01, -1.7337e-01,\n          1.6957e-02,  1.2777e-01, -1.6372e-01,  1.6585e-01,  1.5899e-01,\n          1.4809e-01,  1.1283e-01, -5.2816e-02, -2.9039e-03,  1.5303e-01,\n          2.3872e-02,  1.1833e-01, -4.1892e-02,  6.8199e-02, -1.4760e-01,\n         -8.0409e-02, -3.4979e-02, -1.7360e-01,  6.2031e-02, -1.1618e-01,\n         -1.6153e-01,  7.1461e-02,  1.3943e-01,  1.4543e-01, -1.3975e-01,\n         -2.7829e-03,  1.4672e-02],\n        [-5.5732e-02,  1.2992e-01,  7.6005e-02, -1.0786e-02, -1.3914e-02,\n          4.0537e-02, -5.0218e-02, -7.0527e-02,  9.5206e-02,  9.9186e-02,\n         -8.1037e-02,  1.3654e-01,  4.6955e-02,  1.5911e-01, -5.8232e-02,\n          1.4869e-01,  1.1112e-01, -1.5846e-02,  1.0714e-02, -7.0650e-02,\n          7.0027e-03, -1.3930e-01, -6.9749e-02,  1.4244e-01, -1.2741e-02,\n          1.0962e-01,  1.7336e-01,  8.2044e-02,  1.7907e-02, -1.3872e-01,\n         -6.9801e-02, -1.2998e-01],\n        [-9.6624e-02,  4.3300e-04, -5.8108e-02, -1.1011e-01,  9.0507e-03,\n         -8.8043e-02,  1.0815e-01,  1.2568e-01,  7.9541e-02, -1.4807e-01,\n          1.6030e-01,  9.7995e-02, -3.9271e-03,  8.7290e-02,  1.7327e-01,\n         -9.2590e-02,  5.1825e-02,  4.6521e-02,  4.3804e-02,  8.3433e-02,\n          1.6986e-01, -1.1480e-01,  7.8441e-02,  1.1381e-01,  1.4648e-01,\n         -5.5564e-03,  6.7023e-02,  1.7417e-01,  6.5144e-02, -1.8745e-02,\n         -1.7487e-01,  1.8034e-02],\n        [-5.2790e-02, -1.6598e-01,  5.0948e-02, -1.0871e-02, -6.8591e-02,\n         -9.3866e-02, -1.2471e-01,  1.1726e-01,  3.0193e-02,  1.2929e-01,\n          1.5753e-01, -1.6444e-01, -1.7582e-01,  8.4928e-02, -6.4900e-02,\n          4.4889e-02, -1.2691e-01,  8.4722e-02, -3.3943e-02,  8.2598e-02,\n          8.0148e-02, -1.3940e-01, -1.4701e-01,  1.0103e-01,  5.8823e-02,\n         -1.1332e-01,  8.0663e-02, -2.6355e-03, -2.6247e-02, -1.0148e-03,\n          9.7645e-02, -1.6309e-01],\n        [ 6.8954e-02,  9.3897e-02, -1.2494e-01,  4.2141e-03, -3.1188e-02,\n          9.5836e-02,  5.6179e-02,  7.3313e-02,  4.7262e-02, -1.4335e-01,\n          7.1270e-02, -1.7118e-01,  7.4084e-02, -1.6000e-01, -9.0752e-02,\n         -1.2639e-02,  1.7056e-01,  1.5003e-01,  6.4985e-02, -1.2998e-01,\n          3.2469e-02, -6.1082e-02, -1.7456e-01, -7.3716e-02, -1.3567e-01,\n          5.9263e-02, -1.0587e-01, -1.0003e-01,  1.5734e-01,  7.0821e-02,\n          2.5046e-02,  1.6388e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1002,  0.0390, -0.0817, -0.0421,  0.1569,  0.1004, -0.1757, -0.0358,\n         0.0454,  0.1439,  0.0697,  0.1667, -0.0686, -0.1514, -0.0181, -0.1695],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1180, -0.2295, -0.0911,  0.0357,  0.2190,  0.0481,  0.1981, -0.1198,\n         -0.0553,  0.0979, -0.2423, -0.1061, -0.0147, -0.0438,  0.2219,  0.0271],\n        [ 0.0569,  0.0436,  0.1226, -0.0193, -0.0610, -0.0878, -0.0194, -0.0553,\n          0.0260,  0.0130, -0.0770, -0.0884, -0.0431, -0.0527, -0.1792, -0.1783],\n        [ 0.0764,  0.2244, -0.1683, -0.1365,  0.0858,  0.1011,  0.2022,  0.1357,\n         -0.2186,  0.1743,  0.1127, -0.1380, -0.0029, -0.2196, -0.1645, -0.0394],\n        [-0.0346,  0.0784, -0.0319, -0.2470, -0.1542, -0.1058,  0.1082,  0.2283,\n          0.1944, -0.0101, -0.1085, -0.0879, -0.1223,  0.2202,  0.1554, -0.2274],\n        [-0.0912, -0.1079,  0.1497,  0.1531,  0.2005,  0.1651, -0.2375, -0.0544,\n         -0.2222, -0.1764,  0.0268, -0.2063,  0.1184, -0.2213,  0.1442,  0.1120],\n        [-0.1508,  0.1580,  0.0755,  0.0800, -0.1034,  0.1183, -0.2239, -0.1953,\n         -0.2225,  0.2146,  0.1374, -0.0570, -0.0701, -0.1317,  0.0953, -0.2403],\n        [ 0.1284,  0.0769,  0.0026,  0.1840, -0.2099,  0.2018,  0.1955,  0.1305,\n         -0.1485, -0.0339, -0.1078,  0.0329, -0.1071, -0.1427,  0.0139,  0.1680],\n        [-0.1951, -0.1870,  0.0089,  0.2362, -0.1761,  0.0163,  0.1127,  0.0912,\n         -0.0076, -0.1283,  0.0723, -0.1011, -0.0780,  0.2053,  0.1331, -0.1901]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1136, -0.2402, -0.0179,  0.0370,  0.0894, -0.2274,  0.0965,  0.2174],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0054, -0.0232, -0.2570, -0.3438, -0.1155, -0.2034, -0.0070,  0.0760]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1106], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x00000192A00062F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x00000192E83DCC40>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s218240000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s218240000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1947,  0.2313,  0.0776,  0.0701,  0.1300,  0.1245,  0.0542, -0.3415,\n        -0.2892,  0.0116, -0.2365, -0.0743, -0.2695, -0.1277, -0.3081, -0.3340,\n        -0.2092,  0.0481, -0.0751, -0.2303,  0.0718,  0.0823, -0.1367, -0.0984,\n         0.2886,  0.2223,  0.3471, -0.0686, -0.1498,  0.3347, -0.1740, -0.3395],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3354, -0.1718,  0.2749, -0.1507,  0.3130, -0.1589, -0.2622,  0.0445],\n        [ 0.0416,  0.3446, -0.2773,  0.3528,  0.3089,  0.0248, -0.0862, -0.2786],\n        [ 0.0009,  0.1135, -0.2582, -0.1401,  0.0520,  0.1209, -0.0641, -0.3361],\n        [ 0.1504,  0.3147, -0.1102, -0.0132, -0.1334, -0.1182,  0.0565,  0.1494],\n        [ 0.0799, -0.2094, -0.3504,  0.0219,  0.3315,  0.3262, -0.0110,  0.2458],\n        [ 0.2463, -0.1152, -0.2962,  0.0629,  0.2705, -0.1314,  0.3509, -0.2212],\n        [ 0.2282, -0.1296, -0.2190,  0.3005, -0.2442,  0.2668,  0.2643,  0.1995],\n        [-0.2627,  0.1372, -0.0888, -0.0456, -0.1784,  0.0632, -0.2378, -0.3197],\n        [-0.1326, -0.2448, -0.0260, -0.0013,  0.0799,  0.2929,  0.3039,  0.0810],\n        [ 0.0018,  0.0094,  0.2430,  0.2704,  0.0225, -0.2850,  0.1302, -0.3228],\n        [-0.1954,  0.1015,  0.0650, -0.3065, -0.0556, -0.2494,  0.1673,  0.2114],\n        [-0.0053,  0.0245,  0.3296, -0.1653,  0.1405, -0.2668, -0.2187,  0.2349],\n        [-0.0315,  0.1998, -0.2439,  0.2918, -0.1097, -0.3286, -0.3346, -0.2657],\n        [ 0.0361, -0.2403,  0.0631, -0.2366,  0.1781, -0.0986, -0.1622, -0.3376],\n        [-0.1490, -0.1091,  0.2791,  0.0225,  0.2308, -0.1506, -0.1368,  0.2830],\n        [-0.1702,  0.1929,  0.2643, -0.1367, -0.3012, -0.0689, -0.2281, -0.2552],\n        [-0.1404, -0.3329,  0.1029,  0.0010, -0.1783, -0.2320, -0.3350, -0.1374],\n        [ 0.1391,  0.1169,  0.1381,  0.1405,  0.0622, -0.1562,  0.2963,  0.1499],\n        [-0.0208,  0.2627, -0.2631,  0.0367, -0.2491,  0.0436, -0.1107, -0.3210],\n        [ 0.3105, -0.2832,  0.1255,  0.0666, -0.2119,  0.2617, -0.0353, -0.3332],\n        [ 0.0408,  0.2562, -0.1570,  0.0657, -0.2568,  0.0259, -0.2610, -0.0523],\n        [ 0.1368,  0.1431,  0.0639, -0.1310, -0.0242, -0.1333,  0.2349,  0.2844],\n        [-0.2650, -0.2227,  0.0081,  0.3504, -0.2628,  0.0826, -0.0077, -0.0625],\n        [-0.2921,  0.0229,  0.2260,  0.0762, -0.2444,  0.3362, -0.0035, -0.0104],\n        [ 0.1005,  0.3185, -0.1944,  0.3185, -0.0045, -0.2847,  0.1770, -0.1843],\n        [-0.1402,  0.2122, -0.3025, -0.1204, -0.3075, -0.2525,  0.0125,  0.0477],\n        [ 0.1680, -0.0576, -0.0568, -0.1918,  0.1042,  0.1216, -0.1753,  0.1016],\n        [-0.3399,  0.1109, -0.0731,  0.1108,  0.0456, -0.0793,  0.0202, -0.0045],\n        [-0.1908, -0.2529, -0.2586, -0.2755, -0.1959,  0.2072,  0.0273, -0.1301],\n        [ 0.1789, -0.0528, -0.1781, -0.3079, -0.0398, -0.3196,  0.1909, -0.0047],\n        [-0.1682,  0.1371, -0.1504,  0.1052, -0.3066, -0.1014, -0.2656,  0.1052],\n        [ 0.0078, -0.2736,  0.1213,  0.3189,  0.1728,  0.1191,  0.1083,  0.2517]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1002,  0.0390, -0.0817, -0.0421,  0.1569,  0.1004, -0.1757, -0.0358,\n         0.0454,  0.1439,  0.0697,  0.1667, -0.0686, -0.1514, -0.0181, -0.1695],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.6134e-02,  5.9922e-02,  1.0342e-02,  4.9280e-02,  9.9776e-02,\n          6.4450e-02,  2.3213e-02,  1.4749e-01, -2.7879e-02, -1.6341e-01,\n          3.0864e-02, -9.5538e-02, -3.5716e-02, -1.5356e-01,  1.1915e-01,\n         -2.6759e-03, -1.5728e-01, -2.3171e-02,  6.2554e-02, -1.5521e-01,\n         -7.1615e-02,  9.9546e-02,  1.4843e-01, -7.2842e-02,  1.3625e-01,\n          1.0291e-01, -3.4012e-02, -1.4400e-01, -2.6297e-02, -2.4763e-02,\n         -8.9991e-02, -1.6315e-01],\n        [ 1.3523e-01, -3.6700e-02,  4.2233e-03,  9.3597e-02, -9.3751e-02,\n          1.6161e-01, -1.1091e-01,  1.3980e-01,  5.2399e-02, -1.4403e-01,\n          7.3112e-02,  1.6420e-01, -1.4258e-01, -4.9113e-02, -6.4577e-03,\n          9.7178e-02, -4.8809e-02, -1.7418e-01, -2.5513e-02, -1.1403e-02,\n         -1.5675e-01, -9.6674e-02, -1.6467e-01, -3.8842e-02, -4.8016e-02,\n         -1.1037e-01, -6.3155e-03, -8.5382e-02, -5.1436e-02, -1.2029e-01,\n          6.6902e-02, -1.6193e-01],\n        [-1.1371e-01,  5.3313e-02,  1.0603e-01, -1.2694e-01, -1.4141e-01,\n         -1.5337e-01,  2.9809e-02, -6.9425e-02, -7.8490e-02, -2.2722e-02,\n         -5.4329e-02,  1.1550e-01,  6.5766e-02,  1.7455e-02, -3.4282e-02,\n          9.4530e-02, -1.3525e-01,  1.3415e-01,  9.1504e-02,  1.3654e-01,\n         -7.0478e-02,  2.3124e-02,  3.4172e-02, -1.4482e-01, -9.4052e-02,\n         -1.6179e-01,  1.1315e-01,  6.1312e-02, -1.7355e-01, -1.2911e-01,\n         -8.3314e-02,  1.6011e-01],\n        [ 1.1063e-01, -1.6519e-01,  1.4932e-01,  2.1563e-02, -6.9858e-02,\n          7.1177e-02,  4.9865e-02,  7.1217e-02,  1.2881e-01,  1.4513e-01,\n          1.0139e-01,  6.7149e-03,  1.7128e-01,  1.0268e-01, -1.1371e-01,\n          4.4481e-02,  1.5074e-02, -6.1243e-02, -3.7771e-02, -5.9947e-02,\n         -8.6971e-02,  1.0284e-01,  9.9141e-02,  1.0408e-01, -4.4501e-02,\n          1.2138e-01, -1.1749e-01,  1.2909e-01, -1.6989e-01,  2.9789e-02,\n         -1.4185e-01, -4.5295e-02],\n        [ 1.5474e-01,  2.6877e-02, -1.1826e-01,  1.7453e-01, -1.6852e-02,\n          1.5375e-01, -6.0633e-02, -1.2698e-01,  6.5534e-02,  1.3581e-01,\n          3.6112e-02, -2.7946e-02,  1.5186e-01, -1.3479e-01,  1.0661e-01,\n          1.2808e-01, -1.7046e-01, -5.1849e-02, -1.1906e-01,  4.6974e-02,\n          1.5988e-01, -3.9942e-02, -1.3084e-02,  1.1108e-01,  1.3350e-01,\n         -3.3237e-02, -1.3324e-01,  4.1746e-02,  3.3707e-02,  1.5865e-01,\n          1.3736e-01,  1.3142e-01],\n        [ 1.2616e-01,  8.5860e-02,  3.4532e-03,  1.4399e-01, -4.9660e-02,\n         -4.4534e-02, -1.1971e-01, -9.3368e-02, -8.6895e-02, -1.3445e-01,\n          5.6403e-02,  1.6050e-01, -1.6957e-01, -6.6985e-02,  1.2179e-01,\n         -1.5127e-01,  7.6991e-02, -4.4049e-03, -1.5168e-02,  2.6980e-02,\n          2.1204e-02,  1.4235e-01,  1.1191e-01,  9.0273e-02, -9.5180e-02,\n         -1.7529e-01,  1.7378e-01, -1.3310e-01, -8.2978e-02, -8.2297e-02,\n          1.6836e-01,  7.5716e-02],\n        [-6.4868e-02,  7.3533e-02, -1.4432e-01,  7.1628e-02,  2.4076e-02,\n          1.4603e-01, -1.6896e-01, -1.2825e-01,  1.6695e-01, -7.7804e-02,\n          7.2601e-03, -8.2901e-03, -1.6883e-01,  8.9188e-02, -1.1441e-01,\n         -4.8768e-02, -1.7552e-01,  1.3762e-01, -1.0460e-01, -1.5739e-01,\n          1.3002e-01, -5.8951e-02,  5.0927e-02,  1.4958e-01,  1.5093e-01,\n         -7.1144e-02,  4.1293e-02,  1.5984e-01, -5.9043e-02, -5.6839e-02,\n         -1.6940e-01,  1.5170e-01],\n        [-4.3035e-02,  1.6500e-01,  1.0143e-01,  8.4331e-02, -1.3481e-01,\n         -6.6549e-02, -1.2068e-01,  3.9329e-02, -1.2214e-02, -1.6473e-01,\n          1.0287e-02, -1.7567e-01,  1.4256e-04,  1.2717e-01, -1.0287e-01,\n         -1.5512e-01, -1.1364e-01, -7.9802e-02, -1.7573e-01,  5.0456e-02,\n         -1.5486e-02, -1.6174e-01,  7.0051e-03,  1.0525e-01, -4.3281e-02,\n         -4.4620e-02,  7.9647e-02,  5.9483e-02, -1.6000e-01, -6.7340e-02,\n          1.6177e-01,  7.5221e-02],\n        [-1.7390e-01,  1.7327e-01, -3.4531e-02, -1.5938e-01,  1.1385e-01,\n          4.6496e-02, -1.1487e-01,  3.2965e-02,  3.4630e-02, -1.7102e-01,\n         -3.7333e-02,  1.1103e-01,  1.6559e-01, -1.5305e-01, -1.5351e-01,\n         -3.2715e-02,  1.3343e-01,  7.1717e-02, -1.6452e-01,  8.2286e-02,\n         -4.2387e-02,  1.1224e-01,  6.2646e-02,  1.2951e-03,  1.1420e-01,\n         -1.3187e-01, -1.3132e-01,  8.1860e-02,  1.6233e-02,  1.3477e-01,\n          2.4280e-02, -3.9418e-02],\n        [ 4.3508e-02, -5.0223e-02,  1.1777e-01, -1.3626e-01,  1.3294e-01,\n         -1.0744e-01,  2.7724e-02, -6.9673e-02, -1.3746e-01,  1.6993e-03,\n         -8.7244e-02,  1.5716e-01,  1.5168e-01, -5.1032e-02,  1.1570e-01,\n         -1.3296e-01,  6.0210e-02, -6.6610e-02, -6.5687e-02,  1.2470e-01,\n         -5.5638e-02,  1.6725e-01,  1.7400e-01, -5.4669e-02,  1.2323e-01,\n          6.8276e-02, -3.6686e-02, -1.7617e-01, -4.8471e-02, -1.2750e-01,\n          1.5113e-01,  1.6876e-01],\n        [ 4.2733e-02, -1.3296e-01,  1.5213e-01, -9.9153e-02,  1.0537e-01,\n         -1.1856e-01,  1.5598e-01,  1.1793e-01, -1.5025e-01,  1.2514e-01,\n          1.0171e-02, -1.6743e-01,  1.7120e-01,  1.5901e-01, -8.7494e-02,\n          5.3292e-02,  1.4354e-01,  6.0567e-02, -1.2250e-01, -5.7700e-02,\n          7.8381e-02, -1.5276e-01, -1.0154e-01, -1.5957e-01,  1.6296e-01,\n         -8.0343e-02, -6.7004e-02,  5.1476e-02,  9.3466e-02,  4.0150e-02,\n          7.4355e-02, -1.3474e-01],\n        [-6.5475e-02,  1.3658e-01, -9.7082e-02, -1.4035e-01, -1.7337e-01,\n          1.6957e-02,  1.2777e-01, -1.6372e-01,  1.6585e-01,  1.5899e-01,\n          1.4809e-01,  1.1283e-01, -5.2816e-02, -2.9039e-03,  1.5303e-01,\n          2.3872e-02,  1.1833e-01, -4.1892e-02,  6.8199e-02, -1.4760e-01,\n         -8.0409e-02, -3.4979e-02, -1.7360e-01,  6.2031e-02, -1.1618e-01,\n         -1.6153e-01,  7.1461e-02,  1.3943e-01,  1.4543e-01, -1.3975e-01,\n         -2.7829e-03,  1.4672e-02],\n        [-5.5732e-02,  1.2992e-01,  7.6005e-02, -1.0786e-02, -1.3914e-02,\n          4.0537e-02, -5.0218e-02, -7.0527e-02,  9.5206e-02,  9.9186e-02,\n         -8.1037e-02,  1.3654e-01,  4.6955e-02,  1.5911e-01, -5.8232e-02,\n          1.4869e-01,  1.1112e-01, -1.5846e-02,  1.0714e-02, -7.0650e-02,\n          7.0027e-03, -1.3930e-01, -6.9749e-02,  1.4244e-01, -1.2741e-02,\n          1.0962e-01,  1.7336e-01,  8.2044e-02,  1.7907e-02, -1.3872e-01,\n         -6.9801e-02, -1.2998e-01],\n        [-9.6624e-02,  4.3300e-04, -5.8108e-02, -1.1011e-01,  9.0507e-03,\n         -8.8043e-02,  1.0815e-01,  1.2568e-01,  7.9541e-02, -1.4807e-01,\n          1.6030e-01,  9.7995e-02, -3.9271e-03,  8.7290e-02,  1.7327e-01,\n         -9.2590e-02,  5.1825e-02,  4.6521e-02,  4.3804e-02,  8.3433e-02,\n          1.6986e-01, -1.1480e-01,  7.8441e-02,  1.1381e-01,  1.4648e-01,\n         -5.5564e-03,  6.7023e-02,  1.7417e-01,  6.5144e-02, -1.8745e-02,\n         -1.7487e-01,  1.8034e-02],\n        [-5.2790e-02, -1.6598e-01,  5.0948e-02, -1.0871e-02, -6.8591e-02,\n         -9.3866e-02, -1.2471e-01,  1.1726e-01,  3.0193e-02,  1.2929e-01,\n          1.5753e-01, -1.6444e-01, -1.7582e-01,  8.4928e-02, -6.4900e-02,\n          4.4889e-02, -1.2691e-01,  8.4722e-02, -3.3943e-02,  8.2598e-02,\n          8.0148e-02, -1.3940e-01, -1.4701e-01,  1.0103e-01,  5.8823e-02,\n         -1.1332e-01,  8.0663e-02, -2.6355e-03, -2.6247e-02, -1.0148e-03,\n          9.7645e-02, -1.6309e-01],\n        [ 6.8954e-02,  9.3897e-02, -1.2494e-01,  4.2141e-03, -3.1188e-02,\n          9.5836e-02,  5.6179e-02,  7.3313e-02,  4.7262e-02, -1.4335e-01,\n          7.1270e-02, -1.7118e-01,  7.4084e-02, -1.6000e-01, -9.0752e-02,\n         -1.2639e-02,  1.7056e-01,  1.5003e-01,  6.4985e-02, -1.2998e-01,\n          3.2469e-02, -6.1082e-02, -1.7456e-01, -7.3716e-02, -1.3567e-01,\n          5.9263e-02, -1.0587e-01, -1.0003e-01,  1.5734e-01,  7.0821e-02,\n          2.5046e-02,  1.6388e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1136, -0.2402, -0.0179,  0.0370,  0.0894, -0.2274,  0.0965,  0.2174],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1180, -0.2295, -0.0911,  0.0357,  0.2190,  0.0481,  0.1981, -0.1198,\n         -0.0553,  0.0979, -0.2423, -0.1061, -0.0147, -0.0438,  0.2219,  0.0271],\n        [ 0.0569,  0.0436,  0.1226, -0.0193, -0.0610, -0.0878, -0.0194, -0.0553,\n          0.0260,  0.0130, -0.0770, -0.0884, -0.0431, -0.0527, -0.1792, -0.1783],\n        [ 0.0764,  0.2244, -0.1683, -0.1365,  0.0858,  0.1011,  0.2022,  0.1357,\n         -0.2186,  0.1743,  0.1127, -0.1380, -0.0029, -0.2196, -0.1645, -0.0394],\n        [-0.0346,  0.0784, -0.0319, -0.2470, -0.1542, -0.1058,  0.1082,  0.2283,\n          0.1944, -0.0101, -0.1085, -0.0879, -0.1223,  0.2202,  0.1554, -0.2274],\n        [-0.0912, -0.1079,  0.1497,  0.1531,  0.2005,  0.1651, -0.2375, -0.0544,\n         -0.2222, -0.1764,  0.0268, -0.2063,  0.1184, -0.2213,  0.1442,  0.1120],\n        [-0.1508,  0.1580,  0.0755,  0.0800, -0.1034,  0.1183, -0.2239, -0.1953,\n         -0.2225,  0.2146,  0.1374, -0.0570, -0.0701, -0.1317,  0.0953, -0.2403],\n        [ 0.1284,  0.0769,  0.0026,  0.1840, -0.2099,  0.2018,  0.1955,  0.1305,\n         -0.1485, -0.0339, -0.1078,  0.0329, -0.1071, -0.1427,  0.0139,  0.1680],\n        [-0.1951, -0.1870,  0.0089,  0.2362, -0.1761,  0.0163,  0.1127,  0.0912,\n         -0.0076, -0.1283,  0.0723, -0.1011, -0.0780,  0.2053,  0.1331, -0.1901]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1106], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0054, -0.0232, -0.2570, -0.3438, -0.1155, -0.2034, -0.0070,  0.0760]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}