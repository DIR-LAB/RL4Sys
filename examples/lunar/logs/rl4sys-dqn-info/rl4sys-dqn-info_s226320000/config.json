{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s226320000"
    },
    "q_lr":	0.0005,
    "seed":	226320000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x70178ee9ef50>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1542, -0.1859,  0.1277,  0.0911,  0.2705,  0.1897, -0.1371,  0.2744,\n        -0.0465, -0.1212, -0.2154,  0.3315, -0.1936,  0.2049,  0.1073,  0.3470,\n         0.0739,  0.2167,  0.2069,  0.2801,  0.1352,  0.2687,  0.1515, -0.1243,\n        -0.1611, -0.1053,  0.0782, -0.1434,  0.1217,  0.1961, -0.2342,  0.2425],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1051, -0.3285,  0.1564, -0.1059,  0.0616,  0.1578,  0.2526, -0.3091],\n        [ 0.2157,  0.0882, -0.2784,  0.2739, -0.0886, -0.2130, -0.3381,  0.1836],\n        [-0.2338,  0.2361, -0.1351, -0.1195, -0.3095,  0.1183, -0.0131, -0.2933],\n        [ 0.2816,  0.1962,  0.1759,  0.3024, -0.1688, -0.0461, -0.1352, -0.0094],\n        [-0.3088,  0.0719, -0.2650,  0.0050, -0.2026,  0.1519,  0.0373, -0.1617],\n        [-0.2553,  0.1260, -0.1338, -0.3426, -0.1548,  0.0541, -0.2687,  0.1072],\n        [-0.3479, -0.0107,  0.3333,  0.0016, -0.2772, -0.3346,  0.0093,  0.1270],\n        [-0.0748,  0.0360, -0.1850,  0.0483,  0.1521,  0.2850, -0.3085, -0.0340],\n        [ 0.1576, -0.1409, -0.1808,  0.0998, -0.2199,  0.0837, -0.0805, -0.1535],\n        [-0.1126,  0.0943, -0.0031, -0.0260, -0.2447, -0.2467, -0.3066,  0.1252],\n        [ 0.0197,  0.0463,  0.0728, -0.2138,  0.1708, -0.1033,  0.2653,  0.0780],\n        [ 0.1649, -0.0697,  0.1007,  0.3210,  0.3364,  0.1371, -0.1027, -0.2187],\n        [-0.1914, -0.3269, -0.0858,  0.3414, -0.3038,  0.1262, -0.3497, -0.3012],\n        [ 0.2874,  0.1441, -0.1586, -0.1602, -0.0624, -0.3404,  0.0389, -0.0853],\n        [-0.1706, -0.0122,  0.1378,  0.0252,  0.0078,  0.2230,  0.3195,  0.3294],\n        [-0.0335,  0.0440,  0.3053,  0.1733, -0.2200,  0.2624, -0.2798,  0.0206],\n        [ 0.1871, -0.1363,  0.1605, -0.0517,  0.0626,  0.0473, -0.2999,  0.2859],\n        [-0.0110, -0.0839,  0.3494,  0.2228,  0.1558, -0.2676,  0.2420,  0.1902],\n        [ 0.0414,  0.2369, -0.0148, -0.0188, -0.0732,  0.2368,  0.0110,  0.1468],\n        [ 0.3051,  0.0446,  0.2240, -0.1867, -0.0277, -0.1477,  0.2085,  0.1421],\n        [-0.1282,  0.1063,  0.2252,  0.2597, -0.1522,  0.0452,  0.1599, -0.0298],\n        [ 0.1232, -0.0117,  0.2075,  0.1373, -0.2360,  0.2104, -0.0304,  0.0480],\n        [ 0.2641, -0.1331, -0.0587,  0.2165, -0.0512,  0.2655, -0.1826, -0.0119],\n        [-0.1870, -0.2142, -0.1516,  0.0713, -0.0905, -0.0009, -0.2985, -0.3125],\n        [ 0.0797,  0.1145, -0.2710, -0.1187, -0.1313,  0.1501,  0.0415, -0.1503],\n        [ 0.2382, -0.3322, -0.1919,  0.3318, -0.1128, -0.0208, -0.1275,  0.0324],\n        [-0.3417,  0.2668,  0.1701,  0.2065, -0.1621, -0.0798,  0.2888,  0.1158],\n        [-0.3314,  0.2674,  0.2223,  0.0275, -0.1101, -0.0058, -0.0104, -0.3473],\n        [-0.2847,  0.2207,  0.0137,  0.3067,  0.0351, -0.2850, -0.1485,  0.3396],\n        [-0.1789,  0.1925, -0.1014,  0.0188,  0.1097, -0.1301, -0.1243,  0.1681],\n        [ 0.0724, -0.2771,  0.0345, -0.1181,  0.2457,  0.2374,  0.0599,  0.0880],\n        [-0.1099,  0.3442,  0.0650, -0.1008,  0.0959, -0.1287, -0.1911,  0.0843]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0871,  0.1269,  0.0881,  0.0151, -0.0361, -0.1121,  0.0203, -0.1614,\n        -0.1211, -0.1306,  0.1400,  0.1151,  0.0038, -0.0403, -0.1630,  0.1226],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0149e-01,  1.3739e-01,  1.3744e-01, -7.2916e-02, -5.8632e-02,\n          8.3690e-02,  1.3300e-01,  6.2108e-02, -8.9982e-02,  1.2690e-01,\n         -4.9100e-02, -7.1101e-02, -1.2300e-01,  1.3298e-01,  3.3127e-02,\n          3.5386e-02, -6.8698e-02, -1.6447e-01, -1.3817e-01, -4.8690e-02,\n          8.3218e-02, -3.3541e-02,  1.5693e-03,  4.8140e-02,  1.7587e-01,\n         -1.0757e-02, -1.0803e-01, -1.6658e-01,  1.6329e-02, -1.2786e-01,\n          8.9625e-05,  1.3585e-01],\n        [ 1.1454e-01, -1.0604e-01, -1.2334e-01, -1.5809e-01, -7.0172e-02,\n          3.3103e-02,  1.7512e-01, -1.4679e-01,  7.8935e-02, -1.5905e-01,\n          4.8316e-02,  7.4007e-02, -1.4350e-01,  1.2841e-01, -1.6579e-01,\n         -8.3682e-02,  1.1298e-01, -1.3140e-03,  3.9453e-02,  1.3826e-01,\n          8.1227e-02,  1.2773e-01, -5.3009e-03,  9.1783e-02,  1.6946e-01,\n          3.7485e-02, -9.7803e-02,  5.6341e-02, -1.1049e-01, -1.1153e-01,\n          3.9730e-02, -1.2264e-01],\n        [ 1.3622e-01, -1.1629e-01,  7.1929e-02, -1.6751e-02, -4.9978e-02,\n          7.9703e-02, -9.2306e-02, -6.0918e-02,  1.1550e-02, -9.8679e-02,\n         -1.0074e-01,  1.4207e-01,  4.9147e-02,  1.5720e-01, -3.3681e-02,\n         -1.4588e-01,  2.5297e-02, -1.6762e-02,  8.2118e-02, -6.4262e-02,\n         -2.0698e-02,  3.6322e-02,  8.7989e-03, -4.7692e-02, -3.5840e-03,\n          7.3315e-02, -1.4791e-01,  1.6066e-01,  1.1056e-01,  1.3355e-01,\n          4.2109e-02,  1.1032e-01],\n        [-5.7505e-02, -9.2347e-03,  1.3626e-02, -7.4105e-02, -1.4246e-01,\n         -7.0283e-03, -1.5898e-01,  8.9014e-02,  1.5678e-01,  7.7640e-02,\n          6.5483e-02, -7.4943e-02, -9.6276e-02,  1.5962e-01, -1.2403e-01,\n          5.0323e-02, -1.3167e-01,  1.2301e-01, -8.4163e-02, -9.9116e-02,\n          1.1195e-01, -6.4093e-02, -1.8246e-02,  8.8070e-02, -1.6745e-01,\n         -1.4810e-01,  1.4691e-01,  1.2280e-01, -1.2956e-01, -6.7551e-02,\n         -1.7530e-01,  1.5171e-01],\n        [-1.8699e-02, -4.1491e-02,  1.6332e-01, -1.3826e-01, -1.8098e-02,\n          7.8907e-02, -1.6867e-02,  3.6500e-02, -1.1145e-01, -1.7552e-01,\n         -8.1275e-02, -3.3867e-02, -1.6705e-01,  1.6208e-01,  1.5946e-02,\n          1.3668e-01,  8.4315e-02, -1.2898e-01,  8.8780e-02, -4.6496e-02,\n         -1.5299e-01, -1.3491e-01,  5.2107e-02,  1.6366e-01, -6.5164e-02,\n          2.5550e-02,  1.6069e-01,  8.1732e-02,  1.7354e-01, -1.6982e-01,\n          3.3255e-02, -2.0461e-02],\n        [-1.3827e-01, -1.0030e-01,  1.8075e-02, -1.6732e-01, -9.8222e-02,\n          1.4755e-01,  5.3042e-02,  8.1832e-04,  9.6726e-02,  1.3256e-01,\n          6.9850e-02,  1.3613e-01, -8.1749e-02, -1.4112e-01,  1.7103e-01,\n          1.6746e-01,  3.6606e-02, -7.4676e-02, -1.6084e-01, -5.2357e-02,\n         -1.5687e-01,  1.0190e-01,  7.7382e-02,  1.4643e-02,  1.6378e-01,\n         -8.6764e-02, -1.4200e-01,  1.5751e-01, -1.5831e-01,  3.2121e-02,\n         -4.5694e-02, -5.2117e-02],\n        [-8.1908e-02, -6.9514e-02, -9.1478e-02, -1.1590e-01,  1.2179e-01,\n         -5.5204e-02,  1.2221e-01,  4.8878e-02,  1.6726e-01,  1.7400e-01,\n         -2.1694e-02, -4.1728e-02,  1.2877e-01,  1.3917e-01,  4.3477e-02,\n          6.1917e-02, -1.0863e-01, -8.5453e-02, -1.5750e-01, -4.0521e-02,\n         -3.0205e-03, -6.8011e-02,  1.6801e-01,  7.9071e-02,  1.2732e-01,\n          1.7576e-02, -6.4921e-02, -1.3552e-01, -9.3955e-02, -4.3766e-02,\n          4.4296e-02, -4.8167e-02],\n        [-9.3698e-03, -5.4620e-04, -1.2377e-01, -1.3649e-01, -1.4677e-01,\n          1.3290e-01,  1.4985e-02, -2.4184e-02, -1.6925e-01,  5.9689e-02,\n         -7.0473e-02, -3.4024e-02, -9.9882e-02, -1.0115e-01,  1.3016e-01,\n         -3.9228e-02,  1.4048e-01, -1.4571e-01, -2.8730e-02, -1.6087e-01,\n         -5.3845e-02,  9.7225e-02, -2.6129e-03, -1.6623e-02,  2.8446e-02,\n         -2.8009e-02,  1.1359e-01, -1.4744e-01,  1.1853e-01, -1.2741e-01,\n         -1.3654e-01, -7.1755e-02],\n        [-1.2911e-01, -4.8400e-02, -1.1014e-01, -6.0357e-02, -6.0701e-02,\n          1.9720e-02,  1.4270e-01,  3.1057e-02, -2.3459e-03,  1.1156e-01,\n         -1.4854e-01,  1.6713e-02, -2.4558e-02,  3.9525e-02,  1.1470e-02,\n         -1.6988e-01,  1.1330e-01, -2.2864e-02, -8.0009e-02, -6.3630e-02,\n         -1.2536e-01,  1.7278e-01,  1.6189e-01, -7.4732e-02,  1.0956e-01,\n         -9.1975e-02, -1.5346e-01, -9.6506e-02,  7.0912e-02, -8.4136e-02,\n          6.6481e-02, -2.7250e-02],\n        [ 4.0468e-02,  5.1983e-02, -1.4468e-01, -1.5569e-01,  5.4561e-02,\n          9.0728e-03, -3.4733e-02,  1.6801e-01,  2.0983e-02, -1.0592e-01,\n         -5.0864e-02,  1.6982e-01, -6.1957e-02,  5.3925e-02,  1.3254e-01,\n          9.3566e-02,  6.8269e-02, -1.5832e-01, -1.1312e-01, -7.1976e-03,\n          1.4722e-01,  8.5528e-02,  1.6195e-01, -1.2169e-01, -1.3892e-01,\n         -9.9419e-02, -3.0530e-03, -2.7865e-02,  7.1510e-02, -7.2447e-02,\n         -7.8208e-02,  2.9655e-02],\n        [ 1.3034e-01, -9.3056e-02, -1.7816e-02, -1.0442e-01, -1.7944e-02,\n          4.5080e-02, -1.4912e-01, -1.6321e-01,  6.7109e-03, -1.6426e-01,\n          1.0532e-01, -1.3294e-01,  1.6420e-01, -1.2775e-01, -6.5144e-02,\n          9.9791e-02,  1.7053e-01,  1.0343e-01,  1.0290e-01,  2.2258e-03,\n         -1.4625e-02, -1.6072e-01,  1.0202e-01, -1.0513e-02,  1.6367e-01,\n         -4.7137e-02,  1.6320e-01,  4.9688e-02, -1.3505e-01, -9.9078e-02,\n          8.9967e-02, -4.8596e-02],\n        [-1.0506e-02,  3.5151e-02,  1.5129e-01, -1.3771e-01,  6.2096e-02,\n          1.0471e-01, -1.4265e-01, -1.3416e-02,  2.8990e-02, -4.7332e-02,\n         -5.8706e-02,  1.4616e-01, -1.5650e-01,  1.0795e-01,  2.0439e-04,\n         -1.6497e-01, -1.2418e-01,  7.6854e-02, -5.7832e-02, -1.5546e-01,\n          3.3692e-02,  1.3999e-01,  6.0251e-02, -7.0563e-02, -4.4415e-02,\n          1.4900e-01,  1.0235e-01, -1.5377e-01, -1.5673e-01, -1.5832e-01,\n          1.4826e-01, -1.7291e-01],\n        [ 3.2942e-02, -1.4727e-01, -3.4011e-02,  1.3023e-01,  1.4813e-02,\n         -1.3730e-01, -1.2113e-01, -6.3439e-02,  1.4910e-01,  1.6465e-01,\n         -9.2762e-02, -1.1640e-01, -4.9890e-02, -1.3694e-01,  1.7656e-01,\n          1.5991e-01, -4.1302e-02, -6.2299e-02, -1.1694e-01, -1.2018e-01,\n          2.2508e-02, -1.2837e-01,  2.6457e-02, -6.3531e-02,  1.2361e-01,\n         -1.6786e-01, -1.1470e-01, -1.6255e-01, -4.8543e-02, -7.3636e-02,\n         -6.3577e-02,  1.1136e-01],\n        [-2.3367e-02, -1.7633e-01,  1.5819e-01, -7.0690e-02, -1.1745e-01,\n         -1.4061e-01,  6.7063e-02,  1.1992e-01, -1.3671e-01,  9.9545e-02,\n         -1.0900e-03, -6.9512e-02,  8.0337e-02,  4.5070e-02,  4.6565e-02,\n          3.9632e-02, -4.0325e-02, -1.6355e-02,  1.7460e-01, -1.5695e-01,\n          1.4549e-01, -9.4388e-02,  1.1983e-01,  8.4103e-02,  1.5735e-01,\n         -6.7819e-02, -1.4957e-01,  9.2917e-02, -1.0326e-01,  1.7676e-02,\n         -1.0504e-01, -1.2521e-01],\n        [ 4.6432e-02, -1.3873e-01, -1.1614e-01, -1.0760e-01, -4.5266e-02,\n          1.3039e-01,  1.6714e-01, -1.7676e-01,  3.7213e-02,  1.1791e-01,\n         -1.5207e-02, -1.1776e-01,  6.1093e-02,  6.8097e-02, -5.5996e-02,\n          9.1973e-02,  8.0378e-03,  1.2326e-01, -1.6885e-01, -3.2494e-02,\n          1.0832e-01, -5.5467e-02,  1.5452e-01,  1.6245e-01,  8.2026e-02,\n         -1.2945e-01, -1.1399e-01, -1.0403e-01, -2.7630e-02,  9.0614e-02,\n          1.5065e-01, -8.4561e-02],\n        [-1.2159e-01,  1.0800e-01,  1.3676e-01, -5.5972e-02, -1.3455e-01,\n         -1.7564e-01, -1.4095e-01, -1.3764e-01,  1.0395e-01,  4.6802e-02,\n          1.5522e-01,  1.3930e-02, -1.6447e-01, -7.2447e-02,  1.0071e-01,\n          1.5330e-01, -2.5539e-02, -6.1892e-02,  1.4074e-01, -1.9554e-02,\n         -2.5979e-02, -1.3601e-02,  1.2967e-01, -1.3674e-01, -1.6649e-02,\n         -5.1731e-02, -8.0038e-02, -3.1544e-02,  5.9597e-02,  1.4754e-02,\n          2.8315e-02, -8.3687e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1738, -0.0932, -0.2291, -0.1860, -0.1720, -0.1664, -0.0981, -0.1935],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0534,  0.1325, -0.1353,  0.1564, -0.0356,  0.0277, -0.1212, -0.0015,\n         -0.2342,  0.1259, -0.0572,  0.0569,  0.2387,  0.0088, -0.2060, -0.2253],\n        [ 0.0289,  0.2108,  0.1346,  0.0260, -0.0487,  0.1383,  0.1764,  0.0051,\n          0.0230,  0.0142,  0.0398,  0.1302, -0.2034,  0.1280, -0.0745,  0.2185],\n        [-0.2428, -0.1103, -0.1422,  0.0766, -0.2101, -0.2314,  0.1827,  0.2355,\n         -0.0233, -0.0300,  0.1968,  0.1353,  0.1306,  0.0537,  0.0095, -0.1340],\n        [-0.2424, -0.0272, -0.1779, -0.0432,  0.2120,  0.2139,  0.1562, -0.0625,\n          0.1994,  0.1673,  0.1255, -0.2490, -0.2084,  0.1249,  0.1046, -0.1214],\n        [ 0.0664,  0.1759, -0.0024,  0.2139, -0.0785, -0.0022, -0.0587,  0.0820,\n          0.2280,  0.0217, -0.0484,  0.0969,  0.0393, -0.1298, -0.0037, -0.1256],\n        [-0.1354, -0.1480,  0.0715,  0.0922, -0.0410,  0.0232,  0.2226, -0.2217,\n         -0.0533, -0.0568,  0.1736, -0.0662, -0.1026, -0.1853, -0.1366,  0.1422],\n        [-0.0843,  0.1628,  0.1177, -0.1615, -0.0344,  0.2361,  0.0129,  0.0256,\n         -0.0363,  0.1443,  0.1191,  0.1817, -0.1114,  0.0179, -0.1644,  0.0870],\n        [-0.0859,  0.1136, -0.2210,  0.0147,  0.2039, -0.0619,  0.1518,  0.2144,\n         -0.0658,  0.2195,  0.2451,  0.0475, -0.1705, -0.1717,  0.0226, -0.1867]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2633], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0304,  0.2553, -0.2130, -0.0355, -0.0106, -0.0137,  0.3443,  0.2017]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1051, -0.3285,  0.1564, -0.1059,  0.0616,  0.1578,  0.2526, -0.3091],\n        [ 0.2157,  0.0882, -0.2784,  0.2739, -0.0886, -0.2130, -0.3381,  0.1836],\n        [-0.2338,  0.2361, -0.1351, -0.1195, -0.3095,  0.1183, -0.0131, -0.2933],\n        [ 0.2816,  0.1962,  0.1759,  0.3024, -0.1688, -0.0461, -0.1352, -0.0094],\n        [-0.3088,  0.0719, -0.2650,  0.0050, -0.2026,  0.1519,  0.0373, -0.1617],\n        [-0.2553,  0.1260, -0.1338, -0.3426, -0.1548,  0.0541, -0.2687,  0.1072],\n        [-0.3479, -0.0107,  0.3333,  0.0016, -0.2772, -0.3346,  0.0093,  0.1270],\n        [-0.0748,  0.0360, -0.1850,  0.0483,  0.1521,  0.2850, -0.3085, -0.0340],\n        [ 0.1576, -0.1409, -0.1808,  0.0998, -0.2199,  0.0837, -0.0805, -0.1535],\n        [-0.1126,  0.0943, -0.0031, -0.0260, -0.2447, -0.2467, -0.3066,  0.1252],\n        [ 0.0197,  0.0463,  0.0728, -0.2138,  0.1708, -0.1033,  0.2653,  0.0780],\n        [ 0.1649, -0.0697,  0.1007,  0.3210,  0.3364,  0.1371, -0.1027, -0.2187],\n        [-0.1914, -0.3269, -0.0858,  0.3414, -0.3038,  0.1262, -0.3497, -0.3012],\n        [ 0.2874,  0.1441, -0.1586, -0.1602, -0.0624, -0.3404,  0.0389, -0.0853],\n        [-0.1706, -0.0122,  0.1378,  0.0252,  0.0078,  0.2230,  0.3195,  0.3294],\n        [-0.0335,  0.0440,  0.3053,  0.1733, -0.2200,  0.2624, -0.2798,  0.0206],\n        [ 0.1871, -0.1363,  0.1605, -0.0517,  0.0626,  0.0473, -0.2999,  0.2859],\n        [-0.0110, -0.0839,  0.3494,  0.2228,  0.1558, -0.2676,  0.2420,  0.1902],\n        [ 0.0414,  0.2369, -0.0148, -0.0188, -0.0732,  0.2368,  0.0110,  0.1468],\n        [ 0.3051,  0.0446,  0.2240, -0.1867, -0.0277, -0.1477,  0.2085,  0.1421],\n        [-0.1282,  0.1063,  0.2252,  0.2597, -0.1522,  0.0452,  0.1599, -0.0298],\n        [ 0.1232, -0.0117,  0.2075,  0.1373, -0.2360,  0.2104, -0.0304,  0.0480],\n        [ 0.2641, -0.1331, -0.0587,  0.2165, -0.0512,  0.2655, -0.1826, -0.0119],\n        [-0.1870, -0.2142, -0.1516,  0.0713, -0.0905, -0.0009, -0.2985, -0.3125],\n        [ 0.0797,  0.1145, -0.2710, -0.1187, -0.1313,  0.1501,  0.0415, -0.1503],\n        [ 0.2382, -0.3322, -0.1919,  0.3318, -0.1128, -0.0208, -0.1275,  0.0324],\n        [-0.3417,  0.2668,  0.1701,  0.2065, -0.1621, -0.0798,  0.2888,  0.1158],\n        [-0.3314,  0.2674,  0.2223,  0.0275, -0.1101, -0.0058, -0.0104, -0.3473],\n        [-0.2847,  0.2207,  0.0137,  0.3067,  0.0351, -0.2850, -0.1485,  0.3396],\n        [-0.1789,  0.1925, -0.1014,  0.0188,  0.1097, -0.1301, -0.1243,  0.1681],\n        [ 0.0724, -0.2771,  0.0345, -0.1181,  0.2457,  0.2374,  0.0599,  0.0880],\n        [-0.1099,  0.3442,  0.0650, -0.1008,  0.0959, -0.1287, -0.1911,  0.0843]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1542, -0.1859,  0.1277,  0.0911,  0.2705,  0.1897, -0.1371,  0.2744,\n        -0.0465, -0.1212, -0.2154,  0.3315, -0.1936,  0.2049,  0.1073,  0.3470,\n         0.0739,  0.2167,  0.2069,  0.2801,  0.1352,  0.2687,  0.1515, -0.1243,\n        -0.1611, -0.1053,  0.0782, -0.1434,  0.1217,  0.1961, -0.2342,  0.2425],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.0149e-01,  1.3739e-01,  1.3744e-01, -7.2916e-02, -5.8632e-02,\n          8.3690e-02,  1.3300e-01,  6.2108e-02, -8.9982e-02,  1.2690e-01,\n         -4.9100e-02, -7.1101e-02, -1.2300e-01,  1.3298e-01,  3.3127e-02,\n          3.5386e-02, -6.8698e-02, -1.6447e-01, -1.3817e-01, -4.8690e-02,\n          8.3218e-02, -3.3541e-02,  1.5693e-03,  4.8140e-02,  1.7587e-01,\n         -1.0757e-02, -1.0803e-01, -1.6658e-01,  1.6329e-02, -1.2786e-01,\n          8.9625e-05,  1.3585e-01],\n        [ 1.1454e-01, -1.0604e-01, -1.2334e-01, -1.5809e-01, -7.0172e-02,\n          3.3103e-02,  1.7512e-01, -1.4679e-01,  7.8935e-02, -1.5905e-01,\n          4.8316e-02,  7.4007e-02, -1.4350e-01,  1.2841e-01, -1.6579e-01,\n         -8.3682e-02,  1.1298e-01, -1.3140e-03,  3.9453e-02,  1.3826e-01,\n          8.1227e-02,  1.2773e-01, -5.3009e-03,  9.1783e-02,  1.6946e-01,\n          3.7485e-02, -9.7803e-02,  5.6341e-02, -1.1049e-01, -1.1153e-01,\n          3.9730e-02, -1.2264e-01],\n        [ 1.3622e-01, -1.1629e-01,  7.1929e-02, -1.6751e-02, -4.9978e-02,\n          7.9703e-02, -9.2306e-02, -6.0918e-02,  1.1550e-02, -9.8679e-02,\n         -1.0074e-01,  1.4207e-01,  4.9147e-02,  1.5720e-01, -3.3681e-02,\n         -1.4588e-01,  2.5297e-02, -1.6762e-02,  8.2118e-02, -6.4262e-02,\n         -2.0698e-02,  3.6322e-02,  8.7989e-03, -4.7692e-02, -3.5840e-03,\n          7.3315e-02, -1.4791e-01,  1.6066e-01,  1.1056e-01,  1.3355e-01,\n          4.2109e-02,  1.1032e-01],\n        [-5.7505e-02, -9.2347e-03,  1.3626e-02, -7.4105e-02, -1.4246e-01,\n         -7.0283e-03, -1.5898e-01,  8.9014e-02,  1.5678e-01,  7.7640e-02,\n          6.5483e-02, -7.4943e-02, -9.6276e-02,  1.5962e-01, -1.2403e-01,\n          5.0323e-02, -1.3167e-01,  1.2301e-01, -8.4163e-02, -9.9116e-02,\n          1.1195e-01, -6.4093e-02, -1.8246e-02,  8.8070e-02, -1.6745e-01,\n         -1.4810e-01,  1.4691e-01,  1.2280e-01, -1.2956e-01, -6.7551e-02,\n         -1.7530e-01,  1.5171e-01],\n        [-1.8699e-02, -4.1491e-02,  1.6332e-01, -1.3826e-01, -1.8098e-02,\n          7.8907e-02, -1.6867e-02,  3.6500e-02, -1.1145e-01, -1.7552e-01,\n         -8.1275e-02, -3.3867e-02, -1.6705e-01,  1.6208e-01,  1.5946e-02,\n          1.3668e-01,  8.4315e-02, -1.2898e-01,  8.8780e-02, -4.6496e-02,\n         -1.5299e-01, -1.3491e-01,  5.2107e-02,  1.6366e-01, -6.5164e-02,\n          2.5550e-02,  1.6069e-01,  8.1732e-02,  1.7354e-01, -1.6982e-01,\n          3.3255e-02, -2.0461e-02],\n        [-1.3827e-01, -1.0030e-01,  1.8075e-02, -1.6732e-01, -9.8222e-02,\n          1.4755e-01,  5.3042e-02,  8.1832e-04,  9.6726e-02,  1.3256e-01,\n          6.9850e-02,  1.3613e-01, -8.1749e-02, -1.4112e-01,  1.7103e-01,\n          1.6746e-01,  3.6606e-02, -7.4676e-02, -1.6084e-01, -5.2357e-02,\n         -1.5687e-01,  1.0190e-01,  7.7382e-02,  1.4643e-02,  1.6378e-01,\n         -8.6764e-02, -1.4200e-01,  1.5751e-01, -1.5831e-01,  3.2121e-02,\n         -4.5694e-02, -5.2117e-02],\n        [-8.1908e-02, -6.9514e-02, -9.1478e-02, -1.1590e-01,  1.2179e-01,\n         -5.5204e-02,  1.2221e-01,  4.8878e-02,  1.6726e-01,  1.7400e-01,\n         -2.1694e-02, -4.1728e-02,  1.2877e-01,  1.3917e-01,  4.3477e-02,\n          6.1917e-02, -1.0863e-01, -8.5453e-02, -1.5750e-01, -4.0521e-02,\n         -3.0205e-03, -6.8011e-02,  1.6801e-01,  7.9071e-02,  1.2732e-01,\n          1.7576e-02, -6.4921e-02, -1.3552e-01, -9.3955e-02, -4.3766e-02,\n          4.4296e-02, -4.8167e-02],\n        [-9.3698e-03, -5.4620e-04, -1.2377e-01, -1.3649e-01, -1.4677e-01,\n          1.3290e-01,  1.4985e-02, -2.4184e-02, -1.6925e-01,  5.9689e-02,\n         -7.0473e-02, -3.4024e-02, -9.9882e-02, -1.0115e-01,  1.3016e-01,\n         -3.9228e-02,  1.4048e-01, -1.4571e-01, -2.8730e-02, -1.6087e-01,\n         -5.3845e-02,  9.7225e-02, -2.6129e-03, -1.6623e-02,  2.8446e-02,\n         -2.8009e-02,  1.1359e-01, -1.4744e-01,  1.1853e-01, -1.2741e-01,\n         -1.3654e-01, -7.1755e-02],\n        [-1.2911e-01, -4.8400e-02, -1.1014e-01, -6.0357e-02, -6.0701e-02,\n          1.9720e-02,  1.4270e-01,  3.1057e-02, -2.3459e-03,  1.1156e-01,\n         -1.4854e-01,  1.6713e-02, -2.4558e-02,  3.9525e-02,  1.1470e-02,\n         -1.6988e-01,  1.1330e-01, -2.2864e-02, -8.0009e-02, -6.3630e-02,\n         -1.2536e-01,  1.7278e-01,  1.6189e-01, -7.4732e-02,  1.0956e-01,\n         -9.1975e-02, -1.5346e-01, -9.6506e-02,  7.0912e-02, -8.4136e-02,\n          6.6481e-02, -2.7250e-02],\n        [ 4.0468e-02,  5.1983e-02, -1.4468e-01, -1.5569e-01,  5.4561e-02,\n          9.0728e-03, -3.4733e-02,  1.6801e-01,  2.0983e-02, -1.0592e-01,\n         -5.0864e-02,  1.6982e-01, -6.1957e-02,  5.3925e-02,  1.3254e-01,\n          9.3566e-02,  6.8269e-02, -1.5832e-01, -1.1312e-01, -7.1976e-03,\n          1.4722e-01,  8.5528e-02,  1.6195e-01, -1.2169e-01, -1.3892e-01,\n         -9.9419e-02, -3.0530e-03, -2.7865e-02,  7.1510e-02, -7.2447e-02,\n         -7.8208e-02,  2.9655e-02],\n        [ 1.3034e-01, -9.3056e-02, -1.7816e-02, -1.0442e-01, -1.7944e-02,\n          4.5080e-02, -1.4912e-01, -1.6321e-01,  6.7109e-03, -1.6426e-01,\n          1.0532e-01, -1.3294e-01,  1.6420e-01, -1.2775e-01, -6.5144e-02,\n          9.9791e-02,  1.7053e-01,  1.0343e-01,  1.0290e-01,  2.2258e-03,\n         -1.4625e-02, -1.6072e-01,  1.0202e-01, -1.0513e-02,  1.6367e-01,\n         -4.7137e-02,  1.6320e-01,  4.9688e-02, -1.3505e-01, -9.9078e-02,\n          8.9967e-02, -4.8596e-02],\n        [-1.0506e-02,  3.5151e-02,  1.5129e-01, -1.3771e-01,  6.2096e-02,\n          1.0471e-01, -1.4265e-01, -1.3416e-02,  2.8990e-02, -4.7332e-02,\n         -5.8706e-02,  1.4616e-01, -1.5650e-01,  1.0795e-01,  2.0439e-04,\n         -1.6497e-01, -1.2418e-01,  7.6854e-02, -5.7832e-02, -1.5546e-01,\n          3.3692e-02,  1.3999e-01,  6.0251e-02, -7.0563e-02, -4.4415e-02,\n          1.4900e-01,  1.0235e-01, -1.5377e-01, -1.5673e-01, -1.5832e-01,\n          1.4826e-01, -1.7291e-01],\n        [ 3.2942e-02, -1.4727e-01, -3.4011e-02,  1.3023e-01,  1.4813e-02,\n         -1.3730e-01, -1.2113e-01, -6.3439e-02,  1.4910e-01,  1.6465e-01,\n         -9.2762e-02, -1.1640e-01, -4.9890e-02, -1.3694e-01,  1.7656e-01,\n          1.5991e-01, -4.1302e-02, -6.2299e-02, -1.1694e-01, -1.2018e-01,\n          2.2508e-02, -1.2837e-01,  2.6457e-02, -6.3531e-02,  1.2361e-01,\n         -1.6786e-01, -1.1470e-01, -1.6255e-01, -4.8543e-02, -7.3636e-02,\n         -6.3577e-02,  1.1136e-01],\n        [-2.3367e-02, -1.7633e-01,  1.5819e-01, -7.0690e-02, -1.1745e-01,\n         -1.4061e-01,  6.7063e-02,  1.1992e-01, -1.3671e-01,  9.9545e-02,\n         -1.0900e-03, -6.9512e-02,  8.0337e-02,  4.5070e-02,  4.6565e-02,\n          3.9632e-02, -4.0325e-02, -1.6355e-02,  1.7460e-01, -1.5695e-01,\n          1.4549e-01, -9.4388e-02,  1.1983e-01,  8.4103e-02,  1.5735e-01,\n         -6.7819e-02, -1.4957e-01,  9.2917e-02, -1.0326e-01,  1.7676e-02,\n         -1.0504e-01, -1.2521e-01],\n        [ 4.6432e-02, -1.3873e-01, -1.1614e-01, -1.0760e-01, -4.5266e-02,\n          1.3039e-01,  1.6714e-01, -1.7676e-01,  3.7213e-02,  1.1791e-01,\n         -1.5207e-02, -1.1776e-01,  6.1093e-02,  6.8097e-02, -5.5996e-02,\n          9.1973e-02,  8.0378e-03,  1.2326e-01, -1.6885e-01, -3.2494e-02,\n          1.0832e-01, -5.5467e-02,  1.5452e-01,  1.6245e-01,  8.2026e-02,\n         -1.2945e-01, -1.1399e-01, -1.0403e-01, -2.7630e-02,  9.0614e-02,\n          1.5065e-01, -8.4561e-02],\n        [-1.2159e-01,  1.0800e-01,  1.3676e-01, -5.5972e-02, -1.3455e-01,\n         -1.7564e-01, -1.4095e-01, -1.3764e-01,  1.0395e-01,  4.6802e-02,\n          1.5522e-01,  1.3930e-02, -1.6447e-01, -7.2447e-02,  1.0071e-01,\n          1.5330e-01, -2.5539e-02, -6.1892e-02,  1.4074e-01, -1.9554e-02,\n         -2.5979e-02, -1.3601e-02,  1.2967e-01, -1.3674e-01, -1.6649e-02,\n         -5.1731e-02, -8.0038e-02, -3.1544e-02,  5.9597e-02,  1.4754e-02,\n          2.8315e-02, -8.3687e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0871,  0.1269,  0.0881,  0.0151, -0.0361, -0.1121,  0.0203, -0.1614,\n        -0.1211, -0.1306,  0.1400,  0.1151,  0.0038, -0.0403, -0.1630,  0.1226],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0534,  0.1325, -0.1353,  0.1564, -0.0356,  0.0277, -0.1212, -0.0015,\n         -0.2342,  0.1259, -0.0572,  0.0569,  0.2387,  0.0088, -0.2060, -0.2253],\n        [ 0.0289,  0.2108,  0.1346,  0.0260, -0.0487,  0.1383,  0.1764,  0.0051,\n          0.0230,  0.0142,  0.0398,  0.1302, -0.2034,  0.1280, -0.0745,  0.2185],\n        [-0.2428, -0.1103, -0.1422,  0.0766, -0.2101, -0.2314,  0.1827,  0.2355,\n         -0.0233, -0.0300,  0.1968,  0.1353,  0.1306,  0.0537,  0.0095, -0.1340],\n        [-0.2424, -0.0272, -0.1779, -0.0432,  0.2120,  0.2139,  0.1562, -0.0625,\n          0.1994,  0.1673,  0.1255, -0.2490, -0.2084,  0.1249,  0.1046, -0.1214],\n        [ 0.0664,  0.1759, -0.0024,  0.2139, -0.0785, -0.0022, -0.0587,  0.0820,\n          0.2280,  0.0217, -0.0484,  0.0969,  0.0393, -0.1298, -0.0037, -0.1256],\n        [-0.1354, -0.1480,  0.0715,  0.0922, -0.0410,  0.0232,  0.2226, -0.2217,\n         -0.0533, -0.0568,  0.1736, -0.0662, -0.1026, -0.1853, -0.1366,  0.1422],\n        [-0.0843,  0.1628,  0.1177, -0.1615, -0.0344,  0.2361,  0.0129,  0.0256,\n         -0.0363,  0.1443,  0.1191,  0.1817, -0.1114,  0.0179, -0.1644,  0.0870],\n        [-0.0859,  0.1136, -0.2210,  0.0147,  0.2039, -0.0619,  0.1518,  0.2144,\n         -0.0658,  0.2195,  0.2451,  0.0475, -0.1705, -0.1717,  0.0226, -0.1867]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1738, -0.0932, -0.2291, -0.1860, -0.1720, -0.1664, -0.0981, -0.1935],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0304,  0.2553, -0.2130, -0.0355, -0.0106, -0.0137,  0.3443,  0.2017]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2633], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x70178e04aed0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1542, -0.1859,  0.1277,  0.0911,  0.2705,  0.1897, -0.1371,  0.2744,\n        -0.0465, -0.1212, -0.2154,  0.3315, -0.1936,  0.2049,  0.1073,  0.3470,\n         0.0739,  0.2167,  0.2069,  0.2801,  0.1352,  0.2687,  0.1515, -0.1243,\n        -0.1611, -0.1053,  0.0782, -0.1434,  0.1217,  0.1961, -0.2342,  0.2425],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1051, -0.3285,  0.1564, -0.1059,  0.0616,  0.1578,  0.2526, -0.3091],\n        [ 0.2157,  0.0882, -0.2784,  0.2739, -0.0886, -0.2130, -0.3381,  0.1836],\n        [-0.2338,  0.2361, -0.1351, -0.1195, -0.3095,  0.1183, -0.0131, -0.2933],\n        [ 0.2816,  0.1962,  0.1759,  0.3024, -0.1688, -0.0461, -0.1352, -0.0094],\n        [-0.3088,  0.0719, -0.2650,  0.0050, -0.2026,  0.1519,  0.0373, -0.1617],\n        [-0.2553,  0.1260, -0.1338, -0.3426, -0.1548,  0.0541, -0.2687,  0.1072],\n        [-0.3479, -0.0107,  0.3333,  0.0016, -0.2772, -0.3346,  0.0093,  0.1270],\n        [-0.0748,  0.0360, -0.1850,  0.0483,  0.1521,  0.2850, -0.3085, -0.0340],\n        [ 0.1576, -0.1409, -0.1808,  0.0998, -0.2199,  0.0837, -0.0805, -0.1535],\n        [-0.1126,  0.0943, -0.0031, -0.0260, -0.2447, -0.2467, -0.3066,  0.1252],\n        [ 0.0197,  0.0463,  0.0728, -0.2138,  0.1708, -0.1033,  0.2653,  0.0780],\n        [ 0.1649, -0.0697,  0.1007,  0.3210,  0.3364,  0.1371, -0.1027, -0.2187],\n        [-0.1914, -0.3269, -0.0858,  0.3414, -0.3038,  0.1262, -0.3497, -0.3012],\n        [ 0.2874,  0.1441, -0.1586, -0.1602, -0.0624, -0.3404,  0.0389, -0.0853],\n        [-0.1706, -0.0122,  0.1378,  0.0252,  0.0078,  0.2230,  0.3195,  0.3294],\n        [-0.0335,  0.0440,  0.3053,  0.1733, -0.2200,  0.2624, -0.2798,  0.0206],\n        [ 0.1871, -0.1363,  0.1605, -0.0517,  0.0626,  0.0473, -0.2999,  0.2859],\n        [-0.0110, -0.0839,  0.3494,  0.2228,  0.1558, -0.2676,  0.2420,  0.1902],\n        [ 0.0414,  0.2369, -0.0148, -0.0188, -0.0732,  0.2368,  0.0110,  0.1468],\n        [ 0.3051,  0.0446,  0.2240, -0.1867, -0.0277, -0.1477,  0.2085,  0.1421],\n        [-0.1282,  0.1063,  0.2252,  0.2597, -0.1522,  0.0452,  0.1599, -0.0298],\n        [ 0.1232, -0.0117,  0.2075,  0.1373, -0.2360,  0.2104, -0.0304,  0.0480],\n        [ 0.2641, -0.1331, -0.0587,  0.2165, -0.0512,  0.2655, -0.1826, -0.0119],\n        [-0.1870, -0.2142, -0.1516,  0.0713, -0.0905, -0.0009, -0.2985, -0.3125],\n        [ 0.0797,  0.1145, -0.2710, -0.1187, -0.1313,  0.1501,  0.0415, -0.1503],\n        [ 0.2382, -0.3322, -0.1919,  0.3318, -0.1128, -0.0208, -0.1275,  0.0324],\n        [-0.3417,  0.2668,  0.1701,  0.2065, -0.1621, -0.0798,  0.2888,  0.1158],\n        [-0.3314,  0.2674,  0.2223,  0.0275, -0.1101, -0.0058, -0.0104, -0.3473],\n        [-0.2847,  0.2207,  0.0137,  0.3067,  0.0351, -0.2850, -0.1485,  0.3396],\n        [-0.1789,  0.1925, -0.1014,  0.0188,  0.1097, -0.1301, -0.1243,  0.1681],\n        [ 0.0724, -0.2771,  0.0345, -0.1181,  0.2457,  0.2374,  0.0599,  0.0880],\n        [-0.1099,  0.3442,  0.0650, -0.1008,  0.0959, -0.1287, -0.1911,  0.0843]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0871,  0.1269,  0.0881,  0.0151, -0.0361, -0.1121,  0.0203, -0.1614,\n        -0.1211, -0.1306,  0.1400,  0.1151,  0.0038, -0.0403, -0.1630,  0.1226],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0149e-01,  1.3739e-01,  1.3744e-01, -7.2916e-02, -5.8632e-02,\n          8.3690e-02,  1.3300e-01,  6.2108e-02, -8.9982e-02,  1.2690e-01,\n         -4.9100e-02, -7.1101e-02, -1.2300e-01,  1.3298e-01,  3.3127e-02,\n          3.5386e-02, -6.8698e-02, -1.6447e-01, -1.3817e-01, -4.8690e-02,\n          8.3218e-02, -3.3541e-02,  1.5693e-03,  4.8140e-02,  1.7587e-01,\n         -1.0757e-02, -1.0803e-01, -1.6658e-01,  1.6329e-02, -1.2786e-01,\n          8.9625e-05,  1.3585e-01],\n        [ 1.1454e-01, -1.0604e-01, -1.2334e-01, -1.5809e-01, -7.0172e-02,\n          3.3103e-02,  1.7512e-01, -1.4679e-01,  7.8935e-02, -1.5905e-01,\n          4.8316e-02,  7.4007e-02, -1.4350e-01,  1.2841e-01, -1.6579e-01,\n         -8.3682e-02,  1.1298e-01, -1.3140e-03,  3.9453e-02,  1.3826e-01,\n          8.1227e-02,  1.2773e-01, -5.3009e-03,  9.1783e-02,  1.6946e-01,\n          3.7485e-02, -9.7803e-02,  5.6341e-02, -1.1049e-01, -1.1153e-01,\n          3.9730e-02, -1.2264e-01],\n        [ 1.3622e-01, -1.1629e-01,  7.1929e-02, -1.6751e-02, -4.9978e-02,\n          7.9703e-02, -9.2306e-02, -6.0918e-02,  1.1550e-02, -9.8679e-02,\n         -1.0074e-01,  1.4207e-01,  4.9147e-02,  1.5720e-01, -3.3681e-02,\n         -1.4588e-01,  2.5297e-02, -1.6762e-02,  8.2118e-02, -6.4262e-02,\n         -2.0698e-02,  3.6322e-02,  8.7989e-03, -4.7692e-02, -3.5840e-03,\n          7.3315e-02, -1.4791e-01,  1.6066e-01,  1.1056e-01,  1.3355e-01,\n          4.2109e-02,  1.1032e-01],\n        [-5.7505e-02, -9.2347e-03,  1.3626e-02, -7.4105e-02, -1.4246e-01,\n         -7.0283e-03, -1.5898e-01,  8.9014e-02,  1.5678e-01,  7.7640e-02,\n          6.5483e-02, -7.4943e-02, -9.6276e-02,  1.5962e-01, -1.2403e-01,\n          5.0323e-02, -1.3167e-01,  1.2301e-01, -8.4163e-02, -9.9116e-02,\n          1.1195e-01, -6.4093e-02, -1.8246e-02,  8.8070e-02, -1.6745e-01,\n         -1.4810e-01,  1.4691e-01,  1.2280e-01, -1.2956e-01, -6.7551e-02,\n         -1.7530e-01,  1.5171e-01],\n        [-1.8699e-02, -4.1491e-02,  1.6332e-01, -1.3826e-01, -1.8098e-02,\n          7.8907e-02, -1.6867e-02,  3.6500e-02, -1.1145e-01, -1.7552e-01,\n         -8.1275e-02, -3.3867e-02, -1.6705e-01,  1.6208e-01,  1.5946e-02,\n          1.3668e-01,  8.4315e-02, -1.2898e-01,  8.8780e-02, -4.6496e-02,\n         -1.5299e-01, -1.3491e-01,  5.2107e-02,  1.6366e-01, -6.5164e-02,\n          2.5550e-02,  1.6069e-01,  8.1732e-02,  1.7354e-01, -1.6982e-01,\n          3.3255e-02, -2.0461e-02],\n        [-1.3827e-01, -1.0030e-01,  1.8075e-02, -1.6732e-01, -9.8222e-02,\n          1.4755e-01,  5.3042e-02,  8.1832e-04,  9.6726e-02,  1.3256e-01,\n          6.9850e-02,  1.3613e-01, -8.1749e-02, -1.4112e-01,  1.7103e-01,\n          1.6746e-01,  3.6606e-02, -7.4676e-02, -1.6084e-01, -5.2357e-02,\n         -1.5687e-01,  1.0190e-01,  7.7382e-02,  1.4643e-02,  1.6378e-01,\n         -8.6764e-02, -1.4200e-01,  1.5751e-01, -1.5831e-01,  3.2121e-02,\n         -4.5694e-02, -5.2117e-02],\n        [-8.1908e-02, -6.9514e-02, -9.1478e-02, -1.1590e-01,  1.2179e-01,\n         -5.5204e-02,  1.2221e-01,  4.8878e-02,  1.6726e-01,  1.7400e-01,\n         -2.1694e-02, -4.1728e-02,  1.2877e-01,  1.3917e-01,  4.3477e-02,\n          6.1917e-02, -1.0863e-01, -8.5453e-02, -1.5750e-01, -4.0521e-02,\n         -3.0205e-03, -6.8011e-02,  1.6801e-01,  7.9071e-02,  1.2732e-01,\n          1.7576e-02, -6.4921e-02, -1.3552e-01, -9.3955e-02, -4.3766e-02,\n          4.4296e-02, -4.8167e-02],\n        [-9.3698e-03, -5.4620e-04, -1.2377e-01, -1.3649e-01, -1.4677e-01,\n          1.3290e-01,  1.4985e-02, -2.4184e-02, -1.6925e-01,  5.9689e-02,\n         -7.0473e-02, -3.4024e-02, -9.9882e-02, -1.0115e-01,  1.3016e-01,\n         -3.9228e-02,  1.4048e-01, -1.4571e-01, -2.8730e-02, -1.6087e-01,\n         -5.3845e-02,  9.7225e-02, -2.6129e-03, -1.6623e-02,  2.8446e-02,\n         -2.8009e-02,  1.1359e-01, -1.4744e-01,  1.1853e-01, -1.2741e-01,\n         -1.3654e-01, -7.1755e-02],\n        [-1.2911e-01, -4.8400e-02, -1.1014e-01, -6.0357e-02, -6.0701e-02,\n          1.9720e-02,  1.4270e-01,  3.1057e-02, -2.3459e-03,  1.1156e-01,\n         -1.4854e-01,  1.6713e-02, -2.4558e-02,  3.9525e-02,  1.1470e-02,\n         -1.6988e-01,  1.1330e-01, -2.2864e-02, -8.0009e-02, -6.3630e-02,\n         -1.2536e-01,  1.7278e-01,  1.6189e-01, -7.4732e-02,  1.0956e-01,\n         -9.1975e-02, -1.5346e-01, -9.6506e-02,  7.0912e-02, -8.4136e-02,\n          6.6481e-02, -2.7250e-02],\n        [ 4.0468e-02,  5.1983e-02, -1.4468e-01, -1.5569e-01,  5.4561e-02,\n          9.0728e-03, -3.4733e-02,  1.6801e-01,  2.0983e-02, -1.0592e-01,\n         -5.0864e-02,  1.6982e-01, -6.1957e-02,  5.3925e-02,  1.3254e-01,\n          9.3566e-02,  6.8269e-02, -1.5832e-01, -1.1312e-01, -7.1976e-03,\n          1.4722e-01,  8.5528e-02,  1.6195e-01, -1.2169e-01, -1.3892e-01,\n         -9.9419e-02, -3.0530e-03, -2.7865e-02,  7.1510e-02, -7.2447e-02,\n         -7.8208e-02,  2.9655e-02],\n        [ 1.3034e-01, -9.3056e-02, -1.7816e-02, -1.0442e-01, -1.7944e-02,\n          4.5080e-02, -1.4912e-01, -1.6321e-01,  6.7109e-03, -1.6426e-01,\n          1.0532e-01, -1.3294e-01,  1.6420e-01, -1.2775e-01, -6.5144e-02,\n          9.9791e-02,  1.7053e-01,  1.0343e-01,  1.0290e-01,  2.2258e-03,\n         -1.4625e-02, -1.6072e-01,  1.0202e-01, -1.0513e-02,  1.6367e-01,\n         -4.7137e-02,  1.6320e-01,  4.9688e-02, -1.3505e-01, -9.9078e-02,\n          8.9967e-02, -4.8596e-02],\n        [-1.0506e-02,  3.5151e-02,  1.5129e-01, -1.3771e-01,  6.2096e-02,\n          1.0471e-01, -1.4265e-01, -1.3416e-02,  2.8990e-02, -4.7332e-02,\n         -5.8706e-02,  1.4616e-01, -1.5650e-01,  1.0795e-01,  2.0439e-04,\n         -1.6497e-01, -1.2418e-01,  7.6854e-02, -5.7832e-02, -1.5546e-01,\n          3.3692e-02,  1.3999e-01,  6.0251e-02, -7.0563e-02, -4.4415e-02,\n          1.4900e-01,  1.0235e-01, -1.5377e-01, -1.5673e-01, -1.5832e-01,\n          1.4826e-01, -1.7291e-01],\n        [ 3.2942e-02, -1.4727e-01, -3.4011e-02,  1.3023e-01,  1.4813e-02,\n         -1.3730e-01, -1.2113e-01, -6.3439e-02,  1.4910e-01,  1.6465e-01,\n         -9.2762e-02, -1.1640e-01, -4.9890e-02, -1.3694e-01,  1.7656e-01,\n          1.5991e-01, -4.1302e-02, -6.2299e-02, -1.1694e-01, -1.2018e-01,\n          2.2508e-02, -1.2837e-01,  2.6457e-02, -6.3531e-02,  1.2361e-01,\n         -1.6786e-01, -1.1470e-01, -1.6255e-01, -4.8543e-02, -7.3636e-02,\n         -6.3577e-02,  1.1136e-01],\n        [-2.3367e-02, -1.7633e-01,  1.5819e-01, -7.0690e-02, -1.1745e-01,\n         -1.4061e-01,  6.7063e-02,  1.1992e-01, -1.3671e-01,  9.9545e-02,\n         -1.0900e-03, -6.9512e-02,  8.0337e-02,  4.5070e-02,  4.6565e-02,\n          3.9632e-02, -4.0325e-02, -1.6355e-02,  1.7460e-01, -1.5695e-01,\n          1.4549e-01, -9.4388e-02,  1.1983e-01,  8.4103e-02,  1.5735e-01,\n         -6.7819e-02, -1.4957e-01,  9.2917e-02, -1.0326e-01,  1.7676e-02,\n         -1.0504e-01, -1.2521e-01],\n        [ 4.6432e-02, -1.3873e-01, -1.1614e-01, -1.0760e-01, -4.5266e-02,\n          1.3039e-01,  1.6714e-01, -1.7676e-01,  3.7213e-02,  1.1791e-01,\n         -1.5207e-02, -1.1776e-01,  6.1093e-02,  6.8097e-02, -5.5996e-02,\n          9.1973e-02,  8.0378e-03,  1.2326e-01, -1.6885e-01, -3.2494e-02,\n          1.0832e-01, -5.5467e-02,  1.5452e-01,  1.6245e-01,  8.2026e-02,\n         -1.2945e-01, -1.1399e-01, -1.0403e-01, -2.7630e-02,  9.0614e-02,\n          1.5065e-01, -8.4561e-02],\n        [-1.2159e-01,  1.0800e-01,  1.3676e-01, -5.5972e-02, -1.3455e-01,\n         -1.7564e-01, -1.4095e-01, -1.3764e-01,  1.0395e-01,  4.6802e-02,\n          1.5522e-01,  1.3930e-02, -1.6447e-01, -7.2447e-02,  1.0071e-01,\n          1.5330e-01, -2.5539e-02, -6.1892e-02,  1.4074e-01, -1.9554e-02,\n         -2.5979e-02, -1.3601e-02,  1.2967e-01, -1.3674e-01, -1.6649e-02,\n         -5.1731e-02, -8.0038e-02, -3.1544e-02,  5.9597e-02,  1.4754e-02,\n          2.8315e-02, -8.3687e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1738, -0.0932, -0.2291, -0.1860, -0.1720, -0.1664, -0.0981, -0.1935],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0534,  0.1325, -0.1353,  0.1564, -0.0356,  0.0277, -0.1212, -0.0015,\n         -0.2342,  0.1259, -0.0572,  0.0569,  0.2387,  0.0088, -0.2060, -0.2253],\n        [ 0.0289,  0.2108,  0.1346,  0.0260, -0.0487,  0.1383,  0.1764,  0.0051,\n          0.0230,  0.0142,  0.0398,  0.1302, -0.2034,  0.1280, -0.0745,  0.2185],\n        [-0.2428, -0.1103, -0.1422,  0.0766, -0.2101, -0.2314,  0.1827,  0.2355,\n         -0.0233, -0.0300,  0.1968,  0.1353,  0.1306,  0.0537,  0.0095, -0.1340],\n        [-0.2424, -0.0272, -0.1779, -0.0432,  0.2120,  0.2139,  0.1562, -0.0625,\n          0.1994,  0.1673,  0.1255, -0.2490, -0.2084,  0.1249,  0.1046, -0.1214],\n        [ 0.0664,  0.1759, -0.0024,  0.2139, -0.0785, -0.0022, -0.0587,  0.0820,\n          0.2280,  0.0217, -0.0484,  0.0969,  0.0393, -0.1298, -0.0037, -0.1256],\n        [-0.1354, -0.1480,  0.0715,  0.0922, -0.0410,  0.0232,  0.2226, -0.2217,\n         -0.0533, -0.0568,  0.1736, -0.0662, -0.1026, -0.1853, -0.1366,  0.1422],\n        [-0.0843,  0.1628,  0.1177, -0.1615, -0.0344,  0.2361,  0.0129,  0.0256,\n         -0.0363,  0.1443,  0.1191,  0.1817, -0.1114,  0.0179, -0.1644,  0.0870],\n        [-0.0859,  0.1136, -0.2210,  0.0147,  0.2039, -0.0619,  0.1518,  0.2144,\n         -0.0658,  0.2195,  0.2451,  0.0475, -0.1705, -0.1717,  0.0226, -0.1867]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2633], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0304,  0.2553, -0.2130, -0.0355, -0.0106, -0.0137,  0.3443,  0.2017]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x70178bce1b10>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s226320000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s226320000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}