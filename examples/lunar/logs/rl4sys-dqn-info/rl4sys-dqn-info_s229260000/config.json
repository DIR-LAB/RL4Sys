{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s229260000"
    },
    "q_lr":	0.0005,
    "seed":	229260000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x77ce640d3c10>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1423,  0.2370,  0.0588,  0.2880,  0.1620, -0.1486,  0.0408,  0.2589,\n         0.2796,  0.0849, -0.2557, -0.1839, -0.2187,  0.1114, -0.3288,  0.0365,\n         0.1286, -0.0930,  0.1208, -0.2612,  0.0786,  0.3367, -0.0734,  0.0872,\n         0.1844, -0.3474,  0.3430,  0.2823, -0.3300, -0.2039,  0.3250,  0.2787],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-2.6522e-01,  2.2437e-01, -2.3731e-01, -5.3074e-02,  4.2033e-02,\n         -5.9947e-02,  2.4906e-01, -1.2538e-01],\n        [-3.0632e-01, -2.1238e-01, -2.2450e-01, -2.6250e-01, -7.5275e-02,\n          8.7820e-02, -3.5077e-01, -2.1213e-01],\n        [ 1.3320e-01,  2.3304e-01,  1.4310e-03,  2.6203e-01, -1.9169e-01,\n         -2.4673e-01, -1.0207e-01,  1.3194e-01],\n        [ 2.2460e-02,  1.4163e-01, -7.8439e-02,  3.4340e-01, -1.0018e-01,\n          2.6443e-01,  1.0927e-01,  1.9535e-01],\n        [-2.2908e-01, -7.3571e-02, -1.4578e-01,  1.3386e-01, -9.5470e-02,\n         -1.9713e-01,  1.3913e-02,  2.0158e-01],\n        [-1.7254e-01,  2.0715e-01, -2.2144e-01, -1.9457e-01, -2.2108e-01,\n         -1.7342e-01, -1.9370e-01, -6.4323e-02],\n        [-9.6429e-02, -3.0184e-02,  3.2316e-01,  3.3793e-01,  1.0749e-01,\n          1.7731e-01, -2.4875e-01,  2.6978e-01],\n        [-1.8026e-01, -2.7377e-01, -7.6561e-02,  2.8024e-01, -2.8692e-01,\n         -1.4051e-01,  2.0627e-01,  9.8804e-02],\n        [-2.3849e-01,  1.2478e-01,  1.5711e-01,  9.6550e-02,  3.4999e-01,\n         -2.2795e-01, -9.7429e-02, -1.6545e-01],\n        [-2.8841e-01, -1.4629e-02,  1.7662e-01,  1.8543e-01,  8.1029e-02,\n         -1.2229e-01,  1.2644e-04,  3.3971e-01],\n        [ 1.5097e-01,  2.8795e-01, -1.9615e-01,  5.7703e-02,  2.1736e-01,\n         -8.3128e-02, -1.1988e-01, -1.2243e-01],\n        [-1.2389e-01,  2.3260e-01, -1.2990e-02,  8.7717e-02, -2.9643e-01,\n          1.4415e-02,  6.1463e-02, -1.2044e-01],\n        [ 1.8264e-02,  3.2430e-01,  5.1821e-02, -2.3340e-01, -4.6079e-02,\n          2.7001e-01, -3.9015e-03,  2.9430e-01],\n        [ 5.8765e-02, -9.8199e-02,  1.5264e-02, -3.3217e-01,  1.8193e-01,\n          1.0805e-01, -1.8295e-01,  2.4575e-01],\n        [-2.0856e-01, -3.1858e-01,  3.0255e-01,  2.0189e-01,  1.3766e-02,\n          2.2329e-01, -3.1243e-01,  1.7368e-01],\n        [-1.7042e-01, -1.3201e-01, -3.3787e-01, -3.2457e-01,  3.0431e-01,\n         -2.5132e-02, -8.8897e-03,  2.9402e-01],\n        [-1.2983e-01, -2.8523e-01,  1.8682e-01,  2.0950e-01,  3.7983e-02,\n          9.1417e-04,  3.2385e-01,  3.3901e-01],\n        [-2.2673e-01, -2.5192e-01,  3.1504e-01,  2.4180e-01,  2.3972e-01,\n         -1.2555e-01, -3.0771e-01, -1.4036e-01],\n        [-3.4580e-01, -2.0699e-01,  6.9496e-02,  6.7501e-02,  1.7068e-01,\n         -8.7006e-02, -9.6087e-02, -9.8813e-02],\n        [-2.4091e-01, -2.7191e-01, -1.4209e-01,  2.0368e-01,  2.6148e-01,\n         -1.8245e-02, -1.5389e-01, -1.2265e-01],\n        [ 1.2095e-01,  3.5254e-01, -2.0805e-01,  3.4605e-01,  1.7332e-01,\n          2.9858e-01,  2.4322e-01,  2.8027e-01],\n        [-3.0683e-01, -1.4867e-01,  8.5257e-02, -5.6566e-02, -3.2713e-01,\n         -6.4236e-02, -8.5486e-03, -1.9867e-01],\n        [ 2.1783e-01, -1.9225e-01, -2.3255e-01,  2.0382e-01, -2.6670e-01,\n         -3.9147e-02, -2.6351e-01, -6.4351e-03],\n        [-3.3228e-01, -9.2410e-02, -3.0928e-01, -2.6710e-01,  8.1027e-02,\n         -2.8485e-01, -1.1285e-01, -1.1653e-01],\n        [ 8.4348e-02, -3.2406e-01,  3.1221e-01, -2.3708e-01,  2.6545e-01,\n         -1.3053e-01,  2.8161e-01,  2.1068e-03],\n        [-1.3578e-01, -6.3256e-03,  2.0233e-01,  1.3736e-01, -1.1925e-01,\n          1.0509e-02, -6.8376e-02,  2.8808e-01],\n        [-1.3050e-01,  1.0453e-01,  9.4949e-02,  2.4345e-01, -8.6376e-02,\n          1.8980e-01, -1.0426e-02,  1.7226e-01],\n        [-2.9951e-01,  3.1818e-01,  3.2189e-01,  2.7749e-01, -2.9001e-01,\n         -3.3464e-01, -2.9630e-01, -1.7016e-01],\n        [-8.4174e-02,  1.7899e-01,  3.0478e-01,  6.0528e-03, -3.5261e-01,\n         -2.8712e-01, -7.6116e-02, -4.3042e-02],\n        [-1.2710e-02,  2.6761e-01, -3.2817e-01,  1.8080e-01, -2.9309e-01,\n          2.8536e-01,  2.6901e-01,  3.4889e-01],\n        [-7.0966e-02,  1.3422e-01, -1.4916e-01,  1.1726e-02, -1.5794e-01,\n         -3.0740e-01,  1.9393e-02, -3.3395e-01],\n        [-7.0475e-02,  1.4654e-01,  1.1477e-01,  2.0801e-01,  2.9830e-01,\n          2.2610e-01,  6.4250e-02,  8.4696e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0957,  0.0135, -0.1066, -0.0500,  0.1301, -0.0537, -0.0112,  0.1718,\n        -0.0670, -0.0868,  0.0288,  0.1517, -0.0172,  0.1369, -0.0572,  0.0567],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1029,  0.0567, -0.1539, -0.1075, -0.0572,  0.0874,  0.0023,  0.1479,\n         -0.1343,  0.0398, -0.1690, -0.0191, -0.1214,  0.0143, -0.0968,  0.1586,\n         -0.0884,  0.1679, -0.0488, -0.1151, -0.1077,  0.1012,  0.0327,  0.0488,\n          0.0862,  0.0922, -0.1536,  0.1077, -0.1132, -0.0013,  0.1124,  0.1014],\n        [ 0.1266,  0.0414,  0.0045, -0.1712,  0.0973,  0.1491, -0.1164, -0.1639,\n          0.0747, -0.1378, -0.0239,  0.0356, -0.0216, -0.1523, -0.1725, -0.1066,\n          0.0161,  0.0512, -0.0681,  0.0829, -0.0306, -0.0795, -0.0654, -0.0811,\n         -0.0843,  0.1446,  0.0971,  0.1394,  0.0047,  0.0623,  0.0286, -0.0361],\n        [ 0.0586,  0.0142,  0.1180,  0.0144,  0.0088, -0.1171,  0.1592,  0.0739,\n          0.0913,  0.1455, -0.1512,  0.0558, -0.0162,  0.0042, -0.0611,  0.0708,\n         -0.1079,  0.1100,  0.0106, -0.1017,  0.1502, -0.0984,  0.1412,  0.1319,\n          0.0898,  0.0049,  0.0152, -0.0817,  0.0282,  0.0790, -0.1579, -0.0820],\n        [-0.1294, -0.0839,  0.0092, -0.0576, -0.0431,  0.0805, -0.0303, -0.1719,\n         -0.1006,  0.0654, -0.1092, -0.0389, -0.1646,  0.0898,  0.0948,  0.1596,\n         -0.1241,  0.0149, -0.0819,  0.0251, -0.0359, -0.1024,  0.1730, -0.1727,\n          0.0694,  0.0224, -0.1256, -0.0267,  0.0378, -0.1193,  0.1684, -0.1009],\n        [ 0.1702, -0.0198,  0.1215, -0.1590, -0.1311,  0.0611,  0.1297, -0.0856,\n         -0.0642,  0.1211,  0.1426, -0.0332, -0.1479, -0.1418, -0.1638, -0.1681,\n         -0.1718,  0.0118, -0.0508,  0.1347, -0.1251, -0.1372,  0.0898,  0.0110,\n         -0.1451,  0.0954,  0.1001, -0.0384,  0.1426, -0.1689, -0.1545, -0.1306],\n        [ 0.1142,  0.0941,  0.0187, -0.0603,  0.0711, -0.1094, -0.1082, -0.1382,\n          0.0343, -0.0783, -0.0963,  0.0743,  0.0353, -0.0247,  0.0903,  0.1526,\n          0.1498,  0.1495,  0.1299,  0.1647, -0.0243,  0.1238,  0.1484, -0.1084,\n          0.0209,  0.0888, -0.1438, -0.1471,  0.0491,  0.1579,  0.0426, -0.0739],\n        [ 0.1123,  0.0873,  0.0044,  0.1430,  0.1363,  0.1253, -0.0573,  0.1046,\n          0.1166,  0.1482, -0.0459, -0.0967, -0.0450,  0.0242,  0.1433,  0.1362,\n         -0.1017,  0.1052, -0.0046, -0.1008, -0.0257,  0.1588,  0.0572, -0.1347,\n         -0.0716, -0.0153,  0.1241,  0.0257,  0.0779,  0.1507, -0.1404,  0.0584],\n        [ 0.0456, -0.1537,  0.0387,  0.0019,  0.1186,  0.1402,  0.0132,  0.1404,\n          0.1751,  0.0953, -0.0973, -0.0550, -0.1436, -0.0757, -0.1125, -0.0308,\n         -0.0562,  0.0977,  0.0969, -0.0729, -0.1493,  0.0614,  0.0855,  0.0148,\n          0.1208, -0.0735, -0.1419,  0.1102, -0.0508, -0.0523,  0.1018, -0.0604],\n        [-0.0079, -0.1463, -0.1337,  0.0968,  0.0869,  0.1301,  0.1182, -0.0571,\n          0.0537, -0.0167,  0.0145,  0.0416, -0.0555, -0.0888, -0.0708, -0.1647,\n         -0.1652, -0.0301,  0.0335, -0.0434, -0.0014, -0.1095,  0.1512,  0.0886,\n         -0.1040, -0.1432,  0.1172, -0.1152, -0.0800,  0.1537,  0.0345,  0.0957],\n        [ 0.1312, -0.1606,  0.0602, -0.1615, -0.0555,  0.1587,  0.1569, -0.0418,\n         -0.0463, -0.0024, -0.1325,  0.0456, -0.0430,  0.0138, -0.1525,  0.0664,\n         -0.0270,  0.0825,  0.0198,  0.0460, -0.1619,  0.0972,  0.0539,  0.0651,\n          0.0921,  0.0528,  0.0996, -0.1490,  0.1120,  0.0687, -0.0894, -0.1759],\n        [ 0.0268,  0.0088,  0.1731, -0.0134, -0.1206, -0.1194, -0.1252, -0.0284,\n         -0.0123, -0.1727,  0.0059,  0.0066,  0.0118,  0.1117, -0.1611, -0.1655,\n         -0.0506,  0.0924, -0.1439, -0.0297, -0.0161, -0.0277, -0.0152, -0.0076,\n          0.0625, -0.0925, -0.0948, -0.1131, -0.1286,  0.0346, -0.1313,  0.0721],\n        [ 0.0748,  0.0500,  0.0610, -0.0609,  0.1340,  0.1159,  0.0173,  0.1569,\n         -0.0172,  0.1587,  0.1119, -0.1560,  0.1510, -0.1059, -0.0522, -0.0166,\n         -0.1552, -0.1353,  0.1123, -0.1693, -0.1001,  0.0657,  0.1273, -0.1516,\n         -0.0724,  0.1013, -0.1219, -0.0147, -0.1654, -0.1530,  0.0302,  0.0547],\n        [ 0.1180,  0.1222, -0.0708,  0.0819, -0.1044,  0.0505, -0.0451,  0.0080,\n          0.1699,  0.0495,  0.0418,  0.0671,  0.0407,  0.0065, -0.1627,  0.0662,\n          0.0039, -0.0159,  0.0287,  0.0283, -0.0437,  0.0818,  0.1705, -0.0165,\n         -0.0026, -0.0429, -0.0437,  0.1236, -0.1123,  0.0971,  0.0181, -0.1459],\n        [ 0.1344,  0.1042, -0.1091,  0.0173, -0.1391,  0.1219,  0.0070,  0.0094,\n         -0.0993, -0.1569,  0.0949, -0.0682, -0.0939, -0.1590, -0.0613,  0.1308,\n          0.1438, -0.1627, -0.0123,  0.0717, -0.1409,  0.1107, -0.0442,  0.0118,\n          0.0717,  0.1689, -0.0292, -0.1546,  0.0388,  0.1118, -0.1396, -0.0083],\n        [-0.1228,  0.0602,  0.0910,  0.0234,  0.0993, -0.0444,  0.0088, -0.1373,\n          0.1399, -0.0538, -0.0826,  0.0412, -0.1063, -0.1767,  0.0624,  0.0065,\n          0.1577,  0.1489, -0.1585, -0.1702,  0.1338,  0.1427,  0.0392, -0.0517,\n          0.1663,  0.0816, -0.0070,  0.0771,  0.1404,  0.1179, -0.1033, -0.0204],\n        [-0.1051, -0.0562,  0.1086,  0.0760, -0.0406, -0.0446, -0.0536, -0.0061,\n          0.1559,  0.1456, -0.1558,  0.0171,  0.1392, -0.1611, -0.0720,  0.0503,\n          0.0788, -0.0673,  0.1421,  0.1069, -0.0389,  0.0765, -0.1751,  0.0155,\n          0.1550, -0.0045,  0.0227, -0.0946,  0.0525,  0.1239, -0.0634,  0.0055]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1813,  0.0463,  0.0975, -0.0157, -0.2030,  0.0831,  0.1452,  0.0955],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2247, -0.2312, -0.1262, -0.0266, -0.0604,  0.0837,  0.0962, -0.1060,\n          0.0573, -0.0832, -0.1350, -0.1629,  0.0657,  0.1659, -0.2177, -0.2355],\n        [-0.2268, -0.1547, -0.0301, -0.1620,  0.0736, -0.0443,  0.2445, -0.0061,\n          0.0053, -0.1378,  0.2429,  0.0487,  0.1845, -0.0053,  0.1747, -0.1983],\n        [ 0.1328, -0.1628, -0.1172,  0.1020, -0.1444,  0.1551,  0.1752,  0.0733,\n         -0.0288, -0.1531, -0.2051,  0.0875,  0.0708, -0.1616,  0.0554,  0.0234],\n        [ 0.2356, -0.1662, -0.1667, -0.2310, -0.2265,  0.1430,  0.1039, -0.0640,\n         -0.0246,  0.1741,  0.1905,  0.0879, -0.1964,  0.1950,  0.0973, -0.0782],\n        [-0.0875, -0.0261,  0.1651,  0.0546, -0.1256,  0.0686,  0.2208,  0.2187,\n         -0.2008,  0.1142,  0.1219, -0.0923, -0.1567, -0.0409,  0.2442, -0.0141],\n        [ 0.0381, -0.0545,  0.1364, -0.1182,  0.1339,  0.2231, -0.0192, -0.0264,\n         -0.2026, -0.1689, -0.1993, -0.0747, -0.0544,  0.1157, -0.0793, -0.0423],\n        [ 0.1338,  0.1851,  0.0383, -0.1667,  0.1216,  0.0576, -0.2067,  0.1883,\n         -0.1918,  0.1510, -0.1961,  0.0490, -0.1017, -0.1231,  0.1795, -0.0260],\n        [ 0.2083,  0.0652, -0.0663, -0.1955,  0.2201, -0.1233, -0.0034, -0.0211,\n         -0.0415, -0.1764, -0.1543,  0.0752, -0.1047,  0.2432, -0.0209, -0.0428]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0105,  0.1977, -0.0150,  0.1587], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0123,  0.1546, -0.1215,  0.3053, -0.1891, -0.2970, -0.3362,  0.1748],\n        [ 0.1475, -0.2562, -0.0374, -0.2000, -0.1384,  0.2946,  0.2128, -0.0622],\n        [-0.3375,  0.0895, -0.0287, -0.2006,  0.2299,  0.2054, -0.3410,  0.3019],\n        [ 0.2814,  0.1220, -0.1147,  0.3156,  0.2861,  0.1919, -0.2289,  0.1982]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-2.6522e-01,  2.2437e-01, -2.3731e-01, -5.3074e-02,  4.2033e-02,\n         -5.9947e-02,  2.4906e-01, -1.2538e-01],\n        [-3.0632e-01, -2.1238e-01, -2.2450e-01, -2.6250e-01, -7.5275e-02,\n          8.7820e-02, -3.5077e-01, -2.1213e-01],\n        [ 1.3320e-01,  2.3304e-01,  1.4310e-03,  2.6203e-01, -1.9169e-01,\n         -2.4673e-01, -1.0207e-01,  1.3194e-01],\n        [ 2.2460e-02,  1.4163e-01, -7.8439e-02,  3.4340e-01, -1.0018e-01,\n          2.6443e-01,  1.0927e-01,  1.9535e-01],\n        [-2.2908e-01, -7.3571e-02, -1.4578e-01,  1.3386e-01, -9.5470e-02,\n         -1.9713e-01,  1.3913e-02,  2.0158e-01],\n        [-1.7254e-01,  2.0715e-01, -2.2144e-01, -1.9457e-01, -2.2108e-01,\n         -1.7342e-01, -1.9370e-01, -6.4323e-02],\n        [-9.6429e-02, -3.0184e-02,  3.2316e-01,  3.3793e-01,  1.0749e-01,\n          1.7731e-01, -2.4875e-01,  2.6978e-01],\n        [-1.8026e-01, -2.7377e-01, -7.6561e-02,  2.8024e-01, -2.8692e-01,\n         -1.4051e-01,  2.0627e-01,  9.8804e-02],\n        [-2.3849e-01,  1.2478e-01,  1.5711e-01,  9.6550e-02,  3.4999e-01,\n         -2.2795e-01, -9.7429e-02, -1.6545e-01],\n        [-2.8841e-01, -1.4629e-02,  1.7662e-01,  1.8543e-01,  8.1029e-02,\n         -1.2229e-01,  1.2644e-04,  3.3971e-01],\n        [ 1.5097e-01,  2.8795e-01, -1.9615e-01,  5.7703e-02,  2.1736e-01,\n         -8.3128e-02, -1.1988e-01, -1.2243e-01],\n        [-1.2389e-01,  2.3260e-01, -1.2990e-02,  8.7717e-02, -2.9643e-01,\n          1.4415e-02,  6.1463e-02, -1.2044e-01],\n        [ 1.8264e-02,  3.2430e-01,  5.1821e-02, -2.3340e-01, -4.6079e-02,\n          2.7001e-01, -3.9015e-03,  2.9430e-01],\n        [ 5.8765e-02, -9.8199e-02,  1.5264e-02, -3.3217e-01,  1.8193e-01,\n          1.0805e-01, -1.8295e-01,  2.4575e-01],\n        [-2.0856e-01, -3.1858e-01,  3.0255e-01,  2.0189e-01,  1.3766e-02,\n          2.2329e-01, -3.1243e-01,  1.7368e-01],\n        [-1.7042e-01, -1.3201e-01, -3.3787e-01, -3.2457e-01,  3.0431e-01,\n         -2.5132e-02, -8.8897e-03,  2.9402e-01],\n        [-1.2983e-01, -2.8523e-01,  1.8682e-01,  2.0950e-01,  3.7983e-02,\n          9.1417e-04,  3.2385e-01,  3.3901e-01],\n        [-2.2673e-01, -2.5192e-01,  3.1504e-01,  2.4180e-01,  2.3972e-01,\n         -1.2555e-01, -3.0771e-01, -1.4036e-01],\n        [-3.4580e-01, -2.0699e-01,  6.9496e-02,  6.7501e-02,  1.7068e-01,\n         -8.7006e-02, -9.6087e-02, -9.8813e-02],\n        [-2.4091e-01, -2.7191e-01, -1.4209e-01,  2.0368e-01,  2.6148e-01,\n         -1.8245e-02, -1.5389e-01, -1.2265e-01],\n        [ 1.2095e-01,  3.5254e-01, -2.0805e-01,  3.4605e-01,  1.7332e-01,\n          2.9858e-01,  2.4322e-01,  2.8027e-01],\n        [-3.0683e-01, -1.4867e-01,  8.5257e-02, -5.6566e-02, -3.2713e-01,\n         -6.4236e-02, -8.5486e-03, -1.9867e-01],\n        [ 2.1783e-01, -1.9225e-01, -2.3255e-01,  2.0382e-01, -2.6670e-01,\n         -3.9147e-02, -2.6351e-01, -6.4351e-03],\n        [-3.3228e-01, -9.2410e-02, -3.0928e-01, -2.6710e-01,  8.1027e-02,\n         -2.8485e-01, -1.1285e-01, -1.1653e-01],\n        [ 8.4348e-02, -3.2406e-01,  3.1221e-01, -2.3708e-01,  2.6545e-01,\n         -1.3053e-01,  2.8161e-01,  2.1068e-03],\n        [-1.3578e-01, -6.3256e-03,  2.0233e-01,  1.3736e-01, -1.1925e-01,\n          1.0509e-02, -6.8376e-02,  2.8808e-01],\n        [-1.3050e-01,  1.0453e-01,  9.4949e-02,  2.4345e-01, -8.6376e-02,\n          1.8980e-01, -1.0426e-02,  1.7226e-01],\n        [-2.9951e-01,  3.1818e-01,  3.2189e-01,  2.7749e-01, -2.9001e-01,\n         -3.3464e-01, -2.9630e-01, -1.7016e-01],\n        [-8.4174e-02,  1.7899e-01,  3.0478e-01,  6.0528e-03, -3.5261e-01,\n         -2.8712e-01, -7.6116e-02, -4.3042e-02],\n        [-1.2710e-02,  2.6761e-01, -3.2817e-01,  1.8080e-01, -2.9309e-01,\n          2.8536e-01,  2.6901e-01,  3.4889e-01],\n        [-7.0966e-02,  1.3422e-01, -1.4916e-01,  1.1726e-02, -1.5794e-01,\n         -3.0740e-01,  1.9393e-02, -3.3395e-01],\n        [-7.0475e-02,  1.4654e-01,  1.1477e-01,  2.0801e-01,  2.9830e-01,\n          2.2610e-01,  6.4250e-02,  8.4696e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1423,  0.2370,  0.0588,  0.2880,  0.1620, -0.1486,  0.0408,  0.2589,\n         0.2796,  0.0849, -0.2557, -0.1839, -0.2187,  0.1114, -0.3288,  0.0365,\n         0.1286, -0.0930,  0.1208, -0.2612,  0.0786,  0.3367, -0.0734,  0.0872,\n         0.1844, -0.3474,  0.3430,  0.2823, -0.3300, -0.2039,  0.3250,  0.2787],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1029,  0.0567, -0.1539, -0.1075, -0.0572,  0.0874,  0.0023,  0.1479,\n         -0.1343,  0.0398, -0.1690, -0.0191, -0.1214,  0.0143, -0.0968,  0.1586,\n         -0.0884,  0.1679, -0.0488, -0.1151, -0.1077,  0.1012,  0.0327,  0.0488,\n          0.0862,  0.0922, -0.1536,  0.1077, -0.1132, -0.0013,  0.1124,  0.1014],\n        [ 0.1266,  0.0414,  0.0045, -0.1712,  0.0973,  0.1491, -0.1164, -0.1639,\n          0.0747, -0.1378, -0.0239,  0.0356, -0.0216, -0.1523, -0.1725, -0.1066,\n          0.0161,  0.0512, -0.0681,  0.0829, -0.0306, -0.0795, -0.0654, -0.0811,\n         -0.0843,  0.1446,  0.0971,  0.1394,  0.0047,  0.0623,  0.0286, -0.0361],\n        [ 0.0586,  0.0142,  0.1180,  0.0144,  0.0088, -0.1171,  0.1592,  0.0739,\n          0.0913,  0.1455, -0.1512,  0.0558, -0.0162,  0.0042, -0.0611,  0.0708,\n         -0.1079,  0.1100,  0.0106, -0.1017,  0.1502, -0.0984,  0.1412,  0.1319,\n          0.0898,  0.0049,  0.0152, -0.0817,  0.0282,  0.0790, -0.1579, -0.0820],\n        [-0.1294, -0.0839,  0.0092, -0.0576, -0.0431,  0.0805, -0.0303, -0.1719,\n         -0.1006,  0.0654, -0.1092, -0.0389, -0.1646,  0.0898,  0.0948,  0.1596,\n         -0.1241,  0.0149, -0.0819,  0.0251, -0.0359, -0.1024,  0.1730, -0.1727,\n          0.0694,  0.0224, -0.1256, -0.0267,  0.0378, -0.1193,  0.1684, -0.1009],\n        [ 0.1702, -0.0198,  0.1215, -0.1590, -0.1311,  0.0611,  0.1297, -0.0856,\n         -0.0642,  0.1211,  0.1426, -0.0332, -0.1479, -0.1418, -0.1638, -0.1681,\n         -0.1718,  0.0118, -0.0508,  0.1347, -0.1251, -0.1372,  0.0898,  0.0110,\n         -0.1451,  0.0954,  0.1001, -0.0384,  0.1426, -0.1689, -0.1545, -0.1306],\n        [ 0.1142,  0.0941,  0.0187, -0.0603,  0.0711, -0.1094, -0.1082, -0.1382,\n          0.0343, -0.0783, -0.0963,  0.0743,  0.0353, -0.0247,  0.0903,  0.1526,\n          0.1498,  0.1495,  0.1299,  0.1647, -0.0243,  0.1238,  0.1484, -0.1084,\n          0.0209,  0.0888, -0.1438, -0.1471,  0.0491,  0.1579,  0.0426, -0.0739],\n        [ 0.1123,  0.0873,  0.0044,  0.1430,  0.1363,  0.1253, -0.0573,  0.1046,\n          0.1166,  0.1482, -0.0459, -0.0967, -0.0450,  0.0242,  0.1433,  0.1362,\n         -0.1017,  0.1052, -0.0046, -0.1008, -0.0257,  0.1588,  0.0572, -0.1347,\n         -0.0716, -0.0153,  0.1241,  0.0257,  0.0779,  0.1507, -0.1404,  0.0584],\n        [ 0.0456, -0.1537,  0.0387,  0.0019,  0.1186,  0.1402,  0.0132,  0.1404,\n          0.1751,  0.0953, -0.0973, -0.0550, -0.1436, -0.0757, -0.1125, -0.0308,\n         -0.0562,  0.0977,  0.0969, -0.0729, -0.1493,  0.0614,  0.0855,  0.0148,\n          0.1208, -0.0735, -0.1419,  0.1102, -0.0508, -0.0523,  0.1018, -0.0604],\n        [-0.0079, -0.1463, -0.1337,  0.0968,  0.0869,  0.1301,  0.1182, -0.0571,\n          0.0537, -0.0167,  0.0145,  0.0416, -0.0555, -0.0888, -0.0708, -0.1647,\n         -0.1652, -0.0301,  0.0335, -0.0434, -0.0014, -0.1095,  0.1512,  0.0886,\n         -0.1040, -0.1432,  0.1172, -0.1152, -0.0800,  0.1537,  0.0345,  0.0957],\n        [ 0.1312, -0.1606,  0.0602, -0.1615, -0.0555,  0.1587,  0.1569, -0.0418,\n         -0.0463, -0.0024, -0.1325,  0.0456, -0.0430,  0.0138, -0.1525,  0.0664,\n         -0.0270,  0.0825,  0.0198,  0.0460, -0.1619,  0.0972,  0.0539,  0.0651,\n          0.0921,  0.0528,  0.0996, -0.1490,  0.1120,  0.0687, -0.0894, -0.1759],\n        [ 0.0268,  0.0088,  0.1731, -0.0134, -0.1206, -0.1194, -0.1252, -0.0284,\n         -0.0123, -0.1727,  0.0059,  0.0066,  0.0118,  0.1117, -0.1611, -0.1655,\n         -0.0506,  0.0924, -0.1439, -0.0297, -0.0161, -0.0277, -0.0152, -0.0076,\n          0.0625, -0.0925, -0.0948, -0.1131, -0.1286,  0.0346, -0.1313,  0.0721],\n        [ 0.0748,  0.0500,  0.0610, -0.0609,  0.1340,  0.1159,  0.0173,  0.1569,\n         -0.0172,  0.1587,  0.1119, -0.1560,  0.1510, -0.1059, -0.0522, -0.0166,\n         -0.1552, -0.1353,  0.1123, -0.1693, -0.1001,  0.0657,  0.1273, -0.1516,\n         -0.0724,  0.1013, -0.1219, -0.0147, -0.1654, -0.1530,  0.0302,  0.0547],\n        [ 0.1180,  0.1222, -0.0708,  0.0819, -0.1044,  0.0505, -0.0451,  0.0080,\n          0.1699,  0.0495,  0.0418,  0.0671,  0.0407,  0.0065, -0.1627,  0.0662,\n          0.0039, -0.0159,  0.0287,  0.0283, -0.0437,  0.0818,  0.1705, -0.0165,\n         -0.0026, -0.0429, -0.0437,  0.1236, -0.1123,  0.0971,  0.0181, -0.1459],\n        [ 0.1344,  0.1042, -0.1091,  0.0173, -0.1391,  0.1219,  0.0070,  0.0094,\n         -0.0993, -0.1569,  0.0949, -0.0682, -0.0939, -0.1590, -0.0613,  0.1308,\n          0.1438, -0.1627, -0.0123,  0.0717, -0.1409,  0.1107, -0.0442,  0.0118,\n          0.0717,  0.1689, -0.0292, -0.1546,  0.0388,  0.1118, -0.1396, -0.0083],\n        [-0.1228,  0.0602,  0.0910,  0.0234,  0.0993, -0.0444,  0.0088, -0.1373,\n          0.1399, -0.0538, -0.0826,  0.0412, -0.1063, -0.1767,  0.0624,  0.0065,\n          0.1577,  0.1489, -0.1585, -0.1702,  0.1338,  0.1427,  0.0392, -0.0517,\n          0.1663,  0.0816, -0.0070,  0.0771,  0.1404,  0.1179, -0.1033, -0.0204],\n        [-0.1051, -0.0562,  0.1086,  0.0760, -0.0406, -0.0446, -0.0536, -0.0061,\n          0.1559,  0.1456, -0.1558,  0.0171,  0.1392, -0.1611, -0.0720,  0.0503,\n          0.0788, -0.0673,  0.1421,  0.1069, -0.0389,  0.0765, -0.1751,  0.0155,\n          0.1550, -0.0045,  0.0227, -0.0946,  0.0525,  0.1239, -0.0634,  0.0055]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0957,  0.0135, -0.1066, -0.0500,  0.1301, -0.0537, -0.0112,  0.1718,\n        -0.0670, -0.0868,  0.0288,  0.1517, -0.0172,  0.1369, -0.0572,  0.0567],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2247, -0.2312, -0.1262, -0.0266, -0.0604,  0.0837,  0.0962, -0.1060,\n          0.0573, -0.0832, -0.1350, -0.1629,  0.0657,  0.1659, -0.2177, -0.2355],\n        [-0.2268, -0.1547, -0.0301, -0.1620,  0.0736, -0.0443,  0.2445, -0.0061,\n          0.0053, -0.1378,  0.2429,  0.0487,  0.1845, -0.0053,  0.1747, -0.1983],\n        [ 0.1328, -0.1628, -0.1172,  0.1020, -0.1444,  0.1551,  0.1752,  0.0733,\n         -0.0288, -0.1531, -0.2051,  0.0875,  0.0708, -0.1616,  0.0554,  0.0234],\n        [ 0.2356, -0.1662, -0.1667, -0.2310, -0.2265,  0.1430,  0.1039, -0.0640,\n         -0.0246,  0.1741,  0.1905,  0.0879, -0.1964,  0.1950,  0.0973, -0.0782],\n        [-0.0875, -0.0261,  0.1651,  0.0546, -0.1256,  0.0686,  0.2208,  0.2187,\n         -0.2008,  0.1142,  0.1219, -0.0923, -0.1567, -0.0409,  0.2442, -0.0141],\n        [ 0.0381, -0.0545,  0.1364, -0.1182,  0.1339,  0.2231, -0.0192, -0.0264,\n         -0.2026, -0.1689, -0.1993, -0.0747, -0.0544,  0.1157, -0.0793, -0.0423],\n        [ 0.1338,  0.1851,  0.0383, -0.1667,  0.1216,  0.0576, -0.2067,  0.1883,\n         -0.1918,  0.1510, -0.1961,  0.0490, -0.1017, -0.1231,  0.1795, -0.0260],\n        [ 0.2083,  0.0652, -0.0663, -0.1955,  0.2201, -0.1233, -0.0034, -0.0211,\n         -0.0415, -0.1764, -0.1543,  0.0752, -0.1047,  0.2432, -0.0209, -0.0428]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1813,  0.0463,  0.0975, -0.0157, -0.2030,  0.0831,  0.1452,  0.0955],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0123,  0.1546, -0.1215,  0.3053, -0.1891, -0.2970, -0.3362,  0.1748],\n        [ 0.1475, -0.2562, -0.0374, -0.2000, -0.1384,  0.2946,  0.2128, -0.0622],\n        [-0.3375,  0.0895, -0.0287, -0.2006,  0.2299,  0.2054, -0.3410,  0.3019],\n        [ 0.2814,  0.1220, -0.1147,  0.3156,  0.2861,  0.1919, -0.2289,  0.1982]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0105,  0.1977, -0.0150,  0.1587], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x77ce6377bb90>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1423,  0.2370,  0.0588,  0.2880,  0.1620, -0.1486,  0.0408,  0.2589,\n         0.2796,  0.0849, -0.2557, -0.1839, -0.2187,  0.1114, -0.3288,  0.0365,\n         0.1286, -0.0930,  0.1208, -0.2612,  0.0786,  0.3367, -0.0734,  0.0872,\n         0.1844, -0.3474,  0.3430,  0.2823, -0.3300, -0.2039,  0.3250,  0.2787],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-2.6522e-01,  2.2437e-01, -2.3731e-01, -5.3074e-02,  4.2033e-02,\n         -5.9947e-02,  2.4906e-01, -1.2538e-01],\n        [-3.0632e-01, -2.1238e-01, -2.2450e-01, -2.6250e-01, -7.5275e-02,\n          8.7820e-02, -3.5077e-01, -2.1213e-01],\n        [ 1.3320e-01,  2.3304e-01,  1.4310e-03,  2.6203e-01, -1.9169e-01,\n         -2.4673e-01, -1.0207e-01,  1.3194e-01],\n        [ 2.2460e-02,  1.4163e-01, -7.8439e-02,  3.4340e-01, -1.0018e-01,\n          2.6443e-01,  1.0927e-01,  1.9535e-01],\n        [-2.2908e-01, -7.3571e-02, -1.4578e-01,  1.3386e-01, -9.5470e-02,\n         -1.9713e-01,  1.3913e-02,  2.0158e-01],\n        [-1.7254e-01,  2.0715e-01, -2.2144e-01, -1.9457e-01, -2.2108e-01,\n         -1.7342e-01, -1.9370e-01, -6.4323e-02],\n        [-9.6429e-02, -3.0184e-02,  3.2316e-01,  3.3793e-01,  1.0749e-01,\n          1.7731e-01, -2.4875e-01,  2.6978e-01],\n        [-1.8026e-01, -2.7377e-01, -7.6561e-02,  2.8024e-01, -2.8692e-01,\n         -1.4051e-01,  2.0627e-01,  9.8804e-02],\n        [-2.3849e-01,  1.2478e-01,  1.5711e-01,  9.6550e-02,  3.4999e-01,\n         -2.2795e-01, -9.7429e-02, -1.6545e-01],\n        [-2.8841e-01, -1.4629e-02,  1.7662e-01,  1.8543e-01,  8.1029e-02,\n         -1.2229e-01,  1.2644e-04,  3.3971e-01],\n        [ 1.5097e-01,  2.8795e-01, -1.9615e-01,  5.7703e-02,  2.1736e-01,\n         -8.3128e-02, -1.1988e-01, -1.2243e-01],\n        [-1.2389e-01,  2.3260e-01, -1.2990e-02,  8.7717e-02, -2.9643e-01,\n          1.4415e-02,  6.1463e-02, -1.2044e-01],\n        [ 1.8264e-02,  3.2430e-01,  5.1821e-02, -2.3340e-01, -4.6079e-02,\n          2.7001e-01, -3.9015e-03,  2.9430e-01],\n        [ 5.8765e-02, -9.8199e-02,  1.5264e-02, -3.3217e-01,  1.8193e-01,\n          1.0805e-01, -1.8295e-01,  2.4575e-01],\n        [-2.0856e-01, -3.1858e-01,  3.0255e-01,  2.0189e-01,  1.3766e-02,\n          2.2329e-01, -3.1243e-01,  1.7368e-01],\n        [-1.7042e-01, -1.3201e-01, -3.3787e-01, -3.2457e-01,  3.0431e-01,\n         -2.5132e-02, -8.8897e-03,  2.9402e-01],\n        [-1.2983e-01, -2.8523e-01,  1.8682e-01,  2.0950e-01,  3.7983e-02,\n          9.1417e-04,  3.2385e-01,  3.3901e-01],\n        [-2.2673e-01, -2.5192e-01,  3.1504e-01,  2.4180e-01,  2.3972e-01,\n         -1.2555e-01, -3.0771e-01, -1.4036e-01],\n        [-3.4580e-01, -2.0699e-01,  6.9496e-02,  6.7501e-02,  1.7068e-01,\n         -8.7006e-02, -9.6087e-02, -9.8813e-02],\n        [-2.4091e-01, -2.7191e-01, -1.4209e-01,  2.0368e-01,  2.6148e-01,\n         -1.8245e-02, -1.5389e-01, -1.2265e-01],\n        [ 1.2095e-01,  3.5254e-01, -2.0805e-01,  3.4605e-01,  1.7332e-01,\n          2.9858e-01,  2.4322e-01,  2.8027e-01],\n        [-3.0683e-01, -1.4867e-01,  8.5257e-02, -5.6566e-02, -3.2713e-01,\n         -6.4236e-02, -8.5486e-03, -1.9867e-01],\n        [ 2.1783e-01, -1.9225e-01, -2.3255e-01,  2.0382e-01, -2.6670e-01,\n         -3.9147e-02, -2.6351e-01, -6.4351e-03],\n        [-3.3228e-01, -9.2410e-02, -3.0928e-01, -2.6710e-01,  8.1027e-02,\n         -2.8485e-01, -1.1285e-01, -1.1653e-01],\n        [ 8.4348e-02, -3.2406e-01,  3.1221e-01, -2.3708e-01,  2.6545e-01,\n         -1.3053e-01,  2.8161e-01,  2.1068e-03],\n        [-1.3578e-01, -6.3256e-03,  2.0233e-01,  1.3736e-01, -1.1925e-01,\n          1.0509e-02, -6.8376e-02,  2.8808e-01],\n        [-1.3050e-01,  1.0453e-01,  9.4949e-02,  2.4345e-01, -8.6376e-02,\n          1.8980e-01, -1.0426e-02,  1.7226e-01],\n        [-2.9951e-01,  3.1818e-01,  3.2189e-01,  2.7749e-01, -2.9001e-01,\n         -3.3464e-01, -2.9630e-01, -1.7016e-01],\n        [-8.4174e-02,  1.7899e-01,  3.0478e-01,  6.0528e-03, -3.5261e-01,\n         -2.8712e-01, -7.6116e-02, -4.3042e-02],\n        [-1.2710e-02,  2.6761e-01, -3.2817e-01,  1.8080e-01, -2.9309e-01,\n          2.8536e-01,  2.6901e-01,  3.4889e-01],\n        [-7.0966e-02,  1.3422e-01, -1.4916e-01,  1.1726e-02, -1.5794e-01,\n         -3.0740e-01,  1.9393e-02, -3.3395e-01],\n        [-7.0475e-02,  1.4654e-01,  1.1477e-01,  2.0801e-01,  2.9830e-01,\n          2.2610e-01,  6.4250e-02,  8.4696e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0957,  0.0135, -0.1066, -0.0500,  0.1301, -0.0537, -0.0112,  0.1718,\n        -0.0670, -0.0868,  0.0288,  0.1517, -0.0172,  0.1369, -0.0572,  0.0567],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1029,  0.0567, -0.1539, -0.1075, -0.0572,  0.0874,  0.0023,  0.1479,\n         -0.1343,  0.0398, -0.1690, -0.0191, -0.1214,  0.0143, -0.0968,  0.1586,\n         -0.0884,  0.1679, -0.0488, -0.1151, -0.1077,  0.1012,  0.0327,  0.0488,\n          0.0862,  0.0922, -0.1536,  0.1077, -0.1132, -0.0013,  0.1124,  0.1014],\n        [ 0.1266,  0.0414,  0.0045, -0.1712,  0.0973,  0.1491, -0.1164, -0.1639,\n          0.0747, -0.1378, -0.0239,  0.0356, -0.0216, -0.1523, -0.1725, -0.1066,\n          0.0161,  0.0512, -0.0681,  0.0829, -0.0306, -0.0795, -0.0654, -0.0811,\n         -0.0843,  0.1446,  0.0971,  0.1394,  0.0047,  0.0623,  0.0286, -0.0361],\n        [ 0.0586,  0.0142,  0.1180,  0.0144,  0.0088, -0.1171,  0.1592,  0.0739,\n          0.0913,  0.1455, -0.1512,  0.0558, -0.0162,  0.0042, -0.0611,  0.0708,\n         -0.1079,  0.1100,  0.0106, -0.1017,  0.1502, -0.0984,  0.1412,  0.1319,\n          0.0898,  0.0049,  0.0152, -0.0817,  0.0282,  0.0790, -0.1579, -0.0820],\n        [-0.1294, -0.0839,  0.0092, -0.0576, -0.0431,  0.0805, -0.0303, -0.1719,\n         -0.1006,  0.0654, -0.1092, -0.0389, -0.1646,  0.0898,  0.0948,  0.1596,\n         -0.1241,  0.0149, -0.0819,  0.0251, -0.0359, -0.1024,  0.1730, -0.1727,\n          0.0694,  0.0224, -0.1256, -0.0267,  0.0378, -0.1193,  0.1684, -0.1009],\n        [ 0.1702, -0.0198,  0.1215, -0.1590, -0.1311,  0.0611,  0.1297, -0.0856,\n         -0.0642,  0.1211,  0.1426, -0.0332, -0.1479, -0.1418, -0.1638, -0.1681,\n         -0.1718,  0.0118, -0.0508,  0.1347, -0.1251, -0.1372,  0.0898,  0.0110,\n         -0.1451,  0.0954,  0.1001, -0.0384,  0.1426, -0.1689, -0.1545, -0.1306],\n        [ 0.1142,  0.0941,  0.0187, -0.0603,  0.0711, -0.1094, -0.1082, -0.1382,\n          0.0343, -0.0783, -0.0963,  0.0743,  0.0353, -0.0247,  0.0903,  0.1526,\n          0.1498,  0.1495,  0.1299,  0.1647, -0.0243,  0.1238,  0.1484, -0.1084,\n          0.0209,  0.0888, -0.1438, -0.1471,  0.0491,  0.1579,  0.0426, -0.0739],\n        [ 0.1123,  0.0873,  0.0044,  0.1430,  0.1363,  0.1253, -0.0573,  0.1046,\n          0.1166,  0.1482, -0.0459, -0.0967, -0.0450,  0.0242,  0.1433,  0.1362,\n         -0.1017,  0.1052, -0.0046, -0.1008, -0.0257,  0.1588,  0.0572, -0.1347,\n         -0.0716, -0.0153,  0.1241,  0.0257,  0.0779,  0.1507, -0.1404,  0.0584],\n        [ 0.0456, -0.1537,  0.0387,  0.0019,  0.1186,  0.1402,  0.0132,  0.1404,\n          0.1751,  0.0953, -0.0973, -0.0550, -0.1436, -0.0757, -0.1125, -0.0308,\n         -0.0562,  0.0977,  0.0969, -0.0729, -0.1493,  0.0614,  0.0855,  0.0148,\n          0.1208, -0.0735, -0.1419,  0.1102, -0.0508, -0.0523,  0.1018, -0.0604],\n        [-0.0079, -0.1463, -0.1337,  0.0968,  0.0869,  0.1301,  0.1182, -0.0571,\n          0.0537, -0.0167,  0.0145,  0.0416, -0.0555, -0.0888, -0.0708, -0.1647,\n         -0.1652, -0.0301,  0.0335, -0.0434, -0.0014, -0.1095,  0.1512,  0.0886,\n         -0.1040, -0.1432,  0.1172, -0.1152, -0.0800,  0.1537,  0.0345,  0.0957],\n        [ 0.1312, -0.1606,  0.0602, -0.1615, -0.0555,  0.1587,  0.1569, -0.0418,\n         -0.0463, -0.0024, -0.1325,  0.0456, -0.0430,  0.0138, -0.1525,  0.0664,\n         -0.0270,  0.0825,  0.0198,  0.0460, -0.1619,  0.0972,  0.0539,  0.0651,\n          0.0921,  0.0528,  0.0996, -0.1490,  0.1120,  0.0687, -0.0894, -0.1759],\n        [ 0.0268,  0.0088,  0.1731, -0.0134, -0.1206, -0.1194, -0.1252, -0.0284,\n         -0.0123, -0.1727,  0.0059,  0.0066,  0.0118,  0.1117, -0.1611, -0.1655,\n         -0.0506,  0.0924, -0.1439, -0.0297, -0.0161, -0.0277, -0.0152, -0.0076,\n          0.0625, -0.0925, -0.0948, -0.1131, -0.1286,  0.0346, -0.1313,  0.0721],\n        [ 0.0748,  0.0500,  0.0610, -0.0609,  0.1340,  0.1159,  0.0173,  0.1569,\n         -0.0172,  0.1587,  0.1119, -0.1560,  0.1510, -0.1059, -0.0522, -0.0166,\n         -0.1552, -0.1353,  0.1123, -0.1693, -0.1001,  0.0657,  0.1273, -0.1516,\n         -0.0724,  0.1013, -0.1219, -0.0147, -0.1654, -0.1530,  0.0302,  0.0547],\n        [ 0.1180,  0.1222, -0.0708,  0.0819, -0.1044,  0.0505, -0.0451,  0.0080,\n          0.1699,  0.0495,  0.0418,  0.0671,  0.0407,  0.0065, -0.1627,  0.0662,\n          0.0039, -0.0159,  0.0287,  0.0283, -0.0437,  0.0818,  0.1705, -0.0165,\n         -0.0026, -0.0429, -0.0437,  0.1236, -0.1123,  0.0971,  0.0181, -0.1459],\n        [ 0.1344,  0.1042, -0.1091,  0.0173, -0.1391,  0.1219,  0.0070,  0.0094,\n         -0.0993, -0.1569,  0.0949, -0.0682, -0.0939, -0.1590, -0.0613,  0.1308,\n          0.1438, -0.1627, -0.0123,  0.0717, -0.1409,  0.1107, -0.0442,  0.0118,\n          0.0717,  0.1689, -0.0292, -0.1546,  0.0388,  0.1118, -0.1396, -0.0083],\n        [-0.1228,  0.0602,  0.0910,  0.0234,  0.0993, -0.0444,  0.0088, -0.1373,\n          0.1399, -0.0538, -0.0826,  0.0412, -0.1063, -0.1767,  0.0624,  0.0065,\n          0.1577,  0.1489, -0.1585, -0.1702,  0.1338,  0.1427,  0.0392, -0.0517,\n          0.1663,  0.0816, -0.0070,  0.0771,  0.1404,  0.1179, -0.1033, -0.0204],\n        [-0.1051, -0.0562,  0.1086,  0.0760, -0.0406, -0.0446, -0.0536, -0.0061,\n          0.1559,  0.1456, -0.1558,  0.0171,  0.1392, -0.1611, -0.0720,  0.0503,\n          0.0788, -0.0673,  0.1421,  0.1069, -0.0389,  0.0765, -0.1751,  0.0155,\n          0.1550, -0.0045,  0.0227, -0.0946,  0.0525,  0.1239, -0.0634,  0.0055]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1813,  0.0463,  0.0975, -0.0157, -0.2030,  0.0831,  0.1452,  0.0955],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2247, -0.2312, -0.1262, -0.0266, -0.0604,  0.0837,  0.0962, -0.1060,\n          0.0573, -0.0832, -0.1350, -0.1629,  0.0657,  0.1659, -0.2177, -0.2355],\n        [-0.2268, -0.1547, -0.0301, -0.1620,  0.0736, -0.0443,  0.2445, -0.0061,\n          0.0053, -0.1378,  0.2429,  0.0487,  0.1845, -0.0053,  0.1747, -0.1983],\n        [ 0.1328, -0.1628, -0.1172,  0.1020, -0.1444,  0.1551,  0.1752,  0.0733,\n         -0.0288, -0.1531, -0.2051,  0.0875,  0.0708, -0.1616,  0.0554,  0.0234],\n        [ 0.2356, -0.1662, -0.1667, -0.2310, -0.2265,  0.1430,  0.1039, -0.0640,\n         -0.0246,  0.1741,  0.1905,  0.0879, -0.1964,  0.1950,  0.0973, -0.0782],\n        [-0.0875, -0.0261,  0.1651,  0.0546, -0.1256,  0.0686,  0.2208,  0.2187,\n         -0.2008,  0.1142,  0.1219, -0.0923, -0.1567, -0.0409,  0.2442, -0.0141],\n        [ 0.0381, -0.0545,  0.1364, -0.1182,  0.1339,  0.2231, -0.0192, -0.0264,\n         -0.2026, -0.1689, -0.1993, -0.0747, -0.0544,  0.1157, -0.0793, -0.0423],\n        [ 0.1338,  0.1851,  0.0383, -0.1667,  0.1216,  0.0576, -0.2067,  0.1883,\n         -0.1918,  0.1510, -0.1961,  0.0490, -0.1017, -0.1231,  0.1795, -0.0260],\n        [ 0.2083,  0.0652, -0.0663, -0.1955,  0.2201, -0.1233, -0.0034, -0.0211,\n         -0.0415, -0.1764, -0.1543,  0.0752, -0.1047,  0.2432, -0.0209, -0.0428]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0105,  0.1977, -0.0150,  0.1587], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0123,  0.1546, -0.1215,  0.3053, -0.1891, -0.2970, -0.3362,  0.1748],\n        [ 0.1475, -0.2562, -0.0374, -0.2000, -0.1384,  0.2946,  0.2128, -0.0622],\n        [-0.3375,  0.0895, -0.0287, -0.2006,  0.2299,  0.2054, -0.3410,  0.3019],\n        [ 0.2814,  0.1220, -0.1147,  0.3156,  0.2861,  0.1919, -0.2289,  0.1982]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x77ce61f2cfd0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s229260000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s229260000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}