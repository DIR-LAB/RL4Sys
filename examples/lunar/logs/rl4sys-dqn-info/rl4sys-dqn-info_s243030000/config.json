{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s243030000"
    },
    "q_lr":	0.0005,
    "seed":	243030000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7d27aae49e50>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3153,  0.2694, -0.0273, -0.1148,  0.1241, -0.2367, -0.0279, -0.3450,\n         0.1775,  0.2022,  0.3157,  0.1889, -0.0012, -0.1090,  0.1515, -0.2535,\n        -0.1579, -0.0135,  0.2423, -0.3219,  0.0205,  0.2738,  0.2953, -0.1912,\n         0.1739, -0.1386, -0.2830, -0.0277,  0.1604, -0.0078, -0.1566,  0.2102],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3437, -0.3486,  0.1177,  0.0632,  0.2638, -0.2759,  0.2184,  0.0363],\n        [ 0.2704, -0.1968, -0.1492,  0.0556,  0.3061,  0.1990, -0.1794, -0.0820],\n        [-0.2612, -0.3013, -0.0768,  0.2260, -0.2163, -0.1694,  0.3180,  0.0136],\n        [-0.0179,  0.2747, -0.3025, -0.1815, -0.3007, -0.0140, -0.1018,  0.1193],\n        [-0.2003,  0.2160, -0.0116,  0.3357,  0.2089,  0.3479,  0.3501, -0.1481],\n        [-0.0985, -0.1500, -0.1208, -0.2285,  0.2959, -0.3121,  0.0404,  0.2322],\n        [-0.3142,  0.0079, -0.0935,  0.1383,  0.2595,  0.1562, -0.2016,  0.0518],\n        [ 0.1373, -0.2517, -0.3262, -0.0471,  0.2023, -0.2783,  0.1693, -0.2424],\n        [-0.0812, -0.3173, -0.2896,  0.0348,  0.1196,  0.2749,  0.0014,  0.2852],\n        [ 0.1022,  0.3239, -0.3264, -0.1273, -0.3321, -0.1706,  0.0331,  0.1264],\n        [-0.3233,  0.1866, -0.3015, -0.1828, -0.1528,  0.0620, -0.1553, -0.3275],\n        [ 0.0974,  0.1730,  0.2419, -0.2432,  0.0704, -0.3164,  0.0238,  0.1835],\n        [ 0.2052, -0.0937, -0.1031,  0.1887,  0.1097,  0.3137, -0.1189, -0.0819],\n        [ 0.0583, -0.0345, -0.2254,  0.3201, -0.3424,  0.1490,  0.2224,  0.1671],\n        [-0.0171, -0.0145,  0.0915,  0.1188, -0.0857, -0.0383, -0.2255,  0.1639],\n        [-0.2767,  0.3151, -0.2843, -0.3248, -0.2207, -0.3481, -0.1168,  0.1404],\n        [-0.1451,  0.1116, -0.0267,  0.2408,  0.1892, -0.1863,  0.3217, -0.1176],\n        [ 0.2453, -0.1518,  0.1463,  0.1152,  0.3239,  0.1537, -0.3491, -0.2485],\n        [-0.3149,  0.3120, -0.2655, -0.1560, -0.2725,  0.1311,  0.0599, -0.0630],\n        [-0.1569, -0.2913, -0.3195, -0.0172,  0.3203, -0.2035,  0.0326,  0.1596],\n        [-0.0458, -0.0658, -0.3251, -0.0853, -0.2498,  0.2490,  0.3109,  0.2589],\n        [-0.2195, -0.0375, -0.1514, -0.0042, -0.0125,  0.2851,  0.0707,  0.3479],\n        [-0.2129, -0.1104, -0.0273, -0.1812, -0.0729, -0.0278,  0.2386, -0.1328],\n        [-0.2186,  0.2961, -0.2024, -0.1875, -0.3158,  0.0871, -0.3321, -0.0126],\n        [ 0.0860,  0.2949,  0.2622, -0.1761,  0.3385, -0.0396, -0.1371,  0.2249],\n        [ 0.0015, -0.2284,  0.2303,  0.0204,  0.2227,  0.1597, -0.1486, -0.0914],\n        [ 0.3186, -0.1487,  0.3287, -0.0502, -0.1870, -0.2639, -0.1625,  0.1227],\n        [ 0.0058, -0.0137, -0.1908, -0.3449, -0.2453,  0.2482, -0.1859, -0.0136],\n        [ 0.1249, -0.1559,  0.0309, -0.0856, -0.1052,  0.1962, -0.0694, -0.1384],\n        [ 0.0409, -0.2406,  0.0612,  0.2409, -0.2038, -0.2828,  0.1966,  0.0261],\n        [-0.0255,  0.0371, -0.2773,  0.2166,  0.1814, -0.3172, -0.0149, -0.3072],\n        [ 0.1222,  0.2274, -0.3251,  0.0288,  0.0443,  0.0906,  0.1895, -0.3404]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0773,  0.0193, -0.1563, -0.1146,  0.0463,  0.0540,  0.1234,  0.0422,\n         0.1016,  0.0092,  0.0687,  0.1405,  0.0901,  0.0243,  0.1224,  0.0510],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-6.4972e-02,  1.6087e-01, -1.1665e-01, -1.5332e-02,  4.3679e-02,\n          3.2940e-02,  1.6426e-02,  1.5343e-01, -1.3906e-01, -1.6805e-01,\n          1.2884e-01,  1.3358e-01,  5.5151e-02,  1.4420e-02, -1.4387e-01,\n          1.5033e-01, -8.3915e-02, -1.2550e-01, -8.3019e-04,  1.1673e-01,\n          1.4987e-01, -7.3683e-02, -5.9302e-02,  1.3487e-01,  9.5643e-02,\n         -1.0097e-01,  6.9325e-02,  1.0944e-01, -1.0007e-01, -4.2835e-03,\n          1.3540e-01, -1.7326e-02],\n        [ 1.2731e-01,  1.4272e-01, -9.7848e-02,  6.5801e-02,  1.5405e-01,\n          3.7035e-02,  5.7216e-02,  3.5396e-03, -1.0628e-01,  1.5313e-01,\n         -9.6838e-02, -1.6777e-01,  1.2128e-02,  1.1192e-01, -5.2761e-02,\n          5.2083e-02,  3.2839e-02,  5.4412e-02,  1.4032e-01,  1.1354e-01,\n          1.0183e-01,  1.5136e-01, -8.0076e-02,  1.0110e-01, -3.2376e-02,\n          1.3562e-02,  9.9191e-02, -1.2993e-01,  7.7562e-02,  1.5367e-01,\n         -1.7048e-01, -1.1764e-01],\n        [ 1.5979e-01,  1.5796e-01,  6.7751e-02, -7.8376e-02,  1.1769e-01,\n         -5.1783e-02,  1.4282e-02,  1.2317e-01, -8.4828e-02,  1.4181e-02,\n          6.1068e-02, -2.1516e-02, -1.7285e-01, -1.0176e-01, -1.4687e-01,\n         -7.3597e-02, -1.1578e-01,  9.8341e-03,  1.0771e-02, -1.6930e-01,\n         -1.6088e-01, -1.6217e-01, -1.6903e-01,  3.3231e-02, -1.1112e-01,\n         -1.3643e-02, -4.8448e-03, -1.2624e-01, -1.0022e-02,  7.7674e-02,\n         -1.3885e-01, -1.1464e-01],\n        [-2.8760e-02,  4.5671e-02,  7.8320e-02, -1.6701e-02,  1.0950e-01,\n         -1.7270e-01,  7.8054e-02, -1.3431e-01, -7.4797e-02, -8.5261e-02,\n         -6.8146e-02,  1.5772e-01,  2.2918e-02,  1.0650e-01,  1.1545e-01,\n         -1.2428e-01, -1.6495e-01,  2.4841e-03, -1.7217e-01,  4.0317e-03,\n          1.2759e-01,  5.0212e-03, -1.8322e-02,  4.1901e-02, -6.2452e-02,\n          9.5178e-02,  3.1496e-02, -1.8314e-02, -1.7562e-01, -2.0793e-03,\n         -1.6758e-01,  3.0594e-02],\n        [ 5.8529e-04, -1.3957e-01,  4.6472e-02,  1.0284e-01,  1.6460e-01,\n         -1.0593e-01,  7.2415e-02,  9.6438e-02, -3.1150e-02,  1.7340e-01,\n         -1.7640e-01,  1.4133e-03, -1.6724e-01,  1.0180e-01,  1.0734e-01,\n          1.3574e-01,  5.7057e-02, -2.2468e-02,  1.2007e-01, -5.4081e-02,\n          1.9874e-02,  1.1886e-02,  1.0190e-01,  5.9093e-02,  7.0035e-02,\n         -1.1719e-01,  3.1898e-02, -2.0165e-02, -5.2101e-02, -3.9400e-02,\n          9.7065e-02,  1.3146e-01],\n        [ 5.0643e-02,  1.0186e-01, -1.0538e-01, -1.2569e-01,  8.9138e-02,\n         -1.3999e-01,  1.0241e-01, -9.7252e-02, -5.7825e-02, -1.5057e-02,\n          4.7592e-02, -7.4562e-02,  1.2120e-01, -1.6906e-01,  1.5620e-01,\n          1.5224e-01, -2.4277e-02, -1.0460e-02,  8.9296e-02,  1.1173e-01,\n          7.9532e-02,  1.4696e-01,  9.5998e-02,  3.0521e-03, -7.6871e-02,\n         -1.6512e-01, -4.8787e-02,  3.5763e-02,  1.4943e-01,  8.4451e-02,\n         -1.2986e-02, -1.1639e-01],\n        [ 1.2385e-01,  1.1480e-01,  5.0059e-02,  1.4168e-01, -4.3273e-02,\n          1.6342e-01,  2.8472e-02, -1.0078e-01,  5.5433e-02, -1.6523e-01,\n          1.3553e-01,  1.1056e-01,  5.5056e-02, -1.7847e-02, -1.6512e-01,\n         -7.0325e-02,  7.0664e-02, -7.1453e-02, -6.7788e-02,  7.9520e-02,\n         -1.4138e-01,  1.5961e-01, -4.5588e-02, -1.2977e-02,  1.5959e-01,\n         -1.0400e-01, -1.0465e-01,  2.9897e-02, -3.6827e-02,  9.3118e-02,\n         -8.0243e-02,  3.2620e-03],\n        [ 9.3800e-03, -2.5409e-02,  4.9499e-03,  1.2608e-01,  6.4970e-02,\n          1.0538e-01,  7.6380e-02, -1.7461e-01,  4.1343e-02, -1.3593e-01,\n         -1.5445e-01, -4.7805e-02, -1.8906e-02, -8.1952e-02, -3.5158e-02,\n         -1.0448e-01, -1.7320e-01, -9.7687e-02, -1.1218e-01, -9.8128e-02,\n          1.4094e-01, -1.4281e-01, -7.9915e-02, -1.6536e-01,  4.1040e-03,\n         -1.8141e-02, -1.6196e-02, -1.2974e-01, -1.0826e-01,  4.2777e-02,\n          6.0998e-03,  1.1571e-01],\n        [-1.5821e-01, -1.5189e-02, -5.2027e-02,  7.1411e-03, -9.5136e-02,\n         -5.4126e-02,  6.8670e-03,  2.3468e-02,  1.2589e-01,  1.5005e-01,\n         -7.9625e-02, -6.4264e-02,  1.2691e-01,  1.3308e-01,  5.8845e-02,\n          2.5349e-02, -8.1410e-02, -2.3672e-02, -8.9137e-02,  4.7939e-02,\n         -7.9623e-02, -4.3213e-02,  9.3096e-03,  6.6900e-02,  6.2767e-02,\n          1.7371e-04,  1.6239e-01, -2.6898e-03,  5.9114e-02,  9.6994e-02,\n          1.5462e-01, -5.3226e-02],\n        [-1.1355e-01, -5.2335e-02,  1.4346e-01,  1.6571e-01,  1.6771e-01,\n          1.7373e-01,  2.8484e-02, -1.0032e-01, -1.7180e-02,  4.0865e-03,\n         -1.0465e-01,  1.2783e-01,  1.7083e-01, -7.5869e-02, -1.3856e-01,\n         -4.7490e-02, -9.2962e-02,  9.4224e-02, -1.7012e-01,  7.7933e-02,\n          9.2014e-02,  4.7402e-02, -7.1257e-03, -3.3162e-02, -1.0458e-01,\n         -1.6065e-01, -1.5838e-01, -1.1869e-01,  1.5824e-01, -7.9838e-02,\n         -1.4841e-01, -5.1977e-02],\n        [ 1.3472e-01, -1.6412e-01, -1.1501e-01, -1.5406e-01, -2.3256e-02,\n          1.5925e-01,  5.0766e-02, -1.6219e-01, -1.4109e-01, -1.0128e-01,\n          1.6248e-01,  8.4082e-02, -1.5344e-01,  1.1559e-01, -1.2849e-01,\n          1.2371e-02,  5.7258e-03, -1.5487e-01,  1.3057e-01, -4.2176e-02,\n         -8.3446e-02,  7.9497e-02,  8.3598e-02,  7.6804e-02,  1.2296e-01,\n          1.4294e-01, -3.9923e-02,  1.3569e-01, -3.7199e-02,  1.6999e-01,\n         -3.1639e-02,  1.1340e-01],\n        [-1.2985e-01, -2.3129e-02,  1.0971e-01,  8.5152e-02,  1.3986e-01,\n          4.1104e-02,  1.3190e-01, -1.3128e-01, -1.7500e-01,  5.3345e-02,\n          5.5511e-02,  1.0155e-01, -1.2058e-01, -1.1107e-01,  9.4031e-02,\n          1.3617e-01,  5.6230e-02,  1.6530e-01,  1.3618e-01, -7.5419e-02,\n         -7.9695e-02,  1.6881e-01, -1.2886e-01,  1.2450e-01,  6.1956e-02,\n         -7.5671e-02,  1.1165e-01, -5.1798e-02,  1.5222e-01, -1.3403e-01,\n         -6.8837e-02,  1.7085e-01],\n        [ 1.4604e-02,  4.0081e-02,  1.0151e-01, -3.7360e-02, -1.9765e-02,\n         -1.3709e-01, -1.7216e-01, -3.7783e-04,  1.2940e-01, -1.6826e-01,\n          9.3427e-02,  9.3259e-02,  1.3366e-01, -7.5116e-02,  1.2229e-01,\n          7.5660e-02,  1.2116e-01,  3.5133e-02, -4.3826e-02,  4.7841e-02,\n          7.5007e-02, -1.2767e-01, -3.7770e-03, -3.4816e-03, -5.1034e-02,\n         -9.0388e-02,  1.5441e-01,  1.0776e-01,  9.6813e-02, -9.4710e-02,\n          6.2152e-02, -9.8863e-02],\n        [-1.2067e-01, -1.2013e-01,  1.1861e-01, -5.5027e-02, -1.5259e-01,\n         -1.2160e-01, -4.3589e-02, -1.3560e-01, -4.7700e-03,  2.3681e-02,\n          5.0163e-02, -1.5217e-01, -1.2034e-01, -6.2682e-02,  1.3685e-01,\n         -1.1563e-01, -5.4259e-02, -1.2779e-01,  1.7631e-01,  1.4103e-01,\n          7.1383e-02, -1.3285e-01, -1.4733e-01,  4.8192e-02,  7.4639e-03,\n          1.7341e-01,  3.2021e-03, -1.0921e-01,  8.7389e-02, -1.3916e-01,\n         -4.5829e-02,  1.1227e-02],\n        [-1.8035e-02, -1.7420e-01, -8.7132e-02,  1.6967e-01,  1.3927e-01,\n         -4.3167e-02,  8.6466e-02,  3.0216e-03, -6.3719e-02,  6.7803e-02,\n          1.7345e-01, -1.6285e-01, -2.5312e-03, -1.6547e-01, -9.6407e-03,\n          1.5391e-01, -1.0500e-02, -6.5766e-03,  1.1019e-01,  4.2571e-02,\n         -1.4430e-01,  4.3120e-02, -1.7151e-01, -3.2418e-02, -1.4137e-01,\n          2.9955e-02, -4.6660e-02,  1.8890e-02, -1.1628e-01, -5.9713e-02,\n          1.1768e-01,  7.5558e-02],\n        [ 4.8046e-02,  1.4488e-01,  1.4242e-03,  3.2572e-02,  1.6614e-01,\n         -1.0256e-01, -1.3281e-01, -2.2017e-02,  1.2558e-01, -9.4476e-02,\n         -8.2162e-03, -5.8024e-02, -8.9481e-02,  1.7160e-01, -1.3477e-01,\n          1.5946e-01,  1.2076e-01, -3.7408e-02,  1.0606e-01, -4.5880e-02,\n          1.4493e-01, -6.8878e-03, -1.3044e-01,  1.4336e-01, -1.0408e-01,\n          1.7417e-01,  9.3180e-02, -8.4122e-03,  7.6648e-02, -8.0582e-02,\n         -1.6863e-01, -2.7237e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0927, -0.0008,  0.1498, -0.0541,  0.1931,  0.0236, -0.1678, -0.1685],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1088, -0.0822,  0.1570,  0.2182,  0.0940,  0.0160,  0.1704,  0.1459,\n          0.0926, -0.1636, -0.0698,  0.0786,  0.2071,  0.1529, -0.1773, -0.2438],\n        [-0.1804, -0.0047,  0.0741, -0.0548,  0.2135,  0.0303, -0.0719, -0.0351,\n          0.2286,  0.1739, -0.0107, -0.0503, -0.0599,  0.2032, -0.2027, -0.0508],\n        [-0.1987, -0.1658,  0.1214,  0.1552,  0.2421, -0.1605, -0.0036, -0.1038,\n         -0.0818,  0.1014,  0.0435, -0.1708, -0.0565,  0.0377,  0.0763,  0.0343],\n        [-0.0532,  0.1370, -0.1709,  0.2194, -0.0857,  0.1071, -0.1002,  0.0851,\n         -0.0537,  0.0309,  0.2137, -0.0395,  0.1046, -0.1936, -0.0985,  0.1275],\n        [ 0.0750,  0.2394, -0.1432,  0.1924,  0.0115, -0.0479,  0.2412, -0.0780,\n          0.1477, -0.0164, -0.1509, -0.1657, -0.2254, -0.1831,  0.1750,  0.1056],\n        [ 0.0081, -0.1747,  0.0684,  0.0602, -0.1739,  0.2284, -0.0406, -0.0558,\n          0.0502, -0.2045, -0.1295, -0.1841,  0.0246,  0.1005, -0.0742, -0.2299],\n        [-0.0694,  0.2105, -0.2232, -0.1813, -0.2063,  0.0592, -0.0204,  0.2186,\n          0.0914, -0.2199, -0.0754, -0.0552,  0.0348,  0.1179,  0.1222, -0.0611],\n        [ 0.1551, -0.0830, -0.0863, -0.0478,  0.1450, -0.1462, -0.1171,  0.2113,\n         -0.2326, -0.1270,  0.0644,  0.1997, -0.1512, -0.0657,  0.0228, -0.1925]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0528, -0.1827,  0.0216, -0.2447], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1331,  0.0082, -0.2181,  0.2941, -0.0088, -0.2427, -0.2407,  0.3433],\n        [ 0.1804, -0.2339, -0.3082, -0.3369, -0.2254, -0.2387,  0.1408, -0.0468],\n        [-0.2841,  0.2960,  0.0730,  0.3424, -0.1728, -0.1286, -0.0713,  0.1669],\n        [ 0.2356, -0.1682,  0.0246,  0.3373, -0.2365,  0.2402, -0.1886,  0.1867]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.3437, -0.3486,  0.1177,  0.0632,  0.2638, -0.2759,  0.2184,  0.0363],\n        [ 0.2704, -0.1968, -0.1492,  0.0556,  0.3061,  0.1990, -0.1794, -0.0820],\n        [-0.2612, -0.3013, -0.0768,  0.2260, -0.2163, -0.1694,  0.3180,  0.0136],\n        [-0.0179,  0.2747, -0.3025, -0.1815, -0.3007, -0.0140, -0.1018,  0.1193],\n        [-0.2003,  0.2160, -0.0116,  0.3357,  0.2089,  0.3479,  0.3501, -0.1481],\n        [-0.0985, -0.1500, -0.1208, -0.2285,  0.2959, -0.3121,  0.0404,  0.2322],\n        [-0.3142,  0.0079, -0.0935,  0.1383,  0.2595,  0.1562, -0.2016,  0.0518],\n        [ 0.1373, -0.2517, -0.3262, -0.0471,  0.2023, -0.2783,  0.1693, -0.2424],\n        [-0.0812, -0.3173, -0.2896,  0.0348,  0.1196,  0.2749,  0.0014,  0.2852],\n        [ 0.1022,  0.3239, -0.3264, -0.1273, -0.3321, -0.1706,  0.0331,  0.1264],\n        [-0.3233,  0.1866, -0.3015, -0.1828, -0.1528,  0.0620, -0.1553, -0.3275],\n        [ 0.0974,  0.1730,  0.2419, -0.2432,  0.0704, -0.3164,  0.0238,  0.1835],\n        [ 0.2052, -0.0937, -0.1031,  0.1887,  0.1097,  0.3137, -0.1189, -0.0819],\n        [ 0.0583, -0.0345, -0.2254,  0.3201, -0.3424,  0.1490,  0.2224,  0.1671],\n        [-0.0171, -0.0145,  0.0915,  0.1188, -0.0857, -0.0383, -0.2255,  0.1639],\n        [-0.2767,  0.3151, -0.2843, -0.3248, -0.2207, -0.3481, -0.1168,  0.1404],\n        [-0.1451,  0.1116, -0.0267,  0.2408,  0.1892, -0.1863,  0.3217, -0.1176],\n        [ 0.2453, -0.1518,  0.1463,  0.1152,  0.3239,  0.1537, -0.3491, -0.2485],\n        [-0.3149,  0.3120, -0.2655, -0.1560, -0.2725,  0.1311,  0.0599, -0.0630],\n        [-0.1569, -0.2913, -0.3195, -0.0172,  0.3203, -0.2035,  0.0326,  0.1596],\n        [-0.0458, -0.0658, -0.3251, -0.0853, -0.2498,  0.2490,  0.3109,  0.2589],\n        [-0.2195, -0.0375, -0.1514, -0.0042, -0.0125,  0.2851,  0.0707,  0.3479],\n        [-0.2129, -0.1104, -0.0273, -0.1812, -0.0729, -0.0278,  0.2386, -0.1328],\n        [-0.2186,  0.2961, -0.2024, -0.1875, -0.3158,  0.0871, -0.3321, -0.0126],\n        [ 0.0860,  0.2949,  0.2622, -0.1761,  0.3385, -0.0396, -0.1371,  0.2249],\n        [ 0.0015, -0.2284,  0.2303,  0.0204,  0.2227,  0.1597, -0.1486, -0.0914],\n        [ 0.3186, -0.1487,  0.3287, -0.0502, -0.1870, -0.2639, -0.1625,  0.1227],\n        [ 0.0058, -0.0137, -0.1908, -0.3449, -0.2453,  0.2482, -0.1859, -0.0136],\n        [ 0.1249, -0.1559,  0.0309, -0.0856, -0.1052,  0.1962, -0.0694, -0.1384],\n        [ 0.0409, -0.2406,  0.0612,  0.2409, -0.2038, -0.2828,  0.1966,  0.0261],\n        [-0.0255,  0.0371, -0.2773,  0.2166,  0.1814, -0.3172, -0.0149, -0.3072],\n        [ 0.1222,  0.2274, -0.3251,  0.0288,  0.0443,  0.0906,  0.1895, -0.3404]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3153,  0.2694, -0.0273, -0.1148,  0.1241, -0.2367, -0.0279, -0.3450,\n         0.1775,  0.2022,  0.3157,  0.1889, -0.0012, -0.1090,  0.1515, -0.2535,\n        -0.1579, -0.0135,  0.2423, -0.3219,  0.0205,  0.2738,  0.2953, -0.1912,\n         0.1739, -0.1386, -0.2830, -0.0277,  0.1604, -0.0078, -0.1566,  0.2102],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-6.4972e-02,  1.6087e-01, -1.1665e-01, -1.5332e-02,  4.3679e-02,\n          3.2940e-02,  1.6426e-02,  1.5343e-01, -1.3906e-01, -1.6805e-01,\n          1.2884e-01,  1.3358e-01,  5.5151e-02,  1.4420e-02, -1.4387e-01,\n          1.5033e-01, -8.3915e-02, -1.2550e-01, -8.3019e-04,  1.1673e-01,\n          1.4987e-01, -7.3683e-02, -5.9302e-02,  1.3487e-01,  9.5643e-02,\n         -1.0097e-01,  6.9325e-02,  1.0944e-01, -1.0007e-01, -4.2835e-03,\n          1.3540e-01, -1.7326e-02],\n        [ 1.2731e-01,  1.4272e-01, -9.7848e-02,  6.5801e-02,  1.5405e-01,\n          3.7035e-02,  5.7216e-02,  3.5396e-03, -1.0628e-01,  1.5313e-01,\n         -9.6838e-02, -1.6777e-01,  1.2128e-02,  1.1192e-01, -5.2761e-02,\n          5.2083e-02,  3.2839e-02,  5.4412e-02,  1.4032e-01,  1.1354e-01,\n          1.0183e-01,  1.5136e-01, -8.0076e-02,  1.0110e-01, -3.2376e-02,\n          1.3562e-02,  9.9191e-02, -1.2993e-01,  7.7562e-02,  1.5367e-01,\n         -1.7048e-01, -1.1764e-01],\n        [ 1.5979e-01,  1.5796e-01,  6.7751e-02, -7.8376e-02,  1.1769e-01,\n         -5.1783e-02,  1.4282e-02,  1.2317e-01, -8.4828e-02,  1.4181e-02,\n          6.1068e-02, -2.1516e-02, -1.7285e-01, -1.0176e-01, -1.4687e-01,\n         -7.3597e-02, -1.1578e-01,  9.8341e-03,  1.0771e-02, -1.6930e-01,\n         -1.6088e-01, -1.6217e-01, -1.6903e-01,  3.3231e-02, -1.1112e-01,\n         -1.3643e-02, -4.8448e-03, -1.2624e-01, -1.0022e-02,  7.7674e-02,\n         -1.3885e-01, -1.1464e-01],\n        [-2.8760e-02,  4.5671e-02,  7.8320e-02, -1.6701e-02,  1.0950e-01,\n         -1.7270e-01,  7.8054e-02, -1.3431e-01, -7.4797e-02, -8.5261e-02,\n         -6.8146e-02,  1.5772e-01,  2.2918e-02,  1.0650e-01,  1.1545e-01,\n         -1.2428e-01, -1.6495e-01,  2.4841e-03, -1.7217e-01,  4.0317e-03,\n          1.2759e-01,  5.0212e-03, -1.8322e-02,  4.1901e-02, -6.2452e-02,\n          9.5178e-02,  3.1496e-02, -1.8314e-02, -1.7562e-01, -2.0793e-03,\n         -1.6758e-01,  3.0594e-02],\n        [ 5.8529e-04, -1.3957e-01,  4.6472e-02,  1.0284e-01,  1.6460e-01,\n         -1.0593e-01,  7.2415e-02,  9.6438e-02, -3.1150e-02,  1.7340e-01,\n         -1.7640e-01,  1.4133e-03, -1.6724e-01,  1.0180e-01,  1.0734e-01,\n          1.3574e-01,  5.7057e-02, -2.2468e-02,  1.2007e-01, -5.4081e-02,\n          1.9874e-02,  1.1886e-02,  1.0190e-01,  5.9093e-02,  7.0035e-02,\n         -1.1719e-01,  3.1898e-02, -2.0165e-02, -5.2101e-02, -3.9400e-02,\n          9.7065e-02,  1.3146e-01],\n        [ 5.0643e-02,  1.0186e-01, -1.0538e-01, -1.2569e-01,  8.9138e-02,\n         -1.3999e-01,  1.0241e-01, -9.7252e-02, -5.7825e-02, -1.5057e-02,\n          4.7592e-02, -7.4562e-02,  1.2120e-01, -1.6906e-01,  1.5620e-01,\n          1.5224e-01, -2.4277e-02, -1.0460e-02,  8.9296e-02,  1.1173e-01,\n          7.9532e-02,  1.4696e-01,  9.5998e-02,  3.0521e-03, -7.6871e-02,\n         -1.6512e-01, -4.8787e-02,  3.5763e-02,  1.4943e-01,  8.4451e-02,\n         -1.2986e-02, -1.1639e-01],\n        [ 1.2385e-01,  1.1480e-01,  5.0059e-02,  1.4168e-01, -4.3273e-02,\n          1.6342e-01,  2.8472e-02, -1.0078e-01,  5.5433e-02, -1.6523e-01,\n          1.3553e-01,  1.1056e-01,  5.5056e-02, -1.7847e-02, -1.6512e-01,\n         -7.0325e-02,  7.0664e-02, -7.1453e-02, -6.7788e-02,  7.9520e-02,\n         -1.4138e-01,  1.5961e-01, -4.5588e-02, -1.2977e-02,  1.5959e-01,\n         -1.0400e-01, -1.0465e-01,  2.9897e-02, -3.6827e-02,  9.3118e-02,\n         -8.0243e-02,  3.2620e-03],\n        [ 9.3800e-03, -2.5409e-02,  4.9499e-03,  1.2608e-01,  6.4970e-02,\n          1.0538e-01,  7.6380e-02, -1.7461e-01,  4.1343e-02, -1.3593e-01,\n         -1.5445e-01, -4.7805e-02, -1.8906e-02, -8.1952e-02, -3.5158e-02,\n         -1.0448e-01, -1.7320e-01, -9.7687e-02, -1.1218e-01, -9.8128e-02,\n          1.4094e-01, -1.4281e-01, -7.9915e-02, -1.6536e-01,  4.1040e-03,\n         -1.8141e-02, -1.6196e-02, -1.2974e-01, -1.0826e-01,  4.2777e-02,\n          6.0998e-03,  1.1571e-01],\n        [-1.5821e-01, -1.5189e-02, -5.2027e-02,  7.1411e-03, -9.5136e-02,\n         -5.4126e-02,  6.8670e-03,  2.3468e-02,  1.2589e-01,  1.5005e-01,\n         -7.9625e-02, -6.4264e-02,  1.2691e-01,  1.3308e-01,  5.8845e-02,\n          2.5349e-02, -8.1410e-02, -2.3672e-02, -8.9137e-02,  4.7939e-02,\n         -7.9623e-02, -4.3213e-02,  9.3096e-03,  6.6900e-02,  6.2767e-02,\n          1.7371e-04,  1.6239e-01, -2.6898e-03,  5.9114e-02,  9.6994e-02,\n          1.5462e-01, -5.3226e-02],\n        [-1.1355e-01, -5.2335e-02,  1.4346e-01,  1.6571e-01,  1.6771e-01,\n          1.7373e-01,  2.8484e-02, -1.0032e-01, -1.7180e-02,  4.0865e-03,\n         -1.0465e-01,  1.2783e-01,  1.7083e-01, -7.5869e-02, -1.3856e-01,\n         -4.7490e-02, -9.2962e-02,  9.4224e-02, -1.7012e-01,  7.7933e-02,\n          9.2014e-02,  4.7402e-02, -7.1257e-03, -3.3162e-02, -1.0458e-01,\n         -1.6065e-01, -1.5838e-01, -1.1869e-01,  1.5824e-01, -7.9838e-02,\n         -1.4841e-01, -5.1977e-02],\n        [ 1.3472e-01, -1.6412e-01, -1.1501e-01, -1.5406e-01, -2.3256e-02,\n          1.5925e-01,  5.0766e-02, -1.6219e-01, -1.4109e-01, -1.0128e-01,\n          1.6248e-01,  8.4082e-02, -1.5344e-01,  1.1559e-01, -1.2849e-01,\n          1.2371e-02,  5.7258e-03, -1.5487e-01,  1.3057e-01, -4.2176e-02,\n         -8.3446e-02,  7.9497e-02,  8.3598e-02,  7.6804e-02,  1.2296e-01,\n          1.4294e-01, -3.9923e-02,  1.3569e-01, -3.7199e-02,  1.6999e-01,\n         -3.1639e-02,  1.1340e-01],\n        [-1.2985e-01, -2.3129e-02,  1.0971e-01,  8.5152e-02,  1.3986e-01,\n          4.1104e-02,  1.3190e-01, -1.3128e-01, -1.7500e-01,  5.3345e-02,\n          5.5511e-02,  1.0155e-01, -1.2058e-01, -1.1107e-01,  9.4031e-02,\n          1.3617e-01,  5.6230e-02,  1.6530e-01,  1.3618e-01, -7.5419e-02,\n         -7.9695e-02,  1.6881e-01, -1.2886e-01,  1.2450e-01,  6.1956e-02,\n         -7.5671e-02,  1.1165e-01, -5.1798e-02,  1.5222e-01, -1.3403e-01,\n         -6.8837e-02,  1.7085e-01],\n        [ 1.4604e-02,  4.0081e-02,  1.0151e-01, -3.7360e-02, -1.9765e-02,\n         -1.3709e-01, -1.7216e-01, -3.7783e-04,  1.2940e-01, -1.6826e-01,\n          9.3427e-02,  9.3259e-02,  1.3366e-01, -7.5116e-02,  1.2229e-01,\n          7.5660e-02,  1.2116e-01,  3.5133e-02, -4.3826e-02,  4.7841e-02,\n          7.5007e-02, -1.2767e-01, -3.7770e-03, -3.4816e-03, -5.1034e-02,\n         -9.0388e-02,  1.5441e-01,  1.0776e-01,  9.6813e-02, -9.4710e-02,\n          6.2152e-02, -9.8863e-02],\n        [-1.2067e-01, -1.2013e-01,  1.1861e-01, -5.5027e-02, -1.5259e-01,\n         -1.2160e-01, -4.3589e-02, -1.3560e-01, -4.7700e-03,  2.3681e-02,\n          5.0163e-02, -1.5217e-01, -1.2034e-01, -6.2682e-02,  1.3685e-01,\n         -1.1563e-01, -5.4259e-02, -1.2779e-01,  1.7631e-01,  1.4103e-01,\n          7.1383e-02, -1.3285e-01, -1.4733e-01,  4.8192e-02,  7.4639e-03,\n          1.7341e-01,  3.2021e-03, -1.0921e-01,  8.7389e-02, -1.3916e-01,\n         -4.5829e-02,  1.1227e-02],\n        [-1.8035e-02, -1.7420e-01, -8.7132e-02,  1.6967e-01,  1.3927e-01,\n         -4.3167e-02,  8.6466e-02,  3.0216e-03, -6.3719e-02,  6.7803e-02,\n          1.7345e-01, -1.6285e-01, -2.5312e-03, -1.6547e-01, -9.6407e-03,\n          1.5391e-01, -1.0500e-02, -6.5766e-03,  1.1019e-01,  4.2571e-02,\n         -1.4430e-01,  4.3120e-02, -1.7151e-01, -3.2418e-02, -1.4137e-01,\n          2.9955e-02, -4.6660e-02,  1.8890e-02, -1.1628e-01, -5.9713e-02,\n          1.1768e-01,  7.5558e-02],\n        [ 4.8046e-02,  1.4488e-01,  1.4242e-03,  3.2572e-02,  1.6614e-01,\n         -1.0256e-01, -1.3281e-01, -2.2017e-02,  1.2558e-01, -9.4476e-02,\n         -8.2162e-03, -5.8024e-02, -8.9481e-02,  1.7160e-01, -1.3477e-01,\n          1.5946e-01,  1.2076e-01, -3.7408e-02,  1.0606e-01, -4.5880e-02,\n          1.4493e-01, -6.8878e-03, -1.3044e-01,  1.4336e-01, -1.0408e-01,\n          1.7417e-01,  9.3180e-02, -8.4122e-03,  7.6648e-02, -8.0582e-02,\n         -1.6863e-01, -2.7237e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0773,  0.0193, -0.1563, -0.1146,  0.0463,  0.0540,  0.1234,  0.0422,\n         0.1016,  0.0092,  0.0687,  0.1405,  0.0901,  0.0243,  0.1224,  0.0510],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1088, -0.0822,  0.1570,  0.2182,  0.0940,  0.0160,  0.1704,  0.1459,\n          0.0926, -0.1636, -0.0698,  0.0786,  0.2071,  0.1529, -0.1773, -0.2438],\n        [-0.1804, -0.0047,  0.0741, -0.0548,  0.2135,  0.0303, -0.0719, -0.0351,\n          0.2286,  0.1739, -0.0107, -0.0503, -0.0599,  0.2032, -0.2027, -0.0508],\n        [-0.1987, -0.1658,  0.1214,  0.1552,  0.2421, -0.1605, -0.0036, -0.1038,\n         -0.0818,  0.1014,  0.0435, -0.1708, -0.0565,  0.0377,  0.0763,  0.0343],\n        [-0.0532,  0.1370, -0.1709,  0.2194, -0.0857,  0.1071, -0.1002,  0.0851,\n         -0.0537,  0.0309,  0.2137, -0.0395,  0.1046, -0.1936, -0.0985,  0.1275],\n        [ 0.0750,  0.2394, -0.1432,  0.1924,  0.0115, -0.0479,  0.2412, -0.0780,\n          0.1477, -0.0164, -0.1509, -0.1657, -0.2254, -0.1831,  0.1750,  0.1056],\n        [ 0.0081, -0.1747,  0.0684,  0.0602, -0.1739,  0.2284, -0.0406, -0.0558,\n          0.0502, -0.2045, -0.1295, -0.1841,  0.0246,  0.1005, -0.0742, -0.2299],\n        [-0.0694,  0.2105, -0.2232, -0.1813, -0.2063,  0.0592, -0.0204,  0.2186,\n          0.0914, -0.2199, -0.0754, -0.0552,  0.0348,  0.1179,  0.1222, -0.0611],\n        [ 0.1551, -0.0830, -0.0863, -0.0478,  0.1450, -0.1462, -0.1171,  0.2113,\n         -0.2326, -0.1270,  0.0644,  0.1997, -0.1512, -0.0657,  0.0228, -0.1925]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0927, -0.0008,  0.1498, -0.0541,  0.1931,  0.0236, -0.1678, -0.1685],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1331,  0.0082, -0.2181,  0.2941, -0.0088, -0.2427, -0.2407,  0.3433],\n        [ 0.1804, -0.2339, -0.3082, -0.3369, -0.2254, -0.2387,  0.1408, -0.0468],\n        [-0.2841,  0.2960,  0.0730,  0.3424, -0.1728, -0.1286, -0.0713,  0.1669],\n        [ 0.2356, -0.1682,  0.0246,  0.3373, -0.2365,  0.2402, -0.1886,  0.1867]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0528, -0.1827,  0.0216, -0.2447], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7d281a1ca510>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]",
                    "time":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3153,  0.2694, -0.0273, -0.1148,  0.1241, -0.2367, -0.0279, -0.3450,\n         0.1775,  0.2022,  0.3157,  0.1889, -0.0012, -0.1090,  0.1515, -0.2535,\n        -0.1579, -0.0135,  0.2423, -0.3219,  0.0205,  0.2738,  0.2953, -0.1912,\n         0.1739, -0.1386, -0.2830, -0.0277,  0.1604, -0.0078, -0.1566,  0.2102],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3437, -0.3486,  0.1177,  0.0632,  0.2638, -0.2759,  0.2184,  0.0363],\n        [ 0.2704, -0.1968, -0.1492,  0.0556,  0.3061,  0.1990, -0.1794, -0.0820],\n        [-0.2612, -0.3013, -0.0768,  0.2260, -0.2163, -0.1694,  0.3180,  0.0136],\n        [-0.0179,  0.2747, -0.3025, -0.1815, -0.3007, -0.0140, -0.1018,  0.1193],\n        [-0.2003,  0.2160, -0.0116,  0.3357,  0.2089,  0.3479,  0.3501, -0.1481],\n        [-0.0985, -0.1500, -0.1208, -0.2285,  0.2959, -0.3121,  0.0404,  0.2322],\n        [-0.3142,  0.0079, -0.0935,  0.1383,  0.2595,  0.1562, -0.2016,  0.0518],\n        [ 0.1373, -0.2517, -0.3262, -0.0471,  0.2023, -0.2783,  0.1693, -0.2424],\n        [-0.0812, -0.3173, -0.2896,  0.0348,  0.1196,  0.2749,  0.0014,  0.2852],\n        [ 0.1022,  0.3239, -0.3264, -0.1273, -0.3321, -0.1706,  0.0331,  0.1264],\n        [-0.3233,  0.1866, -0.3015, -0.1828, -0.1528,  0.0620, -0.1553, -0.3275],\n        [ 0.0974,  0.1730,  0.2419, -0.2432,  0.0704, -0.3164,  0.0238,  0.1835],\n        [ 0.2052, -0.0937, -0.1031,  0.1887,  0.1097,  0.3137, -0.1189, -0.0819],\n        [ 0.0583, -0.0345, -0.2254,  0.3201, -0.3424,  0.1490,  0.2224,  0.1671],\n        [-0.0171, -0.0145,  0.0915,  0.1188, -0.0857, -0.0383, -0.2255,  0.1639],\n        [-0.2767,  0.3151, -0.2843, -0.3248, -0.2207, -0.3481, -0.1168,  0.1404],\n        [-0.1451,  0.1116, -0.0267,  0.2408,  0.1892, -0.1863,  0.3217, -0.1176],\n        [ 0.2453, -0.1518,  0.1463,  0.1152,  0.3239,  0.1537, -0.3491, -0.2485],\n        [-0.3149,  0.3120, -0.2655, -0.1560, -0.2725,  0.1311,  0.0599, -0.0630],\n        [-0.1569, -0.2913, -0.3195, -0.0172,  0.3203, -0.2035,  0.0326,  0.1596],\n        [-0.0458, -0.0658, -0.3251, -0.0853, -0.2498,  0.2490,  0.3109,  0.2589],\n        [-0.2195, -0.0375, -0.1514, -0.0042, -0.0125,  0.2851,  0.0707,  0.3479],\n        [-0.2129, -0.1104, -0.0273, -0.1812, -0.0729, -0.0278,  0.2386, -0.1328],\n        [-0.2186,  0.2961, -0.2024, -0.1875, -0.3158,  0.0871, -0.3321, -0.0126],\n        [ 0.0860,  0.2949,  0.2622, -0.1761,  0.3385, -0.0396, -0.1371,  0.2249],\n        [ 0.0015, -0.2284,  0.2303,  0.0204,  0.2227,  0.1597, -0.1486, -0.0914],\n        [ 0.3186, -0.1487,  0.3287, -0.0502, -0.1870, -0.2639, -0.1625,  0.1227],\n        [ 0.0058, -0.0137, -0.1908, -0.3449, -0.2453,  0.2482, -0.1859, -0.0136],\n        [ 0.1249, -0.1559,  0.0309, -0.0856, -0.1052,  0.1962, -0.0694, -0.1384],\n        [ 0.0409, -0.2406,  0.0612,  0.2409, -0.2038, -0.2828,  0.1966,  0.0261],\n        [-0.0255,  0.0371, -0.2773,  0.2166,  0.1814, -0.3172, -0.0149, -0.3072],\n        [ 0.1222,  0.2274, -0.3251,  0.0288,  0.0443,  0.0906,  0.1895, -0.3404]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0773,  0.0193, -0.1563, -0.1146,  0.0463,  0.0540,  0.1234,  0.0422,\n         0.1016,  0.0092,  0.0687,  0.1405,  0.0901,  0.0243,  0.1224,  0.0510],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-6.4972e-02,  1.6087e-01, -1.1665e-01, -1.5332e-02,  4.3679e-02,\n          3.2940e-02,  1.6426e-02,  1.5343e-01, -1.3906e-01, -1.6805e-01,\n          1.2884e-01,  1.3358e-01,  5.5151e-02,  1.4420e-02, -1.4387e-01,\n          1.5033e-01, -8.3915e-02, -1.2550e-01, -8.3019e-04,  1.1673e-01,\n          1.4987e-01, -7.3683e-02, -5.9302e-02,  1.3487e-01,  9.5643e-02,\n         -1.0097e-01,  6.9325e-02,  1.0944e-01, -1.0007e-01, -4.2835e-03,\n          1.3540e-01, -1.7326e-02],\n        [ 1.2731e-01,  1.4272e-01, -9.7848e-02,  6.5801e-02,  1.5405e-01,\n          3.7035e-02,  5.7216e-02,  3.5396e-03, -1.0628e-01,  1.5313e-01,\n         -9.6838e-02, -1.6777e-01,  1.2128e-02,  1.1192e-01, -5.2761e-02,\n          5.2083e-02,  3.2839e-02,  5.4412e-02,  1.4032e-01,  1.1354e-01,\n          1.0183e-01,  1.5136e-01, -8.0076e-02,  1.0110e-01, -3.2376e-02,\n          1.3562e-02,  9.9191e-02, -1.2993e-01,  7.7562e-02,  1.5367e-01,\n         -1.7048e-01, -1.1764e-01],\n        [ 1.5979e-01,  1.5796e-01,  6.7751e-02, -7.8376e-02,  1.1769e-01,\n         -5.1783e-02,  1.4282e-02,  1.2317e-01, -8.4828e-02,  1.4181e-02,\n          6.1068e-02, -2.1516e-02, -1.7285e-01, -1.0176e-01, -1.4687e-01,\n         -7.3597e-02, -1.1578e-01,  9.8341e-03,  1.0771e-02, -1.6930e-01,\n         -1.6088e-01, -1.6217e-01, -1.6903e-01,  3.3231e-02, -1.1112e-01,\n         -1.3643e-02, -4.8448e-03, -1.2624e-01, -1.0022e-02,  7.7674e-02,\n         -1.3885e-01, -1.1464e-01],\n        [-2.8760e-02,  4.5671e-02,  7.8320e-02, -1.6701e-02,  1.0950e-01,\n         -1.7270e-01,  7.8054e-02, -1.3431e-01, -7.4797e-02, -8.5261e-02,\n         -6.8146e-02,  1.5772e-01,  2.2918e-02,  1.0650e-01,  1.1545e-01,\n         -1.2428e-01, -1.6495e-01,  2.4841e-03, -1.7217e-01,  4.0317e-03,\n          1.2759e-01,  5.0212e-03, -1.8322e-02,  4.1901e-02, -6.2452e-02,\n          9.5178e-02,  3.1496e-02, -1.8314e-02, -1.7562e-01, -2.0793e-03,\n         -1.6758e-01,  3.0594e-02],\n        [ 5.8529e-04, -1.3957e-01,  4.6472e-02,  1.0284e-01,  1.6460e-01,\n         -1.0593e-01,  7.2415e-02,  9.6438e-02, -3.1150e-02,  1.7340e-01,\n         -1.7640e-01,  1.4133e-03, -1.6724e-01,  1.0180e-01,  1.0734e-01,\n          1.3574e-01,  5.7057e-02, -2.2468e-02,  1.2007e-01, -5.4081e-02,\n          1.9874e-02,  1.1886e-02,  1.0190e-01,  5.9093e-02,  7.0035e-02,\n         -1.1719e-01,  3.1898e-02, -2.0165e-02, -5.2101e-02, -3.9400e-02,\n          9.7065e-02,  1.3146e-01],\n        [ 5.0643e-02,  1.0186e-01, -1.0538e-01, -1.2569e-01,  8.9138e-02,\n         -1.3999e-01,  1.0241e-01, -9.7252e-02, -5.7825e-02, -1.5057e-02,\n          4.7592e-02, -7.4562e-02,  1.2120e-01, -1.6906e-01,  1.5620e-01,\n          1.5224e-01, -2.4277e-02, -1.0460e-02,  8.9296e-02,  1.1173e-01,\n          7.9532e-02,  1.4696e-01,  9.5998e-02,  3.0521e-03, -7.6871e-02,\n         -1.6512e-01, -4.8787e-02,  3.5763e-02,  1.4943e-01,  8.4451e-02,\n         -1.2986e-02, -1.1639e-01],\n        [ 1.2385e-01,  1.1480e-01,  5.0059e-02,  1.4168e-01, -4.3273e-02,\n          1.6342e-01,  2.8472e-02, -1.0078e-01,  5.5433e-02, -1.6523e-01,\n          1.3553e-01,  1.1056e-01,  5.5056e-02, -1.7847e-02, -1.6512e-01,\n         -7.0325e-02,  7.0664e-02, -7.1453e-02, -6.7788e-02,  7.9520e-02,\n         -1.4138e-01,  1.5961e-01, -4.5588e-02, -1.2977e-02,  1.5959e-01,\n         -1.0400e-01, -1.0465e-01,  2.9897e-02, -3.6827e-02,  9.3118e-02,\n         -8.0243e-02,  3.2620e-03],\n        [ 9.3800e-03, -2.5409e-02,  4.9499e-03,  1.2608e-01,  6.4970e-02,\n          1.0538e-01,  7.6380e-02, -1.7461e-01,  4.1343e-02, -1.3593e-01,\n         -1.5445e-01, -4.7805e-02, -1.8906e-02, -8.1952e-02, -3.5158e-02,\n         -1.0448e-01, -1.7320e-01, -9.7687e-02, -1.1218e-01, -9.8128e-02,\n          1.4094e-01, -1.4281e-01, -7.9915e-02, -1.6536e-01,  4.1040e-03,\n         -1.8141e-02, -1.6196e-02, -1.2974e-01, -1.0826e-01,  4.2777e-02,\n          6.0998e-03,  1.1571e-01],\n        [-1.5821e-01, -1.5189e-02, -5.2027e-02,  7.1411e-03, -9.5136e-02,\n         -5.4126e-02,  6.8670e-03,  2.3468e-02,  1.2589e-01,  1.5005e-01,\n         -7.9625e-02, -6.4264e-02,  1.2691e-01,  1.3308e-01,  5.8845e-02,\n          2.5349e-02, -8.1410e-02, -2.3672e-02, -8.9137e-02,  4.7939e-02,\n         -7.9623e-02, -4.3213e-02,  9.3096e-03,  6.6900e-02,  6.2767e-02,\n          1.7371e-04,  1.6239e-01, -2.6898e-03,  5.9114e-02,  9.6994e-02,\n          1.5462e-01, -5.3226e-02],\n        [-1.1355e-01, -5.2335e-02,  1.4346e-01,  1.6571e-01,  1.6771e-01,\n          1.7373e-01,  2.8484e-02, -1.0032e-01, -1.7180e-02,  4.0865e-03,\n         -1.0465e-01,  1.2783e-01,  1.7083e-01, -7.5869e-02, -1.3856e-01,\n         -4.7490e-02, -9.2962e-02,  9.4224e-02, -1.7012e-01,  7.7933e-02,\n          9.2014e-02,  4.7402e-02, -7.1257e-03, -3.3162e-02, -1.0458e-01,\n         -1.6065e-01, -1.5838e-01, -1.1869e-01,  1.5824e-01, -7.9838e-02,\n         -1.4841e-01, -5.1977e-02],\n        [ 1.3472e-01, -1.6412e-01, -1.1501e-01, -1.5406e-01, -2.3256e-02,\n          1.5925e-01,  5.0766e-02, -1.6219e-01, -1.4109e-01, -1.0128e-01,\n          1.6248e-01,  8.4082e-02, -1.5344e-01,  1.1559e-01, -1.2849e-01,\n          1.2371e-02,  5.7258e-03, -1.5487e-01,  1.3057e-01, -4.2176e-02,\n         -8.3446e-02,  7.9497e-02,  8.3598e-02,  7.6804e-02,  1.2296e-01,\n          1.4294e-01, -3.9923e-02,  1.3569e-01, -3.7199e-02,  1.6999e-01,\n         -3.1639e-02,  1.1340e-01],\n        [-1.2985e-01, -2.3129e-02,  1.0971e-01,  8.5152e-02,  1.3986e-01,\n          4.1104e-02,  1.3190e-01, -1.3128e-01, -1.7500e-01,  5.3345e-02,\n          5.5511e-02,  1.0155e-01, -1.2058e-01, -1.1107e-01,  9.4031e-02,\n          1.3617e-01,  5.6230e-02,  1.6530e-01,  1.3618e-01, -7.5419e-02,\n         -7.9695e-02,  1.6881e-01, -1.2886e-01,  1.2450e-01,  6.1956e-02,\n         -7.5671e-02,  1.1165e-01, -5.1798e-02,  1.5222e-01, -1.3403e-01,\n         -6.8837e-02,  1.7085e-01],\n        [ 1.4604e-02,  4.0081e-02,  1.0151e-01, -3.7360e-02, -1.9765e-02,\n         -1.3709e-01, -1.7216e-01, -3.7783e-04,  1.2940e-01, -1.6826e-01,\n          9.3427e-02,  9.3259e-02,  1.3366e-01, -7.5116e-02,  1.2229e-01,\n          7.5660e-02,  1.2116e-01,  3.5133e-02, -4.3826e-02,  4.7841e-02,\n          7.5007e-02, -1.2767e-01, -3.7770e-03, -3.4816e-03, -5.1034e-02,\n         -9.0388e-02,  1.5441e-01,  1.0776e-01,  9.6813e-02, -9.4710e-02,\n          6.2152e-02, -9.8863e-02],\n        [-1.2067e-01, -1.2013e-01,  1.1861e-01, -5.5027e-02, -1.5259e-01,\n         -1.2160e-01, -4.3589e-02, -1.3560e-01, -4.7700e-03,  2.3681e-02,\n          5.0163e-02, -1.5217e-01, -1.2034e-01, -6.2682e-02,  1.3685e-01,\n         -1.1563e-01, -5.4259e-02, -1.2779e-01,  1.7631e-01,  1.4103e-01,\n          7.1383e-02, -1.3285e-01, -1.4733e-01,  4.8192e-02,  7.4639e-03,\n          1.7341e-01,  3.2021e-03, -1.0921e-01,  8.7389e-02, -1.3916e-01,\n         -4.5829e-02,  1.1227e-02],\n        [-1.8035e-02, -1.7420e-01, -8.7132e-02,  1.6967e-01,  1.3927e-01,\n         -4.3167e-02,  8.6466e-02,  3.0216e-03, -6.3719e-02,  6.7803e-02,\n          1.7345e-01, -1.6285e-01, -2.5312e-03, -1.6547e-01, -9.6407e-03,\n          1.5391e-01, -1.0500e-02, -6.5766e-03,  1.1019e-01,  4.2571e-02,\n         -1.4430e-01,  4.3120e-02, -1.7151e-01, -3.2418e-02, -1.4137e-01,\n          2.9955e-02, -4.6660e-02,  1.8890e-02, -1.1628e-01, -5.9713e-02,\n          1.1768e-01,  7.5558e-02],\n        [ 4.8046e-02,  1.4488e-01,  1.4242e-03,  3.2572e-02,  1.6614e-01,\n         -1.0256e-01, -1.3281e-01, -2.2017e-02,  1.2558e-01, -9.4476e-02,\n         -8.2162e-03, -5.8024e-02, -8.9481e-02,  1.7160e-01, -1.3477e-01,\n          1.5946e-01,  1.2076e-01, -3.7408e-02,  1.0606e-01, -4.5880e-02,\n          1.4493e-01, -6.8878e-03, -1.3044e-01,  1.4336e-01, -1.0408e-01,\n          1.7417e-01,  9.3180e-02, -8.4122e-03,  7.6648e-02, -8.0582e-02,\n         -1.6863e-01, -2.7237e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0927, -0.0008,  0.1498, -0.0541,  0.1931,  0.0236, -0.1678, -0.1685],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1088, -0.0822,  0.1570,  0.2182,  0.0940,  0.0160,  0.1704,  0.1459,\n          0.0926, -0.1636, -0.0698,  0.0786,  0.2071,  0.1529, -0.1773, -0.2438],\n        [-0.1804, -0.0047,  0.0741, -0.0548,  0.2135,  0.0303, -0.0719, -0.0351,\n          0.2286,  0.1739, -0.0107, -0.0503, -0.0599,  0.2032, -0.2027, -0.0508],\n        [-0.1987, -0.1658,  0.1214,  0.1552,  0.2421, -0.1605, -0.0036, -0.1038,\n         -0.0818,  0.1014,  0.0435, -0.1708, -0.0565,  0.0377,  0.0763,  0.0343],\n        [-0.0532,  0.1370, -0.1709,  0.2194, -0.0857,  0.1071, -0.1002,  0.0851,\n         -0.0537,  0.0309,  0.2137, -0.0395,  0.1046, -0.1936, -0.0985,  0.1275],\n        [ 0.0750,  0.2394, -0.1432,  0.1924,  0.0115, -0.0479,  0.2412, -0.0780,\n          0.1477, -0.0164, -0.1509, -0.1657, -0.2254, -0.1831,  0.1750,  0.1056],\n        [ 0.0081, -0.1747,  0.0684,  0.0602, -0.1739,  0.2284, -0.0406, -0.0558,\n          0.0502, -0.2045, -0.1295, -0.1841,  0.0246,  0.1005, -0.0742, -0.2299],\n        [-0.0694,  0.2105, -0.2232, -0.1813, -0.2063,  0.0592, -0.0204,  0.2186,\n          0.0914, -0.2199, -0.0754, -0.0552,  0.0348,  0.1179,  0.1222, -0.0611],\n        [ 0.1551, -0.0830, -0.0863, -0.0478,  0.1450, -0.1462, -0.1171,  0.2113,\n         -0.2326, -0.1270,  0.0644,  0.1997, -0.1512, -0.0657,  0.0228, -0.1925]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0528, -0.1827,  0.0216, -0.2447], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1331,  0.0082, -0.2181,  0.2941, -0.0088, -0.2427, -0.2407,  0.3433],\n        [ 0.1804, -0.2339, -0.3082, -0.3369, -0.2254, -0.2387,  0.1408, -0.0468],\n        [-0.2841,  0.2960,  0.0730,  0.3424, -0.1728, -0.1286, -0.0713,  0.1669],\n        [ 0.2356, -0.1682,  0.0246,  0.3373, -0.2365,  0.2402, -0.1886,  0.1867]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7d27a7afff50>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s243030000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s243030000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}