{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s244230000"
    },
    "q_lr":	0.0005,
    "seed":	244230000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x747e0e2efcd0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0284, -0.2418, -0.0499,  0.2603,  0.0090,  0.1729, -0.3239, -0.0014,\n        -0.0394,  0.0595,  0.0224, -0.1891, -0.1327,  0.0888,  0.0200,  0.1192,\n        -0.0652,  0.2080,  0.1363, -0.0789,  0.2364, -0.3388,  0.0973,  0.1704,\n        -0.1176,  0.2629, -0.3309, -0.2095, -0.0800,  0.3389, -0.1010,  0.0788],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3135, -0.2757, -0.1072,  0.0656, -0.1633, -0.1863, -0.2718,  0.0739],\n        [-0.0218, -0.2914, -0.3387, -0.0286,  0.1010,  0.2428,  0.2411,  0.1331],\n        [-0.0988, -0.1694, -0.3008, -0.0650, -0.1203,  0.3342, -0.2443,  0.1180],\n        [ 0.3312, -0.1175, -0.2610,  0.2628,  0.0373, -0.0622,  0.2605, -0.2524],\n        [-0.0577,  0.1444, -0.2775, -0.3199,  0.1790, -0.1895, -0.0049, -0.0125],\n        [ 0.2846,  0.2707,  0.2499,  0.2429, -0.1680, -0.1252, -0.1336, -0.0042],\n        [-0.3238, -0.2610, -0.0416,  0.1853,  0.0594,  0.2582, -0.3078, -0.1645],\n        [ 0.2480, -0.2521, -0.1357,  0.2191,  0.1766,  0.0995, -0.1030,  0.2585],\n        [-0.2825,  0.1485, -0.0134, -0.3507,  0.0682,  0.3508,  0.1410, -0.2224],\n        [ 0.1864, -0.3106,  0.0812, -0.1348,  0.1281, -0.2044, -0.1695, -0.0355],\n        [ 0.1222, -0.3529,  0.0191,  0.0650,  0.3322, -0.1441, -0.1042, -0.2886],\n        [ 0.2606, -0.1590,  0.0065, -0.2996,  0.2985, -0.0220, -0.2637, -0.1079],\n        [ 0.1227,  0.1284,  0.1945, -0.0007, -0.0463, -0.0098, -0.0528, -0.1643],\n        [-0.2767,  0.1578, -0.1868,  0.0256, -0.1204, -0.0901,  0.0705, -0.1710],\n        [-0.1862,  0.0941, -0.1015,  0.0123,  0.1346, -0.1409,  0.3243,  0.2467],\n        [-0.2153, -0.3496,  0.2578, -0.0992, -0.2906, -0.2539, -0.2015,  0.3341],\n        [-0.1267, -0.1173,  0.1393,  0.3129,  0.3401, -0.0445,  0.0075,  0.3321],\n        [ 0.1610,  0.3225, -0.2855,  0.0055, -0.0498, -0.2008, -0.3467,  0.0117],\n        [ 0.2863, -0.0406,  0.0142,  0.3494, -0.1880,  0.1715,  0.2862, -0.0977],\n        [-0.1819, -0.3125,  0.1128,  0.1946, -0.2094, -0.0122, -0.3173, -0.1239],\n        [-0.2427, -0.2605, -0.1179,  0.1903,  0.1429, -0.2737,  0.2236,  0.3176],\n        [ 0.2967,  0.0008,  0.1384,  0.3339, -0.1901, -0.2815,  0.0471, -0.1950],\n        [ 0.1359,  0.2102, -0.2753, -0.1581, -0.2138,  0.0336, -0.0749,  0.2106],\n        [-0.2900,  0.1137, -0.0139, -0.1537,  0.2965,  0.0876, -0.0895, -0.2335],\n        [ 0.2550, -0.2107, -0.0902, -0.0669,  0.1828, -0.3137, -0.0221, -0.1017],\n        [-0.0292,  0.0286, -0.1890, -0.0179,  0.0065,  0.0187, -0.1311, -0.1186],\n        [ 0.3123, -0.3509,  0.1474, -0.2341,  0.2680, -0.0959,  0.0657,  0.1266],\n        [ 0.1396, -0.0600,  0.1997, -0.3370,  0.2557,  0.2273,  0.3386, -0.2202],\n        [-0.0070,  0.3215, -0.2221,  0.3504, -0.2756, -0.2481, -0.0214,  0.1589],\n        [-0.1917, -0.0754,  0.0529,  0.3114, -0.2262,  0.3255, -0.1602, -0.2330],\n        [-0.3439, -0.2796,  0.2656, -0.2851,  0.0120, -0.3465, -0.1679, -0.1338],\n        [-0.2513, -0.0262,  0.2260,  0.1172,  0.2766,  0.2357,  0.1276, -0.1216]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0943,  0.1536,  0.0495,  0.1635,  0.0763, -0.1342, -0.0682,  0.1084,\n        -0.1674,  0.0540,  0.0358, -0.0971,  0.1396, -0.0643, -0.0148, -0.1642],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 8.6792e-03,  9.7314e-02,  1.0477e-02,  6.5302e-02,  4.3405e-02,\n          1.5566e-01,  1.4004e-01, -8.7306e-02,  1.2878e-01, -1.6912e-01,\n          6.8286e-04, -1.4692e-01, -1.5683e-01,  1.2499e-01,  3.2735e-02,\n         -5.8926e-02, -4.1197e-02,  9.4097e-02, -1.6269e-01,  4.9038e-02,\n          1.2168e-01, -4.7435e-02,  1.0750e-02, -8.4204e-02,  7.9181e-02,\n         -1.5194e-01, -5.6118e-02,  9.7208e-02,  4.4671e-02, -4.2989e-02,\n         -1.4605e-03,  1.2791e-01],\n        [ 2.3196e-02, -7.4346e-02, -1.5992e-01,  1.3382e-01, -7.1610e-02,\n         -4.1274e-02, -1.5330e-01, -1.5976e-01, -7.5674e-02, -5.6966e-02,\n         -1.7341e-01, -1.0161e-01,  1.5089e-01,  1.5150e-02, -1.0911e-02,\n          8.0430e-02, -5.2069e-02, -3.4609e-02, -4.1060e-02,  1.3989e-01,\n         -6.4325e-02, -1.2614e-01,  1.0609e-01, -1.8215e-02, -9.6415e-02,\n         -1.6144e-01, -1.6451e-01, -8.8583e-02,  1.3046e-01,  1.5988e-01,\n          1.8324e-02, -1.1323e-02],\n        [-1.1142e-01,  1.0508e-01, -1.0037e-02,  1.0568e-01, -6.3628e-02,\n         -4.4518e-03, -4.9025e-02,  1.7285e-02, -1.3996e-01,  1.1366e-01,\n          1.6859e-01,  1.5579e-01,  1.7079e-01, -4.5626e-03, -1.7316e-01,\n         -1.0081e-01,  9.4484e-02,  8.2677e-02,  4.2500e-02,  9.5597e-02,\n         -1.9683e-02,  7.5701e-02, -2.6233e-02, -5.1306e-02,  6.3287e-02,\n          6.1273e-02, -1.4222e-01, -4.3183e-02, -6.5230e-02,  1.4984e-01,\n         -9.5136e-02, -6.5856e-02],\n        [ 9.5892e-02,  9.9095e-02, -1.6877e-01,  8.9316e-02, -1.6933e-01,\n         -1.1705e-01,  1.6768e-01,  3.0634e-02, -1.3248e-01, -1.1384e-01,\n         -1.6475e-01, -6.0927e-02, -1.4870e-01,  2.6412e-02, -3.1199e-02,\n         -1.7061e-02, -1.2748e-01, -2.3788e-02, -1.1745e-01, -1.3899e-01,\n         -1.2321e-01,  8.5765e-02, -1.3367e-01,  1.7476e-01, -1.4151e-01,\n          8.9771e-02,  1.7590e-01,  1.5309e-01,  1.3025e-01, -4.0556e-02,\n          2.9419e-02,  4.2715e-02],\n        [ 1.0672e-01, -1.6487e-01,  9.2121e-02, -4.1786e-02,  1.6064e-01,\n         -2.1637e-02,  5.5874e-02,  1.0208e-01,  4.5608e-02, -5.5966e-02,\n          6.8769e-02,  9.0219e-02,  1.0755e-01, -1.6534e-02, -5.1479e-02,\n          6.1387e-02,  1.4999e-02, -1.0829e-01,  1.4433e-02, -5.2566e-02,\n         -1.2418e-01,  1.0991e-01,  5.8379e-02, -4.6938e-02, -3.4311e-02,\n          9.8454e-02, -1.6105e-01, -1.2859e-01, -1.6669e-01, -6.5185e-02,\n          7.0681e-02,  1.1053e-01],\n        [-3.8265e-02, -3.4151e-02,  9.9137e-03, -6.9815e-02,  2.5620e-03,\n          1.0799e-01, -1.0705e-01,  4.2097e-02, -1.1562e-01, -5.0912e-02,\n         -2.4489e-02,  7.9528e-02, -1.1489e-01,  7.0418e-02,  1.5657e-01,\n          1.2941e-01,  4.0715e-02, -6.5728e-02,  1.5428e-01, -1.5924e-02,\n          6.2482e-03,  6.9575e-02, -3.7909e-02,  1.2401e-02, -1.4259e-01,\n          1.2432e-01, -1.0329e-01, -2.4922e-02,  1.3172e-01,  1.6424e-01,\n         -4.5223e-02, -6.8068e-02],\n        [ 1.4451e-01, -1.6675e-01, -1.5605e-01,  1.6676e-01, -9.5456e-02,\n         -1.0553e-01,  3.8321e-02, -4.8421e-02,  4.8071e-02,  4.9677e-02,\n         -1.0452e-01,  3.9393e-02,  5.2165e-02,  1.4494e-01, -1.5687e-01,\n         -1.1290e-01, -5.3467e-02, -1.2930e-01, -7.0899e-02,  4.5901e-02,\n          5.9788e-02,  9.5701e-02,  7.9559e-02, -3.7205e-02,  1.7916e-02,\n          6.6840e-03,  1.1982e-01,  7.9548e-02,  1.3747e-01,  5.9433e-02,\n          3.5007e-02,  1.2209e-01],\n        [-7.1238e-02, -2.7737e-02, -1.2053e-01,  7.2187e-02, -9.0623e-02,\n         -8.5387e-02,  9.9675e-02,  5.4891e-02, -1.1612e-01, -7.3464e-02,\n          1.5187e-01, -1.7433e-01, -1.2301e-01,  6.4048e-02,  4.2804e-02,\n         -1.7021e-01, -1.2872e-01,  1.3692e-01, -6.6851e-02, -1.4352e-02,\n         -2.4367e-02, -1.7125e-01,  1.1676e-02, -1.5959e-01,  1.1565e-01,\n         -1.6531e-01,  1.3831e-02, -1.6330e-01, -1.7017e-01, -1.0902e-01,\n          4.8871e-02, -1.6348e-01],\n        [ 1.7166e-01, -1.0361e-01,  1.1864e-01, -1.4001e-01,  7.1074e-02,\n         -1.3688e-01,  1.3545e-01,  3.6833e-02, -9.4952e-02, -1.4604e-01,\n         -1.5296e-01, -1.1406e-01, -9.6349e-02, -6.4396e-02,  1.0524e-01,\n         -1.1644e-01, -4.1336e-02,  1.2148e-01, -8.0633e-04, -9.1905e-02,\n         -1.1213e-01,  6.7855e-02, -1.2885e-01, -1.6543e-01,  1.6701e-01,\n          1.0114e-01, -1.7327e-01, -3.0815e-02, -8.3112e-02,  5.7391e-03,\n          1.8658e-02,  1.6714e-01],\n        [-1.2596e-01,  1.4612e-01, -4.9629e-02,  1.5790e-01,  1.0490e-01,\n         -1.1217e-01, -1.2085e-01,  5.0414e-03, -1.5159e-01, -1.5195e-01,\n         -6.3285e-02,  1.8154e-02, -4.1738e-02, -1.3583e-01,  1.0258e-01,\n          7.7736e-02,  8.7750e-03,  6.4614e-02, -6.3615e-02,  1.5517e-01,\n          9.4616e-02,  9.7392e-02,  3.0624e-02, -1.5681e-01, -7.6010e-03,\n          1.6276e-01,  1.3198e-01, -1.3689e-01,  1.8899e-02,  6.7105e-02,\n         -8.5241e-03,  4.4859e-02],\n        [ 6.3348e-02, -1.0360e-01,  4.8595e-05, -1.2629e-01,  1.0824e-01,\n         -1.4432e-01, -7.6212e-03,  1.2912e-01,  1.6665e-01,  7.7282e-03,\n         -1.4616e-01,  7.3244e-02,  1.1618e-01, -1.1825e-01, -7.7842e-02,\n          1.5448e-01,  1.3369e-01,  1.3290e-01,  2.4008e-02,  8.2802e-02,\n          1.7405e-01, -1.1601e-01, -1.6278e-01, -1.3655e-02,  1.6913e-02,\n         -3.6582e-02, -8.3961e-02, -8.9632e-02,  9.9511e-02,  1.4704e-02,\n          1.1743e-01, -8.4372e-02],\n        [-4.0956e-02,  5.1451e-02,  4.1660e-02, -1.0894e-01,  3.5788e-03,\n         -4.2927e-02, -1.2554e-01,  1.1171e-01, -8.5852e-02,  1.2011e-01,\n          1.2812e-01,  1.5837e-01, -1.6184e-01, -9.6291e-03,  6.2779e-02,\n          9.7733e-02, -6.8078e-02, -1.0609e-01, -1.2041e-01, -1.4691e-01,\n         -7.4901e-02, -1.4257e-01, -1.5350e-01,  1.2651e-01,  1.6113e-01,\n          1.0577e-01, -3.4932e-02,  3.1640e-02,  1.2288e-01,  2.8391e-02,\n          1.0145e-01,  7.4367e-02],\n        [ 2.4254e-03,  4.8850e-02,  1.4668e-01, -1.5738e-01, -1.5413e-01,\n          1.3467e-01, -1.7008e-01,  1.3829e-01, -1.1153e-01, -7.4719e-02,\n          1.6299e-01, -1.1554e-01,  1.0723e-02, -9.1470e-02,  1.3360e-01,\n         -3.3208e-02,  6.7749e-02, -1.2130e-01,  8.2293e-02, -3.7360e-02,\n         -9.7598e-02, -1.2747e-01,  2.1096e-02,  1.3932e-01, -5.9574e-02,\n          1.4166e-01, -1.1915e-03, -1.5459e-01, -1.7637e-01, -6.3066e-02,\n          1.3826e-01, -1.6712e-01],\n        [-7.3033e-02,  1.0495e-01, -8.0811e-02, -1.1951e-01,  1.6831e-03,\n          7.8834e-02, -9.8483e-03,  9.7781e-02, -5.0453e-02, -9.2792e-02,\n          1.0627e-01, -1.7581e-01,  8.9078e-02, -7.5328e-02, -1.6634e-01,\n         -1.3949e-01, -1.0483e-01, -1.6629e-01,  4.5460e-02,  2.3905e-02,\n          9.8510e-02,  1.0728e-01,  2.0138e-02,  1.3200e-01,  8.6137e-02,\n          1.1053e-01, -3.3811e-02,  1.3624e-01,  2.9424e-03,  3.2113e-02,\n          9.3193e-04, -4.3990e-03],\n        [-1.0384e-01,  8.1888e-02, -1.8120e-02,  2.7330e-02,  1.0975e-01,\n         -1.0353e-02,  1.4958e-01, -3.0394e-02,  7.0254e-02,  1.6990e-01,\n          5.6856e-02,  4.9192e-02, -1.5845e-01, -3.2888e-02,  1.1716e-01,\n          1.5512e-01,  7.4707e-02,  6.4158e-02,  9.8716e-02,  1.4605e-01,\n          5.1773e-02,  9.2148e-02, -1.6062e-01, -4.4785e-02, -4.8731e-02,\n          1.7058e-03, -4.3872e-02,  4.6199e-02,  6.4903e-02, -1.2540e-01,\n         -5.2212e-02,  1.2087e-01],\n        [ 1.5471e-01, -1.0535e-01,  7.6858e-02,  9.7900e-02,  1.7343e-01,\n          3.5896e-03,  1.0926e-01, -1.1793e-01, -4.1465e-03,  1.3335e-01,\n          1.1059e-02, -7.2010e-02,  1.4579e-01,  9.5003e-02, -8.7937e-02,\n         -7.0661e-02, -1.4756e-01,  1.6312e-01, -1.7439e-01, -1.3384e-01,\n         -8.0471e-02,  9.9618e-02,  2.1755e-02,  7.6096e-02,  7.0819e-02,\n          1.5517e-01, -1.4867e-01, -5.0533e-02,  2.6684e-02,  5.3970e-02,\n          1.4716e-01, -1.1579e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0507,  0.0842,  0.0336,  0.0189, -0.1570,  0.1278,  0.0342,  0.1465],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2123,  0.1917,  0.0713,  0.1540,  0.1592, -0.0961,  0.1567, -0.1546,\n          0.1499,  0.1429, -0.1343, -0.1748,  0.1005,  0.2411,  0.1721, -0.0400],\n        [-0.1142,  0.1754, -0.1374,  0.0179, -0.0318, -0.1839, -0.0304,  0.2011,\n         -0.0654, -0.1591,  0.1414, -0.2171,  0.1469,  0.1459, -0.0230,  0.0675],\n        [ 0.0111, -0.0615,  0.0099, -0.0768, -0.1641,  0.0298,  0.2344, -0.1460,\n          0.2450,  0.0707,  0.2284,  0.0516, -0.1448, -0.2483,  0.1982,  0.0362],\n        [ 0.0798,  0.1150, -0.0709,  0.2176, -0.1449, -0.0064,  0.0708,  0.1165,\n          0.0504, -0.0402, -0.0521,  0.2332,  0.2000,  0.0784, -0.0394, -0.1925],\n        [ 0.0598,  0.0524, -0.0752, -0.0930,  0.1182,  0.0268, -0.2458,  0.1510,\n         -0.1498,  0.0150,  0.0966,  0.0974, -0.0204, -0.2149, -0.0760,  0.1268],\n        [ 0.1145,  0.2066, -0.2017, -0.0467, -0.2447,  0.2263, -0.0463, -0.0788,\n          0.0458,  0.0478, -0.1994,  0.2102, -0.0611,  0.1907, -0.2297,  0.0424],\n        [ 0.1279,  0.2371,  0.0583,  0.0510, -0.1986, -0.0489,  0.0420,  0.0185,\n          0.2164, -0.0203, -0.0830,  0.0586, -0.0791, -0.1419,  0.0205, -0.2397],\n        [-0.0573, -0.1298,  0.1306, -0.0824, -0.0835,  0.2318,  0.2102, -0.0100,\n          0.1199,  0.1435,  0.1986, -0.1799, -0.0559, -0.2057, -0.0403, -0.2081]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3036,  0.0832,  0.1223,  0.2030], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3403,  0.1656,  0.3478,  0.0785, -0.2239,  0.1494, -0.1633,  0.0020],\n        [ 0.0208, -0.2549,  0.2553, -0.3018,  0.2692, -0.2650, -0.3209, -0.2570],\n        [ 0.2647,  0.1662,  0.0879,  0.3017, -0.3008,  0.0699,  0.2856,  0.0893],\n        [-0.1235,  0.1295,  0.0514, -0.0925, -0.3508, -0.1495,  0.1368, -0.0093]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.3135, -0.2757, -0.1072,  0.0656, -0.1633, -0.1863, -0.2718,  0.0739],\n        [-0.0218, -0.2914, -0.3387, -0.0286,  0.1010,  0.2428,  0.2411,  0.1331],\n        [-0.0988, -0.1694, -0.3008, -0.0650, -0.1203,  0.3342, -0.2443,  0.1180],\n        [ 0.3312, -0.1175, -0.2610,  0.2628,  0.0373, -0.0622,  0.2605, -0.2524],\n        [-0.0577,  0.1444, -0.2775, -0.3199,  0.1790, -0.1895, -0.0049, -0.0125],\n        [ 0.2846,  0.2707,  0.2499,  0.2429, -0.1680, -0.1252, -0.1336, -0.0042],\n        [-0.3238, -0.2610, -0.0416,  0.1853,  0.0594,  0.2582, -0.3078, -0.1645],\n        [ 0.2480, -0.2521, -0.1357,  0.2191,  0.1766,  0.0995, -0.1030,  0.2585],\n        [-0.2825,  0.1485, -0.0134, -0.3507,  0.0682,  0.3508,  0.1410, -0.2224],\n        [ 0.1864, -0.3106,  0.0812, -0.1348,  0.1281, -0.2044, -0.1695, -0.0355],\n        [ 0.1222, -0.3529,  0.0191,  0.0650,  0.3322, -0.1441, -0.1042, -0.2886],\n        [ 0.2606, -0.1590,  0.0065, -0.2996,  0.2985, -0.0220, -0.2637, -0.1079],\n        [ 0.1227,  0.1284,  0.1945, -0.0007, -0.0463, -0.0098, -0.0528, -0.1643],\n        [-0.2767,  0.1578, -0.1868,  0.0256, -0.1204, -0.0901,  0.0705, -0.1710],\n        [-0.1862,  0.0941, -0.1015,  0.0123,  0.1346, -0.1409,  0.3243,  0.2467],\n        [-0.2153, -0.3496,  0.2578, -0.0992, -0.2906, -0.2539, -0.2015,  0.3341],\n        [-0.1267, -0.1173,  0.1393,  0.3129,  0.3401, -0.0445,  0.0075,  0.3321],\n        [ 0.1610,  0.3225, -0.2855,  0.0055, -0.0498, -0.2008, -0.3467,  0.0117],\n        [ 0.2863, -0.0406,  0.0142,  0.3494, -0.1880,  0.1715,  0.2862, -0.0977],\n        [-0.1819, -0.3125,  0.1128,  0.1946, -0.2094, -0.0122, -0.3173, -0.1239],\n        [-0.2427, -0.2605, -0.1179,  0.1903,  0.1429, -0.2737,  0.2236,  0.3176],\n        [ 0.2967,  0.0008,  0.1384,  0.3339, -0.1901, -0.2815,  0.0471, -0.1950],\n        [ 0.1359,  0.2102, -0.2753, -0.1581, -0.2138,  0.0336, -0.0749,  0.2106],\n        [-0.2900,  0.1137, -0.0139, -0.1537,  0.2965,  0.0876, -0.0895, -0.2335],\n        [ 0.2550, -0.2107, -0.0902, -0.0669,  0.1828, -0.3137, -0.0221, -0.1017],\n        [-0.0292,  0.0286, -0.1890, -0.0179,  0.0065,  0.0187, -0.1311, -0.1186],\n        [ 0.3123, -0.3509,  0.1474, -0.2341,  0.2680, -0.0959,  0.0657,  0.1266],\n        [ 0.1396, -0.0600,  0.1997, -0.3370,  0.2557,  0.2273,  0.3386, -0.2202],\n        [-0.0070,  0.3215, -0.2221,  0.3504, -0.2756, -0.2481, -0.0214,  0.1589],\n        [-0.1917, -0.0754,  0.0529,  0.3114, -0.2262,  0.3255, -0.1602, -0.2330],\n        [-0.3439, -0.2796,  0.2656, -0.2851,  0.0120, -0.3465, -0.1679, -0.1338],\n        [-0.2513, -0.0262,  0.2260,  0.1172,  0.2766,  0.2357,  0.1276, -0.1216]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0284, -0.2418, -0.0499,  0.2603,  0.0090,  0.1729, -0.3239, -0.0014,\n        -0.0394,  0.0595,  0.0224, -0.1891, -0.1327,  0.0888,  0.0200,  0.1192,\n        -0.0652,  0.2080,  0.1363, -0.0789,  0.2364, -0.3388,  0.0973,  0.1704,\n        -0.1176,  0.2629, -0.3309, -0.2095, -0.0800,  0.3389, -0.1010,  0.0788],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 8.6792e-03,  9.7314e-02,  1.0477e-02,  6.5302e-02,  4.3405e-02,\n          1.5566e-01,  1.4004e-01, -8.7306e-02,  1.2878e-01, -1.6912e-01,\n          6.8286e-04, -1.4692e-01, -1.5683e-01,  1.2499e-01,  3.2735e-02,\n         -5.8926e-02, -4.1197e-02,  9.4097e-02, -1.6269e-01,  4.9038e-02,\n          1.2168e-01, -4.7435e-02,  1.0750e-02, -8.4204e-02,  7.9181e-02,\n         -1.5194e-01, -5.6118e-02,  9.7208e-02,  4.4671e-02, -4.2989e-02,\n         -1.4605e-03,  1.2791e-01],\n        [ 2.3196e-02, -7.4346e-02, -1.5992e-01,  1.3382e-01, -7.1610e-02,\n         -4.1274e-02, -1.5330e-01, -1.5976e-01, -7.5674e-02, -5.6966e-02,\n         -1.7341e-01, -1.0161e-01,  1.5089e-01,  1.5150e-02, -1.0911e-02,\n          8.0430e-02, -5.2069e-02, -3.4609e-02, -4.1060e-02,  1.3989e-01,\n         -6.4325e-02, -1.2614e-01,  1.0609e-01, -1.8215e-02, -9.6415e-02,\n         -1.6144e-01, -1.6451e-01, -8.8583e-02,  1.3046e-01,  1.5988e-01,\n          1.8324e-02, -1.1323e-02],\n        [-1.1142e-01,  1.0508e-01, -1.0037e-02,  1.0568e-01, -6.3628e-02,\n         -4.4518e-03, -4.9025e-02,  1.7285e-02, -1.3996e-01,  1.1366e-01,\n          1.6859e-01,  1.5579e-01,  1.7079e-01, -4.5626e-03, -1.7316e-01,\n         -1.0081e-01,  9.4484e-02,  8.2677e-02,  4.2500e-02,  9.5597e-02,\n         -1.9683e-02,  7.5701e-02, -2.6233e-02, -5.1306e-02,  6.3287e-02,\n          6.1273e-02, -1.4222e-01, -4.3183e-02, -6.5230e-02,  1.4984e-01,\n         -9.5136e-02, -6.5856e-02],\n        [ 9.5892e-02,  9.9095e-02, -1.6877e-01,  8.9316e-02, -1.6933e-01,\n         -1.1705e-01,  1.6768e-01,  3.0634e-02, -1.3248e-01, -1.1384e-01,\n         -1.6475e-01, -6.0927e-02, -1.4870e-01,  2.6412e-02, -3.1199e-02,\n         -1.7061e-02, -1.2748e-01, -2.3788e-02, -1.1745e-01, -1.3899e-01,\n         -1.2321e-01,  8.5765e-02, -1.3367e-01,  1.7476e-01, -1.4151e-01,\n          8.9771e-02,  1.7590e-01,  1.5309e-01,  1.3025e-01, -4.0556e-02,\n          2.9419e-02,  4.2715e-02],\n        [ 1.0672e-01, -1.6487e-01,  9.2121e-02, -4.1786e-02,  1.6064e-01,\n         -2.1637e-02,  5.5874e-02,  1.0208e-01,  4.5608e-02, -5.5966e-02,\n          6.8769e-02,  9.0219e-02,  1.0755e-01, -1.6534e-02, -5.1479e-02,\n          6.1387e-02,  1.4999e-02, -1.0829e-01,  1.4433e-02, -5.2566e-02,\n         -1.2418e-01,  1.0991e-01,  5.8379e-02, -4.6938e-02, -3.4311e-02,\n          9.8454e-02, -1.6105e-01, -1.2859e-01, -1.6669e-01, -6.5185e-02,\n          7.0681e-02,  1.1053e-01],\n        [-3.8265e-02, -3.4151e-02,  9.9137e-03, -6.9815e-02,  2.5620e-03,\n          1.0799e-01, -1.0705e-01,  4.2097e-02, -1.1562e-01, -5.0912e-02,\n         -2.4489e-02,  7.9528e-02, -1.1489e-01,  7.0418e-02,  1.5657e-01,\n          1.2941e-01,  4.0715e-02, -6.5728e-02,  1.5428e-01, -1.5924e-02,\n          6.2482e-03,  6.9575e-02, -3.7909e-02,  1.2401e-02, -1.4259e-01,\n          1.2432e-01, -1.0329e-01, -2.4922e-02,  1.3172e-01,  1.6424e-01,\n         -4.5223e-02, -6.8068e-02],\n        [ 1.4451e-01, -1.6675e-01, -1.5605e-01,  1.6676e-01, -9.5456e-02,\n         -1.0553e-01,  3.8321e-02, -4.8421e-02,  4.8071e-02,  4.9677e-02,\n         -1.0452e-01,  3.9393e-02,  5.2165e-02,  1.4494e-01, -1.5687e-01,\n         -1.1290e-01, -5.3467e-02, -1.2930e-01, -7.0899e-02,  4.5901e-02,\n          5.9788e-02,  9.5701e-02,  7.9559e-02, -3.7205e-02,  1.7916e-02,\n          6.6840e-03,  1.1982e-01,  7.9548e-02,  1.3747e-01,  5.9433e-02,\n          3.5007e-02,  1.2209e-01],\n        [-7.1238e-02, -2.7737e-02, -1.2053e-01,  7.2187e-02, -9.0623e-02,\n         -8.5387e-02,  9.9675e-02,  5.4891e-02, -1.1612e-01, -7.3464e-02,\n          1.5187e-01, -1.7433e-01, -1.2301e-01,  6.4048e-02,  4.2804e-02,\n         -1.7021e-01, -1.2872e-01,  1.3692e-01, -6.6851e-02, -1.4352e-02,\n         -2.4367e-02, -1.7125e-01,  1.1676e-02, -1.5959e-01,  1.1565e-01,\n         -1.6531e-01,  1.3831e-02, -1.6330e-01, -1.7017e-01, -1.0902e-01,\n          4.8871e-02, -1.6348e-01],\n        [ 1.7166e-01, -1.0361e-01,  1.1864e-01, -1.4001e-01,  7.1074e-02,\n         -1.3688e-01,  1.3545e-01,  3.6833e-02, -9.4952e-02, -1.4604e-01,\n         -1.5296e-01, -1.1406e-01, -9.6349e-02, -6.4396e-02,  1.0524e-01,\n         -1.1644e-01, -4.1336e-02,  1.2148e-01, -8.0633e-04, -9.1905e-02,\n         -1.1213e-01,  6.7855e-02, -1.2885e-01, -1.6543e-01,  1.6701e-01,\n          1.0114e-01, -1.7327e-01, -3.0815e-02, -8.3112e-02,  5.7391e-03,\n          1.8658e-02,  1.6714e-01],\n        [-1.2596e-01,  1.4612e-01, -4.9629e-02,  1.5790e-01,  1.0490e-01,\n         -1.1217e-01, -1.2085e-01,  5.0414e-03, -1.5159e-01, -1.5195e-01,\n         -6.3285e-02,  1.8154e-02, -4.1738e-02, -1.3583e-01,  1.0258e-01,\n          7.7736e-02,  8.7750e-03,  6.4614e-02, -6.3615e-02,  1.5517e-01,\n          9.4616e-02,  9.7392e-02,  3.0624e-02, -1.5681e-01, -7.6010e-03,\n          1.6276e-01,  1.3198e-01, -1.3689e-01,  1.8899e-02,  6.7105e-02,\n         -8.5241e-03,  4.4859e-02],\n        [ 6.3348e-02, -1.0360e-01,  4.8595e-05, -1.2629e-01,  1.0824e-01,\n         -1.4432e-01, -7.6212e-03,  1.2912e-01,  1.6665e-01,  7.7282e-03,\n         -1.4616e-01,  7.3244e-02,  1.1618e-01, -1.1825e-01, -7.7842e-02,\n          1.5448e-01,  1.3369e-01,  1.3290e-01,  2.4008e-02,  8.2802e-02,\n          1.7405e-01, -1.1601e-01, -1.6278e-01, -1.3655e-02,  1.6913e-02,\n         -3.6582e-02, -8.3961e-02, -8.9632e-02,  9.9511e-02,  1.4704e-02,\n          1.1743e-01, -8.4372e-02],\n        [-4.0956e-02,  5.1451e-02,  4.1660e-02, -1.0894e-01,  3.5788e-03,\n         -4.2927e-02, -1.2554e-01,  1.1171e-01, -8.5852e-02,  1.2011e-01,\n          1.2812e-01,  1.5837e-01, -1.6184e-01, -9.6291e-03,  6.2779e-02,\n          9.7733e-02, -6.8078e-02, -1.0609e-01, -1.2041e-01, -1.4691e-01,\n         -7.4901e-02, -1.4257e-01, -1.5350e-01,  1.2651e-01,  1.6113e-01,\n          1.0577e-01, -3.4932e-02,  3.1640e-02,  1.2288e-01,  2.8391e-02,\n          1.0145e-01,  7.4367e-02],\n        [ 2.4254e-03,  4.8850e-02,  1.4668e-01, -1.5738e-01, -1.5413e-01,\n          1.3467e-01, -1.7008e-01,  1.3829e-01, -1.1153e-01, -7.4719e-02,\n          1.6299e-01, -1.1554e-01,  1.0723e-02, -9.1470e-02,  1.3360e-01,\n         -3.3208e-02,  6.7749e-02, -1.2130e-01,  8.2293e-02, -3.7360e-02,\n         -9.7598e-02, -1.2747e-01,  2.1096e-02,  1.3932e-01, -5.9574e-02,\n          1.4166e-01, -1.1915e-03, -1.5459e-01, -1.7637e-01, -6.3066e-02,\n          1.3826e-01, -1.6712e-01],\n        [-7.3033e-02,  1.0495e-01, -8.0811e-02, -1.1951e-01,  1.6831e-03,\n          7.8834e-02, -9.8483e-03,  9.7781e-02, -5.0453e-02, -9.2792e-02,\n          1.0627e-01, -1.7581e-01,  8.9078e-02, -7.5328e-02, -1.6634e-01,\n         -1.3949e-01, -1.0483e-01, -1.6629e-01,  4.5460e-02,  2.3905e-02,\n          9.8510e-02,  1.0728e-01,  2.0138e-02,  1.3200e-01,  8.6137e-02,\n          1.1053e-01, -3.3811e-02,  1.3624e-01,  2.9424e-03,  3.2113e-02,\n          9.3193e-04, -4.3990e-03],\n        [-1.0384e-01,  8.1888e-02, -1.8120e-02,  2.7330e-02,  1.0975e-01,\n         -1.0353e-02,  1.4958e-01, -3.0394e-02,  7.0254e-02,  1.6990e-01,\n          5.6856e-02,  4.9192e-02, -1.5845e-01, -3.2888e-02,  1.1716e-01,\n          1.5512e-01,  7.4707e-02,  6.4158e-02,  9.8716e-02,  1.4605e-01,\n          5.1773e-02,  9.2148e-02, -1.6062e-01, -4.4785e-02, -4.8731e-02,\n          1.7058e-03, -4.3872e-02,  4.6199e-02,  6.4903e-02, -1.2540e-01,\n         -5.2212e-02,  1.2087e-01],\n        [ 1.5471e-01, -1.0535e-01,  7.6858e-02,  9.7900e-02,  1.7343e-01,\n          3.5896e-03,  1.0926e-01, -1.1793e-01, -4.1465e-03,  1.3335e-01,\n          1.1059e-02, -7.2010e-02,  1.4579e-01,  9.5003e-02, -8.7937e-02,\n         -7.0661e-02, -1.4756e-01,  1.6312e-01, -1.7439e-01, -1.3384e-01,\n         -8.0471e-02,  9.9618e-02,  2.1755e-02,  7.6096e-02,  7.0819e-02,\n          1.5517e-01, -1.4867e-01, -5.0533e-02,  2.6684e-02,  5.3970e-02,\n          1.4716e-01, -1.1579e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0943,  0.1536,  0.0495,  0.1635,  0.0763, -0.1342, -0.0682,  0.1084,\n        -0.1674,  0.0540,  0.0358, -0.0971,  0.1396, -0.0643, -0.0148, -0.1642],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2123,  0.1917,  0.0713,  0.1540,  0.1592, -0.0961,  0.1567, -0.1546,\n          0.1499,  0.1429, -0.1343, -0.1748,  0.1005,  0.2411,  0.1721, -0.0400],\n        [-0.1142,  0.1754, -0.1374,  0.0179, -0.0318, -0.1839, -0.0304,  0.2011,\n         -0.0654, -0.1591,  0.1414, -0.2171,  0.1469,  0.1459, -0.0230,  0.0675],\n        [ 0.0111, -0.0615,  0.0099, -0.0768, -0.1641,  0.0298,  0.2344, -0.1460,\n          0.2450,  0.0707,  0.2284,  0.0516, -0.1448, -0.2483,  0.1982,  0.0362],\n        [ 0.0798,  0.1150, -0.0709,  0.2176, -0.1449, -0.0064,  0.0708,  0.1165,\n          0.0504, -0.0402, -0.0521,  0.2332,  0.2000,  0.0784, -0.0394, -0.1925],\n        [ 0.0598,  0.0524, -0.0752, -0.0930,  0.1182,  0.0268, -0.2458,  0.1510,\n         -0.1498,  0.0150,  0.0966,  0.0974, -0.0204, -0.2149, -0.0760,  0.1268],\n        [ 0.1145,  0.2066, -0.2017, -0.0467, -0.2447,  0.2263, -0.0463, -0.0788,\n          0.0458,  0.0478, -0.1994,  0.2102, -0.0611,  0.1907, -0.2297,  0.0424],\n        [ 0.1279,  0.2371,  0.0583,  0.0510, -0.1986, -0.0489,  0.0420,  0.0185,\n          0.2164, -0.0203, -0.0830,  0.0586, -0.0791, -0.1419,  0.0205, -0.2397],\n        [-0.0573, -0.1298,  0.1306, -0.0824, -0.0835,  0.2318,  0.2102, -0.0100,\n          0.1199,  0.1435,  0.1986, -0.1799, -0.0559, -0.2057, -0.0403, -0.2081]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0507,  0.0842,  0.0336,  0.0189, -0.1570,  0.1278,  0.0342,  0.1465],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3403,  0.1656,  0.3478,  0.0785, -0.2239,  0.1494, -0.1633,  0.0020],\n        [ 0.0208, -0.2549,  0.2553, -0.3018,  0.2692, -0.2650, -0.3209, -0.2570],\n        [ 0.2647,  0.1662,  0.0879,  0.3017, -0.3008,  0.0699,  0.2856,  0.0893],\n        [-0.1235,  0.1295,  0.0514, -0.0925, -0.3508, -0.1495,  0.1368, -0.0093]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3036,  0.0832,  0.1223,  0.2030], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x747e879de790>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]",
                    "time":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0284, -0.2418, -0.0499,  0.2603,  0.0090,  0.1729, -0.3239, -0.0014,\n        -0.0394,  0.0595,  0.0224, -0.1891, -0.1327,  0.0888,  0.0200,  0.1192,\n        -0.0652,  0.2080,  0.1363, -0.0789,  0.2364, -0.3388,  0.0973,  0.1704,\n        -0.1176,  0.2629, -0.3309, -0.2095, -0.0800,  0.3389, -0.1010,  0.0788],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3135, -0.2757, -0.1072,  0.0656, -0.1633, -0.1863, -0.2718,  0.0739],\n        [-0.0218, -0.2914, -0.3387, -0.0286,  0.1010,  0.2428,  0.2411,  0.1331],\n        [-0.0988, -0.1694, -0.3008, -0.0650, -0.1203,  0.3342, -0.2443,  0.1180],\n        [ 0.3312, -0.1175, -0.2610,  0.2628,  0.0373, -0.0622,  0.2605, -0.2524],\n        [-0.0577,  0.1444, -0.2775, -0.3199,  0.1790, -0.1895, -0.0049, -0.0125],\n        [ 0.2846,  0.2707,  0.2499,  0.2429, -0.1680, -0.1252, -0.1336, -0.0042],\n        [-0.3238, -0.2610, -0.0416,  0.1853,  0.0594,  0.2582, -0.3078, -0.1645],\n        [ 0.2480, -0.2521, -0.1357,  0.2191,  0.1766,  0.0995, -0.1030,  0.2585],\n        [-0.2825,  0.1485, -0.0134, -0.3507,  0.0682,  0.3508,  0.1410, -0.2224],\n        [ 0.1864, -0.3106,  0.0812, -0.1348,  0.1281, -0.2044, -0.1695, -0.0355],\n        [ 0.1222, -0.3529,  0.0191,  0.0650,  0.3322, -0.1441, -0.1042, -0.2886],\n        [ 0.2606, -0.1590,  0.0065, -0.2996,  0.2985, -0.0220, -0.2637, -0.1079],\n        [ 0.1227,  0.1284,  0.1945, -0.0007, -0.0463, -0.0098, -0.0528, -0.1643],\n        [-0.2767,  0.1578, -0.1868,  0.0256, -0.1204, -0.0901,  0.0705, -0.1710],\n        [-0.1862,  0.0941, -0.1015,  0.0123,  0.1346, -0.1409,  0.3243,  0.2467],\n        [-0.2153, -0.3496,  0.2578, -0.0992, -0.2906, -0.2539, -0.2015,  0.3341],\n        [-0.1267, -0.1173,  0.1393,  0.3129,  0.3401, -0.0445,  0.0075,  0.3321],\n        [ 0.1610,  0.3225, -0.2855,  0.0055, -0.0498, -0.2008, -0.3467,  0.0117],\n        [ 0.2863, -0.0406,  0.0142,  0.3494, -0.1880,  0.1715,  0.2862, -0.0977],\n        [-0.1819, -0.3125,  0.1128,  0.1946, -0.2094, -0.0122, -0.3173, -0.1239],\n        [-0.2427, -0.2605, -0.1179,  0.1903,  0.1429, -0.2737,  0.2236,  0.3176],\n        [ 0.2967,  0.0008,  0.1384,  0.3339, -0.1901, -0.2815,  0.0471, -0.1950],\n        [ 0.1359,  0.2102, -0.2753, -0.1581, -0.2138,  0.0336, -0.0749,  0.2106],\n        [-0.2900,  0.1137, -0.0139, -0.1537,  0.2965,  0.0876, -0.0895, -0.2335],\n        [ 0.2550, -0.2107, -0.0902, -0.0669,  0.1828, -0.3137, -0.0221, -0.1017],\n        [-0.0292,  0.0286, -0.1890, -0.0179,  0.0065,  0.0187, -0.1311, -0.1186],\n        [ 0.3123, -0.3509,  0.1474, -0.2341,  0.2680, -0.0959,  0.0657,  0.1266],\n        [ 0.1396, -0.0600,  0.1997, -0.3370,  0.2557,  0.2273,  0.3386, -0.2202],\n        [-0.0070,  0.3215, -0.2221,  0.3504, -0.2756, -0.2481, -0.0214,  0.1589],\n        [-0.1917, -0.0754,  0.0529,  0.3114, -0.2262,  0.3255, -0.1602, -0.2330],\n        [-0.3439, -0.2796,  0.2656, -0.2851,  0.0120, -0.3465, -0.1679, -0.1338],\n        [-0.2513, -0.0262,  0.2260,  0.1172,  0.2766,  0.2357,  0.1276, -0.1216]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0943,  0.1536,  0.0495,  0.1635,  0.0763, -0.1342, -0.0682,  0.1084,\n        -0.1674,  0.0540,  0.0358, -0.0971,  0.1396, -0.0643, -0.0148, -0.1642],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 8.6792e-03,  9.7314e-02,  1.0477e-02,  6.5302e-02,  4.3405e-02,\n          1.5566e-01,  1.4004e-01, -8.7306e-02,  1.2878e-01, -1.6912e-01,\n          6.8286e-04, -1.4692e-01, -1.5683e-01,  1.2499e-01,  3.2735e-02,\n         -5.8926e-02, -4.1197e-02,  9.4097e-02, -1.6269e-01,  4.9038e-02,\n          1.2168e-01, -4.7435e-02,  1.0750e-02, -8.4204e-02,  7.9181e-02,\n         -1.5194e-01, -5.6118e-02,  9.7208e-02,  4.4671e-02, -4.2989e-02,\n         -1.4605e-03,  1.2791e-01],\n        [ 2.3196e-02, -7.4346e-02, -1.5992e-01,  1.3382e-01, -7.1610e-02,\n         -4.1274e-02, -1.5330e-01, -1.5976e-01, -7.5674e-02, -5.6966e-02,\n         -1.7341e-01, -1.0161e-01,  1.5089e-01,  1.5150e-02, -1.0911e-02,\n          8.0430e-02, -5.2069e-02, -3.4609e-02, -4.1060e-02,  1.3989e-01,\n         -6.4325e-02, -1.2614e-01,  1.0609e-01, -1.8215e-02, -9.6415e-02,\n         -1.6144e-01, -1.6451e-01, -8.8583e-02,  1.3046e-01,  1.5988e-01,\n          1.8324e-02, -1.1323e-02],\n        [-1.1142e-01,  1.0508e-01, -1.0037e-02,  1.0568e-01, -6.3628e-02,\n         -4.4518e-03, -4.9025e-02,  1.7285e-02, -1.3996e-01,  1.1366e-01,\n          1.6859e-01,  1.5579e-01,  1.7079e-01, -4.5626e-03, -1.7316e-01,\n         -1.0081e-01,  9.4484e-02,  8.2677e-02,  4.2500e-02,  9.5597e-02,\n         -1.9683e-02,  7.5701e-02, -2.6233e-02, -5.1306e-02,  6.3287e-02,\n          6.1273e-02, -1.4222e-01, -4.3183e-02, -6.5230e-02,  1.4984e-01,\n         -9.5136e-02, -6.5856e-02],\n        [ 9.5892e-02,  9.9095e-02, -1.6877e-01,  8.9316e-02, -1.6933e-01,\n         -1.1705e-01,  1.6768e-01,  3.0634e-02, -1.3248e-01, -1.1384e-01,\n         -1.6475e-01, -6.0927e-02, -1.4870e-01,  2.6412e-02, -3.1199e-02,\n         -1.7061e-02, -1.2748e-01, -2.3788e-02, -1.1745e-01, -1.3899e-01,\n         -1.2321e-01,  8.5765e-02, -1.3367e-01,  1.7476e-01, -1.4151e-01,\n          8.9771e-02,  1.7590e-01,  1.5309e-01,  1.3025e-01, -4.0556e-02,\n          2.9419e-02,  4.2715e-02],\n        [ 1.0672e-01, -1.6487e-01,  9.2121e-02, -4.1786e-02,  1.6064e-01,\n         -2.1637e-02,  5.5874e-02,  1.0208e-01,  4.5608e-02, -5.5966e-02,\n          6.8769e-02,  9.0219e-02,  1.0755e-01, -1.6534e-02, -5.1479e-02,\n          6.1387e-02,  1.4999e-02, -1.0829e-01,  1.4433e-02, -5.2566e-02,\n         -1.2418e-01,  1.0991e-01,  5.8379e-02, -4.6938e-02, -3.4311e-02,\n          9.8454e-02, -1.6105e-01, -1.2859e-01, -1.6669e-01, -6.5185e-02,\n          7.0681e-02,  1.1053e-01],\n        [-3.8265e-02, -3.4151e-02,  9.9137e-03, -6.9815e-02,  2.5620e-03,\n          1.0799e-01, -1.0705e-01,  4.2097e-02, -1.1562e-01, -5.0912e-02,\n         -2.4489e-02,  7.9528e-02, -1.1489e-01,  7.0418e-02,  1.5657e-01,\n          1.2941e-01,  4.0715e-02, -6.5728e-02,  1.5428e-01, -1.5924e-02,\n          6.2482e-03,  6.9575e-02, -3.7909e-02,  1.2401e-02, -1.4259e-01,\n          1.2432e-01, -1.0329e-01, -2.4922e-02,  1.3172e-01,  1.6424e-01,\n         -4.5223e-02, -6.8068e-02],\n        [ 1.4451e-01, -1.6675e-01, -1.5605e-01,  1.6676e-01, -9.5456e-02,\n         -1.0553e-01,  3.8321e-02, -4.8421e-02,  4.8071e-02,  4.9677e-02,\n         -1.0452e-01,  3.9393e-02,  5.2165e-02,  1.4494e-01, -1.5687e-01,\n         -1.1290e-01, -5.3467e-02, -1.2930e-01, -7.0899e-02,  4.5901e-02,\n          5.9788e-02,  9.5701e-02,  7.9559e-02, -3.7205e-02,  1.7916e-02,\n          6.6840e-03,  1.1982e-01,  7.9548e-02,  1.3747e-01,  5.9433e-02,\n          3.5007e-02,  1.2209e-01],\n        [-7.1238e-02, -2.7737e-02, -1.2053e-01,  7.2187e-02, -9.0623e-02,\n         -8.5387e-02,  9.9675e-02,  5.4891e-02, -1.1612e-01, -7.3464e-02,\n          1.5187e-01, -1.7433e-01, -1.2301e-01,  6.4048e-02,  4.2804e-02,\n         -1.7021e-01, -1.2872e-01,  1.3692e-01, -6.6851e-02, -1.4352e-02,\n         -2.4367e-02, -1.7125e-01,  1.1676e-02, -1.5959e-01,  1.1565e-01,\n         -1.6531e-01,  1.3831e-02, -1.6330e-01, -1.7017e-01, -1.0902e-01,\n          4.8871e-02, -1.6348e-01],\n        [ 1.7166e-01, -1.0361e-01,  1.1864e-01, -1.4001e-01,  7.1074e-02,\n         -1.3688e-01,  1.3545e-01,  3.6833e-02, -9.4952e-02, -1.4604e-01,\n         -1.5296e-01, -1.1406e-01, -9.6349e-02, -6.4396e-02,  1.0524e-01,\n         -1.1644e-01, -4.1336e-02,  1.2148e-01, -8.0633e-04, -9.1905e-02,\n         -1.1213e-01,  6.7855e-02, -1.2885e-01, -1.6543e-01,  1.6701e-01,\n          1.0114e-01, -1.7327e-01, -3.0815e-02, -8.3112e-02,  5.7391e-03,\n          1.8658e-02,  1.6714e-01],\n        [-1.2596e-01,  1.4612e-01, -4.9629e-02,  1.5790e-01,  1.0490e-01,\n         -1.1217e-01, -1.2085e-01,  5.0414e-03, -1.5159e-01, -1.5195e-01,\n         -6.3285e-02,  1.8154e-02, -4.1738e-02, -1.3583e-01,  1.0258e-01,\n          7.7736e-02,  8.7750e-03,  6.4614e-02, -6.3615e-02,  1.5517e-01,\n          9.4616e-02,  9.7392e-02,  3.0624e-02, -1.5681e-01, -7.6010e-03,\n          1.6276e-01,  1.3198e-01, -1.3689e-01,  1.8899e-02,  6.7105e-02,\n         -8.5241e-03,  4.4859e-02],\n        [ 6.3348e-02, -1.0360e-01,  4.8595e-05, -1.2629e-01,  1.0824e-01,\n         -1.4432e-01, -7.6212e-03,  1.2912e-01,  1.6665e-01,  7.7282e-03,\n         -1.4616e-01,  7.3244e-02,  1.1618e-01, -1.1825e-01, -7.7842e-02,\n          1.5448e-01,  1.3369e-01,  1.3290e-01,  2.4008e-02,  8.2802e-02,\n          1.7405e-01, -1.1601e-01, -1.6278e-01, -1.3655e-02,  1.6913e-02,\n         -3.6582e-02, -8.3961e-02, -8.9632e-02,  9.9511e-02,  1.4704e-02,\n          1.1743e-01, -8.4372e-02],\n        [-4.0956e-02,  5.1451e-02,  4.1660e-02, -1.0894e-01,  3.5788e-03,\n         -4.2927e-02, -1.2554e-01,  1.1171e-01, -8.5852e-02,  1.2011e-01,\n          1.2812e-01,  1.5837e-01, -1.6184e-01, -9.6291e-03,  6.2779e-02,\n          9.7733e-02, -6.8078e-02, -1.0609e-01, -1.2041e-01, -1.4691e-01,\n         -7.4901e-02, -1.4257e-01, -1.5350e-01,  1.2651e-01,  1.6113e-01,\n          1.0577e-01, -3.4932e-02,  3.1640e-02,  1.2288e-01,  2.8391e-02,\n          1.0145e-01,  7.4367e-02],\n        [ 2.4254e-03,  4.8850e-02,  1.4668e-01, -1.5738e-01, -1.5413e-01,\n          1.3467e-01, -1.7008e-01,  1.3829e-01, -1.1153e-01, -7.4719e-02,\n          1.6299e-01, -1.1554e-01,  1.0723e-02, -9.1470e-02,  1.3360e-01,\n         -3.3208e-02,  6.7749e-02, -1.2130e-01,  8.2293e-02, -3.7360e-02,\n         -9.7598e-02, -1.2747e-01,  2.1096e-02,  1.3932e-01, -5.9574e-02,\n          1.4166e-01, -1.1915e-03, -1.5459e-01, -1.7637e-01, -6.3066e-02,\n          1.3826e-01, -1.6712e-01],\n        [-7.3033e-02,  1.0495e-01, -8.0811e-02, -1.1951e-01,  1.6831e-03,\n          7.8834e-02, -9.8483e-03,  9.7781e-02, -5.0453e-02, -9.2792e-02,\n          1.0627e-01, -1.7581e-01,  8.9078e-02, -7.5328e-02, -1.6634e-01,\n         -1.3949e-01, -1.0483e-01, -1.6629e-01,  4.5460e-02,  2.3905e-02,\n          9.8510e-02,  1.0728e-01,  2.0138e-02,  1.3200e-01,  8.6137e-02,\n          1.1053e-01, -3.3811e-02,  1.3624e-01,  2.9424e-03,  3.2113e-02,\n          9.3193e-04, -4.3990e-03],\n        [-1.0384e-01,  8.1888e-02, -1.8120e-02,  2.7330e-02,  1.0975e-01,\n         -1.0353e-02,  1.4958e-01, -3.0394e-02,  7.0254e-02,  1.6990e-01,\n          5.6856e-02,  4.9192e-02, -1.5845e-01, -3.2888e-02,  1.1716e-01,\n          1.5512e-01,  7.4707e-02,  6.4158e-02,  9.8716e-02,  1.4605e-01,\n          5.1773e-02,  9.2148e-02, -1.6062e-01, -4.4785e-02, -4.8731e-02,\n          1.7058e-03, -4.3872e-02,  4.6199e-02,  6.4903e-02, -1.2540e-01,\n         -5.2212e-02,  1.2087e-01],\n        [ 1.5471e-01, -1.0535e-01,  7.6858e-02,  9.7900e-02,  1.7343e-01,\n          3.5896e-03,  1.0926e-01, -1.1793e-01, -4.1465e-03,  1.3335e-01,\n          1.1059e-02, -7.2010e-02,  1.4579e-01,  9.5003e-02, -8.7937e-02,\n         -7.0661e-02, -1.4756e-01,  1.6312e-01, -1.7439e-01, -1.3384e-01,\n         -8.0471e-02,  9.9618e-02,  2.1755e-02,  7.6096e-02,  7.0819e-02,\n          1.5517e-01, -1.4867e-01, -5.0533e-02,  2.6684e-02,  5.3970e-02,\n          1.4716e-01, -1.1579e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0507,  0.0842,  0.0336,  0.0189, -0.1570,  0.1278,  0.0342,  0.1465],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2123,  0.1917,  0.0713,  0.1540,  0.1592, -0.0961,  0.1567, -0.1546,\n          0.1499,  0.1429, -0.1343, -0.1748,  0.1005,  0.2411,  0.1721, -0.0400],\n        [-0.1142,  0.1754, -0.1374,  0.0179, -0.0318, -0.1839, -0.0304,  0.2011,\n         -0.0654, -0.1591,  0.1414, -0.2171,  0.1469,  0.1459, -0.0230,  0.0675],\n        [ 0.0111, -0.0615,  0.0099, -0.0768, -0.1641,  0.0298,  0.2344, -0.1460,\n          0.2450,  0.0707,  0.2284,  0.0516, -0.1448, -0.2483,  0.1982,  0.0362],\n        [ 0.0798,  0.1150, -0.0709,  0.2176, -0.1449, -0.0064,  0.0708,  0.1165,\n          0.0504, -0.0402, -0.0521,  0.2332,  0.2000,  0.0784, -0.0394, -0.1925],\n        [ 0.0598,  0.0524, -0.0752, -0.0930,  0.1182,  0.0268, -0.2458,  0.1510,\n         -0.1498,  0.0150,  0.0966,  0.0974, -0.0204, -0.2149, -0.0760,  0.1268],\n        [ 0.1145,  0.2066, -0.2017, -0.0467, -0.2447,  0.2263, -0.0463, -0.0788,\n          0.0458,  0.0478, -0.1994,  0.2102, -0.0611,  0.1907, -0.2297,  0.0424],\n        [ 0.1279,  0.2371,  0.0583,  0.0510, -0.1986, -0.0489,  0.0420,  0.0185,\n          0.2164, -0.0203, -0.0830,  0.0586, -0.0791, -0.1419,  0.0205, -0.2397],\n        [-0.0573, -0.1298,  0.1306, -0.0824, -0.0835,  0.2318,  0.2102, -0.0100,\n          0.1199,  0.1435,  0.1986, -0.1799, -0.0559, -0.2057, -0.0403, -0.2081]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3036,  0.0832,  0.1223,  0.2030], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3403,  0.1656,  0.3478,  0.0785, -0.2239,  0.1494, -0.1633,  0.0020],\n        [ 0.0208, -0.2549,  0.2553, -0.3018,  0.2692, -0.2650, -0.3209, -0.2570],\n        [ 0.2647,  0.1662,  0.0879,  0.3017, -0.3008,  0.0699,  0.2856,  0.0893],\n        [-0.1235,  0.1295,  0.0514, -0.0925, -0.3508, -0.1495,  0.1368, -0.0093]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x747e0be0e350>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s244230000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s244230000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}