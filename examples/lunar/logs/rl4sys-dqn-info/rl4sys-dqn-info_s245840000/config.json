{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	64,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s245840000"
    },
    "q_lr":	0.001,
    "seed":	245840000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000001D9A45890F0>":	{
            "_act_dim":	1,
            "_batch_size":	64,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3058,  0.0554, -0.2068,  0.3061, -0.0344,  0.3136,  0.1441, -0.0479,\n        -0.3222, -0.1405, -0.2498, -0.2973, -0.1631, -0.3065, -0.1078, -0.0820,\n         0.3346, -0.1098, -0.1371,  0.1389, -0.1484, -0.0816, -0.1888,  0.1408,\n        -0.1755, -0.0560,  0.0033,  0.1080,  0.1691,  0.1362, -0.0490, -0.3186],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1956, -0.1658,  0.1864,  0.1793, -0.3326,  0.1591, -0.2520, -0.2868],\n        [ 0.0396,  0.1887, -0.1032,  0.0892,  0.0358, -0.2076, -0.0130, -0.0927],\n        [ 0.0936, -0.2045, -0.2353, -0.2541, -0.1004,  0.3045,  0.2264, -0.3533],\n        [-0.2336, -0.0580,  0.1961, -0.0632, -0.1486, -0.3067,  0.3288,  0.2718],\n        [-0.2811,  0.0783,  0.3340,  0.3251,  0.2386,  0.2398,  0.1805, -0.2836],\n        [ 0.3102,  0.0596,  0.0684, -0.2080,  0.0093, -0.2273,  0.1868,  0.1867],\n        [ 0.2737,  0.2881, -0.2434, -0.0797, -0.1697,  0.3401, -0.3333, -0.0923],\n        [-0.2275, -0.2311, -0.1008,  0.0705,  0.1972, -0.1180, -0.0422, -0.3332],\n        [-0.0984, -0.2614, -0.0257, -0.1290,  0.0456, -0.0349, -0.2684,  0.0461],\n        [ 0.0802,  0.2080, -0.3287,  0.2524,  0.2702, -0.2221, -0.0880,  0.2571],\n        [ 0.1635, -0.2187, -0.1329,  0.1435, -0.2815,  0.0947, -0.1445, -0.0532],\n        [-0.2175,  0.1815, -0.0539,  0.1083,  0.2934, -0.1706, -0.2639, -0.2956],\n        [-0.2668, -0.0410,  0.0195,  0.2888, -0.3096,  0.0140,  0.0834, -0.0656],\n        [-0.2700,  0.3019, -0.2865, -0.2057,  0.3008, -0.2506, -0.1569, -0.1725],\n        [ 0.1339, -0.0332,  0.0754,  0.0068,  0.2256,  0.2317,  0.2627, -0.1841],\n        [ 0.2631,  0.1664, -0.1322, -0.3227, -0.2268, -0.2032,  0.0510,  0.0604],\n        [ 0.1352,  0.1552,  0.2160, -0.3219, -0.1134,  0.1351,  0.0415,  0.1093],\n        [-0.0672,  0.1861, -0.1387,  0.2909, -0.0933, -0.0077,  0.1311,  0.2690],\n        [-0.1108, -0.2348, -0.0069,  0.2632, -0.2391,  0.1738, -0.1159,  0.0823],\n        [-0.0937,  0.2017,  0.2373, -0.0752,  0.0357,  0.2300, -0.0691,  0.3335],\n        [ 0.1510, -0.0577,  0.1557, -0.1041,  0.0759, -0.3387,  0.0498,  0.3377],\n        [ 0.0921,  0.0396, -0.2466,  0.3047,  0.1393, -0.1272, -0.3397, -0.3174],\n        [ 0.2655,  0.0997,  0.1367,  0.1649,  0.3243, -0.1153,  0.1242,  0.0531],\n        [-0.0420, -0.3443, -0.2651,  0.0417, -0.2119,  0.0148, -0.2891,  0.0744],\n        [-0.3432, -0.0440,  0.1733, -0.1697,  0.0436, -0.1360,  0.0877, -0.0898],\n        [-0.2228,  0.2082,  0.2677,  0.2519, -0.2990,  0.3499, -0.1075,  0.2890],\n        [-0.1339,  0.1654, -0.1968, -0.1216, -0.0281, -0.0672, -0.1833, -0.2797],\n        [ 0.1816,  0.3046,  0.0028,  0.1552,  0.2280,  0.0086,  0.2928,  0.2270],\n        [-0.1948,  0.0906, -0.3403, -0.0771,  0.2888, -0.2178,  0.1942, -0.2076],\n        [-0.0428,  0.1846, -0.1628, -0.3066,  0.1795, -0.0165, -0.2802, -0.1513],\n        [ 0.0483,  0.2163, -0.2648, -0.0327,  0.3180,  0.2020,  0.0710, -0.1428],\n        [-0.1589, -0.1511,  0.1506, -0.1766, -0.2961,  0.0514, -0.0638, -0.1651]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1505,  0.0516, -0.1181,  0.0630,  0.1730, -0.0055, -0.1271, -0.0186,\n         0.0050,  0.0735, -0.0474, -0.0467, -0.1694, -0.0644, -0.0817, -0.0172],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.2501e-02, -1.8048e-02,  8.3166e-02, -1.7358e-01,  9.4757e-02,\n         -1.6897e-01,  1.4602e-01,  6.4127e-02, -1.4407e-01,  9.2666e-02,\n          1.3082e-01, -3.7740e-02,  1.1141e-01,  1.2629e-01,  1.3407e-01,\n         -1.2888e-01, -1.4000e-01, -1.1684e-01,  1.5183e-01,  1.5101e-01,\n         -6.3874e-02, -1.3807e-01, -1.9808e-02, -1.2419e-01, -9.8557e-02,\n          8.7129e-03,  7.4725e-02,  1.2417e-01, -9.3017e-02,  1.0224e-01,\n          1.2211e-01,  1.7324e-01],\n        [ 9.4254e-02, -1.6228e-01, -1.6429e-01, -5.8071e-02,  7.1886e-02,\n          1.4970e-01, -9.8263e-02,  6.8232e-03, -1.9561e-02,  1.5865e-01,\n          9.4103e-02, -7.7967e-02, -3.7527e-02,  1.5964e-01, -8.5563e-02,\n         -2.7928e-02,  8.6052e-02,  1.7278e-01,  9.7405e-02,  1.8910e-03,\n          1.3585e-01,  2.5681e-02,  1.1648e-01,  1.1335e-01,  1.0051e-01,\n         -4.1354e-02, -9.6981e-02,  1.1657e-01,  1.1672e-01,  1.7571e-01,\n          1.5103e-01,  9.8083e-02],\n        [ 5.0723e-02,  1.6952e-02, -7.9563e-02, -1.3318e-01,  1.3263e-01,\n         -9.2771e-02,  1.0717e-02, -6.2595e-02, -1.6432e-01, -6.2780e-02,\n         -1.6413e-01, -1.2683e-01,  5.1955e-02, -1.4368e-01, -9.8340e-02,\n         -3.2108e-02,  9.2722e-02,  1.5661e-01, -1.0126e-01, -1.4831e-01,\n          3.1983e-02,  8.1083e-02, -4.8202e-02,  1.4884e-01, -1.5982e-01,\n         -2.2612e-02, -8.8964e-02, -6.4762e-02,  1.1386e-01, -1.7494e-01,\n         -7.7488e-03,  1.5972e-01],\n        [-8.3750e-02, -1.4830e-01,  2.0324e-03,  6.6230e-02,  1.3623e-01,\n         -1.1181e-01,  1.0895e-01, -4.2350e-02, -1.6057e-01,  1.9040e-02,\n          7.7180e-02,  2.8587e-02,  1.2050e-01,  1.3814e-01,  1.0588e-01,\n          3.3237e-02,  1.5220e-01,  5.0551e-02,  6.3577e-02,  2.3835e-02,\n          1.0611e-01, -9.7262e-02,  1.5889e-01, -1.2718e-01,  1.6642e-01,\n          5.4848e-02, -5.6232e-02,  2.2396e-02,  4.7377e-02, -1.4079e-01,\n          1.1372e-01, -1.1911e-01],\n        [ 1.2173e-01, -6.2409e-02, -1.3372e-01, -1.2882e-01,  1.1375e-01,\n         -1.1011e-01, -7.4386e-03,  1.6264e-01, -1.1022e-01, -1.0359e-02,\n          1.2879e-01,  5.7101e-02, -9.2692e-02,  1.2094e-01, -3.6253e-02,\n          1.4957e-01,  1.2636e-01, -1.1498e-01,  1.6815e-01,  1.0544e-02,\n          1.6328e-01,  1.4027e-01,  3.8344e-02,  4.5703e-02, -8.2471e-02,\n         -1.5238e-01, -6.1425e-02,  1.4222e-01, -1.0910e-01,  1.0608e-01,\n          4.1708e-02, -3.4914e-02],\n        [ 1.4728e-01,  2.6303e-03,  1.2303e-01, -5.1156e-02, -7.0620e-03,\n          5.8047e-02,  1.6611e-01, -1.0263e-01,  1.2990e-01, -9.6927e-02,\n          1.1437e-01, -4.0204e-02,  6.2818e-02,  1.5092e-01,  1.1252e-01,\n          3.6493e-02,  5.1304e-02, -4.7648e-02,  4.2410e-02, -7.3696e-02,\n         -7.6509e-02, -1.1538e-01, -2.9098e-02,  4.0643e-02, -1.4624e-01,\n         -7.6048e-02, -1.6210e-01, -1.3775e-01, -1.0604e-01, -1.3221e-02,\n         -1.4379e-01,  5.2948e-02],\n        [-8.5987e-02,  9.3846e-04, -6.0739e-02,  1.5663e-01, -1.4127e-01,\n          9.3260e-02, -1.2396e-01,  5.7937e-03,  1.2218e-02, -1.3784e-01,\n         -1.7467e-01, -1.0487e-02, -1.5023e-01, -8.8880e-02, -1.4857e-01,\n          2.8482e-02,  1.5676e-01,  2.4633e-02,  1.6531e-01, -5.2915e-02,\n          1.0190e-01,  6.5892e-02,  4.4754e-02,  3.1964e-02,  4.5145e-02,\n         -1.7628e-01, -1.3144e-01,  1.9007e-02, -1.5650e-01, -1.1581e-01,\n         -9.5629e-02,  1.0284e-01],\n        [ 6.7232e-02,  3.3684e-02, -5.4194e-02,  1.3032e-01, -6.6798e-02,\n         -1.3662e-02,  4.2741e-02,  9.1228e-03,  1.3410e-01,  7.8278e-02,\n         -1.0213e-01,  2.4148e-02,  8.5314e-02,  1.2922e-01, -4.5228e-02,\n         -1.7143e-01,  5.8605e-02, -2.0389e-02,  1.7064e-02, -1.5514e-01,\n          6.8513e-03,  6.8571e-02,  9.0048e-02,  6.9560e-03, -1.1023e-01,\n         -1.2842e-01,  1.8502e-02, -1.3414e-02, -3.7814e-03, -6.2268e-02,\n          2.1661e-02, -8.1782e-03],\n        [-1.6857e-01,  1.0268e-01, -4.9764e-02,  3.4791e-02,  8.7950e-03,\n          1.6546e-01,  1.1647e-01, -1.5589e-01, -2.8913e-02, -9.9172e-02,\n          1.4080e-01, -1.0333e-01,  1.0923e-01, -5.0863e-02, -1.0281e-01,\n         -1.6214e-01,  5.7858e-02, -6.9888e-02, -1.7193e-01, -1.3795e-01,\n          1.5920e-01,  1.2623e-01,  9.9627e-02,  1.6895e-01,  4.7113e-02,\n         -1.6701e-02,  8.0275e-02, -4.5730e-02,  1.4273e-01,  1.2545e-01,\n          1.5493e-02,  1.3733e-01],\n        [-3.8337e-02, -9.3012e-02,  5.5535e-02,  9.2746e-02,  2.3003e-02,\n         -5.2752e-02, -4.7189e-02, -9.1802e-02, -4.6254e-02, -2.6525e-02,\n         -1.5993e-01,  6.9166e-02, -1.3650e-01,  9.9956e-02,  1.5110e-01,\n         -5.1177e-02, -1.6631e-01,  5.7013e-02, -4.8258e-02,  6.4459e-02,\n          1.4076e-03, -5.6471e-02, -5.8209e-02, -1.3693e-01,  1.6965e-01,\n         -1.2137e-01, -9.8607e-03, -8.9051e-02,  1.3051e-02, -3.7486e-02,\n          1.6310e-01,  7.1565e-02],\n        [ 1.4938e-01, -1.1514e-01,  1.5456e-01, -2.4036e-02, -1.0717e-01,\n          1.1607e-01, -1.4318e-01,  1.1860e-01, -6.5670e-02,  1.2899e-01,\n         -7.0956e-02, -6.4469e-02, -1.2732e-01,  9.4409e-02,  6.2639e-02,\n         -5.7758e-03,  9.8442e-02,  1.4397e-01,  1.5622e-01,  3.1640e-02,\n          1.7644e-01,  1.2789e-01,  7.9220e-02, -7.6027e-02,  1.6056e-01,\n         -9.3289e-02, -1.7508e-01, -1.5007e-02, -1.1377e-01, -8.1286e-02,\n         -4.7480e-02, -1.3717e-01],\n        [-1.0352e-02, -1.1399e-01,  8.0856e-02,  4.7366e-02, -1.1791e-01,\n         -1.6031e-04, -7.0107e-02,  1.3704e-01,  3.0848e-02,  1.5811e-01,\n          1.3743e-02,  6.6056e-02, -3.9197e-02, -2.6581e-02,  9.1596e-02,\n          1.3130e-01, -2.4251e-02,  1.3162e-01,  1.2629e-02, -1.3846e-01,\n         -1.0192e-01, -1.2399e-01, -8.0952e-02, -1.2592e-01, -1.7216e-01,\n          1.5285e-01,  1.1261e-01, -1.5480e-02, -1.7012e-01, -1.3822e-01,\n          1.2831e-01,  1.0096e-01],\n        [ 3.6089e-02, -1.4988e-01, -9.3525e-02,  4.3984e-02,  1.4503e-01,\n          1.6468e-01,  9.6380e-02, -7.2229e-02,  1.1882e-01,  1.7460e-02,\n         -1.7606e-01, -3.9051e-02, -1.3199e-01,  1.3397e-02, -1.0447e-01,\n          1.1399e-01, -2.8496e-02, -1.3902e-01,  4.2347e-02,  1.6445e-01,\n         -1.1032e-01, -1.2021e-01, -1.2702e-01,  7.7600e-02,  1.0829e-01,\n         -4.1161e-02,  1.2068e-01, -4.8764e-02,  8.5329e-02, -4.0626e-02,\n         -9.1823e-02, -3.2422e-03],\n        [-7.2141e-02, -1.2440e-01, -6.7941e-03,  7.5768e-02, -1.1468e-01,\n         -1.6293e-01, -1.0948e-01, -2.9286e-02,  9.2291e-02,  5.4259e-02,\n         -1.6660e-01,  8.8096e-02,  1.4748e-01,  1.0203e-01, -1.7375e-01,\n         -1.1319e-01,  6.9732e-02, -4.9829e-02,  1.4090e-03,  1.1115e-01,\n          7.4060e-02, -1.4120e-01,  2.3965e-02,  6.1398e-02, -1.6691e-01,\n         -6.7462e-02, -1.4393e-01, -1.4558e-01,  1.0488e-01, -1.2713e-01,\n          1.4469e-01, -7.2483e-02],\n        [-7.7129e-02, -1.1504e-01, -7.1862e-02,  4.6039e-02,  2.6730e-02,\n         -6.4251e-02,  5.9385e-02, -2.6487e-02, -7.1071e-02,  8.7366e-02,\n          2.2046e-03,  8.4226e-02,  1.4409e-02,  2.8144e-02,  1.6818e-03,\n          7.2972e-02,  7.2292e-02,  8.6016e-02, -1.5649e-01,  7.4781e-02,\n         -5.4985e-02, -2.5039e-03, -5.5787e-03,  7.0135e-02,  4.7020e-03,\n         -1.2893e-01, -1.4607e-01, -1.1153e-01, -1.5937e-01,  1.6331e-01,\n         -9.1461e-02,  1.4111e-01],\n        [ 5.7349e-02,  8.7711e-02,  2.4170e-02,  1.4866e-01, -3.3320e-02,\n         -4.1384e-02, -5.2319e-02,  2.1190e-03, -3.6134e-02, -1.2448e-01,\n         -1.3650e-01, -4.4773e-02,  1.4889e-01, -1.1497e-01,  1.5531e-01,\n         -4.8103e-02, -1.0607e-02,  1.6015e-02,  4.1467e-02, -1.5759e-01,\n          1.3084e-01, -7.9114e-02,  1.6698e-01,  2.5947e-03,  5.7054e-02,\n         -1.1406e-01, -1.7716e-02,  1.2111e-01,  1.1868e-01, -1.4618e-01,\n          1.1953e-01,  1.0258e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2291,  0.1948,  0.1546, -0.0397,  0.1640, -0.1873,  0.0246,  0.2486],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0460, -0.1147,  0.0559,  0.1648,  0.1363, -0.1191,  0.0809,  0.2229,\n          0.1921,  0.0167,  0.1153,  0.1590,  0.0386,  0.1259, -0.0228,  0.1313],\n        [ 0.1808,  0.2102, -0.1917,  0.0794, -0.0933, -0.0256,  0.1961, -0.0900,\n         -0.1458,  0.1184,  0.1906, -0.1968,  0.0352,  0.1846, -0.1013, -0.2184],\n        [-0.0391, -0.1616, -0.2321,  0.0538,  0.0536,  0.1154,  0.0836, -0.1494,\n          0.0949, -0.0294,  0.0677, -0.2467,  0.1873,  0.1625,  0.0381, -0.1435],\n        [-0.2118, -0.0231, -0.0328, -0.1593, -0.2077,  0.1046,  0.1077, -0.1304,\n          0.2359, -0.1922, -0.1366,  0.0480, -0.1072, -0.0419, -0.0938,  0.0170],\n        [-0.0892, -0.2347,  0.2459,  0.0261, -0.0859, -0.1661,  0.1350,  0.2224,\n          0.1349, -0.1925,  0.1665,  0.0129, -0.1278, -0.1524,  0.1344,  0.1608],\n        [ 0.0992, -0.0260,  0.1430,  0.2377,  0.1661,  0.1995, -0.1184,  0.1628,\n         -0.2231,  0.1948,  0.2473, -0.1324,  0.1898,  0.2062,  0.1037, -0.0411],\n        [-0.2197, -0.1656,  0.2404, -0.2230, -0.0896, -0.2291,  0.2194, -0.1685,\n         -0.1401, -0.1935,  0.0070, -0.1093, -0.0066,  0.0615,  0.1586, -0.1995],\n        [ 0.1910,  0.1993, -0.1078,  0.0538,  0.1504, -0.1306, -0.1859,  0.0210,\n          0.2077, -0.1224,  0.1144, -0.1469,  0.1603,  0.2425,  0.1490, -0.1366]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2080], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3128,  0.0284,  0.3385, -0.3510,  0.1778,  0.1603,  0.3242, -0.1642]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.001,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.001,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1956, -0.1658,  0.1864,  0.1793, -0.3326,  0.1591, -0.2520, -0.2868],\n        [ 0.0396,  0.1887, -0.1032,  0.0892,  0.0358, -0.2076, -0.0130, -0.0927],\n        [ 0.0936, -0.2045, -0.2353, -0.2541, -0.1004,  0.3045,  0.2264, -0.3533],\n        [-0.2336, -0.0580,  0.1961, -0.0632, -0.1486, -0.3067,  0.3288,  0.2718],\n        [-0.2811,  0.0783,  0.3340,  0.3251,  0.2386,  0.2398,  0.1805, -0.2836],\n        [ 0.3102,  0.0596,  0.0684, -0.2080,  0.0093, -0.2273,  0.1868,  0.1867],\n        [ 0.2737,  0.2881, -0.2434, -0.0797, -0.1697,  0.3401, -0.3333, -0.0923],\n        [-0.2275, -0.2311, -0.1008,  0.0705,  0.1972, -0.1180, -0.0422, -0.3332],\n        [-0.0984, -0.2614, -0.0257, -0.1290,  0.0456, -0.0349, -0.2684,  0.0461],\n        [ 0.0802,  0.2080, -0.3287,  0.2524,  0.2702, -0.2221, -0.0880,  0.2571],\n        [ 0.1635, -0.2187, -0.1329,  0.1435, -0.2815,  0.0947, -0.1445, -0.0532],\n        [-0.2175,  0.1815, -0.0539,  0.1083,  0.2934, -0.1706, -0.2639, -0.2956],\n        [-0.2668, -0.0410,  0.0195,  0.2888, -0.3096,  0.0140,  0.0834, -0.0656],\n        [-0.2700,  0.3019, -0.2865, -0.2057,  0.3008, -0.2506, -0.1569, -0.1725],\n        [ 0.1339, -0.0332,  0.0754,  0.0068,  0.2256,  0.2317,  0.2627, -0.1841],\n        [ 0.2631,  0.1664, -0.1322, -0.3227, -0.2268, -0.2032,  0.0510,  0.0604],\n        [ 0.1352,  0.1552,  0.2160, -0.3219, -0.1134,  0.1351,  0.0415,  0.1093],\n        [-0.0672,  0.1861, -0.1387,  0.2909, -0.0933, -0.0077,  0.1311,  0.2690],\n        [-0.1108, -0.2348, -0.0069,  0.2632, -0.2391,  0.1738, -0.1159,  0.0823],\n        [-0.0937,  0.2017,  0.2373, -0.0752,  0.0357,  0.2300, -0.0691,  0.3335],\n        [ 0.1510, -0.0577,  0.1557, -0.1041,  0.0759, -0.3387,  0.0498,  0.3377],\n        [ 0.0921,  0.0396, -0.2466,  0.3047,  0.1393, -0.1272, -0.3397, -0.3174],\n        [ 0.2655,  0.0997,  0.1367,  0.1649,  0.3243, -0.1153,  0.1242,  0.0531],\n        [-0.0420, -0.3443, -0.2651,  0.0417, -0.2119,  0.0148, -0.2891,  0.0744],\n        [-0.3432, -0.0440,  0.1733, -0.1697,  0.0436, -0.1360,  0.0877, -0.0898],\n        [-0.2228,  0.2082,  0.2677,  0.2519, -0.2990,  0.3499, -0.1075,  0.2890],\n        [-0.1339,  0.1654, -0.1968, -0.1216, -0.0281, -0.0672, -0.1833, -0.2797],\n        [ 0.1816,  0.3046,  0.0028,  0.1552,  0.2280,  0.0086,  0.2928,  0.2270],\n        [-0.1948,  0.0906, -0.3403, -0.0771,  0.2888, -0.2178,  0.1942, -0.2076],\n        [-0.0428,  0.1846, -0.1628, -0.3066,  0.1795, -0.0165, -0.2802, -0.1513],\n        [ 0.0483,  0.2163, -0.2648, -0.0327,  0.3180,  0.2020,  0.0710, -0.1428],\n        [-0.1589, -0.1511,  0.1506, -0.1766, -0.2961,  0.0514, -0.0638, -0.1651]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.3058,  0.0554, -0.2068,  0.3061, -0.0344,  0.3136,  0.1441, -0.0479,\n        -0.3222, -0.1405, -0.2498, -0.2973, -0.1631, -0.3065, -0.1078, -0.0820,\n         0.3346, -0.1098, -0.1371,  0.1389, -0.1484, -0.0816, -0.1888,  0.1408,\n        -0.1755, -0.0560,  0.0033,  0.1080,  0.1691,  0.1362, -0.0490, -0.3186],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.2501e-02, -1.8048e-02,  8.3166e-02, -1.7358e-01,  9.4757e-02,\n         -1.6897e-01,  1.4602e-01,  6.4127e-02, -1.4407e-01,  9.2666e-02,\n          1.3082e-01, -3.7740e-02,  1.1141e-01,  1.2629e-01,  1.3407e-01,\n         -1.2888e-01, -1.4000e-01, -1.1684e-01,  1.5183e-01,  1.5101e-01,\n         -6.3874e-02, -1.3807e-01, -1.9808e-02, -1.2419e-01, -9.8557e-02,\n          8.7129e-03,  7.4725e-02,  1.2417e-01, -9.3017e-02,  1.0224e-01,\n          1.2211e-01,  1.7324e-01],\n        [ 9.4254e-02, -1.6228e-01, -1.6429e-01, -5.8071e-02,  7.1886e-02,\n          1.4970e-01, -9.8263e-02,  6.8232e-03, -1.9561e-02,  1.5865e-01,\n          9.4103e-02, -7.7967e-02, -3.7527e-02,  1.5964e-01, -8.5563e-02,\n         -2.7928e-02,  8.6052e-02,  1.7278e-01,  9.7405e-02,  1.8910e-03,\n          1.3585e-01,  2.5681e-02,  1.1648e-01,  1.1335e-01,  1.0051e-01,\n         -4.1354e-02, -9.6981e-02,  1.1657e-01,  1.1672e-01,  1.7571e-01,\n          1.5103e-01,  9.8083e-02],\n        [ 5.0723e-02,  1.6952e-02, -7.9563e-02, -1.3318e-01,  1.3263e-01,\n         -9.2771e-02,  1.0717e-02, -6.2595e-02, -1.6432e-01, -6.2780e-02,\n         -1.6413e-01, -1.2683e-01,  5.1955e-02, -1.4368e-01, -9.8340e-02,\n         -3.2108e-02,  9.2722e-02,  1.5661e-01, -1.0126e-01, -1.4831e-01,\n          3.1983e-02,  8.1083e-02, -4.8202e-02,  1.4884e-01, -1.5982e-01,\n         -2.2612e-02, -8.8964e-02, -6.4762e-02,  1.1386e-01, -1.7494e-01,\n         -7.7488e-03,  1.5972e-01],\n        [-8.3750e-02, -1.4830e-01,  2.0324e-03,  6.6230e-02,  1.3623e-01,\n         -1.1181e-01,  1.0895e-01, -4.2350e-02, -1.6057e-01,  1.9040e-02,\n          7.7180e-02,  2.8587e-02,  1.2050e-01,  1.3814e-01,  1.0588e-01,\n          3.3237e-02,  1.5220e-01,  5.0551e-02,  6.3577e-02,  2.3835e-02,\n          1.0611e-01, -9.7262e-02,  1.5889e-01, -1.2718e-01,  1.6642e-01,\n          5.4848e-02, -5.6232e-02,  2.2396e-02,  4.7377e-02, -1.4079e-01,\n          1.1372e-01, -1.1911e-01],\n        [ 1.2173e-01, -6.2409e-02, -1.3372e-01, -1.2882e-01,  1.1375e-01,\n         -1.1011e-01, -7.4386e-03,  1.6264e-01, -1.1022e-01, -1.0359e-02,\n          1.2879e-01,  5.7101e-02, -9.2692e-02,  1.2094e-01, -3.6253e-02,\n          1.4957e-01,  1.2636e-01, -1.1498e-01,  1.6815e-01,  1.0544e-02,\n          1.6328e-01,  1.4027e-01,  3.8344e-02,  4.5703e-02, -8.2471e-02,\n         -1.5238e-01, -6.1425e-02,  1.4222e-01, -1.0910e-01,  1.0608e-01,\n          4.1708e-02, -3.4914e-02],\n        [ 1.4728e-01,  2.6303e-03,  1.2303e-01, -5.1156e-02, -7.0620e-03,\n          5.8047e-02,  1.6611e-01, -1.0263e-01,  1.2990e-01, -9.6927e-02,\n          1.1437e-01, -4.0204e-02,  6.2818e-02,  1.5092e-01,  1.1252e-01,\n          3.6493e-02,  5.1304e-02, -4.7648e-02,  4.2410e-02, -7.3696e-02,\n         -7.6509e-02, -1.1538e-01, -2.9098e-02,  4.0643e-02, -1.4624e-01,\n         -7.6048e-02, -1.6210e-01, -1.3775e-01, -1.0604e-01, -1.3221e-02,\n         -1.4379e-01,  5.2948e-02],\n        [-8.5987e-02,  9.3846e-04, -6.0739e-02,  1.5663e-01, -1.4127e-01,\n          9.3260e-02, -1.2396e-01,  5.7937e-03,  1.2218e-02, -1.3784e-01,\n         -1.7467e-01, -1.0487e-02, -1.5023e-01, -8.8880e-02, -1.4857e-01,\n          2.8482e-02,  1.5676e-01,  2.4633e-02,  1.6531e-01, -5.2915e-02,\n          1.0190e-01,  6.5892e-02,  4.4754e-02,  3.1964e-02,  4.5145e-02,\n         -1.7628e-01, -1.3144e-01,  1.9007e-02, -1.5650e-01, -1.1581e-01,\n         -9.5629e-02,  1.0284e-01],\n        [ 6.7232e-02,  3.3684e-02, -5.4194e-02,  1.3032e-01, -6.6798e-02,\n         -1.3662e-02,  4.2741e-02,  9.1228e-03,  1.3410e-01,  7.8278e-02,\n         -1.0213e-01,  2.4148e-02,  8.5314e-02,  1.2922e-01, -4.5228e-02,\n         -1.7143e-01,  5.8605e-02, -2.0389e-02,  1.7064e-02, -1.5514e-01,\n          6.8513e-03,  6.8571e-02,  9.0048e-02,  6.9560e-03, -1.1023e-01,\n         -1.2842e-01,  1.8502e-02, -1.3414e-02, -3.7814e-03, -6.2268e-02,\n          2.1661e-02, -8.1782e-03],\n        [-1.6857e-01,  1.0268e-01, -4.9764e-02,  3.4791e-02,  8.7950e-03,\n          1.6546e-01,  1.1647e-01, -1.5589e-01, -2.8913e-02, -9.9172e-02,\n          1.4080e-01, -1.0333e-01,  1.0923e-01, -5.0863e-02, -1.0281e-01,\n         -1.6214e-01,  5.7858e-02, -6.9888e-02, -1.7193e-01, -1.3795e-01,\n          1.5920e-01,  1.2623e-01,  9.9627e-02,  1.6895e-01,  4.7113e-02,\n         -1.6701e-02,  8.0275e-02, -4.5730e-02,  1.4273e-01,  1.2545e-01,\n          1.5493e-02,  1.3733e-01],\n        [-3.8337e-02, -9.3012e-02,  5.5535e-02,  9.2746e-02,  2.3003e-02,\n         -5.2752e-02, -4.7189e-02, -9.1802e-02, -4.6254e-02, -2.6525e-02,\n         -1.5993e-01,  6.9166e-02, -1.3650e-01,  9.9956e-02,  1.5110e-01,\n         -5.1177e-02, -1.6631e-01,  5.7013e-02, -4.8258e-02,  6.4459e-02,\n          1.4076e-03, -5.6471e-02, -5.8209e-02, -1.3693e-01,  1.6965e-01,\n         -1.2137e-01, -9.8607e-03, -8.9051e-02,  1.3051e-02, -3.7486e-02,\n          1.6310e-01,  7.1565e-02],\n        [ 1.4938e-01, -1.1514e-01,  1.5456e-01, -2.4036e-02, -1.0717e-01,\n          1.1607e-01, -1.4318e-01,  1.1860e-01, -6.5670e-02,  1.2899e-01,\n         -7.0956e-02, -6.4469e-02, -1.2732e-01,  9.4409e-02,  6.2639e-02,\n         -5.7758e-03,  9.8442e-02,  1.4397e-01,  1.5622e-01,  3.1640e-02,\n          1.7644e-01,  1.2789e-01,  7.9220e-02, -7.6027e-02,  1.6056e-01,\n         -9.3289e-02, -1.7508e-01, -1.5007e-02, -1.1377e-01, -8.1286e-02,\n         -4.7480e-02, -1.3717e-01],\n        [-1.0352e-02, -1.1399e-01,  8.0856e-02,  4.7366e-02, -1.1791e-01,\n         -1.6031e-04, -7.0107e-02,  1.3704e-01,  3.0848e-02,  1.5811e-01,\n          1.3743e-02,  6.6056e-02, -3.9197e-02, -2.6581e-02,  9.1596e-02,\n          1.3130e-01, -2.4251e-02,  1.3162e-01,  1.2629e-02, -1.3846e-01,\n         -1.0192e-01, -1.2399e-01, -8.0952e-02, -1.2592e-01, -1.7216e-01,\n          1.5285e-01,  1.1261e-01, -1.5480e-02, -1.7012e-01, -1.3822e-01,\n          1.2831e-01,  1.0096e-01],\n        [ 3.6089e-02, -1.4988e-01, -9.3525e-02,  4.3984e-02,  1.4503e-01,\n          1.6468e-01,  9.6380e-02, -7.2229e-02,  1.1882e-01,  1.7460e-02,\n         -1.7606e-01, -3.9051e-02, -1.3199e-01,  1.3397e-02, -1.0447e-01,\n          1.1399e-01, -2.8496e-02, -1.3902e-01,  4.2347e-02,  1.6445e-01,\n         -1.1032e-01, -1.2021e-01, -1.2702e-01,  7.7600e-02,  1.0829e-01,\n         -4.1161e-02,  1.2068e-01, -4.8764e-02,  8.5329e-02, -4.0626e-02,\n         -9.1823e-02, -3.2422e-03],\n        [-7.2141e-02, -1.2440e-01, -6.7941e-03,  7.5768e-02, -1.1468e-01,\n         -1.6293e-01, -1.0948e-01, -2.9286e-02,  9.2291e-02,  5.4259e-02,\n         -1.6660e-01,  8.8096e-02,  1.4748e-01,  1.0203e-01, -1.7375e-01,\n         -1.1319e-01,  6.9732e-02, -4.9829e-02,  1.4090e-03,  1.1115e-01,\n          7.4060e-02, -1.4120e-01,  2.3965e-02,  6.1398e-02, -1.6691e-01,\n         -6.7462e-02, -1.4393e-01, -1.4558e-01,  1.0488e-01, -1.2713e-01,\n          1.4469e-01, -7.2483e-02],\n        [-7.7129e-02, -1.1504e-01, -7.1862e-02,  4.6039e-02,  2.6730e-02,\n         -6.4251e-02,  5.9385e-02, -2.6487e-02, -7.1071e-02,  8.7366e-02,\n          2.2046e-03,  8.4226e-02,  1.4409e-02,  2.8144e-02,  1.6818e-03,\n          7.2972e-02,  7.2292e-02,  8.6016e-02, -1.5649e-01,  7.4781e-02,\n         -5.4985e-02, -2.5039e-03, -5.5787e-03,  7.0135e-02,  4.7020e-03,\n         -1.2893e-01, -1.4607e-01, -1.1153e-01, -1.5937e-01,  1.6331e-01,\n         -9.1461e-02,  1.4111e-01],\n        [ 5.7349e-02,  8.7711e-02,  2.4170e-02,  1.4866e-01, -3.3320e-02,\n         -4.1384e-02, -5.2319e-02,  2.1190e-03, -3.6134e-02, -1.2448e-01,\n         -1.3650e-01, -4.4773e-02,  1.4889e-01, -1.1497e-01,  1.5531e-01,\n         -4.8103e-02, -1.0607e-02,  1.6015e-02,  4.1467e-02, -1.5759e-01,\n          1.3084e-01, -7.9114e-02,  1.6698e-01,  2.5947e-03,  5.7054e-02,\n         -1.1406e-01, -1.7716e-02,  1.2111e-01,  1.1868e-01, -1.4618e-01,\n          1.1953e-01,  1.0258e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1505,  0.0516, -0.1181,  0.0630,  0.1730, -0.0055, -0.1271, -0.0186,\n         0.0050,  0.0735, -0.0474, -0.0467, -0.1694, -0.0644, -0.0817, -0.0172],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0460, -0.1147,  0.0559,  0.1648,  0.1363, -0.1191,  0.0809,  0.2229,\n          0.1921,  0.0167,  0.1153,  0.1590,  0.0386,  0.1259, -0.0228,  0.1313],\n        [ 0.1808,  0.2102, -0.1917,  0.0794, -0.0933, -0.0256,  0.1961, -0.0900,\n         -0.1458,  0.1184,  0.1906, -0.1968,  0.0352,  0.1846, -0.1013, -0.2184],\n        [-0.0391, -0.1616, -0.2321,  0.0538,  0.0536,  0.1154,  0.0836, -0.1494,\n          0.0949, -0.0294,  0.0677, -0.2467,  0.1873,  0.1625,  0.0381, -0.1435],\n        [-0.2118, -0.0231, -0.0328, -0.1593, -0.2077,  0.1046,  0.1077, -0.1304,\n          0.2359, -0.1922, -0.1366,  0.0480, -0.1072, -0.0419, -0.0938,  0.0170],\n        [-0.0892, -0.2347,  0.2459,  0.0261, -0.0859, -0.1661,  0.1350,  0.2224,\n          0.1349, -0.1925,  0.1665,  0.0129, -0.1278, -0.1524,  0.1344,  0.1608],\n        [ 0.0992, -0.0260,  0.1430,  0.2377,  0.1661,  0.1995, -0.1184,  0.1628,\n         -0.2231,  0.1948,  0.2473, -0.1324,  0.1898,  0.2062,  0.1037, -0.0411],\n        [-0.2197, -0.1656,  0.2404, -0.2230, -0.0896, -0.2291,  0.2194, -0.1685,\n         -0.1401, -0.1935,  0.0070, -0.1093, -0.0066,  0.0615,  0.1586, -0.1995],\n        [ 0.1910,  0.1993, -0.1078,  0.0538,  0.1504, -0.1306, -0.1859,  0.0210,\n          0.2077, -0.1224,  0.1144, -0.1469,  0.1603,  0.2425,  0.1490, -0.1366]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2291,  0.1948,  0.1546, -0.0397,  0.1640, -0.1873,  0.0246,  0.2486],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3128,  0.0284,  0.3385, -0.3510,  0.1778,  0.1603,  0.3242, -0.1642]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2080], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000001D9DC0362F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	1,
            "_train_update_freq":	1,
            "_traj_per_epoch":	64,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001D9A4588C40>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s245840000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s245840000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3058,  0.0554, -0.2068,  0.3061, -0.0344,  0.3136,  0.1441, -0.0479,\n        -0.3222, -0.1405, -0.2498, -0.2973, -0.1631, -0.3065, -0.1078, -0.0820,\n         0.3346, -0.1098, -0.1371,  0.1389, -0.1484, -0.0816, -0.1888,  0.1408,\n        -0.1755, -0.0560,  0.0033,  0.1080,  0.1691,  0.1362, -0.0490, -0.3186],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1956, -0.1658,  0.1864,  0.1793, -0.3326,  0.1591, -0.2520, -0.2868],\n        [ 0.0396,  0.1887, -0.1032,  0.0892,  0.0358, -0.2076, -0.0130, -0.0927],\n        [ 0.0936, -0.2045, -0.2353, -0.2541, -0.1004,  0.3045,  0.2264, -0.3533],\n        [-0.2336, -0.0580,  0.1961, -0.0632, -0.1486, -0.3067,  0.3288,  0.2718],\n        [-0.2811,  0.0783,  0.3340,  0.3251,  0.2386,  0.2398,  0.1805, -0.2836],\n        [ 0.3102,  0.0596,  0.0684, -0.2080,  0.0093, -0.2273,  0.1868,  0.1867],\n        [ 0.2737,  0.2881, -0.2434, -0.0797, -0.1697,  0.3401, -0.3333, -0.0923],\n        [-0.2275, -0.2311, -0.1008,  0.0705,  0.1972, -0.1180, -0.0422, -0.3332],\n        [-0.0984, -0.2614, -0.0257, -0.1290,  0.0456, -0.0349, -0.2684,  0.0461],\n        [ 0.0802,  0.2080, -0.3287,  0.2524,  0.2702, -0.2221, -0.0880,  0.2571],\n        [ 0.1635, -0.2187, -0.1329,  0.1435, -0.2815,  0.0947, -0.1445, -0.0532],\n        [-0.2175,  0.1815, -0.0539,  0.1083,  0.2934, -0.1706, -0.2639, -0.2956],\n        [-0.2668, -0.0410,  0.0195,  0.2888, -0.3096,  0.0140,  0.0834, -0.0656],\n        [-0.2700,  0.3019, -0.2865, -0.2057,  0.3008, -0.2506, -0.1569, -0.1725],\n        [ 0.1339, -0.0332,  0.0754,  0.0068,  0.2256,  0.2317,  0.2627, -0.1841],\n        [ 0.2631,  0.1664, -0.1322, -0.3227, -0.2268, -0.2032,  0.0510,  0.0604],\n        [ 0.1352,  0.1552,  0.2160, -0.3219, -0.1134,  0.1351,  0.0415,  0.1093],\n        [-0.0672,  0.1861, -0.1387,  0.2909, -0.0933, -0.0077,  0.1311,  0.2690],\n        [-0.1108, -0.2348, -0.0069,  0.2632, -0.2391,  0.1738, -0.1159,  0.0823],\n        [-0.0937,  0.2017,  0.2373, -0.0752,  0.0357,  0.2300, -0.0691,  0.3335],\n        [ 0.1510, -0.0577,  0.1557, -0.1041,  0.0759, -0.3387,  0.0498,  0.3377],\n        [ 0.0921,  0.0396, -0.2466,  0.3047,  0.1393, -0.1272, -0.3397, -0.3174],\n        [ 0.2655,  0.0997,  0.1367,  0.1649,  0.3243, -0.1153,  0.1242,  0.0531],\n        [-0.0420, -0.3443, -0.2651,  0.0417, -0.2119,  0.0148, -0.2891,  0.0744],\n        [-0.3432, -0.0440,  0.1733, -0.1697,  0.0436, -0.1360,  0.0877, -0.0898],\n        [-0.2228,  0.2082,  0.2677,  0.2519, -0.2990,  0.3499, -0.1075,  0.2890],\n        [-0.1339,  0.1654, -0.1968, -0.1216, -0.0281, -0.0672, -0.1833, -0.2797],\n        [ 0.1816,  0.3046,  0.0028,  0.1552,  0.2280,  0.0086,  0.2928,  0.2270],\n        [-0.1948,  0.0906, -0.3403, -0.0771,  0.2888, -0.2178,  0.1942, -0.2076],\n        [-0.0428,  0.1846, -0.1628, -0.3066,  0.1795, -0.0165, -0.2802, -0.1513],\n        [ 0.0483,  0.2163, -0.2648, -0.0327,  0.3180,  0.2020,  0.0710, -0.1428],\n        [-0.1589, -0.1511,  0.1506, -0.1766, -0.2961,  0.0514, -0.0638, -0.1651]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1505,  0.0516, -0.1181,  0.0630,  0.1730, -0.0055, -0.1271, -0.0186,\n         0.0050,  0.0735, -0.0474, -0.0467, -0.1694, -0.0644, -0.0817, -0.0172],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.2501e-02, -1.8048e-02,  8.3166e-02, -1.7358e-01,  9.4757e-02,\n         -1.6897e-01,  1.4602e-01,  6.4127e-02, -1.4407e-01,  9.2666e-02,\n          1.3082e-01, -3.7740e-02,  1.1141e-01,  1.2629e-01,  1.3407e-01,\n         -1.2888e-01, -1.4000e-01, -1.1684e-01,  1.5183e-01,  1.5101e-01,\n         -6.3874e-02, -1.3807e-01, -1.9808e-02, -1.2419e-01, -9.8557e-02,\n          8.7129e-03,  7.4725e-02,  1.2417e-01, -9.3017e-02,  1.0224e-01,\n          1.2211e-01,  1.7324e-01],\n        [ 9.4254e-02, -1.6228e-01, -1.6429e-01, -5.8071e-02,  7.1886e-02,\n          1.4970e-01, -9.8263e-02,  6.8232e-03, -1.9561e-02,  1.5865e-01,\n          9.4103e-02, -7.7967e-02, -3.7527e-02,  1.5964e-01, -8.5563e-02,\n         -2.7928e-02,  8.6052e-02,  1.7278e-01,  9.7405e-02,  1.8910e-03,\n          1.3585e-01,  2.5681e-02,  1.1648e-01,  1.1335e-01,  1.0051e-01,\n         -4.1354e-02, -9.6981e-02,  1.1657e-01,  1.1672e-01,  1.7571e-01,\n          1.5103e-01,  9.8083e-02],\n        [ 5.0723e-02,  1.6952e-02, -7.9563e-02, -1.3318e-01,  1.3263e-01,\n         -9.2771e-02,  1.0717e-02, -6.2595e-02, -1.6432e-01, -6.2780e-02,\n         -1.6413e-01, -1.2683e-01,  5.1955e-02, -1.4368e-01, -9.8340e-02,\n         -3.2108e-02,  9.2722e-02,  1.5661e-01, -1.0126e-01, -1.4831e-01,\n          3.1983e-02,  8.1083e-02, -4.8202e-02,  1.4884e-01, -1.5982e-01,\n         -2.2612e-02, -8.8964e-02, -6.4762e-02,  1.1386e-01, -1.7494e-01,\n         -7.7488e-03,  1.5972e-01],\n        [-8.3750e-02, -1.4830e-01,  2.0324e-03,  6.6230e-02,  1.3623e-01,\n         -1.1181e-01,  1.0895e-01, -4.2350e-02, -1.6057e-01,  1.9040e-02,\n          7.7180e-02,  2.8587e-02,  1.2050e-01,  1.3814e-01,  1.0588e-01,\n          3.3237e-02,  1.5220e-01,  5.0551e-02,  6.3577e-02,  2.3835e-02,\n          1.0611e-01, -9.7262e-02,  1.5889e-01, -1.2718e-01,  1.6642e-01,\n          5.4848e-02, -5.6232e-02,  2.2396e-02,  4.7377e-02, -1.4079e-01,\n          1.1372e-01, -1.1911e-01],\n        [ 1.2173e-01, -6.2409e-02, -1.3372e-01, -1.2882e-01,  1.1375e-01,\n         -1.1011e-01, -7.4386e-03,  1.6264e-01, -1.1022e-01, -1.0359e-02,\n          1.2879e-01,  5.7101e-02, -9.2692e-02,  1.2094e-01, -3.6253e-02,\n          1.4957e-01,  1.2636e-01, -1.1498e-01,  1.6815e-01,  1.0544e-02,\n          1.6328e-01,  1.4027e-01,  3.8344e-02,  4.5703e-02, -8.2471e-02,\n         -1.5238e-01, -6.1425e-02,  1.4222e-01, -1.0910e-01,  1.0608e-01,\n          4.1708e-02, -3.4914e-02],\n        [ 1.4728e-01,  2.6303e-03,  1.2303e-01, -5.1156e-02, -7.0620e-03,\n          5.8047e-02,  1.6611e-01, -1.0263e-01,  1.2990e-01, -9.6927e-02,\n          1.1437e-01, -4.0204e-02,  6.2818e-02,  1.5092e-01,  1.1252e-01,\n          3.6493e-02,  5.1304e-02, -4.7648e-02,  4.2410e-02, -7.3696e-02,\n         -7.6509e-02, -1.1538e-01, -2.9098e-02,  4.0643e-02, -1.4624e-01,\n         -7.6048e-02, -1.6210e-01, -1.3775e-01, -1.0604e-01, -1.3221e-02,\n         -1.4379e-01,  5.2948e-02],\n        [-8.5987e-02,  9.3846e-04, -6.0739e-02,  1.5663e-01, -1.4127e-01,\n          9.3260e-02, -1.2396e-01,  5.7937e-03,  1.2218e-02, -1.3784e-01,\n         -1.7467e-01, -1.0487e-02, -1.5023e-01, -8.8880e-02, -1.4857e-01,\n          2.8482e-02,  1.5676e-01,  2.4633e-02,  1.6531e-01, -5.2915e-02,\n          1.0190e-01,  6.5892e-02,  4.4754e-02,  3.1964e-02,  4.5145e-02,\n         -1.7628e-01, -1.3144e-01,  1.9007e-02, -1.5650e-01, -1.1581e-01,\n         -9.5629e-02,  1.0284e-01],\n        [ 6.7232e-02,  3.3684e-02, -5.4194e-02,  1.3032e-01, -6.6798e-02,\n         -1.3662e-02,  4.2741e-02,  9.1228e-03,  1.3410e-01,  7.8278e-02,\n         -1.0213e-01,  2.4148e-02,  8.5314e-02,  1.2922e-01, -4.5228e-02,\n         -1.7143e-01,  5.8605e-02, -2.0389e-02,  1.7064e-02, -1.5514e-01,\n          6.8513e-03,  6.8571e-02,  9.0048e-02,  6.9560e-03, -1.1023e-01,\n         -1.2842e-01,  1.8502e-02, -1.3414e-02, -3.7814e-03, -6.2268e-02,\n          2.1661e-02, -8.1782e-03],\n        [-1.6857e-01,  1.0268e-01, -4.9764e-02,  3.4791e-02,  8.7950e-03,\n          1.6546e-01,  1.1647e-01, -1.5589e-01, -2.8913e-02, -9.9172e-02,\n          1.4080e-01, -1.0333e-01,  1.0923e-01, -5.0863e-02, -1.0281e-01,\n         -1.6214e-01,  5.7858e-02, -6.9888e-02, -1.7193e-01, -1.3795e-01,\n          1.5920e-01,  1.2623e-01,  9.9627e-02,  1.6895e-01,  4.7113e-02,\n         -1.6701e-02,  8.0275e-02, -4.5730e-02,  1.4273e-01,  1.2545e-01,\n          1.5493e-02,  1.3733e-01],\n        [-3.8337e-02, -9.3012e-02,  5.5535e-02,  9.2746e-02,  2.3003e-02,\n         -5.2752e-02, -4.7189e-02, -9.1802e-02, -4.6254e-02, -2.6525e-02,\n         -1.5993e-01,  6.9166e-02, -1.3650e-01,  9.9956e-02,  1.5110e-01,\n         -5.1177e-02, -1.6631e-01,  5.7013e-02, -4.8258e-02,  6.4459e-02,\n          1.4076e-03, -5.6471e-02, -5.8209e-02, -1.3693e-01,  1.6965e-01,\n         -1.2137e-01, -9.8607e-03, -8.9051e-02,  1.3051e-02, -3.7486e-02,\n          1.6310e-01,  7.1565e-02],\n        [ 1.4938e-01, -1.1514e-01,  1.5456e-01, -2.4036e-02, -1.0717e-01,\n          1.1607e-01, -1.4318e-01,  1.1860e-01, -6.5670e-02,  1.2899e-01,\n         -7.0956e-02, -6.4469e-02, -1.2732e-01,  9.4409e-02,  6.2639e-02,\n         -5.7758e-03,  9.8442e-02,  1.4397e-01,  1.5622e-01,  3.1640e-02,\n          1.7644e-01,  1.2789e-01,  7.9220e-02, -7.6027e-02,  1.6056e-01,\n         -9.3289e-02, -1.7508e-01, -1.5007e-02, -1.1377e-01, -8.1286e-02,\n         -4.7480e-02, -1.3717e-01],\n        [-1.0352e-02, -1.1399e-01,  8.0856e-02,  4.7366e-02, -1.1791e-01,\n         -1.6031e-04, -7.0107e-02,  1.3704e-01,  3.0848e-02,  1.5811e-01,\n          1.3743e-02,  6.6056e-02, -3.9197e-02, -2.6581e-02,  9.1596e-02,\n          1.3130e-01, -2.4251e-02,  1.3162e-01,  1.2629e-02, -1.3846e-01,\n         -1.0192e-01, -1.2399e-01, -8.0952e-02, -1.2592e-01, -1.7216e-01,\n          1.5285e-01,  1.1261e-01, -1.5480e-02, -1.7012e-01, -1.3822e-01,\n          1.2831e-01,  1.0096e-01],\n        [ 3.6089e-02, -1.4988e-01, -9.3525e-02,  4.3984e-02,  1.4503e-01,\n          1.6468e-01,  9.6380e-02, -7.2229e-02,  1.1882e-01,  1.7460e-02,\n         -1.7606e-01, -3.9051e-02, -1.3199e-01,  1.3397e-02, -1.0447e-01,\n          1.1399e-01, -2.8496e-02, -1.3902e-01,  4.2347e-02,  1.6445e-01,\n         -1.1032e-01, -1.2021e-01, -1.2702e-01,  7.7600e-02,  1.0829e-01,\n         -4.1161e-02,  1.2068e-01, -4.8764e-02,  8.5329e-02, -4.0626e-02,\n         -9.1823e-02, -3.2422e-03],\n        [-7.2141e-02, -1.2440e-01, -6.7941e-03,  7.5768e-02, -1.1468e-01,\n         -1.6293e-01, -1.0948e-01, -2.9286e-02,  9.2291e-02,  5.4259e-02,\n         -1.6660e-01,  8.8096e-02,  1.4748e-01,  1.0203e-01, -1.7375e-01,\n         -1.1319e-01,  6.9732e-02, -4.9829e-02,  1.4090e-03,  1.1115e-01,\n          7.4060e-02, -1.4120e-01,  2.3965e-02,  6.1398e-02, -1.6691e-01,\n         -6.7462e-02, -1.4393e-01, -1.4558e-01,  1.0488e-01, -1.2713e-01,\n          1.4469e-01, -7.2483e-02],\n        [-7.7129e-02, -1.1504e-01, -7.1862e-02,  4.6039e-02,  2.6730e-02,\n         -6.4251e-02,  5.9385e-02, -2.6487e-02, -7.1071e-02,  8.7366e-02,\n          2.2046e-03,  8.4226e-02,  1.4409e-02,  2.8144e-02,  1.6818e-03,\n          7.2972e-02,  7.2292e-02,  8.6016e-02, -1.5649e-01,  7.4781e-02,\n         -5.4985e-02, -2.5039e-03, -5.5787e-03,  7.0135e-02,  4.7020e-03,\n         -1.2893e-01, -1.4607e-01, -1.1153e-01, -1.5937e-01,  1.6331e-01,\n         -9.1461e-02,  1.4111e-01],\n        [ 5.7349e-02,  8.7711e-02,  2.4170e-02,  1.4866e-01, -3.3320e-02,\n         -4.1384e-02, -5.2319e-02,  2.1190e-03, -3.6134e-02, -1.2448e-01,\n         -1.3650e-01, -4.4773e-02,  1.4889e-01, -1.1497e-01,  1.5531e-01,\n         -4.8103e-02, -1.0607e-02,  1.6015e-02,  4.1467e-02, -1.5759e-01,\n          1.3084e-01, -7.9114e-02,  1.6698e-01,  2.5947e-03,  5.7054e-02,\n         -1.1406e-01, -1.7716e-02,  1.2111e-01,  1.1868e-01, -1.4618e-01,\n          1.1953e-01,  1.0258e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2291,  0.1948,  0.1546, -0.0397,  0.1640, -0.1873,  0.0246,  0.2486],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0460, -0.1147,  0.0559,  0.1648,  0.1363, -0.1191,  0.0809,  0.2229,\n          0.1921,  0.0167,  0.1153,  0.1590,  0.0386,  0.1259, -0.0228,  0.1313],\n        [ 0.1808,  0.2102, -0.1917,  0.0794, -0.0933, -0.0256,  0.1961, -0.0900,\n         -0.1458,  0.1184,  0.1906, -0.1968,  0.0352,  0.1846, -0.1013, -0.2184],\n        [-0.0391, -0.1616, -0.2321,  0.0538,  0.0536,  0.1154,  0.0836, -0.1494,\n          0.0949, -0.0294,  0.0677, -0.2467,  0.1873,  0.1625,  0.0381, -0.1435],\n        [-0.2118, -0.0231, -0.0328, -0.1593, -0.2077,  0.1046,  0.1077, -0.1304,\n          0.2359, -0.1922, -0.1366,  0.0480, -0.1072, -0.0419, -0.0938,  0.0170],\n        [-0.0892, -0.2347,  0.2459,  0.0261, -0.0859, -0.1661,  0.1350,  0.2224,\n          0.1349, -0.1925,  0.1665,  0.0129, -0.1278, -0.1524,  0.1344,  0.1608],\n        [ 0.0992, -0.0260,  0.1430,  0.2377,  0.1661,  0.1995, -0.1184,  0.1628,\n         -0.2231,  0.1948,  0.2473, -0.1324,  0.1898,  0.2062,  0.1037, -0.0411],\n        [-0.2197, -0.1656,  0.2404, -0.2230, -0.0896, -0.2291,  0.2194, -0.1685,\n         -0.1401, -0.1935,  0.0070, -0.1093, -0.0066,  0.0615,  0.1586, -0.1995],\n        [ 0.1910,  0.1993, -0.1078,  0.0538,  0.1504, -0.1306, -0.1859,  0.0210,\n          0.2077, -0.1224,  0.1144, -0.1469,  0.1603,  0.2425,  0.1490, -0.1366]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2080], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3128,  0.0284,  0.3385, -0.3510,  0.1778,  0.1603,  0.3242, -0.1642]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	1,
    "train_update_freq":	1,
    "traj_per_epoch":	64
}