{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s252120000"
    },
    "q_lr":	0.0005,
    "seed":	252120000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x00000225CBB6D0F0>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-2.1370e-01, -4.0857e-02, -3.0807e-01, -6.6606e-02, -2.4722e-01,\n        -2.8131e-01,  3.1409e-01, -5.4927e-02, -4.7329e-02, -5.2070e-02,\n         7.8111e-02,  3.0087e-01, -2.4088e-01, -1.2620e-01, -2.8773e-01,\n        -1.5599e-01,  1.7437e-04, -1.8338e-01, -1.8208e-01, -1.2362e-01,\n         1.7848e-01, -1.5488e-01,  2.5717e-02, -1.8097e-01,  2.0951e-01,\n        -2.9519e-01, -1.2480e-01, -3.3812e-02,  1.3387e-01, -7.1756e-02,\n        -3.3910e-01,  1.5767e-01], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.8070e-01,  1.5971e-01, -3.3843e-03, -3.4869e-02, -1.8369e-01,\n          2.7807e-02, -3.1652e-01,  1.0715e-01],\n        [-2.3537e-01, -4.2065e-03,  1.0576e-01,  3.1712e-01, -8.3638e-02,\n         -2.1448e-02,  8.3392e-02, -1.3976e-01],\n        [ 1.4438e-01,  1.1531e-01, -1.7376e-01, -2.4421e-01,  2.5566e-01,\n         -2.1391e-01,  2.2767e-01,  2.7942e-01],\n        [ 1.8132e-01,  4.1517e-02, -1.2626e-02, -3.0549e-01, -6.3249e-02,\n         -1.9427e-01,  4.2091e-02, -9.1502e-02],\n        [ 1.9790e-01, -3.8022e-02,  2.8790e-01,  1.1893e-01, -5.8543e-03,\n         -2.4192e-01, -1.6068e-01, -3.2689e-01],\n        [ 9.3518e-02, -3.0357e-01, -5.7942e-02, -2.6760e-01, -1.1577e-01,\n         -2.2838e-01,  1.0072e-01, -2.0959e-01],\n        [-3.3283e-01,  2.3652e-03,  1.8765e-02,  9.5370e-03,  3.5013e-01,\n         -2.4319e-01, -2.6003e-01,  8.2456e-02],\n        [-3.4555e-01, -2.2240e-01, -2.2947e-01,  2.9708e-01, -3.2648e-01,\n          3.5230e-02,  1.6824e-01, -6.3602e-02],\n        [ 2.6191e-01,  2.6993e-01, -3.2251e-01, -1.5205e-01, -1.9175e-01,\n         -3.1217e-01,  4.2329e-03,  2.4564e-01],\n        [-1.1662e-01,  2.1957e-01, -3.3837e-01, -3.0861e-01, -2.2239e-01,\n         -2.4541e-01, -3.3623e-01,  3.1547e-01],\n        [-6.8505e-02,  1.6962e-01, -1.6628e-02,  2.8365e-01, -1.5328e-01,\n          1.2383e-01, -2.0726e-01, -7.7541e-02],\n        [ 2.1576e-01,  3.4532e-01, -2.9672e-01,  2.4113e-01, -2.4966e-01,\n          2.0948e-01, -3.3418e-02,  1.5991e-01],\n        [ 2.0504e-01,  1.1281e-01,  3.3759e-01,  2.0710e-01,  1.3114e-01,\n          1.0916e-01,  2.6391e-01,  2.1155e-01],\n        [ 1.6572e-01,  1.7806e-01,  1.0096e-02,  4.6098e-02, -1.4103e-01,\n          2.8034e-01,  3.4057e-01, -7.3458e-02],\n        [-1.3908e-01,  2.0430e-01, -1.3970e-01,  2.3123e-01, -2.5594e-01,\n          1.1712e-01,  2.2424e-01, -2.9372e-01],\n        [ 7.6455e-02, -2.9004e-01, -2.4110e-01,  3.9267e-02, -1.2602e-01,\n          2.6623e-01, -6.9499e-02,  1.9109e-01],\n        [ 3.4877e-01, -9.5452e-02, -2.8143e-01,  8.6384e-02,  2.5921e-01,\n         -1.6359e-01, -3.3975e-01,  3.4850e-01],\n        [ 3.0074e-01,  1.6167e-01,  2.5142e-03, -1.0399e-01, -3.6655e-02,\n         -2.4897e-01, -1.6618e-01,  2.6776e-01],\n        [-1.0990e-01,  1.1893e-01, -2.2585e-01, -2.6644e-01,  2.6376e-01,\n         -2.7362e-01,  3.1849e-01,  8.5503e-02],\n        [-3.0242e-02,  3.1902e-01,  2.2437e-01, -1.1007e-01, -2.8616e-01,\n         -2.5803e-01,  1.6862e-01, -2.2844e-01],\n        [ 3.6550e-02, -1.5074e-01,  8.0434e-02, -2.2438e-01, -3.0934e-01,\n         -9.6489e-02,  2.0906e-01, -7.9690e-02],\n        [-3.1311e-01, -8.2374e-02, -1.4471e-01,  2.2985e-01, -3.0188e-01,\n          2.9426e-01,  2.2802e-01, -3.1932e-01],\n        [-2.2918e-05,  1.7527e-01, -3.4068e-01, -2.8973e-01,  1.8004e-01,\n          2.7766e-01, -2.6097e-01, -2.1959e-01],\n        [ 6.3528e-02, -6.2347e-02,  1.6773e-01, -1.6832e-01, -5.9802e-02,\n         -3.1457e-01, -6.6205e-02, -3.3735e-01],\n        [ 2.1925e-01,  1.8044e-01, -3.4187e-02,  3.4951e-01,  2.3827e-01,\n          3.0205e-02, -2.4013e-01,  3.2206e-01],\n        [-1.1592e-01,  2.3986e-01,  1.3664e-01, -1.1455e-01, -1.6328e-01,\n          4.4461e-02, -2.1190e-01, -2.9543e-01],\n        [-9.7994e-02,  3.0622e-01, -2.4485e-01, -1.2911e-01,  9.7397e-02,\n         -3.0211e-01, -3.1424e-01,  4.0641e-02],\n        [-2.6362e-01, -1.9323e-01, -2.8514e-01,  1.6876e-02, -1.4840e-01,\n         -2.4806e-01, -3.2312e-01, -1.4544e-02],\n        [ 1.8492e-01, -2.8978e-01, -2.4938e-01, -3.4728e-01, -2.6038e-02,\n          9.0325e-02, -1.4075e-01, -8.9825e-02],\n        [-2.1966e-01,  4.3414e-02, -4.5534e-02, -2.0931e-01, -3.5261e-01,\n          2.3860e-01, -2.9235e-01, -4.6054e-02],\n        [-1.1135e-01, -3.3586e-01, -2.7732e-01,  5.8959e-02,  3.3477e-01,\n         -2.0174e-01, -3.4186e-01,  3.0353e-01],\n        [-2.7161e-01, -1.1532e-01, -7.3936e-02, -3.0929e-02,  1.4660e-01,\n          6.5352e-02, -3.0363e-01, -1.2116e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1217, -0.0569,  0.1117,  0.0822,  0.0319,  0.0183, -0.0007,  0.0978,\n        -0.0549,  0.1501,  0.0982, -0.0808, -0.1289, -0.0483,  0.0655,  0.1080],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.3192e-01, -5.3093e-02, -1.4398e-01,  6.1835e-02, -4.9249e-02,\n         -1.4357e-02, -1.5869e-01, -5.5070e-02,  1.1936e-01,  1.4624e-01,\n          5.4109e-02,  1.9763e-02,  1.2296e-01,  8.8789e-02,  6.9785e-02,\n         -1.4319e-01,  1.4333e-01,  1.5176e-01,  4.3371e-02, -8.3796e-02,\n          6.7476e-02, -1.1849e-01,  1.6988e-01, -9.3977e-02,  1.0247e-01,\n         -1.2197e-02, -2.9328e-02, -1.2001e-01,  5.1562e-03, -4.2576e-02,\n          1.5941e-02,  1.2822e-01],\n        [ 1.7172e-01,  8.5123e-02, -1.1807e-01, -1.5319e-01,  1.5900e-01,\n         -1.1533e-01,  2.8113e-02,  1.2861e-01,  1.0598e-01,  5.8625e-02,\n         -3.1744e-02,  2.0854e-02,  7.1638e-02,  2.3924e-02,  1.5461e-02,\n         -1.5304e-01, -2.4377e-02,  1.2192e-01,  4.5895e-03,  6.5655e-03,\n          1.0715e-01, -1.7259e-01, -7.9339e-02, -1.2967e-01, -9.0656e-03,\n         -1.1448e-01, -1.4485e-01, -3.6317e-02, -1.2488e-01,  1.5829e-01,\n         -3.1707e-02, -1.2185e-01],\n        [ 1.6012e-01,  1.1171e-04,  4.4795e-02, -1.1564e-01,  1.2528e-01,\n          1.2569e-01, -4.3859e-02,  6.9082e-02, -5.2222e-02,  1.2619e-01,\n         -7.9830e-02, -1.4628e-01, -4.5524e-02, -4.1791e-02, -1.4400e-02,\n          1.1145e-02, -2.4685e-02, -2.1246e-02,  7.6761e-02,  1.1820e-02,\n         -2.5674e-02, -5.3149e-02,  1.7253e-01,  1.5025e-02,  8.7489e-02,\n         -1.0390e-01,  1.3543e-01,  1.0991e-01, -4.3801e-02,  1.7370e-02,\n         -1.5775e-02,  1.3298e-01],\n        [-1.5746e-01, -1.5386e-01, -2.7902e-02, -4.8250e-02, -6.3915e-02,\n          8.2823e-02, -8.9257e-02,  4.2582e-02, -1.5372e-01, -1.1564e-01,\n          1.2276e-01,  1.1915e-01, -1.7423e-01, -8.3683e-02, -8.0057e-02,\n         -1.0121e-01,  9.6423e-02,  2.6460e-02,  1.0068e-01, -5.4422e-02,\n          6.9981e-02,  7.0990e-02,  9.7402e-03, -3.6256e-02,  1.1583e-02,\n         -7.3368e-02,  1.5407e-01,  5.3060e-02,  9.4515e-02, -5.4464e-02,\n          1.7508e-01, -1.0197e-01],\n        [-1.3667e-01,  3.8939e-02, -3.5876e-02,  1.0860e-01,  1.4103e-01,\n          1.7540e-02,  1.0331e-01, -1.7068e-02,  2.1314e-02,  9.9737e-02,\n         -1.7462e-01, -1.6712e-01,  1.5502e-01,  4.0733e-02,  1.4404e-01,\n         -1.2146e-01, -1.1658e-01,  1.4201e-01, -1.4912e-02, -6.5299e-02,\n          1.1751e-01, -1.6221e-01, -1.6771e-01,  5.1188e-02, -4.4625e-02,\n          9.6562e-02, -6.4252e-02,  1.0742e-02, -1.1201e-01,  7.0479e-02,\n         -1.3223e-01,  7.9655e-02],\n        [ 8.9239e-02, -4.5089e-02,  1.6204e-01, -4.5431e-02, -6.2357e-02,\n          4.7096e-02,  1.5969e-02, -1.5537e-01, -9.8401e-02,  9.8190e-02,\n          6.2434e-02,  5.5648e-02,  1.3910e-01, -6.4444e-02,  9.8413e-02,\n         -1.7517e-01, -2.7014e-02,  1.6329e-01,  8.3605e-03,  8.7320e-03,\n         -1.6301e-01, -9.7310e-02,  1.6595e-01, -1.3802e-02,  1.1153e-01,\n         -1.6867e-01, -1.2713e-01, -9.5122e-02,  5.9405e-03, -1.0785e-01,\n         -1.8852e-02,  6.8465e-02],\n        [-1.2253e-01, -7.8653e-02, -1.3654e-01,  6.6292e-02,  1.3577e-01,\n          1.7063e-02,  8.5651e-02, -1.4284e-01, -1.2637e-01, -1.0881e-01,\n          4.7274e-02,  7.9796e-02, -1.5340e-01, -1.2654e-01, -6.8822e-02,\n         -1.2735e-01, -4.2568e-02,  8.9302e-02, -9.6786e-02,  6.5381e-02,\n          6.0129e-02,  8.0727e-02,  8.9040e-02, -2.2749e-03,  5.9577e-02,\n          8.7208e-02, -1.5467e-01, -6.8623e-04,  1.2582e-01, -1.1033e-01,\n         -4.5590e-02,  1.5326e-01],\n        [-4.6124e-02,  1.1909e-01, -1.1428e-01, -1.5326e-01,  1.5558e-01,\n          1.4543e-01, -1.1860e-01,  7.4235e-02,  4.7038e-04,  1.2237e-01,\n          1.2804e-01,  1.1872e-02,  5.1664e-02,  7.0050e-02, -3.4779e-02,\n          1.6228e-01,  1.2936e-01, -1.6564e-01,  6.1529e-02,  2.5670e-02,\n          8.9482e-02,  1.2002e-01, -6.9578e-02, -1.0847e-01, -1.0451e-01,\n         -6.4742e-02, -3.7173e-03, -9.9294e-02, -5.1535e-02,  3.4715e-02,\n          1.4654e-01, -1.1312e-01],\n        [ 1.3779e-01,  3.9131e-02,  9.3181e-02, -1.2254e-01,  1.7335e-01,\n         -1.2420e-01, -9.7519e-02, -1.2857e-01, -4.1568e-02,  6.8886e-02,\n         -8.8373e-02, -1.1225e-01,  7.7063e-03,  5.1219e-02,  9.1955e-02,\n          7.5742e-02,  1.5552e-01,  1.1603e-01,  3.2010e-02, -1.3107e-01,\n         -1.2925e-01, -8.2139e-02,  9.8794e-02,  1.7329e-01, -1.4645e-01,\n         -6.0017e-02,  3.0841e-02, -1.1772e-01, -3.4199e-02, -1.3538e-01,\n          1.2455e-01,  3.7454e-02],\n        [ 9.9885e-02,  8.7515e-03, -3.8942e-02, -4.3353e-02,  1.1643e-02,\n          8.3420e-02,  1.0420e-01,  6.3995e-02,  1.6822e-01, -1.2284e-01,\n         -1.7205e-01, -2.7443e-02, -1.1432e-02, -7.1633e-02,  9.2140e-02,\n          8.5812e-02, -3.8221e-02, -1.0889e-01,  6.7063e-02,  1.3505e-01,\n         -8.0659e-02,  1.7057e-01, -1.3403e-02,  2.2627e-02, -1.1867e-01,\n          1.2459e-01, -5.3443e-02, -1.0439e-01,  1.6210e-01,  5.1131e-02,\n         -8.8234e-02, -2.0292e-02],\n        [-1.0970e-01,  1.5628e-01,  2.0063e-02, -1.2157e-02, -1.4043e-01,\n          1.0390e-01, -5.4917e-02, -8.5689e-02, -2.4629e-02, -7.0219e-02,\n          1.1161e-01,  2.0806e-02,  4.4369e-02, -6.7857e-02, -1.7617e-01,\n         -1.1307e-01, -1.2563e-01,  1.3052e-01,  1.3694e-01,  1.4265e-01,\n         -1.5826e-01, -8.9572e-02,  2.3612e-02, -1.2027e-01, -1.2316e-01,\n          9.9102e-02,  4.9841e-02, -1.3134e-01,  8.6095e-02, -1.4550e-01,\n          4.0531e-02, -2.6312e-02],\n        [ 1.0449e-01, -2.0223e-03,  8.3700e-03, -1.4167e-01, -1.7327e-01,\n         -1.4970e-01, -9.6392e-02,  1.2169e-01, -1.7263e-01, -1.0055e-01,\n          6.9983e-02,  1.5588e-01, -1.6982e-01, -1.6247e-01,  1.3114e-01,\n         -8.6687e-02, -1.6482e-01, -1.7850e-02, -2.2261e-02,  9.6192e-02,\n         -8.3163e-02, -1.6325e-01, -1.4514e-01, -1.6723e-01,  5.0416e-03,\n          1.3731e-01, -1.0714e-01,  1.3692e-01,  5.1800e-02, -6.9770e-02,\n         -2.1397e-02,  1.2019e-01],\n        [ 1.9882e-02, -1.3332e-02,  7.0625e-02,  6.1762e-02,  1.8665e-03,\n         -1.5148e-01, -5.9226e-02,  7.4618e-02, -1.0987e-01, -1.3102e-02,\n          1.4463e-01, -3.6698e-02,  1.7483e-01, -5.2713e-03,  7.7437e-02,\n         -1.0205e-01, -1.4031e-01,  3.1971e-02,  1.7019e-01, -1.1041e-01,\n         -1.2088e-01,  9.5820e-02,  1.7089e-01, -6.4340e-02, -7.5655e-02,\n          1.5703e-03, -1.7385e-01, -7.3786e-02,  1.3159e-01, -1.3396e-01,\n         -1.3755e-03,  1.1513e-02],\n        [-2.7525e-02, -1.6165e-01, -1.0519e-02,  3.4231e-02, -8.9262e-02,\n         -1.6388e-01, -1.7595e-01, -4.2118e-02,  3.6247e-02, -1.2629e-01,\n          4.4228e-02, -1.1125e-01,  1.3859e-01, -3.0622e-02, -5.3345e-02,\n         -6.1296e-02, -1.1230e-01,  3.3746e-02, -1.2549e-01, -8.4339e-02,\n          1.5079e-01, -7.0935e-02,  8.9617e-02,  6.3022e-02, -1.4110e-01,\n          1.4455e-01,  5.7195e-02,  9.4245e-02,  2.3917e-02, -5.9783e-03,\n          5.7015e-02,  7.1507e-02],\n        [-5.0996e-02, -1.3999e-01,  4.9242e-02, -1.1093e-01, -1.2149e-01,\n          4.2895e-02, -4.9394e-02, -4.5884e-02, -4.8920e-02,  6.2283e-02,\n         -1.4370e-01, -1.3241e-01,  1.7192e-01, -7.1754e-02,  7.6557e-02,\n          6.6474e-04, -1.6839e-01, -1.5188e-01, -1.6685e-02, -1.5648e-01,\n         -7.8210e-02, -1.4175e-01, -1.6403e-01,  9.2792e-02,  1.6486e-02,\n         -1.5727e-02,  1.1459e-01,  1.6742e-01,  1.2010e-01,  1.3426e-01,\n         -1.9559e-02,  1.7342e-01],\n        [-1.4713e-01, -2.4214e-02,  1.0716e-01,  1.7338e-01, -1.5584e-01,\n          1.6191e-01,  1.5379e-01,  4.5908e-02, -3.6466e-02,  5.8198e-02,\n         -8.3641e-02, -1.7188e-01, -1.4541e-01, -7.9651e-02,  1.6289e-01,\n         -8.8963e-02, -1.2996e-01,  1.0289e-01, -6.5278e-02, -2.7344e-02,\n          1.1674e-01, -1.5217e-01, -1.2634e-01,  1.2928e-01,  1.3913e-01,\n          1.2919e-02, -4.2866e-02, -7.0361e-02,  7.4207e-02, -7.4436e-02,\n         -4.2872e-03,  2.1495e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2271,  0.1353, -0.1011, -0.0629, -0.1692, -0.2262, -0.1600,  0.0953],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1356,  0.0687,  0.0894,  0.2256, -0.1728, -0.0473, -0.0315, -0.0724,\n         -0.2353, -0.1108,  0.1799,  0.2385, -0.0748,  0.1274,  0.1168, -0.0405],\n        [-0.1376,  0.1325,  0.0214,  0.2451, -0.2469, -0.0331,  0.2123,  0.1249,\n         -0.0337, -0.0275,  0.0213,  0.1147,  0.2459,  0.0668, -0.0421,  0.0501],\n        [-0.0463, -0.2034,  0.0630,  0.0847,  0.0916,  0.1556, -0.1256, -0.2017,\n          0.0649, -0.0507,  0.2074, -0.1581, -0.1781, -0.2278,  0.0711,  0.0301],\n        [-0.2009, -0.0636,  0.1737, -0.0257, -0.2170, -0.0766, -0.1789,  0.1048,\n          0.0979,  0.2463,  0.0620,  0.0649, -0.0643,  0.1888, -0.1989,  0.2324],\n        [-0.0722, -0.2177, -0.1112, -0.0391,  0.0402, -0.0595, -0.0661, -0.1885,\n          0.2398,  0.2496,  0.1879, -0.0216, -0.1609, -0.0838, -0.2413,  0.1363],\n        [ 0.0394, -0.1145,  0.0376,  0.1433, -0.2426, -0.1342,  0.1476, -0.2409,\n          0.0615,  0.0603, -0.1709, -0.0371,  0.2410, -0.2058, -0.1855,  0.0071],\n        [ 0.1241, -0.2007,  0.0465, -0.0883, -0.0396,  0.1327, -0.1915,  0.1449,\n          0.0354,  0.2087,  0.1641, -0.2144,  0.1979,  0.0380,  0.2498, -0.0702],\n        [ 0.1294,  0.0895,  0.2070,  0.1672,  0.0766, -0.1964, -0.1221, -0.1189,\n          0.2060,  0.1324,  0.1068,  0.2151,  0.2034, -0.0505, -0.0544, -0.1822]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.3302], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2498,  0.1641,  0.0969,  0.1579,  0.3432,  0.3311,  0.1312,  0.0552]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-1.8070e-01,  1.5971e-01, -3.3843e-03, -3.4869e-02, -1.8369e-01,\n          2.7807e-02, -3.1652e-01,  1.0715e-01],\n        [-2.3537e-01, -4.2065e-03,  1.0576e-01,  3.1712e-01, -8.3638e-02,\n         -2.1448e-02,  8.3392e-02, -1.3976e-01],\n        [ 1.4438e-01,  1.1531e-01, -1.7376e-01, -2.4421e-01,  2.5566e-01,\n         -2.1391e-01,  2.2767e-01,  2.7942e-01],\n        [ 1.8132e-01,  4.1517e-02, -1.2626e-02, -3.0549e-01, -6.3249e-02,\n         -1.9427e-01,  4.2091e-02, -9.1502e-02],\n        [ 1.9790e-01, -3.8022e-02,  2.8790e-01,  1.1893e-01, -5.8543e-03,\n         -2.4192e-01, -1.6068e-01, -3.2689e-01],\n        [ 9.3518e-02, -3.0357e-01, -5.7942e-02, -2.6760e-01, -1.1577e-01,\n         -2.2838e-01,  1.0072e-01, -2.0959e-01],\n        [-3.3283e-01,  2.3652e-03,  1.8765e-02,  9.5370e-03,  3.5013e-01,\n         -2.4319e-01, -2.6003e-01,  8.2456e-02],\n        [-3.4555e-01, -2.2240e-01, -2.2947e-01,  2.9708e-01, -3.2648e-01,\n          3.5230e-02,  1.6824e-01, -6.3602e-02],\n        [ 2.6191e-01,  2.6993e-01, -3.2251e-01, -1.5205e-01, -1.9175e-01,\n         -3.1217e-01,  4.2329e-03,  2.4564e-01],\n        [-1.1662e-01,  2.1957e-01, -3.3837e-01, -3.0861e-01, -2.2239e-01,\n         -2.4541e-01, -3.3623e-01,  3.1547e-01],\n        [-6.8505e-02,  1.6962e-01, -1.6628e-02,  2.8365e-01, -1.5328e-01,\n          1.2383e-01, -2.0726e-01, -7.7541e-02],\n        [ 2.1576e-01,  3.4532e-01, -2.9672e-01,  2.4113e-01, -2.4966e-01,\n          2.0948e-01, -3.3418e-02,  1.5991e-01],\n        [ 2.0504e-01,  1.1281e-01,  3.3759e-01,  2.0710e-01,  1.3114e-01,\n          1.0916e-01,  2.6391e-01,  2.1155e-01],\n        [ 1.6572e-01,  1.7806e-01,  1.0096e-02,  4.6098e-02, -1.4103e-01,\n          2.8034e-01,  3.4057e-01, -7.3458e-02],\n        [-1.3908e-01,  2.0430e-01, -1.3970e-01,  2.3123e-01, -2.5594e-01,\n          1.1712e-01,  2.2424e-01, -2.9372e-01],\n        [ 7.6455e-02, -2.9004e-01, -2.4110e-01,  3.9267e-02, -1.2602e-01,\n          2.6623e-01, -6.9499e-02,  1.9109e-01],\n        [ 3.4877e-01, -9.5452e-02, -2.8143e-01,  8.6384e-02,  2.5921e-01,\n         -1.6359e-01, -3.3975e-01,  3.4850e-01],\n        [ 3.0074e-01,  1.6167e-01,  2.5142e-03, -1.0399e-01, -3.6655e-02,\n         -2.4897e-01, -1.6618e-01,  2.6776e-01],\n        [-1.0990e-01,  1.1893e-01, -2.2585e-01, -2.6644e-01,  2.6376e-01,\n         -2.7362e-01,  3.1849e-01,  8.5503e-02],\n        [-3.0242e-02,  3.1902e-01,  2.2437e-01, -1.1007e-01, -2.8616e-01,\n         -2.5803e-01,  1.6862e-01, -2.2844e-01],\n        [ 3.6550e-02, -1.5074e-01,  8.0434e-02, -2.2438e-01, -3.0934e-01,\n         -9.6489e-02,  2.0906e-01, -7.9690e-02],\n        [-3.1311e-01, -8.2374e-02, -1.4471e-01,  2.2985e-01, -3.0188e-01,\n          2.9426e-01,  2.2802e-01, -3.1932e-01],\n        [-2.2918e-05,  1.7527e-01, -3.4068e-01, -2.8973e-01,  1.8004e-01,\n          2.7766e-01, -2.6097e-01, -2.1959e-01],\n        [ 6.3528e-02, -6.2347e-02,  1.6773e-01, -1.6832e-01, -5.9802e-02,\n         -3.1457e-01, -6.6205e-02, -3.3735e-01],\n        [ 2.1925e-01,  1.8044e-01, -3.4187e-02,  3.4951e-01,  2.3827e-01,\n          3.0205e-02, -2.4013e-01,  3.2206e-01],\n        [-1.1592e-01,  2.3986e-01,  1.3664e-01, -1.1455e-01, -1.6328e-01,\n          4.4461e-02, -2.1190e-01, -2.9543e-01],\n        [-9.7994e-02,  3.0622e-01, -2.4485e-01, -1.2911e-01,  9.7397e-02,\n         -3.0211e-01, -3.1424e-01,  4.0641e-02],\n        [-2.6362e-01, -1.9323e-01, -2.8514e-01,  1.6876e-02, -1.4840e-01,\n         -2.4806e-01, -3.2312e-01, -1.4544e-02],\n        [ 1.8492e-01, -2.8978e-01, -2.4938e-01, -3.4728e-01, -2.6038e-02,\n          9.0325e-02, -1.4075e-01, -8.9825e-02],\n        [-2.1966e-01,  4.3414e-02, -4.5534e-02, -2.0931e-01, -3.5261e-01,\n          2.3860e-01, -2.9235e-01, -4.6054e-02],\n        [-1.1135e-01, -3.3586e-01, -2.7732e-01,  5.8959e-02,  3.3477e-01,\n         -2.0174e-01, -3.4186e-01,  3.0353e-01],\n        [-2.7161e-01, -1.1532e-01, -7.3936e-02, -3.0929e-02,  1.4660e-01,\n          6.5352e-02, -3.0363e-01, -1.2116e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-2.1370e-01, -4.0857e-02, -3.0807e-01, -6.6606e-02, -2.4722e-01,\n        -2.8131e-01,  3.1409e-01, -5.4927e-02, -4.7329e-02, -5.2070e-02,\n         7.8111e-02,  3.0087e-01, -2.4088e-01, -1.2620e-01, -2.8773e-01,\n        -1.5599e-01,  1.7437e-04, -1.8338e-01, -1.8208e-01, -1.2362e-01,\n         1.7848e-01, -1.5488e-01,  2.5717e-02, -1.8097e-01,  2.0951e-01,\n        -2.9519e-01, -1.2480e-01, -3.3812e-02,  1.3387e-01, -7.1756e-02,\n        -3.3910e-01,  1.5767e-01], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.3192e-01, -5.3093e-02, -1.4398e-01,  6.1835e-02, -4.9249e-02,\n         -1.4357e-02, -1.5869e-01, -5.5070e-02,  1.1936e-01,  1.4624e-01,\n          5.4109e-02,  1.9763e-02,  1.2296e-01,  8.8789e-02,  6.9785e-02,\n         -1.4319e-01,  1.4333e-01,  1.5176e-01,  4.3371e-02, -8.3796e-02,\n          6.7476e-02, -1.1849e-01,  1.6988e-01, -9.3977e-02,  1.0247e-01,\n         -1.2197e-02, -2.9328e-02, -1.2001e-01,  5.1562e-03, -4.2576e-02,\n          1.5941e-02,  1.2822e-01],\n        [ 1.7172e-01,  8.5123e-02, -1.1807e-01, -1.5319e-01,  1.5900e-01,\n         -1.1533e-01,  2.8113e-02,  1.2861e-01,  1.0598e-01,  5.8625e-02,\n         -3.1744e-02,  2.0854e-02,  7.1638e-02,  2.3924e-02,  1.5461e-02,\n         -1.5304e-01, -2.4377e-02,  1.2192e-01,  4.5895e-03,  6.5655e-03,\n          1.0715e-01, -1.7259e-01, -7.9339e-02, -1.2967e-01, -9.0656e-03,\n         -1.1448e-01, -1.4485e-01, -3.6317e-02, -1.2488e-01,  1.5829e-01,\n         -3.1707e-02, -1.2185e-01],\n        [ 1.6012e-01,  1.1171e-04,  4.4795e-02, -1.1564e-01,  1.2528e-01,\n          1.2569e-01, -4.3859e-02,  6.9082e-02, -5.2222e-02,  1.2619e-01,\n         -7.9830e-02, -1.4628e-01, -4.5524e-02, -4.1791e-02, -1.4400e-02,\n          1.1145e-02, -2.4685e-02, -2.1246e-02,  7.6761e-02,  1.1820e-02,\n         -2.5674e-02, -5.3149e-02,  1.7253e-01,  1.5025e-02,  8.7489e-02,\n         -1.0390e-01,  1.3543e-01,  1.0991e-01, -4.3801e-02,  1.7370e-02,\n         -1.5775e-02,  1.3298e-01],\n        [-1.5746e-01, -1.5386e-01, -2.7902e-02, -4.8250e-02, -6.3915e-02,\n          8.2823e-02, -8.9257e-02,  4.2582e-02, -1.5372e-01, -1.1564e-01,\n          1.2276e-01,  1.1915e-01, -1.7423e-01, -8.3683e-02, -8.0057e-02,\n         -1.0121e-01,  9.6423e-02,  2.6460e-02,  1.0068e-01, -5.4422e-02,\n          6.9981e-02,  7.0990e-02,  9.7402e-03, -3.6256e-02,  1.1583e-02,\n         -7.3368e-02,  1.5407e-01,  5.3060e-02,  9.4515e-02, -5.4464e-02,\n          1.7508e-01, -1.0197e-01],\n        [-1.3667e-01,  3.8939e-02, -3.5876e-02,  1.0860e-01,  1.4103e-01,\n          1.7540e-02,  1.0331e-01, -1.7068e-02,  2.1314e-02,  9.9737e-02,\n         -1.7462e-01, -1.6712e-01,  1.5502e-01,  4.0733e-02,  1.4404e-01,\n         -1.2146e-01, -1.1658e-01,  1.4201e-01, -1.4912e-02, -6.5299e-02,\n          1.1751e-01, -1.6221e-01, -1.6771e-01,  5.1188e-02, -4.4625e-02,\n          9.6562e-02, -6.4252e-02,  1.0742e-02, -1.1201e-01,  7.0479e-02,\n         -1.3223e-01,  7.9655e-02],\n        [ 8.9239e-02, -4.5089e-02,  1.6204e-01, -4.5431e-02, -6.2357e-02,\n          4.7096e-02,  1.5969e-02, -1.5537e-01, -9.8401e-02,  9.8190e-02,\n          6.2434e-02,  5.5648e-02,  1.3910e-01, -6.4444e-02,  9.8413e-02,\n         -1.7517e-01, -2.7014e-02,  1.6329e-01,  8.3605e-03,  8.7320e-03,\n         -1.6301e-01, -9.7310e-02,  1.6595e-01, -1.3802e-02,  1.1153e-01,\n         -1.6867e-01, -1.2713e-01, -9.5122e-02,  5.9405e-03, -1.0785e-01,\n         -1.8852e-02,  6.8465e-02],\n        [-1.2253e-01, -7.8653e-02, -1.3654e-01,  6.6292e-02,  1.3577e-01,\n          1.7063e-02,  8.5651e-02, -1.4284e-01, -1.2637e-01, -1.0881e-01,\n          4.7274e-02,  7.9796e-02, -1.5340e-01, -1.2654e-01, -6.8822e-02,\n         -1.2735e-01, -4.2568e-02,  8.9302e-02, -9.6786e-02,  6.5381e-02,\n          6.0129e-02,  8.0727e-02,  8.9040e-02, -2.2749e-03,  5.9577e-02,\n          8.7208e-02, -1.5467e-01, -6.8623e-04,  1.2582e-01, -1.1033e-01,\n         -4.5590e-02,  1.5326e-01],\n        [-4.6124e-02,  1.1909e-01, -1.1428e-01, -1.5326e-01,  1.5558e-01,\n          1.4543e-01, -1.1860e-01,  7.4235e-02,  4.7038e-04,  1.2237e-01,\n          1.2804e-01,  1.1872e-02,  5.1664e-02,  7.0050e-02, -3.4779e-02,\n          1.6228e-01,  1.2936e-01, -1.6564e-01,  6.1529e-02,  2.5670e-02,\n          8.9482e-02,  1.2002e-01, -6.9578e-02, -1.0847e-01, -1.0451e-01,\n         -6.4742e-02, -3.7173e-03, -9.9294e-02, -5.1535e-02,  3.4715e-02,\n          1.4654e-01, -1.1312e-01],\n        [ 1.3779e-01,  3.9131e-02,  9.3181e-02, -1.2254e-01,  1.7335e-01,\n         -1.2420e-01, -9.7519e-02, -1.2857e-01, -4.1568e-02,  6.8886e-02,\n         -8.8373e-02, -1.1225e-01,  7.7063e-03,  5.1219e-02,  9.1955e-02,\n          7.5742e-02,  1.5552e-01,  1.1603e-01,  3.2010e-02, -1.3107e-01,\n         -1.2925e-01, -8.2139e-02,  9.8794e-02,  1.7329e-01, -1.4645e-01,\n         -6.0017e-02,  3.0841e-02, -1.1772e-01, -3.4199e-02, -1.3538e-01,\n          1.2455e-01,  3.7454e-02],\n        [ 9.9885e-02,  8.7515e-03, -3.8942e-02, -4.3353e-02,  1.1643e-02,\n          8.3420e-02,  1.0420e-01,  6.3995e-02,  1.6822e-01, -1.2284e-01,\n         -1.7205e-01, -2.7443e-02, -1.1432e-02, -7.1633e-02,  9.2140e-02,\n          8.5812e-02, -3.8221e-02, -1.0889e-01,  6.7063e-02,  1.3505e-01,\n         -8.0659e-02,  1.7057e-01, -1.3403e-02,  2.2627e-02, -1.1867e-01,\n          1.2459e-01, -5.3443e-02, -1.0439e-01,  1.6210e-01,  5.1131e-02,\n         -8.8234e-02, -2.0292e-02],\n        [-1.0970e-01,  1.5628e-01,  2.0063e-02, -1.2157e-02, -1.4043e-01,\n          1.0390e-01, -5.4917e-02, -8.5689e-02, -2.4629e-02, -7.0219e-02,\n          1.1161e-01,  2.0806e-02,  4.4369e-02, -6.7857e-02, -1.7617e-01,\n         -1.1307e-01, -1.2563e-01,  1.3052e-01,  1.3694e-01,  1.4265e-01,\n         -1.5826e-01, -8.9572e-02,  2.3612e-02, -1.2027e-01, -1.2316e-01,\n          9.9102e-02,  4.9841e-02, -1.3134e-01,  8.6095e-02, -1.4550e-01,\n          4.0531e-02, -2.6312e-02],\n        [ 1.0449e-01, -2.0223e-03,  8.3700e-03, -1.4167e-01, -1.7327e-01,\n         -1.4970e-01, -9.6392e-02,  1.2169e-01, -1.7263e-01, -1.0055e-01,\n          6.9983e-02,  1.5588e-01, -1.6982e-01, -1.6247e-01,  1.3114e-01,\n         -8.6687e-02, -1.6482e-01, -1.7850e-02, -2.2261e-02,  9.6192e-02,\n         -8.3163e-02, -1.6325e-01, -1.4514e-01, -1.6723e-01,  5.0416e-03,\n          1.3731e-01, -1.0714e-01,  1.3692e-01,  5.1800e-02, -6.9770e-02,\n         -2.1397e-02,  1.2019e-01],\n        [ 1.9882e-02, -1.3332e-02,  7.0625e-02,  6.1762e-02,  1.8665e-03,\n         -1.5148e-01, -5.9226e-02,  7.4618e-02, -1.0987e-01, -1.3102e-02,\n          1.4463e-01, -3.6698e-02,  1.7483e-01, -5.2713e-03,  7.7437e-02,\n         -1.0205e-01, -1.4031e-01,  3.1971e-02,  1.7019e-01, -1.1041e-01,\n         -1.2088e-01,  9.5820e-02,  1.7089e-01, -6.4340e-02, -7.5655e-02,\n          1.5703e-03, -1.7385e-01, -7.3786e-02,  1.3159e-01, -1.3396e-01,\n         -1.3755e-03,  1.1513e-02],\n        [-2.7525e-02, -1.6165e-01, -1.0519e-02,  3.4231e-02, -8.9262e-02,\n         -1.6388e-01, -1.7595e-01, -4.2118e-02,  3.6247e-02, -1.2629e-01,\n          4.4228e-02, -1.1125e-01,  1.3859e-01, -3.0622e-02, -5.3345e-02,\n         -6.1296e-02, -1.1230e-01,  3.3746e-02, -1.2549e-01, -8.4339e-02,\n          1.5079e-01, -7.0935e-02,  8.9617e-02,  6.3022e-02, -1.4110e-01,\n          1.4455e-01,  5.7195e-02,  9.4245e-02,  2.3917e-02, -5.9783e-03,\n          5.7015e-02,  7.1507e-02],\n        [-5.0996e-02, -1.3999e-01,  4.9242e-02, -1.1093e-01, -1.2149e-01,\n          4.2895e-02, -4.9394e-02, -4.5884e-02, -4.8920e-02,  6.2283e-02,\n         -1.4370e-01, -1.3241e-01,  1.7192e-01, -7.1754e-02,  7.6557e-02,\n          6.6474e-04, -1.6839e-01, -1.5188e-01, -1.6685e-02, -1.5648e-01,\n         -7.8210e-02, -1.4175e-01, -1.6403e-01,  9.2792e-02,  1.6486e-02,\n         -1.5727e-02,  1.1459e-01,  1.6742e-01,  1.2010e-01,  1.3426e-01,\n         -1.9559e-02,  1.7342e-01],\n        [-1.4713e-01, -2.4214e-02,  1.0716e-01,  1.7338e-01, -1.5584e-01,\n          1.6191e-01,  1.5379e-01,  4.5908e-02, -3.6466e-02,  5.8198e-02,\n         -8.3641e-02, -1.7188e-01, -1.4541e-01, -7.9651e-02,  1.6289e-01,\n         -8.8963e-02, -1.2996e-01,  1.0289e-01, -6.5278e-02, -2.7344e-02,\n          1.1674e-01, -1.5217e-01, -1.2634e-01,  1.2928e-01,  1.3913e-01,\n          1.2919e-02, -4.2866e-02, -7.0361e-02,  7.4207e-02, -7.4436e-02,\n         -4.2872e-03,  2.1495e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1217, -0.0569,  0.1117,  0.0822,  0.0319,  0.0183, -0.0007,  0.0978,\n        -0.0549,  0.1501,  0.0982, -0.0808, -0.1289, -0.0483,  0.0655,  0.1080],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1356,  0.0687,  0.0894,  0.2256, -0.1728, -0.0473, -0.0315, -0.0724,\n         -0.2353, -0.1108,  0.1799,  0.2385, -0.0748,  0.1274,  0.1168, -0.0405],\n        [-0.1376,  0.1325,  0.0214,  0.2451, -0.2469, -0.0331,  0.2123,  0.1249,\n         -0.0337, -0.0275,  0.0213,  0.1147,  0.2459,  0.0668, -0.0421,  0.0501],\n        [-0.0463, -0.2034,  0.0630,  0.0847,  0.0916,  0.1556, -0.1256, -0.2017,\n          0.0649, -0.0507,  0.2074, -0.1581, -0.1781, -0.2278,  0.0711,  0.0301],\n        [-0.2009, -0.0636,  0.1737, -0.0257, -0.2170, -0.0766, -0.1789,  0.1048,\n          0.0979,  0.2463,  0.0620,  0.0649, -0.0643,  0.1888, -0.1989,  0.2324],\n        [-0.0722, -0.2177, -0.1112, -0.0391,  0.0402, -0.0595, -0.0661, -0.1885,\n          0.2398,  0.2496,  0.1879, -0.0216, -0.1609, -0.0838, -0.2413,  0.1363],\n        [ 0.0394, -0.1145,  0.0376,  0.1433, -0.2426, -0.1342,  0.1476, -0.2409,\n          0.0615,  0.0603, -0.1709, -0.0371,  0.2410, -0.2058, -0.1855,  0.0071],\n        [ 0.1241, -0.2007,  0.0465, -0.0883, -0.0396,  0.1327, -0.1915,  0.1449,\n          0.0354,  0.2087,  0.1641, -0.2144,  0.1979,  0.0380,  0.2498, -0.0702],\n        [ 0.1294,  0.0895,  0.2070,  0.1672,  0.0766, -0.1964, -0.1221, -0.1189,\n          0.2060,  0.1324,  0.1068,  0.2151,  0.2034, -0.0505, -0.0544, -0.1822]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2271,  0.1353, -0.1011, -0.0629, -0.1692, -0.2262, -0.1600,  0.0953],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2498,  0.1641,  0.0969,  0.1579,  0.3432,  0.3311,  0.1312,  0.0552]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.3302], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x00000225FFE562F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x00000225CBB6CC40>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s252120000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s252120000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-2.1370e-01, -4.0857e-02, -3.0807e-01, -6.6606e-02, -2.4722e-01,\n        -2.8131e-01,  3.1409e-01, -5.4927e-02, -4.7329e-02, -5.2070e-02,\n         7.8111e-02,  3.0087e-01, -2.4088e-01, -1.2620e-01, -2.8773e-01,\n        -1.5599e-01,  1.7437e-04, -1.8338e-01, -1.8208e-01, -1.2362e-01,\n         1.7848e-01, -1.5488e-01,  2.5717e-02, -1.8097e-01,  2.0951e-01,\n        -2.9519e-01, -1.2480e-01, -3.3812e-02,  1.3387e-01, -7.1756e-02,\n        -3.3910e-01,  1.5767e-01], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.8070e-01,  1.5971e-01, -3.3843e-03, -3.4869e-02, -1.8369e-01,\n          2.7807e-02, -3.1652e-01,  1.0715e-01],\n        [-2.3537e-01, -4.2065e-03,  1.0576e-01,  3.1712e-01, -8.3638e-02,\n         -2.1448e-02,  8.3392e-02, -1.3976e-01],\n        [ 1.4438e-01,  1.1531e-01, -1.7376e-01, -2.4421e-01,  2.5566e-01,\n         -2.1391e-01,  2.2767e-01,  2.7942e-01],\n        [ 1.8132e-01,  4.1517e-02, -1.2626e-02, -3.0549e-01, -6.3249e-02,\n         -1.9427e-01,  4.2091e-02, -9.1502e-02],\n        [ 1.9790e-01, -3.8022e-02,  2.8790e-01,  1.1893e-01, -5.8543e-03,\n         -2.4192e-01, -1.6068e-01, -3.2689e-01],\n        [ 9.3518e-02, -3.0357e-01, -5.7942e-02, -2.6760e-01, -1.1577e-01,\n         -2.2838e-01,  1.0072e-01, -2.0959e-01],\n        [-3.3283e-01,  2.3652e-03,  1.8765e-02,  9.5370e-03,  3.5013e-01,\n         -2.4319e-01, -2.6003e-01,  8.2456e-02],\n        [-3.4555e-01, -2.2240e-01, -2.2947e-01,  2.9708e-01, -3.2648e-01,\n          3.5230e-02,  1.6824e-01, -6.3602e-02],\n        [ 2.6191e-01,  2.6993e-01, -3.2251e-01, -1.5205e-01, -1.9175e-01,\n         -3.1217e-01,  4.2329e-03,  2.4564e-01],\n        [-1.1662e-01,  2.1957e-01, -3.3837e-01, -3.0861e-01, -2.2239e-01,\n         -2.4541e-01, -3.3623e-01,  3.1547e-01],\n        [-6.8505e-02,  1.6962e-01, -1.6628e-02,  2.8365e-01, -1.5328e-01,\n          1.2383e-01, -2.0726e-01, -7.7541e-02],\n        [ 2.1576e-01,  3.4532e-01, -2.9672e-01,  2.4113e-01, -2.4966e-01,\n          2.0948e-01, -3.3418e-02,  1.5991e-01],\n        [ 2.0504e-01,  1.1281e-01,  3.3759e-01,  2.0710e-01,  1.3114e-01,\n          1.0916e-01,  2.6391e-01,  2.1155e-01],\n        [ 1.6572e-01,  1.7806e-01,  1.0096e-02,  4.6098e-02, -1.4103e-01,\n          2.8034e-01,  3.4057e-01, -7.3458e-02],\n        [-1.3908e-01,  2.0430e-01, -1.3970e-01,  2.3123e-01, -2.5594e-01,\n          1.1712e-01,  2.2424e-01, -2.9372e-01],\n        [ 7.6455e-02, -2.9004e-01, -2.4110e-01,  3.9267e-02, -1.2602e-01,\n          2.6623e-01, -6.9499e-02,  1.9109e-01],\n        [ 3.4877e-01, -9.5452e-02, -2.8143e-01,  8.6384e-02,  2.5921e-01,\n         -1.6359e-01, -3.3975e-01,  3.4850e-01],\n        [ 3.0074e-01,  1.6167e-01,  2.5142e-03, -1.0399e-01, -3.6655e-02,\n         -2.4897e-01, -1.6618e-01,  2.6776e-01],\n        [-1.0990e-01,  1.1893e-01, -2.2585e-01, -2.6644e-01,  2.6376e-01,\n         -2.7362e-01,  3.1849e-01,  8.5503e-02],\n        [-3.0242e-02,  3.1902e-01,  2.2437e-01, -1.1007e-01, -2.8616e-01,\n         -2.5803e-01,  1.6862e-01, -2.2844e-01],\n        [ 3.6550e-02, -1.5074e-01,  8.0434e-02, -2.2438e-01, -3.0934e-01,\n         -9.6489e-02,  2.0906e-01, -7.9690e-02],\n        [-3.1311e-01, -8.2374e-02, -1.4471e-01,  2.2985e-01, -3.0188e-01,\n          2.9426e-01,  2.2802e-01, -3.1932e-01],\n        [-2.2918e-05,  1.7527e-01, -3.4068e-01, -2.8973e-01,  1.8004e-01,\n          2.7766e-01, -2.6097e-01, -2.1959e-01],\n        [ 6.3528e-02, -6.2347e-02,  1.6773e-01, -1.6832e-01, -5.9802e-02,\n         -3.1457e-01, -6.6205e-02, -3.3735e-01],\n        [ 2.1925e-01,  1.8044e-01, -3.4187e-02,  3.4951e-01,  2.3827e-01,\n          3.0205e-02, -2.4013e-01,  3.2206e-01],\n        [-1.1592e-01,  2.3986e-01,  1.3664e-01, -1.1455e-01, -1.6328e-01,\n          4.4461e-02, -2.1190e-01, -2.9543e-01],\n        [-9.7994e-02,  3.0622e-01, -2.4485e-01, -1.2911e-01,  9.7397e-02,\n         -3.0211e-01, -3.1424e-01,  4.0641e-02],\n        [-2.6362e-01, -1.9323e-01, -2.8514e-01,  1.6876e-02, -1.4840e-01,\n         -2.4806e-01, -3.2312e-01, -1.4544e-02],\n        [ 1.8492e-01, -2.8978e-01, -2.4938e-01, -3.4728e-01, -2.6038e-02,\n          9.0325e-02, -1.4075e-01, -8.9825e-02],\n        [-2.1966e-01,  4.3414e-02, -4.5534e-02, -2.0931e-01, -3.5261e-01,\n          2.3860e-01, -2.9235e-01, -4.6054e-02],\n        [-1.1135e-01, -3.3586e-01, -2.7732e-01,  5.8959e-02,  3.3477e-01,\n         -2.0174e-01, -3.4186e-01,  3.0353e-01],\n        [-2.7161e-01, -1.1532e-01, -7.3936e-02, -3.0929e-02,  1.4660e-01,\n          6.5352e-02, -3.0363e-01, -1.2116e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1217, -0.0569,  0.1117,  0.0822,  0.0319,  0.0183, -0.0007,  0.0978,\n        -0.0549,  0.1501,  0.0982, -0.0808, -0.1289, -0.0483,  0.0655,  0.1080],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.3192e-01, -5.3093e-02, -1.4398e-01,  6.1835e-02, -4.9249e-02,\n         -1.4357e-02, -1.5869e-01, -5.5070e-02,  1.1936e-01,  1.4624e-01,\n          5.4109e-02,  1.9763e-02,  1.2296e-01,  8.8789e-02,  6.9785e-02,\n         -1.4319e-01,  1.4333e-01,  1.5176e-01,  4.3371e-02, -8.3796e-02,\n          6.7476e-02, -1.1849e-01,  1.6988e-01, -9.3977e-02,  1.0247e-01,\n         -1.2197e-02, -2.9328e-02, -1.2001e-01,  5.1562e-03, -4.2576e-02,\n          1.5941e-02,  1.2822e-01],\n        [ 1.7172e-01,  8.5123e-02, -1.1807e-01, -1.5319e-01,  1.5900e-01,\n         -1.1533e-01,  2.8113e-02,  1.2861e-01,  1.0598e-01,  5.8625e-02,\n         -3.1744e-02,  2.0854e-02,  7.1638e-02,  2.3924e-02,  1.5461e-02,\n         -1.5304e-01, -2.4377e-02,  1.2192e-01,  4.5895e-03,  6.5655e-03,\n          1.0715e-01, -1.7259e-01, -7.9339e-02, -1.2967e-01, -9.0656e-03,\n         -1.1448e-01, -1.4485e-01, -3.6317e-02, -1.2488e-01,  1.5829e-01,\n         -3.1707e-02, -1.2185e-01],\n        [ 1.6012e-01,  1.1171e-04,  4.4795e-02, -1.1564e-01,  1.2528e-01,\n          1.2569e-01, -4.3859e-02,  6.9082e-02, -5.2222e-02,  1.2619e-01,\n         -7.9830e-02, -1.4628e-01, -4.5524e-02, -4.1791e-02, -1.4400e-02,\n          1.1145e-02, -2.4685e-02, -2.1246e-02,  7.6761e-02,  1.1820e-02,\n         -2.5674e-02, -5.3149e-02,  1.7253e-01,  1.5025e-02,  8.7489e-02,\n         -1.0390e-01,  1.3543e-01,  1.0991e-01, -4.3801e-02,  1.7370e-02,\n         -1.5775e-02,  1.3298e-01],\n        [-1.5746e-01, -1.5386e-01, -2.7902e-02, -4.8250e-02, -6.3915e-02,\n          8.2823e-02, -8.9257e-02,  4.2582e-02, -1.5372e-01, -1.1564e-01,\n          1.2276e-01,  1.1915e-01, -1.7423e-01, -8.3683e-02, -8.0057e-02,\n         -1.0121e-01,  9.6423e-02,  2.6460e-02,  1.0068e-01, -5.4422e-02,\n          6.9981e-02,  7.0990e-02,  9.7402e-03, -3.6256e-02,  1.1583e-02,\n         -7.3368e-02,  1.5407e-01,  5.3060e-02,  9.4515e-02, -5.4464e-02,\n          1.7508e-01, -1.0197e-01],\n        [-1.3667e-01,  3.8939e-02, -3.5876e-02,  1.0860e-01,  1.4103e-01,\n          1.7540e-02,  1.0331e-01, -1.7068e-02,  2.1314e-02,  9.9737e-02,\n         -1.7462e-01, -1.6712e-01,  1.5502e-01,  4.0733e-02,  1.4404e-01,\n         -1.2146e-01, -1.1658e-01,  1.4201e-01, -1.4912e-02, -6.5299e-02,\n          1.1751e-01, -1.6221e-01, -1.6771e-01,  5.1188e-02, -4.4625e-02,\n          9.6562e-02, -6.4252e-02,  1.0742e-02, -1.1201e-01,  7.0479e-02,\n         -1.3223e-01,  7.9655e-02],\n        [ 8.9239e-02, -4.5089e-02,  1.6204e-01, -4.5431e-02, -6.2357e-02,\n          4.7096e-02,  1.5969e-02, -1.5537e-01, -9.8401e-02,  9.8190e-02,\n          6.2434e-02,  5.5648e-02,  1.3910e-01, -6.4444e-02,  9.8413e-02,\n         -1.7517e-01, -2.7014e-02,  1.6329e-01,  8.3605e-03,  8.7320e-03,\n         -1.6301e-01, -9.7310e-02,  1.6595e-01, -1.3802e-02,  1.1153e-01,\n         -1.6867e-01, -1.2713e-01, -9.5122e-02,  5.9405e-03, -1.0785e-01,\n         -1.8852e-02,  6.8465e-02],\n        [-1.2253e-01, -7.8653e-02, -1.3654e-01,  6.6292e-02,  1.3577e-01,\n          1.7063e-02,  8.5651e-02, -1.4284e-01, -1.2637e-01, -1.0881e-01,\n          4.7274e-02,  7.9796e-02, -1.5340e-01, -1.2654e-01, -6.8822e-02,\n         -1.2735e-01, -4.2568e-02,  8.9302e-02, -9.6786e-02,  6.5381e-02,\n          6.0129e-02,  8.0727e-02,  8.9040e-02, -2.2749e-03,  5.9577e-02,\n          8.7208e-02, -1.5467e-01, -6.8623e-04,  1.2582e-01, -1.1033e-01,\n         -4.5590e-02,  1.5326e-01],\n        [-4.6124e-02,  1.1909e-01, -1.1428e-01, -1.5326e-01,  1.5558e-01,\n          1.4543e-01, -1.1860e-01,  7.4235e-02,  4.7038e-04,  1.2237e-01,\n          1.2804e-01,  1.1872e-02,  5.1664e-02,  7.0050e-02, -3.4779e-02,\n          1.6228e-01,  1.2936e-01, -1.6564e-01,  6.1529e-02,  2.5670e-02,\n          8.9482e-02,  1.2002e-01, -6.9578e-02, -1.0847e-01, -1.0451e-01,\n         -6.4742e-02, -3.7173e-03, -9.9294e-02, -5.1535e-02,  3.4715e-02,\n          1.4654e-01, -1.1312e-01],\n        [ 1.3779e-01,  3.9131e-02,  9.3181e-02, -1.2254e-01,  1.7335e-01,\n         -1.2420e-01, -9.7519e-02, -1.2857e-01, -4.1568e-02,  6.8886e-02,\n         -8.8373e-02, -1.1225e-01,  7.7063e-03,  5.1219e-02,  9.1955e-02,\n          7.5742e-02,  1.5552e-01,  1.1603e-01,  3.2010e-02, -1.3107e-01,\n         -1.2925e-01, -8.2139e-02,  9.8794e-02,  1.7329e-01, -1.4645e-01,\n         -6.0017e-02,  3.0841e-02, -1.1772e-01, -3.4199e-02, -1.3538e-01,\n          1.2455e-01,  3.7454e-02],\n        [ 9.9885e-02,  8.7515e-03, -3.8942e-02, -4.3353e-02,  1.1643e-02,\n          8.3420e-02,  1.0420e-01,  6.3995e-02,  1.6822e-01, -1.2284e-01,\n         -1.7205e-01, -2.7443e-02, -1.1432e-02, -7.1633e-02,  9.2140e-02,\n          8.5812e-02, -3.8221e-02, -1.0889e-01,  6.7063e-02,  1.3505e-01,\n         -8.0659e-02,  1.7057e-01, -1.3403e-02,  2.2627e-02, -1.1867e-01,\n          1.2459e-01, -5.3443e-02, -1.0439e-01,  1.6210e-01,  5.1131e-02,\n         -8.8234e-02, -2.0292e-02],\n        [-1.0970e-01,  1.5628e-01,  2.0063e-02, -1.2157e-02, -1.4043e-01,\n          1.0390e-01, -5.4917e-02, -8.5689e-02, -2.4629e-02, -7.0219e-02,\n          1.1161e-01,  2.0806e-02,  4.4369e-02, -6.7857e-02, -1.7617e-01,\n         -1.1307e-01, -1.2563e-01,  1.3052e-01,  1.3694e-01,  1.4265e-01,\n         -1.5826e-01, -8.9572e-02,  2.3612e-02, -1.2027e-01, -1.2316e-01,\n          9.9102e-02,  4.9841e-02, -1.3134e-01,  8.6095e-02, -1.4550e-01,\n          4.0531e-02, -2.6312e-02],\n        [ 1.0449e-01, -2.0223e-03,  8.3700e-03, -1.4167e-01, -1.7327e-01,\n         -1.4970e-01, -9.6392e-02,  1.2169e-01, -1.7263e-01, -1.0055e-01,\n          6.9983e-02,  1.5588e-01, -1.6982e-01, -1.6247e-01,  1.3114e-01,\n         -8.6687e-02, -1.6482e-01, -1.7850e-02, -2.2261e-02,  9.6192e-02,\n         -8.3163e-02, -1.6325e-01, -1.4514e-01, -1.6723e-01,  5.0416e-03,\n          1.3731e-01, -1.0714e-01,  1.3692e-01,  5.1800e-02, -6.9770e-02,\n         -2.1397e-02,  1.2019e-01],\n        [ 1.9882e-02, -1.3332e-02,  7.0625e-02,  6.1762e-02,  1.8665e-03,\n         -1.5148e-01, -5.9226e-02,  7.4618e-02, -1.0987e-01, -1.3102e-02,\n          1.4463e-01, -3.6698e-02,  1.7483e-01, -5.2713e-03,  7.7437e-02,\n         -1.0205e-01, -1.4031e-01,  3.1971e-02,  1.7019e-01, -1.1041e-01,\n         -1.2088e-01,  9.5820e-02,  1.7089e-01, -6.4340e-02, -7.5655e-02,\n          1.5703e-03, -1.7385e-01, -7.3786e-02,  1.3159e-01, -1.3396e-01,\n         -1.3755e-03,  1.1513e-02],\n        [-2.7525e-02, -1.6165e-01, -1.0519e-02,  3.4231e-02, -8.9262e-02,\n         -1.6388e-01, -1.7595e-01, -4.2118e-02,  3.6247e-02, -1.2629e-01,\n          4.4228e-02, -1.1125e-01,  1.3859e-01, -3.0622e-02, -5.3345e-02,\n         -6.1296e-02, -1.1230e-01,  3.3746e-02, -1.2549e-01, -8.4339e-02,\n          1.5079e-01, -7.0935e-02,  8.9617e-02,  6.3022e-02, -1.4110e-01,\n          1.4455e-01,  5.7195e-02,  9.4245e-02,  2.3917e-02, -5.9783e-03,\n          5.7015e-02,  7.1507e-02],\n        [-5.0996e-02, -1.3999e-01,  4.9242e-02, -1.1093e-01, -1.2149e-01,\n          4.2895e-02, -4.9394e-02, -4.5884e-02, -4.8920e-02,  6.2283e-02,\n         -1.4370e-01, -1.3241e-01,  1.7192e-01, -7.1754e-02,  7.6557e-02,\n          6.6474e-04, -1.6839e-01, -1.5188e-01, -1.6685e-02, -1.5648e-01,\n         -7.8210e-02, -1.4175e-01, -1.6403e-01,  9.2792e-02,  1.6486e-02,\n         -1.5727e-02,  1.1459e-01,  1.6742e-01,  1.2010e-01,  1.3426e-01,\n         -1.9559e-02,  1.7342e-01],\n        [-1.4713e-01, -2.4214e-02,  1.0716e-01,  1.7338e-01, -1.5584e-01,\n          1.6191e-01,  1.5379e-01,  4.5908e-02, -3.6466e-02,  5.8198e-02,\n         -8.3641e-02, -1.7188e-01, -1.4541e-01, -7.9651e-02,  1.6289e-01,\n         -8.8963e-02, -1.2996e-01,  1.0289e-01, -6.5278e-02, -2.7344e-02,\n          1.1674e-01, -1.5217e-01, -1.2634e-01,  1.2928e-01,  1.3913e-01,\n          1.2919e-02, -4.2866e-02, -7.0361e-02,  7.4207e-02, -7.4436e-02,\n         -4.2872e-03,  2.1495e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2271,  0.1353, -0.1011, -0.0629, -0.1692, -0.2262, -0.1600,  0.0953],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1356,  0.0687,  0.0894,  0.2256, -0.1728, -0.0473, -0.0315, -0.0724,\n         -0.2353, -0.1108,  0.1799,  0.2385, -0.0748,  0.1274,  0.1168, -0.0405],\n        [-0.1376,  0.1325,  0.0214,  0.2451, -0.2469, -0.0331,  0.2123,  0.1249,\n         -0.0337, -0.0275,  0.0213,  0.1147,  0.2459,  0.0668, -0.0421,  0.0501],\n        [-0.0463, -0.2034,  0.0630,  0.0847,  0.0916,  0.1556, -0.1256, -0.2017,\n          0.0649, -0.0507,  0.2074, -0.1581, -0.1781, -0.2278,  0.0711,  0.0301],\n        [-0.2009, -0.0636,  0.1737, -0.0257, -0.2170, -0.0766, -0.1789,  0.1048,\n          0.0979,  0.2463,  0.0620,  0.0649, -0.0643,  0.1888, -0.1989,  0.2324],\n        [-0.0722, -0.2177, -0.1112, -0.0391,  0.0402, -0.0595, -0.0661, -0.1885,\n          0.2398,  0.2496,  0.1879, -0.0216, -0.1609, -0.0838, -0.2413,  0.1363],\n        [ 0.0394, -0.1145,  0.0376,  0.1433, -0.2426, -0.1342,  0.1476, -0.2409,\n          0.0615,  0.0603, -0.1709, -0.0371,  0.2410, -0.2058, -0.1855,  0.0071],\n        [ 0.1241, -0.2007,  0.0465, -0.0883, -0.0396,  0.1327, -0.1915,  0.1449,\n          0.0354,  0.2087,  0.1641, -0.2144,  0.1979,  0.0380,  0.2498, -0.0702],\n        [ 0.1294,  0.0895,  0.2070,  0.1672,  0.0766, -0.1964, -0.1221, -0.1189,\n          0.2060,  0.1324,  0.1068,  0.2151,  0.2034, -0.0505, -0.0544, -0.1822]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.3302], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2498,  0.1641,  0.0969,  0.1579,  0.3432,  0.3311,  0.1312,  0.0552]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}