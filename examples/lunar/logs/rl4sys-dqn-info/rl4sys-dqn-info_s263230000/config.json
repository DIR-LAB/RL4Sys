{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s263230000"
    },
    "q_lr":	0.0005,
    "seed":	263230000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7bfc251e1f50>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2008,  0.2567, -0.0703,  0.2381,  0.2650, -0.1403, -0.0516, -0.2952,\n         0.2965,  0.1922,  0.2376, -0.1885, -0.0487,  0.1019, -0.1664, -0.0752,\n        -0.2658,  0.0511,  0.2011, -0.2506,  0.3154,  0.1875,  0.2373,  0.0921,\n        -0.2333, -0.1707,  0.1462, -0.3416, -0.1939, -0.2520, -0.2207,  0.3043],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 5.6039e-02, -2.4088e-01,  2.3281e-01,  2.9885e-01,  3.2729e-01,\n         -1.2424e-01,  8.4697e-02,  6.6317e-02],\n        [-1.4880e-01, -1.4073e-01,  3.0418e-01,  2.6855e-01, -9.4447e-02,\n         -1.4780e-01, -2.7524e-01,  2.3177e-01],\n        [-7.3052e-03, -1.4753e-01,  2.0444e-01, -1.9382e-01, -3.3311e-01,\n         -2.4079e-01,  1.8341e-01,  9.2724e-02],\n        [ 1.1104e-01, -1.5743e-01,  1.6128e-01, -1.0214e-01, -7.9695e-02,\n          2.8415e-01, -1.0775e-01,  3.1077e-01],\n        [-3.5536e-02,  1.5674e-01,  1.5110e-01,  2.9148e-01, -1.9610e-02,\n          3.2736e-01, -2.5566e-01,  1.8223e-01],\n        [ 2.1758e-01,  1.1691e-01, -1.7223e-01,  2.4174e-01,  1.2559e-01,\n         -1.3096e-01, -1.2448e-01, -5.5156e-02],\n        [-1.9143e-01, -2.9147e-01, -2.6807e-01,  1.0277e-01,  2.0560e-01,\n          7.5952e-02,  2.3194e-01, -2.3095e-01],\n        [-3.3597e-01,  1.8477e-01,  4.4973e-02,  1.0783e-01,  2.2487e-01,\n         -7.3607e-02,  1.4871e-01,  3.0623e-01],\n        [ 3.1815e-01,  2.9714e-01, -4.2069e-02, -1.4156e-01,  6.0988e-02,\n          2.8987e-01,  1.0388e-01, -3.0735e-01],\n        [-1.3332e-01,  4.6009e-02,  1.3846e-01,  1.1652e-02,  2.2403e-02,\n         -3.3051e-01, -2.7524e-01,  3.2330e-01],\n        [-1.5908e-01, -1.7253e-01, -8.7969e-02, -2.3558e-01, -9.6061e-02,\n         -1.9097e-01,  1.8633e-01, -1.3713e-01],\n        [ 2.0135e-01, -1.0600e-01, -3.0587e-01,  3.6436e-02,  1.9551e-01,\n          6.3763e-02,  2.1878e-01,  1.8507e-01],\n        [ 1.0431e-01, -2.2054e-01,  1.5728e-02,  4.3528e-02,  5.4537e-02,\n         -1.4863e-01, -1.3071e-02,  6.5946e-02],\n        [ 2.2215e-01,  2.9386e-01, -2.0107e-01, -1.5947e-01,  7.9206e-02,\n         -1.6781e-01,  2.6672e-01,  3.2982e-01],\n        [-7.8601e-02,  3.3848e-01, -3.3101e-01,  8.2950e-02,  1.9409e-01,\n          2.3523e-01,  1.8449e-02, -3.0639e-01],\n        [ 1.7643e-01, -4.2655e-02, -1.0613e-01, -1.5217e-01, -5.6248e-02,\n          3.4766e-01,  1.3185e-02,  9.6886e-02],\n        [-3.0287e-01, -3.0330e-01,  1.4130e-01, -3.3053e-01, -2.8253e-02,\n          7.6791e-03, -1.9917e-01, -6.4894e-02],\n        [ 1.7048e-01, -1.1456e-02, -3.5070e-01,  3.1869e-01, -1.6723e-02,\n          1.4954e-02,  3.2226e-01,  3.1610e-01],\n        [-2.8667e-01,  6.1158e-02, -8.5608e-02, -1.0359e-01, -5.8955e-02,\n         -6.3572e-02, -1.4961e-01, -3.3190e-01],\n        [-6.3548e-02,  3.2301e-01, -9.6857e-03,  2.8545e-01,  3.4902e-01,\n          1.3476e-01, -2.0855e-01, -2.5091e-01],\n        [ 3.8604e-02, -2.3463e-01, -1.1033e-01, -1.1916e-01, -4.2801e-02,\n          3.3606e-01,  1.8627e-01, -1.5139e-01],\n        [-2.0452e-01,  2.0080e-01, -3.1074e-01,  6.5332e-02,  8.2593e-02,\n          3.8058e-02, -1.4666e-01, -2.2311e-01],\n        [-1.3417e-01, -1.2143e-01,  8.6177e-02,  1.4219e-01, -1.4612e-01,\n          2.0934e-01, -2.2825e-01,  1.2905e-04],\n        [ 8.1945e-02,  1.7801e-01, -3.1624e-01, -1.6957e-01, -2.8852e-01,\n         -2.9658e-01, -1.4218e-01,  1.1590e-01],\n        [ 3.4565e-01,  2.7752e-01,  3.0347e-01, -8.1984e-02, -3.3272e-01,\n         -3.0331e-01,  4.1344e-02,  3.4502e-01],\n        [ 3.3197e-03,  1.7292e-01,  9.7256e-02, -9.9322e-02,  1.3690e-01,\n         -4.1071e-02,  3.4058e-01,  3.2138e-01],\n        [ 1.6566e-01, -1.2844e-01, -9.5695e-03, -2.7877e-01, -2.3883e-01,\n          3.5097e-01,  1.9676e-01,  2.5003e-01],\n        [ 6.8135e-03, -6.9779e-02,  1.3516e-02,  3.3874e-01,  1.8592e-01,\n         -2.2795e-01, -2.2452e-01, -1.4033e-02],\n        [-1.7843e-01,  6.2761e-02, -2.8199e-01, -6.2544e-02,  2.8933e-01,\n         -3.1152e-02,  1.1239e-01,  9.0107e-02],\n        [-1.8605e-02,  1.1160e-02,  2.9108e-01, -2.3119e-02,  7.8654e-03,\n          1.7732e-01, -1.9641e-01,  5.3804e-02],\n        [ 1.8272e-01,  1.9973e-03,  2.7696e-01,  6.1318e-03, -1.0091e-01,\n         -2.8226e-01,  6.7927e-02, -2.6073e-01],\n        [-3.4040e-01, -1.6326e-02,  1.3601e-01, -7.6393e-02,  5.2695e-02,\n         -1.5092e-01,  1.0609e-01,  3.9650e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1067,  0.0402,  0.0527,  0.0040, -0.1030, -0.0041, -0.0869,  0.1699,\n         0.0851, -0.0753,  0.0487,  0.0127, -0.1716,  0.1190, -0.1281, -0.1436],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 9.1703e-02,  1.0776e-01,  4.2074e-03,  3.9473e-02,  1.1829e-01,\n         -1.2617e-01,  9.7867e-02,  8.6051e-02, -5.9360e-02, -4.3515e-02,\n          1.0994e-01,  7.2455e-02,  1.6652e-01,  1.2496e-01, -4.6849e-03,\n          4.7281e-03, -1.1943e-01,  1.4923e-01,  1.4671e-01,  1.2805e-01,\n         -1.1606e-01,  1.0841e-01,  1.5857e-01, -3.1877e-02,  1.4885e-01,\n          1.5422e-02,  5.7689e-03, -1.1289e-01, -4.4387e-03,  1.1487e-01,\n          5.1336e-02,  1.0246e-01],\n        [ 1.6999e-01,  8.2975e-02,  7.0293e-02, -5.3916e-02,  3.0954e-02,\n          1.2821e-01, -3.7339e-02,  1.1760e-02,  1.1512e-01,  1.1144e-01,\n         -1.0549e-01, -3.2825e-02, -1.6165e-02,  7.6322e-03,  2.7737e-02,\n          1.1556e-01, -6.5012e-02, -1.2360e-01, -4.4142e-02,  1.4165e-01,\n          4.5279e-02, -7.1258e-02, -1.7255e-01, -7.0664e-02, -8.2897e-02,\n         -1.5294e-01,  8.0374e-02,  2.3894e-02,  7.6145e-02,  1.1625e-01,\n          1.4092e-01, -1.4151e-01],\n        [-1.3291e-04, -3.4909e-02,  4.8234e-02, -5.0553e-02,  1.5456e-01,\n         -4.5416e-02,  7.9699e-02, -1.4494e-01,  1.3778e-01,  3.5475e-02,\n         -1.0980e-01,  1.0846e-01, -1.7502e-01,  1.1644e-01,  1.7056e-01,\n          8.4590e-02, -1.1135e-01, -1.4798e-02, -1.7073e-01, -1.7548e-01,\n          4.0135e-02,  9.9453e-02,  1.4266e-01,  2.1192e-02,  1.4793e-01,\n         -1.5883e-01, -7.4794e-02,  7.9324e-02, -3.6585e-02,  5.8177e-02,\n         -4.4321e-02,  1.6009e-01],\n        [ 1.0765e-01,  1.7154e-01, -9.5391e-02,  3.4073e-02, -6.1850e-02,\n         -9.0466e-02, -1.4889e-01,  1.4262e-01,  9.6841e-02,  1.6613e-01,\n         -5.6093e-03, -1.3287e-01, -1.4274e-01, -1.0860e-01,  8.9851e-02,\n          8.6762e-02, -1.4845e-01,  1.0203e-01,  1.3727e-01, -1.7047e-01,\n          1.2762e-04,  4.6605e-02, -2.2505e-03, -8.0119e-02, -9.5472e-02,\n         -1.1159e-01, -1.5904e-01, -9.9183e-02, -1.0154e-01,  1.3139e-02,\n         -1.2996e-01, -6.5011e-02],\n        [ 1.4205e-02, -1.1698e-01,  1.1052e-01, -1.4811e-02, -1.4466e-01,\n          1.3645e-01, -1.6877e-01, -1.2055e-02, -1.5093e-01,  1.3574e-01,\n         -1.0137e-01,  5.6422e-02, -3.2196e-02, -1.4257e-01,  3.9182e-03,\n          1.7116e-01, -2.0489e-02, -3.4265e-02,  1.6410e-01,  1.2398e-01,\n         -1.5604e-01,  6.9602e-02, -4.2324e-02,  3.3143e-02, -1.7426e-01,\n          2.3392e-02,  1.1199e-01, -1.7459e-01,  3.6227e-02, -1.0002e-01,\n          5.3883e-02, -6.9468e-02],\n        [ 1.3663e-01,  1.2365e-01, -2.8089e-04,  1.5873e-01, -8.5946e-02,\n         -5.9343e-02, -1.5850e-01,  2.3085e-02,  1.7677e-01,  1.5739e-01,\n         -1.5354e-01, -1.0057e-01,  1.4756e-01,  1.0286e-01, -3.4257e-03,\n         -6.9149e-02,  1.3177e-01, -1.6644e-01,  1.1313e-01, -7.8890e-02,\n         -3.2262e-02,  1.7168e-01, -8.9356e-02, -1.6454e-01, -1.9970e-02,\n          6.6945e-02,  1.6236e-01,  6.3276e-02, -1.0428e-03, -1.0314e-01,\n         -9.5815e-02,  1.0606e-01],\n        [ 7.0872e-02, -8.8701e-03, -4.6622e-02,  9.8133e-02,  1.2560e-01,\n         -8.0659e-02,  7.2162e-02,  4.1391e-02,  1.7309e-02, -1.3089e-01,\n          1.3045e-01,  1.6641e-01,  1.0291e-01,  1.4007e-01, -1.4825e-01,\n         -6.3554e-02,  3.5769e-02, -6.5843e-02, -8.1373e-02,  2.8215e-02,\n         -1.5874e-01, -1.7083e-01, -1.4618e-01, -7.6491e-02,  1.4011e-02,\n         -8.9327e-03,  1.2924e-01,  8.3014e-02,  5.6771e-02,  1.6518e-01,\n          1.7103e-01, -3.9727e-03],\n        [ 8.2952e-02, -3.9323e-02, -1.5944e-01,  1.0046e-01,  5.3210e-02,\n         -1.6768e-01,  1.1680e-01, -1.0686e-01,  9.6120e-02, -6.8735e-02,\n         -1.6440e-02, -8.4153e-02, -3.5866e-02, -1.1704e-02, -4.5428e-02,\n          1.4805e-02, -3.0528e-02, -1.4151e-01, -8.5136e-02,  1.4020e-01,\n          2.3749e-02, -1.4365e-01, -1.0018e-01,  1.6762e-01,  9.7536e-02,\n          6.5354e-02, -3.9395e-02,  3.6543e-02, -9.3580e-02,  1.2573e-01,\n          6.0254e-02,  1.6645e-01],\n        [-1.1743e-01,  1.6961e-01, -1.6681e-01, -8.6281e-02, -1.6548e-01,\n         -7.8776e-03,  1.6084e-01, -8.6649e-02, -1.1072e-01, -1.0022e-01,\n         -8.3505e-02,  1.9599e-02,  6.8781e-02,  1.3160e-01,  4.3466e-02,\n          1.5020e-01, -8.8965e-02,  1.0318e-01,  1.5463e-01,  1.8994e-02,\n         -8.6934e-02, -1.5838e-01, -1.3940e-01, -9.8741e-02,  1.3752e-01,\n         -8.3785e-02, -1.5410e-01,  1.2864e-01, -8.0239e-02, -2.0063e-02,\n         -1.1358e-01,  8.8600e-02],\n        [-1.7118e-01,  1.1012e-01,  6.8373e-03,  1.7406e-01,  3.9441e-02,\n         -1.5384e-01, -1.5030e-01, -1.0928e-01, -1.2558e-01, -1.4884e-01,\n          1.5283e-01,  2.5301e-02, -4.9951e-02, -1.4540e-01,  1.6314e-01,\n         -7.8622e-02,  5.9030e-02, -1.2421e-01,  1.9374e-02,  3.9948e-02,\n          1.6546e-01,  8.9606e-02,  1.2066e-01, -8.9292e-02, -1.4413e-01,\n         -1.3389e-01,  1.6278e-01,  3.0773e-02, -1.1184e-01, -3.9544e-02,\n         -1.2352e-01, -1.5320e-01],\n        [-1.3828e-01,  2.5211e-02, -9.7636e-02, -1.6312e-01, -8.4098e-02,\n          1.4793e-01,  1.2248e-01, -1.0236e-02,  1.1722e-01,  7.9492e-02,\n         -4.7482e-02,  3.2040e-02, -9.6105e-02, -2.8036e-02,  7.1978e-02,\n         -1.0141e-02, -1.3437e-01, -1.5464e-01, -1.1651e-01,  2.4852e-02,\n         -4.1722e-02, -1.6210e-01,  7.2408e-02, -1.2927e-01, -6.3213e-02,\n         -5.1310e-02,  1.7010e-01,  1.6974e-01, -8.0532e-02, -1.7235e-01,\n         -3.3717e-02,  1.7143e-01],\n        [ 1.1527e-01, -1.6370e-01,  2.7004e-02, -9.7095e-02,  6.3904e-02,\n         -5.3715e-02, -2.4256e-02, -5.3414e-02,  1.2691e-01, -1.1513e-01,\n         -7.5805e-02, -7.9826e-03,  6.6982e-03,  1.6397e-01,  8.2555e-02,\n          5.7608e-03,  1.5157e-01, -6.5327e-02, -1.4648e-01, -3.6837e-02,\n          8.7552e-02,  1.8529e-02,  2.7398e-02, -9.4874e-02,  9.5832e-03,\n         -1.0723e-01, -1.0809e-03,  1.5242e-01, -1.4761e-01, -1.1888e-01,\n         -1.1224e-01, -9.9975e-02],\n        [ 1.1979e-01,  3.4582e-02, -7.9156e-02, -1.0918e-01,  1.0545e-01,\n         -1.2564e-01, -1.3963e-02,  7.0282e-02,  6.3675e-02, -1.4726e-01,\n         -1.0894e-01,  3.6378e-02,  4.8413e-02,  9.9798e-02,  3.6493e-02,\n         -2.0291e-02,  1.1917e-01, -1.7198e-01, -1.4215e-01,  2.7723e-02,\n         -1.3201e-01,  1.4256e-01,  3.9752e-02, -1.1978e-01, -1.3165e-01,\n          1.7639e-01, -2.7151e-02, -1.7117e-01, -7.3830e-02,  1.1683e-01,\n          8.1290e-02,  2.7029e-03],\n        [-6.0488e-02,  1.5647e-01, -1.5652e-01,  1.2752e-01, -1.3507e-02,\n         -1.5946e-01, -1.0045e-01,  1.0163e-01, -1.7574e-01,  1.1088e-01,\n          1.1348e-01, -1.6075e-01,  2.0606e-02, -6.1305e-02,  2.1716e-03,\n         -1.3908e-01,  2.8269e-02,  4.0963e-02, -7.0132e-03,  1.3885e-01,\n          3.6288e-02, -1.5235e-01,  6.7550e-02, -1.1564e-01, -8.7233e-02,\n         -1.7589e-01, -5.4538e-02, -3.2056e-03,  1.3033e-01, -7.7425e-02,\n          1.4199e-01,  1.0792e-01],\n        [ 1.6434e-01,  1.4246e-01, -1.0789e-01,  1.2224e-01,  7.3572e-02,\n         -9.3029e-02, -1.0774e-01,  8.0092e-02,  4.1708e-02, -1.0224e-01,\n          1.5659e-01, -8.7703e-02,  1.0975e-02, -2.4866e-02, -3.7787e-02,\n         -3.8260e-02, -1.0539e-01,  2.8668e-02,  1.5242e-01,  3.4224e-02,\n         -1.2451e-01, -1.2056e-01,  7.6801e-02, -7.8561e-03,  4.7429e-02,\n          9.8447e-02, -1.2420e-01,  8.3989e-02, -1.2736e-01, -2.4032e-02,\n          1.3189e-01,  1.6512e-01],\n        [-7.4809e-02, -9.9894e-02,  8.4972e-02,  4.4220e-02, -2.5633e-02,\n         -2.3652e-02,  1.0107e-01,  4.3752e-02,  1.4771e-02, -1.4569e-01,\n         -1.0875e-01,  6.4882e-02, -3.4845e-02,  8.2857e-02, -1.3253e-01,\n         -1.5885e-01,  1.6340e-01, -1.7251e-01,  1.0560e-01, -4.4801e-02,\n          1.0961e-01,  4.6835e-02,  3.4706e-02, -3.1728e-02, -2.6572e-02,\n          6.4892e-02,  1.8538e-02,  4.2699e-02,  1.7049e-01,  1.5254e-01,\n          4.0038e-02,  3.7985e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0904, -0.0557, -0.0382, -0.2488,  0.1853, -0.1898, -0.1159,  0.1197],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1861, -0.0880, -0.1985, -0.2072,  0.0919,  0.1370,  0.2233,  0.0345,\n          0.1914, -0.2367,  0.0212, -0.1946,  0.0958, -0.1722,  0.1082, -0.1025],\n        [ 0.1569,  0.2288, -0.0137, -0.0156,  0.0214,  0.1484,  0.2325, -0.1543,\n          0.0591, -0.2478,  0.1685, -0.0772, -0.1768, -0.1163,  0.0568,  0.0729],\n        [-0.1735, -0.0181,  0.1828, -0.0303,  0.1512, -0.1125, -0.0244, -0.2233,\n         -0.1807, -0.0868,  0.0621,  0.0031, -0.2211,  0.1829, -0.0775, -0.2323],\n        [ 0.1525, -0.0363, -0.0867, -0.1154, -0.1169,  0.0368,  0.2206,  0.1720,\n         -0.1512,  0.0410,  0.0770, -0.0395, -0.0189,  0.2212,  0.0422,  0.0408],\n        [ 0.1836, -0.1662,  0.1191,  0.2154,  0.2093, -0.0104, -0.1544, -0.2176,\n         -0.0452, -0.2438, -0.1229, -0.0489,  0.1122, -0.0949, -0.2247, -0.0745],\n        [ 0.1655, -0.0770, -0.1947, -0.2468, -0.0685, -0.1798,  0.2042,  0.0356,\n         -0.2031, -0.0352,  0.0799,  0.2404,  0.2025,  0.0233,  0.2292, -0.0956],\n        [ 0.0915, -0.0456, -0.1571, -0.1076, -0.2277,  0.0696, -0.0739, -0.0703,\n         -0.0204,  0.0526,  0.0666, -0.1836,  0.0146,  0.0496,  0.0310, -0.0620],\n        [-0.2180,  0.2148,  0.1617,  0.2166,  0.1845, -0.1108,  0.1209,  0.0308,\n          0.2087, -0.0180, -0.1908, -0.1255,  0.0202, -0.2282, -0.1598,  0.2293]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=1, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2075], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1918,  0.0302,  0.3398, -0.0830, -0.0465,  0.1816, -0.1155, -0.1617]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	1,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 5.6039e-02, -2.4088e-01,  2.3281e-01,  2.9885e-01,  3.2729e-01,\n         -1.2424e-01,  8.4697e-02,  6.6317e-02],\n        [-1.4880e-01, -1.4073e-01,  3.0418e-01,  2.6855e-01, -9.4447e-02,\n         -1.4780e-01, -2.7524e-01,  2.3177e-01],\n        [-7.3052e-03, -1.4753e-01,  2.0444e-01, -1.9382e-01, -3.3311e-01,\n         -2.4079e-01,  1.8341e-01,  9.2724e-02],\n        [ 1.1104e-01, -1.5743e-01,  1.6128e-01, -1.0214e-01, -7.9695e-02,\n          2.8415e-01, -1.0775e-01,  3.1077e-01],\n        [-3.5536e-02,  1.5674e-01,  1.5110e-01,  2.9148e-01, -1.9610e-02,\n          3.2736e-01, -2.5566e-01,  1.8223e-01],\n        [ 2.1758e-01,  1.1691e-01, -1.7223e-01,  2.4174e-01,  1.2559e-01,\n         -1.3096e-01, -1.2448e-01, -5.5156e-02],\n        [-1.9143e-01, -2.9147e-01, -2.6807e-01,  1.0277e-01,  2.0560e-01,\n          7.5952e-02,  2.3194e-01, -2.3095e-01],\n        [-3.3597e-01,  1.8477e-01,  4.4973e-02,  1.0783e-01,  2.2487e-01,\n         -7.3607e-02,  1.4871e-01,  3.0623e-01],\n        [ 3.1815e-01,  2.9714e-01, -4.2069e-02, -1.4156e-01,  6.0988e-02,\n          2.8987e-01,  1.0388e-01, -3.0735e-01],\n        [-1.3332e-01,  4.6009e-02,  1.3846e-01,  1.1652e-02,  2.2403e-02,\n         -3.3051e-01, -2.7524e-01,  3.2330e-01],\n        [-1.5908e-01, -1.7253e-01, -8.7969e-02, -2.3558e-01, -9.6061e-02,\n         -1.9097e-01,  1.8633e-01, -1.3713e-01],\n        [ 2.0135e-01, -1.0600e-01, -3.0587e-01,  3.6436e-02,  1.9551e-01,\n          6.3763e-02,  2.1878e-01,  1.8507e-01],\n        [ 1.0431e-01, -2.2054e-01,  1.5728e-02,  4.3528e-02,  5.4537e-02,\n         -1.4863e-01, -1.3071e-02,  6.5946e-02],\n        [ 2.2215e-01,  2.9386e-01, -2.0107e-01, -1.5947e-01,  7.9206e-02,\n         -1.6781e-01,  2.6672e-01,  3.2982e-01],\n        [-7.8601e-02,  3.3848e-01, -3.3101e-01,  8.2950e-02,  1.9409e-01,\n          2.3523e-01,  1.8449e-02, -3.0639e-01],\n        [ 1.7643e-01, -4.2655e-02, -1.0613e-01, -1.5217e-01, -5.6248e-02,\n          3.4766e-01,  1.3185e-02,  9.6886e-02],\n        [-3.0287e-01, -3.0330e-01,  1.4130e-01, -3.3053e-01, -2.8253e-02,\n          7.6791e-03, -1.9917e-01, -6.4894e-02],\n        [ 1.7048e-01, -1.1456e-02, -3.5070e-01,  3.1869e-01, -1.6723e-02,\n          1.4954e-02,  3.2226e-01,  3.1610e-01],\n        [-2.8667e-01,  6.1158e-02, -8.5608e-02, -1.0359e-01, -5.8955e-02,\n         -6.3572e-02, -1.4961e-01, -3.3190e-01],\n        [-6.3548e-02,  3.2301e-01, -9.6857e-03,  2.8545e-01,  3.4902e-01,\n          1.3476e-01, -2.0855e-01, -2.5091e-01],\n        [ 3.8604e-02, -2.3463e-01, -1.1033e-01, -1.1916e-01, -4.2801e-02,\n          3.3606e-01,  1.8627e-01, -1.5139e-01],\n        [-2.0452e-01,  2.0080e-01, -3.1074e-01,  6.5332e-02,  8.2593e-02,\n          3.8058e-02, -1.4666e-01, -2.2311e-01],\n        [-1.3417e-01, -1.2143e-01,  8.6177e-02,  1.4219e-01, -1.4612e-01,\n          2.0934e-01, -2.2825e-01,  1.2905e-04],\n        [ 8.1945e-02,  1.7801e-01, -3.1624e-01, -1.6957e-01, -2.8852e-01,\n         -2.9658e-01, -1.4218e-01,  1.1590e-01],\n        [ 3.4565e-01,  2.7752e-01,  3.0347e-01, -8.1984e-02, -3.3272e-01,\n         -3.0331e-01,  4.1344e-02,  3.4502e-01],\n        [ 3.3197e-03,  1.7292e-01,  9.7256e-02, -9.9322e-02,  1.3690e-01,\n         -4.1071e-02,  3.4058e-01,  3.2138e-01],\n        [ 1.6566e-01, -1.2844e-01, -9.5695e-03, -2.7877e-01, -2.3883e-01,\n          3.5097e-01,  1.9676e-01,  2.5003e-01],\n        [ 6.8135e-03, -6.9779e-02,  1.3516e-02,  3.3874e-01,  1.8592e-01,\n         -2.2795e-01, -2.2452e-01, -1.4033e-02],\n        [-1.7843e-01,  6.2761e-02, -2.8199e-01, -6.2544e-02,  2.8933e-01,\n         -3.1152e-02,  1.1239e-01,  9.0107e-02],\n        [-1.8605e-02,  1.1160e-02,  2.9108e-01, -2.3119e-02,  7.8654e-03,\n          1.7732e-01, -1.9641e-01,  5.3804e-02],\n        [ 1.8272e-01,  1.9973e-03,  2.7696e-01,  6.1318e-03, -1.0091e-01,\n         -2.8226e-01,  6.7927e-02, -2.6073e-01],\n        [-3.4040e-01, -1.6326e-02,  1.3601e-01, -7.6393e-02,  5.2695e-02,\n         -1.5092e-01,  1.0609e-01,  3.9650e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2008,  0.2567, -0.0703,  0.2381,  0.2650, -0.1403, -0.0516, -0.2952,\n         0.2965,  0.1922,  0.2376, -0.1885, -0.0487,  0.1019, -0.1664, -0.0752,\n        -0.2658,  0.0511,  0.2011, -0.2506,  0.3154,  0.1875,  0.2373,  0.0921,\n        -0.2333, -0.1707,  0.1462, -0.3416, -0.1939, -0.2520, -0.2207,  0.3043],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 9.1703e-02,  1.0776e-01,  4.2074e-03,  3.9473e-02,  1.1829e-01,\n         -1.2617e-01,  9.7867e-02,  8.6051e-02, -5.9360e-02, -4.3515e-02,\n          1.0994e-01,  7.2455e-02,  1.6652e-01,  1.2496e-01, -4.6849e-03,\n          4.7281e-03, -1.1943e-01,  1.4923e-01,  1.4671e-01,  1.2805e-01,\n         -1.1606e-01,  1.0841e-01,  1.5857e-01, -3.1877e-02,  1.4885e-01,\n          1.5422e-02,  5.7689e-03, -1.1289e-01, -4.4387e-03,  1.1487e-01,\n          5.1336e-02,  1.0246e-01],\n        [ 1.6999e-01,  8.2975e-02,  7.0293e-02, -5.3916e-02,  3.0954e-02,\n          1.2821e-01, -3.7339e-02,  1.1760e-02,  1.1512e-01,  1.1144e-01,\n         -1.0549e-01, -3.2825e-02, -1.6165e-02,  7.6322e-03,  2.7737e-02,\n          1.1556e-01, -6.5012e-02, -1.2360e-01, -4.4142e-02,  1.4165e-01,\n          4.5279e-02, -7.1258e-02, -1.7255e-01, -7.0664e-02, -8.2897e-02,\n         -1.5294e-01,  8.0374e-02,  2.3894e-02,  7.6145e-02,  1.1625e-01,\n          1.4092e-01, -1.4151e-01],\n        [-1.3291e-04, -3.4909e-02,  4.8234e-02, -5.0553e-02,  1.5456e-01,\n         -4.5416e-02,  7.9699e-02, -1.4494e-01,  1.3778e-01,  3.5475e-02,\n         -1.0980e-01,  1.0846e-01, -1.7502e-01,  1.1644e-01,  1.7056e-01,\n          8.4590e-02, -1.1135e-01, -1.4798e-02, -1.7073e-01, -1.7548e-01,\n          4.0135e-02,  9.9453e-02,  1.4266e-01,  2.1192e-02,  1.4793e-01,\n         -1.5883e-01, -7.4794e-02,  7.9324e-02, -3.6585e-02,  5.8177e-02,\n         -4.4321e-02,  1.6009e-01],\n        [ 1.0765e-01,  1.7154e-01, -9.5391e-02,  3.4073e-02, -6.1850e-02,\n         -9.0466e-02, -1.4889e-01,  1.4262e-01,  9.6841e-02,  1.6613e-01,\n         -5.6093e-03, -1.3287e-01, -1.4274e-01, -1.0860e-01,  8.9851e-02,\n          8.6762e-02, -1.4845e-01,  1.0203e-01,  1.3727e-01, -1.7047e-01,\n          1.2762e-04,  4.6605e-02, -2.2505e-03, -8.0119e-02, -9.5472e-02,\n         -1.1159e-01, -1.5904e-01, -9.9183e-02, -1.0154e-01,  1.3139e-02,\n         -1.2996e-01, -6.5011e-02],\n        [ 1.4205e-02, -1.1698e-01,  1.1052e-01, -1.4811e-02, -1.4466e-01,\n          1.3645e-01, -1.6877e-01, -1.2055e-02, -1.5093e-01,  1.3574e-01,\n         -1.0137e-01,  5.6422e-02, -3.2196e-02, -1.4257e-01,  3.9182e-03,\n          1.7116e-01, -2.0489e-02, -3.4265e-02,  1.6410e-01,  1.2398e-01,\n         -1.5604e-01,  6.9602e-02, -4.2324e-02,  3.3143e-02, -1.7426e-01,\n          2.3392e-02,  1.1199e-01, -1.7459e-01,  3.6227e-02, -1.0002e-01,\n          5.3883e-02, -6.9468e-02],\n        [ 1.3663e-01,  1.2365e-01, -2.8089e-04,  1.5873e-01, -8.5946e-02,\n         -5.9343e-02, -1.5850e-01,  2.3085e-02,  1.7677e-01,  1.5739e-01,\n         -1.5354e-01, -1.0057e-01,  1.4756e-01,  1.0286e-01, -3.4257e-03,\n         -6.9149e-02,  1.3177e-01, -1.6644e-01,  1.1313e-01, -7.8890e-02,\n         -3.2262e-02,  1.7168e-01, -8.9356e-02, -1.6454e-01, -1.9970e-02,\n          6.6945e-02,  1.6236e-01,  6.3276e-02, -1.0428e-03, -1.0314e-01,\n         -9.5815e-02,  1.0606e-01],\n        [ 7.0872e-02, -8.8701e-03, -4.6622e-02,  9.8133e-02,  1.2560e-01,\n         -8.0659e-02,  7.2162e-02,  4.1391e-02,  1.7309e-02, -1.3089e-01,\n          1.3045e-01,  1.6641e-01,  1.0291e-01,  1.4007e-01, -1.4825e-01,\n         -6.3554e-02,  3.5769e-02, -6.5843e-02, -8.1373e-02,  2.8215e-02,\n         -1.5874e-01, -1.7083e-01, -1.4618e-01, -7.6491e-02,  1.4011e-02,\n         -8.9327e-03,  1.2924e-01,  8.3014e-02,  5.6771e-02,  1.6518e-01,\n          1.7103e-01, -3.9727e-03],\n        [ 8.2952e-02, -3.9323e-02, -1.5944e-01,  1.0046e-01,  5.3210e-02,\n         -1.6768e-01,  1.1680e-01, -1.0686e-01,  9.6120e-02, -6.8735e-02,\n         -1.6440e-02, -8.4153e-02, -3.5866e-02, -1.1704e-02, -4.5428e-02,\n          1.4805e-02, -3.0528e-02, -1.4151e-01, -8.5136e-02,  1.4020e-01,\n          2.3749e-02, -1.4365e-01, -1.0018e-01,  1.6762e-01,  9.7536e-02,\n          6.5354e-02, -3.9395e-02,  3.6543e-02, -9.3580e-02,  1.2573e-01,\n          6.0254e-02,  1.6645e-01],\n        [-1.1743e-01,  1.6961e-01, -1.6681e-01, -8.6281e-02, -1.6548e-01,\n         -7.8776e-03,  1.6084e-01, -8.6649e-02, -1.1072e-01, -1.0022e-01,\n         -8.3505e-02,  1.9599e-02,  6.8781e-02,  1.3160e-01,  4.3466e-02,\n          1.5020e-01, -8.8965e-02,  1.0318e-01,  1.5463e-01,  1.8994e-02,\n         -8.6934e-02, -1.5838e-01, -1.3940e-01, -9.8741e-02,  1.3752e-01,\n         -8.3785e-02, -1.5410e-01,  1.2864e-01, -8.0239e-02, -2.0063e-02,\n         -1.1358e-01,  8.8600e-02],\n        [-1.7118e-01,  1.1012e-01,  6.8373e-03,  1.7406e-01,  3.9441e-02,\n         -1.5384e-01, -1.5030e-01, -1.0928e-01, -1.2558e-01, -1.4884e-01,\n          1.5283e-01,  2.5301e-02, -4.9951e-02, -1.4540e-01,  1.6314e-01,\n         -7.8622e-02,  5.9030e-02, -1.2421e-01,  1.9374e-02,  3.9948e-02,\n          1.6546e-01,  8.9606e-02,  1.2066e-01, -8.9292e-02, -1.4413e-01,\n         -1.3389e-01,  1.6278e-01,  3.0773e-02, -1.1184e-01, -3.9544e-02,\n         -1.2352e-01, -1.5320e-01],\n        [-1.3828e-01,  2.5211e-02, -9.7636e-02, -1.6312e-01, -8.4098e-02,\n          1.4793e-01,  1.2248e-01, -1.0236e-02,  1.1722e-01,  7.9492e-02,\n         -4.7482e-02,  3.2040e-02, -9.6105e-02, -2.8036e-02,  7.1978e-02,\n         -1.0141e-02, -1.3437e-01, -1.5464e-01, -1.1651e-01,  2.4852e-02,\n         -4.1722e-02, -1.6210e-01,  7.2408e-02, -1.2927e-01, -6.3213e-02,\n         -5.1310e-02,  1.7010e-01,  1.6974e-01, -8.0532e-02, -1.7235e-01,\n         -3.3717e-02,  1.7143e-01],\n        [ 1.1527e-01, -1.6370e-01,  2.7004e-02, -9.7095e-02,  6.3904e-02,\n         -5.3715e-02, -2.4256e-02, -5.3414e-02,  1.2691e-01, -1.1513e-01,\n         -7.5805e-02, -7.9826e-03,  6.6982e-03,  1.6397e-01,  8.2555e-02,\n          5.7608e-03,  1.5157e-01, -6.5327e-02, -1.4648e-01, -3.6837e-02,\n          8.7552e-02,  1.8529e-02,  2.7398e-02, -9.4874e-02,  9.5832e-03,\n         -1.0723e-01, -1.0809e-03,  1.5242e-01, -1.4761e-01, -1.1888e-01,\n         -1.1224e-01, -9.9975e-02],\n        [ 1.1979e-01,  3.4582e-02, -7.9156e-02, -1.0918e-01,  1.0545e-01,\n         -1.2564e-01, -1.3963e-02,  7.0282e-02,  6.3675e-02, -1.4726e-01,\n         -1.0894e-01,  3.6378e-02,  4.8413e-02,  9.9798e-02,  3.6493e-02,\n         -2.0291e-02,  1.1917e-01, -1.7198e-01, -1.4215e-01,  2.7723e-02,\n         -1.3201e-01,  1.4256e-01,  3.9752e-02, -1.1978e-01, -1.3165e-01,\n          1.7639e-01, -2.7151e-02, -1.7117e-01, -7.3830e-02,  1.1683e-01,\n          8.1290e-02,  2.7029e-03],\n        [-6.0488e-02,  1.5647e-01, -1.5652e-01,  1.2752e-01, -1.3507e-02,\n         -1.5946e-01, -1.0045e-01,  1.0163e-01, -1.7574e-01,  1.1088e-01,\n          1.1348e-01, -1.6075e-01,  2.0606e-02, -6.1305e-02,  2.1716e-03,\n         -1.3908e-01,  2.8269e-02,  4.0963e-02, -7.0132e-03,  1.3885e-01,\n          3.6288e-02, -1.5235e-01,  6.7550e-02, -1.1564e-01, -8.7233e-02,\n         -1.7589e-01, -5.4538e-02, -3.2056e-03,  1.3033e-01, -7.7425e-02,\n          1.4199e-01,  1.0792e-01],\n        [ 1.6434e-01,  1.4246e-01, -1.0789e-01,  1.2224e-01,  7.3572e-02,\n         -9.3029e-02, -1.0774e-01,  8.0092e-02,  4.1708e-02, -1.0224e-01,\n          1.5659e-01, -8.7703e-02,  1.0975e-02, -2.4866e-02, -3.7787e-02,\n         -3.8260e-02, -1.0539e-01,  2.8668e-02,  1.5242e-01,  3.4224e-02,\n         -1.2451e-01, -1.2056e-01,  7.6801e-02, -7.8561e-03,  4.7429e-02,\n          9.8447e-02, -1.2420e-01,  8.3989e-02, -1.2736e-01, -2.4032e-02,\n          1.3189e-01,  1.6512e-01],\n        [-7.4809e-02, -9.9894e-02,  8.4972e-02,  4.4220e-02, -2.5633e-02,\n         -2.3652e-02,  1.0107e-01,  4.3752e-02,  1.4771e-02, -1.4569e-01,\n         -1.0875e-01,  6.4882e-02, -3.4845e-02,  8.2857e-02, -1.3253e-01,\n         -1.5885e-01,  1.6340e-01, -1.7251e-01,  1.0560e-01, -4.4801e-02,\n          1.0961e-01,  4.6835e-02,  3.4706e-02, -3.1728e-02, -2.6572e-02,\n          6.4892e-02,  1.8538e-02,  4.2699e-02,  1.7049e-01,  1.5254e-01,\n          4.0038e-02,  3.7985e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1067,  0.0402,  0.0527,  0.0040, -0.1030, -0.0041, -0.0869,  0.1699,\n         0.0851, -0.0753,  0.0487,  0.0127, -0.1716,  0.1190, -0.1281, -0.1436],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1861, -0.0880, -0.1985, -0.2072,  0.0919,  0.1370,  0.2233,  0.0345,\n          0.1914, -0.2367,  0.0212, -0.1946,  0.0958, -0.1722,  0.1082, -0.1025],\n        [ 0.1569,  0.2288, -0.0137, -0.0156,  0.0214,  0.1484,  0.2325, -0.1543,\n          0.0591, -0.2478,  0.1685, -0.0772, -0.1768, -0.1163,  0.0568,  0.0729],\n        [-0.1735, -0.0181,  0.1828, -0.0303,  0.1512, -0.1125, -0.0244, -0.2233,\n         -0.1807, -0.0868,  0.0621,  0.0031, -0.2211,  0.1829, -0.0775, -0.2323],\n        [ 0.1525, -0.0363, -0.0867, -0.1154, -0.1169,  0.0368,  0.2206,  0.1720,\n         -0.1512,  0.0410,  0.0770, -0.0395, -0.0189,  0.2212,  0.0422,  0.0408],\n        [ 0.1836, -0.1662,  0.1191,  0.2154,  0.2093, -0.0104, -0.1544, -0.2176,\n         -0.0452, -0.2438, -0.1229, -0.0489,  0.1122, -0.0949, -0.2247, -0.0745],\n        [ 0.1655, -0.0770, -0.1947, -0.2468, -0.0685, -0.1798,  0.2042,  0.0356,\n         -0.2031, -0.0352,  0.0799,  0.2404,  0.2025,  0.0233,  0.2292, -0.0956],\n        [ 0.0915, -0.0456, -0.1571, -0.1076, -0.2277,  0.0696, -0.0739, -0.0703,\n         -0.0204,  0.0526,  0.0666, -0.1836,  0.0146,  0.0496,  0.0310, -0.0620],\n        [-0.2180,  0.2148,  0.1617,  0.2166,  0.1845, -0.1108,  0.1209,  0.0308,\n          0.2087, -0.0180, -0.1908, -0.1255,  0.0202, -0.2282, -0.1598,  0.2293]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0904, -0.0557, -0.0382, -0.2488,  0.1853, -0.1898, -0.1159,  0.1197],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1918,  0.0302,  0.3398, -0.0830, -0.0465,  0.1816, -0.1155, -0.1617]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2075], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7bfc9e5e1110>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2008,  0.2567, -0.0703,  0.2381,  0.2650, -0.1403, -0.0516, -0.2952,\n         0.2965,  0.1922,  0.2376, -0.1885, -0.0487,  0.1019, -0.1664, -0.0752,\n        -0.2658,  0.0511,  0.2011, -0.2506,  0.3154,  0.1875,  0.2373,  0.0921,\n        -0.2333, -0.1707,  0.1462, -0.3416, -0.1939, -0.2520, -0.2207,  0.3043],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 5.6039e-02, -2.4088e-01,  2.3281e-01,  2.9885e-01,  3.2729e-01,\n         -1.2424e-01,  8.4697e-02,  6.6317e-02],\n        [-1.4880e-01, -1.4073e-01,  3.0418e-01,  2.6855e-01, -9.4447e-02,\n         -1.4780e-01, -2.7524e-01,  2.3177e-01],\n        [-7.3052e-03, -1.4753e-01,  2.0444e-01, -1.9382e-01, -3.3311e-01,\n         -2.4079e-01,  1.8341e-01,  9.2724e-02],\n        [ 1.1104e-01, -1.5743e-01,  1.6128e-01, -1.0214e-01, -7.9695e-02,\n          2.8415e-01, -1.0775e-01,  3.1077e-01],\n        [-3.5536e-02,  1.5674e-01,  1.5110e-01,  2.9148e-01, -1.9610e-02,\n          3.2736e-01, -2.5566e-01,  1.8223e-01],\n        [ 2.1758e-01,  1.1691e-01, -1.7223e-01,  2.4174e-01,  1.2559e-01,\n         -1.3096e-01, -1.2448e-01, -5.5156e-02],\n        [-1.9143e-01, -2.9147e-01, -2.6807e-01,  1.0277e-01,  2.0560e-01,\n          7.5952e-02,  2.3194e-01, -2.3095e-01],\n        [-3.3597e-01,  1.8477e-01,  4.4973e-02,  1.0783e-01,  2.2487e-01,\n         -7.3607e-02,  1.4871e-01,  3.0623e-01],\n        [ 3.1815e-01,  2.9714e-01, -4.2069e-02, -1.4156e-01,  6.0988e-02,\n          2.8987e-01,  1.0388e-01, -3.0735e-01],\n        [-1.3332e-01,  4.6009e-02,  1.3846e-01,  1.1652e-02,  2.2403e-02,\n         -3.3051e-01, -2.7524e-01,  3.2330e-01],\n        [-1.5908e-01, -1.7253e-01, -8.7969e-02, -2.3558e-01, -9.6061e-02,\n         -1.9097e-01,  1.8633e-01, -1.3713e-01],\n        [ 2.0135e-01, -1.0600e-01, -3.0587e-01,  3.6436e-02,  1.9551e-01,\n          6.3763e-02,  2.1878e-01,  1.8507e-01],\n        [ 1.0431e-01, -2.2054e-01,  1.5728e-02,  4.3528e-02,  5.4537e-02,\n         -1.4863e-01, -1.3071e-02,  6.5946e-02],\n        [ 2.2215e-01,  2.9386e-01, -2.0107e-01, -1.5947e-01,  7.9206e-02,\n         -1.6781e-01,  2.6672e-01,  3.2982e-01],\n        [-7.8601e-02,  3.3848e-01, -3.3101e-01,  8.2950e-02,  1.9409e-01,\n          2.3523e-01,  1.8449e-02, -3.0639e-01],\n        [ 1.7643e-01, -4.2655e-02, -1.0613e-01, -1.5217e-01, -5.6248e-02,\n          3.4766e-01,  1.3185e-02,  9.6886e-02],\n        [-3.0287e-01, -3.0330e-01,  1.4130e-01, -3.3053e-01, -2.8253e-02,\n          7.6791e-03, -1.9917e-01, -6.4894e-02],\n        [ 1.7048e-01, -1.1456e-02, -3.5070e-01,  3.1869e-01, -1.6723e-02,\n          1.4954e-02,  3.2226e-01,  3.1610e-01],\n        [-2.8667e-01,  6.1158e-02, -8.5608e-02, -1.0359e-01, -5.8955e-02,\n         -6.3572e-02, -1.4961e-01, -3.3190e-01],\n        [-6.3548e-02,  3.2301e-01, -9.6857e-03,  2.8545e-01,  3.4902e-01,\n          1.3476e-01, -2.0855e-01, -2.5091e-01],\n        [ 3.8604e-02, -2.3463e-01, -1.1033e-01, -1.1916e-01, -4.2801e-02,\n          3.3606e-01,  1.8627e-01, -1.5139e-01],\n        [-2.0452e-01,  2.0080e-01, -3.1074e-01,  6.5332e-02,  8.2593e-02,\n          3.8058e-02, -1.4666e-01, -2.2311e-01],\n        [-1.3417e-01, -1.2143e-01,  8.6177e-02,  1.4219e-01, -1.4612e-01,\n          2.0934e-01, -2.2825e-01,  1.2905e-04],\n        [ 8.1945e-02,  1.7801e-01, -3.1624e-01, -1.6957e-01, -2.8852e-01,\n         -2.9658e-01, -1.4218e-01,  1.1590e-01],\n        [ 3.4565e-01,  2.7752e-01,  3.0347e-01, -8.1984e-02, -3.3272e-01,\n         -3.0331e-01,  4.1344e-02,  3.4502e-01],\n        [ 3.3197e-03,  1.7292e-01,  9.7256e-02, -9.9322e-02,  1.3690e-01,\n         -4.1071e-02,  3.4058e-01,  3.2138e-01],\n        [ 1.6566e-01, -1.2844e-01, -9.5695e-03, -2.7877e-01, -2.3883e-01,\n          3.5097e-01,  1.9676e-01,  2.5003e-01],\n        [ 6.8135e-03, -6.9779e-02,  1.3516e-02,  3.3874e-01,  1.8592e-01,\n         -2.2795e-01, -2.2452e-01, -1.4033e-02],\n        [-1.7843e-01,  6.2761e-02, -2.8199e-01, -6.2544e-02,  2.8933e-01,\n         -3.1152e-02,  1.1239e-01,  9.0107e-02],\n        [-1.8605e-02,  1.1160e-02,  2.9108e-01, -2.3119e-02,  7.8654e-03,\n          1.7732e-01, -1.9641e-01,  5.3804e-02],\n        [ 1.8272e-01,  1.9973e-03,  2.7696e-01,  6.1318e-03, -1.0091e-01,\n         -2.8226e-01,  6.7927e-02, -2.6073e-01],\n        [-3.4040e-01, -1.6326e-02,  1.3601e-01, -7.6393e-02,  5.2695e-02,\n         -1.5092e-01,  1.0609e-01,  3.9650e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1067,  0.0402,  0.0527,  0.0040, -0.1030, -0.0041, -0.0869,  0.1699,\n         0.0851, -0.0753,  0.0487,  0.0127, -0.1716,  0.1190, -0.1281, -0.1436],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 9.1703e-02,  1.0776e-01,  4.2074e-03,  3.9473e-02,  1.1829e-01,\n         -1.2617e-01,  9.7867e-02,  8.6051e-02, -5.9360e-02, -4.3515e-02,\n          1.0994e-01,  7.2455e-02,  1.6652e-01,  1.2496e-01, -4.6849e-03,\n          4.7281e-03, -1.1943e-01,  1.4923e-01,  1.4671e-01,  1.2805e-01,\n         -1.1606e-01,  1.0841e-01,  1.5857e-01, -3.1877e-02,  1.4885e-01,\n          1.5422e-02,  5.7689e-03, -1.1289e-01, -4.4387e-03,  1.1487e-01,\n          5.1336e-02,  1.0246e-01],\n        [ 1.6999e-01,  8.2975e-02,  7.0293e-02, -5.3916e-02,  3.0954e-02,\n          1.2821e-01, -3.7339e-02,  1.1760e-02,  1.1512e-01,  1.1144e-01,\n         -1.0549e-01, -3.2825e-02, -1.6165e-02,  7.6322e-03,  2.7737e-02,\n          1.1556e-01, -6.5012e-02, -1.2360e-01, -4.4142e-02,  1.4165e-01,\n          4.5279e-02, -7.1258e-02, -1.7255e-01, -7.0664e-02, -8.2897e-02,\n         -1.5294e-01,  8.0374e-02,  2.3894e-02,  7.6145e-02,  1.1625e-01,\n          1.4092e-01, -1.4151e-01],\n        [-1.3291e-04, -3.4909e-02,  4.8234e-02, -5.0553e-02,  1.5456e-01,\n         -4.5416e-02,  7.9699e-02, -1.4494e-01,  1.3778e-01,  3.5475e-02,\n         -1.0980e-01,  1.0846e-01, -1.7502e-01,  1.1644e-01,  1.7056e-01,\n          8.4590e-02, -1.1135e-01, -1.4798e-02, -1.7073e-01, -1.7548e-01,\n          4.0135e-02,  9.9453e-02,  1.4266e-01,  2.1192e-02,  1.4793e-01,\n         -1.5883e-01, -7.4794e-02,  7.9324e-02, -3.6585e-02,  5.8177e-02,\n         -4.4321e-02,  1.6009e-01],\n        [ 1.0765e-01,  1.7154e-01, -9.5391e-02,  3.4073e-02, -6.1850e-02,\n         -9.0466e-02, -1.4889e-01,  1.4262e-01,  9.6841e-02,  1.6613e-01,\n         -5.6093e-03, -1.3287e-01, -1.4274e-01, -1.0860e-01,  8.9851e-02,\n          8.6762e-02, -1.4845e-01,  1.0203e-01,  1.3727e-01, -1.7047e-01,\n          1.2762e-04,  4.6605e-02, -2.2505e-03, -8.0119e-02, -9.5472e-02,\n         -1.1159e-01, -1.5904e-01, -9.9183e-02, -1.0154e-01,  1.3139e-02,\n         -1.2996e-01, -6.5011e-02],\n        [ 1.4205e-02, -1.1698e-01,  1.1052e-01, -1.4811e-02, -1.4466e-01,\n          1.3645e-01, -1.6877e-01, -1.2055e-02, -1.5093e-01,  1.3574e-01,\n         -1.0137e-01,  5.6422e-02, -3.2196e-02, -1.4257e-01,  3.9182e-03,\n          1.7116e-01, -2.0489e-02, -3.4265e-02,  1.6410e-01,  1.2398e-01,\n         -1.5604e-01,  6.9602e-02, -4.2324e-02,  3.3143e-02, -1.7426e-01,\n          2.3392e-02,  1.1199e-01, -1.7459e-01,  3.6227e-02, -1.0002e-01,\n          5.3883e-02, -6.9468e-02],\n        [ 1.3663e-01,  1.2365e-01, -2.8089e-04,  1.5873e-01, -8.5946e-02,\n         -5.9343e-02, -1.5850e-01,  2.3085e-02,  1.7677e-01,  1.5739e-01,\n         -1.5354e-01, -1.0057e-01,  1.4756e-01,  1.0286e-01, -3.4257e-03,\n         -6.9149e-02,  1.3177e-01, -1.6644e-01,  1.1313e-01, -7.8890e-02,\n         -3.2262e-02,  1.7168e-01, -8.9356e-02, -1.6454e-01, -1.9970e-02,\n          6.6945e-02,  1.6236e-01,  6.3276e-02, -1.0428e-03, -1.0314e-01,\n         -9.5815e-02,  1.0606e-01],\n        [ 7.0872e-02, -8.8701e-03, -4.6622e-02,  9.8133e-02,  1.2560e-01,\n         -8.0659e-02,  7.2162e-02,  4.1391e-02,  1.7309e-02, -1.3089e-01,\n          1.3045e-01,  1.6641e-01,  1.0291e-01,  1.4007e-01, -1.4825e-01,\n         -6.3554e-02,  3.5769e-02, -6.5843e-02, -8.1373e-02,  2.8215e-02,\n         -1.5874e-01, -1.7083e-01, -1.4618e-01, -7.6491e-02,  1.4011e-02,\n         -8.9327e-03,  1.2924e-01,  8.3014e-02,  5.6771e-02,  1.6518e-01,\n          1.7103e-01, -3.9727e-03],\n        [ 8.2952e-02, -3.9323e-02, -1.5944e-01,  1.0046e-01,  5.3210e-02,\n         -1.6768e-01,  1.1680e-01, -1.0686e-01,  9.6120e-02, -6.8735e-02,\n         -1.6440e-02, -8.4153e-02, -3.5866e-02, -1.1704e-02, -4.5428e-02,\n          1.4805e-02, -3.0528e-02, -1.4151e-01, -8.5136e-02,  1.4020e-01,\n          2.3749e-02, -1.4365e-01, -1.0018e-01,  1.6762e-01,  9.7536e-02,\n          6.5354e-02, -3.9395e-02,  3.6543e-02, -9.3580e-02,  1.2573e-01,\n          6.0254e-02,  1.6645e-01],\n        [-1.1743e-01,  1.6961e-01, -1.6681e-01, -8.6281e-02, -1.6548e-01,\n         -7.8776e-03,  1.6084e-01, -8.6649e-02, -1.1072e-01, -1.0022e-01,\n         -8.3505e-02,  1.9599e-02,  6.8781e-02,  1.3160e-01,  4.3466e-02,\n          1.5020e-01, -8.8965e-02,  1.0318e-01,  1.5463e-01,  1.8994e-02,\n         -8.6934e-02, -1.5838e-01, -1.3940e-01, -9.8741e-02,  1.3752e-01,\n         -8.3785e-02, -1.5410e-01,  1.2864e-01, -8.0239e-02, -2.0063e-02,\n         -1.1358e-01,  8.8600e-02],\n        [-1.7118e-01,  1.1012e-01,  6.8373e-03,  1.7406e-01,  3.9441e-02,\n         -1.5384e-01, -1.5030e-01, -1.0928e-01, -1.2558e-01, -1.4884e-01,\n          1.5283e-01,  2.5301e-02, -4.9951e-02, -1.4540e-01,  1.6314e-01,\n         -7.8622e-02,  5.9030e-02, -1.2421e-01,  1.9374e-02,  3.9948e-02,\n          1.6546e-01,  8.9606e-02,  1.2066e-01, -8.9292e-02, -1.4413e-01,\n         -1.3389e-01,  1.6278e-01,  3.0773e-02, -1.1184e-01, -3.9544e-02,\n         -1.2352e-01, -1.5320e-01],\n        [-1.3828e-01,  2.5211e-02, -9.7636e-02, -1.6312e-01, -8.4098e-02,\n          1.4793e-01,  1.2248e-01, -1.0236e-02,  1.1722e-01,  7.9492e-02,\n         -4.7482e-02,  3.2040e-02, -9.6105e-02, -2.8036e-02,  7.1978e-02,\n         -1.0141e-02, -1.3437e-01, -1.5464e-01, -1.1651e-01,  2.4852e-02,\n         -4.1722e-02, -1.6210e-01,  7.2408e-02, -1.2927e-01, -6.3213e-02,\n         -5.1310e-02,  1.7010e-01,  1.6974e-01, -8.0532e-02, -1.7235e-01,\n         -3.3717e-02,  1.7143e-01],\n        [ 1.1527e-01, -1.6370e-01,  2.7004e-02, -9.7095e-02,  6.3904e-02,\n         -5.3715e-02, -2.4256e-02, -5.3414e-02,  1.2691e-01, -1.1513e-01,\n         -7.5805e-02, -7.9826e-03,  6.6982e-03,  1.6397e-01,  8.2555e-02,\n          5.7608e-03,  1.5157e-01, -6.5327e-02, -1.4648e-01, -3.6837e-02,\n          8.7552e-02,  1.8529e-02,  2.7398e-02, -9.4874e-02,  9.5832e-03,\n         -1.0723e-01, -1.0809e-03,  1.5242e-01, -1.4761e-01, -1.1888e-01,\n         -1.1224e-01, -9.9975e-02],\n        [ 1.1979e-01,  3.4582e-02, -7.9156e-02, -1.0918e-01,  1.0545e-01,\n         -1.2564e-01, -1.3963e-02,  7.0282e-02,  6.3675e-02, -1.4726e-01,\n         -1.0894e-01,  3.6378e-02,  4.8413e-02,  9.9798e-02,  3.6493e-02,\n         -2.0291e-02,  1.1917e-01, -1.7198e-01, -1.4215e-01,  2.7723e-02,\n         -1.3201e-01,  1.4256e-01,  3.9752e-02, -1.1978e-01, -1.3165e-01,\n          1.7639e-01, -2.7151e-02, -1.7117e-01, -7.3830e-02,  1.1683e-01,\n          8.1290e-02,  2.7029e-03],\n        [-6.0488e-02,  1.5647e-01, -1.5652e-01,  1.2752e-01, -1.3507e-02,\n         -1.5946e-01, -1.0045e-01,  1.0163e-01, -1.7574e-01,  1.1088e-01,\n          1.1348e-01, -1.6075e-01,  2.0606e-02, -6.1305e-02,  2.1716e-03,\n         -1.3908e-01,  2.8269e-02,  4.0963e-02, -7.0132e-03,  1.3885e-01,\n          3.6288e-02, -1.5235e-01,  6.7550e-02, -1.1564e-01, -8.7233e-02,\n         -1.7589e-01, -5.4538e-02, -3.2056e-03,  1.3033e-01, -7.7425e-02,\n          1.4199e-01,  1.0792e-01],\n        [ 1.6434e-01,  1.4246e-01, -1.0789e-01,  1.2224e-01,  7.3572e-02,\n         -9.3029e-02, -1.0774e-01,  8.0092e-02,  4.1708e-02, -1.0224e-01,\n          1.5659e-01, -8.7703e-02,  1.0975e-02, -2.4866e-02, -3.7787e-02,\n         -3.8260e-02, -1.0539e-01,  2.8668e-02,  1.5242e-01,  3.4224e-02,\n         -1.2451e-01, -1.2056e-01,  7.6801e-02, -7.8561e-03,  4.7429e-02,\n          9.8447e-02, -1.2420e-01,  8.3989e-02, -1.2736e-01, -2.4032e-02,\n          1.3189e-01,  1.6512e-01],\n        [-7.4809e-02, -9.9894e-02,  8.4972e-02,  4.4220e-02, -2.5633e-02,\n         -2.3652e-02,  1.0107e-01,  4.3752e-02,  1.4771e-02, -1.4569e-01,\n         -1.0875e-01,  6.4882e-02, -3.4845e-02,  8.2857e-02, -1.3253e-01,\n         -1.5885e-01,  1.6340e-01, -1.7251e-01,  1.0560e-01, -4.4801e-02,\n          1.0961e-01,  4.6835e-02,  3.4706e-02, -3.1728e-02, -2.6572e-02,\n          6.4892e-02,  1.8538e-02,  4.2699e-02,  1.7049e-01,  1.5254e-01,\n          4.0038e-02,  3.7985e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0904, -0.0557, -0.0382, -0.2488,  0.1853, -0.1898, -0.1159,  0.1197],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1861, -0.0880, -0.1985, -0.2072,  0.0919,  0.1370,  0.2233,  0.0345,\n          0.1914, -0.2367,  0.0212, -0.1946,  0.0958, -0.1722,  0.1082, -0.1025],\n        [ 0.1569,  0.2288, -0.0137, -0.0156,  0.0214,  0.1484,  0.2325, -0.1543,\n          0.0591, -0.2478,  0.1685, -0.0772, -0.1768, -0.1163,  0.0568,  0.0729],\n        [-0.1735, -0.0181,  0.1828, -0.0303,  0.1512, -0.1125, -0.0244, -0.2233,\n         -0.1807, -0.0868,  0.0621,  0.0031, -0.2211,  0.1829, -0.0775, -0.2323],\n        [ 0.1525, -0.0363, -0.0867, -0.1154, -0.1169,  0.0368,  0.2206,  0.1720,\n         -0.1512,  0.0410,  0.0770, -0.0395, -0.0189,  0.2212,  0.0422,  0.0408],\n        [ 0.1836, -0.1662,  0.1191,  0.2154,  0.2093, -0.0104, -0.1544, -0.2176,\n         -0.0452, -0.2438, -0.1229, -0.0489,  0.1122, -0.0949, -0.2247, -0.0745],\n        [ 0.1655, -0.0770, -0.1947, -0.2468, -0.0685, -0.1798,  0.2042,  0.0356,\n         -0.2031, -0.0352,  0.0799,  0.2404,  0.2025,  0.0233,  0.2292, -0.0956],\n        [ 0.0915, -0.0456, -0.1571, -0.1076, -0.2277,  0.0696, -0.0739, -0.0703,\n         -0.0204,  0.0526,  0.0666, -0.1836,  0.0146,  0.0496,  0.0310, -0.0620],\n        [-0.2180,  0.2148,  0.1617,  0.2166,  0.1845, -0.1108,  0.1209,  0.0308,\n          0.2087, -0.0180, -0.1908, -0.1255,  0.0202, -0.2282, -0.1598,  0.2293]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=1, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2075], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1918,  0.0302,  0.3398, -0.0830, -0.0465,  0.1816, -0.1155, -0.1617]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	1,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7bfc2363a150>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s263230000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s263230000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}