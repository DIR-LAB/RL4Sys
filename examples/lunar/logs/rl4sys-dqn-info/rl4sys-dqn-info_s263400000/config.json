{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s263400000"
    },
    "q_lr":	0.0005,
    "seed":	263400000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7879f5fc0590>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1410, -0.0103, -0.0520,  0.0235, -0.1955, -0.1424, -0.2804,  0.1421,\n         0.2305, -0.0975, -0.1323,  0.2737, -0.2674,  0.2816,  0.1328,  0.1663,\n         0.1733, -0.3296,  0.2171, -0.2264, -0.1615, -0.1973, -0.1259,  0.3449,\n         0.3056,  0.1892,  0.0535,  0.0114, -0.1967, -0.2682, -0.1550, -0.3024],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2597,  0.2170,  0.1649, -0.1229, -0.0494, -0.3065, -0.1646,  0.0532],\n        [ 0.3326, -0.2276,  0.3060,  0.0912, -0.1122, -0.2437,  0.1080,  0.3088],\n        [-0.2311, -0.0375,  0.2114, -0.1001,  0.1705,  0.0120,  0.0720, -0.3022],\n        [-0.3378, -0.2722,  0.1560,  0.2166,  0.1741,  0.0451, -0.0801,  0.0461],\n        [-0.0301, -0.3265,  0.2000, -0.3396,  0.2917, -0.3244, -0.2774, -0.0787],\n        [-0.1003,  0.1269,  0.0058,  0.2979, -0.2096,  0.2450,  0.1665,  0.1240],\n        [-0.0619, -0.1213,  0.1108, -0.1117, -0.2013, -0.0665, -0.2429,  0.2926],\n        [-0.2012, -0.1516,  0.2188, -0.0920, -0.0712, -0.1228,  0.3457,  0.1012],\n        [ 0.1589,  0.1019,  0.2712,  0.2509,  0.2783, -0.0854,  0.3130, -0.1874],\n        [ 0.2810, -0.0054, -0.1128, -0.3164, -0.2456, -0.3286, -0.2067,  0.0496],\n        [-0.1103, -0.2205,  0.2739,  0.1866,  0.1021, -0.3489,  0.2744, -0.1376],\n        [-0.0416, -0.1585, -0.2860,  0.0994, -0.3229, -0.0358,  0.0566, -0.1382],\n        [-0.2491, -0.1389, -0.0367, -0.3092, -0.1562, -0.0437,  0.1012, -0.2298],\n        [-0.2887, -0.1803, -0.1286, -0.2385, -0.3077, -0.2352, -0.3371,  0.1481],\n        [-0.0999, -0.1440,  0.1176, -0.2386,  0.3245,  0.3222, -0.3361,  0.2619],\n        [-0.0121, -0.0470,  0.0446, -0.0156,  0.1490, -0.1901,  0.0624, -0.1138],\n        [ 0.1382, -0.1277, -0.1046, -0.1484, -0.1346, -0.1597, -0.2406,  0.3140],\n        [ 0.0555, -0.0058, -0.0890,  0.1864, -0.0355,  0.1229, -0.3084,  0.3123],\n        [-0.2552, -0.2687,  0.2314,  0.0103,  0.0268,  0.0934, -0.2743, -0.2358],\n        [-0.2836,  0.0479, -0.3296, -0.1371,  0.1703, -0.1383, -0.1755,  0.3186],\n        [ 0.0378, -0.2234,  0.0428,  0.2171, -0.1067, -0.2717, -0.0221, -0.1272],\n        [ 0.1155,  0.0742, -0.1292, -0.1256, -0.0745, -0.3456, -0.3531,  0.2244],\n        [ 0.2839,  0.1685,  0.2078, -0.0435, -0.2652, -0.0726,  0.3343,  0.2695],\n        [ 0.1484,  0.1485,  0.2258, -0.3083,  0.3053,  0.3111,  0.0781, -0.2469],\n        [-0.1986,  0.2210,  0.1503,  0.3520, -0.3252, -0.0156,  0.3253,  0.2239],\n        [-0.1134, -0.2488,  0.1179, -0.1054, -0.2235, -0.2989, -0.1380,  0.3268],\n        [ 0.2968, -0.0474,  0.1964,  0.2329, -0.1702, -0.0645,  0.0556,  0.0357],\n        [ 0.0267, -0.2934, -0.0965,  0.1614,  0.2249,  0.1467,  0.0070, -0.0348],\n        [ 0.0946,  0.1259, -0.2722, -0.2259,  0.1157, -0.1907, -0.2489, -0.2332],\n        [ 0.0908, -0.2025,  0.0282, -0.2355, -0.0158, -0.2427,  0.2958, -0.3126],\n        [-0.0717,  0.2492,  0.3483, -0.1985,  0.2626,  0.3232,  0.2164,  0.1963],\n        [-0.3070,  0.3040, -0.0881, -0.2616,  0.0302,  0.2964,  0.0335, -0.3421]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 1.0491e-01,  2.7860e-02,  1.7260e-01, -1.6236e-01, -1.2137e-01,\n         8.1459e-02,  1.4896e-01,  1.3350e-01,  3.7874e-02, -8.6619e-02,\n        -3.2894e-02,  3.4230e-02, -8.6012e-02,  1.0065e-01,  2.2422e-02,\n         1.2893e-04], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 4.7685e-02,  1.6987e-01,  2.5931e-02, -1.6270e-01, -1.7584e-01,\n          5.8283e-02,  1.3581e-01, -5.2263e-02, -1.6693e-02, -1.2954e-01,\n         -2.5627e-02, -1.6250e-01,  8.2962e-02,  1.6498e-01, -1.6815e-01,\n          2.5738e-02,  1.5800e-01, -6.9563e-02,  1.1453e-01,  1.1011e-01,\n          1.2972e-01, -1.1243e-01, -1.7116e-01, -1.5419e-01,  5.9172e-03,\n          1.4459e-01, -7.2541e-02, -1.0791e-01,  9.8179e-03,  1.3681e-01,\n         -2.5849e-02, -9.4294e-02],\n        [ 1.6168e-01,  1.5289e-01,  1.4981e-01,  1.3863e-01, -7.7471e-02,\n          2.0171e-02,  4.8737e-02, -9.6011e-02, -1.1487e-01, -1.0907e-01,\n          1.7323e-01, -5.3639e-02, -1.3400e-01,  1.7366e-01,  5.0796e-02,\n          1.5287e-01, -5.6790e-02,  1.5999e-01,  1.3012e-01, -7.5917e-02,\n         -7.0038e-02, -1.6415e-02, -1.2755e-01, -1.7075e-02, -8.0079e-02,\n          8.4012e-03,  1.4559e-01, -1.0568e-01, -1.5023e-03, -1.2956e-01,\n          1.5768e-01,  8.9969e-02],\n        [-1.1662e-01,  1.3391e-01,  1.6440e-01,  6.5311e-02, -2.5001e-02,\n         -1.5008e-01, -5.2510e-02,  1.5991e-01,  5.9567e-02, -9.2755e-02,\n          9.0382e-02,  1.8272e-02, -9.5574e-02, -3.2312e-02, -1.1582e-01,\n          1.2787e-01, -6.5962e-02, -9.8359e-02,  8.5954e-02,  9.4471e-02,\n         -1.4673e-01,  1.1045e-01, -1.5861e-01, -1.7186e-01, -2.7228e-02,\n          3.6439e-02,  6.8407e-02,  1.6901e-01, -2.9195e-02,  5.8660e-02,\n         -5.0321e-02,  1.1490e-01],\n        [-6.6743e-02,  1.7633e-01,  2.8325e-03, -9.0237e-02, -9.7717e-02,\n         -1.3398e-01,  1.0307e-02, -7.3077e-02, -5.4702e-02,  1.2729e-01,\n          1.4718e-02,  1.6665e-02, -8.8815e-02, -1.5090e-01,  1.4214e-01,\n         -7.2029e-02, -4.9625e-02, -1.2922e-02, -9.3567e-02,  1.0739e-01,\n         -1.2825e-01,  1.6938e-01,  1.1545e-01,  2.8982e-02, -9.0229e-02,\n         -6.2635e-02,  1.4817e-01,  1.1682e-02,  1.1026e-01,  7.3818e-02,\n          1.7297e-01,  1.6639e-01],\n        [ 1.6125e-01, -1.3642e-01, -2.8066e-02, -4.9456e-02, -9.4186e-03,\n         -4.7730e-02, -3.9750e-02, -2.7353e-02,  1.0439e-01,  1.5631e-01,\n         -1.6274e-01, -4.1956e-02, -4.3036e-02, -6.5460e-02, -6.6034e-02,\n         -4.3515e-02,  4.2289e-02, -6.3376e-02, -1.2559e-01, -8.2407e-02,\n         -9.8130e-02, -1.3896e-01, -1.3780e-01,  3.5162e-02,  6.8091e-02,\n         -8.6101e-02,  1.6374e-01,  1.3412e-01,  1.5853e-02,  1.5933e-01,\n         -5.4276e-02, -3.5951e-02],\n        [ 1.7477e-01,  1.6624e-01,  6.8510e-05, -6.0324e-02,  1.6433e-01,\n          7.8036e-02,  1.6298e-01, -8.1065e-02,  4.1575e-02,  3.2199e-02,\n          1.4876e-01, -5.8183e-02,  9.0094e-02, -1.2809e-01,  1.4684e-01,\n          8.9183e-02,  1.3187e-01,  1.5105e-01, -1.4341e-01,  1.7156e-01,\n         -1.3579e-01,  1.3227e-01,  7.0522e-02,  1.6541e-01,  4.3191e-02,\n          8.2222e-02,  1.6007e-01,  8.0966e-02,  5.8746e-02, -1.2629e-01,\n          1.6933e-01, -7.0569e-02],\n        [-1.7530e-01,  4.1884e-02, -8.8387e-02,  1.5693e-01,  1.2848e-01,\n          5.6454e-02, -3.9351e-02,  6.7826e-02,  1.0909e-02,  1.1742e-01,\n          1.0367e-01, -9.5802e-02,  6.9771e-02, -1.7595e-01,  8.2088e-02,\n         -1.5570e-01,  1.5930e-01,  2.0352e-02, -1.5094e-01, -1.6843e-01,\n          1.0463e-01,  8.8818e-02,  3.7021e-02,  8.0684e-02, -1.2642e-01,\n         -1.2001e-01, -4.4052e-03, -3.4712e-03,  1.7082e-01, -1.4876e-01,\n         -1.2978e-01,  8.2478e-02],\n        [ 8.6909e-02,  1.6937e-01,  5.3610e-02, -3.8911e-02,  1.4021e-01,\n         -5.5807e-02, -7.5164e-02,  1.7406e-01,  1.7066e-01,  2.5193e-02,\n         -1.2596e-01,  1.2109e-01, -1.0967e-01,  1.4224e-01, -1.1698e-01,\n          2.3487e-02, -2.8358e-02, -1.2924e-01, -3.7372e-02,  3.6817e-02,\n          2.4610e-02,  2.0991e-03,  7.0340e-02,  1.3229e-02,  9.5921e-02,\n          1.7323e-01,  5.5347e-02, -1.7567e-01, -1.6185e-02,  1.4289e-01,\n          1.5063e-01,  2.2271e-02],\n        [-2.0391e-02,  3.8996e-02, -1.5646e-01,  9.3755e-02, -8.7275e-02,\n          7.5223e-03,  1.6094e-01, -1.1327e-01, -4.4193e-02,  3.9566e-02,\n         -8.3599e-02, -4.0537e-02,  8.2652e-02, -4.6656e-02, -6.7837e-02,\n         -1.3179e-01,  1.8854e-02,  1.0021e-01, -1.7039e-01,  5.9510e-02,\n          1.3755e-01,  5.9568e-02,  1.0541e-02, -3.5745e-02, -1.4702e-01,\n         -8.8804e-02, -1.3539e-01, -5.0036e-02, -7.8367e-02, -7.9993e-02,\n         -7.3121e-02,  8.8879e-02],\n        [-2.9454e-02, -1.0753e-01, -5.9584e-02, -1.6480e-01, -1.4142e-01,\n          1.0635e-02,  1.0149e-01,  1.4335e-02,  5.2760e-02,  4.4889e-02,\n          8.9578e-02, -8.5513e-02,  1.2875e-01,  6.0412e-02, -7.2137e-02,\n          1.2391e-02,  6.1316e-03,  5.7516e-02, -9.2749e-02,  1.6604e-01,\n          1.1558e-01, -8.0178e-02,  1.2814e-01,  1.0100e-01,  4.7931e-02,\n         -8.4144e-02,  1.7231e-01, -6.9435e-04, -1.1326e-01, -7.7829e-02,\n          1.6967e-01, -1.0169e-01],\n        [-1.4512e-01, -8.6519e-02, -5.6758e-03,  1.6568e-01, -6.1334e-03,\n          6.7626e-02, -1.2540e-01, -1.6980e-01, -9.0189e-03, -2.8449e-04,\n         -4.3180e-02, -8.5967e-02,  1.7949e-02, -7.2843e-02,  1.1293e-01,\n         -1.1624e-01,  5.6166e-02,  1.1026e-01, -5.8913e-02, -1.3135e-02,\n         -9.6724e-02, -1.1193e-01, -1.1028e-01,  1.1868e-01, -1.0572e-01,\n          8.0686e-03,  6.0121e-02, -2.9981e-04, -9.7591e-02, -5.6117e-02,\n         -1.5707e-01, -8.0090e-02],\n        [-4.5303e-02, -1.6450e-01, -1.7146e-01,  1.3517e-01, -5.5760e-02,\n          1.5752e-01, -1.3029e-01,  9.1203e-02,  3.7839e-03, -1.4316e-01,\n          6.7907e-02, -8.1748e-02,  5.4972e-02, -9.5101e-02,  1.2159e-01,\n          8.7843e-02, -1.0071e-01,  6.3782e-02,  8.7108e-02, -1.4629e-01,\n         -1.0811e-01, -1.2446e-01,  1.1863e-01, -1.6756e-01, -1.2313e-01,\n          4.0641e-02, -1.4168e-01,  5.7912e-02, -1.2540e-01, -1.0591e-01,\n          2.4344e-03,  2.6904e-02],\n        [ 1.3267e-01,  1.5230e-01, -1.2524e-01, -1.2357e-02, -1.6379e-01,\n         -1.7338e-01, -1.6302e-01, -8.6825e-03, -1.2719e-01,  5.8606e-02,\n          3.6490e-02, -1.3979e-01,  1.4717e-01, -9.6915e-03, -1.1587e-01,\n          2.0643e-02,  1.5926e-01,  7.9277e-02, -3.4078e-02,  1.4408e-01,\n         -3.5858e-02,  7.2385e-02,  8.8185e-02, -8.3182e-02, -1.7158e-01,\n         -1.5058e-01,  2.8477e-02,  4.3589e-02,  1.2622e-01, -1.1754e-01,\n         -9.9997e-02,  1.9628e-02],\n        [ 1.5023e-02, -3.8886e-02,  2.9566e-02,  8.4297e-02,  1.5495e-01,\n         -1.4055e-01, -1.0225e-01, -1.0377e-01,  1.9791e-02, -1.6317e-01,\n          9.7510e-02,  8.7863e-02,  1.5804e-01,  8.5968e-02, -3.4122e-02,\n         -2.0452e-02,  3.9726e-02,  1.6852e-01, -1.5432e-01, -5.0517e-02,\n          1.6108e-01, -1.3043e-01,  1.4944e-01, -6.8556e-02, -5.7625e-02,\n          2.6450e-02, -2.2241e-02,  4.1765e-02, -8.6861e-02,  1.2295e-01,\n         -4.3662e-02,  1.4772e-01],\n        [-1.3947e-01, -4.2261e-02,  1.1213e-01, -8.6848e-02, -1.2088e-01,\n         -2.9160e-02, -5.6242e-03,  4.2984e-02,  2.9452e-02,  1.1190e-01,\n          1.5187e-01,  1.9766e-02, -5.6081e-02, -6.2624e-03, -7.7338e-02,\n          1.6374e-01,  3.1460e-02, -1.5387e-01,  2.8073e-02, -2.1703e-02,\n          4.7149e-03, -6.0166e-02, -5.6431e-02,  1.6547e-01,  4.8012e-02,\n          4.5069e-02,  3.7705e-02, -9.7485e-02,  1.7554e-01, -6.1051e-02,\n         -1.2323e-01,  1.2730e-01],\n        [-9.7016e-03,  7.8946e-02,  1.0471e-01, -2.4013e-02,  3.7580e-02,\n          8.4392e-02,  1.0239e-01, -3.9693e-02,  1.3039e-01,  5.0141e-02,\n          7.9894e-02,  1.0030e-01, -1.3217e-01,  1.4702e-01,  6.2662e-02,\n         -4.4602e-02,  8.1001e-02,  1.1449e-01,  1.0140e-02,  8.3783e-02,\n         -1.4949e-01, -1.0373e-01,  1.0354e-01,  6.5399e-03, -1.6010e-01,\n          1.0878e-02, -8.9743e-02,  6.7370e-02,  1.3866e-01, -1.0413e-01,\n         -1.1446e-02, -1.3793e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0078,  0.0386, -0.1677,  0.2329,  0.1805,  0.1882,  0.1434,  0.0334],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0144,  0.0793, -0.0299,  0.0096, -0.0497, -0.1480, -0.2114, -0.0041,\n          0.1466,  0.2151,  0.1565, -0.2135, -0.1865,  0.0880,  0.2219,  0.2346],\n        [ 0.0807,  0.1414, -0.1764,  0.0620,  0.0698,  0.1581, -0.1403,  0.0128,\n         -0.0487, -0.1895,  0.1081, -0.2274,  0.1766,  0.1515, -0.0457,  0.1341],\n        [-0.0799,  0.1714, -0.0797, -0.2324,  0.0329, -0.0973, -0.2370,  0.0372,\n         -0.1774,  0.1588, -0.1253, -0.2252, -0.2420, -0.1207, -0.1865,  0.1677],\n        [ 0.1739, -0.0090,  0.0451, -0.0779,  0.1568, -0.1703,  0.0949, -0.1246,\n         -0.2307, -0.0587,  0.0515,  0.1533, -0.0696, -0.0140, -0.0275, -0.0617],\n        [ 0.1862, -0.1626,  0.2427, -0.1198,  0.0928, -0.1274, -0.0932, -0.1736,\n         -0.0803,  0.1745, -0.0154,  0.2182, -0.0879, -0.1620,  0.2323, -0.0566],\n        [ 0.1700, -0.0235,  0.1134,  0.2147, -0.1518, -0.1150, -0.0037, -0.2117,\n          0.1083,  0.1963,  0.1916, -0.0121,  0.0829,  0.2039,  0.1344,  0.1473],\n        [ 0.2472, -0.0088, -0.2448,  0.2373,  0.2300, -0.0899, -0.0054,  0.1361,\n         -0.1091,  0.1982, -0.1625,  0.1104,  0.0159,  0.1698,  0.1167,  0.0011],\n        [-0.1836, -0.1327, -0.0046, -0.0114, -0.1851, -0.0110, -0.0202,  0.0921,\n          0.0730, -0.0305, -0.1978,  0.0273,  0.1950,  0.1497, -0.1434, -0.0277]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1506, -0.2340,  0.2808, -0.1620], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1725,  0.2472,  0.0770,  0.2796,  0.1487, -0.1458,  0.1791, -0.1296],\n        [ 0.1058,  0.2797, -0.2333,  0.3369, -0.1458, -0.1959,  0.2890, -0.2541],\n        [ 0.3072, -0.0720,  0.3348,  0.3420, -0.3316,  0.2825,  0.0905, -0.0065],\n        [-0.0724, -0.0630,  0.0515, -0.0929, -0.0941, -0.0968,  0.1353,  0.0933]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2597,  0.2170,  0.1649, -0.1229, -0.0494, -0.3065, -0.1646,  0.0532],\n        [ 0.3326, -0.2276,  0.3060,  0.0912, -0.1122, -0.2437,  0.1080,  0.3088],\n        [-0.2311, -0.0375,  0.2114, -0.1001,  0.1705,  0.0120,  0.0720, -0.3022],\n        [-0.3378, -0.2722,  0.1560,  0.2166,  0.1741,  0.0451, -0.0801,  0.0461],\n        [-0.0301, -0.3265,  0.2000, -0.3396,  0.2917, -0.3244, -0.2774, -0.0787],\n        [-0.1003,  0.1269,  0.0058,  0.2979, -0.2096,  0.2450,  0.1665,  0.1240],\n        [-0.0619, -0.1213,  0.1108, -0.1117, -0.2013, -0.0665, -0.2429,  0.2926],\n        [-0.2012, -0.1516,  0.2188, -0.0920, -0.0712, -0.1228,  0.3457,  0.1012],\n        [ 0.1589,  0.1019,  0.2712,  0.2509,  0.2783, -0.0854,  0.3130, -0.1874],\n        [ 0.2810, -0.0054, -0.1128, -0.3164, -0.2456, -0.3286, -0.2067,  0.0496],\n        [-0.1103, -0.2205,  0.2739,  0.1866,  0.1021, -0.3489,  0.2744, -0.1376],\n        [-0.0416, -0.1585, -0.2860,  0.0994, -0.3229, -0.0358,  0.0566, -0.1382],\n        [-0.2491, -0.1389, -0.0367, -0.3092, -0.1562, -0.0437,  0.1012, -0.2298],\n        [-0.2887, -0.1803, -0.1286, -0.2385, -0.3077, -0.2352, -0.3371,  0.1481],\n        [-0.0999, -0.1440,  0.1176, -0.2386,  0.3245,  0.3222, -0.3361,  0.2619],\n        [-0.0121, -0.0470,  0.0446, -0.0156,  0.1490, -0.1901,  0.0624, -0.1138],\n        [ 0.1382, -0.1277, -0.1046, -0.1484, -0.1346, -0.1597, -0.2406,  0.3140],\n        [ 0.0555, -0.0058, -0.0890,  0.1864, -0.0355,  0.1229, -0.3084,  0.3123],\n        [-0.2552, -0.2687,  0.2314,  0.0103,  0.0268,  0.0934, -0.2743, -0.2358],\n        [-0.2836,  0.0479, -0.3296, -0.1371,  0.1703, -0.1383, -0.1755,  0.3186],\n        [ 0.0378, -0.2234,  0.0428,  0.2171, -0.1067, -0.2717, -0.0221, -0.1272],\n        [ 0.1155,  0.0742, -0.1292, -0.1256, -0.0745, -0.3456, -0.3531,  0.2244],\n        [ 0.2839,  0.1685,  0.2078, -0.0435, -0.2652, -0.0726,  0.3343,  0.2695],\n        [ 0.1484,  0.1485,  0.2258, -0.3083,  0.3053,  0.3111,  0.0781, -0.2469],\n        [-0.1986,  0.2210,  0.1503,  0.3520, -0.3252, -0.0156,  0.3253,  0.2239],\n        [-0.1134, -0.2488,  0.1179, -0.1054, -0.2235, -0.2989, -0.1380,  0.3268],\n        [ 0.2968, -0.0474,  0.1964,  0.2329, -0.1702, -0.0645,  0.0556,  0.0357],\n        [ 0.0267, -0.2934, -0.0965,  0.1614,  0.2249,  0.1467,  0.0070, -0.0348],\n        [ 0.0946,  0.1259, -0.2722, -0.2259,  0.1157, -0.1907, -0.2489, -0.2332],\n        [ 0.0908, -0.2025,  0.0282, -0.2355, -0.0158, -0.2427,  0.2958, -0.3126],\n        [-0.0717,  0.2492,  0.3483, -0.1985,  0.2626,  0.3232,  0.2164,  0.1963],\n        [-0.3070,  0.3040, -0.0881, -0.2616,  0.0302,  0.2964,  0.0335, -0.3421]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1410, -0.0103, -0.0520,  0.0235, -0.1955, -0.1424, -0.2804,  0.1421,\n         0.2305, -0.0975, -0.1323,  0.2737, -0.2674,  0.2816,  0.1328,  0.1663,\n         0.1733, -0.3296,  0.2171, -0.2264, -0.1615, -0.1973, -0.1259,  0.3449,\n         0.3056,  0.1892,  0.0535,  0.0114, -0.1967, -0.2682, -0.1550, -0.3024],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 4.7685e-02,  1.6987e-01,  2.5931e-02, -1.6270e-01, -1.7584e-01,\n          5.8283e-02,  1.3581e-01, -5.2263e-02, -1.6693e-02, -1.2954e-01,\n         -2.5627e-02, -1.6250e-01,  8.2962e-02,  1.6498e-01, -1.6815e-01,\n          2.5738e-02,  1.5800e-01, -6.9563e-02,  1.1453e-01,  1.1011e-01,\n          1.2972e-01, -1.1243e-01, -1.7116e-01, -1.5419e-01,  5.9172e-03,\n          1.4459e-01, -7.2541e-02, -1.0791e-01,  9.8179e-03,  1.3681e-01,\n         -2.5849e-02, -9.4294e-02],\n        [ 1.6168e-01,  1.5289e-01,  1.4981e-01,  1.3863e-01, -7.7471e-02,\n          2.0171e-02,  4.8737e-02, -9.6011e-02, -1.1487e-01, -1.0907e-01,\n          1.7323e-01, -5.3639e-02, -1.3400e-01,  1.7366e-01,  5.0796e-02,\n          1.5287e-01, -5.6790e-02,  1.5999e-01,  1.3012e-01, -7.5917e-02,\n         -7.0038e-02, -1.6415e-02, -1.2755e-01, -1.7075e-02, -8.0079e-02,\n          8.4012e-03,  1.4559e-01, -1.0568e-01, -1.5023e-03, -1.2956e-01,\n          1.5768e-01,  8.9969e-02],\n        [-1.1662e-01,  1.3391e-01,  1.6440e-01,  6.5311e-02, -2.5001e-02,\n         -1.5008e-01, -5.2510e-02,  1.5991e-01,  5.9567e-02, -9.2755e-02,\n          9.0382e-02,  1.8272e-02, -9.5574e-02, -3.2312e-02, -1.1582e-01,\n          1.2787e-01, -6.5962e-02, -9.8359e-02,  8.5954e-02,  9.4471e-02,\n         -1.4673e-01,  1.1045e-01, -1.5861e-01, -1.7186e-01, -2.7228e-02,\n          3.6439e-02,  6.8407e-02,  1.6901e-01, -2.9195e-02,  5.8660e-02,\n         -5.0321e-02,  1.1490e-01],\n        [-6.6743e-02,  1.7633e-01,  2.8325e-03, -9.0237e-02, -9.7717e-02,\n         -1.3398e-01,  1.0307e-02, -7.3077e-02, -5.4702e-02,  1.2729e-01,\n          1.4718e-02,  1.6665e-02, -8.8815e-02, -1.5090e-01,  1.4214e-01,\n         -7.2029e-02, -4.9625e-02, -1.2922e-02, -9.3567e-02,  1.0739e-01,\n         -1.2825e-01,  1.6938e-01,  1.1545e-01,  2.8982e-02, -9.0229e-02,\n         -6.2635e-02,  1.4817e-01,  1.1682e-02,  1.1026e-01,  7.3818e-02,\n          1.7297e-01,  1.6639e-01],\n        [ 1.6125e-01, -1.3642e-01, -2.8066e-02, -4.9456e-02, -9.4186e-03,\n         -4.7730e-02, -3.9750e-02, -2.7353e-02,  1.0439e-01,  1.5631e-01,\n         -1.6274e-01, -4.1956e-02, -4.3036e-02, -6.5460e-02, -6.6034e-02,\n         -4.3515e-02,  4.2289e-02, -6.3376e-02, -1.2559e-01, -8.2407e-02,\n         -9.8130e-02, -1.3896e-01, -1.3780e-01,  3.5162e-02,  6.8091e-02,\n         -8.6101e-02,  1.6374e-01,  1.3412e-01,  1.5853e-02,  1.5933e-01,\n         -5.4276e-02, -3.5951e-02],\n        [ 1.7477e-01,  1.6624e-01,  6.8510e-05, -6.0324e-02,  1.6433e-01,\n          7.8036e-02,  1.6298e-01, -8.1065e-02,  4.1575e-02,  3.2199e-02,\n          1.4876e-01, -5.8183e-02,  9.0094e-02, -1.2809e-01,  1.4684e-01,\n          8.9183e-02,  1.3187e-01,  1.5105e-01, -1.4341e-01,  1.7156e-01,\n         -1.3579e-01,  1.3227e-01,  7.0522e-02,  1.6541e-01,  4.3191e-02,\n          8.2222e-02,  1.6007e-01,  8.0966e-02,  5.8746e-02, -1.2629e-01,\n          1.6933e-01, -7.0569e-02],\n        [-1.7530e-01,  4.1884e-02, -8.8387e-02,  1.5693e-01,  1.2848e-01,\n          5.6454e-02, -3.9351e-02,  6.7826e-02,  1.0909e-02,  1.1742e-01,\n          1.0367e-01, -9.5802e-02,  6.9771e-02, -1.7595e-01,  8.2088e-02,\n         -1.5570e-01,  1.5930e-01,  2.0352e-02, -1.5094e-01, -1.6843e-01,\n          1.0463e-01,  8.8818e-02,  3.7021e-02,  8.0684e-02, -1.2642e-01,\n         -1.2001e-01, -4.4052e-03, -3.4712e-03,  1.7082e-01, -1.4876e-01,\n         -1.2978e-01,  8.2478e-02],\n        [ 8.6909e-02,  1.6937e-01,  5.3610e-02, -3.8911e-02,  1.4021e-01,\n         -5.5807e-02, -7.5164e-02,  1.7406e-01,  1.7066e-01,  2.5193e-02,\n         -1.2596e-01,  1.2109e-01, -1.0967e-01,  1.4224e-01, -1.1698e-01,\n          2.3487e-02, -2.8358e-02, -1.2924e-01, -3.7372e-02,  3.6817e-02,\n          2.4610e-02,  2.0991e-03,  7.0340e-02,  1.3229e-02,  9.5921e-02,\n          1.7323e-01,  5.5347e-02, -1.7567e-01, -1.6185e-02,  1.4289e-01,\n          1.5063e-01,  2.2271e-02],\n        [-2.0391e-02,  3.8996e-02, -1.5646e-01,  9.3755e-02, -8.7275e-02,\n          7.5223e-03,  1.6094e-01, -1.1327e-01, -4.4193e-02,  3.9566e-02,\n         -8.3599e-02, -4.0537e-02,  8.2652e-02, -4.6656e-02, -6.7837e-02,\n         -1.3179e-01,  1.8854e-02,  1.0021e-01, -1.7039e-01,  5.9510e-02,\n          1.3755e-01,  5.9568e-02,  1.0541e-02, -3.5745e-02, -1.4702e-01,\n         -8.8804e-02, -1.3539e-01, -5.0036e-02, -7.8367e-02, -7.9993e-02,\n         -7.3121e-02,  8.8879e-02],\n        [-2.9454e-02, -1.0753e-01, -5.9584e-02, -1.6480e-01, -1.4142e-01,\n          1.0635e-02,  1.0149e-01,  1.4335e-02,  5.2760e-02,  4.4889e-02,\n          8.9578e-02, -8.5513e-02,  1.2875e-01,  6.0412e-02, -7.2137e-02,\n          1.2391e-02,  6.1316e-03,  5.7516e-02, -9.2749e-02,  1.6604e-01,\n          1.1558e-01, -8.0178e-02,  1.2814e-01,  1.0100e-01,  4.7931e-02,\n         -8.4144e-02,  1.7231e-01, -6.9435e-04, -1.1326e-01, -7.7829e-02,\n          1.6967e-01, -1.0169e-01],\n        [-1.4512e-01, -8.6519e-02, -5.6758e-03,  1.6568e-01, -6.1334e-03,\n          6.7626e-02, -1.2540e-01, -1.6980e-01, -9.0189e-03, -2.8449e-04,\n         -4.3180e-02, -8.5967e-02,  1.7949e-02, -7.2843e-02,  1.1293e-01,\n         -1.1624e-01,  5.6166e-02,  1.1026e-01, -5.8913e-02, -1.3135e-02,\n         -9.6724e-02, -1.1193e-01, -1.1028e-01,  1.1868e-01, -1.0572e-01,\n          8.0686e-03,  6.0121e-02, -2.9981e-04, -9.7591e-02, -5.6117e-02,\n         -1.5707e-01, -8.0090e-02],\n        [-4.5303e-02, -1.6450e-01, -1.7146e-01,  1.3517e-01, -5.5760e-02,\n          1.5752e-01, -1.3029e-01,  9.1203e-02,  3.7839e-03, -1.4316e-01,\n          6.7907e-02, -8.1748e-02,  5.4972e-02, -9.5101e-02,  1.2159e-01,\n          8.7843e-02, -1.0071e-01,  6.3782e-02,  8.7108e-02, -1.4629e-01,\n         -1.0811e-01, -1.2446e-01,  1.1863e-01, -1.6756e-01, -1.2313e-01,\n          4.0641e-02, -1.4168e-01,  5.7912e-02, -1.2540e-01, -1.0591e-01,\n          2.4344e-03,  2.6904e-02],\n        [ 1.3267e-01,  1.5230e-01, -1.2524e-01, -1.2357e-02, -1.6379e-01,\n         -1.7338e-01, -1.6302e-01, -8.6825e-03, -1.2719e-01,  5.8606e-02,\n          3.6490e-02, -1.3979e-01,  1.4717e-01, -9.6915e-03, -1.1587e-01,\n          2.0643e-02,  1.5926e-01,  7.9277e-02, -3.4078e-02,  1.4408e-01,\n         -3.5858e-02,  7.2385e-02,  8.8185e-02, -8.3182e-02, -1.7158e-01,\n         -1.5058e-01,  2.8477e-02,  4.3589e-02,  1.2622e-01, -1.1754e-01,\n         -9.9997e-02,  1.9628e-02],\n        [ 1.5023e-02, -3.8886e-02,  2.9566e-02,  8.4297e-02,  1.5495e-01,\n         -1.4055e-01, -1.0225e-01, -1.0377e-01,  1.9791e-02, -1.6317e-01,\n          9.7510e-02,  8.7863e-02,  1.5804e-01,  8.5968e-02, -3.4122e-02,\n         -2.0452e-02,  3.9726e-02,  1.6852e-01, -1.5432e-01, -5.0517e-02,\n          1.6108e-01, -1.3043e-01,  1.4944e-01, -6.8556e-02, -5.7625e-02,\n          2.6450e-02, -2.2241e-02,  4.1765e-02, -8.6861e-02,  1.2295e-01,\n         -4.3662e-02,  1.4772e-01],\n        [-1.3947e-01, -4.2261e-02,  1.1213e-01, -8.6848e-02, -1.2088e-01,\n         -2.9160e-02, -5.6242e-03,  4.2984e-02,  2.9452e-02,  1.1190e-01,\n          1.5187e-01,  1.9766e-02, -5.6081e-02, -6.2624e-03, -7.7338e-02,\n          1.6374e-01,  3.1460e-02, -1.5387e-01,  2.8073e-02, -2.1703e-02,\n          4.7149e-03, -6.0166e-02, -5.6431e-02,  1.6547e-01,  4.8012e-02,\n          4.5069e-02,  3.7705e-02, -9.7485e-02,  1.7554e-01, -6.1051e-02,\n         -1.2323e-01,  1.2730e-01],\n        [-9.7016e-03,  7.8946e-02,  1.0471e-01, -2.4013e-02,  3.7580e-02,\n          8.4392e-02,  1.0239e-01, -3.9693e-02,  1.3039e-01,  5.0141e-02,\n          7.9894e-02,  1.0030e-01, -1.3217e-01,  1.4702e-01,  6.2662e-02,\n         -4.4602e-02,  8.1001e-02,  1.1449e-01,  1.0140e-02,  8.3783e-02,\n         -1.4949e-01, -1.0373e-01,  1.0354e-01,  6.5399e-03, -1.6010e-01,\n          1.0878e-02, -8.9743e-02,  6.7370e-02,  1.3866e-01, -1.0413e-01,\n         -1.1446e-02, -1.3793e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 1.0491e-01,  2.7860e-02,  1.7260e-01, -1.6236e-01, -1.2137e-01,\n         8.1459e-02,  1.4896e-01,  1.3350e-01,  3.7874e-02, -8.6619e-02,\n        -3.2894e-02,  3.4230e-02, -8.6012e-02,  1.0065e-01,  2.2422e-02,\n         1.2893e-04], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0144,  0.0793, -0.0299,  0.0096, -0.0497, -0.1480, -0.2114, -0.0041,\n          0.1466,  0.2151,  0.1565, -0.2135, -0.1865,  0.0880,  0.2219,  0.2346],\n        [ 0.0807,  0.1414, -0.1764,  0.0620,  0.0698,  0.1581, -0.1403,  0.0128,\n         -0.0487, -0.1895,  0.1081, -0.2274,  0.1766,  0.1515, -0.0457,  0.1341],\n        [-0.0799,  0.1714, -0.0797, -0.2324,  0.0329, -0.0973, -0.2370,  0.0372,\n         -0.1774,  0.1588, -0.1253, -0.2252, -0.2420, -0.1207, -0.1865,  0.1677],\n        [ 0.1739, -0.0090,  0.0451, -0.0779,  0.1568, -0.1703,  0.0949, -0.1246,\n         -0.2307, -0.0587,  0.0515,  0.1533, -0.0696, -0.0140, -0.0275, -0.0617],\n        [ 0.1862, -0.1626,  0.2427, -0.1198,  0.0928, -0.1274, -0.0932, -0.1736,\n         -0.0803,  0.1745, -0.0154,  0.2182, -0.0879, -0.1620,  0.2323, -0.0566],\n        [ 0.1700, -0.0235,  0.1134,  0.2147, -0.1518, -0.1150, -0.0037, -0.2117,\n          0.1083,  0.1963,  0.1916, -0.0121,  0.0829,  0.2039,  0.1344,  0.1473],\n        [ 0.2472, -0.0088, -0.2448,  0.2373,  0.2300, -0.0899, -0.0054,  0.1361,\n         -0.1091,  0.1982, -0.1625,  0.1104,  0.0159,  0.1698,  0.1167,  0.0011],\n        [-0.1836, -0.1327, -0.0046, -0.0114, -0.1851, -0.0110, -0.0202,  0.0921,\n          0.0730, -0.0305, -0.1978,  0.0273,  0.1950,  0.1497, -0.1434, -0.0277]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0078,  0.0386, -0.1677,  0.2329,  0.1805,  0.1882,  0.1434,  0.0334],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1725,  0.2472,  0.0770,  0.2796,  0.1487, -0.1458,  0.1791, -0.1296],\n        [ 0.1058,  0.2797, -0.2333,  0.3369, -0.1458, -0.1959,  0.2890, -0.2541],\n        [ 0.3072, -0.0720,  0.3348,  0.3420, -0.3316,  0.2825,  0.0905, -0.0065],\n        [-0.0724, -0.0630,  0.0515, -0.0929, -0.0941, -0.0968,  0.1353,  0.0933]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1506, -0.2340,  0.2808, -0.1620], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7879f72f8ed0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1410, -0.0103, -0.0520,  0.0235, -0.1955, -0.1424, -0.2804,  0.1421,\n         0.2305, -0.0975, -0.1323,  0.2737, -0.2674,  0.2816,  0.1328,  0.1663,\n         0.1733, -0.3296,  0.2171, -0.2264, -0.1615, -0.1973, -0.1259,  0.3449,\n         0.3056,  0.1892,  0.0535,  0.0114, -0.1967, -0.2682, -0.1550, -0.3024],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2597,  0.2170,  0.1649, -0.1229, -0.0494, -0.3065, -0.1646,  0.0532],\n        [ 0.3326, -0.2276,  0.3060,  0.0912, -0.1122, -0.2437,  0.1080,  0.3088],\n        [-0.2311, -0.0375,  0.2114, -0.1001,  0.1705,  0.0120,  0.0720, -0.3022],\n        [-0.3378, -0.2722,  0.1560,  0.2166,  0.1741,  0.0451, -0.0801,  0.0461],\n        [-0.0301, -0.3265,  0.2000, -0.3396,  0.2917, -0.3244, -0.2774, -0.0787],\n        [-0.1003,  0.1269,  0.0058,  0.2979, -0.2096,  0.2450,  0.1665,  0.1240],\n        [-0.0619, -0.1213,  0.1108, -0.1117, -0.2013, -0.0665, -0.2429,  0.2926],\n        [-0.2012, -0.1516,  0.2188, -0.0920, -0.0712, -0.1228,  0.3457,  0.1012],\n        [ 0.1589,  0.1019,  0.2712,  0.2509,  0.2783, -0.0854,  0.3130, -0.1874],\n        [ 0.2810, -0.0054, -0.1128, -0.3164, -0.2456, -0.3286, -0.2067,  0.0496],\n        [-0.1103, -0.2205,  0.2739,  0.1866,  0.1021, -0.3489,  0.2744, -0.1376],\n        [-0.0416, -0.1585, -0.2860,  0.0994, -0.3229, -0.0358,  0.0566, -0.1382],\n        [-0.2491, -0.1389, -0.0367, -0.3092, -0.1562, -0.0437,  0.1012, -0.2298],\n        [-0.2887, -0.1803, -0.1286, -0.2385, -0.3077, -0.2352, -0.3371,  0.1481],\n        [-0.0999, -0.1440,  0.1176, -0.2386,  0.3245,  0.3222, -0.3361,  0.2619],\n        [-0.0121, -0.0470,  0.0446, -0.0156,  0.1490, -0.1901,  0.0624, -0.1138],\n        [ 0.1382, -0.1277, -0.1046, -0.1484, -0.1346, -0.1597, -0.2406,  0.3140],\n        [ 0.0555, -0.0058, -0.0890,  0.1864, -0.0355,  0.1229, -0.3084,  0.3123],\n        [-0.2552, -0.2687,  0.2314,  0.0103,  0.0268,  0.0934, -0.2743, -0.2358],\n        [-0.2836,  0.0479, -0.3296, -0.1371,  0.1703, -0.1383, -0.1755,  0.3186],\n        [ 0.0378, -0.2234,  0.0428,  0.2171, -0.1067, -0.2717, -0.0221, -0.1272],\n        [ 0.1155,  0.0742, -0.1292, -0.1256, -0.0745, -0.3456, -0.3531,  0.2244],\n        [ 0.2839,  0.1685,  0.2078, -0.0435, -0.2652, -0.0726,  0.3343,  0.2695],\n        [ 0.1484,  0.1485,  0.2258, -0.3083,  0.3053,  0.3111,  0.0781, -0.2469],\n        [-0.1986,  0.2210,  0.1503,  0.3520, -0.3252, -0.0156,  0.3253,  0.2239],\n        [-0.1134, -0.2488,  0.1179, -0.1054, -0.2235, -0.2989, -0.1380,  0.3268],\n        [ 0.2968, -0.0474,  0.1964,  0.2329, -0.1702, -0.0645,  0.0556,  0.0357],\n        [ 0.0267, -0.2934, -0.0965,  0.1614,  0.2249,  0.1467,  0.0070, -0.0348],\n        [ 0.0946,  0.1259, -0.2722, -0.2259,  0.1157, -0.1907, -0.2489, -0.2332],\n        [ 0.0908, -0.2025,  0.0282, -0.2355, -0.0158, -0.2427,  0.2958, -0.3126],\n        [-0.0717,  0.2492,  0.3483, -0.1985,  0.2626,  0.3232,  0.2164,  0.1963],\n        [-0.3070,  0.3040, -0.0881, -0.2616,  0.0302,  0.2964,  0.0335, -0.3421]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 1.0491e-01,  2.7860e-02,  1.7260e-01, -1.6236e-01, -1.2137e-01,\n         8.1459e-02,  1.4896e-01,  1.3350e-01,  3.7874e-02, -8.6619e-02,\n        -3.2894e-02,  3.4230e-02, -8.6012e-02,  1.0065e-01,  2.2422e-02,\n         1.2893e-04], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 4.7685e-02,  1.6987e-01,  2.5931e-02, -1.6270e-01, -1.7584e-01,\n          5.8283e-02,  1.3581e-01, -5.2263e-02, -1.6693e-02, -1.2954e-01,\n         -2.5627e-02, -1.6250e-01,  8.2962e-02,  1.6498e-01, -1.6815e-01,\n          2.5738e-02,  1.5800e-01, -6.9563e-02,  1.1453e-01,  1.1011e-01,\n          1.2972e-01, -1.1243e-01, -1.7116e-01, -1.5419e-01,  5.9172e-03,\n          1.4459e-01, -7.2541e-02, -1.0791e-01,  9.8179e-03,  1.3681e-01,\n         -2.5849e-02, -9.4294e-02],\n        [ 1.6168e-01,  1.5289e-01,  1.4981e-01,  1.3863e-01, -7.7471e-02,\n          2.0171e-02,  4.8737e-02, -9.6011e-02, -1.1487e-01, -1.0907e-01,\n          1.7323e-01, -5.3639e-02, -1.3400e-01,  1.7366e-01,  5.0796e-02,\n          1.5287e-01, -5.6790e-02,  1.5999e-01,  1.3012e-01, -7.5917e-02,\n         -7.0038e-02, -1.6415e-02, -1.2755e-01, -1.7075e-02, -8.0079e-02,\n          8.4012e-03,  1.4559e-01, -1.0568e-01, -1.5023e-03, -1.2956e-01,\n          1.5768e-01,  8.9969e-02],\n        [-1.1662e-01,  1.3391e-01,  1.6440e-01,  6.5311e-02, -2.5001e-02,\n         -1.5008e-01, -5.2510e-02,  1.5991e-01,  5.9567e-02, -9.2755e-02,\n          9.0382e-02,  1.8272e-02, -9.5574e-02, -3.2312e-02, -1.1582e-01,\n          1.2787e-01, -6.5962e-02, -9.8359e-02,  8.5954e-02,  9.4471e-02,\n         -1.4673e-01,  1.1045e-01, -1.5861e-01, -1.7186e-01, -2.7228e-02,\n          3.6439e-02,  6.8407e-02,  1.6901e-01, -2.9195e-02,  5.8660e-02,\n         -5.0321e-02,  1.1490e-01],\n        [-6.6743e-02,  1.7633e-01,  2.8325e-03, -9.0237e-02, -9.7717e-02,\n         -1.3398e-01,  1.0307e-02, -7.3077e-02, -5.4702e-02,  1.2729e-01,\n          1.4718e-02,  1.6665e-02, -8.8815e-02, -1.5090e-01,  1.4214e-01,\n         -7.2029e-02, -4.9625e-02, -1.2922e-02, -9.3567e-02,  1.0739e-01,\n         -1.2825e-01,  1.6938e-01,  1.1545e-01,  2.8982e-02, -9.0229e-02,\n         -6.2635e-02,  1.4817e-01,  1.1682e-02,  1.1026e-01,  7.3818e-02,\n          1.7297e-01,  1.6639e-01],\n        [ 1.6125e-01, -1.3642e-01, -2.8066e-02, -4.9456e-02, -9.4186e-03,\n         -4.7730e-02, -3.9750e-02, -2.7353e-02,  1.0439e-01,  1.5631e-01,\n         -1.6274e-01, -4.1956e-02, -4.3036e-02, -6.5460e-02, -6.6034e-02,\n         -4.3515e-02,  4.2289e-02, -6.3376e-02, -1.2559e-01, -8.2407e-02,\n         -9.8130e-02, -1.3896e-01, -1.3780e-01,  3.5162e-02,  6.8091e-02,\n         -8.6101e-02,  1.6374e-01,  1.3412e-01,  1.5853e-02,  1.5933e-01,\n         -5.4276e-02, -3.5951e-02],\n        [ 1.7477e-01,  1.6624e-01,  6.8510e-05, -6.0324e-02,  1.6433e-01,\n          7.8036e-02,  1.6298e-01, -8.1065e-02,  4.1575e-02,  3.2199e-02,\n          1.4876e-01, -5.8183e-02,  9.0094e-02, -1.2809e-01,  1.4684e-01,\n          8.9183e-02,  1.3187e-01,  1.5105e-01, -1.4341e-01,  1.7156e-01,\n         -1.3579e-01,  1.3227e-01,  7.0522e-02,  1.6541e-01,  4.3191e-02,\n          8.2222e-02,  1.6007e-01,  8.0966e-02,  5.8746e-02, -1.2629e-01,\n          1.6933e-01, -7.0569e-02],\n        [-1.7530e-01,  4.1884e-02, -8.8387e-02,  1.5693e-01,  1.2848e-01,\n          5.6454e-02, -3.9351e-02,  6.7826e-02,  1.0909e-02,  1.1742e-01,\n          1.0367e-01, -9.5802e-02,  6.9771e-02, -1.7595e-01,  8.2088e-02,\n         -1.5570e-01,  1.5930e-01,  2.0352e-02, -1.5094e-01, -1.6843e-01,\n          1.0463e-01,  8.8818e-02,  3.7021e-02,  8.0684e-02, -1.2642e-01,\n         -1.2001e-01, -4.4052e-03, -3.4712e-03,  1.7082e-01, -1.4876e-01,\n         -1.2978e-01,  8.2478e-02],\n        [ 8.6909e-02,  1.6937e-01,  5.3610e-02, -3.8911e-02,  1.4021e-01,\n         -5.5807e-02, -7.5164e-02,  1.7406e-01,  1.7066e-01,  2.5193e-02,\n         -1.2596e-01,  1.2109e-01, -1.0967e-01,  1.4224e-01, -1.1698e-01,\n          2.3487e-02, -2.8358e-02, -1.2924e-01, -3.7372e-02,  3.6817e-02,\n          2.4610e-02,  2.0991e-03,  7.0340e-02,  1.3229e-02,  9.5921e-02,\n          1.7323e-01,  5.5347e-02, -1.7567e-01, -1.6185e-02,  1.4289e-01,\n          1.5063e-01,  2.2271e-02],\n        [-2.0391e-02,  3.8996e-02, -1.5646e-01,  9.3755e-02, -8.7275e-02,\n          7.5223e-03,  1.6094e-01, -1.1327e-01, -4.4193e-02,  3.9566e-02,\n         -8.3599e-02, -4.0537e-02,  8.2652e-02, -4.6656e-02, -6.7837e-02,\n         -1.3179e-01,  1.8854e-02,  1.0021e-01, -1.7039e-01,  5.9510e-02,\n          1.3755e-01,  5.9568e-02,  1.0541e-02, -3.5745e-02, -1.4702e-01,\n         -8.8804e-02, -1.3539e-01, -5.0036e-02, -7.8367e-02, -7.9993e-02,\n         -7.3121e-02,  8.8879e-02],\n        [-2.9454e-02, -1.0753e-01, -5.9584e-02, -1.6480e-01, -1.4142e-01,\n          1.0635e-02,  1.0149e-01,  1.4335e-02,  5.2760e-02,  4.4889e-02,\n          8.9578e-02, -8.5513e-02,  1.2875e-01,  6.0412e-02, -7.2137e-02,\n          1.2391e-02,  6.1316e-03,  5.7516e-02, -9.2749e-02,  1.6604e-01,\n          1.1558e-01, -8.0178e-02,  1.2814e-01,  1.0100e-01,  4.7931e-02,\n         -8.4144e-02,  1.7231e-01, -6.9435e-04, -1.1326e-01, -7.7829e-02,\n          1.6967e-01, -1.0169e-01],\n        [-1.4512e-01, -8.6519e-02, -5.6758e-03,  1.6568e-01, -6.1334e-03,\n          6.7626e-02, -1.2540e-01, -1.6980e-01, -9.0189e-03, -2.8449e-04,\n         -4.3180e-02, -8.5967e-02,  1.7949e-02, -7.2843e-02,  1.1293e-01,\n         -1.1624e-01,  5.6166e-02,  1.1026e-01, -5.8913e-02, -1.3135e-02,\n         -9.6724e-02, -1.1193e-01, -1.1028e-01,  1.1868e-01, -1.0572e-01,\n          8.0686e-03,  6.0121e-02, -2.9981e-04, -9.7591e-02, -5.6117e-02,\n         -1.5707e-01, -8.0090e-02],\n        [-4.5303e-02, -1.6450e-01, -1.7146e-01,  1.3517e-01, -5.5760e-02,\n          1.5752e-01, -1.3029e-01,  9.1203e-02,  3.7839e-03, -1.4316e-01,\n          6.7907e-02, -8.1748e-02,  5.4972e-02, -9.5101e-02,  1.2159e-01,\n          8.7843e-02, -1.0071e-01,  6.3782e-02,  8.7108e-02, -1.4629e-01,\n         -1.0811e-01, -1.2446e-01,  1.1863e-01, -1.6756e-01, -1.2313e-01,\n          4.0641e-02, -1.4168e-01,  5.7912e-02, -1.2540e-01, -1.0591e-01,\n          2.4344e-03,  2.6904e-02],\n        [ 1.3267e-01,  1.5230e-01, -1.2524e-01, -1.2357e-02, -1.6379e-01,\n         -1.7338e-01, -1.6302e-01, -8.6825e-03, -1.2719e-01,  5.8606e-02,\n          3.6490e-02, -1.3979e-01,  1.4717e-01, -9.6915e-03, -1.1587e-01,\n          2.0643e-02,  1.5926e-01,  7.9277e-02, -3.4078e-02,  1.4408e-01,\n         -3.5858e-02,  7.2385e-02,  8.8185e-02, -8.3182e-02, -1.7158e-01,\n         -1.5058e-01,  2.8477e-02,  4.3589e-02,  1.2622e-01, -1.1754e-01,\n         -9.9997e-02,  1.9628e-02],\n        [ 1.5023e-02, -3.8886e-02,  2.9566e-02,  8.4297e-02,  1.5495e-01,\n         -1.4055e-01, -1.0225e-01, -1.0377e-01,  1.9791e-02, -1.6317e-01,\n          9.7510e-02,  8.7863e-02,  1.5804e-01,  8.5968e-02, -3.4122e-02,\n         -2.0452e-02,  3.9726e-02,  1.6852e-01, -1.5432e-01, -5.0517e-02,\n          1.6108e-01, -1.3043e-01,  1.4944e-01, -6.8556e-02, -5.7625e-02,\n          2.6450e-02, -2.2241e-02,  4.1765e-02, -8.6861e-02,  1.2295e-01,\n         -4.3662e-02,  1.4772e-01],\n        [-1.3947e-01, -4.2261e-02,  1.1213e-01, -8.6848e-02, -1.2088e-01,\n         -2.9160e-02, -5.6242e-03,  4.2984e-02,  2.9452e-02,  1.1190e-01,\n          1.5187e-01,  1.9766e-02, -5.6081e-02, -6.2624e-03, -7.7338e-02,\n          1.6374e-01,  3.1460e-02, -1.5387e-01,  2.8073e-02, -2.1703e-02,\n          4.7149e-03, -6.0166e-02, -5.6431e-02,  1.6547e-01,  4.8012e-02,\n          4.5069e-02,  3.7705e-02, -9.7485e-02,  1.7554e-01, -6.1051e-02,\n         -1.2323e-01,  1.2730e-01],\n        [-9.7016e-03,  7.8946e-02,  1.0471e-01, -2.4013e-02,  3.7580e-02,\n          8.4392e-02,  1.0239e-01, -3.9693e-02,  1.3039e-01,  5.0141e-02,\n          7.9894e-02,  1.0030e-01, -1.3217e-01,  1.4702e-01,  6.2662e-02,\n         -4.4602e-02,  8.1001e-02,  1.1449e-01,  1.0140e-02,  8.3783e-02,\n         -1.4949e-01, -1.0373e-01,  1.0354e-01,  6.5399e-03, -1.6010e-01,\n          1.0878e-02, -8.9743e-02,  6.7370e-02,  1.3866e-01, -1.0413e-01,\n         -1.1446e-02, -1.3793e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0078,  0.0386, -0.1677,  0.2329,  0.1805,  0.1882,  0.1434,  0.0334],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0144,  0.0793, -0.0299,  0.0096, -0.0497, -0.1480, -0.2114, -0.0041,\n          0.1466,  0.2151,  0.1565, -0.2135, -0.1865,  0.0880,  0.2219,  0.2346],\n        [ 0.0807,  0.1414, -0.1764,  0.0620,  0.0698,  0.1581, -0.1403,  0.0128,\n         -0.0487, -0.1895,  0.1081, -0.2274,  0.1766,  0.1515, -0.0457,  0.1341],\n        [-0.0799,  0.1714, -0.0797, -0.2324,  0.0329, -0.0973, -0.2370,  0.0372,\n         -0.1774,  0.1588, -0.1253, -0.2252, -0.2420, -0.1207, -0.1865,  0.1677],\n        [ 0.1739, -0.0090,  0.0451, -0.0779,  0.1568, -0.1703,  0.0949, -0.1246,\n         -0.2307, -0.0587,  0.0515,  0.1533, -0.0696, -0.0140, -0.0275, -0.0617],\n        [ 0.1862, -0.1626,  0.2427, -0.1198,  0.0928, -0.1274, -0.0932, -0.1736,\n         -0.0803,  0.1745, -0.0154,  0.2182, -0.0879, -0.1620,  0.2323, -0.0566],\n        [ 0.1700, -0.0235,  0.1134,  0.2147, -0.1518, -0.1150, -0.0037, -0.2117,\n          0.1083,  0.1963,  0.1916, -0.0121,  0.0829,  0.2039,  0.1344,  0.1473],\n        [ 0.2472, -0.0088, -0.2448,  0.2373,  0.2300, -0.0899, -0.0054,  0.1361,\n         -0.1091,  0.1982, -0.1625,  0.1104,  0.0159,  0.1698,  0.1167,  0.0011],\n        [-0.1836, -0.1327, -0.0046, -0.0114, -0.1851, -0.0110, -0.0202,  0.0921,\n          0.0730, -0.0305, -0.1978,  0.0273,  0.1950,  0.1497, -0.1434, -0.0277]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1506, -0.2340,  0.2808, -0.1620], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1725,  0.2472,  0.0770,  0.2796,  0.1487, -0.1458,  0.1791, -0.1296],\n        [ 0.1058,  0.2797, -0.2333,  0.3369, -0.1458, -0.1959,  0.2890, -0.2541],\n        [ 0.3072, -0.0720,  0.3348,  0.3420, -0.3316,  0.2825,  0.0905, -0.0065],\n        [-0.0724, -0.0630,  0.0515, -0.0929, -0.0941, -0.0968,  0.1353,  0.0933]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7879f72fbbd0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s263400000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s263400000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}