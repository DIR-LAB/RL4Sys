{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s263640000"
    },
    "q_lr":	0.0005,
    "seed":	263640000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000001A0FA0DD0F0>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1907, -0.2665,  0.1344, -0.0272, -0.0590, -0.2431, -0.1062, -0.2785,\n         0.0182,  0.1509, -0.3221, -0.0676, -0.2128,  0.0270, -0.1716,  0.2806,\n         0.2838,  0.2151,  0.3024, -0.0198,  0.0100, -0.1591, -0.2814,  0.0765,\n         0.2703,  0.0167, -0.2605, -0.0924, -0.2210, -0.2033, -0.3118,  0.2843],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.1744e-02, -3.2662e-03,  7.1615e-02,  3.1748e-01,  9.6208e-02,\n         -2.8296e-01,  2.1392e-02, -1.0971e-01],\n        [ 9.4939e-02,  6.9284e-02, -2.5297e-01, -2.6417e-01,  2.5614e-01,\n          2.6986e-01, -4.3747e-03, -1.8875e-02],\n        [ 2.8932e-01,  1.2381e-01,  3.0050e-01, -3.3590e-01,  1.7838e-01,\n         -1.9062e-01,  7.7981e-02, -1.9761e-01],\n        [ 2.7464e-02,  1.4233e-01, -3.2000e-02, -1.3297e-01, -5.0468e-02,\n         -1.2265e-01,  3.1740e-01, -3.0197e-01],\n        [ 2.0659e-04,  2.9444e-02,  7.8691e-02,  5.5725e-02,  2.0565e-01,\n          3.0729e-01, -2.8951e-01,  8.1720e-02],\n        [-2.3047e-01,  4.1042e-02, -1.7589e-02,  2.7809e-01,  2.8767e-02,\n          7.0036e-02, -3.7834e-02,  2.3837e-01],\n        [ 2.9252e-01,  4.0305e-02, -1.1350e-01, -1.6128e-01,  1.9666e-01,\n          2.5560e-01,  2.8477e-01,  5.5022e-02],\n        [ 1.0002e-01,  1.2952e-01,  2.6274e-01, -7.2552e-02,  2.4547e-02,\n          2.3015e-01, -2.4573e-01,  1.7276e-01],\n        [ 1.6283e-01, -2.7462e-01,  8.6010e-04, -2.6393e-01,  2.8789e-01,\n         -2.2473e-01,  1.4368e-01,  3.2816e-01],\n        [-7.3697e-02,  2.2273e-01,  2.5087e-02,  3.7706e-02,  2.3667e-01,\n          1.1208e-03,  2.4058e-01, -2.1565e-01],\n        [ 1.6538e-01, -1.8996e-02, -1.7587e-01,  2.7294e-01,  1.6167e-02,\n          3.0486e-01,  2.0548e-01,  2.7712e-01],\n        [ 1.5966e-01,  1.6345e-01,  2.0026e-01, -1.0953e-01,  5.4671e-02,\n          2.3226e-01, -1.9367e-01, -2.1042e-01],\n        [-2.3642e-01, -2.1125e-01, -1.1199e-01, -1.6773e-01,  1.3263e-01,\n          2.8316e-01,  3.4980e-01, -3.0094e-01],\n        [-2.7030e-01,  7.3905e-02, -1.6884e-01, -3.1678e-01,  1.0737e-01,\n          2.5990e-02, -1.8838e-01,  1.4701e-01],\n        [ 2.8339e-01,  1.6933e-01,  2.5286e-02, -5.3258e-03, -1.6765e-01,\n         -1.7319e-01,  2.0102e-01, -6.6874e-02],\n        [ 9.5445e-02, -2.5469e-01, -1.0543e-01, -1.5561e-01, -2.9750e-01,\n          8.9669e-02, -3.0810e-02, -1.7130e-01],\n        [-5.0043e-03,  3.4832e-01, -1.3530e-01, -4.6258e-02,  1.1400e-01,\n         -8.4178e-03,  2.0359e-01, -3.5349e-03],\n        [ 7.7424e-02, -1.2884e-01,  3.4432e-01,  2.9691e-01, -1.6826e-01,\n         -6.4363e-02,  1.3257e-01,  2.5114e-01],\n        [-2.9583e-01,  5.5117e-02, -7.2340e-02,  7.9129e-02, -5.5750e-02,\n         -1.5400e-01,  3.0106e-01, -3.3362e-01],\n        [-9.3727e-02, -3.1673e-01, -1.7766e-01,  7.1232e-02, -7.0079e-02,\n         -3.8965e-02,  1.4154e-01,  2.9640e-01],\n        [-2.4583e-01, -2.6681e-01,  1.6727e-01, -4.9700e-02, -3.0639e-02,\n         -9.9665e-02,  2.5108e-01,  1.4528e-01],\n        [-3.3608e-01,  7.6370e-02,  2.9634e-01, -1.4055e-01,  4.7553e-02,\n         -1.2983e-02,  8.8569e-02, -1.2392e-01],\n        [-1.5150e-01,  8.1088e-02, -2.9272e-01,  2.4041e-01,  3.0772e-01,\n          9.5333e-02,  1.0701e-01,  3.0827e-01],\n        [ 3.2658e-02, -3.4894e-01, -1.3529e-01, -2.0612e-01,  7.6090e-02,\n          1.4621e-01, -3.2129e-01, -1.8568e-01],\n        [ 2.1759e-02, -1.2960e-02, -1.3128e-01,  3.3382e-01, -3.1076e-01,\n          3.4440e-01,  3.3246e-01,  2.1385e-01],\n        [-1.6366e-01,  1.1470e-01, -3.0544e-02, -3.0632e-01,  3.2589e-01,\n         -2.3631e-01, -2.7042e-01,  1.2180e-01],\n        [ 2.4540e-01, -2.1001e-01,  3.0575e-01,  2.1471e-01,  2.7968e-01,\n         -7.5424e-02,  9.4924e-02,  1.5144e-01],\n        [-4.2509e-02,  2.4732e-01,  1.6158e-01,  2.0046e-01,  2.5552e-02,\n         -7.1013e-02, -9.0012e-02,  4.5607e-02],\n        [ 9.6822e-02,  1.7575e-01,  5.4208e-02, -2.3138e-01,  7.6873e-02,\n          3.4623e-01, -1.3846e-01,  9.5488e-02],\n        [ 7.1117e-02,  9.4060e-02, -2.0906e-01,  2.6973e-01, -2.8342e-01,\n          1.4923e-01, -1.3876e-02,  1.3401e-01],\n        [ 2.9780e-01, -2.2208e-01,  1.0692e-02, -3.4761e-01, -7.8714e-02,\n          2.1491e-01, -9.7295e-02, -1.8251e-01],\n        [-2.9224e-01, -2.7828e-02, -3.2806e-01,  3.1142e-03, -2.6150e-01,\n         -2.9569e-01,  3.1125e-01, -3.2135e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1718,  0.0442,  0.0018,  0.1212, -0.0810,  0.1407, -0.0257, -0.1257,\n         0.1335,  0.0231,  0.0854, -0.0906, -0.1016, -0.1279, -0.0890, -0.1749],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 9.1465e-02, -7.1617e-02,  5.6758e-02, -4.2830e-02, -1.3746e-01,\n          3.2695e-02,  1.0567e-01,  1.5332e-01,  8.0177e-02,  8.3901e-02,\n         -1.1390e-01,  1.2489e-01, -1.1217e-01, -7.0452e-02,  1.4427e-01,\n         -1.6807e-01,  3.2816e-02,  1.2012e-01, -2.4436e-03,  1.1003e-01,\n         -1.2703e-01, -1.5247e-01,  6.7394e-03,  1.2398e-01,  1.2593e-02,\n          5.9693e-02, -9.5927e-02, -8.8963e-02,  8.3594e-03,  1.6928e-01,\n         -1.3648e-01, -1.3877e-01],\n        [ 6.1988e-03,  6.3111e-02,  3.5773e-02, -2.5487e-02,  4.8574e-02,\n          4.3558e-02,  1.3642e-01,  9.2028e-02, -6.7757e-02,  6.1511e-02,\n         -4.9527e-02, -1.6201e-01,  6.6005e-02, -4.2938e-02,  1.5094e-01,\n         -4.7702e-02, -1.4776e-01,  5.6672e-02, -4.3954e-02, -3.7937e-02,\n         -6.9058e-02, -1.4367e-01, -1.0135e-01,  7.4856e-02,  2.0503e-02,\n          8.3968e-02, -4.7926e-02, -1.3649e-01,  1.6813e-01,  1.5231e-01,\n          1.2965e-01,  2.9133e-02],\n        [-1.7337e-01, -1.5383e-01, -8.1215e-02,  1.6230e-02, -6.2726e-02,\n          1.3064e-02, -1.2691e-01,  1.4543e-01,  5.4729e-03,  5.0092e-02,\n          1.0394e-01, -8.2242e-02,  1.2227e-01, -3.9461e-02,  7.2877e-02,\n          1.0644e-02,  2.5733e-02, -1.6854e-01, -1.0994e-01,  8.6770e-02,\n         -5.5689e-02, -6.6092e-02,  2.4150e-02,  7.6686e-02,  1.6341e-01,\n          1.2831e-01,  1.6695e-01, -1.3935e-01,  2.3891e-02,  9.9742e-02,\n          6.5148e-02,  9.9477e-02],\n        [ 1.5069e-01, -8.6875e-02, -5.7670e-02,  7.1675e-02, -6.5519e-02,\n          3.2420e-02,  1.5560e-01, -1.2274e-01, -6.5566e-02, -1.6462e-01,\n          1.6757e-01, -8.0359e-02,  1.6885e-01, -8.8568e-02, -1.1676e-01,\n         -1.4134e-01, -1.2651e-01,  1.5002e-01,  1.5943e-01,  3.5655e-02,\n          3.2223e-02,  3.0583e-02,  5.7372e-02,  1.0399e-01,  4.6494e-02,\n          1.7054e-01, -4.3632e-02, -9.4129e-02,  9.4147e-02,  1.6655e-01,\n          8.3187e-02,  3.8757e-02],\n        [-6.1702e-02,  1.6646e-01, -9.9896e-02,  9.3648e-02,  1.6060e-01,\n          1.4760e-01, -1.5474e-01, -2.1842e-02,  1.2321e-01, -1.0146e-02,\n         -4.2697e-02, -1.5135e-01, -1.2936e-02,  5.3098e-02, -5.8015e-02,\n          8.9504e-02, -1.3299e-01, -1.6746e-01, -1.0664e-01,  1.0333e-01,\n          1.2536e-01, -1.6312e-01, -9.5519e-02, -5.8824e-02, -5.5367e-02,\n          4.5786e-03,  4.6073e-02,  2.2287e-02, -9.2070e-02,  1.1023e-01,\n          7.7443e-02,  1.5169e-01],\n        [-1.7625e-01, -1.2199e-01, -6.3498e-02, -1.1171e-02,  7.1688e-02,\n          1.7661e-01, -6.7362e-02, -1.2387e-01, -1.2970e-02,  5.4748e-02,\n          1.1244e-01, -2.5764e-02,  1.7321e-01, -7.2758e-02, -4.8863e-02,\n         -1.6512e-01,  6.3671e-02, -1.6609e-01, -1.1745e-01,  1.5545e-01,\n          1.1990e-01, -5.8556e-02,  2.5979e-02,  1.7302e-01,  1.1878e-01,\n         -1.0069e-01, -2.0147e-02, -1.1538e-01, -1.1474e-01,  1.7321e-01,\n          1.1585e-01,  1.4395e-01],\n        [-5.7598e-02, -4.0301e-02,  9.1032e-02,  9.6295e-02,  1.4250e-01,\n          2.8150e-02, -1.3454e-01, -2.6345e-02, -1.6020e-01,  5.3242e-02,\n         -1.6934e-02, -4.1621e-02, -2.6007e-02,  3.6569e-02, -1.2474e-01,\n          1.4240e-02, -1.2628e-01, -1.3947e-01, -1.4054e-01,  6.0285e-02,\n          1.0636e-01, -1.1152e-01,  7.7939e-02, -1.5850e-02,  9.7396e-02,\n          1.0563e-01,  6.5193e-02, -8.4345e-02,  7.1481e-02,  9.3998e-02,\n         -1.5647e-01,  4.2997e-02],\n        [-6.3359e-03, -6.1866e-03, -1.1607e-01, -5.7182e-02, -1.3229e-01,\n          1.2531e-01,  1.7472e-01, -2.7557e-02, -7.3926e-02,  9.0654e-02,\n         -1.6300e-01, -1.5369e-01,  1.1708e-01, -7.2334e-02,  1.5075e-01,\n         -1.0765e-01,  1.0702e-01, -2.6323e-02,  4.9339e-02, -1.1478e-01,\n         -3.3387e-02, -9.6233e-02,  1.6935e-01, -1.1729e-01, -6.2988e-03,\n         -1.2639e-01,  1.1935e-01, -4.3662e-03, -9.8338e-02, -9.4067e-02,\n         -3.8781e-02, -4.7525e-02],\n        [-1.4127e-01, -1.3699e-01, -4.7785e-02,  2.4291e-03, -1.3067e-01,\n          4.3912e-02,  8.5025e-02, -3.8845e-02,  8.1425e-02, -5.3199e-02,\n          1.5380e-01,  1.5141e-01,  9.0921e-02,  5.0608e-02, -2.9314e-02,\n          1.1959e-01, -1.3631e-01, -1.1247e-01,  4.7422e-02, -2.2275e-03,\n         -8.6365e-02, -4.5772e-02,  6.9241e-02, -1.5062e-01,  1.5562e-01,\n         -3.4184e-02, -9.7878e-02,  8.9097e-02, -1.2367e-01, -1.4441e-01,\n         -4.4564e-02, -1.6844e-01],\n        [ 1.3816e-01, -1.6669e-01, -1.4853e-01, -7.5563e-02,  4.7471e-02,\n          3.4491e-02,  2.5748e-02, -1.3064e-01,  1.0285e-01, -3.6500e-02,\n          1.6242e-01, -5.4349e-02,  1.3478e-01,  1.0423e-01, -1.4961e-01,\n          6.9245e-02,  2.1167e-02,  3.9606e-02,  9.1378e-02,  1.7630e-01,\n         -7.3748e-02, -3.7955e-02, -3.3130e-02,  1.2405e-01, -2.5612e-02,\n         -1.3500e-02, -1.1987e-01,  5.6156e-02, -7.9340e-03,  1.2145e-01,\n         -1.5181e-01,  2.6850e-03],\n        [ 1.2503e-01,  1.5438e-01,  1.0114e-01, -3.6378e-02, -1.1999e-01,\n          3.5510e-02, -1.3759e-01, -6.1362e-02, -1.3648e-01, -4.8378e-02,\n          1.9326e-02,  1.3271e-01,  1.0117e-02,  1.0402e-01, -8.6378e-02,\n         -3.6274e-02,  1.4697e-01,  1.5003e-01, -7.4789e-02,  5.4683e-02,\n         -1.1581e-01,  1.0513e-01, -2.1381e-02,  1.3034e-01, -1.3019e-01,\n         -9.5216e-02,  4.7564e-02,  1.1439e-01, -9.8982e-02, -1.3949e-01,\n         -4.8844e-02, -3.2805e-02],\n        [ 1.0942e-01, -8.4107e-02, -4.1855e-02, -1.6455e-01, -1.4070e-01,\n         -9.4642e-02, -1.3723e-01, -5.1274e-02, -1.5645e-01,  5.7290e-02,\n         -7.4652e-02, -1.4201e-01,  6.5898e-02,  2.5692e-02, -1.2561e-01,\n          1.7644e-01,  1.7546e-02, -1.7113e-01, -1.3192e-01,  9.4774e-02,\n          8.1362e-02,  3.3784e-02,  4.4447e-02, -1.5893e-01,  7.1325e-02,\n         -1.7075e-01, -1.1767e-01, -1.2147e-02,  1.7087e-01,  1.1193e-01,\n         -1.2033e-03, -6.0970e-02],\n        [ 9.2925e-02,  1.1834e-01, -9.8367e-02, -1.4174e-01,  5.7123e-02,\n         -1.2311e-02,  1.3928e-01, -1.2256e-01, -4.6888e-02, -8.1157e-02,\n          1.0748e-01,  1.2053e-01,  9.3097e-02,  1.3860e-01, -5.7395e-02,\n         -8.7202e-02, -1.0226e-01, -6.1011e-02, -9.2992e-02,  1.3693e-01,\n          9.3662e-02,  1.5088e-01,  1.7583e-01,  1.5103e-01,  7.2501e-02,\n         -1.6064e-01,  1.5865e-02, -1.0005e-01,  8.9669e-02, -4.3871e-02,\n          1.5878e-01,  1.7360e-01],\n        [ 7.8312e-02,  5.1816e-02, -1.7031e-01, -1.6889e-01, -6.6725e-02,\n          3.8690e-02, -9.5297e-02, -7.5522e-02,  1.0243e-01,  1.2266e-01,\n         -4.1157e-05,  7.5187e-03,  1.5563e-01, -2.3909e-02, -1.9256e-02,\n         -3.5076e-02,  1.1881e-01,  8.0280e-03, -8.9474e-02,  7.2984e-02,\n         -6.7540e-02, -1.0475e-01, -1.4325e-01, -6.0140e-02, -1.0608e-01,\n          8.6508e-02, -9.5406e-02, -8.7364e-02, -1.6951e-01, -1.2003e-01,\n          1.7135e-01, -1.2537e-01],\n        [-5.3095e-02,  8.8334e-03, -8.6294e-02,  1.1534e-01,  4.9854e-02,\n         -5.8215e-02, -7.5686e-02, -1.4423e-01, -1.0426e-01,  1.1165e-01,\n         -6.5868e-02, -7.4008e-02,  1.4126e-02, -1.7585e-01,  1.1099e-01,\n          2.9342e-02,  9.1339e-02,  1.7536e-01,  1.5829e-01, -3.2421e-02,\n          1.0159e-01, -8.9686e-02, -6.4886e-03,  1.4029e-01, -3.0140e-02,\n         -1.2765e-01, -1.6317e-01,  4.8182e-02,  1.0993e-01, -1.5675e-01,\n          1.3812e-01, -1.7535e-01],\n        [ 1.7117e-01,  1.2557e-01, -1.5074e-01, -1.2908e-01,  7.3237e-02,\n          8.1454e-02, -1.6437e-01, -1.3299e-03,  4.9632e-02,  4.2165e-02,\n          8.7542e-02,  1.1302e-01, -9.1003e-03,  4.2548e-02,  2.0990e-02,\n          1.5451e-01, -1.7172e-01,  1.6359e-01, -1.0244e-01,  1.2850e-01,\n          1.1108e-01,  1.9769e-02, -1.2533e-01,  8.7486e-02, -1.1749e-01,\n          1.0909e-01,  1.4312e-01, -3.4381e-02, -1.4205e-01, -9.1080e-02,\n         -3.6274e-02,  2.7516e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0145, -0.1999, -0.1417,  0.0330,  0.1889,  0.1799,  0.1714, -0.0941],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1367,  0.1963,  0.1850,  0.0360, -0.0709,  0.1255,  0.0496,  0.1077,\n          0.1014,  0.0981, -0.0374, -0.1218,  0.1112, -0.1232, -0.0985,  0.2384],\n        [-0.1635,  0.0824,  0.2054, -0.1015,  0.0848,  0.1379,  0.2101, -0.1170,\n         -0.1565,  0.0747, -0.2420,  0.1473,  0.0157, -0.1078,  0.1929, -0.1335],\n        [-0.1919, -0.0802,  0.0541, -0.1959, -0.0446,  0.0011, -0.1624,  0.1906,\n          0.1669,  0.1971,  0.0093,  0.0874, -0.2494,  0.1951, -0.1449,  0.2263],\n        [ 0.0814,  0.0283, -0.1997,  0.0679, -0.2182, -0.0115,  0.2271, -0.1255,\n         -0.2105,  0.0540,  0.0007, -0.2330, -0.1446,  0.2141, -0.1101, -0.2178],\n        [-0.1629, -0.1560, -0.0246, -0.2053,  0.0932, -0.0797, -0.0848,  0.1187,\n          0.1440,  0.1032, -0.0951,  0.2066,  0.1750, -0.1156,  0.0107, -0.0816],\n        [-0.1930, -0.2029,  0.1031,  0.2132, -0.1934,  0.0606, -0.1990, -0.0791,\n         -0.1062,  0.1071, -0.0535,  0.2112,  0.2474,  0.2292,  0.0708,  0.0705],\n        [-0.1820, -0.0121,  0.0802, -0.0751, -0.0976,  0.2295, -0.1035,  0.0137,\n          0.1768,  0.0687, -0.1649,  0.1629,  0.1309, -0.1222,  0.0921,  0.1927],\n        [-0.1408,  0.2465, -0.2387, -0.2079, -0.0462,  0.0282, -0.2422, -0.0450,\n          0.1532, -0.0659, -0.1130,  0.1534,  0.0254,  0.1714,  0.1690, -0.2238]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0275], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3275, -0.0337, -0.0220,  0.0756,  0.1590,  0.1499, -0.2628, -0.1824]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-8.1744e-02, -3.2662e-03,  7.1615e-02,  3.1748e-01,  9.6208e-02,\n         -2.8296e-01,  2.1392e-02, -1.0971e-01],\n        [ 9.4939e-02,  6.9284e-02, -2.5297e-01, -2.6417e-01,  2.5614e-01,\n          2.6986e-01, -4.3747e-03, -1.8875e-02],\n        [ 2.8932e-01,  1.2381e-01,  3.0050e-01, -3.3590e-01,  1.7838e-01,\n         -1.9062e-01,  7.7981e-02, -1.9761e-01],\n        [ 2.7464e-02,  1.4233e-01, -3.2000e-02, -1.3297e-01, -5.0468e-02,\n         -1.2265e-01,  3.1740e-01, -3.0197e-01],\n        [ 2.0659e-04,  2.9444e-02,  7.8691e-02,  5.5725e-02,  2.0565e-01,\n          3.0729e-01, -2.8951e-01,  8.1720e-02],\n        [-2.3047e-01,  4.1042e-02, -1.7589e-02,  2.7809e-01,  2.8767e-02,\n          7.0036e-02, -3.7834e-02,  2.3837e-01],\n        [ 2.9252e-01,  4.0305e-02, -1.1350e-01, -1.6128e-01,  1.9666e-01,\n          2.5560e-01,  2.8477e-01,  5.5022e-02],\n        [ 1.0002e-01,  1.2952e-01,  2.6274e-01, -7.2552e-02,  2.4547e-02,\n          2.3015e-01, -2.4573e-01,  1.7276e-01],\n        [ 1.6283e-01, -2.7462e-01,  8.6010e-04, -2.6393e-01,  2.8789e-01,\n         -2.2473e-01,  1.4368e-01,  3.2816e-01],\n        [-7.3697e-02,  2.2273e-01,  2.5087e-02,  3.7706e-02,  2.3667e-01,\n          1.1208e-03,  2.4058e-01, -2.1565e-01],\n        [ 1.6538e-01, -1.8996e-02, -1.7587e-01,  2.7294e-01,  1.6167e-02,\n          3.0486e-01,  2.0548e-01,  2.7712e-01],\n        [ 1.5966e-01,  1.6345e-01,  2.0026e-01, -1.0953e-01,  5.4671e-02,\n          2.3226e-01, -1.9367e-01, -2.1042e-01],\n        [-2.3642e-01, -2.1125e-01, -1.1199e-01, -1.6773e-01,  1.3263e-01,\n          2.8316e-01,  3.4980e-01, -3.0094e-01],\n        [-2.7030e-01,  7.3905e-02, -1.6884e-01, -3.1678e-01,  1.0737e-01,\n          2.5990e-02, -1.8838e-01,  1.4701e-01],\n        [ 2.8339e-01,  1.6933e-01,  2.5286e-02, -5.3258e-03, -1.6765e-01,\n         -1.7319e-01,  2.0102e-01, -6.6874e-02],\n        [ 9.5445e-02, -2.5469e-01, -1.0543e-01, -1.5561e-01, -2.9750e-01,\n          8.9669e-02, -3.0810e-02, -1.7130e-01],\n        [-5.0043e-03,  3.4832e-01, -1.3530e-01, -4.6258e-02,  1.1400e-01,\n         -8.4178e-03,  2.0359e-01, -3.5349e-03],\n        [ 7.7424e-02, -1.2884e-01,  3.4432e-01,  2.9691e-01, -1.6826e-01,\n         -6.4363e-02,  1.3257e-01,  2.5114e-01],\n        [-2.9583e-01,  5.5117e-02, -7.2340e-02,  7.9129e-02, -5.5750e-02,\n         -1.5400e-01,  3.0106e-01, -3.3362e-01],\n        [-9.3727e-02, -3.1673e-01, -1.7766e-01,  7.1232e-02, -7.0079e-02,\n         -3.8965e-02,  1.4154e-01,  2.9640e-01],\n        [-2.4583e-01, -2.6681e-01,  1.6727e-01, -4.9700e-02, -3.0639e-02,\n         -9.9665e-02,  2.5108e-01,  1.4528e-01],\n        [-3.3608e-01,  7.6370e-02,  2.9634e-01, -1.4055e-01,  4.7553e-02,\n         -1.2983e-02,  8.8569e-02, -1.2392e-01],\n        [-1.5150e-01,  8.1088e-02, -2.9272e-01,  2.4041e-01,  3.0772e-01,\n          9.5333e-02,  1.0701e-01,  3.0827e-01],\n        [ 3.2658e-02, -3.4894e-01, -1.3529e-01, -2.0612e-01,  7.6090e-02,\n          1.4621e-01, -3.2129e-01, -1.8568e-01],\n        [ 2.1759e-02, -1.2960e-02, -1.3128e-01,  3.3382e-01, -3.1076e-01,\n          3.4440e-01,  3.3246e-01,  2.1385e-01],\n        [-1.6366e-01,  1.1470e-01, -3.0544e-02, -3.0632e-01,  3.2589e-01,\n         -2.3631e-01, -2.7042e-01,  1.2180e-01],\n        [ 2.4540e-01, -2.1001e-01,  3.0575e-01,  2.1471e-01,  2.7968e-01,\n         -7.5424e-02,  9.4924e-02,  1.5144e-01],\n        [-4.2509e-02,  2.4732e-01,  1.6158e-01,  2.0046e-01,  2.5552e-02,\n         -7.1013e-02, -9.0012e-02,  4.5607e-02],\n        [ 9.6822e-02,  1.7575e-01,  5.4208e-02, -2.3138e-01,  7.6873e-02,\n          3.4623e-01, -1.3846e-01,  9.5488e-02],\n        [ 7.1117e-02,  9.4060e-02, -2.0906e-01,  2.6973e-01, -2.8342e-01,\n          1.4923e-01, -1.3876e-02,  1.3401e-01],\n        [ 2.9780e-01, -2.2208e-01,  1.0692e-02, -3.4761e-01, -7.8714e-02,\n          2.1491e-01, -9.7295e-02, -1.8251e-01],\n        [-2.9224e-01, -2.7828e-02, -3.2806e-01,  3.1142e-03, -2.6150e-01,\n         -2.9569e-01,  3.1125e-01, -3.2135e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1907, -0.2665,  0.1344, -0.0272, -0.0590, -0.2431, -0.1062, -0.2785,\n         0.0182,  0.1509, -0.3221, -0.0676, -0.2128,  0.0270, -0.1716,  0.2806,\n         0.2838,  0.2151,  0.3024, -0.0198,  0.0100, -0.1591, -0.2814,  0.0765,\n         0.2703,  0.0167, -0.2605, -0.0924, -0.2210, -0.2033, -0.3118,  0.2843],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 9.1465e-02, -7.1617e-02,  5.6758e-02, -4.2830e-02, -1.3746e-01,\n          3.2695e-02,  1.0567e-01,  1.5332e-01,  8.0177e-02,  8.3901e-02,\n         -1.1390e-01,  1.2489e-01, -1.1217e-01, -7.0452e-02,  1.4427e-01,\n         -1.6807e-01,  3.2816e-02,  1.2012e-01, -2.4436e-03,  1.1003e-01,\n         -1.2703e-01, -1.5247e-01,  6.7394e-03,  1.2398e-01,  1.2593e-02,\n          5.9693e-02, -9.5927e-02, -8.8963e-02,  8.3594e-03,  1.6928e-01,\n         -1.3648e-01, -1.3877e-01],\n        [ 6.1988e-03,  6.3111e-02,  3.5773e-02, -2.5487e-02,  4.8574e-02,\n          4.3558e-02,  1.3642e-01,  9.2028e-02, -6.7757e-02,  6.1511e-02,\n         -4.9527e-02, -1.6201e-01,  6.6005e-02, -4.2938e-02,  1.5094e-01,\n         -4.7702e-02, -1.4776e-01,  5.6672e-02, -4.3954e-02, -3.7937e-02,\n         -6.9058e-02, -1.4367e-01, -1.0135e-01,  7.4856e-02,  2.0503e-02,\n          8.3968e-02, -4.7926e-02, -1.3649e-01,  1.6813e-01,  1.5231e-01,\n          1.2965e-01,  2.9133e-02],\n        [-1.7337e-01, -1.5383e-01, -8.1215e-02,  1.6230e-02, -6.2726e-02,\n          1.3064e-02, -1.2691e-01,  1.4543e-01,  5.4729e-03,  5.0092e-02,\n          1.0394e-01, -8.2242e-02,  1.2227e-01, -3.9461e-02,  7.2877e-02,\n          1.0644e-02,  2.5733e-02, -1.6854e-01, -1.0994e-01,  8.6770e-02,\n         -5.5689e-02, -6.6092e-02,  2.4150e-02,  7.6686e-02,  1.6341e-01,\n          1.2831e-01,  1.6695e-01, -1.3935e-01,  2.3891e-02,  9.9742e-02,\n          6.5148e-02,  9.9477e-02],\n        [ 1.5069e-01, -8.6875e-02, -5.7670e-02,  7.1675e-02, -6.5519e-02,\n          3.2420e-02,  1.5560e-01, -1.2274e-01, -6.5566e-02, -1.6462e-01,\n          1.6757e-01, -8.0359e-02,  1.6885e-01, -8.8568e-02, -1.1676e-01,\n         -1.4134e-01, -1.2651e-01,  1.5002e-01,  1.5943e-01,  3.5655e-02,\n          3.2223e-02,  3.0583e-02,  5.7372e-02,  1.0399e-01,  4.6494e-02,\n          1.7054e-01, -4.3632e-02, -9.4129e-02,  9.4147e-02,  1.6655e-01,\n          8.3187e-02,  3.8757e-02],\n        [-6.1702e-02,  1.6646e-01, -9.9896e-02,  9.3648e-02,  1.6060e-01,\n          1.4760e-01, -1.5474e-01, -2.1842e-02,  1.2321e-01, -1.0146e-02,\n         -4.2697e-02, -1.5135e-01, -1.2936e-02,  5.3098e-02, -5.8015e-02,\n          8.9504e-02, -1.3299e-01, -1.6746e-01, -1.0664e-01,  1.0333e-01,\n          1.2536e-01, -1.6312e-01, -9.5519e-02, -5.8824e-02, -5.5367e-02,\n          4.5786e-03,  4.6073e-02,  2.2287e-02, -9.2070e-02,  1.1023e-01,\n          7.7443e-02,  1.5169e-01],\n        [-1.7625e-01, -1.2199e-01, -6.3498e-02, -1.1171e-02,  7.1688e-02,\n          1.7661e-01, -6.7362e-02, -1.2387e-01, -1.2970e-02,  5.4748e-02,\n          1.1244e-01, -2.5764e-02,  1.7321e-01, -7.2758e-02, -4.8863e-02,\n         -1.6512e-01,  6.3671e-02, -1.6609e-01, -1.1745e-01,  1.5545e-01,\n          1.1990e-01, -5.8556e-02,  2.5979e-02,  1.7302e-01,  1.1878e-01,\n         -1.0069e-01, -2.0147e-02, -1.1538e-01, -1.1474e-01,  1.7321e-01,\n          1.1585e-01,  1.4395e-01],\n        [-5.7598e-02, -4.0301e-02,  9.1032e-02,  9.6295e-02,  1.4250e-01,\n          2.8150e-02, -1.3454e-01, -2.6345e-02, -1.6020e-01,  5.3242e-02,\n         -1.6934e-02, -4.1621e-02, -2.6007e-02,  3.6569e-02, -1.2474e-01,\n          1.4240e-02, -1.2628e-01, -1.3947e-01, -1.4054e-01,  6.0285e-02,\n          1.0636e-01, -1.1152e-01,  7.7939e-02, -1.5850e-02,  9.7396e-02,\n          1.0563e-01,  6.5193e-02, -8.4345e-02,  7.1481e-02,  9.3998e-02,\n         -1.5647e-01,  4.2997e-02],\n        [-6.3359e-03, -6.1866e-03, -1.1607e-01, -5.7182e-02, -1.3229e-01,\n          1.2531e-01,  1.7472e-01, -2.7557e-02, -7.3926e-02,  9.0654e-02,\n         -1.6300e-01, -1.5369e-01,  1.1708e-01, -7.2334e-02,  1.5075e-01,\n         -1.0765e-01,  1.0702e-01, -2.6323e-02,  4.9339e-02, -1.1478e-01,\n         -3.3387e-02, -9.6233e-02,  1.6935e-01, -1.1729e-01, -6.2988e-03,\n         -1.2639e-01,  1.1935e-01, -4.3662e-03, -9.8338e-02, -9.4067e-02,\n         -3.8781e-02, -4.7525e-02],\n        [-1.4127e-01, -1.3699e-01, -4.7785e-02,  2.4291e-03, -1.3067e-01,\n          4.3912e-02,  8.5025e-02, -3.8845e-02,  8.1425e-02, -5.3199e-02,\n          1.5380e-01,  1.5141e-01,  9.0921e-02,  5.0608e-02, -2.9314e-02,\n          1.1959e-01, -1.3631e-01, -1.1247e-01,  4.7422e-02, -2.2275e-03,\n         -8.6365e-02, -4.5772e-02,  6.9241e-02, -1.5062e-01,  1.5562e-01,\n         -3.4184e-02, -9.7878e-02,  8.9097e-02, -1.2367e-01, -1.4441e-01,\n         -4.4564e-02, -1.6844e-01],\n        [ 1.3816e-01, -1.6669e-01, -1.4853e-01, -7.5563e-02,  4.7471e-02,\n          3.4491e-02,  2.5748e-02, -1.3064e-01,  1.0285e-01, -3.6500e-02,\n          1.6242e-01, -5.4349e-02,  1.3478e-01,  1.0423e-01, -1.4961e-01,\n          6.9245e-02,  2.1167e-02,  3.9606e-02,  9.1378e-02,  1.7630e-01,\n         -7.3748e-02, -3.7955e-02, -3.3130e-02,  1.2405e-01, -2.5612e-02,\n         -1.3500e-02, -1.1987e-01,  5.6156e-02, -7.9340e-03,  1.2145e-01,\n         -1.5181e-01,  2.6850e-03],\n        [ 1.2503e-01,  1.5438e-01,  1.0114e-01, -3.6378e-02, -1.1999e-01,\n          3.5510e-02, -1.3759e-01, -6.1362e-02, -1.3648e-01, -4.8378e-02,\n          1.9326e-02,  1.3271e-01,  1.0117e-02,  1.0402e-01, -8.6378e-02,\n         -3.6274e-02,  1.4697e-01,  1.5003e-01, -7.4789e-02,  5.4683e-02,\n         -1.1581e-01,  1.0513e-01, -2.1381e-02,  1.3034e-01, -1.3019e-01,\n         -9.5216e-02,  4.7564e-02,  1.1439e-01, -9.8982e-02, -1.3949e-01,\n         -4.8844e-02, -3.2805e-02],\n        [ 1.0942e-01, -8.4107e-02, -4.1855e-02, -1.6455e-01, -1.4070e-01,\n         -9.4642e-02, -1.3723e-01, -5.1274e-02, -1.5645e-01,  5.7290e-02,\n         -7.4652e-02, -1.4201e-01,  6.5898e-02,  2.5692e-02, -1.2561e-01,\n          1.7644e-01,  1.7546e-02, -1.7113e-01, -1.3192e-01,  9.4774e-02,\n          8.1362e-02,  3.3784e-02,  4.4447e-02, -1.5893e-01,  7.1325e-02,\n         -1.7075e-01, -1.1767e-01, -1.2147e-02,  1.7087e-01,  1.1193e-01,\n         -1.2033e-03, -6.0970e-02],\n        [ 9.2925e-02,  1.1834e-01, -9.8367e-02, -1.4174e-01,  5.7123e-02,\n         -1.2311e-02,  1.3928e-01, -1.2256e-01, -4.6888e-02, -8.1157e-02,\n          1.0748e-01,  1.2053e-01,  9.3097e-02,  1.3860e-01, -5.7395e-02,\n         -8.7202e-02, -1.0226e-01, -6.1011e-02, -9.2992e-02,  1.3693e-01,\n          9.3662e-02,  1.5088e-01,  1.7583e-01,  1.5103e-01,  7.2501e-02,\n         -1.6064e-01,  1.5865e-02, -1.0005e-01,  8.9669e-02, -4.3871e-02,\n          1.5878e-01,  1.7360e-01],\n        [ 7.8312e-02,  5.1816e-02, -1.7031e-01, -1.6889e-01, -6.6725e-02,\n          3.8690e-02, -9.5297e-02, -7.5522e-02,  1.0243e-01,  1.2266e-01,\n         -4.1157e-05,  7.5187e-03,  1.5563e-01, -2.3909e-02, -1.9256e-02,\n         -3.5076e-02,  1.1881e-01,  8.0280e-03, -8.9474e-02,  7.2984e-02,\n         -6.7540e-02, -1.0475e-01, -1.4325e-01, -6.0140e-02, -1.0608e-01,\n          8.6508e-02, -9.5406e-02, -8.7364e-02, -1.6951e-01, -1.2003e-01,\n          1.7135e-01, -1.2537e-01],\n        [-5.3095e-02,  8.8334e-03, -8.6294e-02,  1.1534e-01,  4.9854e-02,\n         -5.8215e-02, -7.5686e-02, -1.4423e-01, -1.0426e-01,  1.1165e-01,\n         -6.5868e-02, -7.4008e-02,  1.4126e-02, -1.7585e-01,  1.1099e-01,\n          2.9342e-02,  9.1339e-02,  1.7536e-01,  1.5829e-01, -3.2421e-02,\n          1.0159e-01, -8.9686e-02, -6.4886e-03,  1.4029e-01, -3.0140e-02,\n         -1.2765e-01, -1.6317e-01,  4.8182e-02,  1.0993e-01, -1.5675e-01,\n          1.3812e-01, -1.7535e-01],\n        [ 1.7117e-01,  1.2557e-01, -1.5074e-01, -1.2908e-01,  7.3237e-02,\n          8.1454e-02, -1.6437e-01, -1.3299e-03,  4.9632e-02,  4.2165e-02,\n          8.7542e-02,  1.1302e-01, -9.1003e-03,  4.2548e-02,  2.0990e-02,\n          1.5451e-01, -1.7172e-01,  1.6359e-01, -1.0244e-01,  1.2850e-01,\n          1.1108e-01,  1.9769e-02, -1.2533e-01,  8.7486e-02, -1.1749e-01,\n          1.0909e-01,  1.4312e-01, -3.4381e-02, -1.4205e-01, -9.1080e-02,\n         -3.6274e-02,  2.7516e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1718,  0.0442,  0.0018,  0.1212, -0.0810,  0.1407, -0.0257, -0.1257,\n         0.1335,  0.0231,  0.0854, -0.0906, -0.1016, -0.1279, -0.0890, -0.1749],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1367,  0.1963,  0.1850,  0.0360, -0.0709,  0.1255,  0.0496,  0.1077,\n          0.1014,  0.0981, -0.0374, -0.1218,  0.1112, -0.1232, -0.0985,  0.2384],\n        [-0.1635,  0.0824,  0.2054, -0.1015,  0.0848,  0.1379,  0.2101, -0.1170,\n         -0.1565,  0.0747, -0.2420,  0.1473,  0.0157, -0.1078,  0.1929, -0.1335],\n        [-0.1919, -0.0802,  0.0541, -0.1959, -0.0446,  0.0011, -0.1624,  0.1906,\n          0.1669,  0.1971,  0.0093,  0.0874, -0.2494,  0.1951, -0.1449,  0.2263],\n        [ 0.0814,  0.0283, -0.1997,  0.0679, -0.2182, -0.0115,  0.2271, -0.1255,\n         -0.2105,  0.0540,  0.0007, -0.2330, -0.1446,  0.2141, -0.1101, -0.2178],\n        [-0.1629, -0.1560, -0.0246, -0.2053,  0.0932, -0.0797, -0.0848,  0.1187,\n          0.1440,  0.1032, -0.0951,  0.2066,  0.1750, -0.1156,  0.0107, -0.0816],\n        [-0.1930, -0.2029,  0.1031,  0.2132, -0.1934,  0.0606, -0.1990, -0.0791,\n         -0.1062,  0.1071, -0.0535,  0.2112,  0.2474,  0.2292,  0.0708,  0.0705],\n        [-0.1820, -0.0121,  0.0802, -0.0751, -0.0976,  0.2295, -0.1035,  0.0137,\n          0.1768,  0.0687, -0.1649,  0.1629,  0.1309, -0.1222,  0.0921,  0.1927],\n        [-0.1408,  0.2465, -0.2387, -0.2079, -0.0462,  0.0282, -0.2422, -0.0450,\n          0.1532, -0.0659, -0.1130,  0.1534,  0.0254,  0.1714,  0.1690, -0.2238]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0145, -0.1999, -0.1417,  0.0330,  0.1889,  0.1799,  0.1714, -0.0941],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3275, -0.0337, -0.0220,  0.0756,  0.1590,  0.1499, -0.2628, -0.1824]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0275], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000001A0B1BE22F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001A0FA0DD2D0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s263640000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s263640000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}