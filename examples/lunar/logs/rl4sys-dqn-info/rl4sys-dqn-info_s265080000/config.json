{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s265080000"
    },
    "q_lr":	0.0005,
    "seed":	265080000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000002A39C7890C0>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1782, -0.1942,  0.2839, -0.2677,  0.3268, -0.2706, -0.0127, -0.0177,\n        -0.2342, -0.0100, -0.1302, -0.3214,  0.2605,  0.0148,  0.0081, -0.2454,\n        -0.3224, -0.1519, -0.0981,  0.2543,  0.1906,  0.3244, -0.3192,  0.2084,\n        -0.1800, -0.1716,  0.0114,  0.3474,  0.0097, -0.0752,  0.1573, -0.1112],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0149,  0.0457, -0.2417, -0.3147,  0.1913, -0.2992,  0.0525,  0.0575],\n        [ 0.1821, -0.1847, -0.0057,  0.2553, -0.1618,  0.0907, -0.1494,  0.2405],\n        [-0.1611,  0.0171, -0.1148,  0.3414,  0.2888, -0.0870, -0.1619, -0.0215],\n        [-0.2067,  0.1419,  0.0790,  0.3040, -0.1209, -0.3074, -0.2798,  0.1730],\n        [ 0.2314, -0.3308,  0.0153,  0.2134,  0.1467, -0.3041,  0.2021, -0.0664],\n        [ 0.3308, -0.2381, -0.0320,  0.0255, -0.0832,  0.0296, -0.0426,  0.2466],\n        [ 0.0495, -0.1729, -0.2090, -0.0492, -0.2520,  0.2187,  0.1701,  0.2678],\n        [ 0.1892, -0.3475,  0.2223, -0.1651,  0.1107,  0.1021,  0.2217,  0.3234],\n        [ 0.1268, -0.0949, -0.1571,  0.1973,  0.2559, -0.1289, -0.1151, -0.0610],\n        [-0.1177,  0.2207, -0.0442,  0.3535, -0.2812, -0.1788,  0.1282, -0.2752],\n        [-0.2945, -0.2669, -0.0190, -0.3506,  0.3267,  0.0687,  0.0059, -0.0983],\n        [-0.1870, -0.2577, -0.1748,  0.1389, -0.3069, -0.0677, -0.1633,  0.2132],\n        [ 0.2995, -0.0792,  0.1386,  0.3395, -0.0219,  0.2201, -0.0574,  0.3077],\n        [ 0.1748, -0.2874,  0.2297, -0.1522, -0.2726, -0.0388, -0.3386, -0.0488],\n        [-0.0033, -0.2120,  0.0473,  0.1571, -0.2341, -0.0734,  0.0393,  0.2901],\n        [-0.1319,  0.3313,  0.2339,  0.2159, -0.0425, -0.3225,  0.1892, -0.1845],\n        [-0.0951, -0.2088, -0.3484, -0.2550,  0.3286, -0.3416, -0.1256, -0.3324],\n        [ 0.2390,  0.1615,  0.0958,  0.1433,  0.2787, -0.0880,  0.0896, -0.1368],\n        [ 0.0898,  0.1873, -0.1788,  0.2862, -0.2134, -0.0174, -0.1528,  0.0823],\n        [ 0.0362,  0.2193,  0.2732,  0.2516,  0.1138,  0.0113, -0.2806, -0.2337],\n        [ 0.2150, -0.1845, -0.3449,  0.1207,  0.2781,  0.1009, -0.1942,  0.0115],\n        [ 0.2454,  0.1604,  0.1425, -0.0230, -0.2810,  0.3370, -0.0555,  0.2666],\n        [ 0.3403,  0.2653, -0.2028,  0.0707, -0.3472, -0.1122, -0.0555,  0.3361],\n        [-0.1061, -0.2084,  0.0935, -0.2102, -0.3175,  0.2102, -0.0697, -0.0235],\n        [-0.1461, -0.2301, -0.3535,  0.1791, -0.2317, -0.1973, -0.2806, -0.3026],\n        [ 0.1738, -0.1299,  0.0018, -0.1649,  0.2841,  0.0074, -0.1702,  0.0781],\n        [ 0.1504,  0.2077, -0.0811,  0.1522,  0.2582,  0.0952, -0.1719,  0.1348],\n        [-0.2653, -0.3187, -0.0502, -0.1859, -0.1350,  0.0515,  0.1060, -0.3386],\n        [-0.3525, -0.0266,  0.2403,  0.0067, -0.0866, -0.2232,  0.2305,  0.1421],\n        [ 0.0442,  0.1894,  0.2390, -0.2221,  0.1433,  0.3490, -0.0513,  0.0143],\n        [ 0.3025,  0.0676,  0.0853, -0.0063, -0.2655, -0.2964, -0.0599, -0.0982],\n        [ 0.0569, -0.2661,  0.3215,  0.2460, -0.0634,  0.3044, -0.1961,  0.1410]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0108, -0.1416, -0.0077,  0.1112,  0.0809,  0.0152, -0.0206, -0.0246,\n        -0.1649,  0.0487,  0.0886, -0.1651, -0.1429,  0.1151, -0.1020,  0.1588],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.6413e-01,  1.4335e-01, -5.8750e-02, -4.0428e-02, -3.0337e-02,\n          2.3751e-02,  5.5938e-03, -3.9716e-02,  8.8058e-02,  3.4394e-02,\n          1.2924e-01,  8.1000e-02,  1.6497e-01,  4.4020e-02, -6.1299e-02,\n          8.0713e-02,  1.2921e-01, -1.2166e-01,  1.7450e-01, -1.0407e-01,\n          4.3480e-02,  5.5096e-02,  8.9829e-02,  1.0045e-01, -1.4300e-01,\n          8.3964e-02,  3.2751e-02, -1.1964e-01, -8.7487e-02, -1.7410e-01,\n         -1.2213e-01, -4.2321e-02],\n        [-1.6368e-02,  8.8842e-02, -7.6623e-02, -1.3996e-01, -1.7021e-01,\n          1.7001e-01, -3.1354e-02,  1.3045e-01, -8.4552e-02,  1.1612e-01,\n         -5.9137e-02, -1.0642e-01,  2.1287e-02, -9.5249e-02,  1.0453e-01,\n         -7.4388e-02,  9.9092e-02,  1.6329e-01,  2.6999e-03,  9.9772e-02,\n          1.4743e-01,  1.1940e-01,  1.1737e-01,  1.7935e-02,  7.3365e-02,\n          2.3581e-02,  1.3489e-01,  9.2287e-02,  1.4353e-01, -3.2581e-02,\n         -9.8457e-02, -2.8281e-02],\n        [ 1.0471e-01, -8.3944e-02, -1.0978e-01, -4.8852e-02,  4.9790e-02,\n          1.1280e-01, -1.3320e-01,  2.2371e-02, -1.3933e-01, -3.3293e-02,\n         -1.6755e-01, -8.7638e-02, -2.1916e-02, -1.5739e-01, -1.3579e-01,\n          1.3504e-01, -1.6801e-01, -1.5991e-01, -1.4361e-01, -1.2831e-01,\n          1.7533e-01, -9.8722e-02,  8.0724e-02,  9.6264e-02,  7.8007e-03,\n         -5.9339e-02,  6.5676e-02, -8.4677e-04, -1.6907e-01,  1.3162e-01,\n         -1.4133e-01,  9.6948e-02],\n        [ 1.0357e-01, -9.6167e-02,  1.5862e-01,  4.1867e-02,  3.4097e-02,\n         -1.1468e-01,  5.1326e-02, -5.1490e-02,  9.2020e-02,  1.4204e-01,\n          1.0582e-01,  1.4625e-01,  1.5157e-01,  1.3679e-01, -1.3841e-01,\n         -4.2276e-02,  1.1735e-01, -3.8858e-02,  1.3722e-01,  1.7155e-01,\n         -4.4817e-04, -1.0627e-01,  1.0226e-01, -7.1835e-02, -7.3891e-02,\n         -4.2154e-02, -4.5174e-02,  7.8189e-03, -9.0535e-02,  3.4355e-02,\n          1.1807e-01, -2.1472e-02],\n        [-5.5445e-02, -6.7880e-03,  1.3251e-01,  2.7035e-02,  1.3918e-01,\n         -8.1067e-03,  4.5147e-02, -1.4228e-01,  1.0130e-01,  1.2939e-01,\n         -3.3566e-02, -6.4037e-02,  9.0576e-02,  5.9272e-02,  5.9082e-02,\n          4.4948e-02,  9.3392e-02, -1.1295e-01, -6.4078e-04, -3.7534e-02,\n          1.2356e-01, -1.4235e-01, -1.4101e-01,  2.0878e-02,  6.8926e-02,\n          9.5098e-02,  1.4887e-01,  1.3865e-01,  6.3475e-02, -1.7550e-01,\n         -8.8957e-02, -3.5303e-02],\n        [ 1.3381e-01, -6.9250e-02,  1.6204e-01, -1.6855e-01, -2.6433e-02,\n         -1.6183e-01, -1.6870e-01,  9.5466e-02, -1.7259e-01,  4.9685e-02,\n          1.1318e-01, -2.7693e-02, -1.4627e-02, -1.4595e-01, -4.0936e-02,\n         -1.6553e-01, -6.1002e-02, -8.3314e-02, -6.1047e-02,  1.2799e-01,\n          5.7157e-02, -1.5961e-01, -3.2025e-02, -8.0172e-02,  4.5735e-02,\n         -1.4938e-01,  1.4074e-01,  2.4350e-02, -1.1828e-01,  1.1449e-01,\n         -1.1581e-01, -1.1242e-01],\n        [ 1.7430e-01, -1.4558e-01, -3.2254e-02,  1.2282e-01,  1.7129e-01,\n         -4.1555e-02, -1.3578e-01,  1.7575e-02, -1.4246e-01, -9.9578e-02,\n          1.1428e-01, -1.1346e-01,  8.6479e-02,  1.6179e-01,  6.3006e-02,\n         -1.6273e-01,  1.7171e-01,  1.2330e-01,  1.1335e-01,  1.4811e-01,\n          1.0235e-01, -5.1442e-02, -2.3210e-02,  4.5902e-02, -8.8814e-02,\n          1.5167e-01,  5.0959e-02, -1.1642e-01,  9.1138e-02, -1.9897e-02,\n         -1.6045e-01,  1.3662e-01],\n        [ 3.8606e-02,  1.2163e-01,  1.1736e-01,  9.3573e-02, -1.4911e-01,\n          1.2895e-01,  4.6811e-02,  2.1346e-02, -1.6490e-01, -6.1388e-02,\n          1.0277e-02, -7.3613e-02,  3.3824e-02, -8.4998e-02, -1.0126e-01,\n         -1.2117e-01, -1.7130e-01,  2.0955e-02,  1.2154e-01, -1.0525e-01,\n          1.4879e-01,  1.0395e-01,  9.6185e-02,  2.1439e-02, -1.3866e-01,\n         -4.8721e-02,  1.3407e-03, -1.5183e-02, -1.5387e-01,  1.4708e-02,\n         -1.4530e-01, -6.1610e-02],\n        [-1.9019e-02,  1.1837e-01, -9.4063e-02,  1.2342e-01, -5.7945e-02,\n          9.8115e-02, -1.0845e-01,  1.7209e-01, -1.0965e-02,  1.1458e-01,\n         -8.1400e-02, -1.3797e-01,  1.7443e-01, -3.4451e-02, -7.4758e-02,\n         -1.0637e-01, -6.6547e-02, -2.4538e-02, -1.3321e-01, -1.3809e-01,\n         -1.5011e-01,  3.4483e-02, -1.1498e-01, -4.0185e-02,  1.7521e-01,\n          1.1462e-01, -8.0004e-02,  1.8023e-02,  4.2683e-02,  1.0839e-01,\n         -1.7388e-01, -1.5068e-01],\n        [ 1.6167e-01,  1.9523e-02,  6.3168e-02, -1.3372e-01, -1.2396e-01,\n         -1.6076e-02,  9.3345e-02, -8.7328e-02,  1.2821e-01, -9.3674e-02,\n         -9.6726e-03, -1.3183e-01,  9.2648e-02, -7.7614e-02,  6.4294e-02,\n          1.7209e-01,  9.3586e-02, -1.6035e-01,  3.4720e-02, -8.9796e-02,\n         -4.0174e-02, -7.1731e-02, -2.0720e-02, -7.9488e-02, -1.2233e-01,\n          8.5624e-02,  1.6191e-01,  1.4788e-03, -6.5453e-02, -1.5539e-01,\n         -1.6037e-01,  1.5707e-01],\n        [ 1.0414e-01,  7.7449e-02,  5.8708e-02,  1.6041e-01,  1.2554e-02,\n          1.9863e-02, -4.7008e-02,  1.5755e-03,  1.6587e-01, -1.2674e-01,\n          6.9076e-03,  1.7642e-01,  8.7745e-02,  5.1717e-02,  9.0968e-02,\n          1.3944e-01, -9.9206e-02, -1.2369e-01,  1.7286e-01, -1.6581e-01,\n         -1.3874e-01,  1.5798e-01, -4.5822e-02,  1.7349e-01,  5.7626e-02,\n         -9.1383e-02, -1.0854e-01,  1.1626e-01, -1.7616e-01,  2.1308e-02,\n         -2.2398e-02, -1.2585e-01],\n        [ 8.2437e-02,  1.0500e-02,  6.0081e-02,  4.9026e-02, -3.1881e-02,\n         -1.0860e-01,  1.5369e-01, -7.7372e-02,  1.1448e-01, -1.4476e-01,\n          1.4347e-02,  6.9168e-02, -2.2680e-03, -6.7992e-02,  5.9286e-02,\n         -8.2268e-02,  3.4929e-03,  1.3303e-01,  5.1486e-02,  2.7613e-02,\n         -2.9823e-02,  8.7800e-02,  1.5676e-01,  1.2988e-01,  1.3440e-02,\n          3.6573e-02, -1.5984e-01,  1.2060e-01,  3.1423e-02, -3.8722e-02,\n         -1.2390e-01, -1.0445e-02],\n        [-2.7651e-02, -7.7959e-02,  1.4431e-01,  1.1135e-01, -3.8558e-02,\n          4.0801e-02,  4.7905e-02,  1.5864e-01, -1.1578e-01, -6.4045e-05,\n          9.9202e-02, -8.4559e-02,  1.5993e-01,  9.3470e-02,  7.0481e-02,\n          6.3032e-02, -1.2487e-01,  4.1536e-02, -2.2652e-02, -1.6659e-02,\n         -1.7403e-01,  4.3220e-02,  1.4911e-01,  1.4962e-01, -2.5563e-02,\n         -1.8405e-02,  8.0052e-02, -1.6028e-01, -5.7278e-02, -8.2450e-02,\n          1.3825e-01,  1.2703e-02],\n        [-1.3088e-01,  1.2678e-01,  6.3173e-02,  5.4926e-02,  5.5756e-02,\n         -1.7456e-01, -5.3609e-02, -1.6518e-01, -6.3098e-02, -1.5086e-01,\n         -1.6035e-02,  1.7481e-01,  5.8980e-02, -5.9453e-02,  2.6651e-02,\n          1.4490e-01, -3.9654e-02, -3.4668e-02, -7.3488e-02, -9.4595e-02,\n         -4.5052e-02, -8.1765e-02, -1.1227e-01, -1.5432e-01, -2.4052e-02,\n          4.6525e-02, -1.5643e-01,  1.2408e-01, -1.3137e-01,  7.4378e-02,\n          9.7955e-02, -9.4340e-02],\n        [ 9.9177e-02, -8.0768e-02, -1.5492e-01, -1.3176e-01, -5.0428e-02,\n         -1.4379e-01,  1.0939e-01, -2.9119e-02, -6.6688e-02,  1.4607e-01,\n          1.1949e-01, -1.5708e-01, -1.1738e-03, -7.1633e-02, -6.5604e-02,\n         -3.8577e-02, -8.9645e-02, -1.2364e-01,  6.4513e-02,  3.1008e-02,\n          1.2010e-01, -1.7307e-01, -2.1732e-02, -1.3360e-01, -6.2273e-02,\n          1.6467e-01, -3.4421e-02, -3.7350e-02,  8.1938e-02, -7.5112e-02,\n          1.1391e-01, -1.3671e-01],\n        [ 1.2555e-01,  1.8892e-02, -2.9541e-02, -1.5763e-01,  5.6033e-02,\n          7.6348e-02,  5.4646e-03, -9.8650e-02,  6.9911e-02, -8.7721e-02,\n         -6.6563e-02,  1.4250e-02,  1.3791e-01,  6.3420e-03, -1.5219e-01,\n         -6.7921e-02,  1.5266e-01,  4.7862e-02, -1.2467e-01,  1.6069e-01,\n         -1.0872e-01, -1.6112e-01,  1.0900e-01, -6.6634e-02, -2.8868e-02,\n          9.6325e-02,  2.6896e-02, -1.3227e-01, -2.4830e-02,  7.2475e-02,\n          1.5439e-01,  1.8224e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2251, -0.0581, -0.0373,  0.0941,  0.1568, -0.1267, -0.1013, -0.0749],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0606,  0.2279, -0.1149, -0.2075, -0.1581,  0.0056, -0.0049, -0.1330,\n          0.1562,  0.1654,  0.1816, -0.0982,  0.0077, -0.1184, -0.0848,  0.1526],\n        [-0.0053,  0.1732,  0.1910, -0.1884,  0.0828,  0.0871, -0.0233, -0.1049,\n          0.0070,  0.2066,  0.1429, -0.1803, -0.0718, -0.1629, -0.2063, -0.0342],\n        [ 0.1948, -0.2431, -0.1391, -0.0206, -0.1525,  0.1621, -0.0076,  0.1880,\n         -0.1964,  0.0496, -0.1328, -0.1197,  0.2033,  0.1031, -0.2226,  0.0851],\n        [ 0.1761, -0.1192, -0.0006, -0.1116,  0.2478,  0.1176,  0.0380,  0.0645,\n          0.0570,  0.2093, -0.0901,  0.1597, -0.0802, -0.2281,  0.0373,  0.2147],\n        [ 0.1403, -0.1119, -0.1267,  0.1300,  0.2350, -0.1177,  0.0779, -0.2463,\n          0.0447,  0.0703,  0.1849,  0.0455, -0.1206,  0.0394,  0.0639,  0.1716],\n        [ 0.0608, -0.0444,  0.1934, -0.1047, -0.0790,  0.0677,  0.0643, -0.1932,\n          0.1013,  0.1515, -0.1586,  0.1249,  0.0045,  0.2165, -0.0177,  0.1167],\n        [ 0.0173,  0.2160,  0.0893, -0.2462, -0.2161,  0.1516,  0.1219, -0.1185,\n         -0.0408,  0.1917, -0.0807,  0.1072, -0.0174,  0.2305,  0.2162,  0.1897],\n        [-0.1873, -0.0546,  0.1926,  0.1715, -0.2385, -0.0760, -0.1190,  0.2174,\n         -0.2020, -0.0586, -0.2284,  0.1309, -0.1212, -0.2497,  0.1362, -0.1948]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2402], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2191,  0.2049, -0.0618, -0.0106,  0.3529, -0.1579, -0.1604,  0.0734]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0149,  0.0457, -0.2417, -0.3147,  0.1913, -0.2992,  0.0525,  0.0575],\n        [ 0.1821, -0.1847, -0.0057,  0.2553, -0.1618,  0.0907, -0.1494,  0.2405],\n        [-0.1611,  0.0171, -0.1148,  0.3414,  0.2888, -0.0870, -0.1619, -0.0215],\n        [-0.2067,  0.1419,  0.0790,  0.3040, -0.1209, -0.3074, -0.2798,  0.1730],\n        [ 0.2314, -0.3308,  0.0153,  0.2134,  0.1467, -0.3041,  0.2021, -0.0664],\n        [ 0.3308, -0.2381, -0.0320,  0.0255, -0.0832,  0.0296, -0.0426,  0.2466],\n        [ 0.0495, -0.1729, -0.2090, -0.0492, -0.2520,  0.2187,  0.1701,  0.2678],\n        [ 0.1892, -0.3475,  0.2223, -0.1651,  0.1107,  0.1021,  0.2217,  0.3234],\n        [ 0.1268, -0.0949, -0.1571,  0.1973,  0.2559, -0.1289, -0.1151, -0.0610],\n        [-0.1177,  0.2207, -0.0442,  0.3535, -0.2812, -0.1788,  0.1282, -0.2752],\n        [-0.2945, -0.2669, -0.0190, -0.3506,  0.3267,  0.0687,  0.0059, -0.0983],\n        [-0.1870, -0.2577, -0.1748,  0.1389, -0.3069, -0.0677, -0.1633,  0.2132],\n        [ 0.2995, -0.0792,  0.1386,  0.3395, -0.0219,  0.2201, -0.0574,  0.3077],\n        [ 0.1748, -0.2874,  0.2297, -0.1522, -0.2726, -0.0388, -0.3386, -0.0488],\n        [-0.0033, -0.2120,  0.0473,  0.1571, -0.2341, -0.0734,  0.0393,  0.2901],\n        [-0.1319,  0.3313,  0.2339,  0.2159, -0.0425, -0.3225,  0.1892, -0.1845],\n        [-0.0951, -0.2088, -0.3484, -0.2550,  0.3286, -0.3416, -0.1256, -0.3324],\n        [ 0.2390,  0.1615,  0.0958,  0.1433,  0.2787, -0.0880,  0.0896, -0.1368],\n        [ 0.0898,  0.1873, -0.1788,  0.2862, -0.2134, -0.0174, -0.1528,  0.0823],\n        [ 0.0362,  0.2193,  0.2732,  0.2516,  0.1138,  0.0113, -0.2806, -0.2337],\n        [ 0.2150, -0.1845, -0.3449,  0.1207,  0.2781,  0.1009, -0.1942,  0.0115],\n        [ 0.2454,  0.1604,  0.1425, -0.0230, -0.2810,  0.3370, -0.0555,  0.2666],\n        [ 0.3403,  0.2653, -0.2028,  0.0707, -0.3472, -0.1122, -0.0555,  0.3361],\n        [-0.1061, -0.2084,  0.0935, -0.2102, -0.3175,  0.2102, -0.0697, -0.0235],\n        [-0.1461, -0.2301, -0.3535,  0.1791, -0.2317, -0.1973, -0.2806, -0.3026],\n        [ 0.1738, -0.1299,  0.0018, -0.1649,  0.2841,  0.0074, -0.1702,  0.0781],\n        [ 0.1504,  0.2077, -0.0811,  0.1522,  0.2582,  0.0952, -0.1719,  0.1348],\n        [-0.2653, -0.3187, -0.0502, -0.1859, -0.1350,  0.0515,  0.1060, -0.3386],\n        [-0.3525, -0.0266,  0.2403,  0.0067, -0.0866, -0.2232,  0.2305,  0.1421],\n        [ 0.0442,  0.1894,  0.2390, -0.2221,  0.1433,  0.3490, -0.0513,  0.0143],\n        [ 0.3025,  0.0676,  0.0853, -0.0063, -0.2655, -0.2964, -0.0599, -0.0982],\n        [ 0.0569, -0.2661,  0.3215,  0.2460, -0.0634,  0.3044, -0.1961,  0.1410]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1782, -0.1942,  0.2839, -0.2677,  0.3268, -0.2706, -0.0127, -0.0177,\n        -0.2342, -0.0100, -0.1302, -0.3214,  0.2605,  0.0148,  0.0081, -0.2454,\n        -0.3224, -0.1519, -0.0981,  0.2543,  0.1906,  0.3244, -0.3192,  0.2084,\n        -0.1800, -0.1716,  0.0114,  0.3474,  0.0097, -0.0752,  0.1573, -0.1112],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.6413e-01,  1.4335e-01, -5.8750e-02, -4.0428e-02, -3.0337e-02,\n          2.3751e-02,  5.5938e-03, -3.9716e-02,  8.8058e-02,  3.4394e-02,\n          1.2924e-01,  8.1000e-02,  1.6497e-01,  4.4020e-02, -6.1299e-02,\n          8.0713e-02,  1.2921e-01, -1.2166e-01,  1.7450e-01, -1.0407e-01,\n          4.3480e-02,  5.5096e-02,  8.9829e-02,  1.0045e-01, -1.4300e-01,\n          8.3964e-02,  3.2751e-02, -1.1964e-01, -8.7487e-02, -1.7410e-01,\n         -1.2213e-01, -4.2321e-02],\n        [-1.6368e-02,  8.8842e-02, -7.6623e-02, -1.3996e-01, -1.7021e-01,\n          1.7001e-01, -3.1354e-02,  1.3045e-01, -8.4552e-02,  1.1612e-01,\n         -5.9137e-02, -1.0642e-01,  2.1287e-02, -9.5249e-02,  1.0453e-01,\n         -7.4388e-02,  9.9092e-02,  1.6329e-01,  2.6999e-03,  9.9772e-02,\n          1.4743e-01,  1.1940e-01,  1.1737e-01,  1.7935e-02,  7.3365e-02,\n          2.3581e-02,  1.3489e-01,  9.2287e-02,  1.4353e-01, -3.2581e-02,\n         -9.8457e-02, -2.8281e-02],\n        [ 1.0471e-01, -8.3944e-02, -1.0978e-01, -4.8852e-02,  4.9790e-02,\n          1.1280e-01, -1.3320e-01,  2.2371e-02, -1.3933e-01, -3.3293e-02,\n         -1.6755e-01, -8.7638e-02, -2.1916e-02, -1.5739e-01, -1.3579e-01,\n          1.3504e-01, -1.6801e-01, -1.5991e-01, -1.4361e-01, -1.2831e-01,\n          1.7533e-01, -9.8722e-02,  8.0724e-02,  9.6264e-02,  7.8007e-03,\n         -5.9339e-02,  6.5676e-02, -8.4677e-04, -1.6907e-01,  1.3162e-01,\n         -1.4133e-01,  9.6948e-02],\n        [ 1.0357e-01, -9.6167e-02,  1.5862e-01,  4.1867e-02,  3.4097e-02,\n         -1.1468e-01,  5.1326e-02, -5.1490e-02,  9.2020e-02,  1.4204e-01,\n          1.0582e-01,  1.4625e-01,  1.5157e-01,  1.3679e-01, -1.3841e-01,\n         -4.2276e-02,  1.1735e-01, -3.8858e-02,  1.3722e-01,  1.7155e-01,\n         -4.4817e-04, -1.0627e-01,  1.0226e-01, -7.1835e-02, -7.3891e-02,\n         -4.2154e-02, -4.5174e-02,  7.8189e-03, -9.0535e-02,  3.4355e-02,\n          1.1807e-01, -2.1472e-02],\n        [-5.5445e-02, -6.7880e-03,  1.3251e-01,  2.7035e-02,  1.3918e-01,\n         -8.1067e-03,  4.5147e-02, -1.4228e-01,  1.0130e-01,  1.2939e-01,\n         -3.3566e-02, -6.4037e-02,  9.0576e-02,  5.9272e-02,  5.9082e-02,\n          4.4948e-02,  9.3392e-02, -1.1295e-01, -6.4078e-04, -3.7534e-02,\n          1.2356e-01, -1.4235e-01, -1.4101e-01,  2.0878e-02,  6.8926e-02,\n          9.5098e-02,  1.4887e-01,  1.3865e-01,  6.3475e-02, -1.7550e-01,\n         -8.8957e-02, -3.5303e-02],\n        [ 1.3381e-01, -6.9250e-02,  1.6204e-01, -1.6855e-01, -2.6433e-02,\n         -1.6183e-01, -1.6870e-01,  9.5466e-02, -1.7259e-01,  4.9685e-02,\n          1.1318e-01, -2.7693e-02, -1.4627e-02, -1.4595e-01, -4.0936e-02,\n         -1.6553e-01, -6.1002e-02, -8.3314e-02, -6.1047e-02,  1.2799e-01,\n          5.7157e-02, -1.5961e-01, -3.2025e-02, -8.0172e-02,  4.5735e-02,\n         -1.4938e-01,  1.4074e-01,  2.4350e-02, -1.1828e-01,  1.1449e-01,\n         -1.1581e-01, -1.1242e-01],\n        [ 1.7430e-01, -1.4558e-01, -3.2254e-02,  1.2282e-01,  1.7129e-01,\n         -4.1555e-02, -1.3578e-01,  1.7575e-02, -1.4246e-01, -9.9578e-02,\n          1.1428e-01, -1.1346e-01,  8.6479e-02,  1.6179e-01,  6.3006e-02,\n         -1.6273e-01,  1.7171e-01,  1.2330e-01,  1.1335e-01,  1.4811e-01,\n          1.0235e-01, -5.1442e-02, -2.3210e-02,  4.5902e-02, -8.8814e-02,\n          1.5167e-01,  5.0959e-02, -1.1642e-01,  9.1138e-02, -1.9897e-02,\n         -1.6045e-01,  1.3662e-01],\n        [ 3.8606e-02,  1.2163e-01,  1.1736e-01,  9.3573e-02, -1.4911e-01,\n          1.2895e-01,  4.6811e-02,  2.1346e-02, -1.6490e-01, -6.1388e-02,\n          1.0277e-02, -7.3613e-02,  3.3824e-02, -8.4998e-02, -1.0126e-01,\n         -1.2117e-01, -1.7130e-01,  2.0955e-02,  1.2154e-01, -1.0525e-01,\n          1.4879e-01,  1.0395e-01,  9.6185e-02,  2.1439e-02, -1.3866e-01,\n         -4.8721e-02,  1.3407e-03, -1.5183e-02, -1.5387e-01,  1.4708e-02,\n         -1.4530e-01, -6.1610e-02],\n        [-1.9019e-02,  1.1837e-01, -9.4063e-02,  1.2342e-01, -5.7945e-02,\n          9.8115e-02, -1.0845e-01,  1.7209e-01, -1.0965e-02,  1.1458e-01,\n         -8.1400e-02, -1.3797e-01,  1.7443e-01, -3.4451e-02, -7.4758e-02,\n         -1.0637e-01, -6.6547e-02, -2.4538e-02, -1.3321e-01, -1.3809e-01,\n         -1.5011e-01,  3.4483e-02, -1.1498e-01, -4.0185e-02,  1.7521e-01,\n          1.1462e-01, -8.0004e-02,  1.8023e-02,  4.2683e-02,  1.0839e-01,\n         -1.7388e-01, -1.5068e-01],\n        [ 1.6167e-01,  1.9523e-02,  6.3168e-02, -1.3372e-01, -1.2396e-01,\n         -1.6076e-02,  9.3345e-02, -8.7328e-02,  1.2821e-01, -9.3674e-02,\n         -9.6726e-03, -1.3183e-01,  9.2648e-02, -7.7614e-02,  6.4294e-02,\n          1.7209e-01,  9.3586e-02, -1.6035e-01,  3.4720e-02, -8.9796e-02,\n         -4.0174e-02, -7.1731e-02, -2.0720e-02, -7.9488e-02, -1.2233e-01,\n          8.5624e-02,  1.6191e-01,  1.4788e-03, -6.5453e-02, -1.5539e-01,\n         -1.6037e-01,  1.5707e-01],\n        [ 1.0414e-01,  7.7449e-02,  5.8708e-02,  1.6041e-01,  1.2554e-02,\n          1.9863e-02, -4.7008e-02,  1.5755e-03,  1.6587e-01, -1.2674e-01,\n          6.9076e-03,  1.7642e-01,  8.7745e-02,  5.1717e-02,  9.0968e-02,\n          1.3944e-01, -9.9206e-02, -1.2369e-01,  1.7286e-01, -1.6581e-01,\n         -1.3874e-01,  1.5798e-01, -4.5822e-02,  1.7349e-01,  5.7626e-02,\n         -9.1383e-02, -1.0854e-01,  1.1626e-01, -1.7616e-01,  2.1308e-02,\n         -2.2398e-02, -1.2585e-01],\n        [ 8.2437e-02,  1.0500e-02,  6.0081e-02,  4.9026e-02, -3.1881e-02,\n         -1.0860e-01,  1.5369e-01, -7.7372e-02,  1.1448e-01, -1.4476e-01,\n          1.4347e-02,  6.9168e-02, -2.2680e-03, -6.7992e-02,  5.9286e-02,\n         -8.2268e-02,  3.4929e-03,  1.3303e-01,  5.1486e-02,  2.7613e-02,\n         -2.9823e-02,  8.7800e-02,  1.5676e-01,  1.2988e-01,  1.3440e-02,\n          3.6573e-02, -1.5984e-01,  1.2060e-01,  3.1423e-02, -3.8722e-02,\n         -1.2390e-01, -1.0445e-02],\n        [-2.7651e-02, -7.7959e-02,  1.4431e-01,  1.1135e-01, -3.8558e-02,\n          4.0801e-02,  4.7905e-02,  1.5864e-01, -1.1578e-01, -6.4045e-05,\n          9.9202e-02, -8.4559e-02,  1.5993e-01,  9.3470e-02,  7.0481e-02,\n          6.3032e-02, -1.2487e-01,  4.1536e-02, -2.2652e-02, -1.6659e-02,\n         -1.7403e-01,  4.3220e-02,  1.4911e-01,  1.4962e-01, -2.5563e-02,\n         -1.8405e-02,  8.0052e-02, -1.6028e-01, -5.7278e-02, -8.2450e-02,\n          1.3825e-01,  1.2703e-02],\n        [-1.3088e-01,  1.2678e-01,  6.3173e-02,  5.4926e-02,  5.5756e-02,\n         -1.7456e-01, -5.3609e-02, -1.6518e-01, -6.3098e-02, -1.5086e-01,\n         -1.6035e-02,  1.7481e-01,  5.8980e-02, -5.9453e-02,  2.6651e-02,\n          1.4490e-01, -3.9654e-02, -3.4668e-02, -7.3488e-02, -9.4595e-02,\n         -4.5052e-02, -8.1765e-02, -1.1227e-01, -1.5432e-01, -2.4052e-02,\n          4.6525e-02, -1.5643e-01,  1.2408e-01, -1.3137e-01,  7.4378e-02,\n          9.7955e-02, -9.4340e-02],\n        [ 9.9177e-02, -8.0768e-02, -1.5492e-01, -1.3176e-01, -5.0428e-02,\n         -1.4379e-01,  1.0939e-01, -2.9119e-02, -6.6688e-02,  1.4607e-01,\n          1.1949e-01, -1.5708e-01, -1.1738e-03, -7.1633e-02, -6.5604e-02,\n         -3.8577e-02, -8.9645e-02, -1.2364e-01,  6.4513e-02,  3.1008e-02,\n          1.2010e-01, -1.7307e-01, -2.1732e-02, -1.3360e-01, -6.2273e-02,\n          1.6467e-01, -3.4421e-02, -3.7350e-02,  8.1938e-02, -7.5112e-02,\n          1.1391e-01, -1.3671e-01],\n        [ 1.2555e-01,  1.8892e-02, -2.9541e-02, -1.5763e-01,  5.6033e-02,\n          7.6348e-02,  5.4646e-03, -9.8650e-02,  6.9911e-02, -8.7721e-02,\n         -6.6563e-02,  1.4250e-02,  1.3791e-01,  6.3420e-03, -1.5219e-01,\n         -6.7921e-02,  1.5266e-01,  4.7862e-02, -1.2467e-01,  1.6069e-01,\n         -1.0872e-01, -1.6112e-01,  1.0900e-01, -6.6634e-02, -2.8868e-02,\n          9.6325e-02,  2.6896e-02, -1.3227e-01, -2.4830e-02,  7.2475e-02,\n          1.5439e-01,  1.8224e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0108, -0.1416, -0.0077,  0.1112,  0.0809,  0.0152, -0.0206, -0.0246,\n        -0.1649,  0.0487,  0.0886, -0.1651, -0.1429,  0.1151, -0.1020,  0.1588],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0606,  0.2279, -0.1149, -0.2075, -0.1581,  0.0056, -0.0049, -0.1330,\n          0.1562,  0.1654,  0.1816, -0.0982,  0.0077, -0.1184, -0.0848,  0.1526],\n        [-0.0053,  0.1732,  0.1910, -0.1884,  0.0828,  0.0871, -0.0233, -0.1049,\n          0.0070,  0.2066,  0.1429, -0.1803, -0.0718, -0.1629, -0.2063, -0.0342],\n        [ 0.1948, -0.2431, -0.1391, -0.0206, -0.1525,  0.1621, -0.0076,  0.1880,\n         -0.1964,  0.0496, -0.1328, -0.1197,  0.2033,  0.1031, -0.2226,  0.0851],\n        [ 0.1761, -0.1192, -0.0006, -0.1116,  0.2478,  0.1176,  0.0380,  0.0645,\n          0.0570,  0.2093, -0.0901,  0.1597, -0.0802, -0.2281,  0.0373,  0.2147],\n        [ 0.1403, -0.1119, -0.1267,  0.1300,  0.2350, -0.1177,  0.0779, -0.2463,\n          0.0447,  0.0703,  0.1849,  0.0455, -0.1206,  0.0394,  0.0639,  0.1716],\n        [ 0.0608, -0.0444,  0.1934, -0.1047, -0.0790,  0.0677,  0.0643, -0.1932,\n          0.1013,  0.1515, -0.1586,  0.1249,  0.0045,  0.2165, -0.0177,  0.1167],\n        [ 0.0173,  0.2160,  0.0893, -0.2462, -0.2161,  0.1516,  0.1219, -0.1185,\n         -0.0408,  0.1917, -0.0807,  0.1072, -0.0174,  0.2305,  0.2162,  0.1897],\n        [-0.1873, -0.0546,  0.1926,  0.1715, -0.2385, -0.0760, -0.1190,  0.2174,\n         -0.2020, -0.0586, -0.2284,  0.1309, -0.1212, -0.2497,  0.1362, -0.1948]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2251, -0.0581, -0.0373,  0.0941,  0.1568, -0.1267, -0.1013, -0.0749],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2191,  0.2049, -0.0618, -0.0106,  0.3529, -0.1579, -0.1604,  0.0734]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2402], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000002A3D41822F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000002A39C7892A0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s265080000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s265080000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}