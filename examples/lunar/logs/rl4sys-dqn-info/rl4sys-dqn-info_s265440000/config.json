{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s265440000"
    },
    "q_lr":	0.0005,
    "seed":	265440000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x752e03957610>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-6.4646e-02,  1.2478e-01,  5.6213e-02,  2.8862e-01,  1.1709e-02,\n         2.3739e-01,  1.3553e-01, -1.4827e-01, -2.3061e-01, -2.0395e-01,\n        -2.4400e-01, -2.8710e-01,  2.8513e-01,  4.2016e-02,  1.0033e-01,\n         1.5302e-01, -3.1868e-01,  1.6242e-01,  4.8346e-02, -2.3779e-01,\n         9.3018e-02, -2.7916e-01,  1.9946e-01,  2.9146e-01, -4.0673e-02,\n        -2.6537e-02,  2.8717e-01,  1.0310e-01, -9.7518e-02, -1.7410e-01,\n         9.5294e-05,  1.2775e-01], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-5.6276e-02,  7.1112e-02,  1.1859e-01, -1.5197e-01,  1.3726e-01,\n         -2.9079e-01,  2.1477e-01, -9.2847e-02],\n        [ 1.2631e-01, -2.2161e-01, -7.2355e-02,  1.9635e-01,  2.9984e-01,\n         -2.0431e-01,  2.3115e-01,  2.6764e-01],\n        [ 2.1539e-01,  1.5246e-01,  1.4358e-01, -3.1099e-01,  2.1740e-01,\n         -3.0544e-02,  3.5488e-02,  1.7603e-02],\n        [ 2.1967e-01,  8.3642e-03, -2.4913e-01,  2.1680e-01, -1.1804e-01,\n         -2.4640e-01,  3.2924e-02, -1.4210e-01],\n        [ 1.2577e-01,  1.7284e-01, -7.2915e-02,  3.2705e-01, -2.6711e-01,\n         -2.3508e-01,  7.3442e-02, -1.9903e-02],\n        [ 2.7855e-02, -2.9477e-01, -1.7477e-02,  1.9669e-01, -3.3480e-01,\n          8.1806e-02, -7.3840e-02, -8.4398e-02],\n        [-2.7576e-01, -9.7426e-02, -1.7235e-01,  4.2738e-02,  4.7977e-02,\n         -1.5656e-01, -3.4763e-01,  1.3153e-01],\n        [-2.0689e-01,  2.6705e-01,  2.2117e-01,  2.7255e-01,  5.5093e-02,\n          2.8345e-01, -1.8449e-01, -8.1419e-02],\n        [ 1.2933e-01, -9.6896e-02,  2.6988e-01,  2.3406e-01,  3.3455e-01,\n          1.7501e-01,  2.3809e-01, -2.2328e-01],\n        [ 2.9908e-01,  3.2911e-01,  1.5934e-01,  8.3074e-02, -1.0077e-01,\n         -1.5326e-01, -2.0645e-01,  1.4977e-01],\n        [ 1.7125e-01, -2.7838e-01,  2.3321e-01, -1.9875e-01,  2.3787e-02,\n         -1.1857e-01, -6.5544e-02,  1.0790e-01],\n        [-7.7509e-02, -5.2877e-02, -2.1473e-01,  2.1984e-01, -1.9319e-01,\n          1.6280e-01, -1.7478e-01, -2.6923e-01],\n        [ 1.7494e-01, -3.1207e-01,  1.2059e-01, -3.3044e-02, -2.3442e-01,\n          1.6730e-01,  1.7168e-01, -3.3503e-01],\n        [ 1.0443e-01, -2.4404e-01, -9.3546e-02,  1.5305e-01, -1.3051e-01,\n         -2.8563e-01, -3.8494e-02, -1.0471e-01],\n        [ 3.8720e-02,  3.1302e-01, -3.2320e-01, -1.9216e-01,  3.5085e-01,\n          5.8336e-02, -5.6120e-02, -1.9479e-01],\n        [ 1.0914e-02,  2.6451e-01, -2.6853e-01, -6.1141e-02,  5.8384e-02,\n         -2.8713e-01, -3.5314e-01, -3.0564e-01],\n        [ 3.0802e-01,  7.3794e-02, -5.1979e-02,  1.0820e-02,  5.3345e-02,\n          3.0251e-02,  7.8646e-02,  1.9703e-02],\n        [ 2.2017e-02, -2.0256e-01,  3.1113e-01,  1.1842e-02,  2.3401e-01,\n          1.7858e-01,  8.7017e-02, -2.5571e-01],\n        [-6.0792e-02, -1.2527e-01,  1.5803e-01, -2.2323e-01, -1.7514e-01,\n          4.0752e-04, -3.9132e-03,  1.5410e-01],\n        [ 2.5577e-01, -1.4364e-01, -3.2459e-01,  1.7390e-01,  1.2513e-01,\n         -1.9389e-01,  2.5803e-01,  2.8973e-01],\n        [-3.3816e-01, -3.1199e-01,  1.2022e-01, -3.1285e-01,  1.7493e-01,\n          2.6594e-01,  1.2783e-01, -3.8072e-02],\n        [-2.1858e-01,  2.5975e-01,  3.4793e-01,  2.8827e-01, -7.2792e-02,\n         -3.2030e-01, -9.4930e-02,  3.0781e-01],\n        [-1.0739e-01, -2.3931e-01,  2.2954e-01,  1.4123e-01,  1.8509e-01,\n          4.8378e-02,  2.6545e-01, -3.3390e-01],\n        [ 3.4954e-01, -1.1297e-01, -1.3128e-02, -3.0555e-01,  1.8190e-01,\n          1.5036e-01,  2.2572e-01,  2.1058e-01],\n        [-4.4261e-03,  8.5520e-02,  1.6943e-01,  1.2374e-02,  7.6304e-02,\n          2.9980e-01,  2.1280e-01,  1.2635e-01],\n        [ 1.3522e-01, -2.7650e-01, -2.2411e-01,  6.6924e-02, -1.0505e-01,\n          1.5213e-02,  2.1936e-01,  1.9284e-01],\n        [ 1.0754e-01, -2.8661e-01,  3.1615e-01,  1.8706e-01, -3.3903e-02,\n         -1.8668e-01,  2.4461e-01,  1.7842e-01],\n        [ 2.9340e-01, -3.0194e-03,  6.0465e-02, -1.6132e-02,  2.6671e-01,\n          1.4215e-01, -6.8337e-02, -1.4596e-01],\n        [ 6.1077e-02, -2.7333e-01, -2.7519e-01,  2.8337e-01, -1.4568e-01,\n         -4.1839e-02,  1.9093e-01,  1.4006e-01],\n        [-2.5646e-01,  1.1507e-01,  1.7550e-01,  1.5628e-01,  1.9148e-01,\n         -3.5277e-02,  2.2517e-01, -3.1733e-02],\n        [ 9.4985e-02, -3.6984e-03, -8.5926e-03,  2.7068e-01, -1.1809e-01,\n         -2.2666e-01,  1.8422e-04, -3.0586e-02],\n        [ 3.4035e-01, -2.4700e-01,  1.5708e-01,  3.5035e-01,  2.5259e-01,\n         -2.7556e-01,  3.0753e-01,  2.5816e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1076,  0.1384, -0.1272,  0.1224, -0.0959,  0.0653, -0.1169,  0.0849,\n         0.0876,  0.0616, -0.0329, -0.0792,  0.1281,  0.0612,  0.0800,  0.1598],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.6693e-01,  1.0417e-01, -1.3134e-01,  1.7660e-02,  1.1694e-01,\n         -9.2232e-02,  6.4225e-02,  1.3588e-01, -1.7092e-01,  5.2730e-02,\n         -1.5507e-01, -1.3483e-01, -1.5221e-01, -1.3158e-01, -1.5718e-01,\n         -3.6060e-02, -5.3248e-02,  1.6257e-01,  1.3525e-01, -1.4506e-01,\n          1.2693e-01,  1.1423e-01,  1.5349e-03, -7.5750e-02,  6.9753e-02,\n         -1.7047e-01,  7.7803e-02,  2.0474e-02, -4.5660e-02,  1.2251e-01,\n          2.6506e-02,  1.1262e-01],\n        [-1.2711e-01, -1.3702e-02,  1.3094e-01, -8.2498e-02,  2.5889e-02,\n          1.1801e-01, -7.1393e-02,  1.4494e-01, -1.5935e-02,  1.2727e-01,\n          1.4344e-01,  6.7098e-02, -7.0808e-02,  1.4039e-01, -1.1187e-01,\n         -6.0917e-02, -1.4039e-02,  1.4539e-01, -1.7368e-01,  2.7132e-02,\n          8.4506e-02,  5.2959e-02, -1.3176e-01, -7.6193e-02,  1.3494e-01,\n          1.6680e-01, -1.1944e-01,  1.3116e-01,  8.3935e-05, -1.6619e-01,\n         -1.5803e-01, -4.8570e-02],\n        [-2.0737e-02,  1.6236e-01, -1.5914e-01,  1.0951e-01,  8.5957e-02,\n          1.4351e-01, -2.4070e-02,  1.3874e-01, -1.0006e-01, -1.0689e-01,\n          7.4880e-02, -1.4399e-01,  4.5768e-02,  2.0570e-02,  3.0078e-02,\n          1.3676e-01, -1.1515e-01,  8.9674e-02, -4.2840e-04,  7.7060e-02,\n          1.1537e-01, -9.8662e-02, -1.5839e-01,  1.2119e-01,  9.4508e-02,\n         -2.4510e-02,  9.9374e-02, -6.3015e-02, -1.5291e-01,  8.4928e-02,\n         -1.3503e-01,  3.0539e-02],\n        [-1.5493e-01, -1.7409e-01, -9.2768e-02, -4.1932e-02,  2.6540e-02,\n         -2.5629e-03, -1.1478e-01,  1.0413e-01, -4.0626e-02,  8.2264e-04,\n         -1.5129e-01, -6.3275e-02,  4.8680e-02,  4.8028e-02,  1.4325e-01,\n         -1.6368e-01,  1.0234e-01,  1.3698e-02, -8.2891e-02, -1.4361e-02,\n          5.4876e-02,  9.3120e-02, -1.0418e-01,  4.0442e-02,  1.1160e-01,\n         -1.7612e-01, -7.0732e-02,  1.1022e-01,  6.0299e-02,  4.9211e-02,\n          1.5609e-01,  4.7131e-04],\n        [ 3.2058e-02,  6.3377e-02,  1.6102e-01,  1.4485e-01, -8.5373e-02,\n         -4.5348e-02,  1.2449e-01,  8.3867e-02,  6.7806e-02,  7.6461e-02,\n          8.8229e-02, -2.5041e-03, -1.7728e-02,  9.7954e-02,  1.6435e-01,\n         -9.9831e-02, -1.3623e-01,  2.6190e-04,  5.8744e-02,  1.2569e-01,\n          1.5388e-02, -4.5759e-03,  1.7170e-01,  1.6161e-01, -1.6355e-01,\n         -6.9532e-02,  4.2430e-02,  1.6403e-01, -1.1797e-01, -1.2092e-01,\n         -4.1281e-02,  1.1043e-01],\n        [-5.3948e-02,  5.0049e-03, -1.4804e-01, -3.4127e-02,  1.7216e-02,\n         -5.2769e-03, -1.1926e-01,  9.2697e-02, -4.1619e-02,  1.4551e-01,\n          8.1587e-02,  7.6672e-02,  2.4090e-02, -7.8845e-02, -9.1692e-02,\n         -4.5570e-02, -1.1246e-01,  7.9156e-02,  3.0123e-02,  1.3478e-01,\n          1.3793e-01,  5.0021e-02,  1.0529e-01, -7.7982e-02,  4.2233e-03,\n          1.6320e-01, -1.7179e-01,  6.3778e-02, -1.0170e-01, -3.7700e-02,\n          1.1139e-01,  1.0246e-01],\n        [ 1.2125e-02,  3.0554e-02, -8.3788e-02,  3.1153e-02, -1.0667e-01,\n          3.6894e-02, -1.1832e-01,  1.2625e-01, -1.4064e-01,  4.9770e-02,\n         -1.4350e-01,  9.0006e-02, -9.6803e-02,  2.5056e-02,  1.6213e-01,\n          2.3552e-02,  9.7547e-02,  3.4691e-02,  1.1812e-01,  1.6726e-01,\n         -5.4311e-02,  9.1529e-02, -1.0077e-01, -1.3305e-02, -5.4953e-02,\n          6.8239e-02,  3.3196e-02, -1.3145e-01, -2.1698e-02,  4.4895e-02,\n         -3.2612e-02, -1.4046e-01],\n        [ 3.3005e-02,  1.3363e-01,  1.5504e-01,  1.0766e-01,  1.3846e-01,\n          9.4543e-02,  7.4602e-02,  1.4822e-01,  1.7568e-01,  6.1203e-02,\n          1.0629e-01, -1.6385e-01, -1.1657e-01, -5.2871e-02,  8.5920e-02,\n          1.2126e-03,  3.2420e-03,  3.5020e-02,  5.5484e-02, -8.0550e-02,\n          2.0121e-02,  1.3096e-01,  1.2531e-02, -1.3423e-01,  1.0380e-01,\n          6.8320e-02,  1.7574e-01,  3.0681e-03,  2.5211e-02,  9.7653e-02,\n         -9.4018e-02, -5.5665e-02],\n        [ 2.2299e-02, -6.7574e-02,  5.4062e-02,  7.2827e-02,  1.6573e-01,\n          2.5271e-03, -4.6799e-02,  1.5934e-01,  8.3767e-02,  1.5061e-01,\n         -4.2556e-02, -5.0645e-02, -1.3197e-01,  9.2588e-02,  8.2443e-02,\n         -1.3486e-01,  7.9279e-02,  1.3621e-01,  1.4138e-01,  1.1449e-01,\n          1.2592e-02, -1.2908e-01,  2.0526e-02,  1.2869e-02, -1.6044e-01,\n          6.6145e-03,  2.6234e-02,  1.2027e-01, -7.7748e-03, -1.6019e-01,\n         -3.8530e-02, -6.8085e-02],\n        [ 1.6994e-01, -2.3689e-02,  2.2258e-02,  3.7262e-02, -1.0586e-01,\n          5.4176e-02, -5.7762e-02, -8.6576e-02, -9.9300e-02, -1.4913e-01,\n          9.3254e-02, -2.3878e-02, -1.4729e-02, -1.1664e-01,  1.3002e-01,\n         -3.0132e-02,  1.6146e-01,  5.9158e-02,  1.4918e-01, -4.8687e-02,\n          1.1891e-01, -4.5232e-03, -1.3159e-01,  1.3506e-02, -8.6411e-03,\n         -1.0174e-01, -5.8933e-02, -7.0479e-02, -1.2295e-02,  1.4365e-01,\n         -1.2467e-01,  2.7610e-02],\n        [-1.5287e-01,  1.0526e-01, -2.7772e-02,  3.6447e-02, -4.4100e-03,\n          6.4195e-02, -1.4254e-01,  2.7770e-02,  5.3357e-03, -7.1527e-02,\n          1.2383e-03,  2.4177e-02,  1.1410e-01,  7.5383e-03,  5.4826e-02,\n         -3.2619e-02,  1.0408e-01, -2.3831e-03,  5.6813e-02,  1.1622e-01,\n          5.3391e-02, -5.4241e-02,  1.6379e-01, -5.1335e-02, -1.0996e-01,\n          2.9220e-03, -7.1819e-02, -5.4703e-02,  2.2050e-02, -1.3775e-01,\n         -9.2194e-02,  1.0481e-01],\n        [-4.4636e-02,  2.5166e-02,  1.7604e-02, -6.2993e-02,  2.5957e-02,\n          1.6126e-01, -1.5449e-01,  7.5979e-02, -1.3756e-01, -9.7284e-02,\n         -1.6660e-01, -4.4455e-02, -1.1011e-01,  7.6727e-02, -2.9925e-03,\n         -7.4949e-02,  1.5296e-01,  7.0627e-02, -4.9052e-02,  9.5691e-02,\n         -1.2218e-01,  1.3833e-01,  1.8817e-02, -3.9251e-03, -1.4160e-01,\n          8.8704e-02, -7.2439e-02,  8.1106e-02,  9.5024e-02,  1.2385e-01,\n         -6.2323e-02, -3.3966e-02],\n        [ 1.1290e-01,  6.2151e-03, -9.7740e-02, -1.9260e-02, -1.3568e-01,\n          1.6884e-01,  1.4315e-01,  1.0209e-01, -1.3744e-01,  1.4299e-01,\n          5.1065e-02, -1.7572e-01, -1.6472e-01,  9.4668e-02, -7.5171e-02,\n         -9.6052e-02, -3.0799e-02,  1.5955e-01, -3.0941e-03, -1.4186e-01,\n          1.6717e-01, -9.0648e-02, -1.4614e-01,  8.2107e-02, -3.8591e-02,\n         -9.0599e-02, -1.4364e-01,  1.0211e-01, -1.4718e-01,  1.5601e-01,\n         -1.5324e-01,  4.3225e-02],\n        [-1.3255e-02, -1.6461e-01,  9.0405e-06,  3.5166e-02, -9.9821e-02,\n         -1.1659e-01,  5.5444e-02,  4.7099e-02,  5.2878e-02,  3.2768e-02,\n         -1.5297e-01, -4.2840e-02, -8.4355e-02,  2.4421e-02,  1.3697e-01,\n          6.7150e-02,  1.6503e-01, -1.2441e-01, -7.1824e-02,  2.4947e-02,\n          3.9156e-02, -2.7999e-02,  5.0270e-02,  1.6916e-01,  9.0396e-02,\n          6.2782e-02,  1.3785e-01,  1.5354e-01, -1.3961e-01, -6.4805e-02,\n         -9.6729e-02, -3.5063e-02],\n        [ 1.4446e-01,  5.4506e-02, -1.3596e-01,  1.4154e-01, -1.5894e-01,\n          3.6450e-02,  6.7084e-02, -1.2888e-01,  9.8894e-02,  1.6852e-01,\n         -1.3431e-01, -7.6760e-02,  3.5378e-02,  8.1806e-03, -1.1394e-01,\n         -6.3533e-02, -3.6669e-02, -1.6545e-01,  1.1623e-01, -1.1670e-01,\n          8.2052e-02,  1.4885e-01,  5.2539e-02,  1.0233e-01, -1.3464e-01,\n          1.3009e-01, -9.4016e-02, -1.2578e-01, -8.8287e-02, -5.9627e-02,\n         -1.2157e-01, -1.7331e-01],\n        [ 8.2321e-02, -3.0954e-02,  2.4689e-02,  1.0503e-01, -1.1261e-01,\n         -4.8990e-02,  2.1526e-02, -9.4229e-03,  1.1479e-01,  1.1953e-01,\n          1.0074e-01,  1.4972e-01,  9.8657e-02,  6.4597e-02, -1.7015e-01,\n         -1.3914e-01, -4.0949e-02, -6.4400e-02,  7.3427e-02,  1.5829e-01,\n          1.0595e-01,  7.4699e-02,  1.6382e-01,  5.7078e-02,  1.4401e-01,\n          1.3223e-01,  1.4316e-02,  3.9810e-02,  5.2869e-03, -1.6201e-01,\n          3.4865e-02, -4.7229e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1487, -0.0335, -0.1677, -0.1618, -0.1259,  0.1006, -0.0326,  0.2212],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0468, -0.1295,  0.2065,  0.0765,  0.1115, -0.2136, -0.0609,  0.0159,\n         -0.0661, -0.1284,  0.0089, -0.0932,  0.2311, -0.1350,  0.0644,  0.1613],\n        [-0.1855, -0.0202, -0.0869, -0.2264,  0.1546,  0.0415, -0.2403, -0.1176,\n         -0.0232, -0.2404,  0.1097,  0.0577,  0.1938,  0.0858,  0.2489, -0.1516],\n        [-0.1392, -0.0222, -0.1513, -0.1364, -0.0856, -0.1160,  0.0535, -0.2393,\n          0.2432,  0.0840, -0.1521,  0.0924,  0.2202, -0.2042, -0.2197,  0.1127],\n        [-0.1712, -0.1656,  0.1328, -0.1721, -0.0848, -0.1458,  0.0430, -0.0281,\n         -0.2263,  0.1472,  0.1560, -0.2120, -0.0214,  0.1705,  0.1242,  0.1248],\n        [ 0.1754,  0.0674,  0.0971,  0.0821,  0.1112, -0.2486,  0.0166, -0.1917,\n         -0.2321,  0.0783, -0.0344, -0.2361,  0.2031, -0.0239,  0.0741,  0.2324],\n        [-0.0620, -0.0941,  0.1231, -0.1417,  0.0918, -0.1918,  0.1888, -0.0736,\n         -0.2477,  0.1920, -0.2329,  0.2151,  0.1432, -0.1217,  0.1872, -0.1607],\n        [-0.1969, -0.0181,  0.1629,  0.1746,  0.1877, -0.0138, -0.0812, -0.1806,\n          0.2200,  0.1862, -0.2419, -0.0766, -0.2002, -0.2401,  0.1511,  0.0332],\n        [ 0.0534,  0.2128, -0.2122, -0.2032, -0.0621,  0.2268, -0.1402,  0.2233,\n          0.0249, -0.1242, -0.1880,  0.0758, -0.2341,  0.0513, -0.1980, -0.0070]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=1, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3479], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2574,  0.0926,  0.3176,  0.1250, -0.2043, -0.0183,  0.2261, -0.2921]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	1,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-5.6276e-02,  7.1112e-02,  1.1859e-01, -1.5197e-01,  1.3726e-01,\n         -2.9079e-01,  2.1477e-01, -9.2847e-02],\n        [ 1.2631e-01, -2.2161e-01, -7.2355e-02,  1.9635e-01,  2.9984e-01,\n         -2.0431e-01,  2.3115e-01,  2.6764e-01],\n        [ 2.1539e-01,  1.5246e-01,  1.4358e-01, -3.1099e-01,  2.1740e-01,\n         -3.0544e-02,  3.5488e-02,  1.7603e-02],\n        [ 2.1967e-01,  8.3642e-03, -2.4913e-01,  2.1680e-01, -1.1804e-01,\n         -2.4640e-01,  3.2924e-02, -1.4210e-01],\n        [ 1.2577e-01,  1.7284e-01, -7.2915e-02,  3.2705e-01, -2.6711e-01,\n         -2.3508e-01,  7.3442e-02, -1.9903e-02],\n        [ 2.7855e-02, -2.9477e-01, -1.7477e-02,  1.9669e-01, -3.3480e-01,\n          8.1806e-02, -7.3840e-02, -8.4398e-02],\n        [-2.7576e-01, -9.7426e-02, -1.7235e-01,  4.2738e-02,  4.7977e-02,\n         -1.5656e-01, -3.4763e-01,  1.3153e-01],\n        [-2.0689e-01,  2.6705e-01,  2.2117e-01,  2.7255e-01,  5.5093e-02,\n          2.8345e-01, -1.8449e-01, -8.1419e-02],\n        [ 1.2933e-01, -9.6896e-02,  2.6988e-01,  2.3406e-01,  3.3455e-01,\n          1.7501e-01,  2.3809e-01, -2.2328e-01],\n        [ 2.9908e-01,  3.2911e-01,  1.5934e-01,  8.3074e-02, -1.0077e-01,\n         -1.5326e-01, -2.0645e-01,  1.4977e-01],\n        [ 1.7125e-01, -2.7838e-01,  2.3321e-01, -1.9875e-01,  2.3787e-02,\n         -1.1857e-01, -6.5544e-02,  1.0790e-01],\n        [-7.7509e-02, -5.2877e-02, -2.1473e-01,  2.1984e-01, -1.9319e-01,\n          1.6280e-01, -1.7478e-01, -2.6923e-01],\n        [ 1.7494e-01, -3.1207e-01,  1.2059e-01, -3.3044e-02, -2.3442e-01,\n          1.6730e-01,  1.7168e-01, -3.3503e-01],\n        [ 1.0443e-01, -2.4404e-01, -9.3546e-02,  1.5305e-01, -1.3051e-01,\n         -2.8563e-01, -3.8494e-02, -1.0471e-01],\n        [ 3.8720e-02,  3.1302e-01, -3.2320e-01, -1.9216e-01,  3.5085e-01,\n          5.8336e-02, -5.6120e-02, -1.9479e-01],\n        [ 1.0914e-02,  2.6451e-01, -2.6853e-01, -6.1141e-02,  5.8384e-02,\n         -2.8713e-01, -3.5314e-01, -3.0564e-01],\n        [ 3.0802e-01,  7.3794e-02, -5.1979e-02,  1.0820e-02,  5.3345e-02,\n          3.0251e-02,  7.8646e-02,  1.9703e-02],\n        [ 2.2017e-02, -2.0256e-01,  3.1113e-01,  1.1842e-02,  2.3401e-01,\n          1.7858e-01,  8.7017e-02, -2.5571e-01],\n        [-6.0792e-02, -1.2527e-01,  1.5803e-01, -2.2323e-01, -1.7514e-01,\n          4.0752e-04, -3.9132e-03,  1.5410e-01],\n        [ 2.5577e-01, -1.4364e-01, -3.2459e-01,  1.7390e-01,  1.2513e-01,\n         -1.9389e-01,  2.5803e-01,  2.8973e-01],\n        [-3.3816e-01, -3.1199e-01,  1.2022e-01, -3.1285e-01,  1.7493e-01,\n          2.6594e-01,  1.2783e-01, -3.8072e-02],\n        [-2.1858e-01,  2.5975e-01,  3.4793e-01,  2.8827e-01, -7.2792e-02,\n         -3.2030e-01, -9.4930e-02,  3.0781e-01],\n        [-1.0739e-01, -2.3931e-01,  2.2954e-01,  1.4123e-01,  1.8509e-01,\n          4.8378e-02,  2.6545e-01, -3.3390e-01],\n        [ 3.4954e-01, -1.1297e-01, -1.3128e-02, -3.0555e-01,  1.8190e-01,\n          1.5036e-01,  2.2572e-01,  2.1058e-01],\n        [-4.4261e-03,  8.5520e-02,  1.6943e-01,  1.2374e-02,  7.6304e-02,\n          2.9980e-01,  2.1280e-01,  1.2635e-01],\n        [ 1.3522e-01, -2.7650e-01, -2.2411e-01,  6.6924e-02, -1.0505e-01,\n          1.5213e-02,  2.1936e-01,  1.9284e-01],\n        [ 1.0754e-01, -2.8661e-01,  3.1615e-01,  1.8706e-01, -3.3903e-02,\n         -1.8668e-01,  2.4461e-01,  1.7842e-01],\n        [ 2.9340e-01, -3.0194e-03,  6.0465e-02, -1.6132e-02,  2.6671e-01,\n          1.4215e-01, -6.8337e-02, -1.4596e-01],\n        [ 6.1077e-02, -2.7333e-01, -2.7519e-01,  2.8337e-01, -1.4568e-01,\n         -4.1839e-02,  1.9093e-01,  1.4006e-01],\n        [-2.5646e-01,  1.1507e-01,  1.7550e-01,  1.5628e-01,  1.9148e-01,\n         -3.5277e-02,  2.2517e-01, -3.1733e-02],\n        [ 9.4985e-02, -3.6984e-03, -8.5926e-03,  2.7068e-01, -1.1809e-01,\n         -2.2666e-01,  1.8422e-04, -3.0586e-02],\n        [ 3.4035e-01, -2.4700e-01,  1.5708e-01,  3.5035e-01,  2.5259e-01,\n         -2.7556e-01,  3.0753e-01,  2.5816e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-6.4646e-02,  1.2478e-01,  5.6213e-02,  2.8862e-01,  1.1709e-02,\n         2.3739e-01,  1.3553e-01, -1.4827e-01, -2.3061e-01, -2.0395e-01,\n        -2.4400e-01, -2.8710e-01,  2.8513e-01,  4.2016e-02,  1.0033e-01,\n         1.5302e-01, -3.1868e-01,  1.6242e-01,  4.8346e-02, -2.3779e-01,\n         9.3018e-02, -2.7916e-01,  1.9946e-01,  2.9146e-01, -4.0673e-02,\n        -2.6537e-02,  2.8717e-01,  1.0310e-01, -9.7518e-02, -1.7410e-01,\n         9.5294e-05,  1.2775e-01], requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.6693e-01,  1.0417e-01, -1.3134e-01,  1.7660e-02,  1.1694e-01,\n         -9.2232e-02,  6.4225e-02,  1.3588e-01, -1.7092e-01,  5.2730e-02,\n         -1.5507e-01, -1.3483e-01, -1.5221e-01, -1.3158e-01, -1.5718e-01,\n         -3.6060e-02, -5.3248e-02,  1.6257e-01,  1.3525e-01, -1.4506e-01,\n          1.2693e-01,  1.1423e-01,  1.5349e-03, -7.5750e-02,  6.9753e-02,\n         -1.7047e-01,  7.7803e-02,  2.0474e-02, -4.5660e-02,  1.2251e-01,\n          2.6506e-02,  1.1262e-01],\n        [-1.2711e-01, -1.3702e-02,  1.3094e-01, -8.2498e-02,  2.5889e-02,\n          1.1801e-01, -7.1393e-02,  1.4494e-01, -1.5935e-02,  1.2727e-01,\n          1.4344e-01,  6.7098e-02, -7.0808e-02,  1.4039e-01, -1.1187e-01,\n         -6.0917e-02, -1.4039e-02,  1.4539e-01, -1.7368e-01,  2.7132e-02,\n          8.4506e-02,  5.2959e-02, -1.3176e-01, -7.6193e-02,  1.3494e-01,\n          1.6680e-01, -1.1944e-01,  1.3116e-01,  8.3935e-05, -1.6619e-01,\n         -1.5803e-01, -4.8570e-02],\n        [-2.0737e-02,  1.6236e-01, -1.5914e-01,  1.0951e-01,  8.5957e-02,\n          1.4351e-01, -2.4070e-02,  1.3874e-01, -1.0006e-01, -1.0689e-01,\n          7.4880e-02, -1.4399e-01,  4.5768e-02,  2.0570e-02,  3.0078e-02,\n          1.3676e-01, -1.1515e-01,  8.9674e-02, -4.2840e-04,  7.7060e-02,\n          1.1537e-01, -9.8662e-02, -1.5839e-01,  1.2119e-01,  9.4508e-02,\n         -2.4510e-02,  9.9374e-02, -6.3015e-02, -1.5291e-01,  8.4928e-02,\n         -1.3503e-01,  3.0539e-02],\n        [-1.5493e-01, -1.7409e-01, -9.2768e-02, -4.1932e-02,  2.6540e-02,\n         -2.5629e-03, -1.1478e-01,  1.0413e-01, -4.0626e-02,  8.2264e-04,\n         -1.5129e-01, -6.3275e-02,  4.8680e-02,  4.8028e-02,  1.4325e-01,\n         -1.6368e-01,  1.0234e-01,  1.3698e-02, -8.2891e-02, -1.4361e-02,\n          5.4876e-02,  9.3120e-02, -1.0418e-01,  4.0442e-02,  1.1160e-01,\n         -1.7612e-01, -7.0732e-02,  1.1022e-01,  6.0299e-02,  4.9211e-02,\n          1.5609e-01,  4.7131e-04],\n        [ 3.2058e-02,  6.3377e-02,  1.6102e-01,  1.4485e-01, -8.5373e-02,\n         -4.5348e-02,  1.2449e-01,  8.3867e-02,  6.7806e-02,  7.6461e-02,\n          8.8229e-02, -2.5041e-03, -1.7728e-02,  9.7954e-02,  1.6435e-01,\n         -9.9831e-02, -1.3623e-01,  2.6190e-04,  5.8744e-02,  1.2569e-01,\n          1.5388e-02, -4.5759e-03,  1.7170e-01,  1.6161e-01, -1.6355e-01,\n         -6.9532e-02,  4.2430e-02,  1.6403e-01, -1.1797e-01, -1.2092e-01,\n         -4.1281e-02,  1.1043e-01],\n        [-5.3948e-02,  5.0049e-03, -1.4804e-01, -3.4127e-02,  1.7216e-02,\n         -5.2769e-03, -1.1926e-01,  9.2697e-02, -4.1619e-02,  1.4551e-01,\n          8.1587e-02,  7.6672e-02,  2.4090e-02, -7.8845e-02, -9.1692e-02,\n         -4.5570e-02, -1.1246e-01,  7.9156e-02,  3.0123e-02,  1.3478e-01,\n          1.3793e-01,  5.0021e-02,  1.0529e-01, -7.7982e-02,  4.2233e-03,\n          1.6320e-01, -1.7179e-01,  6.3778e-02, -1.0170e-01, -3.7700e-02,\n          1.1139e-01,  1.0246e-01],\n        [ 1.2125e-02,  3.0554e-02, -8.3788e-02,  3.1153e-02, -1.0667e-01,\n          3.6894e-02, -1.1832e-01,  1.2625e-01, -1.4064e-01,  4.9770e-02,\n         -1.4350e-01,  9.0006e-02, -9.6803e-02,  2.5056e-02,  1.6213e-01,\n          2.3552e-02,  9.7547e-02,  3.4691e-02,  1.1812e-01,  1.6726e-01,\n         -5.4311e-02,  9.1529e-02, -1.0077e-01, -1.3305e-02, -5.4953e-02,\n          6.8239e-02,  3.3196e-02, -1.3145e-01, -2.1698e-02,  4.4895e-02,\n         -3.2612e-02, -1.4046e-01],\n        [ 3.3005e-02,  1.3363e-01,  1.5504e-01,  1.0766e-01,  1.3846e-01,\n          9.4543e-02,  7.4602e-02,  1.4822e-01,  1.7568e-01,  6.1203e-02,\n          1.0629e-01, -1.6385e-01, -1.1657e-01, -5.2871e-02,  8.5920e-02,\n          1.2126e-03,  3.2420e-03,  3.5020e-02,  5.5484e-02, -8.0550e-02,\n          2.0121e-02,  1.3096e-01,  1.2531e-02, -1.3423e-01,  1.0380e-01,\n          6.8320e-02,  1.7574e-01,  3.0681e-03,  2.5211e-02,  9.7653e-02,\n         -9.4018e-02, -5.5665e-02],\n        [ 2.2299e-02, -6.7574e-02,  5.4062e-02,  7.2827e-02,  1.6573e-01,\n          2.5271e-03, -4.6799e-02,  1.5934e-01,  8.3767e-02,  1.5061e-01,\n         -4.2556e-02, -5.0645e-02, -1.3197e-01,  9.2588e-02,  8.2443e-02,\n         -1.3486e-01,  7.9279e-02,  1.3621e-01,  1.4138e-01,  1.1449e-01,\n          1.2592e-02, -1.2908e-01,  2.0526e-02,  1.2869e-02, -1.6044e-01,\n          6.6145e-03,  2.6234e-02,  1.2027e-01, -7.7748e-03, -1.6019e-01,\n         -3.8530e-02, -6.8085e-02],\n        [ 1.6994e-01, -2.3689e-02,  2.2258e-02,  3.7262e-02, -1.0586e-01,\n          5.4176e-02, -5.7762e-02, -8.6576e-02, -9.9300e-02, -1.4913e-01,\n          9.3254e-02, -2.3878e-02, -1.4729e-02, -1.1664e-01,  1.3002e-01,\n         -3.0132e-02,  1.6146e-01,  5.9158e-02,  1.4918e-01, -4.8687e-02,\n          1.1891e-01, -4.5232e-03, -1.3159e-01,  1.3506e-02, -8.6411e-03,\n         -1.0174e-01, -5.8933e-02, -7.0479e-02, -1.2295e-02,  1.4365e-01,\n         -1.2467e-01,  2.7610e-02],\n        [-1.5287e-01,  1.0526e-01, -2.7772e-02,  3.6447e-02, -4.4100e-03,\n          6.4195e-02, -1.4254e-01,  2.7770e-02,  5.3357e-03, -7.1527e-02,\n          1.2383e-03,  2.4177e-02,  1.1410e-01,  7.5383e-03,  5.4826e-02,\n         -3.2619e-02,  1.0408e-01, -2.3831e-03,  5.6813e-02,  1.1622e-01,\n          5.3391e-02, -5.4241e-02,  1.6379e-01, -5.1335e-02, -1.0996e-01,\n          2.9220e-03, -7.1819e-02, -5.4703e-02,  2.2050e-02, -1.3775e-01,\n         -9.2194e-02,  1.0481e-01],\n        [-4.4636e-02,  2.5166e-02,  1.7604e-02, -6.2993e-02,  2.5957e-02,\n          1.6126e-01, -1.5449e-01,  7.5979e-02, -1.3756e-01, -9.7284e-02,\n         -1.6660e-01, -4.4455e-02, -1.1011e-01,  7.6727e-02, -2.9925e-03,\n         -7.4949e-02,  1.5296e-01,  7.0627e-02, -4.9052e-02,  9.5691e-02,\n         -1.2218e-01,  1.3833e-01,  1.8817e-02, -3.9251e-03, -1.4160e-01,\n          8.8704e-02, -7.2439e-02,  8.1106e-02,  9.5024e-02,  1.2385e-01,\n         -6.2323e-02, -3.3966e-02],\n        [ 1.1290e-01,  6.2151e-03, -9.7740e-02, -1.9260e-02, -1.3568e-01,\n          1.6884e-01,  1.4315e-01,  1.0209e-01, -1.3744e-01,  1.4299e-01,\n          5.1065e-02, -1.7572e-01, -1.6472e-01,  9.4668e-02, -7.5171e-02,\n         -9.6052e-02, -3.0799e-02,  1.5955e-01, -3.0941e-03, -1.4186e-01,\n          1.6717e-01, -9.0648e-02, -1.4614e-01,  8.2107e-02, -3.8591e-02,\n         -9.0599e-02, -1.4364e-01,  1.0211e-01, -1.4718e-01,  1.5601e-01,\n         -1.5324e-01,  4.3225e-02],\n        [-1.3255e-02, -1.6461e-01,  9.0405e-06,  3.5166e-02, -9.9821e-02,\n         -1.1659e-01,  5.5444e-02,  4.7099e-02,  5.2878e-02,  3.2768e-02,\n         -1.5297e-01, -4.2840e-02, -8.4355e-02,  2.4421e-02,  1.3697e-01,\n          6.7150e-02,  1.6503e-01, -1.2441e-01, -7.1824e-02,  2.4947e-02,\n          3.9156e-02, -2.7999e-02,  5.0270e-02,  1.6916e-01,  9.0396e-02,\n          6.2782e-02,  1.3785e-01,  1.5354e-01, -1.3961e-01, -6.4805e-02,\n         -9.6729e-02, -3.5063e-02],\n        [ 1.4446e-01,  5.4506e-02, -1.3596e-01,  1.4154e-01, -1.5894e-01,\n          3.6450e-02,  6.7084e-02, -1.2888e-01,  9.8894e-02,  1.6852e-01,\n         -1.3431e-01, -7.6760e-02,  3.5378e-02,  8.1806e-03, -1.1394e-01,\n         -6.3533e-02, -3.6669e-02, -1.6545e-01,  1.1623e-01, -1.1670e-01,\n          8.2052e-02,  1.4885e-01,  5.2539e-02,  1.0233e-01, -1.3464e-01,\n          1.3009e-01, -9.4016e-02, -1.2578e-01, -8.8287e-02, -5.9627e-02,\n         -1.2157e-01, -1.7331e-01],\n        [ 8.2321e-02, -3.0954e-02,  2.4689e-02,  1.0503e-01, -1.1261e-01,\n         -4.8990e-02,  2.1526e-02, -9.4229e-03,  1.1479e-01,  1.1953e-01,\n          1.0074e-01,  1.4972e-01,  9.8657e-02,  6.4597e-02, -1.7015e-01,\n         -1.3914e-01, -4.0949e-02, -6.4400e-02,  7.3427e-02,  1.5829e-01,\n          1.0595e-01,  7.4699e-02,  1.6382e-01,  5.7078e-02,  1.4401e-01,\n          1.3223e-01,  1.4316e-02,  3.9810e-02,  5.2869e-03, -1.6201e-01,\n          3.4865e-02, -4.7229e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1076,  0.1384, -0.1272,  0.1224, -0.0959,  0.0653, -0.1169,  0.0849,\n         0.0876,  0.0616, -0.0329, -0.0792,  0.1281,  0.0612,  0.0800,  0.1598],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0468, -0.1295,  0.2065,  0.0765,  0.1115, -0.2136, -0.0609,  0.0159,\n         -0.0661, -0.1284,  0.0089, -0.0932,  0.2311, -0.1350,  0.0644,  0.1613],\n        [-0.1855, -0.0202, -0.0869, -0.2264,  0.1546,  0.0415, -0.2403, -0.1176,\n         -0.0232, -0.2404,  0.1097,  0.0577,  0.1938,  0.0858,  0.2489, -0.1516],\n        [-0.1392, -0.0222, -0.1513, -0.1364, -0.0856, -0.1160,  0.0535, -0.2393,\n          0.2432,  0.0840, -0.1521,  0.0924,  0.2202, -0.2042, -0.2197,  0.1127],\n        [-0.1712, -0.1656,  0.1328, -0.1721, -0.0848, -0.1458,  0.0430, -0.0281,\n         -0.2263,  0.1472,  0.1560, -0.2120, -0.0214,  0.1705,  0.1242,  0.1248],\n        [ 0.1754,  0.0674,  0.0971,  0.0821,  0.1112, -0.2486,  0.0166, -0.1917,\n         -0.2321,  0.0783, -0.0344, -0.2361,  0.2031, -0.0239,  0.0741,  0.2324],\n        [-0.0620, -0.0941,  0.1231, -0.1417,  0.0918, -0.1918,  0.1888, -0.0736,\n         -0.2477,  0.1920, -0.2329,  0.2151,  0.1432, -0.1217,  0.1872, -0.1607],\n        [-0.1969, -0.0181,  0.1629,  0.1746,  0.1877, -0.0138, -0.0812, -0.1806,\n          0.2200,  0.1862, -0.2419, -0.0766, -0.2002, -0.2401,  0.1511,  0.0332],\n        [ 0.0534,  0.2128, -0.2122, -0.2032, -0.0621,  0.2268, -0.1402,  0.2233,\n          0.0249, -0.1242, -0.1880,  0.0758, -0.2341,  0.0513, -0.1980, -0.0070]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1487, -0.0335, -0.1677, -0.1618, -0.1259,  0.1006, -0.0326,  0.2212],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2574,  0.0926,  0.3176,  0.1250, -0.2043, -0.0183,  0.2261, -0.2921]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3479], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x752e03a987d0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-6.4646e-02,  1.2478e-01,  5.6213e-02,  2.8862e-01,  1.1709e-02,\n         2.3739e-01,  1.3553e-01, -1.4827e-01, -2.3061e-01, -2.0395e-01,\n        -2.4400e-01, -2.8710e-01,  2.8513e-01,  4.2016e-02,  1.0033e-01,\n         1.5302e-01, -3.1868e-01,  1.6242e-01,  4.8346e-02, -2.3779e-01,\n         9.3018e-02, -2.7916e-01,  1.9946e-01,  2.9146e-01, -4.0673e-02,\n        -2.6537e-02,  2.8717e-01,  1.0310e-01, -9.7518e-02, -1.7410e-01,\n         9.5294e-05,  1.2775e-01], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-5.6276e-02,  7.1112e-02,  1.1859e-01, -1.5197e-01,  1.3726e-01,\n         -2.9079e-01,  2.1477e-01, -9.2847e-02],\n        [ 1.2631e-01, -2.2161e-01, -7.2355e-02,  1.9635e-01,  2.9984e-01,\n         -2.0431e-01,  2.3115e-01,  2.6764e-01],\n        [ 2.1539e-01,  1.5246e-01,  1.4358e-01, -3.1099e-01,  2.1740e-01,\n         -3.0544e-02,  3.5488e-02,  1.7603e-02],\n        [ 2.1967e-01,  8.3642e-03, -2.4913e-01,  2.1680e-01, -1.1804e-01,\n         -2.4640e-01,  3.2924e-02, -1.4210e-01],\n        [ 1.2577e-01,  1.7284e-01, -7.2915e-02,  3.2705e-01, -2.6711e-01,\n         -2.3508e-01,  7.3442e-02, -1.9903e-02],\n        [ 2.7855e-02, -2.9477e-01, -1.7477e-02,  1.9669e-01, -3.3480e-01,\n          8.1806e-02, -7.3840e-02, -8.4398e-02],\n        [-2.7576e-01, -9.7426e-02, -1.7235e-01,  4.2738e-02,  4.7977e-02,\n         -1.5656e-01, -3.4763e-01,  1.3153e-01],\n        [-2.0689e-01,  2.6705e-01,  2.2117e-01,  2.7255e-01,  5.5093e-02,\n          2.8345e-01, -1.8449e-01, -8.1419e-02],\n        [ 1.2933e-01, -9.6896e-02,  2.6988e-01,  2.3406e-01,  3.3455e-01,\n          1.7501e-01,  2.3809e-01, -2.2328e-01],\n        [ 2.9908e-01,  3.2911e-01,  1.5934e-01,  8.3074e-02, -1.0077e-01,\n         -1.5326e-01, -2.0645e-01,  1.4977e-01],\n        [ 1.7125e-01, -2.7838e-01,  2.3321e-01, -1.9875e-01,  2.3787e-02,\n         -1.1857e-01, -6.5544e-02,  1.0790e-01],\n        [-7.7509e-02, -5.2877e-02, -2.1473e-01,  2.1984e-01, -1.9319e-01,\n          1.6280e-01, -1.7478e-01, -2.6923e-01],\n        [ 1.7494e-01, -3.1207e-01,  1.2059e-01, -3.3044e-02, -2.3442e-01,\n          1.6730e-01,  1.7168e-01, -3.3503e-01],\n        [ 1.0443e-01, -2.4404e-01, -9.3546e-02,  1.5305e-01, -1.3051e-01,\n         -2.8563e-01, -3.8494e-02, -1.0471e-01],\n        [ 3.8720e-02,  3.1302e-01, -3.2320e-01, -1.9216e-01,  3.5085e-01,\n          5.8336e-02, -5.6120e-02, -1.9479e-01],\n        [ 1.0914e-02,  2.6451e-01, -2.6853e-01, -6.1141e-02,  5.8384e-02,\n         -2.8713e-01, -3.5314e-01, -3.0564e-01],\n        [ 3.0802e-01,  7.3794e-02, -5.1979e-02,  1.0820e-02,  5.3345e-02,\n          3.0251e-02,  7.8646e-02,  1.9703e-02],\n        [ 2.2017e-02, -2.0256e-01,  3.1113e-01,  1.1842e-02,  2.3401e-01,\n          1.7858e-01,  8.7017e-02, -2.5571e-01],\n        [-6.0792e-02, -1.2527e-01,  1.5803e-01, -2.2323e-01, -1.7514e-01,\n          4.0752e-04, -3.9132e-03,  1.5410e-01],\n        [ 2.5577e-01, -1.4364e-01, -3.2459e-01,  1.7390e-01,  1.2513e-01,\n         -1.9389e-01,  2.5803e-01,  2.8973e-01],\n        [-3.3816e-01, -3.1199e-01,  1.2022e-01, -3.1285e-01,  1.7493e-01,\n          2.6594e-01,  1.2783e-01, -3.8072e-02],\n        [-2.1858e-01,  2.5975e-01,  3.4793e-01,  2.8827e-01, -7.2792e-02,\n         -3.2030e-01, -9.4930e-02,  3.0781e-01],\n        [-1.0739e-01, -2.3931e-01,  2.2954e-01,  1.4123e-01,  1.8509e-01,\n          4.8378e-02,  2.6545e-01, -3.3390e-01],\n        [ 3.4954e-01, -1.1297e-01, -1.3128e-02, -3.0555e-01,  1.8190e-01,\n          1.5036e-01,  2.2572e-01,  2.1058e-01],\n        [-4.4261e-03,  8.5520e-02,  1.6943e-01,  1.2374e-02,  7.6304e-02,\n          2.9980e-01,  2.1280e-01,  1.2635e-01],\n        [ 1.3522e-01, -2.7650e-01, -2.2411e-01,  6.6924e-02, -1.0505e-01,\n          1.5213e-02,  2.1936e-01,  1.9284e-01],\n        [ 1.0754e-01, -2.8661e-01,  3.1615e-01,  1.8706e-01, -3.3903e-02,\n         -1.8668e-01,  2.4461e-01,  1.7842e-01],\n        [ 2.9340e-01, -3.0194e-03,  6.0465e-02, -1.6132e-02,  2.6671e-01,\n          1.4215e-01, -6.8337e-02, -1.4596e-01],\n        [ 6.1077e-02, -2.7333e-01, -2.7519e-01,  2.8337e-01, -1.4568e-01,\n         -4.1839e-02,  1.9093e-01,  1.4006e-01],\n        [-2.5646e-01,  1.1507e-01,  1.7550e-01,  1.5628e-01,  1.9148e-01,\n         -3.5277e-02,  2.2517e-01, -3.1733e-02],\n        [ 9.4985e-02, -3.6984e-03, -8.5926e-03,  2.7068e-01, -1.1809e-01,\n         -2.2666e-01,  1.8422e-04, -3.0586e-02],\n        [ 3.4035e-01, -2.4700e-01,  1.5708e-01,  3.5035e-01,  2.5259e-01,\n         -2.7556e-01,  3.0753e-01,  2.5816e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1076,  0.1384, -0.1272,  0.1224, -0.0959,  0.0653, -0.1169,  0.0849,\n         0.0876,  0.0616, -0.0329, -0.0792,  0.1281,  0.0612,  0.0800,  0.1598],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.6693e-01,  1.0417e-01, -1.3134e-01,  1.7660e-02,  1.1694e-01,\n         -9.2232e-02,  6.4225e-02,  1.3588e-01, -1.7092e-01,  5.2730e-02,\n         -1.5507e-01, -1.3483e-01, -1.5221e-01, -1.3158e-01, -1.5718e-01,\n         -3.6060e-02, -5.3248e-02,  1.6257e-01,  1.3525e-01, -1.4506e-01,\n          1.2693e-01,  1.1423e-01,  1.5349e-03, -7.5750e-02,  6.9753e-02,\n         -1.7047e-01,  7.7803e-02,  2.0474e-02, -4.5660e-02,  1.2251e-01,\n          2.6506e-02,  1.1262e-01],\n        [-1.2711e-01, -1.3702e-02,  1.3094e-01, -8.2498e-02,  2.5889e-02,\n          1.1801e-01, -7.1393e-02,  1.4494e-01, -1.5935e-02,  1.2727e-01,\n          1.4344e-01,  6.7098e-02, -7.0808e-02,  1.4039e-01, -1.1187e-01,\n         -6.0917e-02, -1.4039e-02,  1.4539e-01, -1.7368e-01,  2.7132e-02,\n          8.4506e-02,  5.2959e-02, -1.3176e-01, -7.6193e-02,  1.3494e-01,\n          1.6680e-01, -1.1944e-01,  1.3116e-01,  8.3935e-05, -1.6619e-01,\n         -1.5803e-01, -4.8570e-02],\n        [-2.0737e-02,  1.6236e-01, -1.5914e-01,  1.0951e-01,  8.5957e-02,\n          1.4351e-01, -2.4070e-02,  1.3874e-01, -1.0006e-01, -1.0689e-01,\n          7.4880e-02, -1.4399e-01,  4.5768e-02,  2.0570e-02,  3.0078e-02,\n          1.3676e-01, -1.1515e-01,  8.9674e-02, -4.2840e-04,  7.7060e-02,\n          1.1537e-01, -9.8662e-02, -1.5839e-01,  1.2119e-01,  9.4508e-02,\n         -2.4510e-02,  9.9374e-02, -6.3015e-02, -1.5291e-01,  8.4928e-02,\n         -1.3503e-01,  3.0539e-02],\n        [-1.5493e-01, -1.7409e-01, -9.2768e-02, -4.1932e-02,  2.6540e-02,\n         -2.5629e-03, -1.1478e-01,  1.0413e-01, -4.0626e-02,  8.2264e-04,\n         -1.5129e-01, -6.3275e-02,  4.8680e-02,  4.8028e-02,  1.4325e-01,\n         -1.6368e-01,  1.0234e-01,  1.3698e-02, -8.2891e-02, -1.4361e-02,\n          5.4876e-02,  9.3120e-02, -1.0418e-01,  4.0442e-02,  1.1160e-01,\n         -1.7612e-01, -7.0732e-02,  1.1022e-01,  6.0299e-02,  4.9211e-02,\n          1.5609e-01,  4.7131e-04],\n        [ 3.2058e-02,  6.3377e-02,  1.6102e-01,  1.4485e-01, -8.5373e-02,\n         -4.5348e-02,  1.2449e-01,  8.3867e-02,  6.7806e-02,  7.6461e-02,\n          8.8229e-02, -2.5041e-03, -1.7728e-02,  9.7954e-02,  1.6435e-01,\n         -9.9831e-02, -1.3623e-01,  2.6190e-04,  5.8744e-02,  1.2569e-01,\n          1.5388e-02, -4.5759e-03,  1.7170e-01,  1.6161e-01, -1.6355e-01,\n         -6.9532e-02,  4.2430e-02,  1.6403e-01, -1.1797e-01, -1.2092e-01,\n         -4.1281e-02,  1.1043e-01],\n        [-5.3948e-02,  5.0049e-03, -1.4804e-01, -3.4127e-02,  1.7216e-02,\n         -5.2769e-03, -1.1926e-01,  9.2697e-02, -4.1619e-02,  1.4551e-01,\n          8.1587e-02,  7.6672e-02,  2.4090e-02, -7.8845e-02, -9.1692e-02,\n         -4.5570e-02, -1.1246e-01,  7.9156e-02,  3.0123e-02,  1.3478e-01,\n          1.3793e-01,  5.0021e-02,  1.0529e-01, -7.7982e-02,  4.2233e-03,\n          1.6320e-01, -1.7179e-01,  6.3778e-02, -1.0170e-01, -3.7700e-02,\n          1.1139e-01,  1.0246e-01],\n        [ 1.2125e-02,  3.0554e-02, -8.3788e-02,  3.1153e-02, -1.0667e-01,\n          3.6894e-02, -1.1832e-01,  1.2625e-01, -1.4064e-01,  4.9770e-02,\n         -1.4350e-01,  9.0006e-02, -9.6803e-02,  2.5056e-02,  1.6213e-01,\n          2.3552e-02,  9.7547e-02,  3.4691e-02,  1.1812e-01,  1.6726e-01,\n         -5.4311e-02,  9.1529e-02, -1.0077e-01, -1.3305e-02, -5.4953e-02,\n          6.8239e-02,  3.3196e-02, -1.3145e-01, -2.1698e-02,  4.4895e-02,\n         -3.2612e-02, -1.4046e-01],\n        [ 3.3005e-02,  1.3363e-01,  1.5504e-01,  1.0766e-01,  1.3846e-01,\n          9.4543e-02,  7.4602e-02,  1.4822e-01,  1.7568e-01,  6.1203e-02,\n          1.0629e-01, -1.6385e-01, -1.1657e-01, -5.2871e-02,  8.5920e-02,\n          1.2126e-03,  3.2420e-03,  3.5020e-02,  5.5484e-02, -8.0550e-02,\n          2.0121e-02,  1.3096e-01,  1.2531e-02, -1.3423e-01,  1.0380e-01,\n          6.8320e-02,  1.7574e-01,  3.0681e-03,  2.5211e-02,  9.7653e-02,\n         -9.4018e-02, -5.5665e-02],\n        [ 2.2299e-02, -6.7574e-02,  5.4062e-02,  7.2827e-02,  1.6573e-01,\n          2.5271e-03, -4.6799e-02,  1.5934e-01,  8.3767e-02,  1.5061e-01,\n         -4.2556e-02, -5.0645e-02, -1.3197e-01,  9.2588e-02,  8.2443e-02,\n         -1.3486e-01,  7.9279e-02,  1.3621e-01,  1.4138e-01,  1.1449e-01,\n          1.2592e-02, -1.2908e-01,  2.0526e-02,  1.2869e-02, -1.6044e-01,\n          6.6145e-03,  2.6234e-02,  1.2027e-01, -7.7748e-03, -1.6019e-01,\n         -3.8530e-02, -6.8085e-02],\n        [ 1.6994e-01, -2.3689e-02,  2.2258e-02,  3.7262e-02, -1.0586e-01,\n          5.4176e-02, -5.7762e-02, -8.6576e-02, -9.9300e-02, -1.4913e-01,\n          9.3254e-02, -2.3878e-02, -1.4729e-02, -1.1664e-01,  1.3002e-01,\n         -3.0132e-02,  1.6146e-01,  5.9158e-02,  1.4918e-01, -4.8687e-02,\n          1.1891e-01, -4.5232e-03, -1.3159e-01,  1.3506e-02, -8.6411e-03,\n         -1.0174e-01, -5.8933e-02, -7.0479e-02, -1.2295e-02,  1.4365e-01,\n         -1.2467e-01,  2.7610e-02],\n        [-1.5287e-01,  1.0526e-01, -2.7772e-02,  3.6447e-02, -4.4100e-03,\n          6.4195e-02, -1.4254e-01,  2.7770e-02,  5.3357e-03, -7.1527e-02,\n          1.2383e-03,  2.4177e-02,  1.1410e-01,  7.5383e-03,  5.4826e-02,\n         -3.2619e-02,  1.0408e-01, -2.3831e-03,  5.6813e-02,  1.1622e-01,\n          5.3391e-02, -5.4241e-02,  1.6379e-01, -5.1335e-02, -1.0996e-01,\n          2.9220e-03, -7.1819e-02, -5.4703e-02,  2.2050e-02, -1.3775e-01,\n         -9.2194e-02,  1.0481e-01],\n        [-4.4636e-02,  2.5166e-02,  1.7604e-02, -6.2993e-02,  2.5957e-02,\n          1.6126e-01, -1.5449e-01,  7.5979e-02, -1.3756e-01, -9.7284e-02,\n         -1.6660e-01, -4.4455e-02, -1.1011e-01,  7.6727e-02, -2.9925e-03,\n         -7.4949e-02,  1.5296e-01,  7.0627e-02, -4.9052e-02,  9.5691e-02,\n         -1.2218e-01,  1.3833e-01,  1.8817e-02, -3.9251e-03, -1.4160e-01,\n          8.8704e-02, -7.2439e-02,  8.1106e-02,  9.5024e-02,  1.2385e-01,\n         -6.2323e-02, -3.3966e-02],\n        [ 1.1290e-01,  6.2151e-03, -9.7740e-02, -1.9260e-02, -1.3568e-01,\n          1.6884e-01,  1.4315e-01,  1.0209e-01, -1.3744e-01,  1.4299e-01,\n          5.1065e-02, -1.7572e-01, -1.6472e-01,  9.4668e-02, -7.5171e-02,\n         -9.6052e-02, -3.0799e-02,  1.5955e-01, -3.0941e-03, -1.4186e-01,\n          1.6717e-01, -9.0648e-02, -1.4614e-01,  8.2107e-02, -3.8591e-02,\n         -9.0599e-02, -1.4364e-01,  1.0211e-01, -1.4718e-01,  1.5601e-01,\n         -1.5324e-01,  4.3225e-02],\n        [-1.3255e-02, -1.6461e-01,  9.0405e-06,  3.5166e-02, -9.9821e-02,\n         -1.1659e-01,  5.5444e-02,  4.7099e-02,  5.2878e-02,  3.2768e-02,\n         -1.5297e-01, -4.2840e-02, -8.4355e-02,  2.4421e-02,  1.3697e-01,\n          6.7150e-02,  1.6503e-01, -1.2441e-01, -7.1824e-02,  2.4947e-02,\n          3.9156e-02, -2.7999e-02,  5.0270e-02,  1.6916e-01,  9.0396e-02,\n          6.2782e-02,  1.3785e-01,  1.5354e-01, -1.3961e-01, -6.4805e-02,\n         -9.6729e-02, -3.5063e-02],\n        [ 1.4446e-01,  5.4506e-02, -1.3596e-01,  1.4154e-01, -1.5894e-01,\n          3.6450e-02,  6.7084e-02, -1.2888e-01,  9.8894e-02,  1.6852e-01,\n         -1.3431e-01, -7.6760e-02,  3.5378e-02,  8.1806e-03, -1.1394e-01,\n         -6.3533e-02, -3.6669e-02, -1.6545e-01,  1.1623e-01, -1.1670e-01,\n          8.2052e-02,  1.4885e-01,  5.2539e-02,  1.0233e-01, -1.3464e-01,\n          1.3009e-01, -9.4016e-02, -1.2578e-01, -8.8287e-02, -5.9627e-02,\n         -1.2157e-01, -1.7331e-01],\n        [ 8.2321e-02, -3.0954e-02,  2.4689e-02,  1.0503e-01, -1.1261e-01,\n         -4.8990e-02,  2.1526e-02, -9.4229e-03,  1.1479e-01,  1.1953e-01,\n          1.0074e-01,  1.4972e-01,  9.8657e-02,  6.4597e-02, -1.7015e-01,\n         -1.3914e-01, -4.0949e-02, -6.4400e-02,  7.3427e-02,  1.5829e-01,\n          1.0595e-01,  7.4699e-02,  1.6382e-01,  5.7078e-02,  1.4401e-01,\n          1.3223e-01,  1.4316e-02,  3.9810e-02,  5.2869e-03, -1.6201e-01,\n          3.4865e-02, -4.7229e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1487, -0.0335, -0.1677, -0.1618, -0.1259,  0.1006, -0.0326,  0.2212],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0468, -0.1295,  0.2065,  0.0765,  0.1115, -0.2136, -0.0609,  0.0159,\n         -0.0661, -0.1284,  0.0089, -0.0932,  0.2311, -0.1350,  0.0644,  0.1613],\n        [-0.1855, -0.0202, -0.0869, -0.2264,  0.1546,  0.0415, -0.2403, -0.1176,\n         -0.0232, -0.2404,  0.1097,  0.0577,  0.1938,  0.0858,  0.2489, -0.1516],\n        [-0.1392, -0.0222, -0.1513, -0.1364, -0.0856, -0.1160,  0.0535, -0.2393,\n          0.2432,  0.0840, -0.1521,  0.0924,  0.2202, -0.2042, -0.2197,  0.1127],\n        [-0.1712, -0.1656,  0.1328, -0.1721, -0.0848, -0.1458,  0.0430, -0.0281,\n         -0.2263,  0.1472,  0.1560, -0.2120, -0.0214,  0.1705,  0.1242,  0.1248],\n        [ 0.1754,  0.0674,  0.0971,  0.0821,  0.1112, -0.2486,  0.0166, -0.1917,\n         -0.2321,  0.0783, -0.0344, -0.2361,  0.2031, -0.0239,  0.0741,  0.2324],\n        [-0.0620, -0.0941,  0.1231, -0.1417,  0.0918, -0.1918,  0.1888, -0.0736,\n         -0.2477,  0.1920, -0.2329,  0.2151,  0.1432, -0.1217,  0.1872, -0.1607],\n        [-0.1969, -0.0181,  0.1629,  0.1746,  0.1877, -0.0138, -0.0812, -0.1806,\n          0.2200,  0.1862, -0.2419, -0.0766, -0.2002, -0.2401,  0.1511,  0.0332],\n        [ 0.0534,  0.2128, -0.2122, -0.2032, -0.0621,  0.2268, -0.1402,  0.2233,\n          0.0249, -0.1242, -0.1880,  0.0758, -0.2341,  0.0513, -0.1980, -0.0070]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=1, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3479], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2574,  0.0926,  0.3176,  0.1250, -0.2043, -0.0183,  0.2261, -0.2921]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	1,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x752e0297a6d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s265440000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s265440000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}