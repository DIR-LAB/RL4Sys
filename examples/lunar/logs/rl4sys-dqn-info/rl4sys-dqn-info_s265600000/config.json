{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s265600000"
    },
    "q_lr":	0.0005,
    "seed":	265600000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x0000014B2A08D0F0>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1983, -0.0115,  0.3485,  0.0614, -0.2709,  0.3021, -0.0904,  0.2905,\n        -0.2940,  0.0466,  0.2123,  0.0432, -0.3111, -0.3322,  0.0789,  0.1282,\n         0.1977,  0.2351,  0.3506,  0.2896, -0.2495, -0.2134,  0.1984,  0.1773,\n        -0.2720,  0.0186,  0.1288, -0.2600,  0.0235,  0.1695,  0.2897, -0.0345],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.0912e-01, -1.8631e-01, -1.9196e-01, -9.9107e-02, -1.8951e-01,\n          3.4118e-01, -3.4058e-01, -2.1737e-01],\n        [ 3.1828e-01, -2.0632e-01,  3.0679e-01,  3.4181e-03,  3.5135e-01,\n          6.0770e-02,  3.4947e-01, -4.1461e-02],\n        [-1.4743e-01,  3.0875e-01, -1.9459e-01,  3.4533e-01, -1.0185e-01,\n         -2.4095e-01,  6.3633e-02,  2.1278e-01],\n        [-1.0939e-01,  1.0506e-02,  2.1650e-01, -1.5287e-01,  9.2051e-02,\n          2.7804e-01, -2.9693e-01, -2.5017e-01],\n        [ 1.8965e-01, -2.0143e-02, -4.4533e-02,  3.5153e-01, -2.6911e-01,\n         -1.2161e-01,  1.5096e-01,  1.7137e-01],\n        [ 9.0495e-02,  8.3283e-03,  2.5349e-01,  1.8920e-01, -1.6721e-01,\n         -6.3889e-02, -2.7338e-01, -3.1363e-01],\n        [-9.1744e-02,  3.7115e-02,  1.3748e-01,  2.5547e-01,  6.7800e-02,\n          3.1727e-01,  3.5291e-01,  3.2513e-01],\n        [ 9.9263e-02,  4.9060e-02, -8.5267e-02, -2.5477e-01,  2.4653e-01,\n         -1.6312e-02,  2.0314e-01, -3.4313e-01],\n        [ 2.5194e-01, -3.4137e-01,  5.6209e-02, -6.8983e-02,  1.0763e-01,\n          2.4721e-01,  1.8858e-01,  3.0000e-01],\n        [ 1.7754e-01,  1.8447e-01,  2.1556e-02, -2.6258e-01, -7.6195e-02,\n          2.5877e-01, -1.3166e-01,  3.3009e-01],\n        [ 1.5531e-02, -1.7691e-01,  3.3624e-01, -2.5243e-01, -9.3977e-02,\n          3.4254e-01,  8.1204e-02,  2.1910e-01],\n        [-8.8257e-02, -1.7552e-01, -3.0781e-01, -3.4829e-01, -2.5023e-01,\n          2.3276e-01,  2.0422e-01, -1.5770e-01],\n        [ 3.3067e-01,  1.0857e-01,  1.7284e-01,  2.8509e-01,  1.6313e-03,\n          3.0911e-01,  2.1724e-01,  2.6332e-01],\n        [-1.1147e-01, -3.0717e-01,  1.6026e-01, -1.3484e-01, -1.6085e-01,\n          1.2837e-01, -2.4847e-01, -2.4020e-02],\n        [ 5.7458e-02, -1.3148e-01,  4.4394e-04, -2.0287e-01, -1.7191e-01,\n         -4.3372e-02, -3.3737e-01, -1.6567e-01],\n        [-2.6061e-01, -6.0876e-02,  3.2996e-01,  1.3029e-01,  3.0426e-01,\n          2.1610e-01,  1.0624e-01, -1.4355e-01],\n        [-3.4186e-01, -9.3250e-02,  3.3615e-01,  8.8060e-02, -3.2081e-01,\n         -2.4146e-01,  1.8731e-01, -2.6395e-01],\n        [ 2.5494e-01,  1.0091e-02, -2.3067e-01, -1.1730e-01, -3.4240e-01,\n         -5.3421e-02, -1.4865e-01, -4.5402e-02],\n        [-2.0886e-01,  2.3306e-01,  3.1191e-01, -2.7656e-01,  2.3908e-01,\n         -1.0453e-02, -3.3235e-01, -9.9886e-02],\n        [ 3.1460e-01,  2.8444e-01,  2.7301e-02,  1.1973e-01,  2.7087e-01,\n         -8.4323e-02,  2.7629e-01, -2.8156e-01],\n        [-1.6879e-01, -2.4264e-01, -1.3568e-02,  1.3262e-05,  1.5276e-03,\n          1.8065e-01, -8.1656e-02, -2.5163e-01],\n        [ 3.4121e-01,  1.2809e-01,  3.2739e-01,  1.7401e-01,  1.5342e-01,\n         -2.0362e-01, -5.1082e-02, -2.5475e-01],\n        [ 2.4101e-01,  1.3322e-01,  9.5051e-02, -2.1588e-01, -2.6800e-01,\n         -3.0939e-02,  1.7851e-01,  9.2306e-02],\n        [-1.4705e-01,  1.7677e-01, -1.1440e-01,  2.5305e-01,  3.6712e-02,\n         -3.5059e-01, -2.1089e-01, -2.0150e-02],\n        [-1.4415e-01,  3.2904e-01, -2.9506e-01, -2.6916e-01,  1.8316e-01,\n          2.2240e-01,  2.7944e-01,  2.6325e-01],\n        [ 1.1124e-01,  2.9712e-01, -2.3691e-01, -2.8842e-01, -2.0499e-01,\n          6.5770e-02, -6.8256e-02, -2.6033e-01],\n        [ 3.1226e-02,  6.4990e-02, -2.8759e-01,  4.5503e-02, -1.0842e-01,\n          1.8832e-01,  2.7080e-01,  5.8877e-02],\n        [ 3.3146e-01, -5.7453e-02,  7.8273e-02, -1.3341e-01,  1.4676e-01,\n          2.4926e-02, -2.8618e-01,  7.3333e-02],\n        [ 3.1403e-01, -3.0612e-01, -9.5489e-02,  3.2991e-01,  1.6994e-01,\n          2.0779e-01,  1.9040e-01,  6.1561e-02],\n        [ 3.1321e-02, -3.3110e-01,  3.5088e-01, -3.5092e-01,  1.1601e-01,\n          3.1271e-01,  1.2196e-01, -5.4607e-04],\n        [ 9.1361e-02, -2.7445e-01,  3.6966e-02,  1.6157e-01,  2.1126e-01,\n         -1.8047e-01,  1.4816e-01, -4.1949e-02],\n        [ 2.5865e-01, -1.3508e-01,  1.4072e-01,  2.7612e-01,  3.3242e-01,\n         -3.3199e-01, -3.5191e-01, -1.8293e-03]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0112, -0.0551,  0.1303, -0.1189, -0.0298,  0.0977,  0.0831, -0.1512,\n        -0.1208, -0.1313, -0.0133,  0.0910,  0.0542,  0.0054,  0.0466, -0.1242],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-7.3757e-02, -6.5902e-02,  1.1649e-01,  7.6333e-02, -7.7581e-02,\n          1.2668e-01,  1.0046e-01, -5.5680e-03,  1.3319e-01,  1.3081e-01,\n         -1.8946e-02,  1.1965e-01, -1.4310e-01,  2.9898e-03,  3.1402e-02,\n         -6.9060e-02, -3.1303e-02,  8.9815e-02, -5.5309e-02, -2.0386e-02,\n         -2.1333e-02,  1.7147e-01,  9.4509e-02, -1.6159e-01, -1.4612e-02,\n         -5.4722e-02,  9.4621e-02, -1.3847e-01,  1.9355e-02,  7.2757e-02,\n          1.2157e-01, -1.9300e-02],\n        [-1.5141e-01, -1.6582e-01, -1.5454e-02, -5.6325e-02, -2.1187e-02,\n         -4.7346e-02,  5.8252e-02, -1.5341e-01,  1.1383e-01, -2.3674e-02,\n         -1.6064e-01,  1.1571e-01, -1.1716e-01,  5.0877e-02,  1.6761e-01,\n         -1.2564e-01,  6.1240e-03, -1.2764e-01,  9.9762e-02,  3.9731e-02,\n          1.5931e-01,  3.7965e-02, -9.5263e-04, -5.2843e-02, -6.9987e-02,\n         -2.1772e-02,  1.5184e-01, -1.0982e-01,  1.6913e-01,  1.9049e-02,\n         -1.5252e-01, -1.9474e-02],\n        [-1.4091e-01,  1.3146e-01,  1.1247e-01, -1.4939e-01,  5.0916e-02,\n          2.0566e-02, -1.4119e-01,  8.4570e-02,  1.0229e-01,  9.6992e-02,\n          1.4748e-01, -1.7374e-01, -1.2662e-01, -1.1349e-01, -9.7217e-02,\n         -3.3263e-02,  1.5910e-01,  5.5578e-02,  4.4056e-02, -1.1196e-02,\n         -1.1313e-01,  8.4610e-04, -3.4034e-02, -1.1083e-01, -7.2244e-02,\n         -1.2491e-01, -1.5533e-01, -4.7973e-02,  1.1837e-01,  8.5495e-02,\n         -1.2678e-01, -9.6088e-02],\n        [ 7.3297e-02, -2.1531e-02, -8.0891e-02, -1.0867e-01,  3.2865e-02,\n          1.2959e-01, -1.3420e-02,  7.5244e-02, -1.3557e-01,  1.5591e-01,\n         -8.1637e-03, -1.5846e-01,  1.0706e-01, -1.6665e-01,  1.3803e-01,\n         -1.3207e-01, -4.1976e-02,  1.6306e-02,  7.3750e-02,  5.2304e-02,\n          5.9604e-02,  1.6445e-01,  4.0054e-02, -1.7508e-01,  2.7348e-02,\n          1.1574e-02,  4.5249e-02,  1.1359e-01,  7.5356e-02, -5.3726e-02,\n         -1.4044e-01,  1.2251e-01],\n        [ 1.1231e-01,  1.7031e-01,  9.7076e-02,  1.4617e-01,  8.6870e-02,\n          1.2793e-02, -1.2105e-01,  5.1519e-02, -1.6197e-01,  1.5545e-01,\n          1.7439e-01,  4.7199e-02,  1.5037e-01,  6.3787e-02, -9.1879e-02,\n         -8.2988e-02, -3.8470e-02,  5.0080e-02,  1.5898e-01,  1.6400e-01,\n          3.9731e-02,  3.1700e-02, -3.6084e-02, -7.6282e-02,  1.3146e-01,\n         -1.1213e-01,  4.0062e-02,  1.7379e-01,  9.9458e-02,  8.2124e-02,\n          1.0732e-01, -6.6158e-02],\n        [ 3.1243e-02, -4.0181e-03,  1.5418e-02,  1.6460e-01,  3.8374e-03,\n         -1.4359e-01, -1.6560e-01, -1.0538e-01,  5.9777e-02,  9.7268e-02,\n          7.4888e-02,  1.2826e-01,  1.3705e-01,  1.5121e-02,  9.0915e-02,\n         -2.4622e-02, -4.9602e-02, -5.0775e-02,  1.5884e-01,  6.8609e-03,\n         -1.4718e-01,  1.1907e-01,  1.3310e-01, -1.0108e-01,  9.0170e-03,\n         -9.0794e-03, -1.0433e-01, -1.1889e-01, -1.1232e-01, -4.6513e-02,\n          8.3353e-02, -1.5891e-01],\n        [-1.3250e-02,  1.2223e-01, -4.3834e-02,  8.2319e-02, -1.1811e-02,\n          1.7037e-01, -2.6630e-02,  4.6220e-02, -1.0128e-01,  7.6484e-02,\n         -1.4928e-02,  5.4196e-05,  2.4513e-03, -3.4072e-02, -6.5125e-02,\n         -3.0157e-02,  1.4614e-01, -1.5776e-01,  6.6363e-02, -7.2597e-03,\n         -1.0606e-01,  9.4195e-02, -6.9054e-02, -1.0943e-01, -3.1905e-02,\n         -1.2423e-01, -1.5220e-01,  9.6939e-02, -1.0029e-02,  8.2400e-02,\n         -1.4357e-01, -1.3801e-01],\n        [-7.5521e-02,  1.4217e-01,  1.0084e-01,  6.0657e-02,  8.5365e-02,\n          1.0695e-01, -6.0462e-02,  8.6307e-02, -8.8041e-02,  3.2340e-02,\n         -1.6759e-01,  7.3779e-02,  1.7424e-01,  3.8102e-02,  1.8901e-02,\n          1.0673e-01,  8.8191e-02,  8.4338e-02, -6.4249e-02,  5.4539e-02,\n         -1.1038e-01,  1.2968e-01,  1.5769e-01, -6.9126e-02,  5.0243e-02,\n         -5.6837e-02,  2.9922e-02,  1.4756e-01, -1.7218e-01,  6.8477e-02,\n         -1.3522e-01,  3.1567e-02],\n        [ 2.7784e-02, -3.9222e-02,  1.3685e-01,  1.6970e-01, -1.1247e-03,\n         -8.7561e-02,  1.7601e-02,  8.2929e-02, -1.0507e-01,  4.2703e-02,\n         -1.2628e-01,  1.6250e-01,  1.0109e-04, -1.7088e-01,  1.7086e-01,\n          6.8578e-02,  8.4370e-02,  2.3548e-02, -1.0416e-01,  6.4013e-02,\n          7.8199e-02, -1.0235e-01,  1.6295e-01, -1.2585e-01, -1.6604e-01,\n          8.1139e-02, -1.2438e-01,  1.0396e-01, -1.1928e-01, -4.2129e-02,\n          4.8567e-02, -1.6247e-02],\n        [ 4.5416e-02,  1.7162e-01,  6.6756e-02, -1.2514e-01,  1.5546e-01,\n         -1.2490e-01,  6.1610e-02, -5.2601e-02,  1.2266e-01, -1.7149e-01,\n          5.5067e-02,  7.7855e-02, -1.7480e-01, -1.2957e-01, -1.3090e-01,\n         -1.2393e-01, -5.7237e-02, -6.9418e-02,  4.4566e-02,  1.4580e-01,\n         -1.4330e-01, -2.1728e-02, -1.4202e-01, -1.7416e-01, -1.1240e-01,\n          3.3274e-02,  8.4740e-02, -9.7505e-02,  6.9990e-02, -5.9980e-03,\n         -8.1698e-02,  8.1354e-02],\n        [-1.6439e-01, -1.4134e-01, -1.1772e-01,  1.6947e-01, -6.1029e-02,\n         -1.5093e-01, -1.0282e-01, -4.8811e-02, -1.1123e-01,  1.4641e-01,\n          7.1390e-02, -9.3826e-02,  5.1789e-02, -2.1502e-02,  7.7822e-02,\n          1.1242e-01, -9.0153e-02,  1.0420e-01, -4.0607e-02, -3.9202e-02,\n          1.3696e-01,  1.4942e-01,  1.3801e-01, -9.7213e-02,  9.4837e-03,\n         -1.7582e-01, -7.0716e-03, -1.4767e-01,  1.3070e-01,  6.7504e-02,\n          1.2682e-01,  1.4977e-01],\n        [ 1.2424e-01, -1.3734e-01, -4.2254e-02, -1.1823e-01,  1.1010e-02,\n          9.7041e-02, -1.5536e-01,  7.5475e-02,  1.7244e-01,  2.8903e-03,\n          8.9528e-02, -1.3980e-01, -8.7343e-02,  1.4953e-01,  3.9019e-02,\n         -8.6001e-02, -1.6831e-01,  7.3700e-03, -6.8590e-02, -4.8188e-02,\n         -1.2490e-01,  7.4372e-02,  2.9339e-03, -1.3379e-01, -7.0271e-02,\n          5.0296e-02,  1.2823e-01,  1.2114e-01, -1.1830e-01,  6.5536e-02,\n         -4.9013e-02,  1.2322e-02],\n        [-4.6217e-02,  1.0672e-02,  7.4608e-02,  1.5365e-01,  1.5757e-01,\n         -1.0579e-01, -1.6720e-01,  4.7634e-02, -7.9894e-02,  6.9817e-02,\n          9.5818e-02, -1.5371e-01, -1.4422e-01, -9.6134e-02,  9.3735e-02,\n         -1.0316e-01,  2.9896e-02, -5.6944e-03, -4.9470e-02,  1.0508e-01,\n         -2.4007e-02,  1.5231e-01,  7.4851e-02, -9.3673e-02,  1.6255e-01,\n         -7.1979e-03, -6.7045e-02,  4.7729e-02,  1.7335e-01, -1.3949e-01,\n          1.5224e-01,  3.2408e-02],\n        [ 5.4558e-02,  8.6119e-02, -6.6171e-02,  3.6263e-02, -1.4014e-01,\n          7.6568e-03,  7.3707e-02,  1.4007e-01, -2.1189e-02, -6.6103e-02,\n         -1.7193e-01, -1.0471e-01,  1.7111e-01, -6.7718e-03, -3.3843e-02,\n         -1.4757e-01,  9.1290e-02,  9.3703e-02, -1.2742e-02, -2.9762e-02,\n         -1.4239e-01, -1.5798e-01,  1.3585e-01,  1.5986e-01, -3.0658e-02,\n          3.9677e-03, -1.2458e-01, -1.1173e-01, -8.8153e-02, -1.5048e-01,\n          4.9819e-02,  1.5799e-01],\n        [-1.1900e-01, -2.0180e-02, -5.9063e-02, -1.5749e-01, -1.6447e-01,\n          6.1860e-02,  1.1656e-02, -1.3057e-01,  2.6680e-02,  4.1963e-02,\n          1.7182e-01, -1.1328e-01, -2.3089e-03,  5.6022e-02,  3.5178e-02,\n          1.5876e-01,  1.5201e-01,  5.7261e-02, -1.0719e-02,  1.9443e-02,\n          1.3265e-01,  1.5730e-01, -5.1244e-02,  1.5735e-01, -1.1133e-01,\n         -1.2288e-01,  1.0563e-01, -2.8912e-02, -3.6951e-02,  7.3674e-02,\n          5.1710e-03, -1.5220e-01],\n        [ 1.7673e-01, -1.6845e-02, -5.1169e-02, -7.8652e-02,  6.7723e-02,\n          1.2108e-01,  9.9832e-02,  1.6947e-03,  1.5161e-01,  1.7493e-01,\n          1.6678e-02,  5.7662e-02, -2.8646e-02,  6.9237e-02,  1.5796e-01,\n          5.5019e-02,  7.7662e-02, -8.0997e-02,  3.0294e-02,  1.4688e-01,\n          1.4316e-01, -2.1464e-02, -6.6244e-03, -1.1915e-01,  5.7435e-02,\n         -1.7578e-01,  4.9756e-02,  1.4610e-01,  8.7228e-02,  8.1387e-02,\n         -3.7184e-02, -2.5484e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2493, -0.2108, -0.1021,  0.0848,  0.1748,  0.1329, -0.2316, -0.2290],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1903,  0.1654,  0.0857, -0.2329, -0.0046,  0.0135,  0.1563, -0.1318,\n          0.0330,  0.0305,  0.0447,  0.1354, -0.0385, -0.0748,  0.1029,  0.0899],\n        [ 0.1395,  0.2136,  0.1080, -0.1571, -0.1890, -0.1518,  0.1897,  0.1879,\n         -0.0550,  0.1484, -0.1975, -0.1340, -0.0040, -0.1667,  0.0541,  0.2317],\n        [ 0.1208,  0.1243, -0.1666,  0.1814,  0.2286, -0.0997,  0.2482, -0.0784,\n          0.1953, -0.1069, -0.2225, -0.1142,  0.0329,  0.1999,  0.1786, -0.0852],\n        [ 0.2238,  0.2037, -0.2093,  0.0743, -0.2364,  0.1225, -0.2197,  0.0337,\n         -0.1453, -0.2241, -0.1231, -0.1574, -0.0993, -0.1140,  0.0955, -0.1996],\n        [ 0.0883, -0.0186,  0.1187, -0.0271, -0.0562, -0.1412, -0.0739, -0.0209,\n          0.1740, -0.1361,  0.0076,  0.1295,  0.1334, -0.1608,  0.0679, -0.0673],\n        [ 0.1808,  0.2465, -0.0567, -0.1615, -0.2482,  0.1075,  0.0774, -0.2241,\n          0.1855, -0.0939, -0.1291,  0.0372, -0.0329, -0.1412,  0.1668, -0.1467],\n        [ 0.2460,  0.2061,  0.1722, -0.1549,  0.1649, -0.0845, -0.1103, -0.0627,\n          0.1015,  0.1789,  0.1532, -0.2204,  0.1988, -0.0338,  0.1689,  0.2388],\n        [ 0.1526,  0.0921,  0.1198,  0.1113,  0.2343, -0.0116,  0.0193,  0.1560,\n          0.0416,  0.2048,  0.0218, -0.1534,  0.1019, -0.0290,  0.1523,  0.2022]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1337], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3276, -0.0543,  0.3442, -0.0729, -0.1522, -0.1844,  0.1204,  0.1674]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-3.0912e-01, -1.8631e-01, -1.9196e-01, -9.9107e-02, -1.8951e-01,\n          3.4118e-01, -3.4058e-01, -2.1737e-01],\n        [ 3.1828e-01, -2.0632e-01,  3.0679e-01,  3.4181e-03,  3.5135e-01,\n          6.0770e-02,  3.4947e-01, -4.1461e-02],\n        [-1.4743e-01,  3.0875e-01, -1.9459e-01,  3.4533e-01, -1.0185e-01,\n         -2.4095e-01,  6.3633e-02,  2.1278e-01],\n        [-1.0939e-01,  1.0506e-02,  2.1650e-01, -1.5287e-01,  9.2051e-02,\n          2.7804e-01, -2.9693e-01, -2.5017e-01],\n        [ 1.8965e-01, -2.0143e-02, -4.4533e-02,  3.5153e-01, -2.6911e-01,\n         -1.2161e-01,  1.5096e-01,  1.7137e-01],\n        [ 9.0495e-02,  8.3283e-03,  2.5349e-01,  1.8920e-01, -1.6721e-01,\n         -6.3889e-02, -2.7338e-01, -3.1363e-01],\n        [-9.1744e-02,  3.7115e-02,  1.3748e-01,  2.5547e-01,  6.7800e-02,\n          3.1727e-01,  3.5291e-01,  3.2513e-01],\n        [ 9.9263e-02,  4.9060e-02, -8.5267e-02, -2.5477e-01,  2.4653e-01,\n         -1.6312e-02,  2.0314e-01, -3.4313e-01],\n        [ 2.5194e-01, -3.4137e-01,  5.6209e-02, -6.8983e-02,  1.0763e-01,\n          2.4721e-01,  1.8858e-01,  3.0000e-01],\n        [ 1.7754e-01,  1.8447e-01,  2.1556e-02, -2.6258e-01, -7.6195e-02,\n          2.5877e-01, -1.3166e-01,  3.3009e-01],\n        [ 1.5531e-02, -1.7691e-01,  3.3624e-01, -2.5243e-01, -9.3977e-02,\n          3.4254e-01,  8.1204e-02,  2.1910e-01],\n        [-8.8257e-02, -1.7552e-01, -3.0781e-01, -3.4829e-01, -2.5023e-01,\n          2.3276e-01,  2.0422e-01, -1.5770e-01],\n        [ 3.3067e-01,  1.0857e-01,  1.7284e-01,  2.8509e-01,  1.6313e-03,\n          3.0911e-01,  2.1724e-01,  2.6332e-01],\n        [-1.1147e-01, -3.0717e-01,  1.6026e-01, -1.3484e-01, -1.6085e-01,\n          1.2837e-01, -2.4847e-01, -2.4020e-02],\n        [ 5.7458e-02, -1.3148e-01,  4.4394e-04, -2.0287e-01, -1.7191e-01,\n         -4.3372e-02, -3.3737e-01, -1.6567e-01],\n        [-2.6061e-01, -6.0876e-02,  3.2996e-01,  1.3029e-01,  3.0426e-01,\n          2.1610e-01,  1.0624e-01, -1.4355e-01],\n        [-3.4186e-01, -9.3250e-02,  3.3615e-01,  8.8060e-02, -3.2081e-01,\n         -2.4146e-01,  1.8731e-01, -2.6395e-01],\n        [ 2.5494e-01,  1.0091e-02, -2.3067e-01, -1.1730e-01, -3.4240e-01,\n         -5.3421e-02, -1.4865e-01, -4.5402e-02],\n        [-2.0886e-01,  2.3306e-01,  3.1191e-01, -2.7656e-01,  2.3908e-01,\n         -1.0453e-02, -3.3235e-01, -9.9886e-02],\n        [ 3.1460e-01,  2.8444e-01,  2.7301e-02,  1.1973e-01,  2.7087e-01,\n         -8.4323e-02,  2.7629e-01, -2.8156e-01],\n        [-1.6879e-01, -2.4264e-01, -1.3568e-02,  1.3262e-05,  1.5276e-03,\n          1.8065e-01, -8.1656e-02, -2.5163e-01],\n        [ 3.4121e-01,  1.2809e-01,  3.2739e-01,  1.7401e-01,  1.5342e-01,\n         -2.0362e-01, -5.1082e-02, -2.5475e-01],\n        [ 2.4101e-01,  1.3322e-01,  9.5051e-02, -2.1588e-01, -2.6800e-01,\n         -3.0939e-02,  1.7851e-01,  9.2306e-02],\n        [-1.4705e-01,  1.7677e-01, -1.1440e-01,  2.5305e-01,  3.6712e-02,\n         -3.5059e-01, -2.1089e-01, -2.0150e-02],\n        [-1.4415e-01,  3.2904e-01, -2.9506e-01, -2.6916e-01,  1.8316e-01,\n          2.2240e-01,  2.7944e-01,  2.6325e-01],\n        [ 1.1124e-01,  2.9712e-01, -2.3691e-01, -2.8842e-01, -2.0499e-01,\n          6.5770e-02, -6.8256e-02, -2.6033e-01],\n        [ 3.1226e-02,  6.4990e-02, -2.8759e-01,  4.5503e-02, -1.0842e-01,\n          1.8832e-01,  2.7080e-01,  5.8877e-02],\n        [ 3.3146e-01, -5.7453e-02,  7.8273e-02, -1.3341e-01,  1.4676e-01,\n          2.4926e-02, -2.8618e-01,  7.3333e-02],\n        [ 3.1403e-01, -3.0612e-01, -9.5489e-02,  3.2991e-01,  1.6994e-01,\n          2.0779e-01,  1.9040e-01,  6.1561e-02],\n        [ 3.1321e-02, -3.3110e-01,  3.5088e-01, -3.5092e-01,  1.1601e-01,\n          3.1271e-01,  1.2196e-01, -5.4607e-04],\n        [ 9.1361e-02, -2.7445e-01,  3.6966e-02,  1.6157e-01,  2.1126e-01,\n         -1.8047e-01,  1.4816e-01, -4.1949e-02],\n        [ 2.5865e-01, -1.3508e-01,  1.4072e-01,  2.7612e-01,  3.3242e-01,\n         -3.3199e-01, -3.5191e-01, -1.8293e-03]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1983, -0.0115,  0.3485,  0.0614, -0.2709,  0.3021, -0.0904,  0.2905,\n        -0.2940,  0.0466,  0.2123,  0.0432, -0.3111, -0.3322,  0.0789,  0.1282,\n         0.1977,  0.2351,  0.3506,  0.2896, -0.2495, -0.2134,  0.1984,  0.1773,\n        -0.2720,  0.0186,  0.1288, -0.2600,  0.0235,  0.1695,  0.2897, -0.0345],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-7.3757e-02, -6.5902e-02,  1.1649e-01,  7.6333e-02, -7.7581e-02,\n          1.2668e-01,  1.0046e-01, -5.5680e-03,  1.3319e-01,  1.3081e-01,\n         -1.8946e-02,  1.1965e-01, -1.4310e-01,  2.9898e-03,  3.1402e-02,\n         -6.9060e-02, -3.1303e-02,  8.9815e-02, -5.5309e-02, -2.0386e-02,\n         -2.1333e-02,  1.7147e-01,  9.4509e-02, -1.6159e-01, -1.4612e-02,\n         -5.4722e-02,  9.4621e-02, -1.3847e-01,  1.9355e-02,  7.2757e-02,\n          1.2157e-01, -1.9300e-02],\n        [-1.5141e-01, -1.6582e-01, -1.5454e-02, -5.6325e-02, -2.1187e-02,\n         -4.7346e-02,  5.8252e-02, -1.5341e-01,  1.1383e-01, -2.3674e-02,\n         -1.6064e-01,  1.1571e-01, -1.1716e-01,  5.0877e-02,  1.6761e-01,\n         -1.2564e-01,  6.1240e-03, -1.2764e-01,  9.9762e-02,  3.9731e-02,\n          1.5931e-01,  3.7965e-02, -9.5263e-04, -5.2843e-02, -6.9987e-02,\n         -2.1772e-02,  1.5184e-01, -1.0982e-01,  1.6913e-01,  1.9049e-02,\n         -1.5252e-01, -1.9474e-02],\n        [-1.4091e-01,  1.3146e-01,  1.1247e-01, -1.4939e-01,  5.0916e-02,\n          2.0566e-02, -1.4119e-01,  8.4570e-02,  1.0229e-01,  9.6992e-02,\n          1.4748e-01, -1.7374e-01, -1.2662e-01, -1.1349e-01, -9.7217e-02,\n         -3.3263e-02,  1.5910e-01,  5.5578e-02,  4.4056e-02, -1.1196e-02,\n         -1.1313e-01,  8.4610e-04, -3.4034e-02, -1.1083e-01, -7.2244e-02,\n         -1.2491e-01, -1.5533e-01, -4.7973e-02,  1.1837e-01,  8.5495e-02,\n         -1.2678e-01, -9.6088e-02],\n        [ 7.3297e-02, -2.1531e-02, -8.0891e-02, -1.0867e-01,  3.2865e-02,\n          1.2959e-01, -1.3420e-02,  7.5244e-02, -1.3557e-01,  1.5591e-01,\n         -8.1637e-03, -1.5846e-01,  1.0706e-01, -1.6665e-01,  1.3803e-01,\n         -1.3207e-01, -4.1976e-02,  1.6306e-02,  7.3750e-02,  5.2304e-02,\n          5.9604e-02,  1.6445e-01,  4.0054e-02, -1.7508e-01,  2.7348e-02,\n          1.1574e-02,  4.5249e-02,  1.1359e-01,  7.5356e-02, -5.3726e-02,\n         -1.4044e-01,  1.2251e-01],\n        [ 1.1231e-01,  1.7031e-01,  9.7076e-02,  1.4617e-01,  8.6870e-02,\n          1.2793e-02, -1.2105e-01,  5.1519e-02, -1.6197e-01,  1.5545e-01,\n          1.7439e-01,  4.7199e-02,  1.5037e-01,  6.3787e-02, -9.1879e-02,\n         -8.2988e-02, -3.8470e-02,  5.0080e-02,  1.5898e-01,  1.6400e-01,\n          3.9731e-02,  3.1700e-02, -3.6084e-02, -7.6282e-02,  1.3146e-01,\n         -1.1213e-01,  4.0062e-02,  1.7379e-01,  9.9458e-02,  8.2124e-02,\n          1.0732e-01, -6.6158e-02],\n        [ 3.1243e-02, -4.0181e-03,  1.5418e-02,  1.6460e-01,  3.8374e-03,\n         -1.4359e-01, -1.6560e-01, -1.0538e-01,  5.9777e-02,  9.7268e-02,\n          7.4888e-02,  1.2826e-01,  1.3705e-01,  1.5121e-02,  9.0915e-02,\n         -2.4622e-02, -4.9602e-02, -5.0775e-02,  1.5884e-01,  6.8609e-03,\n         -1.4718e-01,  1.1907e-01,  1.3310e-01, -1.0108e-01,  9.0170e-03,\n         -9.0794e-03, -1.0433e-01, -1.1889e-01, -1.1232e-01, -4.6513e-02,\n          8.3353e-02, -1.5891e-01],\n        [-1.3250e-02,  1.2223e-01, -4.3834e-02,  8.2319e-02, -1.1811e-02,\n          1.7037e-01, -2.6630e-02,  4.6220e-02, -1.0128e-01,  7.6484e-02,\n         -1.4928e-02,  5.4196e-05,  2.4513e-03, -3.4072e-02, -6.5125e-02,\n         -3.0157e-02,  1.4614e-01, -1.5776e-01,  6.6363e-02, -7.2597e-03,\n         -1.0606e-01,  9.4195e-02, -6.9054e-02, -1.0943e-01, -3.1905e-02,\n         -1.2423e-01, -1.5220e-01,  9.6939e-02, -1.0029e-02,  8.2400e-02,\n         -1.4357e-01, -1.3801e-01],\n        [-7.5521e-02,  1.4217e-01,  1.0084e-01,  6.0657e-02,  8.5365e-02,\n          1.0695e-01, -6.0462e-02,  8.6307e-02, -8.8041e-02,  3.2340e-02,\n         -1.6759e-01,  7.3779e-02,  1.7424e-01,  3.8102e-02,  1.8901e-02,\n          1.0673e-01,  8.8191e-02,  8.4338e-02, -6.4249e-02,  5.4539e-02,\n         -1.1038e-01,  1.2968e-01,  1.5769e-01, -6.9126e-02,  5.0243e-02,\n         -5.6837e-02,  2.9922e-02,  1.4756e-01, -1.7218e-01,  6.8477e-02,\n         -1.3522e-01,  3.1567e-02],\n        [ 2.7784e-02, -3.9222e-02,  1.3685e-01,  1.6970e-01, -1.1247e-03,\n         -8.7561e-02,  1.7601e-02,  8.2929e-02, -1.0507e-01,  4.2703e-02,\n         -1.2628e-01,  1.6250e-01,  1.0109e-04, -1.7088e-01,  1.7086e-01,\n          6.8578e-02,  8.4370e-02,  2.3548e-02, -1.0416e-01,  6.4013e-02,\n          7.8199e-02, -1.0235e-01,  1.6295e-01, -1.2585e-01, -1.6604e-01,\n          8.1139e-02, -1.2438e-01,  1.0396e-01, -1.1928e-01, -4.2129e-02,\n          4.8567e-02, -1.6247e-02],\n        [ 4.5416e-02,  1.7162e-01,  6.6756e-02, -1.2514e-01,  1.5546e-01,\n         -1.2490e-01,  6.1610e-02, -5.2601e-02,  1.2266e-01, -1.7149e-01,\n          5.5067e-02,  7.7855e-02, -1.7480e-01, -1.2957e-01, -1.3090e-01,\n         -1.2393e-01, -5.7237e-02, -6.9418e-02,  4.4566e-02,  1.4580e-01,\n         -1.4330e-01, -2.1728e-02, -1.4202e-01, -1.7416e-01, -1.1240e-01,\n          3.3274e-02,  8.4740e-02, -9.7505e-02,  6.9990e-02, -5.9980e-03,\n         -8.1698e-02,  8.1354e-02],\n        [-1.6439e-01, -1.4134e-01, -1.1772e-01,  1.6947e-01, -6.1029e-02,\n         -1.5093e-01, -1.0282e-01, -4.8811e-02, -1.1123e-01,  1.4641e-01,\n          7.1390e-02, -9.3826e-02,  5.1789e-02, -2.1502e-02,  7.7822e-02,\n          1.1242e-01, -9.0153e-02,  1.0420e-01, -4.0607e-02, -3.9202e-02,\n          1.3696e-01,  1.4942e-01,  1.3801e-01, -9.7213e-02,  9.4837e-03,\n         -1.7582e-01, -7.0716e-03, -1.4767e-01,  1.3070e-01,  6.7504e-02,\n          1.2682e-01,  1.4977e-01],\n        [ 1.2424e-01, -1.3734e-01, -4.2254e-02, -1.1823e-01,  1.1010e-02,\n          9.7041e-02, -1.5536e-01,  7.5475e-02,  1.7244e-01,  2.8903e-03,\n          8.9528e-02, -1.3980e-01, -8.7343e-02,  1.4953e-01,  3.9019e-02,\n         -8.6001e-02, -1.6831e-01,  7.3700e-03, -6.8590e-02, -4.8188e-02,\n         -1.2490e-01,  7.4372e-02,  2.9339e-03, -1.3379e-01, -7.0271e-02,\n          5.0296e-02,  1.2823e-01,  1.2114e-01, -1.1830e-01,  6.5536e-02,\n         -4.9013e-02,  1.2322e-02],\n        [-4.6217e-02,  1.0672e-02,  7.4608e-02,  1.5365e-01,  1.5757e-01,\n         -1.0579e-01, -1.6720e-01,  4.7634e-02, -7.9894e-02,  6.9817e-02,\n          9.5818e-02, -1.5371e-01, -1.4422e-01, -9.6134e-02,  9.3735e-02,\n         -1.0316e-01,  2.9896e-02, -5.6944e-03, -4.9470e-02,  1.0508e-01,\n         -2.4007e-02,  1.5231e-01,  7.4851e-02, -9.3673e-02,  1.6255e-01,\n         -7.1979e-03, -6.7045e-02,  4.7729e-02,  1.7335e-01, -1.3949e-01,\n          1.5224e-01,  3.2408e-02],\n        [ 5.4558e-02,  8.6119e-02, -6.6171e-02,  3.6263e-02, -1.4014e-01,\n          7.6568e-03,  7.3707e-02,  1.4007e-01, -2.1189e-02, -6.6103e-02,\n         -1.7193e-01, -1.0471e-01,  1.7111e-01, -6.7718e-03, -3.3843e-02,\n         -1.4757e-01,  9.1290e-02,  9.3703e-02, -1.2742e-02, -2.9762e-02,\n         -1.4239e-01, -1.5798e-01,  1.3585e-01,  1.5986e-01, -3.0658e-02,\n          3.9677e-03, -1.2458e-01, -1.1173e-01, -8.8153e-02, -1.5048e-01,\n          4.9819e-02,  1.5799e-01],\n        [-1.1900e-01, -2.0180e-02, -5.9063e-02, -1.5749e-01, -1.6447e-01,\n          6.1860e-02,  1.1656e-02, -1.3057e-01,  2.6680e-02,  4.1963e-02,\n          1.7182e-01, -1.1328e-01, -2.3089e-03,  5.6022e-02,  3.5178e-02,\n          1.5876e-01,  1.5201e-01,  5.7261e-02, -1.0719e-02,  1.9443e-02,\n          1.3265e-01,  1.5730e-01, -5.1244e-02,  1.5735e-01, -1.1133e-01,\n         -1.2288e-01,  1.0563e-01, -2.8912e-02, -3.6951e-02,  7.3674e-02,\n          5.1710e-03, -1.5220e-01],\n        [ 1.7673e-01, -1.6845e-02, -5.1169e-02, -7.8652e-02,  6.7723e-02,\n          1.2108e-01,  9.9832e-02,  1.6947e-03,  1.5161e-01,  1.7493e-01,\n          1.6678e-02,  5.7662e-02, -2.8646e-02,  6.9237e-02,  1.5796e-01,\n          5.5019e-02,  7.7662e-02, -8.0997e-02,  3.0294e-02,  1.4688e-01,\n          1.4316e-01, -2.1464e-02, -6.6244e-03, -1.1915e-01,  5.7435e-02,\n         -1.7578e-01,  4.9756e-02,  1.4610e-01,  8.7228e-02,  8.1387e-02,\n         -3.7184e-02, -2.5484e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0112, -0.0551,  0.1303, -0.1189, -0.0298,  0.0977,  0.0831, -0.1512,\n        -0.1208, -0.1313, -0.0133,  0.0910,  0.0542,  0.0054,  0.0466, -0.1242],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1903,  0.1654,  0.0857, -0.2329, -0.0046,  0.0135,  0.1563, -0.1318,\n          0.0330,  0.0305,  0.0447,  0.1354, -0.0385, -0.0748,  0.1029,  0.0899],\n        [ 0.1395,  0.2136,  0.1080, -0.1571, -0.1890, -0.1518,  0.1897,  0.1879,\n         -0.0550,  0.1484, -0.1975, -0.1340, -0.0040, -0.1667,  0.0541,  0.2317],\n        [ 0.1208,  0.1243, -0.1666,  0.1814,  0.2286, -0.0997,  0.2482, -0.0784,\n          0.1953, -0.1069, -0.2225, -0.1142,  0.0329,  0.1999,  0.1786, -0.0852],\n        [ 0.2238,  0.2037, -0.2093,  0.0743, -0.2364,  0.1225, -0.2197,  0.0337,\n         -0.1453, -0.2241, -0.1231, -0.1574, -0.0993, -0.1140,  0.0955, -0.1996],\n        [ 0.0883, -0.0186,  0.1187, -0.0271, -0.0562, -0.1412, -0.0739, -0.0209,\n          0.1740, -0.1361,  0.0076,  0.1295,  0.1334, -0.1608,  0.0679, -0.0673],\n        [ 0.1808,  0.2465, -0.0567, -0.1615, -0.2482,  0.1075,  0.0774, -0.2241,\n          0.1855, -0.0939, -0.1291,  0.0372, -0.0329, -0.1412,  0.1668, -0.1467],\n        [ 0.2460,  0.2061,  0.1722, -0.1549,  0.1649, -0.0845, -0.1103, -0.0627,\n          0.1015,  0.1789,  0.1532, -0.2204,  0.1988, -0.0338,  0.1689,  0.2388],\n        [ 0.1526,  0.0921,  0.1198,  0.1113,  0.2343, -0.0116,  0.0193,  0.1560,\n          0.0416,  0.2048,  0.0218, -0.1534,  0.1019, -0.0290,  0.1523,  0.2022]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2493, -0.2108, -0.1021,  0.0848,  0.1748,  0.1329, -0.2316, -0.2290],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3276, -0.0543,  0.3442, -0.0729, -0.1522, -0.1844,  0.1204,  0.1674]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1337], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x0000014B619F62F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x0000014B2A08CC40>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s265600000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s265600000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1983, -0.0115,  0.3485,  0.0614, -0.2709,  0.3021, -0.0904,  0.2905,\n        -0.2940,  0.0466,  0.2123,  0.0432, -0.3111, -0.3322,  0.0789,  0.1282,\n         0.1977,  0.2351,  0.3506,  0.2896, -0.2495, -0.2134,  0.1984,  0.1773,\n        -0.2720,  0.0186,  0.1288, -0.2600,  0.0235,  0.1695,  0.2897, -0.0345],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.0912e-01, -1.8631e-01, -1.9196e-01, -9.9107e-02, -1.8951e-01,\n          3.4118e-01, -3.4058e-01, -2.1737e-01],\n        [ 3.1828e-01, -2.0632e-01,  3.0679e-01,  3.4181e-03,  3.5135e-01,\n          6.0770e-02,  3.4947e-01, -4.1461e-02],\n        [-1.4743e-01,  3.0875e-01, -1.9459e-01,  3.4533e-01, -1.0185e-01,\n         -2.4095e-01,  6.3633e-02,  2.1278e-01],\n        [-1.0939e-01,  1.0506e-02,  2.1650e-01, -1.5287e-01,  9.2051e-02,\n          2.7804e-01, -2.9693e-01, -2.5017e-01],\n        [ 1.8965e-01, -2.0143e-02, -4.4533e-02,  3.5153e-01, -2.6911e-01,\n         -1.2161e-01,  1.5096e-01,  1.7137e-01],\n        [ 9.0495e-02,  8.3283e-03,  2.5349e-01,  1.8920e-01, -1.6721e-01,\n         -6.3889e-02, -2.7338e-01, -3.1363e-01],\n        [-9.1744e-02,  3.7115e-02,  1.3748e-01,  2.5547e-01,  6.7800e-02,\n          3.1727e-01,  3.5291e-01,  3.2513e-01],\n        [ 9.9263e-02,  4.9060e-02, -8.5267e-02, -2.5477e-01,  2.4653e-01,\n         -1.6312e-02,  2.0314e-01, -3.4313e-01],\n        [ 2.5194e-01, -3.4137e-01,  5.6209e-02, -6.8983e-02,  1.0763e-01,\n          2.4721e-01,  1.8858e-01,  3.0000e-01],\n        [ 1.7754e-01,  1.8447e-01,  2.1556e-02, -2.6258e-01, -7.6195e-02,\n          2.5877e-01, -1.3166e-01,  3.3009e-01],\n        [ 1.5531e-02, -1.7691e-01,  3.3624e-01, -2.5243e-01, -9.3977e-02,\n          3.4254e-01,  8.1204e-02,  2.1910e-01],\n        [-8.8257e-02, -1.7552e-01, -3.0781e-01, -3.4829e-01, -2.5023e-01,\n          2.3276e-01,  2.0422e-01, -1.5770e-01],\n        [ 3.3067e-01,  1.0857e-01,  1.7284e-01,  2.8509e-01,  1.6313e-03,\n          3.0911e-01,  2.1724e-01,  2.6332e-01],\n        [-1.1147e-01, -3.0717e-01,  1.6026e-01, -1.3484e-01, -1.6085e-01,\n          1.2837e-01, -2.4847e-01, -2.4020e-02],\n        [ 5.7458e-02, -1.3148e-01,  4.4394e-04, -2.0287e-01, -1.7191e-01,\n         -4.3372e-02, -3.3737e-01, -1.6567e-01],\n        [-2.6061e-01, -6.0876e-02,  3.2996e-01,  1.3029e-01,  3.0426e-01,\n          2.1610e-01,  1.0624e-01, -1.4355e-01],\n        [-3.4186e-01, -9.3250e-02,  3.3615e-01,  8.8060e-02, -3.2081e-01,\n         -2.4146e-01,  1.8731e-01, -2.6395e-01],\n        [ 2.5494e-01,  1.0091e-02, -2.3067e-01, -1.1730e-01, -3.4240e-01,\n         -5.3421e-02, -1.4865e-01, -4.5402e-02],\n        [-2.0886e-01,  2.3306e-01,  3.1191e-01, -2.7656e-01,  2.3908e-01,\n         -1.0453e-02, -3.3235e-01, -9.9886e-02],\n        [ 3.1460e-01,  2.8444e-01,  2.7301e-02,  1.1973e-01,  2.7087e-01,\n         -8.4323e-02,  2.7629e-01, -2.8156e-01],\n        [-1.6879e-01, -2.4264e-01, -1.3568e-02,  1.3262e-05,  1.5276e-03,\n          1.8065e-01, -8.1656e-02, -2.5163e-01],\n        [ 3.4121e-01,  1.2809e-01,  3.2739e-01,  1.7401e-01,  1.5342e-01,\n         -2.0362e-01, -5.1082e-02, -2.5475e-01],\n        [ 2.4101e-01,  1.3322e-01,  9.5051e-02, -2.1588e-01, -2.6800e-01,\n         -3.0939e-02,  1.7851e-01,  9.2306e-02],\n        [-1.4705e-01,  1.7677e-01, -1.1440e-01,  2.5305e-01,  3.6712e-02,\n         -3.5059e-01, -2.1089e-01, -2.0150e-02],\n        [-1.4415e-01,  3.2904e-01, -2.9506e-01, -2.6916e-01,  1.8316e-01,\n          2.2240e-01,  2.7944e-01,  2.6325e-01],\n        [ 1.1124e-01,  2.9712e-01, -2.3691e-01, -2.8842e-01, -2.0499e-01,\n          6.5770e-02, -6.8256e-02, -2.6033e-01],\n        [ 3.1226e-02,  6.4990e-02, -2.8759e-01,  4.5503e-02, -1.0842e-01,\n          1.8832e-01,  2.7080e-01,  5.8877e-02],\n        [ 3.3146e-01, -5.7453e-02,  7.8273e-02, -1.3341e-01,  1.4676e-01,\n          2.4926e-02, -2.8618e-01,  7.3333e-02],\n        [ 3.1403e-01, -3.0612e-01, -9.5489e-02,  3.2991e-01,  1.6994e-01,\n          2.0779e-01,  1.9040e-01,  6.1561e-02],\n        [ 3.1321e-02, -3.3110e-01,  3.5088e-01, -3.5092e-01,  1.1601e-01,\n          3.1271e-01,  1.2196e-01, -5.4607e-04],\n        [ 9.1361e-02, -2.7445e-01,  3.6966e-02,  1.6157e-01,  2.1126e-01,\n         -1.8047e-01,  1.4816e-01, -4.1949e-02],\n        [ 2.5865e-01, -1.3508e-01,  1.4072e-01,  2.7612e-01,  3.3242e-01,\n         -3.3199e-01, -3.5191e-01, -1.8293e-03]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0112, -0.0551,  0.1303, -0.1189, -0.0298,  0.0977,  0.0831, -0.1512,\n        -0.1208, -0.1313, -0.0133,  0.0910,  0.0542,  0.0054,  0.0466, -0.1242],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-7.3757e-02, -6.5902e-02,  1.1649e-01,  7.6333e-02, -7.7581e-02,\n          1.2668e-01,  1.0046e-01, -5.5680e-03,  1.3319e-01,  1.3081e-01,\n         -1.8946e-02,  1.1965e-01, -1.4310e-01,  2.9898e-03,  3.1402e-02,\n         -6.9060e-02, -3.1303e-02,  8.9815e-02, -5.5309e-02, -2.0386e-02,\n         -2.1333e-02,  1.7147e-01,  9.4509e-02, -1.6159e-01, -1.4612e-02,\n         -5.4722e-02,  9.4621e-02, -1.3847e-01,  1.9355e-02,  7.2757e-02,\n          1.2157e-01, -1.9300e-02],\n        [-1.5141e-01, -1.6582e-01, -1.5454e-02, -5.6325e-02, -2.1187e-02,\n         -4.7346e-02,  5.8252e-02, -1.5341e-01,  1.1383e-01, -2.3674e-02,\n         -1.6064e-01,  1.1571e-01, -1.1716e-01,  5.0877e-02,  1.6761e-01,\n         -1.2564e-01,  6.1240e-03, -1.2764e-01,  9.9762e-02,  3.9731e-02,\n          1.5931e-01,  3.7965e-02, -9.5263e-04, -5.2843e-02, -6.9987e-02,\n         -2.1772e-02,  1.5184e-01, -1.0982e-01,  1.6913e-01,  1.9049e-02,\n         -1.5252e-01, -1.9474e-02],\n        [-1.4091e-01,  1.3146e-01,  1.1247e-01, -1.4939e-01,  5.0916e-02,\n          2.0566e-02, -1.4119e-01,  8.4570e-02,  1.0229e-01,  9.6992e-02,\n          1.4748e-01, -1.7374e-01, -1.2662e-01, -1.1349e-01, -9.7217e-02,\n         -3.3263e-02,  1.5910e-01,  5.5578e-02,  4.4056e-02, -1.1196e-02,\n         -1.1313e-01,  8.4610e-04, -3.4034e-02, -1.1083e-01, -7.2244e-02,\n         -1.2491e-01, -1.5533e-01, -4.7973e-02,  1.1837e-01,  8.5495e-02,\n         -1.2678e-01, -9.6088e-02],\n        [ 7.3297e-02, -2.1531e-02, -8.0891e-02, -1.0867e-01,  3.2865e-02,\n          1.2959e-01, -1.3420e-02,  7.5244e-02, -1.3557e-01,  1.5591e-01,\n         -8.1637e-03, -1.5846e-01,  1.0706e-01, -1.6665e-01,  1.3803e-01,\n         -1.3207e-01, -4.1976e-02,  1.6306e-02,  7.3750e-02,  5.2304e-02,\n          5.9604e-02,  1.6445e-01,  4.0054e-02, -1.7508e-01,  2.7348e-02,\n          1.1574e-02,  4.5249e-02,  1.1359e-01,  7.5356e-02, -5.3726e-02,\n         -1.4044e-01,  1.2251e-01],\n        [ 1.1231e-01,  1.7031e-01,  9.7076e-02,  1.4617e-01,  8.6870e-02,\n          1.2793e-02, -1.2105e-01,  5.1519e-02, -1.6197e-01,  1.5545e-01,\n          1.7439e-01,  4.7199e-02,  1.5037e-01,  6.3787e-02, -9.1879e-02,\n         -8.2988e-02, -3.8470e-02,  5.0080e-02,  1.5898e-01,  1.6400e-01,\n          3.9731e-02,  3.1700e-02, -3.6084e-02, -7.6282e-02,  1.3146e-01,\n         -1.1213e-01,  4.0062e-02,  1.7379e-01,  9.9458e-02,  8.2124e-02,\n          1.0732e-01, -6.6158e-02],\n        [ 3.1243e-02, -4.0181e-03,  1.5418e-02,  1.6460e-01,  3.8374e-03,\n         -1.4359e-01, -1.6560e-01, -1.0538e-01,  5.9777e-02,  9.7268e-02,\n          7.4888e-02,  1.2826e-01,  1.3705e-01,  1.5121e-02,  9.0915e-02,\n         -2.4622e-02, -4.9602e-02, -5.0775e-02,  1.5884e-01,  6.8609e-03,\n         -1.4718e-01,  1.1907e-01,  1.3310e-01, -1.0108e-01,  9.0170e-03,\n         -9.0794e-03, -1.0433e-01, -1.1889e-01, -1.1232e-01, -4.6513e-02,\n          8.3353e-02, -1.5891e-01],\n        [-1.3250e-02,  1.2223e-01, -4.3834e-02,  8.2319e-02, -1.1811e-02,\n          1.7037e-01, -2.6630e-02,  4.6220e-02, -1.0128e-01,  7.6484e-02,\n         -1.4928e-02,  5.4196e-05,  2.4513e-03, -3.4072e-02, -6.5125e-02,\n         -3.0157e-02,  1.4614e-01, -1.5776e-01,  6.6363e-02, -7.2597e-03,\n         -1.0606e-01,  9.4195e-02, -6.9054e-02, -1.0943e-01, -3.1905e-02,\n         -1.2423e-01, -1.5220e-01,  9.6939e-02, -1.0029e-02,  8.2400e-02,\n         -1.4357e-01, -1.3801e-01],\n        [-7.5521e-02,  1.4217e-01,  1.0084e-01,  6.0657e-02,  8.5365e-02,\n          1.0695e-01, -6.0462e-02,  8.6307e-02, -8.8041e-02,  3.2340e-02,\n         -1.6759e-01,  7.3779e-02,  1.7424e-01,  3.8102e-02,  1.8901e-02,\n          1.0673e-01,  8.8191e-02,  8.4338e-02, -6.4249e-02,  5.4539e-02,\n         -1.1038e-01,  1.2968e-01,  1.5769e-01, -6.9126e-02,  5.0243e-02,\n         -5.6837e-02,  2.9922e-02,  1.4756e-01, -1.7218e-01,  6.8477e-02,\n         -1.3522e-01,  3.1567e-02],\n        [ 2.7784e-02, -3.9222e-02,  1.3685e-01,  1.6970e-01, -1.1247e-03,\n         -8.7561e-02,  1.7601e-02,  8.2929e-02, -1.0507e-01,  4.2703e-02,\n         -1.2628e-01,  1.6250e-01,  1.0109e-04, -1.7088e-01,  1.7086e-01,\n          6.8578e-02,  8.4370e-02,  2.3548e-02, -1.0416e-01,  6.4013e-02,\n          7.8199e-02, -1.0235e-01,  1.6295e-01, -1.2585e-01, -1.6604e-01,\n          8.1139e-02, -1.2438e-01,  1.0396e-01, -1.1928e-01, -4.2129e-02,\n          4.8567e-02, -1.6247e-02],\n        [ 4.5416e-02,  1.7162e-01,  6.6756e-02, -1.2514e-01,  1.5546e-01,\n         -1.2490e-01,  6.1610e-02, -5.2601e-02,  1.2266e-01, -1.7149e-01,\n          5.5067e-02,  7.7855e-02, -1.7480e-01, -1.2957e-01, -1.3090e-01,\n         -1.2393e-01, -5.7237e-02, -6.9418e-02,  4.4566e-02,  1.4580e-01,\n         -1.4330e-01, -2.1728e-02, -1.4202e-01, -1.7416e-01, -1.1240e-01,\n          3.3274e-02,  8.4740e-02, -9.7505e-02,  6.9990e-02, -5.9980e-03,\n         -8.1698e-02,  8.1354e-02],\n        [-1.6439e-01, -1.4134e-01, -1.1772e-01,  1.6947e-01, -6.1029e-02,\n         -1.5093e-01, -1.0282e-01, -4.8811e-02, -1.1123e-01,  1.4641e-01,\n          7.1390e-02, -9.3826e-02,  5.1789e-02, -2.1502e-02,  7.7822e-02,\n          1.1242e-01, -9.0153e-02,  1.0420e-01, -4.0607e-02, -3.9202e-02,\n          1.3696e-01,  1.4942e-01,  1.3801e-01, -9.7213e-02,  9.4837e-03,\n         -1.7582e-01, -7.0716e-03, -1.4767e-01,  1.3070e-01,  6.7504e-02,\n          1.2682e-01,  1.4977e-01],\n        [ 1.2424e-01, -1.3734e-01, -4.2254e-02, -1.1823e-01,  1.1010e-02,\n          9.7041e-02, -1.5536e-01,  7.5475e-02,  1.7244e-01,  2.8903e-03,\n          8.9528e-02, -1.3980e-01, -8.7343e-02,  1.4953e-01,  3.9019e-02,\n         -8.6001e-02, -1.6831e-01,  7.3700e-03, -6.8590e-02, -4.8188e-02,\n         -1.2490e-01,  7.4372e-02,  2.9339e-03, -1.3379e-01, -7.0271e-02,\n          5.0296e-02,  1.2823e-01,  1.2114e-01, -1.1830e-01,  6.5536e-02,\n         -4.9013e-02,  1.2322e-02],\n        [-4.6217e-02,  1.0672e-02,  7.4608e-02,  1.5365e-01,  1.5757e-01,\n         -1.0579e-01, -1.6720e-01,  4.7634e-02, -7.9894e-02,  6.9817e-02,\n          9.5818e-02, -1.5371e-01, -1.4422e-01, -9.6134e-02,  9.3735e-02,\n         -1.0316e-01,  2.9896e-02, -5.6944e-03, -4.9470e-02,  1.0508e-01,\n         -2.4007e-02,  1.5231e-01,  7.4851e-02, -9.3673e-02,  1.6255e-01,\n         -7.1979e-03, -6.7045e-02,  4.7729e-02,  1.7335e-01, -1.3949e-01,\n          1.5224e-01,  3.2408e-02],\n        [ 5.4558e-02,  8.6119e-02, -6.6171e-02,  3.6263e-02, -1.4014e-01,\n          7.6568e-03,  7.3707e-02,  1.4007e-01, -2.1189e-02, -6.6103e-02,\n         -1.7193e-01, -1.0471e-01,  1.7111e-01, -6.7718e-03, -3.3843e-02,\n         -1.4757e-01,  9.1290e-02,  9.3703e-02, -1.2742e-02, -2.9762e-02,\n         -1.4239e-01, -1.5798e-01,  1.3585e-01,  1.5986e-01, -3.0658e-02,\n          3.9677e-03, -1.2458e-01, -1.1173e-01, -8.8153e-02, -1.5048e-01,\n          4.9819e-02,  1.5799e-01],\n        [-1.1900e-01, -2.0180e-02, -5.9063e-02, -1.5749e-01, -1.6447e-01,\n          6.1860e-02,  1.1656e-02, -1.3057e-01,  2.6680e-02,  4.1963e-02,\n          1.7182e-01, -1.1328e-01, -2.3089e-03,  5.6022e-02,  3.5178e-02,\n          1.5876e-01,  1.5201e-01,  5.7261e-02, -1.0719e-02,  1.9443e-02,\n          1.3265e-01,  1.5730e-01, -5.1244e-02,  1.5735e-01, -1.1133e-01,\n         -1.2288e-01,  1.0563e-01, -2.8912e-02, -3.6951e-02,  7.3674e-02,\n          5.1710e-03, -1.5220e-01],\n        [ 1.7673e-01, -1.6845e-02, -5.1169e-02, -7.8652e-02,  6.7723e-02,\n          1.2108e-01,  9.9832e-02,  1.6947e-03,  1.5161e-01,  1.7493e-01,\n          1.6678e-02,  5.7662e-02, -2.8646e-02,  6.9237e-02,  1.5796e-01,\n          5.5019e-02,  7.7662e-02, -8.0997e-02,  3.0294e-02,  1.4688e-01,\n          1.4316e-01, -2.1464e-02, -6.6244e-03, -1.1915e-01,  5.7435e-02,\n         -1.7578e-01,  4.9756e-02,  1.4610e-01,  8.7228e-02,  8.1387e-02,\n         -3.7184e-02, -2.5484e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2493, -0.2108, -0.1021,  0.0848,  0.1748,  0.1329, -0.2316, -0.2290],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1903,  0.1654,  0.0857, -0.2329, -0.0046,  0.0135,  0.1563, -0.1318,\n          0.0330,  0.0305,  0.0447,  0.1354, -0.0385, -0.0748,  0.1029,  0.0899],\n        [ 0.1395,  0.2136,  0.1080, -0.1571, -0.1890, -0.1518,  0.1897,  0.1879,\n         -0.0550,  0.1484, -0.1975, -0.1340, -0.0040, -0.1667,  0.0541,  0.2317],\n        [ 0.1208,  0.1243, -0.1666,  0.1814,  0.2286, -0.0997,  0.2482, -0.0784,\n          0.1953, -0.1069, -0.2225, -0.1142,  0.0329,  0.1999,  0.1786, -0.0852],\n        [ 0.2238,  0.2037, -0.2093,  0.0743, -0.2364,  0.1225, -0.2197,  0.0337,\n         -0.1453, -0.2241, -0.1231, -0.1574, -0.0993, -0.1140,  0.0955, -0.1996],\n        [ 0.0883, -0.0186,  0.1187, -0.0271, -0.0562, -0.1412, -0.0739, -0.0209,\n          0.1740, -0.1361,  0.0076,  0.1295,  0.1334, -0.1608,  0.0679, -0.0673],\n        [ 0.1808,  0.2465, -0.0567, -0.1615, -0.2482,  0.1075,  0.0774, -0.2241,\n          0.1855, -0.0939, -0.1291,  0.0372, -0.0329, -0.1412,  0.1668, -0.1467],\n        [ 0.2460,  0.2061,  0.1722, -0.1549,  0.1649, -0.0845, -0.1103, -0.0627,\n          0.1015,  0.1789,  0.1532, -0.2204,  0.1988, -0.0338,  0.1689,  0.2388],\n        [ 0.1526,  0.0921,  0.1198,  0.1113,  0.2343, -0.0116,  0.0193,  0.1560,\n          0.0416,  0.2048,  0.0218, -0.1534,  0.1019, -0.0290,  0.1523,  0.2022]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1337], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3276, -0.0543,  0.3442, -0.0729, -0.1522, -0.1844,  0.1204,  0.1674]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}