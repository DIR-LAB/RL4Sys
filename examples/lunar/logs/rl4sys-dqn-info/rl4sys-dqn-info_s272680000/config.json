{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s272680000"
    },
    "q_lr":	0.0005,
    "seed":	272680000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x00000273EAFE90F0>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2901,  0.2061,  0.1156, -0.0568, -0.0243,  0.1186,  0.1977, -0.3290,\n         0.1925,  0.3354, -0.2772,  0.0881, -0.2506, -0.1420,  0.0740,  0.0222,\n        -0.2626,  0.1501,  0.2995,  0.0118,  0.2668,  0.1458, -0.0395, -0.1644,\n         0.0986,  0.3395,  0.1284,  0.0064,  0.0268,  0.3213, -0.2493,  0.3334],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1356,  0.0875, -0.2609,  0.3158, -0.3322, -0.3490, -0.3405,  0.2025],\n        [ 0.0019,  0.2862, -0.1549, -0.3469,  0.0349,  0.0777, -0.1173, -0.1131],\n        [ 0.3107,  0.2083,  0.2641,  0.0458, -0.1518,  0.1315,  0.1353,  0.3414],\n        [-0.3451, -0.2776,  0.2499, -0.1658, -0.1276, -0.2065, -0.0598, -0.0788],\n        [-0.2996, -0.0353,  0.3037,  0.1225,  0.3206,  0.2349,  0.1088, -0.3236],\n        [-0.0185,  0.3440,  0.2520, -0.1024, -0.1597,  0.0423,  0.1439,  0.1071],\n        [-0.2680, -0.2670,  0.2421, -0.2185, -0.1234, -0.0819, -0.3353,  0.0943],\n        [-0.0738,  0.1447,  0.2370, -0.3106, -0.0338,  0.0435, -0.1535, -0.2869],\n        [ 0.0294,  0.0254, -0.2106,  0.0101,  0.3479,  0.1553, -0.2281,  0.1149],\n        [ 0.3212, -0.0642,  0.1506,  0.1883, -0.0144, -0.3483, -0.1054, -0.2207],\n        [ 0.1078, -0.0453, -0.3261, -0.0316,  0.0465,  0.1790, -0.1835, -0.2811],\n        [ 0.2743,  0.2148,  0.0378, -0.1975,  0.3129,  0.2141,  0.1100, -0.1466],\n        [-0.0546,  0.1656,  0.1416, -0.3516,  0.1720, -0.3425, -0.2712,  0.0266],\n        [-0.1389, -0.1072, -0.1111,  0.2030,  0.2455,  0.2160,  0.0191, -0.1626],\n        [-0.1816, -0.1110, -0.1729,  0.2491,  0.3286,  0.1906, -0.1885, -0.2122],\n        [-0.1660,  0.1147,  0.0459, -0.0623,  0.2888,  0.3340, -0.2222, -0.3216],\n        [ 0.2390,  0.2920,  0.2400, -0.1193, -0.1883, -0.2058,  0.2911, -0.1565],\n        [-0.1692, -0.1138, -0.1590, -0.2489,  0.1211, -0.3201,  0.1559,  0.3399],\n        [ 0.2447,  0.1842, -0.2576,  0.0288, -0.0932,  0.2970,  0.0997, -0.2766],\n        [-0.2158,  0.0928, -0.0582, -0.1415,  0.2752,  0.0659, -0.2493,  0.2596],\n        [-0.1807,  0.0707,  0.1861, -0.1575,  0.2924, -0.3377, -0.1993,  0.0492],\n        [-0.1729, -0.2412, -0.0781, -0.1024, -0.1467, -0.3311,  0.2311, -0.3393],\n        [ 0.2838,  0.0035, -0.1016,  0.2715, -0.3213, -0.1226,  0.1689, -0.0318],\n        [-0.2842,  0.1606,  0.3235,  0.0823, -0.3221, -0.0077, -0.3420,  0.0585],\n        [-0.2078, -0.2863, -0.3400,  0.2827, -0.1004,  0.3172, -0.1702,  0.2601],\n        [ 0.1755,  0.2312, -0.2165,  0.2500, -0.0389, -0.3252,  0.1778,  0.1525],\n        [ 0.1902,  0.2969,  0.2683,  0.0466, -0.0488,  0.0596, -0.2458, -0.3362],\n        [-0.1530,  0.1330, -0.0185, -0.3533, -0.1804,  0.1999,  0.2999,  0.2873],\n        [-0.1077,  0.0762, -0.3209, -0.0294, -0.2960,  0.1919,  0.1544,  0.0187],\n        [ 0.1594, -0.1639,  0.0225, -0.0110, -0.1368, -0.0937, -0.1382,  0.1703],\n        [-0.0547, -0.0774,  0.0337,  0.3165, -0.0028, -0.1095,  0.3293, -0.0779],\n        [ 0.1968,  0.2051, -0.1985,  0.0593, -0.2210, -0.3346, -0.1792, -0.0478]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1751, -0.0059,  0.1143, -0.1371, -0.0497,  0.1720, -0.1576, -0.0678,\n         0.1453,  0.0756, -0.0350, -0.0955,  0.0999,  0.1344, -0.1643,  0.0651],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.3784e-01, -1.7154e-01,  1.0039e-01, -8.0771e-03,  1.4304e-01,\n          1.8698e-02, -1.7361e-01,  1.4898e-01, -1.6954e-01,  8.2307e-02,\n          1.3777e-01, -2.5238e-02,  1.1322e-01, -6.8836e-02, -1.6838e-01,\n          7.9003e-02, -1.4030e-01,  1.2071e-01, -3.0743e-02, -7.5288e-02,\n          1.7220e-02,  1.1180e-02,  3.1821e-02,  1.5038e-01, -5.7561e-02,\n          1.6606e-01, -1.6256e-01,  1.2895e-01, -9.1751e-02, -6.3039e-02,\n          7.9700e-02,  8.0342e-02],\n        [ 1.3661e-01,  7.4238e-02, -8.0432e-02,  5.0933e-03,  1.3915e-01,\n         -4.8504e-03,  1.7295e-01, -7.1410e-02,  1.2773e-01,  2.0114e-02,\n          7.1062e-02, -6.0457e-02,  1.6814e-02, -1.6288e-01,  3.4511e-02,\n         -1.6792e-01, -1.4853e-01, -1.3924e-04, -1.5381e-01,  1.7352e-01,\n          2.6260e-02, -1.5131e-01, -3.8941e-02,  1.1013e-01, -1.1338e-01,\n          2.8530e-02, -2.8445e-03,  2.4356e-03,  1.6281e-01, -1.7275e-01,\n          3.2869e-02, -1.6531e-01],\n        [-7.6679e-02,  9.2444e-02,  9.2057e-02, -6.7570e-03, -1.3253e-01,\n         -1.1405e-01,  4.3498e-02,  1.3949e-02, -1.7331e-01, -1.6777e-01,\n          1.1741e-01, -3.4132e-02, -1.7664e-01,  1.0484e-01, -6.5528e-04,\n         -5.1152e-02,  2.4950e-02, -7.4969e-02, -8.8085e-02, -2.9469e-02,\n          3.6786e-02,  6.6523e-02, -1.2101e-01,  5.4897e-02, -1.4106e-01,\n         -1.2074e-01,  5.1308e-04,  1.5163e-01, -4.6436e-02,  1.3997e-01,\n         -6.6007e-02, -1.8909e-02],\n        [-1.6068e-03,  5.6904e-02,  1.7533e-01, -1.6372e-01,  6.4052e-02,\n          8.2446e-02,  2.4138e-02, -1.3753e-01, -1.8234e-02,  1.2506e-01,\n         -7.2545e-02, -1.7502e-03, -1.7339e-01,  1.3342e-01,  1.4640e-01,\n         -1.0477e-01,  6.1456e-02,  5.6652e-02, -9.8305e-02, -1.3525e-01,\n         -4.1549e-02,  1.1854e-01,  5.8859e-02, -1.7111e-01,  1.2077e-01,\n          1.7002e-01,  6.9561e-02, -1.3268e-01,  1.2423e-02, -3.7100e-02,\n         -9.3873e-02,  4.1188e-02],\n        [-1.0148e-01, -8.3292e-02,  9.1507e-03,  7.3176e-02,  1.5424e-01,\n          1.5926e-01, -3.5568e-02,  1.0626e-01,  1.6133e-01,  3.7886e-02,\n         -6.7015e-02, -9.7058e-03,  1.2586e-01,  1.5370e-01,  1.1751e-01,\n          1.2848e-01, -9.0028e-02,  7.4156e-02,  8.3668e-02, -1.2863e-01,\n          6.2099e-02, -1.6445e-01, -4.9537e-02, -1.6263e-01, -1.1579e-01,\n         -3.5029e-02,  1.4073e-01, -9.3621e-02,  1.7368e-01,  1.9296e-02,\n         -5.7421e-02, -6.4704e-02],\n        [-8.2260e-02, -8.8003e-02, -6.7718e-02,  9.6219e-02, -1.7141e-01,\n          7.4347e-02, -1.3049e-01,  1.2250e-01,  1.3942e-01,  1.5098e-01,\n         -1.2341e-01,  1.5565e-01,  7.3051e-02, -8.5163e-02,  1.1305e-01,\n          9.4451e-03, -6.0362e-03, -1.4023e-01,  8.7026e-02, -1.3196e-01,\n          2.6377e-02, -1.0252e-01,  4.6835e-03, -1.2414e-01, -1.0019e-01,\n         -1.4310e-01, -1.5483e-01,  3.5526e-02,  1.2824e-02,  1.4745e-01,\n         -6.6311e-02,  5.7201e-03],\n        [ 1.4835e-02, -1.7338e-01, -7.1283e-02, -4.6264e-02, -1.3818e-01,\n          8.5163e-02, -8.7648e-02, -2.8719e-02,  1.2350e-01, -1.5052e-01,\n         -1.3421e-01, -1.7655e-02, -1.1182e-01, -2.8689e-02,  7.1235e-02,\n         -6.2117e-03,  1.4336e-01, -5.7337e-02,  1.0798e-01,  6.9428e-02,\n         -1.3338e-01, -1.6413e-01, -1.3869e-01,  1.2194e-01,  1.4780e-01,\n         -1.5974e-01, -1.4759e-01, -5.4724e-02, -1.3439e-01,  1.2465e-02,\n          1.1692e-01,  8.2529e-02],\n        [-1.0914e-01, -9.4251e-02,  9.1841e-02,  1.3075e-01,  1.1498e-01,\n         -3.6688e-02, -7.5762e-02,  1.3286e-01, -1.2326e-01, -1.4449e-01,\n         -1.5651e-01,  1.1662e-01,  6.1991e-02, -4.7253e-02,  1.4979e-02,\n          1.3875e-01, -2.3761e-02,  1.1325e-01,  8.6495e-04,  6.2813e-03,\n          1.1760e-02, -1.0505e-01, -6.1283e-02,  2.7062e-02, -1.2139e-01,\n         -6.5090e-02,  7.0916e-02, -5.3189e-02, -5.1980e-02, -1.1137e-01,\n         -4.2549e-02,  7.3070e-02],\n        [ 1.1369e-01, -1.1953e-01,  5.5972e-03, -1.2626e-02,  1.1909e-01,\n          1.4558e-01, -3.3010e-02, -1.2018e-01,  1.1326e-01, -3.5286e-02,\n          8.7275e-02,  3.3407e-02,  4.9571e-02, -3.9027e-02,  1.5670e-01,\n          1.0809e-01,  6.0457e-02, -2.8831e-02,  4.6106e-02,  1.0253e-01,\n         -7.3818e-02,  1.3360e-01,  3.6750e-02,  1.6515e-01,  1.1837e-01,\n         -1.3634e-01,  1.4498e-01, -1.2650e-02,  1.4992e-01,  1.2502e-01,\n         -1.2976e-01, -5.8683e-02],\n        [ 9.6422e-02, -5.1860e-03, -1.5808e-01,  1.3246e-01,  5.0929e-02,\n         -5.9943e-03,  1.3350e-01,  1.7269e-01, -1.7052e-01,  1.7210e-01,\n         -8.9064e-02,  1.1294e-01,  1.5892e-01,  1.1702e-01, -4.8800e-02,\n          7.6519e-02, -3.7790e-02, -4.6435e-02,  5.9785e-03,  4.5953e-02,\n          1.5478e-01,  7.2528e-02,  6.8529e-02, -1.7020e-02,  4.3851e-02,\n         -1.0115e-01, -1.1470e-01, -1.5650e-01,  1.1302e-01, -1.5661e-01,\n          9.3381e-02,  7.4390e-02],\n        [ 6.3495e-02, -2.2385e-02, -1.5401e-01,  2.1545e-02,  9.9280e-02,\n          8.0913e-02, -6.7013e-02,  4.7190e-02,  8.9619e-02, -1.6186e-01,\n         -8.1814e-02,  6.8135e-02, -5.1815e-02, -1.1725e-01, -1.6583e-01,\n          1.4623e-01, -1.2372e-01, -1.4370e-01,  1.1300e-01, -1.5592e-02,\n          5.8136e-02, -3.7327e-02, -9.0058e-02, -8.5840e-02, -8.6237e-03,\n         -2.3552e-02,  6.3559e-02,  1.0075e-01,  4.7190e-02, -9.9373e-02,\n          8.1579e-02, -5.0865e-02],\n        [-1.0516e-01,  1.0011e-01,  1.4773e-02, -1.3985e-01, -1.7343e-01,\n          7.8632e-02,  1.5170e-01,  8.0835e-02, -1.3082e-02, -1.2047e-01,\n          1.4371e-01, -4.9680e-02,  1.6041e-01, -9.1419e-02, -1.4485e-01,\n          4.6720e-02, -3.4674e-02,  1.5940e-02,  1.8602e-02, -9.5281e-02,\n          1.1100e-01,  8.7359e-02,  1.2137e-01,  4.6863e-02,  5.0365e-02,\n         -1.3326e-01, -1.0342e-01,  1.6336e-01, -1.7575e-01, -9.9788e-02,\n          1.0313e-01, -3.4709e-02],\n        [ 1.6244e-01,  2.1093e-02,  1.2534e-01, -1.8387e-02, -2.8509e-02,\n         -1.6118e-01, -1.4987e-01, -2.9802e-02,  1.0388e-01, -1.5272e-03,\n         -1.2888e-01,  1.3016e-01, -4.1309e-02,  9.4363e-02,  5.5770e-02,\n         -7.2297e-02,  4.4498e-02, -1.1673e-01,  1.5873e-01,  1.3175e-01,\n         -1.3642e-01,  1.5421e-01,  2.5177e-02, -4.4114e-02, -1.5021e-01,\n          1.6722e-01, -4.9259e-02, -1.1847e-01,  1.3579e-01, -1.0087e-01,\n          1.0768e-01,  3.2778e-02],\n        [ 1.0138e-01,  1.3654e-01,  2.3792e-02,  1.6220e-01, -7.3009e-02,\n         -1.0473e-01,  1.6931e-01,  1.1666e-01,  8.5425e-02,  5.8059e-02,\n          1.4254e-01, -7.0384e-03,  1.4553e-01,  1.6751e-01,  1.1352e-01,\n          6.4417e-02,  9.9029e-02,  1.6138e-01, -3.6844e-03, -1.3447e-01,\n         -1.3047e-01, -7.1644e-02, -1.3183e-01, -1.3815e-01, -5.8683e-02,\n         -3.4240e-02,  5.1699e-02,  1.4019e-01,  1.0319e-01,  7.6691e-02,\n         -6.7936e-02, -1.9254e-02],\n        [ 1.2989e-01,  1.2714e-01, -1.6544e-01,  1.6347e-01, -1.2347e-01,\n          1.4449e-01,  1.3236e-01, -5.3482e-02,  3.7879e-02, -1.1227e-01,\n         -6.8311e-02, -1.0043e-01,  1.3515e-02,  7.1617e-02, -1.1802e-01,\n         -1.0002e-01,  1.0020e-01,  1.6601e-01, -6.7253e-02, -1.1047e-01,\n         -5.7732e-02,  5.9883e-02, -4.1202e-02,  4.2423e-02,  5.1103e-02,\n         -5.8456e-02, -9.3782e-02, -1.2614e-01, -9.8976e-02, -1.3547e-01,\n          9.4294e-02,  6.5269e-02],\n        [-1.6067e-01, -1.2494e-01, -1.2929e-01, -9.5768e-02, -5.3196e-02,\n         -1.4282e-01,  5.8424e-02, -9.5697e-03,  6.7283e-02, -7.4991e-02,\n          1.7208e-01,  1.2711e-01,  6.8927e-02,  1.6045e-01,  7.2504e-02,\n         -2.5984e-02,  1.1789e-01, -5.0854e-02, -5.4430e-02,  3.9652e-02,\n          1.3734e-01, -1.3215e-01, -1.1718e-01,  1.3532e-01,  3.9976e-02,\n          8.7254e-02,  1.5360e-01,  1.3299e-01, -3.7501e-02,  1.5478e-01,\n          1.3386e-01,  4.2482e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2439, -0.1043,  0.2146, -0.1726,  0.0360,  0.1991,  0.0935,  0.1829],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2312,  0.2055,  0.0053, -0.1457,  0.1230, -0.1424,  0.2361, -0.0245,\n         -0.1363,  0.1299,  0.2076,  0.0044, -0.0992,  0.0047, -0.0486, -0.2004],\n        [-0.0115, -0.2409, -0.0237, -0.2488,  0.0128, -0.2012, -0.1340, -0.1609,\n         -0.0186,  0.2043,  0.0826,  0.1615, -0.1037,  0.0886, -0.1543, -0.1262],\n        [-0.0662,  0.1688, -0.1285, -0.0054,  0.0300, -0.2096, -0.0250, -0.1110,\n          0.0943, -0.1610,  0.1768, -0.0435,  0.1005, -0.1160,  0.2301, -0.0617],\n        [ 0.1543,  0.0199, -0.2493, -0.2309, -0.0296,  0.1485,  0.0964,  0.2013,\n          0.1349,  0.1414, -0.1970, -0.1328,  0.1662,  0.0466, -0.2214, -0.0983],\n        [-0.0882,  0.0811, -0.0561, -0.0299, -0.0495, -0.0378,  0.1791, -0.1710,\n         -0.1450, -0.2428, -0.1103,  0.1557, -0.1782, -0.0990, -0.0386,  0.2430],\n        [-0.1284,  0.1110,  0.1930, -0.0813, -0.1089,  0.0970, -0.0829,  0.1165,\n         -0.0575,  0.0059,  0.0506, -0.0338,  0.2368,  0.2473, -0.0037,  0.0822],\n        [-0.1443, -0.0756, -0.0752,  0.0434,  0.1221,  0.1433, -0.2318,  0.0017,\n         -0.1194, -0.0944,  0.0453,  0.0637, -0.1765,  0.0506, -0.1328, -0.1728],\n        [ 0.1934,  0.2220,  0.2375, -0.1740, -0.0266, -0.0774,  0.0268,  0.0631,\n         -0.1030, -0.0122, -0.1214, -0.1542, -0.0163,  0.1315, -0.2092,  0.2322]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1735], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3486, -0.1328,  0.3415,  0.2914, -0.1006, -0.1117,  0.0565,  0.2729]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1356,  0.0875, -0.2609,  0.3158, -0.3322, -0.3490, -0.3405,  0.2025],\n        [ 0.0019,  0.2862, -0.1549, -0.3469,  0.0349,  0.0777, -0.1173, -0.1131],\n        [ 0.3107,  0.2083,  0.2641,  0.0458, -0.1518,  0.1315,  0.1353,  0.3414],\n        [-0.3451, -0.2776,  0.2499, -0.1658, -0.1276, -0.2065, -0.0598, -0.0788],\n        [-0.2996, -0.0353,  0.3037,  0.1225,  0.3206,  0.2349,  0.1088, -0.3236],\n        [-0.0185,  0.3440,  0.2520, -0.1024, -0.1597,  0.0423,  0.1439,  0.1071],\n        [-0.2680, -0.2670,  0.2421, -0.2185, -0.1234, -0.0819, -0.3353,  0.0943],\n        [-0.0738,  0.1447,  0.2370, -0.3106, -0.0338,  0.0435, -0.1535, -0.2869],\n        [ 0.0294,  0.0254, -0.2106,  0.0101,  0.3479,  0.1553, -0.2281,  0.1149],\n        [ 0.3212, -0.0642,  0.1506,  0.1883, -0.0144, -0.3483, -0.1054, -0.2207],\n        [ 0.1078, -0.0453, -0.3261, -0.0316,  0.0465,  0.1790, -0.1835, -0.2811],\n        [ 0.2743,  0.2148,  0.0378, -0.1975,  0.3129,  0.2141,  0.1100, -0.1466],\n        [-0.0546,  0.1656,  0.1416, -0.3516,  0.1720, -0.3425, -0.2712,  0.0266],\n        [-0.1389, -0.1072, -0.1111,  0.2030,  0.2455,  0.2160,  0.0191, -0.1626],\n        [-0.1816, -0.1110, -0.1729,  0.2491,  0.3286,  0.1906, -0.1885, -0.2122],\n        [-0.1660,  0.1147,  0.0459, -0.0623,  0.2888,  0.3340, -0.2222, -0.3216],\n        [ 0.2390,  0.2920,  0.2400, -0.1193, -0.1883, -0.2058,  0.2911, -0.1565],\n        [-0.1692, -0.1138, -0.1590, -0.2489,  0.1211, -0.3201,  0.1559,  0.3399],\n        [ 0.2447,  0.1842, -0.2576,  0.0288, -0.0932,  0.2970,  0.0997, -0.2766],\n        [-0.2158,  0.0928, -0.0582, -0.1415,  0.2752,  0.0659, -0.2493,  0.2596],\n        [-0.1807,  0.0707,  0.1861, -0.1575,  0.2924, -0.3377, -0.1993,  0.0492],\n        [-0.1729, -0.2412, -0.0781, -0.1024, -0.1467, -0.3311,  0.2311, -0.3393],\n        [ 0.2838,  0.0035, -0.1016,  0.2715, -0.3213, -0.1226,  0.1689, -0.0318],\n        [-0.2842,  0.1606,  0.3235,  0.0823, -0.3221, -0.0077, -0.3420,  0.0585],\n        [-0.2078, -0.2863, -0.3400,  0.2827, -0.1004,  0.3172, -0.1702,  0.2601],\n        [ 0.1755,  0.2312, -0.2165,  0.2500, -0.0389, -0.3252,  0.1778,  0.1525],\n        [ 0.1902,  0.2969,  0.2683,  0.0466, -0.0488,  0.0596, -0.2458, -0.3362],\n        [-0.1530,  0.1330, -0.0185, -0.3533, -0.1804,  0.1999,  0.2999,  0.2873],\n        [-0.1077,  0.0762, -0.3209, -0.0294, -0.2960,  0.1919,  0.1544,  0.0187],\n        [ 0.1594, -0.1639,  0.0225, -0.0110, -0.1368, -0.0937, -0.1382,  0.1703],\n        [-0.0547, -0.0774,  0.0337,  0.3165, -0.0028, -0.1095,  0.3293, -0.0779],\n        [ 0.1968,  0.2051, -0.1985,  0.0593, -0.2210, -0.3346, -0.1792, -0.0478]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2901,  0.2061,  0.1156, -0.0568, -0.0243,  0.1186,  0.1977, -0.3290,\n         0.1925,  0.3354, -0.2772,  0.0881, -0.2506, -0.1420,  0.0740,  0.0222,\n        -0.2626,  0.1501,  0.2995,  0.0118,  0.2668,  0.1458, -0.0395, -0.1644,\n         0.0986,  0.3395,  0.1284,  0.0064,  0.0268,  0.3213, -0.2493,  0.3334],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.3784e-01, -1.7154e-01,  1.0039e-01, -8.0771e-03,  1.4304e-01,\n          1.8698e-02, -1.7361e-01,  1.4898e-01, -1.6954e-01,  8.2307e-02,\n          1.3777e-01, -2.5238e-02,  1.1322e-01, -6.8836e-02, -1.6838e-01,\n          7.9003e-02, -1.4030e-01,  1.2071e-01, -3.0743e-02, -7.5288e-02,\n          1.7220e-02,  1.1180e-02,  3.1821e-02,  1.5038e-01, -5.7561e-02,\n          1.6606e-01, -1.6256e-01,  1.2895e-01, -9.1751e-02, -6.3039e-02,\n          7.9700e-02,  8.0342e-02],\n        [ 1.3661e-01,  7.4238e-02, -8.0432e-02,  5.0933e-03,  1.3915e-01,\n         -4.8504e-03,  1.7295e-01, -7.1410e-02,  1.2773e-01,  2.0114e-02,\n          7.1062e-02, -6.0457e-02,  1.6814e-02, -1.6288e-01,  3.4511e-02,\n         -1.6792e-01, -1.4853e-01, -1.3924e-04, -1.5381e-01,  1.7352e-01,\n          2.6260e-02, -1.5131e-01, -3.8941e-02,  1.1013e-01, -1.1338e-01,\n          2.8530e-02, -2.8445e-03,  2.4356e-03,  1.6281e-01, -1.7275e-01,\n          3.2869e-02, -1.6531e-01],\n        [-7.6679e-02,  9.2444e-02,  9.2057e-02, -6.7570e-03, -1.3253e-01,\n         -1.1405e-01,  4.3498e-02,  1.3949e-02, -1.7331e-01, -1.6777e-01,\n          1.1741e-01, -3.4132e-02, -1.7664e-01,  1.0484e-01, -6.5528e-04,\n         -5.1152e-02,  2.4950e-02, -7.4969e-02, -8.8085e-02, -2.9469e-02,\n          3.6786e-02,  6.6523e-02, -1.2101e-01,  5.4897e-02, -1.4106e-01,\n         -1.2074e-01,  5.1308e-04,  1.5163e-01, -4.6436e-02,  1.3997e-01,\n         -6.6007e-02, -1.8909e-02],\n        [-1.6068e-03,  5.6904e-02,  1.7533e-01, -1.6372e-01,  6.4052e-02,\n          8.2446e-02,  2.4138e-02, -1.3753e-01, -1.8234e-02,  1.2506e-01,\n         -7.2545e-02, -1.7502e-03, -1.7339e-01,  1.3342e-01,  1.4640e-01,\n         -1.0477e-01,  6.1456e-02,  5.6652e-02, -9.8305e-02, -1.3525e-01,\n         -4.1549e-02,  1.1854e-01,  5.8859e-02, -1.7111e-01,  1.2077e-01,\n          1.7002e-01,  6.9561e-02, -1.3268e-01,  1.2423e-02, -3.7100e-02,\n         -9.3873e-02,  4.1188e-02],\n        [-1.0148e-01, -8.3292e-02,  9.1507e-03,  7.3176e-02,  1.5424e-01,\n          1.5926e-01, -3.5568e-02,  1.0626e-01,  1.6133e-01,  3.7886e-02,\n         -6.7015e-02, -9.7058e-03,  1.2586e-01,  1.5370e-01,  1.1751e-01,\n          1.2848e-01, -9.0028e-02,  7.4156e-02,  8.3668e-02, -1.2863e-01,\n          6.2099e-02, -1.6445e-01, -4.9537e-02, -1.6263e-01, -1.1579e-01,\n         -3.5029e-02,  1.4073e-01, -9.3621e-02,  1.7368e-01,  1.9296e-02,\n         -5.7421e-02, -6.4704e-02],\n        [-8.2260e-02, -8.8003e-02, -6.7718e-02,  9.6219e-02, -1.7141e-01,\n          7.4347e-02, -1.3049e-01,  1.2250e-01,  1.3942e-01,  1.5098e-01,\n         -1.2341e-01,  1.5565e-01,  7.3051e-02, -8.5163e-02,  1.1305e-01,\n          9.4451e-03, -6.0362e-03, -1.4023e-01,  8.7026e-02, -1.3196e-01,\n          2.6377e-02, -1.0252e-01,  4.6835e-03, -1.2414e-01, -1.0019e-01,\n         -1.4310e-01, -1.5483e-01,  3.5526e-02,  1.2824e-02,  1.4745e-01,\n         -6.6311e-02,  5.7201e-03],\n        [ 1.4835e-02, -1.7338e-01, -7.1283e-02, -4.6264e-02, -1.3818e-01,\n          8.5163e-02, -8.7648e-02, -2.8719e-02,  1.2350e-01, -1.5052e-01,\n         -1.3421e-01, -1.7655e-02, -1.1182e-01, -2.8689e-02,  7.1235e-02,\n         -6.2117e-03,  1.4336e-01, -5.7337e-02,  1.0798e-01,  6.9428e-02,\n         -1.3338e-01, -1.6413e-01, -1.3869e-01,  1.2194e-01,  1.4780e-01,\n         -1.5974e-01, -1.4759e-01, -5.4724e-02, -1.3439e-01,  1.2465e-02,\n          1.1692e-01,  8.2529e-02],\n        [-1.0914e-01, -9.4251e-02,  9.1841e-02,  1.3075e-01,  1.1498e-01,\n         -3.6688e-02, -7.5762e-02,  1.3286e-01, -1.2326e-01, -1.4449e-01,\n         -1.5651e-01,  1.1662e-01,  6.1991e-02, -4.7253e-02,  1.4979e-02,\n          1.3875e-01, -2.3761e-02,  1.1325e-01,  8.6495e-04,  6.2813e-03,\n          1.1760e-02, -1.0505e-01, -6.1283e-02,  2.7062e-02, -1.2139e-01,\n         -6.5090e-02,  7.0916e-02, -5.3189e-02, -5.1980e-02, -1.1137e-01,\n         -4.2549e-02,  7.3070e-02],\n        [ 1.1369e-01, -1.1953e-01,  5.5972e-03, -1.2626e-02,  1.1909e-01,\n          1.4558e-01, -3.3010e-02, -1.2018e-01,  1.1326e-01, -3.5286e-02,\n          8.7275e-02,  3.3407e-02,  4.9571e-02, -3.9027e-02,  1.5670e-01,\n          1.0809e-01,  6.0457e-02, -2.8831e-02,  4.6106e-02,  1.0253e-01,\n         -7.3818e-02,  1.3360e-01,  3.6750e-02,  1.6515e-01,  1.1837e-01,\n         -1.3634e-01,  1.4498e-01, -1.2650e-02,  1.4992e-01,  1.2502e-01,\n         -1.2976e-01, -5.8683e-02],\n        [ 9.6422e-02, -5.1860e-03, -1.5808e-01,  1.3246e-01,  5.0929e-02,\n         -5.9943e-03,  1.3350e-01,  1.7269e-01, -1.7052e-01,  1.7210e-01,\n         -8.9064e-02,  1.1294e-01,  1.5892e-01,  1.1702e-01, -4.8800e-02,\n          7.6519e-02, -3.7790e-02, -4.6435e-02,  5.9785e-03,  4.5953e-02,\n          1.5478e-01,  7.2528e-02,  6.8529e-02, -1.7020e-02,  4.3851e-02,\n         -1.0115e-01, -1.1470e-01, -1.5650e-01,  1.1302e-01, -1.5661e-01,\n          9.3381e-02,  7.4390e-02],\n        [ 6.3495e-02, -2.2385e-02, -1.5401e-01,  2.1545e-02,  9.9280e-02,\n          8.0913e-02, -6.7013e-02,  4.7190e-02,  8.9619e-02, -1.6186e-01,\n         -8.1814e-02,  6.8135e-02, -5.1815e-02, -1.1725e-01, -1.6583e-01,\n          1.4623e-01, -1.2372e-01, -1.4370e-01,  1.1300e-01, -1.5592e-02,\n          5.8136e-02, -3.7327e-02, -9.0058e-02, -8.5840e-02, -8.6237e-03,\n         -2.3552e-02,  6.3559e-02,  1.0075e-01,  4.7190e-02, -9.9373e-02,\n          8.1579e-02, -5.0865e-02],\n        [-1.0516e-01,  1.0011e-01,  1.4773e-02, -1.3985e-01, -1.7343e-01,\n          7.8632e-02,  1.5170e-01,  8.0835e-02, -1.3082e-02, -1.2047e-01,\n          1.4371e-01, -4.9680e-02,  1.6041e-01, -9.1419e-02, -1.4485e-01,\n          4.6720e-02, -3.4674e-02,  1.5940e-02,  1.8602e-02, -9.5281e-02,\n          1.1100e-01,  8.7359e-02,  1.2137e-01,  4.6863e-02,  5.0365e-02,\n         -1.3326e-01, -1.0342e-01,  1.6336e-01, -1.7575e-01, -9.9788e-02,\n          1.0313e-01, -3.4709e-02],\n        [ 1.6244e-01,  2.1093e-02,  1.2534e-01, -1.8387e-02, -2.8509e-02,\n         -1.6118e-01, -1.4987e-01, -2.9802e-02,  1.0388e-01, -1.5272e-03,\n         -1.2888e-01,  1.3016e-01, -4.1309e-02,  9.4363e-02,  5.5770e-02,\n         -7.2297e-02,  4.4498e-02, -1.1673e-01,  1.5873e-01,  1.3175e-01,\n         -1.3642e-01,  1.5421e-01,  2.5177e-02, -4.4114e-02, -1.5021e-01,\n          1.6722e-01, -4.9259e-02, -1.1847e-01,  1.3579e-01, -1.0087e-01,\n          1.0768e-01,  3.2778e-02],\n        [ 1.0138e-01,  1.3654e-01,  2.3792e-02,  1.6220e-01, -7.3009e-02,\n         -1.0473e-01,  1.6931e-01,  1.1666e-01,  8.5425e-02,  5.8059e-02,\n          1.4254e-01, -7.0384e-03,  1.4553e-01,  1.6751e-01,  1.1352e-01,\n          6.4417e-02,  9.9029e-02,  1.6138e-01, -3.6844e-03, -1.3447e-01,\n         -1.3047e-01, -7.1644e-02, -1.3183e-01, -1.3815e-01, -5.8683e-02,\n         -3.4240e-02,  5.1699e-02,  1.4019e-01,  1.0319e-01,  7.6691e-02,\n         -6.7936e-02, -1.9254e-02],\n        [ 1.2989e-01,  1.2714e-01, -1.6544e-01,  1.6347e-01, -1.2347e-01,\n          1.4449e-01,  1.3236e-01, -5.3482e-02,  3.7879e-02, -1.1227e-01,\n         -6.8311e-02, -1.0043e-01,  1.3515e-02,  7.1617e-02, -1.1802e-01,\n         -1.0002e-01,  1.0020e-01,  1.6601e-01, -6.7253e-02, -1.1047e-01,\n         -5.7732e-02,  5.9883e-02, -4.1202e-02,  4.2423e-02,  5.1103e-02,\n         -5.8456e-02, -9.3782e-02, -1.2614e-01, -9.8976e-02, -1.3547e-01,\n          9.4294e-02,  6.5269e-02],\n        [-1.6067e-01, -1.2494e-01, -1.2929e-01, -9.5768e-02, -5.3196e-02,\n         -1.4282e-01,  5.8424e-02, -9.5697e-03,  6.7283e-02, -7.4991e-02,\n          1.7208e-01,  1.2711e-01,  6.8927e-02,  1.6045e-01,  7.2504e-02,\n         -2.5984e-02,  1.1789e-01, -5.0854e-02, -5.4430e-02,  3.9652e-02,\n          1.3734e-01, -1.3215e-01, -1.1718e-01,  1.3532e-01,  3.9976e-02,\n          8.7254e-02,  1.5360e-01,  1.3299e-01, -3.7501e-02,  1.5478e-01,\n          1.3386e-01,  4.2482e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1751, -0.0059,  0.1143, -0.1371, -0.0497,  0.1720, -0.1576, -0.0678,\n         0.1453,  0.0756, -0.0350, -0.0955,  0.0999,  0.1344, -0.1643,  0.0651],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2312,  0.2055,  0.0053, -0.1457,  0.1230, -0.1424,  0.2361, -0.0245,\n         -0.1363,  0.1299,  0.2076,  0.0044, -0.0992,  0.0047, -0.0486, -0.2004],\n        [-0.0115, -0.2409, -0.0237, -0.2488,  0.0128, -0.2012, -0.1340, -0.1609,\n         -0.0186,  0.2043,  0.0826,  0.1615, -0.1037,  0.0886, -0.1543, -0.1262],\n        [-0.0662,  0.1688, -0.1285, -0.0054,  0.0300, -0.2096, -0.0250, -0.1110,\n          0.0943, -0.1610,  0.1768, -0.0435,  0.1005, -0.1160,  0.2301, -0.0617],\n        [ 0.1543,  0.0199, -0.2493, -0.2309, -0.0296,  0.1485,  0.0964,  0.2013,\n          0.1349,  0.1414, -0.1970, -0.1328,  0.1662,  0.0466, -0.2214, -0.0983],\n        [-0.0882,  0.0811, -0.0561, -0.0299, -0.0495, -0.0378,  0.1791, -0.1710,\n         -0.1450, -0.2428, -0.1103,  0.1557, -0.1782, -0.0990, -0.0386,  0.2430],\n        [-0.1284,  0.1110,  0.1930, -0.0813, -0.1089,  0.0970, -0.0829,  0.1165,\n         -0.0575,  0.0059,  0.0506, -0.0338,  0.2368,  0.2473, -0.0037,  0.0822],\n        [-0.1443, -0.0756, -0.0752,  0.0434,  0.1221,  0.1433, -0.2318,  0.0017,\n         -0.1194, -0.0944,  0.0453,  0.0637, -0.1765,  0.0506, -0.1328, -0.1728],\n        [ 0.1934,  0.2220,  0.2375, -0.1740, -0.0266, -0.0774,  0.0268,  0.0631,\n         -0.1030, -0.0122, -0.1214, -0.1542, -0.0163,  0.1315, -0.2092,  0.2322]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2439, -0.1043,  0.2146, -0.1726,  0.0360,  0.1991,  0.0935,  0.1829],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3486, -0.1328,  0.3415,  0.2914, -0.1006, -0.1117,  0.0565,  0.2729]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1735], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x00000273FF3A22F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x00000273EAFE92D0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s272680000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s272680000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}