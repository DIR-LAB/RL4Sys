{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s273660000"
    },
    "q_lr":	0.0005,
    "seed":	273660000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7e127d8e4910>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0334, -0.0230, -0.0772,  0.1098, -0.2298, -0.2127,  0.2832, -0.0961,\n         0.1041, -0.0157,  0.0401,  0.1062,  0.2589,  0.0546,  0.3113,  0.1841,\n        -0.2000, -0.1234,  0.1274, -0.3173, -0.2883,  0.2402, -0.1473, -0.1059,\n        -0.1815, -0.0499, -0.2694, -0.1109,  0.2726, -0.2993, -0.1595,  0.2102],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0946,  0.3032,  0.2656, -0.2084, -0.1803,  0.0543, -0.3259,  0.2746],\n        [-0.1775, -0.0263,  0.2544,  0.0520, -0.3490,  0.1737, -0.1531, -0.2745],\n        [ 0.2564, -0.0878,  0.0030, -0.0502, -0.1343, -0.1072, -0.0039, -0.2914],\n        [-0.0402, -0.0218, -0.3498,  0.2370,  0.0770,  0.1836,  0.3506,  0.2440],\n        [ 0.1626,  0.3009,  0.2421,  0.1544,  0.0674,  0.3375, -0.0349,  0.0827],\n        [ 0.1269, -0.1550,  0.1939,  0.2412, -0.2835,  0.3362,  0.1234,  0.0206],\n        [ 0.0687, -0.1220, -0.0598,  0.0354, -0.1259,  0.0919,  0.1047,  0.0202],\n        [ 0.3458, -0.0500,  0.0329,  0.2240,  0.0831, -0.1030,  0.1139, -0.2421],\n        [-0.3425,  0.3034,  0.2955, -0.2864, -0.0956,  0.0781,  0.0232,  0.0101],\n        [-0.1642, -0.3373, -0.2907, -0.0923,  0.2612, -0.1474, -0.1247, -0.0856],\n        [ 0.2345, -0.2535, -0.2045, -0.3134, -0.0006, -0.1129, -0.2541, -0.2060],\n        [ 0.1940,  0.0762,  0.2786,  0.3513,  0.1852, -0.2102,  0.2734, -0.3054],\n        [ 0.2052,  0.2892,  0.0586,  0.1954, -0.1447,  0.1010,  0.0091,  0.0852],\n        [-0.1433, -0.1022, -0.3319, -0.1007, -0.3356,  0.2986, -0.1749,  0.2436],\n        [ 0.0985, -0.2782, -0.3178, -0.2059,  0.2658,  0.0682,  0.1211, -0.1597],\n        [-0.0714,  0.0788, -0.1510, -0.2027,  0.2698, -0.2878, -0.1562, -0.2382],\n        [ 0.0884, -0.1959, -0.2385, -0.2035, -0.1635, -0.3375, -0.2860, -0.0790],\n        [-0.2038,  0.2682,  0.1523, -0.3037, -0.0534,  0.3476,  0.2765, -0.1411],\n        [ 0.2477,  0.2733, -0.3120,  0.1534,  0.0217, -0.0136, -0.0834,  0.1670],\n        [-0.0834,  0.0197, -0.3074,  0.2604, -0.1330,  0.0714,  0.2679,  0.0792],\n        [ 0.2814,  0.2856, -0.0257, -0.2198, -0.3376, -0.1559,  0.1074, -0.1531],\n        [-0.2258, -0.2594, -0.0113,  0.1007, -0.2203,  0.2629,  0.0726, -0.1765],\n        [ 0.0158, -0.2736, -0.1946, -0.0219,  0.0824, -0.2134,  0.2615, -0.2682],\n        [ 0.1964,  0.3433, -0.2885, -0.1541, -0.0266,  0.1119, -0.1962,  0.1420],\n        [-0.1947,  0.2102, -0.0610,  0.1621, -0.1395, -0.2546,  0.0592, -0.1633],\n        [ 0.3228,  0.3377,  0.1049, -0.0619, -0.0553, -0.2242,  0.3449, -0.0055],\n        [ 0.1910, -0.0701,  0.0030, -0.0900,  0.1349,  0.0491,  0.0537, -0.2506],\n        [ 0.1334, -0.1598,  0.1061,  0.1613, -0.0837, -0.1076, -0.2111, -0.0567],\n        [ 0.2078, -0.3443, -0.2218,  0.1848, -0.3096,  0.2306, -0.2961, -0.2520],\n        [ 0.3075, -0.1329, -0.3158, -0.0386,  0.3307, -0.0573, -0.0454,  0.3491],\n        [ 0.2906, -0.1159, -0.2963, -0.1772, -0.1651,  0.3488,  0.3125, -0.1617],\n        [-0.3147,  0.3032,  0.0413, -0.1795,  0.2034, -0.2511, -0.1879, -0.1526]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1404,  0.1339,  0.0488, -0.1032, -0.1119,  0.0728, -0.1145,  0.0666,\n        -0.0684,  0.0563, -0.0153, -0.1510,  0.0824,  0.0085, -0.0773, -0.0003],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.5020e-01,  3.8563e-02,  1.2614e-01, -4.1583e-02, -9.3780e-03,\n         -7.8959e-02, -3.2092e-02, -5.1732e-02,  7.8521e-02, -1.1647e-01,\n          1.3467e-01, -1.1277e-02, -1.7055e-01,  1.1644e-01, -1.6564e-01,\n          1.2274e-01, -1.3885e-01, -2.1176e-02,  1.1105e-01,  4.3608e-02,\n         -6.1053e-02, -8.3311e-03,  1.6718e-02, -4.2387e-02, -4.3289e-02,\n         -8.8059e-02,  1.6719e-01,  9.5844e-02, -1.2643e-01,  1.1557e-02,\n          1.2995e-01,  1.6699e-03],\n        [-1.6767e-01, -1.6451e-01,  5.7237e-03, -1.4314e-02,  9.4228e-02,\n         -1.4999e-01,  1.2811e-02,  4.3443e-02,  1.3158e-01, -1.4780e-01,\n          3.3508e-02,  1.4399e-01,  1.0070e-01,  7.2867e-02,  5.0230e-02,\n         -2.5023e-02, -1.1774e-01, -1.6056e-01, -3.2499e-02, -2.2975e-02,\n          6.9680e-02, -1.4787e-04,  2.0161e-02, -9.5566e-02,  1.5084e-01,\n         -1.3685e-01,  1.1569e-01,  9.1798e-02,  2.5709e-03, -2.0858e-02,\n         -1.3213e-01,  8.1160e-03],\n        [ 5.7271e-02, -1.1078e-01,  1.1936e-02,  2.7952e-03,  1.3987e-01,\n         -1.4099e-01, -8.8852e-03, -1.7543e-01, -1.4740e-01, -2.7974e-02,\n         -1.1471e-01,  6.8895e-02, -1.7371e-01, -3.4648e-02,  1.4550e-01,\n         -6.3284e-02,  1.6365e-01, -1.3795e-01, -5.8454e-02, -1.4893e-01,\n          8.3022e-02,  2.2011e-02, -3.9337e-02,  7.3164e-02, -1.1506e-01,\n         -2.2368e-02, -1.7494e-01, -8.0596e-03,  3.5941e-02,  8.3669e-02,\n          1.7730e-02, -1.8827e-02],\n        [ 4.1593e-02,  1.2173e-01, -3.7511e-06, -1.1808e-01,  4.2686e-02,\n          1.4735e-01, -7.1975e-03,  1.7223e-02, -8.4087e-03, -2.4611e-02,\n          1.0653e-01,  1.4778e-01,  1.7632e-01,  1.2277e-01,  1.2343e-01,\n          9.5194e-02,  9.5467e-02,  1.0003e-01,  6.5958e-04, -2.2339e-02,\n         -6.8864e-02, -7.7902e-03,  6.0134e-02,  1.4816e-01, -1.5115e-01,\n         -9.3299e-03, -1.4460e-01,  1.2660e-01, -2.5997e-03, -1.4395e-01,\n          8.4458e-02, -5.6026e-02],\n        [ 9.4815e-02, -1.5087e-01, -1.3425e-01,  1.0484e-01, -3.6581e-02,\n          4.3283e-02, -1.6899e-01,  1.3219e-01,  1.3114e-01, -1.2580e-01,\n          2.0152e-02,  2.8039e-03, -3.9072e-02, -5.0187e-02, -1.4773e-01,\n         -6.0903e-02,  1.3914e-01,  1.3626e-01, -1.1335e-01,  8.9604e-02,\n          1.7259e-01,  1.6265e-01,  8.7285e-03,  1.7240e-01,  9.5458e-02,\n         -1.4442e-01, -4.3734e-02, -1.4845e-01, -1.2048e-01, -8.5319e-02,\n          3.7195e-02,  1.2796e-01],\n        [-1.9379e-02, -7.8333e-02, -1.4137e-01,  1.1966e-02,  1.9714e-02,\n          1.2291e-01, -8.5559e-02,  7.1087e-02,  3.8430e-02,  1.1800e-01,\n          1.0783e-01,  4.6798e-02,  1.4383e-01,  6.9394e-02, -4.9676e-03,\n          6.2077e-02, -1.4811e-01,  9.9829e-02,  1.2627e-01,  2.3641e-02,\n          1.9322e-02,  1.6518e-01, -1.7677e-01, -4.2086e-02, -3.0414e-02,\n          2.8513e-02,  1.1297e-01, -5.7476e-02, -3.9366e-02,  7.0739e-02,\n         -9.5944e-02,  1.2266e-01],\n        [-4.6991e-02, -1.4257e-01, -5.7627e-02, -9.9175e-03, -1.6191e-01,\n         -6.6003e-02, -1.6595e-01, -1.4122e-01, -1.0926e-01, -1.6240e-01,\n          5.4482e-02,  1.1977e-02, -6.1906e-02, -4.2941e-02, -1.5345e-01,\n          1.4821e-01, -6.4878e-02,  7.4906e-02,  3.4387e-02, -1.2842e-01,\n          1.0197e-01, -8.0431e-02, -3.5551e-02,  1.0803e-02,  4.7468e-02,\n         -5.9049e-02, -8.4779e-02,  6.9187e-02, -1.6635e-01,  1.0869e-01,\n          6.9128e-02,  1.4823e-01],\n        [-1.4454e-01, -1.5875e-01, -1.0918e-01, -9.2587e-02,  9.7498e-02,\n         -2.2463e-02,  2.0596e-03,  1.2813e-01,  1.7096e-01,  9.1616e-02,\n          8.5447e-02, -1.6916e-01,  6.3819e-03,  4.9961e-03,  1.0750e-01,\n          1.0018e-01, -1.9781e-02,  1.1551e-01, -1.6713e-01, -9.1463e-02,\n          3.9270e-03, -1.6402e-01,  1.3620e-01,  1.6842e-01, -1.2885e-01,\n          3.0815e-02,  1.3034e-01, -1.4901e-01, -2.6758e-02,  3.7418e-02,\n          1.7383e-01,  1.3905e-01],\n        [ 9.3774e-02,  2.1268e-03,  1.2765e-01,  1.6309e-01,  1.1243e-01,\n          7.1300e-02, -1.3422e-01,  7.5407e-02, -8.9281e-03, -1.3937e-01,\n          5.6366e-02, -1.5986e-01, -4.4468e-02,  1.3547e-01, -1.6212e-01,\n         -2.2245e-02,  1.6237e-01,  1.0697e-01,  1.1960e-01, -4.0168e-02,\n         -9.3291e-02, -3.3572e-02,  1.0202e-01,  4.4770e-02,  5.6291e-02,\n          1.3236e-01,  1.0448e-02,  1.2700e-01,  1.8598e-02,  1.5137e-01,\n          1.4591e-01, -5.6622e-03],\n        [-1.1559e-01, -1.0555e-01,  2.3415e-02, -4.3866e-03, -1.7655e-01,\n         -9.4621e-03,  5.8255e-02, -1.3759e-01, -5.7236e-02, -5.1070e-02,\n          1.7487e-01, -7.2579e-02,  1.1074e-01, -9.1652e-02, -4.8787e-02,\n         -1.4779e-01, -1.0014e-02, -1.0083e-02, -9.1478e-02,  7.4225e-02,\n         -1.6840e-01,  1.7588e-01,  5.4742e-02,  9.6845e-02,  1.2962e-01,\n          1.7195e-01,  1.7626e-01, -1.9581e-02, -3.1994e-02, -9.1233e-02,\n          9.0021e-02, -3.6597e-02],\n        [-3.3106e-02,  1.7676e-01, -1.5628e-01, -1.3548e-01,  5.4162e-02,\n         -4.2627e-03,  1.1987e-01, -1.2179e-01,  2.2426e-02,  8.6808e-02,\n         -7.2515e-02, -4.7970e-02, -1.0019e-01,  2.8806e-02,  1.0109e-01,\n          1.1715e-01, -3.7561e-02, -1.1311e-01, -6.4906e-02,  1.3856e-01,\n          1.3087e-01, -1.6964e-01,  3.7730e-02,  1.3334e-01,  1.7586e-01,\n          8.9957e-02,  1.4965e-01, -5.8277e-02,  2.0500e-02, -9.9827e-02,\n         -7.7754e-02,  1.2311e-01],\n        [ 1.3356e-01,  6.0767e-02, -1.1698e-01, -5.8225e-03, -1.0431e-01,\n          3.7971e-02, -1.9272e-02,  8.4935e-02,  1.6918e-01, -5.4653e-02,\n          1.2262e-03,  9.6547e-02,  1.5640e-01, -1.7713e-02, -2.3371e-02,\n          5.5580e-02, -5.4972e-02,  3.0583e-02, -9.9982e-02,  1.0873e-01,\n          6.9103e-02, -4.5629e-02,  1.1357e-02, -1.4082e-01,  1.7468e-01,\n         -1.0462e-01,  1.3606e-01, -1.3670e-02,  1.6720e-01, -1.2126e-01,\n         -1.7004e-01,  1.2585e-01],\n        [-7.9411e-02,  1.3845e-01,  8.4065e-02, -1.4115e-01,  9.4796e-03,\n          4.2018e-02,  1.4721e-01,  1.1568e-01, -8.1628e-02,  4.7494e-02,\n         -3.9317e-02,  1.7551e-01, -1.4099e-01, -1.7985e-02,  9.6277e-02,\n         -4.1590e-02,  1.6067e-01, -1.5611e-01, -1.0359e-01, -1.9570e-02,\n         -1.4081e-02, -7.1067e-02, -1.2341e-01, -1.3320e-01,  2.1455e-02,\n         -3.7863e-02, -8.3823e-02,  1.3520e-01, -1.0539e-01,  1.7573e-01,\n          6.2127e-02,  6.8976e-02],\n        [-3.2837e-03,  1.7277e-01, -3.6475e-02, -9.5320e-02, -5.5357e-02,\n         -1.7251e-02,  9.4047e-02, -8.0327e-03, -1.5990e-01, -1.4048e-01,\n          6.8709e-02,  8.6241e-02,  7.2856e-02,  2.0109e-02,  6.5460e-02,\n          8.5976e-02, -1.3772e-01, -1.4695e-01, -1.5442e-03,  1.6631e-01,\n          1.2363e-01,  1.4866e-01, -4.7666e-02,  8.2910e-02, -3.9978e-04,\n         -5.2995e-02,  1.0927e-02,  6.0760e-02,  1.0139e-01, -4.7793e-02,\n          1.7636e-02,  2.0278e-02],\n        [-5.2366e-02, -9.6724e-02, -3.5295e-02,  7.5260e-03,  1.4182e-01,\n          1.6182e-01,  3.4100e-02,  1.1406e-01,  1.4119e-01,  1.1802e-01,\n         -8.5117e-03,  9.5632e-02,  4.5720e-02,  3.7932e-02,  1.6134e-02,\n         -6.2901e-02,  1.1267e-01, -2.6856e-02, -8.6863e-02, -2.3359e-02,\n         -3.9025e-02, -2.4882e-02,  8.5399e-02,  1.4865e-01,  4.2286e-02,\n         -4.2120e-02, -1.1455e-01,  2.9461e-02, -1.7010e-04,  1.2760e-01,\n          1.1922e-01,  7.7177e-02],\n        [-4.1249e-02, -2.5555e-02, -3.2606e-02, -1.6823e-02,  1.7035e-01,\n         -5.7514e-04,  1.3907e-01,  1.6186e-01,  1.1247e-01, -8.4049e-02,\n          5.5907e-02, -1.0072e-03, -1.6377e-01,  1.7010e-01, -9.1311e-03,\n          1.6127e-02, -6.9980e-02, -1.4316e-01,  1.3012e-01,  1.5823e-01,\n          1.0728e-01, -1.0819e-01,  1.3550e-01,  1.1067e-01, -6.5860e-02,\n         -1.6228e-01, -1.4847e-01, -6.7117e-03,  1.0511e-01, -1.3796e-01,\n         -4.5383e-02, -9.5101e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1283, -0.1364, -0.0384, -0.0211, -0.2293, -0.0425, -0.0367, -0.0443],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2112,  0.0401, -0.1594,  0.0466,  0.1240, -0.1975, -0.2302,  0.1388,\n         -0.0888,  0.1787, -0.0264, -0.0474,  0.0384, -0.1337,  0.2499,  0.0409],\n        [ 0.2213, -0.2379,  0.1820,  0.2159,  0.0620, -0.0743,  0.1958,  0.2394,\n          0.2183,  0.0982,  0.1622, -0.0198,  0.0277, -0.1560, -0.2250, -0.0637],\n        [ 0.1111, -0.2112,  0.1319,  0.1897, -0.1616, -0.1159, -0.1125, -0.1987,\n          0.0935,  0.1485, -0.2466, -0.2068, -0.1453, -0.1437, -0.2190, -0.1542],\n        [-0.2160,  0.2446, -0.2138,  0.1114, -0.0873,  0.0053, -0.1681,  0.2207,\n         -0.1350, -0.2170, -0.0281, -0.1250,  0.1904,  0.1406, -0.0019,  0.0213],\n        [ 0.1274, -0.0047, -0.2471,  0.1581,  0.1553,  0.0261, -0.2299, -0.0772,\n          0.2410, -0.2457,  0.1643,  0.0282, -0.0543,  0.2179,  0.0741,  0.2456],\n        [-0.2206, -0.1559, -0.1563,  0.1659, -0.2457, -0.2158,  0.1029,  0.0873,\n          0.0264, -0.1224,  0.1229,  0.1145,  0.0058, -0.1529, -0.0642, -0.2042],\n        [-0.0884,  0.0131, -0.2407, -0.2194,  0.2071,  0.1590, -0.1357, -0.0060,\n          0.0470,  0.2070, -0.0253, -0.1056, -0.2209, -0.0105,  0.1801, -0.0760],\n        [ 0.0563,  0.1796, -0.2287, -0.1399, -0.1843,  0.1901, -0.0179, -0.1832,\n          0.1349, -0.1208,  0.0380, -0.2410,  0.2270, -0.2342, -0.2410,  0.0576]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2504,  0.3197,  0.1963,  0.2463], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1322,  0.0754, -0.3428,  0.0845,  0.0909, -0.3148,  0.2708,  0.0628],\n        [-0.2050, -0.3316, -0.1702, -0.1331,  0.1450,  0.2495, -0.1050, -0.2713],\n        [-0.0954,  0.0063,  0.2891,  0.0662, -0.3005, -0.0313,  0.2709,  0.0068],\n        [ 0.0408, -0.2667,  0.0752, -0.1870, -0.2273,  0.2852, -0.2238,  0.3074]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0946,  0.3032,  0.2656, -0.2084, -0.1803,  0.0543, -0.3259,  0.2746],\n        [-0.1775, -0.0263,  0.2544,  0.0520, -0.3490,  0.1737, -0.1531, -0.2745],\n        [ 0.2564, -0.0878,  0.0030, -0.0502, -0.1343, -0.1072, -0.0039, -0.2914],\n        [-0.0402, -0.0218, -0.3498,  0.2370,  0.0770,  0.1836,  0.3506,  0.2440],\n        [ 0.1626,  0.3009,  0.2421,  0.1544,  0.0674,  0.3375, -0.0349,  0.0827],\n        [ 0.1269, -0.1550,  0.1939,  0.2412, -0.2835,  0.3362,  0.1234,  0.0206],\n        [ 0.0687, -0.1220, -0.0598,  0.0354, -0.1259,  0.0919,  0.1047,  0.0202],\n        [ 0.3458, -0.0500,  0.0329,  0.2240,  0.0831, -0.1030,  0.1139, -0.2421],\n        [-0.3425,  0.3034,  0.2955, -0.2864, -0.0956,  0.0781,  0.0232,  0.0101],\n        [-0.1642, -0.3373, -0.2907, -0.0923,  0.2612, -0.1474, -0.1247, -0.0856],\n        [ 0.2345, -0.2535, -0.2045, -0.3134, -0.0006, -0.1129, -0.2541, -0.2060],\n        [ 0.1940,  0.0762,  0.2786,  0.3513,  0.1852, -0.2102,  0.2734, -0.3054],\n        [ 0.2052,  0.2892,  0.0586,  0.1954, -0.1447,  0.1010,  0.0091,  0.0852],\n        [-0.1433, -0.1022, -0.3319, -0.1007, -0.3356,  0.2986, -0.1749,  0.2436],\n        [ 0.0985, -0.2782, -0.3178, -0.2059,  0.2658,  0.0682,  0.1211, -0.1597],\n        [-0.0714,  0.0788, -0.1510, -0.2027,  0.2698, -0.2878, -0.1562, -0.2382],\n        [ 0.0884, -0.1959, -0.2385, -0.2035, -0.1635, -0.3375, -0.2860, -0.0790],\n        [-0.2038,  0.2682,  0.1523, -0.3037, -0.0534,  0.3476,  0.2765, -0.1411],\n        [ 0.2477,  0.2733, -0.3120,  0.1534,  0.0217, -0.0136, -0.0834,  0.1670],\n        [-0.0834,  0.0197, -0.3074,  0.2604, -0.1330,  0.0714,  0.2679,  0.0792],\n        [ 0.2814,  0.2856, -0.0257, -0.2198, -0.3376, -0.1559,  0.1074, -0.1531],\n        [-0.2258, -0.2594, -0.0113,  0.1007, -0.2203,  0.2629,  0.0726, -0.1765],\n        [ 0.0158, -0.2736, -0.1946, -0.0219,  0.0824, -0.2134,  0.2615, -0.2682],\n        [ 0.1964,  0.3433, -0.2885, -0.1541, -0.0266,  0.1119, -0.1962,  0.1420],\n        [-0.1947,  0.2102, -0.0610,  0.1621, -0.1395, -0.2546,  0.0592, -0.1633],\n        [ 0.3228,  0.3377,  0.1049, -0.0619, -0.0553, -0.2242,  0.3449, -0.0055],\n        [ 0.1910, -0.0701,  0.0030, -0.0900,  0.1349,  0.0491,  0.0537, -0.2506],\n        [ 0.1334, -0.1598,  0.1061,  0.1613, -0.0837, -0.1076, -0.2111, -0.0567],\n        [ 0.2078, -0.3443, -0.2218,  0.1848, -0.3096,  0.2306, -0.2961, -0.2520],\n        [ 0.3075, -0.1329, -0.3158, -0.0386,  0.3307, -0.0573, -0.0454,  0.3491],\n        [ 0.2906, -0.1159, -0.2963, -0.1772, -0.1651,  0.3488,  0.3125, -0.1617],\n        [-0.3147,  0.3032,  0.0413, -0.1795,  0.2034, -0.2511, -0.1879, -0.1526]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0334, -0.0230, -0.0772,  0.1098, -0.2298, -0.2127,  0.2832, -0.0961,\n         0.1041, -0.0157,  0.0401,  0.1062,  0.2589,  0.0546,  0.3113,  0.1841,\n        -0.2000, -0.1234,  0.1274, -0.3173, -0.2883,  0.2402, -0.1473, -0.1059,\n        -0.1815, -0.0499, -0.2694, -0.1109,  0.2726, -0.2993, -0.1595,  0.2102],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.5020e-01,  3.8563e-02,  1.2614e-01, -4.1583e-02, -9.3780e-03,\n         -7.8959e-02, -3.2092e-02, -5.1732e-02,  7.8521e-02, -1.1647e-01,\n          1.3467e-01, -1.1277e-02, -1.7055e-01,  1.1644e-01, -1.6564e-01,\n          1.2274e-01, -1.3885e-01, -2.1176e-02,  1.1105e-01,  4.3608e-02,\n         -6.1053e-02, -8.3311e-03,  1.6718e-02, -4.2387e-02, -4.3289e-02,\n         -8.8059e-02,  1.6719e-01,  9.5844e-02, -1.2643e-01,  1.1557e-02,\n          1.2995e-01,  1.6699e-03],\n        [-1.6767e-01, -1.6451e-01,  5.7237e-03, -1.4314e-02,  9.4228e-02,\n         -1.4999e-01,  1.2811e-02,  4.3443e-02,  1.3158e-01, -1.4780e-01,\n          3.3508e-02,  1.4399e-01,  1.0070e-01,  7.2867e-02,  5.0230e-02,\n         -2.5023e-02, -1.1774e-01, -1.6056e-01, -3.2499e-02, -2.2975e-02,\n          6.9680e-02, -1.4787e-04,  2.0161e-02, -9.5566e-02,  1.5084e-01,\n         -1.3685e-01,  1.1569e-01,  9.1798e-02,  2.5709e-03, -2.0858e-02,\n         -1.3213e-01,  8.1160e-03],\n        [ 5.7271e-02, -1.1078e-01,  1.1936e-02,  2.7952e-03,  1.3987e-01,\n         -1.4099e-01, -8.8852e-03, -1.7543e-01, -1.4740e-01, -2.7974e-02,\n         -1.1471e-01,  6.8895e-02, -1.7371e-01, -3.4648e-02,  1.4550e-01,\n         -6.3284e-02,  1.6365e-01, -1.3795e-01, -5.8454e-02, -1.4893e-01,\n          8.3022e-02,  2.2011e-02, -3.9337e-02,  7.3164e-02, -1.1506e-01,\n         -2.2368e-02, -1.7494e-01, -8.0596e-03,  3.5941e-02,  8.3669e-02,\n          1.7730e-02, -1.8827e-02],\n        [ 4.1593e-02,  1.2173e-01, -3.7511e-06, -1.1808e-01,  4.2686e-02,\n          1.4735e-01, -7.1975e-03,  1.7223e-02, -8.4087e-03, -2.4611e-02,\n          1.0653e-01,  1.4778e-01,  1.7632e-01,  1.2277e-01,  1.2343e-01,\n          9.5194e-02,  9.5467e-02,  1.0003e-01,  6.5958e-04, -2.2339e-02,\n         -6.8864e-02, -7.7902e-03,  6.0134e-02,  1.4816e-01, -1.5115e-01,\n         -9.3299e-03, -1.4460e-01,  1.2660e-01, -2.5997e-03, -1.4395e-01,\n          8.4458e-02, -5.6026e-02],\n        [ 9.4815e-02, -1.5087e-01, -1.3425e-01,  1.0484e-01, -3.6581e-02,\n          4.3283e-02, -1.6899e-01,  1.3219e-01,  1.3114e-01, -1.2580e-01,\n          2.0152e-02,  2.8039e-03, -3.9072e-02, -5.0187e-02, -1.4773e-01,\n         -6.0903e-02,  1.3914e-01,  1.3626e-01, -1.1335e-01,  8.9604e-02,\n          1.7259e-01,  1.6265e-01,  8.7285e-03,  1.7240e-01,  9.5458e-02,\n         -1.4442e-01, -4.3734e-02, -1.4845e-01, -1.2048e-01, -8.5319e-02,\n          3.7195e-02,  1.2796e-01],\n        [-1.9379e-02, -7.8333e-02, -1.4137e-01,  1.1966e-02,  1.9714e-02,\n          1.2291e-01, -8.5559e-02,  7.1087e-02,  3.8430e-02,  1.1800e-01,\n          1.0783e-01,  4.6798e-02,  1.4383e-01,  6.9394e-02, -4.9676e-03,\n          6.2077e-02, -1.4811e-01,  9.9829e-02,  1.2627e-01,  2.3641e-02,\n          1.9322e-02,  1.6518e-01, -1.7677e-01, -4.2086e-02, -3.0414e-02,\n          2.8513e-02,  1.1297e-01, -5.7476e-02, -3.9366e-02,  7.0739e-02,\n         -9.5944e-02,  1.2266e-01],\n        [-4.6991e-02, -1.4257e-01, -5.7627e-02, -9.9175e-03, -1.6191e-01,\n         -6.6003e-02, -1.6595e-01, -1.4122e-01, -1.0926e-01, -1.6240e-01,\n          5.4482e-02,  1.1977e-02, -6.1906e-02, -4.2941e-02, -1.5345e-01,\n          1.4821e-01, -6.4878e-02,  7.4906e-02,  3.4387e-02, -1.2842e-01,\n          1.0197e-01, -8.0431e-02, -3.5551e-02,  1.0803e-02,  4.7468e-02,\n         -5.9049e-02, -8.4779e-02,  6.9187e-02, -1.6635e-01,  1.0869e-01,\n          6.9128e-02,  1.4823e-01],\n        [-1.4454e-01, -1.5875e-01, -1.0918e-01, -9.2587e-02,  9.7498e-02,\n         -2.2463e-02,  2.0596e-03,  1.2813e-01,  1.7096e-01,  9.1616e-02,\n          8.5447e-02, -1.6916e-01,  6.3819e-03,  4.9961e-03,  1.0750e-01,\n          1.0018e-01, -1.9781e-02,  1.1551e-01, -1.6713e-01, -9.1463e-02,\n          3.9270e-03, -1.6402e-01,  1.3620e-01,  1.6842e-01, -1.2885e-01,\n          3.0815e-02,  1.3034e-01, -1.4901e-01, -2.6758e-02,  3.7418e-02,\n          1.7383e-01,  1.3905e-01],\n        [ 9.3774e-02,  2.1268e-03,  1.2765e-01,  1.6309e-01,  1.1243e-01,\n          7.1300e-02, -1.3422e-01,  7.5407e-02, -8.9281e-03, -1.3937e-01,\n          5.6366e-02, -1.5986e-01, -4.4468e-02,  1.3547e-01, -1.6212e-01,\n         -2.2245e-02,  1.6237e-01,  1.0697e-01,  1.1960e-01, -4.0168e-02,\n         -9.3291e-02, -3.3572e-02,  1.0202e-01,  4.4770e-02,  5.6291e-02,\n          1.3236e-01,  1.0448e-02,  1.2700e-01,  1.8598e-02,  1.5137e-01,\n          1.4591e-01, -5.6622e-03],\n        [-1.1559e-01, -1.0555e-01,  2.3415e-02, -4.3866e-03, -1.7655e-01,\n         -9.4621e-03,  5.8255e-02, -1.3759e-01, -5.7236e-02, -5.1070e-02,\n          1.7487e-01, -7.2579e-02,  1.1074e-01, -9.1652e-02, -4.8787e-02,\n         -1.4779e-01, -1.0014e-02, -1.0083e-02, -9.1478e-02,  7.4225e-02,\n         -1.6840e-01,  1.7588e-01,  5.4742e-02,  9.6845e-02,  1.2962e-01,\n          1.7195e-01,  1.7626e-01, -1.9581e-02, -3.1994e-02, -9.1233e-02,\n          9.0021e-02, -3.6597e-02],\n        [-3.3106e-02,  1.7676e-01, -1.5628e-01, -1.3548e-01,  5.4162e-02,\n         -4.2627e-03,  1.1987e-01, -1.2179e-01,  2.2426e-02,  8.6808e-02,\n         -7.2515e-02, -4.7970e-02, -1.0019e-01,  2.8806e-02,  1.0109e-01,\n          1.1715e-01, -3.7561e-02, -1.1311e-01, -6.4906e-02,  1.3856e-01,\n          1.3087e-01, -1.6964e-01,  3.7730e-02,  1.3334e-01,  1.7586e-01,\n          8.9957e-02,  1.4965e-01, -5.8277e-02,  2.0500e-02, -9.9827e-02,\n         -7.7754e-02,  1.2311e-01],\n        [ 1.3356e-01,  6.0767e-02, -1.1698e-01, -5.8225e-03, -1.0431e-01,\n          3.7971e-02, -1.9272e-02,  8.4935e-02,  1.6918e-01, -5.4653e-02,\n          1.2262e-03,  9.6547e-02,  1.5640e-01, -1.7713e-02, -2.3371e-02,\n          5.5580e-02, -5.4972e-02,  3.0583e-02, -9.9982e-02,  1.0873e-01,\n          6.9103e-02, -4.5629e-02,  1.1357e-02, -1.4082e-01,  1.7468e-01,\n         -1.0462e-01,  1.3606e-01, -1.3670e-02,  1.6720e-01, -1.2126e-01,\n         -1.7004e-01,  1.2585e-01],\n        [-7.9411e-02,  1.3845e-01,  8.4065e-02, -1.4115e-01,  9.4796e-03,\n          4.2018e-02,  1.4721e-01,  1.1568e-01, -8.1628e-02,  4.7494e-02,\n         -3.9317e-02,  1.7551e-01, -1.4099e-01, -1.7985e-02,  9.6277e-02,\n         -4.1590e-02,  1.6067e-01, -1.5611e-01, -1.0359e-01, -1.9570e-02,\n         -1.4081e-02, -7.1067e-02, -1.2341e-01, -1.3320e-01,  2.1455e-02,\n         -3.7863e-02, -8.3823e-02,  1.3520e-01, -1.0539e-01,  1.7573e-01,\n          6.2127e-02,  6.8976e-02],\n        [-3.2837e-03,  1.7277e-01, -3.6475e-02, -9.5320e-02, -5.5357e-02,\n         -1.7251e-02,  9.4047e-02, -8.0327e-03, -1.5990e-01, -1.4048e-01,\n          6.8709e-02,  8.6241e-02,  7.2856e-02,  2.0109e-02,  6.5460e-02,\n          8.5976e-02, -1.3772e-01, -1.4695e-01, -1.5442e-03,  1.6631e-01,\n          1.2363e-01,  1.4866e-01, -4.7666e-02,  8.2910e-02, -3.9978e-04,\n         -5.2995e-02,  1.0927e-02,  6.0760e-02,  1.0139e-01, -4.7793e-02,\n          1.7636e-02,  2.0278e-02],\n        [-5.2366e-02, -9.6724e-02, -3.5295e-02,  7.5260e-03,  1.4182e-01,\n          1.6182e-01,  3.4100e-02,  1.1406e-01,  1.4119e-01,  1.1802e-01,\n         -8.5117e-03,  9.5632e-02,  4.5720e-02,  3.7932e-02,  1.6134e-02,\n         -6.2901e-02,  1.1267e-01, -2.6856e-02, -8.6863e-02, -2.3359e-02,\n         -3.9025e-02, -2.4882e-02,  8.5399e-02,  1.4865e-01,  4.2286e-02,\n         -4.2120e-02, -1.1455e-01,  2.9461e-02, -1.7010e-04,  1.2760e-01,\n          1.1922e-01,  7.7177e-02],\n        [-4.1249e-02, -2.5555e-02, -3.2606e-02, -1.6823e-02,  1.7035e-01,\n         -5.7514e-04,  1.3907e-01,  1.6186e-01,  1.1247e-01, -8.4049e-02,\n          5.5907e-02, -1.0072e-03, -1.6377e-01,  1.7010e-01, -9.1311e-03,\n          1.6127e-02, -6.9980e-02, -1.4316e-01,  1.3012e-01,  1.5823e-01,\n          1.0728e-01, -1.0819e-01,  1.3550e-01,  1.1067e-01, -6.5860e-02,\n         -1.6228e-01, -1.4847e-01, -6.7117e-03,  1.0511e-01, -1.3796e-01,\n         -4.5383e-02, -9.5101e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1404,  0.1339,  0.0488, -0.1032, -0.1119,  0.0728, -0.1145,  0.0666,\n        -0.0684,  0.0563, -0.0153, -0.1510,  0.0824,  0.0085, -0.0773, -0.0003],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2112,  0.0401, -0.1594,  0.0466,  0.1240, -0.1975, -0.2302,  0.1388,\n         -0.0888,  0.1787, -0.0264, -0.0474,  0.0384, -0.1337,  0.2499,  0.0409],\n        [ 0.2213, -0.2379,  0.1820,  0.2159,  0.0620, -0.0743,  0.1958,  0.2394,\n          0.2183,  0.0982,  0.1622, -0.0198,  0.0277, -0.1560, -0.2250, -0.0637],\n        [ 0.1111, -0.2112,  0.1319,  0.1897, -0.1616, -0.1159, -0.1125, -0.1987,\n          0.0935,  0.1485, -0.2466, -0.2068, -0.1453, -0.1437, -0.2190, -0.1542],\n        [-0.2160,  0.2446, -0.2138,  0.1114, -0.0873,  0.0053, -0.1681,  0.2207,\n         -0.1350, -0.2170, -0.0281, -0.1250,  0.1904,  0.1406, -0.0019,  0.0213],\n        [ 0.1274, -0.0047, -0.2471,  0.1581,  0.1553,  0.0261, -0.2299, -0.0772,\n          0.2410, -0.2457,  0.1643,  0.0282, -0.0543,  0.2179,  0.0741,  0.2456],\n        [-0.2206, -0.1559, -0.1563,  0.1659, -0.2457, -0.2158,  0.1029,  0.0873,\n          0.0264, -0.1224,  0.1229,  0.1145,  0.0058, -0.1529, -0.0642, -0.2042],\n        [-0.0884,  0.0131, -0.2407, -0.2194,  0.2071,  0.1590, -0.1357, -0.0060,\n          0.0470,  0.2070, -0.0253, -0.1056, -0.2209, -0.0105,  0.1801, -0.0760],\n        [ 0.0563,  0.1796, -0.2287, -0.1399, -0.1843,  0.1901, -0.0179, -0.1832,\n          0.1349, -0.1208,  0.0380, -0.2410,  0.2270, -0.2342, -0.2410,  0.0576]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1283, -0.1364, -0.0384, -0.0211, -0.2293, -0.0425, -0.0367, -0.0443],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1322,  0.0754, -0.3428,  0.0845,  0.0909, -0.3148,  0.2708,  0.0628],\n        [-0.2050, -0.3316, -0.1702, -0.1331,  0.1450,  0.2495, -0.1050, -0.2713],\n        [-0.0954,  0.0063,  0.2891,  0.0662, -0.3005, -0.0313,  0.2709,  0.0068],\n        [ 0.0408, -0.2667,  0.0752, -0.1870, -0.2273,  0.2852, -0.2238,  0.3074]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2504,  0.3197,  0.1963,  0.2463], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7e12f6df8fd0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0334, -0.0230, -0.0772,  0.1098, -0.2298, -0.2127,  0.2832, -0.0961,\n         0.1041, -0.0157,  0.0401,  0.1062,  0.2589,  0.0546,  0.3113,  0.1841,\n        -0.2000, -0.1234,  0.1274, -0.3173, -0.2883,  0.2402, -0.1473, -0.1059,\n        -0.1815, -0.0499, -0.2694, -0.1109,  0.2726, -0.2993, -0.1595,  0.2102],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0946,  0.3032,  0.2656, -0.2084, -0.1803,  0.0543, -0.3259,  0.2746],\n        [-0.1775, -0.0263,  0.2544,  0.0520, -0.3490,  0.1737, -0.1531, -0.2745],\n        [ 0.2564, -0.0878,  0.0030, -0.0502, -0.1343, -0.1072, -0.0039, -0.2914],\n        [-0.0402, -0.0218, -0.3498,  0.2370,  0.0770,  0.1836,  0.3506,  0.2440],\n        [ 0.1626,  0.3009,  0.2421,  0.1544,  0.0674,  0.3375, -0.0349,  0.0827],\n        [ 0.1269, -0.1550,  0.1939,  0.2412, -0.2835,  0.3362,  0.1234,  0.0206],\n        [ 0.0687, -0.1220, -0.0598,  0.0354, -0.1259,  0.0919,  0.1047,  0.0202],\n        [ 0.3458, -0.0500,  0.0329,  0.2240,  0.0831, -0.1030,  0.1139, -0.2421],\n        [-0.3425,  0.3034,  0.2955, -0.2864, -0.0956,  0.0781,  0.0232,  0.0101],\n        [-0.1642, -0.3373, -0.2907, -0.0923,  0.2612, -0.1474, -0.1247, -0.0856],\n        [ 0.2345, -0.2535, -0.2045, -0.3134, -0.0006, -0.1129, -0.2541, -0.2060],\n        [ 0.1940,  0.0762,  0.2786,  0.3513,  0.1852, -0.2102,  0.2734, -0.3054],\n        [ 0.2052,  0.2892,  0.0586,  0.1954, -0.1447,  0.1010,  0.0091,  0.0852],\n        [-0.1433, -0.1022, -0.3319, -0.1007, -0.3356,  0.2986, -0.1749,  0.2436],\n        [ 0.0985, -0.2782, -0.3178, -0.2059,  0.2658,  0.0682,  0.1211, -0.1597],\n        [-0.0714,  0.0788, -0.1510, -0.2027,  0.2698, -0.2878, -0.1562, -0.2382],\n        [ 0.0884, -0.1959, -0.2385, -0.2035, -0.1635, -0.3375, -0.2860, -0.0790],\n        [-0.2038,  0.2682,  0.1523, -0.3037, -0.0534,  0.3476,  0.2765, -0.1411],\n        [ 0.2477,  0.2733, -0.3120,  0.1534,  0.0217, -0.0136, -0.0834,  0.1670],\n        [-0.0834,  0.0197, -0.3074,  0.2604, -0.1330,  0.0714,  0.2679,  0.0792],\n        [ 0.2814,  0.2856, -0.0257, -0.2198, -0.3376, -0.1559,  0.1074, -0.1531],\n        [-0.2258, -0.2594, -0.0113,  0.1007, -0.2203,  0.2629,  0.0726, -0.1765],\n        [ 0.0158, -0.2736, -0.1946, -0.0219,  0.0824, -0.2134,  0.2615, -0.2682],\n        [ 0.1964,  0.3433, -0.2885, -0.1541, -0.0266,  0.1119, -0.1962,  0.1420],\n        [-0.1947,  0.2102, -0.0610,  0.1621, -0.1395, -0.2546,  0.0592, -0.1633],\n        [ 0.3228,  0.3377,  0.1049, -0.0619, -0.0553, -0.2242,  0.3449, -0.0055],\n        [ 0.1910, -0.0701,  0.0030, -0.0900,  0.1349,  0.0491,  0.0537, -0.2506],\n        [ 0.1334, -0.1598,  0.1061,  0.1613, -0.0837, -0.1076, -0.2111, -0.0567],\n        [ 0.2078, -0.3443, -0.2218,  0.1848, -0.3096,  0.2306, -0.2961, -0.2520],\n        [ 0.3075, -0.1329, -0.3158, -0.0386,  0.3307, -0.0573, -0.0454,  0.3491],\n        [ 0.2906, -0.1159, -0.2963, -0.1772, -0.1651,  0.3488,  0.3125, -0.1617],\n        [-0.3147,  0.3032,  0.0413, -0.1795,  0.2034, -0.2511, -0.1879, -0.1526]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1404,  0.1339,  0.0488, -0.1032, -0.1119,  0.0728, -0.1145,  0.0666,\n        -0.0684,  0.0563, -0.0153, -0.1510,  0.0824,  0.0085, -0.0773, -0.0003],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.5020e-01,  3.8563e-02,  1.2614e-01, -4.1583e-02, -9.3780e-03,\n         -7.8959e-02, -3.2092e-02, -5.1732e-02,  7.8521e-02, -1.1647e-01,\n          1.3467e-01, -1.1277e-02, -1.7055e-01,  1.1644e-01, -1.6564e-01,\n          1.2274e-01, -1.3885e-01, -2.1176e-02,  1.1105e-01,  4.3608e-02,\n         -6.1053e-02, -8.3311e-03,  1.6718e-02, -4.2387e-02, -4.3289e-02,\n         -8.8059e-02,  1.6719e-01,  9.5844e-02, -1.2643e-01,  1.1557e-02,\n          1.2995e-01,  1.6699e-03],\n        [-1.6767e-01, -1.6451e-01,  5.7237e-03, -1.4314e-02,  9.4228e-02,\n         -1.4999e-01,  1.2811e-02,  4.3443e-02,  1.3158e-01, -1.4780e-01,\n          3.3508e-02,  1.4399e-01,  1.0070e-01,  7.2867e-02,  5.0230e-02,\n         -2.5023e-02, -1.1774e-01, -1.6056e-01, -3.2499e-02, -2.2975e-02,\n          6.9680e-02, -1.4787e-04,  2.0161e-02, -9.5566e-02,  1.5084e-01,\n         -1.3685e-01,  1.1569e-01,  9.1798e-02,  2.5709e-03, -2.0858e-02,\n         -1.3213e-01,  8.1160e-03],\n        [ 5.7271e-02, -1.1078e-01,  1.1936e-02,  2.7952e-03,  1.3987e-01,\n         -1.4099e-01, -8.8852e-03, -1.7543e-01, -1.4740e-01, -2.7974e-02,\n         -1.1471e-01,  6.8895e-02, -1.7371e-01, -3.4648e-02,  1.4550e-01,\n         -6.3284e-02,  1.6365e-01, -1.3795e-01, -5.8454e-02, -1.4893e-01,\n          8.3022e-02,  2.2011e-02, -3.9337e-02,  7.3164e-02, -1.1506e-01,\n         -2.2368e-02, -1.7494e-01, -8.0596e-03,  3.5941e-02,  8.3669e-02,\n          1.7730e-02, -1.8827e-02],\n        [ 4.1593e-02,  1.2173e-01, -3.7511e-06, -1.1808e-01,  4.2686e-02,\n          1.4735e-01, -7.1975e-03,  1.7223e-02, -8.4087e-03, -2.4611e-02,\n          1.0653e-01,  1.4778e-01,  1.7632e-01,  1.2277e-01,  1.2343e-01,\n          9.5194e-02,  9.5467e-02,  1.0003e-01,  6.5958e-04, -2.2339e-02,\n         -6.8864e-02, -7.7902e-03,  6.0134e-02,  1.4816e-01, -1.5115e-01,\n         -9.3299e-03, -1.4460e-01,  1.2660e-01, -2.5997e-03, -1.4395e-01,\n          8.4458e-02, -5.6026e-02],\n        [ 9.4815e-02, -1.5087e-01, -1.3425e-01,  1.0484e-01, -3.6581e-02,\n          4.3283e-02, -1.6899e-01,  1.3219e-01,  1.3114e-01, -1.2580e-01,\n          2.0152e-02,  2.8039e-03, -3.9072e-02, -5.0187e-02, -1.4773e-01,\n         -6.0903e-02,  1.3914e-01,  1.3626e-01, -1.1335e-01,  8.9604e-02,\n          1.7259e-01,  1.6265e-01,  8.7285e-03,  1.7240e-01,  9.5458e-02,\n         -1.4442e-01, -4.3734e-02, -1.4845e-01, -1.2048e-01, -8.5319e-02,\n          3.7195e-02,  1.2796e-01],\n        [-1.9379e-02, -7.8333e-02, -1.4137e-01,  1.1966e-02,  1.9714e-02,\n          1.2291e-01, -8.5559e-02,  7.1087e-02,  3.8430e-02,  1.1800e-01,\n          1.0783e-01,  4.6798e-02,  1.4383e-01,  6.9394e-02, -4.9676e-03,\n          6.2077e-02, -1.4811e-01,  9.9829e-02,  1.2627e-01,  2.3641e-02,\n          1.9322e-02,  1.6518e-01, -1.7677e-01, -4.2086e-02, -3.0414e-02,\n          2.8513e-02,  1.1297e-01, -5.7476e-02, -3.9366e-02,  7.0739e-02,\n         -9.5944e-02,  1.2266e-01],\n        [-4.6991e-02, -1.4257e-01, -5.7627e-02, -9.9175e-03, -1.6191e-01,\n         -6.6003e-02, -1.6595e-01, -1.4122e-01, -1.0926e-01, -1.6240e-01,\n          5.4482e-02,  1.1977e-02, -6.1906e-02, -4.2941e-02, -1.5345e-01,\n          1.4821e-01, -6.4878e-02,  7.4906e-02,  3.4387e-02, -1.2842e-01,\n          1.0197e-01, -8.0431e-02, -3.5551e-02,  1.0803e-02,  4.7468e-02,\n         -5.9049e-02, -8.4779e-02,  6.9187e-02, -1.6635e-01,  1.0869e-01,\n          6.9128e-02,  1.4823e-01],\n        [-1.4454e-01, -1.5875e-01, -1.0918e-01, -9.2587e-02,  9.7498e-02,\n         -2.2463e-02,  2.0596e-03,  1.2813e-01,  1.7096e-01,  9.1616e-02,\n          8.5447e-02, -1.6916e-01,  6.3819e-03,  4.9961e-03,  1.0750e-01,\n          1.0018e-01, -1.9781e-02,  1.1551e-01, -1.6713e-01, -9.1463e-02,\n          3.9270e-03, -1.6402e-01,  1.3620e-01,  1.6842e-01, -1.2885e-01,\n          3.0815e-02,  1.3034e-01, -1.4901e-01, -2.6758e-02,  3.7418e-02,\n          1.7383e-01,  1.3905e-01],\n        [ 9.3774e-02,  2.1268e-03,  1.2765e-01,  1.6309e-01,  1.1243e-01,\n          7.1300e-02, -1.3422e-01,  7.5407e-02, -8.9281e-03, -1.3937e-01,\n          5.6366e-02, -1.5986e-01, -4.4468e-02,  1.3547e-01, -1.6212e-01,\n         -2.2245e-02,  1.6237e-01,  1.0697e-01,  1.1960e-01, -4.0168e-02,\n         -9.3291e-02, -3.3572e-02,  1.0202e-01,  4.4770e-02,  5.6291e-02,\n          1.3236e-01,  1.0448e-02,  1.2700e-01,  1.8598e-02,  1.5137e-01,\n          1.4591e-01, -5.6622e-03],\n        [-1.1559e-01, -1.0555e-01,  2.3415e-02, -4.3866e-03, -1.7655e-01,\n         -9.4621e-03,  5.8255e-02, -1.3759e-01, -5.7236e-02, -5.1070e-02,\n          1.7487e-01, -7.2579e-02,  1.1074e-01, -9.1652e-02, -4.8787e-02,\n         -1.4779e-01, -1.0014e-02, -1.0083e-02, -9.1478e-02,  7.4225e-02,\n         -1.6840e-01,  1.7588e-01,  5.4742e-02,  9.6845e-02,  1.2962e-01,\n          1.7195e-01,  1.7626e-01, -1.9581e-02, -3.1994e-02, -9.1233e-02,\n          9.0021e-02, -3.6597e-02],\n        [-3.3106e-02,  1.7676e-01, -1.5628e-01, -1.3548e-01,  5.4162e-02,\n         -4.2627e-03,  1.1987e-01, -1.2179e-01,  2.2426e-02,  8.6808e-02,\n         -7.2515e-02, -4.7970e-02, -1.0019e-01,  2.8806e-02,  1.0109e-01,\n          1.1715e-01, -3.7561e-02, -1.1311e-01, -6.4906e-02,  1.3856e-01,\n          1.3087e-01, -1.6964e-01,  3.7730e-02,  1.3334e-01,  1.7586e-01,\n          8.9957e-02,  1.4965e-01, -5.8277e-02,  2.0500e-02, -9.9827e-02,\n         -7.7754e-02,  1.2311e-01],\n        [ 1.3356e-01,  6.0767e-02, -1.1698e-01, -5.8225e-03, -1.0431e-01,\n          3.7971e-02, -1.9272e-02,  8.4935e-02,  1.6918e-01, -5.4653e-02,\n          1.2262e-03,  9.6547e-02,  1.5640e-01, -1.7713e-02, -2.3371e-02,\n          5.5580e-02, -5.4972e-02,  3.0583e-02, -9.9982e-02,  1.0873e-01,\n          6.9103e-02, -4.5629e-02,  1.1357e-02, -1.4082e-01,  1.7468e-01,\n         -1.0462e-01,  1.3606e-01, -1.3670e-02,  1.6720e-01, -1.2126e-01,\n         -1.7004e-01,  1.2585e-01],\n        [-7.9411e-02,  1.3845e-01,  8.4065e-02, -1.4115e-01,  9.4796e-03,\n          4.2018e-02,  1.4721e-01,  1.1568e-01, -8.1628e-02,  4.7494e-02,\n         -3.9317e-02,  1.7551e-01, -1.4099e-01, -1.7985e-02,  9.6277e-02,\n         -4.1590e-02,  1.6067e-01, -1.5611e-01, -1.0359e-01, -1.9570e-02,\n         -1.4081e-02, -7.1067e-02, -1.2341e-01, -1.3320e-01,  2.1455e-02,\n         -3.7863e-02, -8.3823e-02,  1.3520e-01, -1.0539e-01,  1.7573e-01,\n          6.2127e-02,  6.8976e-02],\n        [-3.2837e-03,  1.7277e-01, -3.6475e-02, -9.5320e-02, -5.5357e-02,\n         -1.7251e-02,  9.4047e-02, -8.0327e-03, -1.5990e-01, -1.4048e-01,\n          6.8709e-02,  8.6241e-02,  7.2856e-02,  2.0109e-02,  6.5460e-02,\n          8.5976e-02, -1.3772e-01, -1.4695e-01, -1.5442e-03,  1.6631e-01,\n          1.2363e-01,  1.4866e-01, -4.7666e-02,  8.2910e-02, -3.9978e-04,\n         -5.2995e-02,  1.0927e-02,  6.0760e-02,  1.0139e-01, -4.7793e-02,\n          1.7636e-02,  2.0278e-02],\n        [-5.2366e-02, -9.6724e-02, -3.5295e-02,  7.5260e-03,  1.4182e-01,\n          1.6182e-01,  3.4100e-02,  1.1406e-01,  1.4119e-01,  1.1802e-01,\n         -8.5117e-03,  9.5632e-02,  4.5720e-02,  3.7932e-02,  1.6134e-02,\n         -6.2901e-02,  1.1267e-01, -2.6856e-02, -8.6863e-02, -2.3359e-02,\n         -3.9025e-02, -2.4882e-02,  8.5399e-02,  1.4865e-01,  4.2286e-02,\n         -4.2120e-02, -1.1455e-01,  2.9461e-02, -1.7010e-04,  1.2760e-01,\n          1.1922e-01,  7.7177e-02],\n        [-4.1249e-02, -2.5555e-02, -3.2606e-02, -1.6823e-02,  1.7035e-01,\n         -5.7514e-04,  1.3907e-01,  1.6186e-01,  1.1247e-01, -8.4049e-02,\n          5.5907e-02, -1.0072e-03, -1.6377e-01,  1.7010e-01, -9.1311e-03,\n          1.6127e-02, -6.9980e-02, -1.4316e-01,  1.3012e-01,  1.5823e-01,\n          1.0728e-01, -1.0819e-01,  1.3550e-01,  1.1067e-01, -6.5860e-02,\n         -1.6228e-01, -1.4847e-01, -6.7117e-03,  1.0511e-01, -1.3796e-01,\n         -4.5383e-02, -9.5101e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1283, -0.1364, -0.0384, -0.0211, -0.2293, -0.0425, -0.0367, -0.0443],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2112,  0.0401, -0.1594,  0.0466,  0.1240, -0.1975, -0.2302,  0.1388,\n         -0.0888,  0.1787, -0.0264, -0.0474,  0.0384, -0.1337,  0.2499,  0.0409],\n        [ 0.2213, -0.2379,  0.1820,  0.2159,  0.0620, -0.0743,  0.1958,  0.2394,\n          0.2183,  0.0982,  0.1622, -0.0198,  0.0277, -0.1560, -0.2250, -0.0637],\n        [ 0.1111, -0.2112,  0.1319,  0.1897, -0.1616, -0.1159, -0.1125, -0.1987,\n          0.0935,  0.1485, -0.2466, -0.2068, -0.1453, -0.1437, -0.2190, -0.1542],\n        [-0.2160,  0.2446, -0.2138,  0.1114, -0.0873,  0.0053, -0.1681,  0.2207,\n         -0.1350, -0.2170, -0.0281, -0.1250,  0.1904,  0.1406, -0.0019,  0.0213],\n        [ 0.1274, -0.0047, -0.2471,  0.1581,  0.1553,  0.0261, -0.2299, -0.0772,\n          0.2410, -0.2457,  0.1643,  0.0282, -0.0543,  0.2179,  0.0741,  0.2456],\n        [-0.2206, -0.1559, -0.1563,  0.1659, -0.2457, -0.2158,  0.1029,  0.0873,\n          0.0264, -0.1224,  0.1229,  0.1145,  0.0058, -0.1529, -0.0642, -0.2042],\n        [-0.0884,  0.0131, -0.2407, -0.2194,  0.2071,  0.1590, -0.1357, -0.0060,\n          0.0470,  0.2070, -0.0253, -0.1056, -0.2209, -0.0105,  0.1801, -0.0760],\n        [ 0.0563,  0.1796, -0.2287, -0.1399, -0.1843,  0.1901, -0.0179, -0.1832,\n          0.1349, -0.1208,  0.0380, -0.2410,  0.2270, -0.2342, -0.2410,  0.0576]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2504,  0.3197,  0.1963,  0.2463], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1322,  0.0754, -0.3428,  0.0845,  0.0909, -0.3148,  0.2708,  0.0628],\n        [-0.2050, -0.3316, -0.1702, -0.1331,  0.1450,  0.2495, -0.1050, -0.2713],\n        [-0.0954,  0.0063,  0.2891,  0.0662, -0.3005, -0.0313,  0.2709,  0.0068],\n        [ 0.0408, -0.2667,  0.0752, -0.1870, -0.2273,  0.2852, -0.2238,  0.3074]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7e127c411e90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s273660000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s273660000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}