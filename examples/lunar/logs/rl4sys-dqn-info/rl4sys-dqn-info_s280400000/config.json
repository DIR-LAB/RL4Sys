{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	64,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s280400000"
    },
    "q_lr":	0.001,
    "seed":	280400000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000001E42D3B90F0>":	{
            "_act_dim":	1,
            "_batch_size":	64,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3171, -0.0236,  0.3141, -0.0816, -0.0420, -0.0752,  0.0411, -0.0934,\n         0.2987,  0.1637,  0.2147,  0.0573,  0.2737, -0.1470, -0.1954, -0.2366,\n        -0.1010, -0.0711,  0.1365, -0.2869, -0.3401,  0.1079,  0.1661, -0.1296,\n         0.1619, -0.3025, -0.1969,  0.3444, -0.1821,  0.3140, -0.0347, -0.0180],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0575,  0.2052,  0.3067, -0.1474, -0.1327,  0.0652, -0.0819,  0.3092],\n        [ 0.0346,  0.0817,  0.0802, -0.1576,  0.3479, -0.1706, -0.2801, -0.1868],\n        [-0.3074, -0.0881, -0.0245, -0.2156,  0.0416, -0.0909,  0.2056, -0.1852],\n        [ 0.3258, -0.0126,  0.1191, -0.1848, -0.0075, -0.1748,  0.0008, -0.1047],\n        [-0.1071,  0.3274, -0.2274, -0.1625, -0.0012,  0.1808,  0.2175, -0.0673],\n        [-0.2235,  0.3302,  0.0186, -0.3426,  0.0876,  0.1978,  0.3190, -0.0744],\n        [ 0.0419,  0.0298,  0.2996,  0.0591, -0.3313, -0.1371,  0.3533,  0.2986],\n        [ 0.2550,  0.0209,  0.2189,  0.1389,  0.0996, -0.1135,  0.2674, -0.0890],\n        [-0.1003, -0.0859,  0.3242,  0.2085,  0.2919, -0.2773, -0.2322,  0.1481],\n        [-0.2758, -0.1730, -0.1075, -0.3487,  0.1546, -0.3284, -0.2046,  0.1518],\n        [-0.1920, -0.3292,  0.0436, -0.2191,  0.1844, -0.1298, -0.2214,  0.1530],\n        [-0.2489, -0.3246, -0.1720,  0.1444,  0.3414, -0.3490, -0.2548, -0.3436],\n        [ 0.0710, -0.0652, -0.1172,  0.1131, -0.0160, -0.2575,  0.0967, -0.2519],\n        [ 0.1318,  0.1351,  0.2625,  0.2640, -0.1569, -0.2910, -0.0081,  0.1949],\n        [-0.1920,  0.1521,  0.2498,  0.2120, -0.1879,  0.0018,  0.2401, -0.0502],\n        [ 0.2314, -0.3410, -0.0956, -0.2863, -0.0945, -0.1140, -0.3067, -0.1173],\n        [-0.1906,  0.2147, -0.1328,  0.1710, -0.3000,  0.2896,  0.2786,  0.0726],\n        [-0.2962, -0.2730, -0.2501, -0.3364, -0.2956,  0.3521,  0.1666, -0.2190],\n        [-0.2418, -0.2458, -0.0938, -0.0880,  0.1401, -0.3116,  0.2901, -0.1188],\n        [ 0.1569,  0.3232, -0.1307, -0.2282,  0.2607, -0.2026, -0.1926,  0.2227],\n        [ 0.3344,  0.2997,  0.0434, -0.1922,  0.0637, -0.0914,  0.1916, -0.2838],\n        [ 0.1684, -0.2631, -0.2166, -0.3378, -0.2621, -0.2724, -0.0830,  0.1276],\n        [-0.0542,  0.0017, -0.0990, -0.2443,  0.3431, -0.2359, -0.2114, -0.0931],\n        [-0.1950, -0.0112,  0.1117, -0.1015,  0.2714,  0.1191,  0.0891,  0.0390],\n        [ 0.2872,  0.1655,  0.0092, -0.3205, -0.1053,  0.1595,  0.0827, -0.3032],\n        [-0.2951,  0.2229, -0.3137, -0.1162,  0.1360,  0.1663, -0.0685, -0.3346],\n        [-0.2804,  0.0730, -0.0913, -0.3369, -0.0392, -0.1251, -0.2745,  0.0456],\n        [-0.3488,  0.3151, -0.2451,  0.2828,  0.1602,  0.1339, -0.2539, -0.0867],\n        [ 0.3010,  0.3021,  0.1269, -0.1821,  0.2248,  0.0607,  0.1274, -0.3070],\n        [ 0.0856, -0.3073,  0.2546,  0.1623,  0.0060, -0.1269, -0.3377, -0.0872],\n        [-0.1707, -0.1429, -0.0154, -0.1554, -0.1170,  0.3433, -0.0371, -0.3453],\n        [ 0.1945, -0.2354, -0.2804, -0.1889, -0.2888, -0.1748,  0.1856, -0.3064]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0417, -0.1434,  0.1136,  0.0397,  0.1725,  0.1608,  0.0062, -0.0742,\n         0.1097, -0.0032,  0.1669,  0.1611, -0.1243,  0.0258, -0.1698,  0.1165],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-9.7528e-02,  1.0829e-01,  1.0547e-01, -7.9513e-03,  5.8658e-02,\n          1.2187e-01, -1.0126e-01,  1.7061e-01, -2.8183e-02,  1.6890e-01,\n         -7.6074e-02,  1.4226e-01,  2.9508e-02, -1.0585e-01, -1.0700e-01,\n          7.5790e-02, -1.5694e-01, -1.4950e-02, -6.8431e-03, -6.5460e-03,\n          3.4570e-02, -1.2995e-01,  4.5788e-02, -1.3838e-01,  1.5030e-02,\n          1.3989e-01, -2.2614e-02,  1.5978e-01, -3.2048e-02,  8.8467e-02,\n          7.0314e-03,  4.5462e-02],\n        [-1.2844e-01, -1.0694e-01,  1.0219e-01, -1.5545e-01, -1.7735e-02,\n          1.1906e-01, -1.2631e-01, -4.6922e-02,  1.5509e-01, -5.2342e-02,\n          1.3858e-01,  6.5981e-02, -9.3964e-02, -1.0611e-01, -1.5025e-01,\n         -4.2504e-02, -1.2254e-01,  7.9279e-02, -5.9454e-02,  8.4600e-02,\n         -6.4887e-02,  1.1417e-01, -5.1183e-02, -1.3759e-01,  3.7511e-03,\n         -1.3497e-01,  1.0694e-01,  1.5130e-01,  1.7022e-01, -9.7746e-02,\n          1.1451e-01, -1.7675e-01],\n        [-9.8810e-02, -7.7499e-02,  3.1644e-02, -1.1364e-01, -1.7452e-01,\n          1.0574e-01,  9.1491e-02, -1.3604e-01,  3.8545e-02, -2.0761e-02,\n         -1.3460e-02,  1.1232e-02,  3.6136e-02,  6.7117e-02, -1.0080e-01,\n         -5.4993e-02, -6.3354e-02, -1.9014e-03, -9.8725e-02,  8.1446e-02,\n         -1.2397e-01,  1.4534e-01,  9.6055e-02, -5.6852e-02,  1.7525e-01,\n         -1.0225e-01, -1.1046e-01,  1.5628e-01,  1.6375e-01,  1.1008e-01,\n         -1.1971e-01,  1.3982e-01],\n        [ 1.3273e-01, -1.1739e-01, -1.5853e-01, -1.5540e-01, -1.4033e-01,\n         -2.9663e-02, -1.4857e-01,  6.5315e-04, -6.8758e-02,  3.7977e-02,\n          1.5255e-01, -8.1915e-02,  9.9338e-02, -1.3836e-02, -5.2394e-03,\n          1.6858e-01,  7.3779e-02, -1.4233e-02,  8.9282e-02, -1.2309e-01,\n          5.3710e-02,  4.5101e-02, -1.1419e-01, -2.2887e-02, -1.0060e-02,\n          1.5233e-01, -9.7077e-02,  6.4904e-02,  1.1071e-02,  1.8468e-02,\n         -3.5308e-02,  9.4616e-02],\n        [ 6.1754e-02,  1.7692e-02,  8.9137e-02, -1.3894e-01, -4.7286e-02,\n          1.7328e-01,  1.5358e-01,  7.1879e-03,  1.0790e-01, -2.1724e-03,\n         -1.5303e-02,  2.1715e-02,  1.2589e-01,  3.0417e-02, -3.5244e-02,\n          1.4833e-01, -1.4708e-01,  1.1369e-02,  7.5605e-02, -1.0157e-01,\n          9.1168e-03,  1.2282e-01, -1.7091e-01,  1.2259e-01, -1.4641e-01,\n          1.5041e-01, -1.3187e-01,  4.7949e-02,  9.2867e-02, -1.5697e-01,\n          1.9911e-02,  9.8702e-02],\n        [ 1.2269e-01, -5.3843e-02,  5.1648e-02,  4.2628e-02,  1.5150e-01,\n         -1.1620e-01,  4.3121e-02, -1.3284e-01,  6.7652e-02,  1.5627e-02,\n          4.3050e-02, -1.4315e-01,  3.3176e-02, -7.3225e-02,  1.5587e-01,\n         -1.2234e-02, -1.5440e-01,  1.5016e-01, -1.0169e-03,  8.2326e-02,\n         -1.1635e-01,  1.3884e-02,  3.8954e-02, -1.3978e-01, -1.0610e-02,\n         -1.6171e-01, -1.1701e-01, -1.2548e-01, -1.6761e-01,  1.2401e-01,\n          2.0492e-02,  1.3534e-01],\n        [ 9.7748e-02,  1.6986e-01,  2.9859e-02,  1.7110e-01,  9.0021e-02,\n          3.7593e-02,  2.2310e-02, -1.3076e-01,  4.4629e-03, -1.5982e-01,\n          1.3867e-01,  8.4191e-02, -4.3330e-02, -4.0426e-02, -1.0556e-01,\n         -1.1000e-01, -4.7239e-02, -1.7041e-01,  1.2258e-01,  6.4670e-02,\n         -5.1395e-02, -1.3591e-01, -5.0927e-02,  1.2289e-01,  1.4448e-01,\n         -7.4227e-02, -2.9615e-02, -1.6322e-01,  1.0500e-01,  3.7160e-02,\n          1.7051e-01,  1.4560e-01],\n        [-1.4615e-02, -1.6929e-01,  3.6152e-02,  1.6049e-03,  1.3910e-01,\n          9.4682e-02,  9.9608e-03, -1.8509e-03, -1.1282e-01,  1.0751e-01,\n         -8.8125e-02,  1.3639e-02, -9.6148e-02,  1.7124e-01, -6.9537e-02,\n         -2.5131e-02, -1.6183e-03, -3.2777e-02,  1.1322e-01,  1.1930e-01,\n         -6.6813e-02, -8.1353e-02, -1.4367e-01,  4.3407e-02,  5.7998e-02,\n         -5.5039e-02, -9.7468e-02,  1.6124e-01, -9.8944e-02,  2.3483e-04,\n          7.3512e-02,  8.9887e-02],\n        [-1.1671e-01, -1.0291e-02, -1.7246e-01, -1.6913e-01, -4.1845e-03,\n         -1.5826e-01, -1.0852e-02, -8.2137e-02, -1.7543e-01, -7.9466e-03,\n          1.6617e-01,  4.3214e-02,  1.0943e-02, -1.4395e-01, -2.4139e-02,\n         -1.9602e-02,  8.8029e-02,  7.6633e-03,  1.7454e-01, -1.0566e-01,\n         -7.2344e-02,  5.8276e-02, -1.1421e-01, -1.0403e-01,  1.1365e-01,\n         -2.2880e-03, -1.3954e-01, -1.5556e-01,  1.4331e-01, -1.8864e-02,\n         -7.9478e-02, -3.0098e-02],\n        [ 1.7517e-01,  3.1580e-02,  3.5911e-02, -1.1931e-01,  1.3303e-01,\n         -5.3790e-02, -1.1423e-01, -8.2966e-03, -1.0947e-01,  1.5504e-01,\n          7.0249e-02,  1.0625e-01, -7.5927e-02,  2.4662e-02,  1.2002e-01,\n          3.2091e-02,  7.7888e-02, -7.5627e-02,  3.6225e-02,  5.3244e-02,\n          5.9813e-02, -3.3705e-02,  1.3851e-01, -1.2382e-01, -3.6562e-02,\n          1.1609e-02, -8.2496e-03, -5.9849e-02, -3.5726e-02, -5.3354e-02,\n         -9.0107e-02, -3.3574e-02],\n        [ 2.1160e-02, -7.7976e-02,  3.5485e-02,  1.6009e-02, -1.6893e-01,\n          8.6873e-03, -1.5149e-01,  1.1739e-01, -1.7442e-01,  9.5303e-02,\n         -1.1408e-01,  1.2691e-01, -1.4797e-01, -3.6988e-02, -8.5361e-02,\n          1.4078e-01, -3.2775e-02,  1.4498e-01, -1.1277e-01,  8.1318e-02,\n         -1.6430e-01,  8.6149e-02, -6.1411e-02, -2.4864e-02, -6.4456e-02,\n         -1.7316e-01,  8.1834e-02, -2.3350e-02, -1.3286e-02,  1.5911e-01,\n         -1.3760e-01,  4.0087e-03],\n        [ 1.1938e-01, -3.9419e-02,  4.6189e-02, -1.0013e-01,  1.7099e-02,\n         -1.4405e-01,  7.9554e-03, -1.3771e-01, -5.1274e-02, -1.1330e-01,\n          1.1986e-01, -4.7539e-02,  1.2540e-01,  3.1242e-02,  5.3147e-02,\n         -5.6504e-02, -1.5460e-01,  8.4969e-02,  1.0005e-01, -1.7106e-01,\n          1.4646e-01,  2.5057e-02,  1.3308e-01, -1.4342e-01,  6.9446e-02,\n          8.1315e-02, -8.0913e-02,  5.5154e-02, -1.2864e-01, -8.9425e-02,\n         -9.4611e-02,  1.7664e-01],\n        [ 6.4288e-02, -1.4882e-01,  2.4387e-02,  1.6449e-01, -1.8947e-02,\n         -1.6849e-01,  3.0792e-02,  3.1033e-02,  1.4013e-01,  1.6890e-01,\n         -1.4369e-01,  1.0560e-01, -1.3732e-02,  1.6749e-01,  1.4629e-01,\n          1.3239e-01,  1.0040e-01,  3.8223e-02,  1.3699e-02, -1.6547e-01,\n         -7.0330e-02, -1.1277e-01,  3.5879e-04,  7.5495e-02, -1.5164e-01,\n          7.9425e-03,  2.4095e-03,  4.7472e-03,  9.2591e-02, -1.4427e-01,\n          1.1767e-01, -1.5885e-01],\n        [-8.0482e-02,  1.2217e-01, -1.3562e-01, -5.2695e-02,  1.6087e-01,\n         -2.2406e-02, -3.0064e-02,  5.1684e-03,  2.9765e-03,  1.7324e-01,\n         -1.5756e-01, -1.0596e-01, -3.0316e-02, -1.6252e-02, -9.9600e-02,\n          1.1673e-01,  8.6528e-02,  8.5993e-02, -1.6817e-01, -4.7438e-02,\n         -8.4954e-02, -1.4252e-01,  5.7459e-02,  9.5374e-02, -1.7277e-01,\n          1.6941e-01,  8.4513e-02, -1.9955e-02, -1.5493e-01,  1.4533e-01,\n          1.5491e-01,  5.6653e-02],\n        [ 2.8686e-02, -1.1800e-01, -6.5296e-02, -9.6958e-02,  5.0402e-02,\n         -8.8959e-02,  1.0380e-01,  5.4758e-02, -1.4835e-01,  1.5150e-01,\n         -1.4997e-01,  1.2565e-01, -9.2562e-03,  5.1997e-02, -1.5837e-01,\n          1.5701e-01, -1.5967e-01, -2.8901e-02,  6.8145e-02,  1.0937e-01,\n          6.5270e-02, -6.3836e-02,  1.3106e-01, -6.7589e-03,  9.7626e-02,\n          1.2553e-01,  8.9572e-03,  1.2093e-01, -1.0418e-01, -1.0053e-01,\n          1.6013e-01,  3.3532e-02],\n        [-6.4879e-02,  1.2857e-01, -7.7016e-02, -1.4501e-01,  1.4350e-05,\n         -1.4134e-01,  7.1059e-02, -6.3827e-03, -1.4090e-01, -1.8908e-02,\n         -3.9965e-02,  4.4424e-02,  4.7827e-02, -1.2805e-01,  8.1129e-02,\n          1.4264e-01, -1.0309e-01, -3.4715e-02, -1.0421e-01,  9.2579e-02,\n         -1.2154e-01,  1.2064e-01,  8.5125e-02, -6.7333e-02, -1.5195e-01,\n         -9.9815e-03, -1.0411e-01,  8.6155e-02,  1.5259e-01,  1.3851e-02,\n         -6.1112e-02, -1.0796e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1852, -0.0462, -0.0910, -0.1269, -0.2000,  0.2021,  0.1050,  0.0727],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0764,  0.1089, -0.0382, -0.2449,  0.0479, -0.0701, -0.0064, -0.1836,\n          0.2424,  0.1398, -0.1051, -0.2283, -0.1741,  0.0325,  0.0559, -0.1241],\n        [-0.0598,  0.2052, -0.2105, -0.0855,  0.0714,  0.2020,  0.2271, -0.1097,\n         -0.2102, -0.0620,  0.2294, -0.0096,  0.1354,  0.0773,  0.2061,  0.0325],\n        [-0.2205,  0.2014, -0.1190,  0.0201, -0.0033, -0.0982,  0.1238,  0.1408,\n         -0.0667,  0.0554,  0.2272,  0.0264, -0.2114,  0.1589, -0.1070, -0.0005],\n        [-0.1234,  0.1058,  0.0714, -0.0515,  0.0768,  0.1592, -0.0030, -0.0165,\n         -0.1627, -0.1893, -0.1258, -0.2096, -0.1449,  0.0200,  0.0465,  0.1149],\n        [-0.0828,  0.0053,  0.1771,  0.0328, -0.0048, -0.0366, -0.0388, -0.0125,\n         -0.0227,  0.2417,  0.0810,  0.0141, -0.0516,  0.1326,  0.2409, -0.0695],\n        [ 0.0207,  0.0598, -0.0482, -0.1449,  0.1946,  0.1845, -0.1787, -0.1185,\n         -0.2268, -0.0704, -0.1812,  0.1835,  0.2413,  0.1425, -0.0218, -0.1844],\n        [ 0.1605,  0.1337, -0.0452,  0.1170,  0.1075,  0.0268,  0.0119,  0.0659,\n         -0.1517, -0.1965,  0.0596,  0.2238,  0.1627, -0.1547, -0.2145,  0.2444],\n        [-0.1306, -0.1715, -0.1254, -0.2156, -0.1720,  0.1736, -0.0798,  0.1111,\n         -0.1207,  0.1419, -0.0371,  0.0593,  0.0006,  0.1419, -0.0467,  0.1313]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0232], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1801, -0.3084,  0.3287,  0.1963,  0.1759, -0.1587, -0.1092, -0.2079]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.001,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.001,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0575,  0.2052,  0.3067, -0.1474, -0.1327,  0.0652, -0.0819,  0.3092],\n        [ 0.0346,  0.0817,  0.0802, -0.1576,  0.3479, -0.1706, -0.2801, -0.1868],\n        [-0.3074, -0.0881, -0.0245, -0.2156,  0.0416, -0.0909,  0.2056, -0.1852],\n        [ 0.3258, -0.0126,  0.1191, -0.1848, -0.0075, -0.1748,  0.0008, -0.1047],\n        [-0.1071,  0.3274, -0.2274, -0.1625, -0.0012,  0.1808,  0.2175, -0.0673],\n        [-0.2235,  0.3302,  0.0186, -0.3426,  0.0876,  0.1978,  0.3190, -0.0744],\n        [ 0.0419,  0.0298,  0.2996,  0.0591, -0.3313, -0.1371,  0.3533,  0.2986],\n        [ 0.2550,  0.0209,  0.2189,  0.1389,  0.0996, -0.1135,  0.2674, -0.0890],\n        [-0.1003, -0.0859,  0.3242,  0.2085,  0.2919, -0.2773, -0.2322,  0.1481],\n        [-0.2758, -0.1730, -0.1075, -0.3487,  0.1546, -0.3284, -0.2046,  0.1518],\n        [-0.1920, -0.3292,  0.0436, -0.2191,  0.1844, -0.1298, -0.2214,  0.1530],\n        [-0.2489, -0.3246, -0.1720,  0.1444,  0.3414, -0.3490, -0.2548, -0.3436],\n        [ 0.0710, -0.0652, -0.1172,  0.1131, -0.0160, -0.2575,  0.0967, -0.2519],\n        [ 0.1318,  0.1351,  0.2625,  0.2640, -0.1569, -0.2910, -0.0081,  0.1949],\n        [-0.1920,  0.1521,  0.2498,  0.2120, -0.1879,  0.0018,  0.2401, -0.0502],\n        [ 0.2314, -0.3410, -0.0956, -0.2863, -0.0945, -0.1140, -0.3067, -0.1173],\n        [-0.1906,  0.2147, -0.1328,  0.1710, -0.3000,  0.2896,  0.2786,  0.0726],\n        [-0.2962, -0.2730, -0.2501, -0.3364, -0.2956,  0.3521,  0.1666, -0.2190],\n        [-0.2418, -0.2458, -0.0938, -0.0880,  0.1401, -0.3116,  0.2901, -0.1188],\n        [ 0.1569,  0.3232, -0.1307, -0.2282,  0.2607, -0.2026, -0.1926,  0.2227],\n        [ 0.3344,  0.2997,  0.0434, -0.1922,  0.0637, -0.0914,  0.1916, -0.2838],\n        [ 0.1684, -0.2631, -0.2166, -0.3378, -0.2621, -0.2724, -0.0830,  0.1276],\n        [-0.0542,  0.0017, -0.0990, -0.2443,  0.3431, -0.2359, -0.2114, -0.0931],\n        [-0.1950, -0.0112,  0.1117, -0.1015,  0.2714,  0.1191,  0.0891,  0.0390],\n        [ 0.2872,  0.1655,  0.0092, -0.3205, -0.1053,  0.1595,  0.0827, -0.3032],\n        [-0.2951,  0.2229, -0.3137, -0.1162,  0.1360,  0.1663, -0.0685, -0.3346],\n        [-0.2804,  0.0730, -0.0913, -0.3369, -0.0392, -0.1251, -0.2745,  0.0456],\n        [-0.3488,  0.3151, -0.2451,  0.2828,  0.1602,  0.1339, -0.2539, -0.0867],\n        [ 0.3010,  0.3021,  0.1269, -0.1821,  0.2248,  0.0607,  0.1274, -0.3070],\n        [ 0.0856, -0.3073,  0.2546,  0.1623,  0.0060, -0.1269, -0.3377, -0.0872],\n        [-0.1707, -0.1429, -0.0154, -0.1554, -0.1170,  0.3433, -0.0371, -0.3453],\n        [ 0.1945, -0.2354, -0.2804, -0.1889, -0.2888, -0.1748,  0.1856, -0.3064]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3171, -0.0236,  0.3141, -0.0816, -0.0420, -0.0752,  0.0411, -0.0934,\n         0.2987,  0.1637,  0.2147,  0.0573,  0.2737, -0.1470, -0.1954, -0.2366,\n        -0.1010, -0.0711,  0.1365, -0.2869, -0.3401,  0.1079,  0.1661, -0.1296,\n         0.1619, -0.3025, -0.1969,  0.3444, -0.1821,  0.3140, -0.0347, -0.0180],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-9.7528e-02,  1.0829e-01,  1.0547e-01, -7.9513e-03,  5.8658e-02,\n          1.2187e-01, -1.0126e-01,  1.7061e-01, -2.8183e-02,  1.6890e-01,\n         -7.6074e-02,  1.4226e-01,  2.9508e-02, -1.0585e-01, -1.0700e-01,\n          7.5790e-02, -1.5694e-01, -1.4950e-02, -6.8431e-03, -6.5460e-03,\n          3.4570e-02, -1.2995e-01,  4.5788e-02, -1.3838e-01,  1.5030e-02,\n          1.3989e-01, -2.2614e-02,  1.5978e-01, -3.2048e-02,  8.8467e-02,\n          7.0314e-03,  4.5462e-02],\n        [-1.2844e-01, -1.0694e-01,  1.0219e-01, -1.5545e-01, -1.7735e-02,\n          1.1906e-01, -1.2631e-01, -4.6922e-02,  1.5509e-01, -5.2342e-02,\n          1.3858e-01,  6.5981e-02, -9.3964e-02, -1.0611e-01, -1.5025e-01,\n         -4.2504e-02, -1.2254e-01,  7.9279e-02, -5.9454e-02,  8.4600e-02,\n         -6.4887e-02,  1.1417e-01, -5.1183e-02, -1.3759e-01,  3.7511e-03,\n         -1.3497e-01,  1.0694e-01,  1.5130e-01,  1.7022e-01, -9.7746e-02,\n          1.1451e-01, -1.7675e-01],\n        [-9.8810e-02, -7.7499e-02,  3.1644e-02, -1.1364e-01, -1.7452e-01,\n          1.0574e-01,  9.1491e-02, -1.3604e-01,  3.8545e-02, -2.0761e-02,\n         -1.3460e-02,  1.1232e-02,  3.6136e-02,  6.7117e-02, -1.0080e-01,\n         -5.4993e-02, -6.3354e-02, -1.9014e-03, -9.8725e-02,  8.1446e-02,\n         -1.2397e-01,  1.4534e-01,  9.6055e-02, -5.6852e-02,  1.7525e-01,\n         -1.0225e-01, -1.1046e-01,  1.5628e-01,  1.6375e-01,  1.1008e-01,\n         -1.1971e-01,  1.3982e-01],\n        [ 1.3273e-01, -1.1739e-01, -1.5853e-01, -1.5540e-01, -1.4033e-01,\n         -2.9663e-02, -1.4857e-01,  6.5315e-04, -6.8758e-02,  3.7977e-02,\n          1.5255e-01, -8.1915e-02,  9.9338e-02, -1.3836e-02, -5.2394e-03,\n          1.6858e-01,  7.3779e-02, -1.4233e-02,  8.9282e-02, -1.2309e-01,\n          5.3710e-02,  4.5101e-02, -1.1419e-01, -2.2887e-02, -1.0060e-02,\n          1.5233e-01, -9.7077e-02,  6.4904e-02,  1.1071e-02,  1.8468e-02,\n         -3.5308e-02,  9.4616e-02],\n        [ 6.1754e-02,  1.7692e-02,  8.9137e-02, -1.3894e-01, -4.7286e-02,\n          1.7328e-01,  1.5358e-01,  7.1879e-03,  1.0790e-01, -2.1724e-03,\n         -1.5303e-02,  2.1715e-02,  1.2589e-01,  3.0417e-02, -3.5244e-02,\n          1.4833e-01, -1.4708e-01,  1.1369e-02,  7.5605e-02, -1.0157e-01,\n          9.1168e-03,  1.2282e-01, -1.7091e-01,  1.2259e-01, -1.4641e-01,\n          1.5041e-01, -1.3187e-01,  4.7949e-02,  9.2867e-02, -1.5697e-01,\n          1.9911e-02,  9.8702e-02],\n        [ 1.2269e-01, -5.3843e-02,  5.1648e-02,  4.2628e-02,  1.5150e-01,\n         -1.1620e-01,  4.3121e-02, -1.3284e-01,  6.7652e-02,  1.5627e-02,\n          4.3050e-02, -1.4315e-01,  3.3176e-02, -7.3225e-02,  1.5587e-01,\n         -1.2234e-02, -1.5440e-01,  1.5016e-01, -1.0169e-03,  8.2326e-02,\n         -1.1635e-01,  1.3884e-02,  3.8954e-02, -1.3978e-01, -1.0610e-02,\n         -1.6171e-01, -1.1701e-01, -1.2548e-01, -1.6761e-01,  1.2401e-01,\n          2.0492e-02,  1.3534e-01],\n        [ 9.7748e-02,  1.6986e-01,  2.9859e-02,  1.7110e-01,  9.0021e-02,\n          3.7593e-02,  2.2310e-02, -1.3076e-01,  4.4629e-03, -1.5982e-01,\n          1.3867e-01,  8.4191e-02, -4.3330e-02, -4.0426e-02, -1.0556e-01,\n         -1.1000e-01, -4.7239e-02, -1.7041e-01,  1.2258e-01,  6.4670e-02,\n         -5.1395e-02, -1.3591e-01, -5.0927e-02,  1.2289e-01,  1.4448e-01,\n         -7.4227e-02, -2.9615e-02, -1.6322e-01,  1.0500e-01,  3.7160e-02,\n          1.7051e-01,  1.4560e-01],\n        [-1.4615e-02, -1.6929e-01,  3.6152e-02,  1.6049e-03,  1.3910e-01,\n          9.4682e-02,  9.9608e-03, -1.8509e-03, -1.1282e-01,  1.0751e-01,\n         -8.8125e-02,  1.3639e-02, -9.6148e-02,  1.7124e-01, -6.9537e-02,\n         -2.5131e-02, -1.6183e-03, -3.2777e-02,  1.1322e-01,  1.1930e-01,\n         -6.6813e-02, -8.1353e-02, -1.4367e-01,  4.3407e-02,  5.7998e-02,\n         -5.5039e-02, -9.7468e-02,  1.6124e-01, -9.8944e-02,  2.3483e-04,\n          7.3512e-02,  8.9887e-02],\n        [-1.1671e-01, -1.0291e-02, -1.7246e-01, -1.6913e-01, -4.1845e-03,\n         -1.5826e-01, -1.0852e-02, -8.2137e-02, -1.7543e-01, -7.9466e-03,\n          1.6617e-01,  4.3214e-02,  1.0943e-02, -1.4395e-01, -2.4139e-02,\n         -1.9602e-02,  8.8029e-02,  7.6633e-03,  1.7454e-01, -1.0566e-01,\n         -7.2344e-02,  5.8276e-02, -1.1421e-01, -1.0403e-01,  1.1365e-01,\n         -2.2880e-03, -1.3954e-01, -1.5556e-01,  1.4331e-01, -1.8864e-02,\n         -7.9478e-02, -3.0098e-02],\n        [ 1.7517e-01,  3.1580e-02,  3.5911e-02, -1.1931e-01,  1.3303e-01,\n         -5.3790e-02, -1.1423e-01, -8.2966e-03, -1.0947e-01,  1.5504e-01,\n          7.0249e-02,  1.0625e-01, -7.5927e-02,  2.4662e-02,  1.2002e-01,\n          3.2091e-02,  7.7888e-02, -7.5627e-02,  3.6225e-02,  5.3244e-02,\n          5.9813e-02, -3.3705e-02,  1.3851e-01, -1.2382e-01, -3.6562e-02,\n          1.1609e-02, -8.2496e-03, -5.9849e-02, -3.5726e-02, -5.3354e-02,\n         -9.0107e-02, -3.3574e-02],\n        [ 2.1160e-02, -7.7976e-02,  3.5485e-02,  1.6009e-02, -1.6893e-01,\n          8.6873e-03, -1.5149e-01,  1.1739e-01, -1.7442e-01,  9.5303e-02,\n         -1.1408e-01,  1.2691e-01, -1.4797e-01, -3.6988e-02, -8.5361e-02,\n          1.4078e-01, -3.2775e-02,  1.4498e-01, -1.1277e-01,  8.1318e-02,\n         -1.6430e-01,  8.6149e-02, -6.1411e-02, -2.4864e-02, -6.4456e-02,\n         -1.7316e-01,  8.1834e-02, -2.3350e-02, -1.3286e-02,  1.5911e-01,\n         -1.3760e-01,  4.0087e-03],\n        [ 1.1938e-01, -3.9419e-02,  4.6189e-02, -1.0013e-01,  1.7099e-02,\n         -1.4405e-01,  7.9554e-03, -1.3771e-01, -5.1274e-02, -1.1330e-01,\n          1.1986e-01, -4.7539e-02,  1.2540e-01,  3.1242e-02,  5.3147e-02,\n         -5.6504e-02, -1.5460e-01,  8.4969e-02,  1.0005e-01, -1.7106e-01,\n          1.4646e-01,  2.5057e-02,  1.3308e-01, -1.4342e-01,  6.9446e-02,\n          8.1315e-02, -8.0913e-02,  5.5154e-02, -1.2864e-01, -8.9425e-02,\n         -9.4611e-02,  1.7664e-01],\n        [ 6.4288e-02, -1.4882e-01,  2.4387e-02,  1.6449e-01, -1.8947e-02,\n         -1.6849e-01,  3.0792e-02,  3.1033e-02,  1.4013e-01,  1.6890e-01,\n         -1.4369e-01,  1.0560e-01, -1.3732e-02,  1.6749e-01,  1.4629e-01,\n          1.3239e-01,  1.0040e-01,  3.8223e-02,  1.3699e-02, -1.6547e-01,\n         -7.0330e-02, -1.1277e-01,  3.5879e-04,  7.5495e-02, -1.5164e-01,\n          7.9425e-03,  2.4095e-03,  4.7472e-03,  9.2591e-02, -1.4427e-01,\n          1.1767e-01, -1.5885e-01],\n        [-8.0482e-02,  1.2217e-01, -1.3562e-01, -5.2695e-02,  1.6087e-01,\n         -2.2406e-02, -3.0064e-02,  5.1684e-03,  2.9765e-03,  1.7324e-01,\n         -1.5756e-01, -1.0596e-01, -3.0316e-02, -1.6252e-02, -9.9600e-02,\n          1.1673e-01,  8.6528e-02,  8.5993e-02, -1.6817e-01, -4.7438e-02,\n         -8.4954e-02, -1.4252e-01,  5.7459e-02,  9.5374e-02, -1.7277e-01,\n          1.6941e-01,  8.4513e-02, -1.9955e-02, -1.5493e-01,  1.4533e-01,\n          1.5491e-01,  5.6653e-02],\n        [ 2.8686e-02, -1.1800e-01, -6.5296e-02, -9.6958e-02,  5.0402e-02,\n         -8.8959e-02,  1.0380e-01,  5.4758e-02, -1.4835e-01,  1.5150e-01,\n         -1.4997e-01,  1.2565e-01, -9.2562e-03,  5.1997e-02, -1.5837e-01,\n          1.5701e-01, -1.5967e-01, -2.8901e-02,  6.8145e-02,  1.0937e-01,\n          6.5270e-02, -6.3836e-02,  1.3106e-01, -6.7589e-03,  9.7626e-02,\n          1.2553e-01,  8.9572e-03,  1.2093e-01, -1.0418e-01, -1.0053e-01,\n          1.6013e-01,  3.3532e-02],\n        [-6.4879e-02,  1.2857e-01, -7.7016e-02, -1.4501e-01,  1.4350e-05,\n         -1.4134e-01,  7.1059e-02, -6.3827e-03, -1.4090e-01, -1.8908e-02,\n         -3.9965e-02,  4.4424e-02,  4.7827e-02, -1.2805e-01,  8.1129e-02,\n          1.4264e-01, -1.0309e-01, -3.4715e-02, -1.0421e-01,  9.2579e-02,\n         -1.2154e-01,  1.2064e-01,  8.5125e-02, -6.7333e-02, -1.5195e-01,\n         -9.9815e-03, -1.0411e-01,  8.6155e-02,  1.5259e-01,  1.3851e-02,\n         -6.1112e-02, -1.0796e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0417, -0.1434,  0.1136,  0.0397,  0.1725,  0.1608,  0.0062, -0.0742,\n         0.1097, -0.0032,  0.1669,  0.1611, -0.1243,  0.0258, -0.1698,  0.1165],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0764,  0.1089, -0.0382, -0.2449,  0.0479, -0.0701, -0.0064, -0.1836,\n          0.2424,  0.1398, -0.1051, -0.2283, -0.1741,  0.0325,  0.0559, -0.1241],\n        [-0.0598,  0.2052, -0.2105, -0.0855,  0.0714,  0.2020,  0.2271, -0.1097,\n         -0.2102, -0.0620,  0.2294, -0.0096,  0.1354,  0.0773,  0.2061,  0.0325],\n        [-0.2205,  0.2014, -0.1190,  0.0201, -0.0033, -0.0982,  0.1238,  0.1408,\n         -0.0667,  0.0554,  0.2272,  0.0264, -0.2114,  0.1589, -0.1070, -0.0005],\n        [-0.1234,  0.1058,  0.0714, -0.0515,  0.0768,  0.1592, -0.0030, -0.0165,\n         -0.1627, -0.1893, -0.1258, -0.2096, -0.1449,  0.0200,  0.0465,  0.1149],\n        [-0.0828,  0.0053,  0.1771,  0.0328, -0.0048, -0.0366, -0.0388, -0.0125,\n         -0.0227,  0.2417,  0.0810,  0.0141, -0.0516,  0.1326,  0.2409, -0.0695],\n        [ 0.0207,  0.0598, -0.0482, -0.1449,  0.1946,  0.1845, -0.1787, -0.1185,\n         -0.2268, -0.0704, -0.1812,  0.1835,  0.2413,  0.1425, -0.0218, -0.1844],\n        [ 0.1605,  0.1337, -0.0452,  0.1170,  0.1075,  0.0268,  0.0119,  0.0659,\n         -0.1517, -0.1965,  0.0596,  0.2238,  0.1627, -0.1547, -0.2145,  0.2444],\n        [-0.1306, -0.1715, -0.1254, -0.2156, -0.1720,  0.1736, -0.0798,  0.1111,\n         -0.1207,  0.1419, -0.0371,  0.0593,  0.0006,  0.1419, -0.0467,  0.1313]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1852, -0.0462, -0.0910, -0.1269, -0.2000,  0.2021,  0.1050,  0.0727],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1801, -0.3084,  0.3287,  0.1963,  0.1759, -0.1587, -0.1092, -0.2079]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0232], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000001E464B862F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	1,
            "_train_update_freq":	1,
            "_traj_per_epoch":	64,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001E42D3B8C40>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s280400000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s280400000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3171, -0.0236,  0.3141, -0.0816, -0.0420, -0.0752,  0.0411, -0.0934,\n         0.2987,  0.1637,  0.2147,  0.0573,  0.2737, -0.1470, -0.1954, -0.2366,\n        -0.1010, -0.0711,  0.1365, -0.2869, -0.3401,  0.1079,  0.1661, -0.1296,\n         0.1619, -0.3025, -0.1969,  0.3444, -0.1821,  0.3140, -0.0347, -0.0180],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0575,  0.2052,  0.3067, -0.1474, -0.1327,  0.0652, -0.0819,  0.3092],\n        [ 0.0346,  0.0817,  0.0802, -0.1576,  0.3479, -0.1706, -0.2801, -0.1868],\n        [-0.3074, -0.0881, -0.0245, -0.2156,  0.0416, -0.0909,  0.2056, -0.1852],\n        [ 0.3258, -0.0126,  0.1191, -0.1848, -0.0075, -0.1748,  0.0008, -0.1047],\n        [-0.1071,  0.3274, -0.2274, -0.1625, -0.0012,  0.1808,  0.2175, -0.0673],\n        [-0.2235,  0.3302,  0.0186, -0.3426,  0.0876,  0.1978,  0.3190, -0.0744],\n        [ 0.0419,  0.0298,  0.2996,  0.0591, -0.3313, -0.1371,  0.3533,  0.2986],\n        [ 0.2550,  0.0209,  0.2189,  0.1389,  0.0996, -0.1135,  0.2674, -0.0890],\n        [-0.1003, -0.0859,  0.3242,  0.2085,  0.2919, -0.2773, -0.2322,  0.1481],\n        [-0.2758, -0.1730, -0.1075, -0.3487,  0.1546, -0.3284, -0.2046,  0.1518],\n        [-0.1920, -0.3292,  0.0436, -0.2191,  0.1844, -0.1298, -0.2214,  0.1530],\n        [-0.2489, -0.3246, -0.1720,  0.1444,  0.3414, -0.3490, -0.2548, -0.3436],\n        [ 0.0710, -0.0652, -0.1172,  0.1131, -0.0160, -0.2575,  0.0967, -0.2519],\n        [ 0.1318,  0.1351,  0.2625,  0.2640, -0.1569, -0.2910, -0.0081,  0.1949],\n        [-0.1920,  0.1521,  0.2498,  0.2120, -0.1879,  0.0018,  0.2401, -0.0502],\n        [ 0.2314, -0.3410, -0.0956, -0.2863, -0.0945, -0.1140, -0.3067, -0.1173],\n        [-0.1906,  0.2147, -0.1328,  0.1710, -0.3000,  0.2896,  0.2786,  0.0726],\n        [-0.2962, -0.2730, -0.2501, -0.3364, -0.2956,  0.3521,  0.1666, -0.2190],\n        [-0.2418, -0.2458, -0.0938, -0.0880,  0.1401, -0.3116,  0.2901, -0.1188],\n        [ 0.1569,  0.3232, -0.1307, -0.2282,  0.2607, -0.2026, -0.1926,  0.2227],\n        [ 0.3344,  0.2997,  0.0434, -0.1922,  0.0637, -0.0914,  0.1916, -0.2838],\n        [ 0.1684, -0.2631, -0.2166, -0.3378, -0.2621, -0.2724, -0.0830,  0.1276],\n        [-0.0542,  0.0017, -0.0990, -0.2443,  0.3431, -0.2359, -0.2114, -0.0931],\n        [-0.1950, -0.0112,  0.1117, -0.1015,  0.2714,  0.1191,  0.0891,  0.0390],\n        [ 0.2872,  0.1655,  0.0092, -0.3205, -0.1053,  0.1595,  0.0827, -0.3032],\n        [-0.2951,  0.2229, -0.3137, -0.1162,  0.1360,  0.1663, -0.0685, -0.3346],\n        [-0.2804,  0.0730, -0.0913, -0.3369, -0.0392, -0.1251, -0.2745,  0.0456],\n        [-0.3488,  0.3151, -0.2451,  0.2828,  0.1602,  0.1339, -0.2539, -0.0867],\n        [ 0.3010,  0.3021,  0.1269, -0.1821,  0.2248,  0.0607,  0.1274, -0.3070],\n        [ 0.0856, -0.3073,  0.2546,  0.1623,  0.0060, -0.1269, -0.3377, -0.0872],\n        [-0.1707, -0.1429, -0.0154, -0.1554, -0.1170,  0.3433, -0.0371, -0.3453],\n        [ 0.1945, -0.2354, -0.2804, -0.1889, -0.2888, -0.1748,  0.1856, -0.3064]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0417, -0.1434,  0.1136,  0.0397,  0.1725,  0.1608,  0.0062, -0.0742,\n         0.1097, -0.0032,  0.1669,  0.1611, -0.1243,  0.0258, -0.1698,  0.1165],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-9.7528e-02,  1.0829e-01,  1.0547e-01, -7.9513e-03,  5.8658e-02,\n          1.2187e-01, -1.0126e-01,  1.7061e-01, -2.8183e-02,  1.6890e-01,\n         -7.6074e-02,  1.4226e-01,  2.9508e-02, -1.0585e-01, -1.0700e-01,\n          7.5790e-02, -1.5694e-01, -1.4950e-02, -6.8431e-03, -6.5460e-03,\n          3.4570e-02, -1.2995e-01,  4.5788e-02, -1.3838e-01,  1.5030e-02,\n          1.3989e-01, -2.2614e-02,  1.5978e-01, -3.2048e-02,  8.8467e-02,\n          7.0314e-03,  4.5462e-02],\n        [-1.2844e-01, -1.0694e-01,  1.0219e-01, -1.5545e-01, -1.7735e-02,\n          1.1906e-01, -1.2631e-01, -4.6922e-02,  1.5509e-01, -5.2342e-02,\n          1.3858e-01,  6.5981e-02, -9.3964e-02, -1.0611e-01, -1.5025e-01,\n         -4.2504e-02, -1.2254e-01,  7.9279e-02, -5.9454e-02,  8.4600e-02,\n         -6.4887e-02,  1.1417e-01, -5.1183e-02, -1.3759e-01,  3.7511e-03,\n         -1.3497e-01,  1.0694e-01,  1.5130e-01,  1.7022e-01, -9.7746e-02,\n          1.1451e-01, -1.7675e-01],\n        [-9.8810e-02, -7.7499e-02,  3.1644e-02, -1.1364e-01, -1.7452e-01,\n          1.0574e-01,  9.1491e-02, -1.3604e-01,  3.8545e-02, -2.0761e-02,\n         -1.3460e-02,  1.1232e-02,  3.6136e-02,  6.7117e-02, -1.0080e-01,\n         -5.4993e-02, -6.3354e-02, -1.9014e-03, -9.8725e-02,  8.1446e-02,\n         -1.2397e-01,  1.4534e-01,  9.6055e-02, -5.6852e-02,  1.7525e-01,\n         -1.0225e-01, -1.1046e-01,  1.5628e-01,  1.6375e-01,  1.1008e-01,\n         -1.1971e-01,  1.3982e-01],\n        [ 1.3273e-01, -1.1739e-01, -1.5853e-01, -1.5540e-01, -1.4033e-01,\n         -2.9663e-02, -1.4857e-01,  6.5315e-04, -6.8758e-02,  3.7977e-02,\n          1.5255e-01, -8.1915e-02,  9.9338e-02, -1.3836e-02, -5.2394e-03,\n          1.6858e-01,  7.3779e-02, -1.4233e-02,  8.9282e-02, -1.2309e-01,\n          5.3710e-02,  4.5101e-02, -1.1419e-01, -2.2887e-02, -1.0060e-02,\n          1.5233e-01, -9.7077e-02,  6.4904e-02,  1.1071e-02,  1.8468e-02,\n         -3.5308e-02,  9.4616e-02],\n        [ 6.1754e-02,  1.7692e-02,  8.9137e-02, -1.3894e-01, -4.7286e-02,\n          1.7328e-01,  1.5358e-01,  7.1879e-03,  1.0790e-01, -2.1724e-03,\n         -1.5303e-02,  2.1715e-02,  1.2589e-01,  3.0417e-02, -3.5244e-02,\n          1.4833e-01, -1.4708e-01,  1.1369e-02,  7.5605e-02, -1.0157e-01,\n          9.1168e-03,  1.2282e-01, -1.7091e-01,  1.2259e-01, -1.4641e-01,\n          1.5041e-01, -1.3187e-01,  4.7949e-02,  9.2867e-02, -1.5697e-01,\n          1.9911e-02,  9.8702e-02],\n        [ 1.2269e-01, -5.3843e-02,  5.1648e-02,  4.2628e-02,  1.5150e-01,\n         -1.1620e-01,  4.3121e-02, -1.3284e-01,  6.7652e-02,  1.5627e-02,\n          4.3050e-02, -1.4315e-01,  3.3176e-02, -7.3225e-02,  1.5587e-01,\n         -1.2234e-02, -1.5440e-01,  1.5016e-01, -1.0169e-03,  8.2326e-02,\n         -1.1635e-01,  1.3884e-02,  3.8954e-02, -1.3978e-01, -1.0610e-02,\n         -1.6171e-01, -1.1701e-01, -1.2548e-01, -1.6761e-01,  1.2401e-01,\n          2.0492e-02,  1.3534e-01],\n        [ 9.7748e-02,  1.6986e-01,  2.9859e-02,  1.7110e-01,  9.0021e-02,\n          3.7593e-02,  2.2310e-02, -1.3076e-01,  4.4629e-03, -1.5982e-01,\n          1.3867e-01,  8.4191e-02, -4.3330e-02, -4.0426e-02, -1.0556e-01,\n         -1.1000e-01, -4.7239e-02, -1.7041e-01,  1.2258e-01,  6.4670e-02,\n         -5.1395e-02, -1.3591e-01, -5.0927e-02,  1.2289e-01,  1.4448e-01,\n         -7.4227e-02, -2.9615e-02, -1.6322e-01,  1.0500e-01,  3.7160e-02,\n          1.7051e-01,  1.4560e-01],\n        [-1.4615e-02, -1.6929e-01,  3.6152e-02,  1.6049e-03,  1.3910e-01,\n          9.4682e-02,  9.9608e-03, -1.8509e-03, -1.1282e-01,  1.0751e-01,\n         -8.8125e-02,  1.3639e-02, -9.6148e-02,  1.7124e-01, -6.9537e-02,\n         -2.5131e-02, -1.6183e-03, -3.2777e-02,  1.1322e-01,  1.1930e-01,\n         -6.6813e-02, -8.1353e-02, -1.4367e-01,  4.3407e-02,  5.7998e-02,\n         -5.5039e-02, -9.7468e-02,  1.6124e-01, -9.8944e-02,  2.3483e-04,\n          7.3512e-02,  8.9887e-02],\n        [-1.1671e-01, -1.0291e-02, -1.7246e-01, -1.6913e-01, -4.1845e-03,\n         -1.5826e-01, -1.0852e-02, -8.2137e-02, -1.7543e-01, -7.9466e-03,\n          1.6617e-01,  4.3214e-02,  1.0943e-02, -1.4395e-01, -2.4139e-02,\n         -1.9602e-02,  8.8029e-02,  7.6633e-03,  1.7454e-01, -1.0566e-01,\n         -7.2344e-02,  5.8276e-02, -1.1421e-01, -1.0403e-01,  1.1365e-01,\n         -2.2880e-03, -1.3954e-01, -1.5556e-01,  1.4331e-01, -1.8864e-02,\n         -7.9478e-02, -3.0098e-02],\n        [ 1.7517e-01,  3.1580e-02,  3.5911e-02, -1.1931e-01,  1.3303e-01,\n         -5.3790e-02, -1.1423e-01, -8.2966e-03, -1.0947e-01,  1.5504e-01,\n          7.0249e-02,  1.0625e-01, -7.5927e-02,  2.4662e-02,  1.2002e-01,\n          3.2091e-02,  7.7888e-02, -7.5627e-02,  3.6225e-02,  5.3244e-02,\n          5.9813e-02, -3.3705e-02,  1.3851e-01, -1.2382e-01, -3.6562e-02,\n          1.1609e-02, -8.2496e-03, -5.9849e-02, -3.5726e-02, -5.3354e-02,\n         -9.0107e-02, -3.3574e-02],\n        [ 2.1160e-02, -7.7976e-02,  3.5485e-02,  1.6009e-02, -1.6893e-01,\n          8.6873e-03, -1.5149e-01,  1.1739e-01, -1.7442e-01,  9.5303e-02,\n         -1.1408e-01,  1.2691e-01, -1.4797e-01, -3.6988e-02, -8.5361e-02,\n          1.4078e-01, -3.2775e-02,  1.4498e-01, -1.1277e-01,  8.1318e-02,\n         -1.6430e-01,  8.6149e-02, -6.1411e-02, -2.4864e-02, -6.4456e-02,\n         -1.7316e-01,  8.1834e-02, -2.3350e-02, -1.3286e-02,  1.5911e-01,\n         -1.3760e-01,  4.0087e-03],\n        [ 1.1938e-01, -3.9419e-02,  4.6189e-02, -1.0013e-01,  1.7099e-02,\n         -1.4405e-01,  7.9554e-03, -1.3771e-01, -5.1274e-02, -1.1330e-01,\n          1.1986e-01, -4.7539e-02,  1.2540e-01,  3.1242e-02,  5.3147e-02,\n         -5.6504e-02, -1.5460e-01,  8.4969e-02,  1.0005e-01, -1.7106e-01,\n          1.4646e-01,  2.5057e-02,  1.3308e-01, -1.4342e-01,  6.9446e-02,\n          8.1315e-02, -8.0913e-02,  5.5154e-02, -1.2864e-01, -8.9425e-02,\n         -9.4611e-02,  1.7664e-01],\n        [ 6.4288e-02, -1.4882e-01,  2.4387e-02,  1.6449e-01, -1.8947e-02,\n         -1.6849e-01,  3.0792e-02,  3.1033e-02,  1.4013e-01,  1.6890e-01,\n         -1.4369e-01,  1.0560e-01, -1.3732e-02,  1.6749e-01,  1.4629e-01,\n          1.3239e-01,  1.0040e-01,  3.8223e-02,  1.3699e-02, -1.6547e-01,\n         -7.0330e-02, -1.1277e-01,  3.5879e-04,  7.5495e-02, -1.5164e-01,\n          7.9425e-03,  2.4095e-03,  4.7472e-03,  9.2591e-02, -1.4427e-01,\n          1.1767e-01, -1.5885e-01],\n        [-8.0482e-02,  1.2217e-01, -1.3562e-01, -5.2695e-02,  1.6087e-01,\n         -2.2406e-02, -3.0064e-02,  5.1684e-03,  2.9765e-03,  1.7324e-01,\n         -1.5756e-01, -1.0596e-01, -3.0316e-02, -1.6252e-02, -9.9600e-02,\n          1.1673e-01,  8.6528e-02,  8.5993e-02, -1.6817e-01, -4.7438e-02,\n         -8.4954e-02, -1.4252e-01,  5.7459e-02,  9.5374e-02, -1.7277e-01,\n          1.6941e-01,  8.4513e-02, -1.9955e-02, -1.5493e-01,  1.4533e-01,\n          1.5491e-01,  5.6653e-02],\n        [ 2.8686e-02, -1.1800e-01, -6.5296e-02, -9.6958e-02,  5.0402e-02,\n         -8.8959e-02,  1.0380e-01,  5.4758e-02, -1.4835e-01,  1.5150e-01,\n         -1.4997e-01,  1.2565e-01, -9.2562e-03,  5.1997e-02, -1.5837e-01,\n          1.5701e-01, -1.5967e-01, -2.8901e-02,  6.8145e-02,  1.0937e-01,\n          6.5270e-02, -6.3836e-02,  1.3106e-01, -6.7589e-03,  9.7626e-02,\n          1.2553e-01,  8.9572e-03,  1.2093e-01, -1.0418e-01, -1.0053e-01,\n          1.6013e-01,  3.3532e-02],\n        [-6.4879e-02,  1.2857e-01, -7.7016e-02, -1.4501e-01,  1.4350e-05,\n         -1.4134e-01,  7.1059e-02, -6.3827e-03, -1.4090e-01, -1.8908e-02,\n         -3.9965e-02,  4.4424e-02,  4.7827e-02, -1.2805e-01,  8.1129e-02,\n          1.4264e-01, -1.0309e-01, -3.4715e-02, -1.0421e-01,  9.2579e-02,\n         -1.2154e-01,  1.2064e-01,  8.5125e-02, -6.7333e-02, -1.5195e-01,\n         -9.9815e-03, -1.0411e-01,  8.6155e-02,  1.5259e-01,  1.3851e-02,\n         -6.1112e-02, -1.0796e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1852, -0.0462, -0.0910, -0.1269, -0.2000,  0.2021,  0.1050,  0.0727],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0764,  0.1089, -0.0382, -0.2449,  0.0479, -0.0701, -0.0064, -0.1836,\n          0.2424,  0.1398, -0.1051, -0.2283, -0.1741,  0.0325,  0.0559, -0.1241],\n        [-0.0598,  0.2052, -0.2105, -0.0855,  0.0714,  0.2020,  0.2271, -0.1097,\n         -0.2102, -0.0620,  0.2294, -0.0096,  0.1354,  0.0773,  0.2061,  0.0325],\n        [-0.2205,  0.2014, -0.1190,  0.0201, -0.0033, -0.0982,  0.1238,  0.1408,\n         -0.0667,  0.0554,  0.2272,  0.0264, -0.2114,  0.1589, -0.1070, -0.0005],\n        [-0.1234,  0.1058,  0.0714, -0.0515,  0.0768,  0.1592, -0.0030, -0.0165,\n         -0.1627, -0.1893, -0.1258, -0.2096, -0.1449,  0.0200,  0.0465,  0.1149],\n        [-0.0828,  0.0053,  0.1771,  0.0328, -0.0048, -0.0366, -0.0388, -0.0125,\n         -0.0227,  0.2417,  0.0810,  0.0141, -0.0516,  0.1326,  0.2409, -0.0695],\n        [ 0.0207,  0.0598, -0.0482, -0.1449,  0.1946,  0.1845, -0.1787, -0.1185,\n         -0.2268, -0.0704, -0.1812,  0.1835,  0.2413,  0.1425, -0.0218, -0.1844],\n        [ 0.1605,  0.1337, -0.0452,  0.1170,  0.1075,  0.0268,  0.0119,  0.0659,\n         -0.1517, -0.1965,  0.0596,  0.2238,  0.1627, -0.1547, -0.2145,  0.2444],\n        [-0.1306, -0.1715, -0.1254, -0.2156, -0.1720,  0.1736, -0.0798,  0.1111,\n         -0.1207,  0.1419, -0.0371,  0.0593,  0.0006,  0.1419, -0.0467,  0.1313]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0232], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1801, -0.3084,  0.3287,  0.1963,  0.1759, -0.1587, -0.1092, -0.2079]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	1,
    "train_update_freq":	1,
    "traj_per_epoch":	64
}