{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	64,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s294480000"
    },
    "q_lr":	0.0005,
    "seed":	294480000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000001B48E3890F0>":	{
            "_act_dim":	1,
            "_batch_size":	64,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1514,  0.1102,  0.2476, -0.2723, -0.1815, -0.2830,  0.1047, -0.1841,\n         0.0866,  0.3366,  0.3268, -0.3472, -0.2825, -0.2005,  0.2088,  0.2124,\n         0.2427,  0.0585, -0.2891,  0.2318,  0.1893,  0.2438, -0.2284, -0.1039,\n        -0.1496, -0.0463,  0.1679, -0.2635,  0.0281,  0.2704,  0.2327,  0.2142],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1504, -0.1510, -0.3531, -0.0709,  0.0696, -0.1486, -0.1320,  0.0918],\n        [ 0.3418,  0.0613,  0.0852, -0.1239,  0.3471, -0.1703,  0.2029, -0.1189],\n        [ 0.0956,  0.3220, -0.1236,  0.2222,  0.1389, -0.0889,  0.1800,  0.3448],\n        [-0.2469,  0.2215,  0.1619, -0.0704,  0.0371,  0.0639, -0.0359,  0.0338],\n        [ 0.3034,  0.0496,  0.0267, -0.2081, -0.1042,  0.3267, -0.3411, -0.0185],\n        [ 0.2559, -0.0297,  0.0063, -0.2717, -0.2573, -0.1894,  0.2360, -0.3258],\n        [-0.2458,  0.1367,  0.0651,  0.1632, -0.2612, -0.0484, -0.2817, -0.1072],\n        [ 0.0322, -0.2107, -0.0526,  0.3471,  0.0661,  0.2013,  0.3384,  0.1237],\n        [-0.2642, -0.1844,  0.1164, -0.1687,  0.2060, -0.0353, -0.0437, -0.2623],\n        [ 0.0935,  0.3364, -0.0366, -0.1199, -0.1953, -0.1483, -0.1726, -0.0052],\n        [ 0.0475, -0.0847, -0.0097,  0.2421, -0.2151,  0.0134, -0.3452, -0.0052],\n        [ 0.1418,  0.0700,  0.0260, -0.2411,  0.2295,  0.1528,  0.1504,  0.2582],\n        [ 0.1654,  0.1380, -0.3513,  0.1087,  0.2732,  0.0316, -0.3114,  0.2832],\n        [-0.0245,  0.2130, -0.2834, -0.0978,  0.3515,  0.3444, -0.1849,  0.1282],\n        [ 0.1977, -0.1653, -0.2438,  0.2990, -0.1668, -0.0913, -0.1313,  0.1675],\n        [-0.2852, -0.1701,  0.3340, -0.2693,  0.0008,  0.2718,  0.1334,  0.1512],\n        [ 0.0421,  0.1520,  0.3190,  0.3470, -0.2882,  0.2738,  0.1534, -0.0866],\n        [-0.0077, -0.1197, -0.2964, -0.2671, -0.1662,  0.2933, -0.3469, -0.1580],\n        [-0.2795, -0.0316, -0.1992, -0.0996, -0.3412, -0.3413,  0.1290,  0.2010],\n        [ 0.3017,  0.1559,  0.1436, -0.2677,  0.2633, -0.1000, -0.1164,  0.3182],\n        [ 0.1823, -0.1949, -0.3235, -0.1084, -0.1756,  0.1779,  0.2769,  0.0456],\n        [ 0.2397, -0.0894, -0.3159,  0.2998,  0.2115,  0.1886,  0.1869, -0.0431],\n        [-0.3533, -0.1611,  0.0384, -0.3257, -0.3058,  0.3484,  0.1643, -0.2771],\n        [ 0.0984,  0.1143, -0.1827,  0.1858, -0.2777, -0.1083, -0.1203, -0.1790],\n        [ 0.2204, -0.0365, -0.1339, -0.2800,  0.0091,  0.3370,  0.0556,  0.1728],\n        [ 0.2811,  0.1698, -0.3441,  0.2110,  0.2694, -0.2120, -0.0172, -0.2404],\n        [ 0.2715, -0.0217, -0.2963,  0.0937, -0.2760,  0.2513, -0.1669,  0.1578],\n        [-0.1351, -0.2269, -0.3198, -0.0533, -0.3329, -0.2894, -0.2205, -0.3181],\n        [-0.1711, -0.3031,  0.1096, -0.2830, -0.1138,  0.2127, -0.3197,  0.2312],\n        [-0.3090,  0.0692, -0.1325,  0.3110, -0.3095, -0.2736,  0.1052, -0.0960],\n        [ 0.1229, -0.1410,  0.0192, -0.1979, -0.1974,  0.0782,  0.0778, -0.1587],\n        [ 0.0302, -0.0609, -0.1187,  0.1641,  0.3388,  0.1221,  0.1923, -0.0616]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0107,  0.0152,  0.0897, -0.1407,  0.1611,  0.1236, -0.1259,  0.1100,\n         0.1492, -0.1672, -0.1378, -0.0500,  0.1357, -0.1665,  0.0436,  0.1304],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-4.6136e-02, -3.3856e-02,  1.5010e-01, -1.0260e-01,  2.4973e-02,\n          1.5749e-01,  7.1849e-02,  1.1889e-01, -1.6661e-01,  1.4487e-01,\n         -8.9104e-02,  8.3411e-02, -1.6773e-01,  6.9041e-02,  1.1240e-01,\n          1.9819e-02, -2.8597e-02, -7.8599e-02, -4.1526e-02, -1.3132e-01,\n         -1.0269e-01, -1.0232e-01,  2.5378e-02,  8.6007e-02,  9.4377e-02,\n         -1.7574e-01, -1.5588e-02, -1.3182e-01, -6.9192e-02, -5.2430e-02,\n          1.6744e-01,  1.4248e-01],\n        [-1.3878e-01,  1.2433e-01,  7.8194e-02, -5.4030e-02,  1.1590e-01,\n         -9.3707e-02, -7.4158e-02,  4.0244e-02, -9.1156e-02,  8.2639e-02,\n          1.5689e-01, -1.5001e-01,  1.0902e-01, -5.1072e-02,  8.4892e-02,\n          1.1882e-01, -5.2437e-03,  1.0367e-01,  1.0735e-01, -1.5971e-01,\n         -7.7241e-02, -9.1686e-02, -3.3266e-02, -5.2938e-02,  1.5454e-01,\n         -1.2491e-01, -1.1318e-01, -3.3739e-02, -1.3238e-01, -3.7040e-02,\n          7.6590e-02,  6.4223e-02],\n        [ 1.5818e-01, -1.6548e-01,  4.2573e-02,  7.6135e-02,  1.3511e-01,\n          1.7151e-01,  3.9925e-02,  1.3367e-01,  5.5972e-02, -1.0950e-01,\n         -1.4372e-01, -1.0185e-01, -4.5481e-02,  1.3456e-01,  1.5418e-01,\n          9.4353e-02, -1.9147e-02,  1.4775e-01,  1.2069e-01, -6.6908e-02,\n         -2.0627e-02,  5.5698e-02, -1.3640e-01, -1.4082e-01, -3.7057e-02,\n         -1.5262e-01, -1.1489e-01, -1.6262e-01, -1.6113e-01, -2.1830e-02,\n         -7.6026e-02, -1.3011e-01],\n        [-1.1611e-01,  1.7300e-01,  4.7949e-02,  8.5925e-02, -1.6854e-01,\n          9.7315e-02, -9.0526e-02,  1.1337e-01, -1.7605e-01,  4.8591e-02,\n          1.0652e-02, -1.1058e-01, -1.0894e-01,  8.3199e-02,  6.3171e-02,\n          3.6020e-02, -1.5945e-01, -2.3042e-02, -7.1594e-02,  3.9358e-02,\n         -2.8520e-02, -4.3741e-02,  1.7319e-01, -4.5228e-02,  2.6301e-02,\n          8.8166e-02,  8.7492e-02,  1.3022e-01, -1.1841e-01,  7.2019e-02,\n         -1.7402e-01, -1.2568e-01],\n        [ 2.3365e-02, -1.6623e-01, -1.1448e-01,  1.7416e-01,  7.9219e-02,\n         -9.0845e-02,  1.0365e-01,  1.0137e-01, -1.1183e-01,  4.7566e-03,\n          1.6239e-02, -1.2838e-01,  8.8279e-02,  7.6325e-03, -1.6815e-01,\n          1.2318e-01, -1.6868e-03, -1.4817e-01, -1.0718e-01,  1.6673e-01,\n         -1.6435e-01,  1.2673e-01, -7.6000e-02, -5.6626e-02, -1.3162e-01,\n          4.3197e-02, -7.2652e-02, -9.2914e-02, -4.8104e-02,  8.6632e-02,\n         -5.3543e-03,  7.5030e-02],\n        [-1.7388e-01,  8.9873e-02,  1.7467e-01, -1.3255e-04, -6.6354e-02,\n          1.5656e-01,  5.8711e-02, -2.7549e-02, -6.4653e-03, -6.9467e-02,\n          1.1386e-01,  1.6869e-01,  8.7977e-02, -5.4120e-02, -1.0940e-01,\n         -2.0475e-03, -1.7386e-01,  1.2929e-01, -1.5062e-02,  1.0447e-01,\n         -8.2093e-02,  4.6073e-02,  1.6221e-03, -5.8244e-02,  9.1917e-02,\n          8.1709e-02,  5.6089e-02, -9.6491e-02,  1.2565e-01,  1.4416e-01,\n          4.7516e-02,  7.6213e-02],\n        [ 1.3093e-01, -1.6999e-01,  5.0417e-02, -1.1616e-02,  1.0748e-01,\n          1.0060e-02, -1.7584e-01,  1.0103e-01, -6.5672e-02, -4.9613e-02,\n          1.2665e-01,  1.0157e-01, -1.2073e-02,  5.6360e-02,  1.1904e-01,\n          1.5004e-01, -1.6237e-01,  1.4865e-01,  5.7216e-02, -4.1112e-02,\n         -1.0143e-01,  1.2517e-01,  1.6349e-01,  8.1586e-02, -1.6392e-01,\n         -1.7653e-02, -1.2166e-01,  7.0617e-02,  5.3217e-02, -3.0256e-02,\n         -1.4118e-01,  1.3869e-01],\n        [-1.2137e-01,  6.0630e-02, -1.4842e-01,  1.5828e-01,  5.7753e-02,\n          1.2861e-01,  9.3777e-02, -8.9142e-02,  5.1448e-02,  1.1374e-01,\n          1.4590e-01,  2.1816e-02,  3.3073e-02,  1.3809e-01, -1.9649e-02,\n          1.0581e-01, -5.8043e-02,  1.6010e-01, -1.2279e-01,  8.0030e-02,\n         -5.2363e-02,  1.5684e-02, -1.4067e-01, -1.1154e-01, -1.2116e-01,\n         -6.1479e-02, -1.2231e-01,  2.3634e-02, -1.3841e-01,  3.1772e-03,\n          1.0032e-01,  7.0925e-02],\n        [ 7.9771e-02,  1.5970e-01,  1.8528e-02, -1.1366e-02, -4.3284e-02,\n          8.4912e-02, -1.2151e-01,  1.1091e-01,  1.1514e-01, -1.2606e-01,\n         -5.9327e-02, -8.1933e-02, -2.4406e-02, -3.9634e-02, -1.5130e-01,\n         -1.0121e-01, -5.0639e-02,  3.4238e-02,  1.2575e-01,  3.3206e-02,\n         -1.7109e-01, -1.7677e-01,  1.7469e-01,  1.5630e-01, -1.4951e-01,\n          6.8542e-02,  1.4744e-01, -1.4661e-01, -1.7059e-01,  4.8869e-02,\n         -1.3693e-01, -2.3131e-02],\n        [-1.3479e-02,  8.1169e-02,  1.3348e-01, -1.6970e-01, -1.2567e-01,\n         -7.8464e-02,  9.5620e-02,  9.5595e-02, -7.6280e-02, -5.0361e-02,\n         -1.8868e-02, -1.1593e-01,  1.2573e-01, -1.4888e-01,  1.4624e-01,\n          1.5281e-01,  6.7574e-02, -1.6890e-01, -2.6615e-03,  1.0344e-01,\n          8.5702e-02,  6.8399e-03, -1.0252e-01, -2.2616e-02,  5.0079e-02,\n          9.5563e-02, -6.3723e-02, -2.0881e-02, -8.3529e-02,  7.7909e-02,\n          1.6868e-01, -1.2447e-01],\n        [ 1.0590e-01, -1.4016e-01,  1.4050e-01,  1.1235e-02,  6.7979e-02,\n          1.0805e-01,  8.3450e-02, -1.4714e-01,  9.5328e-02,  1.6060e-02,\n         -9.6418e-02, -1.2147e-01,  6.2538e-02,  5.6715e-02,  8.0553e-02,\n          5.4919e-02,  1.5299e-01, -1.6827e-01,  1.4874e-01, -1.1088e-01,\n         -1.1581e-01, -1.7467e-01, -1.6441e-01,  7.2184e-02,  1.7100e-01,\n          5.9524e-02,  1.4739e-01, -9.2840e-02,  1.3352e-01,  1.0162e-01,\n         -4.3053e-02,  1.7005e-02],\n        [-1.2520e-01, -1.1688e-01, -1.2441e-01, -1.5359e-01, -1.0763e-01,\n         -2.2534e-03, -2.7324e-02, -8.8524e-02,  4.5079e-02,  1.0346e-01,\n         -1.1343e-01, -8.5597e-03, -8.6313e-02,  7.6822e-02, -1.0431e-03,\n          1.1694e-02,  4.6278e-02,  1.5321e-01,  7.9138e-02,  1.6966e-01,\n         -9.5139e-02, -8.0852e-02, -1.6719e-01,  1.7246e-01, -8.3328e-02,\n         -6.5515e-02,  1.0171e-01, -3.4455e-02,  1.6394e-01, -5.8880e-02,\n         -8.2527e-02, -1.0402e-01],\n        [ 1.4189e-01,  1.4099e-01, -6.3490e-02, -1.0805e-01,  9.2202e-03,\n         -2.1076e-02, -3.7439e-03,  9.9987e-03, -5.0165e-02, -1.6776e-01,\n          8.9807e-02,  1.7669e-01,  1.7280e-01, -6.6710e-02,  1.3151e-02,\n         -1.0351e-01, -1.0494e-01,  5.9597e-02,  1.2704e-01,  3.7753e-02,\n          1.3674e-01, -1.6706e-01, -9.1301e-02,  9.2258e-03, -3.8424e-02,\n          1.6818e-01, -1.7539e-01,  1.1668e-03, -1.0916e-01, -1.3576e-01,\n          1.0585e-01,  1.2277e-01],\n        [-1.5972e-01,  7.1594e-02, -5.9334e-02,  2.5116e-04,  1.2357e-01,\n         -9.0826e-02, -1.1842e-02,  5.1353e-02, -9.5449e-02, -1.3174e-01,\n          3.9265e-02,  8.2646e-02,  5.6372e-02, -5.3022e-02, -1.2839e-01,\n          5.8147e-02,  3.6025e-02, -1.6625e-02,  2.3568e-02,  9.8857e-02,\n         -1.1966e-01, -7.8487e-02, -4.5243e-02, -9.5716e-02, -7.1614e-02,\n         -1.7673e-01,  1.2784e-01, -1.1985e-02, -1.3327e-01, -1.4174e-01,\n         -1.7353e-01, -1.9720e-03],\n        [ 2.7066e-02, -1.1252e-02,  6.3741e-02,  1.5428e-01, -8.6089e-02,\n          1.2226e-01, -1.2783e-01, -8.3742e-02,  2.0750e-02, -1.2612e-02,\n         -1.0496e-01,  6.4012e-02, -8.5684e-02,  1.1971e-01, -9.3099e-02,\n          7.9199e-02, -1.6849e-01, -1.5623e-01,  9.2906e-02,  3.7644e-02,\n         -1.5169e-01,  1.1352e-01,  1.7359e-01,  5.9039e-02, -4.4724e-02,\n          1.4820e-01, -2.7027e-02,  1.4689e-01, -2.2310e-02, -1.0570e-01,\n          9.7544e-02, -9.6360e-02],\n        [ 1.6809e-01,  8.6789e-02, -6.9273e-02,  1.6124e-01, -1.5946e-01,\n         -1.6713e-01, -9.7758e-02,  1.3527e-01,  8.7889e-02, -1.7441e-01,\n          7.7270e-02, -1.2511e-01,  5.6706e-02, -1.4890e-02, -4.6377e-02,\n          1.1877e-01,  2.0766e-04,  4.8908e-02,  1.2571e-01,  1.5807e-01,\n          1.1492e-01, -1.0621e-02,  8.6889e-02,  7.5853e-02, -1.4016e-01,\n         -1.5224e-01,  1.7389e-01,  1.9867e-02, -1.0855e-01,  9.5752e-03,\n          1.6573e-01, -1.4681e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1693,  0.1486,  0.1167,  0.1793, -0.2299, -0.2035,  0.2390,  0.0728],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1365, -0.0033,  0.1707,  0.0977, -0.2112,  0.0900,  0.1861, -0.0507,\n         -0.2031,  0.2465, -0.2054, -0.1157, -0.2324,  0.0409, -0.1422,  0.0394],\n        [-0.0754, -0.1382,  0.2219,  0.0971, -0.0629, -0.0055, -0.0660, -0.1363,\n         -0.2481,  0.1760, -0.0771,  0.0658, -0.0938,  0.1342,  0.1059,  0.1693],\n        [ 0.0140,  0.1714,  0.0341, -0.0051, -0.0875, -0.0873,  0.1384,  0.1401,\n          0.0860, -0.0091, -0.0585, -0.1096, -0.2057,  0.0606, -0.1305, -0.1669],\n        [-0.1088, -0.1328,  0.2113,  0.1292, -0.2220, -0.2293, -0.1261, -0.1684,\n         -0.2292, -0.2255, -0.1498,  0.0660,  0.0936, -0.0298,  0.0319,  0.2258],\n        [-0.1492, -0.0601, -0.0698,  0.1828, -0.0755,  0.0295, -0.0512,  0.1283,\n         -0.0846,  0.1433, -0.1958,  0.1648, -0.2400,  0.0796,  0.0677,  0.2155],\n        [-0.1108, -0.0955,  0.2342, -0.0524,  0.1662, -0.0384,  0.1134, -0.2230,\n         -0.2367,  0.1560,  0.0290,  0.0187, -0.2450,  0.2223, -0.1472, -0.1629],\n        [ 0.1449, -0.2402,  0.0207, -0.0453,  0.1715, -0.0530, -0.1533,  0.2029,\n         -0.0684, -0.0467,  0.2070, -0.1481, -0.0810,  0.1146,  0.1571, -0.1748],\n        [ 0.1746,  0.1846,  0.0910,  0.2077,  0.1164, -0.1296, -0.1955, -0.1455,\n          0.1441,  0.1074,  0.1229, -0.2224, -0.1647,  0.0234, -0.1046, -0.0336]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2358], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2251,  0.3074,  0.1940, -0.1637,  0.2064,  0.3483, -0.2789, -0.3276]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1504, -0.1510, -0.3531, -0.0709,  0.0696, -0.1486, -0.1320,  0.0918],\n        [ 0.3418,  0.0613,  0.0852, -0.1239,  0.3471, -0.1703,  0.2029, -0.1189],\n        [ 0.0956,  0.3220, -0.1236,  0.2222,  0.1389, -0.0889,  0.1800,  0.3448],\n        [-0.2469,  0.2215,  0.1619, -0.0704,  0.0371,  0.0639, -0.0359,  0.0338],\n        [ 0.3034,  0.0496,  0.0267, -0.2081, -0.1042,  0.3267, -0.3411, -0.0185],\n        [ 0.2559, -0.0297,  0.0063, -0.2717, -0.2573, -0.1894,  0.2360, -0.3258],\n        [-0.2458,  0.1367,  0.0651,  0.1632, -0.2612, -0.0484, -0.2817, -0.1072],\n        [ 0.0322, -0.2107, -0.0526,  0.3471,  0.0661,  0.2013,  0.3384,  0.1237],\n        [-0.2642, -0.1844,  0.1164, -0.1687,  0.2060, -0.0353, -0.0437, -0.2623],\n        [ 0.0935,  0.3364, -0.0366, -0.1199, -0.1953, -0.1483, -0.1726, -0.0052],\n        [ 0.0475, -0.0847, -0.0097,  0.2421, -0.2151,  0.0134, -0.3452, -0.0052],\n        [ 0.1418,  0.0700,  0.0260, -0.2411,  0.2295,  0.1528,  0.1504,  0.2582],\n        [ 0.1654,  0.1380, -0.3513,  0.1087,  0.2732,  0.0316, -0.3114,  0.2832],\n        [-0.0245,  0.2130, -0.2834, -0.0978,  0.3515,  0.3444, -0.1849,  0.1282],\n        [ 0.1977, -0.1653, -0.2438,  0.2990, -0.1668, -0.0913, -0.1313,  0.1675],\n        [-0.2852, -0.1701,  0.3340, -0.2693,  0.0008,  0.2718,  0.1334,  0.1512],\n        [ 0.0421,  0.1520,  0.3190,  0.3470, -0.2882,  0.2738,  0.1534, -0.0866],\n        [-0.0077, -0.1197, -0.2964, -0.2671, -0.1662,  0.2933, -0.3469, -0.1580],\n        [-0.2795, -0.0316, -0.1992, -0.0996, -0.3412, -0.3413,  0.1290,  0.2010],\n        [ 0.3017,  0.1559,  0.1436, -0.2677,  0.2633, -0.1000, -0.1164,  0.3182],\n        [ 0.1823, -0.1949, -0.3235, -0.1084, -0.1756,  0.1779,  0.2769,  0.0456],\n        [ 0.2397, -0.0894, -0.3159,  0.2998,  0.2115,  0.1886,  0.1869, -0.0431],\n        [-0.3533, -0.1611,  0.0384, -0.3257, -0.3058,  0.3484,  0.1643, -0.2771],\n        [ 0.0984,  0.1143, -0.1827,  0.1858, -0.2777, -0.1083, -0.1203, -0.1790],\n        [ 0.2204, -0.0365, -0.1339, -0.2800,  0.0091,  0.3370,  0.0556,  0.1728],\n        [ 0.2811,  0.1698, -0.3441,  0.2110,  0.2694, -0.2120, -0.0172, -0.2404],\n        [ 0.2715, -0.0217, -0.2963,  0.0937, -0.2760,  0.2513, -0.1669,  0.1578],\n        [-0.1351, -0.2269, -0.3198, -0.0533, -0.3329, -0.2894, -0.2205, -0.3181],\n        [-0.1711, -0.3031,  0.1096, -0.2830, -0.1138,  0.2127, -0.3197,  0.2312],\n        [-0.3090,  0.0692, -0.1325,  0.3110, -0.3095, -0.2736,  0.1052, -0.0960],\n        [ 0.1229, -0.1410,  0.0192, -0.1979, -0.1974,  0.0782,  0.0778, -0.1587],\n        [ 0.0302, -0.0609, -0.1187,  0.1641,  0.3388,  0.1221,  0.1923, -0.0616]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1514,  0.1102,  0.2476, -0.2723, -0.1815, -0.2830,  0.1047, -0.1841,\n         0.0866,  0.3366,  0.3268, -0.3472, -0.2825, -0.2005,  0.2088,  0.2124,\n         0.2427,  0.0585, -0.2891,  0.2318,  0.1893,  0.2438, -0.2284, -0.1039,\n        -0.1496, -0.0463,  0.1679, -0.2635,  0.0281,  0.2704,  0.2327,  0.2142],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-4.6136e-02, -3.3856e-02,  1.5010e-01, -1.0260e-01,  2.4973e-02,\n          1.5749e-01,  7.1849e-02,  1.1889e-01, -1.6661e-01,  1.4487e-01,\n         -8.9104e-02,  8.3411e-02, -1.6773e-01,  6.9041e-02,  1.1240e-01,\n          1.9819e-02, -2.8597e-02, -7.8599e-02, -4.1526e-02, -1.3132e-01,\n         -1.0269e-01, -1.0232e-01,  2.5378e-02,  8.6007e-02,  9.4377e-02,\n         -1.7574e-01, -1.5588e-02, -1.3182e-01, -6.9192e-02, -5.2430e-02,\n          1.6744e-01,  1.4248e-01],\n        [-1.3878e-01,  1.2433e-01,  7.8194e-02, -5.4030e-02,  1.1590e-01,\n         -9.3707e-02, -7.4158e-02,  4.0244e-02, -9.1156e-02,  8.2639e-02,\n          1.5689e-01, -1.5001e-01,  1.0902e-01, -5.1072e-02,  8.4892e-02,\n          1.1882e-01, -5.2437e-03,  1.0367e-01,  1.0735e-01, -1.5971e-01,\n         -7.7241e-02, -9.1686e-02, -3.3266e-02, -5.2938e-02,  1.5454e-01,\n         -1.2491e-01, -1.1318e-01, -3.3739e-02, -1.3238e-01, -3.7040e-02,\n          7.6590e-02,  6.4223e-02],\n        [ 1.5818e-01, -1.6548e-01,  4.2573e-02,  7.6135e-02,  1.3511e-01,\n          1.7151e-01,  3.9925e-02,  1.3367e-01,  5.5972e-02, -1.0950e-01,\n         -1.4372e-01, -1.0185e-01, -4.5481e-02,  1.3456e-01,  1.5418e-01,\n          9.4353e-02, -1.9147e-02,  1.4775e-01,  1.2069e-01, -6.6908e-02,\n         -2.0627e-02,  5.5698e-02, -1.3640e-01, -1.4082e-01, -3.7057e-02,\n         -1.5262e-01, -1.1489e-01, -1.6262e-01, -1.6113e-01, -2.1830e-02,\n         -7.6026e-02, -1.3011e-01],\n        [-1.1611e-01,  1.7300e-01,  4.7949e-02,  8.5925e-02, -1.6854e-01,\n          9.7315e-02, -9.0526e-02,  1.1337e-01, -1.7605e-01,  4.8591e-02,\n          1.0652e-02, -1.1058e-01, -1.0894e-01,  8.3199e-02,  6.3171e-02,\n          3.6020e-02, -1.5945e-01, -2.3042e-02, -7.1594e-02,  3.9358e-02,\n         -2.8520e-02, -4.3741e-02,  1.7319e-01, -4.5228e-02,  2.6301e-02,\n          8.8166e-02,  8.7492e-02,  1.3022e-01, -1.1841e-01,  7.2019e-02,\n         -1.7402e-01, -1.2568e-01],\n        [ 2.3365e-02, -1.6623e-01, -1.1448e-01,  1.7416e-01,  7.9219e-02,\n         -9.0845e-02,  1.0365e-01,  1.0137e-01, -1.1183e-01,  4.7566e-03,\n          1.6239e-02, -1.2838e-01,  8.8279e-02,  7.6325e-03, -1.6815e-01,\n          1.2318e-01, -1.6868e-03, -1.4817e-01, -1.0718e-01,  1.6673e-01,\n         -1.6435e-01,  1.2673e-01, -7.6000e-02, -5.6626e-02, -1.3162e-01,\n          4.3197e-02, -7.2652e-02, -9.2914e-02, -4.8104e-02,  8.6632e-02,\n         -5.3543e-03,  7.5030e-02],\n        [-1.7388e-01,  8.9873e-02,  1.7467e-01, -1.3255e-04, -6.6354e-02,\n          1.5656e-01,  5.8711e-02, -2.7549e-02, -6.4653e-03, -6.9467e-02,\n          1.1386e-01,  1.6869e-01,  8.7977e-02, -5.4120e-02, -1.0940e-01,\n         -2.0475e-03, -1.7386e-01,  1.2929e-01, -1.5062e-02,  1.0447e-01,\n         -8.2093e-02,  4.6073e-02,  1.6221e-03, -5.8244e-02,  9.1917e-02,\n          8.1709e-02,  5.6089e-02, -9.6491e-02,  1.2565e-01,  1.4416e-01,\n          4.7516e-02,  7.6213e-02],\n        [ 1.3093e-01, -1.6999e-01,  5.0417e-02, -1.1616e-02,  1.0748e-01,\n          1.0060e-02, -1.7584e-01,  1.0103e-01, -6.5672e-02, -4.9613e-02,\n          1.2665e-01,  1.0157e-01, -1.2073e-02,  5.6360e-02,  1.1904e-01,\n          1.5004e-01, -1.6237e-01,  1.4865e-01,  5.7216e-02, -4.1112e-02,\n         -1.0143e-01,  1.2517e-01,  1.6349e-01,  8.1586e-02, -1.6392e-01,\n         -1.7653e-02, -1.2166e-01,  7.0617e-02,  5.3217e-02, -3.0256e-02,\n         -1.4118e-01,  1.3869e-01],\n        [-1.2137e-01,  6.0630e-02, -1.4842e-01,  1.5828e-01,  5.7753e-02,\n          1.2861e-01,  9.3777e-02, -8.9142e-02,  5.1448e-02,  1.1374e-01,\n          1.4590e-01,  2.1816e-02,  3.3073e-02,  1.3809e-01, -1.9649e-02,\n          1.0581e-01, -5.8043e-02,  1.6010e-01, -1.2279e-01,  8.0030e-02,\n         -5.2363e-02,  1.5684e-02, -1.4067e-01, -1.1154e-01, -1.2116e-01,\n         -6.1479e-02, -1.2231e-01,  2.3634e-02, -1.3841e-01,  3.1772e-03,\n          1.0032e-01,  7.0925e-02],\n        [ 7.9771e-02,  1.5970e-01,  1.8528e-02, -1.1366e-02, -4.3284e-02,\n          8.4912e-02, -1.2151e-01,  1.1091e-01,  1.1514e-01, -1.2606e-01,\n         -5.9327e-02, -8.1933e-02, -2.4406e-02, -3.9634e-02, -1.5130e-01,\n         -1.0121e-01, -5.0639e-02,  3.4238e-02,  1.2575e-01,  3.3206e-02,\n         -1.7109e-01, -1.7677e-01,  1.7469e-01,  1.5630e-01, -1.4951e-01,\n          6.8542e-02,  1.4744e-01, -1.4661e-01, -1.7059e-01,  4.8869e-02,\n         -1.3693e-01, -2.3131e-02],\n        [-1.3479e-02,  8.1169e-02,  1.3348e-01, -1.6970e-01, -1.2567e-01,\n         -7.8464e-02,  9.5620e-02,  9.5595e-02, -7.6280e-02, -5.0361e-02,\n         -1.8868e-02, -1.1593e-01,  1.2573e-01, -1.4888e-01,  1.4624e-01,\n          1.5281e-01,  6.7574e-02, -1.6890e-01, -2.6615e-03,  1.0344e-01,\n          8.5702e-02,  6.8399e-03, -1.0252e-01, -2.2616e-02,  5.0079e-02,\n          9.5563e-02, -6.3723e-02, -2.0881e-02, -8.3529e-02,  7.7909e-02,\n          1.6868e-01, -1.2447e-01],\n        [ 1.0590e-01, -1.4016e-01,  1.4050e-01,  1.1235e-02,  6.7979e-02,\n          1.0805e-01,  8.3450e-02, -1.4714e-01,  9.5328e-02,  1.6060e-02,\n         -9.6418e-02, -1.2147e-01,  6.2538e-02,  5.6715e-02,  8.0553e-02,\n          5.4919e-02,  1.5299e-01, -1.6827e-01,  1.4874e-01, -1.1088e-01,\n         -1.1581e-01, -1.7467e-01, -1.6441e-01,  7.2184e-02,  1.7100e-01,\n          5.9524e-02,  1.4739e-01, -9.2840e-02,  1.3352e-01,  1.0162e-01,\n         -4.3053e-02,  1.7005e-02],\n        [-1.2520e-01, -1.1688e-01, -1.2441e-01, -1.5359e-01, -1.0763e-01,\n         -2.2534e-03, -2.7324e-02, -8.8524e-02,  4.5079e-02,  1.0346e-01,\n         -1.1343e-01, -8.5597e-03, -8.6313e-02,  7.6822e-02, -1.0431e-03,\n          1.1694e-02,  4.6278e-02,  1.5321e-01,  7.9138e-02,  1.6966e-01,\n         -9.5139e-02, -8.0852e-02, -1.6719e-01,  1.7246e-01, -8.3328e-02,\n         -6.5515e-02,  1.0171e-01, -3.4455e-02,  1.6394e-01, -5.8880e-02,\n         -8.2527e-02, -1.0402e-01],\n        [ 1.4189e-01,  1.4099e-01, -6.3490e-02, -1.0805e-01,  9.2202e-03,\n         -2.1076e-02, -3.7439e-03,  9.9987e-03, -5.0165e-02, -1.6776e-01,\n          8.9807e-02,  1.7669e-01,  1.7280e-01, -6.6710e-02,  1.3151e-02,\n         -1.0351e-01, -1.0494e-01,  5.9597e-02,  1.2704e-01,  3.7753e-02,\n          1.3674e-01, -1.6706e-01, -9.1301e-02,  9.2258e-03, -3.8424e-02,\n          1.6818e-01, -1.7539e-01,  1.1668e-03, -1.0916e-01, -1.3576e-01,\n          1.0585e-01,  1.2277e-01],\n        [-1.5972e-01,  7.1594e-02, -5.9334e-02,  2.5116e-04,  1.2357e-01,\n         -9.0826e-02, -1.1842e-02,  5.1353e-02, -9.5449e-02, -1.3174e-01,\n          3.9265e-02,  8.2646e-02,  5.6372e-02, -5.3022e-02, -1.2839e-01,\n          5.8147e-02,  3.6025e-02, -1.6625e-02,  2.3568e-02,  9.8857e-02,\n         -1.1966e-01, -7.8487e-02, -4.5243e-02, -9.5716e-02, -7.1614e-02,\n         -1.7673e-01,  1.2784e-01, -1.1985e-02, -1.3327e-01, -1.4174e-01,\n         -1.7353e-01, -1.9720e-03],\n        [ 2.7066e-02, -1.1252e-02,  6.3741e-02,  1.5428e-01, -8.6089e-02,\n          1.2226e-01, -1.2783e-01, -8.3742e-02,  2.0750e-02, -1.2612e-02,\n         -1.0496e-01,  6.4012e-02, -8.5684e-02,  1.1971e-01, -9.3099e-02,\n          7.9199e-02, -1.6849e-01, -1.5623e-01,  9.2906e-02,  3.7644e-02,\n         -1.5169e-01,  1.1352e-01,  1.7359e-01,  5.9039e-02, -4.4724e-02,\n          1.4820e-01, -2.7027e-02,  1.4689e-01, -2.2310e-02, -1.0570e-01,\n          9.7544e-02, -9.6360e-02],\n        [ 1.6809e-01,  8.6789e-02, -6.9273e-02,  1.6124e-01, -1.5946e-01,\n         -1.6713e-01, -9.7758e-02,  1.3527e-01,  8.7889e-02, -1.7441e-01,\n          7.7270e-02, -1.2511e-01,  5.6706e-02, -1.4890e-02, -4.6377e-02,\n          1.1877e-01,  2.0766e-04,  4.8908e-02,  1.2571e-01,  1.5807e-01,\n          1.1492e-01, -1.0621e-02,  8.6889e-02,  7.5853e-02, -1.4016e-01,\n         -1.5224e-01,  1.7389e-01,  1.9867e-02, -1.0855e-01,  9.5752e-03,\n          1.6573e-01, -1.4681e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0107,  0.0152,  0.0897, -0.1407,  0.1611,  0.1236, -0.1259,  0.1100,\n         0.1492, -0.1672, -0.1378, -0.0500,  0.1357, -0.1665,  0.0436,  0.1304],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1365, -0.0033,  0.1707,  0.0977, -0.2112,  0.0900,  0.1861, -0.0507,\n         -0.2031,  0.2465, -0.2054, -0.1157, -0.2324,  0.0409, -0.1422,  0.0394],\n        [-0.0754, -0.1382,  0.2219,  0.0971, -0.0629, -0.0055, -0.0660, -0.1363,\n         -0.2481,  0.1760, -0.0771,  0.0658, -0.0938,  0.1342,  0.1059,  0.1693],\n        [ 0.0140,  0.1714,  0.0341, -0.0051, -0.0875, -0.0873,  0.1384,  0.1401,\n          0.0860, -0.0091, -0.0585, -0.1096, -0.2057,  0.0606, -0.1305, -0.1669],\n        [-0.1088, -0.1328,  0.2113,  0.1292, -0.2220, -0.2293, -0.1261, -0.1684,\n         -0.2292, -0.2255, -0.1498,  0.0660,  0.0936, -0.0298,  0.0319,  0.2258],\n        [-0.1492, -0.0601, -0.0698,  0.1828, -0.0755,  0.0295, -0.0512,  0.1283,\n         -0.0846,  0.1433, -0.1958,  0.1648, -0.2400,  0.0796,  0.0677,  0.2155],\n        [-0.1108, -0.0955,  0.2342, -0.0524,  0.1662, -0.0384,  0.1134, -0.2230,\n         -0.2367,  0.1560,  0.0290,  0.0187, -0.2450,  0.2223, -0.1472, -0.1629],\n        [ 0.1449, -0.2402,  0.0207, -0.0453,  0.1715, -0.0530, -0.1533,  0.2029,\n         -0.0684, -0.0467,  0.2070, -0.1481, -0.0810,  0.1146,  0.1571, -0.1748],\n        [ 0.1746,  0.1846,  0.0910,  0.2077,  0.1164, -0.1296, -0.1955, -0.1455,\n          0.1441,  0.1074,  0.1229, -0.2224, -0.1647,  0.0234, -0.1046, -0.0336]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1693,  0.1486,  0.1167,  0.1793, -0.2299, -0.2035,  0.2390,  0.0728],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2251,  0.3074,  0.1940, -0.1637,  0.2064,  0.3483, -0.2789, -0.3276]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2358], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000001B4C5DA62F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001B48E388C40>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s294480000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s294480000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1514,  0.1102,  0.2476, -0.2723, -0.1815, -0.2830,  0.1047, -0.1841,\n         0.0866,  0.3366,  0.3268, -0.3472, -0.2825, -0.2005,  0.2088,  0.2124,\n         0.2427,  0.0585, -0.2891,  0.2318,  0.1893,  0.2438, -0.2284, -0.1039,\n        -0.1496, -0.0463,  0.1679, -0.2635,  0.0281,  0.2704,  0.2327,  0.2142],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1504, -0.1510, -0.3531, -0.0709,  0.0696, -0.1486, -0.1320,  0.0918],\n        [ 0.3418,  0.0613,  0.0852, -0.1239,  0.3471, -0.1703,  0.2029, -0.1189],\n        [ 0.0956,  0.3220, -0.1236,  0.2222,  0.1389, -0.0889,  0.1800,  0.3448],\n        [-0.2469,  0.2215,  0.1619, -0.0704,  0.0371,  0.0639, -0.0359,  0.0338],\n        [ 0.3034,  0.0496,  0.0267, -0.2081, -0.1042,  0.3267, -0.3411, -0.0185],\n        [ 0.2559, -0.0297,  0.0063, -0.2717, -0.2573, -0.1894,  0.2360, -0.3258],\n        [-0.2458,  0.1367,  0.0651,  0.1632, -0.2612, -0.0484, -0.2817, -0.1072],\n        [ 0.0322, -0.2107, -0.0526,  0.3471,  0.0661,  0.2013,  0.3384,  0.1237],\n        [-0.2642, -0.1844,  0.1164, -0.1687,  0.2060, -0.0353, -0.0437, -0.2623],\n        [ 0.0935,  0.3364, -0.0366, -0.1199, -0.1953, -0.1483, -0.1726, -0.0052],\n        [ 0.0475, -0.0847, -0.0097,  0.2421, -0.2151,  0.0134, -0.3452, -0.0052],\n        [ 0.1418,  0.0700,  0.0260, -0.2411,  0.2295,  0.1528,  0.1504,  0.2582],\n        [ 0.1654,  0.1380, -0.3513,  0.1087,  0.2732,  0.0316, -0.3114,  0.2832],\n        [-0.0245,  0.2130, -0.2834, -0.0978,  0.3515,  0.3444, -0.1849,  0.1282],\n        [ 0.1977, -0.1653, -0.2438,  0.2990, -0.1668, -0.0913, -0.1313,  0.1675],\n        [-0.2852, -0.1701,  0.3340, -0.2693,  0.0008,  0.2718,  0.1334,  0.1512],\n        [ 0.0421,  0.1520,  0.3190,  0.3470, -0.2882,  0.2738,  0.1534, -0.0866],\n        [-0.0077, -0.1197, -0.2964, -0.2671, -0.1662,  0.2933, -0.3469, -0.1580],\n        [-0.2795, -0.0316, -0.1992, -0.0996, -0.3412, -0.3413,  0.1290,  0.2010],\n        [ 0.3017,  0.1559,  0.1436, -0.2677,  0.2633, -0.1000, -0.1164,  0.3182],\n        [ 0.1823, -0.1949, -0.3235, -0.1084, -0.1756,  0.1779,  0.2769,  0.0456],\n        [ 0.2397, -0.0894, -0.3159,  0.2998,  0.2115,  0.1886,  0.1869, -0.0431],\n        [-0.3533, -0.1611,  0.0384, -0.3257, -0.3058,  0.3484,  0.1643, -0.2771],\n        [ 0.0984,  0.1143, -0.1827,  0.1858, -0.2777, -0.1083, -0.1203, -0.1790],\n        [ 0.2204, -0.0365, -0.1339, -0.2800,  0.0091,  0.3370,  0.0556,  0.1728],\n        [ 0.2811,  0.1698, -0.3441,  0.2110,  0.2694, -0.2120, -0.0172, -0.2404],\n        [ 0.2715, -0.0217, -0.2963,  0.0937, -0.2760,  0.2513, -0.1669,  0.1578],\n        [-0.1351, -0.2269, -0.3198, -0.0533, -0.3329, -0.2894, -0.2205, -0.3181],\n        [-0.1711, -0.3031,  0.1096, -0.2830, -0.1138,  0.2127, -0.3197,  0.2312],\n        [-0.3090,  0.0692, -0.1325,  0.3110, -0.3095, -0.2736,  0.1052, -0.0960],\n        [ 0.1229, -0.1410,  0.0192, -0.1979, -0.1974,  0.0782,  0.0778, -0.1587],\n        [ 0.0302, -0.0609, -0.1187,  0.1641,  0.3388,  0.1221,  0.1923, -0.0616]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0107,  0.0152,  0.0897, -0.1407,  0.1611,  0.1236, -0.1259,  0.1100,\n         0.1492, -0.1672, -0.1378, -0.0500,  0.1357, -0.1665,  0.0436,  0.1304],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-4.6136e-02, -3.3856e-02,  1.5010e-01, -1.0260e-01,  2.4973e-02,\n          1.5749e-01,  7.1849e-02,  1.1889e-01, -1.6661e-01,  1.4487e-01,\n         -8.9104e-02,  8.3411e-02, -1.6773e-01,  6.9041e-02,  1.1240e-01,\n          1.9819e-02, -2.8597e-02, -7.8599e-02, -4.1526e-02, -1.3132e-01,\n         -1.0269e-01, -1.0232e-01,  2.5378e-02,  8.6007e-02,  9.4377e-02,\n         -1.7574e-01, -1.5588e-02, -1.3182e-01, -6.9192e-02, -5.2430e-02,\n          1.6744e-01,  1.4248e-01],\n        [-1.3878e-01,  1.2433e-01,  7.8194e-02, -5.4030e-02,  1.1590e-01,\n         -9.3707e-02, -7.4158e-02,  4.0244e-02, -9.1156e-02,  8.2639e-02,\n          1.5689e-01, -1.5001e-01,  1.0902e-01, -5.1072e-02,  8.4892e-02,\n          1.1882e-01, -5.2437e-03,  1.0367e-01,  1.0735e-01, -1.5971e-01,\n         -7.7241e-02, -9.1686e-02, -3.3266e-02, -5.2938e-02,  1.5454e-01,\n         -1.2491e-01, -1.1318e-01, -3.3739e-02, -1.3238e-01, -3.7040e-02,\n          7.6590e-02,  6.4223e-02],\n        [ 1.5818e-01, -1.6548e-01,  4.2573e-02,  7.6135e-02,  1.3511e-01,\n          1.7151e-01,  3.9925e-02,  1.3367e-01,  5.5972e-02, -1.0950e-01,\n         -1.4372e-01, -1.0185e-01, -4.5481e-02,  1.3456e-01,  1.5418e-01,\n          9.4353e-02, -1.9147e-02,  1.4775e-01,  1.2069e-01, -6.6908e-02,\n         -2.0627e-02,  5.5698e-02, -1.3640e-01, -1.4082e-01, -3.7057e-02,\n         -1.5262e-01, -1.1489e-01, -1.6262e-01, -1.6113e-01, -2.1830e-02,\n         -7.6026e-02, -1.3011e-01],\n        [-1.1611e-01,  1.7300e-01,  4.7949e-02,  8.5925e-02, -1.6854e-01,\n          9.7315e-02, -9.0526e-02,  1.1337e-01, -1.7605e-01,  4.8591e-02,\n          1.0652e-02, -1.1058e-01, -1.0894e-01,  8.3199e-02,  6.3171e-02,\n          3.6020e-02, -1.5945e-01, -2.3042e-02, -7.1594e-02,  3.9358e-02,\n         -2.8520e-02, -4.3741e-02,  1.7319e-01, -4.5228e-02,  2.6301e-02,\n          8.8166e-02,  8.7492e-02,  1.3022e-01, -1.1841e-01,  7.2019e-02,\n         -1.7402e-01, -1.2568e-01],\n        [ 2.3365e-02, -1.6623e-01, -1.1448e-01,  1.7416e-01,  7.9219e-02,\n         -9.0845e-02,  1.0365e-01,  1.0137e-01, -1.1183e-01,  4.7566e-03,\n          1.6239e-02, -1.2838e-01,  8.8279e-02,  7.6325e-03, -1.6815e-01,\n          1.2318e-01, -1.6868e-03, -1.4817e-01, -1.0718e-01,  1.6673e-01,\n         -1.6435e-01,  1.2673e-01, -7.6000e-02, -5.6626e-02, -1.3162e-01,\n          4.3197e-02, -7.2652e-02, -9.2914e-02, -4.8104e-02,  8.6632e-02,\n         -5.3543e-03,  7.5030e-02],\n        [-1.7388e-01,  8.9873e-02,  1.7467e-01, -1.3255e-04, -6.6354e-02,\n          1.5656e-01,  5.8711e-02, -2.7549e-02, -6.4653e-03, -6.9467e-02,\n          1.1386e-01,  1.6869e-01,  8.7977e-02, -5.4120e-02, -1.0940e-01,\n         -2.0475e-03, -1.7386e-01,  1.2929e-01, -1.5062e-02,  1.0447e-01,\n         -8.2093e-02,  4.6073e-02,  1.6221e-03, -5.8244e-02,  9.1917e-02,\n          8.1709e-02,  5.6089e-02, -9.6491e-02,  1.2565e-01,  1.4416e-01,\n          4.7516e-02,  7.6213e-02],\n        [ 1.3093e-01, -1.6999e-01,  5.0417e-02, -1.1616e-02,  1.0748e-01,\n          1.0060e-02, -1.7584e-01,  1.0103e-01, -6.5672e-02, -4.9613e-02,\n          1.2665e-01,  1.0157e-01, -1.2073e-02,  5.6360e-02,  1.1904e-01,\n          1.5004e-01, -1.6237e-01,  1.4865e-01,  5.7216e-02, -4.1112e-02,\n         -1.0143e-01,  1.2517e-01,  1.6349e-01,  8.1586e-02, -1.6392e-01,\n         -1.7653e-02, -1.2166e-01,  7.0617e-02,  5.3217e-02, -3.0256e-02,\n         -1.4118e-01,  1.3869e-01],\n        [-1.2137e-01,  6.0630e-02, -1.4842e-01,  1.5828e-01,  5.7753e-02,\n          1.2861e-01,  9.3777e-02, -8.9142e-02,  5.1448e-02,  1.1374e-01,\n          1.4590e-01,  2.1816e-02,  3.3073e-02,  1.3809e-01, -1.9649e-02,\n          1.0581e-01, -5.8043e-02,  1.6010e-01, -1.2279e-01,  8.0030e-02,\n         -5.2363e-02,  1.5684e-02, -1.4067e-01, -1.1154e-01, -1.2116e-01,\n         -6.1479e-02, -1.2231e-01,  2.3634e-02, -1.3841e-01,  3.1772e-03,\n          1.0032e-01,  7.0925e-02],\n        [ 7.9771e-02,  1.5970e-01,  1.8528e-02, -1.1366e-02, -4.3284e-02,\n          8.4912e-02, -1.2151e-01,  1.1091e-01,  1.1514e-01, -1.2606e-01,\n         -5.9327e-02, -8.1933e-02, -2.4406e-02, -3.9634e-02, -1.5130e-01,\n         -1.0121e-01, -5.0639e-02,  3.4238e-02,  1.2575e-01,  3.3206e-02,\n         -1.7109e-01, -1.7677e-01,  1.7469e-01,  1.5630e-01, -1.4951e-01,\n          6.8542e-02,  1.4744e-01, -1.4661e-01, -1.7059e-01,  4.8869e-02,\n         -1.3693e-01, -2.3131e-02],\n        [-1.3479e-02,  8.1169e-02,  1.3348e-01, -1.6970e-01, -1.2567e-01,\n         -7.8464e-02,  9.5620e-02,  9.5595e-02, -7.6280e-02, -5.0361e-02,\n         -1.8868e-02, -1.1593e-01,  1.2573e-01, -1.4888e-01,  1.4624e-01,\n          1.5281e-01,  6.7574e-02, -1.6890e-01, -2.6615e-03,  1.0344e-01,\n          8.5702e-02,  6.8399e-03, -1.0252e-01, -2.2616e-02,  5.0079e-02,\n          9.5563e-02, -6.3723e-02, -2.0881e-02, -8.3529e-02,  7.7909e-02,\n          1.6868e-01, -1.2447e-01],\n        [ 1.0590e-01, -1.4016e-01,  1.4050e-01,  1.1235e-02,  6.7979e-02,\n          1.0805e-01,  8.3450e-02, -1.4714e-01,  9.5328e-02,  1.6060e-02,\n         -9.6418e-02, -1.2147e-01,  6.2538e-02,  5.6715e-02,  8.0553e-02,\n          5.4919e-02,  1.5299e-01, -1.6827e-01,  1.4874e-01, -1.1088e-01,\n         -1.1581e-01, -1.7467e-01, -1.6441e-01,  7.2184e-02,  1.7100e-01,\n          5.9524e-02,  1.4739e-01, -9.2840e-02,  1.3352e-01,  1.0162e-01,\n         -4.3053e-02,  1.7005e-02],\n        [-1.2520e-01, -1.1688e-01, -1.2441e-01, -1.5359e-01, -1.0763e-01,\n         -2.2534e-03, -2.7324e-02, -8.8524e-02,  4.5079e-02,  1.0346e-01,\n         -1.1343e-01, -8.5597e-03, -8.6313e-02,  7.6822e-02, -1.0431e-03,\n          1.1694e-02,  4.6278e-02,  1.5321e-01,  7.9138e-02,  1.6966e-01,\n         -9.5139e-02, -8.0852e-02, -1.6719e-01,  1.7246e-01, -8.3328e-02,\n         -6.5515e-02,  1.0171e-01, -3.4455e-02,  1.6394e-01, -5.8880e-02,\n         -8.2527e-02, -1.0402e-01],\n        [ 1.4189e-01,  1.4099e-01, -6.3490e-02, -1.0805e-01,  9.2202e-03,\n         -2.1076e-02, -3.7439e-03,  9.9987e-03, -5.0165e-02, -1.6776e-01,\n          8.9807e-02,  1.7669e-01,  1.7280e-01, -6.6710e-02,  1.3151e-02,\n         -1.0351e-01, -1.0494e-01,  5.9597e-02,  1.2704e-01,  3.7753e-02,\n          1.3674e-01, -1.6706e-01, -9.1301e-02,  9.2258e-03, -3.8424e-02,\n          1.6818e-01, -1.7539e-01,  1.1668e-03, -1.0916e-01, -1.3576e-01,\n          1.0585e-01,  1.2277e-01],\n        [-1.5972e-01,  7.1594e-02, -5.9334e-02,  2.5116e-04,  1.2357e-01,\n         -9.0826e-02, -1.1842e-02,  5.1353e-02, -9.5449e-02, -1.3174e-01,\n          3.9265e-02,  8.2646e-02,  5.6372e-02, -5.3022e-02, -1.2839e-01,\n          5.8147e-02,  3.6025e-02, -1.6625e-02,  2.3568e-02,  9.8857e-02,\n         -1.1966e-01, -7.8487e-02, -4.5243e-02, -9.5716e-02, -7.1614e-02,\n         -1.7673e-01,  1.2784e-01, -1.1985e-02, -1.3327e-01, -1.4174e-01,\n         -1.7353e-01, -1.9720e-03],\n        [ 2.7066e-02, -1.1252e-02,  6.3741e-02,  1.5428e-01, -8.6089e-02,\n          1.2226e-01, -1.2783e-01, -8.3742e-02,  2.0750e-02, -1.2612e-02,\n         -1.0496e-01,  6.4012e-02, -8.5684e-02,  1.1971e-01, -9.3099e-02,\n          7.9199e-02, -1.6849e-01, -1.5623e-01,  9.2906e-02,  3.7644e-02,\n         -1.5169e-01,  1.1352e-01,  1.7359e-01,  5.9039e-02, -4.4724e-02,\n          1.4820e-01, -2.7027e-02,  1.4689e-01, -2.2310e-02, -1.0570e-01,\n          9.7544e-02, -9.6360e-02],\n        [ 1.6809e-01,  8.6789e-02, -6.9273e-02,  1.6124e-01, -1.5946e-01,\n         -1.6713e-01, -9.7758e-02,  1.3527e-01,  8.7889e-02, -1.7441e-01,\n          7.7270e-02, -1.2511e-01,  5.6706e-02, -1.4890e-02, -4.6377e-02,\n          1.1877e-01,  2.0766e-04,  4.8908e-02,  1.2571e-01,  1.5807e-01,\n          1.1492e-01, -1.0621e-02,  8.6889e-02,  7.5853e-02, -1.4016e-01,\n         -1.5224e-01,  1.7389e-01,  1.9867e-02, -1.0855e-01,  9.5752e-03,\n          1.6573e-01, -1.4681e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1693,  0.1486,  0.1167,  0.1793, -0.2299, -0.2035,  0.2390,  0.0728],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1365, -0.0033,  0.1707,  0.0977, -0.2112,  0.0900,  0.1861, -0.0507,\n         -0.2031,  0.2465, -0.2054, -0.1157, -0.2324,  0.0409, -0.1422,  0.0394],\n        [-0.0754, -0.1382,  0.2219,  0.0971, -0.0629, -0.0055, -0.0660, -0.1363,\n         -0.2481,  0.1760, -0.0771,  0.0658, -0.0938,  0.1342,  0.1059,  0.1693],\n        [ 0.0140,  0.1714,  0.0341, -0.0051, -0.0875, -0.0873,  0.1384,  0.1401,\n          0.0860, -0.0091, -0.0585, -0.1096, -0.2057,  0.0606, -0.1305, -0.1669],\n        [-0.1088, -0.1328,  0.2113,  0.1292, -0.2220, -0.2293, -0.1261, -0.1684,\n         -0.2292, -0.2255, -0.1498,  0.0660,  0.0936, -0.0298,  0.0319,  0.2258],\n        [-0.1492, -0.0601, -0.0698,  0.1828, -0.0755,  0.0295, -0.0512,  0.1283,\n         -0.0846,  0.1433, -0.1958,  0.1648, -0.2400,  0.0796,  0.0677,  0.2155],\n        [-0.1108, -0.0955,  0.2342, -0.0524,  0.1662, -0.0384,  0.1134, -0.2230,\n         -0.2367,  0.1560,  0.0290,  0.0187, -0.2450,  0.2223, -0.1472, -0.1629],\n        [ 0.1449, -0.2402,  0.0207, -0.0453,  0.1715, -0.0530, -0.1533,  0.2029,\n         -0.0684, -0.0467,  0.2070, -0.1481, -0.0810,  0.1146,  0.1571, -0.1748],\n        [ 0.1746,  0.1846,  0.0910,  0.2077,  0.1164, -0.1296, -0.1955, -0.1455,\n          0.1441,  0.1074,  0.1229, -0.2224, -0.1647,  0.0234, -0.1046, -0.0336]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2358], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2251,  0.3074,  0.1940, -0.1637,  0.2064,  0.3483, -0.2789, -0.3276]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}