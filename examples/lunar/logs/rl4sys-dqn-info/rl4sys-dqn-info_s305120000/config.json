{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s305120000"
    },
    "q_lr":	0.0005,
    "seed":	305120000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x00000255150B9120>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0731, -0.0362, -0.0341, -0.2312,  0.1192,  0.1816,  0.2142, -0.2474,\n         0.2083, -0.1203, -0.1563, -0.2339, -0.0378,  0.2381, -0.1713,  0.0317,\n         0.1328, -0.0117, -0.2603, -0.0921,  0.2619,  0.1610,  0.0612, -0.1312,\n        -0.0064, -0.3196, -0.0324,  0.2852, -0.1671, -0.3334, -0.1404,  0.3526],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2995,  0.2658, -0.3144, -0.3471, -0.2865, -0.1417,  0.1387, -0.1950],\n        [-0.1562,  0.0246, -0.1119,  0.2914,  0.2275, -0.2017,  0.0207, -0.2928],\n        [ 0.3335, -0.3219,  0.2427,  0.2058,  0.0868, -0.0015,  0.2865, -0.3204],\n        [ 0.2763, -0.0424, -0.0793,  0.2342,  0.3161,  0.1409, -0.1081, -0.0098],\n        [ 0.0067, -0.1938, -0.1684, -0.1352,  0.2127, -0.2466, -0.2743,  0.0637],\n        [ 0.2966, -0.1457,  0.0233, -0.2299,  0.2299,  0.2125, -0.1088, -0.2911],\n        [-0.0462,  0.1356,  0.0398, -0.1351, -0.0403,  0.2323,  0.2776,  0.0437],\n        [-0.1627,  0.1636, -0.3336,  0.0008, -0.3532,  0.1645,  0.0104,  0.1871],\n        [ 0.2617,  0.2204,  0.3169,  0.3029,  0.2598, -0.3485,  0.1146,  0.1638],\n        [-0.2655,  0.1576,  0.1535, -0.1940,  0.1696,  0.1448,  0.1506,  0.0088],\n        [-0.2042,  0.1826,  0.1060, -0.3371,  0.1713, -0.2645, -0.0510,  0.2981],\n        [ 0.0630,  0.0792,  0.3199, -0.1892, -0.1100, -0.2581, -0.2377, -0.2755],\n        [ 0.1030,  0.2486,  0.0830,  0.0782,  0.2773,  0.2761,  0.0677, -0.2775],\n        [ 0.3499, -0.0238,  0.1411, -0.1752, -0.2594,  0.2715,  0.1364,  0.0869],\n        [-0.0449,  0.1846, -0.3120,  0.0340, -0.1789, -0.3205,  0.0160,  0.2342],\n        [-0.0985,  0.0258,  0.1965, -0.1808,  0.3192, -0.2556,  0.1862,  0.3059],\n        [-0.3474,  0.2893, -0.1042, -0.2810, -0.3515,  0.1725,  0.1866,  0.0393],\n        [-0.3478, -0.3275,  0.1418, -0.2514, -0.1937, -0.3436, -0.0804,  0.1252],\n        [-0.1159,  0.0461, -0.1193, -0.1282,  0.0611, -0.2857, -0.2517, -0.2915],\n        [ 0.0134, -0.1644, -0.0249, -0.2462, -0.3475, -0.1048,  0.3405,  0.3240],\n        [ 0.1311, -0.1472, -0.0438, -0.1266, -0.2520, -0.2834, -0.2280,  0.0819],\n        [-0.3014, -0.1352, -0.0440, -0.1497,  0.2958,  0.0696, -0.0894, -0.0704],\n        [ 0.0509, -0.1425,  0.0441, -0.0171, -0.0108, -0.0761, -0.0255,  0.1223],\n        [ 0.2112,  0.0121, -0.3193, -0.2682,  0.0221,  0.3215,  0.0143,  0.0826],\n        [ 0.0245, -0.0689, -0.2354,  0.1593, -0.0443,  0.2794, -0.3362, -0.3087],\n        [ 0.2468,  0.3455,  0.0310, -0.1688,  0.3289, -0.2298,  0.0963, -0.2373],\n        [ 0.0406, -0.3045,  0.1450, -0.2659, -0.0910,  0.2822, -0.0590, -0.2679],\n        [ 0.1272,  0.2592,  0.3046,  0.0677,  0.2694, -0.3522, -0.0091,  0.1570],\n        [ 0.0335, -0.1275,  0.1856,  0.2144, -0.1624,  0.0872,  0.0379, -0.1674],\n        [-0.3278, -0.1481,  0.1365, -0.3213,  0.2569, -0.0250, -0.1515,  0.0216],\n        [-0.0591, -0.2315,  0.2201,  0.0448,  0.1279,  0.2432,  0.1493, -0.1940],\n        [ 0.1291, -0.3294,  0.0581, -0.3417, -0.1535,  0.1375,  0.2899, -0.1588]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1176,  0.0387, -0.0413,  0.1283,  0.0936, -0.0779,  0.0717,  0.0358,\n        -0.0899, -0.0770,  0.0600,  0.0952, -0.1395,  0.1142,  0.0440, -0.1272],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.3207e-01,  8.2332e-02, -3.1429e-02, -7.4704e-02, -6.6868e-02,\n         -1.3304e-01, -1.0275e-01, -1.4820e-01, -1.4391e-01,  5.5679e-02,\n          6.0477e-02,  1.1125e-01, -3.1763e-02,  1.5677e-01, -1.5350e-01,\n          7.9540e-02,  4.9588e-02, -1.5069e-02, -5.3171e-03, -6.4594e-02,\n          9.6680e-02, -3.3807e-02,  4.0115e-02,  3.5860e-02,  4.9676e-02,\n         -2.0893e-03, -1.7409e-01,  1.0824e-01,  1.5941e-01,  1.3499e-01,\n          1.4287e-01, -1.6110e-01],\n        [ 3.4659e-02,  1.2537e-02, -3.1498e-02,  1.0366e-01, -6.3337e-02,\n         -2.5884e-02,  1.8781e-02,  9.0486e-02,  1.5707e-01, -6.1869e-02,\n          6.2984e-02,  1.4653e-01,  8.0680e-02, -1.2306e-01, -4.7666e-02,\n          3.3733e-03, -1.0902e-01, -4.2343e-02,  9.7283e-02, -5.4065e-03,\n         -7.8753e-02, -4.2913e-02, -6.5487e-02,  1.3057e-01,  1.6083e-01,\n         -7.9843e-02, -2.4073e-02,  8.7047e-03,  4.5668e-02,  3.9496e-03,\n          1.1174e-02,  4.4193e-02],\n        [-9.3927e-02, -1.0347e-01,  1.7353e-01, -1.3537e-01, -1.2909e-01,\n          1.7121e-01, -1.7563e-01, -7.7516e-03,  4.3109e-02, -1.0745e-01,\n         -8.4240e-02,  1.5175e-01, -1.4602e-01,  1.0559e-02,  1.2615e-01,\n         -7.4548e-02,  1.2829e-01,  5.2794e-02,  3.4449e-02,  8.3174e-02,\n         -6.9289e-02, -3.4459e-02, -7.5164e-03, -1.6334e-01, -1.5583e-01,\n         -1.2759e-01, -1.6388e-01, -1.4525e-01, -1.2776e-01,  8.2284e-02,\n          1.3055e-01, -3.6496e-02],\n        [-4.6909e-02, -1.2021e-01,  9.0765e-02, -1.6348e-01,  1.6894e-02,\n         -3.8981e-02, -8.5635e-02,  3.3265e-02, -1.4658e-01,  1.4214e-01,\n         -1.3550e-01, -1.5063e-01,  1.5550e-01,  7.8763e-02,  1.6142e-01,\n          1.0298e-01, -9.8475e-02,  6.3988e-02,  7.5235e-02,  1.7123e-01,\n          9.0691e-02, -8.1793e-02, -2.6971e-02, -1.3348e-01, -1.9475e-02,\n         -1.4423e-01, -1.3316e-01, -2.5710e-02,  9.8496e-02,  4.3922e-02,\n          9.4316e-02,  1.6760e-01],\n        [-1.2195e-01, -1.6695e-01,  9.0789e-02, -1.3547e-01,  5.5836e-02,\n         -1.2770e-01,  9.3187e-02, -1.3338e-01, -9.2734e-02,  3.6107e-02,\n          8.1975e-02,  1.6370e-01,  1.7172e-01,  3.7129e-02,  6.9291e-02,\n          1.1100e-01, -5.6094e-02, -8.9844e-02, -1.1485e-01,  9.8335e-02,\n          1.2433e-01, -1.0544e-01, -3.9548e-05,  2.9059e-02,  1.3135e-02,\n         -1.2568e-01,  9.5330e-02, -3.4353e-02,  1.3925e-01, -1.0041e-01,\n          1.0022e-01, -1.3952e-01],\n        [-1.2599e-01,  4.8728e-02,  1.1227e-01, -2.1095e-02, -7.7303e-02,\n          7.7707e-02, -9.8773e-02, -2.4659e-02, -1.4189e-01, -1.3893e-01,\n          1.5092e-01,  4.1471e-02,  1.3337e-01,  1.4599e-01,  1.0058e-01,\n         -9.4369e-02,  5.5250e-02, -1.2133e-01, -1.6493e-01, -1.4906e-01,\n         -5.7461e-02, -1.5912e-01, -7.5955e-02,  3.4469e-02,  6.3329e-02,\n          1.7029e-01, -1.1363e-01, -1.0526e-01, -1.0559e-01, -2.7503e-02,\n         -1.6885e-01,  2.1211e-02],\n        [ 1.4364e-01,  1.0293e-01,  3.2361e-02, -1.0672e-01,  1.2837e-01,\n         -1.6428e-01,  1.1740e-01,  1.4718e-01,  8.2165e-02,  1.4147e-01,\n          1.1127e-01, -1.4959e-01, -1.0929e-01,  1.0597e-01,  1.3861e-01,\n         -1.1390e-01, -1.0742e-01,  1.2648e-01,  2.9165e-02, -2.3133e-02,\n         -2.6576e-02,  1.9142e-02, -1.4862e-01,  1.0227e-01,  3.7301e-02,\n          1.1900e-01, -7.6005e-02,  4.6840e-02, -3.7155e-02, -6.7075e-02,\n         -5.8409e-02, -1.4413e-01],\n        [ 9.9191e-02, -1.7603e-01,  7.1191e-02,  1.2124e-01,  1.0987e-01,\n          2.4785e-02,  1.5645e-01, -9.9460e-02, -1.1274e-02,  1.0891e-01,\n         -1.7195e-01,  2.9344e-02, -6.2919e-02,  5.0003e-02, -4.4998e-02,\n          1.6498e-01, -4.8961e-02, -1.6050e-01, -3.7043e-02, -4.1699e-02,\n          1.2418e-01,  1.7066e-01, -5.6710e-02,  1.7052e-01, -4.8934e-02,\n         -1.6081e-02,  1.1149e-01, -1.0785e-01, -5.5164e-02, -1.6619e-01,\n         -9.1279e-02, -8.1340e-02],\n        [-2.7294e-02, -1.3992e-01, -1.4422e-01,  1.6957e-01,  1.6633e-01,\n         -4.3540e-03,  9.1418e-02,  7.0092e-02, -1.5093e-01,  3.1513e-02,\n          7.8655e-02, -1.7515e-03, -1.4904e-01, -1.2170e-01,  1.2932e-01,\n          3.9637e-02, -8.2655e-02,  1.6344e-01,  1.3408e-01, -4.7515e-02,\n         -1.5955e-01, -7.8662e-02,  2.4606e-02,  1.2371e-01,  7.6130e-02,\n          1.7024e-01, -3.7171e-02, -1.5248e-01,  2.5240e-02,  7.5923e-02,\n          1.0446e-01,  1.2890e-01],\n        [ 1.0605e-01, -7.1972e-02,  8.5944e-02, -1.0770e-01,  1.6071e-01,\n          4.5508e-02, -4.7595e-02,  5.6434e-02, -2.2205e-02,  8.1915e-02,\n         -5.6778e-02, -5.2207e-02,  2.3875e-02, -1.2005e-01, -1.1016e-01,\n         -7.3336e-02, -9.5448e-02, -3.5653e-02,  1.5275e-01, -6.7968e-02,\n         -1.2060e-01,  6.8456e-02,  1.2338e-01,  1.9957e-02, -1.0288e-01,\n          3.6957e-03,  9.6232e-02,  9.7940e-03, -1.0042e-01, -2.1063e-02,\n          7.9223e-02, -6.7758e-02],\n        [-8.7391e-02,  1.5927e-01,  2.0581e-02,  1.4512e-01,  8.0939e-02,\n         -1.0466e-01,  2.0026e-02, -1.1229e-01,  9.8065e-02,  1.0248e-01,\n         -4.0873e-02, -1.7395e-01, -1.4164e-01, -5.3604e-04, -1.8133e-02,\n         -1.0301e-01, -6.0457e-02, -6.0293e-02, -1.7164e-02,  1.3676e-01,\n         -7.1380e-03,  1.3070e-01, -5.6071e-02,  1.2217e-01, -3.1659e-02,\n         -1.6658e-02, -1.1902e-01, -5.0991e-02, -3.1397e-02, -4.0689e-02,\n          1.2704e-01, -9.4429e-02],\n        [-8.1938e-02, -1.2883e-01, -5.7269e-02, -6.0329e-02,  1.3836e-01,\n         -1.3428e-01,  1.8570e-02,  7.3464e-02,  1.4849e-01, -4.8081e-02,\n         -9.9823e-02,  4.3900e-03, -9.2844e-02, -1.0195e-01,  1.4028e-01,\n         -1.2123e-01,  3.6499e-02,  1.2408e-01, -3.8831e-02, -1.0320e-01,\n         -2.0513e-02,  1.1683e-01,  9.6758e-02, -1.8927e-02, -8.1323e-02,\n         -4.2233e-02,  4.4578e-02, -1.1043e-01,  1.0091e-01,  1.0826e-01,\n          1.4010e-01,  2.4381e-02],\n        [ 1.7249e-01, -4.5735e-02, -6.2928e-02, -1.4716e-02,  2.7256e-02,\n         -5.0338e-02,  1.0613e-01, -4.8279e-02, -9.5470e-02, -5.7194e-02,\n          1.4852e-02, -1.2484e-01, -6.5122e-02, -7.2031e-03, -2.8766e-02,\n          1.6485e-01,  1.6519e-01, -1.2966e-01, -8.0033e-02, -8.1188e-02,\n          8.4209e-02, -1.2157e-01, -1.2335e-01, -4.8807e-03,  1.5607e-01,\n         -1.4331e-01,  2.5753e-03, -3.6003e-02,  8.1301e-03, -2.4694e-02,\n          1.0688e-01,  1.7478e-01],\n        [ 1.7628e-01,  1.3987e-01,  9.5416e-02,  1.0336e-01,  1.7502e-01,\n         -3.9005e-02,  7.6811e-03,  1.4975e-01, -5.3807e-02,  8.6679e-02,\n         -1.2784e-01, -1.7589e-01, -5.2361e-02, -8.0552e-02,  2.9016e-02,\n          1.5805e-01, -1.6192e-01,  5.6274e-02, -1.2064e-01,  9.5657e-02,\n         -3.7571e-02,  1.2891e-01, -1.4143e-01,  1.7228e-01, -1.6167e-01,\n         -3.4370e-02, -1.4070e-01, -1.3621e-01, -1.0307e-01,  8.7644e-02,\n          1.1358e-01, -4.0964e-02],\n        [-1.0669e-01,  5.3236e-02,  1.3573e-01,  4.0489e-02, -4.1078e-02,\n          4.9052e-02,  2.0366e-02, -6.5163e-05,  1.3314e-01,  1.6479e-02,\n          7.2406e-02, -4.5271e-02, -2.6551e-02,  1.6357e-01,  1.2799e-01,\n          9.3266e-02, -1.5879e-01, -1.3529e-01,  3.9323e-02, -1.5664e-01,\n          2.3775e-02, -1.4044e-02,  1.5422e-03, -1.9354e-02,  1.4702e-01,\n         -2.3921e-02,  1.5356e-01,  1.5129e-01,  5.5780e-02, -2.6696e-02,\n         -2.3542e-02, -2.2843e-02],\n        [ 5.9073e-02, -6.9157e-02, -9.0566e-02,  1.2196e-01, -1.0701e-01,\n         -8.9412e-02,  1.3941e-01, -9.9527e-02, -1.7052e-02,  3.8802e-02,\n          9.9091e-02, -1.4004e-01,  8.4012e-02,  1.4389e-01,  9.7625e-02,\n         -1.3135e-01, -1.3672e-01, -4.7234e-02,  1.7869e-02, -1.0708e-01,\n         -1.3587e-01,  5.3410e-02, -6.1777e-02,  1.5851e-01, -8.9102e-02,\n         -8.6370e-02,  2.5926e-02, -9.9829e-02,  2.7903e-02, -1.6668e-01,\n         -3.5327e-02, -9.4563e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0139, -0.2270,  0.0161,  0.1906, -0.1642, -0.0021, -0.0495, -0.1037],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1950,  0.1099,  0.1810,  0.1211,  0.2122,  0.0006, -0.1101, -0.2478,\n          0.2465,  0.0778, -0.1187, -0.0201,  0.0665, -0.1407, -0.0321, -0.2162],\n        [ 0.1251,  0.0295, -0.1294,  0.0915, -0.0452,  0.2376, -0.2477,  0.2241,\n          0.1722,  0.2059, -0.1798, -0.0491,  0.0947,  0.0054,  0.0674, -0.1502],\n        [-0.2492, -0.1592, -0.2144,  0.2403, -0.2309, -0.0831,  0.1411, -0.0675,\n         -0.0647,  0.1120, -0.0922,  0.1873,  0.0556, -0.0356, -0.0099, -0.0656],\n        [ 0.1675, -0.0958, -0.1815,  0.1354, -0.1320,  0.0767,  0.0580,  0.2475,\n          0.0711,  0.1976,  0.2154,  0.1538, -0.0768,  0.0855, -0.0287, -0.0584],\n        [-0.0867, -0.0795,  0.0546,  0.2250, -0.0439, -0.1835, -0.1635,  0.0215,\n          0.2046,  0.0619,  0.0400,  0.0092, -0.1826,  0.2013,  0.1806, -0.0865],\n        [ 0.2106, -0.2119, -0.1663,  0.2334,  0.1297, -0.0357,  0.2267,  0.1470,\n         -0.0857, -0.1483, -0.1986,  0.0063, -0.1999,  0.0046, -0.1111,  0.2441],\n        [-0.1188,  0.2159, -0.2185, -0.0464, -0.0454, -0.1584, -0.0054,  0.0275,\n         -0.0204,  0.0687, -0.1090, -0.1085, -0.0602, -0.0722,  0.1728,  0.0537],\n        [ 0.2170,  0.1546, -0.1751, -0.2132,  0.1982,  0.1413,  0.2089,  0.1749,\n          0.0003,  0.1094, -0.0786, -0.0683, -0.0043, -0.1569, -0.1412,  0.0419]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1159], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1721, -0.1495, -0.1403,  0.1098,  0.1460, -0.1511, -0.1052, -0.0012]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2995,  0.2658, -0.3144, -0.3471, -0.2865, -0.1417,  0.1387, -0.1950],\n        [-0.1562,  0.0246, -0.1119,  0.2914,  0.2275, -0.2017,  0.0207, -0.2928],\n        [ 0.3335, -0.3219,  0.2427,  0.2058,  0.0868, -0.0015,  0.2865, -0.3204],\n        [ 0.2763, -0.0424, -0.0793,  0.2342,  0.3161,  0.1409, -0.1081, -0.0098],\n        [ 0.0067, -0.1938, -0.1684, -0.1352,  0.2127, -0.2466, -0.2743,  0.0637],\n        [ 0.2966, -0.1457,  0.0233, -0.2299,  0.2299,  0.2125, -0.1088, -0.2911],\n        [-0.0462,  0.1356,  0.0398, -0.1351, -0.0403,  0.2323,  0.2776,  0.0437],\n        [-0.1627,  0.1636, -0.3336,  0.0008, -0.3532,  0.1645,  0.0104,  0.1871],\n        [ 0.2617,  0.2204,  0.3169,  0.3029,  0.2598, -0.3485,  0.1146,  0.1638],\n        [-0.2655,  0.1576,  0.1535, -0.1940,  0.1696,  0.1448,  0.1506,  0.0088],\n        [-0.2042,  0.1826,  0.1060, -0.3371,  0.1713, -0.2645, -0.0510,  0.2981],\n        [ 0.0630,  0.0792,  0.3199, -0.1892, -0.1100, -0.2581, -0.2377, -0.2755],\n        [ 0.1030,  0.2486,  0.0830,  0.0782,  0.2773,  0.2761,  0.0677, -0.2775],\n        [ 0.3499, -0.0238,  0.1411, -0.1752, -0.2594,  0.2715,  0.1364,  0.0869],\n        [-0.0449,  0.1846, -0.3120,  0.0340, -0.1789, -0.3205,  0.0160,  0.2342],\n        [-0.0985,  0.0258,  0.1965, -0.1808,  0.3192, -0.2556,  0.1862,  0.3059],\n        [-0.3474,  0.2893, -0.1042, -0.2810, -0.3515,  0.1725,  0.1866,  0.0393],\n        [-0.3478, -0.3275,  0.1418, -0.2514, -0.1937, -0.3436, -0.0804,  0.1252],\n        [-0.1159,  0.0461, -0.1193, -0.1282,  0.0611, -0.2857, -0.2517, -0.2915],\n        [ 0.0134, -0.1644, -0.0249, -0.2462, -0.3475, -0.1048,  0.3405,  0.3240],\n        [ 0.1311, -0.1472, -0.0438, -0.1266, -0.2520, -0.2834, -0.2280,  0.0819],\n        [-0.3014, -0.1352, -0.0440, -0.1497,  0.2958,  0.0696, -0.0894, -0.0704],\n        [ 0.0509, -0.1425,  0.0441, -0.0171, -0.0108, -0.0761, -0.0255,  0.1223],\n        [ 0.2112,  0.0121, -0.3193, -0.2682,  0.0221,  0.3215,  0.0143,  0.0826],\n        [ 0.0245, -0.0689, -0.2354,  0.1593, -0.0443,  0.2794, -0.3362, -0.3087],\n        [ 0.2468,  0.3455,  0.0310, -0.1688,  0.3289, -0.2298,  0.0963, -0.2373],\n        [ 0.0406, -0.3045,  0.1450, -0.2659, -0.0910,  0.2822, -0.0590, -0.2679],\n        [ 0.1272,  0.2592,  0.3046,  0.0677,  0.2694, -0.3522, -0.0091,  0.1570],\n        [ 0.0335, -0.1275,  0.1856,  0.2144, -0.1624,  0.0872,  0.0379, -0.1674],\n        [-0.3278, -0.1481,  0.1365, -0.3213,  0.2569, -0.0250, -0.1515,  0.0216],\n        [-0.0591, -0.2315,  0.2201,  0.0448,  0.1279,  0.2432,  0.1493, -0.1940],\n        [ 0.1291, -0.3294,  0.0581, -0.3417, -0.1535,  0.1375,  0.2899, -0.1588]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0731, -0.0362, -0.0341, -0.2312,  0.1192,  0.1816,  0.2142, -0.2474,\n         0.2083, -0.1203, -0.1563, -0.2339, -0.0378,  0.2381, -0.1713,  0.0317,\n         0.1328, -0.0117, -0.2603, -0.0921,  0.2619,  0.1610,  0.0612, -0.1312,\n        -0.0064, -0.3196, -0.0324,  0.2852, -0.1671, -0.3334, -0.1404,  0.3526],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.3207e-01,  8.2332e-02, -3.1429e-02, -7.4704e-02, -6.6868e-02,\n         -1.3304e-01, -1.0275e-01, -1.4820e-01, -1.4391e-01,  5.5679e-02,\n          6.0477e-02,  1.1125e-01, -3.1763e-02,  1.5677e-01, -1.5350e-01,\n          7.9540e-02,  4.9588e-02, -1.5069e-02, -5.3171e-03, -6.4594e-02,\n          9.6680e-02, -3.3807e-02,  4.0115e-02,  3.5860e-02,  4.9676e-02,\n         -2.0893e-03, -1.7409e-01,  1.0824e-01,  1.5941e-01,  1.3499e-01,\n          1.4287e-01, -1.6110e-01],\n        [ 3.4659e-02,  1.2537e-02, -3.1498e-02,  1.0366e-01, -6.3337e-02,\n         -2.5884e-02,  1.8781e-02,  9.0486e-02,  1.5707e-01, -6.1869e-02,\n          6.2984e-02,  1.4653e-01,  8.0680e-02, -1.2306e-01, -4.7666e-02,\n          3.3733e-03, -1.0902e-01, -4.2343e-02,  9.7283e-02, -5.4065e-03,\n         -7.8753e-02, -4.2913e-02, -6.5487e-02,  1.3057e-01,  1.6083e-01,\n         -7.9843e-02, -2.4073e-02,  8.7047e-03,  4.5668e-02,  3.9496e-03,\n          1.1174e-02,  4.4193e-02],\n        [-9.3927e-02, -1.0347e-01,  1.7353e-01, -1.3537e-01, -1.2909e-01,\n          1.7121e-01, -1.7563e-01, -7.7516e-03,  4.3109e-02, -1.0745e-01,\n         -8.4240e-02,  1.5175e-01, -1.4602e-01,  1.0559e-02,  1.2615e-01,\n         -7.4548e-02,  1.2829e-01,  5.2794e-02,  3.4449e-02,  8.3174e-02,\n         -6.9289e-02, -3.4459e-02, -7.5164e-03, -1.6334e-01, -1.5583e-01,\n         -1.2759e-01, -1.6388e-01, -1.4525e-01, -1.2776e-01,  8.2284e-02,\n          1.3055e-01, -3.6496e-02],\n        [-4.6909e-02, -1.2021e-01,  9.0765e-02, -1.6348e-01,  1.6894e-02,\n         -3.8981e-02, -8.5635e-02,  3.3265e-02, -1.4658e-01,  1.4214e-01,\n         -1.3550e-01, -1.5063e-01,  1.5550e-01,  7.8763e-02,  1.6142e-01,\n          1.0298e-01, -9.8475e-02,  6.3988e-02,  7.5235e-02,  1.7123e-01,\n          9.0691e-02, -8.1793e-02, -2.6971e-02, -1.3348e-01, -1.9475e-02,\n         -1.4423e-01, -1.3316e-01, -2.5710e-02,  9.8496e-02,  4.3922e-02,\n          9.4316e-02,  1.6760e-01],\n        [-1.2195e-01, -1.6695e-01,  9.0789e-02, -1.3547e-01,  5.5836e-02,\n         -1.2770e-01,  9.3187e-02, -1.3338e-01, -9.2734e-02,  3.6107e-02,\n          8.1975e-02,  1.6370e-01,  1.7172e-01,  3.7129e-02,  6.9291e-02,\n          1.1100e-01, -5.6094e-02, -8.9844e-02, -1.1485e-01,  9.8335e-02,\n          1.2433e-01, -1.0544e-01, -3.9548e-05,  2.9059e-02,  1.3135e-02,\n         -1.2568e-01,  9.5330e-02, -3.4353e-02,  1.3925e-01, -1.0041e-01,\n          1.0022e-01, -1.3952e-01],\n        [-1.2599e-01,  4.8728e-02,  1.1227e-01, -2.1095e-02, -7.7303e-02,\n          7.7707e-02, -9.8773e-02, -2.4659e-02, -1.4189e-01, -1.3893e-01,\n          1.5092e-01,  4.1471e-02,  1.3337e-01,  1.4599e-01,  1.0058e-01,\n         -9.4369e-02,  5.5250e-02, -1.2133e-01, -1.6493e-01, -1.4906e-01,\n         -5.7461e-02, -1.5912e-01, -7.5955e-02,  3.4469e-02,  6.3329e-02,\n          1.7029e-01, -1.1363e-01, -1.0526e-01, -1.0559e-01, -2.7503e-02,\n         -1.6885e-01,  2.1211e-02],\n        [ 1.4364e-01,  1.0293e-01,  3.2361e-02, -1.0672e-01,  1.2837e-01,\n         -1.6428e-01,  1.1740e-01,  1.4718e-01,  8.2165e-02,  1.4147e-01,\n          1.1127e-01, -1.4959e-01, -1.0929e-01,  1.0597e-01,  1.3861e-01,\n         -1.1390e-01, -1.0742e-01,  1.2648e-01,  2.9165e-02, -2.3133e-02,\n         -2.6576e-02,  1.9142e-02, -1.4862e-01,  1.0227e-01,  3.7301e-02,\n          1.1900e-01, -7.6005e-02,  4.6840e-02, -3.7155e-02, -6.7075e-02,\n         -5.8409e-02, -1.4413e-01],\n        [ 9.9191e-02, -1.7603e-01,  7.1191e-02,  1.2124e-01,  1.0987e-01,\n          2.4785e-02,  1.5645e-01, -9.9460e-02, -1.1274e-02,  1.0891e-01,\n         -1.7195e-01,  2.9344e-02, -6.2919e-02,  5.0003e-02, -4.4998e-02,\n          1.6498e-01, -4.8961e-02, -1.6050e-01, -3.7043e-02, -4.1699e-02,\n          1.2418e-01,  1.7066e-01, -5.6710e-02,  1.7052e-01, -4.8934e-02,\n         -1.6081e-02,  1.1149e-01, -1.0785e-01, -5.5164e-02, -1.6619e-01,\n         -9.1279e-02, -8.1340e-02],\n        [-2.7294e-02, -1.3992e-01, -1.4422e-01,  1.6957e-01,  1.6633e-01,\n         -4.3540e-03,  9.1418e-02,  7.0092e-02, -1.5093e-01,  3.1513e-02,\n          7.8655e-02, -1.7515e-03, -1.4904e-01, -1.2170e-01,  1.2932e-01,\n          3.9637e-02, -8.2655e-02,  1.6344e-01,  1.3408e-01, -4.7515e-02,\n         -1.5955e-01, -7.8662e-02,  2.4606e-02,  1.2371e-01,  7.6130e-02,\n          1.7024e-01, -3.7171e-02, -1.5248e-01,  2.5240e-02,  7.5923e-02,\n          1.0446e-01,  1.2890e-01],\n        [ 1.0605e-01, -7.1972e-02,  8.5944e-02, -1.0770e-01,  1.6071e-01,\n          4.5508e-02, -4.7595e-02,  5.6434e-02, -2.2205e-02,  8.1915e-02,\n         -5.6778e-02, -5.2207e-02,  2.3875e-02, -1.2005e-01, -1.1016e-01,\n         -7.3336e-02, -9.5448e-02, -3.5653e-02,  1.5275e-01, -6.7968e-02,\n         -1.2060e-01,  6.8456e-02,  1.2338e-01,  1.9957e-02, -1.0288e-01,\n          3.6957e-03,  9.6232e-02,  9.7940e-03, -1.0042e-01, -2.1063e-02,\n          7.9223e-02, -6.7758e-02],\n        [-8.7391e-02,  1.5927e-01,  2.0581e-02,  1.4512e-01,  8.0939e-02,\n         -1.0466e-01,  2.0026e-02, -1.1229e-01,  9.8065e-02,  1.0248e-01,\n         -4.0873e-02, -1.7395e-01, -1.4164e-01, -5.3604e-04, -1.8133e-02,\n         -1.0301e-01, -6.0457e-02, -6.0293e-02, -1.7164e-02,  1.3676e-01,\n         -7.1380e-03,  1.3070e-01, -5.6071e-02,  1.2217e-01, -3.1659e-02,\n         -1.6658e-02, -1.1902e-01, -5.0991e-02, -3.1397e-02, -4.0689e-02,\n          1.2704e-01, -9.4429e-02],\n        [-8.1938e-02, -1.2883e-01, -5.7269e-02, -6.0329e-02,  1.3836e-01,\n         -1.3428e-01,  1.8570e-02,  7.3464e-02,  1.4849e-01, -4.8081e-02,\n         -9.9823e-02,  4.3900e-03, -9.2844e-02, -1.0195e-01,  1.4028e-01,\n         -1.2123e-01,  3.6499e-02,  1.2408e-01, -3.8831e-02, -1.0320e-01,\n         -2.0513e-02,  1.1683e-01,  9.6758e-02, -1.8927e-02, -8.1323e-02,\n         -4.2233e-02,  4.4578e-02, -1.1043e-01,  1.0091e-01,  1.0826e-01,\n          1.4010e-01,  2.4381e-02],\n        [ 1.7249e-01, -4.5735e-02, -6.2928e-02, -1.4716e-02,  2.7256e-02,\n         -5.0338e-02,  1.0613e-01, -4.8279e-02, -9.5470e-02, -5.7194e-02,\n          1.4852e-02, -1.2484e-01, -6.5122e-02, -7.2031e-03, -2.8766e-02,\n          1.6485e-01,  1.6519e-01, -1.2966e-01, -8.0033e-02, -8.1188e-02,\n          8.4209e-02, -1.2157e-01, -1.2335e-01, -4.8807e-03,  1.5607e-01,\n         -1.4331e-01,  2.5753e-03, -3.6003e-02,  8.1301e-03, -2.4694e-02,\n          1.0688e-01,  1.7478e-01],\n        [ 1.7628e-01,  1.3987e-01,  9.5416e-02,  1.0336e-01,  1.7502e-01,\n         -3.9005e-02,  7.6811e-03,  1.4975e-01, -5.3807e-02,  8.6679e-02,\n         -1.2784e-01, -1.7589e-01, -5.2361e-02, -8.0552e-02,  2.9016e-02,\n          1.5805e-01, -1.6192e-01,  5.6274e-02, -1.2064e-01,  9.5657e-02,\n         -3.7571e-02,  1.2891e-01, -1.4143e-01,  1.7228e-01, -1.6167e-01,\n         -3.4370e-02, -1.4070e-01, -1.3621e-01, -1.0307e-01,  8.7644e-02,\n          1.1358e-01, -4.0964e-02],\n        [-1.0669e-01,  5.3236e-02,  1.3573e-01,  4.0489e-02, -4.1078e-02,\n          4.9052e-02,  2.0366e-02, -6.5163e-05,  1.3314e-01,  1.6479e-02,\n          7.2406e-02, -4.5271e-02, -2.6551e-02,  1.6357e-01,  1.2799e-01,\n          9.3266e-02, -1.5879e-01, -1.3529e-01,  3.9323e-02, -1.5664e-01,\n          2.3775e-02, -1.4044e-02,  1.5422e-03, -1.9354e-02,  1.4702e-01,\n         -2.3921e-02,  1.5356e-01,  1.5129e-01,  5.5780e-02, -2.6696e-02,\n         -2.3542e-02, -2.2843e-02],\n        [ 5.9073e-02, -6.9157e-02, -9.0566e-02,  1.2196e-01, -1.0701e-01,\n         -8.9412e-02,  1.3941e-01, -9.9527e-02, -1.7052e-02,  3.8802e-02,\n          9.9091e-02, -1.4004e-01,  8.4012e-02,  1.4389e-01,  9.7625e-02,\n         -1.3135e-01, -1.3672e-01, -4.7234e-02,  1.7869e-02, -1.0708e-01,\n         -1.3587e-01,  5.3410e-02, -6.1777e-02,  1.5851e-01, -8.9102e-02,\n         -8.6370e-02,  2.5926e-02, -9.9829e-02,  2.7903e-02, -1.6668e-01,\n         -3.5327e-02, -9.4563e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1176,  0.0387, -0.0413,  0.1283,  0.0936, -0.0779,  0.0717,  0.0358,\n        -0.0899, -0.0770,  0.0600,  0.0952, -0.1395,  0.1142,  0.0440, -0.1272],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1950,  0.1099,  0.1810,  0.1211,  0.2122,  0.0006, -0.1101, -0.2478,\n          0.2465,  0.0778, -0.1187, -0.0201,  0.0665, -0.1407, -0.0321, -0.2162],\n        [ 0.1251,  0.0295, -0.1294,  0.0915, -0.0452,  0.2376, -0.2477,  0.2241,\n          0.1722,  0.2059, -0.1798, -0.0491,  0.0947,  0.0054,  0.0674, -0.1502],\n        [-0.2492, -0.1592, -0.2144,  0.2403, -0.2309, -0.0831,  0.1411, -0.0675,\n         -0.0647,  0.1120, -0.0922,  0.1873,  0.0556, -0.0356, -0.0099, -0.0656],\n        [ 0.1675, -0.0958, -0.1815,  0.1354, -0.1320,  0.0767,  0.0580,  0.2475,\n          0.0711,  0.1976,  0.2154,  0.1538, -0.0768,  0.0855, -0.0287, -0.0584],\n        [-0.0867, -0.0795,  0.0546,  0.2250, -0.0439, -0.1835, -0.1635,  0.0215,\n          0.2046,  0.0619,  0.0400,  0.0092, -0.1826,  0.2013,  0.1806, -0.0865],\n        [ 0.2106, -0.2119, -0.1663,  0.2334,  0.1297, -0.0357,  0.2267,  0.1470,\n         -0.0857, -0.1483, -0.1986,  0.0063, -0.1999,  0.0046, -0.1111,  0.2441],\n        [-0.1188,  0.2159, -0.2185, -0.0464, -0.0454, -0.1584, -0.0054,  0.0275,\n         -0.0204,  0.0687, -0.1090, -0.1085, -0.0602, -0.0722,  0.1728,  0.0537],\n        [ 0.2170,  0.1546, -0.1751, -0.2132,  0.1982,  0.1413,  0.2089,  0.1749,\n          0.0003,  0.1094, -0.0786, -0.0683, -0.0043, -0.1569, -0.1412,  0.0419]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0139, -0.2270,  0.0161,  0.1906, -0.1642, -0.0021, -0.0495, -0.1037],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1721, -0.1495, -0.1403,  0.1098,  0.1460, -0.1511, -0.1052, -0.0012]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1159], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000002554CA662F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x00000255150B8C70>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s305120000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s305120000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0731, -0.0362, -0.0341, -0.2312,  0.1192,  0.1816,  0.2142, -0.2474,\n         0.2083, -0.1203, -0.1563, -0.2339, -0.0378,  0.2381, -0.1713,  0.0317,\n         0.1328, -0.0117, -0.2603, -0.0921,  0.2619,  0.1610,  0.0612, -0.1312,\n        -0.0064, -0.3196, -0.0324,  0.2852, -0.1671, -0.3334, -0.1404,  0.3526],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2995,  0.2658, -0.3144, -0.3471, -0.2865, -0.1417,  0.1387, -0.1950],\n        [-0.1562,  0.0246, -0.1119,  0.2914,  0.2275, -0.2017,  0.0207, -0.2928],\n        [ 0.3335, -0.3219,  0.2427,  0.2058,  0.0868, -0.0015,  0.2865, -0.3204],\n        [ 0.2763, -0.0424, -0.0793,  0.2342,  0.3161,  0.1409, -0.1081, -0.0098],\n        [ 0.0067, -0.1938, -0.1684, -0.1352,  0.2127, -0.2466, -0.2743,  0.0637],\n        [ 0.2966, -0.1457,  0.0233, -0.2299,  0.2299,  0.2125, -0.1088, -0.2911],\n        [-0.0462,  0.1356,  0.0398, -0.1351, -0.0403,  0.2323,  0.2776,  0.0437],\n        [-0.1627,  0.1636, -0.3336,  0.0008, -0.3532,  0.1645,  0.0104,  0.1871],\n        [ 0.2617,  0.2204,  0.3169,  0.3029,  0.2598, -0.3485,  0.1146,  0.1638],\n        [-0.2655,  0.1576,  0.1535, -0.1940,  0.1696,  0.1448,  0.1506,  0.0088],\n        [-0.2042,  0.1826,  0.1060, -0.3371,  0.1713, -0.2645, -0.0510,  0.2981],\n        [ 0.0630,  0.0792,  0.3199, -0.1892, -0.1100, -0.2581, -0.2377, -0.2755],\n        [ 0.1030,  0.2486,  0.0830,  0.0782,  0.2773,  0.2761,  0.0677, -0.2775],\n        [ 0.3499, -0.0238,  0.1411, -0.1752, -0.2594,  0.2715,  0.1364,  0.0869],\n        [-0.0449,  0.1846, -0.3120,  0.0340, -0.1789, -0.3205,  0.0160,  0.2342],\n        [-0.0985,  0.0258,  0.1965, -0.1808,  0.3192, -0.2556,  0.1862,  0.3059],\n        [-0.3474,  0.2893, -0.1042, -0.2810, -0.3515,  0.1725,  0.1866,  0.0393],\n        [-0.3478, -0.3275,  0.1418, -0.2514, -0.1937, -0.3436, -0.0804,  0.1252],\n        [-0.1159,  0.0461, -0.1193, -0.1282,  0.0611, -0.2857, -0.2517, -0.2915],\n        [ 0.0134, -0.1644, -0.0249, -0.2462, -0.3475, -0.1048,  0.3405,  0.3240],\n        [ 0.1311, -0.1472, -0.0438, -0.1266, -0.2520, -0.2834, -0.2280,  0.0819],\n        [-0.3014, -0.1352, -0.0440, -0.1497,  0.2958,  0.0696, -0.0894, -0.0704],\n        [ 0.0509, -0.1425,  0.0441, -0.0171, -0.0108, -0.0761, -0.0255,  0.1223],\n        [ 0.2112,  0.0121, -0.3193, -0.2682,  0.0221,  0.3215,  0.0143,  0.0826],\n        [ 0.0245, -0.0689, -0.2354,  0.1593, -0.0443,  0.2794, -0.3362, -0.3087],\n        [ 0.2468,  0.3455,  0.0310, -0.1688,  0.3289, -0.2298,  0.0963, -0.2373],\n        [ 0.0406, -0.3045,  0.1450, -0.2659, -0.0910,  0.2822, -0.0590, -0.2679],\n        [ 0.1272,  0.2592,  0.3046,  0.0677,  0.2694, -0.3522, -0.0091,  0.1570],\n        [ 0.0335, -0.1275,  0.1856,  0.2144, -0.1624,  0.0872,  0.0379, -0.1674],\n        [-0.3278, -0.1481,  0.1365, -0.3213,  0.2569, -0.0250, -0.1515,  0.0216],\n        [-0.0591, -0.2315,  0.2201,  0.0448,  0.1279,  0.2432,  0.1493, -0.1940],\n        [ 0.1291, -0.3294,  0.0581, -0.3417, -0.1535,  0.1375,  0.2899, -0.1588]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1176,  0.0387, -0.0413,  0.1283,  0.0936, -0.0779,  0.0717,  0.0358,\n        -0.0899, -0.0770,  0.0600,  0.0952, -0.1395,  0.1142,  0.0440, -0.1272],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.3207e-01,  8.2332e-02, -3.1429e-02, -7.4704e-02, -6.6868e-02,\n         -1.3304e-01, -1.0275e-01, -1.4820e-01, -1.4391e-01,  5.5679e-02,\n          6.0477e-02,  1.1125e-01, -3.1763e-02,  1.5677e-01, -1.5350e-01,\n          7.9540e-02,  4.9588e-02, -1.5069e-02, -5.3171e-03, -6.4594e-02,\n          9.6680e-02, -3.3807e-02,  4.0115e-02,  3.5860e-02,  4.9676e-02,\n         -2.0893e-03, -1.7409e-01,  1.0824e-01,  1.5941e-01,  1.3499e-01,\n          1.4287e-01, -1.6110e-01],\n        [ 3.4659e-02,  1.2537e-02, -3.1498e-02,  1.0366e-01, -6.3337e-02,\n         -2.5884e-02,  1.8781e-02,  9.0486e-02,  1.5707e-01, -6.1869e-02,\n          6.2984e-02,  1.4653e-01,  8.0680e-02, -1.2306e-01, -4.7666e-02,\n          3.3733e-03, -1.0902e-01, -4.2343e-02,  9.7283e-02, -5.4065e-03,\n         -7.8753e-02, -4.2913e-02, -6.5487e-02,  1.3057e-01,  1.6083e-01,\n         -7.9843e-02, -2.4073e-02,  8.7047e-03,  4.5668e-02,  3.9496e-03,\n          1.1174e-02,  4.4193e-02],\n        [-9.3927e-02, -1.0347e-01,  1.7353e-01, -1.3537e-01, -1.2909e-01,\n          1.7121e-01, -1.7563e-01, -7.7516e-03,  4.3109e-02, -1.0745e-01,\n         -8.4240e-02,  1.5175e-01, -1.4602e-01,  1.0559e-02,  1.2615e-01,\n         -7.4548e-02,  1.2829e-01,  5.2794e-02,  3.4449e-02,  8.3174e-02,\n         -6.9289e-02, -3.4459e-02, -7.5164e-03, -1.6334e-01, -1.5583e-01,\n         -1.2759e-01, -1.6388e-01, -1.4525e-01, -1.2776e-01,  8.2284e-02,\n          1.3055e-01, -3.6496e-02],\n        [-4.6909e-02, -1.2021e-01,  9.0765e-02, -1.6348e-01,  1.6894e-02,\n         -3.8981e-02, -8.5635e-02,  3.3265e-02, -1.4658e-01,  1.4214e-01,\n         -1.3550e-01, -1.5063e-01,  1.5550e-01,  7.8763e-02,  1.6142e-01,\n          1.0298e-01, -9.8475e-02,  6.3988e-02,  7.5235e-02,  1.7123e-01,\n          9.0691e-02, -8.1793e-02, -2.6971e-02, -1.3348e-01, -1.9475e-02,\n         -1.4423e-01, -1.3316e-01, -2.5710e-02,  9.8496e-02,  4.3922e-02,\n          9.4316e-02,  1.6760e-01],\n        [-1.2195e-01, -1.6695e-01,  9.0789e-02, -1.3547e-01,  5.5836e-02,\n         -1.2770e-01,  9.3187e-02, -1.3338e-01, -9.2734e-02,  3.6107e-02,\n          8.1975e-02,  1.6370e-01,  1.7172e-01,  3.7129e-02,  6.9291e-02,\n          1.1100e-01, -5.6094e-02, -8.9844e-02, -1.1485e-01,  9.8335e-02,\n          1.2433e-01, -1.0544e-01, -3.9548e-05,  2.9059e-02,  1.3135e-02,\n         -1.2568e-01,  9.5330e-02, -3.4353e-02,  1.3925e-01, -1.0041e-01,\n          1.0022e-01, -1.3952e-01],\n        [-1.2599e-01,  4.8728e-02,  1.1227e-01, -2.1095e-02, -7.7303e-02,\n          7.7707e-02, -9.8773e-02, -2.4659e-02, -1.4189e-01, -1.3893e-01,\n          1.5092e-01,  4.1471e-02,  1.3337e-01,  1.4599e-01,  1.0058e-01,\n         -9.4369e-02,  5.5250e-02, -1.2133e-01, -1.6493e-01, -1.4906e-01,\n         -5.7461e-02, -1.5912e-01, -7.5955e-02,  3.4469e-02,  6.3329e-02,\n          1.7029e-01, -1.1363e-01, -1.0526e-01, -1.0559e-01, -2.7503e-02,\n         -1.6885e-01,  2.1211e-02],\n        [ 1.4364e-01,  1.0293e-01,  3.2361e-02, -1.0672e-01,  1.2837e-01,\n         -1.6428e-01,  1.1740e-01,  1.4718e-01,  8.2165e-02,  1.4147e-01,\n          1.1127e-01, -1.4959e-01, -1.0929e-01,  1.0597e-01,  1.3861e-01,\n         -1.1390e-01, -1.0742e-01,  1.2648e-01,  2.9165e-02, -2.3133e-02,\n         -2.6576e-02,  1.9142e-02, -1.4862e-01,  1.0227e-01,  3.7301e-02,\n          1.1900e-01, -7.6005e-02,  4.6840e-02, -3.7155e-02, -6.7075e-02,\n         -5.8409e-02, -1.4413e-01],\n        [ 9.9191e-02, -1.7603e-01,  7.1191e-02,  1.2124e-01,  1.0987e-01,\n          2.4785e-02,  1.5645e-01, -9.9460e-02, -1.1274e-02,  1.0891e-01,\n         -1.7195e-01,  2.9344e-02, -6.2919e-02,  5.0003e-02, -4.4998e-02,\n          1.6498e-01, -4.8961e-02, -1.6050e-01, -3.7043e-02, -4.1699e-02,\n          1.2418e-01,  1.7066e-01, -5.6710e-02,  1.7052e-01, -4.8934e-02,\n         -1.6081e-02,  1.1149e-01, -1.0785e-01, -5.5164e-02, -1.6619e-01,\n         -9.1279e-02, -8.1340e-02],\n        [-2.7294e-02, -1.3992e-01, -1.4422e-01,  1.6957e-01,  1.6633e-01,\n         -4.3540e-03,  9.1418e-02,  7.0092e-02, -1.5093e-01,  3.1513e-02,\n          7.8655e-02, -1.7515e-03, -1.4904e-01, -1.2170e-01,  1.2932e-01,\n          3.9637e-02, -8.2655e-02,  1.6344e-01,  1.3408e-01, -4.7515e-02,\n         -1.5955e-01, -7.8662e-02,  2.4606e-02,  1.2371e-01,  7.6130e-02,\n          1.7024e-01, -3.7171e-02, -1.5248e-01,  2.5240e-02,  7.5923e-02,\n          1.0446e-01,  1.2890e-01],\n        [ 1.0605e-01, -7.1972e-02,  8.5944e-02, -1.0770e-01,  1.6071e-01,\n          4.5508e-02, -4.7595e-02,  5.6434e-02, -2.2205e-02,  8.1915e-02,\n         -5.6778e-02, -5.2207e-02,  2.3875e-02, -1.2005e-01, -1.1016e-01,\n         -7.3336e-02, -9.5448e-02, -3.5653e-02,  1.5275e-01, -6.7968e-02,\n         -1.2060e-01,  6.8456e-02,  1.2338e-01,  1.9957e-02, -1.0288e-01,\n          3.6957e-03,  9.6232e-02,  9.7940e-03, -1.0042e-01, -2.1063e-02,\n          7.9223e-02, -6.7758e-02],\n        [-8.7391e-02,  1.5927e-01,  2.0581e-02,  1.4512e-01,  8.0939e-02,\n         -1.0466e-01,  2.0026e-02, -1.1229e-01,  9.8065e-02,  1.0248e-01,\n         -4.0873e-02, -1.7395e-01, -1.4164e-01, -5.3604e-04, -1.8133e-02,\n         -1.0301e-01, -6.0457e-02, -6.0293e-02, -1.7164e-02,  1.3676e-01,\n         -7.1380e-03,  1.3070e-01, -5.6071e-02,  1.2217e-01, -3.1659e-02,\n         -1.6658e-02, -1.1902e-01, -5.0991e-02, -3.1397e-02, -4.0689e-02,\n          1.2704e-01, -9.4429e-02],\n        [-8.1938e-02, -1.2883e-01, -5.7269e-02, -6.0329e-02,  1.3836e-01,\n         -1.3428e-01,  1.8570e-02,  7.3464e-02,  1.4849e-01, -4.8081e-02,\n         -9.9823e-02,  4.3900e-03, -9.2844e-02, -1.0195e-01,  1.4028e-01,\n         -1.2123e-01,  3.6499e-02,  1.2408e-01, -3.8831e-02, -1.0320e-01,\n         -2.0513e-02,  1.1683e-01,  9.6758e-02, -1.8927e-02, -8.1323e-02,\n         -4.2233e-02,  4.4578e-02, -1.1043e-01,  1.0091e-01,  1.0826e-01,\n          1.4010e-01,  2.4381e-02],\n        [ 1.7249e-01, -4.5735e-02, -6.2928e-02, -1.4716e-02,  2.7256e-02,\n         -5.0338e-02,  1.0613e-01, -4.8279e-02, -9.5470e-02, -5.7194e-02,\n          1.4852e-02, -1.2484e-01, -6.5122e-02, -7.2031e-03, -2.8766e-02,\n          1.6485e-01,  1.6519e-01, -1.2966e-01, -8.0033e-02, -8.1188e-02,\n          8.4209e-02, -1.2157e-01, -1.2335e-01, -4.8807e-03,  1.5607e-01,\n         -1.4331e-01,  2.5753e-03, -3.6003e-02,  8.1301e-03, -2.4694e-02,\n          1.0688e-01,  1.7478e-01],\n        [ 1.7628e-01,  1.3987e-01,  9.5416e-02,  1.0336e-01,  1.7502e-01,\n         -3.9005e-02,  7.6811e-03,  1.4975e-01, -5.3807e-02,  8.6679e-02,\n         -1.2784e-01, -1.7589e-01, -5.2361e-02, -8.0552e-02,  2.9016e-02,\n          1.5805e-01, -1.6192e-01,  5.6274e-02, -1.2064e-01,  9.5657e-02,\n         -3.7571e-02,  1.2891e-01, -1.4143e-01,  1.7228e-01, -1.6167e-01,\n         -3.4370e-02, -1.4070e-01, -1.3621e-01, -1.0307e-01,  8.7644e-02,\n          1.1358e-01, -4.0964e-02],\n        [-1.0669e-01,  5.3236e-02,  1.3573e-01,  4.0489e-02, -4.1078e-02,\n          4.9052e-02,  2.0366e-02, -6.5163e-05,  1.3314e-01,  1.6479e-02,\n          7.2406e-02, -4.5271e-02, -2.6551e-02,  1.6357e-01,  1.2799e-01,\n          9.3266e-02, -1.5879e-01, -1.3529e-01,  3.9323e-02, -1.5664e-01,\n          2.3775e-02, -1.4044e-02,  1.5422e-03, -1.9354e-02,  1.4702e-01,\n         -2.3921e-02,  1.5356e-01,  1.5129e-01,  5.5780e-02, -2.6696e-02,\n         -2.3542e-02, -2.2843e-02],\n        [ 5.9073e-02, -6.9157e-02, -9.0566e-02,  1.2196e-01, -1.0701e-01,\n         -8.9412e-02,  1.3941e-01, -9.9527e-02, -1.7052e-02,  3.8802e-02,\n          9.9091e-02, -1.4004e-01,  8.4012e-02,  1.4389e-01,  9.7625e-02,\n         -1.3135e-01, -1.3672e-01, -4.7234e-02,  1.7869e-02, -1.0708e-01,\n         -1.3587e-01,  5.3410e-02, -6.1777e-02,  1.5851e-01, -8.9102e-02,\n         -8.6370e-02,  2.5926e-02, -9.9829e-02,  2.7903e-02, -1.6668e-01,\n         -3.5327e-02, -9.4563e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0139, -0.2270,  0.0161,  0.1906, -0.1642, -0.0021, -0.0495, -0.1037],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1950,  0.1099,  0.1810,  0.1211,  0.2122,  0.0006, -0.1101, -0.2478,\n          0.2465,  0.0778, -0.1187, -0.0201,  0.0665, -0.1407, -0.0321, -0.2162],\n        [ 0.1251,  0.0295, -0.1294,  0.0915, -0.0452,  0.2376, -0.2477,  0.2241,\n          0.1722,  0.2059, -0.1798, -0.0491,  0.0947,  0.0054,  0.0674, -0.1502],\n        [-0.2492, -0.1592, -0.2144,  0.2403, -0.2309, -0.0831,  0.1411, -0.0675,\n         -0.0647,  0.1120, -0.0922,  0.1873,  0.0556, -0.0356, -0.0099, -0.0656],\n        [ 0.1675, -0.0958, -0.1815,  0.1354, -0.1320,  0.0767,  0.0580,  0.2475,\n          0.0711,  0.1976,  0.2154,  0.1538, -0.0768,  0.0855, -0.0287, -0.0584],\n        [-0.0867, -0.0795,  0.0546,  0.2250, -0.0439, -0.1835, -0.1635,  0.0215,\n          0.2046,  0.0619,  0.0400,  0.0092, -0.1826,  0.2013,  0.1806, -0.0865],\n        [ 0.2106, -0.2119, -0.1663,  0.2334,  0.1297, -0.0357,  0.2267,  0.1470,\n         -0.0857, -0.1483, -0.1986,  0.0063, -0.1999,  0.0046, -0.1111,  0.2441],\n        [-0.1188,  0.2159, -0.2185, -0.0464, -0.0454, -0.1584, -0.0054,  0.0275,\n         -0.0204,  0.0687, -0.1090, -0.1085, -0.0602, -0.0722,  0.1728,  0.0537],\n        [ 0.2170,  0.1546, -0.1751, -0.2132,  0.1982,  0.1413,  0.2089,  0.1749,\n          0.0003,  0.1094, -0.0786, -0.0683, -0.0043, -0.1569, -0.1412,  0.0419]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1159], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1721, -0.1495, -0.1403,  0.1098,  0.1460, -0.1511, -0.1052, -0.0012]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}