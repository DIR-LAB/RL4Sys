{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0003,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s320320000"
    },
    "max_sample_age":	250,
    "q_lr":	0.0003,
    "sample_decay":	0.8,
    "seed":	320320000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7348471b6dd0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0003,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0245,  0.1476,  0.1786, -0.2898,  0.1792,  0.0976, -0.0293,  0.1717,\n         0.1263,  0.2716, -0.3214,  0.0228,  0.3257, -0.3222,  0.2048, -0.1336,\n        -0.2207,  0.2638,  0.1821,  0.1575, -0.1327, -0.3343, -0.3307,  0.1640,\n         0.0396, -0.1656, -0.0129, -0.1892,  0.0888,  0.2554,  0.1854,  0.0732,\n        -0.0678, -0.2078, -0.1760, -0.0309, -0.1349, -0.2863,  0.3283,  0.2962,\n        -0.1638,  0.0439,  0.2741,  0.0684, -0.1737, -0.0398, -0.3145,  0.3388,\n         0.1588,  0.2498, -0.0474,  0.1154,  0.2632,  0.3482, -0.0602,  0.0411,\n        -0.3511,  0.0322, -0.3205,  0.0419, -0.2109,  0.1199,  0.1884,  0.1029,\n         0.2998, -0.0554, -0.2366, -0.1652, -0.0044, -0.2453, -0.2665, -0.2075,\n        -0.1793,  0.0266,  0.3166, -0.1779,  0.2715,  0.3217,  0.0444,  0.3210,\n        -0.0433,  0.1216, -0.2186, -0.2405, -0.1458, -0.3313, -0.2403,  0.2936,\n        -0.0805, -0.1831, -0.2027, -0.1607,  0.2746,  0.1086,  0.1866, -0.0485,\n        -0.2850,  0.2333,  0.2167, -0.2203,  0.1729, -0.2212,  0.1125, -0.1054,\n        -0.2040, -0.1298, -0.0038,  0.0805, -0.0854, -0.2207, -0.0569,  0.0579,\n        -0.3351,  0.0319,  0.3108, -0.1068, -0.2821, -0.1673, -0.0622,  0.2282,\n         0.0397,  0.2595, -0.2201, -0.2742,  0.1276,  0.2219, -0.1837, -0.3399],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0654, -0.1593, -0.0395,  ...,  0.3445, -0.0426, -0.2021],\n        [ 0.2175, -0.0065, -0.0263,  ...,  0.1934, -0.1844, -0.1595],\n        [-0.0327, -0.2934,  0.0239,  ..., -0.0614,  0.1380,  0.2092],\n        ...,\n        [ 0.0920, -0.0575, -0.1469,  ...,  0.1284, -0.3128, -0.1894],\n        [-0.0653,  0.1595, -0.2526,  ..., -0.2023,  0.3095, -0.2487],\n        [-0.2987,  0.3151,  0.0217,  ..., -0.2376, -0.2527,  0.2282]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0530,  0.0553,  0.0556,  0.0290,  0.0877, -0.0470,  0.0582, -0.0498,\n         0.0601,  0.0882, -0.0222, -0.0111,  0.0734, -0.0153, -0.0785, -0.0158,\n        -0.0753, -0.0035,  0.0097,  0.0015,  0.0522,  0.0207, -0.0730, -0.0112,\n         0.0795,  0.0123,  0.0165,  0.0242, -0.0118,  0.0611, -0.0173,  0.0692,\n         0.0206,  0.0012,  0.0785,  0.0317, -0.0234,  0.0360,  0.0581,  0.0047,\n        -0.0837, -0.0285, -0.0529,  0.0416,  0.0167, -0.0573, -0.0005,  0.0013,\n        -0.0343, -0.0837,  0.0218,  0.0621, -0.0164,  0.0010,  0.0029,  0.0654,\n        -0.0733,  0.0880,  0.0008, -0.0388,  0.0313,  0.0612,  0.0262, -0.0032,\n         0.0236,  0.0129,  0.0609, -0.0788,  0.0460, -0.0013, -0.0508, -0.0566,\n         0.0543,  0.0407, -0.0168,  0.0165, -0.0265,  0.0328, -0.0408, -0.0730,\n         0.0739,  0.0474, -0.0454,  0.0351,  0.0177, -0.0193,  0.0605, -0.0727,\n        -0.0804, -0.0324, -0.0837, -0.0239, -0.0041, -0.0281, -0.0273,  0.0436,\n        -0.0308,  0.0611,  0.0222, -0.0280,  0.0800,  0.0146,  0.0178,  0.0144,\n         0.0585,  0.0629, -0.0720,  0.0641,  0.0196, -0.0825, -0.0813,  0.0069,\n         0.0183, -0.0198, -0.0683, -0.0569,  0.0653,  0.0608, -0.0684,  0.0658,\n         0.0186,  0.0475,  0.0162,  0.0686,  0.0222, -0.0312, -0.0408,  0.0704],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 5.5143e-02,  3.8103e-02,  4.7338e-02,  ..., -3.8561e-02,\n         -2.1679e-02, -5.2085e-02],\n        [-6.0346e-02, -2.7279e-02, -6.9279e-02,  ..., -1.3924e-02,\n          3.2484e-02, -3.9552e-02],\n        [ 3.5589e-02, -8.2595e-02,  7.9503e-02,  ...,  8.8071e-02,\n          8.6833e-02, -2.2447e-03],\n        ...,\n        [ 3.5002e-02, -4.4567e-02, -3.7070e-02,  ...,  9.2955e-05,\n          4.1010e-02, -7.7940e-02],\n        [ 3.0396e-02, -5.8995e-02, -8.2630e-02,  ..., -2.2141e-02,\n          2.9968e-02,  7.8824e-02],\n        [-5.6124e-02, -3.5402e-02,  1.4551e-02,  ..., -6.5187e-02,\n          6.7032e-02,  4.2394e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0352,  0.0637,  0.0249, -0.0292], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.8489e-02, -6.4751e-02,  2.7545e-02, -3.3799e-02,  6.8943e-02,\n          7.2217e-03, -5.1802e-02,  4.7955e-02, -6.1153e-02,  9.1178e-03,\n         -1.5937e-02,  8.4773e-02, -7.1091e-02, -2.6645e-02,  6.2125e-02,\n          6.1185e-02,  3.9318e-02, -9.6497e-04, -8.5350e-02, -1.1920e-02,\n         -6.9180e-02, -3.8978e-02,  7.5858e-02, -1.5295e-02, -3.0452e-02,\n          6.6476e-03,  8.6581e-02, -4.7786e-02,  5.3368e-02,  3.2631e-02,\n          9.8653e-03, -4.5593e-02,  6.8680e-02,  6.5724e-02,  7.0825e-02,\n          5.3912e-02,  1.3442e-02, -6.0370e-02,  6.8172e-02, -4.1145e-02,\n          8.1283e-02,  4.1245e-02, -4.8678e-03, -7.5497e-02,  7.6935e-03,\n         -4.4630e-02, -3.9891e-02, -4.2991e-02,  5.1482e-02, -2.2108e-03,\n         -1.4835e-02,  7.5095e-02,  1.1986e-03, -5.4395e-02,  7.8979e-02,\n          7.7007e-02, -6.6133e-02,  4.2500e-02, -6.7606e-02,  6.2957e-02,\n         -6.3652e-02,  5.4775e-02, -3.3153e-02, -3.1533e-02,  3.0163e-02,\n          7.2802e-02,  4.8390e-02, -1.3077e-02,  6.3806e-02,  8.2522e-02,\n         -3.6479e-02, -4.3315e-02,  8.0328e-02,  8.9622e-03, -1.6471e-02,\n          7.1543e-02, -7.4479e-02, -7.6037e-02, -2.3344e-02, -7.8372e-02,\n          3.9843e-02,  2.3629e-02,  5.4469e-02,  6.1325e-02,  4.1824e-02,\n          1.1732e-02,  3.8487e-02, -2.1887e-02, -7.4032e-03,  5.8735e-02,\n         -6.7494e-03,  7.3239e-02,  3.9898e-02,  1.2696e-02, -1.8653e-02,\n         -1.0967e-02,  3.7699e-02, -7.7974e-02, -1.9768e-02,  3.1850e-02,\n         -1.2193e-02,  3.4630e-02,  3.2483e-03, -6.1689e-02, -1.3486e-02,\n         -3.2710e-02,  1.9185e-02,  5.4127e-02, -4.2682e-02,  3.7953e-03,\n          4.6405e-02,  4.9626e-02,  3.5193e-02, -5.6746e-03,  4.1795e-02,\n          1.4476e-02, -7.4852e-02, -7.9226e-02,  5.4098e-02,  1.7922e-02,\n          1.2614e-02,  1.3202e-02, -1.7342e-02,  2.2176e-02,  8.4267e-02,\n          7.7314e-02,  4.9966e-02, -8.5127e-02],\n        [ 7.9548e-02, -1.3687e-02, -1.9746e-02, -8.1197e-02,  5.0291e-02,\n         -8.5647e-02, -4.2544e-02,  7.7849e-02, -4.8398e-02,  5.0176e-02,\n          1.6428e-02,  5.5764e-02,  6.5404e-03,  6.8082e-02,  8.8287e-02,\n         -3.8149e-03,  2.5392e-02,  4.4351e-02,  6.1632e-02,  4.4926e-03,\n         -2.4745e-02, -1.4917e-03,  7.7497e-02, -7.1466e-02, -4.5747e-02,\n          2.0947e-02,  7.8337e-03,  1.2601e-02, -8.8291e-02,  3.8738e-03,\n          4.2545e-02,  1.9667e-02, -5.6083e-02, -6.9162e-02, -8.2150e-02,\n          2.6812e-02, -4.8231e-02, -4.3792e-02, -4.5864e-02,  4.6663e-02,\n         -7.9007e-02,  4.9291e-02,  5.1221e-03, -7.7185e-02, -2.1072e-02,\n          7.9735e-02,  9.2292e-03,  3.3815e-02,  6.9154e-02, -3.5311e-02,\n          8.5727e-02, -5.1761e-02, -1.7541e-02,  3.7905e-02, -8.4329e-02,\n         -7.4936e-02,  3.0974e-02, -1.3078e-02, -1.2716e-03,  2.5599e-02,\n         -3.4171e-02,  7.2130e-02, -4.8156e-03,  3.7487e-02,  3.1617e-02,\n          2.3368e-02,  5.6369e-02,  2.6475e-02,  5.5594e-02,  6.3699e-04,\n         -1.9324e-02, -7.5037e-02,  3.8935e-02,  4.6816e-02, -3.3877e-02,\n         -7.8347e-02,  6.4845e-02,  6.1472e-02,  7.6393e-03,  2.5433e-02,\n          7.6433e-02,  4.8697e-02,  6.0358e-02,  6.7309e-02,  7.7626e-02,\n         -4.0257e-03, -7.0783e-02,  4.9205e-02, -3.2209e-02,  5.0313e-02,\n         -4.3835e-03,  2.9095e-02,  1.8468e-02,  6.7519e-02,  3.0535e-02,\n         -3.1038e-02,  3.5943e-02,  7.0239e-02, -4.5728e-02,  3.4143e-02,\n          3.7069e-02,  1.2961e-02, -3.3193e-02,  8.6726e-02, -6.0338e-02,\n         -2.4166e-02,  1.9191e-02, -8.4592e-03, -4.8281e-02,  2.7412e-03,\n         -1.7736e-02, -6.1408e-02, -3.5845e-02, -8.6743e-02,  4.7157e-02,\n         -9.0130e-03, -6.1358e-02, -5.9452e-02,  1.1847e-02, -4.1394e-02,\n         -1.9675e-02,  2.6727e-02,  3.6514e-02,  1.4407e-02, -2.1987e-02,\n          5.8022e-02,  1.2162e-02, -2.7529e-03],\n        [ 2.3399e-02,  6.7034e-02, -6.4218e-02, -5.0313e-03,  1.2248e-03,\n         -2.7357e-02,  2.7691e-02,  7.6587e-02, -9.2365e-03,  7.2802e-02,\n         -4.0519e-02,  1.4513e-02,  3.6079e-02, -1.5394e-03, -8.0310e-02,\n         -7.2043e-02, -1.2082e-02,  5.3468e-02,  4.4616e-04, -2.6334e-02,\n         -6.5426e-02,  5.0957e-02, -6.2434e-02,  5.1108e-02, -2.0663e-02,\n          6.0856e-02,  4.1355e-02, -5.8239e-02,  2.5716e-02,  6.3763e-02,\n         -9.6275e-03,  5.8354e-02, -5.7300e-02, -2.0860e-02,  7.0520e-02,\n         -1.9857e-02, -6.5985e-02, -1.7488e-03,  4.0360e-02,  8.1381e-02,\n          2.4600e-02,  3.4140e-02, -2.0875e-03, -3.7127e-02,  4.1620e-03,\n         -2.8640e-02,  6.8829e-02, -2.3377e-02,  3.8544e-02,  3.3355e-02,\n         -1.1257e-02, -5.9474e-02,  3.5290e-02,  1.2748e-02,  4.5638e-02,\n         -6.5614e-02, -2.8117e-02, -8.2945e-05, -5.0281e-02, -5.0942e-02,\n          6.0642e-02, -8.6424e-03, -5.4111e-02, -7.6633e-02,  8.0143e-02,\n         -5.4274e-02,  1.3166e-02,  3.2492e-02,  2.2857e-02,  6.9459e-02,\n          8.7701e-02,  2.1964e-02, -7.3562e-02,  2.1118e-02, -4.2026e-02,\n          5.6847e-02,  4.1404e-02,  4.7949e-02, -8.8174e-02,  6.2341e-02,\n          6.9555e-02, -1.7489e-02, -7.4275e-02,  5.7804e-03, -7.4266e-02,\n          2.9231e-02,  3.7152e-02, -5.3172e-02,  7.1656e-02, -5.9499e-02,\n          4.2343e-02, -5.1615e-04, -3.6644e-02, -2.5407e-02,  2.4064e-02,\n         -2.5072e-02, -6.0883e-02,  6.4109e-02,  5.0405e-02, -7.2146e-03,\n         -7.3346e-02,  5.1836e-02,  6.6095e-02, -8.5925e-03,  2.6926e-03,\n         -7.7371e-02, -7.3267e-02,  7.8186e-02, -5.3619e-03,  1.5216e-02,\n          7.3640e-02,  1.0745e-02, -2.7086e-02, -7.5356e-02, -1.6333e-02,\n         -5.7321e-02, -4.5204e-02,  8.6899e-02, -1.2032e-02, -2.3117e-02,\n          1.5653e-02, -5.2143e-03, -3.8203e-03,  5.5208e-04,  7.8577e-02,\n         -3.7806e-03, -2.3283e-02, -5.0174e-02],\n        [-8.1118e-02,  1.6441e-02,  5.8501e-02, -4.9930e-02, -3.0766e-02,\n         -1.0781e-03, -7.8511e-04, -3.2640e-02,  2.1199e-02,  4.7202e-02,\n         -7.0348e-02,  5.3145e-02, -4.2142e-02,  6.4310e-02,  5.1742e-02,\n         -1.6382e-02,  2.8874e-02,  3.1597e-02,  8.8051e-02,  2.8203e-02,\n         -2.8710e-02,  5.3345e-02,  1.0421e-02, -1.6145e-02, -1.0417e-04,\n          6.5518e-02,  4.5032e-02,  3.8547e-02,  7.8323e-02,  4.5350e-02,\n          1.2085e-02, -5.8652e-02, -2.2620e-02, -3.1263e-02,  1.6540e-02,\n         -3.1285e-02, -2.5622e-02, -8.1617e-02,  1.3055e-02, -5.9441e-02,\n          4.3273e-02,  4.8973e-02, -6.6168e-02, -7.1508e-02,  8.0368e-02,\n          4.2323e-02, -5.7769e-02, -4.4597e-02, -4.6084e-02, -3.2356e-02,\n         -5.2658e-02, -7.7543e-02, -7.9582e-03,  7.5932e-02, -7.4238e-02,\n          2.4722e-02,  7.2806e-02, -7.6560e-02,  5.5787e-03,  7.9090e-02,\n          1.2876e-02, -6.6705e-02, -4.2631e-02, -8.7364e-02,  1.0218e-02,\n          2.6370e-02, -6.2680e-03,  5.6738e-02, -6.8050e-02,  3.1124e-02,\n          4.4242e-02,  7.5350e-02,  2.8250e-02,  8.7113e-02,  2.6918e-02,\n         -6.0572e-02, -6.2483e-02,  7.9558e-02,  2.4617e-02,  7.0146e-02,\n         -4.6024e-02,  1.8185e-02,  5.3737e-03, -2.7957e-02, -1.4294e-02,\n         -4.3624e-02,  1.7430e-03,  9.1413e-04, -4.8555e-02,  3.3498e-02,\n          6.8074e-02, -2.0033e-02, -4.1707e-02, -7.2346e-03,  5.0837e-02,\n         -5.4423e-02,  8.5131e-02,  6.3838e-02,  6.0050e-03,  5.9217e-02,\n          1.3911e-02, -6.3954e-02, -1.6525e-02,  2.8155e-02,  8.8308e-02,\n         -6.6666e-02, -4.5653e-02, -6.5139e-02,  1.9041e-03, -7.8868e-02,\n         -6.2024e-02, -6.9237e-03, -8.1530e-02, -4.2804e-02, -1.3704e-02,\n          2.8800e-03, -3.0139e-02,  7.3349e-02, -1.6756e-02,  2.3482e-02,\n         -6.9511e-02, -6.9008e-02, -5.7776e-02,  4.0743e-02, -4.4495e-02,\n         -3.2220e-02,  7.2969e-02, -5.9157e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0654, -0.1593, -0.0395,  ...,  0.3445, -0.0426, -0.2021],\n        [ 0.2175, -0.0065, -0.0263,  ...,  0.1934, -0.1844, -0.1595],\n        [-0.0327, -0.2934,  0.0239,  ..., -0.0614,  0.1380,  0.2092],\n        ...,\n        [ 0.0920, -0.0575, -0.1469,  ...,  0.1284, -0.3128, -0.1894],\n        [-0.0653,  0.1595, -0.2526,  ..., -0.2023,  0.3095, -0.2487],\n        [-0.2987,  0.3151,  0.0217,  ..., -0.2376, -0.2527,  0.2282]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0245,  0.1476,  0.1786, -0.2898,  0.1792,  0.0976, -0.0293,  0.1717,\n         0.1263,  0.2716, -0.3214,  0.0228,  0.3257, -0.3222,  0.2048, -0.1336,\n        -0.2207,  0.2638,  0.1821,  0.1575, -0.1327, -0.3343, -0.3307,  0.1640,\n         0.0396, -0.1656, -0.0129, -0.1892,  0.0888,  0.2554,  0.1854,  0.0732,\n        -0.0678, -0.2078, -0.1760, -0.0309, -0.1349, -0.2863,  0.3283,  0.2962,\n        -0.1638,  0.0439,  0.2741,  0.0684, -0.1737, -0.0398, -0.3145,  0.3388,\n         0.1588,  0.2498, -0.0474,  0.1154,  0.2632,  0.3482, -0.0602,  0.0411,\n        -0.3511,  0.0322, -0.3205,  0.0419, -0.2109,  0.1199,  0.1884,  0.1029,\n         0.2998, -0.0554, -0.2366, -0.1652, -0.0044, -0.2453, -0.2665, -0.2075,\n        -0.1793,  0.0266,  0.3166, -0.1779,  0.2715,  0.3217,  0.0444,  0.3210,\n        -0.0433,  0.1216, -0.2186, -0.2405, -0.1458, -0.3313, -0.2403,  0.2936,\n        -0.0805, -0.1831, -0.2027, -0.1607,  0.2746,  0.1086,  0.1866, -0.0485,\n        -0.2850,  0.2333,  0.2167, -0.2203,  0.1729, -0.2212,  0.1125, -0.1054,\n        -0.2040, -0.1298, -0.0038,  0.0805, -0.0854, -0.2207, -0.0569,  0.0579,\n        -0.3351,  0.0319,  0.3108, -0.1068, -0.2821, -0.1673, -0.0622,  0.2282,\n         0.0397,  0.2595, -0.2201, -0.2742,  0.1276,  0.2219, -0.1837, -0.3399],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 5.5143e-02,  3.8103e-02,  4.7338e-02,  ..., -3.8561e-02,\n         -2.1679e-02, -5.2085e-02],\n        [-6.0346e-02, -2.7279e-02, -6.9279e-02,  ..., -1.3924e-02,\n          3.2484e-02, -3.9552e-02],\n        [ 3.5589e-02, -8.2595e-02,  7.9503e-02,  ...,  8.8071e-02,\n          8.6833e-02, -2.2447e-03],\n        ...,\n        [ 3.5002e-02, -4.4567e-02, -3.7070e-02,  ...,  9.2955e-05,\n          4.1010e-02, -7.7940e-02],\n        [ 3.0396e-02, -5.8995e-02, -8.2630e-02,  ..., -2.2141e-02,\n          2.9968e-02,  7.8824e-02],\n        [-5.6124e-02, -3.5402e-02,  1.4551e-02,  ..., -6.5187e-02,\n          6.7032e-02,  4.2394e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0530,  0.0553,  0.0556,  0.0290,  0.0877, -0.0470,  0.0582, -0.0498,\n         0.0601,  0.0882, -0.0222, -0.0111,  0.0734, -0.0153, -0.0785, -0.0158,\n        -0.0753, -0.0035,  0.0097,  0.0015,  0.0522,  0.0207, -0.0730, -0.0112,\n         0.0795,  0.0123,  0.0165,  0.0242, -0.0118,  0.0611, -0.0173,  0.0692,\n         0.0206,  0.0012,  0.0785,  0.0317, -0.0234,  0.0360,  0.0581,  0.0047,\n        -0.0837, -0.0285, -0.0529,  0.0416,  0.0167, -0.0573, -0.0005,  0.0013,\n        -0.0343, -0.0837,  0.0218,  0.0621, -0.0164,  0.0010,  0.0029,  0.0654,\n        -0.0733,  0.0880,  0.0008, -0.0388,  0.0313,  0.0612,  0.0262, -0.0032,\n         0.0236,  0.0129,  0.0609, -0.0788,  0.0460, -0.0013, -0.0508, -0.0566,\n         0.0543,  0.0407, -0.0168,  0.0165, -0.0265,  0.0328, -0.0408, -0.0730,\n         0.0739,  0.0474, -0.0454,  0.0351,  0.0177, -0.0193,  0.0605, -0.0727,\n        -0.0804, -0.0324, -0.0837, -0.0239, -0.0041, -0.0281, -0.0273,  0.0436,\n        -0.0308,  0.0611,  0.0222, -0.0280,  0.0800,  0.0146,  0.0178,  0.0144,\n         0.0585,  0.0629, -0.0720,  0.0641,  0.0196, -0.0825, -0.0813,  0.0069,\n         0.0183, -0.0198, -0.0683, -0.0569,  0.0653,  0.0608, -0.0684,  0.0658,\n         0.0186,  0.0475,  0.0162,  0.0686,  0.0222, -0.0312, -0.0408,  0.0704],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.8489e-02, -6.4751e-02,  2.7545e-02, -3.3799e-02,  6.8943e-02,\n          7.2217e-03, -5.1802e-02,  4.7955e-02, -6.1153e-02,  9.1178e-03,\n         -1.5937e-02,  8.4773e-02, -7.1091e-02, -2.6645e-02,  6.2125e-02,\n          6.1185e-02,  3.9318e-02, -9.6497e-04, -8.5350e-02, -1.1920e-02,\n         -6.9180e-02, -3.8978e-02,  7.5858e-02, -1.5295e-02, -3.0452e-02,\n          6.6476e-03,  8.6581e-02, -4.7786e-02,  5.3368e-02,  3.2631e-02,\n          9.8653e-03, -4.5593e-02,  6.8680e-02,  6.5724e-02,  7.0825e-02,\n          5.3912e-02,  1.3442e-02, -6.0370e-02,  6.8172e-02, -4.1145e-02,\n          8.1283e-02,  4.1245e-02, -4.8678e-03, -7.5497e-02,  7.6935e-03,\n         -4.4630e-02, -3.9891e-02, -4.2991e-02,  5.1482e-02, -2.2108e-03,\n         -1.4835e-02,  7.5095e-02,  1.1986e-03, -5.4395e-02,  7.8979e-02,\n          7.7007e-02, -6.6133e-02,  4.2500e-02, -6.7606e-02,  6.2957e-02,\n         -6.3652e-02,  5.4775e-02, -3.3153e-02, -3.1533e-02,  3.0163e-02,\n          7.2802e-02,  4.8390e-02, -1.3077e-02,  6.3806e-02,  8.2522e-02,\n         -3.6479e-02, -4.3315e-02,  8.0328e-02,  8.9622e-03, -1.6471e-02,\n          7.1543e-02, -7.4479e-02, -7.6037e-02, -2.3344e-02, -7.8372e-02,\n          3.9843e-02,  2.3629e-02,  5.4469e-02,  6.1325e-02,  4.1824e-02,\n          1.1732e-02,  3.8487e-02, -2.1887e-02, -7.4032e-03,  5.8735e-02,\n         -6.7494e-03,  7.3239e-02,  3.9898e-02,  1.2696e-02, -1.8653e-02,\n         -1.0967e-02,  3.7699e-02, -7.7974e-02, -1.9768e-02,  3.1850e-02,\n         -1.2193e-02,  3.4630e-02,  3.2483e-03, -6.1689e-02, -1.3486e-02,\n         -3.2710e-02,  1.9185e-02,  5.4127e-02, -4.2682e-02,  3.7953e-03,\n          4.6405e-02,  4.9626e-02,  3.5193e-02, -5.6746e-03,  4.1795e-02,\n          1.4476e-02, -7.4852e-02, -7.9226e-02,  5.4098e-02,  1.7922e-02,\n          1.2614e-02,  1.3202e-02, -1.7342e-02,  2.2176e-02,  8.4267e-02,\n          7.7314e-02,  4.9966e-02, -8.5127e-02],\n        [ 7.9548e-02, -1.3687e-02, -1.9746e-02, -8.1197e-02,  5.0291e-02,\n         -8.5647e-02, -4.2544e-02,  7.7849e-02, -4.8398e-02,  5.0176e-02,\n          1.6428e-02,  5.5764e-02,  6.5404e-03,  6.8082e-02,  8.8287e-02,\n         -3.8149e-03,  2.5392e-02,  4.4351e-02,  6.1632e-02,  4.4926e-03,\n         -2.4745e-02, -1.4917e-03,  7.7497e-02, -7.1466e-02, -4.5747e-02,\n          2.0947e-02,  7.8337e-03,  1.2601e-02, -8.8291e-02,  3.8738e-03,\n          4.2545e-02,  1.9667e-02, -5.6083e-02, -6.9162e-02, -8.2150e-02,\n          2.6812e-02, -4.8231e-02, -4.3792e-02, -4.5864e-02,  4.6663e-02,\n         -7.9007e-02,  4.9291e-02,  5.1221e-03, -7.7185e-02, -2.1072e-02,\n          7.9735e-02,  9.2292e-03,  3.3815e-02,  6.9154e-02, -3.5311e-02,\n          8.5727e-02, -5.1761e-02, -1.7541e-02,  3.7905e-02, -8.4329e-02,\n         -7.4936e-02,  3.0974e-02, -1.3078e-02, -1.2716e-03,  2.5599e-02,\n         -3.4171e-02,  7.2130e-02, -4.8156e-03,  3.7487e-02,  3.1617e-02,\n          2.3368e-02,  5.6369e-02,  2.6475e-02,  5.5594e-02,  6.3699e-04,\n         -1.9324e-02, -7.5037e-02,  3.8935e-02,  4.6816e-02, -3.3877e-02,\n         -7.8347e-02,  6.4845e-02,  6.1472e-02,  7.6393e-03,  2.5433e-02,\n          7.6433e-02,  4.8697e-02,  6.0358e-02,  6.7309e-02,  7.7626e-02,\n         -4.0257e-03, -7.0783e-02,  4.9205e-02, -3.2209e-02,  5.0313e-02,\n         -4.3835e-03,  2.9095e-02,  1.8468e-02,  6.7519e-02,  3.0535e-02,\n         -3.1038e-02,  3.5943e-02,  7.0239e-02, -4.5728e-02,  3.4143e-02,\n          3.7069e-02,  1.2961e-02, -3.3193e-02,  8.6726e-02, -6.0338e-02,\n         -2.4166e-02,  1.9191e-02, -8.4592e-03, -4.8281e-02,  2.7412e-03,\n         -1.7736e-02, -6.1408e-02, -3.5845e-02, -8.6743e-02,  4.7157e-02,\n         -9.0130e-03, -6.1358e-02, -5.9452e-02,  1.1847e-02, -4.1394e-02,\n         -1.9675e-02,  2.6727e-02,  3.6514e-02,  1.4407e-02, -2.1987e-02,\n          5.8022e-02,  1.2162e-02, -2.7529e-03],\n        [ 2.3399e-02,  6.7034e-02, -6.4218e-02, -5.0313e-03,  1.2248e-03,\n         -2.7357e-02,  2.7691e-02,  7.6587e-02, -9.2365e-03,  7.2802e-02,\n         -4.0519e-02,  1.4513e-02,  3.6079e-02, -1.5394e-03, -8.0310e-02,\n         -7.2043e-02, -1.2082e-02,  5.3468e-02,  4.4616e-04, -2.6334e-02,\n         -6.5426e-02,  5.0957e-02, -6.2434e-02,  5.1108e-02, -2.0663e-02,\n          6.0856e-02,  4.1355e-02, -5.8239e-02,  2.5716e-02,  6.3763e-02,\n         -9.6275e-03,  5.8354e-02, -5.7300e-02, -2.0860e-02,  7.0520e-02,\n         -1.9857e-02, -6.5985e-02, -1.7488e-03,  4.0360e-02,  8.1381e-02,\n          2.4600e-02,  3.4140e-02, -2.0875e-03, -3.7127e-02,  4.1620e-03,\n         -2.8640e-02,  6.8829e-02, -2.3377e-02,  3.8544e-02,  3.3355e-02,\n         -1.1257e-02, -5.9474e-02,  3.5290e-02,  1.2748e-02,  4.5638e-02,\n         -6.5614e-02, -2.8117e-02, -8.2945e-05, -5.0281e-02, -5.0942e-02,\n          6.0642e-02, -8.6424e-03, -5.4111e-02, -7.6633e-02,  8.0143e-02,\n         -5.4274e-02,  1.3166e-02,  3.2492e-02,  2.2857e-02,  6.9459e-02,\n          8.7701e-02,  2.1964e-02, -7.3562e-02,  2.1118e-02, -4.2026e-02,\n          5.6847e-02,  4.1404e-02,  4.7949e-02, -8.8174e-02,  6.2341e-02,\n          6.9555e-02, -1.7489e-02, -7.4275e-02,  5.7804e-03, -7.4266e-02,\n          2.9231e-02,  3.7152e-02, -5.3172e-02,  7.1656e-02, -5.9499e-02,\n          4.2343e-02, -5.1615e-04, -3.6644e-02, -2.5407e-02,  2.4064e-02,\n         -2.5072e-02, -6.0883e-02,  6.4109e-02,  5.0405e-02, -7.2146e-03,\n         -7.3346e-02,  5.1836e-02,  6.6095e-02, -8.5925e-03,  2.6926e-03,\n         -7.7371e-02, -7.3267e-02,  7.8186e-02, -5.3619e-03,  1.5216e-02,\n          7.3640e-02,  1.0745e-02, -2.7086e-02, -7.5356e-02, -1.6333e-02,\n         -5.7321e-02, -4.5204e-02,  8.6899e-02, -1.2032e-02, -2.3117e-02,\n          1.5653e-02, -5.2143e-03, -3.8203e-03,  5.5208e-04,  7.8577e-02,\n         -3.7806e-03, -2.3283e-02, -5.0174e-02],\n        [-8.1118e-02,  1.6441e-02,  5.8501e-02, -4.9930e-02, -3.0766e-02,\n         -1.0781e-03, -7.8511e-04, -3.2640e-02,  2.1199e-02,  4.7202e-02,\n         -7.0348e-02,  5.3145e-02, -4.2142e-02,  6.4310e-02,  5.1742e-02,\n         -1.6382e-02,  2.8874e-02,  3.1597e-02,  8.8051e-02,  2.8203e-02,\n         -2.8710e-02,  5.3345e-02,  1.0421e-02, -1.6145e-02, -1.0417e-04,\n          6.5518e-02,  4.5032e-02,  3.8547e-02,  7.8323e-02,  4.5350e-02,\n          1.2085e-02, -5.8652e-02, -2.2620e-02, -3.1263e-02,  1.6540e-02,\n         -3.1285e-02, -2.5622e-02, -8.1617e-02,  1.3055e-02, -5.9441e-02,\n          4.3273e-02,  4.8973e-02, -6.6168e-02, -7.1508e-02,  8.0368e-02,\n          4.2323e-02, -5.7769e-02, -4.4597e-02, -4.6084e-02, -3.2356e-02,\n         -5.2658e-02, -7.7543e-02, -7.9582e-03,  7.5932e-02, -7.4238e-02,\n          2.4722e-02,  7.2806e-02, -7.6560e-02,  5.5787e-03,  7.9090e-02,\n          1.2876e-02, -6.6705e-02, -4.2631e-02, -8.7364e-02,  1.0218e-02,\n          2.6370e-02, -6.2680e-03,  5.6738e-02, -6.8050e-02,  3.1124e-02,\n          4.4242e-02,  7.5350e-02,  2.8250e-02,  8.7113e-02,  2.6918e-02,\n         -6.0572e-02, -6.2483e-02,  7.9558e-02,  2.4617e-02,  7.0146e-02,\n         -4.6024e-02,  1.8185e-02,  5.3737e-03, -2.7957e-02, -1.4294e-02,\n         -4.3624e-02,  1.7430e-03,  9.1413e-04, -4.8555e-02,  3.3498e-02,\n          6.8074e-02, -2.0033e-02, -4.1707e-02, -7.2346e-03,  5.0837e-02,\n         -5.4423e-02,  8.5131e-02,  6.3838e-02,  6.0050e-03,  5.9217e-02,\n          1.3911e-02, -6.3954e-02, -1.6525e-02,  2.8155e-02,  8.8308e-02,\n         -6.6666e-02, -4.5653e-02, -6.5139e-02,  1.9041e-03, -7.8868e-02,\n         -6.2024e-02, -6.9237e-03, -8.1530e-02, -4.2804e-02, -1.3704e-02,\n          2.8800e-03, -3.0139e-02,  7.3349e-02, -1.6756e-02,  2.3482e-02,\n         -6.9511e-02, -6.9008e-02, -5.7776e-02,  4.0743e-02, -4.4495e-02,\n         -3.2220e-02,  7.2969e-02, -5.9157e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0352,  0.0637,  0.0249, -0.0292], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x7348473c8f90>":	{
                    "capacity":	50000,
                    "current_segment":	0,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	250,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "sample_decay":	0.8,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0245,  0.1476,  0.1786, -0.2898,  0.1792,  0.0976, -0.0293,  0.1717,\n         0.1263,  0.2716, -0.3214,  0.0228,  0.3257, -0.3222,  0.2048, -0.1336,\n        -0.2207,  0.2638,  0.1821,  0.1575, -0.1327, -0.3343, -0.3307,  0.1640,\n         0.0396, -0.1656, -0.0129, -0.1892,  0.0888,  0.2554,  0.1854,  0.0732,\n        -0.0678, -0.2078, -0.1760, -0.0309, -0.1349, -0.2863,  0.3283,  0.2962,\n        -0.1638,  0.0439,  0.2741,  0.0684, -0.1737, -0.0398, -0.3145,  0.3388,\n         0.1588,  0.2498, -0.0474,  0.1154,  0.2632,  0.3482, -0.0602,  0.0411,\n        -0.3511,  0.0322, -0.3205,  0.0419, -0.2109,  0.1199,  0.1884,  0.1029,\n         0.2998, -0.0554, -0.2366, -0.1652, -0.0044, -0.2453, -0.2665, -0.2075,\n        -0.1793,  0.0266,  0.3166, -0.1779,  0.2715,  0.3217,  0.0444,  0.3210,\n        -0.0433,  0.1216, -0.2186, -0.2405, -0.1458, -0.3313, -0.2403,  0.2936,\n        -0.0805, -0.1831, -0.2027, -0.1607,  0.2746,  0.1086,  0.1866, -0.0485,\n        -0.2850,  0.2333,  0.2167, -0.2203,  0.1729, -0.2212,  0.1125, -0.1054,\n        -0.2040, -0.1298, -0.0038,  0.0805, -0.0854, -0.2207, -0.0569,  0.0579,\n        -0.3351,  0.0319,  0.3108, -0.1068, -0.2821, -0.1673, -0.0622,  0.2282,\n         0.0397,  0.2595, -0.2201, -0.2742,  0.1276,  0.2219, -0.1837, -0.3399],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0654, -0.1593, -0.0395,  ...,  0.3445, -0.0426, -0.2021],\n        [ 0.2175, -0.0065, -0.0263,  ...,  0.1934, -0.1844, -0.1595],\n        [-0.0327, -0.2934,  0.0239,  ..., -0.0614,  0.1380,  0.2092],\n        ...,\n        [ 0.0920, -0.0575, -0.1469,  ...,  0.1284, -0.3128, -0.1894],\n        [-0.0653,  0.1595, -0.2526,  ..., -0.2023,  0.3095, -0.2487],\n        [-0.2987,  0.3151,  0.0217,  ..., -0.2376, -0.2527,  0.2282]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0530,  0.0553,  0.0556,  0.0290,  0.0877, -0.0470,  0.0582, -0.0498,\n         0.0601,  0.0882, -0.0222, -0.0111,  0.0734, -0.0153, -0.0785, -0.0158,\n        -0.0753, -0.0035,  0.0097,  0.0015,  0.0522,  0.0207, -0.0730, -0.0112,\n         0.0795,  0.0123,  0.0165,  0.0242, -0.0118,  0.0611, -0.0173,  0.0692,\n         0.0206,  0.0012,  0.0785,  0.0317, -0.0234,  0.0360,  0.0581,  0.0047,\n        -0.0837, -0.0285, -0.0529,  0.0416,  0.0167, -0.0573, -0.0005,  0.0013,\n        -0.0343, -0.0837,  0.0218,  0.0621, -0.0164,  0.0010,  0.0029,  0.0654,\n        -0.0733,  0.0880,  0.0008, -0.0388,  0.0313,  0.0612,  0.0262, -0.0032,\n         0.0236,  0.0129,  0.0609, -0.0788,  0.0460, -0.0013, -0.0508, -0.0566,\n         0.0543,  0.0407, -0.0168,  0.0165, -0.0265,  0.0328, -0.0408, -0.0730,\n         0.0739,  0.0474, -0.0454,  0.0351,  0.0177, -0.0193,  0.0605, -0.0727,\n        -0.0804, -0.0324, -0.0837, -0.0239, -0.0041, -0.0281, -0.0273,  0.0436,\n        -0.0308,  0.0611,  0.0222, -0.0280,  0.0800,  0.0146,  0.0178,  0.0144,\n         0.0585,  0.0629, -0.0720,  0.0641,  0.0196, -0.0825, -0.0813,  0.0069,\n         0.0183, -0.0198, -0.0683, -0.0569,  0.0653,  0.0608, -0.0684,  0.0658,\n         0.0186,  0.0475,  0.0162,  0.0686,  0.0222, -0.0312, -0.0408,  0.0704],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 5.5143e-02,  3.8103e-02,  4.7338e-02,  ..., -3.8561e-02,\n         -2.1679e-02, -5.2085e-02],\n        [-6.0346e-02, -2.7279e-02, -6.9279e-02,  ..., -1.3924e-02,\n          3.2484e-02, -3.9552e-02],\n        [ 3.5589e-02, -8.2595e-02,  7.9503e-02,  ...,  8.8071e-02,\n          8.6833e-02, -2.2447e-03],\n        ...,\n        [ 3.5002e-02, -4.4567e-02, -3.7070e-02,  ...,  9.2955e-05,\n          4.1010e-02, -7.7940e-02],\n        [ 3.0396e-02, -5.8995e-02, -8.2630e-02,  ..., -2.2141e-02,\n          2.9968e-02,  7.8824e-02],\n        [-5.6124e-02, -3.5402e-02,  1.4551e-02,  ..., -6.5187e-02,\n          6.7032e-02,  4.2394e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0352,  0.0637,  0.0249, -0.0292], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.8489e-02, -6.4751e-02,  2.7545e-02, -3.3799e-02,  6.8943e-02,\n          7.2217e-03, -5.1802e-02,  4.7955e-02, -6.1153e-02,  9.1178e-03,\n         -1.5937e-02,  8.4773e-02, -7.1091e-02, -2.6645e-02,  6.2125e-02,\n          6.1185e-02,  3.9318e-02, -9.6497e-04, -8.5350e-02, -1.1920e-02,\n         -6.9180e-02, -3.8978e-02,  7.5858e-02, -1.5295e-02, -3.0452e-02,\n          6.6476e-03,  8.6581e-02, -4.7786e-02,  5.3368e-02,  3.2631e-02,\n          9.8653e-03, -4.5593e-02,  6.8680e-02,  6.5724e-02,  7.0825e-02,\n          5.3912e-02,  1.3442e-02, -6.0370e-02,  6.8172e-02, -4.1145e-02,\n          8.1283e-02,  4.1245e-02, -4.8678e-03, -7.5497e-02,  7.6935e-03,\n         -4.4630e-02, -3.9891e-02, -4.2991e-02,  5.1482e-02, -2.2108e-03,\n         -1.4835e-02,  7.5095e-02,  1.1986e-03, -5.4395e-02,  7.8979e-02,\n          7.7007e-02, -6.6133e-02,  4.2500e-02, -6.7606e-02,  6.2957e-02,\n         -6.3652e-02,  5.4775e-02, -3.3153e-02, -3.1533e-02,  3.0163e-02,\n          7.2802e-02,  4.8390e-02, -1.3077e-02,  6.3806e-02,  8.2522e-02,\n         -3.6479e-02, -4.3315e-02,  8.0328e-02,  8.9622e-03, -1.6471e-02,\n          7.1543e-02, -7.4479e-02, -7.6037e-02, -2.3344e-02, -7.8372e-02,\n          3.9843e-02,  2.3629e-02,  5.4469e-02,  6.1325e-02,  4.1824e-02,\n          1.1732e-02,  3.8487e-02, -2.1887e-02, -7.4032e-03,  5.8735e-02,\n         -6.7494e-03,  7.3239e-02,  3.9898e-02,  1.2696e-02, -1.8653e-02,\n         -1.0967e-02,  3.7699e-02, -7.7974e-02, -1.9768e-02,  3.1850e-02,\n         -1.2193e-02,  3.4630e-02,  3.2483e-03, -6.1689e-02, -1.3486e-02,\n         -3.2710e-02,  1.9185e-02,  5.4127e-02, -4.2682e-02,  3.7953e-03,\n          4.6405e-02,  4.9626e-02,  3.5193e-02, -5.6746e-03,  4.1795e-02,\n          1.4476e-02, -7.4852e-02, -7.9226e-02,  5.4098e-02,  1.7922e-02,\n          1.2614e-02,  1.3202e-02, -1.7342e-02,  2.2176e-02,  8.4267e-02,\n          7.7314e-02,  4.9966e-02, -8.5127e-02],\n        [ 7.9548e-02, -1.3687e-02, -1.9746e-02, -8.1197e-02,  5.0291e-02,\n         -8.5647e-02, -4.2544e-02,  7.7849e-02, -4.8398e-02,  5.0176e-02,\n          1.6428e-02,  5.5764e-02,  6.5404e-03,  6.8082e-02,  8.8287e-02,\n         -3.8149e-03,  2.5392e-02,  4.4351e-02,  6.1632e-02,  4.4926e-03,\n         -2.4745e-02, -1.4917e-03,  7.7497e-02, -7.1466e-02, -4.5747e-02,\n          2.0947e-02,  7.8337e-03,  1.2601e-02, -8.8291e-02,  3.8738e-03,\n          4.2545e-02,  1.9667e-02, -5.6083e-02, -6.9162e-02, -8.2150e-02,\n          2.6812e-02, -4.8231e-02, -4.3792e-02, -4.5864e-02,  4.6663e-02,\n         -7.9007e-02,  4.9291e-02,  5.1221e-03, -7.7185e-02, -2.1072e-02,\n          7.9735e-02,  9.2292e-03,  3.3815e-02,  6.9154e-02, -3.5311e-02,\n          8.5727e-02, -5.1761e-02, -1.7541e-02,  3.7905e-02, -8.4329e-02,\n         -7.4936e-02,  3.0974e-02, -1.3078e-02, -1.2716e-03,  2.5599e-02,\n         -3.4171e-02,  7.2130e-02, -4.8156e-03,  3.7487e-02,  3.1617e-02,\n          2.3368e-02,  5.6369e-02,  2.6475e-02,  5.5594e-02,  6.3699e-04,\n         -1.9324e-02, -7.5037e-02,  3.8935e-02,  4.6816e-02, -3.3877e-02,\n         -7.8347e-02,  6.4845e-02,  6.1472e-02,  7.6393e-03,  2.5433e-02,\n          7.6433e-02,  4.8697e-02,  6.0358e-02,  6.7309e-02,  7.7626e-02,\n         -4.0257e-03, -7.0783e-02,  4.9205e-02, -3.2209e-02,  5.0313e-02,\n         -4.3835e-03,  2.9095e-02,  1.8468e-02,  6.7519e-02,  3.0535e-02,\n         -3.1038e-02,  3.5943e-02,  7.0239e-02, -4.5728e-02,  3.4143e-02,\n          3.7069e-02,  1.2961e-02, -3.3193e-02,  8.6726e-02, -6.0338e-02,\n         -2.4166e-02,  1.9191e-02, -8.4592e-03, -4.8281e-02,  2.7412e-03,\n         -1.7736e-02, -6.1408e-02, -3.5845e-02, -8.6743e-02,  4.7157e-02,\n         -9.0130e-03, -6.1358e-02, -5.9452e-02,  1.1847e-02, -4.1394e-02,\n         -1.9675e-02,  2.6727e-02,  3.6514e-02,  1.4407e-02, -2.1987e-02,\n          5.8022e-02,  1.2162e-02, -2.7529e-03],\n        [ 2.3399e-02,  6.7034e-02, -6.4218e-02, -5.0313e-03,  1.2248e-03,\n         -2.7357e-02,  2.7691e-02,  7.6587e-02, -9.2365e-03,  7.2802e-02,\n         -4.0519e-02,  1.4513e-02,  3.6079e-02, -1.5394e-03, -8.0310e-02,\n         -7.2043e-02, -1.2082e-02,  5.3468e-02,  4.4616e-04, -2.6334e-02,\n         -6.5426e-02,  5.0957e-02, -6.2434e-02,  5.1108e-02, -2.0663e-02,\n          6.0856e-02,  4.1355e-02, -5.8239e-02,  2.5716e-02,  6.3763e-02,\n         -9.6275e-03,  5.8354e-02, -5.7300e-02, -2.0860e-02,  7.0520e-02,\n         -1.9857e-02, -6.5985e-02, -1.7488e-03,  4.0360e-02,  8.1381e-02,\n          2.4600e-02,  3.4140e-02, -2.0875e-03, -3.7127e-02,  4.1620e-03,\n         -2.8640e-02,  6.8829e-02, -2.3377e-02,  3.8544e-02,  3.3355e-02,\n         -1.1257e-02, -5.9474e-02,  3.5290e-02,  1.2748e-02,  4.5638e-02,\n         -6.5614e-02, -2.8117e-02, -8.2945e-05, -5.0281e-02, -5.0942e-02,\n          6.0642e-02, -8.6424e-03, -5.4111e-02, -7.6633e-02,  8.0143e-02,\n         -5.4274e-02,  1.3166e-02,  3.2492e-02,  2.2857e-02,  6.9459e-02,\n          8.7701e-02,  2.1964e-02, -7.3562e-02,  2.1118e-02, -4.2026e-02,\n          5.6847e-02,  4.1404e-02,  4.7949e-02, -8.8174e-02,  6.2341e-02,\n          6.9555e-02, -1.7489e-02, -7.4275e-02,  5.7804e-03, -7.4266e-02,\n          2.9231e-02,  3.7152e-02, -5.3172e-02,  7.1656e-02, -5.9499e-02,\n          4.2343e-02, -5.1615e-04, -3.6644e-02, -2.5407e-02,  2.4064e-02,\n         -2.5072e-02, -6.0883e-02,  6.4109e-02,  5.0405e-02, -7.2146e-03,\n         -7.3346e-02,  5.1836e-02,  6.6095e-02, -8.5925e-03,  2.6926e-03,\n         -7.7371e-02, -7.3267e-02,  7.8186e-02, -5.3619e-03,  1.5216e-02,\n          7.3640e-02,  1.0745e-02, -2.7086e-02, -7.5356e-02, -1.6333e-02,\n         -5.7321e-02, -4.5204e-02,  8.6899e-02, -1.2032e-02, -2.3117e-02,\n          1.5653e-02, -5.2143e-03, -3.8203e-03,  5.5208e-04,  7.8577e-02,\n         -3.7806e-03, -2.3283e-02, -5.0174e-02],\n        [-8.1118e-02,  1.6441e-02,  5.8501e-02, -4.9930e-02, -3.0766e-02,\n         -1.0781e-03, -7.8511e-04, -3.2640e-02,  2.1199e-02,  4.7202e-02,\n         -7.0348e-02,  5.3145e-02, -4.2142e-02,  6.4310e-02,  5.1742e-02,\n         -1.6382e-02,  2.8874e-02,  3.1597e-02,  8.8051e-02,  2.8203e-02,\n         -2.8710e-02,  5.3345e-02,  1.0421e-02, -1.6145e-02, -1.0417e-04,\n          6.5518e-02,  4.5032e-02,  3.8547e-02,  7.8323e-02,  4.5350e-02,\n          1.2085e-02, -5.8652e-02, -2.2620e-02, -3.1263e-02,  1.6540e-02,\n         -3.1285e-02, -2.5622e-02, -8.1617e-02,  1.3055e-02, -5.9441e-02,\n          4.3273e-02,  4.8973e-02, -6.6168e-02, -7.1508e-02,  8.0368e-02,\n          4.2323e-02, -5.7769e-02, -4.4597e-02, -4.6084e-02, -3.2356e-02,\n         -5.2658e-02, -7.7543e-02, -7.9582e-03,  7.5932e-02, -7.4238e-02,\n          2.4722e-02,  7.2806e-02, -7.6560e-02,  5.5787e-03,  7.9090e-02,\n          1.2876e-02, -6.6705e-02, -4.2631e-02, -8.7364e-02,  1.0218e-02,\n          2.6370e-02, -6.2680e-03,  5.6738e-02, -6.8050e-02,  3.1124e-02,\n          4.4242e-02,  7.5350e-02,  2.8250e-02,  8.7113e-02,  2.6918e-02,\n         -6.0572e-02, -6.2483e-02,  7.9558e-02,  2.4617e-02,  7.0146e-02,\n         -4.6024e-02,  1.8185e-02,  5.3737e-03, -2.7957e-02, -1.4294e-02,\n         -4.3624e-02,  1.7430e-03,  9.1413e-04, -4.8555e-02,  3.3498e-02,\n          6.8074e-02, -2.0033e-02, -4.1707e-02, -7.2346e-03,  5.0837e-02,\n         -5.4423e-02,  8.5131e-02,  6.3838e-02,  6.0050e-03,  5.9217e-02,\n          1.3911e-02, -6.3954e-02, -1.6525e-02,  2.8155e-02,  8.8308e-02,\n         -6.6666e-02, -4.5653e-02, -6.5139e-02,  1.9041e-03, -7.8868e-02,\n         -6.2024e-02, -6.9237e-03, -8.1530e-02, -4.2804e-02, -1.3704e-02,\n          2.8800e-03, -3.0139e-02,  7.3349e-02, -1.6756e-02,  2.3482e-02,\n         -6.9511e-02, -6.9008e-02, -5.7776e-02,  4.0743e-02, -4.4495e-02,\n         -3.2220e-02,  7.2969e-02, -5.9157e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x734843bbac90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s320320000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s320320000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}