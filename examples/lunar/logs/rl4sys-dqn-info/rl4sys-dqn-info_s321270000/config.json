{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s321270000"
    },
    "q_lr":	0.0005,
    "seed":	321270000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x76f9423353d0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3521,  0.0967,  0.3183, -0.2823, -0.3504,  0.2576, -0.2015, -0.0744,\n        -0.0084, -0.2957,  0.0606, -0.1754, -0.2230,  0.1799,  0.2834,  0.2052,\n         0.0122,  0.2535,  0.2076, -0.0875,  0.2087,  0.1766, -0.2256,  0.2901,\n         0.1591,  0.0448,  0.0861, -0.1812, -0.1794,  0.3144,  0.2590,  0.0348],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.3395, -0.0879,  0.1761,  0.1900, -0.1241,  0.0118, -0.2960, -0.0438],\n        [ 0.1251, -0.1376,  0.2274,  0.2684, -0.1382,  0.0040, -0.1198, -0.2029],\n        [ 0.2273,  0.2906, -0.0912,  0.0509,  0.1091,  0.2614,  0.2067,  0.2349],\n        [ 0.1028,  0.1610,  0.2466,  0.1340, -0.1883,  0.0640, -0.0489,  0.2754],\n        [ 0.2587, -0.2419, -0.3128, -0.2047, -0.0145, -0.0354, -0.0291, -0.0203],\n        [-0.1506, -0.3271,  0.1429, -0.1394,  0.0037, -0.3526, -0.2611,  0.2022],\n        [ 0.1475, -0.0578,  0.2597,  0.2614,  0.2512, -0.1956, -0.0044,  0.2180],\n        [-0.0037, -0.2104, -0.2634, -0.0944, -0.3276,  0.2085, -0.3279, -0.0588],\n        [-0.1654,  0.2706, -0.0187,  0.0519,  0.2225,  0.3189, -0.0761,  0.0734],\n        [ 0.2583, -0.1487,  0.0664, -0.0372, -0.3361, -0.3242, -0.2750,  0.2378],\n        [-0.2683, -0.1287,  0.2091, -0.2095,  0.1579,  0.1086, -0.0244,  0.0295],\n        [-0.1417, -0.2132,  0.1598, -0.2699, -0.3340, -0.0746,  0.0956, -0.2045],\n        [ 0.2520, -0.1666, -0.2352, -0.0313,  0.0451, -0.1987, -0.0287,  0.1147],\n        [-0.2997, -0.3027, -0.3229,  0.0948,  0.1370,  0.2431,  0.3273,  0.0844],\n        [-0.3222,  0.2943, -0.3385,  0.1835,  0.2299,  0.0091, -0.3205,  0.0541],\n        [-0.1406,  0.0411,  0.1621, -0.2447,  0.2611,  0.3286,  0.1681, -0.1627],\n        [ 0.2183, -0.1143, -0.2877, -0.0464,  0.2089, -0.2559,  0.1106,  0.1490],\n        [-0.1911,  0.1221,  0.0213,  0.2856,  0.1814,  0.0813,  0.1960, -0.1869],\n        [ 0.1544, -0.2912,  0.1287,  0.1218,  0.1716,  0.0476,  0.3221, -0.3414],\n        [-0.0902,  0.1083, -0.0399,  0.2775,  0.3487,  0.2681,  0.0308, -0.2665],\n        [ 0.3202,  0.1431,  0.0280, -0.2302, -0.2308,  0.0202, -0.0464,  0.1689],\n        [ 0.1653, -0.0780,  0.3183, -0.2631,  0.0877, -0.0141, -0.2937,  0.1948],\n        [ 0.3122, -0.1971,  0.1705,  0.3071,  0.2224, -0.3312, -0.0048,  0.1778],\n        [-0.0182, -0.3278, -0.2404,  0.3146,  0.0497,  0.0400, -0.0669,  0.0644],\n        [ 0.2540, -0.0039,  0.1353, -0.1274, -0.1719, -0.2511, -0.3517,  0.2414],\n        [ 0.2796,  0.2031,  0.2237,  0.1470, -0.2213, -0.2165,  0.0588, -0.0782],\n        [-0.1576,  0.3418, -0.3289, -0.2724,  0.1742,  0.2568, -0.3102, -0.2990],\n        [-0.3243,  0.3384, -0.0254, -0.1259, -0.0098, -0.2614, -0.0244,  0.0820],\n        [ 0.1506,  0.0724, -0.0462,  0.0374,  0.1999, -0.0991, -0.0976, -0.3338],\n        [ 0.0826, -0.2680, -0.1699,  0.3009, -0.1854,  0.2676, -0.0916,  0.1031],\n        [ 0.1623, -0.1458, -0.2785,  0.3450,  0.2221,  0.1470,  0.0234,  0.0600],\n        [ 0.3070, -0.0164,  0.0119, -0.1879, -0.2432,  0.2666, -0.1304,  0.0092]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1623, -0.0248,  0.0539, -0.1531,  0.0896, -0.0712, -0.0072, -0.1694,\n        -0.1671, -0.1760, -0.0086,  0.0649,  0.1761,  0.1320, -0.0436, -0.1081],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.4164e-01,  4.9998e-02,  9.4587e-02, -1.4819e-01, -6.4117e-02,\n          8.8083e-02,  4.3626e-02, -1.2887e-01,  2.0452e-02, -6.9333e-03,\n          1.4913e-01,  1.4824e-01, -5.4354e-02, -1.4343e-01,  1.8616e-02,\n         -1.1190e-01, -5.5895e-02, -1.0882e-01, -1.4800e-01,  6.2586e-02,\n          1.4709e-01, -1.4805e-01, -1.0750e-01, -1.8683e-02,  9.5916e-03,\n          4.0883e-02,  8.6613e-02,  9.5325e-02, -1.5871e-01,  1.2573e-01,\n          1.4573e-01, -4.7535e-02],\n        [-8.2195e-02,  1.3446e-01, -5.4868e-02,  1.5400e-01, -7.2470e-02,\n         -1.5521e-02, -7.7573e-02,  6.9886e-02,  7.7779e-02,  1.4580e-02,\n          1.4622e-01,  5.1345e-04, -9.6822e-02, -2.0393e-02,  6.4412e-02,\n          1.2672e-01,  1.2845e-01, -1.6954e-01, -1.1473e-01, -1.5924e-03,\n         -1.7520e-01, -1.1850e-01, -1.1673e-01, -1.3770e-02,  8.3546e-02,\n         -8.6541e-02,  1.1290e-01, -1.1763e-01, -4.2697e-03,  1.7276e-01,\n          4.1532e-02, -3.0640e-02],\n        [-1.4316e-01,  8.6533e-02, -2.8384e-02, -7.5813e-02, -1.3991e-01,\n          1.5363e-01,  9.4876e-02,  1.3671e-01, -1.7088e-01, -7.9606e-02,\n         -4.4264e-02,  1.5986e-01, -1.1564e-01, -6.4540e-03,  1.6457e-01,\n          3.8141e-02, -1.5604e-01,  5.4864e-02,  3.9292e-02,  1.7249e-01,\n          1.1940e-04,  1.3645e-01,  1.7427e-01, -1.0796e-01,  3.1420e-02,\n         -1.3929e-01, -9.9538e-02, -1.2790e-01, -5.1091e-02, -1.3031e-02,\n         -1.7376e-01, -4.2091e-02],\n        [-7.1749e-02, -1.4958e-01, -1.0692e-03, -5.3338e-02, -1.4461e-01,\n         -7.4490e-02,  3.3394e-02,  3.8975e-04,  2.6090e-02,  1.1892e-01,\n         -8.9638e-02,  1.2179e-01, -2.4129e-02,  1.3856e-02,  7.5605e-03,\n         -5.7807e-03, -1.3991e-01, -1.4958e-01, -1.1970e-02,  1.6946e-01,\n          1.2676e-01, -3.4209e-02,  4.2555e-02, -3.9441e-02,  9.1757e-02,\n          6.6502e-02,  2.3496e-02, -8.6223e-02, -3.6790e-02, -1.2756e-01,\n         -1.3351e-01,  1.5829e-01],\n        [-9.1450e-02,  4.0400e-04,  1.4979e-01, -6.2904e-02,  1.1551e-02,\n         -1.3523e-01, -1.7461e-01, -8.6543e-02,  1.6253e-02,  1.6941e-01,\n         -7.5792e-02,  1.4151e-01,  7.0122e-02,  7.6291e-02, -1.2033e-01,\n          8.7828e-02, -9.4884e-02,  1.4642e-01, -3.8381e-02,  6.2421e-02,\n         -7.8018e-03, -1.7518e-01,  1.3094e-01,  1.2322e-01, -4.9281e-02,\n          5.2731e-02,  1.6888e-01, -1.2087e-01, -1.1189e-01,  1.0178e-01,\n          7.4903e-02,  8.2449e-02],\n        [ 4.2874e-02, -1.4464e-01,  5.9353e-02, -1.6138e-01,  1.6636e-01,\n          5.2324e-02,  1.1302e-01,  4.4067e-02,  4.0590e-02,  3.9453e-03,\n         -1.3381e-01,  7.7182e-02,  1.1976e-01, -8.6848e-02,  4.1724e-02,\n          1.0893e-01, -1.9396e-02, -1.0576e-02,  1.2009e-01, -1.2587e-01,\n          1.5269e-01,  9.4369e-02,  1.2224e-01,  1.1262e-01, -1.2895e-01,\n         -4.4121e-03, -8.2041e-02,  1.0329e-01,  4.2199e-02, -6.7599e-02,\n          1.0647e-01, -1.4847e-01],\n        [ 1.8984e-02,  4.0416e-02,  8.5473e-02,  7.4861e-02,  3.8330e-02,\n          6.6576e-02,  1.4469e-01, -1.3353e-01,  9.5792e-02,  9.1761e-03,\n         -1.5071e-01, -5.1057e-02,  3.9096e-02, -6.9404e-02, -1.3028e-01,\n          1.2851e-01,  1.0514e-01, -1.1391e-01,  6.4374e-02,  5.0399e-02,\n          1.5977e-01,  3.7523e-02,  6.0794e-02, -1.2072e-01, -2.4094e-02,\n          1.2299e-01, -1.4874e-01, -2.9434e-02,  1.2319e-01, -3.5837e-02,\n         -8.8173e-02, -1.9478e-02],\n        [ 1.5679e-01, -1.8064e-03,  2.6542e-02,  6.3215e-02, -1.7389e-01,\n         -1.0170e-01,  1.5694e-01, -7.1268e-02,  1.2887e-01,  3.4880e-02,\n         -1.4448e-01,  1.0568e-01,  1.5316e-01, -1.2495e-01,  1.1414e-02,\n          1.1823e-02,  1.2910e-02,  1.5421e-01,  1.7541e-01,  4.0261e-02,\n          2.1148e-02, -1.7031e-01,  1.0754e-01,  1.2899e-01,  1.2755e-01,\n         -1.0955e-01,  1.1002e-02, -1.6780e-01,  5.4924e-02, -1.4224e-01,\n          8.2599e-02, -1.0226e-01],\n        [ 8.2857e-02, -1.5285e-01, -2.3472e-02, -1.1134e-01, -1.7075e-01,\n         -2.8099e-02,  1.6476e-01,  9.1932e-02,  1.6935e-01, -9.0696e-02,\n         -1.6090e-01,  5.4233e-02, -1.7207e-01, -1.5134e-01,  1.5060e-01,\n         -2.4710e-02, -3.7284e-02, -1.2032e-01, -3.8265e-02,  1.5710e-02,\n          1.4063e-01,  1.6238e-01,  1.2343e-01, -1.6959e-01,  3.7754e-02,\n         -4.8759e-02, -9.2434e-02, -1.0723e-01, -6.1937e-02,  1.1720e-01,\n          1.6277e-01, -8.7480e-02],\n        [ 1.7556e-01, -7.4363e-02,  9.1024e-03, -1.6649e-01, -1.0240e-01,\n         -1.1329e-01,  9.6215e-02, -3.3707e-02, -1.7417e-01,  1.1020e-01,\n          1.6229e-02,  1.1089e-01, -2.4669e-02,  1.0588e-01,  6.2829e-02,\n          9.0557e-02, -9.7801e-02, -6.5377e-02,  2.0681e-02,  6.6766e-02,\n          9.2502e-02,  6.1951e-02, -7.4137e-03, -9.2668e-03, -7.5928e-02,\n          1.5336e-01, -1.5458e-01, -5.6608e-02,  1.3691e-01,  1.4827e-01,\n          9.1174e-02, -4.3405e-02],\n        [ 1.2114e-01, -5.7264e-02,  1.4715e-01, -1.0370e-01,  5.9215e-02,\n         -1.5462e-01,  8.1680e-02, -1.4589e-01, -1.0415e-01,  4.5540e-04,\n          1.6228e-01, -6.6313e-02, -1.6722e-01,  1.4000e-02, -1.1398e-01,\n          9.8576e-02,  8.4185e-03, -3.3646e-03, -2.9327e-02,  1.1424e-01,\n          1.2155e-01, -9.8112e-02,  1.6191e-01,  1.0915e-01,  4.3743e-02,\n         -3.4206e-02, -7.0041e-02, -3.9643e-02,  1.5330e-01,  7.1139e-02,\n         -3.7660e-02,  1.6502e-01],\n        [-6.2810e-02, -9.5538e-02,  1.3427e-01,  1.8745e-03,  1.6346e-01,\n          1.5736e-01,  3.2509e-02,  7.1743e-02, -1.1786e-01, -4.6321e-02,\n          1.1253e-01,  5.6210e-02, -1.4847e-01,  6.8439e-02, -1.4668e-01,\n          4.2022e-02, -8.6356e-02,  1.5711e-01, -1.7445e-01,  7.8872e-02,\n         -3.2466e-02, -1.3113e-02,  6.4376e-02,  4.7718e-03, -1.4915e-01,\n          6.4961e-02,  1.3131e-01, -4.1308e-02, -1.3597e-01, -1.2023e-01,\n          6.9268e-02, -7.1581e-02],\n        [-3.4838e-02,  1.4505e-01, -1.7467e-01,  8.5321e-02,  1.4914e-01,\n         -1.7484e-02, -1.0275e-01, -7.3413e-02,  1.5599e-01,  5.7858e-02,\n          1.2154e-01,  8.7817e-02, -4.4730e-02, -2.8210e-02, -1.6264e-01,\n         -1.0533e-01,  6.1856e-03,  5.4205e-02,  1.6007e-01, -2.1598e-02,\n          1.3502e-01, -1.2019e-01, -1.0900e-01,  1.6699e-01,  1.5621e-01,\n         -1.1992e-01,  7.6516e-02,  4.1088e-02, -2.1245e-02, -1.6813e-01,\n         -3.8280e-02,  7.3434e-02],\n        [ 9.7815e-02, -1.6951e-01, -7.4896e-02, -1.5089e-01,  1.9896e-02,\n          1.5889e-01,  3.7364e-02,  1.6405e-01, -7.3978e-02,  8.5876e-02,\n         -3.3537e-02, -3.3059e-03,  1.4585e-02,  1.7206e-02, -8.8287e-02,\n          1.7068e-01,  9.8664e-02, -1.6785e-01, -8.1319e-02, -1.0873e-01,\n         -1.2358e-01, -8.2990e-02,  5.8945e-02,  6.7608e-04,  1.6422e-01,\n          1.7648e-01,  5.8385e-02, -1.4099e-01,  1.9485e-02,  5.2488e-02,\n          1.2340e-01,  1.4233e-02],\n        [ 1.6035e-01,  4.3390e-03, -1.0192e-01, -7.9308e-03, -7.2530e-02,\n          9.7504e-02,  5.9228e-02,  2.8681e-02,  8.7285e-02, -1.6797e-01,\n          1.3127e-01, -1.3971e-01,  1.7613e-01, -1.0467e-01,  1.2409e-01,\n          8.3073e-02,  8.9449e-02, -2.4724e-02,  7.1128e-02, -1.3330e-01,\n         -1.2473e-01, -3.9580e-02, -7.4173e-02, -1.4750e-01, -1.5402e-01,\n          9.7212e-02,  8.0385e-02,  1.3524e-01, -1.1920e-01,  1.3529e-01,\n         -6.5968e-02, -4.5228e-02],\n        [ 1.1926e-01, -1.6282e-01, -6.3395e-02, -1.1036e-01, -7.3849e-02,\n          1.2832e-02,  9.4942e-02,  2.5077e-02, -8.5065e-02, -3.5302e-02,\n          4.9882e-02,  8.1627e-02, -1.4323e-01,  3.6491e-02,  1.6413e-01,\n          1.0179e-02, -5.1196e-02, -1.7474e-01, -1.4420e-01, -6.5626e-02,\n         -1.0158e-02, -1.1223e-01, -2.6221e-02, -1.6426e-01, -6.1769e-02,\n         -5.7792e-02,  1.5038e-01, -1.0410e-01,  9.1519e-02,  1.4055e-01,\n         -1.6057e-01,  5.0658e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0314, -0.0116, -0.1759,  0.0013, -0.1767, -0.1728,  0.0432,  0.1657],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0714,  0.0375, -0.0247,  0.2356,  0.0175, -0.1228, -0.0229, -0.1693,\n          0.0569,  0.0417,  0.2388, -0.2079,  0.2019, -0.2144,  0.2079,  0.2182],\n        [ 0.2249, -0.1636,  0.1685, -0.2209, -0.1642, -0.1226, -0.1607,  0.1838,\n          0.1919,  0.2130, -0.2021, -0.1711, -0.0915,  0.2166,  0.2482,  0.0935],\n        [ 0.0320,  0.0961, -0.0973,  0.1529,  0.1876, -0.0064, -0.1506, -0.1087,\n          0.2056,  0.2004, -0.1594, -0.2419, -0.1869, -0.0085, -0.1187, -0.1239],\n        [-0.0180, -0.0636,  0.1000, -0.1686,  0.2484,  0.1092,  0.0151,  0.1271,\n          0.1561, -0.1158,  0.0934, -0.0032, -0.2478, -0.1049,  0.0907, -0.2482],\n        [-0.1727, -0.2457, -0.1297, -0.0024,  0.2267,  0.1885,  0.1174, -0.1291,\n         -0.0977,  0.1011,  0.1934,  0.0301,  0.0903, -0.2107, -0.1379,  0.2325],\n        [ 0.0592, -0.2124,  0.0993,  0.0982, -0.0445, -0.1621, -0.2036, -0.1720,\n          0.1786,  0.1558, -0.2025, -0.0614, -0.1899, -0.1558, -0.0319,  0.0172],\n        [ 0.2326,  0.0058, -0.0599, -0.1197,  0.0279,  0.1372,  0.1840, -0.1760,\n          0.2160, -0.1191, -0.0736,  0.1027,  0.0483,  0.2291, -0.0631, -0.0480],\n        [-0.0528,  0.1657,  0.0299, -0.0639, -0.0044, -0.0466, -0.1340,  0.1585,\n         -0.2077, -0.0740,  0.1308,  0.2048, -0.0030,  0.0493,  0.2417,  0.0412]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2125, -0.2253, -0.0618,  0.1841], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2113,  0.0537,  0.3004, -0.1310,  0.1315,  0.2390, -0.2568,  0.2520],\n        [-0.1139, -0.1354, -0.1750,  0.3247,  0.2728,  0.0067, -0.0253, -0.1014],\n        [ 0.2189,  0.0065,  0.1175, -0.1085, -0.2499, -0.1224,  0.1790, -0.1516],\n        [-0.0527,  0.0341, -0.0369,  0.1762, -0.0823,  0.1009,  0.3505, -0.1482]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.3395, -0.0879,  0.1761,  0.1900, -0.1241,  0.0118, -0.2960, -0.0438],\n        [ 0.1251, -0.1376,  0.2274,  0.2684, -0.1382,  0.0040, -0.1198, -0.2029],\n        [ 0.2273,  0.2906, -0.0912,  0.0509,  0.1091,  0.2614,  0.2067,  0.2349],\n        [ 0.1028,  0.1610,  0.2466,  0.1340, -0.1883,  0.0640, -0.0489,  0.2754],\n        [ 0.2587, -0.2419, -0.3128, -0.2047, -0.0145, -0.0354, -0.0291, -0.0203],\n        [-0.1506, -0.3271,  0.1429, -0.1394,  0.0037, -0.3526, -0.2611,  0.2022],\n        [ 0.1475, -0.0578,  0.2597,  0.2614,  0.2512, -0.1956, -0.0044,  0.2180],\n        [-0.0037, -0.2104, -0.2634, -0.0944, -0.3276,  0.2085, -0.3279, -0.0588],\n        [-0.1654,  0.2706, -0.0187,  0.0519,  0.2225,  0.3189, -0.0761,  0.0734],\n        [ 0.2583, -0.1487,  0.0664, -0.0372, -0.3361, -0.3242, -0.2750,  0.2378],\n        [-0.2683, -0.1287,  0.2091, -0.2095,  0.1579,  0.1086, -0.0244,  0.0295],\n        [-0.1417, -0.2132,  0.1598, -0.2699, -0.3340, -0.0746,  0.0956, -0.2045],\n        [ 0.2520, -0.1666, -0.2352, -0.0313,  0.0451, -0.1987, -0.0287,  0.1147],\n        [-0.2997, -0.3027, -0.3229,  0.0948,  0.1370,  0.2431,  0.3273,  0.0844],\n        [-0.3222,  0.2943, -0.3385,  0.1835,  0.2299,  0.0091, -0.3205,  0.0541],\n        [-0.1406,  0.0411,  0.1621, -0.2447,  0.2611,  0.3286,  0.1681, -0.1627],\n        [ 0.2183, -0.1143, -0.2877, -0.0464,  0.2089, -0.2559,  0.1106,  0.1490],\n        [-0.1911,  0.1221,  0.0213,  0.2856,  0.1814,  0.0813,  0.1960, -0.1869],\n        [ 0.1544, -0.2912,  0.1287,  0.1218,  0.1716,  0.0476,  0.3221, -0.3414],\n        [-0.0902,  0.1083, -0.0399,  0.2775,  0.3487,  0.2681,  0.0308, -0.2665],\n        [ 0.3202,  0.1431,  0.0280, -0.2302, -0.2308,  0.0202, -0.0464,  0.1689],\n        [ 0.1653, -0.0780,  0.3183, -0.2631,  0.0877, -0.0141, -0.2937,  0.1948],\n        [ 0.3122, -0.1971,  0.1705,  0.3071,  0.2224, -0.3312, -0.0048,  0.1778],\n        [-0.0182, -0.3278, -0.2404,  0.3146,  0.0497,  0.0400, -0.0669,  0.0644],\n        [ 0.2540, -0.0039,  0.1353, -0.1274, -0.1719, -0.2511, -0.3517,  0.2414],\n        [ 0.2796,  0.2031,  0.2237,  0.1470, -0.2213, -0.2165,  0.0588, -0.0782],\n        [-0.1576,  0.3418, -0.3289, -0.2724,  0.1742,  0.2568, -0.3102, -0.2990],\n        [-0.3243,  0.3384, -0.0254, -0.1259, -0.0098, -0.2614, -0.0244,  0.0820],\n        [ 0.1506,  0.0724, -0.0462,  0.0374,  0.1999, -0.0991, -0.0976, -0.3338],\n        [ 0.0826, -0.2680, -0.1699,  0.3009, -0.1854,  0.2676, -0.0916,  0.1031],\n        [ 0.1623, -0.1458, -0.2785,  0.3450,  0.2221,  0.1470,  0.0234,  0.0600],\n        [ 0.3070, -0.0164,  0.0119, -0.1879, -0.2432,  0.2666, -0.1304,  0.0092]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3521,  0.0967,  0.3183, -0.2823, -0.3504,  0.2576, -0.2015, -0.0744,\n        -0.0084, -0.2957,  0.0606, -0.1754, -0.2230,  0.1799,  0.2834,  0.2052,\n         0.0122,  0.2535,  0.2076, -0.0875,  0.2087,  0.1766, -0.2256,  0.2901,\n         0.1591,  0.0448,  0.0861, -0.1812, -0.1794,  0.3144,  0.2590,  0.0348],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.4164e-01,  4.9998e-02,  9.4587e-02, -1.4819e-01, -6.4117e-02,\n          8.8083e-02,  4.3626e-02, -1.2887e-01,  2.0452e-02, -6.9333e-03,\n          1.4913e-01,  1.4824e-01, -5.4354e-02, -1.4343e-01,  1.8616e-02,\n         -1.1190e-01, -5.5895e-02, -1.0882e-01, -1.4800e-01,  6.2586e-02,\n          1.4709e-01, -1.4805e-01, -1.0750e-01, -1.8683e-02,  9.5916e-03,\n          4.0883e-02,  8.6613e-02,  9.5325e-02, -1.5871e-01,  1.2573e-01,\n          1.4573e-01, -4.7535e-02],\n        [-8.2195e-02,  1.3446e-01, -5.4868e-02,  1.5400e-01, -7.2470e-02,\n         -1.5521e-02, -7.7573e-02,  6.9886e-02,  7.7779e-02,  1.4580e-02,\n          1.4622e-01,  5.1345e-04, -9.6822e-02, -2.0393e-02,  6.4412e-02,\n          1.2672e-01,  1.2845e-01, -1.6954e-01, -1.1473e-01, -1.5924e-03,\n         -1.7520e-01, -1.1850e-01, -1.1673e-01, -1.3770e-02,  8.3546e-02,\n         -8.6541e-02,  1.1290e-01, -1.1763e-01, -4.2697e-03,  1.7276e-01,\n          4.1532e-02, -3.0640e-02],\n        [-1.4316e-01,  8.6533e-02, -2.8384e-02, -7.5813e-02, -1.3991e-01,\n          1.5363e-01,  9.4876e-02,  1.3671e-01, -1.7088e-01, -7.9606e-02,\n         -4.4264e-02,  1.5986e-01, -1.1564e-01, -6.4540e-03,  1.6457e-01,\n          3.8141e-02, -1.5604e-01,  5.4864e-02,  3.9292e-02,  1.7249e-01,\n          1.1940e-04,  1.3645e-01,  1.7427e-01, -1.0796e-01,  3.1420e-02,\n         -1.3929e-01, -9.9538e-02, -1.2790e-01, -5.1091e-02, -1.3031e-02,\n         -1.7376e-01, -4.2091e-02],\n        [-7.1749e-02, -1.4958e-01, -1.0692e-03, -5.3338e-02, -1.4461e-01,\n         -7.4490e-02,  3.3394e-02,  3.8975e-04,  2.6090e-02,  1.1892e-01,\n         -8.9638e-02,  1.2179e-01, -2.4129e-02,  1.3856e-02,  7.5605e-03,\n         -5.7807e-03, -1.3991e-01, -1.4958e-01, -1.1970e-02,  1.6946e-01,\n          1.2676e-01, -3.4209e-02,  4.2555e-02, -3.9441e-02,  9.1757e-02,\n          6.6502e-02,  2.3496e-02, -8.6223e-02, -3.6790e-02, -1.2756e-01,\n         -1.3351e-01,  1.5829e-01],\n        [-9.1450e-02,  4.0400e-04,  1.4979e-01, -6.2904e-02,  1.1551e-02,\n         -1.3523e-01, -1.7461e-01, -8.6543e-02,  1.6253e-02,  1.6941e-01,\n         -7.5792e-02,  1.4151e-01,  7.0122e-02,  7.6291e-02, -1.2033e-01,\n          8.7828e-02, -9.4884e-02,  1.4642e-01, -3.8381e-02,  6.2421e-02,\n         -7.8018e-03, -1.7518e-01,  1.3094e-01,  1.2322e-01, -4.9281e-02,\n          5.2731e-02,  1.6888e-01, -1.2087e-01, -1.1189e-01,  1.0178e-01,\n          7.4903e-02,  8.2449e-02],\n        [ 4.2874e-02, -1.4464e-01,  5.9353e-02, -1.6138e-01,  1.6636e-01,\n          5.2324e-02,  1.1302e-01,  4.4067e-02,  4.0590e-02,  3.9453e-03,\n         -1.3381e-01,  7.7182e-02,  1.1976e-01, -8.6848e-02,  4.1724e-02,\n          1.0893e-01, -1.9396e-02, -1.0576e-02,  1.2009e-01, -1.2587e-01,\n          1.5269e-01,  9.4369e-02,  1.2224e-01,  1.1262e-01, -1.2895e-01,\n         -4.4121e-03, -8.2041e-02,  1.0329e-01,  4.2199e-02, -6.7599e-02,\n          1.0647e-01, -1.4847e-01],\n        [ 1.8984e-02,  4.0416e-02,  8.5473e-02,  7.4861e-02,  3.8330e-02,\n          6.6576e-02,  1.4469e-01, -1.3353e-01,  9.5792e-02,  9.1761e-03,\n         -1.5071e-01, -5.1057e-02,  3.9096e-02, -6.9404e-02, -1.3028e-01,\n          1.2851e-01,  1.0514e-01, -1.1391e-01,  6.4374e-02,  5.0399e-02,\n          1.5977e-01,  3.7523e-02,  6.0794e-02, -1.2072e-01, -2.4094e-02,\n          1.2299e-01, -1.4874e-01, -2.9434e-02,  1.2319e-01, -3.5837e-02,\n         -8.8173e-02, -1.9478e-02],\n        [ 1.5679e-01, -1.8064e-03,  2.6542e-02,  6.3215e-02, -1.7389e-01,\n         -1.0170e-01,  1.5694e-01, -7.1268e-02,  1.2887e-01,  3.4880e-02,\n         -1.4448e-01,  1.0568e-01,  1.5316e-01, -1.2495e-01,  1.1414e-02,\n          1.1823e-02,  1.2910e-02,  1.5421e-01,  1.7541e-01,  4.0261e-02,\n          2.1148e-02, -1.7031e-01,  1.0754e-01,  1.2899e-01,  1.2755e-01,\n         -1.0955e-01,  1.1002e-02, -1.6780e-01,  5.4924e-02, -1.4224e-01,\n          8.2599e-02, -1.0226e-01],\n        [ 8.2857e-02, -1.5285e-01, -2.3472e-02, -1.1134e-01, -1.7075e-01,\n         -2.8099e-02,  1.6476e-01,  9.1932e-02,  1.6935e-01, -9.0696e-02,\n         -1.6090e-01,  5.4233e-02, -1.7207e-01, -1.5134e-01,  1.5060e-01,\n         -2.4710e-02, -3.7284e-02, -1.2032e-01, -3.8265e-02,  1.5710e-02,\n          1.4063e-01,  1.6238e-01,  1.2343e-01, -1.6959e-01,  3.7754e-02,\n         -4.8759e-02, -9.2434e-02, -1.0723e-01, -6.1937e-02,  1.1720e-01,\n          1.6277e-01, -8.7480e-02],\n        [ 1.7556e-01, -7.4363e-02,  9.1024e-03, -1.6649e-01, -1.0240e-01,\n         -1.1329e-01,  9.6215e-02, -3.3707e-02, -1.7417e-01,  1.1020e-01,\n          1.6229e-02,  1.1089e-01, -2.4669e-02,  1.0588e-01,  6.2829e-02,\n          9.0557e-02, -9.7801e-02, -6.5377e-02,  2.0681e-02,  6.6766e-02,\n          9.2502e-02,  6.1951e-02, -7.4137e-03, -9.2668e-03, -7.5928e-02,\n          1.5336e-01, -1.5458e-01, -5.6608e-02,  1.3691e-01,  1.4827e-01,\n          9.1174e-02, -4.3405e-02],\n        [ 1.2114e-01, -5.7264e-02,  1.4715e-01, -1.0370e-01,  5.9215e-02,\n         -1.5462e-01,  8.1680e-02, -1.4589e-01, -1.0415e-01,  4.5540e-04,\n          1.6228e-01, -6.6313e-02, -1.6722e-01,  1.4000e-02, -1.1398e-01,\n          9.8576e-02,  8.4185e-03, -3.3646e-03, -2.9327e-02,  1.1424e-01,\n          1.2155e-01, -9.8112e-02,  1.6191e-01,  1.0915e-01,  4.3743e-02,\n         -3.4206e-02, -7.0041e-02, -3.9643e-02,  1.5330e-01,  7.1139e-02,\n         -3.7660e-02,  1.6502e-01],\n        [-6.2810e-02, -9.5538e-02,  1.3427e-01,  1.8745e-03,  1.6346e-01,\n          1.5736e-01,  3.2509e-02,  7.1743e-02, -1.1786e-01, -4.6321e-02,\n          1.1253e-01,  5.6210e-02, -1.4847e-01,  6.8439e-02, -1.4668e-01,\n          4.2022e-02, -8.6356e-02,  1.5711e-01, -1.7445e-01,  7.8872e-02,\n         -3.2466e-02, -1.3113e-02,  6.4376e-02,  4.7718e-03, -1.4915e-01,\n          6.4961e-02,  1.3131e-01, -4.1308e-02, -1.3597e-01, -1.2023e-01,\n          6.9268e-02, -7.1581e-02],\n        [-3.4838e-02,  1.4505e-01, -1.7467e-01,  8.5321e-02,  1.4914e-01,\n         -1.7484e-02, -1.0275e-01, -7.3413e-02,  1.5599e-01,  5.7858e-02,\n          1.2154e-01,  8.7817e-02, -4.4730e-02, -2.8210e-02, -1.6264e-01,\n         -1.0533e-01,  6.1856e-03,  5.4205e-02,  1.6007e-01, -2.1598e-02,\n          1.3502e-01, -1.2019e-01, -1.0900e-01,  1.6699e-01,  1.5621e-01,\n         -1.1992e-01,  7.6516e-02,  4.1088e-02, -2.1245e-02, -1.6813e-01,\n         -3.8280e-02,  7.3434e-02],\n        [ 9.7815e-02, -1.6951e-01, -7.4896e-02, -1.5089e-01,  1.9896e-02,\n          1.5889e-01,  3.7364e-02,  1.6405e-01, -7.3978e-02,  8.5876e-02,\n         -3.3537e-02, -3.3059e-03,  1.4585e-02,  1.7206e-02, -8.8287e-02,\n          1.7068e-01,  9.8664e-02, -1.6785e-01, -8.1319e-02, -1.0873e-01,\n         -1.2358e-01, -8.2990e-02,  5.8945e-02,  6.7608e-04,  1.6422e-01,\n          1.7648e-01,  5.8385e-02, -1.4099e-01,  1.9485e-02,  5.2488e-02,\n          1.2340e-01,  1.4233e-02],\n        [ 1.6035e-01,  4.3390e-03, -1.0192e-01, -7.9308e-03, -7.2530e-02,\n          9.7504e-02,  5.9228e-02,  2.8681e-02,  8.7285e-02, -1.6797e-01,\n          1.3127e-01, -1.3971e-01,  1.7613e-01, -1.0467e-01,  1.2409e-01,\n          8.3073e-02,  8.9449e-02, -2.4724e-02,  7.1128e-02, -1.3330e-01,\n         -1.2473e-01, -3.9580e-02, -7.4173e-02, -1.4750e-01, -1.5402e-01,\n          9.7212e-02,  8.0385e-02,  1.3524e-01, -1.1920e-01,  1.3529e-01,\n         -6.5968e-02, -4.5228e-02],\n        [ 1.1926e-01, -1.6282e-01, -6.3395e-02, -1.1036e-01, -7.3849e-02,\n          1.2832e-02,  9.4942e-02,  2.5077e-02, -8.5065e-02, -3.5302e-02,\n          4.9882e-02,  8.1627e-02, -1.4323e-01,  3.6491e-02,  1.6413e-01,\n          1.0179e-02, -5.1196e-02, -1.7474e-01, -1.4420e-01, -6.5626e-02,\n         -1.0158e-02, -1.1223e-01, -2.6221e-02, -1.6426e-01, -6.1769e-02,\n         -5.7792e-02,  1.5038e-01, -1.0410e-01,  9.1519e-02,  1.4055e-01,\n         -1.6057e-01,  5.0658e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1623, -0.0248,  0.0539, -0.1531,  0.0896, -0.0712, -0.0072, -0.1694,\n        -0.1671, -0.1760, -0.0086,  0.0649,  0.1761,  0.1320, -0.0436, -0.1081],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0714,  0.0375, -0.0247,  0.2356,  0.0175, -0.1228, -0.0229, -0.1693,\n          0.0569,  0.0417,  0.2388, -0.2079,  0.2019, -0.2144,  0.2079,  0.2182],\n        [ 0.2249, -0.1636,  0.1685, -0.2209, -0.1642, -0.1226, -0.1607,  0.1838,\n          0.1919,  0.2130, -0.2021, -0.1711, -0.0915,  0.2166,  0.2482,  0.0935],\n        [ 0.0320,  0.0961, -0.0973,  0.1529,  0.1876, -0.0064, -0.1506, -0.1087,\n          0.2056,  0.2004, -0.1594, -0.2419, -0.1869, -0.0085, -0.1187, -0.1239],\n        [-0.0180, -0.0636,  0.1000, -0.1686,  0.2484,  0.1092,  0.0151,  0.1271,\n          0.1561, -0.1158,  0.0934, -0.0032, -0.2478, -0.1049,  0.0907, -0.2482],\n        [-0.1727, -0.2457, -0.1297, -0.0024,  0.2267,  0.1885,  0.1174, -0.1291,\n         -0.0977,  0.1011,  0.1934,  0.0301,  0.0903, -0.2107, -0.1379,  0.2325],\n        [ 0.0592, -0.2124,  0.0993,  0.0982, -0.0445, -0.1621, -0.2036, -0.1720,\n          0.1786,  0.1558, -0.2025, -0.0614, -0.1899, -0.1558, -0.0319,  0.0172],\n        [ 0.2326,  0.0058, -0.0599, -0.1197,  0.0279,  0.1372,  0.1840, -0.1760,\n          0.2160, -0.1191, -0.0736,  0.1027,  0.0483,  0.2291, -0.0631, -0.0480],\n        [-0.0528,  0.1657,  0.0299, -0.0639, -0.0044, -0.0466, -0.1340,  0.1585,\n         -0.2077, -0.0740,  0.1308,  0.2048, -0.0030,  0.0493,  0.2417,  0.0412]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0314, -0.0116, -0.1759,  0.0013, -0.1767, -0.1728,  0.0432,  0.1657],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2113,  0.0537,  0.3004, -0.1310,  0.1315,  0.2390, -0.2568,  0.2520],\n        [-0.1139, -0.1354, -0.1750,  0.3247,  0.2728,  0.0067, -0.0253, -0.1014],\n        [ 0.2189,  0.0065,  0.1175, -0.1085, -0.2499, -0.1224,  0.1790, -0.1516],\n        [-0.0527,  0.0341, -0.0369,  0.1762, -0.0823,  0.1009,  0.3505, -0.1482]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2125, -0.2253, -0.0618,  0.1841], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x76f94067e710>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3521,  0.0967,  0.3183, -0.2823, -0.3504,  0.2576, -0.2015, -0.0744,\n        -0.0084, -0.2957,  0.0606, -0.1754, -0.2230,  0.1799,  0.2834,  0.2052,\n         0.0122,  0.2535,  0.2076, -0.0875,  0.2087,  0.1766, -0.2256,  0.2901,\n         0.1591,  0.0448,  0.0861, -0.1812, -0.1794,  0.3144,  0.2590,  0.0348],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.3395, -0.0879,  0.1761,  0.1900, -0.1241,  0.0118, -0.2960, -0.0438],\n        [ 0.1251, -0.1376,  0.2274,  0.2684, -0.1382,  0.0040, -0.1198, -0.2029],\n        [ 0.2273,  0.2906, -0.0912,  0.0509,  0.1091,  0.2614,  0.2067,  0.2349],\n        [ 0.1028,  0.1610,  0.2466,  0.1340, -0.1883,  0.0640, -0.0489,  0.2754],\n        [ 0.2587, -0.2419, -0.3128, -0.2047, -0.0145, -0.0354, -0.0291, -0.0203],\n        [-0.1506, -0.3271,  0.1429, -0.1394,  0.0037, -0.3526, -0.2611,  0.2022],\n        [ 0.1475, -0.0578,  0.2597,  0.2614,  0.2512, -0.1956, -0.0044,  0.2180],\n        [-0.0037, -0.2104, -0.2634, -0.0944, -0.3276,  0.2085, -0.3279, -0.0588],\n        [-0.1654,  0.2706, -0.0187,  0.0519,  0.2225,  0.3189, -0.0761,  0.0734],\n        [ 0.2583, -0.1487,  0.0664, -0.0372, -0.3361, -0.3242, -0.2750,  0.2378],\n        [-0.2683, -0.1287,  0.2091, -0.2095,  0.1579,  0.1086, -0.0244,  0.0295],\n        [-0.1417, -0.2132,  0.1598, -0.2699, -0.3340, -0.0746,  0.0956, -0.2045],\n        [ 0.2520, -0.1666, -0.2352, -0.0313,  0.0451, -0.1987, -0.0287,  0.1147],\n        [-0.2997, -0.3027, -0.3229,  0.0948,  0.1370,  0.2431,  0.3273,  0.0844],\n        [-0.3222,  0.2943, -0.3385,  0.1835,  0.2299,  0.0091, -0.3205,  0.0541],\n        [-0.1406,  0.0411,  0.1621, -0.2447,  0.2611,  0.3286,  0.1681, -0.1627],\n        [ 0.2183, -0.1143, -0.2877, -0.0464,  0.2089, -0.2559,  0.1106,  0.1490],\n        [-0.1911,  0.1221,  0.0213,  0.2856,  0.1814,  0.0813,  0.1960, -0.1869],\n        [ 0.1544, -0.2912,  0.1287,  0.1218,  0.1716,  0.0476,  0.3221, -0.3414],\n        [-0.0902,  0.1083, -0.0399,  0.2775,  0.3487,  0.2681,  0.0308, -0.2665],\n        [ 0.3202,  0.1431,  0.0280, -0.2302, -0.2308,  0.0202, -0.0464,  0.1689],\n        [ 0.1653, -0.0780,  0.3183, -0.2631,  0.0877, -0.0141, -0.2937,  0.1948],\n        [ 0.3122, -0.1971,  0.1705,  0.3071,  0.2224, -0.3312, -0.0048,  0.1778],\n        [-0.0182, -0.3278, -0.2404,  0.3146,  0.0497,  0.0400, -0.0669,  0.0644],\n        [ 0.2540, -0.0039,  0.1353, -0.1274, -0.1719, -0.2511, -0.3517,  0.2414],\n        [ 0.2796,  0.2031,  0.2237,  0.1470, -0.2213, -0.2165,  0.0588, -0.0782],\n        [-0.1576,  0.3418, -0.3289, -0.2724,  0.1742,  0.2568, -0.3102, -0.2990],\n        [-0.3243,  0.3384, -0.0254, -0.1259, -0.0098, -0.2614, -0.0244,  0.0820],\n        [ 0.1506,  0.0724, -0.0462,  0.0374,  0.1999, -0.0991, -0.0976, -0.3338],\n        [ 0.0826, -0.2680, -0.1699,  0.3009, -0.1854,  0.2676, -0.0916,  0.1031],\n        [ 0.1623, -0.1458, -0.2785,  0.3450,  0.2221,  0.1470,  0.0234,  0.0600],\n        [ 0.3070, -0.0164,  0.0119, -0.1879, -0.2432,  0.2666, -0.1304,  0.0092]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1623, -0.0248,  0.0539, -0.1531,  0.0896, -0.0712, -0.0072, -0.1694,\n        -0.1671, -0.1760, -0.0086,  0.0649,  0.1761,  0.1320, -0.0436, -0.1081],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.4164e-01,  4.9998e-02,  9.4587e-02, -1.4819e-01, -6.4117e-02,\n          8.8083e-02,  4.3626e-02, -1.2887e-01,  2.0452e-02, -6.9333e-03,\n          1.4913e-01,  1.4824e-01, -5.4354e-02, -1.4343e-01,  1.8616e-02,\n         -1.1190e-01, -5.5895e-02, -1.0882e-01, -1.4800e-01,  6.2586e-02,\n          1.4709e-01, -1.4805e-01, -1.0750e-01, -1.8683e-02,  9.5916e-03,\n          4.0883e-02,  8.6613e-02,  9.5325e-02, -1.5871e-01,  1.2573e-01,\n          1.4573e-01, -4.7535e-02],\n        [-8.2195e-02,  1.3446e-01, -5.4868e-02,  1.5400e-01, -7.2470e-02,\n         -1.5521e-02, -7.7573e-02,  6.9886e-02,  7.7779e-02,  1.4580e-02,\n          1.4622e-01,  5.1345e-04, -9.6822e-02, -2.0393e-02,  6.4412e-02,\n          1.2672e-01,  1.2845e-01, -1.6954e-01, -1.1473e-01, -1.5924e-03,\n         -1.7520e-01, -1.1850e-01, -1.1673e-01, -1.3770e-02,  8.3546e-02,\n         -8.6541e-02,  1.1290e-01, -1.1763e-01, -4.2697e-03,  1.7276e-01,\n          4.1532e-02, -3.0640e-02],\n        [-1.4316e-01,  8.6533e-02, -2.8384e-02, -7.5813e-02, -1.3991e-01,\n          1.5363e-01,  9.4876e-02,  1.3671e-01, -1.7088e-01, -7.9606e-02,\n         -4.4264e-02,  1.5986e-01, -1.1564e-01, -6.4540e-03,  1.6457e-01,\n          3.8141e-02, -1.5604e-01,  5.4864e-02,  3.9292e-02,  1.7249e-01,\n          1.1940e-04,  1.3645e-01,  1.7427e-01, -1.0796e-01,  3.1420e-02,\n         -1.3929e-01, -9.9538e-02, -1.2790e-01, -5.1091e-02, -1.3031e-02,\n         -1.7376e-01, -4.2091e-02],\n        [-7.1749e-02, -1.4958e-01, -1.0692e-03, -5.3338e-02, -1.4461e-01,\n         -7.4490e-02,  3.3394e-02,  3.8975e-04,  2.6090e-02,  1.1892e-01,\n         -8.9638e-02,  1.2179e-01, -2.4129e-02,  1.3856e-02,  7.5605e-03,\n         -5.7807e-03, -1.3991e-01, -1.4958e-01, -1.1970e-02,  1.6946e-01,\n          1.2676e-01, -3.4209e-02,  4.2555e-02, -3.9441e-02,  9.1757e-02,\n          6.6502e-02,  2.3496e-02, -8.6223e-02, -3.6790e-02, -1.2756e-01,\n         -1.3351e-01,  1.5829e-01],\n        [-9.1450e-02,  4.0400e-04,  1.4979e-01, -6.2904e-02,  1.1551e-02,\n         -1.3523e-01, -1.7461e-01, -8.6543e-02,  1.6253e-02,  1.6941e-01,\n         -7.5792e-02,  1.4151e-01,  7.0122e-02,  7.6291e-02, -1.2033e-01,\n          8.7828e-02, -9.4884e-02,  1.4642e-01, -3.8381e-02,  6.2421e-02,\n         -7.8018e-03, -1.7518e-01,  1.3094e-01,  1.2322e-01, -4.9281e-02,\n          5.2731e-02,  1.6888e-01, -1.2087e-01, -1.1189e-01,  1.0178e-01,\n          7.4903e-02,  8.2449e-02],\n        [ 4.2874e-02, -1.4464e-01,  5.9353e-02, -1.6138e-01,  1.6636e-01,\n          5.2324e-02,  1.1302e-01,  4.4067e-02,  4.0590e-02,  3.9453e-03,\n         -1.3381e-01,  7.7182e-02,  1.1976e-01, -8.6848e-02,  4.1724e-02,\n          1.0893e-01, -1.9396e-02, -1.0576e-02,  1.2009e-01, -1.2587e-01,\n          1.5269e-01,  9.4369e-02,  1.2224e-01,  1.1262e-01, -1.2895e-01,\n         -4.4121e-03, -8.2041e-02,  1.0329e-01,  4.2199e-02, -6.7599e-02,\n          1.0647e-01, -1.4847e-01],\n        [ 1.8984e-02,  4.0416e-02,  8.5473e-02,  7.4861e-02,  3.8330e-02,\n          6.6576e-02,  1.4469e-01, -1.3353e-01,  9.5792e-02,  9.1761e-03,\n         -1.5071e-01, -5.1057e-02,  3.9096e-02, -6.9404e-02, -1.3028e-01,\n          1.2851e-01,  1.0514e-01, -1.1391e-01,  6.4374e-02,  5.0399e-02,\n          1.5977e-01,  3.7523e-02,  6.0794e-02, -1.2072e-01, -2.4094e-02,\n          1.2299e-01, -1.4874e-01, -2.9434e-02,  1.2319e-01, -3.5837e-02,\n         -8.8173e-02, -1.9478e-02],\n        [ 1.5679e-01, -1.8064e-03,  2.6542e-02,  6.3215e-02, -1.7389e-01,\n         -1.0170e-01,  1.5694e-01, -7.1268e-02,  1.2887e-01,  3.4880e-02,\n         -1.4448e-01,  1.0568e-01,  1.5316e-01, -1.2495e-01,  1.1414e-02,\n          1.1823e-02,  1.2910e-02,  1.5421e-01,  1.7541e-01,  4.0261e-02,\n          2.1148e-02, -1.7031e-01,  1.0754e-01,  1.2899e-01,  1.2755e-01,\n         -1.0955e-01,  1.1002e-02, -1.6780e-01,  5.4924e-02, -1.4224e-01,\n          8.2599e-02, -1.0226e-01],\n        [ 8.2857e-02, -1.5285e-01, -2.3472e-02, -1.1134e-01, -1.7075e-01,\n         -2.8099e-02,  1.6476e-01,  9.1932e-02,  1.6935e-01, -9.0696e-02,\n         -1.6090e-01,  5.4233e-02, -1.7207e-01, -1.5134e-01,  1.5060e-01,\n         -2.4710e-02, -3.7284e-02, -1.2032e-01, -3.8265e-02,  1.5710e-02,\n          1.4063e-01,  1.6238e-01,  1.2343e-01, -1.6959e-01,  3.7754e-02,\n         -4.8759e-02, -9.2434e-02, -1.0723e-01, -6.1937e-02,  1.1720e-01,\n          1.6277e-01, -8.7480e-02],\n        [ 1.7556e-01, -7.4363e-02,  9.1024e-03, -1.6649e-01, -1.0240e-01,\n         -1.1329e-01,  9.6215e-02, -3.3707e-02, -1.7417e-01,  1.1020e-01,\n          1.6229e-02,  1.1089e-01, -2.4669e-02,  1.0588e-01,  6.2829e-02,\n          9.0557e-02, -9.7801e-02, -6.5377e-02,  2.0681e-02,  6.6766e-02,\n          9.2502e-02,  6.1951e-02, -7.4137e-03, -9.2668e-03, -7.5928e-02,\n          1.5336e-01, -1.5458e-01, -5.6608e-02,  1.3691e-01,  1.4827e-01,\n          9.1174e-02, -4.3405e-02],\n        [ 1.2114e-01, -5.7264e-02,  1.4715e-01, -1.0370e-01,  5.9215e-02,\n         -1.5462e-01,  8.1680e-02, -1.4589e-01, -1.0415e-01,  4.5540e-04,\n          1.6228e-01, -6.6313e-02, -1.6722e-01,  1.4000e-02, -1.1398e-01,\n          9.8576e-02,  8.4185e-03, -3.3646e-03, -2.9327e-02,  1.1424e-01,\n          1.2155e-01, -9.8112e-02,  1.6191e-01,  1.0915e-01,  4.3743e-02,\n         -3.4206e-02, -7.0041e-02, -3.9643e-02,  1.5330e-01,  7.1139e-02,\n         -3.7660e-02,  1.6502e-01],\n        [-6.2810e-02, -9.5538e-02,  1.3427e-01,  1.8745e-03,  1.6346e-01,\n          1.5736e-01,  3.2509e-02,  7.1743e-02, -1.1786e-01, -4.6321e-02,\n          1.1253e-01,  5.6210e-02, -1.4847e-01,  6.8439e-02, -1.4668e-01,\n          4.2022e-02, -8.6356e-02,  1.5711e-01, -1.7445e-01,  7.8872e-02,\n         -3.2466e-02, -1.3113e-02,  6.4376e-02,  4.7718e-03, -1.4915e-01,\n          6.4961e-02,  1.3131e-01, -4.1308e-02, -1.3597e-01, -1.2023e-01,\n          6.9268e-02, -7.1581e-02],\n        [-3.4838e-02,  1.4505e-01, -1.7467e-01,  8.5321e-02,  1.4914e-01,\n         -1.7484e-02, -1.0275e-01, -7.3413e-02,  1.5599e-01,  5.7858e-02,\n          1.2154e-01,  8.7817e-02, -4.4730e-02, -2.8210e-02, -1.6264e-01,\n         -1.0533e-01,  6.1856e-03,  5.4205e-02,  1.6007e-01, -2.1598e-02,\n          1.3502e-01, -1.2019e-01, -1.0900e-01,  1.6699e-01,  1.5621e-01,\n         -1.1992e-01,  7.6516e-02,  4.1088e-02, -2.1245e-02, -1.6813e-01,\n         -3.8280e-02,  7.3434e-02],\n        [ 9.7815e-02, -1.6951e-01, -7.4896e-02, -1.5089e-01,  1.9896e-02,\n          1.5889e-01,  3.7364e-02,  1.6405e-01, -7.3978e-02,  8.5876e-02,\n         -3.3537e-02, -3.3059e-03,  1.4585e-02,  1.7206e-02, -8.8287e-02,\n          1.7068e-01,  9.8664e-02, -1.6785e-01, -8.1319e-02, -1.0873e-01,\n         -1.2358e-01, -8.2990e-02,  5.8945e-02,  6.7608e-04,  1.6422e-01,\n          1.7648e-01,  5.8385e-02, -1.4099e-01,  1.9485e-02,  5.2488e-02,\n          1.2340e-01,  1.4233e-02],\n        [ 1.6035e-01,  4.3390e-03, -1.0192e-01, -7.9308e-03, -7.2530e-02,\n          9.7504e-02,  5.9228e-02,  2.8681e-02,  8.7285e-02, -1.6797e-01,\n          1.3127e-01, -1.3971e-01,  1.7613e-01, -1.0467e-01,  1.2409e-01,\n          8.3073e-02,  8.9449e-02, -2.4724e-02,  7.1128e-02, -1.3330e-01,\n         -1.2473e-01, -3.9580e-02, -7.4173e-02, -1.4750e-01, -1.5402e-01,\n          9.7212e-02,  8.0385e-02,  1.3524e-01, -1.1920e-01,  1.3529e-01,\n         -6.5968e-02, -4.5228e-02],\n        [ 1.1926e-01, -1.6282e-01, -6.3395e-02, -1.1036e-01, -7.3849e-02,\n          1.2832e-02,  9.4942e-02,  2.5077e-02, -8.5065e-02, -3.5302e-02,\n          4.9882e-02,  8.1627e-02, -1.4323e-01,  3.6491e-02,  1.6413e-01,\n          1.0179e-02, -5.1196e-02, -1.7474e-01, -1.4420e-01, -6.5626e-02,\n         -1.0158e-02, -1.1223e-01, -2.6221e-02, -1.6426e-01, -6.1769e-02,\n         -5.7792e-02,  1.5038e-01, -1.0410e-01,  9.1519e-02,  1.4055e-01,\n         -1.6057e-01,  5.0658e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0314, -0.0116, -0.1759,  0.0013, -0.1767, -0.1728,  0.0432,  0.1657],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0714,  0.0375, -0.0247,  0.2356,  0.0175, -0.1228, -0.0229, -0.1693,\n          0.0569,  0.0417,  0.2388, -0.2079,  0.2019, -0.2144,  0.2079,  0.2182],\n        [ 0.2249, -0.1636,  0.1685, -0.2209, -0.1642, -0.1226, -0.1607,  0.1838,\n          0.1919,  0.2130, -0.2021, -0.1711, -0.0915,  0.2166,  0.2482,  0.0935],\n        [ 0.0320,  0.0961, -0.0973,  0.1529,  0.1876, -0.0064, -0.1506, -0.1087,\n          0.2056,  0.2004, -0.1594, -0.2419, -0.1869, -0.0085, -0.1187, -0.1239],\n        [-0.0180, -0.0636,  0.1000, -0.1686,  0.2484,  0.1092,  0.0151,  0.1271,\n          0.1561, -0.1158,  0.0934, -0.0032, -0.2478, -0.1049,  0.0907, -0.2482],\n        [-0.1727, -0.2457, -0.1297, -0.0024,  0.2267,  0.1885,  0.1174, -0.1291,\n         -0.0977,  0.1011,  0.1934,  0.0301,  0.0903, -0.2107, -0.1379,  0.2325],\n        [ 0.0592, -0.2124,  0.0993,  0.0982, -0.0445, -0.1621, -0.2036, -0.1720,\n          0.1786,  0.1558, -0.2025, -0.0614, -0.1899, -0.1558, -0.0319,  0.0172],\n        [ 0.2326,  0.0058, -0.0599, -0.1197,  0.0279,  0.1372,  0.1840, -0.1760,\n          0.2160, -0.1191, -0.0736,  0.1027,  0.0483,  0.2291, -0.0631, -0.0480],\n        [-0.0528,  0.1657,  0.0299, -0.0639, -0.0044, -0.0466, -0.1340,  0.1585,\n         -0.2077, -0.0740,  0.1308,  0.2048, -0.0030,  0.0493,  0.2417,  0.0412]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2125, -0.2253, -0.0618,  0.1841], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2113,  0.0537,  0.3004, -0.1310,  0.1315,  0.2390, -0.2568,  0.2520],\n        [-0.1139, -0.1354, -0.1750,  0.3247,  0.2728,  0.0067, -0.0253, -0.1014],\n        [ 0.2189,  0.0065,  0.1175, -0.1085, -0.2499, -0.1224,  0.1790, -0.1516],\n        [-0.0527,  0.0341, -0.0369,  0.1762, -0.0823,  0.1009,  0.3505, -0.1482]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x76f93e4d2b90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s321270000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s321270000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}