{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s322720000"
    },
    "q_lr":	0.0005,
    "seed":	322720000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7e30e5252450>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2679, -0.1431,  0.0046, -0.0099, -0.2915, -0.1608, -0.1118,  0.0901,\n        -0.1297,  0.0451,  0.2970, -0.2091, -0.2774, -0.1249,  0.3242, -0.1085,\n        -0.1299, -0.2610,  0.0422, -0.3199,  0.0785, -0.2562,  0.0836, -0.0217,\n        -0.1622,  0.2470, -0.3322,  0.0599,  0.1977,  0.0448, -0.2135,  0.2391],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0139,  0.2967,  0.0706, -0.0477,  0.1137,  0.2455,  0.0236,  0.1903],\n        [-0.2080,  0.0060, -0.1161, -0.2114,  0.0778,  0.0807,  0.0615,  0.1632],\n        [-0.0129, -0.3018, -0.0338, -0.3273, -0.3523,  0.1962,  0.1669,  0.3211],\n        [-0.0579, -0.0699,  0.3353,  0.0843, -0.2360, -0.1872, -0.2244, -0.1953],\n        [ 0.1627,  0.3417, -0.0351,  0.2944,  0.2020, -0.2704,  0.3529,  0.0132],\n        [-0.1315, -0.1907, -0.2633, -0.0731, -0.2515, -0.2988, -0.0975, -0.2100],\n        [ 0.2304, -0.1197, -0.0927,  0.1731, -0.3098,  0.1493,  0.1918, -0.0015],\n        [ 0.1397, -0.3082,  0.2869, -0.3446,  0.2313, -0.2348, -0.0530,  0.3014],\n        [-0.2555, -0.2141,  0.0900,  0.0504,  0.2531, -0.2929, -0.2458, -0.0909],\n        [-0.1758, -0.0462, -0.2942,  0.1825, -0.1007, -0.0406,  0.0113, -0.1349],\n        [-0.0318,  0.2525,  0.2224,  0.0893,  0.0973,  0.3346, -0.0688, -0.0560],\n        [ 0.1463,  0.0727, -0.0654,  0.1597,  0.0044,  0.2755, -0.0308, -0.0211],\n        [-0.2093, -0.1397, -0.2569,  0.2345, -0.3209, -0.1149, -0.0174, -0.0906],\n        [ 0.2700, -0.1704,  0.0711, -0.1317, -0.2059,  0.1129,  0.3235,  0.3009],\n        [ 0.0437,  0.2029,  0.2123, -0.2465,  0.1526,  0.1301,  0.3360, -0.3188],\n        [ 0.2361,  0.0054, -0.2851,  0.0847,  0.3149, -0.1628,  0.2618,  0.1456],\n        [-0.3334, -0.1571,  0.2838,  0.1021,  0.1937, -0.0544,  0.0216,  0.1892],\n        [-0.1944, -0.0976,  0.0005, -0.0107,  0.1546,  0.1489,  0.2598, -0.1592],\n        [ 0.0685, -0.0916,  0.0311, -0.0086,  0.0351,  0.1638,  0.2613,  0.1699],\n        [ 0.3243, -0.1688,  0.0083,  0.0599,  0.2388,  0.2365,  0.1996,  0.0487],\n        [ 0.0983, -0.3328, -0.3057,  0.1971,  0.0426,  0.0307,  0.0876,  0.1461],\n        [-0.1108, -0.0212, -0.0131,  0.1857, -0.2404, -0.1620,  0.0217, -0.2880],\n        [-0.3400, -0.2975,  0.0355,  0.0860, -0.1943, -0.0611, -0.0403,  0.2704],\n        [-0.2825, -0.0540, -0.1250, -0.0152, -0.0776,  0.2085, -0.2253, -0.0479],\n        [-0.1369, -0.0937, -0.3289, -0.2283,  0.2662, -0.0832, -0.0697, -0.0912],\n        [-0.1428,  0.2189,  0.1516,  0.1643, -0.3356,  0.2366, -0.1916,  0.3452],\n        [-0.2314,  0.1829,  0.3479,  0.2194,  0.1524,  0.1893, -0.3449,  0.0829],\n        [ 0.2444, -0.0863, -0.0314, -0.1193,  0.1424,  0.0454,  0.2431,  0.1644],\n        [-0.1702,  0.1908,  0.0512,  0.0261, -0.2208, -0.3015,  0.3090,  0.0006],\n        [-0.0656, -0.0892, -0.0834, -0.0731,  0.2212,  0.1607, -0.3302, -0.3334],\n        [-0.3139, -0.2475,  0.1171,  0.1244, -0.2611, -0.0670, -0.0350,  0.2473],\n        [ 0.0264,  0.1203,  0.0162,  0.2257,  0.1609,  0.1739, -0.0602,  0.3038]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0231,  0.1294,  0.0628, -0.1662,  0.1159, -0.0739,  0.0679,  0.1263,\n        -0.0232, -0.0644,  0.1087,  0.0958,  0.1737, -0.0256, -0.1269, -0.0224],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-2.7807e-02,  1.2147e-01, -6.1231e-02, -1.4565e-01, -8.5385e-02,\n         -1.3709e-01,  4.6629e-02,  1.4365e-01, -8.5778e-03,  4.4010e-02,\n          3.0575e-02, -8.1170e-02, -1.2934e-01,  1.2887e-01, -6.8142e-02,\n         -4.6222e-02,  9.7006e-02,  1.3774e-01,  1.7265e-01,  3.6840e-02,\n         -4.8415e-02,  2.7102e-02,  1.0194e-01, -8.1154e-03, -1.5739e-01,\n         -1.0080e-01, -1.7118e-01, -1.4810e-02, -3.7413e-02, -1.5679e-01,\n          7.5476e-02, -6.7780e-02],\n        [-5.0545e-02, -1.1080e-01, -4.3584e-02,  7.3983e-02,  8.2238e-02,\n         -2.4971e-02, -3.2314e-02, -5.2666e-02,  1.0341e-02, -1.0726e-01,\n          8.5463e-02, -4.5728e-02, -3.8982e-04, -1.0782e-01,  1.4392e-01,\n         -1.3185e-01,  1.3339e-01, -1.1913e-01, -1.6586e-01, -5.0390e-02,\n         -1.6937e-01, -1.6009e-01,  5.7896e-02,  8.6707e-02, -1.3318e-01,\n          6.8102e-02,  3.3882e-02,  1.3629e-01,  1.6744e-01,  2.6390e-02,\n         -1.2139e-01,  1.2313e-01],\n        [ 2.5320e-02, -1.0275e-01, -2.9679e-02, -9.4368e-02,  1.0299e-01,\n         -6.3278e-02, -1.5300e-01,  1.4166e-01,  1.5924e-02, -1.6594e-01,\n          4.7441e-02,  7.9657e-02,  8.5693e-02,  8.0212e-02, -1.5621e-01,\n         -9.5165e-02,  1.0406e-01, -5.6852e-02,  1.3261e-01, -1.5628e-01,\n          9.3374e-02,  1.1724e-01, -1.4698e-01, -1.1729e-01, -1.0842e-01,\n         -1.2876e-01, -8.2179e-02,  1.3007e-01,  1.7108e-01,  1.2793e-01,\n         -1.5355e-01, -1.3199e-01],\n        [ 9.7713e-02, -4.9312e-02,  4.8839e-03, -3.4732e-02,  5.6394e-02,\n          5.5250e-02,  2.6464e-03, -1.2668e-01, -4.1152e-03,  6.8575e-02,\n          2.5870e-02, -5.8796e-02,  3.9069e-02,  1.0440e-01, -9.7565e-02,\n          8.4241e-02, -1.1660e-02,  9.3001e-02,  6.6887e-02,  1.2234e-01,\n         -4.7070e-03, -1.1776e-01,  6.3612e-03, -1.2456e-01, -8.6778e-02,\n         -1.0275e-01,  8.7402e-02, -1.0914e-01,  6.6772e-02,  4.5283e-03,\n         -1.3323e-01, -6.6591e-02],\n        [-2.9632e-02,  9.4039e-02,  1.1148e-01,  9.8913e-02, -1.4817e-01,\n          1.5563e-01, -9.2149e-02,  4.2708e-02,  2.4624e-02, -2.3047e-02,\n         -1.3621e-01,  1.6282e-01,  4.2575e-02,  4.6632e-02,  1.5545e-01,\n         -7.0469e-02,  5.9246e-02,  1.0028e-01,  9.8602e-02,  5.3955e-02,\n         -3.9455e-02,  2.8511e-02,  1.4141e-01,  9.6423e-02,  6.4285e-02,\n          1.0571e-02, -1.2774e-01,  1.8817e-02, -6.3452e-02, -1.1616e-02,\n          1.2378e-01, -1.0322e-01],\n        [-1.2391e-01, -1.5085e-01, -1.3143e-01, -7.5331e-02, -8.9794e-02,\n          2.6026e-03,  1.1173e-01, -1.5196e-01,  1.1545e-01, -5.1173e-03,\n          1.2998e-01,  7.1164e-02, -2.2772e-02,  7.8308e-02, -5.3648e-02,\n         -1.4220e-01, -3.8797e-02,  4.3045e-02,  1.1239e-01,  1.2720e-01,\n          1.5960e-01,  5.3767e-03, -1.1016e-01, -6.1199e-02,  1.7426e-04,\n          1.2886e-01, -1.2872e-02,  1.5772e-03, -3.2090e-02, -9.7389e-02,\n          2.1241e-02,  1.6330e-03],\n        [ 2.2792e-02, -1.1469e-01, -8.2996e-03, -1.4959e-01, -1.6183e-01,\n          1.2835e-01, -6.5075e-02, -1.6748e-01, -1.1441e-01, -3.1956e-02,\n         -1.3534e-01, -1.4531e-02,  2.1421e-02,  1.4824e-01,  1.6049e-01,\n         -1.3386e-01,  6.6653e-02, -8.5979e-02,  1.4073e-01, -5.0603e-02,\n         -1.1392e-01, -1.3792e-01, -1.3765e-01,  8.6437e-02,  1.6422e-02,\n          1.0937e-01, -5.0870e-02, -6.6763e-02, -3.7235e-02, -1.4302e-01,\n         -1.7179e-01, -1.5044e-01],\n        [ 7.9047e-02,  2.5046e-02, -1.6716e-01,  4.5376e-02,  1.3425e-01,\n         -7.9323e-02,  3.8819e-02,  1.2444e-01,  3.7835e-03, -9.4682e-03,\n         -3.0918e-02,  6.4232e-02,  8.9190e-02, -1.4730e-01, -1.7979e-02,\n          1.4124e-01, -9.9739e-02,  7.1006e-03, -1.5385e-01,  9.0169e-02,\n          1.4206e-01,  4.8286e-02, -1.0510e-01,  1.1490e-01, -1.7620e-02,\n         -2.2328e-03, -1.4540e-01, -4.9348e-02,  1.0047e-01, -1.3103e-01,\n          9.3249e-02, -1.0114e-01],\n        [-1.5458e-01,  2.2885e-02,  1.1166e-02, -1.4333e-01, -1.3755e-01,\n          1.7406e-01, -1.4595e-01,  3.6503e-02, -1.3835e-01,  1.5139e-01,\n          1.2081e-01,  5.8909e-02, -7.7678e-02, -6.1170e-02, -8.8553e-02,\n          9.2658e-02,  1.0790e-01,  2.8063e-02, -1.5293e-01,  5.3400e-05,\n          1.3822e-01,  1.2549e-01, -7.9908e-02, -3.8900e-02, -9.0767e-02,\n          8.3427e-02,  1.0158e-01, -1.6441e-01,  1.6966e-01, -1.4808e-01,\n         -1.2548e-01, -5.7146e-02],\n        [ 1.0914e-02, -1.0147e-01, -1.1702e-01,  1.3249e-01,  1.5219e-01,\n          7.7529e-02,  9.3323e-02, -1.6149e-01, -2.5961e-02,  1.7916e-02,\n          9.1831e-02,  1.1538e-01, -2.0442e-02, -1.5221e-01,  1.4871e-01,\n          1.3302e-01,  6.4066e-02, -1.0576e-01, -1.7483e-01,  6.3141e-02,\n          1.5934e-01,  4.9170e-02,  1.2476e-01, -1.3596e-01,  9.7177e-02,\n          2.8746e-02,  1.2135e-01, -1.3126e-01,  1.7583e-01, -1.1442e-01,\n          7.8189e-02,  1.5387e-01],\n        [-3.4238e-02,  1.7145e-01, -9.8982e-02,  6.7789e-02,  1.4419e-01,\n         -1.3284e-01, -1.4252e-01, -1.2142e-01,  1.0710e-01, -1.1005e-01,\n         -5.9551e-03, -6.2154e-02,  1.7095e-01,  8.1769e-02, -1.2777e-01,\n         -1.6632e-01, -9.5732e-04,  1.3273e-01,  6.6623e-02,  1.7135e-01,\n          1.1800e-01, -1.2472e-01,  1.5518e-01, -1.6634e-01,  8.5855e-02,\n          4.6468e-02, -3.2765e-02,  1.0944e-01,  1.0147e-01, -5.2282e-02,\n         -6.2911e-02, -1.0564e-01],\n        [-1.1332e-01,  1.6599e-01,  9.8408e-02, -6.1039e-02,  1.6185e-01,\n          5.6010e-02,  1.7096e-01, -1.7244e-01, -5.3253e-02, -7.4148e-02,\n         -4.3951e-03, -4.0772e-02,  1.5368e-01, -1.3600e-01,  1.2010e-01,\n         -9.5697e-02,  1.1466e-01,  9.0315e-02, -1.3012e-02,  5.9368e-02,\n         -8.1408e-02,  1.1182e-01, -7.5998e-02,  1.7343e-02, -1.7516e-01,\n         -4.5483e-02,  7.6850e-02,  7.6342e-03,  4.1670e-02,  1.0864e-01,\n          1.6322e-01, -1.7560e-01],\n        [ 6.4881e-03, -2.6727e-02,  2.6087e-02, -8.4902e-03,  1.2673e-01,\n          1.5025e-01,  2.3702e-02, -7.7116e-02,  9.8870e-02, -2.0500e-02,\n          1.0258e-01,  1.3496e-01, -3.9501e-02, -1.5978e-01, -8.5107e-02,\n         -9.0827e-02, -1.4794e-01,  1.0860e-01, -5.0515e-02, -6.8235e-02,\n          4.2512e-02,  1.5730e-01, -5.6104e-02,  8.4492e-02,  1.5525e-01,\n         -1.1957e-01, -4.6997e-02, -1.4476e-02,  6.3747e-02, -1.3251e-01,\n         -1.0497e-01,  4.9198e-02],\n        [-4.2279e-02,  1.0887e-01, -1.0415e-01,  4.1341e-02,  1.4210e-01,\n          7.4817e-02,  1.5122e-01,  1.0770e-01, -9.0861e-03, -4.3290e-02,\n          6.3121e-02,  1.2207e-01,  7.3049e-02, -1.0224e-01, -3.2577e-02,\n         -7.7646e-02, -1.3651e-01, -1.7245e-01,  3.3219e-02, -6.2784e-02,\n         -3.2661e-02,  1.1527e-01,  1.5855e-01,  8.2309e-02, -4.4802e-02,\n          1.3688e-01, -9.0053e-02,  1.2235e-01, -1.1808e-01,  1.4761e-01,\n         -7.1916e-02, -6.9827e-03],\n        [-1.5199e-01, -1.2402e-01,  7.7972e-02, -5.1638e-02,  1.7172e-01,\n          8.3089e-02, -1.6950e-01,  7.6596e-02,  1.0875e-01, -1.0400e-01,\n          1.5503e-01,  8.3770e-02, -1.1071e-01,  1.5276e-01,  1.5941e-01,\n          1.6975e-02, -4.6615e-02,  3.3994e-02, -5.7960e-02,  1.5370e-01,\n         -1.6370e-01, -1.4213e-01, -1.1988e-01, -1.3904e-01, -9.7936e-03,\n          9.7276e-02, -1.3048e-01,  1.4748e-02,  1.0653e-01,  6.6629e-02,\n         -1.2110e-01, -1.0571e-01],\n        [-5.7025e-02, -8.8984e-02,  4.0176e-02, -4.5341e-02,  1.5649e-02,\n          1.0520e-01, -1.2530e-01, -1.4084e-01,  1.5276e-01, -1.5963e-02,\n         -1.1248e-01,  8.1661e-02,  8.8492e-02, -6.5731e-02, -1.6347e-01,\n          8.5194e-02, -5.3633e-02,  8.5065e-03, -1.0139e-01,  1.5291e-01,\n          3.6221e-03, -1.0849e-01,  7.3645e-02, -2.1267e-02, -1.6624e-01,\n         -1.3619e-01, -1.0708e-01, -3.8965e-02, -7.4933e-02, -3.3066e-02,\n          1.3881e-01,  2.1211e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0135,  0.1909,  0.1366, -0.2080,  0.0285, -0.2114, -0.1873,  0.1790],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1943,  0.0146,  0.2363,  0.1328,  0.0529, -0.1992,  0.1602, -0.1257,\n          0.1423,  0.1791,  0.0040,  0.0349, -0.1337,  0.1624,  0.1286,  0.1400],\n        [-0.0230,  0.0874, -0.0512,  0.0214,  0.0891,  0.2182,  0.1481,  0.1575,\n         -0.0870, -0.0352, -0.1478, -0.1481,  0.0129, -0.0016,  0.2349,  0.1549],\n        [-0.0696, -0.1402, -0.0246, -0.2024,  0.1714, -0.0830,  0.2320, -0.0694,\n         -0.0201,  0.2050,  0.0977, -0.1139,  0.0972, -0.1075, -0.0800,  0.0305],\n        [-0.1576, -0.1473, -0.1909,  0.1597,  0.1939, -0.0516, -0.2034, -0.0302,\n          0.0947, -0.0117, -0.2180, -0.1710, -0.1146, -0.0672,  0.1508, -0.1938],\n        [-0.1669, -0.1318,  0.0735, -0.0019,  0.0948, -0.1690, -0.1784,  0.0948,\n         -0.1047, -0.0874, -0.0271,  0.2096,  0.2086, -0.1712,  0.2231,  0.0458],\n        [ 0.0608, -0.2308, -0.1244,  0.0547,  0.0353,  0.1210,  0.1484,  0.0797,\n         -0.0692,  0.0464,  0.0136,  0.1343,  0.0449,  0.1687,  0.0847,  0.2063],\n        [ 0.2385, -0.0076,  0.0822, -0.2307,  0.0642,  0.1281, -0.0030, -0.2227,\n         -0.1186, -0.1051, -0.0518, -0.1579,  0.2470,  0.0074, -0.0623,  0.2369],\n        [ 0.0526,  0.2095, -0.0362,  0.1743, -0.0832, -0.0517, -0.0811, -0.0704,\n          0.1364, -0.0179,  0.2387,  0.2446, -0.0610,  0.1888, -0.1796, -0.2466]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0686, -0.1401, -0.2433,  0.2022], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.3353, -0.2380,  0.2633,  0.2928,  0.1114,  0.2309,  0.0768,  0.2781],\n        [-0.0630, -0.1749,  0.2920,  0.3172,  0.2385,  0.0867, -0.3507,  0.0775],\n        [-0.2542,  0.1884, -0.2390, -0.0795, -0.2271, -0.1973,  0.1593, -0.0831],\n        [ 0.3233, -0.1355, -0.3170, -0.0640, -0.2727, -0.3451,  0.2173,  0.1128]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0139,  0.2967,  0.0706, -0.0477,  0.1137,  0.2455,  0.0236,  0.1903],\n        [-0.2080,  0.0060, -0.1161, -0.2114,  0.0778,  0.0807,  0.0615,  0.1632],\n        [-0.0129, -0.3018, -0.0338, -0.3273, -0.3523,  0.1962,  0.1669,  0.3211],\n        [-0.0579, -0.0699,  0.3353,  0.0843, -0.2360, -0.1872, -0.2244, -0.1953],\n        [ 0.1627,  0.3417, -0.0351,  0.2944,  0.2020, -0.2704,  0.3529,  0.0132],\n        [-0.1315, -0.1907, -0.2633, -0.0731, -0.2515, -0.2988, -0.0975, -0.2100],\n        [ 0.2304, -0.1197, -0.0927,  0.1731, -0.3098,  0.1493,  0.1918, -0.0015],\n        [ 0.1397, -0.3082,  0.2869, -0.3446,  0.2313, -0.2348, -0.0530,  0.3014],\n        [-0.2555, -0.2141,  0.0900,  0.0504,  0.2531, -0.2929, -0.2458, -0.0909],\n        [-0.1758, -0.0462, -0.2942,  0.1825, -0.1007, -0.0406,  0.0113, -0.1349],\n        [-0.0318,  0.2525,  0.2224,  0.0893,  0.0973,  0.3346, -0.0688, -0.0560],\n        [ 0.1463,  0.0727, -0.0654,  0.1597,  0.0044,  0.2755, -0.0308, -0.0211],\n        [-0.2093, -0.1397, -0.2569,  0.2345, -0.3209, -0.1149, -0.0174, -0.0906],\n        [ 0.2700, -0.1704,  0.0711, -0.1317, -0.2059,  0.1129,  0.3235,  0.3009],\n        [ 0.0437,  0.2029,  0.2123, -0.2465,  0.1526,  0.1301,  0.3360, -0.3188],\n        [ 0.2361,  0.0054, -0.2851,  0.0847,  0.3149, -0.1628,  0.2618,  0.1456],\n        [-0.3334, -0.1571,  0.2838,  0.1021,  0.1937, -0.0544,  0.0216,  0.1892],\n        [-0.1944, -0.0976,  0.0005, -0.0107,  0.1546,  0.1489,  0.2598, -0.1592],\n        [ 0.0685, -0.0916,  0.0311, -0.0086,  0.0351,  0.1638,  0.2613,  0.1699],\n        [ 0.3243, -0.1688,  0.0083,  0.0599,  0.2388,  0.2365,  0.1996,  0.0487],\n        [ 0.0983, -0.3328, -0.3057,  0.1971,  0.0426,  0.0307,  0.0876,  0.1461],\n        [-0.1108, -0.0212, -0.0131,  0.1857, -0.2404, -0.1620,  0.0217, -0.2880],\n        [-0.3400, -0.2975,  0.0355,  0.0860, -0.1943, -0.0611, -0.0403,  0.2704],\n        [-0.2825, -0.0540, -0.1250, -0.0152, -0.0776,  0.2085, -0.2253, -0.0479],\n        [-0.1369, -0.0937, -0.3289, -0.2283,  0.2662, -0.0832, -0.0697, -0.0912],\n        [-0.1428,  0.2189,  0.1516,  0.1643, -0.3356,  0.2366, -0.1916,  0.3452],\n        [-0.2314,  0.1829,  0.3479,  0.2194,  0.1524,  0.1893, -0.3449,  0.0829],\n        [ 0.2444, -0.0863, -0.0314, -0.1193,  0.1424,  0.0454,  0.2431,  0.1644],\n        [-0.1702,  0.1908,  0.0512,  0.0261, -0.2208, -0.3015,  0.3090,  0.0006],\n        [-0.0656, -0.0892, -0.0834, -0.0731,  0.2212,  0.1607, -0.3302, -0.3334],\n        [-0.3139, -0.2475,  0.1171,  0.1244, -0.2611, -0.0670, -0.0350,  0.2473],\n        [ 0.0264,  0.1203,  0.0162,  0.2257,  0.1609,  0.1739, -0.0602,  0.3038]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2679, -0.1431,  0.0046, -0.0099, -0.2915, -0.1608, -0.1118,  0.0901,\n        -0.1297,  0.0451,  0.2970, -0.2091, -0.2774, -0.1249,  0.3242, -0.1085,\n        -0.1299, -0.2610,  0.0422, -0.3199,  0.0785, -0.2562,  0.0836, -0.0217,\n        -0.1622,  0.2470, -0.3322,  0.0599,  0.1977,  0.0448, -0.2135,  0.2391],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-2.7807e-02,  1.2147e-01, -6.1231e-02, -1.4565e-01, -8.5385e-02,\n         -1.3709e-01,  4.6629e-02,  1.4365e-01, -8.5778e-03,  4.4010e-02,\n          3.0575e-02, -8.1170e-02, -1.2934e-01,  1.2887e-01, -6.8142e-02,\n         -4.6222e-02,  9.7006e-02,  1.3774e-01,  1.7265e-01,  3.6840e-02,\n         -4.8415e-02,  2.7102e-02,  1.0194e-01, -8.1154e-03, -1.5739e-01,\n         -1.0080e-01, -1.7118e-01, -1.4810e-02, -3.7413e-02, -1.5679e-01,\n          7.5476e-02, -6.7780e-02],\n        [-5.0545e-02, -1.1080e-01, -4.3584e-02,  7.3983e-02,  8.2238e-02,\n         -2.4971e-02, -3.2314e-02, -5.2666e-02,  1.0341e-02, -1.0726e-01,\n          8.5463e-02, -4.5728e-02, -3.8982e-04, -1.0782e-01,  1.4392e-01,\n         -1.3185e-01,  1.3339e-01, -1.1913e-01, -1.6586e-01, -5.0390e-02,\n         -1.6937e-01, -1.6009e-01,  5.7896e-02,  8.6707e-02, -1.3318e-01,\n          6.8102e-02,  3.3882e-02,  1.3629e-01,  1.6744e-01,  2.6390e-02,\n         -1.2139e-01,  1.2313e-01],\n        [ 2.5320e-02, -1.0275e-01, -2.9679e-02, -9.4368e-02,  1.0299e-01,\n         -6.3278e-02, -1.5300e-01,  1.4166e-01,  1.5924e-02, -1.6594e-01,\n          4.7441e-02,  7.9657e-02,  8.5693e-02,  8.0212e-02, -1.5621e-01,\n         -9.5165e-02,  1.0406e-01, -5.6852e-02,  1.3261e-01, -1.5628e-01,\n          9.3374e-02,  1.1724e-01, -1.4698e-01, -1.1729e-01, -1.0842e-01,\n         -1.2876e-01, -8.2179e-02,  1.3007e-01,  1.7108e-01,  1.2793e-01,\n         -1.5355e-01, -1.3199e-01],\n        [ 9.7713e-02, -4.9312e-02,  4.8839e-03, -3.4732e-02,  5.6394e-02,\n          5.5250e-02,  2.6464e-03, -1.2668e-01, -4.1152e-03,  6.8575e-02,\n          2.5870e-02, -5.8796e-02,  3.9069e-02,  1.0440e-01, -9.7565e-02,\n          8.4241e-02, -1.1660e-02,  9.3001e-02,  6.6887e-02,  1.2234e-01,\n         -4.7070e-03, -1.1776e-01,  6.3612e-03, -1.2456e-01, -8.6778e-02,\n         -1.0275e-01,  8.7402e-02, -1.0914e-01,  6.6772e-02,  4.5283e-03,\n         -1.3323e-01, -6.6591e-02],\n        [-2.9632e-02,  9.4039e-02,  1.1148e-01,  9.8913e-02, -1.4817e-01,\n          1.5563e-01, -9.2149e-02,  4.2708e-02,  2.4624e-02, -2.3047e-02,\n         -1.3621e-01,  1.6282e-01,  4.2575e-02,  4.6632e-02,  1.5545e-01,\n         -7.0469e-02,  5.9246e-02,  1.0028e-01,  9.8602e-02,  5.3955e-02,\n         -3.9455e-02,  2.8511e-02,  1.4141e-01,  9.6423e-02,  6.4285e-02,\n          1.0571e-02, -1.2774e-01,  1.8817e-02, -6.3452e-02, -1.1616e-02,\n          1.2378e-01, -1.0322e-01],\n        [-1.2391e-01, -1.5085e-01, -1.3143e-01, -7.5331e-02, -8.9794e-02,\n          2.6026e-03,  1.1173e-01, -1.5196e-01,  1.1545e-01, -5.1173e-03,\n          1.2998e-01,  7.1164e-02, -2.2772e-02,  7.8308e-02, -5.3648e-02,\n         -1.4220e-01, -3.8797e-02,  4.3045e-02,  1.1239e-01,  1.2720e-01,\n          1.5960e-01,  5.3767e-03, -1.1016e-01, -6.1199e-02,  1.7426e-04,\n          1.2886e-01, -1.2872e-02,  1.5772e-03, -3.2090e-02, -9.7389e-02,\n          2.1241e-02,  1.6330e-03],\n        [ 2.2792e-02, -1.1469e-01, -8.2996e-03, -1.4959e-01, -1.6183e-01,\n          1.2835e-01, -6.5075e-02, -1.6748e-01, -1.1441e-01, -3.1956e-02,\n         -1.3534e-01, -1.4531e-02,  2.1421e-02,  1.4824e-01,  1.6049e-01,\n         -1.3386e-01,  6.6653e-02, -8.5979e-02,  1.4073e-01, -5.0603e-02,\n         -1.1392e-01, -1.3792e-01, -1.3765e-01,  8.6437e-02,  1.6422e-02,\n          1.0937e-01, -5.0870e-02, -6.6763e-02, -3.7235e-02, -1.4302e-01,\n         -1.7179e-01, -1.5044e-01],\n        [ 7.9047e-02,  2.5046e-02, -1.6716e-01,  4.5376e-02,  1.3425e-01,\n         -7.9323e-02,  3.8819e-02,  1.2444e-01,  3.7835e-03, -9.4682e-03,\n         -3.0918e-02,  6.4232e-02,  8.9190e-02, -1.4730e-01, -1.7979e-02,\n          1.4124e-01, -9.9739e-02,  7.1006e-03, -1.5385e-01,  9.0169e-02,\n          1.4206e-01,  4.8286e-02, -1.0510e-01,  1.1490e-01, -1.7620e-02,\n         -2.2328e-03, -1.4540e-01, -4.9348e-02,  1.0047e-01, -1.3103e-01,\n          9.3249e-02, -1.0114e-01],\n        [-1.5458e-01,  2.2885e-02,  1.1166e-02, -1.4333e-01, -1.3755e-01,\n          1.7406e-01, -1.4595e-01,  3.6503e-02, -1.3835e-01,  1.5139e-01,\n          1.2081e-01,  5.8909e-02, -7.7678e-02, -6.1170e-02, -8.8553e-02,\n          9.2658e-02,  1.0790e-01,  2.8063e-02, -1.5293e-01,  5.3400e-05,\n          1.3822e-01,  1.2549e-01, -7.9908e-02, -3.8900e-02, -9.0767e-02,\n          8.3427e-02,  1.0158e-01, -1.6441e-01,  1.6966e-01, -1.4808e-01,\n         -1.2548e-01, -5.7146e-02],\n        [ 1.0914e-02, -1.0147e-01, -1.1702e-01,  1.3249e-01,  1.5219e-01,\n          7.7529e-02,  9.3323e-02, -1.6149e-01, -2.5961e-02,  1.7916e-02,\n          9.1831e-02,  1.1538e-01, -2.0442e-02, -1.5221e-01,  1.4871e-01,\n          1.3302e-01,  6.4066e-02, -1.0576e-01, -1.7483e-01,  6.3141e-02,\n          1.5934e-01,  4.9170e-02,  1.2476e-01, -1.3596e-01,  9.7177e-02,\n          2.8746e-02,  1.2135e-01, -1.3126e-01,  1.7583e-01, -1.1442e-01,\n          7.8189e-02,  1.5387e-01],\n        [-3.4238e-02,  1.7145e-01, -9.8982e-02,  6.7789e-02,  1.4419e-01,\n         -1.3284e-01, -1.4252e-01, -1.2142e-01,  1.0710e-01, -1.1005e-01,\n         -5.9551e-03, -6.2154e-02,  1.7095e-01,  8.1769e-02, -1.2777e-01,\n         -1.6632e-01, -9.5732e-04,  1.3273e-01,  6.6623e-02,  1.7135e-01,\n          1.1800e-01, -1.2472e-01,  1.5518e-01, -1.6634e-01,  8.5855e-02,\n          4.6468e-02, -3.2765e-02,  1.0944e-01,  1.0147e-01, -5.2282e-02,\n         -6.2911e-02, -1.0564e-01],\n        [-1.1332e-01,  1.6599e-01,  9.8408e-02, -6.1039e-02,  1.6185e-01,\n          5.6010e-02,  1.7096e-01, -1.7244e-01, -5.3253e-02, -7.4148e-02,\n         -4.3951e-03, -4.0772e-02,  1.5368e-01, -1.3600e-01,  1.2010e-01,\n         -9.5697e-02,  1.1466e-01,  9.0315e-02, -1.3012e-02,  5.9368e-02,\n         -8.1408e-02,  1.1182e-01, -7.5998e-02,  1.7343e-02, -1.7516e-01,\n         -4.5483e-02,  7.6850e-02,  7.6342e-03,  4.1670e-02,  1.0864e-01,\n          1.6322e-01, -1.7560e-01],\n        [ 6.4881e-03, -2.6727e-02,  2.6087e-02, -8.4902e-03,  1.2673e-01,\n          1.5025e-01,  2.3702e-02, -7.7116e-02,  9.8870e-02, -2.0500e-02,\n          1.0258e-01,  1.3496e-01, -3.9501e-02, -1.5978e-01, -8.5107e-02,\n         -9.0827e-02, -1.4794e-01,  1.0860e-01, -5.0515e-02, -6.8235e-02,\n          4.2512e-02,  1.5730e-01, -5.6104e-02,  8.4492e-02,  1.5525e-01,\n         -1.1957e-01, -4.6997e-02, -1.4476e-02,  6.3747e-02, -1.3251e-01,\n         -1.0497e-01,  4.9198e-02],\n        [-4.2279e-02,  1.0887e-01, -1.0415e-01,  4.1341e-02,  1.4210e-01,\n          7.4817e-02,  1.5122e-01,  1.0770e-01, -9.0861e-03, -4.3290e-02,\n          6.3121e-02,  1.2207e-01,  7.3049e-02, -1.0224e-01, -3.2577e-02,\n         -7.7646e-02, -1.3651e-01, -1.7245e-01,  3.3219e-02, -6.2784e-02,\n         -3.2661e-02,  1.1527e-01,  1.5855e-01,  8.2309e-02, -4.4802e-02,\n          1.3688e-01, -9.0053e-02,  1.2235e-01, -1.1808e-01,  1.4761e-01,\n         -7.1916e-02, -6.9827e-03],\n        [-1.5199e-01, -1.2402e-01,  7.7972e-02, -5.1638e-02,  1.7172e-01,\n          8.3089e-02, -1.6950e-01,  7.6596e-02,  1.0875e-01, -1.0400e-01,\n          1.5503e-01,  8.3770e-02, -1.1071e-01,  1.5276e-01,  1.5941e-01,\n          1.6975e-02, -4.6615e-02,  3.3994e-02, -5.7960e-02,  1.5370e-01,\n         -1.6370e-01, -1.4213e-01, -1.1988e-01, -1.3904e-01, -9.7936e-03,\n          9.7276e-02, -1.3048e-01,  1.4748e-02,  1.0653e-01,  6.6629e-02,\n         -1.2110e-01, -1.0571e-01],\n        [-5.7025e-02, -8.8984e-02,  4.0176e-02, -4.5341e-02,  1.5649e-02,\n          1.0520e-01, -1.2530e-01, -1.4084e-01,  1.5276e-01, -1.5963e-02,\n         -1.1248e-01,  8.1661e-02,  8.8492e-02, -6.5731e-02, -1.6347e-01,\n          8.5194e-02, -5.3633e-02,  8.5065e-03, -1.0139e-01,  1.5291e-01,\n          3.6221e-03, -1.0849e-01,  7.3645e-02, -2.1267e-02, -1.6624e-01,\n         -1.3619e-01, -1.0708e-01, -3.8965e-02, -7.4933e-02, -3.3066e-02,\n          1.3881e-01,  2.1211e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0231,  0.1294,  0.0628, -0.1662,  0.1159, -0.0739,  0.0679,  0.1263,\n        -0.0232, -0.0644,  0.1087,  0.0958,  0.1737, -0.0256, -0.1269, -0.0224],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1943,  0.0146,  0.2363,  0.1328,  0.0529, -0.1992,  0.1602, -0.1257,\n          0.1423,  0.1791,  0.0040,  0.0349, -0.1337,  0.1624,  0.1286,  0.1400],\n        [-0.0230,  0.0874, -0.0512,  0.0214,  0.0891,  0.2182,  0.1481,  0.1575,\n         -0.0870, -0.0352, -0.1478, -0.1481,  0.0129, -0.0016,  0.2349,  0.1549],\n        [-0.0696, -0.1402, -0.0246, -0.2024,  0.1714, -0.0830,  0.2320, -0.0694,\n         -0.0201,  0.2050,  0.0977, -0.1139,  0.0972, -0.1075, -0.0800,  0.0305],\n        [-0.1576, -0.1473, -0.1909,  0.1597,  0.1939, -0.0516, -0.2034, -0.0302,\n          0.0947, -0.0117, -0.2180, -0.1710, -0.1146, -0.0672,  0.1508, -0.1938],\n        [-0.1669, -0.1318,  0.0735, -0.0019,  0.0948, -0.1690, -0.1784,  0.0948,\n         -0.1047, -0.0874, -0.0271,  0.2096,  0.2086, -0.1712,  0.2231,  0.0458],\n        [ 0.0608, -0.2308, -0.1244,  0.0547,  0.0353,  0.1210,  0.1484,  0.0797,\n         -0.0692,  0.0464,  0.0136,  0.1343,  0.0449,  0.1687,  0.0847,  0.2063],\n        [ 0.2385, -0.0076,  0.0822, -0.2307,  0.0642,  0.1281, -0.0030, -0.2227,\n         -0.1186, -0.1051, -0.0518, -0.1579,  0.2470,  0.0074, -0.0623,  0.2369],\n        [ 0.0526,  0.2095, -0.0362,  0.1743, -0.0832, -0.0517, -0.0811, -0.0704,\n          0.1364, -0.0179,  0.2387,  0.2446, -0.0610,  0.1888, -0.1796, -0.2466]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0135,  0.1909,  0.1366, -0.2080,  0.0285, -0.2114, -0.1873,  0.1790],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3353, -0.2380,  0.2633,  0.2928,  0.1114,  0.2309,  0.0768,  0.2781],\n        [-0.0630, -0.1749,  0.2920,  0.3172,  0.2385,  0.0867, -0.3507,  0.0775],\n        [-0.2542,  0.1884, -0.2390, -0.0795, -0.2271, -0.1973,  0.1593, -0.0831],\n        [ 0.3233, -0.1355, -0.3170, -0.0640, -0.2727, -0.3451,  0.2173,  0.1128]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0686, -0.1401, -0.2433,  0.2022], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7e316b3ee550>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2679, -0.1431,  0.0046, -0.0099, -0.2915, -0.1608, -0.1118,  0.0901,\n        -0.1297,  0.0451,  0.2970, -0.2091, -0.2774, -0.1249,  0.3242, -0.1085,\n        -0.1299, -0.2610,  0.0422, -0.3199,  0.0785, -0.2562,  0.0836, -0.0217,\n        -0.1622,  0.2470, -0.3322,  0.0599,  0.1977,  0.0448, -0.2135,  0.2391],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0139,  0.2967,  0.0706, -0.0477,  0.1137,  0.2455,  0.0236,  0.1903],\n        [-0.2080,  0.0060, -0.1161, -0.2114,  0.0778,  0.0807,  0.0615,  0.1632],\n        [-0.0129, -0.3018, -0.0338, -0.3273, -0.3523,  0.1962,  0.1669,  0.3211],\n        [-0.0579, -0.0699,  0.3353,  0.0843, -0.2360, -0.1872, -0.2244, -0.1953],\n        [ 0.1627,  0.3417, -0.0351,  0.2944,  0.2020, -0.2704,  0.3529,  0.0132],\n        [-0.1315, -0.1907, -0.2633, -0.0731, -0.2515, -0.2988, -0.0975, -0.2100],\n        [ 0.2304, -0.1197, -0.0927,  0.1731, -0.3098,  0.1493,  0.1918, -0.0015],\n        [ 0.1397, -0.3082,  0.2869, -0.3446,  0.2313, -0.2348, -0.0530,  0.3014],\n        [-0.2555, -0.2141,  0.0900,  0.0504,  0.2531, -0.2929, -0.2458, -0.0909],\n        [-0.1758, -0.0462, -0.2942,  0.1825, -0.1007, -0.0406,  0.0113, -0.1349],\n        [-0.0318,  0.2525,  0.2224,  0.0893,  0.0973,  0.3346, -0.0688, -0.0560],\n        [ 0.1463,  0.0727, -0.0654,  0.1597,  0.0044,  0.2755, -0.0308, -0.0211],\n        [-0.2093, -0.1397, -0.2569,  0.2345, -0.3209, -0.1149, -0.0174, -0.0906],\n        [ 0.2700, -0.1704,  0.0711, -0.1317, -0.2059,  0.1129,  0.3235,  0.3009],\n        [ 0.0437,  0.2029,  0.2123, -0.2465,  0.1526,  0.1301,  0.3360, -0.3188],\n        [ 0.2361,  0.0054, -0.2851,  0.0847,  0.3149, -0.1628,  0.2618,  0.1456],\n        [-0.3334, -0.1571,  0.2838,  0.1021,  0.1937, -0.0544,  0.0216,  0.1892],\n        [-0.1944, -0.0976,  0.0005, -0.0107,  0.1546,  0.1489,  0.2598, -0.1592],\n        [ 0.0685, -0.0916,  0.0311, -0.0086,  0.0351,  0.1638,  0.2613,  0.1699],\n        [ 0.3243, -0.1688,  0.0083,  0.0599,  0.2388,  0.2365,  0.1996,  0.0487],\n        [ 0.0983, -0.3328, -0.3057,  0.1971,  0.0426,  0.0307,  0.0876,  0.1461],\n        [-0.1108, -0.0212, -0.0131,  0.1857, -0.2404, -0.1620,  0.0217, -0.2880],\n        [-0.3400, -0.2975,  0.0355,  0.0860, -0.1943, -0.0611, -0.0403,  0.2704],\n        [-0.2825, -0.0540, -0.1250, -0.0152, -0.0776,  0.2085, -0.2253, -0.0479],\n        [-0.1369, -0.0937, -0.3289, -0.2283,  0.2662, -0.0832, -0.0697, -0.0912],\n        [-0.1428,  0.2189,  0.1516,  0.1643, -0.3356,  0.2366, -0.1916,  0.3452],\n        [-0.2314,  0.1829,  0.3479,  0.2194,  0.1524,  0.1893, -0.3449,  0.0829],\n        [ 0.2444, -0.0863, -0.0314, -0.1193,  0.1424,  0.0454,  0.2431,  0.1644],\n        [-0.1702,  0.1908,  0.0512,  0.0261, -0.2208, -0.3015,  0.3090,  0.0006],\n        [-0.0656, -0.0892, -0.0834, -0.0731,  0.2212,  0.1607, -0.3302, -0.3334],\n        [-0.3139, -0.2475,  0.1171,  0.1244, -0.2611, -0.0670, -0.0350,  0.2473],\n        [ 0.0264,  0.1203,  0.0162,  0.2257,  0.1609,  0.1739, -0.0602,  0.3038]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0231,  0.1294,  0.0628, -0.1662,  0.1159, -0.0739,  0.0679,  0.1263,\n        -0.0232, -0.0644,  0.1087,  0.0958,  0.1737, -0.0256, -0.1269, -0.0224],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-2.7807e-02,  1.2147e-01, -6.1231e-02, -1.4565e-01, -8.5385e-02,\n         -1.3709e-01,  4.6629e-02,  1.4365e-01, -8.5778e-03,  4.4010e-02,\n          3.0575e-02, -8.1170e-02, -1.2934e-01,  1.2887e-01, -6.8142e-02,\n         -4.6222e-02,  9.7006e-02,  1.3774e-01,  1.7265e-01,  3.6840e-02,\n         -4.8415e-02,  2.7102e-02,  1.0194e-01, -8.1154e-03, -1.5739e-01,\n         -1.0080e-01, -1.7118e-01, -1.4810e-02, -3.7413e-02, -1.5679e-01,\n          7.5476e-02, -6.7780e-02],\n        [-5.0545e-02, -1.1080e-01, -4.3584e-02,  7.3983e-02,  8.2238e-02,\n         -2.4971e-02, -3.2314e-02, -5.2666e-02,  1.0341e-02, -1.0726e-01,\n          8.5463e-02, -4.5728e-02, -3.8982e-04, -1.0782e-01,  1.4392e-01,\n         -1.3185e-01,  1.3339e-01, -1.1913e-01, -1.6586e-01, -5.0390e-02,\n         -1.6937e-01, -1.6009e-01,  5.7896e-02,  8.6707e-02, -1.3318e-01,\n          6.8102e-02,  3.3882e-02,  1.3629e-01,  1.6744e-01,  2.6390e-02,\n         -1.2139e-01,  1.2313e-01],\n        [ 2.5320e-02, -1.0275e-01, -2.9679e-02, -9.4368e-02,  1.0299e-01,\n         -6.3278e-02, -1.5300e-01,  1.4166e-01,  1.5924e-02, -1.6594e-01,\n          4.7441e-02,  7.9657e-02,  8.5693e-02,  8.0212e-02, -1.5621e-01,\n         -9.5165e-02,  1.0406e-01, -5.6852e-02,  1.3261e-01, -1.5628e-01,\n          9.3374e-02,  1.1724e-01, -1.4698e-01, -1.1729e-01, -1.0842e-01,\n         -1.2876e-01, -8.2179e-02,  1.3007e-01,  1.7108e-01,  1.2793e-01,\n         -1.5355e-01, -1.3199e-01],\n        [ 9.7713e-02, -4.9312e-02,  4.8839e-03, -3.4732e-02,  5.6394e-02,\n          5.5250e-02,  2.6464e-03, -1.2668e-01, -4.1152e-03,  6.8575e-02,\n          2.5870e-02, -5.8796e-02,  3.9069e-02,  1.0440e-01, -9.7565e-02,\n          8.4241e-02, -1.1660e-02,  9.3001e-02,  6.6887e-02,  1.2234e-01,\n         -4.7070e-03, -1.1776e-01,  6.3612e-03, -1.2456e-01, -8.6778e-02,\n         -1.0275e-01,  8.7402e-02, -1.0914e-01,  6.6772e-02,  4.5283e-03,\n         -1.3323e-01, -6.6591e-02],\n        [-2.9632e-02,  9.4039e-02,  1.1148e-01,  9.8913e-02, -1.4817e-01,\n          1.5563e-01, -9.2149e-02,  4.2708e-02,  2.4624e-02, -2.3047e-02,\n         -1.3621e-01,  1.6282e-01,  4.2575e-02,  4.6632e-02,  1.5545e-01,\n         -7.0469e-02,  5.9246e-02,  1.0028e-01,  9.8602e-02,  5.3955e-02,\n         -3.9455e-02,  2.8511e-02,  1.4141e-01,  9.6423e-02,  6.4285e-02,\n          1.0571e-02, -1.2774e-01,  1.8817e-02, -6.3452e-02, -1.1616e-02,\n          1.2378e-01, -1.0322e-01],\n        [-1.2391e-01, -1.5085e-01, -1.3143e-01, -7.5331e-02, -8.9794e-02,\n          2.6026e-03,  1.1173e-01, -1.5196e-01,  1.1545e-01, -5.1173e-03,\n          1.2998e-01,  7.1164e-02, -2.2772e-02,  7.8308e-02, -5.3648e-02,\n         -1.4220e-01, -3.8797e-02,  4.3045e-02,  1.1239e-01,  1.2720e-01,\n          1.5960e-01,  5.3767e-03, -1.1016e-01, -6.1199e-02,  1.7426e-04,\n          1.2886e-01, -1.2872e-02,  1.5772e-03, -3.2090e-02, -9.7389e-02,\n          2.1241e-02,  1.6330e-03],\n        [ 2.2792e-02, -1.1469e-01, -8.2996e-03, -1.4959e-01, -1.6183e-01,\n          1.2835e-01, -6.5075e-02, -1.6748e-01, -1.1441e-01, -3.1956e-02,\n         -1.3534e-01, -1.4531e-02,  2.1421e-02,  1.4824e-01,  1.6049e-01,\n         -1.3386e-01,  6.6653e-02, -8.5979e-02,  1.4073e-01, -5.0603e-02,\n         -1.1392e-01, -1.3792e-01, -1.3765e-01,  8.6437e-02,  1.6422e-02,\n          1.0937e-01, -5.0870e-02, -6.6763e-02, -3.7235e-02, -1.4302e-01,\n         -1.7179e-01, -1.5044e-01],\n        [ 7.9047e-02,  2.5046e-02, -1.6716e-01,  4.5376e-02,  1.3425e-01,\n         -7.9323e-02,  3.8819e-02,  1.2444e-01,  3.7835e-03, -9.4682e-03,\n         -3.0918e-02,  6.4232e-02,  8.9190e-02, -1.4730e-01, -1.7979e-02,\n          1.4124e-01, -9.9739e-02,  7.1006e-03, -1.5385e-01,  9.0169e-02,\n          1.4206e-01,  4.8286e-02, -1.0510e-01,  1.1490e-01, -1.7620e-02,\n         -2.2328e-03, -1.4540e-01, -4.9348e-02,  1.0047e-01, -1.3103e-01,\n          9.3249e-02, -1.0114e-01],\n        [-1.5458e-01,  2.2885e-02,  1.1166e-02, -1.4333e-01, -1.3755e-01,\n          1.7406e-01, -1.4595e-01,  3.6503e-02, -1.3835e-01,  1.5139e-01,\n          1.2081e-01,  5.8909e-02, -7.7678e-02, -6.1170e-02, -8.8553e-02,\n          9.2658e-02,  1.0790e-01,  2.8063e-02, -1.5293e-01,  5.3400e-05,\n          1.3822e-01,  1.2549e-01, -7.9908e-02, -3.8900e-02, -9.0767e-02,\n          8.3427e-02,  1.0158e-01, -1.6441e-01,  1.6966e-01, -1.4808e-01,\n         -1.2548e-01, -5.7146e-02],\n        [ 1.0914e-02, -1.0147e-01, -1.1702e-01,  1.3249e-01,  1.5219e-01,\n          7.7529e-02,  9.3323e-02, -1.6149e-01, -2.5961e-02,  1.7916e-02,\n          9.1831e-02,  1.1538e-01, -2.0442e-02, -1.5221e-01,  1.4871e-01,\n          1.3302e-01,  6.4066e-02, -1.0576e-01, -1.7483e-01,  6.3141e-02,\n          1.5934e-01,  4.9170e-02,  1.2476e-01, -1.3596e-01,  9.7177e-02,\n          2.8746e-02,  1.2135e-01, -1.3126e-01,  1.7583e-01, -1.1442e-01,\n          7.8189e-02,  1.5387e-01],\n        [-3.4238e-02,  1.7145e-01, -9.8982e-02,  6.7789e-02,  1.4419e-01,\n         -1.3284e-01, -1.4252e-01, -1.2142e-01,  1.0710e-01, -1.1005e-01,\n         -5.9551e-03, -6.2154e-02,  1.7095e-01,  8.1769e-02, -1.2777e-01,\n         -1.6632e-01, -9.5732e-04,  1.3273e-01,  6.6623e-02,  1.7135e-01,\n          1.1800e-01, -1.2472e-01,  1.5518e-01, -1.6634e-01,  8.5855e-02,\n          4.6468e-02, -3.2765e-02,  1.0944e-01,  1.0147e-01, -5.2282e-02,\n         -6.2911e-02, -1.0564e-01],\n        [-1.1332e-01,  1.6599e-01,  9.8408e-02, -6.1039e-02,  1.6185e-01,\n          5.6010e-02,  1.7096e-01, -1.7244e-01, -5.3253e-02, -7.4148e-02,\n         -4.3951e-03, -4.0772e-02,  1.5368e-01, -1.3600e-01,  1.2010e-01,\n         -9.5697e-02,  1.1466e-01,  9.0315e-02, -1.3012e-02,  5.9368e-02,\n         -8.1408e-02,  1.1182e-01, -7.5998e-02,  1.7343e-02, -1.7516e-01,\n         -4.5483e-02,  7.6850e-02,  7.6342e-03,  4.1670e-02,  1.0864e-01,\n          1.6322e-01, -1.7560e-01],\n        [ 6.4881e-03, -2.6727e-02,  2.6087e-02, -8.4902e-03,  1.2673e-01,\n          1.5025e-01,  2.3702e-02, -7.7116e-02,  9.8870e-02, -2.0500e-02,\n          1.0258e-01,  1.3496e-01, -3.9501e-02, -1.5978e-01, -8.5107e-02,\n         -9.0827e-02, -1.4794e-01,  1.0860e-01, -5.0515e-02, -6.8235e-02,\n          4.2512e-02,  1.5730e-01, -5.6104e-02,  8.4492e-02,  1.5525e-01,\n         -1.1957e-01, -4.6997e-02, -1.4476e-02,  6.3747e-02, -1.3251e-01,\n         -1.0497e-01,  4.9198e-02],\n        [-4.2279e-02,  1.0887e-01, -1.0415e-01,  4.1341e-02,  1.4210e-01,\n          7.4817e-02,  1.5122e-01,  1.0770e-01, -9.0861e-03, -4.3290e-02,\n          6.3121e-02,  1.2207e-01,  7.3049e-02, -1.0224e-01, -3.2577e-02,\n         -7.7646e-02, -1.3651e-01, -1.7245e-01,  3.3219e-02, -6.2784e-02,\n         -3.2661e-02,  1.1527e-01,  1.5855e-01,  8.2309e-02, -4.4802e-02,\n          1.3688e-01, -9.0053e-02,  1.2235e-01, -1.1808e-01,  1.4761e-01,\n         -7.1916e-02, -6.9827e-03],\n        [-1.5199e-01, -1.2402e-01,  7.7972e-02, -5.1638e-02,  1.7172e-01,\n          8.3089e-02, -1.6950e-01,  7.6596e-02,  1.0875e-01, -1.0400e-01,\n          1.5503e-01,  8.3770e-02, -1.1071e-01,  1.5276e-01,  1.5941e-01,\n          1.6975e-02, -4.6615e-02,  3.3994e-02, -5.7960e-02,  1.5370e-01,\n         -1.6370e-01, -1.4213e-01, -1.1988e-01, -1.3904e-01, -9.7936e-03,\n          9.7276e-02, -1.3048e-01,  1.4748e-02,  1.0653e-01,  6.6629e-02,\n         -1.2110e-01, -1.0571e-01],\n        [-5.7025e-02, -8.8984e-02,  4.0176e-02, -4.5341e-02,  1.5649e-02,\n          1.0520e-01, -1.2530e-01, -1.4084e-01,  1.5276e-01, -1.5963e-02,\n         -1.1248e-01,  8.1661e-02,  8.8492e-02, -6.5731e-02, -1.6347e-01,\n          8.5194e-02, -5.3633e-02,  8.5065e-03, -1.0139e-01,  1.5291e-01,\n          3.6221e-03, -1.0849e-01,  7.3645e-02, -2.1267e-02, -1.6624e-01,\n         -1.3619e-01, -1.0708e-01, -3.8965e-02, -7.4933e-02, -3.3066e-02,\n          1.3881e-01,  2.1211e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0135,  0.1909,  0.1366, -0.2080,  0.0285, -0.2114, -0.1873,  0.1790],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1943,  0.0146,  0.2363,  0.1328,  0.0529, -0.1992,  0.1602, -0.1257,\n          0.1423,  0.1791,  0.0040,  0.0349, -0.1337,  0.1624,  0.1286,  0.1400],\n        [-0.0230,  0.0874, -0.0512,  0.0214,  0.0891,  0.2182,  0.1481,  0.1575,\n         -0.0870, -0.0352, -0.1478, -0.1481,  0.0129, -0.0016,  0.2349,  0.1549],\n        [-0.0696, -0.1402, -0.0246, -0.2024,  0.1714, -0.0830,  0.2320, -0.0694,\n         -0.0201,  0.2050,  0.0977, -0.1139,  0.0972, -0.1075, -0.0800,  0.0305],\n        [-0.1576, -0.1473, -0.1909,  0.1597,  0.1939, -0.0516, -0.2034, -0.0302,\n          0.0947, -0.0117, -0.2180, -0.1710, -0.1146, -0.0672,  0.1508, -0.1938],\n        [-0.1669, -0.1318,  0.0735, -0.0019,  0.0948, -0.1690, -0.1784,  0.0948,\n         -0.1047, -0.0874, -0.0271,  0.2096,  0.2086, -0.1712,  0.2231,  0.0458],\n        [ 0.0608, -0.2308, -0.1244,  0.0547,  0.0353,  0.1210,  0.1484,  0.0797,\n         -0.0692,  0.0464,  0.0136,  0.1343,  0.0449,  0.1687,  0.0847,  0.2063],\n        [ 0.2385, -0.0076,  0.0822, -0.2307,  0.0642,  0.1281, -0.0030, -0.2227,\n         -0.1186, -0.1051, -0.0518, -0.1579,  0.2470,  0.0074, -0.0623,  0.2369],\n        [ 0.0526,  0.2095, -0.0362,  0.1743, -0.0832, -0.0517, -0.0811, -0.0704,\n          0.1364, -0.0179,  0.2387,  0.2446, -0.0610,  0.1888, -0.1796, -0.2466]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0686, -0.1401, -0.2433,  0.2022], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.3353, -0.2380,  0.2633,  0.2928,  0.1114,  0.2309,  0.0768,  0.2781],\n        [-0.0630, -0.1749,  0.2920,  0.3172,  0.2385,  0.0867, -0.3507,  0.0775],\n        [-0.2542,  0.1884, -0.2390, -0.0795, -0.2271, -0.1973,  0.1593, -0.0831],\n        [ 0.3233, -0.1355, -0.3170, -0.0640, -0.2727, -0.3451,  0.2173,  0.1128]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7e30e373df90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s322720000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s322720000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}