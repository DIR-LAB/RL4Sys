{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	0,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.01,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s327440000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0001,
    "sample_decay":	0.5,
    "seed":	327440000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7f4a2c0e5690>":	{
            "_act_dim":	4,
            "_aux_batch_size":	0,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.01,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-1.7873e-01,  1.2538e-02,  1.7909e-01, -2.2792e-01,  1.2688e-01,\n        -1.8633e-01,  4.8281e-02, -9.1986e-02, -3.2141e-02,  3.3948e-01,\n        -2.5969e-01,  1.8605e-01,  2.2363e-04, -2.3099e-01, -1.4830e-01,\n         2.0516e-01,  1.3950e-01,  9.6929e-02,  1.4246e-01,  1.5445e-01,\n        -2.6180e-01,  3.1135e-02,  2.1081e-01, -1.1844e-01,  3.0819e-01,\n        -1.4230e-01,  3.6735e-02, -2.5951e-01, -6.4151e-02, -2.8479e-02,\n         2.8736e-01,  3.3549e-01], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.1749e-01, -3.0441e-01,  7.4688e-02, -6.2347e-02,  1.4045e-02,\n         -2.2074e-01,  3.3671e-01, -2.3758e-01],\n        [ 1.6776e-01, -3.1305e-01,  2.7605e-01, -3.2154e-02, -1.8838e-01,\n          1.6823e-01,  2.2956e-01,  1.9027e-01],\n        [-2.1690e-01,  1.8670e-01,  1.7922e-01,  2.1948e-02, -1.6463e-01,\n          1.5568e-01, -2.5503e-01, -1.8726e-01],\n        [ 2.4973e-01,  1.9425e-01, -3.2671e-01,  2.0001e-01,  2.7947e-01,\n         -9.2754e-02, -2.9623e-01,  2.8245e-01],\n        [-7.4103e-02, -2.7631e-01, -8.8961e-03, -3.2004e-01,  1.4868e-01,\n         -3.3120e-01,  3.4130e-01,  3.5251e-01],\n        [-7.7817e-02,  2.9233e-01,  7.5264e-02,  1.8106e-01,  7.6771e-02,\n          2.5694e-01, -9.4363e-02,  2.2691e-01],\n        [ 1.1890e-01, -2.4856e-01,  3.3337e-02, -2.5742e-01, -9.0140e-02,\n         -1.1278e-01,  9.1234e-02, -2.6782e-01],\n        [ 2.0028e-01,  1.7402e-01,  1.3578e-03,  1.8623e-02,  2.5050e-01,\n         -2.4379e-01,  1.2202e-01,  1.6210e-01],\n        [-1.4485e-01, -3.5212e-01,  2.4812e-01, -3.0961e-01, -1.0391e-01,\n         -4.9840e-02, -2.8683e-01,  2.7420e-01],\n        [-4.0299e-02,  7.0153e-02,  3.4789e-01, -7.5844e-02, -3.1100e-01,\n         -2.9983e-01, -2.5097e-02,  2.3477e-01],\n        [ 1.3084e-01, -1.7274e-01, -2.7071e-01,  2.3001e-01,  9.0235e-02,\n         -3.0291e-01,  1.4642e-02,  9.4986e-02],\n        [-7.5265e-02, -1.8901e-01,  3.2294e-01, -3.5328e-01,  1.7869e-01,\n         -1.0224e-01,  2.0882e-01,  3.2701e-01],\n        [ 1.6355e-01,  3.5235e-01,  1.0406e-01,  1.0373e-01, -1.2971e-01,\n         -2.1118e-01,  2.9805e-01,  1.9503e-01],\n        [ 2.7720e-01, -2.6472e-04, -1.6864e-01, -1.5807e-01, -3.5293e-01,\n         -3.1821e-01,  2.1748e-01, -1.0613e-01],\n        [ 2.5626e-01, -3.4958e-01, -1.4165e-01,  1.5883e-01,  1.9901e-01,\n          7.5100e-02, -3.2341e-01, -8.7336e-02],\n        [-1.0357e-01,  3.2157e-01, -2.2773e-01,  2.0775e-01,  2.3524e-01,\n         -2.9483e-01,  2.2818e-01,  5.0043e-02],\n        [-3.0557e-01,  9.7500e-02, -2.5740e-01, -2.8577e-01, -1.4618e-01,\n         -1.4706e-01, -1.0767e-01, -2.7476e-01],\n        [ 6.0184e-02,  3.3078e-01,  2.7680e-01, -2.8463e-01,  5.5991e-02,\n         -1.5952e-01,  3.4436e-01,  7.8406e-02],\n        [-1.1976e-01, -2.6091e-01, -3.0488e-01,  1.8713e-01, -3.2772e-01,\n          1.0901e-01, -1.3601e-01, -4.0582e-03],\n        [-6.5532e-02,  9.7472e-02, -5.8224e-02, -1.7468e-01,  2.4077e-02,\n          1.1047e-01, -2.9656e-01,  2.5358e-01],\n        [ 2.1473e-01, -1.3243e-01,  2.0831e-02,  3.1311e-01,  2.4339e-01,\n          1.4648e-01, -2.1711e-01,  1.1394e-01],\n        [-3.6721e-02, -2.3232e-01,  2.4832e-01, -1.7951e-01,  6.5247e-02,\n         -3.2808e-01, -6.1880e-02,  1.1948e-01],\n        [ 1.7959e-01,  3.1138e-01, -9.7404e-02,  3.1180e-01, -2.7469e-01,\n          4.3376e-02,  6.8959e-03, -2.8165e-01],\n        [ 7.8461e-02,  2.2089e-01, -8.2240e-02, -3.2614e-01, -2.8846e-01,\n         -2.9330e-01, -9.0971e-02, -5.1015e-02],\n        [-8.3322e-02, -3.1618e-01,  1.1332e-01, -5.7113e-02, -2.8778e-01,\n          2.3993e-01, -2.2607e-01,  2.9538e-01],\n        [-8.3751e-02,  1.8978e-02, -9.4422e-02, -2.9385e-01,  3.2481e-01,\n          2.1500e-01,  8.5297e-02,  2.5838e-01],\n        [-7.5616e-02, -1.5545e-01,  2.6569e-02, -2.4555e-01, -5.4715e-03,\n         -4.5631e-02, -3.5259e-01,  1.0085e-01],\n        [ 1.2607e-01, -2.3860e-01,  6.3564e-02,  5.6359e-02,  3.1156e-01,\n          3.1242e-02, -8.1575e-02,  1.1846e-01],\n        [ 6.4567e-03,  1.1335e-01, -1.1391e-01, -3.4726e-01,  3.2785e-01,\n          3.5178e-01, -2.3129e-01, -1.2502e-01],\n        [-1.0229e-01, -5.7225e-02,  2.5587e-01, -5.9210e-02,  1.4959e-01,\n          3.4723e-01,  2.0800e-01, -2.3044e-01],\n        [-1.8802e-01, -3.2334e-01,  6.2012e-02, -1.5985e-01,  1.3843e-01,\n          3.1983e-02,  3.2386e-01,  2.4375e-01],\n        [-2.2672e-01, -1.6445e-01,  1.9897e-01, -3.1782e-01,  1.7955e-01,\n         -2.6809e-01, -2.9869e-01, -3.4985e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0129, -0.1437, -0.0055, -0.0107, -0.1309,  0.0894, -0.0695,  0.1115,\n        -0.1184, -0.1372, -0.1397,  0.0903, -0.0159, -0.0083,  0.1368, -0.1499],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 7.6761e-02, -1.5348e-01,  6.0648e-03, -1.2045e-01,  1.5559e-01,\n          3.2294e-02,  1.3331e-01,  1.4353e-01,  4.2355e-02, -1.4553e-02,\n          1.0470e-01, -6.0720e-02,  1.5187e-01, -5.1037e-02, -2.7262e-02,\n          1.1692e-01,  1.2190e-01,  5.5541e-02, -1.2696e-01, -1.7634e-01,\n         -2.9117e-02,  1.0036e-01, -6.4085e-02, -1.1116e-01, -1.4746e-01,\n         -7.2030e-03,  1.7821e-02,  1.3945e-01, -1.4937e-01,  3.9004e-02,\n         -1.0291e-01,  1.0204e-01],\n        [-3.2269e-02,  1.3823e-01,  1.7000e-03, -1.3021e-02,  1.2023e-02,\n          3.6244e-02,  9.6107e-02,  9.9599e-02, -1.2545e-01,  1.6670e-01,\n         -3.4511e-02,  7.0457e-02,  7.5301e-02,  1.2734e-01, -1.8410e-03,\n         -1.1622e-01,  9.7902e-02, -1.2854e-01,  1.6292e-01, -1.4357e-01,\n         -9.6565e-02, -1.3011e-01,  1.3678e-01, -6.9694e-02,  7.2457e-02,\n          1.4301e-01, -2.6435e-03, -1.3529e-01, -1.6867e-01, -9.6368e-02,\n          7.9714e-02, -1.7789e-02],\n        [ 1.0973e-02,  5.2554e-02,  7.4193e-02, -1.0977e-01,  5.4017e-02,\n          1.2806e-01, -1.4670e-01, -1.6049e-01, -1.5934e-01,  2.9920e-02,\n          1.6713e-01, -1.6084e-01,  7.0521e-02,  8.4905e-02,  2.4272e-02,\n          1.0197e-01, -6.9745e-02, -6.7871e-02,  7.6016e-02,  7.5992e-02,\n          5.0842e-02,  2.0912e-02,  1.6878e-01,  5.9924e-02,  7.5248e-02,\n         -1.8790e-03, -3.0708e-02,  8.6045e-02,  7.7288e-02, -9.0568e-02,\n         -1.1056e-01,  1.6579e-01],\n        [ 1.3617e-01, -1.2332e-01, -1.6196e-01,  1.0181e-01, -2.0386e-02,\n          1.6095e-01,  1.7008e-04,  8.7003e-02,  1.6620e-01, -6.4764e-02,\n         -1.7410e-01, -1.3680e-01, -1.4399e-01, -1.1055e-01, -5.5506e-02,\n          1.7003e-01,  2.7864e-02,  1.2629e-01,  9.0148e-02, -1.4838e-01,\n          2.8298e-02,  5.0981e-02,  1.1078e-01,  2.6838e-02, -1.3986e-01,\n         -5.1482e-02,  1.6268e-01, -1.4506e-01, -1.3450e-01,  1.1823e-01,\n         -1.5427e-01,  1.2910e-01],\n        [ 8.5165e-02,  8.9313e-04,  8.1096e-02, -1.5505e-02,  1.1043e-01,\n          1.7205e-01, -7.6570e-02,  2.5697e-02, -1.4505e-01, -7.5563e-02,\n          4.6372e-02, -1.4666e-01, -1.0498e-01, -8.7353e-03, -7.4408e-02,\n         -2.9806e-02, -4.2609e-02, -1.3804e-01,  1.4225e-01,  1.1924e-01,\n          1.2734e-01, -1.2720e-01, -1.5310e-01, -3.3042e-02, -3.1167e-02,\n          1.0234e-01,  9.6330e-02,  2.6621e-02,  1.4689e-01,  4.9789e-02,\n         -5.2601e-02,  1.0067e-01],\n        [ 1.0226e-01,  1.4394e-01,  1.0977e-01,  1.7458e-01,  4.1568e-02,\n         -1.0473e-01,  1.2454e-01,  1.1786e-01, -4.2567e-02, -6.3477e-02,\n          1.4297e-01, -1.4283e-01, -1.1636e-01,  1.0556e-01, -1.2645e-01,\n          1.6831e-01,  3.8274e-02,  1.1963e-01, -5.4270e-02, -1.0408e-01,\n         -8.4112e-02,  8.6504e-02, -8.6969e-02, -1.2292e-01, -1.5622e-01,\n         -1.7438e-01,  2.3999e-02,  5.5096e-02, -1.5892e-01,  7.8700e-02,\n         -1.3634e-01,  1.6604e-02],\n        [-6.6550e-02, -1.1832e-01, -1.7390e-01,  8.5319e-02, -4.9584e-02,\n          4.6310e-02,  1.6975e-01,  1.4076e-01, -1.6446e-01,  1.1811e-01,\n          2.8958e-02,  3.9669e-03,  1.1540e-01, -1.6134e-01, -1.6015e-01,\n         -5.6537e-03,  3.9182e-02,  6.1757e-02, -9.3455e-02,  9.4669e-02,\n         -1.4418e-01, -1.4212e-04,  1.5964e-01,  9.3089e-02, -1.3768e-01,\n          1.1194e-01,  1.5557e-01,  1.7670e-01,  5.6898e-02, -1.6132e-01,\n          1.5243e-01, -6.9443e-02],\n        [ 8.3498e-03,  4.1549e-02, -8.7194e-02,  1.6221e-01, -1.5614e-01,\n         -1.6079e-02,  1.0486e-01, -1.2201e-01,  1.6999e-01,  6.7326e-02,\n         -7.5640e-02,  5.1699e-03, -1.3655e-02, -1.2676e-01, -1.6216e-01,\n         -5.2177e-02, -2.9708e-02, -3.6011e-02, -6.8490e-02,  8.4488e-02,\n          1.2745e-01, -9.2092e-02, -1.1470e-01, -4.5770e-02,  1.5368e-01,\n         -1.9329e-02,  1.3120e-01, -1.4196e-01, -8.9326e-02, -3.0075e-02,\n         -6.1087e-02, -8.4868e-02],\n        [ 1.7053e-02, -8.9274e-02,  1.1946e-01, -2.3472e-02, -1.2961e-01,\n          1.1951e-01,  1.5019e-01,  7.0537e-02, -6.5296e-02,  4.0968e-02,\n         -1.5347e-01, -1.1923e-01,  1.0753e-01, -1.8785e-02, -5.1661e-04,\n          4.4928e-02,  9.3724e-02,  1.2200e-01,  1.1313e-01, -2.9460e-02,\n          6.7341e-02, -7.7005e-02, -7.5378e-02, -7.9671e-02,  1.0428e-01,\n         -1.6937e-01,  8.9521e-02, -1.2460e-01,  1.4193e-01, -5.0100e-02,\n          6.7393e-03, -1.5036e-01],\n        [ 1.0466e-01, -3.3301e-02,  4.9401e-02, -9.5911e-02,  1.4871e-01,\n         -1.4377e-01, -3.3079e-02, -1.7598e-01, -1.6973e-01,  1.0486e-01,\n         -7.4213e-02, -1.6874e-01,  2.9903e-02, -6.0345e-02, -1.6158e-01,\n         -1.3230e-01,  1.4916e-01,  1.5706e-01,  1.6330e-01, -1.5914e-01,\n          4.2248e-02, -5.9720e-04, -1.5943e-01, -2.3052e-02,  1.4629e-01,\n          1.2133e-01, -1.3102e-01,  2.2929e-02,  1.3621e-01, -4.6882e-02,\n         -1.7660e-01,  7.4782e-02],\n        [ 1.3298e-01,  5.8640e-02, -1.3577e-01, -2.0413e-02, -1.2227e-01,\n         -1.0583e-01,  9.8547e-02,  1.4853e-01,  1.0083e-01,  1.3159e-01,\n         -1.0854e-01, -1.4855e-01,  6.6632e-02, -6.9240e-02,  5.4249e-02,\n          1.3078e-01,  7.4909e-02,  1.4765e-01, -4.0602e-02, -9.6154e-03,\n          9.6428e-02,  1.6455e-01, -3.4347e-02,  1.7103e-01,  3.5238e-03,\n          1.7513e-01, -1.5962e-01, -4.4932e-02, -5.2022e-02, -7.1543e-02,\n         -1.1606e-01,  1.0000e-01],\n        [ 6.8706e-02, -9.5311e-02,  1.7990e-02,  1.3900e-02,  8.9316e-02,\n          1.4111e-01, -5.0461e-02, -1.5489e-01,  3.2958e-02,  9.7992e-02,\n         -5.7002e-02,  1.4458e-01, -3.7833e-02,  9.1140e-02, -3.3631e-02,\n         -1.0290e-01, -1.2014e-01,  3.8049e-02, -1.1458e-01,  1.6495e-01,\n          1.6071e-01, -6.2270e-02, -1.4451e-01, -8.6310e-02, -1.6020e-01,\n         -3.2501e-02,  1.2827e-01, -1.5673e-01,  1.3137e-01,  1.0753e-03,\n          2.7668e-02,  5.2794e-02],\n        [ 9.5946e-02,  9.8314e-02, -5.5026e-02,  1.4290e-02, -1.1873e-01,\n          3.2975e-02,  1.4940e-01, -1.7255e-04, -1.3602e-01,  7.1283e-02,\n         -1.7104e-01, -6.4814e-02, -1.2080e-01, -6.3172e-02,  1.2751e-01,\n          1.0554e-01, -1.7512e-01,  6.2001e-02,  1.3095e-01, -1.5886e-01,\n          1.4165e-01,  3.5150e-04,  1.1376e-01,  1.2178e-01, -3.7860e-02,\n          1.4066e-01,  1.1790e-01, -6.9163e-02,  4.3990e-02, -3.7917e-02,\n          3.6816e-02, -2.8903e-02],\n        [-1.4931e-01,  1.0662e-01, -1.6799e-01, -8.4061e-02, -8.9556e-02,\n         -7.5738e-02,  1.0133e-01, -1.6444e-02, -1.4850e-01,  1.5958e-01,\n         -6.7027e-02,  1.5756e-01, -5.9524e-02,  1.6464e-01,  1.1211e-02,\n          1.6057e-01, -1.6643e-01, -1.6488e-01, -1.6552e-01,  9.6932e-02,\n         -8.7388e-02,  1.5534e-01,  1.7735e-02, -6.4731e-02,  1.4327e-01,\n          1.7738e-02, -3.1193e-02,  1.7293e-01,  6.3451e-02,  3.1067e-02,\n          3.1649e-02, -1.2477e-01],\n        [ 2.7136e-02, -1.5896e-01,  9.4702e-02, -1.6952e-01,  4.5405e-02,\n         -9.4745e-02,  8.3893e-02, -1.1937e-01, -5.3336e-02,  1.1436e-01,\n          4.5929e-02,  2.7227e-02,  9.4725e-02, -1.3172e-01,  1.3065e-02,\n          8.8957e-02, -1.0656e-01,  9.5721e-02, -5.8023e-02,  8.4449e-03,\n          1.0271e-01,  8.1291e-02, -1.4697e-01, -1.1546e-01,  1.6365e-02,\n         -1.4040e-01, -1.0018e-01,  8.6995e-02, -1.4577e-01,  8.6431e-02,\n          3.3309e-02,  9.5476e-02],\n        [-1.3867e-01,  7.2825e-02,  8.9928e-02,  7.0997e-02, -4.2358e-02,\n         -6.1025e-02, -9.8169e-02,  5.6531e-03,  1.4893e-01, -9.8392e-02,\n          1.1850e-01,  3.3973e-02, -1.3455e-02,  7.3737e-02,  1.6130e-01,\n         -9.2538e-02, -2.6704e-02,  4.8834e-02, -1.1509e-01, -6.4295e-02,\n          1.6333e-01,  5.9654e-02, -1.0540e-01, -9.0680e-02,  1.4288e-01,\n         -1.4882e-01, -1.1803e-01,  6.9252e-02, -2.8692e-02,  9.5437e-02,\n          1.3414e-01,  4.4385e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1088,  0.1453, -0.1569,  0.0738, -0.0809,  0.1566,  0.2114,  0.0484],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2065,  0.1467, -0.1650,  0.2127,  0.2414,  0.0956, -0.0279,  0.1208,\n          0.2491,  0.1173, -0.0342, -0.1278,  0.1466,  0.1757,  0.0921, -0.1875],\n        [-0.1658, -0.2361, -0.0977, -0.2279,  0.0372, -0.2037,  0.0765,  0.1580,\n          0.1183, -0.0910, -0.1223,  0.0467, -0.0314, -0.0644, -0.1557,  0.1003],\n        [ 0.1019,  0.1653,  0.1137, -0.1489,  0.2421, -0.2179, -0.0690,  0.2288,\n         -0.1719, -0.0773, -0.2255, -0.0118, -0.1827,  0.0597,  0.0424,  0.0827],\n        [-0.0566,  0.0511, -0.0846, -0.2463,  0.0401, -0.1607,  0.0500, -0.0378,\n          0.2231,  0.0686, -0.0693,  0.1469, -0.1632, -0.2464,  0.0035, -0.1184],\n        [-0.0011,  0.1481, -0.1624, -0.0718,  0.0943,  0.0753,  0.2083, -0.2088,\n          0.0703, -0.2452,  0.1104,  0.0773,  0.0603,  0.0562, -0.1115,  0.1663],\n        [ 0.1168,  0.2095,  0.1995,  0.1252, -0.2039, -0.1887,  0.0259,  0.0138,\n         -0.1267, -0.0071, -0.0460,  0.1711,  0.0067, -0.0091, -0.1062, -0.0192],\n        [-0.2488,  0.1722,  0.0210, -0.0492,  0.2312,  0.0301,  0.1432,  0.1907,\n         -0.0706,  0.1740,  0.0713, -0.2398, -0.0885,  0.0316,  0.2069, -0.1978],\n        [-0.2142,  0.1192,  0.0953, -0.0690,  0.2177, -0.2130, -0.0874,  0.0591,\n          0.1776, -0.2073, -0.0400, -0.1240, -0.0964,  0.0846,  0.2169, -0.0300]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3263,  0.1580, -0.3361,  0.0503], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3405,  0.1150, -0.2870, -0.1928,  0.0282,  0.0773, -0.3101, -0.2968],\n        [ 0.2721,  0.0098, -0.0431,  0.2105,  0.3289,  0.1563, -0.1869,  0.2866],\n        [-0.2439, -0.0336,  0.1291, -0.0909, -0.2507,  0.2906,  0.3407,  0.2058],\n        [ 0.1686, -0.3150, -0.0111, -0.1928,  0.2841,  0.2441,  0.1426,  0.3255]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0001\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0001,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0001,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-3.1749e-01, -3.0441e-01,  7.4688e-02, -6.2347e-02,  1.4045e-02,\n         -2.2074e-01,  3.3671e-01, -2.3758e-01],\n        [ 1.6776e-01, -3.1305e-01,  2.7605e-01, -3.2154e-02, -1.8838e-01,\n          1.6823e-01,  2.2956e-01,  1.9027e-01],\n        [-2.1690e-01,  1.8670e-01,  1.7922e-01,  2.1948e-02, -1.6463e-01,\n          1.5568e-01, -2.5503e-01, -1.8726e-01],\n        [ 2.4973e-01,  1.9425e-01, -3.2671e-01,  2.0001e-01,  2.7947e-01,\n         -9.2754e-02, -2.9623e-01,  2.8245e-01],\n        [-7.4103e-02, -2.7631e-01, -8.8961e-03, -3.2004e-01,  1.4868e-01,\n         -3.3120e-01,  3.4130e-01,  3.5251e-01],\n        [-7.7817e-02,  2.9233e-01,  7.5264e-02,  1.8106e-01,  7.6771e-02,\n          2.5694e-01, -9.4363e-02,  2.2691e-01],\n        [ 1.1890e-01, -2.4856e-01,  3.3337e-02, -2.5742e-01, -9.0140e-02,\n         -1.1278e-01,  9.1234e-02, -2.6782e-01],\n        [ 2.0028e-01,  1.7402e-01,  1.3578e-03,  1.8623e-02,  2.5050e-01,\n         -2.4379e-01,  1.2202e-01,  1.6210e-01],\n        [-1.4485e-01, -3.5212e-01,  2.4812e-01, -3.0961e-01, -1.0391e-01,\n         -4.9840e-02, -2.8683e-01,  2.7420e-01],\n        [-4.0299e-02,  7.0153e-02,  3.4789e-01, -7.5844e-02, -3.1100e-01,\n         -2.9983e-01, -2.5097e-02,  2.3477e-01],\n        [ 1.3084e-01, -1.7274e-01, -2.7071e-01,  2.3001e-01,  9.0235e-02,\n         -3.0291e-01,  1.4642e-02,  9.4986e-02],\n        [-7.5265e-02, -1.8901e-01,  3.2294e-01, -3.5328e-01,  1.7869e-01,\n         -1.0224e-01,  2.0882e-01,  3.2701e-01],\n        [ 1.6355e-01,  3.5235e-01,  1.0406e-01,  1.0373e-01, -1.2971e-01,\n         -2.1118e-01,  2.9805e-01,  1.9503e-01],\n        [ 2.7720e-01, -2.6472e-04, -1.6864e-01, -1.5807e-01, -3.5293e-01,\n         -3.1821e-01,  2.1748e-01, -1.0613e-01],\n        [ 2.5626e-01, -3.4958e-01, -1.4165e-01,  1.5883e-01,  1.9901e-01,\n          7.5100e-02, -3.2341e-01, -8.7336e-02],\n        [-1.0357e-01,  3.2157e-01, -2.2773e-01,  2.0775e-01,  2.3524e-01,\n         -2.9483e-01,  2.2818e-01,  5.0043e-02],\n        [-3.0557e-01,  9.7500e-02, -2.5740e-01, -2.8577e-01, -1.4618e-01,\n         -1.4706e-01, -1.0767e-01, -2.7476e-01],\n        [ 6.0184e-02,  3.3078e-01,  2.7680e-01, -2.8463e-01,  5.5991e-02,\n         -1.5952e-01,  3.4436e-01,  7.8406e-02],\n        [-1.1976e-01, -2.6091e-01, -3.0488e-01,  1.8713e-01, -3.2772e-01,\n          1.0901e-01, -1.3601e-01, -4.0582e-03],\n        [-6.5532e-02,  9.7472e-02, -5.8224e-02, -1.7468e-01,  2.4077e-02,\n          1.1047e-01, -2.9656e-01,  2.5358e-01],\n        [ 2.1473e-01, -1.3243e-01,  2.0831e-02,  3.1311e-01,  2.4339e-01,\n          1.4648e-01, -2.1711e-01,  1.1394e-01],\n        [-3.6721e-02, -2.3232e-01,  2.4832e-01, -1.7951e-01,  6.5247e-02,\n         -3.2808e-01, -6.1880e-02,  1.1948e-01],\n        [ 1.7959e-01,  3.1138e-01, -9.7404e-02,  3.1180e-01, -2.7469e-01,\n          4.3376e-02,  6.8959e-03, -2.8165e-01],\n        [ 7.8461e-02,  2.2089e-01, -8.2240e-02, -3.2614e-01, -2.8846e-01,\n         -2.9330e-01, -9.0971e-02, -5.1015e-02],\n        [-8.3322e-02, -3.1618e-01,  1.1332e-01, -5.7113e-02, -2.8778e-01,\n          2.3993e-01, -2.2607e-01,  2.9538e-01],\n        [-8.3751e-02,  1.8978e-02, -9.4422e-02, -2.9385e-01,  3.2481e-01,\n          2.1500e-01,  8.5297e-02,  2.5838e-01],\n        [-7.5616e-02, -1.5545e-01,  2.6569e-02, -2.4555e-01, -5.4715e-03,\n         -4.5631e-02, -3.5259e-01,  1.0085e-01],\n        [ 1.2607e-01, -2.3860e-01,  6.3564e-02,  5.6359e-02,  3.1156e-01,\n          3.1242e-02, -8.1575e-02,  1.1846e-01],\n        [ 6.4567e-03,  1.1335e-01, -1.1391e-01, -3.4726e-01,  3.2785e-01,\n          3.5178e-01, -2.3129e-01, -1.2502e-01],\n        [-1.0229e-01, -5.7225e-02,  2.5587e-01, -5.9210e-02,  1.4959e-01,\n          3.4723e-01,  2.0800e-01, -2.3044e-01],\n        [-1.8802e-01, -3.2334e-01,  6.2012e-02, -1.5985e-01,  1.3843e-01,\n          3.1983e-02,  3.2386e-01,  2.4375e-01],\n        [-2.2672e-01, -1.6445e-01,  1.9897e-01, -3.1782e-01,  1.7955e-01,\n         -2.6809e-01, -2.9869e-01, -3.4985e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-1.7873e-01,  1.2538e-02,  1.7909e-01, -2.2792e-01,  1.2688e-01,\n        -1.8633e-01,  4.8281e-02, -9.1986e-02, -3.2141e-02,  3.3948e-01,\n        -2.5969e-01,  1.8605e-01,  2.2363e-04, -2.3099e-01, -1.4830e-01,\n         2.0516e-01,  1.3950e-01,  9.6929e-02,  1.4246e-01,  1.5445e-01,\n        -2.6180e-01,  3.1135e-02,  2.1081e-01, -1.1844e-01,  3.0819e-01,\n        -1.4230e-01,  3.6735e-02, -2.5951e-01, -6.4151e-02, -2.8479e-02,\n         2.8736e-01,  3.3549e-01], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 7.6761e-02, -1.5348e-01,  6.0648e-03, -1.2045e-01,  1.5559e-01,\n          3.2294e-02,  1.3331e-01,  1.4353e-01,  4.2355e-02, -1.4553e-02,\n          1.0470e-01, -6.0720e-02,  1.5187e-01, -5.1037e-02, -2.7262e-02,\n          1.1692e-01,  1.2190e-01,  5.5541e-02, -1.2696e-01, -1.7634e-01,\n         -2.9117e-02,  1.0036e-01, -6.4085e-02, -1.1116e-01, -1.4746e-01,\n         -7.2030e-03,  1.7821e-02,  1.3945e-01, -1.4937e-01,  3.9004e-02,\n         -1.0291e-01,  1.0204e-01],\n        [-3.2269e-02,  1.3823e-01,  1.7000e-03, -1.3021e-02,  1.2023e-02,\n          3.6244e-02,  9.6107e-02,  9.9599e-02, -1.2545e-01,  1.6670e-01,\n         -3.4511e-02,  7.0457e-02,  7.5301e-02,  1.2734e-01, -1.8410e-03,\n         -1.1622e-01,  9.7902e-02, -1.2854e-01,  1.6292e-01, -1.4357e-01,\n         -9.6565e-02, -1.3011e-01,  1.3678e-01, -6.9694e-02,  7.2457e-02,\n          1.4301e-01, -2.6435e-03, -1.3529e-01, -1.6867e-01, -9.6368e-02,\n          7.9714e-02, -1.7789e-02],\n        [ 1.0973e-02,  5.2554e-02,  7.4193e-02, -1.0977e-01,  5.4017e-02,\n          1.2806e-01, -1.4670e-01, -1.6049e-01, -1.5934e-01,  2.9920e-02,\n          1.6713e-01, -1.6084e-01,  7.0521e-02,  8.4905e-02,  2.4272e-02,\n          1.0197e-01, -6.9745e-02, -6.7871e-02,  7.6016e-02,  7.5992e-02,\n          5.0842e-02,  2.0912e-02,  1.6878e-01,  5.9924e-02,  7.5248e-02,\n         -1.8790e-03, -3.0708e-02,  8.6045e-02,  7.7288e-02, -9.0568e-02,\n         -1.1056e-01,  1.6579e-01],\n        [ 1.3617e-01, -1.2332e-01, -1.6196e-01,  1.0181e-01, -2.0386e-02,\n          1.6095e-01,  1.7008e-04,  8.7003e-02,  1.6620e-01, -6.4764e-02,\n         -1.7410e-01, -1.3680e-01, -1.4399e-01, -1.1055e-01, -5.5506e-02,\n          1.7003e-01,  2.7864e-02,  1.2629e-01,  9.0148e-02, -1.4838e-01,\n          2.8298e-02,  5.0981e-02,  1.1078e-01,  2.6838e-02, -1.3986e-01,\n         -5.1482e-02,  1.6268e-01, -1.4506e-01, -1.3450e-01,  1.1823e-01,\n         -1.5427e-01,  1.2910e-01],\n        [ 8.5165e-02,  8.9313e-04,  8.1096e-02, -1.5505e-02,  1.1043e-01,\n          1.7205e-01, -7.6570e-02,  2.5697e-02, -1.4505e-01, -7.5563e-02,\n          4.6372e-02, -1.4666e-01, -1.0498e-01, -8.7353e-03, -7.4408e-02,\n         -2.9806e-02, -4.2609e-02, -1.3804e-01,  1.4225e-01,  1.1924e-01,\n          1.2734e-01, -1.2720e-01, -1.5310e-01, -3.3042e-02, -3.1167e-02,\n          1.0234e-01,  9.6330e-02,  2.6621e-02,  1.4689e-01,  4.9789e-02,\n         -5.2601e-02,  1.0067e-01],\n        [ 1.0226e-01,  1.4394e-01,  1.0977e-01,  1.7458e-01,  4.1568e-02,\n         -1.0473e-01,  1.2454e-01,  1.1786e-01, -4.2567e-02, -6.3477e-02,\n          1.4297e-01, -1.4283e-01, -1.1636e-01,  1.0556e-01, -1.2645e-01,\n          1.6831e-01,  3.8274e-02,  1.1963e-01, -5.4270e-02, -1.0408e-01,\n         -8.4112e-02,  8.6504e-02, -8.6969e-02, -1.2292e-01, -1.5622e-01,\n         -1.7438e-01,  2.3999e-02,  5.5096e-02, -1.5892e-01,  7.8700e-02,\n         -1.3634e-01,  1.6604e-02],\n        [-6.6550e-02, -1.1832e-01, -1.7390e-01,  8.5319e-02, -4.9584e-02,\n          4.6310e-02,  1.6975e-01,  1.4076e-01, -1.6446e-01,  1.1811e-01,\n          2.8958e-02,  3.9669e-03,  1.1540e-01, -1.6134e-01, -1.6015e-01,\n         -5.6537e-03,  3.9182e-02,  6.1757e-02, -9.3455e-02,  9.4669e-02,\n         -1.4418e-01, -1.4212e-04,  1.5964e-01,  9.3089e-02, -1.3768e-01,\n          1.1194e-01,  1.5557e-01,  1.7670e-01,  5.6898e-02, -1.6132e-01,\n          1.5243e-01, -6.9443e-02],\n        [ 8.3498e-03,  4.1549e-02, -8.7194e-02,  1.6221e-01, -1.5614e-01,\n         -1.6079e-02,  1.0486e-01, -1.2201e-01,  1.6999e-01,  6.7326e-02,\n         -7.5640e-02,  5.1699e-03, -1.3655e-02, -1.2676e-01, -1.6216e-01,\n         -5.2177e-02, -2.9708e-02, -3.6011e-02, -6.8490e-02,  8.4488e-02,\n          1.2745e-01, -9.2092e-02, -1.1470e-01, -4.5770e-02,  1.5368e-01,\n         -1.9329e-02,  1.3120e-01, -1.4196e-01, -8.9326e-02, -3.0075e-02,\n         -6.1087e-02, -8.4868e-02],\n        [ 1.7053e-02, -8.9274e-02,  1.1946e-01, -2.3472e-02, -1.2961e-01,\n          1.1951e-01,  1.5019e-01,  7.0537e-02, -6.5296e-02,  4.0968e-02,\n         -1.5347e-01, -1.1923e-01,  1.0753e-01, -1.8785e-02, -5.1661e-04,\n          4.4928e-02,  9.3724e-02,  1.2200e-01,  1.1313e-01, -2.9460e-02,\n          6.7341e-02, -7.7005e-02, -7.5378e-02, -7.9671e-02,  1.0428e-01,\n         -1.6937e-01,  8.9521e-02, -1.2460e-01,  1.4193e-01, -5.0100e-02,\n          6.7393e-03, -1.5036e-01],\n        [ 1.0466e-01, -3.3301e-02,  4.9401e-02, -9.5911e-02,  1.4871e-01,\n         -1.4377e-01, -3.3079e-02, -1.7598e-01, -1.6973e-01,  1.0486e-01,\n         -7.4213e-02, -1.6874e-01,  2.9903e-02, -6.0345e-02, -1.6158e-01,\n         -1.3230e-01,  1.4916e-01,  1.5706e-01,  1.6330e-01, -1.5914e-01,\n          4.2248e-02, -5.9720e-04, -1.5943e-01, -2.3052e-02,  1.4629e-01,\n          1.2133e-01, -1.3102e-01,  2.2929e-02,  1.3621e-01, -4.6882e-02,\n         -1.7660e-01,  7.4782e-02],\n        [ 1.3298e-01,  5.8640e-02, -1.3577e-01, -2.0413e-02, -1.2227e-01,\n         -1.0583e-01,  9.8547e-02,  1.4853e-01,  1.0083e-01,  1.3159e-01,\n         -1.0854e-01, -1.4855e-01,  6.6632e-02, -6.9240e-02,  5.4249e-02,\n          1.3078e-01,  7.4909e-02,  1.4765e-01, -4.0602e-02, -9.6154e-03,\n          9.6428e-02,  1.6455e-01, -3.4347e-02,  1.7103e-01,  3.5238e-03,\n          1.7513e-01, -1.5962e-01, -4.4932e-02, -5.2022e-02, -7.1543e-02,\n         -1.1606e-01,  1.0000e-01],\n        [ 6.8706e-02, -9.5311e-02,  1.7990e-02,  1.3900e-02,  8.9316e-02,\n          1.4111e-01, -5.0461e-02, -1.5489e-01,  3.2958e-02,  9.7992e-02,\n         -5.7002e-02,  1.4458e-01, -3.7833e-02,  9.1140e-02, -3.3631e-02,\n         -1.0290e-01, -1.2014e-01,  3.8049e-02, -1.1458e-01,  1.6495e-01,\n          1.6071e-01, -6.2270e-02, -1.4451e-01, -8.6310e-02, -1.6020e-01,\n         -3.2501e-02,  1.2827e-01, -1.5673e-01,  1.3137e-01,  1.0753e-03,\n          2.7668e-02,  5.2794e-02],\n        [ 9.5946e-02,  9.8314e-02, -5.5026e-02,  1.4290e-02, -1.1873e-01,\n          3.2975e-02,  1.4940e-01, -1.7255e-04, -1.3602e-01,  7.1283e-02,\n         -1.7104e-01, -6.4814e-02, -1.2080e-01, -6.3172e-02,  1.2751e-01,\n          1.0554e-01, -1.7512e-01,  6.2001e-02,  1.3095e-01, -1.5886e-01,\n          1.4165e-01,  3.5150e-04,  1.1376e-01,  1.2178e-01, -3.7860e-02,\n          1.4066e-01,  1.1790e-01, -6.9163e-02,  4.3990e-02, -3.7917e-02,\n          3.6816e-02, -2.8903e-02],\n        [-1.4931e-01,  1.0662e-01, -1.6799e-01, -8.4061e-02, -8.9556e-02,\n         -7.5738e-02,  1.0133e-01, -1.6444e-02, -1.4850e-01,  1.5958e-01,\n         -6.7027e-02,  1.5756e-01, -5.9524e-02,  1.6464e-01,  1.1211e-02,\n          1.6057e-01, -1.6643e-01, -1.6488e-01, -1.6552e-01,  9.6932e-02,\n         -8.7388e-02,  1.5534e-01,  1.7735e-02, -6.4731e-02,  1.4327e-01,\n          1.7738e-02, -3.1193e-02,  1.7293e-01,  6.3451e-02,  3.1067e-02,\n          3.1649e-02, -1.2477e-01],\n        [ 2.7136e-02, -1.5896e-01,  9.4702e-02, -1.6952e-01,  4.5405e-02,\n         -9.4745e-02,  8.3893e-02, -1.1937e-01, -5.3336e-02,  1.1436e-01,\n          4.5929e-02,  2.7227e-02,  9.4725e-02, -1.3172e-01,  1.3065e-02,\n          8.8957e-02, -1.0656e-01,  9.5721e-02, -5.8023e-02,  8.4449e-03,\n          1.0271e-01,  8.1291e-02, -1.4697e-01, -1.1546e-01,  1.6365e-02,\n         -1.4040e-01, -1.0018e-01,  8.6995e-02, -1.4577e-01,  8.6431e-02,\n          3.3309e-02,  9.5476e-02],\n        [-1.3867e-01,  7.2825e-02,  8.9928e-02,  7.0997e-02, -4.2358e-02,\n         -6.1025e-02, -9.8169e-02,  5.6531e-03,  1.4893e-01, -9.8392e-02,\n          1.1850e-01,  3.3973e-02, -1.3455e-02,  7.3737e-02,  1.6130e-01,\n         -9.2538e-02, -2.6704e-02,  4.8834e-02, -1.1509e-01, -6.4295e-02,\n          1.6333e-01,  5.9654e-02, -1.0540e-01, -9.0680e-02,  1.4288e-01,\n         -1.4882e-01, -1.1803e-01,  6.9252e-02, -2.8692e-02,  9.5437e-02,\n          1.3414e-01,  4.4385e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0129, -0.1437, -0.0055, -0.0107, -0.1309,  0.0894, -0.0695,  0.1115,\n        -0.1184, -0.1372, -0.1397,  0.0903, -0.0159, -0.0083,  0.1368, -0.1499],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2065,  0.1467, -0.1650,  0.2127,  0.2414,  0.0956, -0.0279,  0.1208,\n          0.2491,  0.1173, -0.0342, -0.1278,  0.1466,  0.1757,  0.0921, -0.1875],\n        [-0.1658, -0.2361, -0.0977, -0.2279,  0.0372, -0.2037,  0.0765,  0.1580,\n          0.1183, -0.0910, -0.1223,  0.0467, -0.0314, -0.0644, -0.1557,  0.1003],\n        [ 0.1019,  0.1653,  0.1137, -0.1489,  0.2421, -0.2179, -0.0690,  0.2288,\n         -0.1719, -0.0773, -0.2255, -0.0118, -0.1827,  0.0597,  0.0424,  0.0827],\n        [-0.0566,  0.0511, -0.0846, -0.2463,  0.0401, -0.1607,  0.0500, -0.0378,\n          0.2231,  0.0686, -0.0693,  0.1469, -0.1632, -0.2464,  0.0035, -0.1184],\n        [-0.0011,  0.1481, -0.1624, -0.0718,  0.0943,  0.0753,  0.2083, -0.2088,\n          0.0703, -0.2452,  0.1104,  0.0773,  0.0603,  0.0562, -0.1115,  0.1663],\n        [ 0.1168,  0.2095,  0.1995,  0.1252, -0.2039, -0.1887,  0.0259,  0.0138,\n         -0.1267, -0.0071, -0.0460,  0.1711,  0.0067, -0.0091, -0.1062, -0.0192],\n        [-0.2488,  0.1722,  0.0210, -0.0492,  0.2312,  0.0301,  0.1432,  0.1907,\n         -0.0706,  0.1740,  0.0713, -0.2398, -0.0885,  0.0316,  0.2069, -0.1978],\n        [-0.2142,  0.1192,  0.0953, -0.0690,  0.2177, -0.2130, -0.0874,  0.0591,\n          0.1776, -0.2073, -0.0400, -0.1240, -0.0964,  0.0846,  0.2169, -0.0300]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1088,  0.1453, -0.1569,  0.0738, -0.0809,  0.1566,  0.2114,  0.0484],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3405,  0.1150, -0.2870, -0.1928,  0.0282,  0.0773, -0.3101, -0.2968],\n        [ 0.2721,  0.0098, -0.0431,  0.2105,  0.3289,  0.1563, -0.1869,  0.2866],\n        [-0.2439, -0.0336,  0.1291, -0.0909, -0.2507,  0.2906,  0.3407,  0.2058],\n        [ 0.1686, -0.3150, -0.0111, -0.1928,  0.2841,  0.2441,  0.1426,  0.3255]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3263,  0.1580, -0.3361,  0.0503], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7f4a2a6a2750>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-1.7873e-01,  1.2538e-02,  1.7909e-01, -2.2792e-01,  1.2688e-01,\n        -1.8633e-01,  4.8281e-02, -9.1986e-02, -3.2141e-02,  3.3948e-01,\n        -2.5969e-01,  1.8605e-01,  2.2363e-04, -2.3099e-01, -1.4830e-01,\n         2.0516e-01,  1.3950e-01,  9.6929e-02,  1.4246e-01,  1.5445e-01,\n        -2.6180e-01,  3.1135e-02,  2.1081e-01, -1.1844e-01,  3.0819e-01,\n        -1.4230e-01,  3.6735e-02, -2.5951e-01, -6.4151e-02, -2.8479e-02,\n         2.8736e-01,  3.3549e-01], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.1749e-01, -3.0441e-01,  7.4688e-02, -6.2347e-02,  1.4045e-02,\n         -2.2074e-01,  3.3671e-01, -2.3758e-01],\n        [ 1.6776e-01, -3.1305e-01,  2.7605e-01, -3.2154e-02, -1.8838e-01,\n          1.6823e-01,  2.2956e-01,  1.9027e-01],\n        [-2.1690e-01,  1.8670e-01,  1.7922e-01,  2.1948e-02, -1.6463e-01,\n          1.5568e-01, -2.5503e-01, -1.8726e-01],\n        [ 2.4973e-01,  1.9425e-01, -3.2671e-01,  2.0001e-01,  2.7947e-01,\n         -9.2754e-02, -2.9623e-01,  2.8245e-01],\n        [-7.4103e-02, -2.7631e-01, -8.8961e-03, -3.2004e-01,  1.4868e-01,\n         -3.3120e-01,  3.4130e-01,  3.5251e-01],\n        [-7.7817e-02,  2.9233e-01,  7.5264e-02,  1.8106e-01,  7.6771e-02,\n          2.5694e-01, -9.4363e-02,  2.2691e-01],\n        [ 1.1890e-01, -2.4856e-01,  3.3337e-02, -2.5742e-01, -9.0140e-02,\n         -1.1278e-01,  9.1234e-02, -2.6782e-01],\n        [ 2.0028e-01,  1.7402e-01,  1.3578e-03,  1.8623e-02,  2.5050e-01,\n         -2.4379e-01,  1.2202e-01,  1.6210e-01],\n        [-1.4485e-01, -3.5212e-01,  2.4812e-01, -3.0961e-01, -1.0391e-01,\n         -4.9840e-02, -2.8683e-01,  2.7420e-01],\n        [-4.0299e-02,  7.0153e-02,  3.4789e-01, -7.5844e-02, -3.1100e-01,\n         -2.9983e-01, -2.5097e-02,  2.3477e-01],\n        [ 1.3084e-01, -1.7274e-01, -2.7071e-01,  2.3001e-01,  9.0235e-02,\n         -3.0291e-01,  1.4642e-02,  9.4986e-02],\n        [-7.5265e-02, -1.8901e-01,  3.2294e-01, -3.5328e-01,  1.7869e-01,\n         -1.0224e-01,  2.0882e-01,  3.2701e-01],\n        [ 1.6355e-01,  3.5235e-01,  1.0406e-01,  1.0373e-01, -1.2971e-01,\n         -2.1118e-01,  2.9805e-01,  1.9503e-01],\n        [ 2.7720e-01, -2.6472e-04, -1.6864e-01, -1.5807e-01, -3.5293e-01,\n         -3.1821e-01,  2.1748e-01, -1.0613e-01],\n        [ 2.5626e-01, -3.4958e-01, -1.4165e-01,  1.5883e-01,  1.9901e-01,\n          7.5100e-02, -3.2341e-01, -8.7336e-02],\n        [-1.0357e-01,  3.2157e-01, -2.2773e-01,  2.0775e-01,  2.3524e-01,\n         -2.9483e-01,  2.2818e-01,  5.0043e-02],\n        [-3.0557e-01,  9.7500e-02, -2.5740e-01, -2.8577e-01, -1.4618e-01,\n         -1.4706e-01, -1.0767e-01, -2.7476e-01],\n        [ 6.0184e-02,  3.3078e-01,  2.7680e-01, -2.8463e-01,  5.5991e-02,\n         -1.5952e-01,  3.4436e-01,  7.8406e-02],\n        [-1.1976e-01, -2.6091e-01, -3.0488e-01,  1.8713e-01, -3.2772e-01,\n          1.0901e-01, -1.3601e-01, -4.0582e-03],\n        [-6.5532e-02,  9.7472e-02, -5.8224e-02, -1.7468e-01,  2.4077e-02,\n          1.1047e-01, -2.9656e-01,  2.5358e-01],\n        [ 2.1473e-01, -1.3243e-01,  2.0831e-02,  3.1311e-01,  2.4339e-01,\n          1.4648e-01, -2.1711e-01,  1.1394e-01],\n        [-3.6721e-02, -2.3232e-01,  2.4832e-01, -1.7951e-01,  6.5247e-02,\n         -3.2808e-01, -6.1880e-02,  1.1948e-01],\n        [ 1.7959e-01,  3.1138e-01, -9.7404e-02,  3.1180e-01, -2.7469e-01,\n          4.3376e-02,  6.8959e-03, -2.8165e-01],\n        [ 7.8461e-02,  2.2089e-01, -8.2240e-02, -3.2614e-01, -2.8846e-01,\n         -2.9330e-01, -9.0971e-02, -5.1015e-02],\n        [-8.3322e-02, -3.1618e-01,  1.1332e-01, -5.7113e-02, -2.8778e-01,\n          2.3993e-01, -2.2607e-01,  2.9538e-01],\n        [-8.3751e-02,  1.8978e-02, -9.4422e-02, -2.9385e-01,  3.2481e-01,\n          2.1500e-01,  8.5297e-02,  2.5838e-01],\n        [-7.5616e-02, -1.5545e-01,  2.6569e-02, -2.4555e-01, -5.4715e-03,\n         -4.5631e-02, -3.5259e-01,  1.0085e-01],\n        [ 1.2607e-01, -2.3860e-01,  6.3564e-02,  5.6359e-02,  3.1156e-01,\n          3.1242e-02, -8.1575e-02,  1.1846e-01],\n        [ 6.4567e-03,  1.1335e-01, -1.1391e-01, -3.4726e-01,  3.2785e-01,\n          3.5178e-01, -2.3129e-01, -1.2502e-01],\n        [-1.0229e-01, -5.7225e-02,  2.5587e-01, -5.9210e-02,  1.4959e-01,\n          3.4723e-01,  2.0800e-01, -2.3044e-01],\n        [-1.8802e-01, -3.2334e-01,  6.2012e-02, -1.5985e-01,  1.3843e-01,\n          3.1983e-02,  3.2386e-01,  2.4375e-01],\n        [-2.2672e-01, -1.6445e-01,  1.9897e-01, -3.1782e-01,  1.7955e-01,\n         -2.6809e-01, -2.9869e-01, -3.4985e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0129, -0.1437, -0.0055, -0.0107, -0.1309,  0.0894, -0.0695,  0.1115,\n        -0.1184, -0.1372, -0.1397,  0.0903, -0.0159, -0.0083,  0.1368, -0.1499],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 7.6761e-02, -1.5348e-01,  6.0648e-03, -1.2045e-01,  1.5559e-01,\n          3.2294e-02,  1.3331e-01,  1.4353e-01,  4.2355e-02, -1.4553e-02,\n          1.0470e-01, -6.0720e-02,  1.5187e-01, -5.1037e-02, -2.7262e-02,\n          1.1692e-01,  1.2190e-01,  5.5541e-02, -1.2696e-01, -1.7634e-01,\n         -2.9117e-02,  1.0036e-01, -6.4085e-02, -1.1116e-01, -1.4746e-01,\n         -7.2030e-03,  1.7821e-02,  1.3945e-01, -1.4937e-01,  3.9004e-02,\n         -1.0291e-01,  1.0204e-01],\n        [-3.2269e-02,  1.3823e-01,  1.7000e-03, -1.3021e-02,  1.2023e-02,\n          3.6244e-02,  9.6107e-02,  9.9599e-02, -1.2545e-01,  1.6670e-01,\n         -3.4511e-02,  7.0457e-02,  7.5301e-02,  1.2734e-01, -1.8410e-03,\n         -1.1622e-01,  9.7902e-02, -1.2854e-01,  1.6292e-01, -1.4357e-01,\n         -9.6565e-02, -1.3011e-01,  1.3678e-01, -6.9694e-02,  7.2457e-02,\n          1.4301e-01, -2.6435e-03, -1.3529e-01, -1.6867e-01, -9.6368e-02,\n          7.9714e-02, -1.7789e-02],\n        [ 1.0973e-02,  5.2554e-02,  7.4193e-02, -1.0977e-01,  5.4017e-02,\n          1.2806e-01, -1.4670e-01, -1.6049e-01, -1.5934e-01,  2.9920e-02,\n          1.6713e-01, -1.6084e-01,  7.0521e-02,  8.4905e-02,  2.4272e-02,\n          1.0197e-01, -6.9745e-02, -6.7871e-02,  7.6016e-02,  7.5992e-02,\n          5.0842e-02,  2.0912e-02,  1.6878e-01,  5.9924e-02,  7.5248e-02,\n         -1.8790e-03, -3.0708e-02,  8.6045e-02,  7.7288e-02, -9.0568e-02,\n         -1.1056e-01,  1.6579e-01],\n        [ 1.3617e-01, -1.2332e-01, -1.6196e-01,  1.0181e-01, -2.0386e-02,\n          1.6095e-01,  1.7008e-04,  8.7003e-02,  1.6620e-01, -6.4764e-02,\n         -1.7410e-01, -1.3680e-01, -1.4399e-01, -1.1055e-01, -5.5506e-02,\n          1.7003e-01,  2.7864e-02,  1.2629e-01,  9.0148e-02, -1.4838e-01,\n          2.8298e-02,  5.0981e-02,  1.1078e-01,  2.6838e-02, -1.3986e-01,\n         -5.1482e-02,  1.6268e-01, -1.4506e-01, -1.3450e-01,  1.1823e-01,\n         -1.5427e-01,  1.2910e-01],\n        [ 8.5165e-02,  8.9313e-04,  8.1096e-02, -1.5505e-02,  1.1043e-01,\n          1.7205e-01, -7.6570e-02,  2.5697e-02, -1.4505e-01, -7.5563e-02,\n          4.6372e-02, -1.4666e-01, -1.0498e-01, -8.7353e-03, -7.4408e-02,\n         -2.9806e-02, -4.2609e-02, -1.3804e-01,  1.4225e-01,  1.1924e-01,\n          1.2734e-01, -1.2720e-01, -1.5310e-01, -3.3042e-02, -3.1167e-02,\n          1.0234e-01,  9.6330e-02,  2.6621e-02,  1.4689e-01,  4.9789e-02,\n         -5.2601e-02,  1.0067e-01],\n        [ 1.0226e-01,  1.4394e-01,  1.0977e-01,  1.7458e-01,  4.1568e-02,\n         -1.0473e-01,  1.2454e-01,  1.1786e-01, -4.2567e-02, -6.3477e-02,\n          1.4297e-01, -1.4283e-01, -1.1636e-01,  1.0556e-01, -1.2645e-01,\n          1.6831e-01,  3.8274e-02,  1.1963e-01, -5.4270e-02, -1.0408e-01,\n         -8.4112e-02,  8.6504e-02, -8.6969e-02, -1.2292e-01, -1.5622e-01,\n         -1.7438e-01,  2.3999e-02,  5.5096e-02, -1.5892e-01,  7.8700e-02,\n         -1.3634e-01,  1.6604e-02],\n        [-6.6550e-02, -1.1832e-01, -1.7390e-01,  8.5319e-02, -4.9584e-02,\n          4.6310e-02,  1.6975e-01,  1.4076e-01, -1.6446e-01,  1.1811e-01,\n          2.8958e-02,  3.9669e-03,  1.1540e-01, -1.6134e-01, -1.6015e-01,\n         -5.6537e-03,  3.9182e-02,  6.1757e-02, -9.3455e-02,  9.4669e-02,\n         -1.4418e-01, -1.4212e-04,  1.5964e-01,  9.3089e-02, -1.3768e-01,\n          1.1194e-01,  1.5557e-01,  1.7670e-01,  5.6898e-02, -1.6132e-01,\n          1.5243e-01, -6.9443e-02],\n        [ 8.3498e-03,  4.1549e-02, -8.7194e-02,  1.6221e-01, -1.5614e-01,\n         -1.6079e-02,  1.0486e-01, -1.2201e-01,  1.6999e-01,  6.7326e-02,\n         -7.5640e-02,  5.1699e-03, -1.3655e-02, -1.2676e-01, -1.6216e-01,\n         -5.2177e-02, -2.9708e-02, -3.6011e-02, -6.8490e-02,  8.4488e-02,\n          1.2745e-01, -9.2092e-02, -1.1470e-01, -4.5770e-02,  1.5368e-01,\n         -1.9329e-02,  1.3120e-01, -1.4196e-01, -8.9326e-02, -3.0075e-02,\n         -6.1087e-02, -8.4868e-02],\n        [ 1.7053e-02, -8.9274e-02,  1.1946e-01, -2.3472e-02, -1.2961e-01,\n          1.1951e-01,  1.5019e-01,  7.0537e-02, -6.5296e-02,  4.0968e-02,\n         -1.5347e-01, -1.1923e-01,  1.0753e-01, -1.8785e-02, -5.1661e-04,\n          4.4928e-02,  9.3724e-02,  1.2200e-01,  1.1313e-01, -2.9460e-02,\n          6.7341e-02, -7.7005e-02, -7.5378e-02, -7.9671e-02,  1.0428e-01,\n         -1.6937e-01,  8.9521e-02, -1.2460e-01,  1.4193e-01, -5.0100e-02,\n          6.7393e-03, -1.5036e-01],\n        [ 1.0466e-01, -3.3301e-02,  4.9401e-02, -9.5911e-02,  1.4871e-01,\n         -1.4377e-01, -3.3079e-02, -1.7598e-01, -1.6973e-01,  1.0486e-01,\n         -7.4213e-02, -1.6874e-01,  2.9903e-02, -6.0345e-02, -1.6158e-01,\n         -1.3230e-01,  1.4916e-01,  1.5706e-01,  1.6330e-01, -1.5914e-01,\n          4.2248e-02, -5.9720e-04, -1.5943e-01, -2.3052e-02,  1.4629e-01,\n          1.2133e-01, -1.3102e-01,  2.2929e-02,  1.3621e-01, -4.6882e-02,\n         -1.7660e-01,  7.4782e-02],\n        [ 1.3298e-01,  5.8640e-02, -1.3577e-01, -2.0413e-02, -1.2227e-01,\n         -1.0583e-01,  9.8547e-02,  1.4853e-01,  1.0083e-01,  1.3159e-01,\n         -1.0854e-01, -1.4855e-01,  6.6632e-02, -6.9240e-02,  5.4249e-02,\n          1.3078e-01,  7.4909e-02,  1.4765e-01, -4.0602e-02, -9.6154e-03,\n          9.6428e-02,  1.6455e-01, -3.4347e-02,  1.7103e-01,  3.5238e-03,\n          1.7513e-01, -1.5962e-01, -4.4932e-02, -5.2022e-02, -7.1543e-02,\n         -1.1606e-01,  1.0000e-01],\n        [ 6.8706e-02, -9.5311e-02,  1.7990e-02,  1.3900e-02,  8.9316e-02,\n          1.4111e-01, -5.0461e-02, -1.5489e-01,  3.2958e-02,  9.7992e-02,\n         -5.7002e-02,  1.4458e-01, -3.7833e-02,  9.1140e-02, -3.3631e-02,\n         -1.0290e-01, -1.2014e-01,  3.8049e-02, -1.1458e-01,  1.6495e-01,\n          1.6071e-01, -6.2270e-02, -1.4451e-01, -8.6310e-02, -1.6020e-01,\n         -3.2501e-02,  1.2827e-01, -1.5673e-01,  1.3137e-01,  1.0753e-03,\n          2.7668e-02,  5.2794e-02],\n        [ 9.5946e-02,  9.8314e-02, -5.5026e-02,  1.4290e-02, -1.1873e-01,\n          3.2975e-02,  1.4940e-01, -1.7255e-04, -1.3602e-01,  7.1283e-02,\n         -1.7104e-01, -6.4814e-02, -1.2080e-01, -6.3172e-02,  1.2751e-01,\n          1.0554e-01, -1.7512e-01,  6.2001e-02,  1.3095e-01, -1.5886e-01,\n          1.4165e-01,  3.5150e-04,  1.1376e-01,  1.2178e-01, -3.7860e-02,\n          1.4066e-01,  1.1790e-01, -6.9163e-02,  4.3990e-02, -3.7917e-02,\n          3.6816e-02, -2.8903e-02],\n        [-1.4931e-01,  1.0662e-01, -1.6799e-01, -8.4061e-02, -8.9556e-02,\n         -7.5738e-02,  1.0133e-01, -1.6444e-02, -1.4850e-01,  1.5958e-01,\n         -6.7027e-02,  1.5756e-01, -5.9524e-02,  1.6464e-01,  1.1211e-02,\n          1.6057e-01, -1.6643e-01, -1.6488e-01, -1.6552e-01,  9.6932e-02,\n         -8.7388e-02,  1.5534e-01,  1.7735e-02, -6.4731e-02,  1.4327e-01,\n          1.7738e-02, -3.1193e-02,  1.7293e-01,  6.3451e-02,  3.1067e-02,\n          3.1649e-02, -1.2477e-01],\n        [ 2.7136e-02, -1.5896e-01,  9.4702e-02, -1.6952e-01,  4.5405e-02,\n         -9.4745e-02,  8.3893e-02, -1.1937e-01, -5.3336e-02,  1.1436e-01,\n          4.5929e-02,  2.7227e-02,  9.4725e-02, -1.3172e-01,  1.3065e-02,\n          8.8957e-02, -1.0656e-01,  9.5721e-02, -5.8023e-02,  8.4449e-03,\n          1.0271e-01,  8.1291e-02, -1.4697e-01, -1.1546e-01,  1.6365e-02,\n         -1.4040e-01, -1.0018e-01,  8.6995e-02, -1.4577e-01,  8.6431e-02,\n          3.3309e-02,  9.5476e-02],\n        [-1.3867e-01,  7.2825e-02,  8.9928e-02,  7.0997e-02, -4.2358e-02,\n         -6.1025e-02, -9.8169e-02,  5.6531e-03,  1.4893e-01, -9.8392e-02,\n          1.1850e-01,  3.3973e-02, -1.3455e-02,  7.3737e-02,  1.6130e-01,\n         -9.2538e-02, -2.6704e-02,  4.8834e-02, -1.1509e-01, -6.4295e-02,\n          1.6333e-01,  5.9654e-02, -1.0540e-01, -9.0680e-02,  1.4288e-01,\n         -1.4882e-01, -1.1803e-01,  6.9252e-02, -2.8692e-02,  9.5437e-02,\n          1.3414e-01,  4.4385e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1088,  0.1453, -0.1569,  0.0738, -0.0809,  0.1566,  0.2114,  0.0484],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2065,  0.1467, -0.1650,  0.2127,  0.2414,  0.0956, -0.0279,  0.1208,\n          0.2491,  0.1173, -0.0342, -0.1278,  0.1466,  0.1757,  0.0921, -0.1875],\n        [-0.1658, -0.2361, -0.0977, -0.2279,  0.0372, -0.2037,  0.0765,  0.1580,\n          0.1183, -0.0910, -0.1223,  0.0467, -0.0314, -0.0644, -0.1557,  0.1003],\n        [ 0.1019,  0.1653,  0.1137, -0.1489,  0.2421, -0.2179, -0.0690,  0.2288,\n         -0.1719, -0.0773, -0.2255, -0.0118, -0.1827,  0.0597,  0.0424,  0.0827],\n        [-0.0566,  0.0511, -0.0846, -0.2463,  0.0401, -0.1607,  0.0500, -0.0378,\n          0.2231,  0.0686, -0.0693,  0.1469, -0.1632, -0.2464,  0.0035, -0.1184],\n        [-0.0011,  0.1481, -0.1624, -0.0718,  0.0943,  0.0753,  0.2083, -0.2088,\n          0.0703, -0.2452,  0.1104,  0.0773,  0.0603,  0.0562, -0.1115,  0.1663],\n        [ 0.1168,  0.2095,  0.1995,  0.1252, -0.2039, -0.1887,  0.0259,  0.0138,\n         -0.1267, -0.0071, -0.0460,  0.1711,  0.0067, -0.0091, -0.1062, -0.0192],\n        [-0.2488,  0.1722,  0.0210, -0.0492,  0.2312,  0.0301,  0.1432,  0.1907,\n         -0.0706,  0.1740,  0.0713, -0.2398, -0.0885,  0.0316,  0.2069, -0.1978],\n        [-0.2142,  0.1192,  0.0953, -0.0690,  0.2177, -0.2130, -0.0874,  0.0591,\n          0.1776, -0.2073, -0.0400, -0.1240, -0.0964,  0.0846,  0.2169, -0.0300]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3263,  0.1580, -0.3361,  0.0503], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3405,  0.1150, -0.2870, -0.1928,  0.0282,  0.0773, -0.3101, -0.2968],\n        [ 0.2721,  0.0098, -0.0431,  0.2105,  0.3289,  0.1563, -0.1869,  0.2866],\n        [-0.2439, -0.0336,  0.1291, -0.0909, -0.2507,  0.2906,  0.3407,  0.2058],\n        [ 0.1686, -0.3150, -0.0111, -0.1928,  0.2841,  0.2441,  0.1426,  0.3255]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	160,
            "_train_update_freq":	32,
            "_traj_per_epoch":	16,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7f4a2111a7d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s327440000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s327440000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	160,
    "train_update_freq":	32,
    "traj_per_epoch":	16
}