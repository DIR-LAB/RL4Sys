{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s329670000"
    },
    "q_lr":	0.0005,
    "seed":	329670000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7cfa1b50ccd0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2103, -0.1526,  0.2908,  0.1035,  0.2858, -0.2985, -0.3456,  0.0036,\n         0.2640, -0.1176, -0.1269,  0.3445, -0.0967,  0.0242, -0.1814,  0.2837,\n        -0.1395,  0.0520,  0.1108, -0.1877, -0.0296, -0.2283, -0.3408,  0.0992,\n        -0.2876, -0.3362, -0.1116, -0.3085,  0.3402, -0.2511,  0.3210, -0.0652],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.5374e-03, -4.5396e-02,  2.9389e-01, -1.0465e-01, -1.5113e-02,\n         -1.3793e-01,  2.3973e-02, -3.5050e-01],\n        [ 3.0769e-01,  1.3313e-01,  1.4891e-01, -1.1490e-01,  2.5089e-01,\n         -1.4342e-01,  9.8044e-02, -1.9260e-01],\n        [ 2.5649e-01,  1.5202e-01, -2.1352e-01, -1.6797e-02,  1.9639e-01,\n          1.2131e-01, -2.9756e-01, -3.4730e-02],\n        [-3.0348e-01,  5.2399e-02, -2.5880e-01, -2.2892e-01, -2.4128e-01,\n          3.0073e-01,  2.0653e-01, -4.6371e-02],\n        [-2.5694e-01, -2.0009e-01, -1.1523e-01,  2.7128e-01, -1.2667e-01,\n          3.3803e-01,  7.8782e-02, -2.7317e-01],\n        [ 1.9735e-01,  2.7014e-02, -3.4205e-01, -2.3034e-01, -3.1075e-01,\n          2.2409e-01,  3.4818e-01,  2.6071e-01],\n        [-1.6729e-01,  1.1393e-01,  1.0859e-01, -3.1976e-01, -2.0412e-02,\n         -5.0858e-02,  2.5533e-01, -2.0190e-02],\n        [-1.8738e-02, -2.1378e-01, -3.3939e-02,  1.5444e-01,  6.0397e-02,\n          1.2818e-01, -1.4997e-02,  2.8629e-01],\n        [-2.9065e-01, -1.9944e-01, -2.0719e-01,  1.0957e-01, -2.9661e-01,\n          1.2369e-01, -2.9108e-01, -1.9769e-01],\n        [-3.5096e-01,  2.3657e-01, -9.0431e-03,  3.4602e-01, -1.4015e-01,\n         -3.0791e-01,  1.9760e-01,  7.2584e-02],\n        [-2.1779e-01,  3.1865e-01, -2.2600e-01,  1.6508e-01,  2.0716e-01,\n          1.0437e-01, -3.3643e-01,  2.3856e-01],\n        [ 1.8618e-01,  7.5278e-02, -7.1288e-02, -8.9982e-02, -1.8415e-01,\n          3.1663e-01,  2.9926e-01,  2.8184e-01],\n        [-8.1745e-02,  1.6547e-02,  2.7097e-01,  3.1898e-01, -1.4082e-01,\n         -2.0984e-01, -1.3242e-01,  9.5747e-02],\n        [ 1.1903e-01, -1.2214e-01,  8.1835e-02,  2.0563e-01, -1.6071e-01,\n         -2.7210e-02, -2.2343e-01, -9.9597e-02],\n        [ 2.2120e-02,  1.0117e-01, -5.1775e-02, -1.8509e-01, -7.7962e-02,\n          1.2975e-01,  2.0592e-01, -1.6233e-01],\n        [-1.0449e-01,  2.4138e-01,  3.5209e-01, -2.4479e-01,  7.1727e-02,\n          6.7713e-02,  1.5888e-01,  3.0026e-01],\n        [ 2.1964e-01, -2.3313e-01,  2.6834e-01, -1.8840e-01, -2.9330e-01,\n         -3.2760e-01,  1.7320e-01, -4.4556e-02],\n        [ 8.0579e-02,  3.4383e-01, -8.7563e-02,  3.4249e-01,  1.4177e-02,\n          1.0699e-01,  3.2912e-01, -2.4592e-01],\n        [-1.6637e-01, -2.3013e-01,  2.6392e-01, -2.6110e-01,  2.3675e-02,\n          9.7861e-02,  1.3920e-01, -3.2338e-01],\n        [ 1.6591e-01, -1.0584e-02, -2.4811e-01, -6.6821e-02, -1.3505e-01,\n         -1.7784e-01, -6.8737e-02, -2.9221e-01],\n        [ 2.2172e-01,  1.5036e-01,  3.3909e-01,  2.9075e-01,  4.6568e-02,\n         -2.4401e-01,  3.3502e-01, -7.9095e-02],\n        [-1.9798e-02,  5.0182e-02,  2.2292e-01, -2.9358e-01,  8.4780e-02,\n         -1.8069e-02,  1.6181e-01, -2.8996e-02],\n        [ 2.3768e-01, -1.1424e-01, -2.5985e-01,  2.4402e-01,  3.2831e-01,\n         -1.5671e-01,  1.7173e-01, -2.9430e-01],\n        [-2.8052e-01,  2.1502e-01, -8.3217e-02, -2.8484e-02,  1.1703e-01,\n          3.2366e-01, -3.4331e-01,  1.8698e-01],\n        [ 3.0166e-01, -1.8948e-01,  1.6024e-01, -1.9429e-01,  8.3114e-02,\n         -1.4961e-01,  2.4503e-01, -7.6391e-02],\n        [-7.4679e-02, -1.6045e-01, -1.4823e-01,  2.8047e-01,  2.3404e-01,\n          3.3454e-01, -8.4462e-05,  2.8939e-01],\n        [ 2.2642e-01,  2.8955e-01, -1.7635e-01,  1.0365e-01, -4.9164e-02,\n          1.2730e-01, -2.0424e-01, -1.5685e-01],\n        [ 1.7242e-01,  2.6142e-01,  4.4452e-02, -1.1585e-01,  2.3942e-01,\n         -3.4939e-02, -3.1480e-01, -3.4860e-01],\n        [ 1.6458e-01, -2.6177e-01,  1.9591e-01, -2.6606e-01,  4.7019e-02,\n         -1.9968e-01, -3.4744e-01, -2.2722e-01],\n        [ 1.9273e-01, -2.6216e-01, -2.3735e-01,  2.6401e-01,  2.4244e-01,\n         -8.5654e-02, -1.9605e-01,  2.9586e-01],\n        [-2.7915e-01, -1.2538e-01, -8.0341e-02,  1.5371e-01, -1.4847e-01,\n         -1.0302e-01,  2.3145e-01,  1.0237e-01],\n        [ 4.9888e-02,  1.2924e-01,  3.2373e-01,  1.3056e-01,  6.6758e-02,\n         -2.2491e-01, -1.7157e-01, -3.2778e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1451,  0.0309, -0.1089,  0.0021,  0.1082,  0.1237,  0.1159, -0.0047,\n         0.0789, -0.1550,  0.1219,  0.0383,  0.1236,  0.1062,  0.1461, -0.1636],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0765, -0.0916,  0.0215,  0.1288, -0.1118,  0.0203, -0.1305, -0.0661,\n          0.1344,  0.1674, -0.1108, -0.1657,  0.1235,  0.1741,  0.0008,  0.0982,\n          0.0009, -0.0470, -0.0178,  0.0308, -0.0945,  0.1650,  0.0621, -0.0931,\n          0.0125,  0.0592,  0.1519, -0.1741,  0.1359, -0.1505,  0.1691,  0.1376],\n        [ 0.0925, -0.0470,  0.1059,  0.1208, -0.0921,  0.0559,  0.0991,  0.0277,\n          0.1663, -0.0246,  0.1761, -0.1274, -0.0191, -0.0831,  0.0104, -0.0818,\n         -0.0116, -0.1138, -0.0025, -0.0763, -0.0308,  0.1532, -0.0899,  0.0958,\n         -0.0119, -0.0922,  0.1264,  0.0652,  0.0341, -0.0071,  0.1224,  0.0414],\n        [ 0.0420, -0.0171,  0.1358, -0.0378,  0.1388,  0.1235,  0.1331,  0.1638,\n         -0.0572,  0.1358, -0.0721, -0.0500,  0.0729,  0.1676, -0.1701,  0.1469,\n          0.0711,  0.0036,  0.1544,  0.0483,  0.0247,  0.0457,  0.0392, -0.0288,\n         -0.0238,  0.0327,  0.1278, -0.0294,  0.0958,  0.0298,  0.1151,  0.0852],\n        [-0.0681, -0.0583, -0.0008,  0.1699, -0.1746, -0.1347,  0.0981, -0.0730,\n          0.1623,  0.1200, -0.0140,  0.1277, -0.0183,  0.0677,  0.0785, -0.1417,\n          0.0985, -0.0996, -0.0951, -0.1342,  0.0082, -0.0914, -0.1363, -0.0916,\n         -0.0046, -0.0199, -0.1569, -0.0638, -0.1427, -0.0341,  0.0140, -0.0378],\n        [ 0.1002,  0.0402,  0.0559, -0.1042,  0.0664,  0.1135, -0.1464,  0.0906,\n         -0.0940,  0.1360, -0.0406, -0.0240, -0.1219, -0.1072,  0.1245,  0.0110,\n          0.0819,  0.1319,  0.0171, -0.1341,  0.0751,  0.0072,  0.0423,  0.0727,\n          0.0888,  0.1389, -0.1117,  0.1480,  0.1584,  0.0048, -0.0735, -0.0015],\n        [-0.1000,  0.1123, -0.0455,  0.0879,  0.0914,  0.0394,  0.0658, -0.0127,\n          0.0746, -0.0950,  0.1761,  0.0583, -0.1138,  0.0057, -0.1467,  0.1034,\n          0.0629, -0.1684,  0.0902, -0.0570, -0.1595, -0.0217, -0.0849,  0.1242,\n          0.0523,  0.0759, -0.0063, -0.1486,  0.0361,  0.0564, -0.1014, -0.1051],\n        [-0.0372,  0.0104, -0.1253, -0.0700, -0.1632,  0.1037,  0.1283,  0.0438,\n         -0.0744,  0.0450,  0.1529, -0.0486, -0.1354, -0.1511,  0.1683, -0.1376,\n         -0.0333, -0.1362, -0.1222, -0.0277, -0.1142, -0.0073,  0.0309, -0.0215,\n          0.1677, -0.0506, -0.0874, -0.0717,  0.1442, -0.0108,  0.0722, -0.0937],\n        [-0.0956,  0.1360, -0.1148,  0.0570,  0.1016, -0.0198, -0.0239, -0.0844,\n         -0.1197,  0.0479,  0.0433, -0.0671,  0.1384, -0.1103,  0.1018, -0.1118,\n         -0.1523,  0.0630, -0.1317, -0.0292, -0.0941, -0.0569, -0.0551, -0.0270,\n          0.0622,  0.0769,  0.0578, -0.0985, -0.1130,  0.0172,  0.0502,  0.1642],\n        [-0.1401,  0.0205,  0.0833, -0.1602,  0.1293,  0.0199,  0.0638, -0.0542,\n          0.0416, -0.1485,  0.0804, -0.0468,  0.0208,  0.0696,  0.1303,  0.1213,\n         -0.0345,  0.0405,  0.1356,  0.0192,  0.0122, -0.0565,  0.1506, -0.1530,\n          0.0783,  0.0802,  0.1056, -0.0813, -0.0726, -0.1285, -0.1168, -0.0593],\n        [ 0.0465, -0.1530, -0.1694, -0.0013,  0.0241,  0.0918,  0.0376, -0.1282,\n          0.0209,  0.1504, -0.0337,  0.1752,  0.1617,  0.0080,  0.1484, -0.0242,\n         -0.0598,  0.1270, -0.0081,  0.0516, -0.1327,  0.1186,  0.0116, -0.0033,\n         -0.0876, -0.0852, -0.1695,  0.1197, -0.1406, -0.0553, -0.1167,  0.0624],\n        [-0.0868, -0.0622,  0.0377,  0.0936, -0.0489,  0.1628,  0.0514, -0.0628,\n          0.0876,  0.0439,  0.1504, -0.0311,  0.1001,  0.0053, -0.0888, -0.1293,\n          0.0495, -0.0059,  0.0514, -0.0480,  0.0120, -0.0811,  0.0612,  0.0429,\n         -0.0308, -0.0602,  0.1717,  0.1591,  0.1241,  0.0359, -0.1413,  0.1712],\n        [ 0.1068, -0.0773, -0.0649, -0.1072, -0.1372, -0.0694,  0.0992,  0.0732,\n         -0.1746,  0.0503, -0.0188, -0.1524, -0.1017, -0.0290, -0.0404, -0.0294,\n          0.0733, -0.0006,  0.0819,  0.1676,  0.1068, -0.1435, -0.0515, -0.1608,\n          0.1297, -0.1062,  0.0727, -0.1206,  0.0293, -0.0087, -0.0468,  0.1150],\n        [-0.0890, -0.0509,  0.0432, -0.1014, -0.1381, -0.0230, -0.0749, -0.1159,\n         -0.1670,  0.0391,  0.1643,  0.0949,  0.0574,  0.1640, -0.0234, -0.0885,\n          0.0801,  0.0702,  0.0222,  0.1245,  0.1511,  0.1748, -0.0298,  0.1104,\n         -0.0033, -0.0729, -0.0902,  0.1107, -0.0377,  0.0009,  0.0041,  0.0902],\n        [ 0.1265, -0.1295,  0.0549,  0.1098, -0.0579,  0.0882,  0.0666,  0.0660,\n         -0.0495,  0.0120, -0.0058, -0.0604, -0.0264,  0.0697, -0.1085,  0.1463,\n          0.0614, -0.0772, -0.0490,  0.1411, -0.1401,  0.1524, -0.0747, -0.0811,\n          0.0200, -0.1062, -0.0801, -0.0061, -0.0343, -0.0770, -0.0075, -0.0775],\n        [ 0.1711,  0.0898,  0.0254, -0.1441,  0.1129, -0.0530, -0.0267, -0.1620,\n          0.1048, -0.1328,  0.0571,  0.0994,  0.1757,  0.0871,  0.0804, -0.0311,\n         -0.1681,  0.1240,  0.0572, -0.1300, -0.1126, -0.0169,  0.1157, -0.0458,\n          0.0834, -0.1274,  0.1184, -0.1752, -0.0128, -0.0750,  0.1621,  0.1488],\n        [-0.1429, -0.1134,  0.1068,  0.0774,  0.1061,  0.0256, -0.1228,  0.1068,\n         -0.0086, -0.0284, -0.1244,  0.0133, -0.1605, -0.0222,  0.1140, -0.0933,\n         -0.1346, -0.0697, -0.0053, -0.0807,  0.0590, -0.0480,  0.1018, -0.0682,\n         -0.1748, -0.0060,  0.0578,  0.0733,  0.0884, -0.1067, -0.1209, -0.0148]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1771,  0.0959, -0.1270, -0.1170, -0.2155,  0.0097,  0.0928,  0.1125],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0383, -0.0266, -0.2086,  0.1500,  0.0360,  0.0247,  0.2203,  0.0194,\n          0.1976, -0.1690,  0.0863,  0.1201,  0.2038,  0.1848, -0.0941,  0.1826],\n        [ 0.1138, -0.0837,  0.1419,  0.0618, -0.2227,  0.0164,  0.0733,  0.1588,\n          0.0244,  0.0562,  0.0820,  0.1845,  0.0799, -0.2295, -0.0149, -0.2477],\n        [ 0.2360,  0.0071, -0.1623, -0.1331,  0.1257, -0.1826, -0.0187, -0.1757,\n          0.0243, -0.1659,  0.2045,  0.1912, -0.2210,  0.0848, -0.1381,  0.1285],\n        [-0.0753, -0.0510,  0.0911,  0.0876, -0.1035,  0.0239,  0.2499,  0.2060,\n         -0.0555,  0.1308, -0.0645, -0.0008, -0.0442, -0.1476,  0.0914, -0.0498],\n        [ 0.1873, -0.1937,  0.0133, -0.0813,  0.1221, -0.1557, -0.0438, -0.0593,\n         -0.1188, -0.1418, -0.0578,  0.0063,  0.2193, -0.1403,  0.0580,  0.1872],\n        [-0.0850, -0.1252, -0.2197,  0.1159,  0.1651,  0.0474, -0.1292,  0.1384,\n          0.1118, -0.0413, -0.2253,  0.2226,  0.2035,  0.1981, -0.2122, -0.0102],\n        [ 0.1133, -0.1856,  0.2016, -0.1511, -0.1442, -0.0894, -0.0106,  0.2185,\n          0.1137,  0.1293,  0.0233,  0.1740, -0.1691, -0.1001, -0.1867, -0.1600],\n        [-0.0052,  0.1724,  0.1126,  0.1997, -0.1442, -0.0726, -0.1855,  0.1617,\n         -0.0050,  0.0886, -0.0278, -0.1720,  0.1505,  0.1562, -0.1442,  0.0768]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1845, -0.2436,  0.1635, -0.2671], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.3293, -0.0089, -0.3057, -0.2547,  0.1904,  0.2957,  0.2875, -0.2266],\n        [ 0.0968, -0.2047,  0.2542, -0.1587, -0.2154,  0.2848, -0.2564, -0.2095],\n        [-0.0121, -0.1516, -0.0834,  0.0505, -0.2918, -0.0401, -0.2025,  0.1342],\n        [-0.2635,  0.2397,  0.2303,  0.2767,  0.2618, -0.1959, -0.1445, -0.2253]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 1.5374e-03, -4.5396e-02,  2.9389e-01, -1.0465e-01, -1.5113e-02,\n         -1.3793e-01,  2.3973e-02, -3.5050e-01],\n        [ 3.0769e-01,  1.3313e-01,  1.4891e-01, -1.1490e-01,  2.5089e-01,\n         -1.4342e-01,  9.8044e-02, -1.9260e-01],\n        [ 2.5649e-01,  1.5202e-01, -2.1352e-01, -1.6797e-02,  1.9639e-01,\n          1.2131e-01, -2.9756e-01, -3.4730e-02],\n        [-3.0348e-01,  5.2399e-02, -2.5880e-01, -2.2892e-01, -2.4128e-01,\n          3.0073e-01,  2.0653e-01, -4.6371e-02],\n        [-2.5694e-01, -2.0009e-01, -1.1523e-01,  2.7128e-01, -1.2667e-01,\n          3.3803e-01,  7.8782e-02, -2.7317e-01],\n        [ 1.9735e-01,  2.7014e-02, -3.4205e-01, -2.3034e-01, -3.1075e-01,\n          2.2409e-01,  3.4818e-01,  2.6071e-01],\n        [-1.6729e-01,  1.1393e-01,  1.0859e-01, -3.1976e-01, -2.0412e-02,\n         -5.0858e-02,  2.5533e-01, -2.0190e-02],\n        [-1.8738e-02, -2.1378e-01, -3.3939e-02,  1.5444e-01,  6.0397e-02,\n          1.2818e-01, -1.4997e-02,  2.8629e-01],\n        [-2.9065e-01, -1.9944e-01, -2.0719e-01,  1.0957e-01, -2.9661e-01,\n          1.2369e-01, -2.9108e-01, -1.9769e-01],\n        [-3.5096e-01,  2.3657e-01, -9.0431e-03,  3.4602e-01, -1.4015e-01,\n         -3.0791e-01,  1.9760e-01,  7.2584e-02],\n        [-2.1779e-01,  3.1865e-01, -2.2600e-01,  1.6508e-01,  2.0716e-01,\n          1.0437e-01, -3.3643e-01,  2.3856e-01],\n        [ 1.8618e-01,  7.5278e-02, -7.1288e-02, -8.9982e-02, -1.8415e-01,\n          3.1663e-01,  2.9926e-01,  2.8184e-01],\n        [-8.1745e-02,  1.6547e-02,  2.7097e-01,  3.1898e-01, -1.4082e-01,\n         -2.0984e-01, -1.3242e-01,  9.5747e-02],\n        [ 1.1903e-01, -1.2214e-01,  8.1835e-02,  2.0563e-01, -1.6071e-01,\n         -2.7210e-02, -2.2343e-01, -9.9597e-02],\n        [ 2.2120e-02,  1.0117e-01, -5.1775e-02, -1.8509e-01, -7.7962e-02,\n          1.2975e-01,  2.0592e-01, -1.6233e-01],\n        [-1.0449e-01,  2.4138e-01,  3.5209e-01, -2.4479e-01,  7.1727e-02,\n          6.7713e-02,  1.5888e-01,  3.0026e-01],\n        [ 2.1964e-01, -2.3313e-01,  2.6834e-01, -1.8840e-01, -2.9330e-01,\n         -3.2760e-01,  1.7320e-01, -4.4556e-02],\n        [ 8.0579e-02,  3.4383e-01, -8.7563e-02,  3.4249e-01,  1.4177e-02,\n          1.0699e-01,  3.2912e-01, -2.4592e-01],\n        [-1.6637e-01, -2.3013e-01,  2.6392e-01, -2.6110e-01,  2.3675e-02,\n          9.7861e-02,  1.3920e-01, -3.2338e-01],\n        [ 1.6591e-01, -1.0584e-02, -2.4811e-01, -6.6821e-02, -1.3505e-01,\n         -1.7784e-01, -6.8737e-02, -2.9221e-01],\n        [ 2.2172e-01,  1.5036e-01,  3.3909e-01,  2.9075e-01,  4.6568e-02,\n         -2.4401e-01,  3.3502e-01, -7.9095e-02],\n        [-1.9798e-02,  5.0182e-02,  2.2292e-01, -2.9358e-01,  8.4780e-02,\n         -1.8069e-02,  1.6181e-01, -2.8996e-02],\n        [ 2.3768e-01, -1.1424e-01, -2.5985e-01,  2.4402e-01,  3.2831e-01,\n         -1.5671e-01,  1.7173e-01, -2.9430e-01],\n        [-2.8052e-01,  2.1502e-01, -8.3217e-02, -2.8484e-02,  1.1703e-01,\n          3.2366e-01, -3.4331e-01,  1.8698e-01],\n        [ 3.0166e-01, -1.8948e-01,  1.6024e-01, -1.9429e-01,  8.3114e-02,\n         -1.4961e-01,  2.4503e-01, -7.6391e-02],\n        [-7.4679e-02, -1.6045e-01, -1.4823e-01,  2.8047e-01,  2.3404e-01,\n          3.3454e-01, -8.4462e-05,  2.8939e-01],\n        [ 2.2642e-01,  2.8955e-01, -1.7635e-01,  1.0365e-01, -4.9164e-02,\n          1.2730e-01, -2.0424e-01, -1.5685e-01],\n        [ 1.7242e-01,  2.6142e-01,  4.4452e-02, -1.1585e-01,  2.3942e-01,\n         -3.4939e-02, -3.1480e-01, -3.4860e-01],\n        [ 1.6458e-01, -2.6177e-01,  1.9591e-01, -2.6606e-01,  4.7019e-02,\n         -1.9968e-01, -3.4744e-01, -2.2722e-01],\n        [ 1.9273e-01, -2.6216e-01, -2.3735e-01,  2.6401e-01,  2.4244e-01,\n         -8.5654e-02, -1.9605e-01,  2.9586e-01],\n        [-2.7915e-01, -1.2538e-01, -8.0341e-02,  1.5371e-01, -1.4847e-01,\n         -1.0302e-01,  2.3145e-01,  1.0237e-01],\n        [ 4.9888e-02,  1.2924e-01,  3.2373e-01,  1.3056e-01,  6.6758e-02,\n         -2.2491e-01, -1.7157e-01, -3.2778e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2103, -0.1526,  0.2908,  0.1035,  0.2858, -0.2985, -0.3456,  0.0036,\n         0.2640, -0.1176, -0.1269,  0.3445, -0.0967,  0.0242, -0.1814,  0.2837,\n        -0.1395,  0.0520,  0.1108, -0.1877, -0.0296, -0.2283, -0.3408,  0.0992,\n        -0.2876, -0.3362, -0.1116, -0.3085,  0.3402, -0.2511,  0.3210, -0.0652],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0765, -0.0916,  0.0215,  0.1288, -0.1118,  0.0203, -0.1305, -0.0661,\n          0.1344,  0.1674, -0.1108, -0.1657,  0.1235,  0.1741,  0.0008,  0.0982,\n          0.0009, -0.0470, -0.0178,  0.0308, -0.0945,  0.1650,  0.0621, -0.0931,\n          0.0125,  0.0592,  0.1519, -0.1741,  0.1359, -0.1505,  0.1691,  0.1376],\n        [ 0.0925, -0.0470,  0.1059,  0.1208, -0.0921,  0.0559,  0.0991,  0.0277,\n          0.1663, -0.0246,  0.1761, -0.1274, -0.0191, -0.0831,  0.0104, -0.0818,\n         -0.0116, -0.1138, -0.0025, -0.0763, -0.0308,  0.1532, -0.0899,  0.0958,\n         -0.0119, -0.0922,  0.1264,  0.0652,  0.0341, -0.0071,  0.1224,  0.0414],\n        [ 0.0420, -0.0171,  0.1358, -0.0378,  0.1388,  0.1235,  0.1331,  0.1638,\n         -0.0572,  0.1358, -0.0721, -0.0500,  0.0729,  0.1676, -0.1701,  0.1469,\n          0.0711,  0.0036,  0.1544,  0.0483,  0.0247,  0.0457,  0.0392, -0.0288,\n         -0.0238,  0.0327,  0.1278, -0.0294,  0.0958,  0.0298,  0.1151,  0.0852],\n        [-0.0681, -0.0583, -0.0008,  0.1699, -0.1746, -0.1347,  0.0981, -0.0730,\n          0.1623,  0.1200, -0.0140,  0.1277, -0.0183,  0.0677,  0.0785, -0.1417,\n          0.0985, -0.0996, -0.0951, -0.1342,  0.0082, -0.0914, -0.1363, -0.0916,\n         -0.0046, -0.0199, -0.1569, -0.0638, -0.1427, -0.0341,  0.0140, -0.0378],\n        [ 0.1002,  0.0402,  0.0559, -0.1042,  0.0664,  0.1135, -0.1464,  0.0906,\n         -0.0940,  0.1360, -0.0406, -0.0240, -0.1219, -0.1072,  0.1245,  0.0110,\n          0.0819,  0.1319,  0.0171, -0.1341,  0.0751,  0.0072,  0.0423,  0.0727,\n          0.0888,  0.1389, -0.1117,  0.1480,  0.1584,  0.0048, -0.0735, -0.0015],\n        [-0.1000,  0.1123, -0.0455,  0.0879,  0.0914,  0.0394,  0.0658, -0.0127,\n          0.0746, -0.0950,  0.1761,  0.0583, -0.1138,  0.0057, -0.1467,  0.1034,\n          0.0629, -0.1684,  0.0902, -0.0570, -0.1595, -0.0217, -0.0849,  0.1242,\n          0.0523,  0.0759, -0.0063, -0.1486,  0.0361,  0.0564, -0.1014, -0.1051],\n        [-0.0372,  0.0104, -0.1253, -0.0700, -0.1632,  0.1037,  0.1283,  0.0438,\n         -0.0744,  0.0450,  0.1529, -0.0486, -0.1354, -0.1511,  0.1683, -0.1376,\n         -0.0333, -0.1362, -0.1222, -0.0277, -0.1142, -0.0073,  0.0309, -0.0215,\n          0.1677, -0.0506, -0.0874, -0.0717,  0.1442, -0.0108,  0.0722, -0.0937],\n        [-0.0956,  0.1360, -0.1148,  0.0570,  0.1016, -0.0198, -0.0239, -0.0844,\n         -0.1197,  0.0479,  0.0433, -0.0671,  0.1384, -0.1103,  0.1018, -0.1118,\n         -0.1523,  0.0630, -0.1317, -0.0292, -0.0941, -0.0569, -0.0551, -0.0270,\n          0.0622,  0.0769,  0.0578, -0.0985, -0.1130,  0.0172,  0.0502,  0.1642],\n        [-0.1401,  0.0205,  0.0833, -0.1602,  0.1293,  0.0199,  0.0638, -0.0542,\n          0.0416, -0.1485,  0.0804, -0.0468,  0.0208,  0.0696,  0.1303,  0.1213,\n         -0.0345,  0.0405,  0.1356,  0.0192,  0.0122, -0.0565,  0.1506, -0.1530,\n          0.0783,  0.0802,  0.1056, -0.0813, -0.0726, -0.1285, -0.1168, -0.0593],\n        [ 0.0465, -0.1530, -0.1694, -0.0013,  0.0241,  0.0918,  0.0376, -0.1282,\n          0.0209,  0.1504, -0.0337,  0.1752,  0.1617,  0.0080,  0.1484, -0.0242,\n         -0.0598,  0.1270, -0.0081,  0.0516, -0.1327,  0.1186,  0.0116, -0.0033,\n         -0.0876, -0.0852, -0.1695,  0.1197, -0.1406, -0.0553, -0.1167,  0.0624],\n        [-0.0868, -0.0622,  0.0377,  0.0936, -0.0489,  0.1628,  0.0514, -0.0628,\n          0.0876,  0.0439,  0.1504, -0.0311,  0.1001,  0.0053, -0.0888, -0.1293,\n          0.0495, -0.0059,  0.0514, -0.0480,  0.0120, -0.0811,  0.0612,  0.0429,\n         -0.0308, -0.0602,  0.1717,  0.1591,  0.1241,  0.0359, -0.1413,  0.1712],\n        [ 0.1068, -0.0773, -0.0649, -0.1072, -0.1372, -0.0694,  0.0992,  0.0732,\n         -0.1746,  0.0503, -0.0188, -0.1524, -0.1017, -0.0290, -0.0404, -0.0294,\n          0.0733, -0.0006,  0.0819,  0.1676,  0.1068, -0.1435, -0.0515, -0.1608,\n          0.1297, -0.1062,  0.0727, -0.1206,  0.0293, -0.0087, -0.0468,  0.1150],\n        [-0.0890, -0.0509,  0.0432, -0.1014, -0.1381, -0.0230, -0.0749, -0.1159,\n         -0.1670,  0.0391,  0.1643,  0.0949,  0.0574,  0.1640, -0.0234, -0.0885,\n          0.0801,  0.0702,  0.0222,  0.1245,  0.1511,  0.1748, -0.0298,  0.1104,\n         -0.0033, -0.0729, -0.0902,  0.1107, -0.0377,  0.0009,  0.0041,  0.0902],\n        [ 0.1265, -0.1295,  0.0549,  0.1098, -0.0579,  0.0882,  0.0666,  0.0660,\n         -0.0495,  0.0120, -0.0058, -0.0604, -0.0264,  0.0697, -0.1085,  0.1463,\n          0.0614, -0.0772, -0.0490,  0.1411, -0.1401,  0.1524, -0.0747, -0.0811,\n          0.0200, -0.1062, -0.0801, -0.0061, -0.0343, -0.0770, -0.0075, -0.0775],\n        [ 0.1711,  0.0898,  0.0254, -0.1441,  0.1129, -0.0530, -0.0267, -0.1620,\n          0.1048, -0.1328,  0.0571,  0.0994,  0.1757,  0.0871,  0.0804, -0.0311,\n         -0.1681,  0.1240,  0.0572, -0.1300, -0.1126, -0.0169,  0.1157, -0.0458,\n          0.0834, -0.1274,  0.1184, -0.1752, -0.0128, -0.0750,  0.1621,  0.1488],\n        [-0.1429, -0.1134,  0.1068,  0.0774,  0.1061,  0.0256, -0.1228,  0.1068,\n         -0.0086, -0.0284, -0.1244,  0.0133, -0.1605, -0.0222,  0.1140, -0.0933,\n         -0.1346, -0.0697, -0.0053, -0.0807,  0.0590, -0.0480,  0.1018, -0.0682,\n         -0.1748, -0.0060,  0.0578,  0.0733,  0.0884, -0.1067, -0.1209, -0.0148]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1451,  0.0309, -0.1089,  0.0021,  0.1082,  0.1237,  0.1159, -0.0047,\n         0.0789, -0.1550,  0.1219,  0.0383,  0.1236,  0.1062,  0.1461, -0.1636],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0383, -0.0266, -0.2086,  0.1500,  0.0360,  0.0247,  0.2203,  0.0194,\n          0.1976, -0.1690,  0.0863,  0.1201,  0.2038,  0.1848, -0.0941,  0.1826],\n        [ 0.1138, -0.0837,  0.1419,  0.0618, -0.2227,  0.0164,  0.0733,  0.1588,\n          0.0244,  0.0562,  0.0820,  0.1845,  0.0799, -0.2295, -0.0149, -0.2477],\n        [ 0.2360,  0.0071, -0.1623, -0.1331,  0.1257, -0.1826, -0.0187, -0.1757,\n          0.0243, -0.1659,  0.2045,  0.1912, -0.2210,  0.0848, -0.1381,  0.1285],\n        [-0.0753, -0.0510,  0.0911,  0.0876, -0.1035,  0.0239,  0.2499,  0.2060,\n         -0.0555,  0.1308, -0.0645, -0.0008, -0.0442, -0.1476,  0.0914, -0.0498],\n        [ 0.1873, -0.1937,  0.0133, -0.0813,  0.1221, -0.1557, -0.0438, -0.0593,\n         -0.1188, -0.1418, -0.0578,  0.0063,  0.2193, -0.1403,  0.0580,  0.1872],\n        [-0.0850, -0.1252, -0.2197,  0.1159,  0.1651,  0.0474, -0.1292,  0.1384,\n          0.1118, -0.0413, -0.2253,  0.2226,  0.2035,  0.1981, -0.2122, -0.0102],\n        [ 0.1133, -0.1856,  0.2016, -0.1511, -0.1442, -0.0894, -0.0106,  0.2185,\n          0.1137,  0.1293,  0.0233,  0.1740, -0.1691, -0.1001, -0.1867, -0.1600],\n        [-0.0052,  0.1724,  0.1126,  0.1997, -0.1442, -0.0726, -0.1855,  0.1617,\n         -0.0050,  0.0886, -0.0278, -0.1720,  0.1505,  0.1562, -0.1442,  0.0768]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1771,  0.0959, -0.1270, -0.1170, -0.2155,  0.0097,  0.0928,  0.1125],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3293, -0.0089, -0.3057, -0.2547,  0.1904,  0.2957,  0.2875, -0.2266],\n        [ 0.0968, -0.2047,  0.2542, -0.1587, -0.2154,  0.2848, -0.2564, -0.2095],\n        [-0.0121, -0.1516, -0.0834,  0.0505, -0.2918, -0.0401, -0.2025,  0.1342],\n        [-0.2635,  0.2397,  0.2303,  0.2767,  0.2618, -0.1959, -0.1445, -0.2253]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1845, -0.2436,  0.1635, -0.2671], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7cfa1b4fb110>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2103, -0.1526,  0.2908,  0.1035,  0.2858, -0.2985, -0.3456,  0.0036,\n         0.2640, -0.1176, -0.1269,  0.3445, -0.0967,  0.0242, -0.1814,  0.2837,\n        -0.1395,  0.0520,  0.1108, -0.1877, -0.0296, -0.2283, -0.3408,  0.0992,\n        -0.2876, -0.3362, -0.1116, -0.3085,  0.3402, -0.2511,  0.3210, -0.0652],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.5374e-03, -4.5396e-02,  2.9389e-01, -1.0465e-01, -1.5113e-02,\n         -1.3793e-01,  2.3973e-02, -3.5050e-01],\n        [ 3.0769e-01,  1.3313e-01,  1.4891e-01, -1.1490e-01,  2.5089e-01,\n         -1.4342e-01,  9.8044e-02, -1.9260e-01],\n        [ 2.5649e-01,  1.5202e-01, -2.1352e-01, -1.6797e-02,  1.9639e-01,\n          1.2131e-01, -2.9756e-01, -3.4730e-02],\n        [-3.0348e-01,  5.2399e-02, -2.5880e-01, -2.2892e-01, -2.4128e-01,\n          3.0073e-01,  2.0653e-01, -4.6371e-02],\n        [-2.5694e-01, -2.0009e-01, -1.1523e-01,  2.7128e-01, -1.2667e-01,\n          3.3803e-01,  7.8782e-02, -2.7317e-01],\n        [ 1.9735e-01,  2.7014e-02, -3.4205e-01, -2.3034e-01, -3.1075e-01,\n          2.2409e-01,  3.4818e-01,  2.6071e-01],\n        [-1.6729e-01,  1.1393e-01,  1.0859e-01, -3.1976e-01, -2.0412e-02,\n         -5.0858e-02,  2.5533e-01, -2.0190e-02],\n        [-1.8738e-02, -2.1378e-01, -3.3939e-02,  1.5444e-01,  6.0397e-02,\n          1.2818e-01, -1.4997e-02,  2.8629e-01],\n        [-2.9065e-01, -1.9944e-01, -2.0719e-01,  1.0957e-01, -2.9661e-01,\n          1.2369e-01, -2.9108e-01, -1.9769e-01],\n        [-3.5096e-01,  2.3657e-01, -9.0431e-03,  3.4602e-01, -1.4015e-01,\n         -3.0791e-01,  1.9760e-01,  7.2584e-02],\n        [-2.1779e-01,  3.1865e-01, -2.2600e-01,  1.6508e-01,  2.0716e-01,\n          1.0437e-01, -3.3643e-01,  2.3856e-01],\n        [ 1.8618e-01,  7.5278e-02, -7.1288e-02, -8.9982e-02, -1.8415e-01,\n          3.1663e-01,  2.9926e-01,  2.8184e-01],\n        [-8.1745e-02,  1.6547e-02,  2.7097e-01,  3.1898e-01, -1.4082e-01,\n         -2.0984e-01, -1.3242e-01,  9.5747e-02],\n        [ 1.1903e-01, -1.2214e-01,  8.1835e-02,  2.0563e-01, -1.6071e-01,\n         -2.7210e-02, -2.2343e-01, -9.9597e-02],\n        [ 2.2120e-02,  1.0117e-01, -5.1775e-02, -1.8509e-01, -7.7962e-02,\n          1.2975e-01,  2.0592e-01, -1.6233e-01],\n        [-1.0449e-01,  2.4138e-01,  3.5209e-01, -2.4479e-01,  7.1727e-02,\n          6.7713e-02,  1.5888e-01,  3.0026e-01],\n        [ 2.1964e-01, -2.3313e-01,  2.6834e-01, -1.8840e-01, -2.9330e-01,\n         -3.2760e-01,  1.7320e-01, -4.4556e-02],\n        [ 8.0579e-02,  3.4383e-01, -8.7563e-02,  3.4249e-01,  1.4177e-02,\n          1.0699e-01,  3.2912e-01, -2.4592e-01],\n        [-1.6637e-01, -2.3013e-01,  2.6392e-01, -2.6110e-01,  2.3675e-02,\n          9.7861e-02,  1.3920e-01, -3.2338e-01],\n        [ 1.6591e-01, -1.0584e-02, -2.4811e-01, -6.6821e-02, -1.3505e-01,\n         -1.7784e-01, -6.8737e-02, -2.9221e-01],\n        [ 2.2172e-01,  1.5036e-01,  3.3909e-01,  2.9075e-01,  4.6568e-02,\n         -2.4401e-01,  3.3502e-01, -7.9095e-02],\n        [-1.9798e-02,  5.0182e-02,  2.2292e-01, -2.9358e-01,  8.4780e-02,\n         -1.8069e-02,  1.6181e-01, -2.8996e-02],\n        [ 2.3768e-01, -1.1424e-01, -2.5985e-01,  2.4402e-01,  3.2831e-01,\n         -1.5671e-01,  1.7173e-01, -2.9430e-01],\n        [-2.8052e-01,  2.1502e-01, -8.3217e-02, -2.8484e-02,  1.1703e-01,\n          3.2366e-01, -3.4331e-01,  1.8698e-01],\n        [ 3.0166e-01, -1.8948e-01,  1.6024e-01, -1.9429e-01,  8.3114e-02,\n         -1.4961e-01,  2.4503e-01, -7.6391e-02],\n        [-7.4679e-02, -1.6045e-01, -1.4823e-01,  2.8047e-01,  2.3404e-01,\n          3.3454e-01, -8.4462e-05,  2.8939e-01],\n        [ 2.2642e-01,  2.8955e-01, -1.7635e-01,  1.0365e-01, -4.9164e-02,\n          1.2730e-01, -2.0424e-01, -1.5685e-01],\n        [ 1.7242e-01,  2.6142e-01,  4.4452e-02, -1.1585e-01,  2.3942e-01,\n         -3.4939e-02, -3.1480e-01, -3.4860e-01],\n        [ 1.6458e-01, -2.6177e-01,  1.9591e-01, -2.6606e-01,  4.7019e-02,\n         -1.9968e-01, -3.4744e-01, -2.2722e-01],\n        [ 1.9273e-01, -2.6216e-01, -2.3735e-01,  2.6401e-01,  2.4244e-01,\n         -8.5654e-02, -1.9605e-01,  2.9586e-01],\n        [-2.7915e-01, -1.2538e-01, -8.0341e-02,  1.5371e-01, -1.4847e-01,\n         -1.0302e-01,  2.3145e-01,  1.0237e-01],\n        [ 4.9888e-02,  1.2924e-01,  3.2373e-01,  1.3056e-01,  6.6758e-02,\n         -2.2491e-01, -1.7157e-01, -3.2778e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1451,  0.0309, -0.1089,  0.0021,  0.1082,  0.1237,  0.1159, -0.0047,\n         0.0789, -0.1550,  0.1219,  0.0383,  0.1236,  0.1062,  0.1461, -0.1636],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0765, -0.0916,  0.0215,  0.1288, -0.1118,  0.0203, -0.1305, -0.0661,\n          0.1344,  0.1674, -0.1108, -0.1657,  0.1235,  0.1741,  0.0008,  0.0982,\n          0.0009, -0.0470, -0.0178,  0.0308, -0.0945,  0.1650,  0.0621, -0.0931,\n          0.0125,  0.0592,  0.1519, -0.1741,  0.1359, -0.1505,  0.1691,  0.1376],\n        [ 0.0925, -0.0470,  0.1059,  0.1208, -0.0921,  0.0559,  0.0991,  0.0277,\n          0.1663, -0.0246,  0.1761, -0.1274, -0.0191, -0.0831,  0.0104, -0.0818,\n         -0.0116, -0.1138, -0.0025, -0.0763, -0.0308,  0.1532, -0.0899,  0.0958,\n         -0.0119, -0.0922,  0.1264,  0.0652,  0.0341, -0.0071,  0.1224,  0.0414],\n        [ 0.0420, -0.0171,  0.1358, -0.0378,  0.1388,  0.1235,  0.1331,  0.1638,\n         -0.0572,  0.1358, -0.0721, -0.0500,  0.0729,  0.1676, -0.1701,  0.1469,\n          0.0711,  0.0036,  0.1544,  0.0483,  0.0247,  0.0457,  0.0392, -0.0288,\n         -0.0238,  0.0327,  0.1278, -0.0294,  0.0958,  0.0298,  0.1151,  0.0852],\n        [-0.0681, -0.0583, -0.0008,  0.1699, -0.1746, -0.1347,  0.0981, -0.0730,\n          0.1623,  0.1200, -0.0140,  0.1277, -0.0183,  0.0677,  0.0785, -0.1417,\n          0.0985, -0.0996, -0.0951, -0.1342,  0.0082, -0.0914, -0.1363, -0.0916,\n         -0.0046, -0.0199, -0.1569, -0.0638, -0.1427, -0.0341,  0.0140, -0.0378],\n        [ 0.1002,  0.0402,  0.0559, -0.1042,  0.0664,  0.1135, -0.1464,  0.0906,\n         -0.0940,  0.1360, -0.0406, -0.0240, -0.1219, -0.1072,  0.1245,  0.0110,\n          0.0819,  0.1319,  0.0171, -0.1341,  0.0751,  0.0072,  0.0423,  0.0727,\n          0.0888,  0.1389, -0.1117,  0.1480,  0.1584,  0.0048, -0.0735, -0.0015],\n        [-0.1000,  0.1123, -0.0455,  0.0879,  0.0914,  0.0394,  0.0658, -0.0127,\n          0.0746, -0.0950,  0.1761,  0.0583, -0.1138,  0.0057, -0.1467,  0.1034,\n          0.0629, -0.1684,  0.0902, -0.0570, -0.1595, -0.0217, -0.0849,  0.1242,\n          0.0523,  0.0759, -0.0063, -0.1486,  0.0361,  0.0564, -0.1014, -0.1051],\n        [-0.0372,  0.0104, -0.1253, -0.0700, -0.1632,  0.1037,  0.1283,  0.0438,\n         -0.0744,  0.0450,  0.1529, -0.0486, -0.1354, -0.1511,  0.1683, -0.1376,\n         -0.0333, -0.1362, -0.1222, -0.0277, -0.1142, -0.0073,  0.0309, -0.0215,\n          0.1677, -0.0506, -0.0874, -0.0717,  0.1442, -0.0108,  0.0722, -0.0937],\n        [-0.0956,  0.1360, -0.1148,  0.0570,  0.1016, -0.0198, -0.0239, -0.0844,\n         -0.1197,  0.0479,  0.0433, -0.0671,  0.1384, -0.1103,  0.1018, -0.1118,\n         -0.1523,  0.0630, -0.1317, -0.0292, -0.0941, -0.0569, -0.0551, -0.0270,\n          0.0622,  0.0769,  0.0578, -0.0985, -0.1130,  0.0172,  0.0502,  0.1642],\n        [-0.1401,  0.0205,  0.0833, -0.1602,  0.1293,  0.0199,  0.0638, -0.0542,\n          0.0416, -0.1485,  0.0804, -0.0468,  0.0208,  0.0696,  0.1303,  0.1213,\n         -0.0345,  0.0405,  0.1356,  0.0192,  0.0122, -0.0565,  0.1506, -0.1530,\n          0.0783,  0.0802,  0.1056, -0.0813, -0.0726, -0.1285, -0.1168, -0.0593],\n        [ 0.0465, -0.1530, -0.1694, -0.0013,  0.0241,  0.0918,  0.0376, -0.1282,\n          0.0209,  0.1504, -0.0337,  0.1752,  0.1617,  0.0080,  0.1484, -0.0242,\n         -0.0598,  0.1270, -0.0081,  0.0516, -0.1327,  0.1186,  0.0116, -0.0033,\n         -0.0876, -0.0852, -0.1695,  0.1197, -0.1406, -0.0553, -0.1167,  0.0624],\n        [-0.0868, -0.0622,  0.0377,  0.0936, -0.0489,  0.1628,  0.0514, -0.0628,\n          0.0876,  0.0439,  0.1504, -0.0311,  0.1001,  0.0053, -0.0888, -0.1293,\n          0.0495, -0.0059,  0.0514, -0.0480,  0.0120, -0.0811,  0.0612,  0.0429,\n         -0.0308, -0.0602,  0.1717,  0.1591,  0.1241,  0.0359, -0.1413,  0.1712],\n        [ 0.1068, -0.0773, -0.0649, -0.1072, -0.1372, -0.0694,  0.0992,  0.0732,\n         -0.1746,  0.0503, -0.0188, -0.1524, -0.1017, -0.0290, -0.0404, -0.0294,\n          0.0733, -0.0006,  0.0819,  0.1676,  0.1068, -0.1435, -0.0515, -0.1608,\n          0.1297, -0.1062,  0.0727, -0.1206,  0.0293, -0.0087, -0.0468,  0.1150],\n        [-0.0890, -0.0509,  0.0432, -0.1014, -0.1381, -0.0230, -0.0749, -0.1159,\n         -0.1670,  0.0391,  0.1643,  0.0949,  0.0574,  0.1640, -0.0234, -0.0885,\n          0.0801,  0.0702,  0.0222,  0.1245,  0.1511,  0.1748, -0.0298,  0.1104,\n         -0.0033, -0.0729, -0.0902,  0.1107, -0.0377,  0.0009,  0.0041,  0.0902],\n        [ 0.1265, -0.1295,  0.0549,  0.1098, -0.0579,  0.0882,  0.0666,  0.0660,\n         -0.0495,  0.0120, -0.0058, -0.0604, -0.0264,  0.0697, -0.1085,  0.1463,\n          0.0614, -0.0772, -0.0490,  0.1411, -0.1401,  0.1524, -0.0747, -0.0811,\n          0.0200, -0.1062, -0.0801, -0.0061, -0.0343, -0.0770, -0.0075, -0.0775],\n        [ 0.1711,  0.0898,  0.0254, -0.1441,  0.1129, -0.0530, -0.0267, -0.1620,\n          0.1048, -0.1328,  0.0571,  0.0994,  0.1757,  0.0871,  0.0804, -0.0311,\n         -0.1681,  0.1240,  0.0572, -0.1300, -0.1126, -0.0169,  0.1157, -0.0458,\n          0.0834, -0.1274,  0.1184, -0.1752, -0.0128, -0.0750,  0.1621,  0.1488],\n        [-0.1429, -0.1134,  0.1068,  0.0774,  0.1061,  0.0256, -0.1228,  0.1068,\n         -0.0086, -0.0284, -0.1244,  0.0133, -0.1605, -0.0222,  0.1140, -0.0933,\n         -0.1346, -0.0697, -0.0053, -0.0807,  0.0590, -0.0480,  0.1018, -0.0682,\n         -0.1748, -0.0060,  0.0578,  0.0733,  0.0884, -0.1067, -0.1209, -0.0148]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1771,  0.0959, -0.1270, -0.1170, -0.2155,  0.0097,  0.0928,  0.1125],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0383, -0.0266, -0.2086,  0.1500,  0.0360,  0.0247,  0.2203,  0.0194,\n          0.1976, -0.1690,  0.0863,  0.1201,  0.2038,  0.1848, -0.0941,  0.1826],\n        [ 0.1138, -0.0837,  0.1419,  0.0618, -0.2227,  0.0164,  0.0733,  0.1588,\n          0.0244,  0.0562,  0.0820,  0.1845,  0.0799, -0.2295, -0.0149, -0.2477],\n        [ 0.2360,  0.0071, -0.1623, -0.1331,  0.1257, -0.1826, -0.0187, -0.1757,\n          0.0243, -0.1659,  0.2045,  0.1912, -0.2210,  0.0848, -0.1381,  0.1285],\n        [-0.0753, -0.0510,  0.0911,  0.0876, -0.1035,  0.0239,  0.2499,  0.2060,\n         -0.0555,  0.1308, -0.0645, -0.0008, -0.0442, -0.1476,  0.0914, -0.0498],\n        [ 0.1873, -0.1937,  0.0133, -0.0813,  0.1221, -0.1557, -0.0438, -0.0593,\n         -0.1188, -0.1418, -0.0578,  0.0063,  0.2193, -0.1403,  0.0580,  0.1872],\n        [-0.0850, -0.1252, -0.2197,  0.1159,  0.1651,  0.0474, -0.1292,  0.1384,\n          0.1118, -0.0413, -0.2253,  0.2226,  0.2035,  0.1981, -0.2122, -0.0102],\n        [ 0.1133, -0.1856,  0.2016, -0.1511, -0.1442, -0.0894, -0.0106,  0.2185,\n          0.1137,  0.1293,  0.0233,  0.1740, -0.1691, -0.1001, -0.1867, -0.1600],\n        [-0.0052,  0.1724,  0.1126,  0.1997, -0.1442, -0.0726, -0.1855,  0.1617,\n         -0.0050,  0.0886, -0.0278, -0.1720,  0.1505,  0.1562, -0.1442,  0.0768]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1845, -0.2436,  0.1635, -0.2671], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.3293, -0.0089, -0.3057, -0.2547,  0.1904,  0.2957,  0.2875, -0.2266],\n        [ 0.0968, -0.2047,  0.2542, -0.1587, -0.2154,  0.2848, -0.2564, -0.2095],\n        [-0.0121, -0.1516, -0.0834,  0.0505, -0.2918, -0.0401, -0.2025,  0.1342],\n        [-0.2635,  0.2397,  0.2303,  0.2767,  0.2618, -0.1959, -0.1445, -0.2253]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7cfa177fc090>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s329670000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s329670000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}