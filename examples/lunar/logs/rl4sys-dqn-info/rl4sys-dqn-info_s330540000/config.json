{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s330540000"
    },
    "q_lr":	0.0005,
    "seed":	330540000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7747b3dcb410>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3431, -0.2008,  0.2611, -0.0767, -0.0023, -0.0938, -0.1158,  0.1146,\n        -0.2445, -0.0037,  0.2779,  0.0089, -0.0759,  0.3331, -0.3226,  0.1907,\n         0.2616, -0.0644, -0.1335,  0.0981, -0.3010, -0.3096,  0.1142,  0.1753,\n         0.3311, -0.0456,  0.3097,  0.2428, -0.1555,  0.0697,  0.0628,  0.2217],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 7.0351e-02,  7.5223e-02,  2.1902e-01, -6.6133e-03, -2.1712e-01,\n          1.4284e-01,  5.5658e-02, -1.3670e-01],\n        [-3.2636e-01, -7.4376e-02, -8.5984e-03, -3.3988e-02, -3.1530e-01,\n          2.6097e-01, -1.6864e-01, -2.9825e-01],\n        [-2.4138e-01,  2.9988e-01, -8.2824e-02,  2.9697e-01, -1.0554e-01,\n         -3.2284e-01, -1.6754e-01, -3.4603e-01],\n        [ 2.1753e-01,  4.9226e-02, -2.5833e-01,  7.2996e-02,  2.6825e-01,\n         -2.4888e-01,  2.9775e-01, -3.4061e-01],\n        [ 1.8641e-01,  1.2527e-01, -1.7026e-01, -3.2552e-01, -2.8027e-01,\n          3.1821e-01, -1.4244e-01,  2.2106e-01],\n        [-7.0649e-02,  1.5692e-01,  1.7959e-01, -3.5261e-01,  4.4653e-02,\n          2.4525e-01, -1.3711e-01, -4.4710e-02],\n        [-1.9974e-01, -7.4551e-02, -1.5135e-01, -2.6975e-02,  2.9390e-01,\n          9.6642e-02,  2.0562e-01, -1.8749e-01],\n        [ 1.2836e-01, -1.2573e-01,  1.0229e-01,  1.2737e-01,  2.5733e-01,\n         -3.5173e-01, -9.3208e-04,  3.2196e-01],\n        [-5.6417e-02,  3.3831e-01, -2.1825e-01, -2.1976e-01,  2.3647e-01,\n         -2.4937e-02, -2.8609e-02,  3.3023e-01],\n        [ 1.1846e-01,  2.0421e-01,  3.9620e-02,  1.7018e-01,  2.2751e-01,\n         -3.0924e-01,  6.0296e-02,  3.6840e-02],\n        [ 1.1913e-01, -2.2662e-01, -1.2540e-02, -2.6131e-01,  3.4362e-01,\n         -2.3520e-01,  1.4143e-01,  3.4360e-01],\n        [ 1.0353e-01, -3.3613e-01,  3.0281e-01, -2.1336e-01, -4.7187e-02,\n          3.0085e-01,  2.6764e-01, -1.6574e-01],\n        [-3.1873e-01,  1.6575e-01,  1.3701e-01,  7.1273e-02,  1.8628e-01,\n         -3.4769e-01, -8.1999e-02, -1.5803e-01],\n        [-2.0903e-01, -1.0328e-01,  3.4023e-01, -2.7359e-01, -2.3112e-02,\n          1.3657e-01,  2.7109e-01, -1.2717e-01],\n        [-1.0828e-01,  3.2972e-01,  2.6562e-01,  2.7364e-01, -1.7252e-01,\n         -3.1175e-01,  5.2730e-02,  1.3714e-01],\n        [-3.1648e-01, -5.5411e-02,  2.5196e-01, -2.4166e-01, -3.2898e-01,\n         -2.8035e-01,  1.0795e-01,  2.2280e-01],\n        [ 4.0836e-02,  8.7210e-03,  1.6761e-01, -4.7006e-02,  8.1984e-03,\n          9.5534e-02,  1.6163e-01, -2.3309e-01],\n        [-1.5985e-01,  1.0198e-01, -2.4300e-01, -2.3607e-01,  5.4021e-02,\n          1.5307e-01,  1.8424e-02, -2.1397e-01],\n        [-3.2872e-01, -1.8998e-01,  1.1046e-01,  1.1599e-01, -3.1870e-01,\n          3.0941e-01, -2.2596e-01,  5.3482e-02],\n        [-2.0607e-01,  2.6384e-01, -1.8957e-01,  1.9783e-01,  1.2228e-01,\n         -3.2397e-01, -1.1359e-01,  2.4833e-01],\n        [ 2.7307e-01, -2.3381e-01, -1.3322e-01,  4.2827e-02,  2.3089e-01,\n         -7.6086e-02, -9.7054e-02,  1.1032e-01],\n        [-3.4661e-01,  3.3607e-01,  8.8257e-02,  2.5817e-01,  8.6597e-02,\n          1.9299e-01,  3.4151e-01,  3.2109e-01],\n        [ 1.1217e-01,  6.5835e-02, -1.1821e-01, -2.7716e-01, -1.6353e-01,\n          3.4672e-01,  1.7495e-01,  1.3594e-01],\n        [-2.9682e-01, -3.5100e-01,  2.6801e-01, -2.5345e-01, -6.3824e-02,\n          2.8149e-01,  9.9520e-02,  1.8803e-01],\n        [ 2.7397e-01, -1.0977e-01,  1.1608e-01,  3.4713e-01,  8.8347e-02,\n          3.9687e-02,  3.5048e-01,  3.2411e-01],\n        [-1.3074e-01, -3.0629e-01, -1.4718e-01,  1.3903e-01, -1.9309e-01,\n          8.2060e-02,  3.1939e-01, -2.9723e-01],\n        [ 2.2130e-01,  1.3905e-01, -2.4089e-01, -2.0631e-04, -2.8582e-01,\n         -1.9840e-01, -1.8774e-01,  8.7046e-02],\n        [ 3.2571e-01, -3.3083e-01,  9.2249e-02, -3.2356e-01,  8.9955e-02,\n         -2.8546e-01, -7.5525e-02, -2.8571e-01],\n        [ 7.5652e-02,  9.3257e-02,  3.9845e-02,  4.8303e-02, -1.7848e-01,\n          2.0520e-01, -1.3692e-01, -1.4227e-02],\n        [-2.7303e-01,  3.8511e-02,  2.0984e-01, -3.3932e-01,  1.0980e-01,\n          1.9158e-01,  1.3625e-01,  3.0443e-02],\n        [ 1.6506e-01,  3.0434e-01,  2.0678e-01, -6.9678e-02,  1.5495e-01,\n         -1.1979e-01, -1.2949e-01,  1.4910e-01],\n        [-3.0911e-01, -2.6194e-01, -4.8615e-02, -7.9165e-02, -9.9991e-02,\n          3.1139e-01,  9.5106e-02,  1.5677e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1314, -0.1208, -0.0304, -0.1304, -0.0128, -0.0367, -0.0462,  0.0289,\n         0.1171,  0.0268, -0.0870,  0.0160, -0.1516, -0.1003,  0.1363, -0.0720],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1609, -0.0311, -0.1441,  0.1697,  0.1679,  0.0555,  0.1313,  0.1047,\n         -0.1157, -0.1476, -0.1273, -0.0009,  0.1559, -0.0440, -0.0985, -0.1135,\n          0.1191,  0.1541,  0.0589,  0.0194, -0.1144,  0.1040, -0.0543,  0.1442,\n         -0.1191,  0.0556, -0.1749,  0.1356,  0.1516,  0.1002,  0.1552, -0.0022],\n        [-0.0042,  0.0167, -0.1105, -0.0026, -0.1310, -0.0202,  0.1321,  0.0935,\n         -0.1115,  0.1539,  0.0258, -0.0061,  0.0105, -0.1398,  0.0607, -0.0746,\n          0.0973, -0.0095,  0.1683, -0.1325, -0.0688,  0.0606,  0.1694, -0.0742,\n          0.0999, -0.1510, -0.0168,  0.0638, -0.0138, -0.1442, -0.0154,  0.0045],\n        [-0.0512, -0.0033, -0.1026,  0.1194,  0.1339,  0.1320, -0.1452, -0.0852,\n         -0.0780,  0.0605, -0.1175,  0.0338, -0.0505,  0.0039, -0.0184, -0.0087,\n         -0.0615,  0.0342,  0.0392,  0.1048, -0.1267, -0.0508,  0.0190,  0.1110,\n          0.0989, -0.0887, -0.0151,  0.0210,  0.1059, -0.1688,  0.0727,  0.0073],\n        [ 0.1042, -0.1513, -0.0046, -0.1727, -0.1208, -0.0022, -0.1540, -0.1143,\n         -0.0927,  0.1235,  0.1214, -0.1533, -0.0948, -0.0906, -0.0542, -0.0347,\n         -0.0604, -0.1361,  0.0526,  0.0438, -0.1318, -0.0339, -0.0453, -0.0267,\n         -0.0252, -0.0535, -0.1248,  0.0064, -0.0200,  0.1244,  0.0316, -0.0207],\n        [-0.0552,  0.0736, -0.1658, -0.1669,  0.0838, -0.1644,  0.1712, -0.0857,\n         -0.0963,  0.1195, -0.1410, -0.1380, -0.1166,  0.0709,  0.0989, -0.1744,\n         -0.0652,  0.0204,  0.1195,  0.0306,  0.1598,  0.1074,  0.1702,  0.1605,\n         -0.1215, -0.1410,  0.0570, -0.0926, -0.0233,  0.0691, -0.0916, -0.1482],\n        [ 0.0701,  0.1275, -0.0578, -0.1214,  0.1725, -0.1631, -0.0683, -0.0363,\n          0.0208, -0.0216, -0.1312,  0.1741,  0.0974,  0.1437, -0.1407, -0.1340,\n          0.1667, -0.0514, -0.1325, -0.0169, -0.0987,  0.1170, -0.0498,  0.1699,\n         -0.1090, -0.0120, -0.1252,  0.1235, -0.1397,  0.0455, -0.1728, -0.0811],\n        [-0.0698, -0.1288,  0.0343, -0.0549,  0.0424,  0.1174, -0.1185,  0.1650,\n         -0.1019, -0.0169,  0.1385, -0.1390, -0.0414, -0.1350, -0.0058,  0.0550,\n         -0.1693, -0.1698, -0.0216,  0.1591,  0.0560, -0.1540,  0.1038,  0.0237,\n          0.0884, -0.1307, -0.1642,  0.1279,  0.0745, -0.0590, -0.1746,  0.1044],\n        [-0.1477, -0.1272,  0.1457,  0.1348,  0.0369, -0.0305, -0.1184,  0.1490,\n          0.0879,  0.1075, -0.0939, -0.0428,  0.1694,  0.0840,  0.0334, -0.1014,\n         -0.0958,  0.1680, -0.1097,  0.1446,  0.0088, -0.1062,  0.1464,  0.1660,\n          0.1511,  0.1735, -0.0547,  0.1212, -0.0685, -0.0008, -0.1591, -0.1109],\n        [-0.0960, -0.0995,  0.1101,  0.0132,  0.0772, -0.0028,  0.0089, -0.0805,\n         -0.0453,  0.1436,  0.1723,  0.1241,  0.0719, -0.1187, -0.0817,  0.1625,\n         -0.1684, -0.0932, -0.0261, -0.1303, -0.0736, -0.0658,  0.1759, -0.0644,\n          0.0088,  0.0081,  0.0094, -0.0727,  0.1173, -0.0571,  0.0479, -0.1653],\n        [ 0.0625,  0.0930, -0.1424,  0.1335, -0.1400,  0.1273, -0.0550, -0.0045,\n         -0.0479,  0.1731,  0.1489, -0.1393,  0.1143,  0.0634, -0.0549, -0.1585,\n          0.1299, -0.0250, -0.0309, -0.0861, -0.0094,  0.0249, -0.0090,  0.1043,\n         -0.1554,  0.0583,  0.0607,  0.0486,  0.1455, -0.0034, -0.0891, -0.1387],\n        [ 0.1323, -0.0976,  0.0322,  0.0926, -0.0857,  0.1108,  0.0514, -0.0437,\n          0.1587,  0.0614, -0.0615,  0.0301,  0.1501,  0.1226,  0.0635, -0.0326,\n         -0.1454,  0.0481, -0.1063, -0.0145,  0.0896,  0.1417,  0.0045, -0.0590,\n          0.1156, -0.0237, -0.1663,  0.1012, -0.1275,  0.0122, -0.1413, -0.1152],\n        [ 0.1310,  0.0773,  0.0771,  0.0704,  0.0711, -0.0875,  0.1071, -0.1611,\n          0.0561,  0.1524, -0.0866,  0.0953, -0.0220,  0.0483, -0.0721, -0.1340,\n         -0.0476, -0.0883, -0.0799, -0.0468, -0.0689, -0.0987,  0.0476,  0.0827,\n         -0.0875,  0.0183, -0.0530,  0.0903,  0.1527,  0.0667,  0.0681,  0.0856],\n        [ 0.1738,  0.0760, -0.1747,  0.0936, -0.0860,  0.1488,  0.0997, -0.1555,\n         -0.1131, -0.0265,  0.1019,  0.0569, -0.1136, -0.0047,  0.0813,  0.0561,\n         -0.1192,  0.0761, -0.0361,  0.0598,  0.1512, -0.0600,  0.1311,  0.0659,\n         -0.0953,  0.0021, -0.0707, -0.0322, -0.1057,  0.1595, -0.0917, -0.1013],\n        [ 0.1123,  0.0858, -0.1432, -0.0176,  0.1477, -0.1597, -0.1103,  0.0528,\n          0.1341, -0.1758, -0.0666,  0.0151,  0.0313, -0.0169, -0.1341,  0.1401,\n          0.0806, -0.0761,  0.1578,  0.1481, -0.0986, -0.0237, -0.0922,  0.1700,\n         -0.0023,  0.1734,  0.0926,  0.1420,  0.0774,  0.0727,  0.0337,  0.1100],\n        [ 0.0923,  0.1211, -0.1362, -0.0742,  0.1568,  0.1171, -0.0059, -0.1403,\n         -0.0647, -0.1115,  0.0470,  0.0763,  0.1536,  0.0746,  0.0512,  0.1271,\n         -0.1485, -0.1614,  0.0948,  0.1440,  0.0351, -0.1243,  0.1357,  0.0456,\n          0.0391, -0.1603,  0.1613, -0.0410, -0.1235, -0.1561,  0.1649,  0.0660],\n        [ 0.1052,  0.0425,  0.0911,  0.0882, -0.1050,  0.1000, -0.0748, -0.0996,\n          0.1608, -0.0716,  0.0060,  0.0403, -0.0132, -0.0480,  0.1390, -0.1581,\n         -0.1402, -0.0148,  0.0761,  0.0931, -0.0139, -0.0253, -0.1559,  0.0857,\n         -0.0894, -0.1559, -0.1431, -0.1409,  0.1672, -0.0378,  0.1581, -0.1611]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0364, -0.1706,  0.0947, -0.0870, -0.0633,  0.1848,  0.1013, -0.0298],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1505,  0.0536,  0.0752, -0.0956, -0.0107, -0.1603, -0.1528, -0.2075,\n         -0.1206, -0.0110, -0.1794, -0.0174,  0.0813, -0.0006, -0.0437, -0.2168],\n        [-0.0661, -0.1533,  0.2432, -0.0615,  0.1003,  0.1308,  0.1666, -0.2212,\n          0.2418,  0.0187,  0.0125, -0.0368,  0.2435,  0.2345, -0.1169,  0.0361],\n        [ 0.1911, -0.1478,  0.2466, -0.1112,  0.1377, -0.2056, -0.2230, -0.0151,\n         -0.1807,  0.1271,  0.2274,  0.0556,  0.0027, -0.2255, -0.2307,  0.0411],\n        [ 0.1430, -0.1660,  0.1943,  0.0753, -0.2309,  0.0793,  0.1976,  0.1875,\n          0.0224, -0.0080,  0.0034,  0.0647, -0.0226, -0.1012, -0.1138, -0.0867],\n        [-0.0011,  0.0128, -0.0388,  0.2036,  0.1334, -0.0561,  0.0944,  0.0335,\n         -0.1303,  0.0454,  0.1460, -0.1114, -0.0381, -0.0859, -0.1456, -0.1281],\n        [-0.2249,  0.0590,  0.0404,  0.2049, -0.0865,  0.0700,  0.1080,  0.2235,\n          0.1621,  0.1621,  0.1989,  0.1056, -0.0206, -0.0112, -0.0273,  0.1383],\n        [-0.1385,  0.0245, -0.0812,  0.0986, -0.1413, -0.0446, -0.1244, -0.1838,\n          0.0836, -0.0139,  0.0321,  0.0056, -0.0163, -0.2193, -0.2009,  0.2247],\n        [-0.1415, -0.0027, -0.1664, -0.1743, -0.1760,  0.2217,  0.1313,  0.0693,\n         -0.1243,  0.0171, -0.1510, -0.1725,  0.0285,  0.1969, -0.1618, -0.1653]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.3290,  0.3463,  0.1791, -0.1167], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.3144, -0.2970,  0.3204,  0.1882,  0.0781, -0.1356,  0.3502,  0.0483],\n        [-0.1528,  0.1284,  0.3233, -0.0048, -0.2332,  0.0480, -0.2002, -0.2540],\n        [-0.0843,  0.1965, -0.1754,  0.2372,  0.2079, -0.0537,  0.1462,  0.0583],\n        [ 0.0302,  0.1943,  0.2278, -0.2914, -0.2939,  0.2186, -0.0316, -0.0974]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 7.0351e-02,  7.5223e-02,  2.1902e-01, -6.6133e-03, -2.1712e-01,\n          1.4284e-01,  5.5658e-02, -1.3670e-01],\n        [-3.2636e-01, -7.4376e-02, -8.5984e-03, -3.3988e-02, -3.1530e-01,\n          2.6097e-01, -1.6864e-01, -2.9825e-01],\n        [-2.4138e-01,  2.9988e-01, -8.2824e-02,  2.9697e-01, -1.0554e-01,\n         -3.2284e-01, -1.6754e-01, -3.4603e-01],\n        [ 2.1753e-01,  4.9226e-02, -2.5833e-01,  7.2996e-02,  2.6825e-01,\n         -2.4888e-01,  2.9775e-01, -3.4061e-01],\n        [ 1.8641e-01,  1.2527e-01, -1.7026e-01, -3.2552e-01, -2.8027e-01,\n          3.1821e-01, -1.4244e-01,  2.2106e-01],\n        [-7.0649e-02,  1.5692e-01,  1.7959e-01, -3.5261e-01,  4.4653e-02,\n          2.4525e-01, -1.3711e-01, -4.4710e-02],\n        [-1.9974e-01, -7.4551e-02, -1.5135e-01, -2.6975e-02,  2.9390e-01,\n          9.6642e-02,  2.0562e-01, -1.8749e-01],\n        [ 1.2836e-01, -1.2573e-01,  1.0229e-01,  1.2737e-01,  2.5733e-01,\n         -3.5173e-01, -9.3208e-04,  3.2196e-01],\n        [-5.6417e-02,  3.3831e-01, -2.1825e-01, -2.1976e-01,  2.3647e-01,\n         -2.4937e-02, -2.8609e-02,  3.3023e-01],\n        [ 1.1846e-01,  2.0421e-01,  3.9620e-02,  1.7018e-01,  2.2751e-01,\n         -3.0924e-01,  6.0296e-02,  3.6840e-02],\n        [ 1.1913e-01, -2.2662e-01, -1.2540e-02, -2.6131e-01,  3.4362e-01,\n         -2.3520e-01,  1.4143e-01,  3.4360e-01],\n        [ 1.0353e-01, -3.3613e-01,  3.0281e-01, -2.1336e-01, -4.7187e-02,\n          3.0085e-01,  2.6764e-01, -1.6574e-01],\n        [-3.1873e-01,  1.6575e-01,  1.3701e-01,  7.1273e-02,  1.8628e-01,\n         -3.4769e-01, -8.1999e-02, -1.5803e-01],\n        [-2.0903e-01, -1.0328e-01,  3.4023e-01, -2.7359e-01, -2.3112e-02,\n          1.3657e-01,  2.7109e-01, -1.2717e-01],\n        [-1.0828e-01,  3.2972e-01,  2.6562e-01,  2.7364e-01, -1.7252e-01,\n         -3.1175e-01,  5.2730e-02,  1.3714e-01],\n        [-3.1648e-01, -5.5411e-02,  2.5196e-01, -2.4166e-01, -3.2898e-01,\n         -2.8035e-01,  1.0795e-01,  2.2280e-01],\n        [ 4.0836e-02,  8.7210e-03,  1.6761e-01, -4.7006e-02,  8.1984e-03,\n          9.5534e-02,  1.6163e-01, -2.3309e-01],\n        [-1.5985e-01,  1.0198e-01, -2.4300e-01, -2.3607e-01,  5.4021e-02,\n          1.5307e-01,  1.8424e-02, -2.1397e-01],\n        [-3.2872e-01, -1.8998e-01,  1.1046e-01,  1.1599e-01, -3.1870e-01,\n          3.0941e-01, -2.2596e-01,  5.3482e-02],\n        [-2.0607e-01,  2.6384e-01, -1.8957e-01,  1.9783e-01,  1.2228e-01,\n         -3.2397e-01, -1.1359e-01,  2.4833e-01],\n        [ 2.7307e-01, -2.3381e-01, -1.3322e-01,  4.2827e-02,  2.3089e-01,\n         -7.6086e-02, -9.7054e-02,  1.1032e-01],\n        [-3.4661e-01,  3.3607e-01,  8.8257e-02,  2.5817e-01,  8.6597e-02,\n          1.9299e-01,  3.4151e-01,  3.2109e-01],\n        [ 1.1217e-01,  6.5835e-02, -1.1821e-01, -2.7716e-01, -1.6353e-01,\n          3.4672e-01,  1.7495e-01,  1.3594e-01],\n        [-2.9682e-01, -3.5100e-01,  2.6801e-01, -2.5345e-01, -6.3824e-02,\n          2.8149e-01,  9.9520e-02,  1.8803e-01],\n        [ 2.7397e-01, -1.0977e-01,  1.1608e-01,  3.4713e-01,  8.8347e-02,\n          3.9687e-02,  3.5048e-01,  3.2411e-01],\n        [-1.3074e-01, -3.0629e-01, -1.4718e-01,  1.3903e-01, -1.9309e-01,\n          8.2060e-02,  3.1939e-01, -2.9723e-01],\n        [ 2.2130e-01,  1.3905e-01, -2.4089e-01, -2.0631e-04, -2.8582e-01,\n         -1.9840e-01, -1.8774e-01,  8.7046e-02],\n        [ 3.2571e-01, -3.3083e-01,  9.2249e-02, -3.2356e-01,  8.9955e-02,\n         -2.8546e-01, -7.5525e-02, -2.8571e-01],\n        [ 7.5652e-02,  9.3257e-02,  3.9845e-02,  4.8303e-02, -1.7848e-01,\n          2.0520e-01, -1.3692e-01, -1.4227e-02],\n        [-2.7303e-01,  3.8511e-02,  2.0984e-01, -3.3932e-01,  1.0980e-01,\n          1.9158e-01,  1.3625e-01,  3.0443e-02],\n        [ 1.6506e-01,  3.0434e-01,  2.0678e-01, -6.9678e-02,  1.5495e-01,\n         -1.1979e-01, -1.2949e-01,  1.4910e-01],\n        [-3.0911e-01, -2.6194e-01, -4.8615e-02, -7.9165e-02, -9.9991e-02,\n          3.1139e-01,  9.5106e-02,  1.5677e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3431, -0.2008,  0.2611, -0.0767, -0.0023, -0.0938, -0.1158,  0.1146,\n        -0.2445, -0.0037,  0.2779,  0.0089, -0.0759,  0.3331, -0.3226,  0.1907,\n         0.2616, -0.0644, -0.1335,  0.0981, -0.3010, -0.3096,  0.1142,  0.1753,\n         0.3311, -0.0456,  0.3097,  0.2428, -0.1555,  0.0697,  0.0628,  0.2217],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1609, -0.0311, -0.1441,  0.1697,  0.1679,  0.0555,  0.1313,  0.1047,\n         -0.1157, -0.1476, -0.1273, -0.0009,  0.1559, -0.0440, -0.0985, -0.1135,\n          0.1191,  0.1541,  0.0589,  0.0194, -0.1144,  0.1040, -0.0543,  0.1442,\n         -0.1191,  0.0556, -0.1749,  0.1356,  0.1516,  0.1002,  0.1552, -0.0022],\n        [-0.0042,  0.0167, -0.1105, -0.0026, -0.1310, -0.0202,  0.1321,  0.0935,\n         -0.1115,  0.1539,  0.0258, -0.0061,  0.0105, -0.1398,  0.0607, -0.0746,\n          0.0973, -0.0095,  0.1683, -0.1325, -0.0688,  0.0606,  0.1694, -0.0742,\n          0.0999, -0.1510, -0.0168,  0.0638, -0.0138, -0.1442, -0.0154,  0.0045],\n        [-0.0512, -0.0033, -0.1026,  0.1194,  0.1339,  0.1320, -0.1452, -0.0852,\n         -0.0780,  0.0605, -0.1175,  0.0338, -0.0505,  0.0039, -0.0184, -0.0087,\n         -0.0615,  0.0342,  0.0392,  0.1048, -0.1267, -0.0508,  0.0190,  0.1110,\n          0.0989, -0.0887, -0.0151,  0.0210,  0.1059, -0.1688,  0.0727,  0.0073],\n        [ 0.1042, -0.1513, -0.0046, -0.1727, -0.1208, -0.0022, -0.1540, -0.1143,\n         -0.0927,  0.1235,  0.1214, -0.1533, -0.0948, -0.0906, -0.0542, -0.0347,\n         -0.0604, -0.1361,  0.0526,  0.0438, -0.1318, -0.0339, -0.0453, -0.0267,\n         -0.0252, -0.0535, -0.1248,  0.0064, -0.0200,  0.1244,  0.0316, -0.0207],\n        [-0.0552,  0.0736, -0.1658, -0.1669,  0.0838, -0.1644,  0.1712, -0.0857,\n         -0.0963,  0.1195, -0.1410, -0.1380, -0.1166,  0.0709,  0.0989, -0.1744,\n         -0.0652,  0.0204,  0.1195,  0.0306,  0.1598,  0.1074,  0.1702,  0.1605,\n         -0.1215, -0.1410,  0.0570, -0.0926, -0.0233,  0.0691, -0.0916, -0.1482],\n        [ 0.0701,  0.1275, -0.0578, -0.1214,  0.1725, -0.1631, -0.0683, -0.0363,\n          0.0208, -0.0216, -0.1312,  0.1741,  0.0974,  0.1437, -0.1407, -0.1340,\n          0.1667, -0.0514, -0.1325, -0.0169, -0.0987,  0.1170, -0.0498,  0.1699,\n         -0.1090, -0.0120, -0.1252,  0.1235, -0.1397,  0.0455, -0.1728, -0.0811],\n        [-0.0698, -0.1288,  0.0343, -0.0549,  0.0424,  0.1174, -0.1185,  0.1650,\n         -0.1019, -0.0169,  0.1385, -0.1390, -0.0414, -0.1350, -0.0058,  0.0550,\n         -0.1693, -0.1698, -0.0216,  0.1591,  0.0560, -0.1540,  0.1038,  0.0237,\n          0.0884, -0.1307, -0.1642,  0.1279,  0.0745, -0.0590, -0.1746,  0.1044],\n        [-0.1477, -0.1272,  0.1457,  0.1348,  0.0369, -0.0305, -0.1184,  0.1490,\n          0.0879,  0.1075, -0.0939, -0.0428,  0.1694,  0.0840,  0.0334, -0.1014,\n         -0.0958,  0.1680, -0.1097,  0.1446,  0.0088, -0.1062,  0.1464,  0.1660,\n          0.1511,  0.1735, -0.0547,  0.1212, -0.0685, -0.0008, -0.1591, -0.1109],\n        [-0.0960, -0.0995,  0.1101,  0.0132,  0.0772, -0.0028,  0.0089, -0.0805,\n         -0.0453,  0.1436,  0.1723,  0.1241,  0.0719, -0.1187, -0.0817,  0.1625,\n         -0.1684, -0.0932, -0.0261, -0.1303, -0.0736, -0.0658,  0.1759, -0.0644,\n          0.0088,  0.0081,  0.0094, -0.0727,  0.1173, -0.0571,  0.0479, -0.1653],\n        [ 0.0625,  0.0930, -0.1424,  0.1335, -0.1400,  0.1273, -0.0550, -0.0045,\n         -0.0479,  0.1731,  0.1489, -0.1393,  0.1143,  0.0634, -0.0549, -0.1585,\n          0.1299, -0.0250, -0.0309, -0.0861, -0.0094,  0.0249, -0.0090,  0.1043,\n         -0.1554,  0.0583,  0.0607,  0.0486,  0.1455, -0.0034, -0.0891, -0.1387],\n        [ 0.1323, -0.0976,  0.0322,  0.0926, -0.0857,  0.1108,  0.0514, -0.0437,\n          0.1587,  0.0614, -0.0615,  0.0301,  0.1501,  0.1226,  0.0635, -0.0326,\n         -0.1454,  0.0481, -0.1063, -0.0145,  0.0896,  0.1417,  0.0045, -0.0590,\n          0.1156, -0.0237, -0.1663,  0.1012, -0.1275,  0.0122, -0.1413, -0.1152],\n        [ 0.1310,  0.0773,  0.0771,  0.0704,  0.0711, -0.0875,  0.1071, -0.1611,\n          0.0561,  0.1524, -0.0866,  0.0953, -0.0220,  0.0483, -0.0721, -0.1340,\n         -0.0476, -0.0883, -0.0799, -0.0468, -0.0689, -0.0987,  0.0476,  0.0827,\n         -0.0875,  0.0183, -0.0530,  0.0903,  0.1527,  0.0667,  0.0681,  0.0856],\n        [ 0.1738,  0.0760, -0.1747,  0.0936, -0.0860,  0.1488,  0.0997, -0.1555,\n         -0.1131, -0.0265,  0.1019,  0.0569, -0.1136, -0.0047,  0.0813,  0.0561,\n         -0.1192,  0.0761, -0.0361,  0.0598,  0.1512, -0.0600,  0.1311,  0.0659,\n         -0.0953,  0.0021, -0.0707, -0.0322, -0.1057,  0.1595, -0.0917, -0.1013],\n        [ 0.1123,  0.0858, -0.1432, -0.0176,  0.1477, -0.1597, -0.1103,  0.0528,\n          0.1341, -0.1758, -0.0666,  0.0151,  0.0313, -0.0169, -0.1341,  0.1401,\n          0.0806, -0.0761,  0.1578,  0.1481, -0.0986, -0.0237, -0.0922,  0.1700,\n         -0.0023,  0.1734,  0.0926,  0.1420,  0.0774,  0.0727,  0.0337,  0.1100],\n        [ 0.0923,  0.1211, -0.1362, -0.0742,  0.1568,  0.1171, -0.0059, -0.1403,\n         -0.0647, -0.1115,  0.0470,  0.0763,  0.1536,  0.0746,  0.0512,  0.1271,\n         -0.1485, -0.1614,  0.0948,  0.1440,  0.0351, -0.1243,  0.1357,  0.0456,\n          0.0391, -0.1603,  0.1613, -0.0410, -0.1235, -0.1561,  0.1649,  0.0660],\n        [ 0.1052,  0.0425,  0.0911,  0.0882, -0.1050,  0.1000, -0.0748, -0.0996,\n          0.1608, -0.0716,  0.0060,  0.0403, -0.0132, -0.0480,  0.1390, -0.1581,\n         -0.1402, -0.0148,  0.0761,  0.0931, -0.0139, -0.0253, -0.1559,  0.0857,\n         -0.0894, -0.1559, -0.1431, -0.1409,  0.1672, -0.0378,  0.1581, -0.1611]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1314, -0.1208, -0.0304, -0.1304, -0.0128, -0.0367, -0.0462,  0.0289,\n         0.1171,  0.0268, -0.0870,  0.0160, -0.1516, -0.1003,  0.1363, -0.0720],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1505,  0.0536,  0.0752, -0.0956, -0.0107, -0.1603, -0.1528, -0.2075,\n         -0.1206, -0.0110, -0.1794, -0.0174,  0.0813, -0.0006, -0.0437, -0.2168],\n        [-0.0661, -0.1533,  0.2432, -0.0615,  0.1003,  0.1308,  0.1666, -0.2212,\n          0.2418,  0.0187,  0.0125, -0.0368,  0.2435,  0.2345, -0.1169,  0.0361],\n        [ 0.1911, -0.1478,  0.2466, -0.1112,  0.1377, -0.2056, -0.2230, -0.0151,\n         -0.1807,  0.1271,  0.2274,  0.0556,  0.0027, -0.2255, -0.2307,  0.0411],\n        [ 0.1430, -0.1660,  0.1943,  0.0753, -0.2309,  0.0793,  0.1976,  0.1875,\n          0.0224, -0.0080,  0.0034,  0.0647, -0.0226, -0.1012, -0.1138, -0.0867],\n        [-0.0011,  0.0128, -0.0388,  0.2036,  0.1334, -0.0561,  0.0944,  0.0335,\n         -0.1303,  0.0454,  0.1460, -0.1114, -0.0381, -0.0859, -0.1456, -0.1281],\n        [-0.2249,  0.0590,  0.0404,  0.2049, -0.0865,  0.0700,  0.1080,  0.2235,\n          0.1621,  0.1621,  0.1989,  0.1056, -0.0206, -0.0112, -0.0273,  0.1383],\n        [-0.1385,  0.0245, -0.0812,  0.0986, -0.1413, -0.0446, -0.1244, -0.1838,\n          0.0836, -0.0139,  0.0321,  0.0056, -0.0163, -0.2193, -0.2009,  0.2247],\n        [-0.1415, -0.0027, -0.1664, -0.1743, -0.1760,  0.2217,  0.1313,  0.0693,\n         -0.1243,  0.0171, -0.1510, -0.1725,  0.0285,  0.1969, -0.1618, -0.1653]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0364, -0.1706,  0.0947, -0.0870, -0.0633,  0.1848,  0.1013, -0.0298],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3144, -0.2970,  0.3204,  0.1882,  0.0781, -0.1356,  0.3502,  0.0483],\n        [-0.1528,  0.1284,  0.3233, -0.0048, -0.2332,  0.0480, -0.2002, -0.2540],\n        [-0.0843,  0.1965, -0.1754,  0.2372,  0.2079, -0.0537,  0.1462,  0.0583],\n        [ 0.0302,  0.1943,  0.2278, -0.2914, -0.2939,  0.2186, -0.0316, -0.0974]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.3290,  0.3463,  0.1791, -0.1167], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x77482abdcdd0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3431, -0.2008,  0.2611, -0.0767, -0.0023, -0.0938, -0.1158,  0.1146,\n        -0.2445, -0.0037,  0.2779,  0.0089, -0.0759,  0.3331, -0.3226,  0.1907,\n         0.2616, -0.0644, -0.1335,  0.0981, -0.3010, -0.3096,  0.1142,  0.1753,\n         0.3311, -0.0456,  0.3097,  0.2428, -0.1555,  0.0697,  0.0628,  0.2217],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 7.0351e-02,  7.5223e-02,  2.1902e-01, -6.6133e-03, -2.1712e-01,\n          1.4284e-01,  5.5658e-02, -1.3670e-01],\n        [-3.2636e-01, -7.4376e-02, -8.5984e-03, -3.3988e-02, -3.1530e-01,\n          2.6097e-01, -1.6864e-01, -2.9825e-01],\n        [-2.4138e-01,  2.9988e-01, -8.2824e-02,  2.9697e-01, -1.0554e-01,\n         -3.2284e-01, -1.6754e-01, -3.4603e-01],\n        [ 2.1753e-01,  4.9226e-02, -2.5833e-01,  7.2996e-02,  2.6825e-01,\n         -2.4888e-01,  2.9775e-01, -3.4061e-01],\n        [ 1.8641e-01,  1.2527e-01, -1.7026e-01, -3.2552e-01, -2.8027e-01,\n          3.1821e-01, -1.4244e-01,  2.2106e-01],\n        [-7.0649e-02,  1.5692e-01,  1.7959e-01, -3.5261e-01,  4.4653e-02,\n          2.4525e-01, -1.3711e-01, -4.4710e-02],\n        [-1.9974e-01, -7.4551e-02, -1.5135e-01, -2.6975e-02,  2.9390e-01,\n          9.6642e-02,  2.0562e-01, -1.8749e-01],\n        [ 1.2836e-01, -1.2573e-01,  1.0229e-01,  1.2737e-01,  2.5733e-01,\n         -3.5173e-01, -9.3208e-04,  3.2196e-01],\n        [-5.6417e-02,  3.3831e-01, -2.1825e-01, -2.1976e-01,  2.3647e-01,\n         -2.4937e-02, -2.8609e-02,  3.3023e-01],\n        [ 1.1846e-01,  2.0421e-01,  3.9620e-02,  1.7018e-01,  2.2751e-01,\n         -3.0924e-01,  6.0296e-02,  3.6840e-02],\n        [ 1.1913e-01, -2.2662e-01, -1.2540e-02, -2.6131e-01,  3.4362e-01,\n         -2.3520e-01,  1.4143e-01,  3.4360e-01],\n        [ 1.0353e-01, -3.3613e-01,  3.0281e-01, -2.1336e-01, -4.7187e-02,\n          3.0085e-01,  2.6764e-01, -1.6574e-01],\n        [-3.1873e-01,  1.6575e-01,  1.3701e-01,  7.1273e-02,  1.8628e-01,\n         -3.4769e-01, -8.1999e-02, -1.5803e-01],\n        [-2.0903e-01, -1.0328e-01,  3.4023e-01, -2.7359e-01, -2.3112e-02,\n          1.3657e-01,  2.7109e-01, -1.2717e-01],\n        [-1.0828e-01,  3.2972e-01,  2.6562e-01,  2.7364e-01, -1.7252e-01,\n         -3.1175e-01,  5.2730e-02,  1.3714e-01],\n        [-3.1648e-01, -5.5411e-02,  2.5196e-01, -2.4166e-01, -3.2898e-01,\n         -2.8035e-01,  1.0795e-01,  2.2280e-01],\n        [ 4.0836e-02,  8.7210e-03,  1.6761e-01, -4.7006e-02,  8.1984e-03,\n          9.5534e-02,  1.6163e-01, -2.3309e-01],\n        [-1.5985e-01,  1.0198e-01, -2.4300e-01, -2.3607e-01,  5.4021e-02,\n          1.5307e-01,  1.8424e-02, -2.1397e-01],\n        [-3.2872e-01, -1.8998e-01,  1.1046e-01,  1.1599e-01, -3.1870e-01,\n          3.0941e-01, -2.2596e-01,  5.3482e-02],\n        [-2.0607e-01,  2.6384e-01, -1.8957e-01,  1.9783e-01,  1.2228e-01,\n         -3.2397e-01, -1.1359e-01,  2.4833e-01],\n        [ 2.7307e-01, -2.3381e-01, -1.3322e-01,  4.2827e-02,  2.3089e-01,\n         -7.6086e-02, -9.7054e-02,  1.1032e-01],\n        [-3.4661e-01,  3.3607e-01,  8.8257e-02,  2.5817e-01,  8.6597e-02,\n          1.9299e-01,  3.4151e-01,  3.2109e-01],\n        [ 1.1217e-01,  6.5835e-02, -1.1821e-01, -2.7716e-01, -1.6353e-01,\n          3.4672e-01,  1.7495e-01,  1.3594e-01],\n        [-2.9682e-01, -3.5100e-01,  2.6801e-01, -2.5345e-01, -6.3824e-02,\n          2.8149e-01,  9.9520e-02,  1.8803e-01],\n        [ 2.7397e-01, -1.0977e-01,  1.1608e-01,  3.4713e-01,  8.8347e-02,\n          3.9687e-02,  3.5048e-01,  3.2411e-01],\n        [-1.3074e-01, -3.0629e-01, -1.4718e-01,  1.3903e-01, -1.9309e-01,\n          8.2060e-02,  3.1939e-01, -2.9723e-01],\n        [ 2.2130e-01,  1.3905e-01, -2.4089e-01, -2.0631e-04, -2.8582e-01,\n         -1.9840e-01, -1.8774e-01,  8.7046e-02],\n        [ 3.2571e-01, -3.3083e-01,  9.2249e-02, -3.2356e-01,  8.9955e-02,\n         -2.8546e-01, -7.5525e-02, -2.8571e-01],\n        [ 7.5652e-02,  9.3257e-02,  3.9845e-02,  4.8303e-02, -1.7848e-01,\n          2.0520e-01, -1.3692e-01, -1.4227e-02],\n        [-2.7303e-01,  3.8511e-02,  2.0984e-01, -3.3932e-01,  1.0980e-01,\n          1.9158e-01,  1.3625e-01,  3.0443e-02],\n        [ 1.6506e-01,  3.0434e-01,  2.0678e-01, -6.9678e-02,  1.5495e-01,\n         -1.1979e-01, -1.2949e-01,  1.4910e-01],\n        [-3.0911e-01, -2.6194e-01, -4.8615e-02, -7.9165e-02, -9.9991e-02,\n          3.1139e-01,  9.5106e-02,  1.5677e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1314, -0.1208, -0.0304, -0.1304, -0.0128, -0.0367, -0.0462,  0.0289,\n         0.1171,  0.0268, -0.0870,  0.0160, -0.1516, -0.1003,  0.1363, -0.0720],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1609, -0.0311, -0.1441,  0.1697,  0.1679,  0.0555,  0.1313,  0.1047,\n         -0.1157, -0.1476, -0.1273, -0.0009,  0.1559, -0.0440, -0.0985, -0.1135,\n          0.1191,  0.1541,  0.0589,  0.0194, -0.1144,  0.1040, -0.0543,  0.1442,\n         -0.1191,  0.0556, -0.1749,  0.1356,  0.1516,  0.1002,  0.1552, -0.0022],\n        [-0.0042,  0.0167, -0.1105, -0.0026, -0.1310, -0.0202,  0.1321,  0.0935,\n         -0.1115,  0.1539,  0.0258, -0.0061,  0.0105, -0.1398,  0.0607, -0.0746,\n          0.0973, -0.0095,  0.1683, -0.1325, -0.0688,  0.0606,  0.1694, -0.0742,\n          0.0999, -0.1510, -0.0168,  0.0638, -0.0138, -0.1442, -0.0154,  0.0045],\n        [-0.0512, -0.0033, -0.1026,  0.1194,  0.1339,  0.1320, -0.1452, -0.0852,\n         -0.0780,  0.0605, -0.1175,  0.0338, -0.0505,  0.0039, -0.0184, -0.0087,\n         -0.0615,  0.0342,  0.0392,  0.1048, -0.1267, -0.0508,  0.0190,  0.1110,\n          0.0989, -0.0887, -0.0151,  0.0210,  0.1059, -0.1688,  0.0727,  0.0073],\n        [ 0.1042, -0.1513, -0.0046, -0.1727, -0.1208, -0.0022, -0.1540, -0.1143,\n         -0.0927,  0.1235,  0.1214, -0.1533, -0.0948, -0.0906, -0.0542, -0.0347,\n         -0.0604, -0.1361,  0.0526,  0.0438, -0.1318, -0.0339, -0.0453, -0.0267,\n         -0.0252, -0.0535, -0.1248,  0.0064, -0.0200,  0.1244,  0.0316, -0.0207],\n        [-0.0552,  0.0736, -0.1658, -0.1669,  0.0838, -0.1644,  0.1712, -0.0857,\n         -0.0963,  0.1195, -0.1410, -0.1380, -0.1166,  0.0709,  0.0989, -0.1744,\n         -0.0652,  0.0204,  0.1195,  0.0306,  0.1598,  0.1074,  0.1702,  0.1605,\n         -0.1215, -0.1410,  0.0570, -0.0926, -0.0233,  0.0691, -0.0916, -0.1482],\n        [ 0.0701,  0.1275, -0.0578, -0.1214,  0.1725, -0.1631, -0.0683, -0.0363,\n          0.0208, -0.0216, -0.1312,  0.1741,  0.0974,  0.1437, -0.1407, -0.1340,\n          0.1667, -0.0514, -0.1325, -0.0169, -0.0987,  0.1170, -0.0498,  0.1699,\n         -0.1090, -0.0120, -0.1252,  0.1235, -0.1397,  0.0455, -0.1728, -0.0811],\n        [-0.0698, -0.1288,  0.0343, -0.0549,  0.0424,  0.1174, -0.1185,  0.1650,\n         -0.1019, -0.0169,  0.1385, -0.1390, -0.0414, -0.1350, -0.0058,  0.0550,\n         -0.1693, -0.1698, -0.0216,  0.1591,  0.0560, -0.1540,  0.1038,  0.0237,\n          0.0884, -0.1307, -0.1642,  0.1279,  0.0745, -0.0590, -0.1746,  0.1044],\n        [-0.1477, -0.1272,  0.1457,  0.1348,  0.0369, -0.0305, -0.1184,  0.1490,\n          0.0879,  0.1075, -0.0939, -0.0428,  0.1694,  0.0840,  0.0334, -0.1014,\n         -0.0958,  0.1680, -0.1097,  0.1446,  0.0088, -0.1062,  0.1464,  0.1660,\n          0.1511,  0.1735, -0.0547,  0.1212, -0.0685, -0.0008, -0.1591, -0.1109],\n        [-0.0960, -0.0995,  0.1101,  0.0132,  0.0772, -0.0028,  0.0089, -0.0805,\n         -0.0453,  0.1436,  0.1723,  0.1241,  0.0719, -0.1187, -0.0817,  0.1625,\n         -0.1684, -0.0932, -0.0261, -0.1303, -0.0736, -0.0658,  0.1759, -0.0644,\n          0.0088,  0.0081,  0.0094, -0.0727,  0.1173, -0.0571,  0.0479, -0.1653],\n        [ 0.0625,  0.0930, -0.1424,  0.1335, -0.1400,  0.1273, -0.0550, -0.0045,\n         -0.0479,  0.1731,  0.1489, -0.1393,  0.1143,  0.0634, -0.0549, -0.1585,\n          0.1299, -0.0250, -0.0309, -0.0861, -0.0094,  0.0249, -0.0090,  0.1043,\n         -0.1554,  0.0583,  0.0607,  0.0486,  0.1455, -0.0034, -0.0891, -0.1387],\n        [ 0.1323, -0.0976,  0.0322,  0.0926, -0.0857,  0.1108,  0.0514, -0.0437,\n          0.1587,  0.0614, -0.0615,  0.0301,  0.1501,  0.1226,  0.0635, -0.0326,\n         -0.1454,  0.0481, -0.1063, -0.0145,  0.0896,  0.1417,  0.0045, -0.0590,\n          0.1156, -0.0237, -0.1663,  0.1012, -0.1275,  0.0122, -0.1413, -0.1152],\n        [ 0.1310,  0.0773,  0.0771,  0.0704,  0.0711, -0.0875,  0.1071, -0.1611,\n          0.0561,  0.1524, -0.0866,  0.0953, -0.0220,  0.0483, -0.0721, -0.1340,\n         -0.0476, -0.0883, -0.0799, -0.0468, -0.0689, -0.0987,  0.0476,  0.0827,\n         -0.0875,  0.0183, -0.0530,  0.0903,  0.1527,  0.0667,  0.0681,  0.0856],\n        [ 0.1738,  0.0760, -0.1747,  0.0936, -0.0860,  0.1488,  0.0997, -0.1555,\n         -0.1131, -0.0265,  0.1019,  0.0569, -0.1136, -0.0047,  0.0813,  0.0561,\n         -0.1192,  0.0761, -0.0361,  0.0598,  0.1512, -0.0600,  0.1311,  0.0659,\n         -0.0953,  0.0021, -0.0707, -0.0322, -0.1057,  0.1595, -0.0917, -0.1013],\n        [ 0.1123,  0.0858, -0.1432, -0.0176,  0.1477, -0.1597, -0.1103,  0.0528,\n          0.1341, -0.1758, -0.0666,  0.0151,  0.0313, -0.0169, -0.1341,  0.1401,\n          0.0806, -0.0761,  0.1578,  0.1481, -0.0986, -0.0237, -0.0922,  0.1700,\n         -0.0023,  0.1734,  0.0926,  0.1420,  0.0774,  0.0727,  0.0337,  0.1100],\n        [ 0.0923,  0.1211, -0.1362, -0.0742,  0.1568,  0.1171, -0.0059, -0.1403,\n         -0.0647, -0.1115,  0.0470,  0.0763,  0.1536,  0.0746,  0.0512,  0.1271,\n         -0.1485, -0.1614,  0.0948,  0.1440,  0.0351, -0.1243,  0.1357,  0.0456,\n          0.0391, -0.1603,  0.1613, -0.0410, -0.1235, -0.1561,  0.1649,  0.0660],\n        [ 0.1052,  0.0425,  0.0911,  0.0882, -0.1050,  0.1000, -0.0748, -0.0996,\n          0.1608, -0.0716,  0.0060,  0.0403, -0.0132, -0.0480,  0.1390, -0.1581,\n         -0.1402, -0.0148,  0.0761,  0.0931, -0.0139, -0.0253, -0.1559,  0.0857,\n         -0.0894, -0.1559, -0.1431, -0.1409,  0.1672, -0.0378,  0.1581, -0.1611]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0364, -0.1706,  0.0947, -0.0870, -0.0633,  0.1848,  0.1013, -0.0298],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1505,  0.0536,  0.0752, -0.0956, -0.0107, -0.1603, -0.1528, -0.2075,\n         -0.1206, -0.0110, -0.1794, -0.0174,  0.0813, -0.0006, -0.0437, -0.2168],\n        [-0.0661, -0.1533,  0.2432, -0.0615,  0.1003,  0.1308,  0.1666, -0.2212,\n          0.2418,  0.0187,  0.0125, -0.0368,  0.2435,  0.2345, -0.1169,  0.0361],\n        [ 0.1911, -0.1478,  0.2466, -0.1112,  0.1377, -0.2056, -0.2230, -0.0151,\n         -0.1807,  0.1271,  0.2274,  0.0556,  0.0027, -0.2255, -0.2307,  0.0411],\n        [ 0.1430, -0.1660,  0.1943,  0.0753, -0.2309,  0.0793,  0.1976,  0.1875,\n          0.0224, -0.0080,  0.0034,  0.0647, -0.0226, -0.1012, -0.1138, -0.0867],\n        [-0.0011,  0.0128, -0.0388,  0.2036,  0.1334, -0.0561,  0.0944,  0.0335,\n         -0.1303,  0.0454,  0.1460, -0.1114, -0.0381, -0.0859, -0.1456, -0.1281],\n        [-0.2249,  0.0590,  0.0404,  0.2049, -0.0865,  0.0700,  0.1080,  0.2235,\n          0.1621,  0.1621,  0.1989,  0.1056, -0.0206, -0.0112, -0.0273,  0.1383],\n        [-0.1385,  0.0245, -0.0812,  0.0986, -0.1413, -0.0446, -0.1244, -0.1838,\n          0.0836, -0.0139,  0.0321,  0.0056, -0.0163, -0.2193, -0.2009,  0.2247],\n        [-0.1415, -0.0027, -0.1664, -0.1743, -0.1760,  0.2217,  0.1313,  0.0693,\n         -0.1243,  0.0171, -0.1510, -0.1725,  0.0285,  0.1969, -0.1618, -0.1653]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.3290,  0.3463,  0.1791, -0.1167], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.3144, -0.2970,  0.3204,  0.1882,  0.0781, -0.1356,  0.3502,  0.0483],\n        [-0.1528,  0.1284,  0.3233, -0.0048, -0.2332,  0.0480, -0.2002, -0.2540],\n        [-0.0843,  0.1965, -0.1754,  0.2372,  0.2079, -0.0537,  0.1462,  0.0583],\n        [ 0.0302,  0.1943,  0.2278, -0.2914, -0.2939,  0.2186, -0.0316, -0.0974]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7747a8704290>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s330540000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s330540000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}