{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s331870000"
    },
    "q_lr":	0.0005,
    "seed":	331870000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x74a40b4ca990>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1622, -0.3367, -0.0169, -0.0210,  0.2346, -0.2902,  0.0445, -0.0688,\n        -0.0678, -0.3423,  0.2528, -0.3257,  0.3217, -0.1723,  0.1786, -0.1548,\n         0.1983, -0.0928,  0.2914, -0.2494, -0.0613,  0.3334, -0.1256,  0.0906,\n         0.2697, -0.2186,  0.3457, -0.0047, -0.1692, -0.0326, -0.1100,  0.2832],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1341, -0.3242, -0.0049,  0.1578,  0.0085,  0.0719, -0.3146, -0.2332],\n        [ 0.0745,  0.0679,  0.0408, -0.2683,  0.3267, -0.0016,  0.2675, -0.1128],\n        [-0.1392,  0.2758,  0.2484,  0.0805, -0.1359,  0.2299, -0.3057,  0.2890],\n        [ 0.2217, -0.0832, -0.1169,  0.1803,  0.0024, -0.0318,  0.2829,  0.0641],\n        [-0.2839, -0.2562, -0.3005,  0.3405, -0.2080, -0.0363,  0.2369,  0.0267],\n        [-0.0139, -0.0971,  0.1953, -0.1752, -0.2169,  0.2054,  0.2773,  0.3216],\n        [-0.0822,  0.3410, -0.2289, -0.3040, -0.1865, -0.0034,  0.0099, -0.0716],\n        [ 0.3522,  0.0315,  0.1595, -0.0780, -0.1733,  0.2320, -0.1211, -0.1307],\n        [ 0.1094,  0.2891, -0.0698, -0.1237, -0.2471,  0.0330,  0.0046,  0.2165],\n        [ 0.1295, -0.3123, -0.1543, -0.2271,  0.2423,  0.1507,  0.2538, -0.1864],\n        [ 0.0777, -0.0017, -0.3344, -0.1302, -0.2753, -0.2745, -0.1035, -0.0063],\n        [ 0.0514,  0.1879,  0.3060, -0.2446, -0.0728, -0.1984,  0.1593, -0.2134],\n        [-0.3026, -0.0157,  0.2052, -0.0775,  0.2941, -0.1676,  0.3057,  0.3506],\n        [ 0.2397, -0.1222,  0.2236, -0.3458,  0.1930,  0.1908, -0.3042,  0.2310],\n        [ 0.2364, -0.2497, -0.2896, -0.0698, -0.1004,  0.2731,  0.1833, -0.0876],\n        [-0.3091, -0.1536, -0.0394,  0.0782, -0.1844,  0.2551,  0.2389,  0.3395],\n        [ 0.2568,  0.1021, -0.1790, -0.1077, -0.1764,  0.2584, -0.2955,  0.1526],\n        [ 0.1054, -0.0740, -0.0509,  0.1116,  0.0684,  0.0877,  0.0253,  0.2786],\n        [ 0.3508, -0.1575, -0.0571,  0.1120, -0.1487, -0.1845, -0.3140,  0.2616],\n        [-0.2960,  0.0550, -0.1603,  0.3378,  0.2857, -0.2210, -0.0889, -0.2468],\n        [ 0.1674, -0.1719,  0.1494,  0.2028, -0.1430, -0.1430, -0.1231, -0.1262],\n        [ 0.1056,  0.1493, -0.1296,  0.1968,  0.2754,  0.1178, -0.0064,  0.3019],\n        [-0.0090,  0.0436, -0.0161, -0.0855, -0.0011, -0.1743,  0.1493, -0.2372],\n        [ 0.0686, -0.1981,  0.3385, -0.0562, -0.0720,  0.1783,  0.2127, -0.2348],\n        [ 0.0402,  0.0073,  0.1966,  0.0569,  0.3065,  0.1764,  0.3469, -0.0333],\n        [ 0.2968, -0.0459,  0.1011, -0.0348,  0.3168, -0.2669, -0.1295,  0.3299],\n        [-0.1054,  0.1574, -0.2621,  0.1445, -0.3224, -0.0068,  0.1837, -0.2833],\n        [ 0.2053,  0.2483,  0.1726, -0.2762,  0.2496, -0.1306,  0.2421, -0.1566],\n        [ 0.0543,  0.0275, -0.1718, -0.0849, -0.2042,  0.0863,  0.1054, -0.0089],\n        [-0.3344,  0.3065, -0.0107, -0.1180,  0.3343, -0.1934, -0.2208,  0.0963],\n        [ 0.2439,  0.1447,  0.0546,  0.3266,  0.1429, -0.0280,  0.2917, -0.3248],\n        [-0.1959, -0.2114,  0.0200, -0.0315, -0.1777,  0.2081, -0.1498, -0.0710]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0108, -0.0666,  0.0532,  0.1533,  0.0566, -0.1420, -0.0888,  0.1073,\n        -0.0814, -0.1278, -0.1347, -0.0473,  0.1763,  0.1751, -0.1053, -0.0585],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.2633e-01,  1.3243e-01, -1.5934e-01, -1.2791e-01,  1.4979e-01,\n          8.9069e-02,  5.4658e-02,  1.5604e-01,  1.3145e-01, -8.7115e-02,\n          3.9104e-02,  1.0991e-02, -6.0717e-03, -4.0574e-02, -6.0349e-03,\n          7.4008e-02,  1.6130e-01,  1.2242e-01,  1.5725e-01, -1.6370e-01,\n         -7.2077e-03,  3.4647e-02, -1.0332e-02, -1.5587e-01, -1.0938e-01,\n         -8.9885e-02,  1.5173e-01, -6.3899e-02,  1.4772e-01, -5.3482e-02,\n         -1.3938e-01, -7.1987e-02],\n        [-8.0317e-02,  8.8466e-04,  7.7336e-02,  5.5184e-02, -3.9921e-02,\n          8.4953e-02, -1.1713e-01, -9.4080e-02, -3.8380e-02,  1.2170e-01,\n         -1.5084e-01, -1.0177e-01, -8.4984e-02,  1.2724e-01, -1.4370e-01,\n          5.5238e-02, -2.4803e-02,  1.7552e-01,  2.0388e-03,  1.6370e-01,\n         -4.3587e-02,  5.1460e-02, -9.3833e-02,  4.9987e-02, -1.4512e-01,\n          1.3050e-01,  1.0615e-01,  8.0710e-02, -3.8096e-02,  2.3365e-02,\n          1.3255e-01,  2.7286e-03],\n        [ 1.3761e-01,  7.9760e-02, -6.8462e-02, -1.6641e-01,  4.0706e-02,\n         -1.6995e-01, -7.0128e-02,  1.6859e-01, -2.6150e-02,  4.6008e-02,\n         -3.7308e-02, -3.1290e-02, -1.2373e-01,  4.1420e-02, -1.6746e-01,\n          1.5553e-01, -7.0849e-02,  5.0820e-02,  9.4004e-02,  1.4621e-01,\n         -6.9796e-02, -1.0518e-01,  1.5670e-01, -1.5922e-01, -6.0588e-02,\n          2.4309e-02,  1.4993e-01,  1.0263e-01,  4.4622e-03, -6.8010e-02,\n          1.1117e-01, -6.3114e-03],\n        [ 8.7623e-02,  8.1125e-02,  1.0306e-01, -1.2839e-01,  5.8542e-02,\n         -1.6097e-01,  2.3282e-03, -1.7062e-01,  1.1373e-01, -7.7074e-02,\n          1.2653e-01,  7.3343e-02, -1.5389e-01, -1.2214e-01,  5.4821e-02,\n          6.8976e-02, -8.3560e-02,  2.2572e-02, -1.0578e-01,  6.2864e-02,\n         -3.2101e-02, -5.5290e-02, -1.6937e-01, -4.8798e-02, -1.7595e-01,\n          1.4813e-01,  1.6451e-01,  1.6288e-01, -1.3191e-01,  1.3949e-01,\n         -2.1537e-02, -8.9337e-02],\n        [-1.1606e-01, -6.0680e-02,  3.7560e-02, -3.5186e-02, -1.8331e-02,\n         -6.3878e-02, -1.0578e-02,  4.8554e-02,  1.2479e-02,  1.7476e-01,\n          2.8567e-03, -1.6517e-01,  1.6626e-01,  2.4832e-02,  1.7120e-01,\n          1.1076e-01,  1.6292e-01, -1.2413e-01, -1.0611e-01, -2.9221e-02,\n         -5.7111e-02, -1.5912e-01,  1.7023e-01,  1.5721e-01, -7.7068e-02,\n          1.4654e-01, -1.3075e-01, -1.1421e-01,  1.6273e-01, -7.6686e-02,\n          1.2715e-01,  9.2682e-02],\n        [-8.9288e-02, -4.7645e-02, -3.2208e-02,  2.3061e-02, -5.6395e-02,\n          4.2586e-02, -3.7592e-02, -1.3937e-01, -3.2980e-02, -1.3960e-01,\n          9.9030e-02, -1.2804e-01, -2.0839e-02,  3.8171e-02,  1.2590e-01,\n          1.6246e-01,  4.9921e-02,  1.9537e-02, -1.0728e-01,  1.2158e-01,\n          1.0794e-01,  9.9532e-02, -2.0898e-02,  1.4917e-01, -1.5189e-01,\n         -1.1363e-01,  6.5988e-02, -6.5475e-02,  1.4376e-01, -2.1652e-02,\n          1.0752e-01, -5.7881e-03],\n        [ 1.5501e-02,  1.0042e-01, -3.4339e-02,  1.6816e-01, -6.4109e-03,\n         -1.2357e-01,  1.7175e-01, -1.1254e-01,  3.0080e-02,  7.9535e-04,\n          7.3867e-02,  1.2522e-01,  1.0461e-01,  2.2647e-02, -1.5153e-01,\n          2.5499e-04,  4.7207e-02, -1.3529e-01, -2.9572e-02, -2.5114e-02,\n          5.0005e-02, -2.0399e-03, -1.4005e-01,  1.5271e-01,  1.0610e-01,\n         -1.1375e-01,  4.2055e-02, -1.3891e-01, -8.2394e-03,  7.8861e-02,\n          1.1013e-01,  4.1302e-02],\n        [ 9.4502e-02, -1.5499e-01, -1.7850e-02, -1.1449e-01, -1.3842e-01,\n         -5.0481e-02,  1.8180e-02,  1.7621e-01,  4.1072e-02,  1.7170e-01,\n         -1.4005e-01, -6.2982e-02, -1.1542e-01,  8.3494e-03,  1.6310e-01,\n          7.4158e-02,  8.6179e-02,  1.0826e-01, -3.6056e-02,  7.9910e-02,\n         -1.5623e-02,  3.7413e-02, -1.6705e-02, -1.2003e-01,  1.2309e-01,\n         -7.8790e-02,  1.1335e-02, -1.1532e-01, -6.5951e-02,  1.7507e-01,\n         -1.0285e-01,  1.2772e-01],\n        [ 1.0647e-02,  1.6840e-01, -5.4683e-02,  8.6047e-02,  6.6998e-02,\n          1.4328e-01,  5.0743e-02,  1.5754e-01,  1.6141e-01, -2.2686e-02,\n          1.3723e-01, -2.7864e-02, -5.3632e-02,  4.2047e-02, -7.8547e-02,\n          1.3461e-01,  8.9948e-02,  4.2330e-02,  1.2100e-01,  1.4077e-01,\n          1.1922e-01,  1.1907e-01, -1.5493e-01, -1.0351e-01, -1.6365e-01,\n          7.0676e-02,  4.9054e-02,  7.6077e-02,  7.4803e-02,  1.3928e-01,\n          3.7719e-02,  1.5001e-01],\n        [-1.5620e-01, -2.6365e-02, -8.1584e-02, -3.5007e-02, -1.4087e-01,\n         -1.6088e-01, -1.0347e-01,  2.4541e-03,  8.5859e-03, -6.7761e-02,\n          4.9190e-02,  6.3095e-02, -7.8359e-02,  1.1704e-01,  1.8078e-03,\n         -4.9268e-02,  2.4982e-02, -2.2160e-02,  8.8774e-02, -2.8089e-02,\n         -1.2047e-01, -5.6146e-02, -1.2562e-01, -8.2559e-02,  1.3065e-01,\n          1.3940e-01, -7.1246e-02, -1.9622e-02,  1.3975e-02, -8.0957e-02,\n          8.4010e-03,  8.7606e-02],\n        [-5.3182e-02,  5.7381e-03,  9.3199e-02,  1.3040e-01,  4.7300e-02,\n          2.3009e-02, -7.6308e-02,  8.1998e-02, -2.9048e-02,  1.3537e-01,\n          7.6626e-02, -1.4246e-01,  1.5439e-01,  1.5873e-01, -7.3930e-02,\n         -8.2778e-02, -6.6058e-03,  6.0065e-02,  1.3782e-01, -1.6550e-01,\n         -8.1882e-02,  1.1090e-01, -1.5935e-01, -2.5042e-03,  2.8063e-02,\n          4.7802e-02, -6.6607e-02,  1.5134e-01, -1.7531e-01,  1.9125e-02,\n         -6.9009e-02,  7.5351e-02],\n        [-1.3244e-01,  6.7667e-02,  1.4970e-01, -1.4156e-01, -1.0123e-01,\n         -3.1176e-02, -1.2056e-02,  7.7925e-03,  1.5598e-01, -7.8795e-02,\n          9.5001e-03,  1.0019e-02,  1.9205e-02, -8.7372e-02, -8.1240e-02,\n          6.7049e-02,  7.0171e-02, -1.6177e-01,  1.1581e-01, -1.3195e-01,\n          8.5393e-02, -1.7361e-02,  9.2753e-02, -8.6605e-02, -1.5613e-01,\n          8.0073e-02, -1.8163e-02, -5.1557e-02,  2.8167e-02,  8.3881e-02,\n          1.4168e-01, -4.1920e-02],\n        [-5.1807e-02,  1.0473e-01, -1.2269e-01,  3.8941e-02, -1.5005e-01,\n          8.5783e-02,  6.1634e-02,  1.4913e-01,  1.3947e-01,  8.5280e-02,\n          7.9510e-02,  1.0172e-01, -1.0136e-02, -1.0266e-01, -8.3488e-02,\n          1.0747e-01, -7.5959e-02,  1.0361e-01,  1.5269e-01, -1.2540e-01,\n          1.3672e-02, -1.3166e-01, -1.0723e-01,  2.6644e-02,  4.1101e-02,\n          2.9083e-02,  1.2814e-01,  1.2216e-01,  1.9200e-02,  1.5161e-01,\n         -5.2712e-02, -9.5363e-02],\n        [-1.4778e-01,  1.1662e-01,  5.7759e-02, -1.6331e-01, -4.8959e-02,\n         -5.7463e-02, -1.2859e-01, -1.2508e-01,  1.0468e-02,  3.2934e-02,\n          1.2404e-01,  1.2232e-01, -3.1590e-02,  9.8647e-02, -5.5629e-03,\n         -1.1312e-01, -7.9125e-02,  1.4911e-01,  7.4309e-02,  1.8492e-02,\n         -6.9033e-02,  1.5155e-01, -2.4179e-02, -8.7390e-02,  4.0001e-02,\n         -3.9273e-03,  1.3382e-01,  1.5254e-01, -9.5142e-02, -1.7172e-01,\n          1.6115e-01, -1.2801e-01],\n        [-5.8635e-02,  4.4867e-02, -1.7298e-03, -1.5350e-01,  1.0376e-01,\n          9.3824e-02,  8.3540e-02, -1.8414e-02,  1.7593e-01,  1.7630e-01,\n         -1.2054e-01,  8.0407e-03, -1.4285e-01, -1.7652e-01, -1.2635e-01,\n          1.4437e-01,  1.2052e-01, -1.7351e-01,  1.4337e-01,  9.6524e-02,\n          4.4427e-02,  7.3223e-02, -1.3745e-01, -2.5926e-02, -1.0705e-01,\n          1.5358e-01,  1.6257e-01,  4.9056e-02,  4.4314e-02,  3.3641e-02,\n          1.6908e-01,  1.5630e-01],\n        [-8.2482e-02,  4.1655e-02, -5.7382e-02, -3.2327e-05, -9.8772e-02,\n          2.9329e-02,  1.6090e-01,  8.0430e-02, -1.0608e-01, -8.1707e-02,\n         -1.4196e-01,  1.7575e-02, -6.3312e-02, -1.7545e-01, -1.3556e-02,\n         -3.7370e-02, -2.8850e-02, -5.5289e-02, -1.1080e-02, -1.2301e-01,\n          7.1910e-02, -5.3999e-02, -1.1874e-01,  1.2262e-01, -1.0955e-01,\n         -8.6529e-02,  8.0507e-02, -5.4445e-02,  1.3681e-01,  9.9139e-02,\n          1.6016e-01, -5.1601e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2182,  0.0416,  0.0617,  0.0034,  0.1666,  0.2131, -0.0026,  0.2162],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0727,  0.1690, -0.0605, -0.0167,  0.1705,  0.0343,  0.0164, -0.0760,\n         -0.1062,  0.0647,  0.0052, -0.2456,  0.1958, -0.2237,  0.0046,  0.0304],\n        [-0.1527,  0.0143,  0.0222, -0.1765, -0.0812, -0.0594,  0.0675, -0.0984,\n          0.1525, -0.0068,  0.0283, -0.2046,  0.1270,  0.0397,  0.1329, -0.1461],\n        [-0.0432,  0.0435, -0.1290,  0.0558, -0.1085,  0.1063,  0.2033, -0.0020,\n          0.0946,  0.1109,  0.0157, -0.0115,  0.0543, -0.2284, -0.0149, -0.1907],\n        [-0.1939,  0.0735,  0.1492, -0.2384, -0.0911,  0.1582, -0.2344, -0.2235,\n          0.1016, -0.2477, -0.0478, -0.1354,  0.2143,  0.1116, -0.1033,  0.2191],\n        [ 0.1611, -0.0266,  0.0520, -0.1769,  0.2465, -0.0559,  0.1209,  0.1870,\n          0.0919,  0.1792,  0.1897, -0.0990,  0.1951, -0.0797,  0.0568, -0.0886],\n        [-0.1926,  0.1406, -0.1069,  0.2024, -0.0366, -0.1532,  0.1846, -0.0954,\n          0.0579,  0.0719, -0.0738,  0.0584, -0.0979, -0.0485,  0.2376,  0.1239],\n        [-0.1472, -0.1206, -0.0146,  0.1293, -0.1479, -0.2311,  0.0943, -0.0387,\n          0.1616,  0.0450, -0.0699,  0.2448, -0.0129, -0.2298, -0.2413, -0.0678],\n        [-0.1968,  0.2204,  0.1269,  0.1280, -0.0390,  0.2369,  0.1924,  0.2412,\n          0.0958, -0.2118,  0.0450, -0.1031, -0.1649, -0.0501,  0.0820,  0.1541]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2563,  0.2217, -0.1013,  0.3386], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1017,  0.2943, -0.2679,  0.1288, -0.1004,  0.0787, -0.2602, -0.1133],\n        [ 0.2137, -0.0552, -0.2529, -0.0327,  0.1385, -0.3491, -0.0926,  0.2531],\n        [ 0.0694, -0.2125, -0.3409,  0.0217,  0.1099,  0.2808,  0.1474,  0.1083],\n        [ 0.0695,  0.0208,  0.3104, -0.3404, -0.2177, -0.3470, -0.0831,  0.1178]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1341, -0.3242, -0.0049,  0.1578,  0.0085,  0.0719, -0.3146, -0.2332],\n        [ 0.0745,  0.0679,  0.0408, -0.2683,  0.3267, -0.0016,  0.2675, -0.1128],\n        [-0.1392,  0.2758,  0.2484,  0.0805, -0.1359,  0.2299, -0.3057,  0.2890],\n        [ 0.2217, -0.0832, -0.1169,  0.1803,  0.0024, -0.0318,  0.2829,  0.0641],\n        [-0.2839, -0.2562, -0.3005,  0.3405, -0.2080, -0.0363,  0.2369,  0.0267],\n        [-0.0139, -0.0971,  0.1953, -0.1752, -0.2169,  0.2054,  0.2773,  0.3216],\n        [-0.0822,  0.3410, -0.2289, -0.3040, -0.1865, -0.0034,  0.0099, -0.0716],\n        [ 0.3522,  0.0315,  0.1595, -0.0780, -0.1733,  0.2320, -0.1211, -0.1307],\n        [ 0.1094,  0.2891, -0.0698, -0.1237, -0.2471,  0.0330,  0.0046,  0.2165],\n        [ 0.1295, -0.3123, -0.1543, -0.2271,  0.2423,  0.1507,  0.2538, -0.1864],\n        [ 0.0777, -0.0017, -0.3344, -0.1302, -0.2753, -0.2745, -0.1035, -0.0063],\n        [ 0.0514,  0.1879,  0.3060, -0.2446, -0.0728, -0.1984,  0.1593, -0.2134],\n        [-0.3026, -0.0157,  0.2052, -0.0775,  0.2941, -0.1676,  0.3057,  0.3506],\n        [ 0.2397, -0.1222,  0.2236, -0.3458,  0.1930,  0.1908, -0.3042,  0.2310],\n        [ 0.2364, -0.2497, -0.2896, -0.0698, -0.1004,  0.2731,  0.1833, -0.0876],\n        [-0.3091, -0.1536, -0.0394,  0.0782, -0.1844,  0.2551,  0.2389,  0.3395],\n        [ 0.2568,  0.1021, -0.1790, -0.1077, -0.1764,  0.2584, -0.2955,  0.1526],\n        [ 0.1054, -0.0740, -0.0509,  0.1116,  0.0684,  0.0877,  0.0253,  0.2786],\n        [ 0.3508, -0.1575, -0.0571,  0.1120, -0.1487, -0.1845, -0.3140,  0.2616],\n        [-0.2960,  0.0550, -0.1603,  0.3378,  0.2857, -0.2210, -0.0889, -0.2468],\n        [ 0.1674, -0.1719,  0.1494,  0.2028, -0.1430, -0.1430, -0.1231, -0.1262],\n        [ 0.1056,  0.1493, -0.1296,  0.1968,  0.2754,  0.1178, -0.0064,  0.3019],\n        [-0.0090,  0.0436, -0.0161, -0.0855, -0.0011, -0.1743,  0.1493, -0.2372],\n        [ 0.0686, -0.1981,  0.3385, -0.0562, -0.0720,  0.1783,  0.2127, -0.2348],\n        [ 0.0402,  0.0073,  0.1966,  0.0569,  0.3065,  0.1764,  0.3469, -0.0333],\n        [ 0.2968, -0.0459,  0.1011, -0.0348,  0.3168, -0.2669, -0.1295,  0.3299],\n        [-0.1054,  0.1574, -0.2621,  0.1445, -0.3224, -0.0068,  0.1837, -0.2833],\n        [ 0.2053,  0.2483,  0.1726, -0.2762,  0.2496, -0.1306,  0.2421, -0.1566],\n        [ 0.0543,  0.0275, -0.1718, -0.0849, -0.2042,  0.0863,  0.1054, -0.0089],\n        [-0.3344,  0.3065, -0.0107, -0.1180,  0.3343, -0.1934, -0.2208,  0.0963],\n        [ 0.2439,  0.1447,  0.0546,  0.3266,  0.1429, -0.0280,  0.2917, -0.3248],\n        [-0.1959, -0.2114,  0.0200, -0.0315, -0.1777,  0.2081, -0.1498, -0.0710]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1622, -0.3367, -0.0169, -0.0210,  0.2346, -0.2902,  0.0445, -0.0688,\n        -0.0678, -0.3423,  0.2528, -0.3257,  0.3217, -0.1723,  0.1786, -0.1548,\n         0.1983, -0.0928,  0.2914, -0.2494, -0.0613,  0.3334, -0.1256,  0.0906,\n         0.2697, -0.2186,  0.3457, -0.0047, -0.1692, -0.0326, -0.1100,  0.2832],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.2633e-01,  1.3243e-01, -1.5934e-01, -1.2791e-01,  1.4979e-01,\n          8.9069e-02,  5.4658e-02,  1.5604e-01,  1.3145e-01, -8.7115e-02,\n          3.9104e-02,  1.0991e-02, -6.0717e-03, -4.0574e-02, -6.0349e-03,\n          7.4008e-02,  1.6130e-01,  1.2242e-01,  1.5725e-01, -1.6370e-01,\n         -7.2077e-03,  3.4647e-02, -1.0332e-02, -1.5587e-01, -1.0938e-01,\n         -8.9885e-02,  1.5173e-01, -6.3899e-02,  1.4772e-01, -5.3482e-02,\n         -1.3938e-01, -7.1987e-02],\n        [-8.0317e-02,  8.8466e-04,  7.7336e-02,  5.5184e-02, -3.9921e-02,\n          8.4953e-02, -1.1713e-01, -9.4080e-02, -3.8380e-02,  1.2170e-01,\n         -1.5084e-01, -1.0177e-01, -8.4984e-02,  1.2724e-01, -1.4370e-01,\n          5.5238e-02, -2.4803e-02,  1.7552e-01,  2.0388e-03,  1.6370e-01,\n         -4.3587e-02,  5.1460e-02, -9.3833e-02,  4.9987e-02, -1.4512e-01,\n          1.3050e-01,  1.0615e-01,  8.0710e-02, -3.8096e-02,  2.3365e-02,\n          1.3255e-01,  2.7286e-03],\n        [ 1.3761e-01,  7.9760e-02, -6.8462e-02, -1.6641e-01,  4.0706e-02,\n         -1.6995e-01, -7.0128e-02,  1.6859e-01, -2.6150e-02,  4.6008e-02,\n         -3.7308e-02, -3.1290e-02, -1.2373e-01,  4.1420e-02, -1.6746e-01,\n          1.5553e-01, -7.0849e-02,  5.0820e-02,  9.4004e-02,  1.4621e-01,\n         -6.9796e-02, -1.0518e-01,  1.5670e-01, -1.5922e-01, -6.0588e-02,\n          2.4309e-02,  1.4993e-01,  1.0263e-01,  4.4622e-03, -6.8010e-02,\n          1.1117e-01, -6.3114e-03],\n        [ 8.7623e-02,  8.1125e-02,  1.0306e-01, -1.2839e-01,  5.8542e-02,\n         -1.6097e-01,  2.3282e-03, -1.7062e-01,  1.1373e-01, -7.7074e-02,\n          1.2653e-01,  7.3343e-02, -1.5389e-01, -1.2214e-01,  5.4821e-02,\n          6.8976e-02, -8.3560e-02,  2.2572e-02, -1.0578e-01,  6.2864e-02,\n         -3.2101e-02, -5.5290e-02, -1.6937e-01, -4.8798e-02, -1.7595e-01,\n          1.4813e-01,  1.6451e-01,  1.6288e-01, -1.3191e-01,  1.3949e-01,\n         -2.1537e-02, -8.9337e-02],\n        [-1.1606e-01, -6.0680e-02,  3.7560e-02, -3.5186e-02, -1.8331e-02,\n         -6.3878e-02, -1.0578e-02,  4.8554e-02,  1.2479e-02,  1.7476e-01,\n          2.8567e-03, -1.6517e-01,  1.6626e-01,  2.4832e-02,  1.7120e-01,\n          1.1076e-01,  1.6292e-01, -1.2413e-01, -1.0611e-01, -2.9221e-02,\n         -5.7111e-02, -1.5912e-01,  1.7023e-01,  1.5721e-01, -7.7068e-02,\n          1.4654e-01, -1.3075e-01, -1.1421e-01,  1.6273e-01, -7.6686e-02,\n          1.2715e-01,  9.2682e-02],\n        [-8.9288e-02, -4.7645e-02, -3.2208e-02,  2.3061e-02, -5.6395e-02,\n          4.2586e-02, -3.7592e-02, -1.3937e-01, -3.2980e-02, -1.3960e-01,\n          9.9030e-02, -1.2804e-01, -2.0839e-02,  3.8171e-02,  1.2590e-01,\n          1.6246e-01,  4.9921e-02,  1.9537e-02, -1.0728e-01,  1.2158e-01,\n          1.0794e-01,  9.9532e-02, -2.0898e-02,  1.4917e-01, -1.5189e-01,\n         -1.1363e-01,  6.5988e-02, -6.5475e-02,  1.4376e-01, -2.1652e-02,\n          1.0752e-01, -5.7881e-03],\n        [ 1.5501e-02,  1.0042e-01, -3.4339e-02,  1.6816e-01, -6.4109e-03,\n         -1.2357e-01,  1.7175e-01, -1.1254e-01,  3.0080e-02,  7.9535e-04,\n          7.3867e-02,  1.2522e-01,  1.0461e-01,  2.2647e-02, -1.5153e-01,\n          2.5499e-04,  4.7207e-02, -1.3529e-01, -2.9572e-02, -2.5114e-02,\n          5.0005e-02, -2.0399e-03, -1.4005e-01,  1.5271e-01,  1.0610e-01,\n         -1.1375e-01,  4.2055e-02, -1.3891e-01, -8.2394e-03,  7.8861e-02,\n          1.1013e-01,  4.1302e-02],\n        [ 9.4502e-02, -1.5499e-01, -1.7850e-02, -1.1449e-01, -1.3842e-01,\n         -5.0481e-02,  1.8180e-02,  1.7621e-01,  4.1072e-02,  1.7170e-01,\n         -1.4005e-01, -6.2982e-02, -1.1542e-01,  8.3494e-03,  1.6310e-01,\n          7.4158e-02,  8.6179e-02,  1.0826e-01, -3.6056e-02,  7.9910e-02,\n         -1.5623e-02,  3.7413e-02, -1.6705e-02, -1.2003e-01,  1.2309e-01,\n         -7.8790e-02,  1.1335e-02, -1.1532e-01, -6.5951e-02,  1.7507e-01,\n         -1.0285e-01,  1.2772e-01],\n        [ 1.0647e-02,  1.6840e-01, -5.4683e-02,  8.6047e-02,  6.6998e-02,\n          1.4328e-01,  5.0743e-02,  1.5754e-01,  1.6141e-01, -2.2686e-02,\n          1.3723e-01, -2.7864e-02, -5.3632e-02,  4.2047e-02, -7.8547e-02,\n          1.3461e-01,  8.9948e-02,  4.2330e-02,  1.2100e-01,  1.4077e-01,\n          1.1922e-01,  1.1907e-01, -1.5493e-01, -1.0351e-01, -1.6365e-01,\n          7.0676e-02,  4.9054e-02,  7.6077e-02,  7.4803e-02,  1.3928e-01,\n          3.7719e-02,  1.5001e-01],\n        [-1.5620e-01, -2.6365e-02, -8.1584e-02, -3.5007e-02, -1.4087e-01,\n         -1.6088e-01, -1.0347e-01,  2.4541e-03,  8.5859e-03, -6.7761e-02,\n          4.9190e-02,  6.3095e-02, -7.8359e-02,  1.1704e-01,  1.8078e-03,\n         -4.9268e-02,  2.4982e-02, -2.2160e-02,  8.8774e-02, -2.8089e-02,\n         -1.2047e-01, -5.6146e-02, -1.2562e-01, -8.2559e-02,  1.3065e-01,\n          1.3940e-01, -7.1246e-02, -1.9622e-02,  1.3975e-02, -8.0957e-02,\n          8.4010e-03,  8.7606e-02],\n        [-5.3182e-02,  5.7381e-03,  9.3199e-02,  1.3040e-01,  4.7300e-02,\n          2.3009e-02, -7.6308e-02,  8.1998e-02, -2.9048e-02,  1.3537e-01,\n          7.6626e-02, -1.4246e-01,  1.5439e-01,  1.5873e-01, -7.3930e-02,\n         -8.2778e-02, -6.6058e-03,  6.0065e-02,  1.3782e-01, -1.6550e-01,\n         -8.1882e-02,  1.1090e-01, -1.5935e-01, -2.5042e-03,  2.8063e-02,\n          4.7802e-02, -6.6607e-02,  1.5134e-01, -1.7531e-01,  1.9125e-02,\n         -6.9009e-02,  7.5351e-02],\n        [-1.3244e-01,  6.7667e-02,  1.4970e-01, -1.4156e-01, -1.0123e-01,\n         -3.1176e-02, -1.2056e-02,  7.7925e-03,  1.5598e-01, -7.8795e-02,\n          9.5001e-03,  1.0019e-02,  1.9205e-02, -8.7372e-02, -8.1240e-02,\n          6.7049e-02,  7.0171e-02, -1.6177e-01,  1.1581e-01, -1.3195e-01,\n          8.5393e-02, -1.7361e-02,  9.2753e-02, -8.6605e-02, -1.5613e-01,\n          8.0073e-02, -1.8163e-02, -5.1557e-02,  2.8167e-02,  8.3881e-02,\n          1.4168e-01, -4.1920e-02],\n        [-5.1807e-02,  1.0473e-01, -1.2269e-01,  3.8941e-02, -1.5005e-01,\n          8.5783e-02,  6.1634e-02,  1.4913e-01,  1.3947e-01,  8.5280e-02,\n          7.9510e-02,  1.0172e-01, -1.0136e-02, -1.0266e-01, -8.3488e-02,\n          1.0747e-01, -7.5959e-02,  1.0361e-01,  1.5269e-01, -1.2540e-01,\n          1.3672e-02, -1.3166e-01, -1.0723e-01,  2.6644e-02,  4.1101e-02,\n          2.9083e-02,  1.2814e-01,  1.2216e-01,  1.9200e-02,  1.5161e-01,\n         -5.2712e-02, -9.5363e-02],\n        [-1.4778e-01,  1.1662e-01,  5.7759e-02, -1.6331e-01, -4.8959e-02,\n         -5.7463e-02, -1.2859e-01, -1.2508e-01,  1.0468e-02,  3.2934e-02,\n          1.2404e-01,  1.2232e-01, -3.1590e-02,  9.8647e-02, -5.5629e-03,\n         -1.1312e-01, -7.9125e-02,  1.4911e-01,  7.4309e-02,  1.8492e-02,\n         -6.9033e-02,  1.5155e-01, -2.4179e-02, -8.7390e-02,  4.0001e-02,\n         -3.9273e-03,  1.3382e-01,  1.5254e-01, -9.5142e-02, -1.7172e-01,\n          1.6115e-01, -1.2801e-01],\n        [-5.8635e-02,  4.4867e-02, -1.7298e-03, -1.5350e-01,  1.0376e-01,\n          9.3824e-02,  8.3540e-02, -1.8414e-02,  1.7593e-01,  1.7630e-01,\n         -1.2054e-01,  8.0407e-03, -1.4285e-01, -1.7652e-01, -1.2635e-01,\n          1.4437e-01,  1.2052e-01, -1.7351e-01,  1.4337e-01,  9.6524e-02,\n          4.4427e-02,  7.3223e-02, -1.3745e-01, -2.5926e-02, -1.0705e-01,\n          1.5358e-01,  1.6257e-01,  4.9056e-02,  4.4314e-02,  3.3641e-02,\n          1.6908e-01,  1.5630e-01],\n        [-8.2482e-02,  4.1655e-02, -5.7382e-02, -3.2327e-05, -9.8772e-02,\n          2.9329e-02,  1.6090e-01,  8.0430e-02, -1.0608e-01, -8.1707e-02,\n         -1.4196e-01,  1.7575e-02, -6.3312e-02, -1.7545e-01, -1.3556e-02,\n         -3.7370e-02, -2.8850e-02, -5.5289e-02, -1.1080e-02, -1.2301e-01,\n          7.1910e-02, -5.3999e-02, -1.1874e-01,  1.2262e-01, -1.0955e-01,\n         -8.6529e-02,  8.0507e-02, -5.4445e-02,  1.3681e-01,  9.9139e-02,\n          1.6016e-01, -5.1601e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0108, -0.0666,  0.0532,  0.1533,  0.0566, -0.1420, -0.0888,  0.1073,\n        -0.0814, -0.1278, -0.1347, -0.0473,  0.1763,  0.1751, -0.1053, -0.0585],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0727,  0.1690, -0.0605, -0.0167,  0.1705,  0.0343,  0.0164, -0.0760,\n         -0.1062,  0.0647,  0.0052, -0.2456,  0.1958, -0.2237,  0.0046,  0.0304],\n        [-0.1527,  0.0143,  0.0222, -0.1765, -0.0812, -0.0594,  0.0675, -0.0984,\n          0.1525, -0.0068,  0.0283, -0.2046,  0.1270,  0.0397,  0.1329, -0.1461],\n        [-0.0432,  0.0435, -0.1290,  0.0558, -0.1085,  0.1063,  0.2033, -0.0020,\n          0.0946,  0.1109,  0.0157, -0.0115,  0.0543, -0.2284, -0.0149, -0.1907],\n        [-0.1939,  0.0735,  0.1492, -0.2384, -0.0911,  0.1582, -0.2344, -0.2235,\n          0.1016, -0.2477, -0.0478, -0.1354,  0.2143,  0.1116, -0.1033,  0.2191],\n        [ 0.1611, -0.0266,  0.0520, -0.1769,  0.2465, -0.0559,  0.1209,  0.1870,\n          0.0919,  0.1792,  0.1897, -0.0990,  0.1951, -0.0797,  0.0568, -0.0886],\n        [-0.1926,  0.1406, -0.1069,  0.2024, -0.0366, -0.1532,  0.1846, -0.0954,\n          0.0579,  0.0719, -0.0738,  0.0584, -0.0979, -0.0485,  0.2376,  0.1239],\n        [-0.1472, -0.1206, -0.0146,  0.1293, -0.1479, -0.2311,  0.0943, -0.0387,\n          0.1616,  0.0450, -0.0699,  0.2448, -0.0129, -0.2298, -0.2413, -0.0678],\n        [-0.1968,  0.2204,  0.1269,  0.1280, -0.0390,  0.2369,  0.1924,  0.2412,\n          0.0958, -0.2118,  0.0450, -0.1031, -0.1649, -0.0501,  0.0820,  0.1541]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2182,  0.0416,  0.0617,  0.0034,  0.1666,  0.2131, -0.0026,  0.2162],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1017,  0.2943, -0.2679,  0.1288, -0.1004,  0.0787, -0.2602, -0.1133],\n        [ 0.2137, -0.0552, -0.2529, -0.0327,  0.1385, -0.3491, -0.0926,  0.2531],\n        [ 0.0694, -0.2125, -0.3409,  0.0217,  0.1099,  0.2808,  0.1474,  0.1083],\n        [ 0.0695,  0.0208,  0.3104, -0.3404, -0.2177, -0.3470, -0.0831,  0.1178]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2563,  0.2217, -0.1013,  0.3386], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x74a48f9eff10>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1622, -0.3367, -0.0169, -0.0210,  0.2346, -0.2902,  0.0445, -0.0688,\n        -0.0678, -0.3423,  0.2528, -0.3257,  0.3217, -0.1723,  0.1786, -0.1548,\n         0.1983, -0.0928,  0.2914, -0.2494, -0.0613,  0.3334, -0.1256,  0.0906,\n         0.2697, -0.2186,  0.3457, -0.0047, -0.1692, -0.0326, -0.1100,  0.2832],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1341, -0.3242, -0.0049,  0.1578,  0.0085,  0.0719, -0.3146, -0.2332],\n        [ 0.0745,  0.0679,  0.0408, -0.2683,  0.3267, -0.0016,  0.2675, -0.1128],\n        [-0.1392,  0.2758,  0.2484,  0.0805, -0.1359,  0.2299, -0.3057,  0.2890],\n        [ 0.2217, -0.0832, -0.1169,  0.1803,  0.0024, -0.0318,  0.2829,  0.0641],\n        [-0.2839, -0.2562, -0.3005,  0.3405, -0.2080, -0.0363,  0.2369,  0.0267],\n        [-0.0139, -0.0971,  0.1953, -0.1752, -0.2169,  0.2054,  0.2773,  0.3216],\n        [-0.0822,  0.3410, -0.2289, -0.3040, -0.1865, -0.0034,  0.0099, -0.0716],\n        [ 0.3522,  0.0315,  0.1595, -0.0780, -0.1733,  0.2320, -0.1211, -0.1307],\n        [ 0.1094,  0.2891, -0.0698, -0.1237, -0.2471,  0.0330,  0.0046,  0.2165],\n        [ 0.1295, -0.3123, -0.1543, -0.2271,  0.2423,  0.1507,  0.2538, -0.1864],\n        [ 0.0777, -0.0017, -0.3344, -0.1302, -0.2753, -0.2745, -0.1035, -0.0063],\n        [ 0.0514,  0.1879,  0.3060, -0.2446, -0.0728, -0.1984,  0.1593, -0.2134],\n        [-0.3026, -0.0157,  0.2052, -0.0775,  0.2941, -0.1676,  0.3057,  0.3506],\n        [ 0.2397, -0.1222,  0.2236, -0.3458,  0.1930,  0.1908, -0.3042,  0.2310],\n        [ 0.2364, -0.2497, -0.2896, -0.0698, -0.1004,  0.2731,  0.1833, -0.0876],\n        [-0.3091, -0.1536, -0.0394,  0.0782, -0.1844,  0.2551,  0.2389,  0.3395],\n        [ 0.2568,  0.1021, -0.1790, -0.1077, -0.1764,  0.2584, -0.2955,  0.1526],\n        [ 0.1054, -0.0740, -0.0509,  0.1116,  0.0684,  0.0877,  0.0253,  0.2786],\n        [ 0.3508, -0.1575, -0.0571,  0.1120, -0.1487, -0.1845, -0.3140,  0.2616],\n        [-0.2960,  0.0550, -0.1603,  0.3378,  0.2857, -0.2210, -0.0889, -0.2468],\n        [ 0.1674, -0.1719,  0.1494,  0.2028, -0.1430, -0.1430, -0.1231, -0.1262],\n        [ 0.1056,  0.1493, -0.1296,  0.1968,  0.2754,  0.1178, -0.0064,  0.3019],\n        [-0.0090,  0.0436, -0.0161, -0.0855, -0.0011, -0.1743,  0.1493, -0.2372],\n        [ 0.0686, -0.1981,  0.3385, -0.0562, -0.0720,  0.1783,  0.2127, -0.2348],\n        [ 0.0402,  0.0073,  0.1966,  0.0569,  0.3065,  0.1764,  0.3469, -0.0333],\n        [ 0.2968, -0.0459,  0.1011, -0.0348,  0.3168, -0.2669, -0.1295,  0.3299],\n        [-0.1054,  0.1574, -0.2621,  0.1445, -0.3224, -0.0068,  0.1837, -0.2833],\n        [ 0.2053,  0.2483,  0.1726, -0.2762,  0.2496, -0.1306,  0.2421, -0.1566],\n        [ 0.0543,  0.0275, -0.1718, -0.0849, -0.2042,  0.0863,  0.1054, -0.0089],\n        [-0.3344,  0.3065, -0.0107, -0.1180,  0.3343, -0.1934, -0.2208,  0.0963],\n        [ 0.2439,  0.1447,  0.0546,  0.3266,  0.1429, -0.0280,  0.2917, -0.3248],\n        [-0.1959, -0.2114,  0.0200, -0.0315, -0.1777,  0.2081, -0.1498, -0.0710]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0108, -0.0666,  0.0532,  0.1533,  0.0566, -0.1420, -0.0888,  0.1073,\n        -0.0814, -0.1278, -0.1347, -0.0473,  0.1763,  0.1751, -0.1053, -0.0585],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.2633e-01,  1.3243e-01, -1.5934e-01, -1.2791e-01,  1.4979e-01,\n          8.9069e-02,  5.4658e-02,  1.5604e-01,  1.3145e-01, -8.7115e-02,\n          3.9104e-02,  1.0991e-02, -6.0717e-03, -4.0574e-02, -6.0349e-03,\n          7.4008e-02,  1.6130e-01,  1.2242e-01,  1.5725e-01, -1.6370e-01,\n         -7.2077e-03,  3.4647e-02, -1.0332e-02, -1.5587e-01, -1.0938e-01,\n         -8.9885e-02,  1.5173e-01, -6.3899e-02,  1.4772e-01, -5.3482e-02,\n         -1.3938e-01, -7.1987e-02],\n        [-8.0317e-02,  8.8466e-04,  7.7336e-02,  5.5184e-02, -3.9921e-02,\n          8.4953e-02, -1.1713e-01, -9.4080e-02, -3.8380e-02,  1.2170e-01,\n         -1.5084e-01, -1.0177e-01, -8.4984e-02,  1.2724e-01, -1.4370e-01,\n          5.5238e-02, -2.4803e-02,  1.7552e-01,  2.0388e-03,  1.6370e-01,\n         -4.3587e-02,  5.1460e-02, -9.3833e-02,  4.9987e-02, -1.4512e-01,\n          1.3050e-01,  1.0615e-01,  8.0710e-02, -3.8096e-02,  2.3365e-02,\n          1.3255e-01,  2.7286e-03],\n        [ 1.3761e-01,  7.9760e-02, -6.8462e-02, -1.6641e-01,  4.0706e-02,\n         -1.6995e-01, -7.0128e-02,  1.6859e-01, -2.6150e-02,  4.6008e-02,\n         -3.7308e-02, -3.1290e-02, -1.2373e-01,  4.1420e-02, -1.6746e-01,\n          1.5553e-01, -7.0849e-02,  5.0820e-02,  9.4004e-02,  1.4621e-01,\n         -6.9796e-02, -1.0518e-01,  1.5670e-01, -1.5922e-01, -6.0588e-02,\n          2.4309e-02,  1.4993e-01,  1.0263e-01,  4.4622e-03, -6.8010e-02,\n          1.1117e-01, -6.3114e-03],\n        [ 8.7623e-02,  8.1125e-02,  1.0306e-01, -1.2839e-01,  5.8542e-02,\n         -1.6097e-01,  2.3282e-03, -1.7062e-01,  1.1373e-01, -7.7074e-02,\n          1.2653e-01,  7.3343e-02, -1.5389e-01, -1.2214e-01,  5.4821e-02,\n          6.8976e-02, -8.3560e-02,  2.2572e-02, -1.0578e-01,  6.2864e-02,\n         -3.2101e-02, -5.5290e-02, -1.6937e-01, -4.8798e-02, -1.7595e-01,\n          1.4813e-01,  1.6451e-01,  1.6288e-01, -1.3191e-01,  1.3949e-01,\n         -2.1537e-02, -8.9337e-02],\n        [-1.1606e-01, -6.0680e-02,  3.7560e-02, -3.5186e-02, -1.8331e-02,\n         -6.3878e-02, -1.0578e-02,  4.8554e-02,  1.2479e-02,  1.7476e-01,\n          2.8567e-03, -1.6517e-01,  1.6626e-01,  2.4832e-02,  1.7120e-01,\n          1.1076e-01,  1.6292e-01, -1.2413e-01, -1.0611e-01, -2.9221e-02,\n         -5.7111e-02, -1.5912e-01,  1.7023e-01,  1.5721e-01, -7.7068e-02,\n          1.4654e-01, -1.3075e-01, -1.1421e-01,  1.6273e-01, -7.6686e-02,\n          1.2715e-01,  9.2682e-02],\n        [-8.9288e-02, -4.7645e-02, -3.2208e-02,  2.3061e-02, -5.6395e-02,\n          4.2586e-02, -3.7592e-02, -1.3937e-01, -3.2980e-02, -1.3960e-01,\n          9.9030e-02, -1.2804e-01, -2.0839e-02,  3.8171e-02,  1.2590e-01,\n          1.6246e-01,  4.9921e-02,  1.9537e-02, -1.0728e-01,  1.2158e-01,\n          1.0794e-01,  9.9532e-02, -2.0898e-02,  1.4917e-01, -1.5189e-01,\n         -1.1363e-01,  6.5988e-02, -6.5475e-02,  1.4376e-01, -2.1652e-02,\n          1.0752e-01, -5.7881e-03],\n        [ 1.5501e-02,  1.0042e-01, -3.4339e-02,  1.6816e-01, -6.4109e-03,\n         -1.2357e-01,  1.7175e-01, -1.1254e-01,  3.0080e-02,  7.9535e-04,\n          7.3867e-02,  1.2522e-01,  1.0461e-01,  2.2647e-02, -1.5153e-01,\n          2.5499e-04,  4.7207e-02, -1.3529e-01, -2.9572e-02, -2.5114e-02,\n          5.0005e-02, -2.0399e-03, -1.4005e-01,  1.5271e-01,  1.0610e-01,\n         -1.1375e-01,  4.2055e-02, -1.3891e-01, -8.2394e-03,  7.8861e-02,\n          1.1013e-01,  4.1302e-02],\n        [ 9.4502e-02, -1.5499e-01, -1.7850e-02, -1.1449e-01, -1.3842e-01,\n         -5.0481e-02,  1.8180e-02,  1.7621e-01,  4.1072e-02,  1.7170e-01,\n         -1.4005e-01, -6.2982e-02, -1.1542e-01,  8.3494e-03,  1.6310e-01,\n          7.4158e-02,  8.6179e-02,  1.0826e-01, -3.6056e-02,  7.9910e-02,\n         -1.5623e-02,  3.7413e-02, -1.6705e-02, -1.2003e-01,  1.2309e-01,\n         -7.8790e-02,  1.1335e-02, -1.1532e-01, -6.5951e-02,  1.7507e-01,\n         -1.0285e-01,  1.2772e-01],\n        [ 1.0647e-02,  1.6840e-01, -5.4683e-02,  8.6047e-02,  6.6998e-02,\n          1.4328e-01,  5.0743e-02,  1.5754e-01,  1.6141e-01, -2.2686e-02,\n          1.3723e-01, -2.7864e-02, -5.3632e-02,  4.2047e-02, -7.8547e-02,\n          1.3461e-01,  8.9948e-02,  4.2330e-02,  1.2100e-01,  1.4077e-01,\n          1.1922e-01,  1.1907e-01, -1.5493e-01, -1.0351e-01, -1.6365e-01,\n          7.0676e-02,  4.9054e-02,  7.6077e-02,  7.4803e-02,  1.3928e-01,\n          3.7719e-02,  1.5001e-01],\n        [-1.5620e-01, -2.6365e-02, -8.1584e-02, -3.5007e-02, -1.4087e-01,\n         -1.6088e-01, -1.0347e-01,  2.4541e-03,  8.5859e-03, -6.7761e-02,\n          4.9190e-02,  6.3095e-02, -7.8359e-02,  1.1704e-01,  1.8078e-03,\n         -4.9268e-02,  2.4982e-02, -2.2160e-02,  8.8774e-02, -2.8089e-02,\n         -1.2047e-01, -5.6146e-02, -1.2562e-01, -8.2559e-02,  1.3065e-01,\n          1.3940e-01, -7.1246e-02, -1.9622e-02,  1.3975e-02, -8.0957e-02,\n          8.4010e-03,  8.7606e-02],\n        [-5.3182e-02,  5.7381e-03,  9.3199e-02,  1.3040e-01,  4.7300e-02,\n          2.3009e-02, -7.6308e-02,  8.1998e-02, -2.9048e-02,  1.3537e-01,\n          7.6626e-02, -1.4246e-01,  1.5439e-01,  1.5873e-01, -7.3930e-02,\n         -8.2778e-02, -6.6058e-03,  6.0065e-02,  1.3782e-01, -1.6550e-01,\n         -8.1882e-02,  1.1090e-01, -1.5935e-01, -2.5042e-03,  2.8063e-02,\n          4.7802e-02, -6.6607e-02,  1.5134e-01, -1.7531e-01,  1.9125e-02,\n         -6.9009e-02,  7.5351e-02],\n        [-1.3244e-01,  6.7667e-02,  1.4970e-01, -1.4156e-01, -1.0123e-01,\n         -3.1176e-02, -1.2056e-02,  7.7925e-03,  1.5598e-01, -7.8795e-02,\n          9.5001e-03,  1.0019e-02,  1.9205e-02, -8.7372e-02, -8.1240e-02,\n          6.7049e-02,  7.0171e-02, -1.6177e-01,  1.1581e-01, -1.3195e-01,\n          8.5393e-02, -1.7361e-02,  9.2753e-02, -8.6605e-02, -1.5613e-01,\n          8.0073e-02, -1.8163e-02, -5.1557e-02,  2.8167e-02,  8.3881e-02,\n          1.4168e-01, -4.1920e-02],\n        [-5.1807e-02,  1.0473e-01, -1.2269e-01,  3.8941e-02, -1.5005e-01,\n          8.5783e-02,  6.1634e-02,  1.4913e-01,  1.3947e-01,  8.5280e-02,\n          7.9510e-02,  1.0172e-01, -1.0136e-02, -1.0266e-01, -8.3488e-02,\n          1.0747e-01, -7.5959e-02,  1.0361e-01,  1.5269e-01, -1.2540e-01,\n          1.3672e-02, -1.3166e-01, -1.0723e-01,  2.6644e-02,  4.1101e-02,\n          2.9083e-02,  1.2814e-01,  1.2216e-01,  1.9200e-02,  1.5161e-01,\n         -5.2712e-02, -9.5363e-02],\n        [-1.4778e-01,  1.1662e-01,  5.7759e-02, -1.6331e-01, -4.8959e-02,\n         -5.7463e-02, -1.2859e-01, -1.2508e-01,  1.0468e-02,  3.2934e-02,\n          1.2404e-01,  1.2232e-01, -3.1590e-02,  9.8647e-02, -5.5629e-03,\n         -1.1312e-01, -7.9125e-02,  1.4911e-01,  7.4309e-02,  1.8492e-02,\n         -6.9033e-02,  1.5155e-01, -2.4179e-02, -8.7390e-02,  4.0001e-02,\n         -3.9273e-03,  1.3382e-01,  1.5254e-01, -9.5142e-02, -1.7172e-01,\n          1.6115e-01, -1.2801e-01],\n        [-5.8635e-02,  4.4867e-02, -1.7298e-03, -1.5350e-01,  1.0376e-01,\n          9.3824e-02,  8.3540e-02, -1.8414e-02,  1.7593e-01,  1.7630e-01,\n         -1.2054e-01,  8.0407e-03, -1.4285e-01, -1.7652e-01, -1.2635e-01,\n          1.4437e-01,  1.2052e-01, -1.7351e-01,  1.4337e-01,  9.6524e-02,\n          4.4427e-02,  7.3223e-02, -1.3745e-01, -2.5926e-02, -1.0705e-01,\n          1.5358e-01,  1.6257e-01,  4.9056e-02,  4.4314e-02,  3.3641e-02,\n          1.6908e-01,  1.5630e-01],\n        [-8.2482e-02,  4.1655e-02, -5.7382e-02, -3.2327e-05, -9.8772e-02,\n          2.9329e-02,  1.6090e-01,  8.0430e-02, -1.0608e-01, -8.1707e-02,\n         -1.4196e-01,  1.7575e-02, -6.3312e-02, -1.7545e-01, -1.3556e-02,\n         -3.7370e-02, -2.8850e-02, -5.5289e-02, -1.1080e-02, -1.2301e-01,\n          7.1910e-02, -5.3999e-02, -1.1874e-01,  1.2262e-01, -1.0955e-01,\n         -8.6529e-02,  8.0507e-02, -5.4445e-02,  1.3681e-01,  9.9139e-02,\n          1.6016e-01, -5.1601e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2182,  0.0416,  0.0617,  0.0034,  0.1666,  0.2131, -0.0026,  0.2162],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0727,  0.1690, -0.0605, -0.0167,  0.1705,  0.0343,  0.0164, -0.0760,\n         -0.1062,  0.0647,  0.0052, -0.2456,  0.1958, -0.2237,  0.0046,  0.0304],\n        [-0.1527,  0.0143,  0.0222, -0.1765, -0.0812, -0.0594,  0.0675, -0.0984,\n          0.1525, -0.0068,  0.0283, -0.2046,  0.1270,  0.0397,  0.1329, -0.1461],\n        [-0.0432,  0.0435, -0.1290,  0.0558, -0.1085,  0.1063,  0.2033, -0.0020,\n          0.0946,  0.1109,  0.0157, -0.0115,  0.0543, -0.2284, -0.0149, -0.1907],\n        [-0.1939,  0.0735,  0.1492, -0.2384, -0.0911,  0.1582, -0.2344, -0.2235,\n          0.1016, -0.2477, -0.0478, -0.1354,  0.2143,  0.1116, -0.1033,  0.2191],\n        [ 0.1611, -0.0266,  0.0520, -0.1769,  0.2465, -0.0559,  0.1209,  0.1870,\n          0.0919,  0.1792,  0.1897, -0.0990,  0.1951, -0.0797,  0.0568, -0.0886],\n        [-0.1926,  0.1406, -0.1069,  0.2024, -0.0366, -0.1532,  0.1846, -0.0954,\n          0.0579,  0.0719, -0.0738,  0.0584, -0.0979, -0.0485,  0.2376,  0.1239],\n        [-0.1472, -0.1206, -0.0146,  0.1293, -0.1479, -0.2311,  0.0943, -0.0387,\n          0.1616,  0.0450, -0.0699,  0.2448, -0.0129, -0.2298, -0.2413, -0.0678],\n        [-0.1968,  0.2204,  0.1269,  0.1280, -0.0390,  0.2369,  0.1924,  0.2412,\n          0.0958, -0.2118,  0.0450, -0.1031, -0.1649, -0.0501,  0.0820,  0.1541]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2563,  0.2217, -0.1013,  0.3386], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1017,  0.2943, -0.2679,  0.1288, -0.1004,  0.0787, -0.2602, -0.1133],\n        [ 0.2137, -0.0552, -0.2529, -0.0327,  0.1385, -0.3491, -0.0926,  0.2531],\n        [ 0.0694, -0.2125, -0.3409,  0.0217,  0.1099,  0.2808,  0.1474,  0.1083],\n        [ 0.0695,  0.0208,  0.3104, -0.3404, -0.2177, -0.3470, -0.0831,  0.1178]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x74a408d5bc90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s331870000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s331870000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}