{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s341580000"
    },
    "q_lr":	0.0005,
    "seed":	341580000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7bd5d35c3550>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1170,  0.0853, -0.0088,  0.0363, -0.0337, -0.0222, -0.2034, -0.3354,\n        -0.0835,  0.1305, -0.3064,  0.2212, -0.2578,  0.2860, -0.2690,  0.2949,\n         0.0083,  0.1693, -0.0750,  0.2453,  0.2749, -0.1780,  0.2321,  0.3266,\n        -0.0088, -0.1622,  0.0558,  0.0793, -0.2471,  0.3514, -0.2404, -0.1743],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1354,  0.2490, -0.0605, -0.0544, -0.2587,  0.3234,  0.0484, -0.2857],\n        [ 0.2365, -0.0646, -0.3066, -0.3027,  0.2818, -0.3344, -0.2010, -0.0218],\n        [ 0.1592, -0.3110,  0.2804,  0.1018, -0.3105, -0.3259, -0.1759, -0.2052],\n        [-0.1777, -0.3000, -0.0712,  0.2784,  0.1562, -0.0321, -0.3445, -0.0020],\n        [-0.2628, -0.1085, -0.2546,  0.0218,  0.0152, -0.2319, -0.1725,  0.0919],\n        [ 0.2760, -0.2603, -0.3346,  0.2831,  0.1640, -0.0781, -0.3103, -0.3496],\n        [-0.3148, -0.1640,  0.2322, -0.3309, -0.0202,  0.1596, -0.2159, -0.0946],\n        [-0.3377,  0.2644,  0.2778,  0.1028,  0.2734, -0.0352,  0.1965, -0.1981],\n        [-0.2455, -0.1615,  0.3488,  0.0291,  0.2075,  0.1730,  0.0239,  0.1544],\n        [-0.2473,  0.3021, -0.1023, -0.2215, -0.2919, -0.0827, -0.3003, -0.0850],\n        [-0.2242,  0.1362,  0.0567,  0.3008,  0.3029, -0.0280,  0.2246, -0.1770],\n        [ 0.2496, -0.1733,  0.0902,  0.0900, -0.1920, -0.2928,  0.2374,  0.0663],\n        [ 0.2454,  0.2234,  0.0399,  0.1164,  0.0028, -0.1552, -0.0527,  0.3064],\n        [-0.3151,  0.1288, -0.0732, -0.1441, -0.2374,  0.1920, -0.0488, -0.0072],\n        [ 0.2325, -0.0405, -0.0074,  0.0502, -0.0810, -0.2469, -0.2456, -0.2989],\n        [-0.2608, -0.1879, -0.2704, -0.1271, -0.3530,  0.3196,  0.0214, -0.2936],\n        [ 0.2966, -0.1025,  0.0218, -0.1776, -0.2075,  0.2769,  0.0970,  0.3433],\n        [ 0.2180,  0.1352, -0.0839,  0.2058,  0.2314,  0.2147,  0.2232, -0.0964],\n        [ 0.0980,  0.2774, -0.2386,  0.0199,  0.3121, -0.2696, -0.2166, -0.3510],\n        [-0.1516,  0.1809, -0.2777,  0.2320,  0.0512, -0.2782,  0.0363, -0.0782],\n        [ 0.0282, -0.3323,  0.3293,  0.0990, -0.2497,  0.0096, -0.1372, -0.0321],\n        [ 0.0257,  0.3202, -0.2655,  0.0576, -0.2817,  0.1063, -0.1365, -0.0137],\n        [-0.1284,  0.1575, -0.3499,  0.3187, -0.3397, -0.2969, -0.1090, -0.1477],\n        [-0.1030,  0.2025, -0.2593,  0.3205, -0.2688, -0.0072,  0.0196,  0.0247],\n        [-0.2574,  0.2017,  0.1605, -0.0784, -0.3456,  0.0562, -0.2606, -0.3362],\n        [ 0.1630,  0.1240, -0.1067,  0.1530,  0.2912,  0.3147, -0.2408, -0.0127],\n        [-0.2861,  0.2701, -0.0760,  0.3483, -0.2481,  0.2988,  0.0553,  0.2381],\n        [-0.0670,  0.2515, -0.1056, -0.2216, -0.0004, -0.0448, -0.0026, -0.0990],\n        [-0.1107, -0.1912,  0.2829,  0.2487, -0.0526, -0.1088,  0.1174,  0.0138],\n        [-0.2662,  0.3115,  0.2314,  0.1770,  0.2438, -0.0124,  0.0607,  0.3253],\n        [ 0.1887, -0.0821,  0.3472,  0.1751, -0.3292, -0.2492, -0.2460, -0.2960],\n        [ 0.0653,  0.0899, -0.0500,  0.1595, -0.0153,  0.3462,  0.2365, -0.1202]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1570, -0.1478, -0.1049, -0.0539,  0.1439, -0.0662, -0.0216, -0.1432,\n        -0.0910, -0.0552,  0.1683, -0.1192, -0.0977,  0.0736, -0.1455,  0.0156],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.6181e-01,  1.5542e-01,  8.2311e-02,  6.8213e-02, -2.8721e-02,\n         -1.2012e-01, -1.6087e-01,  1.3725e-01, -6.5845e-02, -5.3377e-02,\n         -1.0892e-03,  5.6452e-02,  6.6605e-02, -1.2141e-01,  2.1544e-02,\n         -9.3670e-02,  6.6683e-03, -1.0078e-01,  1.2328e-01,  6.5397e-02,\n         -7.9636e-02,  1.0079e-01,  1.4503e-01, -1.2328e-02, -1.6562e-01,\n         -1.7572e-02,  2.2053e-02, -7.7217e-02,  1.6184e-01, -1.3332e-01,\n         -1.7509e-01,  1.4717e-01],\n        [ 9.0484e-02,  4.2598e-02,  3.9358e-02, -4.4989e-02, -1.7203e-01,\n         -9.4690e-02, -7.0482e-02, -1.5411e-01, -1.6566e-01,  1.6214e-01,\n         -8.7184e-02, -2.2513e-02, -3.4271e-02,  1.2169e-01, -5.8986e-02,\n         -8.8185e-02, -1.2144e-01,  7.1404e-02,  1.4544e-01, -1.4393e-01,\n          1.5108e-01,  7.8596e-02,  1.2613e-01, -1.2751e-01, -6.3504e-02,\n         -1.4457e-01,  6.1490e-03,  1.0984e-01,  1.4236e-01, -6.0670e-02,\n          1.2783e-01,  1.6773e-01],\n        [-1.5803e-01,  1.6447e-01, -1.3246e-01, -1.9533e-02,  1.2199e-01,\n         -1.5732e-01, -7.8996e-02, -9.8381e-02,  1.1654e-02, -5.4529e-02,\n         -2.7631e-02,  1.5842e-01, -1.2245e-01, -1.2114e-01, -6.4312e-02,\n          1.4467e-02, -6.5165e-02, -1.1737e-01, -1.4728e-01,  1.4356e-01,\n         -1.0752e-01,  1.4471e-01,  9.6725e-02,  1.5939e-01, -9.6714e-02,\n         -1.1512e-01,  3.4316e-02, -2.4022e-02, -1.5829e-02,  1.1069e-02,\n         -1.3843e-01, -1.6078e-01],\n        [-9.4155e-02, -1.4448e-01,  1.5851e-01, -3.1954e-02,  1.3229e-01,\n         -5.6759e-02, -1.0319e-01,  1.3338e-01, -1.6239e-01,  3.7710e-02,\n         -1.3680e-02,  1.5495e-01, -8.0310e-02, -1.4627e-01, -3.8903e-02,\n          6.3728e-02,  6.4021e-02, -1.3887e-01, -1.7613e-01, -8.1374e-02,\n         -1.5507e-01, -9.2129e-02,  1.0917e-01, -1.7667e-01, -1.5401e-02,\n          1.3518e-01,  1.6964e-01,  1.4738e-01, -1.4811e-01,  3.1057e-03,\n         -3.1935e-02, -4.9389e-02],\n        [ 7.9280e-02,  5.2262e-03,  1.6861e-01, -1.0077e-01, -1.0320e-02,\n         -3.8081e-02, -4.1442e-02,  1.0746e-01,  7.7292e-02,  1.6526e-01,\n          7.4285e-02,  2.5978e-02,  1.0796e-01,  7.2626e-02,  1.4068e-01,\n          1.2898e-01, -1.7513e-01,  1.9022e-02,  3.5347e-02,  4.0072e-02,\n          5.7467e-02, -1.6680e-01, -9.5202e-02, -9.4104e-02, -1.0334e-01,\n         -7.9468e-02, -6.9163e-02, -7.5560e-02,  1.1554e-01, -4.7294e-02,\n          1.1087e-01, -1.6458e-01],\n        [ 5.7015e-02, -1.3472e-01, -2.5986e-02, -9.1472e-02,  1.5319e-01,\n          1.2846e-02,  1.4936e-01,  1.5649e-01,  1.4590e-01,  1.3649e-01,\n         -1.0578e-01,  4.4358e-02, -4.0132e-02, -4.3555e-02, -1.1884e-02,\n          3.4185e-02,  6.7902e-02, -9.5189e-02,  6.2802e-02,  1.1225e-01,\n         -7.9731e-02,  1.4125e-01,  1.4366e-01, -1.4606e-01,  1.3062e-01,\n         -9.6466e-02, -1.3884e-01,  5.3854e-02,  8.6621e-02, -8.5250e-02,\n         -1.0731e-01,  1.2308e-01],\n        [-1.6140e-01,  1.5287e-01,  1.6719e-01,  1.7119e-01, -1.2153e-01,\n          2.6394e-02,  8.5604e-02,  3.3338e-02, -7.7942e-02,  1.3739e-01,\n          1.1543e-01, -1.1884e-01, -1.1527e-01, -1.4819e-01, -4.6152e-02,\n         -5.8722e-02, -1.6329e-01,  9.5381e-02,  3.0342e-02,  4.9545e-02,\n          1.0280e-01, -1.4243e-01, -1.0527e-01, -1.7456e-01, -1.2897e-01,\n          6.0796e-02, -9.6584e-03,  1.3854e-01,  4.5472e-02,  7.1688e-02,\n         -6.3993e-02,  2.5493e-02],\n        [-1.6980e-01,  9.6832e-02, -9.0870e-02,  1.6844e-01,  1.2491e-01,\n          5.2744e-02,  6.1502e-02, -1.1715e-01, -2.8701e-02,  9.3572e-02,\n          1.2715e-01,  1.4064e-02, -3.6118e-02, -5.7542e-02,  7.7040e-02,\n         -7.6166e-02,  1.4926e-01, -5.6698e-02,  1.2551e-01,  7.0998e-03,\n          4.2221e-02,  4.3611e-02, -1.4825e-01,  7.1959e-02,  5.5633e-02,\n          1.1664e-01, -8.2832e-02, -1.3384e-01, -8.3148e-02, -1.1441e-01,\n         -1.0421e-01, -1.4235e-01],\n        [-8.3864e-03, -1.4026e-01,  1.7211e-01,  1.6665e-01,  1.0463e-01,\n          9.1399e-02,  3.3161e-02,  4.1695e-02,  1.4268e-01, -8.4024e-02,\n          1.1804e-01, -7.3286e-03,  1.2015e-01,  6.6630e-02, -2.4005e-02,\n         -1.3465e-01, -1.5998e-02, -6.7131e-02, -9.2237e-02, -4.3076e-02,\n          9.1833e-02,  1.6600e-01,  2.2903e-02, -1.4896e-01,  1.0968e-01,\n          1.5106e-01, -9.0910e-02, -7.6702e-02,  4.5419e-02,  1.1455e-01,\n         -1.6070e-01,  2.6006e-03],\n        [ 8.0335e-02, -1.3316e-01, -1.5396e-01, -1.6082e-01, -5.2404e-02,\n         -1.2812e-01,  1.3054e-02,  1.0831e-01,  2.4705e-02,  1.4011e-01,\n         -1.3808e-01,  8.7470e-02, -4.5746e-02, -1.2794e-01, -5.5369e-02,\n          1.2005e-01,  7.5594e-02,  1.7881e-02,  4.2784e-02, -1.5668e-02,\n         -1.6654e-01,  1.4823e-01,  6.5999e-02,  5.0840e-02,  7.9281e-02,\n          8.1970e-02, -1.6477e-01,  1.2220e-01, -8.7468e-02, -1.7228e-01,\n         -2.6049e-02,  4.2230e-02],\n        [-9.7881e-02,  5.1628e-02,  1.0144e-02,  5.4793e-02,  6.9702e-02,\n          1.0746e-01, -1.4198e-01, -8.4317e-02, -1.5832e-01, -2.3262e-02,\n         -1.5673e-01,  1.7235e-01,  1.9340e-02,  1.5882e-01, -6.0605e-02,\n         -1.0076e-01,  4.7440e-02,  5.3191e-03, -8.4089e-02,  1.0391e-01,\n         -1.6050e-01,  1.5217e-01, -5.1065e-02, -4.2069e-02, -1.4532e-01,\n          4.3100e-02,  1.2129e-01,  5.2496e-02,  3.0082e-03,  6.9681e-03,\n         -1.1112e-01, -8.9421e-02],\n        [ 1.4859e-01, -9.5893e-03, -1.6513e-01, -1.3862e-01, -1.3379e-02,\n          1.3825e-01, -7.2564e-02,  1.3881e-01, -1.7479e-01,  1.3801e-01,\n         -4.9265e-02, -6.5497e-02,  1.5204e-01, -1.6067e-01, -5.0612e-02,\n         -5.3376e-02, -4.3495e-02,  7.6169e-02, -6.6637e-02,  1.1464e-01,\n         -1.4351e-01, -1.5047e-01,  8.5147e-02, -3.2087e-02,  1.3777e-01,\n         -2.5864e-02, -1.6932e-01,  1.0852e-02, -3.3445e-02,  4.0105e-02,\n          9.3328e-02, -3.2456e-02],\n        [-2.2780e-02, -7.4409e-02, -4.9189e-02, -2.0776e-02,  4.6551e-02,\n          9.3154e-02, -7.7726e-02,  6.9394e-02,  8.3048e-02, -7.3959e-02,\n         -1.0581e-01, -2.2733e-02, -7.7818e-02, -1.2631e-02,  2.6244e-02,\n         -1.4323e-01, -8.7423e-02, -5.8413e-02,  1.6293e-01,  1.0165e-01,\n         -6.3065e-02, -1.5215e-01, -1.4501e-04, -5.7718e-02,  3.2146e-02,\n          1.2073e-01,  7.5048e-02, -7.2995e-02,  8.3639e-02,  1.0908e-01,\n          3.1216e-02,  1.6137e-01],\n        [-6.8265e-03,  1.4436e-01, -1.2957e-01, -1.3988e-01, -1.3757e-01,\n          1.7241e-01,  5.5994e-02, -8.8372e-02, -1.7806e-02,  8.6385e-02,\n          8.5119e-02,  1.5743e-01,  8.5629e-02, -1.5711e-01,  1.0577e-01,\n         -1.1324e-01, -1.3371e-01,  9.6753e-02,  9.5932e-02,  1.2442e-01,\n          7.9731e-02,  1.5897e-01, -1.4479e-01, -1.1891e-02, -1.3917e-01,\n         -1.6576e-01,  1.4940e-01,  5.8628e-02, -1.2309e-01,  1.6548e-01,\n         -1.2782e-01, -8.1809e-02],\n        [-6.9391e-03, -4.8028e-02,  1.1353e-01, -1.1631e-01, -1.1103e-02,\n          1.4033e-01, -1.0771e-01,  1.2940e-01,  5.3300e-02,  1.4300e-01,\n          1.2807e-01,  1.6002e-01,  1.3489e-01, -4.7300e-02,  2.0761e-03,\n          7.1231e-02, -8.6346e-03,  2.6451e-02,  8.5930e-02,  1.0365e-01,\n         -5.4066e-02,  1.4156e-01, -1.6553e-01, -1.5491e-01,  2.3825e-02,\n         -1.4420e-01,  1.5988e-01, -8.5633e-02,  6.8806e-02, -1.6724e-01,\n         -8.7565e-02, -2.2065e-02],\n        [ 1.4168e-01,  1.7258e-01,  3.0827e-02, -1.1182e-01,  9.5845e-02,\n          1.0455e-01, -5.5114e-02, -1.1231e-01, -1.6433e-01,  1.3388e-01,\n         -1.4222e-01, -2.4350e-02,  8.0301e-03,  1.3237e-01, -1.7658e-01,\n          1.3846e-01,  5.4521e-02, -1.4827e-01,  1.5763e-01, -6.3717e-02,\n         -1.4217e-01, -9.8106e-02, -1.2460e-01,  1.4485e-01, -2.4605e-02,\n         -3.7757e-02, -4.5659e-02,  1.7166e-01, -1.4890e-02, -6.2945e-03,\n          1.6744e-01, -1.4491e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2113, -0.1140,  0.2422, -0.0660, -0.2445, -0.0513, -0.1156,  0.1605],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.6790e-01, -1.9125e-01, -2.0014e-01,  5.9060e-02,  1.0643e-03,\n          4.6470e-02,  2.0061e-01,  9.0686e-02,  1.2389e-01, -8.3318e-02,\n          1.3111e-01, -1.0350e-01,  1.1533e-01,  1.2239e-01,  1.5138e-01,\n         -9.4537e-02],\n        [-1.7303e-01, -2.1978e-02,  1.3516e-01, -1.8074e-01, -1.7781e-01,\n          7.3105e-02,  1.6720e-01, -1.1545e-02, -1.5351e-01, -2.3725e-01,\n          1.0534e-01,  1.1001e-01, -1.7280e-01, -1.8183e-01, -1.8928e-01,\n          4.7240e-02],\n        [-1.3524e-01,  1.7468e-01,  1.4949e-01, -5.9550e-02, -2.1011e-01,\n          1.8594e-01, -6.5046e-02,  7.7836e-02,  1.2744e-01, -1.3814e-01,\n         -1.5677e-01,  1.7480e-02, -4.5306e-02, -9.5914e-02, -2.3972e-01,\n          3.5532e-02],\n        [-7.8047e-02, -1.2948e-01, -5.2391e-02,  1.0941e-01,  3.9453e-02,\n          1.1460e-01, -1.8425e-01, -1.2865e-01, -7.1115e-02,  1.0543e-01,\n          5.7574e-02,  1.4943e-01,  1.5890e-01,  2.3248e-01,  1.5171e-01,\n          2.2280e-02],\n        [ 1.9283e-01, -1.3409e-01,  5.4319e-02, -4.8275e-02,  1.9931e-01,\n          1.8851e-01, -7.9031e-02,  1.9779e-02, -2.4497e-01,  1.6651e-01,\n          2.0230e-01,  1.3167e-01,  1.3251e-02, -2.3987e-02,  7.8370e-02,\n          2.1215e-01],\n        [-1.4305e-01, -3.9616e-02, -1.9853e-01,  1.7877e-01,  2.0563e-01,\n         -1.0486e-01, -1.1852e-01,  1.3619e-01, -3.4452e-02, -2.2219e-01,\n         -2.3574e-01, -1.6023e-01, -2.3125e-01,  4.3589e-04, -9.3546e-03,\n          2.0517e-01],\n        [-1.1897e-01, -8.2386e-02, -1.9080e-01, -7.3372e-02, -4.6702e-03,\n         -9.1359e-02,  7.4814e-02, -1.6374e-01,  2.1959e-01,  2.3674e-01,\n         -2.0907e-01, -8.5374e-02,  5.2608e-02,  2.3154e-02, -3.4977e-02,\n          1.5592e-02],\n        [-2.0892e-01,  1.6602e-01,  2.0352e-01,  1.8246e-01,  1.4659e-01,\n          1.7861e-01,  5.9870e-03, -2.2802e-01,  8.3158e-02, -1.4220e-01,\n         -2.1669e-04,  1.2162e-01,  1.4152e-01,  1.3871e-02,  1.5386e-01,\n         -3.2322e-03]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0307,  0.3258, -0.1576,  0.3026], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2357, -0.3036, -0.2550, -0.1328,  0.3001,  0.2793,  0.1631,  0.3279],\n        [-0.1211, -0.2132,  0.2771,  0.0490, -0.1318, -0.0230, -0.1927,  0.3257],\n        [-0.1021,  0.2914, -0.0572, -0.1765,  0.2479, -0.2613, -0.1884, -0.0334],\n        [-0.2043,  0.0792,  0.2360,  0.1133,  0.2444, -0.1064,  0.2032,  0.0852]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1354,  0.2490, -0.0605, -0.0544, -0.2587,  0.3234,  0.0484, -0.2857],\n        [ 0.2365, -0.0646, -0.3066, -0.3027,  0.2818, -0.3344, -0.2010, -0.0218],\n        [ 0.1592, -0.3110,  0.2804,  0.1018, -0.3105, -0.3259, -0.1759, -0.2052],\n        [-0.1777, -0.3000, -0.0712,  0.2784,  0.1562, -0.0321, -0.3445, -0.0020],\n        [-0.2628, -0.1085, -0.2546,  0.0218,  0.0152, -0.2319, -0.1725,  0.0919],\n        [ 0.2760, -0.2603, -0.3346,  0.2831,  0.1640, -0.0781, -0.3103, -0.3496],\n        [-0.3148, -0.1640,  0.2322, -0.3309, -0.0202,  0.1596, -0.2159, -0.0946],\n        [-0.3377,  0.2644,  0.2778,  0.1028,  0.2734, -0.0352,  0.1965, -0.1981],\n        [-0.2455, -0.1615,  0.3488,  0.0291,  0.2075,  0.1730,  0.0239,  0.1544],\n        [-0.2473,  0.3021, -0.1023, -0.2215, -0.2919, -0.0827, -0.3003, -0.0850],\n        [-0.2242,  0.1362,  0.0567,  0.3008,  0.3029, -0.0280,  0.2246, -0.1770],\n        [ 0.2496, -0.1733,  0.0902,  0.0900, -0.1920, -0.2928,  0.2374,  0.0663],\n        [ 0.2454,  0.2234,  0.0399,  0.1164,  0.0028, -0.1552, -0.0527,  0.3064],\n        [-0.3151,  0.1288, -0.0732, -0.1441, -0.2374,  0.1920, -0.0488, -0.0072],\n        [ 0.2325, -0.0405, -0.0074,  0.0502, -0.0810, -0.2469, -0.2456, -0.2989],\n        [-0.2608, -0.1879, -0.2704, -0.1271, -0.3530,  0.3196,  0.0214, -0.2936],\n        [ 0.2966, -0.1025,  0.0218, -0.1776, -0.2075,  0.2769,  0.0970,  0.3433],\n        [ 0.2180,  0.1352, -0.0839,  0.2058,  0.2314,  0.2147,  0.2232, -0.0964],\n        [ 0.0980,  0.2774, -0.2386,  0.0199,  0.3121, -0.2696, -0.2166, -0.3510],\n        [-0.1516,  0.1809, -0.2777,  0.2320,  0.0512, -0.2782,  0.0363, -0.0782],\n        [ 0.0282, -0.3323,  0.3293,  0.0990, -0.2497,  0.0096, -0.1372, -0.0321],\n        [ 0.0257,  0.3202, -0.2655,  0.0576, -0.2817,  0.1063, -0.1365, -0.0137],\n        [-0.1284,  0.1575, -0.3499,  0.3187, -0.3397, -0.2969, -0.1090, -0.1477],\n        [-0.1030,  0.2025, -0.2593,  0.3205, -0.2688, -0.0072,  0.0196,  0.0247],\n        [-0.2574,  0.2017,  0.1605, -0.0784, -0.3456,  0.0562, -0.2606, -0.3362],\n        [ 0.1630,  0.1240, -0.1067,  0.1530,  0.2912,  0.3147, -0.2408, -0.0127],\n        [-0.2861,  0.2701, -0.0760,  0.3483, -0.2481,  0.2988,  0.0553,  0.2381],\n        [-0.0670,  0.2515, -0.1056, -0.2216, -0.0004, -0.0448, -0.0026, -0.0990],\n        [-0.1107, -0.1912,  0.2829,  0.2487, -0.0526, -0.1088,  0.1174,  0.0138],\n        [-0.2662,  0.3115,  0.2314,  0.1770,  0.2438, -0.0124,  0.0607,  0.3253],\n        [ 0.1887, -0.0821,  0.3472,  0.1751, -0.3292, -0.2492, -0.2460, -0.2960],\n        [ 0.0653,  0.0899, -0.0500,  0.1595, -0.0153,  0.3462,  0.2365, -0.1202]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1170,  0.0853, -0.0088,  0.0363, -0.0337, -0.0222, -0.2034, -0.3354,\n        -0.0835,  0.1305, -0.3064,  0.2212, -0.2578,  0.2860, -0.2690,  0.2949,\n         0.0083,  0.1693, -0.0750,  0.2453,  0.2749, -0.1780,  0.2321,  0.3266,\n        -0.0088, -0.1622,  0.0558,  0.0793, -0.2471,  0.3514, -0.2404, -0.1743],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.6181e-01,  1.5542e-01,  8.2311e-02,  6.8213e-02, -2.8721e-02,\n         -1.2012e-01, -1.6087e-01,  1.3725e-01, -6.5845e-02, -5.3377e-02,\n         -1.0892e-03,  5.6452e-02,  6.6605e-02, -1.2141e-01,  2.1544e-02,\n         -9.3670e-02,  6.6683e-03, -1.0078e-01,  1.2328e-01,  6.5397e-02,\n         -7.9636e-02,  1.0079e-01,  1.4503e-01, -1.2328e-02, -1.6562e-01,\n         -1.7572e-02,  2.2053e-02, -7.7217e-02,  1.6184e-01, -1.3332e-01,\n         -1.7509e-01,  1.4717e-01],\n        [ 9.0484e-02,  4.2598e-02,  3.9358e-02, -4.4989e-02, -1.7203e-01,\n         -9.4690e-02, -7.0482e-02, -1.5411e-01, -1.6566e-01,  1.6214e-01,\n         -8.7184e-02, -2.2513e-02, -3.4271e-02,  1.2169e-01, -5.8986e-02,\n         -8.8185e-02, -1.2144e-01,  7.1404e-02,  1.4544e-01, -1.4393e-01,\n          1.5108e-01,  7.8596e-02,  1.2613e-01, -1.2751e-01, -6.3504e-02,\n         -1.4457e-01,  6.1490e-03,  1.0984e-01,  1.4236e-01, -6.0670e-02,\n          1.2783e-01,  1.6773e-01],\n        [-1.5803e-01,  1.6447e-01, -1.3246e-01, -1.9533e-02,  1.2199e-01,\n         -1.5732e-01, -7.8996e-02, -9.8381e-02,  1.1654e-02, -5.4529e-02,\n         -2.7631e-02,  1.5842e-01, -1.2245e-01, -1.2114e-01, -6.4312e-02,\n          1.4467e-02, -6.5165e-02, -1.1737e-01, -1.4728e-01,  1.4356e-01,\n         -1.0752e-01,  1.4471e-01,  9.6725e-02,  1.5939e-01, -9.6714e-02,\n         -1.1512e-01,  3.4316e-02, -2.4022e-02, -1.5829e-02,  1.1069e-02,\n         -1.3843e-01, -1.6078e-01],\n        [-9.4155e-02, -1.4448e-01,  1.5851e-01, -3.1954e-02,  1.3229e-01,\n         -5.6759e-02, -1.0319e-01,  1.3338e-01, -1.6239e-01,  3.7710e-02,\n         -1.3680e-02,  1.5495e-01, -8.0310e-02, -1.4627e-01, -3.8903e-02,\n          6.3728e-02,  6.4021e-02, -1.3887e-01, -1.7613e-01, -8.1374e-02,\n         -1.5507e-01, -9.2129e-02,  1.0917e-01, -1.7667e-01, -1.5401e-02,\n          1.3518e-01,  1.6964e-01,  1.4738e-01, -1.4811e-01,  3.1057e-03,\n         -3.1935e-02, -4.9389e-02],\n        [ 7.9280e-02,  5.2262e-03,  1.6861e-01, -1.0077e-01, -1.0320e-02,\n         -3.8081e-02, -4.1442e-02,  1.0746e-01,  7.7292e-02,  1.6526e-01,\n          7.4285e-02,  2.5978e-02,  1.0796e-01,  7.2626e-02,  1.4068e-01,\n          1.2898e-01, -1.7513e-01,  1.9022e-02,  3.5347e-02,  4.0072e-02,\n          5.7467e-02, -1.6680e-01, -9.5202e-02, -9.4104e-02, -1.0334e-01,\n         -7.9468e-02, -6.9163e-02, -7.5560e-02,  1.1554e-01, -4.7294e-02,\n          1.1087e-01, -1.6458e-01],\n        [ 5.7015e-02, -1.3472e-01, -2.5986e-02, -9.1472e-02,  1.5319e-01,\n          1.2846e-02,  1.4936e-01,  1.5649e-01,  1.4590e-01,  1.3649e-01,\n         -1.0578e-01,  4.4358e-02, -4.0132e-02, -4.3555e-02, -1.1884e-02,\n          3.4185e-02,  6.7902e-02, -9.5189e-02,  6.2802e-02,  1.1225e-01,\n         -7.9731e-02,  1.4125e-01,  1.4366e-01, -1.4606e-01,  1.3062e-01,\n         -9.6466e-02, -1.3884e-01,  5.3854e-02,  8.6621e-02, -8.5250e-02,\n         -1.0731e-01,  1.2308e-01],\n        [-1.6140e-01,  1.5287e-01,  1.6719e-01,  1.7119e-01, -1.2153e-01,\n          2.6394e-02,  8.5604e-02,  3.3338e-02, -7.7942e-02,  1.3739e-01,\n          1.1543e-01, -1.1884e-01, -1.1527e-01, -1.4819e-01, -4.6152e-02,\n         -5.8722e-02, -1.6329e-01,  9.5381e-02,  3.0342e-02,  4.9545e-02,\n          1.0280e-01, -1.4243e-01, -1.0527e-01, -1.7456e-01, -1.2897e-01,\n          6.0796e-02, -9.6584e-03,  1.3854e-01,  4.5472e-02,  7.1688e-02,\n         -6.3993e-02,  2.5493e-02],\n        [-1.6980e-01,  9.6832e-02, -9.0870e-02,  1.6844e-01,  1.2491e-01,\n          5.2744e-02,  6.1502e-02, -1.1715e-01, -2.8701e-02,  9.3572e-02,\n          1.2715e-01,  1.4064e-02, -3.6118e-02, -5.7542e-02,  7.7040e-02,\n         -7.6166e-02,  1.4926e-01, -5.6698e-02,  1.2551e-01,  7.0998e-03,\n          4.2221e-02,  4.3611e-02, -1.4825e-01,  7.1959e-02,  5.5633e-02,\n          1.1664e-01, -8.2832e-02, -1.3384e-01, -8.3148e-02, -1.1441e-01,\n         -1.0421e-01, -1.4235e-01],\n        [-8.3864e-03, -1.4026e-01,  1.7211e-01,  1.6665e-01,  1.0463e-01,\n          9.1399e-02,  3.3161e-02,  4.1695e-02,  1.4268e-01, -8.4024e-02,\n          1.1804e-01, -7.3286e-03,  1.2015e-01,  6.6630e-02, -2.4005e-02,\n         -1.3465e-01, -1.5998e-02, -6.7131e-02, -9.2237e-02, -4.3076e-02,\n          9.1833e-02,  1.6600e-01,  2.2903e-02, -1.4896e-01,  1.0968e-01,\n          1.5106e-01, -9.0910e-02, -7.6702e-02,  4.5419e-02,  1.1455e-01,\n         -1.6070e-01,  2.6006e-03],\n        [ 8.0335e-02, -1.3316e-01, -1.5396e-01, -1.6082e-01, -5.2404e-02,\n         -1.2812e-01,  1.3054e-02,  1.0831e-01,  2.4705e-02,  1.4011e-01,\n         -1.3808e-01,  8.7470e-02, -4.5746e-02, -1.2794e-01, -5.5369e-02,\n          1.2005e-01,  7.5594e-02,  1.7881e-02,  4.2784e-02, -1.5668e-02,\n         -1.6654e-01,  1.4823e-01,  6.5999e-02,  5.0840e-02,  7.9281e-02,\n          8.1970e-02, -1.6477e-01,  1.2220e-01, -8.7468e-02, -1.7228e-01,\n         -2.6049e-02,  4.2230e-02],\n        [-9.7881e-02,  5.1628e-02,  1.0144e-02,  5.4793e-02,  6.9702e-02,\n          1.0746e-01, -1.4198e-01, -8.4317e-02, -1.5832e-01, -2.3262e-02,\n         -1.5673e-01,  1.7235e-01,  1.9340e-02,  1.5882e-01, -6.0605e-02,\n         -1.0076e-01,  4.7440e-02,  5.3191e-03, -8.4089e-02,  1.0391e-01,\n         -1.6050e-01,  1.5217e-01, -5.1065e-02, -4.2069e-02, -1.4532e-01,\n          4.3100e-02,  1.2129e-01,  5.2496e-02,  3.0082e-03,  6.9681e-03,\n         -1.1112e-01, -8.9421e-02],\n        [ 1.4859e-01, -9.5893e-03, -1.6513e-01, -1.3862e-01, -1.3379e-02,\n          1.3825e-01, -7.2564e-02,  1.3881e-01, -1.7479e-01,  1.3801e-01,\n         -4.9265e-02, -6.5497e-02,  1.5204e-01, -1.6067e-01, -5.0612e-02,\n         -5.3376e-02, -4.3495e-02,  7.6169e-02, -6.6637e-02,  1.1464e-01,\n         -1.4351e-01, -1.5047e-01,  8.5147e-02, -3.2087e-02,  1.3777e-01,\n         -2.5864e-02, -1.6932e-01,  1.0852e-02, -3.3445e-02,  4.0105e-02,\n          9.3328e-02, -3.2456e-02],\n        [-2.2780e-02, -7.4409e-02, -4.9189e-02, -2.0776e-02,  4.6551e-02,\n          9.3154e-02, -7.7726e-02,  6.9394e-02,  8.3048e-02, -7.3959e-02,\n         -1.0581e-01, -2.2733e-02, -7.7818e-02, -1.2631e-02,  2.6244e-02,\n         -1.4323e-01, -8.7423e-02, -5.8413e-02,  1.6293e-01,  1.0165e-01,\n         -6.3065e-02, -1.5215e-01, -1.4501e-04, -5.7718e-02,  3.2146e-02,\n          1.2073e-01,  7.5048e-02, -7.2995e-02,  8.3639e-02,  1.0908e-01,\n          3.1216e-02,  1.6137e-01],\n        [-6.8265e-03,  1.4436e-01, -1.2957e-01, -1.3988e-01, -1.3757e-01,\n          1.7241e-01,  5.5994e-02, -8.8372e-02, -1.7806e-02,  8.6385e-02,\n          8.5119e-02,  1.5743e-01,  8.5629e-02, -1.5711e-01,  1.0577e-01,\n         -1.1324e-01, -1.3371e-01,  9.6753e-02,  9.5932e-02,  1.2442e-01,\n          7.9731e-02,  1.5897e-01, -1.4479e-01, -1.1891e-02, -1.3917e-01,\n         -1.6576e-01,  1.4940e-01,  5.8628e-02, -1.2309e-01,  1.6548e-01,\n         -1.2782e-01, -8.1809e-02],\n        [-6.9391e-03, -4.8028e-02,  1.1353e-01, -1.1631e-01, -1.1103e-02,\n          1.4033e-01, -1.0771e-01,  1.2940e-01,  5.3300e-02,  1.4300e-01,\n          1.2807e-01,  1.6002e-01,  1.3489e-01, -4.7300e-02,  2.0761e-03,\n          7.1231e-02, -8.6346e-03,  2.6451e-02,  8.5930e-02,  1.0365e-01,\n         -5.4066e-02,  1.4156e-01, -1.6553e-01, -1.5491e-01,  2.3825e-02,\n         -1.4420e-01,  1.5988e-01, -8.5633e-02,  6.8806e-02, -1.6724e-01,\n         -8.7565e-02, -2.2065e-02],\n        [ 1.4168e-01,  1.7258e-01,  3.0827e-02, -1.1182e-01,  9.5845e-02,\n          1.0455e-01, -5.5114e-02, -1.1231e-01, -1.6433e-01,  1.3388e-01,\n         -1.4222e-01, -2.4350e-02,  8.0301e-03,  1.3237e-01, -1.7658e-01,\n          1.3846e-01,  5.4521e-02, -1.4827e-01,  1.5763e-01, -6.3717e-02,\n         -1.4217e-01, -9.8106e-02, -1.2460e-01,  1.4485e-01, -2.4605e-02,\n         -3.7757e-02, -4.5659e-02,  1.7166e-01, -1.4890e-02, -6.2945e-03,\n          1.6744e-01, -1.4491e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1570, -0.1478, -0.1049, -0.0539,  0.1439, -0.0662, -0.0216, -0.1432,\n        -0.0910, -0.0552,  0.1683, -0.1192, -0.0977,  0.0736, -0.1455,  0.0156],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.6790e-01, -1.9125e-01, -2.0014e-01,  5.9060e-02,  1.0643e-03,\n          4.6470e-02,  2.0061e-01,  9.0686e-02,  1.2389e-01, -8.3318e-02,\n          1.3111e-01, -1.0350e-01,  1.1533e-01,  1.2239e-01,  1.5138e-01,\n         -9.4537e-02],\n        [-1.7303e-01, -2.1978e-02,  1.3516e-01, -1.8074e-01, -1.7781e-01,\n          7.3105e-02,  1.6720e-01, -1.1545e-02, -1.5351e-01, -2.3725e-01,\n          1.0534e-01,  1.1001e-01, -1.7280e-01, -1.8183e-01, -1.8928e-01,\n          4.7240e-02],\n        [-1.3524e-01,  1.7468e-01,  1.4949e-01, -5.9550e-02, -2.1011e-01,\n          1.8594e-01, -6.5046e-02,  7.7836e-02,  1.2744e-01, -1.3814e-01,\n         -1.5677e-01,  1.7480e-02, -4.5306e-02, -9.5914e-02, -2.3972e-01,\n          3.5532e-02],\n        [-7.8047e-02, -1.2948e-01, -5.2391e-02,  1.0941e-01,  3.9453e-02,\n          1.1460e-01, -1.8425e-01, -1.2865e-01, -7.1115e-02,  1.0543e-01,\n          5.7574e-02,  1.4943e-01,  1.5890e-01,  2.3248e-01,  1.5171e-01,\n          2.2280e-02],\n        [ 1.9283e-01, -1.3409e-01,  5.4319e-02, -4.8275e-02,  1.9931e-01,\n          1.8851e-01, -7.9031e-02,  1.9779e-02, -2.4497e-01,  1.6651e-01,\n          2.0230e-01,  1.3167e-01,  1.3251e-02, -2.3987e-02,  7.8370e-02,\n          2.1215e-01],\n        [-1.4305e-01, -3.9616e-02, -1.9853e-01,  1.7877e-01,  2.0563e-01,\n         -1.0486e-01, -1.1852e-01,  1.3619e-01, -3.4452e-02, -2.2219e-01,\n         -2.3574e-01, -1.6023e-01, -2.3125e-01,  4.3589e-04, -9.3546e-03,\n          2.0517e-01],\n        [-1.1897e-01, -8.2386e-02, -1.9080e-01, -7.3372e-02, -4.6702e-03,\n         -9.1359e-02,  7.4814e-02, -1.6374e-01,  2.1959e-01,  2.3674e-01,\n         -2.0907e-01, -8.5374e-02,  5.2608e-02,  2.3154e-02, -3.4977e-02,\n          1.5592e-02],\n        [-2.0892e-01,  1.6602e-01,  2.0352e-01,  1.8246e-01,  1.4659e-01,\n          1.7861e-01,  5.9870e-03, -2.2802e-01,  8.3158e-02, -1.4220e-01,\n         -2.1669e-04,  1.2162e-01,  1.4152e-01,  1.3871e-02,  1.5386e-01,\n         -3.2322e-03]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2113, -0.1140,  0.2422, -0.0660, -0.2445, -0.0513, -0.1156,  0.1605],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2357, -0.3036, -0.2550, -0.1328,  0.3001,  0.2793,  0.1631,  0.3279],\n        [-0.1211, -0.2132,  0.2771,  0.0490, -0.1318, -0.0230, -0.1927,  0.3257],\n        [-0.1021,  0.2914, -0.0572, -0.1765,  0.2479, -0.2613, -0.1884, -0.0334],\n        [-0.2043,  0.0792,  0.2360,  0.1133,  0.2444, -0.1064,  0.2032,  0.0852]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0307,  0.3258, -0.1576,  0.3026], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7bd65170a790>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1170,  0.0853, -0.0088,  0.0363, -0.0337, -0.0222, -0.2034, -0.3354,\n        -0.0835,  0.1305, -0.3064,  0.2212, -0.2578,  0.2860, -0.2690,  0.2949,\n         0.0083,  0.1693, -0.0750,  0.2453,  0.2749, -0.1780,  0.2321,  0.3266,\n        -0.0088, -0.1622,  0.0558,  0.0793, -0.2471,  0.3514, -0.2404, -0.1743],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1354,  0.2490, -0.0605, -0.0544, -0.2587,  0.3234,  0.0484, -0.2857],\n        [ 0.2365, -0.0646, -0.3066, -0.3027,  0.2818, -0.3344, -0.2010, -0.0218],\n        [ 0.1592, -0.3110,  0.2804,  0.1018, -0.3105, -0.3259, -0.1759, -0.2052],\n        [-0.1777, -0.3000, -0.0712,  0.2784,  0.1562, -0.0321, -0.3445, -0.0020],\n        [-0.2628, -0.1085, -0.2546,  0.0218,  0.0152, -0.2319, -0.1725,  0.0919],\n        [ 0.2760, -0.2603, -0.3346,  0.2831,  0.1640, -0.0781, -0.3103, -0.3496],\n        [-0.3148, -0.1640,  0.2322, -0.3309, -0.0202,  0.1596, -0.2159, -0.0946],\n        [-0.3377,  0.2644,  0.2778,  0.1028,  0.2734, -0.0352,  0.1965, -0.1981],\n        [-0.2455, -0.1615,  0.3488,  0.0291,  0.2075,  0.1730,  0.0239,  0.1544],\n        [-0.2473,  0.3021, -0.1023, -0.2215, -0.2919, -0.0827, -0.3003, -0.0850],\n        [-0.2242,  0.1362,  0.0567,  0.3008,  0.3029, -0.0280,  0.2246, -0.1770],\n        [ 0.2496, -0.1733,  0.0902,  0.0900, -0.1920, -0.2928,  0.2374,  0.0663],\n        [ 0.2454,  0.2234,  0.0399,  0.1164,  0.0028, -0.1552, -0.0527,  0.3064],\n        [-0.3151,  0.1288, -0.0732, -0.1441, -0.2374,  0.1920, -0.0488, -0.0072],\n        [ 0.2325, -0.0405, -0.0074,  0.0502, -0.0810, -0.2469, -0.2456, -0.2989],\n        [-0.2608, -0.1879, -0.2704, -0.1271, -0.3530,  0.3196,  0.0214, -0.2936],\n        [ 0.2966, -0.1025,  0.0218, -0.1776, -0.2075,  0.2769,  0.0970,  0.3433],\n        [ 0.2180,  0.1352, -0.0839,  0.2058,  0.2314,  0.2147,  0.2232, -0.0964],\n        [ 0.0980,  0.2774, -0.2386,  0.0199,  0.3121, -0.2696, -0.2166, -0.3510],\n        [-0.1516,  0.1809, -0.2777,  0.2320,  0.0512, -0.2782,  0.0363, -0.0782],\n        [ 0.0282, -0.3323,  0.3293,  0.0990, -0.2497,  0.0096, -0.1372, -0.0321],\n        [ 0.0257,  0.3202, -0.2655,  0.0576, -0.2817,  0.1063, -0.1365, -0.0137],\n        [-0.1284,  0.1575, -0.3499,  0.3187, -0.3397, -0.2969, -0.1090, -0.1477],\n        [-0.1030,  0.2025, -0.2593,  0.3205, -0.2688, -0.0072,  0.0196,  0.0247],\n        [-0.2574,  0.2017,  0.1605, -0.0784, -0.3456,  0.0562, -0.2606, -0.3362],\n        [ 0.1630,  0.1240, -0.1067,  0.1530,  0.2912,  0.3147, -0.2408, -0.0127],\n        [-0.2861,  0.2701, -0.0760,  0.3483, -0.2481,  0.2988,  0.0553,  0.2381],\n        [-0.0670,  0.2515, -0.1056, -0.2216, -0.0004, -0.0448, -0.0026, -0.0990],\n        [-0.1107, -0.1912,  0.2829,  0.2487, -0.0526, -0.1088,  0.1174,  0.0138],\n        [-0.2662,  0.3115,  0.2314,  0.1770,  0.2438, -0.0124,  0.0607,  0.3253],\n        [ 0.1887, -0.0821,  0.3472,  0.1751, -0.3292, -0.2492, -0.2460, -0.2960],\n        [ 0.0653,  0.0899, -0.0500,  0.1595, -0.0153,  0.3462,  0.2365, -0.1202]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1570, -0.1478, -0.1049, -0.0539,  0.1439, -0.0662, -0.0216, -0.1432,\n        -0.0910, -0.0552,  0.1683, -0.1192, -0.0977,  0.0736, -0.1455,  0.0156],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.6181e-01,  1.5542e-01,  8.2311e-02,  6.8213e-02, -2.8721e-02,\n         -1.2012e-01, -1.6087e-01,  1.3725e-01, -6.5845e-02, -5.3377e-02,\n         -1.0892e-03,  5.6452e-02,  6.6605e-02, -1.2141e-01,  2.1544e-02,\n         -9.3670e-02,  6.6683e-03, -1.0078e-01,  1.2328e-01,  6.5397e-02,\n         -7.9636e-02,  1.0079e-01,  1.4503e-01, -1.2328e-02, -1.6562e-01,\n         -1.7572e-02,  2.2053e-02, -7.7217e-02,  1.6184e-01, -1.3332e-01,\n         -1.7509e-01,  1.4717e-01],\n        [ 9.0484e-02,  4.2598e-02,  3.9358e-02, -4.4989e-02, -1.7203e-01,\n         -9.4690e-02, -7.0482e-02, -1.5411e-01, -1.6566e-01,  1.6214e-01,\n         -8.7184e-02, -2.2513e-02, -3.4271e-02,  1.2169e-01, -5.8986e-02,\n         -8.8185e-02, -1.2144e-01,  7.1404e-02,  1.4544e-01, -1.4393e-01,\n          1.5108e-01,  7.8596e-02,  1.2613e-01, -1.2751e-01, -6.3504e-02,\n         -1.4457e-01,  6.1490e-03,  1.0984e-01,  1.4236e-01, -6.0670e-02,\n          1.2783e-01,  1.6773e-01],\n        [-1.5803e-01,  1.6447e-01, -1.3246e-01, -1.9533e-02,  1.2199e-01,\n         -1.5732e-01, -7.8996e-02, -9.8381e-02,  1.1654e-02, -5.4529e-02,\n         -2.7631e-02,  1.5842e-01, -1.2245e-01, -1.2114e-01, -6.4312e-02,\n          1.4467e-02, -6.5165e-02, -1.1737e-01, -1.4728e-01,  1.4356e-01,\n         -1.0752e-01,  1.4471e-01,  9.6725e-02,  1.5939e-01, -9.6714e-02,\n         -1.1512e-01,  3.4316e-02, -2.4022e-02, -1.5829e-02,  1.1069e-02,\n         -1.3843e-01, -1.6078e-01],\n        [-9.4155e-02, -1.4448e-01,  1.5851e-01, -3.1954e-02,  1.3229e-01,\n         -5.6759e-02, -1.0319e-01,  1.3338e-01, -1.6239e-01,  3.7710e-02,\n         -1.3680e-02,  1.5495e-01, -8.0310e-02, -1.4627e-01, -3.8903e-02,\n          6.3728e-02,  6.4021e-02, -1.3887e-01, -1.7613e-01, -8.1374e-02,\n         -1.5507e-01, -9.2129e-02,  1.0917e-01, -1.7667e-01, -1.5401e-02,\n          1.3518e-01,  1.6964e-01,  1.4738e-01, -1.4811e-01,  3.1057e-03,\n         -3.1935e-02, -4.9389e-02],\n        [ 7.9280e-02,  5.2262e-03,  1.6861e-01, -1.0077e-01, -1.0320e-02,\n         -3.8081e-02, -4.1442e-02,  1.0746e-01,  7.7292e-02,  1.6526e-01,\n          7.4285e-02,  2.5978e-02,  1.0796e-01,  7.2626e-02,  1.4068e-01,\n          1.2898e-01, -1.7513e-01,  1.9022e-02,  3.5347e-02,  4.0072e-02,\n          5.7467e-02, -1.6680e-01, -9.5202e-02, -9.4104e-02, -1.0334e-01,\n         -7.9468e-02, -6.9163e-02, -7.5560e-02,  1.1554e-01, -4.7294e-02,\n          1.1087e-01, -1.6458e-01],\n        [ 5.7015e-02, -1.3472e-01, -2.5986e-02, -9.1472e-02,  1.5319e-01,\n          1.2846e-02,  1.4936e-01,  1.5649e-01,  1.4590e-01,  1.3649e-01,\n         -1.0578e-01,  4.4358e-02, -4.0132e-02, -4.3555e-02, -1.1884e-02,\n          3.4185e-02,  6.7902e-02, -9.5189e-02,  6.2802e-02,  1.1225e-01,\n         -7.9731e-02,  1.4125e-01,  1.4366e-01, -1.4606e-01,  1.3062e-01,\n         -9.6466e-02, -1.3884e-01,  5.3854e-02,  8.6621e-02, -8.5250e-02,\n         -1.0731e-01,  1.2308e-01],\n        [-1.6140e-01,  1.5287e-01,  1.6719e-01,  1.7119e-01, -1.2153e-01,\n          2.6394e-02,  8.5604e-02,  3.3338e-02, -7.7942e-02,  1.3739e-01,\n          1.1543e-01, -1.1884e-01, -1.1527e-01, -1.4819e-01, -4.6152e-02,\n         -5.8722e-02, -1.6329e-01,  9.5381e-02,  3.0342e-02,  4.9545e-02,\n          1.0280e-01, -1.4243e-01, -1.0527e-01, -1.7456e-01, -1.2897e-01,\n          6.0796e-02, -9.6584e-03,  1.3854e-01,  4.5472e-02,  7.1688e-02,\n         -6.3993e-02,  2.5493e-02],\n        [-1.6980e-01,  9.6832e-02, -9.0870e-02,  1.6844e-01,  1.2491e-01,\n          5.2744e-02,  6.1502e-02, -1.1715e-01, -2.8701e-02,  9.3572e-02,\n          1.2715e-01,  1.4064e-02, -3.6118e-02, -5.7542e-02,  7.7040e-02,\n         -7.6166e-02,  1.4926e-01, -5.6698e-02,  1.2551e-01,  7.0998e-03,\n          4.2221e-02,  4.3611e-02, -1.4825e-01,  7.1959e-02,  5.5633e-02,\n          1.1664e-01, -8.2832e-02, -1.3384e-01, -8.3148e-02, -1.1441e-01,\n         -1.0421e-01, -1.4235e-01],\n        [-8.3864e-03, -1.4026e-01,  1.7211e-01,  1.6665e-01,  1.0463e-01,\n          9.1399e-02,  3.3161e-02,  4.1695e-02,  1.4268e-01, -8.4024e-02,\n          1.1804e-01, -7.3286e-03,  1.2015e-01,  6.6630e-02, -2.4005e-02,\n         -1.3465e-01, -1.5998e-02, -6.7131e-02, -9.2237e-02, -4.3076e-02,\n          9.1833e-02,  1.6600e-01,  2.2903e-02, -1.4896e-01,  1.0968e-01,\n          1.5106e-01, -9.0910e-02, -7.6702e-02,  4.5419e-02,  1.1455e-01,\n         -1.6070e-01,  2.6006e-03],\n        [ 8.0335e-02, -1.3316e-01, -1.5396e-01, -1.6082e-01, -5.2404e-02,\n         -1.2812e-01,  1.3054e-02,  1.0831e-01,  2.4705e-02,  1.4011e-01,\n         -1.3808e-01,  8.7470e-02, -4.5746e-02, -1.2794e-01, -5.5369e-02,\n          1.2005e-01,  7.5594e-02,  1.7881e-02,  4.2784e-02, -1.5668e-02,\n         -1.6654e-01,  1.4823e-01,  6.5999e-02,  5.0840e-02,  7.9281e-02,\n          8.1970e-02, -1.6477e-01,  1.2220e-01, -8.7468e-02, -1.7228e-01,\n         -2.6049e-02,  4.2230e-02],\n        [-9.7881e-02,  5.1628e-02,  1.0144e-02,  5.4793e-02,  6.9702e-02,\n          1.0746e-01, -1.4198e-01, -8.4317e-02, -1.5832e-01, -2.3262e-02,\n         -1.5673e-01,  1.7235e-01,  1.9340e-02,  1.5882e-01, -6.0605e-02,\n         -1.0076e-01,  4.7440e-02,  5.3191e-03, -8.4089e-02,  1.0391e-01,\n         -1.6050e-01,  1.5217e-01, -5.1065e-02, -4.2069e-02, -1.4532e-01,\n          4.3100e-02,  1.2129e-01,  5.2496e-02,  3.0082e-03,  6.9681e-03,\n         -1.1112e-01, -8.9421e-02],\n        [ 1.4859e-01, -9.5893e-03, -1.6513e-01, -1.3862e-01, -1.3379e-02,\n          1.3825e-01, -7.2564e-02,  1.3881e-01, -1.7479e-01,  1.3801e-01,\n         -4.9265e-02, -6.5497e-02,  1.5204e-01, -1.6067e-01, -5.0612e-02,\n         -5.3376e-02, -4.3495e-02,  7.6169e-02, -6.6637e-02,  1.1464e-01,\n         -1.4351e-01, -1.5047e-01,  8.5147e-02, -3.2087e-02,  1.3777e-01,\n         -2.5864e-02, -1.6932e-01,  1.0852e-02, -3.3445e-02,  4.0105e-02,\n          9.3328e-02, -3.2456e-02],\n        [-2.2780e-02, -7.4409e-02, -4.9189e-02, -2.0776e-02,  4.6551e-02,\n          9.3154e-02, -7.7726e-02,  6.9394e-02,  8.3048e-02, -7.3959e-02,\n         -1.0581e-01, -2.2733e-02, -7.7818e-02, -1.2631e-02,  2.6244e-02,\n         -1.4323e-01, -8.7423e-02, -5.8413e-02,  1.6293e-01,  1.0165e-01,\n         -6.3065e-02, -1.5215e-01, -1.4501e-04, -5.7718e-02,  3.2146e-02,\n          1.2073e-01,  7.5048e-02, -7.2995e-02,  8.3639e-02,  1.0908e-01,\n          3.1216e-02,  1.6137e-01],\n        [-6.8265e-03,  1.4436e-01, -1.2957e-01, -1.3988e-01, -1.3757e-01,\n          1.7241e-01,  5.5994e-02, -8.8372e-02, -1.7806e-02,  8.6385e-02,\n          8.5119e-02,  1.5743e-01,  8.5629e-02, -1.5711e-01,  1.0577e-01,\n         -1.1324e-01, -1.3371e-01,  9.6753e-02,  9.5932e-02,  1.2442e-01,\n          7.9731e-02,  1.5897e-01, -1.4479e-01, -1.1891e-02, -1.3917e-01,\n         -1.6576e-01,  1.4940e-01,  5.8628e-02, -1.2309e-01,  1.6548e-01,\n         -1.2782e-01, -8.1809e-02],\n        [-6.9391e-03, -4.8028e-02,  1.1353e-01, -1.1631e-01, -1.1103e-02,\n          1.4033e-01, -1.0771e-01,  1.2940e-01,  5.3300e-02,  1.4300e-01,\n          1.2807e-01,  1.6002e-01,  1.3489e-01, -4.7300e-02,  2.0761e-03,\n          7.1231e-02, -8.6346e-03,  2.6451e-02,  8.5930e-02,  1.0365e-01,\n         -5.4066e-02,  1.4156e-01, -1.6553e-01, -1.5491e-01,  2.3825e-02,\n         -1.4420e-01,  1.5988e-01, -8.5633e-02,  6.8806e-02, -1.6724e-01,\n         -8.7565e-02, -2.2065e-02],\n        [ 1.4168e-01,  1.7258e-01,  3.0827e-02, -1.1182e-01,  9.5845e-02,\n          1.0455e-01, -5.5114e-02, -1.1231e-01, -1.6433e-01,  1.3388e-01,\n         -1.4222e-01, -2.4350e-02,  8.0301e-03,  1.3237e-01, -1.7658e-01,\n          1.3846e-01,  5.4521e-02, -1.4827e-01,  1.5763e-01, -6.3717e-02,\n         -1.4217e-01, -9.8106e-02, -1.2460e-01,  1.4485e-01, -2.4605e-02,\n         -3.7757e-02, -4.5659e-02,  1.7166e-01, -1.4890e-02, -6.2945e-03,\n          1.6744e-01, -1.4491e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2113, -0.1140,  0.2422, -0.0660, -0.2445, -0.0513, -0.1156,  0.1605],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.6790e-01, -1.9125e-01, -2.0014e-01,  5.9060e-02,  1.0643e-03,\n          4.6470e-02,  2.0061e-01,  9.0686e-02,  1.2389e-01, -8.3318e-02,\n          1.3111e-01, -1.0350e-01,  1.1533e-01,  1.2239e-01,  1.5138e-01,\n         -9.4537e-02],\n        [-1.7303e-01, -2.1978e-02,  1.3516e-01, -1.8074e-01, -1.7781e-01,\n          7.3105e-02,  1.6720e-01, -1.1545e-02, -1.5351e-01, -2.3725e-01,\n          1.0534e-01,  1.1001e-01, -1.7280e-01, -1.8183e-01, -1.8928e-01,\n          4.7240e-02],\n        [-1.3524e-01,  1.7468e-01,  1.4949e-01, -5.9550e-02, -2.1011e-01,\n          1.8594e-01, -6.5046e-02,  7.7836e-02,  1.2744e-01, -1.3814e-01,\n         -1.5677e-01,  1.7480e-02, -4.5306e-02, -9.5914e-02, -2.3972e-01,\n          3.5532e-02],\n        [-7.8047e-02, -1.2948e-01, -5.2391e-02,  1.0941e-01,  3.9453e-02,\n          1.1460e-01, -1.8425e-01, -1.2865e-01, -7.1115e-02,  1.0543e-01,\n          5.7574e-02,  1.4943e-01,  1.5890e-01,  2.3248e-01,  1.5171e-01,\n          2.2280e-02],\n        [ 1.9283e-01, -1.3409e-01,  5.4319e-02, -4.8275e-02,  1.9931e-01,\n          1.8851e-01, -7.9031e-02,  1.9779e-02, -2.4497e-01,  1.6651e-01,\n          2.0230e-01,  1.3167e-01,  1.3251e-02, -2.3987e-02,  7.8370e-02,\n          2.1215e-01],\n        [-1.4305e-01, -3.9616e-02, -1.9853e-01,  1.7877e-01,  2.0563e-01,\n         -1.0486e-01, -1.1852e-01,  1.3619e-01, -3.4452e-02, -2.2219e-01,\n         -2.3574e-01, -1.6023e-01, -2.3125e-01,  4.3589e-04, -9.3546e-03,\n          2.0517e-01],\n        [-1.1897e-01, -8.2386e-02, -1.9080e-01, -7.3372e-02, -4.6702e-03,\n         -9.1359e-02,  7.4814e-02, -1.6374e-01,  2.1959e-01,  2.3674e-01,\n         -2.0907e-01, -8.5374e-02,  5.2608e-02,  2.3154e-02, -3.4977e-02,\n          1.5592e-02],\n        [-2.0892e-01,  1.6602e-01,  2.0352e-01,  1.8246e-01,  1.4659e-01,\n          1.7861e-01,  5.9870e-03, -2.2802e-01,  8.3158e-02, -1.4220e-01,\n         -2.1669e-04,  1.2162e-01,  1.4152e-01,  1.3871e-02,  1.5386e-01,\n         -3.2322e-03]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0307,  0.3258, -0.1576,  0.3026], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2357, -0.3036, -0.2550, -0.1328,  0.3001,  0.2793,  0.1631,  0.3279],\n        [-0.1211, -0.2132,  0.2771,  0.0490, -0.1318, -0.0230, -0.1927,  0.3257],\n        [-0.1021,  0.2914, -0.0572, -0.1765,  0.2479, -0.2613, -0.1884, -0.0334],\n        [-0.2043,  0.0792,  0.2360,  0.1133,  0.2444, -0.1064,  0.2032,  0.0852]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7bd5dc39d890>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s341580000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s341580000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}