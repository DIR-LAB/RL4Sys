{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s342980000"
    },
    "q_lr":	0.0005,
    "seed":	342980000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7e781d158710>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2359,  0.2095, -0.0780,  0.1294, -0.0985, -0.1883, -0.1308,  0.2636,\n        -0.1196, -0.0170, -0.1204,  0.3316,  0.0670,  0.2467, -0.2675, -0.2280,\n         0.3136, -0.1205, -0.0653, -0.1175, -0.2647, -0.0589,  0.1745, -0.3532,\n         0.2092,  0.1948, -0.0875, -0.3163, -0.1068,  0.2763, -0.1044,  0.3456],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-3.1507e-01,  2.9241e-04,  2.1310e-01, -3.1243e-01,  3.4395e-01,\n          3.0971e-01,  2.5832e-02, -1.6303e-01],\n        [ 5.2009e-02,  1.4318e-01,  5.5891e-02, -2.2555e-03, -3.1360e-01,\n          3.0938e-01,  2.1563e-01, -5.4779e-02],\n        [-2.3187e-01,  1.5709e-01,  2.6051e-01,  2.1622e-01, -9.6420e-02,\n         -1.9939e-01, -5.9207e-02,  7.2606e-02],\n        [-6.9765e-03, -1.7082e-01,  1.0345e-01,  3.3876e-02, -4.1320e-02,\n          6.7782e-02,  1.0674e-01,  1.3222e-01],\n        [-2.2591e-01,  2.3801e-02, -1.8580e-01,  8.5783e-02,  3.4257e-01,\n         -9.5345e-02, -1.1379e-01, -1.4472e-01],\n        [-2.5578e-01,  2.4332e-01,  1.6623e-02,  3.2802e-02,  7.8358e-02,\n         -2.6938e-01,  2.4160e-01, -2.1516e-01],\n        [-1.9317e-01, -2.4888e-01,  5.5961e-03,  2.9556e-01,  5.7566e-02,\n          1.5498e-03,  1.2436e-01,  2.0334e-02],\n        [ 1.4120e-01, -3.4352e-01,  3.1360e-01, -2.8416e-01, -1.4401e-01,\n          2.7271e-01, -3.2856e-01,  3.4976e-01],\n        [ 3.2819e-01,  3.4903e-01,  2.2498e-01,  3.0889e-01, -3.2610e-01,\n          1.8098e-01,  2.5769e-01, -1.2390e-01],\n        [-7.9394e-02,  1.8651e-02, -1.2308e-02,  1.7197e-01,  1.4596e-01,\n         -2.2491e-01, -2.1299e-01,  3.1251e-01],\n        [ 7.1511e-02, -2.2654e-01,  1.8945e-01, -1.9190e-01, -1.2732e-01,\n          8.6480e-02, -2.6809e-01,  2.8064e-02],\n        [-2.6923e-01, -2.8786e-01, -6.7180e-02, -2.3885e-01,  1.7072e-01,\n         -6.9663e-02, -2.8685e-01, -2.8834e-01],\n        [-3.4188e-01, -8.6341e-02,  9.7627e-02,  2.5564e-01,  5.2315e-02,\n         -3.2016e-01, -3.1575e-01, -1.8665e-01],\n        [-2.1928e-01,  1.1254e-01, -6.7742e-02,  2.1997e-01, -9.3205e-03,\n         -2.6735e-01,  1.3470e-01,  7.8144e-02],\n        [-7.6613e-02,  1.9342e-01,  3.0340e-01,  4.0803e-02, -1.7137e-02,\n         -2.5311e-01, -2.3591e-01, -1.4051e-01],\n        [-2.9229e-01,  1.0080e-01, -2.6890e-01, -2.2974e-01, -1.2178e-02,\n          1.1540e-01,  5.6064e-02, -1.4916e-01],\n        [-1.8655e-02, -2.9013e-01, -3.4727e-01,  1.9975e-01,  1.8002e-01,\n         -3.7528e-02, -2.2363e-01, -1.6517e-01],\n        [ 2.4272e-01,  1.2050e-01,  6.8689e-02,  3.1148e-02,  2.4445e-01,\n          3.1204e-01,  6.1401e-02,  1.7035e-01],\n        [-1.6918e-02, -3.3710e-01,  2.3719e-01, -1.4813e-02,  9.9082e-02,\n         -5.0416e-02,  8.5228e-02,  3.1387e-01],\n        [-2.9078e-01,  2.9684e-01,  2.1789e-01, -2.7148e-01, -1.8876e-01,\n         -7.9738e-02,  9.2847e-02, -2.9989e-01],\n        [-2.7443e-01, -2.1590e-01, -5.8925e-02,  1.7280e-01, -1.5014e-01,\n         -3.2846e-01, -9.2969e-02,  2.5701e-01],\n        [-1.4969e-01, -2.0819e-01,  3.8353e-02, -3.3613e-01, -1.8183e-01,\n         -4.7162e-03, -8.7719e-02, -1.2519e-01],\n        [-2.1144e-01, -2.3718e-01, -3.5191e-01,  3.1229e-01,  2.7141e-01,\n         -2.8238e-02, -1.9671e-01, -3.1580e-02],\n        [ 2.7688e-01,  1.9577e-01, -1.0288e-01, -6.3999e-02, -1.0918e-01,\n         -2.6457e-01, -9.8496e-02, -2.5421e-01],\n        [ 2.4000e-01,  1.6373e-01, -2.8379e-01, -6.6231e-02, -2.8875e-01,\n         -2.4029e-01, -3.3996e-01,  2.8537e-01],\n        [-3.0115e-01,  1.2552e-01,  2.5358e-01, -1.0122e-01,  1.8471e-01,\n         -1.2914e-01, -2.5071e-01,  1.0736e-01],\n        [-2.0843e-01, -1.5869e-01, -2.7231e-01, -2.5350e-01,  1.3022e-01,\n          1.4708e-01,  3.0753e-01,  3.2102e-01],\n        [ 9.5073e-02, -1.1667e-01, -6.4100e-02, -2.0262e-01,  9.3673e-02,\n          2.7166e-01,  2.6873e-01, -2.0267e-01],\n        [ 2.4230e-01, -8.5687e-02, -3.3360e-01,  8.7551e-02,  1.0112e-02,\n          2.4106e-01, -1.2494e-01,  1.6047e-01],\n        [ 3.9157e-02,  2.6657e-01, -1.2611e-01, -1.9573e-01, -1.0695e-01,\n         -2.6451e-01, -3.1969e-01, -3.1717e-01],\n        [-8.6262e-02,  1.9342e-01,  6.6650e-02,  3.2215e-01, -1.3921e-01,\n          2.5382e-01,  9.3572e-02, -2.2102e-01],\n        [ 1.7927e-01,  1.8017e-01, -2.3283e-01, -3.3322e-01, -2.9045e-01,\n          2.5714e-01,  1.2324e-01, -6.5996e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0519, -0.0996, -0.1032, -0.1617,  0.0524, -0.1570,  0.0440,  0.1277,\n        -0.0743,  0.0094, -0.0872,  0.1659, -0.0798, -0.0244,  0.1012,  0.0504],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0114, -0.0833,  0.0699,  0.0768, -0.1002,  0.1196, -0.0557,  0.1590,\n         -0.1465,  0.0633,  0.0199,  0.1348, -0.0263, -0.1033, -0.0956, -0.0662,\n          0.0728,  0.1064,  0.0849, -0.1260,  0.1170, -0.0678,  0.0674,  0.1041,\n         -0.1164,  0.1731,  0.0951,  0.1103,  0.1736, -0.0284,  0.1132, -0.1004],\n        [-0.0679, -0.0748,  0.0884, -0.0136, -0.0246, -0.0902, -0.0569,  0.0721,\n         -0.0408,  0.0206, -0.0211, -0.0505,  0.0292, -0.1658,  0.0155, -0.1068,\n          0.0540,  0.1679,  0.1197,  0.1217, -0.0201,  0.0999, -0.0918,  0.0842,\n         -0.1328, -0.0050, -0.1352,  0.1752,  0.1019, -0.0128, -0.0153, -0.0351],\n        [-0.0307,  0.0875,  0.0037, -0.0177,  0.1058, -0.0559, -0.0067, -0.0411,\n         -0.0571, -0.1548, -0.0390,  0.1172,  0.1379, -0.1139,  0.0449, -0.1661,\n         -0.1003,  0.1325,  0.0152,  0.1068, -0.1463, -0.1483,  0.0586,  0.0931,\n          0.1278,  0.1693, -0.0486, -0.1400,  0.0106, -0.0060,  0.1445,  0.0872],\n        [-0.0280,  0.0552,  0.0695, -0.1345, -0.1017,  0.0709,  0.0637,  0.0895,\n          0.1765, -0.0040,  0.0987,  0.1225, -0.0551,  0.0482, -0.0502, -0.1194,\n         -0.0856, -0.0186, -0.1159,  0.1612,  0.0307,  0.0032, -0.0900, -0.1749,\n          0.1264,  0.0861, -0.0062,  0.1504, -0.1615, -0.1294,  0.0336, -0.0009],\n        [-0.1297, -0.1328, -0.0509, -0.1269, -0.0468,  0.1303,  0.0561,  0.0694,\n          0.1342, -0.1025, -0.1280, -0.0057, -0.1605,  0.0929, -0.1766, -0.0019,\n         -0.0891,  0.1028,  0.1219,  0.1281, -0.1523,  0.1389,  0.0436,  0.0599,\n         -0.1086,  0.1448,  0.0006,  0.0655, -0.1432,  0.0817,  0.0688, -0.1313],\n        [-0.0864,  0.0478, -0.1523, -0.1332,  0.0077,  0.0154,  0.1017,  0.0294,\n         -0.0916,  0.1384, -0.0888, -0.1038,  0.1135, -0.1189, -0.1542,  0.0726,\n          0.1437,  0.0607, -0.1300,  0.0721,  0.0025,  0.0631, -0.1762, -0.0241,\n          0.1410, -0.1044, -0.0225,  0.0640, -0.0182, -0.0267,  0.0917,  0.0683],\n        [ 0.0528, -0.0824, -0.1748, -0.1440, -0.0066, -0.0555,  0.0975, -0.0591,\n          0.1013, -0.0752,  0.0915,  0.0357, -0.1354, -0.0040, -0.0560, -0.1327,\n          0.1007, -0.1742, -0.0022, -0.1344,  0.0503, -0.0145, -0.1447,  0.1392,\n         -0.0513, -0.1059, -0.1377,  0.1614, -0.0765,  0.1188, -0.0943, -0.0474],\n        [ 0.1625, -0.0055,  0.0272,  0.0828, -0.0163,  0.0533,  0.0057,  0.0923,\n         -0.0369, -0.0094, -0.0367, -0.0598,  0.0100,  0.0077, -0.1207,  0.0591,\n         -0.0877, -0.0199, -0.1704,  0.0076, -0.1138, -0.0626,  0.0540, -0.1078,\n          0.0773,  0.1475, -0.1276, -0.1308,  0.0985,  0.1592,  0.1069, -0.1710],\n        [ 0.1480,  0.0168, -0.0306,  0.0673, -0.1358,  0.1629,  0.1586,  0.0713,\n          0.0119, -0.1284,  0.0751,  0.0943,  0.1370,  0.0724, -0.1144,  0.0950,\n         -0.1153,  0.0148,  0.0643,  0.1266,  0.1544,  0.0863,  0.0926, -0.0290,\n         -0.1271,  0.0985, -0.0765, -0.0554,  0.1447, -0.0953,  0.0471,  0.1432],\n        [-0.1593, -0.0652, -0.0016, -0.0732, -0.0562,  0.0105, -0.1156, -0.0345,\n          0.1308,  0.0673, -0.1562, -0.0802,  0.0961,  0.1359, -0.0023,  0.0172,\n         -0.0978, -0.0198,  0.0490, -0.1734, -0.0178,  0.1714, -0.0266,  0.1252,\n         -0.1235,  0.0693, -0.0391,  0.1420,  0.0848, -0.1402, -0.1414,  0.0915],\n        [ 0.0590, -0.0753, -0.1727,  0.0586, -0.1407,  0.0260, -0.1321,  0.1136,\n         -0.0506, -0.1308,  0.1459,  0.1746, -0.0610,  0.0422, -0.1180, -0.1753,\n          0.0815,  0.0321, -0.0495, -0.0294,  0.1726,  0.1471, -0.0708,  0.1157,\n          0.1512, -0.0545,  0.1171,  0.1251, -0.0098, -0.1200,  0.0604, -0.0602],\n        [-0.1665,  0.0648, -0.0320, -0.1466, -0.0182, -0.0207, -0.0205,  0.1481,\n         -0.0821,  0.1287, -0.0892, -0.0692,  0.0955,  0.1222, -0.1172,  0.0071,\n          0.0518, -0.0756, -0.1575, -0.0265,  0.0192,  0.0253, -0.1584, -0.0587,\n          0.0096, -0.0140,  0.0897, -0.0250,  0.0023, -0.0388,  0.0934,  0.1363],\n        [-0.0476, -0.0102, -0.1265,  0.0057, -0.0574,  0.1007, -0.0472,  0.1252,\n          0.1720,  0.0857, -0.0211,  0.0262,  0.0461,  0.1315, -0.1191, -0.0833,\n         -0.0017, -0.1551,  0.0087,  0.0538, -0.0034,  0.0653,  0.1660,  0.0758,\n          0.0970,  0.0952,  0.1093, -0.0179,  0.0773,  0.1700, -0.0773, -0.1240],\n        [-0.0610,  0.1393,  0.0215, -0.0386,  0.1429,  0.1453,  0.0392, -0.1030,\n          0.0959,  0.0534,  0.0194, -0.0467, -0.0162,  0.0970,  0.1168,  0.0812,\n         -0.0726, -0.0231, -0.1626, -0.0069, -0.1021,  0.0429, -0.1360, -0.1135,\n         -0.0432, -0.1490, -0.0905,  0.0750, -0.1369,  0.1550,  0.0036, -0.1720],\n        [ 0.0787, -0.1107, -0.0715,  0.0764, -0.1540,  0.0243, -0.1253, -0.0331,\n          0.1408, -0.1396,  0.0189,  0.1447, -0.0809, -0.1479, -0.0376,  0.0836,\n          0.1460, -0.0027, -0.0669, -0.0340,  0.1037, -0.0541, -0.0440,  0.0028,\n          0.0759,  0.0113,  0.0853,  0.0046, -0.1240, -0.1474,  0.0436,  0.1074],\n        [ 0.0329, -0.1389, -0.0350, -0.1481, -0.1604,  0.0119, -0.0874, -0.1433,\n         -0.0277,  0.0109, -0.0378, -0.1134,  0.1361, -0.0119, -0.1551, -0.1158,\n          0.1238, -0.0681,  0.0152, -0.1489,  0.1481, -0.0152,  0.1258,  0.0078,\n         -0.0427, -0.1254, -0.0925,  0.1149,  0.0085, -0.0250, -0.0273,  0.0838]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0275,  0.1370,  0.2284,  0.2374,  0.0636, -0.2066, -0.0320, -0.2084],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1902,  0.2116,  0.1593,  0.1383,  0.1736, -0.1961, -0.1849,  0.1564,\n         -0.0235, -0.0794,  0.0211, -0.1149,  0.0130,  0.1524,  0.1388,  0.0204],\n        [-0.0741, -0.1513, -0.1956,  0.0274,  0.1534,  0.0140,  0.2482,  0.0161,\n         -0.1028,  0.1823,  0.0375,  0.0747, -0.1708,  0.0269, -0.0316, -0.2492],\n        [ 0.2332, -0.1317,  0.1302,  0.2316,  0.1079,  0.0282, -0.2463,  0.2154,\n          0.1826,  0.1919, -0.0999,  0.0990, -0.1136, -0.0047, -0.1881,  0.0665],\n        [-0.1425, -0.0545,  0.1333, -0.0189, -0.1755, -0.0920, -0.0900,  0.2192,\n          0.0562,  0.0119,  0.0712, -0.0611, -0.2141,  0.1306, -0.0833,  0.0791],\n        [-0.0874, -0.1347,  0.1543,  0.0008, -0.0345,  0.1112,  0.0823, -0.1462,\n         -0.1344, -0.2404, -0.1674,  0.1916, -0.0079, -0.1272, -0.1486,  0.0210],\n        [ 0.1008,  0.0495,  0.0326,  0.1940, -0.1314, -0.1189,  0.2230, -0.2196,\n          0.2191,  0.1025,  0.0529, -0.0633,  0.2345, -0.0154,  0.1088, -0.1016],\n        [-0.2190,  0.1479,  0.1970, -0.1856,  0.0051,  0.2053, -0.1540,  0.0797,\n         -0.1303, -0.1236,  0.0164, -0.2360,  0.0558, -0.1706,  0.0987,  0.1368],\n        [ 0.1918,  0.1357, -0.1776,  0.0545,  0.1079,  0.2207, -0.2373, -0.0183,\n         -0.0306,  0.2436,  0.1243,  0.1049, -0.1100, -0.2147,  0.0936, -0.0945]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0197,  0.3448, -0.0091, -0.2366], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0206,  0.2068, -0.2965,  0.1300, -0.0133,  0.2193,  0.3202,  0.0162],\n        [-0.0875, -0.1540,  0.2448, -0.0765,  0.1255, -0.3452,  0.1363,  0.2397],\n        [-0.1658,  0.1755, -0.1080, -0.3317,  0.1099, -0.2445, -0.3500, -0.0624],\n        [ 0.0835,  0.1044, -0.3255,  0.1536,  0.3025, -0.1563,  0.2861,  0.2829]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-3.1507e-01,  2.9241e-04,  2.1310e-01, -3.1243e-01,  3.4395e-01,\n          3.0971e-01,  2.5832e-02, -1.6303e-01],\n        [ 5.2009e-02,  1.4318e-01,  5.5891e-02, -2.2555e-03, -3.1360e-01,\n          3.0938e-01,  2.1563e-01, -5.4779e-02],\n        [-2.3187e-01,  1.5709e-01,  2.6051e-01,  2.1622e-01, -9.6420e-02,\n         -1.9939e-01, -5.9207e-02,  7.2606e-02],\n        [-6.9765e-03, -1.7082e-01,  1.0345e-01,  3.3876e-02, -4.1320e-02,\n          6.7782e-02,  1.0674e-01,  1.3222e-01],\n        [-2.2591e-01,  2.3801e-02, -1.8580e-01,  8.5783e-02,  3.4257e-01,\n         -9.5345e-02, -1.1379e-01, -1.4472e-01],\n        [-2.5578e-01,  2.4332e-01,  1.6623e-02,  3.2802e-02,  7.8358e-02,\n         -2.6938e-01,  2.4160e-01, -2.1516e-01],\n        [-1.9317e-01, -2.4888e-01,  5.5961e-03,  2.9556e-01,  5.7566e-02,\n          1.5498e-03,  1.2436e-01,  2.0334e-02],\n        [ 1.4120e-01, -3.4352e-01,  3.1360e-01, -2.8416e-01, -1.4401e-01,\n          2.7271e-01, -3.2856e-01,  3.4976e-01],\n        [ 3.2819e-01,  3.4903e-01,  2.2498e-01,  3.0889e-01, -3.2610e-01,\n          1.8098e-01,  2.5769e-01, -1.2390e-01],\n        [-7.9394e-02,  1.8651e-02, -1.2308e-02,  1.7197e-01,  1.4596e-01,\n         -2.2491e-01, -2.1299e-01,  3.1251e-01],\n        [ 7.1511e-02, -2.2654e-01,  1.8945e-01, -1.9190e-01, -1.2732e-01,\n          8.6480e-02, -2.6809e-01,  2.8064e-02],\n        [-2.6923e-01, -2.8786e-01, -6.7180e-02, -2.3885e-01,  1.7072e-01,\n         -6.9663e-02, -2.8685e-01, -2.8834e-01],\n        [-3.4188e-01, -8.6341e-02,  9.7627e-02,  2.5564e-01,  5.2315e-02,\n         -3.2016e-01, -3.1575e-01, -1.8665e-01],\n        [-2.1928e-01,  1.1254e-01, -6.7742e-02,  2.1997e-01, -9.3205e-03,\n         -2.6735e-01,  1.3470e-01,  7.8144e-02],\n        [-7.6613e-02,  1.9342e-01,  3.0340e-01,  4.0803e-02, -1.7137e-02,\n         -2.5311e-01, -2.3591e-01, -1.4051e-01],\n        [-2.9229e-01,  1.0080e-01, -2.6890e-01, -2.2974e-01, -1.2178e-02,\n          1.1540e-01,  5.6064e-02, -1.4916e-01],\n        [-1.8655e-02, -2.9013e-01, -3.4727e-01,  1.9975e-01,  1.8002e-01,\n         -3.7528e-02, -2.2363e-01, -1.6517e-01],\n        [ 2.4272e-01,  1.2050e-01,  6.8689e-02,  3.1148e-02,  2.4445e-01,\n          3.1204e-01,  6.1401e-02,  1.7035e-01],\n        [-1.6918e-02, -3.3710e-01,  2.3719e-01, -1.4813e-02,  9.9082e-02,\n         -5.0416e-02,  8.5228e-02,  3.1387e-01],\n        [-2.9078e-01,  2.9684e-01,  2.1789e-01, -2.7148e-01, -1.8876e-01,\n         -7.9738e-02,  9.2847e-02, -2.9989e-01],\n        [-2.7443e-01, -2.1590e-01, -5.8925e-02,  1.7280e-01, -1.5014e-01,\n         -3.2846e-01, -9.2969e-02,  2.5701e-01],\n        [-1.4969e-01, -2.0819e-01,  3.8353e-02, -3.3613e-01, -1.8183e-01,\n         -4.7162e-03, -8.7719e-02, -1.2519e-01],\n        [-2.1144e-01, -2.3718e-01, -3.5191e-01,  3.1229e-01,  2.7141e-01,\n         -2.8238e-02, -1.9671e-01, -3.1580e-02],\n        [ 2.7688e-01,  1.9577e-01, -1.0288e-01, -6.3999e-02, -1.0918e-01,\n         -2.6457e-01, -9.8496e-02, -2.5421e-01],\n        [ 2.4000e-01,  1.6373e-01, -2.8379e-01, -6.6231e-02, -2.8875e-01,\n         -2.4029e-01, -3.3996e-01,  2.8537e-01],\n        [-3.0115e-01,  1.2552e-01,  2.5358e-01, -1.0122e-01,  1.8471e-01,\n         -1.2914e-01, -2.5071e-01,  1.0736e-01],\n        [-2.0843e-01, -1.5869e-01, -2.7231e-01, -2.5350e-01,  1.3022e-01,\n          1.4708e-01,  3.0753e-01,  3.2102e-01],\n        [ 9.5073e-02, -1.1667e-01, -6.4100e-02, -2.0262e-01,  9.3673e-02,\n          2.7166e-01,  2.6873e-01, -2.0267e-01],\n        [ 2.4230e-01, -8.5687e-02, -3.3360e-01,  8.7551e-02,  1.0112e-02,\n          2.4106e-01, -1.2494e-01,  1.6047e-01],\n        [ 3.9157e-02,  2.6657e-01, -1.2611e-01, -1.9573e-01, -1.0695e-01,\n         -2.6451e-01, -3.1969e-01, -3.1717e-01],\n        [-8.6262e-02,  1.9342e-01,  6.6650e-02,  3.2215e-01, -1.3921e-01,\n          2.5382e-01,  9.3572e-02, -2.2102e-01],\n        [ 1.7927e-01,  1.8017e-01, -2.3283e-01, -3.3322e-01, -2.9045e-01,\n          2.5714e-01,  1.2324e-01, -6.5996e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2359,  0.2095, -0.0780,  0.1294, -0.0985, -0.1883, -0.1308,  0.2636,\n        -0.1196, -0.0170, -0.1204,  0.3316,  0.0670,  0.2467, -0.2675, -0.2280,\n         0.3136, -0.1205, -0.0653, -0.1175, -0.2647, -0.0589,  0.1745, -0.3532,\n         0.2092,  0.1948, -0.0875, -0.3163, -0.1068,  0.2763, -0.1044,  0.3456],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0114, -0.0833,  0.0699,  0.0768, -0.1002,  0.1196, -0.0557,  0.1590,\n         -0.1465,  0.0633,  0.0199,  0.1348, -0.0263, -0.1033, -0.0956, -0.0662,\n          0.0728,  0.1064,  0.0849, -0.1260,  0.1170, -0.0678,  0.0674,  0.1041,\n         -0.1164,  0.1731,  0.0951,  0.1103,  0.1736, -0.0284,  0.1132, -0.1004],\n        [-0.0679, -0.0748,  0.0884, -0.0136, -0.0246, -0.0902, -0.0569,  0.0721,\n         -0.0408,  0.0206, -0.0211, -0.0505,  0.0292, -0.1658,  0.0155, -0.1068,\n          0.0540,  0.1679,  0.1197,  0.1217, -0.0201,  0.0999, -0.0918,  0.0842,\n         -0.1328, -0.0050, -0.1352,  0.1752,  0.1019, -0.0128, -0.0153, -0.0351],\n        [-0.0307,  0.0875,  0.0037, -0.0177,  0.1058, -0.0559, -0.0067, -0.0411,\n         -0.0571, -0.1548, -0.0390,  0.1172,  0.1379, -0.1139,  0.0449, -0.1661,\n         -0.1003,  0.1325,  0.0152,  0.1068, -0.1463, -0.1483,  0.0586,  0.0931,\n          0.1278,  0.1693, -0.0486, -0.1400,  0.0106, -0.0060,  0.1445,  0.0872],\n        [-0.0280,  0.0552,  0.0695, -0.1345, -0.1017,  0.0709,  0.0637,  0.0895,\n          0.1765, -0.0040,  0.0987,  0.1225, -0.0551,  0.0482, -0.0502, -0.1194,\n         -0.0856, -0.0186, -0.1159,  0.1612,  0.0307,  0.0032, -0.0900, -0.1749,\n          0.1264,  0.0861, -0.0062,  0.1504, -0.1615, -0.1294,  0.0336, -0.0009],\n        [-0.1297, -0.1328, -0.0509, -0.1269, -0.0468,  0.1303,  0.0561,  0.0694,\n          0.1342, -0.1025, -0.1280, -0.0057, -0.1605,  0.0929, -0.1766, -0.0019,\n         -0.0891,  0.1028,  0.1219,  0.1281, -0.1523,  0.1389,  0.0436,  0.0599,\n         -0.1086,  0.1448,  0.0006,  0.0655, -0.1432,  0.0817,  0.0688, -0.1313],\n        [-0.0864,  0.0478, -0.1523, -0.1332,  0.0077,  0.0154,  0.1017,  0.0294,\n         -0.0916,  0.1384, -0.0888, -0.1038,  0.1135, -0.1189, -0.1542,  0.0726,\n          0.1437,  0.0607, -0.1300,  0.0721,  0.0025,  0.0631, -0.1762, -0.0241,\n          0.1410, -0.1044, -0.0225,  0.0640, -0.0182, -0.0267,  0.0917,  0.0683],\n        [ 0.0528, -0.0824, -0.1748, -0.1440, -0.0066, -0.0555,  0.0975, -0.0591,\n          0.1013, -0.0752,  0.0915,  0.0357, -0.1354, -0.0040, -0.0560, -0.1327,\n          0.1007, -0.1742, -0.0022, -0.1344,  0.0503, -0.0145, -0.1447,  0.1392,\n         -0.0513, -0.1059, -0.1377,  0.1614, -0.0765,  0.1188, -0.0943, -0.0474],\n        [ 0.1625, -0.0055,  0.0272,  0.0828, -0.0163,  0.0533,  0.0057,  0.0923,\n         -0.0369, -0.0094, -0.0367, -0.0598,  0.0100,  0.0077, -0.1207,  0.0591,\n         -0.0877, -0.0199, -0.1704,  0.0076, -0.1138, -0.0626,  0.0540, -0.1078,\n          0.0773,  0.1475, -0.1276, -0.1308,  0.0985,  0.1592,  0.1069, -0.1710],\n        [ 0.1480,  0.0168, -0.0306,  0.0673, -0.1358,  0.1629,  0.1586,  0.0713,\n          0.0119, -0.1284,  0.0751,  0.0943,  0.1370,  0.0724, -0.1144,  0.0950,\n         -0.1153,  0.0148,  0.0643,  0.1266,  0.1544,  0.0863,  0.0926, -0.0290,\n         -0.1271,  0.0985, -0.0765, -0.0554,  0.1447, -0.0953,  0.0471,  0.1432],\n        [-0.1593, -0.0652, -0.0016, -0.0732, -0.0562,  0.0105, -0.1156, -0.0345,\n          0.1308,  0.0673, -0.1562, -0.0802,  0.0961,  0.1359, -0.0023,  0.0172,\n         -0.0978, -0.0198,  0.0490, -0.1734, -0.0178,  0.1714, -0.0266,  0.1252,\n         -0.1235,  0.0693, -0.0391,  0.1420,  0.0848, -0.1402, -0.1414,  0.0915],\n        [ 0.0590, -0.0753, -0.1727,  0.0586, -0.1407,  0.0260, -0.1321,  0.1136,\n         -0.0506, -0.1308,  0.1459,  0.1746, -0.0610,  0.0422, -0.1180, -0.1753,\n          0.0815,  0.0321, -0.0495, -0.0294,  0.1726,  0.1471, -0.0708,  0.1157,\n          0.1512, -0.0545,  0.1171,  0.1251, -0.0098, -0.1200,  0.0604, -0.0602],\n        [-0.1665,  0.0648, -0.0320, -0.1466, -0.0182, -0.0207, -0.0205,  0.1481,\n         -0.0821,  0.1287, -0.0892, -0.0692,  0.0955,  0.1222, -0.1172,  0.0071,\n          0.0518, -0.0756, -0.1575, -0.0265,  0.0192,  0.0253, -0.1584, -0.0587,\n          0.0096, -0.0140,  0.0897, -0.0250,  0.0023, -0.0388,  0.0934,  0.1363],\n        [-0.0476, -0.0102, -0.1265,  0.0057, -0.0574,  0.1007, -0.0472,  0.1252,\n          0.1720,  0.0857, -0.0211,  0.0262,  0.0461,  0.1315, -0.1191, -0.0833,\n         -0.0017, -0.1551,  0.0087,  0.0538, -0.0034,  0.0653,  0.1660,  0.0758,\n          0.0970,  0.0952,  0.1093, -0.0179,  0.0773,  0.1700, -0.0773, -0.1240],\n        [-0.0610,  0.1393,  0.0215, -0.0386,  0.1429,  0.1453,  0.0392, -0.1030,\n          0.0959,  0.0534,  0.0194, -0.0467, -0.0162,  0.0970,  0.1168,  0.0812,\n         -0.0726, -0.0231, -0.1626, -0.0069, -0.1021,  0.0429, -0.1360, -0.1135,\n         -0.0432, -0.1490, -0.0905,  0.0750, -0.1369,  0.1550,  0.0036, -0.1720],\n        [ 0.0787, -0.1107, -0.0715,  0.0764, -0.1540,  0.0243, -0.1253, -0.0331,\n          0.1408, -0.1396,  0.0189,  0.1447, -0.0809, -0.1479, -0.0376,  0.0836,\n          0.1460, -0.0027, -0.0669, -0.0340,  0.1037, -0.0541, -0.0440,  0.0028,\n          0.0759,  0.0113,  0.0853,  0.0046, -0.1240, -0.1474,  0.0436,  0.1074],\n        [ 0.0329, -0.1389, -0.0350, -0.1481, -0.1604,  0.0119, -0.0874, -0.1433,\n         -0.0277,  0.0109, -0.0378, -0.1134,  0.1361, -0.0119, -0.1551, -0.1158,\n          0.1238, -0.0681,  0.0152, -0.1489,  0.1481, -0.0152,  0.1258,  0.0078,\n         -0.0427, -0.1254, -0.0925,  0.1149,  0.0085, -0.0250, -0.0273,  0.0838]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0519, -0.0996, -0.1032, -0.1617,  0.0524, -0.1570,  0.0440,  0.1277,\n        -0.0743,  0.0094, -0.0872,  0.1659, -0.0798, -0.0244,  0.1012,  0.0504],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1902,  0.2116,  0.1593,  0.1383,  0.1736, -0.1961, -0.1849,  0.1564,\n         -0.0235, -0.0794,  0.0211, -0.1149,  0.0130,  0.1524,  0.1388,  0.0204],\n        [-0.0741, -0.1513, -0.1956,  0.0274,  0.1534,  0.0140,  0.2482,  0.0161,\n         -0.1028,  0.1823,  0.0375,  0.0747, -0.1708,  0.0269, -0.0316, -0.2492],\n        [ 0.2332, -0.1317,  0.1302,  0.2316,  0.1079,  0.0282, -0.2463,  0.2154,\n          0.1826,  0.1919, -0.0999,  0.0990, -0.1136, -0.0047, -0.1881,  0.0665],\n        [-0.1425, -0.0545,  0.1333, -0.0189, -0.1755, -0.0920, -0.0900,  0.2192,\n          0.0562,  0.0119,  0.0712, -0.0611, -0.2141,  0.1306, -0.0833,  0.0791],\n        [-0.0874, -0.1347,  0.1543,  0.0008, -0.0345,  0.1112,  0.0823, -0.1462,\n         -0.1344, -0.2404, -0.1674,  0.1916, -0.0079, -0.1272, -0.1486,  0.0210],\n        [ 0.1008,  0.0495,  0.0326,  0.1940, -0.1314, -0.1189,  0.2230, -0.2196,\n          0.2191,  0.1025,  0.0529, -0.0633,  0.2345, -0.0154,  0.1088, -0.1016],\n        [-0.2190,  0.1479,  0.1970, -0.1856,  0.0051,  0.2053, -0.1540,  0.0797,\n         -0.1303, -0.1236,  0.0164, -0.2360,  0.0558, -0.1706,  0.0987,  0.1368],\n        [ 0.1918,  0.1357, -0.1776,  0.0545,  0.1079,  0.2207, -0.2373, -0.0183,\n         -0.0306,  0.2436,  0.1243,  0.1049, -0.1100, -0.2147,  0.0936, -0.0945]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0275,  0.1370,  0.2284,  0.2374,  0.0636, -0.2066, -0.0320, -0.2084],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0206,  0.2068, -0.2965,  0.1300, -0.0133,  0.2193,  0.3202,  0.0162],\n        [-0.0875, -0.1540,  0.2448, -0.0765,  0.1255, -0.3452,  0.1363,  0.2397],\n        [-0.1658,  0.1755, -0.1080, -0.3317,  0.1099, -0.2445, -0.3500, -0.0624],\n        [ 0.0835,  0.1044, -0.3255,  0.1536,  0.3025, -0.1563,  0.2861,  0.2829]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0197,  0.3448, -0.0091, -0.2366], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7e781d9fca10>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2359,  0.2095, -0.0780,  0.1294, -0.0985, -0.1883, -0.1308,  0.2636,\n        -0.1196, -0.0170, -0.1204,  0.3316,  0.0670,  0.2467, -0.2675, -0.2280,\n         0.3136, -0.1205, -0.0653, -0.1175, -0.2647, -0.0589,  0.1745, -0.3532,\n         0.2092,  0.1948, -0.0875, -0.3163, -0.1068,  0.2763, -0.1044,  0.3456],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-3.1507e-01,  2.9241e-04,  2.1310e-01, -3.1243e-01,  3.4395e-01,\n          3.0971e-01,  2.5832e-02, -1.6303e-01],\n        [ 5.2009e-02,  1.4318e-01,  5.5891e-02, -2.2555e-03, -3.1360e-01,\n          3.0938e-01,  2.1563e-01, -5.4779e-02],\n        [-2.3187e-01,  1.5709e-01,  2.6051e-01,  2.1622e-01, -9.6420e-02,\n         -1.9939e-01, -5.9207e-02,  7.2606e-02],\n        [-6.9765e-03, -1.7082e-01,  1.0345e-01,  3.3876e-02, -4.1320e-02,\n          6.7782e-02,  1.0674e-01,  1.3222e-01],\n        [-2.2591e-01,  2.3801e-02, -1.8580e-01,  8.5783e-02,  3.4257e-01,\n         -9.5345e-02, -1.1379e-01, -1.4472e-01],\n        [-2.5578e-01,  2.4332e-01,  1.6623e-02,  3.2802e-02,  7.8358e-02,\n         -2.6938e-01,  2.4160e-01, -2.1516e-01],\n        [-1.9317e-01, -2.4888e-01,  5.5961e-03,  2.9556e-01,  5.7566e-02,\n          1.5498e-03,  1.2436e-01,  2.0334e-02],\n        [ 1.4120e-01, -3.4352e-01,  3.1360e-01, -2.8416e-01, -1.4401e-01,\n          2.7271e-01, -3.2856e-01,  3.4976e-01],\n        [ 3.2819e-01,  3.4903e-01,  2.2498e-01,  3.0889e-01, -3.2610e-01,\n          1.8098e-01,  2.5769e-01, -1.2390e-01],\n        [-7.9394e-02,  1.8651e-02, -1.2308e-02,  1.7197e-01,  1.4596e-01,\n         -2.2491e-01, -2.1299e-01,  3.1251e-01],\n        [ 7.1511e-02, -2.2654e-01,  1.8945e-01, -1.9190e-01, -1.2732e-01,\n          8.6480e-02, -2.6809e-01,  2.8064e-02],\n        [-2.6923e-01, -2.8786e-01, -6.7180e-02, -2.3885e-01,  1.7072e-01,\n         -6.9663e-02, -2.8685e-01, -2.8834e-01],\n        [-3.4188e-01, -8.6341e-02,  9.7627e-02,  2.5564e-01,  5.2315e-02,\n         -3.2016e-01, -3.1575e-01, -1.8665e-01],\n        [-2.1928e-01,  1.1254e-01, -6.7742e-02,  2.1997e-01, -9.3205e-03,\n         -2.6735e-01,  1.3470e-01,  7.8144e-02],\n        [-7.6613e-02,  1.9342e-01,  3.0340e-01,  4.0803e-02, -1.7137e-02,\n         -2.5311e-01, -2.3591e-01, -1.4051e-01],\n        [-2.9229e-01,  1.0080e-01, -2.6890e-01, -2.2974e-01, -1.2178e-02,\n          1.1540e-01,  5.6064e-02, -1.4916e-01],\n        [-1.8655e-02, -2.9013e-01, -3.4727e-01,  1.9975e-01,  1.8002e-01,\n         -3.7528e-02, -2.2363e-01, -1.6517e-01],\n        [ 2.4272e-01,  1.2050e-01,  6.8689e-02,  3.1148e-02,  2.4445e-01,\n          3.1204e-01,  6.1401e-02,  1.7035e-01],\n        [-1.6918e-02, -3.3710e-01,  2.3719e-01, -1.4813e-02,  9.9082e-02,\n         -5.0416e-02,  8.5228e-02,  3.1387e-01],\n        [-2.9078e-01,  2.9684e-01,  2.1789e-01, -2.7148e-01, -1.8876e-01,\n         -7.9738e-02,  9.2847e-02, -2.9989e-01],\n        [-2.7443e-01, -2.1590e-01, -5.8925e-02,  1.7280e-01, -1.5014e-01,\n         -3.2846e-01, -9.2969e-02,  2.5701e-01],\n        [-1.4969e-01, -2.0819e-01,  3.8353e-02, -3.3613e-01, -1.8183e-01,\n         -4.7162e-03, -8.7719e-02, -1.2519e-01],\n        [-2.1144e-01, -2.3718e-01, -3.5191e-01,  3.1229e-01,  2.7141e-01,\n         -2.8238e-02, -1.9671e-01, -3.1580e-02],\n        [ 2.7688e-01,  1.9577e-01, -1.0288e-01, -6.3999e-02, -1.0918e-01,\n         -2.6457e-01, -9.8496e-02, -2.5421e-01],\n        [ 2.4000e-01,  1.6373e-01, -2.8379e-01, -6.6231e-02, -2.8875e-01,\n         -2.4029e-01, -3.3996e-01,  2.8537e-01],\n        [-3.0115e-01,  1.2552e-01,  2.5358e-01, -1.0122e-01,  1.8471e-01,\n         -1.2914e-01, -2.5071e-01,  1.0736e-01],\n        [-2.0843e-01, -1.5869e-01, -2.7231e-01, -2.5350e-01,  1.3022e-01,\n          1.4708e-01,  3.0753e-01,  3.2102e-01],\n        [ 9.5073e-02, -1.1667e-01, -6.4100e-02, -2.0262e-01,  9.3673e-02,\n          2.7166e-01,  2.6873e-01, -2.0267e-01],\n        [ 2.4230e-01, -8.5687e-02, -3.3360e-01,  8.7551e-02,  1.0112e-02,\n          2.4106e-01, -1.2494e-01,  1.6047e-01],\n        [ 3.9157e-02,  2.6657e-01, -1.2611e-01, -1.9573e-01, -1.0695e-01,\n         -2.6451e-01, -3.1969e-01, -3.1717e-01],\n        [-8.6262e-02,  1.9342e-01,  6.6650e-02,  3.2215e-01, -1.3921e-01,\n          2.5382e-01,  9.3572e-02, -2.2102e-01],\n        [ 1.7927e-01,  1.8017e-01, -2.3283e-01, -3.3322e-01, -2.9045e-01,\n          2.5714e-01,  1.2324e-01, -6.5996e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0519, -0.0996, -0.1032, -0.1617,  0.0524, -0.1570,  0.0440,  0.1277,\n        -0.0743,  0.0094, -0.0872,  0.1659, -0.0798, -0.0244,  0.1012,  0.0504],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0114, -0.0833,  0.0699,  0.0768, -0.1002,  0.1196, -0.0557,  0.1590,\n         -0.1465,  0.0633,  0.0199,  0.1348, -0.0263, -0.1033, -0.0956, -0.0662,\n          0.0728,  0.1064,  0.0849, -0.1260,  0.1170, -0.0678,  0.0674,  0.1041,\n         -0.1164,  0.1731,  0.0951,  0.1103,  0.1736, -0.0284,  0.1132, -0.1004],\n        [-0.0679, -0.0748,  0.0884, -0.0136, -0.0246, -0.0902, -0.0569,  0.0721,\n         -0.0408,  0.0206, -0.0211, -0.0505,  0.0292, -0.1658,  0.0155, -0.1068,\n          0.0540,  0.1679,  0.1197,  0.1217, -0.0201,  0.0999, -0.0918,  0.0842,\n         -0.1328, -0.0050, -0.1352,  0.1752,  0.1019, -0.0128, -0.0153, -0.0351],\n        [-0.0307,  0.0875,  0.0037, -0.0177,  0.1058, -0.0559, -0.0067, -0.0411,\n         -0.0571, -0.1548, -0.0390,  0.1172,  0.1379, -0.1139,  0.0449, -0.1661,\n         -0.1003,  0.1325,  0.0152,  0.1068, -0.1463, -0.1483,  0.0586,  0.0931,\n          0.1278,  0.1693, -0.0486, -0.1400,  0.0106, -0.0060,  0.1445,  0.0872],\n        [-0.0280,  0.0552,  0.0695, -0.1345, -0.1017,  0.0709,  0.0637,  0.0895,\n          0.1765, -0.0040,  0.0987,  0.1225, -0.0551,  0.0482, -0.0502, -0.1194,\n         -0.0856, -0.0186, -0.1159,  0.1612,  0.0307,  0.0032, -0.0900, -0.1749,\n          0.1264,  0.0861, -0.0062,  0.1504, -0.1615, -0.1294,  0.0336, -0.0009],\n        [-0.1297, -0.1328, -0.0509, -0.1269, -0.0468,  0.1303,  0.0561,  0.0694,\n          0.1342, -0.1025, -0.1280, -0.0057, -0.1605,  0.0929, -0.1766, -0.0019,\n         -0.0891,  0.1028,  0.1219,  0.1281, -0.1523,  0.1389,  0.0436,  0.0599,\n         -0.1086,  0.1448,  0.0006,  0.0655, -0.1432,  0.0817,  0.0688, -0.1313],\n        [-0.0864,  0.0478, -0.1523, -0.1332,  0.0077,  0.0154,  0.1017,  0.0294,\n         -0.0916,  0.1384, -0.0888, -0.1038,  0.1135, -0.1189, -0.1542,  0.0726,\n          0.1437,  0.0607, -0.1300,  0.0721,  0.0025,  0.0631, -0.1762, -0.0241,\n          0.1410, -0.1044, -0.0225,  0.0640, -0.0182, -0.0267,  0.0917,  0.0683],\n        [ 0.0528, -0.0824, -0.1748, -0.1440, -0.0066, -0.0555,  0.0975, -0.0591,\n          0.1013, -0.0752,  0.0915,  0.0357, -0.1354, -0.0040, -0.0560, -0.1327,\n          0.1007, -0.1742, -0.0022, -0.1344,  0.0503, -0.0145, -0.1447,  0.1392,\n         -0.0513, -0.1059, -0.1377,  0.1614, -0.0765,  0.1188, -0.0943, -0.0474],\n        [ 0.1625, -0.0055,  0.0272,  0.0828, -0.0163,  0.0533,  0.0057,  0.0923,\n         -0.0369, -0.0094, -0.0367, -0.0598,  0.0100,  0.0077, -0.1207,  0.0591,\n         -0.0877, -0.0199, -0.1704,  0.0076, -0.1138, -0.0626,  0.0540, -0.1078,\n          0.0773,  0.1475, -0.1276, -0.1308,  0.0985,  0.1592,  0.1069, -0.1710],\n        [ 0.1480,  0.0168, -0.0306,  0.0673, -0.1358,  0.1629,  0.1586,  0.0713,\n          0.0119, -0.1284,  0.0751,  0.0943,  0.1370,  0.0724, -0.1144,  0.0950,\n         -0.1153,  0.0148,  0.0643,  0.1266,  0.1544,  0.0863,  0.0926, -0.0290,\n         -0.1271,  0.0985, -0.0765, -0.0554,  0.1447, -0.0953,  0.0471,  0.1432],\n        [-0.1593, -0.0652, -0.0016, -0.0732, -0.0562,  0.0105, -0.1156, -0.0345,\n          0.1308,  0.0673, -0.1562, -0.0802,  0.0961,  0.1359, -0.0023,  0.0172,\n         -0.0978, -0.0198,  0.0490, -0.1734, -0.0178,  0.1714, -0.0266,  0.1252,\n         -0.1235,  0.0693, -0.0391,  0.1420,  0.0848, -0.1402, -0.1414,  0.0915],\n        [ 0.0590, -0.0753, -0.1727,  0.0586, -0.1407,  0.0260, -0.1321,  0.1136,\n         -0.0506, -0.1308,  0.1459,  0.1746, -0.0610,  0.0422, -0.1180, -0.1753,\n          0.0815,  0.0321, -0.0495, -0.0294,  0.1726,  0.1471, -0.0708,  0.1157,\n          0.1512, -0.0545,  0.1171,  0.1251, -0.0098, -0.1200,  0.0604, -0.0602],\n        [-0.1665,  0.0648, -0.0320, -0.1466, -0.0182, -0.0207, -0.0205,  0.1481,\n         -0.0821,  0.1287, -0.0892, -0.0692,  0.0955,  0.1222, -0.1172,  0.0071,\n          0.0518, -0.0756, -0.1575, -0.0265,  0.0192,  0.0253, -0.1584, -0.0587,\n          0.0096, -0.0140,  0.0897, -0.0250,  0.0023, -0.0388,  0.0934,  0.1363],\n        [-0.0476, -0.0102, -0.1265,  0.0057, -0.0574,  0.1007, -0.0472,  0.1252,\n          0.1720,  0.0857, -0.0211,  0.0262,  0.0461,  0.1315, -0.1191, -0.0833,\n         -0.0017, -0.1551,  0.0087,  0.0538, -0.0034,  0.0653,  0.1660,  0.0758,\n          0.0970,  0.0952,  0.1093, -0.0179,  0.0773,  0.1700, -0.0773, -0.1240],\n        [-0.0610,  0.1393,  0.0215, -0.0386,  0.1429,  0.1453,  0.0392, -0.1030,\n          0.0959,  0.0534,  0.0194, -0.0467, -0.0162,  0.0970,  0.1168,  0.0812,\n         -0.0726, -0.0231, -0.1626, -0.0069, -0.1021,  0.0429, -0.1360, -0.1135,\n         -0.0432, -0.1490, -0.0905,  0.0750, -0.1369,  0.1550,  0.0036, -0.1720],\n        [ 0.0787, -0.1107, -0.0715,  0.0764, -0.1540,  0.0243, -0.1253, -0.0331,\n          0.1408, -0.1396,  0.0189,  0.1447, -0.0809, -0.1479, -0.0376,  0.0836,\n          0.1460, -0.0027, -0.0669, -0.0340,  0.1037, -0.0541, -0.0440,  0.0028,\n          0.0759,  0.0113,  0.0853,  0.0046, -0.1240, -0.1474,  0.0436,  0.1074],\n        [ 0.0329, -0.1389, -0.0350, -0.1481, -0.1604,  0.0119, -0.0874, -0.1433,\n         -0.0277,  0.0109, -0.0378, -0.1134,  0.1361, -0.0119, -0.1551, -0.1158,\n          0.1238, -0.0681,  0.0152, -0.1489,  0.1481, -0.0152,  0.1258,  0.0078,\n         -0.0427, -0.1254, -0.0925,  0.1149,  0.0085, -0.0250, -0.0273,  0.0838]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0275,  0.1370,  0.2284,  0.2374,  0.0636, -0.2066, -0.0320, -0.2084],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1902,  0.2116,  0.1593,  0.1383,  0.1736, -0.1961, -0.1849,  0.1564,\n         -0.0235, -0.0794,  0.0211, -0.1149,  0.0130,  0.1524,  0.1388,  0.0204],\n        [-0.0741, -0.1513, -0.1956,  0.0274,  0.1534,  0.0140,  0.2482,  0.0161,\n         -0.1028,  0.1823,  0.0375,  0.0747, -0.1708,  0.0269, -0.0316, -0.2492],\n        [ 0.2332, -0.1317,  0.1302,  0.2316,  0.1079,  0.0282, -0.2463,  0.2154,\n          0.1826,  0.1919, -0.0999,  0.0990, -0.1136, -0.0047, -0.1881,  0.0665],\n        [-0.1425, -0.0545,  0.1333, -0.0189, -0.1755, -0.0920, -0.0900,  0.2192,\n          0.0562,  0.0119,  0.0712, -0.0611, -0.2141,  0.1306, -0.0833,  0.0791],\n        [-0.0874, -0.1347,  0.1543,  0.0008, -0.0345,  0.1112,  0.0823, -0.1462,\n         -0.1344, -0.2404, -0.1674,  0.1916, -0.0079, -0.1272, -0.1486,  0.0210],\n        [ 0.1008,  0.0495,  0.0326,  0.1940, -0.1314, -0.1189,  0.2230, -0.2196,\n          0.2191,  0.1025,  0.0529, -0.0633,  0.2345, -0.0154,  0.1088, -0.1016],\n        [-0.2190,  0.1479,  0.1970, -0.1856,  0.0051,  0.2053, -0.1540,  0.0797,\n         -0.1303, -0.1236,  0.0164, -0.2360,  0.0558, -0.1706,  0.0987,  0.1368],\n        [ 0.1918,  0.1357, -0.1776,  0.0545,  0.1079,  0.2207, -0.2373, -0.0183,\n         -0.0306,  0.2436,  0.1243,  0.1049, -0.1100, -0.2147,  0.0936, -0.0945]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0197,  0.3448, -0.0091, -0.2366], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0206,  0.2068, -0.2965,  0.1300, -0.0133,  0.2193,  0.3202,  0.0162],\n        [-0.0875, -0.1540,  0.2448, -0.0765,  0.1255, -0.3452,  0.1363,  0.2397],\n        [-0.1658,  0.1755, -0.1080, -0.3317,  0.1099, -0.2445, -0.3500, -0.0624],\n        [ 0.0835,  0.1044, -0.3255,  0.1536,  0.3025, -0.1563,  0.2861,  0.2829]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7e7819cea090>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s342980000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s342980000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}