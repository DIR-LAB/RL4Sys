{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s357440000"
    },
    "q_lr":	0.0005,
    "seed":	357440000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x0000024EB12B9090>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0040,  0.2968,  0.1862,  0.0850,  0.3044,  0.2898,  0.2233,  0.0542,\n         0.0155,  0.2889,  0.2982, -0.1236,  0.3441,  0.2060, -0.0883, -0.0172,\n        -0.0359, -0.2315,  0.3202, -0.0215,  0.3526,  0.1639, -0.2572,  0.2740,\n         0.0684,  0.2084,  0.0770,  0.2038, -0.2355, -0.2716, -0.2549, -0.1169],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3530,  0.0227,  0.1939,  0.0338,  0.2241,  0.0800,  0.1019,  0.2781],\n        [-0.3376, -0.2203,  0.2914, -0.1001, -0.1680,  0.1045, -0.1917, -0.2103],\n        [-0.1778,  0.0947, -0.2297,  0.1403, -0.1846, -0.0105, -0.0984, -0.2819],\n        [ 0.1780,  0.1698,  0.1536,  0.1119,  0.2125,  0.2704,  0.2592,  0.1035],\n        [-0.0208, -0.1978,  0.2431,  0.2847,  0.1272,  0.2727,  0.3201,  0.3459],\n        [-0.2350,  0.2608,  0.2185,  0.2991, -0.2036, -0.2622,  0.1734, -0.0680],\n        [ 0.0188,  0.0737, -0.1411,  0.3361,  0.1496,  0.1814, -0.0459,  0.2451],\n        [-0.2947,  0.2386,  0.0594, -0.0978, -0.3132,  0.0443,  0.0530,  0.2510],\n        [ 0.3048, -0.0921, -0.1119, -0.2595, -0.3409,  0.2492, -0.1738, -0.2078],\n        [ 0.3384, -0.0543, -0.3428,  0.0325,  0.1074,  0.1999, -0.1347,  0.2731],\n        [ 0.1170, -0.0653,  0.2119, -0.0886, -0.2901, -0.3279,  0.1019,  0.1706],\n        [ 0.2689,  0.2003,  0.1330, -0.2778,  0.0481,  0.2230, -0.0708,  0.3135],\n        [-0.0561,  0.1850,  0.1998,  0.1740, -0.1405, -0.1741,  0.2656,  0.0113],\n        [ 0.2759,  0.3328,  0.2741,  0.0315,  0.1653, -0.1758,  0.2595, -0.0522],\n        [-0.1590,  0.0887,  0.2148,  0.3250,  0.2941,  0.1628, -0.0948,  0.3259],\n        [-0.0312,  0.2734,  0.2523,  0.3218, -0.0183,  0.0805, -0.3243, -0.0914],\n        [ 0.0583, -0.0153,  0.1490, -0.2494,  0.1904,  0.2861,  0.2529,  0.1705],\n        [ 0.0819,  0.2392,  0.2739,  0.2046, -0.3029,  0.3049,  0.0921,  0.2397],\n        [ 0.0360,  0.3029,  0.0940,  0.2925, -0.2656, -0.1074, -0.2877,  0.3388],\n        [-0.0496,  0.1893,  0.1258,  0.0061,  0.1169,  0.2154,  0.0831, -0.1485],\n        [ 0.0828,  0.1132,  0.0941, -0.2877, -0.3051,  0.0723,  0.1703, -0.0961],\n        [-0.2208, -0.0086,  0.2056,  0.1364,  0.2769,  0.2533,  0.1739, -0.0206],\n        [ 0.0478,  0.2679, -0.0944, -0.3359,  0.1480,  0.2555,  0.1314,  0.0607],\n        [-0.2923,  0.0835,  0.1051,  0.0014,  0.0108, -0.1380, -0.2237,  0.1357],\n        [-0.0066,  0.1789,  0.1516,  0.1590, -0.1556, -0.0118,  0.2333, -0.2281],\n        [-0.3504,  0.2744, -0.2516, -0.1789, -0.0023, -0.0409,  0.0134, -0.2665],\n        [ 0.1114, -0.3152,  0.3496, -0.3451, -0.3327,  0.2326, -0.1325,  0.3050],\n        [ 0.1628,  0.1799,  0.1794,  0.1336, -0.1232,  0.0741, -0.0455, -0.2536],\n        [-0.1588,  0.3457,  0.3470, -0.1885, -0.2322, -0.0643,  0.0932, -0.1778],\n        [-0.0346, -0.1263,  0.1893, -0.2160,  0.0355, -0.0964, -0.2587, -0.2773],\n        [-0.0229, -0.2786,  0.0197,  0.0913,  0.0996,  0.0405,  0.1942,  0.3280],\n        [ 0.1654,  0.3012,  0.2315, -0.3439, -0.2891,  0.0713,  0.1268, -0.0687]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0247,  0.1380, -0.1758,  0.1517, -0.0765, -0.0580,  0.1752, -0.1375,\n         0.1190,  0.1344,  0.1628, -0.0870, -0.0335, -0.1003, -0.0758, -0.1610],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0540e-01,  1.1036e-01,  1.6342e-01,  1.2172e-01, -1.7282e-01,\n          9.6865e-02,  1.5006e-02,  5.1301e-02,  4.5770e-02,  5.3565e-02,\n         -1.2878e-01,  1.7488e-01,  6.4458e-02, -1.4365e-01,  6.8181e-02,\n         -6.3317e-02, -1.4653e-01,  9.2164e-02,  1.3667e-01,  1.1397e-01,\n         -6.5663e-02,  1.7246e-01, -7.9297e-02,  9.6142e-02,  1.5993e-02,\n          8.4189e-03, -1.4137e-01,  1.3218e-01,  1.1196e-02,  2.6450e-02,\n         -4.7277e-02,  9.7410e-02],\n        [-1.3777e-01,  1.1125e-01,  4.1357e-02,  4.3391e-02, -1.7289e-01,\n         -1.6383e-01,  1.8987e-02, -1.6049e-01,  1.0694e-02, -4.6085e-02,\n         -9.6814e-02,  1.0157e-01,  1.3560e-01, -1.2451e-01, -1.3187e-01,\n         -1.3472e-02,  1.4524e-01, -5.9363e-02,  1.4169e-01, -1.6574e-01,\n         -3.5222e-02,  1.4912e-01,  1.4744e-01, -1.1585e-01,  3.0167e-02,\n          6.3445e-02, -1.4511e-01, -9.1005e-03, -1.0813e-01, -1.2100e-01,\n          1.0735e-01,  5.5822e-02],\n        [-2.5563e-02, -1.2422e-01, -5.4149e-02,  3.2330e-02,  2.3776e-02,\n         -1.1485e-01, -1.0097e-01,  5.9592e-02,  2.3958e-02, -1.6781e-01,\n          1.5885e-01,  1.3922e-01,  2.4684e-02, -8.3897e-02, -8.3147e-02,\n         -6.1228e-02,  5.9596e-02, -1.1022e-01, -9.3235e-02, -1.3240e-01,\n          5.0073e-02,  1.1799e-01,  1.0516e-04,  5.6609e-02,  1.7363e-01,\n          8.2834e-02,  9.0158e-02, -1.7008e-01,  5.0363e-02,  9.6550e-03,\n         -3.0394e-02,  7.9227e-02],\n        [ 1.6365e-01,  4.2950e-02, -1.6705e-02, -1.8095e-02,  1.2580e-02,\n          1.2427e-01,  1.6900e-01,  1.7137e-01,  5.7846e-02, -5.9105e-02,\n          1.0543e-01,  1.2300e-01, -3.4084e-02,  8.3281e-02, -1.5498e-01,\n          6.4757e-02,  9.6815e-02,  9.9477e-02,  9.3937e-02, -3.9605e-02,\n         -2.1269e-02,  1.3367e-01,  1.0087e-01,  2.8817e-02, -1.0443e-01,\n         -1.7697e-02,  7.5707e-02, -3.0804e-03, -3.7865e-02,  5.5176e-02,\n         -1.5395e-03, -5.2008e-02],\n        [-1.1579e-02,  9.1318e-02,  1.4998e-01, -1.4858e-01,  2.5828e-02,\n          1.1498e-01, -9.5622e-02, -2.2738e-02, -4.8878e-02, -2.9332e-02,\n         -1.1256e-01, -5.4215e-02,  1.7123e-01,  1.0899e-01, -3.6079e-02,\n          7.0888e-03, -1.2290e-01, -1.4603e-01,  1.1735e-01,  1.0124e-01,\n         -9.8270e-02, -4.4305e-02, -8.6945e-03, -1.0985e-01, -1.6068e-01,\n         -4.4552e-02,  1.0003e-02, -1.6550e-01,  1.4740e-01,  1.6554e-01,\n         -4.6456e-02,  1.3007e-01],\n        [-1.6229e-01, -1.9169e-02, -1.1513e-01,  1.5217e-02, -9.8933e-02,\n         -1.3997e-01,  5.4831e-02,  5.7890e-02,  7.6516e-02, -1.4436e-02,\n          1.6788e-01,  1.1215e-01,  1.1788e-02, -6.5665e-02,  1.4538e-01,\n         -7.9581e-02,  8.7437e-02, -1.2387e-01,  4.7201e-02,  1.3487e-01,\n          1.6486e-01,  4.1885e-02, -9.8081e-02,  1.3379e-01,  1.7460e-01,\n         -2.7115e-02,  5.2819e-03,  1.5614e-01,  1.0396e-01,  1.0663e-01,\n         -2.4146e-02, -6.8245e-02],\n        [ 8.2707e-02,  1.3787e-01, -7.6712e-02, -6.7394e-02, -6.7646e-02,\n          1.0989e-01, -1.1472e-01, -1.5504e-02,  2.5762e-02,  8.0494e-02,\n         -1.7633e-01, -1.7030e-01, -1.4457e-01, -5.3272e-02, -9.2545e-02,\n         -1.7360e-01,  1.1595e-02, -1.8642e-02, -7.8476e-02, -1.4626e-01,\n         -1.0236e-01, -3.3918e-02,  8.3661e-02,  6.6468e-03,  1.5279e-01,\n          1.3026e-01,  3.1792e-02,  1.0240e-01,  1.5409e-04, -3.0872e-02,\n         -7.3793e-03,  1.4293e-02],\n        [ 9.7383e-02,  4.2478e-02,  2.8694e-02,  3.4360e-02, -3.0128e-02,\n          4.4086e-02, -1.1704e-01,  7.9343e-02, -5.5697e-02,  2.8349e-02,\n          8.6703e-02,  1.4038e-01, -1.2265e-01, -6.2482e-02, -1.6719e-01,\n         -1.4874e-01,  1.6981e-02, -3.2329e-03, -1.7595e-01, -6.3969e-02,\n          4.7099e-02,  3.3113e-02,  1.4316e-01,  8.4562e-02,  6.8339e-02,\n         -1.3054e-01,  8.9043e-02, -1.9592e-02, -8.6344e-02, -1.0939e-01,\n         -7.5479e-02, -1.5459e-01],\n        [-2.3599e-02,  1.5332e-01,  9.9243e-02,  6.5920e-02, -8.1849e-02,\n         -1.3079e-01, -1.4430e-01, -4.8690e-02,  9.2689e-02,  1.6096e-01,\n         -1.3877e-01, -3.4830e-02,  1.6690e-01,  1.6656e-01, -1.1822e-02,\n         -3.4901e-02,  1.4292e-01,  1.1926e-01, -5.6298e-02,  3.5415e-02,\n         -3.9778e-02,  5.5292e-02,  1.5080e-01, -1.7348e-01, -2.3537e-02,\n          1.4312e-01, -9.3516e-02,  3.8701e-03,  1.9998e-03,  1.7088e-01,\n         -9.2536e-02,  2.1219e-02],\n        [ 3.1938e-02,  1.1807e-01,  9.4810e-02, -7.1605e-02, -9.8138e-02,\n          1.6080e-01, -6.3706e-02,  1.3756e-01, -1.1744e-01,  1.3857e-01,\n         -1.1287e-01, -2.6020e-02, -1.0508e-01, -6.3810e-02,  1.5454e-01,\n          1.7267e-01,  1.7142e-01,  1.5683e-01,  1.3317e-01,  3.0561e-02,\n         -9.7483e-02, -2.1945e-02, -9.1716e-02, -1.2524e-01, -3.4671e-03,\n          1.4716e-01,  1.2163e-01,  7.1278e-02,  1.3724e-01, -4.7904e-02,\n          7.1606e-02,  1.7419e-01],\n        [-1.6634e-01,  9.5430e-02,  4.5806e-02,  1.2180e-01,  1.2214e-01,\n          5.5566e-02,  1.5068e-01, -1.6873e-01,  3.1644e-02,  1.0282e-01,\n          5.4282e-02, -9.3300e-02,  9.0309e-02,  8.4501e-02,  1.4831e-01,\n          1.0120e-01, -1.0905e-01, -9.6346e-02, -1.1509e-01,  3.6807e-02,\n         -7.3746e-02,  8.3387e-02, -2.2655e-02,  3.8670e-02, -1.6067e-01,\n          1.1315e-01, -1.3272e-01, -1.7021e-01, -1.0378e-01, -1.5356e-01,\n         -1.8505e-02,  3.9857e-02],\n        [ 2.0241e-02,  5.5408e-02, -1.5631e-01, -7.2025e-02,  1.0542e-01,\n         -1.0420e-01,  1.6184e-01, -1.3964e-01,  1.4820e-02, -5.8639e-02,\n         -1.3519e-01,  1.4707e-01,  9.2033e-02, -9.0465e-03,  1.6304e-01,\n         -1.4080e-01,  8.8492e-02, -8.1872e-02, -5.9581e-02,  3.1723e-02,\n         -1.0739e-01, -3.3448e-02,  7.2313e-03, -1.5237e-02,  1.6666e-01,\n          1.1410e-01,  4.9000e-02,  3.8183e-02,  7.1445e-02,  9.2169e-02,\n          4.7037e-02,  1.0085e-01],\n        [-1.8308e-02, -3.2434e-02,  1.7119e-01, -1.2015e-01,  5.1286e-02,\n         -8.2920e-02,  1.5055e-01,  1.3996e-01,  1.4506e-01, -5.5957e-02,\n          4.4864e-03,  6.5285e-02,  1.6872e-01,  1.4179e-02,  2.6078e-02,\n          6.3210e-02,  1.2896e-01,  6.5604e-02,  1.5436e-01, -3.7958e-02,\n         -3.8650e-02, -6.8819e-02,  1.5120e-01,  2.3663e-02, -1.3285e-02,\n          5.1383e-02, -9.1354e-02, -1.4754e-02,  6.9569e-02,  1.1462e-01,\n         -1.3232e-01,  1.0600e-01],\n        [ 2.6896e-03, -1.0745e-01,  1.4407e-01,  9.8432e-02, -1.9894e-02,\n          1.2127e-01, -1.2405e-01, -2.8985e-02,  3.7145e-02, -4.8982e-02,\n          8.0263e-02,  1.4474e-01,  5.9123e-02, -7.7260e-02, -9.9949e-02,\n         -1.1892e-01, -1.0850e-02, -1.4589e-01, -1.3076e-01,  1.2737e-01,\n          1.4098e-01, -1.0987e-01,  2.8156e-02, -1.4433e-01, -2.7582e-02,\n          5.9881e-02, -6.0737e-02, -1.6700e-01, -6.7889e-02, -1.1227e-01,\n         -1.3304e-01, -1.2287e-01],\n        [ 1.2828e-02,  4.2605e-02,  2.7891e-02, -6.6125e-02, -7.3980e-02,\n         -2.4561e-02,  1.3331e-01,  1.7544e-01,  3.6036e-02,  1.4427e-01,\n         -1.7001e-01, -1.1009e-01, -6.6537e-02,  8.2633e-02, -9.2817e-02,\n          1.1435e-01, -1.4698e-01, -4.8743e-02,  1.6708e-01, -1.0339e-01,\n          9.5770e-02, -1.2394e-01, -8.5184e-02,  4.7618e-02, -6.4882e-02,\n         -6.8851e-02, -1.3100e-01, -5.2646e-02, -7.0012e-02,  3.2794e-02,\n          9.1835e-02, -1.6389e-01],\n        [ 1.6288e-02, -1.6255e-01,  1.0221e-01, -1.4014e-01, -1.1121e-01,\n         -7.4727e-02,  9.3516e-02, -8.8222e-03,  1.1158e-01, -8.1025e-02,\n          1.3424e-01, -1.5923e-01, -1.0275e-01, -8.1043e-02,  1.0206e-01,\n          1.2343e-01, -6.6348e-02, -5.6909e-02,  4.8673e-02, -7.1338e-02,\n          1.4958e-01, -9.5854e-02,  2.3490e-02, -1.9149e-02,  8.9004e-02,\n         -1.2654e-01,  1.6217e-02, -1.3524e-01, -5.8350e-02,  4.8051e-02,\n         -1.4576e-01, -1.1434e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2363, -0.0621, -0.1640,  0.0233, -0.0844,  0.0078,  0.0523,  0.0907],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2292, -0.0910, -0.0402,  0.0886, -0.2182,  0.1177,  0.2325,  0.0679,\n          0.1418,  0.0843, -0.0853, -0.1859,  0.0364, -0.2182,  0.0770, -0.0022],\n        [-0.0551, -0.0108, -0.0260,  0.2302, -0.1918, -0.2024,  0.1439,  0.1164,\n          0.0517, -0.1016, -0.1897, -0.1668, -0.1387,  0.2174, -0.0230, -0.0645],\n        [ 0.0890, -0.0810, -0.0882, -0.2080,  0.0165,  0.1521,  0.1542, -0.2146,\n         -0.2308, -0.1495, -0.2015,  0.0977, -0.1864, -0.1277,  0.2481, -0.1025],\n        [ 0.0478,  0.1797,  0.0450, -0.1888,  0.1297, -0.0537,  0.1064, -0.0695,\n          0.1904,  0.0454, -0.0884, -0.2033,  0.2034, -0.0557,  0.0635,  0.0219],\n        [-0.1105, -0.2484,  0.2482,  0.2049,  0.0292, -0.1530, -0.0842,  0.0258,\n          0.1579,  0.1433,  0.0311,  0.0222,  0.1738,  0.2068, -0.2388,  0.0148],\n        [-0.1818, -0.1482,  0.1875, -0.0355,  0.0152, -0.0951,  0.2283, -0.0614,\n          0.1502,  0.0259,  0.1090, -0.1574, -0.0655, -0.0163,  0.0401, -0.1531],\n        [-0.0499, -0.1107,  0.0577,  0.1106,  0.1508, -0.0974,  0.1675, -0.2286,\n          0.1875,  0.2282,  0.2056, -0.0220, -0.0699,  0.1990, -0.1266,  0.1869],\n        [ 0.0263, -0.1046, -0.0272, -0.0455,  0.1511,  0.1356,  0.1110,  0.2496,\n          0.0981, -0.2343,  0.0632, -0.1608,  0.0388, -0.1912, -0.0948, -0.0431]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1308], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0490, -0.1932,  0.0360, -0.1022,  0.1815,  0.2447,  0.0296,  0.2828]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.3530,  0.0227,  0.1939,  0.0338,  0.2241,  0.0800,  0.1019,  0.2781],\n        [-0.3376, -0.2203,  0.2914, -0.1001, -0.1680,  0.1045, -0.1917, -0.2103],\n        [-0.1778,  0.0947, -0.2297,  0.1403, -0.1846, -0.0105, -0.0984, -0.2819],\n        [ 0.1780,  0.1698,  0.1536,  0.1119,  0.2125,  0.2704,  0.2592,  0.1035],\n        [-0.0208, -0.1978,  0.2431,  0.2847,  0.1272,  0.2727,  0.3201,  0.3459],\n        [-0.2350,  0.2608,  0.2185,  0.2991, -0.2036, -0.2622,  0.1734, -0.0680],\n        [ 0.0188,  0.0737, -0.1411,  0.3361,  0.1496,  0.1814, -0.0459,  0.2451],\n        [-0.2947,  0.2386,  0.0594, -0.0978, -0.3132,  0.0443,  0.0530,  0.2510],\n        [ 0.3048, -0.0921, -0.1119, -0.2595, -0.3409,  0.2492, -0.1738, -0.2078],\n        [ 0.3384, -0.0543, -0.3428,  0.0325,  0.1074,  0.1999, -0.1347,  0.2731],\n        [ 0.1170, -0.0653,  0.2119, -0.0886, -0.2901, -0.3279,  0.1019,  0.1706],\n        [ 0.2689,  0.2003,  0.1330, -0.2778,  0.0481,  0.2230, -0.0708,  0.3135],\n        [-0.0561,  0.1850,  0.1998,  0.1740, -0.1405, -0.1741,  0.2656,  0.0113],\n        [ 0.2759,  0.3328,  0.2741,  0.0315,  0.1653, -0.1758,  0.2595, -0.0522],\n        [-0.1590,  0.0887,  0.2148,  0.3250,  0.2941,  0.1628, -0.0948,  0.3259],\n        [-0.0312,  0.2734,  0.2523,  0.3218, -0.0183,  0.0805, -0.3243, -0.0914],\n        [ 0.0583, -0.0153,  0.1490, -0.2494,  0.1904,  0.2861,  0.2529,  0.1705],\n        [ 0.0819,  0.2392,  0.2739,  0.2046, -0.3029,  0.3049,  0.0921,  0.2397],\n        [ 0.0360,  0.3029,  0.0940,  0.2925, -0.2656, -0.1074, -0.2877,  0.3388],\n        [-0.0496,  0.1893,  0.1258,  0.0061,  0.1169,  0.2154,  0.0831, -0.1485],\n        [ 0.0828,  0.1132,  0.0941, -0.2877, -0.3051,  0.0723,  0.1703, -0.0961],\n        [-0.2208, -0.0086,  0.2056,  0.1364,  0.2769,  0.2533,  0.1739, -0.0206],\n        [ 0.0478,  0.2679, -0.0944, -0.3359,  0.1480,  0.2555,  0.1314,  0.0607],\n        [-0.2923,  0.0835,  0.1051,  0.0014,  0.0108, -0.1380, -0.2237,  0.1357],\n        [-0.0066,  0.1789,  0.1516,  0.1590, -0.1556, -0.0118,  0.2333, -0.2281],\n        [-0.3504,  0.2744, -0.2516, -0.1789, -0.0023, -0.0409,  0.0134, -0.2665],\n        [ 0.1114, -0.3152,  0.3496, -0.3451, -0.3327,  0.2326, -0.1325,  0.3050],\n        [ 0.1628,  0.1799,  0.1794,  0.1336, -0.1232,  0.0741, -0.0455, -0.2536],\n        [-0.1588,  0.3457,  0.3470, -0.1885, -0.2322, -0.0643,  0.0932, -0.1778],\n        [-0.0346, -0.1263,  0.1893, -0.2160,  0.0355, -0.0964, -0.2587, -0.2773],\n        [-0.0229, -0.2786,  0.0197,  0.0913,  0.0996,  0.0405,  0.1942,  0.3280],\n        [ 0.1654,  0.3012,  0.2315, -0.3439, -0.2891,  0.0713,  0.1268, -0.0687]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0040,  0.2968,  0.1862,  0.0850,  0.3044,  0.2898,  0.2233,  0.0542,\n         0.0155,  0.2889,  0.2982, -0.1236,  0.3441,  0.2060, -0.0883, -0.0172,\n        -0.0359, -0.2315,  0.3202, -0.0215,  0.3526,  0.1639, -0.2572,  0.2740,\n         0.0684,  0.2084,  0.0770,  0.2038, -0.2355, -0.2716, -0.2549, -0.1169],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.0540e-01,  1.1036e-01,  1.6342e-01,  1.2172e-01, -1.7282e-01,\n          9.6865e-02,  1.5006e-02,  5.1301e-02,  4.5770e-02,  5.3565e-02,\n         -1.2878e-01,  1.7488e-01,  6.4458e-02, -1.4365e-01,  6.8181e-02,\n         -6.3317e-02, -1.4653e-01,  9.2164e-02,  1.3667e-01,  1.1397e-01,\n         -6.5663e-02,  1.7246e-01, -7.9297e-02,  9.6142e-02,  1.5993e-02,\n          8.4189e-03, -1.4137e-01,  1.3218e-01,  1.1196e-02,  2.6450e-02,\n         -4.7277e-02,  9.7410e-02],\n        [-1.3777e-01,  1.1125e-01,  4.1357e-02,  4.3391e-02, -1.7289e-01,\n         -1.6383e-01,  1.8987e-02, -1.6049e-01,  1.0694e-02, -4.6085e-02,\n         -9.6814e-02,  1.0157e-01,  1.3560e-01, -1.2451e-01, -1.3187e-01,\n         -1.3472e-02,  1.4524e-01, -5.9363e-02,  1.4169e-01, -1.6574e-01,\n         -3.5222e-02,  1.4912e-01,  1.4744e-01, -1.1585e-01,  3.0167e-02,\n          6.3445e-02, -1.4511e-01, -9.1005e-03, -1.0813e-01, -1.2100e-01,\n          1.0735e-01,  5.5822e-02],\n        [-2.5563e-02, -1.2422e-01, -5.4149e-02,  3.2330e-02,  2.3776e-02,\n         -1.1485e-01, -1.0097e-01,  5.9592e-02,  2.3958e-02, -1.6781e-01,\n          1.5885e-01,  1.3922e-01,  2.4684e-02, -8.3897e-02, -8.3147e-02,\n         -6.1228e-02,  5.9596e-02, -1.1022e-01, -9.3235e-02, -1.3240e-01,\n          5.0073e-02,  1.1799e-01,  1.0516e-04,  5.6609e-02,  1.7363e-01,\n          8.2834e-02,  9.0158e-02, -1.7008e-01,  5.0363e-02,  9.6550e-03,\n         -3.0394e-02,  7.9227e-02],\n        [ 1.6365e-01,  4.2950e-02, -1.6705e-02, -1.8095e-02,  1.2580e-02,\n          1.2427e-01,  1.6900e-01,  1.7137e-01,  5.7846e-02, -5.9105e-02,\n          1.0543e-01,  1.2300e-01, -3.4084e-02,  8.3281e-02, -1.5498e-01,\n          6.4757e-02,  9.6815e-02,  9.9477e-02,  9.3937e-02, -3.9605e-02,\n         -2.1269e-02,  1.3367e-01,  1.0087e-01,  2.8817e-02, -1.0443e-01,\n         -1.7697e-02,  7.5707e-02, -3.0804e-03, -3.7865e-02,  5.5176e-02,\n         -1.5395e-03, -5.2008e-02],\n        [-1.1579e-02,  9.1318e-02,  1.4998e-01, -1.4858e-01,  2.5828e-02,\n          1.1498e-01, -9.5622e-02, -2.2738e-02, -4.8878e-02, -2.9332e-02,\n         -1.1256e-01, -5.4215e-02,  1.7123e-01,  1.0899e-01, -3.6079e-02,\n          7.0888e-03, -1.2290e-01, -1.4603e-01,  1.1735e-01,  1.0124e-01,\n         -9.8270e-02, -4.4305e-02, -8.6945e-03, -1.0985e-01, -1.6068e-01,\n         -4.4552e-02,  1.0003e-02, -1.6550e-01,  1.4740e-01,  1.6554e-01,\n         -4.6456e-02,  1.3007e-01],\n        [-1.6229e-01, -1.9169e-02, -1.1513e-01,  1.5217e-02, -9.8933e-02,\n         -1.3997e-01,  5.4831e-02,  5.7890e-02,  7.6516e-02, -1.4436e-02,\n          1.6788e-01,  1.1215e-01,  1.1788e-02, -6.5665e-02,  1.4538e-01,\n         -7.9581e-02,  8.7437e-02, -1.2387e-01,  4.7201e-02,  1.3487e-01,\n          1.6486e-01,  4.1885e-02, -9.8081e-02,  1.3379e-01,  1.7460e-01,\n         -2.7115e-02,  5.2819e-03,  1.5614e-01,  1.0396e-01,  1.0663e-01,\n         -2.4146e-02, -6.8245e-02],\n        [ 8.2707e-02,  1.3787e-01, -7.6712e-02, -6.7394e-02, -6.7646e-02,\n          1.0989e-01, -1.1472e-01, -1.5504e-02,  2.5762e-02,  8.0494e-02,\n         -1.7633e-01, -1.7030e-01, -1.4457e-01, -5.3272e-02, -9.2545e-02,\n         -1.7360e-01,  1.1595e-02, -1.8642e-02, -7.8476e-02, -1.4626e-01,\n         -1.0236e-01, -3.3918e-02,  8.3661e-02,  6.6468e-03,  1.5279e-01,\n          1.3026e-01,  3.1792e-02,  1.0240e-01,  1.5409e-04, -3.0872e-02,\n         -7.3793e-03,  1.4293e-02],\n        [ 9.7383e-02,  4.2478e-02,  2.8694e-02,  3.4360e-02, -3.0128e-02,\n          4.4086e-02, -1.1704e-01,  7.9343e-02, -5.5697e-02,  2.8349e-02,\n          8.6703e-02,  1.4038e-01, -1.2265e-01, -6.2482e-02, -1.6719e-01,\n         -1.4874e-01,  1.6981e-02, -3.2329e-03, -1.7595e-01, -6.3969e-02,\n          4.7099e-02,  3.3113e-02,  1.4316e-01,  8.4562e-02,  6.8339e-02,\n         -1.3054e-01,  8.9043e-02, -1.9592e-02, -8.6344e-02, -1.0939e-01,\n         -7.5479e-02, -1.5459e-01],\n        [-2.3599e-02,  1.5332e-01,  9.9243e-02,  6.5920e-02, -8.1849e-02,\n         -1.3079e-01, -1.4430e-01, -4.8690e-02,  9.2689e-02,  1.6096e-01,\n         -1.3877e-01, -3.4830e-02,  1.6690e-01,  1.6656e-01, -1.1822e-02,\n         -3.4901e-02,  1.4292e-01,  1.1926e-01, -5.6298e-02,  3.5415e-02,\n         -3.9778e-02,  5.5292e-02,  1.5080e-01, -1.7348e-01, -2.3537e-02,\n          1.4312e-01, -9.3516e-02,  3.8701e-03,  1.9998e-03,  1.7088e-01,\n         -9.2536e-02,  2.1219e-02],\n        [ 3.1938e-02,  1.1807e-01,  9.4810e-02, -7.1605e-02, -9.8138e-02,\n          1.6080e-01, -6.3706e-02,  1.3756e-01, -1.1744e-01,  1.3857e-01,\n         -1.1287e-01, -2.6020e-02, -1.0508e-01, -6.3810e-02,  1.5454e-01,\n          1.7267e-01,  1.7142e-01,  1.5683e-01,  1.3317e-01,  3.0561e-02,\n         -9.7483e-02, -2.1945e-02, -9.1716e-02, -1.2524e-01, -3.4671e-03,\n          1.4716e-01,  1.2163e-01,  7.1278e-02,  1.3724e-01, -4.7904e-02,\n          7.1606e-02,  1.7419e-01],\n        [-1.6634e-01,  9.5430e-02,  4.5806e-02,  1.2180e-01,  1.2214e-01,\n          5.5566e-02,  1.5068e-01, -1.6873e-01,  3.1644e-02,  1.0282e-01,\n          5.4282e-02, -9.3300e-02,  9.0309e-02,  8.4501e-02,  1.4831e-01,\n          1.0120e-01, -1.0905e-01, -9.6346e-02, -1.1509e-01,  3.6807e-02,\n         -7.3746e-02,  8.3387e-02, -2.2655e-02,  3.8670e-02, -1.6067e-01,\n          1.1315e-01, -1.3272e-01, -1.7021e-01, -1.0378e-01, -1.5356e-01,\n         -1.8505e-02,  3.9857e-02],\n        [ 2.0241e-02,  5.5408e-02, -1.5631e-01, -7.2025e-02,  1.0542e-01,\n         -1.0420e-01,  1.6184e-01, -1.3964e-01,  1.4820e-02, -5.8639e-02,\n         -1.3519e-01,  1.4707e-01,  9.2033e-02, -9.0465e-03,  1.6304e-01,\n         -1.4080e-01,  8.8492e-02, -8.1872e-02, -5.9581e-02,  3.1723e-02,\n         -1.0739e-01, -3.3448e-02,  7.2313e-03, -1.5237e-02,  1.6666e-01,\n          1.1410e-01,  4.9000e-02,  3.8183e-02,  7.1445e-02,  9.2169e-02,\n          4.7037e-02,  1.0085e-01],\n        [-1.8308e-02, -3.2434e-02,  1.7119e-01, -1.2015e-01,  5.1286e-02,\n         -8.2920e-02,  1.5055e-01,  1.3996e-01,  1.4506e-01, -5.5957e-02,\n          4.4864e-03,  6.5285e-02,  1.6872e-01,  1.4179e-02,  2.6078e-02,\n          6.3210e-02,  1.2896e-01,  6.5604e-02,  1.5436e-01, -3.7958e-02,\n         -3.8650e-02, -6.8819e-02,  1.5120e-01,  2.3663e-02, -1.3285e-02,\n          5.1383e-02, -9.1354e-02, -1.4754e-02,  6.9569e-02,  1.1462e-01,\n         -1.3232e-01,  1.0600e-01],\n        [ 2.6896e-03, -1.0745e-01,  1.4407e-01,  9.8432e-02, -1.9894e-02,\n          1.2127e-01, -1.2405e-01, -2.8985e-02,  3.7145e-02, -4.8982e-02,\n          8.0263e-02,  1.4474e-01,  5.9123e-02, -7.7260e-02, -9.9949e-02,\n         -1.1892e-01, -1.0850e-02, -1.4589e-01, -1.3076e-01,  1.2737e-01,\n          1.4098e-01, -1.0987e-01,  2.8156e-02, -1.4433e-01, -2.7582e-02,\n          5.9881e-02, -6.0737e-02, -1.6700e-01, -6.7889e-02, -1.1227e-01,\n         -1.3304e-01, -1.2287e-01],\n        [ 1.2828e-02,  4.2605e-02,  2.7891e-02, -6.6125e-02, -7.3980e-02,\n         -2.4561e-02,  1.3331e-01,  1.7544e-01,  3.6036e-02,  1.4427e-01,\n         -1.7001e-01, -1.1009e-01, -6.6537e-02,  8.2633e-02, -9.2817e-02,\n          1.1435e-01, -1.4698e-01, -4.8743e-02,  1.6708e-01, -1.0339e-01,\n          9.5770e-02, -1.2394e-01, -8.5184e-02,  4.7618e-02, -6.4882e-02,\n         -6.8851e-02, -1.3100e-01, -5.2646e-02, -7.0012e-02,  3.2794e-02,\n          9.1835e-02, -1.6389e-01],\n        [ 1.6288e-02, -1.6255e-01,  1.0221e-01, -1.4014e-01, -1.1121e-01,\n         -7.4727e-02,  9.3516e-02, -8.8222e-03,  1.1158e-01, -8.1025e-02,\n          1.3424e-01, -1.5923e-01, -1.0275e-01, -8.1043e-02,  1.0206e-01,\n          1.2343e-01, -6.6348e-02, -5.6909e-02,  4.8673e-02, -7.1338e-02,\n          1.4958e-01, -9.5854e-02,  2.3490e-02, -1.9149e-02,  8.9004e-02,\n         -1.2654e-01,  1.6217e-02, -1.3524e-01, -5.8350e-02,  4.8051e-02,\n         -1.4576e-01, -1.1434e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0247,  0.1380, -0.1758,  0.1517, -0.0765, -0.0580,  0.1752, -0.1375,\n         0.1190,  0.1344,  0.1628, -0.0870, -0.0335, -0.1003, -0.0758, -0.1610],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2292, -0.0910, -0.0402,  0.0886, -0.2182,  0.1177,  0.2325,  0.0679,\n          0.1418,  0.0843, -0.0853, -0.1859,  0.0364, -0.2182,  0.0770, -0.0022],\n        [-0.0551, -0.0108, -0.0260,  0.2302, -0.1918, -0.2024,  0.1439,  0.1164,\n          0.0517, -0.1016, -0.1897, -0.1668, -0.1387,  0.2174, -0.0230, -0.0645],\n        [ 0.0890, -0.0810, -0.0882, -0.2080,  0.0165,  0.1521,  0.1542, -0.2146,\n         -0.2308, -0.1495, -0.2015,  0.0977, -0.1864, -0.1277,  0.2481, -0.1025],\n        [ 0.0478,  0.1797,  0.0450, -0.1888,  0.1297, -0.0537,  0.1064, -0.0695,\n          0.1904,  0.0454, -0.0884, -0.2033,  0.2034, -0.0557,  0.0635,  0.0219],\n        [-0.1105, -0.2484,  0.2482,  0.2049,  0.0292, -0.1530, -0.0842,  0.0258,\n          0.1579,  0.1433,  0.0311,  0.0222,  0.1738,  0.2068, -0.2388,  0.0148],\n        [-0.1818, -0.1482,  0.1875, -0.0355,  0.0152, -0.0951,  0.2283, -0.0614,\n          0.1502,  0.0259,  0.1090, -0.1574, -0.0655, -0.0163,  0.0401, -0.1531],\n        [-0.0499, -0.1107,  0.0577,  0.1106,  0.1508, -0.0974,  0.1675, -0.2286,\n          0.1875,  0.2282,  0.2056, -0.0220, -0.0699,  0.1990, -0.1266,  0.1869],\n        [ 0.0263, -0.1046, -0.0272, -0.0455,  0.1511,  0.1356,  0.1110,  0.2496,\n          0.0981, -0.2343,  0.0632, -0.1608,  0.0388, -0.1912, -0.0948, -0.0431]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2363, -0.0621, -0.1640,  0.0233, -0.0844,  0.0078,  0.0523,  0.0907],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0490, -0.1932,  0.0360, -0.1022,  0.1815,  0.2447,  0.0296,  0.2828]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1308], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x0000024EE89A22F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x0000024EB12B9270>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s357440000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s357440000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}