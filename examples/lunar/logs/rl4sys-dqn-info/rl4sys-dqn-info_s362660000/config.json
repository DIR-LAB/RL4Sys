{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s362660000"
    },
    "q_lr":	0.0003,
    "seed":	362660000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7bd32b486f10>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0587,  0.0157,  0.1075,  0.1873,  0.0343,  0.3248,  0.1024, -0.0821,\n         0.0798, -0.2041, -0.3462, -0.1433, -0.3473, -0.2081,  0.0907,  0.1156,\n        -0.1673,  0.0836,  0.2139,  0.2929, -0.2781,  0.0951,  0.2636,  0.3486,\n         0.0263,  0.3102,  0.2191,  0.1036, -0.0050,  0.1067, -0.0327,  0.3191],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 5.9012e-02,  1.0780e-01, -7.2885e-02,  9.2062e-02,  1.7925e-01,\n          2.1839e-01, -2.4511e-01,  3.1733e-02],\n        [-2.0124e-01, -4.9324e-03,  3.3673e-01,  1.6650e-01,  1.3859e-01,\n         -2.4548e-01, -1.2727e-01,  1.0050e-01],\n        [ 2.3376e-02,  1.7176e-01, -1.3501e-02,  1.6323e-01,  1.3317e-01,\n         -2.2175e-01, -1.6621e-01,  2.3584e-01],\n        [-1.8168e-01,  2.1123e-01,  1.2757e-01, -1.2393e-02, -2.6296e-01,\n          2.0137e-01,  2.1277e-03,  1.5947e-01],\n        [ 1.1037e-01,  2.4091e-01,  2.9754e-01, -2.8910e-01,  2.5478e-01,\n         -2.2895e-01,  1.5039e-01,  5.3357e-02],\n        [ 2.6222e-01, -2.1330e-01, -1.4663e-01, -3.1254e-01,  1.7900e-01,\n         -3.4361e-01, -2.7346e-01,  1.5730e-01],\n        [ 3.0310e-01, -2.0689e-01,  6.2078e-02,  1.3674e-01, -1.2344e-01,\n         -3.6821e-02,  2.0711e-01, -2.5450e-03],\n        [ 3.8760e-02, -2.7014e-01, -5.0584e-03, -2.1907e-01,  1.6877e-01,\n         -3.4456e-01,  1.1185e-01,  2.3303e-01],\n        [ 1.8021e-01,  1.3339e-03, -2.5058e-01,  2.5691e-02, -2.0761e-01,\n         -1.4550e-01,  7.5450e-02,  1.2004e-01],\n        [-1.6603e-01,  1.9772e-01, -1.7216e-01,  2.0683e-01,  2.6050e-01,\n         -4.7735e-02,  3.1607e-01, -2.9462e-01],\n        [ 2.1138e-01,  2.3492e-01, -2.8559e-01, -1.5101e-01, -1.2593e-01,\n         -5.3310e-02, -2.7568e-01,  1.4346e-01],\n        [ 2.0156e-01,  2.3061e-01, -2.2675e-01,  3.3247e-01,  9.0897e-02,\n         -2.7283e-02,  1.0900e-01, -2.7217e-01],\n        [ 1.2272e-01, -1.9536e-01,  2.3248e-01,  1.3665e-02, -7.2562e-02,\n          3.3223e-01,  1.9963e-01,  2.4787e-01],\n        [-1.5726e-01, -2.5873e-02, -1.0114e-01,  1.0388e-01, -2.7739e-01,\n         -1.7290e-01, -7.3088e-02,  1.1117e-01],\n        [-2.0812e-01,  1.6437e-01, -1.2691e-01, -8.2044e-02,  2.8705e-01,\n         -2.7743e-01, -4.2998e-02, -8.4826e-02],\n        [-2.4656e-01,  1.3734e-01, -1.2339e-01,  8.3108e-02,  6.6047e-02,\n         -2.2843e-01,  3.1034e-01, -1.3167e-02],\n        [-2.7624e-01, -1.4847e-01,  3.3592e-01,  1.8682e-01,  3.3040e-02,\n          3.4892e-02, -1.2241e-01, -6.4086e-02],\n        [ 2.3124e-01, -3.3488e-01, -3.4896e-01,  6.0645e-02, -1.6309e-02,\n          3.0005e-01, -1.8760e-01, -1.7248e-01],\n        [-2.7237e-01,  1.6651e-01,  1.5827e-01,  1.5029e-01, -3.3915e-01,\n          2.8361e-04, -1.1314e-01, -2.5454e-01],\n        [ 3.2512e-01,  5.7101e-02, -2.2045e-01,  1.7029e-01, -2.1508e-01,\n          3.5179e-02, -1.8259e-01,  1.5351e-01],\n        [-2.0896e-01, -3.4443e-01, -3.2927e-01, -2.2385e-01,  8.8086e-02,\n         -1.7638e-01, -1.7335e-01, -6.0720e-02],\n        [-7.9667e-02, -1.1136e-01, -2.3889e-01,  3.3770e-01,  1.0481e-01,\n          1.8973e-01,  2.5239e-01, -1.1216e-01],\n        [ 3.3907e-01, -3.2141e-01, -1.9429e-01,  1.0775e-01, -2.9063e-01,\n          1.4081e-01, -1.2265e-01,  1.9440e-01],\n        [ 8.7514e-02, -7.1144e-02, -3.1529e-01, -2.7501e-01, -1.4419e-01,\n         -3.1150e-01,  2.1479e-01, -2.8653e-01],\n        [ 3.4377e-01, -3.2972e-01,  6.9145e-02, -3.4839e-01,  3.0458e-01,\n          8.2464e-02,  1.0737e-01,  2.1583e-01],\n        [ 2.9709e-01,  2.9130e-01, -1.0043e-01,  4.8964e-03,  2.0418e-01,\n         -1.0978e-01, -9.4472e-02, -7.4475e-02],\n        [-1.5912e-01,  3.0944e-01,  2.3896e-01,  3.1013e-01, -2.9277e-01,\n         -1.2104e-01,  2.6954e-01, -4.5564e-02],\n        [ 1.7531e-01, -5.9499e-02,  2.3820e-01,  1.9215e-01, -9.9634e-02,\n         -2.1425e-01, -2.2849e-01, -2.2125e-01],\n        [ 7.6663e-03,  1.3595e-01,  2.5732e-01, -3.1879e-02,  1.1893e-01,\n          2.6259e-01,  2.5663e-01,  1.8226e-01],\n        [-2.1409e-01,  1.2700e-02,  3.7535e-02,  2.2074e-01, -1.0313e-01,\n         -2.8131e-01,  8.7483e-02,  3.0076e-01],\n        [ 1.1303e-01, -1.6345e-01,  7.0567e-02,  3.0839e-01,  1.9385e-01,\n         -2.5811e-01, -6.3761e-02,  7.1112e-02],\n        [ 2.9430e-01, -2.9679e-01,  5.5044e-02,  3.0971e-01,  1.2976e-01,\n          7.0928e-02, -6.0573e-02, -2.1125e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0684,  0.1377,  0.0235, -0.1104, -0.0310,  0.0875,  0.0694, -0.0907,\n        -0.0709, -0.0301,  0.0780,  0.0294,  0.1363,  0.0124, -0.1300,  0.0480],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.6352e-01, -3.1778e-02, -1.0570e-01, -1.4706e-01,  8.6530e-02,\n          8.2930e-02,  2.1150e-02,  1.6239e-01, -1.2249e-01, -1.0484e-01,\n         -1.7659e-01,  8.1325e-02,  1.0049e-01, -6.6281e-02, -9.4909e-02,\n          3.8809e-02,  1.5947e-01, -1.3166e-01, -2.0723e-02, -1.0381e-01,\n          1.2982e-01, -2.2898e-02, -1.3187e-01, -4.1290e-02,  8.8606e-02,\n         -3.1237e-02,  7.9045e-02, -6.9013e-02, -8.6425e-02,  7.2147e-02,\n         -1.7411e-01, -1.2132e-02],\n        [-3.8414e-02, -9.3342e-02,  5.8856e-02, -1.5227e-01,  5.5591e-02,\n         -5.7334e-02,  2.3731e-02,  2.6027e-02, -1.0084e-01,  4.5593e-02,\n          1.7577e-01, -1.1996e-01, -1.4083e-01, -6.7366e-02, -1.4892e-01,\n         -1.9620e-02, -9.1039e-02, -5.0154e-02,  1.5297e-01,  3.4153e-02,\n          7.6243e-02,  4.8168e-02,  6.8319e-02, -1.4734e-01,  2.6278e-03,\n          1.0286e-01,  3.4329e-02,  1.5499e-02, -1.5693e-01,  6.1171e-02,\n         -2.1677e-02, -9.0371e-02],\n        [-1.6022e-01, -6.6725e-02, -5.4837e-02,  8.2338e-02, -9.9409e-02,\n          1.6052e-01, -1.5107e-01,  1.5431e-01,  7.5230e-02, -3.5361e-02,\n         -8.8437e-02,  9.8067e-02,  6.6288e-02, -1.5070e-01,  1.1809e-01,\n          3.7856e-02,  7.2906e-02, -1.2095e-01, -1.0290e-01, -6.6853e-02,\n          7.6520e-02, -5.1632e-02, -1.3030e-01, -1.7038e-01, -1.5386e-01,\n          8.4117e-02,  9.9208e-02,  1.1662e-01, -1.0781e-01,  1.5074e-02,\n          1.5441e-01, -2.6721e-02],\n        [-7.1668e-02, -1.1266e-02, -5.4150e-02,  7.8734e-02,  3.6046e-03,\n         -1.1118e-01, -8.2746e-02,  5.9093e-02,  1.1599e-01, -9.9405e-02,\n         -2.5091e-02,  4.0083e-02, -2.7952e-02,  1.6103e-01, -2.2997e-03,\n         -1.6219e-01,  1.7501e-01, -7.1699e-02,  6.5364e-02, -6.7514e-02,\n          8.0365e-03,  1.6957e-01,  1.0975e-01, -1.6999e-01,  3.0633e-02,\n         -6.3151e-02, -1.4640e-02,  8.9542e-02,  4.0980e-02,  4.9792e-02,\n         -1.3617e-01,  9.0300e-02],\n        [-1.9857e-02,  1.4713e-01, -8.9882e-02, -1.4895e-01,  1.2253e-01,\n         -1.6149e-01,  2.8299e-03,  1.6886e-02, -4.7238e-02,  1.0702e-01,\n          1.2147e-01, -3.2426e-02,  1.2107e-01, -1.3330e-01,  2.2796e-02,\n          1.5258e-01,  1.3684e-02,  1.4532e-01,  1.1976e-01,  1.4294e-01,\n         -1.4201e-01, -1.7059e-01,  9.5245e-02, -1.6288e-01, -6.8982e-02,\n          1.1311e-01, -3.3578e-03, -6.7187e-02,  1.1275e-01,  1.7189e-01,\n          1.3277e-01,  5.6648e-02],\n        [ 1.2189e-01,  1.3893e-01, -5.7147e-02,  6.8937e-02,  2.6096e-02,\n         -5.8312e-02, -1.7585e-01,  6.7770e-02,  9.8878e-02,  3.5758e-02,\n          1.5892e-01, -1.1925e-01,  1.3966e-01,  8.3631e-02,  2.7912e-02,\n         -1.4032e-01,  3.9932e-02, -9.0168e-02, -5.9018e-02,  1.9240e-02,\n          1.4016e-01,  1.7454e-01,  4.9798e-02,  1.1950e-01,  8.8551e-03,\n         -1.5245e-01,  3.6847e-02,  1.7224e-01,  7.0024e-02,  3.5789e-02,\n         -1.6415e-01, -1.1409e-01],\n        [ 9.4750e-02,  1.0335e-01,  1.3350e-01,  1.4590e-01, -1.4597e-02,\n         -9.8814e-02,  1.3106e-01,  3.6248e-02, -1.2270e-01,  1.1976e-01,\n          1.1400e-01, -1.2065e-01, -3.1542e-02,  1.1912e-01, -1.1820e-01,\n         -1.0406e-01,  1.6054e-01,  1.7125e-01,  5.0293e-02, -1.0399e-02,\n          5.5885e-02,  8.8015e-02, -1.5086e-01, -1.2954e-01,  1.0977e-01,\n          6.6809e-02, -1.7207e-01, -7.2190e-02,  1.4483e-01,  8.5300e-02,\n         -1.1603e-01, -3.5736e-02],\n        [-1.1004e-01, -4.5027e-02, -6.1653e-02, -1.3067e-01, -4.3036e-02,\n          8.3607e-02, -1.5857e-01,  1.5140e-02,  7.1226e-02,  1.7458e-01,\n         -1.3342e-01, -1.0397e-01,  1.2201e-01,  1.7700e-02,  7.7537e-02,\n          1.4827e-01, -4.5244e-02, -1.1297e-01,  1.3878e-01,  5.3630e-03,\n          7.2979e-02, -4.9714e-02, -9.0792e-02, -1.7840e-02,  1.3664e-01,\n          8.4666e-02,  8.2444e-02,  5.7815e-02, -1.7280e-01, -1.5742e-01,\n          1.1179e-01,  2.1070e-03],\n        [-2.6719e-02, -2.5918e-02, -6.8717e-02,  1.5763e-01, -1.4215e-01,\n          1.5437e-01, -9.6211e-02, -1.5411e-01, -7.9683e-02, -5.4235e-02,\n          1.5111e-02,  6.2592e-02, -7.6948e-02, -6.4307e-02,  8.1149e-02,\n         -1.0554e-01, -9.5432e-02,  9.5679e-02,  1.3942e-01, -6.2265e-02,\n         -1.2532e-01,  1.3772e-02,  1.6857e-01, -6.4792e-02, -3.6057e-02,\n          1.5683e-01, -1.3411e-01,  8.3967e-02, -1.6972e-01,  7.0117e-02,\n         -5.9580e-02, -1.3582e-01],\n        [-6.8379e-02,  3.3565e-02, -1.0074e-01, -1.3280e-01,  1.2261e-04,\n         -1.5441e-02, -1.2654e-01,  1.4448e-01,  1.1268e-01,  2.0627e-02,\n          1.3760e-01,  1.5549e-01, -1.5988e-01,  6.6964e-02,  7.6685e-02,\n          1.7368e-01,  1.3315e-01,  8.8769e-02,  2.6607e-02,  3.3400e-02,\n          8.4983e-02, -3.8033e-02, -8.5476e-02,  7.1844e-02,  9.4793e-02,\n         -1.6136e-02,  6.7599e-02,  1.4994e-01, -4.8267e-02, -2.3464e-02,\n         -9.0399e-02,  3.6646e-02],\n        [ 1.7266e-01, -1.4401e-01, -1.0534e-01,  1.5791e-01, -1.5355e-01,\n         -1.6196e-01, -3.9789e-02, -1.1472e-01,  7.0589e-03, -1.0696e-01,\n          7.8910e-02,  2.0282e-02, -8.8391e-02, -1.5918e-01,  9.1965e-02,\n          9.5245e-02,  1.6779e-01, -1.4672e-01,  5.7956e-02, -8.4207e-02,\n          8.0357e-03, -9.4443e-02,  1.7299e-01,  1.5700e-01,  9.7525e-02,\n         -1.7363e-01,  4.3182e-02, -1.7373e-01, -9.8937e-02,  2.6393e-02,\n         -1.0766e-01,  3.8426e-02],\n        [ 1.4013e-01, -4.8774e-02,  1.5742e-01, -1.3454e-01,  6.6324e-03,\n          4.8170e-02,  1.0247e-03, -7.1190e-02, -1.5332e-01, -1.4205e-01,\n         -6.2458e-02,  4.4681e-02,  2.8464e-02,  9.4567e-02,  1.4702e-01,\n         -2.1483e-02,  1.1759e-01,  9.6027e-02,  5.7121e-02, -1.0303e-01,\n          2.9381e-03, -7.0145e-02,  9.9217e-02, -6.4032e-02, -7.0115e-02,\n          4.5299e-02, -1.2930e-01,  7.9169e-02, -1.2992e-01, -4.6909e-02,\n         -1.1181e-01,  1.6886e-01],\n        [-1.4439e-01,  1.4404e-01, -9.1473e-02, -1.2750e-01, -6.9330e-02,\n          9.3158e-02, -1.2722e-01, -9.8276e-04, -1.3400e-01,  1.6769e-02,\n         -9.6564e-02, -1.4394e-01,  1.1259e-01, -4.2486e-02, -1.5492e-01,\n         -1.7480e-01,  1.4838e-01, -3.7816e-02,  5.1395e-02,  1.2670e-01,\n          1.1909e-01, -3.1955e-02,  5.7121e-02,  5.2487e-02, -1.6646e-01,\n         -1.5227e-01,  6.3039e-02, -7.5691e-02, -1.3825e-01,  3.2021e-02,\n          1.2124e-01, -1.1827e-01],\n        [-9.7864e-02,  1.5720e-01,  4.6972e-02,  9.1471e-02, -1.2945e-01,\n          1.1825e-01, -5.7751e-02,  1.3214e-01,  5.4804e-02,  1.3112e-01,\n          1.3887e-01,  1.2864e-01, -1.5008e-01, -1.6364e-01, -1.2862e-01,\n         -1.6102e-01,  4.0341e-02, -5.1678e-02, -1.1133e-03, -4.1050e-02,\n         -5.0538e-02,  4.2969e-02,  2.7160e-02, -2.4345e-02, -2.9593e-02,\n          1.3671e-01, -1.6754e-01, -1.0966e-01,  5.3787e-02,  7.9306e-02,\n         -1.1815e-01,  1.3830e-02],\n        [-1.0806e-01, -5.5920e-02, -4.2381e-02, -3.1582e-02,  7.7456e-03,\n          6.0071e-02,  6.6893e-04, -1.1383e-01,  1.3275e-01,  9.2892e-02,\n          1.0833e-01, -1.0931e-01, -5.7453e-02, -5.3555e-02,  1.4612e-01,\n          1.6564e-01, -1.2334e-02, -1.7057e-01,  1.7927e-02, -1.5196e-01,\n          1.7002e-01,  6.8674e-02, -1.2029e-01,  8.1689e-02, -1.4428e-01,\n          1.6003e-01, -1.6356e-01,  1.1336e-01,  9.5601e-02,  7.1967e-02,\n         -7.1182e-03, -1.2615e-01],\n        [-1.1075e-01,  1.7288e-01, -8.3099e-02, -1.3852e-01,  2.2932e-02,\n          3.3949e-02, -1.4511e-01,  1.5479e-01, -3.3876e-02, -1.6111e-01,\n          1.0910e-01,  1.4799e-02,  1.3363e-01,  1.1179e-01,  8.8068e-02,\n         -1.0902e-01,  5.9539e-02, -7.3715e-02, -7.7824e-02,  1.1355e-01,\n         -9.2091e-02, -2.6886e-02,  5.9804e-02, -1.7416e-01, -7.0140e-02,\n         -1.8754e-02, -7.5672e-02, -8.3609e-02, -3.3375e-02, -7.2439e-02,\n         -8.9459e-02, -9.9231e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2249, -0.2182,  0.0985,  0.0269, -0.0045, -0.1760, -0.0281,  0.2189],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1549, -0.2286, -0.1291,  0.0932, -0.1576, -0.0630,  0.0441,  0.1341,\n         -0.0462,  0.0655, -0.1829, -0.1850, -0.0025, -0.1102, -0.0483, -0.0938],\n        [ 0.1994,  0.1450,  0.0409, -0.0904, -0.1077,  0.0702, -0.2091,  0.1182,\n         -0.1458, -0.1756,  0.1543, -0.1355,  0.1250, -0.2029, -0.1284, -0.2195],\n        [-0.0255, -0.0854,  0.1965,  0.1376,  0.2371,  0.2246,  0.1271, -0.2329,\n         -0.0990, -0.1430,  0.0681,  0.0417,  0.0540,  0.0784,  0.0547,  0.0637],\n        [-0.1260, -0.0932,  0.0277, -0.0277,  0.1820, -0.1182,  0.2453,  0.0744,\n          0.0602, -0.1976,  0.2109, -0.2038,  0.2281,  0.0186, -0.1375, -0.0714],\n        [-0.0317, -0.0892,  0.0708,  0.2191, -0.2117, -0.1679,  0.0779,  0.1338,\n         -0.0333,  0.0326,  0.1352, -0.0654, -0.0006,  0.1648, -0.0064,  0.1827],\n        [ 0.2055, -0.1553,  0.1829,  0.1780,  0.0980, -0.0335, -0.1030, -0.0751,\n          0.0377, -0.0269, -0.0185,  0.0979,  0.0429,  0.0946, -0.0522, -0.2042],\n        [-0.2381,  0.1318, -0.2263, -0.1202,  0.0417,  0.0541,  0.2014, -0.2269,\n          0.1065,  0.1461,  0.1872, -0.1702,  0.1243, -0.1007,  0.0927, -0.1205],\n        [-0.0653,  0.0254, -0.1997,  0.2339, -0.1060, -0.0655, -0.0081,  0.0361,\n          0.0107, -0.0718,  0.1851, -0.1948, -0.0227,  0.1198,  0.0465, -0.0424]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0169, -0.2908, -0.2661, -0.0302], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0239, -0.3095, -0.1571,  0.0687, -0.0821,  0.3431,  0.0032,  0.0074],\n        [-0.2269,  0.1785,  0.2915, -0.2835, -0.1802, -0.2371,  0.1511,  0.2114],\n        [-0.3090, -0.0342,  0.1097, -0.2316, -0.3105,  0.0595,  0.1987,  0.1212],\n        [ 0.1799,  0.2540,  0.1198, -0.1677,  0.1559, -0.0538,  0.0041, -0.1497]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 5.9012e-02,  1.0780e-01, -7.2885e-02,  9.2062e-02,  1.7925e-01,\n          2.1839e-01, -2.4511e-01,  3.1733e-02],\n        [-2.0124e-01, -4.9324e-03,  3.3673e-01,  1.6650e-01,  1.3859e-01,\n         -2.4548e-01, -1.2727e-01,  1.0050e-01],\n        [ 2.3376e-02,  1.7176e-01, -1.3501e-02,  1.6323e-01,  1.3317e-01,\n         -2.2175e-01, -1.6621e-01,  2.3584e-01],\n        [-1.8168e-01,  2.1123e-01,  1.2757e-01, -1.2393e-02, -2.6296e-01,\n          2.0137e-01,  2.1277e-03,  1.5947e-01],\n        [ 1.1037e-01,  2.4091e-01,  2.9754e-01, -2.8910e-01,  2.5478e-01,\n         -2.2895e-01,  1.5039e-01,  5.3357e-02],\n        [ 2.6222e-01, -2.1330e-01, -1.4663e-01, -3.1254e-01,  1.7900e-01,\n         -3.4361e-01, -2.7346e-01,  1.5730e-01],\n        [ 3.0310e-01, -2.0689e-01,  6.2078e-02,  1.3674e-01, -1.2344e-01,\n         -3.6821e-02,  2.0711e-01, -2.5450e-03],\n        [ 3.8760e-02, -2.7014e-01, -5.0584e-03, -2.1907e-01,  1.6877e-01,\n         -3.4456e-01,  1.1185e-01,  2.3303e-01],\n        [ 1.8021e-01,  1.3339e-03, -2.5058e-01,  2.5691e-02, -2.0761e-01,\n         -1.4550e-01,  7.5450e-02,  1.2004e-01],\n        [-1.6603e-01,  1.9772e-01, -1.7216e-01,  2.0683e-01,  2.6050e-01,\n         -4.7735e-02,  3.1607e-01, -2.9462e-01],\n        [ 2.1138e-01,  2.3492e-01, -2.8559e-01, -1.5101e-01, -1.2593e-01,\n         -5.3310e-02, -2.7568e-01,  1.4346e-01],\n        [ 2.0156e-01,  2.3061e-01, -2.2675e-01,  3.3247e-01,  9.0897e-02,\n         -2.7283e-02,  1.0900e-01, -2.7217e-01],\n        [ 1.2272e-01, -1.9536e-01,  2.3248e-01,  1.3665e-02, -7.2562e-02,\n          3.3223e-01,  1.9963e-01,  2.4787e-01],\n        [-1.5726e-01, -2.5873e-02, -1.0114e-01,  1.0388e-01, -2.7739e-01,\n         -1.7290e-01, -7.3088e-02,  1.1117e-01],\n        [-2.0812e-01,  1.6437e-01, -1.2691e-01, -8.2044e-02,  2.8705e-01,\n         -2.7743e-01, -4.2998e-02, -8.4826e-02],\n        [-2.4656e-01,  1.3734e-01, -1.2339e-01,  8.3108e-02,  6.6047e-02,\n         -2.2843e-01,  3.1034e-01, -1.3167e-02],\n        [-2.7624e-01, -1.4847e-01,  3.3592e-01,  1.8682e-01,  3.3040e-02,\n          3.4892e-02, -1.2241e-01, -6.4086e-02],\n        [ 2.3124e-01, -3.3488e-01, -3.4896e-01,  6.0645e-02, -1.6309e-02,\n          3.0005e-01, -1.8760e-01, -1.7248e-01],\n        [-2.7237e-01,  1.6651e-01,  1.5827e-01,  1.5029e-01, -3.3915e-01,\n          2.8361e-04, -1.1314e-01, -2.5454e-01],\n        [ 3.2512e-01,  5.7101e-02, -2.2045e-01,  1.7029e-01, -2.1508e-01,\n          3.5179e-02, -1.8259e-01,  1.5351e-01],\n        [-2.0896e-01, -3.4443e-01, -3.2927e-01, -2.2385e-01,  8.8086e-02,\n         -1.7638e-01, -1.7335e-01, -6.0720e-02],\n        [-7.9667e-02, -1.1136e-01, -2.3889e-01,  3.3770e-01,  1.0481e-01,\n          1.8973e-01,  2.5239e-01, -1.1216e-01],\n        [ 3.3907e-01, -3.2141e-01, -1.9429e-01,  1.0775e-01, -2.9063e-01,\n          1.4081e-01, -1.2265e-01,  1.9440e-01],\n        [ 8.7514e-02, -7.1144e-02, -3.1529e-01, -2.7501e-01, -1.4419e-01,\n         -3.1150e-01,  2.1479e-01, -2.8653e-01],\n        [ 3.4377e-01, -3.2972e-01,  6.9145e-02, -3.4839e-01,  3.0458e-01,\n          8.2464e-02,  1.0737e-01,  2.1583e-01],\n        [ 2.9709e-01,  2.9130e-01, -1.0043e-01,  4.8964e-03,  2.0418e-01,\n         -1.0978e-01, -9.4472e-02, -7.4475e-02],\n        [-1.5912e-01,  3.0944e-01,  2.3896e-01,  3.1013e-01, -2.9277e-01,\n         -1.2104e-01,  2.6954e-01, -4.5564e-02],\n        [ 1.7531e-01, -5.9499e-02,  2.3820e-01,  1.9215e-01, -9.9634e-02,\n         -2.1425e-01, -2.2849e-01, -2.2125e-01],\n        [ 7.6663e-03,  1.3595e-01,  2.5732e-01, -3.1879e-02,  1.1893e-01,\n          2.6259e-01,  2.5663e-01,  1.8226e-01],\n        [-2.1409e-01,  1.2700e-02,  3.7535e-02,  2.2074e-01, -1.0313e-01,\n         -2.8131e-01,  8.7483e-02,  3.0076e-01],\n        [ 1.1303e-01, -1.6345e-01,  7.0567e-02,  3.0839e-01,  1.9385e-01,\n         -2.5811e-01, -6.3761e-02,  7.1112e-02],\n        [ 2.9430e-01, -2.9679e-01,  5.5044e-02,  3.0971e-01,  1.2976e-01,\n          7.0928e-02, -6.0573e-02, -2.1125e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0587,  0.0157,  0.1075,  0.1873,  0.0343,  0.3248,  0.1024, -0.0821,\n         0.0798, -0.2041, -0.3462, -0.1433, -0.3473, -0.2081,  0.0907,  0.1156,\n        -0.1673,  0.0836,  0.2139,  0.2929, -0.2781,  0.0951,  0.2636,  0.3486,\n         0.0263,  0.3102,  0.2191,  0.1036, -0.0050,  0.1067, -0.0327,  0.3191],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.6352e-01, -3.1778e-02, -1.0570e-01, -1.4706e-01,  8.6530e-02,\n          8.2930e-02,  2.1150e-02,  1.6239e-01, -1.2249e-01, -1.0484e-01,\n         -1.7659e-01,  8.1325e-02,  1.0049e-01, -6.6281e-02, -9.4909e-02,\n          3.8809e-02,  1.5947e-01, -1.3166e-01, -2.0723e-02, -1.0381e-01,\n          1.2982e-01, -2.2898e-02, -1.3187e-01, -4.1290e-02,  8.8606e-02,\n         -3.1237e-02,  7.9045e-02, -6.9013e-02, -8.6425e-02,  7.2147e-02,\n         -1.7411e-01, -1.2132e-02],\n        [-3.8414e-02, -9.3342e-02,  5.8856e-02, -1.5227e-01,  5.5591e-02,\n         -5.7334e-02,  2.3731e-02,  2.6027e-02, -1.0084e-01,  4.5593e-02,\n          1.7577e-01, -1.1996e-01, -1.4083e-01, -6.7366e-02, -1.4892e-01,\n         -1.9620e-02, -9.1039e-02, -5.0154e-02,  1.5297e-01,  3.4153e-02,\n          7.6243e-02,  4.8168e-02,  6.8319e-02, -1.4734e-01,  2.6278e-03,\n          1.0286e-01,  3.4329e-02,  1.5499e-02, -1.5693e-01,  6.1171e-02,\n         -2.1677e-02, -9.0371e-02],\n        [-1.6022e-01, -6.6725e-02, -5.4837e-02,  8.2338e-02, -9.9409e-02,\n          1.6052e-01, -1.5107e-01,  1.5431e-01,  7.5230e-02, -3.5361e-02,\n         -8.8437e-02,  9.8067e-02,  6.6288e-02, -1.5070e-01,  1.1809e-01,\n          3.7856e-02,  7.2906e-02, -1.2095e-01, -1.0290e-01, -6.6853e-02,\n          7.6520e-02, -5.1632e-02, -1.3030e-01, -1.7038e-01, -1.5386e-01,\n          8.4117e-02,  9.9208e-02,  1.1662e-01, -1.0781e-01,  1.5074e-02,\n          1.5441e-01, -2.6721e-02],\n        [-7.1668e-02, -1.1266e-02, -5.4150e-02,  7.8734e-02,  3.6046e-03,\n         -1.1118e-01, -8.2746e-02,  5.9093e-02,  1.1599e-01, -9.9405e-02,\n         -2.5091e-02,  4.0083e-02, -2.7952e-02,  1.6103e-01, -2.2997e-03,\n         -1.6219e-01,  1.7501e-01, -7.1699e-02,  6.5364e-02, -6.7514e-02,\n          8.0365e-03,  1.6957e-01,  1.0975e-01, -1.6999e-01,  3.0633e-02,\n         -6.3151e-02, -1.4640e-02,  8.9542e-02,  4.0980e-02,  4.9792e-02,\n         -1.3617e-01,  9.0300e-02],\n        [-1.9857e-02,  1.4713e-01, -8.9882e-02, -1.4895e-01,  1.2253e-01,\n         -1.6149e-01,  2.8299e-03,  1.6886e-02, -4.7238e-02,  1.0702e-01,\n          1.2147e-01, -3.2426e-02,  1.2107e-01, -1.3330e-01,  2.2796e-02,\n          1.5258e-01,  1.3684e-02,  1.4532e-01,  1.1976e-01,  1.4294e-01,\n         -1.4201e-01, -1.7059e-01,  9.5245e-02, -1.6288e-01, -6.8982e-02,\n          1.1311e-01, -3.3578e-03, -6.7187e-02,  1.1275e-01,  1.7189e-01,\n          1.3277e-01,  5.6648e-02],\n        [ 1.2189e-01,  1.3893e-01, -5.7147e-02,  6.8937e-02,  2.6096e-02,\n         -5.8312e-02, -1.7585e-01,  6.7770e-02,  9.8878e-02,  3.5758e-02,\n          1.5892e-01, -1.1925e-01,  1.3966e-01,  8.3631e-02,  2.7912e-02,\n         -1.4032e-01,  3.9932e-02, -9.0168e-02, -5.9018e-02,  1.9240e-02,\n          1.4016e-01,  1.7454e-01,  4.9798e-02,  1.1950e-01,  8.8551e-03,\n         -1.5245e-01,  3.6847e-02,  1.7224e-01,  7.0024e-02,  3.5789e-02,\n         -1.6415e-01, -1.1409e-01],\n        [ 9.4750e-02,  1.0335e-01,  1.3350e-01,  1.4590e-01, -1.4597e-02,\n         -9.8814e-02,  1.3106e-01,  3.6248e-02, -1.2270e-01,  1.1976e-01,\n          1.1400e-01, -1.2065e-01, -3.1542e-02,  1.1912e-01, -1.1820e-01,\n         -1.0406e-01,  1.6054e-01,  1.7125e-01,  5.0293e-02, -1.0399e-02,\n          5.5885e-02,  8.8015e-02, -1.5086e-01, -1.2954e-01,  1.0977e-01,\n          6.6809e-02, -1.7207e-01, -7.2190e-02,  1.4483e-01,  8.5300e-02,\n         -1.1603e-01, -3.5736e-02],\n        [-1.1004e-01, -4.5027e-02, -6.1653e-02, -1.3067e-01, -4.3036e-02,\n          8.3607e-02, -1.5857e-01,  1.5140e-02,  7.1226e-02,  1.7458e-01,\n         -1.3342e-01, -1.0397e-01,  1.2201e-01,  1.7700e-02,  7.7537e-02,\n          1.4827e-01, -4.5244e-02, -1.1297e-01,  1.3878e-01,  5.3630e-03,\n          7.2979e-02, -4.9714e-02, -9.0792e-02, -1.7840e-02,  1.3664e-01,\n          8.4666e-02,  8.2444e-02,  5.7815e-02, -1.7280e-01, -1.5742e-01,\n          1.1179e-01,  2.1070e-03],\n        [-2.6719e-02, -2.5918e-02, -6.8717e-02,  1.5763e-01, -1.4215e-01,\n          1.5437e-01, -9.6211e-02, -1.5411e-01, -7.9683e-02, -5.4235e-02,\n          1.5111e-02,  6.2592e-02, -7.6948e-02, -6.4307e-02,  8.1149e-02,\n         -1.0554e-01, -9.5432e-02,  9.5679e-02,  1.3942e-01, -6.2265e-02,\n         -1.2532e-01,  1.3772e-02,  1.6857e-01, -6.4792e-02, -3.6057e-02,\n          1.5683e-01, -1.3411e-01,  8.3967e-02, -1.6972e-01,  7.0117e-02,\n         -5.9580e-02, -1.3582e-01],\n        [-6.8379e-02,  3.3565e-02, -1.0074e-01, -1.3280e-01,  1.2261e-04,\n         -1.5441e-02, -1.2654e-01,  1.4448e-01,  1.1268e-01,  2.0627e-02,\n          1.3760e-01,  1.5549e-01, -1.5988e-01,  6.6964e-02,  7.6685e-02,\n          1.7368e-01,  1.3315e-01,  8.8769e-02,  2.6607e-02,  3.3400e-02,\n          8.4983e-02, -3.8033e-02, -8.5476e-02,  7.1844e-02,  9.4793e-02,\n         -1.6136e-02,  6.7599e-02,  1.4994e-01, -4.8267e-02, -2.3464e-02,\n         -9.0399e-02,  3.6646e-02],\n        [ 1.7266e-01, -1.4401e-01, -1.0534e-01,  1.5791e-01, -1.5355e-01,\n         -1.6196e-01, -3.9789e-02, -1.1472e-01,  7.0589e-03, -1.0696e-01,\n          7.8910e-02,  2.0282e-02, -8.8391e-02, -1.5918e-01,  9.1965e-02,\n          9.5245e-02,  1.6779e-01, -1.4672e-01,  5.7956e-02, -8.4207e-02,\n          8.0357e-03, -9.4443e-02,  1.7299e-01,  1.5700e-01,  9.7525e-02,\n         -1.7363e-01,  4.3182e-02, -1.7373e-01, -9.8937e-02,  2.6393e-02,\n         -1.0766e-01,  3.8426e-02],\n        [ 1.4013e-01, -4.8774e-02,  1.5742e-01, -1.3454e-01,  6.6324e-03,\n          4.8170e-02,  1.0247e-03, -7.1190e-02, -1.5332e-01, -1.4205e-01,\n         -6.2458e-02,  4.4681e-02,  2.8464e-02,  9.4567e-02,  1.4702e-01,\n         -2.1483e-02,  1.1759e-01,  9.6027e-02,  5.7121e-02, -1.0303e-01,\n          2.9381e-03, -7.0145e-02,  9.9217e-02, -6.4032e-02, -7.0115e-02,\n          4.5299e-02, -1.2930e-01,  7.9169e-02, -1.2992e-01, -4.6909e-02,\n         -1.1181e-01,  1.6886e-01],\n        [-1.4439e-01,  1.4404e-01, -9.1473e-02, -1.2750e-01, -6.9330e-02,\n          9.3158e-02, -1.2722e-01, -9.8276e-04, -1.3400e-01,  1.6769e-02,\n         -9.6564e-02, -1.4394e-01,  1.1259e-01, -4.2486e-02, -1.5492e-01,\n         -1.7480e-01,  1.4838e-01, -3.7816e-02,  5.1395e-02,  1.2670e-01,\n          1.1909e-01, -3.1955e-02,  5.7121e-02,  5.2487e-02, -1.6646e-01,\n         -1.5227e-01,  6.3039e-02, -7.5691e-02, -1.3825e-01,  3.2021e-02,\n          1.2124e-01, -1.1827e-01],\n        [-9.7864e-02,  1.5720e-01,  4.6972e-02,  9.1471e-02, -1.2945e-01,\n          1.1825e-01, -5.7751e-02,  1.3214e-01,  5.4804e-02,  1.3112e-01,\n          1.3887e-01,  1.2864e-01, -1.5008e-01, -1.6364e-01, -1.2862e-01,\n         -1.6102e-01,  4.0341e-02, -5.1678e-02, -1.1133e-03, -4.1050e-02,\n         -5.0538e-02,  4.2969e-02,  2.7160e-02, -2.4345e-02, -2.9593e-02,\n          1.3671e-01, -1.6754e-01, -1.0966e-01,  5.3787e-02,  7.9306e-02,\n         -1.1815e-01,  1.3830e-02],\n        [-1.0806e-01, -5.5920e-02, -4.2381e-02, -3.1582e-02,  7.7456e-03,\n          6.0071e-02,  6.6893e-04, -1.1383e-01,  1.3275e-01,  9.2892e-02,\n          1.0833e-01, -1.0931e-01, -5.7453e-02, -5.3555e-02,  1.4612e-01,\n          1.6564e-01, -1.2334e-02, -1.7057e-01,  1.7927e-02, -1.5196e-01,\n          1.7002e-01,  6.8674e-02, -1.2029e-01,  8.1689e-02, -1.4428e-01,\n          1.6003e-01, -1.6356e-01,  1.1336e-01,  9.5601e-02,  7.1967e-02,\n         -7.1182e-03, -1.2615e-01],\n        [-1.1075e-01,  1.7288e-01, -8.3099e-02, -1.3852e-01,  2.2932e-02,\n          3.3949e-02, -1.4511e-01,  1.5479e-01, -3.3876e-02, -1.6111e-01,\n          1.0910e-01,  1.4799e-02,  1.3363e-01,  1.1179e-01,  8.8068e-02,\n         -1.0902e-01,  5.9539e-02, -7.3715e-02, -7.7824e-02,  1.1355e-01,\n         -9.2091e-02, -2.6886e-02,  5.9804e-02, -1.7416e-01, -7.0140e-02,\n         -1.8754e-02, -7.5672e-02, -8.3609e-02, -3.3375e-02, -7.2439e-02,\n         -8.9459e-02, -9.9231e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0684,  0.1377,  0.0235, -0.1104, -0.0310,  0.0875,  0.0694, -0.0907,\n        -0.0709, -0.0301,  0.0780,  0.0294,  0.1363,  0.0124, -0.1300,  0.0480],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1549, -0.2286, -0.1291,  0.0932, -0.1576, -0.0630,  0.0441,  0.1341,\n         -0.0462,  0.0655, -0.1829, -0.1850, -0.0025, -0.1102, -0.0483, -0.0938],\n        [ 0.1994,  0.1450,  0.0409, -0.0904, -0.1077,  0.0702, -0.2091,  0.1182,\n         -0.1458, -0.1756,  0.1543, -0.1355,  0.1250, -0.2029, -0.1284, -0.2195],\n        [-0.0255, -0.0854,  0.1965,  0.1376,  0.2371,  0.2246,  0.1271, -0.2329,\n         -0.0990, -0.1430,  0.0681,  0.0417,  0.0540,  0.0784,  0.0547,  0.0637],\n        [-0.1260, -0.0932,  0.0277, -0.0277,  0.1820, -0.1182,  0.2453,  0.0744,\n          0.0602, -0.1976,  0.2109, -0.2038,  0.2281,  0.0186, -0.1375, -0.0714],\n        [-0.0317, -0.0892,  0.0708,  0.2191, -0.2117, -0.1679,  0.0779,  0.1338,\n         -0.0333,  0.0326,  0.1352, -0.0654, -0.0006,  0.1648, -0.0064,  0.1827],\n        [ 0.2055, -0.1553,  0.1829,  0.1780,  0.0980, -0.0335, -0.1030, -0.0751,\n          0.0377, -0.0269, -0.0185,  0.0979,  0.0429,  0.0946, -0.0522, -0.2042],\n        [-0.2381,  0.1318, -0.2263, -0.1202,  0.0417,  0.0541,  0.2014, -0.2269,\n          0.1065,  0.1461,  0.1872, -0.1702,  0.1243, -0.1007,  0.0927, -0.1205],\n        [-0.0653,  0.0254, -0.1997,  0.2339, -0.1060, -0.0655, -0.0081,  0.0361,\n          0.0107, -0.0718,  0.1851, -0.1948, -0.0227,  0.1198,  0.0465, -0.0424]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2249, -0.2182,  0.0985,  0.0269, -0.0045, -0.1760, -0.0281,  0.2189],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0239, -0.3095, -0.1571,  0.0687, -0.0821,  0.3431,  0.0032,  0.0074],\n        [-0.2269,  0.1785,  0.2915, -0.2835, -0.1802, -0.2371,  0.1511,  0.2114],\n        [-0.3090, -0.0342,  0.1097, -0.2316, -0.3105,  0.0595,  0.1987,  0.1212],\n        [ 0.1799,  0.2540,  0.1198, -0.1677,  0.1559, -0.0538,  0.0041, -0.1497]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0169, -0.2908, -0.2661, -0.0302], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7bd3299df010>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0587,  0.0157,  0.1075,  0.1873,  0.0343,  0.3248,  0.1024, -0.0821,\n         0.0798, -0.2041, -0.3462, -0.1433, -0.3473, -0.2081,  0.0907,  0.1156,\n        -0.1673,  0.0836,  0.2139,  0.2929, -0.2781,  0.0951,  0.2636,  0.3486,\n         0.0263,  0.3102,  0.2191,  0.1036, -0.0050,  0.1067, -0.0327,  0.3191],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 5.9012e-02,  1.0780e-01, -7.2885e-02,  9.2062e-02,  1.7925e-01,\n          2.1839e-01, -2.4511e-01,  3.1733e-02],\n        [-2.0124e-01, -4.9324e-03,  3.3673e-01,  1.6650e-01,  1.3859e-01,\n         -2.4548e-01, -1.2727e-01,  1.0050e-01],\n        [ 2.3376e-02,  1.7176e-01, -1.3501e-02,  1.6323e-01,  1.3317e-01,\n         -2.2175e-01, -1.6621e-01,  2.3584e-01],\n        [-1.8168e-01,  2.1123e-01,  1.2757e-01, -1.2393e-02, -2.6296e-01,\n          2.0137e-01,  2.1277e-03,  1.5947e-01],\n        [ 1.1037e-01,  2.4091e-01,  2.9754e-01, -2.8910e-01,  2.5478e-01,\n         -2.2895e-01,  1.5039e-01,  5.3357e-02],\n        [ 2.6222e-01, -2.1330e-01, -1.4663e-01, -3.1254e-01,  1.7900e-01,\n         -3.4361e-01, -2.7346e-01,  1.5730e-01],\n        [ 3.0310e-01, -2.0689e-01,  6.2078e-02,  1.3674e-01, -1.2344e-01,\n         -3.6821e-02,  2.0711e-01, -2.5450e-03],\n        [ 3.8760e-02, -2.7014e-01, -5.0584e-03, -2.1907e-01,  1.6877e-01,\n         -3.4456e-01,  1.1185e-01,  2.3303e-01],\n        [ 1.8021e-01,  1.3339e-03, -2.5058e-01,  2.5691e-02, -2.0761e-01,\n         -1.4550e-01,  7.5450e-02,  1.2004e-01],\n        [-1.6603e-01,  1.9772e-01, -1.7216e-01,  2.0683e-01,  2.6050e-01,\n         -4.7735e-02,  3.1607e-01, -2.9462e-01],\n        [ 2.1138e-01,  2.3492e-01, -2.8559e-01, -1.5101e-01, -1.2593e-01,\n         -5.3310e-02, -2.7568e-01,  1.4346e-01],\n        [ 2.0156e-01,  2.3061e-01, -2.2675e-01,  3.3247e-01,  9.0897e-02,\n         -2.7283e-02,  1.0900e-01, -2.7217e-01],\n        [ 1.2272e-01, -1.9536e-01,  2.3248e-01,  1.3665e-02, -7.2562e-02,\n          3.3223e-01,  1.9963e-01,  2.4787e-01],\n        [-1.5726e-01, -2.5873e-02, -1.0114e-01,  1.0388e-01, -2.7739e-01,\n         -1.7290e-01, -7.3088e-02,  1.1117e-01],\n        [-2.0812e-01,  1.6437e-01, -1.2691e-01, -8.2044e-02,  2.8705e-01,\n         -2.7743e-01, -4.2998e-02, -8.4826e-02],\n        [-2.4656e-01,  1.3734e-01, -1.2339e-01,  8.3108e-02,  6.6047e-02,\n         -2.2843e-01,  3.1034e-01, -1.3167e-02],\n        [-2.7624e-01, -1.4847e-01,  3.3592e-01,  1.8682e-01,  3.3040e-02,\n          3.4892e-02, -1.2241e-01, -6.4086e-02],\n        [ 2.3124e-01, -3.3488e-01, -3.4896e-01,  6.0645e-02, -1.6309e-02,\n          3.0005e-01, -1.8760e-01, -1.7248e-01],\n        [-2.7237e-01,  1.6651e-01,  1.5827e-01,  1.5029e-01, -3.3915e-01,\n          2.8361e-04, -1.1314e-01, -2.5454e-01],\n        [ 3.2512e-01,  5.7101e-02, -2.2045e-01,  1.7029e-01, -2.1508e-01,\n          3.5179e-02, -1.8259e-01,  1.5351e-01],\n        [-2.0896e-01, -3.4443e-01, -3.2927e-01, -2.2385e-01,  8.8086e-02,\n         -1.7638e-01, -1.7335e-01, -6.0720e-02],\n        [-7.9667e-02, -1.1136e-01, -2.3889e-01,  3.3770e-01,  1.0481e-01,\n          1.8973e-01,  2.5239e-01, -1.1216e-01],\n        [ 3.3907e-01, -3.2141e-01, -1.9429e-01,  1.0775e-01, -2.9063e-01,\n          1.4081e-01, -1.2265e-01,  1.9440e-01],\n        [ 8.7514e-02, -7.1144e-02, -3.1529e-01, -2.7501e-01, -1.4419e-01,\n         -3.1150e-01,  2.1479e-01, -2.8653e-01],\n        [ 3.4377e-01, -3.2972e-01,  6.9145e-02, -3.4839e-01,  3.0458e-01,\n          8.2464e-02,  1.0737e-01,  2.1583e-01],\n        [ 2.9709e-01,  2.9130e-01, -1.0043e-01,  4.8964e-03,  2.0418e-01,\n         -1.0978e-01, -9.4472e-02, -7.4475e-02],\n        [-1.5912e-01,  3.0944e-01,  2.3896e-01,  3.1013e-01, -2.9277e-01,\n         -1.2104e-01,  2.6954e-01, -4.5564e-02],\n        [ 1.7531e-01, -5.9499e-02,  2.3820e-01,  1.9215e-01, -9.9634e-02,\n         -2.1425e-01, -2.2849e-01, -2.2125e-01],\n        [ 7.6663e-03,  1.3595e-01,  2.5732e-01, -3.1879e-02,  1.1893e-01,\n          2.6259e-01,  2.5663e-01,  1.8226e-01],\n        [-2.1409e-01,  1.2700e-02,  3.7535e-02,  2.2074e-01, -1.0313e-01,\n         -2.8131e-01,  8.7483e-02,  3.0076e-01],\n        [ 1.1303e-01, -1.6345e-01,  7.0567e-02,  3.0839e-01,  1.9385e-01,\n         -2.5811e-01, -6.3761e-02,  7.1112e-02],\n        [ 2.9430e-01, -2.9679e-01,  5.5044e-02,  3.0971e-01,  1.2976e-01,\n          7.0928e-02, -6.0573e-02, -2.1125e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0684,  0.1377,  0.0235, -0.1104, -0.0310,  0.0875,  0.0694, -0.0907,\n        -0.0709, -0.0301,  0.0780,  0.0294,  0.1363,  0.0124, -0.1300,  0.0480],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.6352e-01, -3.1778e-02, -1.0570e-01, -1.4706e-01,  8.6530e-02,\n          8.2930e-02,  2.1150e-02,  1.6239e-01, -1.2249e-01, -1.0484e-01,\n         -1.7659e-01,  8.1325e-02,  1.0049e-01, -6.6281e-02, -9.4909e-02,\n          3.8809e-02,  1.5947e-01, -1.3166e-01, -2.0723e-02, -1.0381e-01,\n          1.2982e-01, -2.2898e-02, -1.3187e-01, -4.1290e-02,  8.8606e-02,\n         -3.1237e-02,  7.9045e-02, -6.9013e-02, -8.6425e-02,  7.2147e-02,\n         -1.7411e-01, -1.2132e-02],\n        [-3.8414e-02, -9.3342e-02,  5.8856e-02, -1.5227e-01,  5.5591e-02,\n         -5.7334e-02,  2.3731e-02,  2.6027e-02, -1.0084e-01,  4.5593e-02,\n          1.7577e-01, -1.1996e-01, -1.4083e-01, -6.7366e-02, -1.4892e-01,\n         -1.9620e-02, -9.1039e-02, -5.0154e-02,  1.5297e-01,  3.4153e-02,\n          7.6243e-02,  4.8168e-02,  6.8319e-02, -1.4734e-01,  2.6278e-03,\n          1.0286e-01,  3.4329e-02,  1.5499e-02, -1.5693e-01,  6.1171e-02,\n         -2.1677e-02, -9.0371e-02],\n        [-1.6022e-01, -6.6725e-02, -5.4837e-02,  8.2338e-02, -9.9409e-02,\n          1.6052e-01, -1.5107e-01,  1.5431e-01,  7.5230e-02, -3.5361e-02,\n         -8.8437e-02,  9.8067e-02,  6.6288e-02, -1.5070e-01,  1.1809e-01,\n          3.7856e-02,  7.2906e-02, -1.2095e-01, -1.0290e-01, -6.6853e-02,\n          7.6520e-02, -5.1632e-02, -1.3030e-01, -1.7038e-01, -1.5386e-01,\n          8.4117e-02,  9.9208e-02,  1.1662e-01, -1.0781e-01,  1.5074e-02,\n          1.5441e-01, -2.6721e-02],\n        [-7.1668e-02, -1.1266e-02, -5.4150e-02,  7.8734e-02,  3.6046e-03,\n         -1.1118e-01, -8.2746e-02,  5.9093e-02,  1.1599e-01, -9.9405e-02,\n         -2.5091e-02,  4.0083e-02, -2.7952e-02,  1.6103e-01, -2.2997e-03,\n         -1.6219e-01,  1.7501e-01, -7.1699e-02,  6.5364e-02, -6.7514e-02,\n          8.0365e-03,  1.6957e-01,  1.0975e-01, -1.6999e-01,  3.0633e-02,\n         -6.3151e-02, -1.4640e-02,  8.9542e-02,  4.0980e-02,  4.9792e-02,\n         -1.3617e-01,  9.0300e-02],\n        [-1.9857e-02,  1.4713e-01, -8.9882e-02, -1.4895e-01,  1.2253e-01,\n         -1.6149e-01,  2.8299e-03,  1.6886e-02, -4.7238e-02,  1.0702e-01,\n          1.2147e-01, -3.2426e-02,  1.2107e-01, -1.3330e-01,  2.2796e-02,\n          1.5258e-01,  1.3684e-02,  1.4532e-01,  1.1976e-01,  1.4294e-01,\n         -1.4201e-01, -1.7059e-01,  9.5245e-02, -1.6288e-01, -6.8982e-02,\n          1.1311e-01, -3.3578e-03, -6.7187e-02,  1.1275e-01,  1.7189e-01,\n          1.3277e-01,  5.6648e-02],\n        [ 1.2189e-01,  1.3893e-01, -5.7147e-02,  6.8937e-02,  2.6096e-02,\n         -5.8312e-02, -1.7585e-01,  6.7770e-02,  9.8878e-02,  3.5758e-02,\n          1.5892e-01, -1.1925e-01,  1.3966e-01,  8.3631e-02,  2.7912e-02,\n         -1.4032e-01,  3.9932e-02, -9.0168e-02, -5.9018e-02,  1.9240e-02,\n          1.4016e-01,  1.7454e-01,  4.9798e-02,  1.1950e-01,  8.8551e-03,\n         -1.5245e-01,  3.6847e-02,  1.7224e-01,  7.0024e-02,  3.5789e-02,\n         -1.6415e-01, -1.1409e-01],\n        [ 9.4750e-02,  1.0335e-01,  1.3350e-01,  1.4590e-01, -1.4597e-02,\n         -9.8814e-02,  1.3106e-01,  3.6248e-02, -1.2270e-01,  1.1976e-01,\n          1.1400e-01, -1.2065e-01, -3.1542e-02,  1.1912e-01, -1.1820e-01,\n         -1.0406e-01,  1.6054e-01,  1.7125e-01,  5.0293e-02, -1.0399e-02,\n          5.5885e-02,  8.8015e-02, -1.5086e-01, -1.2954e-01,  1.0977e-01,\n          6.6809e-02, -1.7207e-01, -7.2190e-02,  1.4483e-01,  8.5300e-02,\n         -1.1603e-01, -3.5736e-02],\n        [-1.1004e-01, -4.5027e-02, -6.1653e-02, -1.3067e-01, -4.3036e-02,\n          8.3607e-02, -1.5857e-01,  1.5140e-02,  7.1226e-02,  1.7458e-01,\n         -1.3342e-01, -1.0397e-01,  1.2201e-01,  1.7700e-02,  7.7537e-02,\n          1.4827e-01, -4.5244e-02, -1.1297e-01,  1.3878e-01,  5.3630e-03,\n          7.2979e-02, -4.9714e-02, -9.0792e-02, -1.7840e-02,  1.3664e-01,\n          8.4666e-02,  8.2444e-02,  5.7815e-02, -1.7280e-01, -1.5742e-01,\n          1.1179e-01,  2.1070e-03],\n        [-2.6719e-02, -2.5918e-02, -6.8717e-02,  1.5763e-01, -1.4215e-01,\n          1.5437e-01, -9.6211e-02, -1.5411e-01, -7.9683e-02, -5.4235e-02,\n          1.5111e-02,  6.2592e-02, -7.6948e-02, -6.4307e-02,  8.1149e-02,\n         -1.0554e-01, -9.5432e-02,  9.5679e-02,  1.3942e-01, -6.2265e-02,\n         -1.2532e-01,  1.3772e-02,  1.6857e-01, -6.4792e-02, -3.6057e-02,\n          1.5683e-01, -1.3411e-01,  8.3967e-02, -1.6972e-01,  7.0117e-02,\n         -5.9580e-02, -1.3582e-01],\n        [-6.8379e-02,  3.3565e-02, -1.0074e-01, -1.3280e-01,  1.2261e-04,\n         -1.5441e-02, -1.2654e-01,  1.4448e-01,  1.1268e-01,  2.0627e-02,\n          1.3760e-01,  1.5549e-01, -1.5988e-01,  6.6964e-02,  7.6685e-02,\n          1.7368e-01,  1.3315e-01,  8.8769e-02,  2.6607e-02,  3.3400e-02,\n          8.4983e-02, -3.8033e-02, -8.5476e-02,  7.1844e-02,  9.4793e-02,\n         -1.6136e-02,  6.7599e-02,  1.4994e-01, -4.8267e-02, -2.3464e-02,\n         -9.0399e-02,  3.6646e-02],\n        [ 1.7266e-01, -1.4401e-01, -1.0534e-01,  1.5791e-01, -1.5355e-01,\n         -1.6196e-01, -3.9789e-02, -1.1472e-01,  7.0589e-03, -1.0696e-01,\n          7.8910e-02,  2.0282e-02, -8.8391e-02, -1.5918e-01,  9.1965e-02,\n          9.5245e-02,  1.6779e-01, -1.4672e-01,  5.7956e-02, -8.4207e-02,\n          8.0357e-03, -9.4443e-02,  1.7299e-01,  1.5700e-01,  9.7525e-02,\n         -1.7363e-01,  4.3182e-02, -1.7373e-01, -9.8937e-02,  2.6393e-02,\n         -1.0766e-01,  3.8426e-02],\n        [ 1.4013e-01, -4.8774e-02,  1.5742e-01, -1.3454e-01,  6.6324e-03,\n          4.8170e-02,  1.0247e-03, -7.1190e-02, -1.5332e-01, -1.4205e-01,\n         -6.2458e-02,  4.4681e-02,  2.8464e-02,  9.4567e-02,  1.4702e-01,\n         -2.1483e-02,  1.1759e-01,  9.6027e-02,  5.7121e-02, -1.0303e-01,\n          2.9381e-03, -7.0145e-02,  9.9217e-02, -6.4032e-02, -7.0115e-02,\n          4.5299e-02, -1.2930e-01,  7.9169e-02, -1.2992e-01, -4.6909e-02,\n         -1.1181e-01,  1.6886e-01],\n        [-1.4439e-01,  1.4404e-01, -9.1473e-02, -1.2750e-01, -6.9330e-02,\n          9.3158e-02, -1.2722e-01, -9.8276e-04, -1.3400e-01,  1.6769e-02,\n         -9.6564e-02, -1.4394e-01,  1.1259e-01, -4.2486e-02, -1.5492e-01,\n         -1.7480e-01,  1.4838e-01, -3.7816e-02,  5.1395e-02,  1.2670e-01,\n          1.1909e-01, -3.1955e-02,  5.7121e-02,  5.2487e-02, -1.6646e-01,\n         -1.5227e-01,  6.3039e-02, -7.5691e-02, -1.3825e-01,  3.2021e-02,\n          1.2124e-01, -1.1827e-01],\n        [-9.7864e-02,  1.5720e-01,  4.6972e-02,  9.1471e-02, -1.2945e-01,\n          1.1825e-01, -5.7751e-02,  1.3214e-01,  5.4804e-02,  1.3112e-01,\n          1.3887e-01,  1.2864e-01, -1.5008e-01, -1.6364e-01, -1.2862e-01,\n         -1.6102e-01,  4.0341e-02, -5.1678e-02, -1.1133e-03, -4.1050e-02,\n         -5.0538e-02,  4.2969e-02,  2.7160e-02, -2.4345e-02, -2.9593e-02,\n          1.3671e-01, -1.6754e-01, -1.0966e-01,  5.3787e-02,  7.9306e-02,\n         -1.1815e-01,  1.3830e-02],\n        [-1.0806e-01, -5.5920e-02, -4.2381e-02, -3.1582e-02,  7.7456e-03,\n          6.0071e-02,  6.6893e-04, -1.1383e-01,  1.3275e-01,  9.2892e-02,\n          1.0833e-01, -1.0931e-01, -5.7453e-02, -5.3555e-02,  1.4612e-01,\n          1.6564e-01, -1.2334e-02, -1.7057e-01,  1.7927e-02, -1.5196e-01,\n          1.7002e-01,  6.8674e-02, -1.2029e-01,  8.1689e-02, -1.4428e-01,\n          1.6003e-01, -1.6356e-01,  1.1336e-01,  9.5601e-02,  7.1967e-02,\n         -7.1182e-03, -1.2615e-01],\n        [-1.1075e-01,  1.7288e-01, -8.3099e-02, -1.3852e-01,  2.2932e-02,\n          3.3949e-02, -1.4511e-01,  1.5479e-01, -3.3876e-02, -1.6111e-01,\n          1.0910e-01,  1.4799e-02,  1.3363e-01,  1.1179e-01,  8.8068e-02,\n         -1.0902e-01,  5.9539e-02, -7.3715e-02, -7.7824e-02,  1.1355e-01,\n         -9.2091e-02, -2.6886e-02,  5.9804e-02, -1.7416e-01, -7.0140e-02,\n         -1.8754e-02, -7.5672e-02, -8.3609e-02, -3.3375e-02, -7.2439e-02,\n         -8.9459e-02, -9.9231e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2249, -0.2182,  0.0985,  0.0269, -0.0045, -0.1760, -0.0281,  0.2189],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1549, -0.2286, -0.1291,  0.0932, -0.1576, -0.0630,  0.0441,  0.1341,\n         -0.0462,  0.0655, -0.1829, -0.1850, -0.0025, -0.1102, -0.0483, -0.0938],\n        [ 0.1994,  0.1450,  0.0409, -0.0904, -0.1077,  0.0702, -0.2091,  0.1182,\n         -0.1458, -0.1756,  0.1543, -0.1355,  0.1250, -0.2029, -0.1284, -0.2195],\n        [-0.0255, -0.0854,  0.1965,  0.1376,  0.2371,  0.2246,  0.1271, -0.2329,\n         -0.0990, -0.1430,  0.0681,  0.0417,  0.0540,  0.0784,  0.0547,  0.0637],\n        [-0.1260, -0.0932,  0.0277, -0.0277,  0.1820, -0.1182,  0.2453,  0.0744,\n          0.0602, -0.1976,  0.2109, -0.2038,  0.2281,  0.0186, -0.1375, -0.0714],\n        [-0.0317, -0.0892,  0.0708,  0.2191, -0.2117, -0.1679,  0.0779,  0.1338,\n         -0.0333,  0.0326,  0.1352, -0.0654, -0.0006,  0.1648, -0.0064,  0.1827],\n        [ 0.2055, -0.1553,  0.1829,  0.1780,  0.0980, -0.0335, -0.1030, -0.0751,\n          0.0377, -0.0269, -0.0185,  0.0979,  0.0429,  0.0946, -0.0522, -0.2042],\n        [-0.2381,  0.1318, -0.2263, -0.1202,  0.0417,  0.0541,  0.2014, -0.2269,\n          0.1065,  0.1461,  0.1872, -0.1702,  0.1243, -0.1007,  0.0927, -0.1205],\n        [-0.0653,  0.0254, -0.1997,  0.2339, -0.1060, -0.0655, -0.0081,  0.0361,\n          0.0107, -0.0718,  0.1851, -0.1948, -0.0227,  0.1198,  0.0465, -0.0424]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0169, -0.2908, -0.2661, -0.0302], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0239, -0.3095, -0.1571,  0.0687, -0.0821,  0.3431,  0.0032,  0.0074],\n        [-0.2269,  0.1785,  0.2915, -0.2835, -0.1802, -0.2371,  0.1511,  0.2114],\n        [-0.3090, -0.0342,  0.1097, -0.2316, -0.3105,  0.0595,  0.1987,  0.1212],\n        [ 0.1799,  0.2540,  0.1198, -0.1677,  0.1559, -0.0538,  0.0041, -0.1497]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7bd3273f5110>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s362660000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s362660000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}