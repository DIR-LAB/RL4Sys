{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s366480000"
    },
    "q_lr":	0.0005,
    "seed":	366480000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x0000021EA7BC9090>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2188,  0.1573,  0.2264, -0.1373,  0.1066,  0.0145, -0.2204, -0.1910,\n         0.0630,  0.3118,  0.2026,  0.0495,  0.2108,  0.1828,  0.1445,  0.1581,\n        -0.3194, -0.0537,  0.0719, -0.0635, -0.2634, -0.1257, -0.2443, -0.0263,\n        -0.2567, -0.2437,  0.3440, -0.1609, -0.2137, -0.1142,  0.2722, -0.3386],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0724, -0.1320,  0.1059, -0.1224,  0.2080, -0.3140, -0.3509,  0.1808],\n        [-0.2175,  0.2055, -0.3522,  0.1490, -0.0866, -0.2358, -0.1357, -0.1102],\n        [-0.1580,  0.2663,  0.2620, -0.3442, -0.1889, -0.3160, -0.0760,  0.1031],\n        [-0.0258,  0.1153, -0.3225,  0.3170, -0.2889,  0.0980, -0.3489, -0.1899],\n        [-0.2425, -0.0382,  0.2391,  0.2630,  0.0453,  0.2407, -0.3348,  0.0938],\n        [-0.1196, -0.0555, -0.3277, -0.2509,  0.0483, -0.0070, -0.0933,  0.0513],\n        [-0.0790,  0.2065,  0.2410, -0.1593,  0.0706, -0.2470,  0.0239,  0.0426],\n        [-0.0057,  0.2745, -0.2103,  0.2335, -0.1882, -0.2436, -0.0418,  0.3283],\n        [-0.0862,  0.1608, -0.1059, -0.0356, -0.2873, -0.0222, -0.2051, -0.0038],\n        [ 0.1701, -0.2522,  0.1637,  0.1046,  0.2632,  0.0111,  0.0200, -0.1258],\n        [ 0.2590,  0.1783,  0.1377, -0.1986,  0.2780,  0.0789,  0.3345, -0.1259],\n        [-0.1349, -0.0684,  0.2376,  0.1031, -0.2450, -0.2092, -0.3260, -0.2731],\n        [-0.2359, -0.2943,  0.3279,  0.1864, -0.2941,  0.1256, -0.0185,  0.0964],\n        [-0.3455,  0.3195,  0.2631, -0.3319, -0.1557, -0.2486,  0.1018,  0.3505],\n        [-0.0483, -0.1268,  0.1978, -0.1522, -0.0281, -0.2674,  0.2382,  0.3081],\n        [-0.2504, -0.3469,  0.0105, -0.0705, -0.3447, -0.0076, -0.1055,  0.3478],\n        [ 0.0421, -0.2546, -0.0556, -0.0211,  0.0146, -0.1252, -0.1494, -0.1335],\n        [ 0.0336, -0.1968, -0.3055, -0.2396, -0.0731, -0.0303,  0.0684,  0.3168],\n        [-0.1481, -0.2424,  0.3421,  0.1309, -0.0921,  0.3503, -0.2111, -0.2154],\n        [ 0.0196, -0.2238, -0.2916,  0.3407, -0.0804,  0.1499,  0.2483, -0.2919],\n        [ 0.2681,  0.2400,  0.1679, -0.2943,  0.2428,  0.2547,  0.2847, -0.1044],\n        [ 0.0367, -0.1384, -0.1082, -0.0596, -0.0143,  0.1945, -0.3431,  0.2178],\n        [ 0.3371,  0.0810, -0.0956, -0.2925, -0.2717,  0.2888, -0.1102, -0.2942],\n        [-0.2472,  0.3428, -0.1779, -0.0243,  0.1866,  0.2593,  0.0629, -0.0542],\n        [ 0.2114,  0.1331, -0.0440,  0.3490,  0.0039,  0.3288,  0.0243, -0.0081],\n        [-0.2967, -0.2151,  0.3442,  0.3167,  0.1757,  0.2043,  0.1583,  0.1475],\n        [ 0.2737,  0.1718, -0.0020, -0.2959, -0.2085,  0.1280, -0.1077,  0.1960],\n        [ 0.2717,  0.2769,  0.0235,  0.3248, -0.2305,  0.0656, -0.0004, -0.1592],\n        [-0.0728,  0.1008, -0.0442, -0.0765,  0.2981,  0.2558, -0.1751,  0.3138],\n        [ 0.1061,  0.1150, -0.1232, -0.0985,  0.2282, -0.0030,  0.1729, -0.2687],\n        [-0.0124, -0.3364, -0.1429,  0.2974,  0.3510, -0.0190, -0.0838,  0.0385],\n        [ 0.1129, -0.1326,  0.2818, -0.1436,  0.1930,  0.0981, -0.2338, -0.0569]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1490,  0.0621, -0.0667, -0.1318,  0.1588, -0.1657,  0.1589,  0.0222,\n        -0.0653, -0.0492, -0.1476, -0.0168,  0.0894,  0.0656,  0.0533,  0.0244],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.6782e-02,  5.9283e-02,  1.6402e-01, -1.2807e-01,  1.0106e-01,\n          1.1355e-01, -1.3511e-01,  6.1698e-02,  3.4478e-03,  7.9249e-02,\n         -5.2765e-02, -3.5830e-02, -2.5168e-02,  4.5006e-02,  1.5492e-01,\n          2.7109e-02,  1.1726e-01,  5.7364e-02,  2.4896e-03, -4.6792e-02,\n          3.0614e-02, -3.1188e-02, -1.5705e-02, -1.5456e-02,  1.6804e-01,\n          1.1688e-02,  1.1222e-01, -1.0268e-01, -3.9206e-03, -1.2427e-02,\n          7.2900e-02,  8.9902e-02],\n        [ 1.3646e-01, -1.6657e-01,  1.6795e-02,  5.3621e-02, -7.2319e-03,\n          1.4181e-03, -7.7274e-02,  5.2535e-03, -1.6939e-02,  1.3364e-01,\n          1.6826e-02,  4.0989e-02, -7.5696e-02, -3.3145e-02, -1.6666e-01,\n          6.6202e-02, -8.8931e-02,  5.6996e-02,  8.8019e-02,  1.6465e-01,\n          1.0573e-01, -1.1348e-01,  2.2718e-03,  2.7811e-02, -6.8956e-02,\n         -1.1516e-01, -4.9223e-02, -6.4957e-02, -1.5647e-01,  1.2042e-01,\n         -1.6905e-02, -6.5150e-02],\n        [-2.4127e-02,  1.1587e-01, -1.0537e-01,  1.0709e-01,  2.6791e-02,\n          2.7368e-02,  7.7946e-02, -5.2856e-02,  6.9147e-02, -1.0350e-02,\n          9.5884e-02,  2.1852e-02, -1.2009e-01,  1.5301e-01, -1.0946e-01,\n          1.5071e-01,  7.5285e-02, -1.6661e-02, -7.0411e-02, -1.3065e-01,\n          1.5281e-01,  1.0333e-01,  1.7467e-01, -1.0502e-01, -1.5245e-01,\n          7.1511e-02, -1.9815e-02,  3.4736e-02,  9.1876e-02, -1.0620e-01,\n         -6.9244e-02, -1.3781e-01],\n        [ 1.0529e-01,  1.4197e-01, -2.8531e-02, -1.3140e-01,  4.8732e-02,\n         -3.2495e-02, -1.4552e-01, -1.1216e-01,  1.7330e-01, -1.7666e-01,\n         -1.0141e-01, -1.2453e-01, -5.7683e-02, -4.6835e-02,  1.6986e-04,\n          2.7646e-04, -1.6503e-01,  1.0515e-01,  1.6587e-01,  9.0205e-02,\n          4.9972e-02, -2.0900e-03, -2.7159e-02, -1.1272e-01,  9.9188e-04,\n         -1.5809e-02,  1.7034e-01,  1.4386e-01, -1.3941e-01,  4.6235e-02,\n         -2.9866e-02,  3.1372e-02],\n        [ 1.5534e-01, -1.6542e-01, -6.1830e-02, -1.2739e-01, -5.3346e-02,\n         -1.6447e-01,  6.2500e-02,  1.3694e-01,  1.4987e-01, -1.1679e-02,\n         -2.4348e-03,  7.5008e-02,  5.6852e-02, -1.5634e-01,  1.0945e-01,\n         -1.2477e-01, -1.4159e-02,  6.4399e-02,  1.5694e-01,  9.3001e-02,\n         -1.4781e-01,  9.1047e-03,  9.7180e-02, -4.4005e-02,  5.6861e-03,\n         -9.4687e-02, -7.7641e-03,  1.2803e-01, -6.3146e-02,  3.0129e-02,\n         -6.1650e-02,  1.6930e-01],\n        [ 1.3354e-01,  2.4232e-02, -7.6565e-02, -2.7961e-02, -1.1300e-01,\n          8.0416e-02,  1.0113e-01, -3.8271e-02, -1.3245e-01, -1.0684e-01,\n         -5.5258e-02,  5.1058e-02, -7.5921e-02, -2.6292e-02,  8.1968e-02,\n         -9.2128e-02, -1.3208e-01, -2.3326e-02, -1.3955e-01,  1.7233e-01,\n         -5.6098e-02,  1.4569e-01,  2.0569e-02, -1.2652e-01,  9.5952e-02,\n         -8.4152e-02, -3.3153e-02,  9.0674e-02, -1.5602e-01, -3.9468e-02,\n          8.1220e-02,  1.2083e-01],\n        [-1.3001e-01, -3.8453e-02,  5.7277e-02, -8.7948e-02,  4.2578e-02,\n          8.8408e-02,  1.6396e-01, -9.4691e-02, -1.0144e-01,  1.3102e-01,\n         -1.2567e-01, -1.6268e-02,  2.0223e-02,  6.6972e-02,  1.3624e-01,\n          1.5641e-01, -3.7561e-02,  1.2167e-01, -1.6004e-01, -1.0377e-01,\n          2.6819e-02, -5.2610e-02, -9.6860e-02,  4.5447e-02,  6.2367e-02,\n          1.1497e-01,  1.8052e-02, -7.8913e-02, -7.7580e-02,  1.0432e-01,\n         -5.5315e-02,  2.1318e-02],\n        [-5.9412e-02, -5.7861e-02,  1.4119e-01,  6.2960e-02, -6.5032e-02,\n         -3.8503e-03,  1.4234e-01, -4.7205e-02, -1.5910e-01,  9.3833e-02,\n         -5.4757e-02, -1.1967e-01,  9.4361e-02, -1.7232e-01, -9.7761e-02,\n          1.3831e-01, -1.7430e-01, -9.0377e-02,  8.9656e-02, -1.7672e-02,\n          2.3489e-02,  1.3980e-02, -1.3899e-01,  3.1515e-02, -8.8756e-02,\n         -1.0690e-01, -2.1770e-02,  7.2806e-02,  1.5127e-02, -2.4571e-02,\n          6.1870e-02,  1.5916e-01],\n        [-1.3874e-01,  1.1373e-01,  7.2592e-02, -9.1358e-02,  1.3985e-01,\n         -1.7156e-01,  7.3487e-02,  1.6404e-01,  7.2526e-02,  6.7886e-02,\n         -1.3358e-01, -1.5198e-01, -1.5480e-01,  1.4883e-01, -4.4318e-02,\n         -6.0450e-02, -6.0525e-02, -2.2401e-02,  5.2474e-02,  2.0931e-02,\n          4.9646e-02,  1.5179e-01, -1.5123e-01, -3.6560e-03, -7.1179e-02,\n         -1.5910e-02, -9.7565e-02,  6.7992e-02, -1.4197e-01,  4.7862e-02,\n          8.8300e-02, -6.9370e-02],\n        [-1.1046e-01,  1.6016e-01,  1.1246e-01, -1.4886e-01, -5.9556e-02,\n         -1.4389e-01, -1.5492e-01, -1.6439e-01, -1.8158e-02, -1.6440e-01,\n          1.0805e-01,  9.0441e-02,  1.4005e-01,  2.5562e-02, -7.4858e-02,\n         -4.8578e-03, -8.7454e-02, -2.2583e-02, -2.7162e-02,  9.3961e-02,\n          7.3912e-03,  6.4697e-02,  1.2613e-01,  1.5512e-01,  1.0446e-01,\n         -5.3600e-02, -1.5045e-01, -1.1108e-02,  9.3915e-02,  3.2050e-02,\n         -3.3640e-02, -7.5272e-02],\n        [ 6.2394e-02,  7.9583e-02, -1.6338e-02, -1.5919e-01,  1.3598e-02,\n         -3.2795e-03, -1.4981e-01,  8.8481e-02,  5.3012e-02, -1.6552e-01,\n         -1.0760e-01, -1.1156e-01, -1.4371e-01,  9.6962e-02, -9.0799e-02,\n          1.5095e-01, -1.4584e-02, -7.4873e-02,  1.1270e-01, -1.2543e-01,\n         -8.1097e-02,  2.5494e-02,  1.4594e-01,  7.1011e-02,  2.3139e-02,\n          7.1672e-02,  1.1790e-01,  1.3498e-01, -4.3157e-02,  1.3055e-01,\n         -1.4723e-01,  7.3758e-02],\n        [-1.0559e-01,  8.1519e-02, -3.9569e-02, -1.6344e-01, -1.2296e-01,\n          2.6888e-02,  7.2529e-02,  1.6895e-01,  1.2207e-03,  1.1953e-01,\n          1.1046e-01,  1.7407e-01, -4.2673e-02,  2.2122e-02,  6.5892e-02,\n         -8.7044e-02,  1.7374e-01,  1.5658e-01,  8.7581e-02,  1.4258e-01,\n          1.5143e-01,  1.2933e-01, -1.3374e-01, -1.2702e-01,  4.9455e-02,\n         -7.4217e-02,  1.6015e-01,  1.1127e-01, -1.3840e-01,  1.4867e-01,\n          1.0469e-01,  6.9449e-02],\n        [-2.8272e-02,  1.5570e-01,  1.0650e-01,  1.2594e-01,  1.5003e-02,\n          4.6639e-02, -1.3748e-01, -1.6924e-01,  1.3980e-01,  1.2370e-02,\n         -9.3015e-02,  1.0162e-01, -8.7691e-02, -6.2085e-02,  1.1759e-01,\n         -5.2907e-03, -1.0954e-01,  1.0637e-01,  1.3322e-01,  8.2401e-02,\n          1.4298e-01, -8.8236e-02,  1.1755e-01, -5.0295e-02,  1.6893e-01,\n         -1.3782e-01, -3.8014e-02, -1.3192e-01, -7.0189e-02,  9.3992e-02,\n         -1.2285e-01,  6.8110e-03],\n        [ 1.4319e-01,  8.0204e-02,  9.8135e-02,  1.1672e-02, -1.0009e-01,\n         -1.4924e-01, -7.9041e-03,  7.9517e-02,  1.0667e-02,  1.3484e-01,\n          3.1803e-02,  1.0403e-01,  1.4207e-01,  4.7897e-02, -1.7356e-01,\n         -4.3004e-02,  7.6353e-02,  2.5710e-02, -1.9137e-02,  4.2311e-02,\n          1.5649e-02,  1.1711e-01,  1.1907e-01,  5.2904e-02,  1.6052e-01,\n          6.1416e-02, -5.1914e-02,  2.7720e-02, -1.5529e-01, -1.1168e-01,\n          1.6274e-01, -8.5354e-02],\n        [ 5.1806e-02,  2.8482e-02, -1.2420e-01, -6.4904e-02,  3.0178e-02,\n         -3.5235e-02, -1.4786e-02,  1.0859e-01, -1.4125e-01,  1.0744e-01,\n          1.1928e-01, -1.4149e-01,  2.6296e-02, -1.6206e-01, -6.2727e-02,\n          7.4096e-03,  1.6094e-01, -9.2410e-02,  5.8083e-02,  4.1749e-02,\n         -1.5384e-01, -1.1574e-01,  1.2895e-01, -3.8857e-02, -1.1557e-01,\n         -1.0743e-01, -1.4274e-02,  1.5370e-01,  5.0599e-02, -1.5012e-01,\n         -1.6006e-01, -4.3644e-02],\n        [ 9.3572e-02,  3.4968e-02, -1.3601e-01, -1.2417e-01,  5.7058e-02,\n         -8.2138e-03,  1.0200e-01, -1.2011e-02,  1.0045e-01, -1.6294e-01,\n          7.0064e-02, -1.4222e-01, -4.2326e-02,  1.3599e-01,  9.5586e-02,\n          8.2818e-02, -9.5343e-02,  1.0789e-02,  1.3813e-01,  1.2638e-01,\n         -1.2170e-01,  4.6389e-02,  1.0572e-02,  1.3881e-01, -3.7708e-02,\n          1.2039e-01,  8.0420e-02,  1.0941e-01, -5.6468e-02,  9.1223e-02,\n         -1.6607e-01, -1.5322e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1616,  0.0359, -0.0011, -0.0137,  0.2090, -0.1897, -0.1322,  0.0784],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1843,  0.0186,  0.1086, -0.1958, -0.0684, -0.0133,  0.0164, -0.1033,\n         -0.0534, -0.1761,  0.2274, -0.0566,  0.2233,  0.1498, -0.1959,  0.1729],\n        [-0.1666, -0.0802,  0.1460, -0.1712,  0.1530, -0.2386,  0.1127, -0.1471,\n         -0.0891,  0.0255,  0.0627,  0.2091,  0.1400,  0.0798, -0.2080, -0.2102],\n        [ 0.0151, -0.1675, -0.1799,  0.2214, -0.0508,  0.2287, -0.0758,  0.0715,\n          0.0713, -0.0254,  0.1817, -0.1761, -0.1944,  0.1092,  0.0652,  0.1903],\n        [ 0.0261,  0.0721, -0.1776,  0.0739, -0.1953,  0.2453,  0.0154, -0.1917,\n         -0.1570, -0.1303, -0.0138,  0.1317, -0.0409, -0.1509,  0.0241,  0.2262],\n        [-0.2329,  0.1279, -0.2090,  0.2326, -0.2368,  0.0734, -0.0403, -0.1830,\n          0.1853, -0.0592,  0.0409,  0.1650,  0.0562, -0.1824,  0.2285,  0.0763],\n        [-0.2284,  0.1259, -0.2007,  0.1359,  0.0967, -0.0429, -0.1847, -0.2094,\n          0.1314, -0.1360, -0.1549, -0.2183,  0.0466, -0.1040,  0.0591,  0.1082],\n        [ 0.2184, -0.2435, -0.2079, -0.1340, -0.1002,  0.1175, -0.2114, -0.0323,\n         -0.2381, -0.1360, -0.2192, -0.0851, -0.0794, -0.1466, -0.0536, -0.0499],\n        [-0.0385, -0.0255, -0.1578,  0.1643,  0.0430, -0.2315,  0.1299, -0.0762,\n         -0.1266,  0.2065,  0.2477,  0.0070,  0.0815, -0.2327,  0.1664, -0.0375]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0040], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0994,  0.2291,  0.0384,  0.2012,  0.0886,  0.2736,  0.1131, -0.2949]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0724, -0.1320,  0.1059, -0.1224,  0.2080, -0.3140, -0.3509,  0.1808],\n        [-0.2175,  0.2055, -0.3522,  0.1490, -0.0866, -0.2358, -0.1357, -0.1102],\n        [-0.1580,  0.2663,  0.2620, -0.3442, -0.1889, -0.3160, -0.0760,  0.1031],\n        [-0.0258,  0.1153, -0.3225,  0.3170, -0.2889,  0.0980, -0.3489, -0.1899],\n        [-0.2425, -0.0382,  0.2391,  0.2630,  0.0453,  0.2407, -0.3348,  0.0938],\n        [-0.1196, -0.0555, -0.3277, -0.2509,  0.0483, -0.0070, -0.0933,  0.0513],\n        [-0.0790,  0.2065,  0.2410, -0.1593,  0.0706, -0.2470,  0.0239,  0.0426],\n        [-0.0057,  0.2745, -0.2103,  0.2335, -0.1882, -0.2436, -0.0418,  0.3283],\n        [-0.0862,  0.1608, -0.1059, -0.0356, -0.2873, -0.0222, -0.2051, -0.0038],\n        [ 0.1701, -0.2522,  0.1637,  0.1046,  0.2632,  0.0111,  0.0200, -0.1258],\n        [ 0.2590,  0.1783,  0.1377, -0.1986,  0.2780,  0.0789,  0.3345, -0.1259],\n        [-0.1349, -0.0684,  0.2376,  0.1031, -0.2450, -0.2092, -0.3260, -0.2731],\n        [-0.2359, -0.2943,  0.3279,  0.1864, -0.2941,  0.1256, -0.0185,  0.0964],\n        [-0.3455,  0.3195,  0.2631, -0.3319, -0.1557, -0.2486,  0.1018,  0.3505],\n        [-0.0483, -0.1268,  0.1978, -0.1522, -0.0281, -0.2674,  0.2382,  0.3081],\n        [-0.2504, -0.3469,  0.0105, -0.0705, -0.3447, -0.0076, -0.1055,  0.3478],\n        [ 0.0421, -0.2546, -0.0556, -0.0211,  0.0146, -0.1252, -0.1494, -0.1335],\n        [ 0.0336, -0.1968, -0.3055, -0.2396, -0.0731, -0.0303,  0.0684,  0.3168],\n        [-0.1481, -0.2424,  0.3421,  0.1309, -0.0921,  0.3503, -0.2111, -0.2154],\n        [ 0.0196, -0.2238, -0.2916,  0.3407, -0.0804,  0.1499,  0.2483, -0.2919],\n        [ 0.2681,  0.2400,  0.1679, -0.2943,  0.2428,  0.2547,  0.2847, -0.1044],\n        [ 0.0367, -0.1384, -0.1082, -0.0596, -0.0143,  0.1945, -0.3431,  0.2178],\n        [ 0.3371,  0.0810, -0.0956, -0.2925, -0.2717,  0.2888, -0.1102, -0.2942],\n        [-0.2472,  0.3428, -0.1779, -0.0243,  0.1866,  0.2593,  0.0629, -0.0542],\n        [ 0.2114,  0.1331, -0.0440,  0.3490,  0.0039,  0.3288,  0.0243, -0.0081],\n        [-0.2967, -0.2151,  0.3442,  0.3167,  0.1757,  0.2043,  0.1583,  0.1475],\n        [ 0.2737,  0.1718, -0.0020, -0.2959, -0.2085,  0.1280, -0.1077,  0.1960],\n        [ 0.2717,  0.2769,  0.0235,  0.3248, -0.2305,  0.0656, -0.0004, -0.1592],\n        [-0.0728,  0.1008, -0.0442, -0.0765,  0.2981,  0.2558, -0.1751,  0.3138],\n        [ 0.1061,  0.1150, -0.1232, -0.0985,  0.2282, -0.0030,  0.1729, -0.2687],\n        [-0.0124, -0.3364, -0.1429,  0.2974,  0.3510, -0.0190, -0.0838,  0.0385],\n        [ 0.1129, -0.1326,  0.2818, -0.1436,  0.1930,  0.0981, -0.2338, -0.0569]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2188,  0.1573,  0.2264, -0.1373,  0.1066,  0.0145, -0.2204, -0.1910,\n         0.0630,  0.3118,  0.2026,  0.0495,  0.2108,  0.1828,  0.1445,  0.1581,\n        -0.3194, -0.0537,  0.0719, -0.0635, -0.2634, -0.1257, -0.2443, -0.0263,\n        -0.2567, -0.2437,  0.3440, -0.1609, -0.2137, -0.1142,  0.2722, -0.3386],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-3.6782e-02,  5.9283e-02,  1.6402e-01, -1.2807e-01,  1.0106e-01,\n          1.1355e-01, -1.3511e-01,  6.1698e-02,  3.4478e-03,  7.9249e-02,\n         -5.2765e-02, -3.5830e-02, -2.5168e-02,  4.5006e-02,  1.5492e-01,\n          2.7109e-02,  1.1726e-01,  5.7364e-02,  2.4896e-03, -4.6792e-02,\n          3.0614e-02, -3.1188e-02, -1.5705e-02, -1.5456e-02,  1.6804e-01,\n          1.1688e-02,  1.1222e-01, -1.0268e-01, -3.9206e-03, -1.2427e-02,\n          7.2900e-02,  8.9902e-02],\n        [ 1.3646e-01, -1.6657e-01,  1.6795e-02,  5.3621e-02, -7.2319e-03,\n          1.4181e-03, -7.7274e-02,  5.2535e-03, -1.6939e-02,  1.3364e-01,\n          1.6826e-02,  4.0989e-02, -7.5696e-02, -3.3145e-02, -1.6666e-01,\n          6.6202e-02, -8.8931e-02,  5.6996e-02,  8.8019e-02,  1.6465e-01,\n          1.0573e-01, -1.1348e-01,  2.2718e-03,  2.7811e-02, -6.8956e-02,\n         -1.1516e-01, -4.9223e-02, -6.4957e-02, -1.5647e-01,  1.2042e-01,\n         -1.6905e-02, -6.5150e-02],\n        [-2.4127e-02,  1.1587e-01, -1.0537e-01,  1.0709e-01,  2.6791e-02,\n          2.7368e-02,  7.7946e-02, -5.2856e-02,  6.9147e-02, -1.0350e-02,\n          9.5884e-02,  2.1852e-02, -1.2009e-01,  1.5301e-01, -1.0946e-01,\n          1.5071e-01,  7.5285e-02, -1.6661e-02, -7.0411e-02, -1.3065e-01,\n          1.5281e-01,  1.0333e-01,  1.7467e-01, -1.0502e-01, -1.5245e-01,\n          7.1511e-02, -1.9815e-02,  3.4736e-02,  9.1876e-02, -1.0620e-01,\n         -6.9244e-02, -1.3781e-01],\n        [ 1.0529e-01,  1.4197e-01, -2.8531e-02, -1.3140e-01,  4.8732e-02,\n         -3.2495e-02, -1.4552e-01, -1.1216e-01,  1.7330e-01, -1.7666e-01,\n         -1.0141e-01, -1.2453e-01, -5.7683e-02, -4.6835e-02,  1.6986e-04,\n          2.7646e-04, -1.6503e-01,  1.0515e-01,  1.6587e-01,  9.0205e-02,\n          4.9972e-02, -2.0900e-03, -2.7159e-02, -1.1272e-01,  9.9188e-04,\n         -1.5809e-02,  1.7034e-01,  1.4386e-01, -1.3941e-01,  4.6235e-02,\n         -2.9866e-02,  3.1372e-02],\n        [ 1.5534e-01, -1.6542e-01, -6.1830e-02, -1.2739e-01, -5.3346e-02,\n         -1.6447e-01,  6.2500e-02,  1.3694e-01,  1.4987e-01, -1.1679e-02,\n         -2.4348e-03,  7.5008e-02,  5.6852e-02, -1.5634e-01,  1.0945e-01,\n         -1.2477e-01, -1.4159e-02,  6.4399e-02,  1.5694e-01,  9.3001e-02,\n         -1.4781e-01,  9.1047e-03,  9.7180e-02, -4.4005e-02,  5.6861e-03,\n         -9.4687e-02, -7.7641e-03,  1.2803e-01, -6.3146e-02,  3.0129e-02,\n         -6.1650e-02,  1.6930e-01],\n        [ 1.3354e-01,  2.4232e-02, -7.6565e-02, -2.7961e-02, -1.1300e-01,\n          8.0416e-02,  1.0113e-01, -3.8271e-02, -1.3245e-01, -1.0684e-01,\n         -5.5258e-02,  5.1058e-02, -7.5921e-02, -2.6292e-02,  8.1968e-02,\n         -9.2128e-02, -1.3208e-01, -2.3326e-02, -1.3955e-01,  1.7233e-01,\n         -5.6098e-02,  1.4569e-01,  2.0569e-02, -1.2652e-01,  9.5952e-02,\n         -8.4152e-02, -3.3153e-02,  9.0674e-02, -1.5602e-01, -3.9468e-02,\n          8.1220e-02,  1.2083e-01],\n        [-1.3001e-01, -3.8453e-02,  5.7277e-02, -8.7948e-02,  4.2578e-02,\n          8.8408e-02,  1.6396e-01, -9.4691e-02, -1.0144e-01,  1.3102e-01,\n         -1.2567e-01, -1.6268e-02,  2.0223e-02,  6.6972e-02,  1.3624e-01,\n          1.5641e-01, -3.7561e-02,  1.2167e-01, -1.6004e-01, -1.0377e-01,\n          2.6819e-02, -5.2610e-02, -9.6860e-02,  4.5447e-02,  6.2367e-02,\n          1.1497e-01,  1.8052e-02, -7.8913e-02, -7.7580e-02,  1.0432e-01,\n         -5.5315e-02,  2.1318e-02],\n        [-5.9412e-02, -5.7861e-02,  1.4119e-01,  6.2960e-02, -6.5032e-02,\n         -3.8503e-03,  1.4234e-01, -4.7205e-02, -1.5910e-01,  9.3833e-02,\n         -5.4757e-02, -1.1967e-01,  9.4361e-02, -1.7232e-01, -9.7761e-02,\n          1.3831e-01, -1.7430e-01, -9.0377e-02,  8.9656e-02, -1.7672e-02,\n          2.3489e-02,  1.3980e-02, -1.3899e-01,  3.1515e-02, -8.8756e-02,\n         -1.0690e-01, -2.1770e-02,  7.2806e-02,  1.5127e-02, -2.4571e-02,\n          6.1870e-02,  1.5916e-01],\n        [-1.3874e-01,  1.1373e-01,  7.2592e-02, -9.1358e-02,  1.3985e-01,\n         -1.7156e-01,  7.3487e-02,  1.6404e-01,  7.2526e-02,  6.7886e-02,\n         -1.3358e-01, -1.5198e-01, -1.5480e-01,  1.4883e-01, -4.4318e-02,\n         -6.0450e-02, -6.0525e-02, -2.2401e-02,  5.2474e-02,  2.0931e-02,\n          4.9646e-02,  1.5179e-01, -1.5123e-01, -3.6560e-03, -7.1179e-02,\n         -1.5910e-02, -9.7565e-02,  6.7992e-02, -1.4197e-01,  4.7862e-02,\n          8.8300e-02, -6.9370e-02],\n        [-1.1046e-01,  1.6016e-01,  1.1246e-01, -1.4886e-01, -5.9556e-02,\n         -1.4389e-01, -1.5492e-01, -1.6439e-01, -1.8158e-02, -1.6440e-01,\n          1.0805e-01,  9.0441e-02,  1.4005e-01,  2.5562e-02, -7.4858e-02,\n         -4.8578e-03, -8.7454e-02, -2.2583e-02, -2.7162e-02,  9.3961e-02,\n          7.3912e-03,  6.4697e-02,  1.2613e-01,  1.5512e-01,  1.0446e-01,\n         -5.3600e-02, -1.5045e-01, -1.1108e-02,  9.3915e-02,  3.2050e-02,\n         -3.3640e-02, -7.5272e-02],\n        [ 6.2394e-02,  7.9583e-02, -1.6338e-02, -1.5919e-01,  1.3598e-02,\n         -3.2795e-03, -1.4981e-01,  8.8481e-02,  5.3012e-02, -1.6552e-01,\n         -1.0760e-01, -1.1156e-01, -1.4371e-01,  9.6962e-02, -9.0799e-02,\n          1.5095e-01, -1.4584e-02, -7.4873e-02,  1.1270e-01, -1.2543e-01,\n         -8.1097e-02,  2.5494e-02,  1.4594e-01,  7.1011e-02,  2.3139e-02,\n          7.1672e-02,  1.1790e-01,  1.3498e-01, -4.3157e-02,  1.3055e-01,\n         -1.4723e-01,  7.3758e-02],\n        [-1.0559e-01,  8.1519e-02, -3.9569e-02, -1.6344e-01, -1.2296e-01,\n          2.6888e-02,  7.2529e-02,  1.6895e-01,  1.2207e-03,  1.1953e-01,\n          1.1046e-01,  1.7407e-01, -4.2673e-02,  2.2122e-02,  6.5892e-02,\n         -8.7044e-02,  1.7374e-01,  1.5658e-01,  8.7581e-02,  1.4258e-01,\n          1.5143e-01,  1.2933e-01, -1.3374e-01, -1.2702e-01,  4.9455e-02,\n         -7.4217e-02,  1.6015e-01,  1.1127e-01, -1.3840e-01,  1.4867e-01,\n          1.0469e-01,  6.9449e-02],\n        [-2.8272e-02,  1.5570e-01,  1.0650e-01,  1.2594e-01,  1.5003e-02,\n          4.6639e-02, -1.3748e-01, -1.6924e-01,  1.3980e-01,  1.2370e-02,\n         -9.3015e-02,  1.0162e-01, -8.7691e-02, -6.2085e-02,  1.1759e-01,\n         -5.2907e-03, -1.0954e-01,  1.0637e-01,  1.3322e-01,  8.2401e-02,\n          1.4298e-01, -8.8236e-02,  1.1755e-01, -5.0295e-02,  1.6893e-01,\n         -1.3782e-01, -3.8014e-02, -1.3192e-01, -7.0189e-02,  9.3992e-02,\n         -1.2285e-01,  6.8110e-03],\n        [ 1.4319e-01,  8.0204e-02,  9.8135e-02,  1.1672e-02, -1.0009e-01,\n         -1.4924e-01, -7.9041e-03,  7.9517e-02,  1.0667e-02,  1.3484e-01,\n          3.1803e-02,  1.0403e-01,  1.4207e-01,  4.7897e-02, -1.7356e-01,\n         -4.3004e-02,  7.6353e-02,  2.5710e-02, -1.9137e-02,  4.2311e-02,\n          1.5649e-02,  1.1711e-01,  1.1907e-01,  5.2904e-02,  1.6052e-01,\n          6.1416e-02, -5.1914e-02,  2.7720e-02, -1.5529e-01, -1.1168e-01,\n          1.6274e-01, -8.5354e-02],\n        [ 5.1806e-02,  2.8482e-02, -1.2420e-01, -6.4904e-02,  3.0178e-02,\n         -3.5235e-02, -1.4786e-02,  1.0859e-01, -1.4125e-01,  1.0744e-01,\n          1.1928e-01, -1.4149e-01,  2.6296e-02, -1.6206e-01, -6.2727e-02,\n          7.4096e-03,  1.6094e-01, -9.2410e-02,  5.8083e-02,  4.1749e-02,\n         -1.5384e-01, -1.1574e-01,  1.2895e-01, -3.8857e-02, -1.1557e-01,\n         -1.0743e-01, -1.4274e-02,  1.5370e-01,  5.0599e-02, -1.5012e-01,\n         -1.6006e-01, -4.3644e-02],\n        [ 9.3572e-02,  3.4968e-02, -1.3601e-01, -1.2417e-01,  5.7058e-02,\n         -8.2138e-03,  1.0200e-01, -1.2011e-02,  1.0045e-01, -1.6294e-01,\n          7.0064e-02, -1.4222e-01, -4.2326e-02,  1.3599e-01,  9.5586e-02,\n          8.2818e-02, -9.5343e-02,  1.0789e-02,  1.3813e-01,  1.2638e-01,\n         -1.2170e-01,  4.6389e-02,  1.0572e-02,  1.3881e-01, -3.7708e-02,\n          1.2039e-01,  8.0420e-02,  1.0941e-01, -5.6468e-02,  9.1223e-02,\n         -1.6607e-01, -1.5322e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1490,  0.0621, -0.0667, -0.1318,  0.1588, -0.1657,  0.1589,  0.0222,\n        -0.0653, -0.0492, -0.1476, -0.0168,  0.0894,  0.0656,  0.0533,  0.0244],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1843,  0.0186,  0.1086, -0.1958, -0.0684, -0.0133,  0.0164, -0.1033,\n         -0.0534, -0.1761,  0.2274, -0.0566,  0.2233,  0.1498, -0.1959,  0.1729],\n        [-0.1666, -0.0802,  0.1460, -0.1712,  0.1530, -0.2386,  0.1127, -0.1471,\n         -0.0891,  0.0255,  0.0627,  0.2091,  0.1400,  0.0798, -0.2080, -0.2102],\n        [ 0.0151, -0.1675, -0.1799,  0.2214, -0.0508,  0.2287, -0.0758,  0.0715,\n          0.0713, -0.0254,  0.1817, -0.1761, -0.1944,  0.1092,  0.0652,  0.1903],\n        [ 0.0261,  0.0721, -0.1776,  0.0739, -0.1953,  0.2453,  0.0154, -0.1917,\n         -0.1570, -0.1303, -0.0138,  0.1317, -0.0409, -0.1509,  0.0241,  0.2262],\n        [-0.2329,  0.1279, -0.2090,  0.2326, -0.2368,  0.0734, -0.0403, -0.1830,\n          0.1853, -0.0592,  0.0409,  0.1650,  0.0562, -0.1824,  0.2285,  0.0763],\n        [-0.2284,  0.1259, -0.2007,  0.1359,  0.0967, -0.0429, -0.1847, -0.2094,\n          0.1314, -0.1360, -0.1549, -0.2183,  0.0466, -0.1040,  0.0591,  0.1082],\n        [ 0.2184, -0.2435, -0.2079, -0.1340, -0.1002,  0.1175, -0.2114, -0.0323,\n         -0.2381, -0.1360, -0.2192, -0.0851, -0.0794, -0.1466, -0.0536, -0.0499],\n        [-0.0385, -0.0255, -0.1578,  0.1643,  0.0430, -0.2315,  0.1299, -0.0762,\n         -0.1266,  0.2065,  0.2477,  0.0070,  0.0815, -0.2327,  0.1664, -0.0375]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1616,  0.0359, -0.0011, -0.0137,  0.2090, -0.1897, -0.1322,  0.0784],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0994,  0.2291,  0.0384,  0.2012,  0.0886,  0.2736,  0.1131, -0.2949]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0040], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x0000021EDF4F22F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x0000021EA7BC9270>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s366480000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s366480000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}