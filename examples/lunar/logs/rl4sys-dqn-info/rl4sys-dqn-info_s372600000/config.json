{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s372600000"
    },
    "q_lr":	0.0005,
    "seed":	372600000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000002CF8D1BD0F0>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2655, -0.2243,  0.3478, -0.3494, -0.1407,  0.3110, -0.0041, -0.2655,\n         0.2634, -0.3191, -0.1638,  0.2522,  0.0076, -0.0775, -0.3432,  0.1778,\n         0.3131,  0.0961, -0.0886,  0.3531,  0.2659, -0.3359, -0.3337,  0.1743,\n        -0.2606, -0.0620,  0.0932,  0.1781, -0.1770, -0.3155, -0.1752,  0.0315],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2060, -0.2466,  0.2641, -0.1534,  0.0824,  0.3375, -0.1951,  0.1778],\n        [ 0.2831, -0.0294,  0.0502, -0.0270,  0.0204, -0.3003,  0.0486,  0.2771],\n        [-0.1049, -0.2020,  0.2120,  0.1520,  0.1969, -0.0110, -0.0282, -0.0016],\n        [-0.2122,  0.2697,  0.0119,  0.0020, -0.3146,  0.2606, -0.2721,  0.1995],\n        [-0.0821,  0.0498,  0.0793,  0.2170, -0.1959,  0.0531,  0.2483, -0.2393],\n        [ 0.2407, -0.1766, -0.0144, -0.2842, -0.3327, -0.2095, -0.1177, -0.0959],\n        [-0.3138,  0.0301, -0.1644,  0.0860,  0.2360,  0.0835,  0.2481, -0.0447],\n        [-0.0888, -0.0909,  0.2848,  0.0815,  0.1852,  0.1888,  0.2676,  0.2442],\n        [ 0.1434,  0.1501,  0.0977,  0.1298,  0.1530,  0.2857, -0.1570, -0.2265],\n        [-0.2962,  0.0952, -0.0048, -0.2925,  0.1277, -0.1064, -0.0876, -0.1666],\n        [-0.3065,  0.3243, -0.3122,  0.3436,  0.1965, -0.0890, -0.0392,  0.1461],\n        [ 0.1337,  0.3067, -0.1990, -0.0009, -0.1686, -0.1953,  0.1520,  0.3195],\n        [-0.2443, -0.2314,  0.2638,  0.1586,  0.1072, -0.2365,  0.1374,  0.1590],\n        [ 0.1571,  0.1339, -0.1893,  0.2849,  0.3041, -0.2408,  0.2362, -0.0082],\n        [-0.3384,  0.0461,  0.1619,  0.1374,  0.2654,  0.1889, -0.1050,  0.0575],\n        [ 0.1917, -0.3034,  0.3249,  0.0223,  0.2820,  0.2330,  0.0843, -0.2715],\n        [-0.0838, -0.0787,  0.1412, -0.1850,  0.2375, -0.0319, -0.3490, -0.1315],\n        [ 0.2486,  0.1194, -0.2070, -0.0193, -0.3286,  0.1727, -0.2699,  0.2058],\n        [-0.0415,  0.0020, -0.1813, -0.2581,  0.0506, -0.2237, -0.0153,  0.1396],\n        [-0.1000, -0.2177,  0.0559, -0.0517, -0.1325,  0.0663,  0.3083,  0.2346],\n        [ 0.3441, -0.0051,  0.0566, -0.0273, -0.2307, -0.3077, -0.2143, -0.3212],\n        [-0.1346, -0.0919, -0.1405, -0.3232,  0.1811, -0.1021,  0.2619, -0.3394],\n        [-0.2804,  0.0650, -0.0699, -0.1707, -0.3325, -0.0230,  0.2320, -0.2100],\n        [ 0.1644,  0.1029,  0.0355,  0.1260, -0.3497, -0.2305,  0.0510,  0.1693],\n        [-0.2975,  0.3396,  0.2002,  0.1533, -0.2657,  0.0318, -0.1220, -0.2985],\n        [-0.0477, -0.2263,  0.2972,  0.2537,  0.1565, -0.0748,  0.3110,  0.1042],\n        [ 0.2819,  0.1598, -0.1651,  0.2013, -0.1421, -0.0774,  0.2690, -0.0123],\n        [-0.2189,  0.1744,  0.0085,  0.3339, -0.3241,  0.3103,  0.1538, -0.1817],\n        [ 0.0998,  0.0227, -0.3350, -0.0582, -0.0433,  0.1888,  0.1670,  0.0894],\n        [-0.3140,  0.0763, -0.2766,  0.0054, -0.1904, -0.3098, -0.1815, -0.3190],\n        [-0.2468, -0.1169,  0.0179, -0.0820,  0.1413, -0.2393,  0.1376, -0.3286],\n        [ 0.2745,  0.3129, -0.2057, -0.0541,  0.3414, -0.3280,  0.3497,  0.2558]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0106,  0.0706, -0.1163,  0.0043,  0.0420, -0.0366, -0.0128, -0.1012,\n         0.0637, -0.1577, -0.1327, -0.1091,  0.1378, -0.1128,  0.0065,  0.1093],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.0711e-02,  5.4747e-02, -1.5351e-02,  4.7094e-02, -8.9999e-02,\n         -3.3241e-02,  1.4541e-01,  9.0225e-02,  6.0285e-02, -1.2261e-01,\n         -1.2060e-01, -1.6370e-01,  9.0079e-02,  3.0572e-02,  6.3569e-02,\n         -8.6901e-02, -6.9601e-02, -9.3043e-02,  1.1398e-01, -9.4108e-02,\n          1.0448e-01, -1.6175e-01,  8.6080e-02, -1.1425e-01, -1.1789e-01,\n         -1.6748e-01,  6.8209e-02, -1.2619e-01, -4.3497e-02, -2.1947e-02,\n         -3.9574e-02,  5.4625e-02],\n        [-7.2873e-02,  1.2217e-01,  1.3324e-02, -1.2603e-01,  2.1021e-02,\n         -7.6252e-02, -1.6494e-01, -1.1770e-01, -1.2285e-01,  1.7060e-01,\n         -2.0335e-02, -7.1204e-03, -1.3986e-01, -1.7570e-01,  3.7743e-02,\n         -1.7553e-01,  1.1434e-01,  5.2151e-02, -5.9727e-02,  6.0812e-02,\n          1.4316e-01, -9.0406e-02, -1.1998e-01, -1.6222e-02,  1.4805e-01,\n         -2.3793e-02, -1.1350e-01,  2.5060e-02,  1.2406e-01, -3.0396e-02,\n         -9.3439e-02,  1.7735e-03],\n        [ 1.7275e-01, -1.3752e-01,  4.4065e-02, -3.2725e-02,  8.0903e-02,\n          8.0361e-02,  8.9588e-02, -3.9615e-02, -5.8607e-02,  1.3663e-01,\n          1.7398e-02, -1.4756e-01, -3.7565e-02,  1.3338e-01,  5.5951e-02,\n          8.6835e-02,  1.3005e-01, -1.4920e-01,  8.6107e-02,  6.3149e-02,\n          3.6256e-02,  6.6277e-02,  5.9627e-02,  1.7591e-01,  8.2075e-02,\n         -1.6984e-01, -1.2131e-01,  1.3532e-01,  1.3532e-01,  1.3790e-01,\n         -9.3365e-02,  9.4300e-02],\n        [ 7.5584e-02, -5.7811e-03,  7.3285e-03, -1.0859e-01, -1.8613e-02,\n         -1.7124e-01, -1.3155e-01, -1.4841e-01, -2.6701e-03, -1.4634e-01,\n          1.6810e-01,  1.5357e-01,  1.5246e-01, -8.8423e-02,  1.2153e-01,\n         -9.8623e-02, -6.4241e-02, -9.9244e-02,  3.8047e-02,  8.0781e-02,\n          1.5996e-01, -1.7227e-01, -3.8142e-02, -6.1225e-03, -1.0283e-01,\n          1.0336e-01, -4.6903e-02,  2.3460e-02, -9.3897e-02, -8.8378e-02,\n         -3.4075e-02, -1.2752e-02],\n        [-3.3087e-02,  1.7386e-01, -1.0343e-01,  4.0423e-02, -1.5617e-01,\n         -1.7049e-01,  8.4240e-02,  8.2566e-03, -1.1496e-02, -9.7010e-03,\n         -2.4808e-02, -1.4250e-01,  1.0065e-01, -4.9055e-02,  1.5094e-01,\n          1.0253e-01, -2.3582e-02, -1.3156e-01, -1.4343e-01,  8.1633e-02,\n         -1.7303e-01,  1.2263e-01,  6.0594e-02,  6.3082e-02, -1.6619e-01,\n         -6.9762e-02, -4.1763e-03,  2.3078e-02,  3.1069e-02, -3.6960e-02,\n         -7.8309e-03,  6.5367e-02],\n        [ 4.4566e-02, -6.5188e-02,  1.4489e-01, -1.6390e-01,  1.6088e-01,\n          3.2821e-02,  1.1954e-01,  1.6780e-04,  1.4252e-01,  2.1515e-02,\n         -1.3029e-01, -7.9991e-02,  1.4059e-01,  1.5616e-01, -8.0110e-02,\n         -8.9817e-02, -1.4069e-01, -1.7098e-02, -9.6803e-02, -1.7666e-01,\n         -7.8846e-03,  5.6166e-02, -1.3058e-01,  1.1194e-01,  8.8915e-02,\n         -1.1013e-01, -1.6903e-01,  6.0007e-02, -6.6302e-02,  6.8146e-02,\n          1.5234e-02,  1.5715e-01],\n        [ 1.2981e-01, -6.3823e-02,  8.8450e-02,  4.6894e-02,  9.1007e-02,\n          4.1555e-02,  1.4314e-01,  1.0498e-01,  1.1567e-01, -8.3061e-03,\n          1.3165e-01, -1.7250e-01,  9.1545e-02,  1.5807e-01,  3.6364e-02,\n         -6.7835e-02,  9.6050e-02,  5.4548e-02,  1.4994e-01, -4.0656e-02,\n          5.2847e-02,  1.0312e-01,  7.9494e-02, -4.4937e-02,  1.6089e-01,\n         -1.9790e-02,  1.4965e-01,  1.6386e-01, -6.3957e-02, -3.2657e-02,\n         -3.8432e-03, -3.6406e-02],\n        [-1.2632e-01, -1.4457e-01, -1.6994e-01, -7.4892e-02, -1.6450e-01,\n         -4.9810e-02,  1.6764e-02,  1.0706e-01,  6.5800e-02,  3.0056e-02,\n          4.9388e-02,  1.2107e-01, -1.4073e-01, -1.4404e-01,  3.8899e-03,\n          4.9159e-02, -5.8740e-02,  3.5529e-02, -1.1514e-04,  8.4128e-02,\n         -7.8344e-02, -1.1903e-01,  1.3569e-01,  1.3230e-01,  6.4692e-03,\n         -8.8024e-02,  7.0765e-02,  1.4039e-03,  6.2607e-02,  3.9923e-03,\n          1.3999e-01,  7.0180e-02],\n        [ 1.3452e-01,  1.1213e-01,  1.0389e-02,  4.9391e-02, -8.4267e-02,\n         -6.2831e-03,  4.7834e-02,  9.9704e-02, -1.2098e-01, -1.3745e-01,\n          1.2036e-01,  1.4236e-01,  1.5894e-02,  1.4556e-02, -1.6678e-01,\n          4.2827e-02, -1.7378e-01, -3.4141e-02,  1.1381e-02,  4.7065e-02,\n         -1.4241e-01,  8.5818e-02, -9.7170e-02,  1.1979e-01,  8.3704e-02,\n         -1.8550e-02,  3.1983e-02, -6.8061e-02,  3.2044e-03, -2.2563e-03,\n         -5.7805e-03,  9.5019e-02],\n        [-8.5576e-02, -8.0882e-02,  3.6142e-02,  1.0397e-02,  1.1581e-01,\n         -5.3685e-02, -1.6349e-01, -1.3682e-01, -1.2092e-01, -1.5247e-01,\n         -5.7649e-02,  9.7210e-02, -1.0478e-01, -7.4296e-02, -4.6819e-02,\n          1.0206e-01,  1.3974e-01,  1.0477e-01,  4.5408e-02,  2.4961e-02,\n          1.0592e-01,  1.4714e-01, -4.3380e-02, -8.1602e-02, -7.3345e-02,\n         -4.0042e-02, -1.6735e-02,  9.8475e-02,  1.1262e-02,  5.4910e-02,\n          5.9119e-02,  8.6440e-02],\n        [ 8.3352e-02, -1.5100e-02, -8.2949e-02,  4.9458e-02, -7.2356e-02,\n         -1.6845e-01,  9.7720e-02, -1.0279e-01, -1.3187e-01, -1.0589e-01,\n          3.2798e-02,  7.3687e-02, -5.6047e-02,  1.0468e-01,  1.0274e-01,\n         -8.3375e-02, -5.3801e-02, -9.9707e-03,  4.3465e-02, -1.0820e-01,\n          2.6083e-02,  1.4374e-01, -1.1785e-01,  5.7530e-02, -1.2688e-01,\n          1.1359e-01,  3.5694e-02, -6.4740e-02, -3.1087e-02, -1.2264e-01,\n          1.1833e-01,  7.3949e-02],\n        [-1.5105e-01,  1.1725e-01, -1.2162e-01, -1.5191e-01,  8.4384e-02,\n          1.6479e-01, -6.5395e-02, -8.3645e-03, -7.9115e-02,  1.3613e-01,\n         -8.5538e-02,  1.8370e-02, -1.3649e-01, -2.6210e-03, -2.0113e-02,\n         -1.3532e-01, -2.8448e-02,  1.0567e-01, -7.4061e-02,  4.3275e-02,\n          1.0666e-01, -7.1153e-02,  1.2192e-01, -4.5859e-02,  8.9670e-02,\n          7.5407e-02,  3.9658e-02,  9.5294e-02,  1.0853e-01,  5.4600e-02,\n          5.3737e-02, -3.8045e-02],\n        [-4.9199e-02, -4.9937e-02,  1.5817e-01, -1.0265e-01,  1.5378e-01,\n         -1.1427e-01, -6.2786e-02, -9.3591e-02,  5.3705e-02,  8.1464e-02,\n         -1.4516e-01,  1.3573e-01,  6.4038e-02,  4.2838e-02,  8.8410e-03,\n         -1.2874e-01,  4.3450e-02, -7.7332e-02, -1.7629e-01, -1.5383e-01,\n         -7.3245e-02, -1.5303e-01,  7.4177e-02,  5.4745e-02,  1.7299e-01,\n         -4.2572e-02,  4.2816e-02, -9.0600e-02, -1.5026e-01,  1.5096e-02,\n         -6.8711e-02,  1.2665e-01],\n        [-4.3755e-02,  1.9605e-02,  4.3309e-02,  1.2004e-01, -3.9170e-02,\n         -4.2483e-02,  4.6836e-04, -7.1047e-02, -1.3902e-01, -9.4904e-04,\n         -3.2499e-02, -6.5688e-02,  7.0414e-02,  1.3095e-01, -1.3473e-01,\n         -1.1549e-01,  4.5874e-02, -9.3940e-02,  8.6352e-02, -2.7235e-02,\n          3.3032e-02, -9.3475e-02, -1.4193e-02, -2.8369e-02, -6.7731e-02,\n         -1.1025e-01,  5.7027e-02,  1.0149e-01,  1.4854e-02,  7.1950e-04,\n         -3.4095e-02, -1.0327e-01],\n        [-1.0284e-01, -5.2637e-02, -3.2109e-02, -1.7027e-01,  1.4456e-01,\n          7.0455e-02, -5.4760e-03, -6.0685e-02, -1.1369e-02,  1.1260e-01,\n          5.4198e-02,  1.6975e-01, -6.8900e-02, -1.3161e-01, -7.4389e-03,\n          9.4687e-02,  6.8517e-02,  1.6123e-01,  8.4415e-02, -1.0460e-01,\n          1.3808e-01, -1.3605e-02, -1.6396e-01, -1.3885e-01,  4.3606e-02,\n          8.0679e-02, -4.6827e-02, -1.4799e-01,  7.4814e-02,  1.2025e-01,\n         -3.6811e-02, -1.1922e-01],\n        [-1.7474e-02, -6.8974e-02, -2.7773e-02, -1.4781e-02, -1.1776e-01,\n          1.1782e-01, -5.3733e-02,  1.7187e-01,  1.4198e-01, -1.7023e-01,\n         -8.6296e-02,  1.7646e-01,  1.1484e-01, -9.5249e-02, -1.4588e-01,\n         -1.4923e-01,  7.7033e-02,  1.0704e-01, -1.1333e-01,  2.4205e-02,\n          6.3069e-02,  1.0635e-01, -9.6142e-02, -1.7511e-01,  8.0278e-02,\n          1.1575e-01,  1.2486e-01, -8.3258e-02, -1.3139e-01, -2.0687e-02,\n         -1.5664e-01, -1.5474e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0821,  0.0047, -0.1919,  0.0862,  0.1569,  0.0283, -0.0940, -0.0097],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 2.1113e-01, -2.2386e-01, -2.3987e-01,  9.9162e-02,  2.3507e-01,\n         -1.7706e-01,  6.5399e-02, -1.7916e-01,  3.4364e-02,  4.9948e-03,\n         -1.2926e-01,  6.6320e-02,  1.9651e-01, -1.9500e-01,  5.9469e-02,\n         -1.6291e-01],\n        [-2.3570e-01, -2.4213e-01,  2.1194e-01, -1.1543e-01, -3.7114e-02,\n          2.1086e-01, -2.3809e-01, -1.7870e-01,  1.5402e-01,  2.3930e-01,\n          2.4244e-01,  1.9144e-01, -7.3236e-04, -2.8175e-02,  8.8036e-03,\n          1.6299e-01],\n        [ 1.2752e-01, -8.1422e-02,  8.9053e-02, -6.5653e-02,  5.1962e-02,\n          9.6550e-02,  4.5703e-02,  1.9858e-01,  1.6896e-01, -2.3346e-01,\n         -1.1392e-01,  2.1110e-01, -1.8455e-01, -6.7643e-02, -6.8606e-02,\n         -1.4358e-02],\n        [-3.8054e-03,  1.3355e-01,  1.0915e-01, -7.7502e-02, -9.7795e-02,\n          5.4296e-02,  1.2227e-01,  2.4126e-01, -8.4628e-02, -9.6820e-02,\n          1.9531e-01,  1.7881e-01, -8.9423e-02, -2.2917e-01,  1.2565e-01,\n         -2.2251e-02],\n        [-1.9434e-01,  8.0754e-02,  4.5733e-02, -1.4448e-01, -7.6020e-02,\n          3.2415e-02, -1.3293e-01, -6.8882e-02, -1.6981e-01, -7.6701e-03,\n          6.7747e-02, -5.2219e-02, -1.0581e-01,  1.1505e-01, -1.5903e-01,\n          5.8144e-05],\n        [-4.9342e-02,  1.1322e-01,  2.3657e-01, -1.8899e-01,  2.4997e-01,\n          2.7447e-02, -2.3282e-01, -1.5967e-01, -1.6064e-01, -8.0125e-02,\n          5.5391e-02, -7.1471e-02,  5.3396e-02,  1.7619e-01,  6.6085e-02,\n          3.4217e-02],\n        [ 2.1534e-01,  1.2303e-01, -7.8248e-03, -6.4820e-02, -1.5056e-01,\n          1.8134e-01,  9.2041e-02, -1.0119e-01, -1.0972e-01,  1.7276e-01,\n         -1.0089e-01,  2.3198e-01,  1.5452e-01, -1.3180e-01,  4.5213e-02,\n         -1.9280e-01],\n        [-2.3203e-01,  1.6587e-01,  2.4068e-01,  2.2813e-01, -2.3380e-01,\n         -4.2640e-02,  2.0139e-01,  2.0472e-01,  1.8716e-01,  6.5472e-02,\n          2.1497e-01, -1.1212e-01, -2.0440e-01,  1.5737e-01, -1.0773e-02,\n          9.2425e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2587], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2488,  0.2344,  0.0793, -0.0470,  0.2489, -0.2012,  0.3133, -0.2923]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2060, -0.2466,  0.2641, -0.1534,  0.0824,  0.3375, -0.1951,  0.1778],\n        [ 0.2831, -0.0294,  0.0502, -0.0270,  0.0204, -0.3003,  0.0486,  0.2771],\n        [-0.1049, -0.2020,  0.2120,  0.1520,  0.1969, -0.0110, -0.0282, -0.0016],\n        [-0.2122,  0.2697,  0.0119,  0.0020, -0.3146,  0.2606, -0.2721,  0.1995],\n        [-0.0821,  0.0498,  0.0793,  0.2170, -0.1959,  0.0531,  0.2483, -0.2393],\n        [ 0.2407, -0.1766, -0.0144, -0.2842, -0.3327, -0.2095, -0.1177, -0.0959],\n        [-0.3138,  0.0301, -0.1644,  0.0860,  0.2360,  0.0835,  0.2481, -0.0447],\n        [-0.0888, -0.0909,  0.2848,  0.0815,  0.1852,  0.1888,  0.2676,  0.2442],\n        [ 0.1434,  0.1501,  0.0977,  0.1298,  0.1530,  0.2857, -0.1570, -0.2265],\n        [-0.2962,  0.0952, -0.0048, -0.2925,  0.1277, -0.1064, -0.0876, -0.1666],\n        [-0.3065,  0.3243, -0.3122,  0.3436,  0.1965, -0.0890, -0.0392,  0.1461],\n        [ 0.1337,  0.3067, -0.1990, -0.0009, -0.1686, -0.1953,  0.1520,  0.3195],\n        [-0.2443, -0.2314,  0.2638,  0.1586,  0.1072, -0.2365,  0.1374,  0.1590],\n        [ 0.1571,  0.1339, -0.1893,  0.2849,  0.3041, -0.2408,  0.2362, -0.0082],\n        [-0.3384,  0.0461,  0.1619,  0.1374,  0.2654,  0.1889, -0.1050,  0.0575],\n        [ 0.1917, -0.3034,  0.3249,  0.0223,  0.2820,  0.2330,  0.0843, -0.2715],\n        [-0.0838, -0.0787,  0.1412, -0.1850,  0.2375, -0.0319, -0.3490, -0.1315],\n        [ 0.2486,  0.1194, -0.2070, -0.0193, -0.3286,  0.1727, -0.2699,  0.2058],\n        [-0.0415,  0.0020, -0.1813, -0.2581,  0.0506, -0.2237, -0.0153,  0.1396],\n        [-0.1000, -0.2177,  0.0559, -0.0517, -0.1325,  0.0663,  0.3083,  0.2346],\n        [ 0.3441, -0.0051,  0.0566, -0.0273, -0.2307, -0.3077, -0.2143, -0.3212],\n        [-0.1346, -0.0919, -0.1405, -0.3232,  0.1811, -0.1021,  0.2619, -0.3394],\n        [-0.2804,  0.0650, -0.0699, -0.1707, -0.3325, -0.0230,  0.2320, -0.2100],\n        [ 0.1644,  0.1029,  0.0355,  0.1260, -0.3497, -0.2305,  0.0510,  0.1693],\n        [-0.2975,  0.3396,  0.2002,  0.1533, -0.2657,  0.0318, -0.1220, -0.2985],\n        [-0.0477, -0.2263,  0.2972,  0.2537,  0.1565, -0.0748,  0.3110,  0.1042],\n        [ 0.2819,  0.1598, -0.1651,  0.2013, -0.1421, -0.0774,  0.2690, -0.0123],\n        [-0.2189,  0.1744,  0.0085,  0.3339, -0.3241,  0.3103,  0.1538, -0.1817],\n        [ 0.0998,  0.0227, -0.3350, -0.0582, -0.0433,  0.1888,  0.1670,  0.0894],\n        [-0.3140,  0.0763, -0.2766,  0.0054, -0.1904, -0.3098, -0.1815, -0.3190],\n        [-0.2468, -0.1169,  0.0179, -0.0820,  0.1413, -0.2393,  0.1376, -0.3286],\n        [ 0.2745,  0.3129, -0.2057, -0.0541,  0.3414, -0.3280,  0.3497,  0.2558]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2655, -0.2243,  0.3478, -0.3494, -0.1407,  0.3110, -0.0041, -0.2655,\n         0.2634, -0.3191, -0.1638,  0.2522,  0.0076, -0.0775, -0.3432,  0.1778,\n         0.3131,  0.0961, -0.0886,  0.3531,  0.2659, -0.3359, -0.3337,  0.1743,\n        -0.2606, -0.0620,  0.0932,  0.1781, -0.1770, -0.3155, -0.1752,  0.0315],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-8.0711e-02,  5.4747e-02, -1.5351e-02,  4.7094e-02, -8.9999e-02,\n         -3.3241e-02,  1.4541e-01,  9.0225e-02,  6.0285e-02, -1.2261e-01,\n         -1.2060e-01, -1.6370e-01,  9.0079e-02,  3.0572e-02,  6.3569e-02,\n         -8.6901e-02, -6.9601e-02, -9.3043e-02,  1.1398e-01, -9.4108e-02,\n          1.0448e-01, -1.6175e-01,  8.6080e-02, -1.1425e-01, -1.1789e-01,\n         -1.6748e-01,  6.8209e-02, -1.2619e-01, -4.3497e-02, -2.1947e-02,\n         -3.9574e-02,  5.4625e-02],\n        [-7.2873e-02,  1.2217e-01,  1.3324e-02, -1.2603e-01,  2.1021e-02,\n         -7.6252e-02, -1.6494e-01, -1.1770e-01, -1.2285e-01,  1.7060e-01,\n         -2.0335e-02, -7.1204e-03, -1.3986e-01, -1.7570e-01,  3.7743e-02,\n         -1.7553e-01,  1.1434e-01,  5.2151e-02, -5.9727e-02,  6.0812e-02,\n          1.4316e-01, -9.0406e-02, -1.1998e-01, -1.6222e-02,  1.4805e-01,\n         -2.3793e-02, -1.1350e-01,  2.5060e-02,  1.2406e-01, -3.0396e-02,\n         -9.3439e-02,  1.7735e-03],\n        [ 1.7275e-01, -1.3752e-01,  4.4065e-02, -3.2725e-02,  8.0903e-02,\n          8.0361e-02,  8.9588e-02, -3.9615e-02, -5.8607e-02,  1.3663e-01,\n          1.7398e-02, -1.4756e-01, -3.7565e-02,  1.3338e-01,  5.5951e-02,\n          8.6835e-02,  1.3005e-01, -1.4920e-01,  8.6107e-02,  6.3149e-02,\n          3.6256e-02,  6.6277e-02,  5.9627e-02,  1.7591e-01,  8.2075e-02,\n         -1.6984e-01, -1.2131e-01,  1.3532e-01,  1.3532e-01,  1.3790e-01,\n         -9.3365e-02,  9.4300e-02],\n        [ 7.5584e-02, -5.7811e-03,  7.3285e-03, -1.0859e-01, -1.8613e-02,\n         -1.7124e-01, -1.3155e-01, -1.4841e-01, -2.6701e-03, -1.4634e-01,\n          1.6810e-01,  1.5357e-01,  1.5246e-01, -8.8423e-02,  1.2153e-01,\n         -9.8623e-02, -6.4241e-02, -9.9244e-02,  3.8047e-02,  8.0781e-02,\n          1.5996e-01, -1.7227e-01, -3.8142e-02, -6.1225e-03, -1.0283e-01,\n          1.0336e-01, -4.6903e-02,  2.3460e-02, -9.3897e-02, -8.8378e-02,\n         -3.4075e-02, -1.2752e-02],\n        [-3.3087e-02,  1.7386e-01, -1.0343e-01,  4.0423e-02, -1.5617e-01,\n         -1.7049e-01,  8.4240e-02,  8.2566e-03, -1.1496e-02, -9.7010e-03,\n         -2.4808e-02, -1.4250e-01,  1.0065e-01, -4.9055e-02,  1.5094e-01,\n          1.0253e-01, -2.3582e-02, -1.3156e-01, -1.4343e-01,  8.1633e-02,\n         -1.7303e-01,  1.2263e-01,  6.0594e-02,  6.3082e-02, -1.6619e-01,\n         -6.9762e-02, -4.1763e-03,  2.3078e-02,  3.1069e-02, -3.6960e-02,\n         -7.8309e-03,  6.5367e-02],\n        [ 4.4566e-02, -6.5188e-02,  1.4489e-01, -1.6390e-01,  1.6088e-01,\n          3.2821e-02,  1.1954e-01,  1.6780e-04,  1.4252e-01,  2.1515e-02,\n         -1.3029e-01, -7.9991e-02,  1.4059e-01,  1.5616e-01, -8.0110e-02,\n         -8.9817e-02, -1.4069e-01, -1.7098e-02, -9.6803e-02, -1.7666e-01,\n         -7.8846e-03,  5.6166e-02, -1.3058e-01,  1.1194e-01,  8.8915e-02,\n         -1.1013e-01, -1.6903e-01,  6.0007e-02, -6.6302e-02,  6.8146e-02,\n          1.5234e-02,  1.5715e-01],\n        [ 1.2981e-01, -6.3823e-02,  8.8450e-02,  4.6894e-02,  9.1007e-02,\n          4.1555e-02,  1.4314e-01,  1.0498e-01,  1.1567e-01, -8.3061e-03,\n          1.3165e-01, -1.7250e-01,  9.1545e-02,  1.5807e-01,  3.6364e-02,\n         -6.7835e-02,  9.6050e-02,  5.4548e-02,  1.4994e-01, -4.0656e-02,\n          5.2847e-02,  1.0312e-01,  7.9494e-02, -4.4937e-02,  1.6089e-01,\n         -1.9790e-02,  1.4965e-01,  1.6386e-01, -6.3957e-02, -3.2657e-02,\n         -3.8432e-03, -3.6406e-02],\n        [-1.2632e-01, -1.4457e-01, -1.6994e-01, -7.4892e-02, -1.6450e-01,\n         -4.9810e-02,  1.6764e-02,  1.0706e-01,  6.5800e-02,  3.0056e-02,\n          4.9388e-02,  1.2107e-01, -1.4073e-01, -1.4404e-01,  3.8899e-03,\n          4.9159e-02, -5.8740e-02,  3.5529e-02, -1.1514e-04,  8.4128e-02,\n         -7.8344e-02, -1.1903e-01,  1.3569e-01,  1.3230e-01,  6.4692e-03,\n         -8.8024e-02,  7.0765e-02,  1.4039e-03,  6.2607e-02,  3.9923e-03,\n          1.3999e-01,  7.0180e-02],\n        [ 1.3452e-01,  1.1213e-01,  1.0389e-02,  4.9391e-02, -8.4267e-02,\n         -6.2831e-03,  4.7834e-02,  9.9704e-02, -1.2098e-01, -1.3745e-01,\n          1.2036e-01,  1.4236e-01,  1.5894e-02,  1.4556e-02, -1.6678e-01,\n          4.2827e-02, -1.7378e-01, -3.4141e-02,  1.1381e-02,  4.7065e-02,\n         -1.4241e-01,  8.5818e-02, -9.7170e-02,  1.1979e-01,  8.3704e-02,\n         -1.8550e-02,  3.1983e-02, -6.8061e-02,  3.2044e-03, -2.2563e-03,\n         -5.7805e-03,  9.5019e-02],\n        [-8.5576e-02, -8.0882e-02,  3.6142e-02,  1.0397e-02,  1.1581e-01,\n         -5.3685e-02, -1.6349e-01, -1.3682e-01, -1.2092e-01, -1.5247e-01,\n         -5.7649e-02,  9.7210e-02, -1.0478e-01, -7.4296e-02, -4.6819e-02,\n          1.0206e-01,  1.3974e-01,  1.0477e-01,  4.5408e-02,  2.4961e-02,\n          1.0592e-01,  1.4714e-01, -4.3380e-02, -8.1602e-02, -7.3345e-02,\n         -4.0042e-02, -1.6735e-02,  9.8475e-02,  1.1262e-02,  5.4910e-02,\n          5.9119e-02,  8.6440e-02],\n        [ 8.3352e-02, -1.5100e-02, -8.2949e-02,  4.9458e-02, -7.2356e-02,\n         -1.6845e-01,  9.7720e-02, -1.0279e-01, -1.3187e-01, -1.0589e-01,\n          3.2798e-02,  7.3687e-02, -5.6047e-02,  1.0468e-01,  1.0274e-01,\n         -8.3375e-02, -5.3801e-02, -9.9707e-03,  4.3465e-02, -1.0820e-01,\n          2.6083e-02,  1.4374e-01, -1.1785e-01,  5.7530e-02, -1.2688e-01,\n          1.1359e-01,  3.5694e-02, -6.4740e-02, -3.1087e-02, -1.2264e-01,\n          1.1833e-01,  7.3949e-02],\n        [-1.5105e-01,  1.1725e-01, -1.2162e-01, -1.5191e-01,  8.4384e-02,\n          1.6479e-01, -6.5395e-02, -8.3645e-03, -7.9115e-02,  1.3613e-01,\n         -8.5538e-02,  1.8370e-02, -1.3649e-01, -2.6210e-03, -2.0113e-02,\n         -1.3532e-01, -2.8448e-02,  1.0567e-01, -7.4061e-02,  4.3275e-02,\n          1.0666e-01, -7.1153e-02,  1.2192e-01, -4.5859e-02,  8.9670e-02,\n          7.5407e-02,  3.9658e-02,  9.5294e-02,  1.0853e-01,  5.4600e-02,\n          5.3737e-02, -3.8045e-02],\n        [-4.9199e-02, -4.9937e-02,  1.5817e-01, -1.0265e-01,  1.5378e-01,\n         -1.1427e-01, -6.2786e-02, -9.3591e-02,  5.3705e-02,  8.1464e-02,\n         -1.4516e-01,  1.3573e-01,  6.4038e-02,  4.2838e-02,  8.8410e-03,\n         -1.2874e-01,  4.3450e-02, -7.7332e-02, -1.7629e-01, -1.5383e-01,\n         -7.3245e-02, -1.5303e-01,  7.4177e-02,  5.4745e-02,  1.7299e-01,\n         -4.2572e-02,  4.2816e-02, -9.0600e-02, -1.5026e-01,  1.5096e-02,\n         -6.8711e-02,  1.2665e-01],\n        [-4.3755e-02,  1.9605e-02,  4.3309e-02,  1.2004e-01, -3.9170e-02,\n         -4.2483e-02,  4.6836e-04, -7.1047e-02, -1.3902e-01, -9.4904e-04,\n         -3.2499e-02, -6.5688e-02,  7.0414e-02,  1.3095e-01, -1.3473e-01,\n         -1.1549e-01,  4.5874e-02, -9.3940e-02,  8.6352e-02, -2.7235e-02,\n          3.3032e-02, -9.3475e-02, -1.4193e-02, -2.8369e-02, -6.7731e-02,\n         -1.1025e-01,  5.7027e-02,  1.0149e-01,  1.4854e-02,  7.1950e-04,\n         -3.4095e-02, -1.0327e-01],\n        [-1.0284e-01, -5.2637e-02, -3.2109e-02, -1.7027e-01,  1.4456e-01,\n          7.0455e-02, -5.4760e-03, -6.0685e-02, -1.1369e-02,  1.1260e-01,\n          5.4198e-02,  1.6975e-01, -6.8900e-02, -1.3161e-01, -7.4389e-03,\n          9.4687e-02,  6.8517e-02,  1.6123e-01,  8.4415e-02, -1.0460e-01,\n          1.3808e-01, -1.3605e-02, -1.6396e-01, -1.3885e-01,  4.3606e-02,\n          8.0679e-02, -4.6827e-02, -1.4799e-01,  7.4814e-02,  1.2025e-01,\n         -3.6811e-02, -1.1922e-01],\n        [-1.7474e-02, -6.8974e-02, -2.7773e-02, -1.4781e-02, -1.1776e-01,\n          1.1782e-01, -5.3733e-02,  1.7187e-01,  1.4198e-01, -1.7023e-01,\n         -8.6296e-02,  1.7646e-01,  1.1484e-01, -9.5249e-02, -1.4588e-01,\n         -1.4923e-01,  7.7033e-02,  1.0704e-01, -1.1333e-01,  2.4205e-02,\n          6.3069e-02,  1.0635e-01, -9.6142e-02, -1.7511e-01,  8.0278e-02,\n          1.1575e-01,  1.2486e-01, -8.3258e-02, -1.3139e-01, -2.0687e-02,\n         -1.5664e-01, -1.5474e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0106,  0.0706, -0.1163,  0.0043,  0.0420, -0.0366, -0.0128, -0.1012,\n         0.0637, -0.1577, -0.1327, -0.1091,  0.1378, -0.1128,  0.0065,  0.1093],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 2.1113e-01, -2.2386e-01, -2.3987e-01,  9.9162e-02,  2.3507e-01,\n         -1.7706e-01,  6.5399e-02, -1.7916e-01,  3.4364e-02,  4.9948e-03,\n         -1.2926e-01,  6.6320e-02,  1.9651e-01, -1.9500e-01,  5.9469e-02,\n         -1.6291e-01],\n        [-2.3570e-01, -2.4213e-01,  2.1194e-01, -1.1543e-01, -3.7114e-02,\n          2.1086e-01, -2.3809e-01, -1.7870e-01,  1.5402e-01,  2.3930e-01,\n          2.4244e-01,  1.9144e-01, -7.3236e-04, -2.8175e-02,  8.8036e-03,\n          1.6299e-01],\n        [ 1.2752e-01, -8.1422e-02,  8.9053e-02, -6.5653e-02,  5.1962e-02,\n          9.6550e-02,  4.5703e-02,  1.9858e-01,  1.6896e-01, -2.3346e-01,\n         -1.1392e-01,  2.1110e-01, -1.8455e-01, -6.7643e-02, -6.8606e-02,\n         -1.4358e-02],\n        [-3.8054e-03,  1.3355e-01,  1.0915e-01, -7.7502e-02, -9.7795e-02,\n          5.4296e-02,  1.2227e-01,  2.4126e-01, -8.4628e-02, -9.6820e-02,\n          1.9531e-01,  1.7881e-01, -8.9423e-02, -2.2917e-01,  1.2565e-01,\n         -2.2251e-02],\n        [-1.9434e-01,  8.0754e-02,  4.5733e-02, -1.4448e-01, -7.6020e-02,\n          3.2415e-02, -1.3293e-01, -6.8882e-02, -1.6981e-01, -7.6701e-03,\n          6.7747e-02, -5.2219e-02, -1.0581e-01,  1.1505e-01, -1.5903e-01,\n          5.8144e-05],\n        [-4.9342e-02,  1.1322e-01,  2.3657e-01, -1.8899e-01,  2.4997e-01,\n          2.7447e-02, -2.3282e-01, -1.5967e-01, -1.6064e-01, -8.0125e-02,\n          5.5391e-02, -7.1471e-02,  5.3396e-02,  1.7619e-01,  6.6085e-02,\n          3.4217e-02],\n        [ 2.1534e-01,  1.2303e-01, -7.8248e-03, -6.4820e-02, -1.5056e-01,\n          1.8134e-01,  9.2041e-02, -1.0119e-01, -1.0972e-01,  1.7276e-01,\n         -1.0089e-01,  2.3198e-01,  1.5452e-01, -1.3180e-01,  4.5213e-02,\n         -1.9280e-01],\n        [-2.3203e-01,  1.6587e-01,  2.4068e-01,  2.2813e-01, -2.3380e-01,\n         -4.2640e-02,  2.0139e-01,  2.0472e-01,  1.8716e-01,  6.5472e-02,\n          2.1497e-01, -1.1212e-01, -2.0440e-01,  1.5737e-01, -1.0773e-02,\n          9.2425e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0821,  0.0047, -0.1919,  0.0862,  0.1569,  0.0283, -0.0940, -0.0097],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2488,  0.2344,  0.0793, -0.0470,  0.2489, -0.2012,  0.3133, -0.2923]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2587], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000002CFC4A422F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000002CF8D1BD2D0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s372600000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s372600000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}