{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0003,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s387660000"
    },
    "max_sample_age":	250,
    "q_lr":	0.0003,
    "sample_decay":	0.8,
    "seed":	387660000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7f30aa5cdf50>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0003,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0456,  0.1205, -0.2534,  0.0752,  0.0460,  0.1424, -0.3417, -0.0496,\n        -0.0144,  0.2359, -0.0101, -0.3289, -0.3469,  0.1046, -0.1301,  0.1709,\n         0.0576, -0.2520, -0.2073, -0.1581,  0.2176,  0.1700,  0.0178, -0.1589,\n        -0.2083, -0.2493,  0.0106, -0.1925, -0.1052, -0.0347, -0.1639,  0.0134,\n         0.1289,  0.0927,  0.0794, -0.3081, -0.3267, -0.1741,  0.2414,  0.1315,\n        -0.3166,  0.2356, -0.2879, -0.2487,  0.2231, -0.1114,  0.2666, -0.3367,\n        -0.2963, -0.1462,  0.1478,  0.2250,  0.2751, -0.0355,  0.2985, -0.1477,\n         0.1828, -0.1451,  0.1823, -0.1231,  0.1325, -0.1449, -0.1627,  0.0994,\n        -0.3408, -0.2821, -0.1740, -0.0136, -0.0659,  0.3474,  0.0097, -0.1359,\n        -0.1178,  0.1077,  0.0997,  0.2720,  0.2511,  0.2355,  0.2536,  0.1320,\n         0.0891,  0.1187,  0.2199, -0.0110, -0.2117, -0.0799, -0.1989, -0.3047,\n        -0.3317,  0.2140,  0.0886,  0.3289, -0.3238, -0.2176,  0.1109, -0.0066,\n        -0.2102,  0.1768,  0.0515, -0.0060, -0.2272, -0.0256,  0.0217, -0.2487,\n         0.0752, -0.0314, -0.0933, -0.1076, -0.0153, -0.2114, -0.3325,  0.0460,\n         0.3530, -0.1460, -0.2940, -0.1841, -0.2339,  0.3481, -0.0508,  0.2991,\n         0.0437, -0.0928, -0.2818, -0.1202,  0.2107,  0.0377, -0.1452,  0.3459],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1475,  0.2923,  0.0692,  ..., -0.0692, -0.3057,  0.0122],\n        [ 0.3142, -0.2870,  0.2147,  ...,  0.0248,  0.0928, -0.1868],\n        [ 0.1474, -0.3465,  0.0094,  ...,  0.0086, -0.2342,  0.1407],\n        ...,\n        [-0.0601, -0.0427,  0.1953,  ..., -0.2190,  0.0999, -0.3494],\n        [-0.0636, -0.0272, -0.1643,  ...,  0.0713, -0.2885,  0.1655],\n        [-0.1538,  0.1333,  0.1858,  ...,  0.1776,  0.1140, -0.0201]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0179,  0.0467, -0.0281, -0.0744, -0.0497,  0.0154, -0.0753,  0.0479,\n         0.0526,  0.0004,  0.0238,  0.0311, -0.0642,  0.0049,  0.0510,  0.0686,\n        -0.0104, -0.0632,  0.0871,  0.0652,  0.0508,  0.0740, -0.0696, -0.0383,\n         0.0665,  0.0205, -0.0711, -0.0082, -0.0139, -0.0833, -0.0136,  0.0579,\n         0.0098,  0.0019,  0.0643,  0.0453,  0.0572, -0.0796, -0.0484,  0.0170,\n         0.0230,  0.0824,  0.0683, -0.0227, -0.0485,  0.0598, -0.0161,  0.0599,\n         0.0578, -0.0633, -0.0083, -0.0485, -0.0159, -0.0169, -0.0799, -0.0222,\n         0.0466, -0.0305,  0.0619, -0.0414, -0.0694, -0.0657,  0.0525,  0.0167,\n         0.0844,  0.0663, -0.0876,  0.0434,  0.0058,  0.0118, -0.0602,  0.0797,\n         0.0089, -0.0511,  0.0031, -0.0230,  0.0529, -0.0648,  0.0472, -0.0440,\n        -0.0195, -0.0539,  0.0057, -0.0543, -0.0796,  0.0299,  0.0165,  0.0606,\n         0.0261,  0.0027,  0.0577,  0.0326,  0.0393,  0.0564,  0.0790,  0.0431,\n         0.0182, -0.0490,  0.0253,  0.0623,  0.0407,  0.0242,  0.0562,  0.0565,\n        -0.0273, -0.0581, -0.0764,  0.0097,  0.0738,  0.0623, -0.0461,  0.0395,\n        -0.0720, -0.0396, -0.0545, -0.0644, -0.0572, -0.0604, -0.0361, -0.0736,\n         0.0563, -0.0186,  0.0774,  0.0538,  0.0039, -0.0085, -0.0603,  0.0573],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0648,  0.0350, -0.0654,  ..., -0.0802, -0.0485,  0.0216],\n        [ 0.0784, -0.0360, -0.0294,  ...,  0.0761, -0.0869,  0.0741],\n        [ 0.0120, -0.0100, -0.0009,  ..., -0.0856,  0.0490, -0.0685],\n        ...,\n        [ 0.0080,  0.0746, -0.0561,  ..., -0.0492,  0.0300, -0.0692],\n        [-0.0024,  0.0223,  0.0675,  ...,  0.0834,  0.0421, -0.0287],\n        [-0.0571,  0.0208, -0.0194,  ..., -0.0369,  0.0590, -0.0048]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0834,  0.0825,  0.0284, -0.0843], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-5.2228e-02,  3.7329e-02, -7.7349e-02, -8.1129e-02, -1.9509e-02,\n          2.7640e-03,  1.3332e-03,  7.7228e-03, -5.8318e-02,  4.5343e-02,\n          2.0858e-02,  7.8550e-02, -1.1785e-02,  1.3944e-02, -2.3567e-02,\n          2.1734e-02, -7.5171e-02,  2.3829e-02,  6.7846e-02, -4.7273e-02,\n          7.7095e-02,  8.1577e-02,  2.7521e-03,  7.6080e-02,  2.1058e-02,\n         -2.3114e-02, -6.4951e-02, -6.5871e-02, -6.7935e-02,  5.0092e-02,\n          6.0751e-02,  8.2697e-02,  8.6149e-02,  5.0482e-02, -1.2436e-02,\n          8.5820e-02,  5.1939e-02, -8.3322e-02,  2.7187e-02, -1.8662e-02,\n         -2.2398e-02,  3.0161e-02,  4.1220e-02,  4.5366e-02,  6.4996e-02,\n         -6.6891e-02,  2.7804e-02, -5.6127e-02,  3.8592e-02,  2.3571e-02,\n         -5.8740e-02,  6.9550e-03,  2.5492e-02, -1.3534e-02, -6.5950e-02,\n          5.2092e-03, -8.4712e-02,  4.4108e-02, -4.9188e-02,  1.2317e-02,\n         -7.2920e-03,  6.8393e-02, -3.9247e-02,  5.6254e-02, -3.5521e-02,\n          4.1119e-02,  6.9723e-02,  5.2432e-02, -4.7468e-02,  8.7887e-02,\n          2.5981e-02, -1.6369e-02,  1.7199e-02, -2.2043e-02, -8.1416e-02,\n          5.9039e-02, -1.5346e-02, -2.2675e-02, -2.8984e-02,  5.7061e-02,\n          1.3812e-02,  6.9209e-02, -1.6499e-02,  1.5857e-02, -7.2339e-02,\n          4.7784e-02, -3.7990e-02, -2.7470e-02, -1.4244e-02,  4.8772e-02,\n          1.4287e-03,  6.1429e-03,  4.5875e-02,  1.0392e-02,  7.3680e-02,\n          7.4054e-02, -2.2529e-02, -5.5089e-02,  6.3188e-02, -6.3433e-02,\n         -5.4565e-02,  8.5964e-02, -4.6464e-02,  6.2858e-02,  2.6771e-03,\n         -1.9190e-02, -8.3953e-02,  5.0966e-02, -3.4752e-02,  2.8541e-02,\n         -7.8290e-02,  7.9255e-02, -7.8618e-02,  2.8181e-02,  8.3822e-02,\n         -8.8384e-02, -7.6839e-02, -6.6110e-02,  6.8299e-02, -5.3902e-03,\n          4.7293e-02, -1.6138e-02, -6.0783e-02,  5.1341e-02, -2.6967e-02,\n          8.3717e-02,  8.0336e-02,  7.5719e-02],\n        [ 5.5499e-02, -1.8495e-02, -2.3282e-02,  5.0214e-03,  4.9095e-03,\n          1.7927e-02,  1.2747e-02,  5.6674e-02,  7.3666e-02,  5.1893e-02,\n          3.1373e-02,  7.5189e-02,  7.4163e-02, -8.7299e-02, -6.1497e-02,\n         -4.5475e-02, -5.9381e-02, -5.1537e-02, -4.2022e-02,  3.6510e-02,\n          7.4833e-02, -8.1750e-02,  5.5057e-02, -7.3974e-02,  3.4413e-02,\n          5.8726e-02, -5.5465e-02,  4.8500e-02, -4.7376e-02,  2.7661e-02,\n          1.1128e-02,  5.4957e-02,  5.7639e-02,  6.0264e-02, -7.4616e-02,\n          1.3821e-02, -7.6471e-02,  4.3905e-03,  1.4910e-02, -1.5062e-02,\n         -7.9345e-02,  2.8208e-02, -6.5994e-03,  5.1449e-02,  1.0091e-02,\n          6.9290e-02,  8.6120e-02, -5.4438e-02,  8.6632e-02,  3.3699e-02,\n         -2.5111e-03,  3.4960e-02,  4.3739e-02, -1.7374e-02, -7.1721e-02,\n          6.8804e-02,  5.4464e-04,  5.9961e-04,  7.9147e-02,  3.8560e-03,\n          3.2744e-03, -2.4936e-02,  5.5541e-02, -1.5965e-02, -8.6224e-02,\n          7.2228e-02,  2.5645e-02, -5.5498e-02,  4.5182e-02, -7.7124e-02,\n         -6.2886e-02,  3.4556e-02, -3.3209e-02,  1.4733e-02, -7.5466e-02,\n          5.3629e-02, -1.8737e-02,  2.1852e-02, -3.1206e-02, -2.3291e-02,\n          5.6879e-02, -7.0988e-02,  6.0846e-02,  1.0602e-02, -6.0128e-02,\n         -1.6959e-02,  6.7071e-02, -4.4362e-02, -7.2359e-02,  7.3248e-02,\n         -8.5052e-02,  4.3704e-03, -2.6136e-02,  1.3451e-02, -4.8529e-02,\n          6.2613e-02, -4.9193e-02,  1.4192e-02,  8.6709e-03, -6.1427e-02,\n          3.6797e-03,  4.4422e-02,  7.4599e-02, -5.7335e-02, -1.7567e-02,\n          8.6613e-02, -1.9690e-02,  7.0496e-02,  4.1562e-02,  5.1012e-02,\n         -6.0890e-02,  6.7249e-02,  7.0380e-02, -2.4012e-02, -7.6103e-02,\n         -2.3586e-02,  3.4942e-02,  8.1703e-02, -8.0645e-02, -4.7856e-02,\n          7.1871e-02,  5.5535e-02, -3.4779e-02,  7.3566e-02, -7.3222e-02,\n          5.0276e-02, -2.7190e-02, -4.4955e-02],\n        [ 8.2028e-05,  6.7229e-02, -5.3377e-02,  2.4825e-02,  5.5291e-02,\n         -2.6744e-02, -7.2027e-02,  4.0012e-02, -7.6570e-02, -5.7804e-02,\n         -1.0843e-02, -6.1617e-03, -6.9285e-02,  6.1142e-02, -2.6328e-02,\n          8.1555e-02, -5.3328e-02,  1.2289e-02, -3.9080e-02,  7.2144e-02,\n         -1.4743e-02, -3.4145e-02, -8.4653e-02,  7.7073e-02, -8.1623e-02,\n         -7.9579e-02,  6.4756e-02,  8.8356e-02, -5.8715e-02, -3.6605e-02,\n          8.2672e-02,  6.6061e-02,  1.8619e-02, -6.4067e-02,  1.8929e-02,\n         -7.9809e-02,  6.7375e-02, -9.5712e-04,  2.1736e-02, -4.0640e-02,\n          6.9987e-02, -9.6026e-03,  7.9186e-02,  7.4790e-02,  9.7133e-03,\n          2.1996e-02,  8.4927e-02, -3.5557e-02,  1.9590e-02, -8.5185e-02,\n          6.1441e-02, -2.9835e-02, -2.7310e-02, -8.1968e-03,  6.7802e-02,\n          5.1698e-02, -2.7438e-02,  5.5678e-03,  5.4310e-02,  4.4430e-02,\n         -7.3109e-02,  4.1933e-02,  7.9317e-02,  5.5123e-03, -4.0335e-02,\n          5.1799e-02, -8.0739e-02, -5.7569e-02, -1.1422e-02, -6.5322e-02,\n         -5.6020e-02, -2.1048e-02, -7.6900e-02,  6.1731e-02, -9.4726e-04,\n          5.8283e-02, -7.6710e-02, -2.6597e-02,  1.7530e-02,  6.6365e-02,\n         -5.1687e-02,  6.0800e-02,  3.1645e-02,  2.5778e-02,  8.3801e-02,\n          8.3831e-02,  2.9603e-02,  8.7300e-02,  9.8702e-03, -9.5149e-03,\n          6.3353e-03, -1.2122e-02,  3.0480e-02, -7.5556e-02,  4.8985e-02,\n          7.9277e-02, -7.6074e-02,  8.4101e-02,  4.4992e-02,  4.2608e-03,\n         -6.9153e-02, -3.1248e-02, -2.9186e-02,  8.2953e-02, -7.8736e-02,\n         -6.8744e-02, -1.9514e-02,  5.3707e-02,  1.5109e-02, -7.6477e-02,\n          6.4048e-02,  5.6157e-02,  5.7342e-02, -5.6131e-02,  1.7574e-02,\n          7.7734e-02, -1.4802e-02,  4.2883e-02, -5.9938e-02, -1.2289e-02,\n          6.5848e-02,  8.4030e-02, -6.7591e-02, -1.3313e-02,  4.2660e-02,\n          3.5938e-02,  5.7829e-02, -4.7499e-02],\n        [ 3.0753e-02, -6.1668e-02,  6.7369e-02, -7.8175e-02,  6.1228e-02,\n         -5.0717e-02,  8.6933e-02, -1.1731e-02,  6.6160e-04,  7.2493e-02,\n         -7.3762e-02, -2.5424e-02, -5.8534e-02, -1.7145e-02, -2.5453e-02,\n         -2.1319e-02,  4.1547e-02, -8.7656e-03, -6.3760e-02, -7.0393e-02,\n         -3.8514e-02,  4.1832e-02,  1.6180e-02, -6.1880e-02, -2.5014e-02,\n          8.7483e-02,  7.3773e-02, -6.1088e-02,  4.5352e-02, -2.9619e-05,\n          2.1125e-02, -8.4933e-03, -7.5099e-02,  8.1149e-02,  7.1838e-02,\n          1.3826e-02, -8.1070e-02, -2.4488e-02, -1.9604e-02,  6.9577e-02,\n         -2.3080e-02, -6.1031e-03,  2.0211e-02, -5.8648e-02, -8.4973e-02,\n         -8.3227e-02,  1.6523e-02,  7.6091e-02, -6.2951e-02, -4.7292e-02,\n         -2.3216e-02,  2.9243e-02,  3.4730e-02,  1.6087e-02, -2.7734e-02,\n         -6.0498e-02, -5.0740e-02,  3.3887e-02,  3.7899e-02,  2.7225e-02,\n         -2.5514e-02,  2.1253e-02, -4.3383e-03,  5.4366e-02,  2.5439e-02,\n          8.1863e-02,  1.4273e-02,  7.9701e-02,  2.1752e-02,  6.7514e-02,\n          6.1242e-02,  5.8428e-02,  3.1492e-02, -2.1897e-02, -8.7990e-03,\n         -5.8318e-02, -3.9031e-02, -6.5725e-02, -4.5741e-02,  5.6301e-02,\n         -7.2207e-02, -2.6533e-02, -2.8111e-02, -4.3553e-02, -5.7501e-02,\n         -6.0258e-03,  3.0589e-02, -7.6134e-02,  1.6292e-02, -4.0386e-02,\n         -6.4613e-02,  5.5547e-02, -9.9982e-04,  8.5597e-02, -2.7561e-02,\n         -2.6885e-02, -3.4308e-02,  4.0412e-02,  2.8218e-02, -4.5864e-02,\n         -3.4320e-03,  1.8083e-03, -5.2776e-03, -2.5866e-02, -3.3089e-03,\n          2.9746e-02,  6.0750e-02, -5.0580e-02, -6.3028e-02, -2.8483e-02,\n          7.5684e-02,  5.8893e-02, -1.7399e-02, -6.5997e-02, -3.0538e-02,\n         -7.6479e-02,  7.9795e-02, -6.3730e-02, -2.6250e-02,  7.9018e-02,\n         -7.7387e-03, -7.2283e-02, -2.4693e-02, -5.1592e-02,  2.5385e-02,\n         -3.2225e-02,  4.2816e-03,  1.6579e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1475,  0.2923,  0.0692,  ..., -0.0692, -0.3057,  0.0122],\n        [ 0.3142, -0.2870,  0.2147,  ...,  0.0248,  0.0928, -0.1868],\n        [ 0.1474, -0.3465,  0.0094,  ...,  0.0086, -0.2342,  0.1407],\n        ...,\n        [-0.0601, -0.0427,  0.1953,  ..., -0.2190,  0.0999, -0.3494],\n        [-0.0636, -0.0272, -0.1643,  ...,  0.0713, -0.2885,  0.1655],\n        [-0.1538,  0.1333,  0.1858,  ...,  0.1776,  0.1140, -0.0201]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0456,  0.1205, -0.2534,  0.0752,  0.0460,  0.1424, -0.3417, -0.0496,\n        -0.0144,  0.2359, -0.0101, -0.3289, -0.3469,  0.1046, -0.1301,  0.1709,\n         0.0576, -0.2520, -0.2073, -0.1581,  0.2176,  0.1700,  0.0178, -0.1589,\n        -0.2083, -0.2493,  0.0106, -0.1925, -0.1052, -0.0347, -0.1639,  0.0134,\n         0.1289,  0.0927,  0.0794, -0.3081, -0.3267, -0.1741,  0.2414,  0.1315,\n        -0.3166,  0.2356, -0.2879, -0.2487,  0.2231, -0.1114,  0.2666, -0.3367,\n        -0.2963, -0.1462,  0.1478,  0.2250,  0.2751, -0.0355,  0.2985, -0.1477,\n         0.1828, -0.1451,  0.1823, -0.1231,  0.1325, -0.1449, -0.1627,  0.0994,\n        -0.3408, -0.2821, -0.1740, -0.0136, -0.0659,  0.3474,  0.0097, -0.1359,\n        -0.1178,  0.1077,  0.0997,  0.2720,  0.2511,  0.2355,  0.2536,  0.1320,\n         0.0891,  0.1187,  0.2199, -0.0110, -0.2117, -0.0799, -0.1989, -0.3047,\n        -0.3317,  0.2140,  0.0886,  0.3289, -0.3238, -0.2176,  0.1109, -0.0066,\n        -0.2102,  0.1768,  0.0515, -0.0060, -0.2272, -0.0256,  0.0217, -0.2487,\n         0.0752, -0.0314, -0.0933, -0.1076, -0.0153, -0.2114, -0.3325,  0.0460,\n         0.3530, -0.1460, -0.2940, -0.1841, -0.2339,  0.3481, -0.0508,  0.2991,\n         0.0437, -0.0928, -0.2818, -0.1202,  0.2107,  0.0377, -0.1452,  0.3459],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0648,  0.0350, -0.0654,  ..., -0.0802, -0.0485,  0.0216],\n        [ 0.0784, -0.0360, -0.0294,  ...,  0.0761, -0.0869,  0.0741],\n        [ 0.0120, -0.0100, -0.0009,  ..., -0.0856,  0.0490, -0.0685],\n        ...,\n        [ 0.0080,  0.0746, -0.0561,  ..., -0.0492,  0.0300, -0.0692],\n        [-0.0024,  0.0223,  0.0675,  ...,  0.0834,  0.0421, -0.0287],\n        [-0.0571,  0.0208, -0.0194,  ..., -0.0369,  0.0590, -0.0048]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0179,  0.0467, -0.0281, -0.0744, -0.0497,  0.0154, -0.0753,  0.0479,\n         0.0526,  0.0004,  0.0238,  0.0311, -0.0642,  0.0049,  0.0510,  0.0686,\n        -0.0104, -0.0632,  0.0871,  0.0652,  0.0508,  0.0740, -0.0696, -0.0383,\n         0.0665,  0.0205, -0.0711, -0.0082, -0.0139, -0.0833, -0.0136,  0.0579,\n         0.0098,  0.0019,  0.0643,  0.0453,  0.0572, -0.0796, -0.0484,  0.0170,\n         0.0230,  0.0824,  0.0683, -0.0227, -0.0485,  0.0598, -0.0161,  0.0599,\n         0.0578, -0.0633, -0.0083, -0.0485, -0.0159, -0.0169, -0.0799, -0.0222,\n         0.0466, -0.0305,  0.0619, -0.0414, -0.0694, -0.0657,  0.0525,  0.0167,\n         0.0844,  0.0663, -0.0876,  0.0434,  0.0058,  0.0118, -0.0602,  0.0797,\n         0.0089, -0.0511,  0.0031, -0.0230,  0.0529, -0.0648,  0.0472, -0.0440,\n        -0.0195, -0.0539,  0.0057, -0.0543, -0.0796,  0.0299,  0.0165,  0.0606,\n         0.0261,  0.0027,  0.0577,  0.0326,  0.0393,  0.0564,  0.0790,  0.0431,\n         0.0182, -0.0490,  0.0253,  0.0623,  0.0407,  0.0242,  0.0562,  0.0565,\n        -0.0273, -0.0581, -0.0764,  0.0097,  0.0738,  0.0623, -0.0461,  0.0395,\n        -0.0720, -0.0396, -0.0545, -0.0644, -0.0572, -0.0604, -0.0361, -0.0736,\n         0.0563, -0.0186,  0.0774,  0.0538,  0.0039, -0.0085, -0.0603,  0.0573],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-5.2228e-02,  3.7329e-02, -7.7349e-02, -8.1129e-02, -1.9509e-02,\n          2.7640e-03,  1.3332e-03,  7.7228e-03, -5.8318e-02,  4.5343e-02,\n          2.0858e-02,  7.8550e-02, -1.1785e-02,  1.3944e-02, -2.3567e-02,\n          2.1734e-02, -7.5171e-02,  2.3829e-02,  6.7846e-02, -4.7273e-02,\n          7.7095e-02,  8.1577e-02,  2.7521e-03,  7.6080e-02,  2.1058e-02,\n         -2.3114e-02, -6.4951e-02, -6.5871e-02, -6.7935e-02,  5.0092e-02,\n          6.0751e-02,  8.2697e-02,  8.6149e-02,  5.0482e-02, -1.2436e-02,\n          8.5820e-02,  5.1939e-02, -8.3322e-02,  2.7187e-02, -1.8662e-02,\n         -2.2398e-02,  3.0161e-02,  4.1220e-02,  4.5366e-02,  6.4996e-02,\n         -6.6891e-02,  2.7804e-02, -5.6127e-02,  3.8592e-02,  2.3571e-02,\n         -5.8740e-02,  6.9550e-03,  2.5492e-02, -1.3534e-02, -6.5950e-02,\n          5.2092e-03, -8.4712e-02,  4.4108e-02, -4.9188e-02,  1.2317e-02,\n         -7.2920e-03,  6.8393e-02, -3.9247e-02,  5.6254e-02, -3.5521e-02,\n          4.1119e-02,  6.9723e-02,  5.2432e-02, -4.7468e-02,  8.7887e-02,\n          2.5981e-02, -1.6369e-02,  1.7199e-02, -2.2043e-02, -8.1416e-02,\n          5.9039e-02, -1.5346e-02, -2.2675e-02, -2.8984e-02,  5.7061e-02,\n          1.3812e-02,  6.9209e-02, -1.6499e-02,  1.5857e-02, -7.2339e-02,\n          4.7784e-02, -3.7990e-02, -2.7470e-02, -1.4244e-02,  4.8772e-02,\n          1.4287e-03,  6.1429e-03,  4.5875e-02,  1.0392e-02,  7.3680e-02,\n          7.4054e-02, -2.2529e-02, -5.5089e-02,  6.3188e-02, -6.3433e-02,\n         -5.4565e-02,  8.5964e-02, -4.6464e-02,  6.2858e-02,  2.6771e-03,\n         -1.9190e-02, -8.3953e-02,  5.0966e-02, -3.4752e-02,  2.8541e-02,\n         -7.8290e-02,  7.9255e-02, -7.8618e-02,  2.8181e-02,  8.3822e-02,\n         -8.8384e-02, -7.6839e-02, -6.6110e-02,  6.8299e-02, -5.3902e-03,\n          4.7293e-02, -1.6138e-02, -6.0783e-02,  5.1341e-02, -2.6967e-02,\n          8.3717e-02,  8.0336e-02,  7.5719e-02],\n        [ 5.5499e-02, -1.8495e-02, -2.3282e-02,  5.0214e-03,  4.9095e-03,\n          1.7927e-02,  1.2747e-02,  5.6674e-02,  7.3666e-02,  5.1893e-02,\n          3.1373e-02,  7.5189e-02,  7.4163e-02, -8.7299e-02, -6.1497e-02,\n         -4.5475e-02, -5.9381e-02, -5.1537e-02, -4.2022e-02,  3.6510e-02,\n          7.4833e-02, -8.1750e-02,  5.5057e-02, -7.3974e-02,  3.4413e-02,\n          5.8726e-02, -5.5465e-02,  4.8500e-02, -4.7376e-02,  2.7661e-02,\n          1.1128e-02,  5.4957e-02,  5.7639e-02,  6.0264e-02, -7.4616e-02,\n          1.3821e-02, -7.6471e-02,  4.3905e-03,  1.4910e-02, -1.5062e-02,\n         -7.9345e-02,  2.8208e-02, -6.5994e-03,  5.1449e-02,  1.0091e-02,\n          6.9290e-02,  8.6120e-02, -5.4438e-02,  8.6632e-02,  3.3699e-02,\n         -2.5111e-03,  3.4960e-02,  4.3739e-02, -1.7374e-02, -7.1721e-02,\n          6.8804e-02,  5.4464e-04,  5.9961e-04,  7.9147e-02,  3.8560e-03,\n          3.2744e-03, -2.4936e-02,  5.5541e-02, -1.5965e-02, -8.6224e-02,\n          7.2228e-02,  2.5645e-02, -5.5498e-02,  4.5182e-02, -7.7124e-02,\n         -6.2886e-02,  3.4556e-02, -3.3209e-02,  1.4733e-02, -7.5466e-02,\n          5.3629e-02, -1.8737e-02,  2.1852e-02, -3.1206e-02, -2.3291e-02,\n          5.6879e-02, -7.0988e-02,  6.0846e-02,  1.0602e-02, -6.0128e-02,\n         -1.6959e-02,  6.7071e-02, -4.4362e-02, -7.2359e-02,  7.3248e-02,\n         -8.5052e-02,  4.3704e-03, -2.6136e-02,  1.3451e-02, -4.8529e-02,\n          6.2613e-02, -4.9193e-02,  1.4192e-02,  8.6709e-03, -6.1427e-02,\n          3.6797e-03,  4.4422e-02,  7.4599e-02, -5.7335e-02, -1.7567e-02,\n          8.6613e-02, -1.9690e-02,  7.0496e-02,  4.1562e-02,  5.1012e-02,\n         -6.0890e-02,  6.7249e-02,  7.0380e-02, -2.4012e-02, -7.6103e-02,\n         -2.3586e-02,  3.4942e-02,  8.1703e-02, -8.0645e-02, -4.7856e-02,\n          7.1871e-02,  5.5535e-02, -3.4779e-02,  7.3566e-02, -7.3222e-02,\n          5.0276e-02, -2.7190e-02, -4.4955e-02],\n        [ 8.2028e-05,  6.7229e-02, -5.3377e-02,  2.4825e-02,  5.5291e-02,\n         -2.6744e-02, -7.2027e-02,  4.0012e-02, -7.6570e-02, -5.7804e-02,\n         -1.0843e-02, -6.1617e-03, -6.9285e-02,  6.1142e-02, -2.6328e-02,\n          8.1555e-02, -5.3328e-02,  1.2289e-02, -3.9080e-02,  7.2144e-02,\n         -1.4743e-02, -3.4145e-02, -8.4653e-02,  7.7073e-02, -8.1623e-02,\n         -7.9579e-02,  6.4756e-02,  8.8356e-02, -5.8715e-02, -3.6605e-02,\n          8.2672e-02,  6.6061e-02,  1.8619e-02, -6.4067e-02,  1.8929e-02,\n         -7.9809e-02,  6.7375e-02, -9.5712e-04,  2.1736e-02, -4.0640e-02,\n          6.9987e-02, -9.6026e-03,  7.9186e-02,  7.4790e-02,  9.7133e-03,\n          2.1996e-02,  8.4927e-02, -3.5557e-02,  1.9590e-02, -8.5185e-02,\n          6.1441e-02, -2.9835e-02, -2.7310e-02, -8.1968e-03,  6.7802e-02,\n          5.1698e-02, -2.7438e-02,  5.5678e-03,  5.4310e-02,  4.4430e-02,\n         -7.3109e-02,  4.1933e-02,  7.9317e-02,  5.5123e-03, -4.0335e-02,\n          5.1799e-02, -8.0739e-02, -5.7569e-02, -1.1422e-02, -6.5322e-02,\n         -5.6020e-02, -2.1048e-02, -7.6900e-02,  6.1731e-02, -9.4726e-04,\n          5.8283e-02, -7.6710e-02, -2.6597e-02,  1.7530e-02,  6.6365e-02,\n         -5.1687e-02,  6.0800e-02,  3.1645e-02,  2.5778e-02,  8.3801e-02,\n          8.3831e-02,  2.9603e-02,  8.7300e-02,  9.8702e-03, -9.5149e-03,\n          6.3353e-03, -1.2122e-02,  3.0480e-02, -7.5556e-02,  4.8985e-02,\n          7.9277e-02, -7.6074e-02,  8.4101e-02,  4.4992e-02,  4.2608e-03,\n         -6.9153e-02, -3.1248e-02, -2.9186e-02,  8.2953e-02, -7.8736e-02,\n         -6.8744e-02, -1.9514e-02,  5.3707e-02,  1.5109e-02, -7.6477e-02,\n          6.4048e-02,  5.6157e-02,  5.7342e-02, -5.6131e-02,  1.7574e-02,\n          7.7734e-02, -1.4802e-02,  4.2883e-02, -5.9938e-02, -1.2289e-02,\n          6.5848e-02,  8.4030e-02, -6.7591e-02, -1.3313e-02,  4.2660e-02,\n          3.5938e-02,  5.7829e-02, -4.7499e-02],\n        [ 3.0753e-02, -6.1668e-02,  6.7369e-02, -7.8175e-02,  6.1228e-02,\n         -5.0717e-02,  8.6933e-02, -1.1731e-02,  6.6160e-04,  7.2493e-02,\n         -7.3762e-02, -2.5424e-02, -5.8534e-02, -1.7145e-02, -2.5453e-02,\n         -2.1319e-02,  4.1547e-02, -8.7656e-03, -6.3760e-02, -7.0393e-02,\n         -3.8514e-02,  4.1832e-02,  1.6180e-02, -6.1880e-02, -2.5014e-02,\n          8.7483e-02,  7.3773e-02, -6.1088e-02,  4.5352e-02, -2.9619e-05,\n          2.1125e-02, -8.4933e-03, -7.5099e-02,  8.1149e-02,  7.1838e-02,\n          1.3826e-02, -8.1070e-02, -2.4488e-02, -1.9604e-02,  6.9577e-02,\n         -2.3080e-02, -6.1031e-03,  2.0211e-02, -5.8648e-02, -8.4973e-02,\n         -8.3227e-02,  1.6523e-02,  7.6091e-02, -6.2951e-02, -4.7292e-02,\n         -2.3216e-02,  2.9243e-02,  3.4730e-02,  1.6087e-02, -2.7734e-02,\n         -6.0498e-02, -5.0740e-02,  3.3887e-02,  3.7899e-02,  2.7225e-02,\n         -2.5514e-02,  2.1253e-02, -4.3383e-03,  5.4366e-02,  2.5439e-02,\n          8.1863e-02,  1.4273e-02,  7.9701e-02,  2.1752e-02,  6.7514e-02,\n          6.1242e-02,  5.8428e-02,  3.1492e-02, -2.1897e-02, -8.7990e-03,\n         -5.8318e-02, -3.9031e-02, -6.5725e-02, -4.5741e-02,  5.6301e-02,\n         -7.2207e-02, -2.6533e-02, -2.8111e-02, -4.3553e-02, -5.7501e-02,\n         -6.0258e-03,  3.0589e-02, -7.6134e-02,  1.6292e-02, -4.0386e-02,\n         -6.4613e-02,  5.5547e-02, -9.9982e-04,  8.5597e-02, -2.7561e-02,\n         -2.6885e-02, -3.4308e-02,  4.0412e-02,  2.8218e-02, -4.5864e-02,\n         -3.4320e-03,  1.8083e-03, -5.2776e-03, -2.5866e-02, -3.3089e-03,\n          2.9746e-02,  6.0750e-02, -5.0580e-02, -6.3028e-02, -2.8483e-02,\n          7.5684e-02,  5.8893e-02, -1.7399e-02, -6.5997e-02, -3.0538e-02,\n         -7.6479e-02,  7.9795e-02, -6.3730e-02, -2.6250e-02,  7.9018e-02,\n         -7.7387e-03, -7.2283e-02, -2.4693e-02, -5.1592e-02,  2.5385e-02,\n         -3.2225e-02,  4.2816e-03,  1.6579e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0834,  0.0825,  0.0284, -0.0843], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x7f3122bf6dd0>":	{
                    "aux_buf_size":	5000,
                    "aux_buffer":	{
                        "act_buf":	"[0 0 0 ... 0 0 0]",
                        "done_buf":	"[False False False ... False False False]",
                        "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                        "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                        "timestamps":	"[0 0 0 ... 0 0 0]"
                    },
                    "aux_ptr":	0,
                    "capacity":	50000,
                    "current_segment":	0,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	250,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "sample_decay":	0.8,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0456,  0.1205, -0.2534,  0.0752,  0.0460,  0.1424, -0.3417, -0.0496,\n        -0.0144,  0.2359, -0.0101, -0.3289, -0.3469,  0.1046, -0.1301,  0.1709,\n         0.0576, -0.2520, -0.2073, -0.1581,  0.2176,  0.1700,  0.0178, -0.1589,\n        -0.2083, -0.2493,  0.0106, -0.1925, -0.1052, -0.0347, -0.1639,  0.0134,\n         0.1289,  0.0927,  0.0794, -0.3081, -0.3267, -0.1741,  0.2414,  0.1315,\n        -0.3166,  0.2356, -0.2879, -0.2487,  0.2231, -0.1114,  0.2666, -0.3367,\n        -0.2963, -0.1462,  0.1478,  0.2250,  0.2751, -0.0355,  0.2985, -0.1477,\n         0.1828, -0.1451,  0.1823, -0.1231,  0.1325, -0.1449, -0.1627,  0.0994,\n        -0.3408, -0.2821, -0.1740, -0.0136, -0.0659,  0.3474,  0.0097, -0.1359,\n        -0.1178,  0.1077,  0.0997,  0.2720,  0.2511,  0.2355,  0.2536,  0.1320,\n         0.0891,  0.1187,  0.2199, -0.0110, -0.2117, -0.0799, -0.1989, -0.3047,\n        -0.3317,  0.2140,  0.0886,  0.3289, -0.3238, -0.2176,  0.1109, -0.0066,\n        -0.2102,  0.1768,  0.0515, -0.0060, -0.2272, -0.0256,  0.0217, -0.2487,\n         0.0752, -0.0314, -0.0933, -0.1076, -0.0153, -0.2114, -0.3325,  0.0460,\n         0.3530, -0.1460, -0.2940, -0.1841, -0.2339,  0.3481, -0.0508,  0.2991,\n         0.0437, -0.0928, -0.2818, -0.1202,  0.2107,  0.0377, -0.1452,  0.3459],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.1475,  0.2923,  0.0692,  ..., -0.0692, -0.3057,  0.0122],\n        [ 0.3142, -0.2870,  0.2147,  ...,  0.0248,  0.0928, -0.1868],\n        [ 0.1474, -0.3465,  0.0094,  ...,  0.0086, -0.2342,  0.1407],\n        ...,\n        [-0.0601, -0.0427,  0.1953,  ..., -0.2190,  0.0999, -0.3494],\n        [-0.0636, -0.0272, -0.1643,  ...,  0.0713, -0.2885,  0.1655],\n        [-0.1538,  0.1333,  0.1858,  ...,  0.1776,  0.1140, -0.0201]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0179,  0.0467, -0.0281, -0.0744, -0.0497,  0.0154, -0.0753,  0.0479,\n         0.0526,  0.0004,  0.0238,  0.0311, -0.0642,  0.0049,  0.0510,  0.0686,\n        -0.0104, -0.0632,  0.0871,  0.0652,  0.0508,  0.0740, -0.0696, -0.0383,\n         0.0665,  0.0205, -0.0711, -0.0082, -0.0139, -0.0833, -0.0136,  0.0579,\n         0.0098,  0.0019,  0.0643,  0.0453,  0.0572, -0.0796, -0.0484,  0.0170,\n         0.0230,  0.0824,  0.0683, -0.0227, -0.0485,  0.0598, -0.0161,  0.0599,\n         0.0578, -0.0633, -0.0083, -0.0485, -0.0159, -0.0169, -0.0799, -0.0222,\n         0.0466, -0.0305,  0.0619, -0.0414, -0.0694, -0.0657,  0.0525,  0.0167,\n         0.0844,  0.0663, -0.0876,  0.0434,  0.0058,  0.0118, -0.0602,  0.0797,\n         0.0089, -0.0511,  0.0031, -0.0230,  0.0529, -0.0648,  0.0472, -0.0440,\n        -0.0195, -0.0539,  0.0057, -0.0543, -0.0796,  0.0299,  0.0165,  0.0606,\n         0.0261,  0.0027,  0.0577,  0.0326,  0.0393,  0.0564,  0.0790,  0.0431,\n         0.0182, -0.0490,  0.0253,  0.0623,  0.0407,  0.0242,  0.0562,  0.0565,\n        -0.0273, -0.0581, -0.0764,  0.0097,  0.0738,  0.0623, -0.0461,  0.0395,\n        -0.0720, -0.0396, -0.0545, -0.0644, -0.0572, -0.0604, -0.0361, -0.0736,\n         0.0563, -0.0186,  0.0774,  0.0538,  0.0039, -0.0085, -0.0603,  0.0573],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0648,  0.0350, -0.0654,  ..., -0.0802, -0.0485,  0.0216],\n        [ 0.0784, -0.0360, -0.0294,  ...,  0.0761, -0.0869,  0.0741],\n        [ 0.0120, -0.0100, -0.0009,  ..., -0.0856,  0.0490, -0.0685],\n        ...,\n        [ 0.0080,  0.0746, -0.0561,  ..., -0.0492,  0.0300, -0.0692],\n        [-0.0024,  0.0223,  0.0675,  ...,  0.0834,  0.0421, -0.0287],\n        [-0.0571,  0.0208, -0.0194,  ..., -0.0369,  0.0590, -0.0048]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0834,  0.0825,  0.0284, -0.0843], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-5.2228e-02,  3.7329e-02, -7.7349e-02, -8.1129e-02, -1.9509e-02,\n          2.7640e-03,  1.3332e-03,  7.7228e-03, -5.8318e-02,  4.5343e-02,\n          2.0858e-02,  7.8550e-02, -1.1785e-02,  1.3944e-02, -2.3567e-02,\n          2.1734e-02, -7.5171e-02,  2.3829e-02,  6.7846e-02, -4.7273e-02,\n          7.7095e-02,  8.1577e-02,  2.7521e-03,  7.6080e-02,  2.1058e-02,\n         -2.3114e-02, -6.4951e-02, -6.5871e-02, -6.7935e-02,  5.0092e-02,\n          6.0751e-02,  8.2697e-02,  8.6149e-02,  5.0482e-02, -1.2436e-02,\n          8.5820e-02,  5.1939e-02, -8.3322e-02,  2.7187e-02, -1.8662e-02,\n         -2.2398e-02,  3.0161e-02,  4.1220e-02,  4.5366e-02,  6.4996e-02,\n         -6.6891e-02,  2.7804e-02, -5.6127e-02,  3.8592e-02,  2.3571e-02,\n         -5.8740e-02,  6.9550e-03,  2.5492e-02, -1.3534e-02, -6.5950e-02,\n          5.2092e-03, -8.4712e-02,  4.4108e-02, -4.9188e-02,  1.2317e-02,\n         -7.2920e-03,  6.8393e-02, -3.9247e-02,  5.6254e-02, -3.5521e-02,\n          4.1119e-02,  6.9723e-02,  5.2432e-02, -4.7468e-02,  8.7887e-02,\n          2.5981e-02, -1.6369e-02,  1.7199e-02, -2.2043e-02, -8.1416e-02,\n          5.9039e-02, -1.5346e-02, -2.2675e-02, -2.8984e-02,  5.7061e-02,\n          1.3812e-02,  6.9209e-02, -1.6499e-02,  1.5857e-02, -7.2339e-02,\n          4.7784e-02, -3.7990e-02, -2.7470e-02, -1.4244e-02,  4.8772e-02,\n          1.4287e-03,  6.1429e-03,  4.5875e-02,  1.0392e-02,  7.3680e-02,\n          7.4054e-02, -2.2529e-02, -5.5089e-02,  6.3188e-02, -6.3433e-02,\n         -5.4565e-02,  8.5964e-02, -4.6464e-02,  6.2858e-02,  2.6771e-03,\n         -1.9190e-02, -8.3953e-02,  5.0966e-02, -3.4752e-02,  2.8541e-02,\n         -7.8290e-02,  7.9255e-02, -7.8618e-02,  2.8181e-02,  8.3822e-02,\n         -8.8384e-02, -7.6839e-02, -6.6110e-02,  6.8299e-02, -5.3902e-03,\n          4.7293e-02, -1.6138e-02, -6.0783e-02,  5.1341e-02, -2.6967e-02,\n          8.3717e-02,  8.0336e-02,  7.5719e-02],\n        [ 5.5499e-02, -1.8495e-02, -2.3282e-02,  5.0214e-03,  4.9095e-03,\n          1.7927e-02,  1.2747e-02,  5.6674e-02,  7.3666e-02,  5.1893e-02,\n          3.1373e-02,  7.5189e-02,  7.4163e-02, -8.7299e-02, -6.1497e-02,\n         -4.5475e-02, -5.9381e-02, -5.1537e-02, -4.2022e-02,  3.6510e-02,\n          7.4833e-02, -8.1750e-02,  5.5057e-02, -7.3974e-02,  3.4413e-02,\n          5.8726e-02, -5.5465e-02,  4.8500e-02, -4.7376e-02,  2.7661e-02,\n          1.1128e-02,  5.4957e-02,  5.7639e-02,  6.0264e-02, -7.4616e-02,\n          1.3821e-02, -7.6471e-02,  4.3905e-03,  1.4910e-02, -1.5062e-02,\n         -7.9345e-02,  2.8208e-02, -6.5994e-03,  5.1449e-02,  1.0091e-02,\n          6.9290e-02,  8.6120e-02, -5.4438e-02,  8.6632e-02,  3.3699e-02,\n         -2.5111e-03,  3.4960e-02,  4.3739e-02, -1.7374e-02, -7.1721e-02,\n          6.8804e-02,  5.4464e-04,  5.9961e-04,  7.9147e-02,  3.8560e-03,\n          3.2744e-03, -2.4936e-02,  5.5541e-02, -1.5965e-02, -8.6224e-02,\n          7.2228e-02,  2.5645e-02, -5.5498e-02,  4.5182e-02, -7.7124e-02,\n         -6.2886e-02,  3.4556e-02, -3.3209e-02,  1.4733e-02, -7.5466e-02,\n          5.3629e-02, -1.8737e-02,  2.1852e-02, -3.1206e-02, -2.3291e-02,\n          5.6879e-02, -7.0988e-02,  6.0846e-02,  1.0602e-02, -6.0128e-02,\n         -1.6959e-02,  6.7071e-02, -4.4362e-02, -7.2359e-02,  7.3248e-02,\n         -8.5052e-02,  4.3704e-03, -2.6136e-02,  1.3451e-02, -4.8529e-02,\n          6.2613e-02, -4.9193e-02,  1.4192e-02,  8.6709e-03, -6.1427e-02,\n          3.6797e-03,  4.4422e-02,  7.4599e-02, -5.7335e-02, -1.7567e-02,\n          8.6613e-02, -1.9690e-02,  7.0496e-02,  4.1562e-02,  5.1012e-02,\n         -6.0890e-02,  6.7249e-02,  7.0380e-02, -2.4012e-02, -7.6103e-02,\n         -2.3586e-02,  3.4942e-02,  8.1703e-02, -8.0645e-02, -4.7856e-02,\n          7.1871e-02,  5.5535e-02, -3.4779e-02,  7.3566e-02, -7.3222e-02,\n          5.0276e-02, -2.7190e-02, -4.4955e-02],\n        [ 8.2028e-05,  6.7229e-02, -5.3377e-02,  2.4825e-02,  5.5291e-02,\n         -2.6744e-02, -7.2027e-02,  4.0012e-02, -7.6570e-02, -5.7804e-02,\n         -1.0843e-02, -6.1617e-03, -6.9285e-02,  6.1142e-02, -2.6328e-02,\n          8.1555e-02, -5.3328e-02,  1.2289e-02, -3.9080e-02,  7.2144e-02,\n         -1.4743e-02, -3.4145e-02, -8.4653e-02,  7.7073e-02, -8.1623e-02,\n         -7.9579e-02,  6.4756e-02,  8.8356e-02, -5.8715e-02, -3.6605e-02,\n          8.2672e-02,  6.6061e-02,  1.8619e-02, -6.4067e-02,  1.8929e-02,\n         -7.9809e-02,  6.7375e-02, -9.5712e-04,  2.1736e-02, -4.0640e-02,\n          6.9987e-02, -9.6026e-03,  7.9186e-02,  7.4790e-02,  9.7133e-03,\n          2.1996e-02,  8.4927e-02, -3.5557e-02,  1.9590e-02, -8.5185e-02,\n          6.1441e-02, -2.9835e-02, -2.7310e-02, -8.1968e-03,  6.7802e-02,\n          5.1698e-02, -2.7438e-02,  5.5678e-03,  5.4310e-02,  4.4430e-02,\n         -7.3109e-02,  4.1933e-02,  7.9317e-02,  5.5123e-03, -4.0335e-02,\n          5.1799e-02, -8.0739e-02, -5.7569e-02, -1.1422e-02, -6.5322e-02,\n         -5.6020e-02, -2.1048e-02, -7.6900e-02,  6.1731e-02, -9.4726e-04,\n          5.8283e-02, -7.6710e-02, -2.6597e-02,  1.7530e-02,  6.6365e-02,\n         -5.1687e-02,  6.0800e-02,  3.1645e-02,  2.5778e-02,  8.3801e-02,\n          8.3831e-02,  2.9603e-02,  8.7300e-02,  9.8702e-03, -9.5149e-03,\n          6.3353e-03, -1.2122e-02,  3.0480e-02, -7.5556e-02,  4.8985e-02,\n          7.9277e-02, -7.6074e-02,  8.4101e-02,  4.4992e-02,  4.2608e-03,\n         -6.9153e-02, -3.1248e-02, -2.9186e-02,  8.2953e-02, -7.8736e-02,\n         -6.8744e-02, -1.9514e-02,  5.3707e-02,  1.5109e-02, -7.6477e-02,\n          6.4048e-02,  5.6157e-02,  5.7342e-02, -5.6131e-02,  1.7574e-02,\n          7.7734e-02, -1.4802e-02,  4.2883e-02, -5.9938e-02, -1.2289e-02,\n          6.5848e-02,  8.4030e-02, -6.7591e-02, -1.3313e-02,  4.2660e-02,\n          3.5938e-02,  5.7829e-02, -4.7499e-02],\n        [ 3.0753e-02, -6.1668e-02,  6.7369e-02, -7.8175e-02,  6.1228e-02,\n         -5.0717e-02,  8.6933e-02, -1.1731e-02,  6.6160e-04,  7.2493e-02,\n         -7.3762e-02, -2.5424e-02, -5.8534e-02, -1.7145e-02, -2.5453e-02,\n         -2.1319e-02,  4.1547e-02, -8.7656e-03, -6.3760e-02, -7.0393e-02,\n         -3.8514e-02,  4.1832e-02,  1.6180e-02, -6.1880e-02, -2.5014e-02,\n          8.7483e-02,  7.3773e-02, -6.1088e-02,  4.5352e-02, -2.9619e-05,\n          2.1125e-02, -8.4933e-03, -7.5099e-02,  8.1149e-02,  7.1838e-02,\n          1.3826e-02, -8.1070e-02, -2.4488e-02, -1.9604e-02,  6.9577e-02,\n         -2.3080e-02, -6.1031e-03,  2.0211e-02, -5.8648e-02, -8.4973e-02,\n         -8.3227e-02,  1.6523e-02,  7.6091e-02, -6.2951e-02, -4.7292e-02,\n         -2.3216e-02,  2.9243e-02,  3.4730e-02,  1.6087e-02, -2.7734e-02,\n         -6.0498e-02, -5.0740e-02,  3.3887e-02,  3.7899e-02,  2.7225e-02,\n         -2.5514e-02,  2.1253e-02, -4.3383e-03,  5.4366e-02,  2.5439e-02,\n          8.1863e-02,  1.4273e-02,  7.9701e-02,  2.1752e-02,  6.7514e-02,\n          6.1242e-02,  5.8428e-02,  3.1492e-02, -2.1897e-02, -8.7990e-03,\n         -5.8318e-02, -3.9031e-02, -6.5725e-02, -4.5741e-02,  5.6301e-02,\n         -7.2207e-02, -2.6533e-02, -2.8111e-02, -4.3553e-02, -5.7501e-02,\n         -6.0258e-03,  3.0589e-02, -7.6134e-02,  1.6292e-02, -4.0386e-02,\n         -6.4613e-02,  5.5547e-02, -9.9982e-04,  8.5597e-02, -2.7561e-02,\n         -2.6885e-02, -3.4308e-02,  4.0412e-02,  2.8218e-02, -4.5864e-02,\n         -3.4320e-03,  1.8083e-03, -5.2776e-03, -2.5866e-02, -3.3089e-03,\n          2.9746e-02,  6.0750e-02, -5.0580e-02, -6.3028e-02, -2.8483e-02,\n          7.5684e-02,  5.8893e-02, -1.7399e-02, -6.5997e-02, -3.0538e-02,\n         -7.6479e-02,  7.9795e-02, -6.3730e-02, -2.6250e-02,  7.9018e-02,\n         -7.7387e-03, -7.2283e-02, -2.4693e-02, -5.1592e-02,  2.5385e-02,\n         -3.2225e-02,  4.2816e-03,  1.6579e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7f30a98ca610>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s387660000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s387660000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}