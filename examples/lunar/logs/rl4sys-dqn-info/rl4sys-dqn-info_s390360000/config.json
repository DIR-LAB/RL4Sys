{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0003,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s390360000"
    },
    "max_sample_age":	250,
    "q_lr":	0.0003,
    "sample_decay":	0.8,
    "seed":	390360000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7baa0651f2d0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0003,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2138, -0.0396,  0.0617, -0.1711,  0.1405, -0.2627,  0.1835, -0.1148,\n        -0.1761,  0.3343,  0.3021, -0.0587,  0.0103,  0.0424, -0.3115, -0.3132,\n        -0.3201,  0.0067, -0.1299,  0.3367,  0.2394,  0.1008, -0.1323, -0.2186,\n        -0.2031, -0.2455, -0.1562,  0.3279, -0.2066, -0.0044, -0.2549, -0.3245,\n        -0.1104,  0.0462,  0.1075,  0.2416,  0.2526, -0.1608, -0.1082, -0.0099,\n        -0.1802, -0.3150, -0.1820, -0.0311, -0.3320,  0.1311,  0.1115, -0.2313,\n        -0.0463, -0.0234, -0.2531, -0.1511, -0.2851,  0.1922, -0.2903, -0.3063,\n        -0.1963,  0.0865, -0.2953, -0.2160, -0.1927, -0.0192,  0.0635,  0.0454,\n        -0.0271,  0.2226,  0.2550,  0.2456,  0.1253,  0.0119, -0.1457,  0.3356,\n         0.1701,  0.3050, -0.3257, -0.0422,  0.0364, -0.1484, -0.2391, -0.2931,\n         0.2812, -0.2781,  0.1930,  0.2095, -0.2883, -0.0305,  0.3182, -0.0155,\n         0.3228, -0.2594, -0.1078,  0.1940, -0.1554,  0.1791, -0.1655,  0.1576,\n        -0.2535, -0.0072, -0.1667,  0.1903, -0.1557, -0.0769, -0.0079, -0.1536,\n        -0.0568, -0.0486,  0.0786,  0.1222,  0.0597, -0.2321, -0.2754,  0.1878,\n        -0.3518, -0.1392, -0.1955,  0.1109,  0.2539,  0.1299, -0.0606, -0.2884,\n        -0.3384,  0.1297,  0.1540, -0.0835, -0.1967, -0.2957, -0.3321, -0.0687],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2151, -0.1270,  0.2894,  ..., -0.0831, -0.0919, -0.1668],\n        [-0.2098, -0.0909, -0.1444,  ...,  0.0508, -0.2112,  0.0073],\n        [ 0.2803,  0.1562, -0.2034,  ...,  0.1557, -0.0283,  0.0084],\n        ...,\n        [ 0.1311,  0.3062,  0.1319,  ...,  0.0802, -0.1331, -0.1920],\n        [-0.3451,  0.2046, -0.1815,  ...,  0.2421, -0.0948, -0.1628],\n        [ 0.2357, -0.2881, -0.1073,  ..., -0.0442,  0.0388, -0.3231]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-1.6024e-02, -4.9002e-02,  7.1738e-02,  1.0521e-02,  7.9192e-02,\n         5.5050e-02, -1.4890e-03,  3.4034e-02,  2.2194e-02,  6.4223e-02,\n        -6.2810e-02, -2.4095e-02, -4.2698e-02,  4.6155e-02, -8.5719e-02,\n        -3.9551e-02, -6.0398e-02,  1.6729e-02,  2.5321e-02,  5.9965e-02,\n         2.7609e-03,  5.2006e-02, -2.8459e-02,  3.6497e-02,  7.9077e-02,\n        -5.3360e-03, -4.8315e-02,  7.9000e-02,  8.5902e-02,  3.3180e-02,\n         6.7012e-02,  2.3762e-02,  5.9905e-02,  4.3017e-02, -7.8556e-02,\n        -3.4760e-02, -2.9446e-02, -3.0616e-02,  7.3579e-02, -8.5127e-02,\n        -6.7329e-02, -6.4794e-02,  3.5424e-02, -8.8356e-02, -2.2966e-02,\n         4.5767e-02, -1.4142e-02, -2.8659e-02,  1.3980e-02, -8.5440e-02,\n         5.3092e-02, -4.0806e-03, -3.9689e-03,  2.4261e-02, -1.3870e-02,\n        -4.2355e-02,  2.8960e-02, -8.5847e-02, -3.2988e-02,  2.0239e-02,\n         7.3954e-02, -5.2945e-02,  2.2441e-02, -2.9642e-02,  7.6330e-02,\n        -6.4454e-02, -7.9639e-02, -6.6307e-02,  1.2741e-02,  1.6168e-02,\n        -7.1664e-02, -5.9943e-05,  2.1152e-02,  5.8559e-02, -4.4094e-02,\n        -7.6062e-02,  8.1963e-02, -1.3290e-02, -2.3210e-02,  5.5489e-02,\n        -4.3320e-02,  6.2566e-02,  7.2880e-04, -8.3509e-02, -3.2006e-02,\n         5.5353e-02, -9.6792e-03,  3.2559e-02, -7.8102e-02,  6.6697e-02,\n        -7.3108e-02,  2.4708e-02, -8.1897e-02, -3.1386e-02, -1.3237e-03,\n         4.7449e-02,  2.5741e-02,  3.8790e-02, -1.9480e-03, -3.3206e-02,\n        -3.4273e-02, -8.0767e-02, -2.7357e-02, -4.9134e-02, -5.2344e-02,\n        -7.1076e-02,  7.5541e-02,  3.3144e-02, -1.5222e-02, -3.2331e-02,\n        -5.0261e-02,  3.6920e-02, -5.5113e-02, -2.0702e-02, -7.2617e-02,\n         2.9012e-02, -8.0948e-03,  8.0128e-02, -4.6479e-02, -2.7896e-02,\n         8.5289e-02,  4.1787e-02, -7.1070e-02, -2.2709e-02, -5.1662e-02,\n         6.8915e-02,  5.6839e-02, -4.7454e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0507,  0.0383, -0.0457,  ..., -0.0062, -0.0569,  0.0808],\n        [-0.0192, -0.0006,  0.0041,  ..., -0.0373, -0.0100,  0.0050],\n        [ 0.0880,  0.0764, -0.0782,  ..., -0.0285, -0.0491, -0.0457],\n        ...,\n        [-0.0234, -0.0082,  0.0518,  ...,  0.0568,  0.0648, -0.0076],\n        [-0.0784, -0.0330, -0.0440,  ..., -0.0526, -0.0290,  0.0602],\n        [ 0.0507,  0.0216,  0.0285,  ...,  0.0235,  0.0598, -0.0560]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0410, -0.0824,  0.0348, -0.0113], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 7.0390e-02, -1.4278e-02,  7.4868e-02,  5.4089e-02,  3.0257e-02,\n         -4.9074e-02, -2.7283e-02,  3.7674e-03, -1.5370e-03,  6.2191e-02,\n         -7.8710e-02, -8.0761e-02,  2.5200e-03, -6.2080e-02, -7.3777e-02,\n          7.7156e-02, -4.1313e-02, -2.9981e-03,  1.6713e-02,  1.2250e-02,\n          8.6156e-02,  3.1530e-02,  8.1634e-02,  5.5439e-02,  8.7525e-02,\n          6.0149e-02,  1.9615e-03, -5.0618e-02, -6.8941e-02,  3.4260e-02,\n         -7.1976e-02,  5.6496e-02, -6.1775e-02,  3.6537e-02,  4.6100e-02,\n         -8.3585e-02, -4.6567e-02,  9.0499e-03,  4.0692e-02,  5.5495e-02,\n         -6.4516e-02, -3.1258e-02,  1.7628e-02,  6.1292e-02, -3.5457e-02,\n          8.0555e-02,  2.5443e-02, -3.0407e-02,  8.3138e-02, -3.4355e-02,\n         -6.1701e-02, -3.5946e-02,  9.0684e-03, -5.5585e-02,  1.4205e-02,\n         -8.5017e-02, -1.6228e-02, -5.3913e-02,  2.8364e-02, -6.9519e-02,\n         -7.7319e-02, -6.9518e-03, -1.0580e-02,  7.7579e-02,  7.2597e-02,\n          7.4871e-03,  7.0590e-02, -2.5792e-03,  6.6164e-02, -2.9040e-02,\n         -1.7238e-04, -8.2049e-02, -1.9128e-02,  2.9961e-02, -1.1901e-02,\n          3.5368e-02, -4.7354e-02, -5.7708e-02, -4.4035e-02, -2.6910e-02,\n         -9.9444e-03, -5.3186e-02,  1.0430e-02, -1.8859e-02,  2.3305e-02,\n          7.0070e-02,  4.3443e-02,  4.2916e-02,  2.1012e-02, -3.2667e-03,\n          7.4652e-02,  3.5872e-02,  6.3284e-02, -4.1000e-02, -4.6340e-02,\n         -3.8679e-02,  6.4025e-02,  7.5977e-02, -6.3627e-02,  2.2268e-03,\n         -5.3433e-02,  6.1865e-03,  5.1742e-02, -3.7243e-02,  6.9540e-02,\n         -7.0369e-02, -6.3083e-05,  8.7954e-02,  1.2879e-02, -8.5366e-02,\n         -6.0338e-02, -8.2297e-02,  1.6638e-02,  8.8025e-02,  4.3269e-02,\n          7.4070e-02, -1.0042e-02,  4.9333e-02, -6.8758e-02, -1.5630e-02,\n         -5.5243e-02,  3.2562e-02,  5.1948e-02, -3.8959e-03,  7.5444e-03,\n         -7.4555e-02, -3.3165e-02,  3.1818e-02],\n        [ 6.6870e-02,  1.9064e-02,  8.1605e-02,  3.3526e-02, -6.2951e-02,\n          6.6390e-02,  6.1317e-02,  1.6226e-02,  6.7903e-03, -3.8207e-02,\n         -1.1475e-03, -4.8034e-02, -3.4751e-02, -6.2763e-02, -1.7698e-02,\n         -3.8351e-02,  8.6156e-02,  4.1136e-02, -3.7249e-02,  5.6499e-02,\n         -1.8934e-02, -3.9456e-03, -3.6567e-02, -1.2353e-02,  1.2047e-02,\n          9.5005e-03,  5.9690e-02, -1.0337e-02, -4.6565e-02,  2.5736e-03,\n         -6.0530e-02,  5.8932e-02,  4.5640e-02,  6.3530e-02,  7.6830e-02,\n         -1.5895e-02,  9.6359e-03,  3.6701e-02,  1.7491e-03, -4.3246e-02,\n          1.5836e-03,  8.1786e-05,  3.7368e-02,  8.4889e-02, -6.8407e-02,\n          4.2919e-02, -3.0219e-02,  7.4917e-02,  2.0465e-02,  1.7579e-02,\n         -4.6643e-02,  5.7924e-02, -2.1827e-02, -3.0921e-02,  5.1351e-02,\n         -4.6014e-02, -4.2058e-03, -5.4247e-02,  4.3903e-02, -1.6038e-02,\n         -5.6008e-02, -8.7640e-02,  5.3796e-02, -2.5871e-02, -7.2213e-02,\n          4.2165e-03, -3.8228e-02,  3.8066e-02,  5.7549e-02, -6.6374e-02,\n          3.8634e-02,  3.0192e-02,  1.7232e-02,  7.1584e-02,  3.6339e-02,\n         -4.8427e-02, -2.2037e-02,  6.3173e-02,  2.2172e-02, -6.7713e-02,\n          6.9298e-02,  6.7214e-02,  3.4895e-02, -8.4214e-02,  7.3981e-03,\n         -6.0910e-02,  2.1104e-02,  8.2950e-02,  8.1265e-02, -1.2263e-02,\n         -7.4736e-02, -2.9284e-02, -3.9737e-02, -7.8104e-02,  4.2287e-02,\n         -7.4217e-02, -5.7870e-02, -8.7585e-02, -2.3887e-03,  3.3038e-02,\n         -4.8737e-02,  5.2733e-02,  3.4324e-02,  8.4352e-02,  7.6470e-02,\n          8.7994e-02, -4.6703e-02,  1.0603e-02, -4.5577e-02,  6.7546e-02,\n         -3.9356e-02, -3.9293e-03,  5.0703e-02,  2.0978e-02,  4.8732e-02,\n         -8.4545e-02, -4.0914e-02,  1.2345e-02,  7.3050e-02,  2.7526e-02,\n         -1.7505e-02, -8.1804e-02, -5.0825e-02,  8.5331e-03, -3.5197e-02,\n         -2.3367e-03,  2.2909e-02,  8.2667e-02],\n        [ 5.4955e-02, -1.3879e-02,  4.3834e-02,  1.6390e-02,  2.8424e-02,\n          4.5105e-02,  2.3072e-02, -3.1025e-02, -6.7649e-02,  5.3227e-02,\n          3.6609e-02, -6.6260e-02,  1.9006e-02,  5.7314e-02,  6.4614e-02,\n         -4.9567e-03,  8.7590e-02, -5.2501e-02,  5.2617e-02,  1.1394e-03,\n          2.2143e-02, -5.7019e-02, -8.3510e-02, -4.3092e-02,  5.3248e-02,\n          4.0958e-02, -6.4911e-02,  6.5180e-02,  6.6350e-02, -3.9737e-02,\n         -2.6603e-02,  1.8418e-02,  1.6957e-02, -4.9411e-03,  1.2930e-02,\n         -9.1211e-03,  6.3412e-02,  7.0138e-02,  4.1337e-02, -4.5168e-02,\n          8.7952e-02,  6.0252e-02, -6.3922e-02,  8.1635e-02,  4.1778e-02,\n          5.1014e-02,  3.7903e-02, -1.0107e-02, -5.4656e-02,  6.2165e-02,\n         -5.2962e-02,  5.1480e-02, -1.0031e-02,  7.1690e-02,  2.0735e-02,\n         -3.0921e-02,  4.1226e-02, -7.4264e-02, -4.5866e-02,  4.0452e-02,\n          5.9951e-02,  7.8161e-02, -6.8335e-02,  3.1012e-02,  2.1805e-02,\n         -3.8140e-02,  1.3861e-02, -2.0483e-02,  6.9922e-02,  4.6598e-02,\n         -6.8185e-02, -4.9474e-02, -3.3501e-02, -4.8515e-02,  6.6229e-02,\n          8.8291e-02, -3.2803e-02,  4.3160e-02,  4.4890e-02,  5.4653e-02,\n         -1.0930e-02,  1.4283e-02,  6.2331e-02,  3.6666e-02,  1.0305e-02,\n         -3.4782e-02, -7.6515e-02, -7.0488e-02,  6.6773e-02, -5.9051e-02,\n          4.3703e-02, -4.4898e-02,  4.3995e-02,  7.6529e-02, -3.3289e-02,\n         -7.8956e-03, -2.5025e-02,  4.5015e-02,  6.3323e-02, -3.9716e-02,\n         -5.6027e-02, -8.0819e-02, -6.0840e-03,  5.9611e-02,  6.2422e-02,\n         -7.1339e-02,  9.1379e-03, -1.3289e-03, -4.5636e-02, -7.9153e-03,\n         -6.5879e-02, -5.0174e-02,  2.0995e-02, -1.3242e-02,  7.6117e-02,\n          2.6919e-02,  8.6872e-02, -4.5771e-02,  6.8642e-02,  4.4345e-03,\n         -7.9544e-02,  6.7806e-02, -2.8261e-02,  7.8739e-02, -3.9279e-02,\n          3.0168e-02, -1.5098e-02,  9.2657e-03],\n        [ 5.1687e-02,  4.3176e-02, -8.5462e-02,  2.8925e-02,  7.8815e-02,\n         -5.8857e-03,  4.6070e-02, -2.2413e-02,  4.5290e-02,  1.8906e-02,\n         -4.9133e-02,  7.1550e-02, -8.6494e-02, -7.4103e-02, -3.0760e-02,\n          5.2279e-02, -5.5586e-02, -3.6187e-02, -1.6249e-02,  2.3659e-03,\n         -7.2266e-02, -5.6605e-02, -7.3092e-02, -6.4671e-02,  6.5219e-02,\n          5.8626e-02,  2.2279e-02, -6.6831e-02, -7.1789e-02, -5.9781e-02,\n         -4.7406e-02,  3.3137e-02,  1.2834e-02,  3.8144e-02, -3.4083e-02,\n          4.5674e-02, -2.7419e-02, -2.3456e-02,  2.4198e-02, -1.8163e-02,\n         -5.4082e-02, -5.5256e-02,  4.3396e-02,  7.6021e-02,  1.2614e-02,\n         -6.3472e-02,  6.2159e-02,  8.1974e-02, -3.1359e-02, -6.2071e-02,\n          5.5359e-02,  1.3536e-02,  5.4866e-02, -5.3736e-02,  9.0250e-04,\n          7.9103e-02, -8.2490e-02, -6.7410e-02, -1.2758e-02, -7.2281e-02,\n         -8.3217e-02,  8.2816e-02,  8.2750e-02,  4.9994e-03, -8.2015e-02,\n         -1.9791e-02,  9.3818e-03,  8.4762e-02,  2.7971e-04,  3.4676e-03,\n          8.3927e-02, -9.7233e-03,  8.1753e-02, -1.7146e-02,  4.0433e-02,\n          1.8445e-02,  6.6945e-02,  7.8598e-02, -7.2123e-02, -3.0010e-02,\n          6.1126e-02, -6.0090e-03, -6.8623e-02, -5.7729e-03,  3.1394e-02,\n         -6.0408e-02,  1.8918e-02, -1.8532e-02,  7.6972e-02, -7.4389e-05,\n          4.8707e-02, -8.3390e-02,  4.4726e-02,  5.7389e-02, -8.1342e-02,\n          5.5852e-02, -1.6210e-02,  4.6484e-02,  7.7339e-02,  3.1656e-02,\n          1.5800e-02,  6.2298e-04, -4.9246e-02, -8.8156e-02,  4.7384e-02,\n          2.4810e-02,  3.6829e-02, -1.4796e-03,  1.1876e-02, -1.5953e-02,\n          5.0393e-03,  4.7295e-02, -1.7811e-02,  4.1233e-02, -3.2473e-02,\n          3.9558e-02, -2.6146e-02,  2.8130e-02,  1.2748e-02, -5.4982e-03,\n          2.0093e-02,  4.0250e-02,  2.3068e-02,  1.0509e-02,  4.0125e-02,\n         -6.3005e-02, -2.0295e-02,  4.2436e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2151, -0.1270,  0.2894,  ..., -0.0831, -0.0919, -0.1668],\n        [-0.2098, -0.0909, -0.1444,  ...,  0.0508, -0.2112,  0.0073],\n        [ 0.2803,  0.1562, -0.2034,  ...,  0.1557, -0.0283,  0.0084],\n        ...,\n        [ 0.1311,  0.3062,  0.1319,  ...,  0.0802, -0.1331, -0.1920],\n        [-0.3451,  0.2046, -0.1815,  ...,  0.2421, -0.0948, -0.1628],\n        [ 0.2357, -0.2881, -0.1073,  ..., -0.0442,  0.0388, -0.3231]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2138, -0.0396,  0.0617, -0.1711,  0.1405, -0.2627,  0.1835, -0.1148,\n        -0.1761,  0.3343,  0.3021, -0.0587,  0.0103,  0.0424, -0.3115, -0.3132,\n        -0.3201,  0.0067, -0.1299,  0.3367,  0.2394,  0.1008, -0.1323, -0.2186,\n        -0.2031, -0.2455, -0.1562,  0.3279, -0.2066, -0.0044, -0.2549, -0.3245,\n        -0.1104,  0.0462,  0.1075,  0.2416,  0.2526, -0.1608, -0.1082, -0.0099,\n        -0.1802, -0.3150, -0.1820, -0.0311, -0.3320,  0.1311,  0.1115, -0.2313,\n        -0.0463, -0.0234, -0.2531, -0.1511, -0.2851,  0.1922, -0.2903, -0.3063,\n        -0.1963,  0.0865, -0.2953, -0.2160, -0.1927, -0.0192,  0.0635,  0.0454,\n        -0.0271,  0.2226,  0.2550,  0.2456,  0.1253,  0.0119, -0.1457,  0.3356,\n         0.1701,  0.3050, -0.3257, -0.0422,  0.0364, -0.1484, -0.2391, -0.2931,\n         0.2812, -0.2781,  0.1930,  0.2095, -0.2883, -0.0305,  0.3182, -0.0155,\n         0.3228, -0.2594, -0.1078,  0.1940, -0.1554,  0.1791, -0.1655,  0.1576,\n        -0.2535, -0.0072, -0.1667,  0.1903, -0.1557, -0.0769, -0.0079, -0.1536,\n        -0.0568, -0.0486,  0.0786,  0.1222,  0.0597, -0.2321, -0.2754,  0.1878,\n        -0.3518, -0.1392, -0.1955,  0.1109,  0.2539,  0.1299, -0.0606, -0.2884,\n        -0.3384,  0.1297,  0.1540, -0.0835, -0.1967, -0.2957, -0.3321, -0.0687],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0507,  0.0383, -0.0457,  ..., -0.0062, -0.0569,  0.0808],\n        [-0.0192, -0.0006,  0.0041,  ..., -0.0373, -0.0100,  0.0050],\n        [ 0.0880,  0.0764, -0.0782,  ..., -0.0285, -0.0491, -0.0457],\n        ...,\n        [-0.0234, -0.0082,  0.0518,  ...,  0.0568,  0.0648, -0.0076],\n        [-0.0784, -0.0330, -0.0440,  ..., -0.0526, -0.0290,  0.0602],\n        [ 0.0507,  0.0216,  0.0285,  ...,  0.0235,  0.0598, -0.0560]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-1.6024e-02, -4.9002e-02,  7.1738e-02,  1.0521e-02,  7.9192e-02,\n         5.5050e-02, -1.4890e-03,  3.4034e-02,  2.2194e-02,  6.4223e-02,\n        -6.2810e-02, -2.4095e-02, -4.2698e-02,  4.6155e-02, -8.5719e-02,\n        -3.9551e-02, -6.0398e-02,  1.6729e-02,  2.5321e-02,  5.9965e-02,\n         2.7609e-03,  5.2006e-02, -2.8459e-02,  3.6497e-02,  7.9077e-02,\n        -5.3360e-03, -4.8315e-02,  7.9000e-02,  8.5902e-02,  3.3180e-02,\n         6.7012e-02,  2.3762e-02,  5.9905e-02,  4.3017e-02, -7.8556e-02,\n        -3.4760e-02, -2.9446e-02, -3.0616e-02,  7.3579e-02, -8.5127e-02,\n        -6.7329e-02, -6.4794e-02,  3.5424e-02, -8.8356e-02, -2.2966e-02,\n         4.5767e-02, -1.4142e-02, -2.8659e-02,  1.3980e-02, -8.5440e-02,\n         5.3092e-02, -4.0806e-03, -3.9689e-03,  2.4261e-02, -1.3870e-02,\n        -4.2355e-02,  2.8960e-02, -8.5847e-02, -3.2988e-02,  2.0239e-02,\n         7.3954e-02, -5.2945e-02,  2.2441e-02, -2.9642e-02,  7.6330e-02,\n        -6.4454e-02, -7.9639e-02, -6.6307e-02,  1.2741e-02,  1.6168e-02,\n        -7.1664e-02, -5.9943e-05,  2.1152e-02,  5.8559e-02, -4.4094e-02,\n        -7.6062e-02,  8.1963e-02, -1.3290e-02, -2.3210e-02,  5.5489e-02,\n        -4.3320e-02,  6.2566e-02,  7.2880e-04, -8.3509e-02, -3.2006e-02,\n         5.5353e-02, -9.6792e-03,  3.2559e-02, -7.8102e-02,  6.6697e-02,\n        -7.3108e-02,  2.4708e-02, -8.1897e-02, -3.1386e-02, -1.3237e-03,\n         4.7449e-02,  2.5741e-02,  3.8790e-02, -1.9480e-03, -3.3206e-02,\n        -3.4273e-02, -8.0767e-02, -2.7357e-02, -4.9134e-02, -5.2344e-02,\n        -7.1076e-02,  7.5541e-02,  3.3144e-02, -1.5222e-02, -3.2331e-02,\n        -5.0261e-02,  3.6920e-02, -5.5113e-02, -2.0702e-02, -7.2617e-02,\n         2.9012e-02, -8.0948e-03,  8.0128e-02, -4.6479e-02, -2.7896e-02,\n         8.5289e-02,  4.1787e-02, -7.1070e-02, -2.2709e-02, -5.1662e-02,\n         6.8915e-02,  5.6839e-02, -4.7454e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 7.0390e-02, -1.4278e-02,  7.4868e-02,  5.4089e-02,  3.0257e-02,\n         -4.9074e-02, -2.7283e-02,  3.7674e-03, -1.5370e-03,  6.2191e-02,\n         -7.8710e-02, -8.0761e-02,  2.5200e-03, -6.2080e-02, -7.3777e-02,\n          7.7156e-02, -4.1313e-02, -2.9981e-03,  1.6713e-02,  1.2250e-02,\n          8.6156e-02,  3.1530e-02,  8.1634e-02,  5.5439e-02,  8.7525e-02,\n          6.0149e-02,  1.9615e-03, -5.0618e-02, -6.8941e-02,  3.4260e-02,\n         -7.1976e-02,  5.6496e-02, -6.1775e-02,  3.6537e-02,  4.6100e-02,\n         -8.3585e-02, -4.6567e-02,  9.0499e-03,  4.0692e-02,  5.5495e-02,\n         -6.4516e-02, -3.1258e-02,  1.7628e-02,  6.1292e-02, -3.5457e-02,\n          8.0555e-02,  2.5443e-02, -3.0407e-02,  8.3138e-02, -3.4355e-02,\n         -6.1701e-02, -3.5946e-02,  9.0684e-03, -5.5585e-02,  1.4205e-02,\n         -8.5017e-02, -1.6228e-02, -5.3913e-02,  2.8364e-02, -6.9519e-02,\n         -7.7319e-02, -6.9518e-03, -1.0580e-02,  7.7579e-02,  7.2597e-02,\n          7.4871e-03,  7.0590e-02, -2.5792e-03,  6.6164e-02, -2.9040e-02,\n         -1.7238e-04, -8.2049e-02, -1.9128e-02,  2.9961e-02, -1.1901e-02,\n          3.5368e-02, -4.7354e-02, -5.7708e-02, -4.4035e-02, -2.6910e-02,\n         -9.9444e-03, -5.3186e-02,  1.0430e-02, -1.8859e-02,  2.3305e-02,\n          7.0070e-02,  4.3443e-02,  4.2916e-02,  2.1012e-02, -3.2667e-03,\n          7.4652e-02,  3.5872e-02,  6.3284e-02, -4.1000e-02, -4.6340e-02,\n         -3.8679e-02,  6.4025e-02,  7.5977e-02, -6.3627e-02,  2.2268e-03,\n         -5.3433e-02,  6.1865e-03,  5.1742e-02, -3.7243e-02,  6.9540e-02,\n         -7.0369e-02, -6.3083e-05,  8.7954e-02,  1.2879e-02, -8.5366e-02,\n         -6.0338e-02, -8.2297e-02,  1.6638e-02,  8.8025e-02,  4.3269e-02,\n          7.4070e-02, -1.0042e-02,  4.9333e-02, -6.8758e-02, -1.5630e-02,\n         -5.5243e-02,  3.2562e-02,  5.1948e-02, -3.8959e-03,  7.5444e-03,\n         -7.4555e-02, -3.3165e-02,  3.1818e-02],\n        [ 6.6870e-02,  1.9064e-02,  8.1605e-02,  3.3526e-02, -6.2951e-02,\n          6.6390e-02,  6.1317e-02,  1.6226e-02,  6.7903e-03, -3.8207e-02,\n         -1.1475e-03, -4.8034e-02, -3.4751e-02, -6.2763e-02, -1.7698e-02,\n         -3.8351e-02,  8.6156e-02,  4.1136e-02, -3.7249e-02,  5.6499e-02,\n         -1.8934e-02, -3.9456e-03, -3.6567e-02, -1.2353e-02,  1.2047e-02,\n          9.5005e-03,  5.9690e-02, -1.0337e-02, -4.6565e-02,  2.5736e-03,\n         -6.0530e-02,  5.8932e-02,  4.5640e-02,  6.3530e-02,  7.6830e-02,\n         -1.5895e-02,  9.6359e-03,  3.6701e-02,  1.7491e-03, -4.3246e-02,\n          1.5836e-03,  8.1786e-05,  3.7368e-02,  8.4889e-02, -6.8407e-02,\n          4.2919e-02, -3.0219e-02,  7.4917e-02,  2.0465e-02,  1.7579e-02,\n         -4.6643e-02,  5.7924e-02, -2.1827e-02, -3.0921e-02,  5.1351e-02,\n         -4.6014e-02, -4.2058e-03, -5.4247e-02,  4.3903e-02, -1.6038e-02,\n         -5.6008e-02, -8.7640e-02,  5.3796e-02, -2.5871e-02, -7.2213e-02,\n          4.2165e-03, -3.8228e-02,  3.8066e-02,  5.7549e-02, -6.6374e-02,\n          3.8634e-02,  3.0192e-02,  1.7232e-02,  7.1584e-02,  3.6339e-02,\n         -4.8427e-02, -2.2037e-02,  6.3173e-02,  2.2172e-02, -6.7713e-02,\n          6.9298e-02,  6.7214e-02,  3.4895e-02, -8.4214e-02,  7.3981e-03,\n         -6.0910e-02,  2.1104e-02,  8.2950e-02,  8.1265e-02, -1.2263e-02,\n         -7.4736e-02, -2.9284e-02, -3.9737e-02, -7.8104e-02,  4.2287e-02,\n         -7.4217e-02, -5.7870e-02, -8.7585e-02, -2.3887e-03,  3.3038e-02,\n         -4.8737e-02,  5.2733e-02,  3.4324e-02,  8.4352e-02,  7.6470e-02,\n          8.7994e-02, -4.6703e-02,  1.0603e-02, -4.5577e-02,  6.7546e-02,\n         -3.9356e-02, -3.9293e-03,  5.0703e-02,  2.0978e-02,  4.8732e-02,\n         -8.4545e-02, -4.0914e-02,  1.2345e-02,  7.3050e-02,  2.7526e-02,\n         -1.7505e-02, -8.1804e-02, -5.0825e-02,  8.5331e-03, -3.5197e-02,\n         -2.3367e-03,  2.2909e-02,  8.2667e-02],\n        [ 5.4955e-02, -1.3879e-02,  4.3834e-02,  1.6390e-02,  2.8424e-02,\n          4.5105e-02,  2.3072e-02, -3.1025e-02, -6.7649e-02,  5.3227e-02,\n          3.6609e-02, -6.6260e-02,  1.9006e-02,  5.7314e-02,  6.4614e-02,\n         -4.9567e-03,  8.7590e-02, -5.2501e-02,  5.2617e-02,  1.1394e-03,\n          2.2143e-02, -5.7019e-02, -8.3510e-02, -4.3092e-02,  5.3248e-02,\n          4.0958e-02, -6.4911e-02,  6.5180e-02,  6.6350e-02, -3.9737e-02,\n         -2.6603e-02,  1.8418e-02,  1.6957e-02, -4.9411e-03,  1.2930e-02,\n         -9.1211e-03,  6.3412e-02,  7.0138e-02,  4.1337e-02, -4.5168e-02,\n          8.7952e-02,  6.0252e-02, -6.3922e-02,  8.1635e-02,  4.1778e-02,\n          5.1014e-02,  3.7903e-02, -1.0107e-02, -5.4656e-02,  6.2165e-02,\n         -5.2962e-02,  5.1480e-02, -1.0031e-02,  7.1690e-02,  2.0735e-02,\n         -3.0921e-02,  4.1226e-02, -7.4264e-02, -4.5866e-02,  4.0452e-02,\n          5.9951e-02,  7.8161e-02, -6.8335e-02,  3.1012e-02,  2.1805e-02,\n         -3.8140e-02,  1.3861e-02, -2.0483e-02,  6.9922e-02,  4.6598e-02,\n         -6.8185e-02, -4.9474e-02, -3.3501e-02, -4.8515e-02,  6.6229e-02,\n          8.8291e-02, -3.2803e-02,  4.3160e-02,  4.4890e-02,  5.4653e-02,\n         -1.0930e-02,  1.4283e-02,  6.2331e-02,  3.6666e-02,  1.0305e-02,\n         -3.4782e-02, -7.6515e-02, -7.0488e-02,  6.6773e-02, -5.9051e-02,\n          4.3703e-02, -4.4898e-02,  4.3995e-02,  7.6529e-02, -3.3289e-02,\n         -7.8956e-03, -2.5025e-02,  4.5015e-02,  6.3323e-02, -3.9716e-02,\n         -5.6027e-02, -8.0819e-02, -6.0840e-03,  5.9611e-02,  6.2422e-02,\n         -7.1339e-02,  9.1379e-03, -1.3289e-03, -4.5636e-02, -7.9153e-03,\n         -6.5879e-02, -5.0174e-02,  2.0995e-02, -1.3242e-02,  7.6117e-02,\n          2.6919e-02,  8.6872e-02, -4.5771e-02,  6.8642e-02,  4.4345e-03,\n         -7.9544e-02,  6.7806e-02, -2.8261e-02,  7.8739e-02, -3.9279e-02,\n          3.0168e-02, -1.5098e-02,  9.2657e-03],\n        [ 5.1687e-02,  4.3176e-02, -8.5462e-02,  2.8925e-02,  7.8815e-02,\n         -5.8857e-03,  4.6070e-02, -2.2413e-02,  4.5290e-02,  1.8906e-02,\n         -4.9133e-02,  7.1550e-02, -8.6494e-02, -7.4103e-02, -3.0760e-02,\n          5.2279e-02, -5.5586e-02, -3.6187e-02, -1.6249e-02,  2.3659e-03,\n         -7.2266e-02, -5.6605e-02, -7.3092e-02, -6.4671e-02,  6.5219e-02,\n          5.8626e-02,  2.2279e-02, -6.6831e-02, -7.1789e-02, -5.9781e-02,\n         -4.7406e-02,  3.3137e-02,  1.2834e-02,  3.8144e-02, -3.4083e-02,\n          4.5674e-02, -2.7419e-02, -2.3456e-02,  2.4198e-02, -1.8163e-02,\n         -5.4082e-02, -5.5256e-02,  4.3396e-02,  7.6021e-02,  1.2614e-02,\n         -6.3472e-02,  6.2159e-02,  8.1974e-02, -3.1359e-02, -6.2071e-02,\n          5.5359e-02,  1.3536e-02,  5.4866e-02, -5.3736e-02,  9.0250e-04,\n          7.9103e-02, -8.2490e-02, -6.7410e-02, -1.2758e-02, -7.2281e-02,\n         -8.3217e-02,  8.2816e-02,  8.2750e-02,  4.9994e-03, -8.2015e-02,\n         -1.9791e-02,  9.3818e-03,  8.4762e-02,  2.7971e-04,  3.4676e-03,\n          8.3927e-02, -9.7233e-03,  8.1753e-02, -1.7146e-02,  4.0433e-02,\n          1.8445e-02,  6.6945e-02,  7.8598e-02, -7.2123e-02, -3.0010e-02,\n          6.1126e-02, -6.0090e-03, -6.8623e-02, -5.7729e-03,  3.1394e-02,\n         -6.0408e-02,  1.8918e-02, -1.8532e-02,  7.6972e-02, -7.4389e-05,\n          4.8707e-02, -8.3390e-02,  4.4726e-02,  5.7389e-02, -8.1342e-02,\n          5.5852e-02, -1.6210e-02,  4.6484e-02,  7.7339e-02,  3.1656e-02,\n          1.5800e-02,  6.2298e-04, -4.9246e-02, -8.8156e-02,  4.7384e-02,\n          2.4810e-02,  3.6829e-02, -1.4796e-03,  1.1876e-02, -1.5953e-02,\n          5.0393e-03,  4.7295e-02, -1.7811e-02,  4.1233e-02, -3.2473e-02,\n          3.9558e-02, -2.6146e-02,  2.8130e-02,  1.2748e-02, -5.4982e-03,\n          2.0093e-02,  4.0250e-02,  2.3068e-02,  1.0509e-02,  4.0125e-02,\n         -6.3005e-02, -2.0295e-02,  4.2436e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0410, -0.0824,  0.0348, -0.0113], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x7baa05306890>":	{
                    "aux_buf_size":	5000,
                    "aux_buffer":	{
                        "act_buf":	"[0 0 0 ... 0 0 0]",
                        "done_buf":	"[False False False ... False False False]",
                        "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                        "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                        "timestamps":	"[0 0 0 ... 0 0 0]"
                    },
                    "aux_ptr":	0,
                    "capacity":	50000,
                    "current_segment":	0,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	250,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "sample_decay":	0.8,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2138, -0.0396,  0.0617, -0.1711,  0.1405, -0.2627,  0.1835, -0.1148,\n        -0.1761,  0.3343,  0.3021, -0.0587,  0.0103,  0.0424, -0.3115, -0.3132,\n        -0.3201,  0.0067, -0.1299,  0.3367,  0.2394,  0.1008, -0.1323, -0.2186,\n        -0.2031, -0.2455, -0.1562,  0.3279, -0.2066, -0.0044, -0.2549, -0.3245,\n        -0.1104,  0.0462,  0.1075,  0.2416,  0.2526, -0.1608, -0.1082, -0.0099,\n        -0.1802, -0.3150, -0.1820, -0.0311, -0.3320,  0.1311,  0.1115, -0.2313,\n        -0.0463, -0.0234, -0.2531, -0.1511, -0.2851,  0.1922, -0.2903, -0.3063,\n        -0.1963,  0.0865, -0.2953, -0.2160, -0.1927, -0.0192,  0.0635,  0.0454,\n        -0.0271,  0.2226,  0.2550,  0.2456,  0.1253,  0.0119, -0.1457,  0.3356,\n         0.1701,  0.3050, -0.3257, -0.0422,  0.0364, -0.1484, -0.2391, -0.2931,\n         0.2812, -0.2781,  0.1930,  0.2095, -0.2883, -0.0305,  0.3182, -0.0155,\n         0.3228, -0.2594, -0.1078,  0.1940, -0.1554,  0.1791, -0.1655,  0.1576,\n        -0.2535, -0.0072, -0.1667,  0.1903, -0.1557, -0.0769, -0.0079, -0.1536,\n        -0.0568, -0.0486,  0.0786,  0.1222,  0.0597, -0.2321, -0.2754,  0.1878,\n        -0.3518, -0.1392, -0.1955,  0.1109,  0.2539,  0.1299, -0.0606, -0.2884,\n        -0.3384,  0.1297,  0.1540, -0.0835, -0.1967, -0.2957, -0.3321, -0.0687],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2151, -0.1270,  0.2894,  ..., -0.0831, -0.0919, -0.1668],\n        [-0.2098, -0.0909, -0.1444,  ...,  0.0508, -0.2112,  0.0073],\n        [ 0.2803,  0.1562, -0.2034,  ...,  0.1557, -0.0283,  0.0084],\n        ...,\n        [ 0.1311,  0.3062,  0.1319,  ...,  0.0802, -0.1331, -0.1920],\n        [-0.3451,  0.2046, -0.1815,  ...,  0.2421, -0.0948, -0.1628],\n        [ 0.2357, -0.2881, -0.1073,  ..., -0.0442,  0.0388, -0.3231]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-1.6024e-02, -4.9002e-02,  7.1738e-02,  1.0521e-02,  7.9192e-02,\n         5.5050e-02, -1.4890e-03,  3.4034e-02,  2.2194e-02,  6.4223e-02,\n        -6.2810e-02, -2.4095e-02, -4.2698e-02,  4.6155e-02, -8.5719e-02,\n        -3.9551e-02, -6.0398e-02,  1.6729e-02,  2.5321e-02,  5.9965e-02,\n         2.7609e-03,  5.2006e-02, -2.8459e-02,  3.6497e-02,  7.9077e-02,\n        -5.3360e-03, -4.8315e-02,  7.9000e-02,  8.5902e-02,  3.3180e-02,\n         6.7012e-02,  2.3762e-02,  5.9905e-02,  4.3017e-02, -7.8556e-02,\n        -3.4760e-02, -2.9446e-02, -3.0616e-02,  7.3579e-02, -8.5127e-02,\n        -6.7329e-02, -6.4794e-02,  3.5424e-02, -8.8356e-02, -2.2966e-02,\n         4.5767e-02, -1.4142e-02, -2.8659e-02,  1.3980e-02, -8.5440e-02,\n         5.3092e-02, -4.0806e-03, -3.9689e-03,  2.4261e-02, -1.3870e-02,\n        -4.2355e-02,  2.8960e-02, -8.5847e-02, -3.2988e-02,  2.0239e-02,\n         7.3954e-02, -5.2945e-02,  2.2441e-02, -2.9642e-02,  7.6330e-02,\n        -6.4454e-02, -7.9639e-02, -6.6307e-02,  1.2741e-02,  1.6168e-02,\n        -7.1664e-02, -5.9943e-05,  2.1152e-02,  5.8559e-02, -4.4094e-02,\n        -7.6062e-02,  8.1963e-02, -1.3290e-02, -2.3210e-02,  5.5489e-02,\n        -4.3320e-02,  6.2566e-02,  7.2880e-04, -8.3509e-02, -3.2006e-02,\n         5.5353e-02, -9.6792e-03,  3.2559e-02, -7.8102e-02,  6.6697e-02,\n        -7.3108e-02,  2.4708e-02, -8.1897e-02, -3.1386e-02, -1.3237e-03,\n         4.7449e-02,  2.5741e-02,  3.8790e-02, -1.9480e-03, -3.3206e-02,\n        -3.4273e-02, -8.0767e-02, -2.7357e-02, -4.9134e-02, -5.2344e-02,\n        -7.1076e-02,  7.5541e-02,  3.3144e-02, -1.5222e-02, -3.2331e-02,\n        -5.0261e-02,  3.6920e-02, -5.5113e-02, -2.0702e-02, -7.2617e-02,\n         2.9012e-02, -8.0948e-03,  8.0128e-02, -4.6479e-02, -2.7896e-02,\n         8.5289e-02,  4.1787e-02, -7.1070e-02, -2.2709e-02, -5.1662e-02,\n         6.8915e-02,  5.6839e-02, -4.7454e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0507,  0.0383, -0.0457,  ..., -0.0062, -0.0569,  0.0808],\n        [-0.0192, -0.0006,  0.0041,  ..., -0.0373, -0.0100,  0.0050],\n        [ 0.0880,  0.0764, -0.0782,  ..., -0.0285, -0.0491, -0.0457],\n        ...,\n        [-0.0234, -0.0082,  0.0518,  ...,  0.0568,  0.0648, -0.0076],\n        [-0.0784, -0.0330, -0.0440,  ..., -0.0526, -0.0290,  0.0602],\n        [ 0.0507,  0.0216,  0.0285,  ...,  0.0235,  0.0598, -0.0560]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0410, -0.0824,  0.0348, -0.0113], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 7.0390e-02, -1.4278e-02,  7.4868e-02,  5.4089e-02,  3.0257e-02,\n         -4.9074e-02, -2.7283e-02,  3.7674e-03, -1.5370e-03,  6.2191e-02,\n         -7.8710e-02, -8.0761e-02,  2.5200e-03, -6.2080e-02, -7.3777e-02,\n          7.7156e-02, -4.1313e-02, -2.9981e-03,  1.6713e-02,  1.2250e-02,\n          8.6156e-02,  3.1530e-02,  8.1634e-02,  5.5439e-02,  8.7525e-02,\n          6.0149e-02,  1.9615e-03, -5.0618e-02, -6.8941e-02,  3.4260e-02,\n         -7.1976e-02,  5.6496e-02, -6.1775e-02,  3.6537e-02,  4.6100e-02,\n         -8.3585e-02, -4.6567e-02,  9.0499e-03,  4.0692e-02,  5.5495e-02,\n         -6.4516e-02, -3.1258e-02,  1.7628e-02,  6.1292e-02, -3.5457e-02,\n          8.0555e-02,  2.5443e-02, -3.0407e-02,  8.3138e-02, -3.4355e-02,\n         -6.1701e-02, -3.5946e-02,  9.0684e-03, -5.5585e-02,  1.4205e-02,\n         -8.5017e-02, -1.6228e-02, -5.3913e-02,  2.8364e-02, -6.9519e-02,\n         -7.7319e-02, -6.9518e-03, -1.0580e-02,  7.7579e-02,  7.2597e-02,\n          7.4871e-03,  7.0590e-02, -2.5792e-03,  6.6164e-02, -2.9040e-02,\n         -1.7238e-04, -8.2049e-02, -1.9128e-02,  2.9961e-02, -1.1901e-02,\n          3.5368e-02, -4.7354e-02, -5.7708e-02, -4.4035e-02, -2.6910e-02,\n         -9.9444e-03, -5.3186e-02,  1.0430e-02, -1.8859e-02,  2.3305e-02,\n          7.0070e-02,  4.3443e-02,  4.2916e-02,  2.1012e-02, -3.2667e-03,\n          7.4652e-02,  3.5872e-02,  6.3284e-02, -4.1000e-02, -4.6340e-02,\n         -3.8679e-02,  6.4025e-02,  7.5977e-02, -6.3627e-02,  2.2268e-03,\n         -5.3433e-02,  6.1865e-03,  5.1742e-02, -3.7243e-02,  6.9540e-02,\n         -7.0369e-02, -6.3083e-05,  8.7954e-02,  1.2879e-02, -8.5366e-02,\n         -6.0338e-02, -8.2297e-02,  1.6638e-02,  8.8025e-02,  4.3269e-02,\n          7.4070e-02, -1.0042e-02,  4.9333e-02, -6.8758e-02, -1.5630e-02,\n         -5.5243e-02,  3.2562e-02,  5.1948e-02, -3.8959e-03,  7.5444e-03,\n         -7.4555e-02, -3.3165e-02,  3.1818e-02],\n        [ 6.6870e-02,  1.9064e-02,  8.1605e-02,  3.3526e-02, -6.2951e-02,\n          6.6390e-02,  6.1317e-02,  1.6226e-02,  6.7903e-03, -3.8207e-02,\n         -1.1475e-03, -4.8034e-02, -3.4751e-02, -6.2763e-02, -1.7698e-02,\n         -3.8351e-02,  8.6156e-02,  4.1136e-02, -3.7249e-02,  5.6499e-02,\n         -1.8934e-02, -3.9456e-03, -3.6567e-02, -1.2353e-02,  1.2047e-02,\n          9.5005e-03,  5.9690e-02, -1.0337e-02, -4.6565e-02,  2.5736e-03,\n         -6.0530e-02,  5.8932e-02,  4.5640e-02,  6.3530e-02,  7.6830e-02,\n         -1.5895e-02,  9.6359e-03,  3.6701e-02,  1.7491e-03, -4.3246e-02,\n          1.5836e-03,  8.1786e-05,  3.7368e-02,  8.4889e-02, -6.8407e-02,\n          4.2919e-02, -3.0219e-02,  7.4917e-02,  2.0465e-02,  1.7579e-02,\n         -4.6643e-02,  5.7924e-02, -2.1827e-02, -3.0921e-02,  5.1351e-02,\n         -4.6014e-02, -4.2058e-03, -5.4247e-02,  4.3903e-02, -1.6038e-02,\n         -5.6008e-02, -8.7640e-02,  5.3796e-02, -2.5871e-02, -7.2213e-02,\n          4.2165e-03, -3.8228e-02,  3.8066e-02,  5.7549e-02, -6.6374e-02,\n          3.8634e-02,  3.0192e-02,  1.7232e-02,  7.1584e-02,  3.6339e-02,\n         -4.8427e-02, -2.2037e-02,  6.3173e-02,  2.2172e-02, -6.7713e-02,\n          6.9298e-02,  6.7214e-02,  3.4895e-02, -8.4214e-02,  7.3981e-03,\n         -6.0910e-02,  2.1104e-02,  8.2950e-02,  8.1265e-02, -1.2263e-02,\n         -7.4736e-02, -2.9284e-02, -3.9737e-02, -7.8104e-02,  4.2287e-02,\n         -7.4217e-02, -5.7870e-02, -8.7585e-02, -2.3887e-03,  3.3038e-02,\n         -4.8737e-02,  5.2733e-02,  3.4324e-02,  8.4352e-02,  7.6470e-02,\n          8.7994e-02, -4.6703e-02,  1.0603e-02, -4.5577e-02,  6.7546e-02,\n         -3.9356e-02, -3.9293e-03,  5.0703e-02,  2.0978e-02,  4.8732e-02,\n         -8.4545e-02, -4.0914e-02,  1.2345e-02,  7.3050e-02,  2.7526e-02,\n         -1.7505e-02, -8.1804e-02, -5.0825e-02,  8.5331e-03, -3.5197e-02,\n         -2.3367e-03,  2.2909e-02,  8.2667e-02],\n        [ 5.4955e-02, -1.3879e-02,  4.3834e-02,  1.6390e-02,  2.8424e-02,\n          4.5105e-02,  2.3072e-02, -3.1025e-02, -6.7649e-02,  5.3227e-02,\n          3.6609e-02, -6.6260e-02,  1.9006e-02,  5.7314e-02,  6.4614e-02,\n         -4.9567e-03,  8.7590e-02, -5.2501e-02,  5.2617e-02,  1.1394e-03,\n          2.2143e-02, -5.7019e-02, -8.3510e-02, -4.3092e-02,  5.3248e-02,\n          4.0958e-02, -6.4911e-02,  6.5180e-02,  6.6350e-02, -3.9737e-02,\n         -2.6603e-02,  1.8418e-02,  1.6957e-02, -4.9411e-03,  1.2930e-02,\n         -9.1211e-03,  6.3412e-02,  7.0138e-02,  4.1337e-02, -4.5168e-02,\n          8.7952e-02,  6.0252e-02, -6.3922e-02,  8.1635e-02,  4.1778e-02,\n          5.1014e-02,  3.7903e-02, -1.0107e-02, -5.4656e-02,  6.2165e-02,\n         -5.2962e-02,  5.1480e-02, -1.0031e-02,  7.1690e-02,  2.0735e-02,\n         -3.0921e-02,  4.1226e-02, -7.4264e-02, -4.5866e-02,  4.0452e-02,\n          5.9951e-02,  7.8161e-02, -6.8335e-02,  3.1012e-02,  2.1805e-02,\n         -3.8140e-02,  1.3861e-02, -2.0483e-02,  6.9922e-02,  4.6598e-02,\n         -6.8185e-02, -4.9474e-02, -3.3501e-02, -4.8515e-02,  6.6229e-02,\n          8.8291e-02, -3.2803e-02,  4.3160e-02,  4.4890e-02,  5.4653e-02,\n         -1.0930e-02,  1.4283e-02,  6.2331e-02,  3.6666e-02,  1.0305e-02,\n         -3.4782e-02, -7.6515e-02, -7.0488e-02,  6.6773e-02, -5.9051e-02,\n          4.3703e-02, -4.4898e-02,  4.3995e-02,  7.6529e-02, -3.3289e-02,\n         -7.8956e-03, -2.5025e-02,  4.5015e-02,  6.3323e-02, -3.9716e-02,\n         -5.6027e-02, -8.0819e-02, -6.0840e-03,  5.9611e-02,  6.2422e-02,\n         -7.1339e-02,  9.1379e-03, -1.3289e-03, -4.5636e-02, -7.9153e-03,\n         -6.5879e-02, -5.0174e-02,  2.0995e-02, -1.3242e-02,  7.6117e-02,\n          2.6919e-02,  8.6872e-02, -4.5771e-02,  6.8642e-02,  4.4345e-03,\n         -7.9544e-02,  6.7806e-02, -2.8261e-02,  7.8739e-02, -3.9279e-02,\n          3.0168e-02, -1.5098e-02,  9.2657e-03],\n        [ 5.1687e-02,  4.3176e-02, -8.5462e-02,  2.8925e-02,  7.8815e-02,\n         -5.8857e-03,  4.6070e-02, -2.2413e-02,  4.5290e-02,  1.8906e-02,\n         -4.9133e-02,  7.1550e-02, -8.6494e-02, -7.4103e-02, -3.0760e-02,\n          5.2279e-02, -5.5586e-02, -3.6187e-02, -1.6249e-02,  2.3659e-03,\n         -7.2266e-02, -5.6605e-02, -7.3092e-02, -6.4671e-02,  6.5219e-02,\n          5.8626e-02,  2.2279e-02, -6.6831e-02, -7.1789e-02, -5.9781e-02,\n         -4.7406e-02,  3.3137e-02,  1.2834e-02,  3.8144e-02, -3.4083e-02,\n          4.5674e-02, -2.7419e-02, -2.3456e-02,  2.4198e-02, -1.8163e-02,\n         -5.4082e-02, -5.5256e-02,  4.3396e-02,  7.6021e-02,  1.2614e-02,\n         -6.3472e-02,  6.2159e-02,  8.1974e-02, -3.1359e-02, -6.2071e-02,\n          5.5359e-02,  1.3536e-02,  5.4866e-02, -5.3736e-02,  9.0250e-04,\n          7.9103e-02, -8.2490e-02, -6.7410e-02, -1.2758e-02, -7.2281e-02,\n         -8.3217e-02,  8.2816e-02,  8.2750e-02,  4.9994e-03, -8.2015e-02,\n         -1.9791e-02,  9.3818e-03,  8.4762e-02,  2.7971e-04,  3.4676e-03,\n          8.3927e-02, -9.7233e-03,  8.1753e-02, -1.7146e-02,  4.0433e-02,\n          1.8445e-02,  6.6945e-02,  7.8598e-02, -7.2123e-02, -3.0010e-02,\n          6.1126e-02, -6.0090e-03, -6.8623e-02, -5.7729e-03,  3.1394e-02,\n         -6.0408e-02,  1.8918e-02, -1.8532e-02,  7.6972e-02, -7.4389e-05,\n          4.8707e-02, -8.3390e-02,  4.4726e-02,  5.7389e-02, -8.1342e-02,\n          5.5852e-02, -1.6210e-02,  4.6484e-02,  7.7339e-02,  3.1656e-02,\n          1.5800e-02,  6.2298e-04, -4.9246e-02, -8.8156e-02,  4.7384e-02,\n          2.4810e-02,  3.6829e-02, -1.4796e-03,  1.1876e-02, -1.5953e-02,\n          5.0393e-03,  4.7295e-02, -1.7811e-02,  4.1233e-02, -3.2473e-02,\n          3.9558e-02, -2.6146e-02,  2.8130e-02,  1.2748e-02, -5.4982e-03,\n          2.0093e-02,  4.0250e-02,  2.3068e-02,  1.0509e-02,  4.0125e-02,\n         -6.3005e-02, -2.0295e-02,  4.2436e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7baa03d81150>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s390360000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s390360000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}