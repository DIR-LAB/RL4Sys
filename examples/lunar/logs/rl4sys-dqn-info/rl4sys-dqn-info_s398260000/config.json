{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0003,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s398260000"
    },
    "max_sample_age":	250,
    "q_lr":	0.0003,
    "sample_decay":	0.8,
    "seed":	398260000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7fd29e8fed10>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0003,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2066,  0.1574,  0.2937,  0.1923, -0.1586,  0.1466,  0.1221, -0.3135,\n        -0.0145, -0.0383,  0.2500, -0.1123, -0.2638,  0.1749,  0.3291, -0.1133,\n         0.0625, -0.3236, -0.3026, -0.0564,  0.0986,  0.1465,  0.1091, -0.3315,\n        -0.2391, -0.0671, -0.0548, -0.0014,  0.1550, -0.1515, -0.2847,  0.2292,\n         0.1882,  0.2194, -0.0784, -0.2333,  0.1190,  0.0986,  0.0905,  0.3251,\n        -0.0641,  0.0659, -0.0385, -0.0745, -0.1760, -0.0436,  0.0145,  0.0782,\n        -0.3020, -0.1318, -0.1934,  0.1594,  0.0621, -0.0111, -0.2862,  0.3134,\n         0.1289, -0.0332,  0.1865,  0.1066, -0.2808, -0.1742,  0.2231, -0.1010,\n         0.2802, -0.2557, -0.1477, -0.2671, -0.3304, -0.2942, -0.2097, -0.0808,\n         0.2910, -0.1228,  0.1160,  0.0785, -0.1880,  0.0475,  0.2814,  0.2692,\n        -0.0548, -0.3412, -0.0562,  0.2216,  0.1156,  0.0922, -0.1839, -0.2373,\n         0.0126,  0.3502, -0.2316,  0.0084,  0.3488, -0.1082, -0.1466,  0.2023,\n         0.0088,  0.2924, -0.3078,  0.0215,  0.0938,  0.1125,  0.2316,  0.0209,\n         0.2852,  0.3217, -0.3266, -0.0235,  0.1858, -0.0811,  0.0153, -0.0490,\n        -0.0766, -0.0112,  0.0860,  0.1240,  0.1250, -0.0562,  0.1055,  0.1463,\n         0.2457,  0.0183,  0.0367, -0.3477,  0.0007, -0.1706, -0.2625,  0.1896],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2750,  0.2990, -0.0396,  ...,  0.2689, -0.0796,  0.1215],\n        [-0.0052,  0.0496,  0.0037,  ..., -0.1555, -0.2903,  0.0081],\n        [ 0.3184, -0.3491, -0.1025,  ...,  0.1518, -0.1524, -0.2859],\n        ...,\n        [ 0.1860, -0.2224, -0.2530,  ..., -0.1708,  0.3477,  0.1364],\n        [-0.2240,  0.3074, -0.1292,  ..., -0.2202,  0.3393,  0.1936],\n        [-0.1370,  0.2358, -0.1709,  ..., -0.0406,  0.3015,  0.0341]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-4.8277e-02, -8.4242e-02,  5.2378e-05, -2.0259e-02, -7.1606e-02,\n        -1.7601e-02, -8.2586e-02, -1.7260e-02, -3.0118e-02, -7.7141e-02,\n         2.1366e-02,  5.0091e-02,  1.1663e-02, -1.7394e-02, -8.7220e-02,\n         4.2945e-02,  1.0616e-02, -5.2032e-02,  6.3205e-02,  5.3510e-02,\n         5.3621e-02, -5.7752e-02,  3.0098e-02, -3.9715e-02,  2.7979e-02,\n        -2.2543e-02,  3.7811e-02,  4.9159e-03,  8.0356e-02,  7.3807e-02,\n         5.4922e-02,  2.8098e-02, -8.6363e-02,  1.0008e-02,  8.2197e-02,\n         7.6747e-02,  1.8586e-02,  7.3866e-03, -3.1303e-03,  5.1687e-02,\n         7.5850e-02, -4.7679e-03, -4.8170e-02, -4.5465e-02, -5.7308e-02,\n         8.5989e-03, -5.8561e-02,  2.7018e-02,  6.5154e-02,  3.5533e-02,\n         5.7262e-02,  8.3401e-02,  2.4345e-02,  7.1569e-02,  2.6044e-02,\n        -7.3598e-03,  4.8476e-02,  1.5308e-02, -6.9788e-04, -4.8334e-02,\n         6.2478e-02,  1.3961e-02,  1.4283e-04,  4.5188e-02,  7.0604e-02,\n         4.9298e-02, -1.2938e-02,  1.9699e-02,  3.6992e-02, -7.6561e-02,\n         1.0603e-02,  1.0908e-02,  7.7345e-02,  4.3685e-02, -6.0095e-02,\n        -5.1424e-02,  1.1053e-03,  5.7017e-02, -7.2202e-02, -7.9147e-02,\n        -8.4170e-02,  2.7131e-02, -3.4847e-03, -3.6592e-02, -2.8945e-02,\n         2.5339e-02, -5.1328e-02, -7.2671e-03, -6.9480e-02,  4.5163e-02,\n        -4.4963e-02, -7.7465e-02,  4.0514e-03,  4.8947e-02,  7.0769e-02,\n        -1.5658e-02,  5.8550e-02, -3.2763e-02, -3.8357e-02, -3.8927e-02,\n         3.6598e-02, -6.5897e-03,  7.2850e-02, -7.3697e-02, -7.4113e-02,\n        -2.1735e-02, -8.4786e-02, -1.8825e-02, -3.7061e-02, -2.6121e-02,\n        -8.6749e-02,  3.1395e-02,  2.1357e-02, -8.1758e-03,  3.9698e-02,\n         7.3655e-02, -8.0701e-03, -2.3875e-02,  8.7334e-02, -3.8423e-02,\n        -5.3431e-02,  6.4656e-02,  2.9332e-02,  7.9109e-02,  5.5623e-02,\n         2.0697e-02, -2.4233e-02, -5.5066e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0279, -0.0874, -0.0437,  ..., -0.0091, -0.0579,  0.0594],\n        [ 0.0384,  0.0259, -0.0252,  ..., -0.0858,  0.0719, -0.0408],\n        [-0.0334,  0.0302, -0.0785,  ..., -0.0264, -0.0610, -0.0558],\n        ...,\n        [-0.0341, -0.0212,  0.0349,  ..., -0.0330,  0.0216, -0.0764],\n        [ 0.0823, -0.0292,  0.0238,  ...,  0.0308,  0.0754, -0.0646],\n        [ 0.0137, -0.0169, -0.0267,  ..., -0.0531, -0.0185,  0.0250]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0536,  0.0238, -0.0658,  0.0781], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-5.6237e-02, -7.7472e-02, -2.7705e-02,  4.2296e-02,  6.5902e-02,\n          8.5388e-02, -3.9716e-02, -6.9343e-02,  1.0369e-02,  5.7089e-02,\n         -7.8752e-02, -8.4844e-02,  1.5749e-02,  2.6977e-02, -6.4174e-03,\n          5.6892e-02,  1.5656e-03, -4.5576e-03, -3.5996e-02,  2.7118e-02,\n          6.9475e-02, -8.2710e-02,  2.4356e-02, -3.2846e-02,  3.8162e-02,\n          4.0543e-02, -5.9799e-02,  2.3425e-02,  4.8223e-02, -6.6100e-02,\n         -4.7293e-02, -4.5607e-02,  9.9235e-03,  3.6161e-02,  3.1167e-02,\n          2.2310e-02,  7.8038e-02, -4.7672e-02, -4.4009e-02, -4.7057e-02,\n          5.9551e-02, -6.8811e-02, -2.9543e-02,  2.1079e-02,  8.4609e-02,\n         -3.3825e-03, -6.8010e-02, -7.9188e-02,  7.5910e-02, -8.3342e-02,\n          4.1030e-02, -7.3948e-02, -5.2559e-02,  8.7348e-02, -3.8683e-02,\n          8.4983e-02, -4.5823e-02,  2.8027e-02, -6.8083e-02, -4.2776e-02,\n          8.6308e-02,  3.6107e-03, -3.9345e-02,  6.4164e-02, -5.4258e-02,\n         -4.6095e-02,  3.7557e-02, -1.0460e-02, -2.1554e-02,  5.8222e-02,\n          5.2416e-02, -9.8551e-03,  5.6103e-02, -2.6645e-02, -3.1935e-02,\n          3.2999e-02,  6.4683e-02, -9.9316e-03, -7.2754e-02,  1.0786e-02,\n         -5.7459e-02,  1.9946e-02,  3.8081e-02, -3.0618e-02, -4.1275e-02,\n         -2.6773e-02,  3.3178e-02,  7.6135e-02,  5.2770e-03,  6.3555e-02,\n         -8.7879e-03, -7.9921e-02,  6.5782e-03,  6.5957e-02,  1.7031e-02,\n         -6.5704e-03, -5.4391e-02,  2.8659e-02, -3.1725e-04, -5.5061e-02,\n         -1.0979e-02,  8.4450e-02,  4.0980e-02, -4.7349e-02, -6.3893e-02,\n         -5.6031e-02, -4.8037e-02,  1.4242e-02, -1.2344e-02, -2.8975e-02,\n          8.3626e-02,  3.2885e-02,  3.9192e-02,  8.2220e-02,  3.4081e-02,\n         -7.9384e-02, -4.5449e-03, -4.8517e-02, -5.6485e-03,  4.1660e-02,\n          6.9119e-02, -9.2252e-03,  2.3436e-02,  5.4927e-02, -5.1339e-02,\n          5.4906e-03, -8.6589e-02, -3.9084e-02],\n        [ 7.2780e-04, -5.7914e-02, -4.7222e-02,  8.4980e-02,  5.1617e-02,\n          3.2772e-02, -8.2243e-03, -3.0033e-02, -8.2802e-02, -8.0366e-02,\n          3.4399e-02,  9.9326e-03, -2.7259e-02,  5.9460e-02,  2.6539e-02,\n         -7.8355e-02,  1.4983e-03, -1.8667e-02,  1.4820e-02, -7.4333e-02,\n         -8.0218e-02,  1.0374e-02,  1.1204e-02,  2.3717e-02, -7.2962e-02,\n          1.3476e-02, -6.7522e-02, -8.5373e-02, -3.2513e-02,  8.8328e-02,\n         -7.2384e-02,  6.6588e-02,  4.7202e-02,  4.4240e-03,  2.2702e-02,\n         -5.6381e-02, -5.8953e-02,  6.5017e-02,  4.9509e-02,  2.4512e-03,\n          7.6804e-02, -3.8756e-02,  1.3873e-02, -4.2116e-02, -7.1869e-03,\n          3.6862e-02, -5.9248e-02, -5.9437e-02, -5.9983e-02, -4.2473e-02,\n         -1.5635e-02,  4.0171e-02,  5.7896e-02,  3.8986e-02,  2.7037e-03,\n         -7.1909e-02,  3.0274e-02, -3.4565e-02,  2.6469e-02,  1.8020e-02,\n          6.3191e-03,  3.8907e-02, -2.3091e-02,  1.1701e-02,  7.8280e-02,\n          8.5877e-02, -8.9961e-03, -3.2721e-02,  5.0250e-03,  6.1793e-02,\n         -4.8362e-02,  4.8954e-02, -8.1551e-02, -3.9306e-02, -6.1247e-02,\n          3.0094e-02,  5.5500e-02,  5.6797e-02, -7.8589e-02, -5.7316e-03,\n         -5.0912e-02,  1.1608e-02,  1.6413e-02,  1.6595e-02,  2.1669e-02,\n          3.9868e-02,  7.3800e-02,  1.4682e-02,  6.7864e-02,  2.3236e-03,\n         -1.4864e-02,  1.8635e-03, -7.3528e-03, -8.2590e-02,  8.5211e-02,\n         -6.8978e-02,  8.3664e-02,  3.7334e-02,  1.4413e-02,  1.2592e-02,\n         -4.7137e-02, -1.6167e-02,  5.3390e-02,  7.3296e-02,  5.3226e-02,\n         -6.2776e-02, -2.1236e-02,  5.0841e-02, -5.1350e-02,  2.0943e-02,\n          4.2106e-02, -1.7123e-02,  3.7255e-02, -6.5760e-02, -3.6652e-02,\n          2.2934e-02,  2.8446e-02,  4.9556e-02,  3.8557e-02, -6.4522e-02,\n          6.6098e-02, -4.0605e-02,  3.6877e-02, -1.2069e-02,  6.8800e-02,\n         -2.6602e-02,  3.6825e-02,  5.4986e-02],\n        [ 4.5651e-02, -2.4381e-02, -1.9070e-02,  5.4542e-02, -3.3742e-02,\n          3.8149e-02,  4.8648e-02,  7.6797e-02,  5.4566e-02,  3.6420e-02,\n          4.2031e-02, -8.3003e-02,  5.5911e-02, -3.6138e-02, -8.3197e-02,\n          1.5961e-02, -2.2656e-02, -4.9696e-02, -6.7424e-02,  4.3439e-02,\n          2.5768e-02,  7.5920e-02, -1.8085e-02,  6.5839e-02, -4.5083e-02,\n          3.4901e-02, -2.2620e-02, -6.6610e-02, -7.3244e-02, -8.4053e-02,\n         -2.7518e-02, -7.3610e-02,  5.9521e-02,  5.4597e-02,  1.0020e-02,\n          3.5771e-02,  2.3955e-02,  8.5264e-02, -6.7645e-02,  6.9966e-02,\n          6.2506e-02, -6.6990e-02, -7.4401e-02, -5.3720e-02,  6.4472e-02,\n          5.9486e-02, -1.8578e-02,  4.7616e-02, -7.3305e-02,  4.5236e-02,\n          4.1135e-02, -5.8091e-02,  3.6811e-02,  6.8200e-02,  3.7335e-03,\n          1.0964e-02, -4.7415e-06, -4.2127e-03,  6.9770e-02, -2.4708e-02,\n          1.5430e-02,  8.2802e-02,  6.5051e-02, -1.8832e-02,  1.9441e-02,\n          2.4384e-02, -3.3169e-03, -1.5227e-02, -7.0578e-02,  6.2831e-03,\n         -3.6984e-02, -2.2289e-02, -3.3068e-02,  7.1784e-03,  4.7002e-02,\n         -6.1500e-02, -8.6824e-02,  1.1812e-02, -4.9375e-02,  1.7629e-02,\n         -3.2380e-02,  2.0631e-03,  1.9033e-02, -5.6198e-02, -2.9311e-03,\n         -1.0358e-02,  6.5619e-02,  5.8873e-02,  9.2674e-04,  3.0950e-02,\n         -4.4072e-02, -1.1219e-02,  6.4781e-02, -6.4179e-02,  8.1278e-02,\n          1.6829e-02, -5.0409e-02, -7.2910e-02,  2.9316e-02, -2.0051e-02,\n          4.0246e-02, -2.8436e-03, -5.8265e-03, -2.9942e-02, -5.8797e-02,\n          5.7786e-02,  4.8160e-02,  4.8076e-02, -7.5157e-02, -2.3719e-02,\n          1.2378e-02, -3.3996e-02, -1.1493e-02, -5.4164e-02,  2.7601e-02,\n          3.3951e-02, -8.5460e-02, -5.2794e-02,  4.8190e-02,  6.5948e-02,\n          6.2227e-02, -6.0555e-03,  4.4262e-02,  6.4169e-02, -7.7532e-02,\n          4.6255e-04, -7.9796e-02,  3.5915e-02],\n        [-3.0525e-02,  4.9549e-03,  7.9379e-02,  3.6417e-03,  5.0397e-02,\n         -5.8514e-02, -3.6181e-03, -7.6562e-03,  1.4000e-02, -1.0942e-04,\n          7.8480e-02,  7.7050e-02,  2.2351e-02,  6.9525e-02,  5.9674e-03,\n          8.6249e-02,  8.1118e-02, -4.7843e-03,  9.5119e-03,  4.1550e-02,\n         -2.8497e-02, -6.1169e-02,  4.3036e-02,  8.3813e-02,  5.5025e-02,\n         -3.1644e-02,  4.2060e-02, -3.2089e-02,  6.6070e-03, -6.0397e-02,\n          4.3231e-02, -2.9860e-02,  3.8814e-02,  5.2265e-02,  7.9042e-02,\n          6.7571e-03,  4.3920e-02, -6.2394e-02, -8.8022e-02,  2.2975e-02,\n          4.8803e-03,  7.2694e-02, -4.5394e-02, -7.4097e-02, -5.3943e-02,\n         -1.4874e-02,  6.3319e-02, -1.7662e-02, -2.8573e-02,  6.3831e-02,\n          4.6546e-02,  3.5237e-02,  4.4235e-02,  8.1260e-02, -4.8561e-04,\n          1.4317e-02,  6.3401e-02,  5.4970e-02, -2.6692e-02,  3.3137e-02,\n         -4.1712e-02, -1.6915e-02,  6.0936e-02, -1.5719e-02,  3.6424e-02,\n          2.3551e-02,  5.5825e-02, -6.1410e-02, -5.6409e-02,  7.7923e-02,\n          3.4201e-02,  3.4524e-02,  4.4623e-02,  2.6183e-02, -6.7946e-02,\n          5.6149e-02,  3.1389e-02,  2.0955e-02, -8.2281e-02,  4.9136e-02,\n          8.5703e-02, -8.2562e-02, -6.7133e-02, -1.2761e-02, -8.6855e-02,\n          3.2044e-02,  5.9312e-02,  2.5033e-02, -8.3099e-04,  3.6805e-02,\n         -5.6906e-02, -4.6063e-02, -7.0646e-02,  1.7308e-02, -2.7281e-02,\n          1.7717e-02,  1.7273e-02,  3.9075e-02,  6.4005e-03, -4.6749e-02,\n         -5.4179e-02,  2.3439e-02,  1.6492e-03, -2.6512e-02, -3.7744e-02,\n          2.2059e-02,  1.9105e-02, -4.7363e-02, -2.1792e-02, -8.5559e-02,\n         -8.6535e-02,  7.1785e-03,  3.6634e-02, -4.8074e-02,  2.5747e-02,\n          1.8634e-02,  2.4127e-02, -4.6877e-02,  2.8244e-02, -6.0144e-02,\n          7.7920e-02,  5.8718e-02, -6.9905e-02,  3.7311e-02, -4.8957e-02,\n          5.7240e-02,  1.7515e-02, -9.3112e-03]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2750,  0.2990, -0.0396,  ...,  0.2689, -0.0796,  0.1215],\n        [-0.0052,  0.0496,  0.0037,  ..., -0.1555, -0.2903,  0.0081],\n        [ 0.3184, -0.3491, -0.1025,  ...,  0.1518, -0.1524, -0.2859],\n        ...,\n        [ 0.1860, -0.2224, -0.2530,  ..., -0.1708,  0.3477,  0.1364],\n        [-0.2240,  0.3074, -0.1292,  ..., -0.2202,  0.3393,  0.1936],\n        [-0.1370,  0.2358, -0.1709,  ..., -0.0406,  0.3015,  0.0341]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2066,  0.1574,  0.2937,  0.1923, -0.1586,  0.1466,  0.1221, -0.3135,\n        -0.0145, -0.0383,  0.2500, -0.1123, -0.2638,  0.1749,  0.3291, -0.1133,\n         0.0625, -0.3236, -0.3026, -0.0564,  0.0986,  0.1465,  0.1091, -0.3315,\n        -0.2391, -0.0671, -0.0548, -0.0014,  0.1550, -0.1515, -0.2847,  0.2292,\n         0.1882,  0.2194, -0.0784, -0.2333,  0.1190,  0.0986,  0.0905,  0.3251,\n        -0.0641,  0.0659, -0.0385, -0.0745, -0.1760, -0.0436,  0.0145,  0.0782,\n        -0.3020, -0.1318, -0.1934,  0.1594,  0.0621, -0.0111, -0.2862,  0.3134,\n         0.1289, -0.0332,  0.1865,  0.1066, -0.2808, -0.1742,  0.2231, -0.1010,\n         0.2802, -0.2557, -0.1477, -0.2671, -0.3304, -0.2942, -0.2097, -0.0808,\n         0.2910, -0.1228,  0.1160,  0.0785, -0.1880,  0.0475,  0.2814,  0.2692,\n        -0.0548, -0.3412, -0.0562,  0.2216,  0.1156,  0.0922, -0.1839, -0.2373,\n         0.0126,  0.3502, -0.2316,  0.0084,  0.3488, -0.1082, -0.1466,  0.2023,\n         0.0088,  0.2924, -0.3078,  0.0215,  0.0938,  0.1125,  0.2316,  0.0209,\n         0.2852,  0.3217, -0.3266, -0.0235,  0.1858, -0.0811,  0.0153, -0.0490,\n        -0.0766, -0.0112,  0.0860,  0.1240,  0.1250, -0.0562,  0.1055,  0.1463,\n         0.2457,  0.0183,  0.0367, -0.3477,  0.0007, -0.1706, -0.2625,  0.1896],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0279, -0.0874, -0.0437,  ..., -0.0091, -0.0579,  0.0594],\n        [ 0.0384,  0.0259, -0.0252,  ..., -0.0858,  0.0719, -0.0408],\n        [-0.0334,  0.0302, -0.0785,  ..., -0.0264, -0.0610, -0.0558],\n        ...,\n        [-0.0341, -0.0212,  0.0349,  ..., -0.0330,  0.0216, -0.0764],\n        [ 0.0823, -0.0292,  0.0238,  ...,  0.0308,  0.0754, -0.0646],\n        [ 0.0137, -0.0169, -0.0267,  ..., -0.0531, -0.0185,  0.0250]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-4.8277e-02, -8.4242e-02,  5.2378e-05, -2.0259e-02, -7.1606e-02,\n        -1.7601e-02, -8.2586e-02, -1.7260e-02, -3.0118e-02, -7.7141e-02,\n         2.1366e-02,  5.0091e-02,  1.1663e-02, -1.7394e-02, -8.7220e-02,\n         4.2945e-02,  1.0616e-02, -5.2032e-02,  6.3205e-02,  5.3510e-02,\n         5.3621e-02, -5.7752e-02,  3.0098e-02, -3.9715e-02,  2.7979e-02,\n        -2.2543e-02,  3.7811e-02,  4.9159e-03,  8.0356e-02,  7.3807e-02,\n         5.4922e-02,  2.8098e-02, -8.6363e-02,  1.0008e-02,  8.2197e-02,\n         7.6747e-02,  1.8586e-02,  7.3866e-03, -3.1303e-03,  5.1687e-02,\n         7.5850e-02, -4.7679e-03, -4.8170e-02, -4.5465e-02, -5.7308e-02,\n         8.5989e-03, -5.8561e-02,  2.7018e-02,  6.5154e-02,  3.5533e-02,\n         5.7262e-02,  8.3401e-02,  2.4345e-02,  7.1569e-02,  2.6044e-02,\n        -7.3598e-03,  4.8476e-02,  1.5308e-02, -6.9788e-04, -4.8334e-02,\n         6.2478e-02,  1.3961e-02,  1.4283e-04,  4.5188e-02,  7.0604e-02,\n         4.9298e-02, -1.2938e-02,  1.9699e-02,  3.6992e-02, -7.6561e-02,\n         1.0603e-02,  1.0908e-02,  7.7345e-02,  4.3685e-02, -6.0095e-02,\n        -5.1424e-02,  1.1053e-03,  5.7017e-02, -7.2202e-02, -7.9147e-02,\n        -8.4170e-02,  2.7131e-02, -3.4847e-03, -3.6592e-02, -2.8945e-02,\n         2.5339e-02, -5.1328e-02, -7.2671e-03, -6.9480e-02,  4.5163e-02,\n        -4.4963e-02, -7.7465e-02,  4.0514e-03,  4.8947e-02,  7.0769e-02,\n        -1.5658e-02,  5.8550e-02, -3.2763e-02, -3.8357e-02, -3.8927e-02,\n         3.6598e-02, -6.5897e-03,  7.2850e-02, -7.3697e-02, -7.4113e-02,\n        -2.1735e-02, -8.4786e-02, -1.8825e-02, -3.7061e-02, -2.6121e-02,\n        -8.6749e-02,  3.1395e-02,  2.1357e-02, -8.1758e-03,  3.9698e-02,\n         7.3655e-02, -8.0701e-03, -2.3875e-02,  8.7334e-02, -3.8423e-02,\n        -5.3431e-02,  6.4656e-02,  2.9332e-02,  7.9109e-02,  5.5623e-02,\n         2.0697e-02, -2.4233e-02, -5.5066e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[-5.6237e-02, -7.7472e-02, -2.7705e-02,  4.2296e-02,  6.5902e-02,\n          8.5388e-02, -3.9716e-02, -6.9343e-02,  1.0369e-02,  5.7089e-02,\n         -7.8752e-02, -8.4844e-02,  1.5749e-02,  2.6977e-02, -6.4174e-03,\n          5.6892e-02,  1.5656e-03, -4.5576e-03, -3.5996e-02,  2.7118e-02,\n          6.9475e-02, -8.2710e-02,  2.4356e-02, -3.2846e-02,  3.8162e-02,\n          4.0543e-02, -5.9799e-02,  2.3425e-02,  4.8223e-02, -6.6100e-02,\n         -4.7293e-02, -4.5607e-02,  9.9235e-03,  3.6161e-02,  3.1167e-02,\n          2.2310e-02,  7.8038e-02, -4.7672e-02, -4.4009e-02, -4.7057e-02,\n          5.9551e-02, -6.8811e-02, -2.9543e-02,  2.1079e-02,  8.4609e-02,\n         -3.3825e-03, -6.8010e-02, -7.9188e-02,  7.5910e-02, -8.3342e-02,\n          4.1030e-02, -7.3948e-02, -5.2559e-02,  8.7348e-02, -3.8683e-02,\n          8.4983e-02, -4.5823e-02,  2.8027e-02, -6.8083e-02, -4.2776e-02,\n          8.6308e-02,  3.6107e-03, -3.9345e-02,  6.4164e-02, -5.4258e-02,\n         -4.6095e-02,  3.7557e-02, -1.0460e-02, -2.1554e-02,  5.8222e-02,\n          5.2416e-02, -9.8551e-03,  5.6103e-02, -2.6645e-02, -3.1935e-02,\n          3.2999e-02,  6.4683e-02, -9.9316e-03, -7.2754e-02,  1.0786e-02,\n         -5.7459e-02,  1.9946e-02,  3.8081e-02, -3.0618e-02, -4.1275e-02,\n         -2.6773e-02,  3.3178e-02,  7.6135e-02,  5.2770e-03,  6.3555e-02,\n         -8.7879e-03, -7.9921e-02,  6.5782e-03,  6.5957e-02,  1.7031e-02,\n         -6.5704e-03, -5.4391e-02,  2.8659e-02, -3.1725e-04, -5.5061e-02,\n         -1.0979e-02,  8.4450e-02,  4.0980e-02, -4.7349e-02, -6.3893e-02,\n         -5.6031e-02, -4.8037e-02,  1.4242e-02, -1.2344e-02, -2.8975e-02,\n          8.3626e-02,  3.2885e-02,  3.9192e-02,  8.2220e-02,  3.4081e-02,\n         -7.9384e-02, -4.5449e-03, -4.8517e-02, -5.6485e-03,  4.1660e-02,\n          6.9119e-02, -9.2252e-03,  2.3436e-02,  5.4927e-02, -5.1339e-02,\n          5.4906e-03, -8.6589e-02, -3.9084e-02],\n        [ 7.2780e-04, -5.7914e-02, -4.7222e-02,  8.4980e-02,  5.1617e-02,\n          3.2772e-02, -8.2243e-03, -3.0033e-02, -8.2802e-02, -8.0366e-02,\n          3.4399e-02,  9.9326e-03, -2.7259e-02,  5.9460e-02,  2.6539e-02,\n         -7.8355e-02,  1.4983e-03, -1.8667e-02,  1.4820e-02, -7.4333e-02,\n         -8.0218e-02,  1.0374e-02,  1.1204e-02,  2.3717e-02, -7.2962e-02,\n          1.3476e-02, -6.7522e-02, -8.5373e-02, -3.2513e-02,  8.8328e-02,\n         -7.2384e-02,  6.6588e-02,  4.7202e-02,  4.4240e-03,  2.2702e-02,\n         -5.6381e-02, -5.8953e-02,  6.5017e-02,  4.9509e-02,  2.4512e-03,\n          7.6804e-02, -3.8756e-02,  1.3873e-02, -4.2116e-02, -7.1869e-03,\n          3.6862e-02, -5.9248e-02, -5.9437e-02, -5.9983e-02, -4.2473e-02,\n         -1.5635e-02,  4.0171e-02,  5.7896e-02,  3.8986e-02,  2.7037e-03,\n         -7.1909e-02,  3.0274e-02, -3.4565e-02,  2.6469e-02,  1.8020e-02,\n          6.3191e-03,  3.8907e-02, -2.3091e-02,  1.1701e-02,  7.8280e-02,\n          8.5877e-02, -8.9961e-03, -3.2721e-02,  5.0250e-03,  6.1793e-02,\n         -4.8362e-02,  4.8954e-02, -8.1551e-02, -3.9306e-02, -6.1247e-02,\n          3.0094e-02,  5.5500e-02,  5.6797e-02, -7.8589e-02, -5.7316e-03,\n         -5.0912e-02,  1.1608e-02,  1.6413e-02,  1.6595e-02,  2.1669e-02,\n          3.9868e-02,  7.3800e-02,  1.4682e-02,  6.7864e-02,  2.3236e-03,\n         -1.4864e-02,  1.8635e-03, -7.3528e-03, -8.2590e-02,  8.5211e-02,\n         -6.8978e-02,  8.3664e-02,  3.7334e-02,  1.4413e-02,  1.2592e-02,\n         -4.7137e-02, -1.6167e-02,  5.3390e-02,  7.3296e-02,  5.3226e-02,\n         -6.2776e-02, -2.1236e-02,  5.0841e-02, -5.1350e-02,  2.0943e-02,\n          4.2106e-02, -1.7123e-02,  3.7255e-02, -6.5760e-02, -3.6652e-02,\n          2.2934e-02,  2.8446e-02,  4.9556e-02,  3.8557e-02, -6.4522e-02,\n          6.6098e-02, -4.0605e-02,  3.6877e-02, -1.2069e-02,  6.8800e-02,\n         -2.6602e-02,  3.6825e-02,  5.4986e-02],\n        [ 4.5651e-02, -2.4381e-02, -1.9070e-02,  5.4542e-02, -3.3742e-02,\n          3.8149e-02,  4.8648e-02,  7.6797e-02,  5.4566e-02,  3.6420e-02,\n          4.2031e-02, -8.3003e-02,  5.5911e-02, -3.6138e-02, -8.3197e-02,\n          1.5961e-02, -2.2656e-02, -4.9696e-02, -6.7424e-02,  4.3439e-02,\n          2.5768e-02,  7.5920e-02, -1.8085e-02,  6.5839e-02, -4.5083e-02,\n          3.4901e-02, -2.2620e-02, -6.6610e-02, -7.3244e-02, -8.4053e-02,\n         -2.7518e-02, -7.3610e-02,  5.9521e-02,  5.4597e-02,  1.0020e-02,\n          3.5771e-02,  2.3955e-02,  8.5264e-02, -6.7645e-02,  6.9966e-02,\n          6.2506e-02, -6.6990e-02, -7.4401e-02, -5.3720e-02,  6.4472e-02,\n          5.9486e-02, -1.8578e-02,  4.7616e-02, -7.3305e-02,  4.5236e-02,\n          4.1135e-02, -5.8091e-02,  3.6811e-02,  6.8200e-02,  3.7335e-03,\n          1.0964e-02, -4.7415e-06, -4.2127e-03,  6.9770e-02, -2.4708e-02,\n          1.5430e-02,  8.2802e-02,  6.5051e-02, -1.8832e-02,  1.9441e-02,\n          2.4384e-02, -3.3169e-03, -1.5227e-02, -7.0578e-02,  6.2831e-03,\n         -3.6984e-02, -2.2289e-02, -3.3068e-02,  7.1784e-03,  4.7002e-02,\n         -6.1500e-02, -8.6824e-02,  1.1812e-02, -4.9375e-02,  1.7629e-02,\n         -3.2380e-02,  2.0631e-03,  1.9033e-02, -5.6198e-02, -2.9311e-03,\n         -1.0358e-02,  6.5619e-02,  5.8873e-02,  9.2674e-04,  3.0950e-02,\n         -4.4072e-02, -1.1219e-02,  6.4781e-02, -6.4179e-02,  8.1278e-02,\n          1.6829e-02, -5.0409e-02, -7.2910e-02,  2.9316e-02, -2.0051e-02,\n          4.0246e-02, -2.8436e-03, -5.8265e-03, -2.9942e-02, -5.8797e-02,\n          5.7786e-02,  4.8160e-02,  4.8076e-02, -7.5157e-02, -2.3719e-02,\n          1.2378e-02, -3.3996e-02, -1.1493e-02, -5.4164e-02,  2.7601e-02,\n          3.3951e-02, -8.5460e-02, -5.2794e-02,  4.8190e-02,  6.5948e-02,\n          6.2227e-02, -6.0555e-03,  4.4262e-02,  6.4169e-02, -7.7532e-02,\n          4.6255e-04, -7.9796e-02,  3.5915e-02],\n        [-3.0525e-02,  4.9549e-03,  7.9379e-02,  3.6417e-03,  5.0397e-02,\n         -5.8514e-02, -3.6181e-03, -7.6562e-03,  1.4000e-02, -1.0942e-04,\n          7.8480e-02,  7.7050e-02,  2.2351e-02,  6.9525e-02,  5.9674e-03,\n          8.6249e-02,  8.1118e-02, -4.7843e-03,  9.5119e-03,  4.1550e-02,\n         -2.8497e-02, -6.1169e-02,  4.3036e-02,  8.3813e-02,  5.5025e-02,\n         -3.1644e-02,  4.2060e-02, -3.2089e-02,  6.6070e-03, -6.0397e-02,\n          4.3231e-02, -2.9860e-02,  3.8814e-02,  5.2265e-02,  7.9042e-02,\n          6.7571e-03,  4.3920e-02, -6.2394e-02, -8.8022e-02,  2.2975e-02,\n          4.8803e-03,  7.2694e-02, -4.5394e-02, -7.4097e-02, -5.3943e-02,\n         -1.4874e-02,  6.3319e-02, -1.7662e-02, -2.8573e-02,  6.3831e-02,\n          4.6546e-02,  3.5237e-02,  4.4235e-02,  8.1260e-02, -4.8561e-04,\n          1.4317e-02,  6.3401e-02,  5.4970e-02, -2.6692e-02,  3.3137e-02,\n         -4.1712e-02, -1.6915e-02,  6.0936e-02, -1.5719e-02,  3.6424e-02,\n          2.3551e-02,  5.5825e-02, -6.1410e-02, -5.6409e-02,  7.7923e-02,\n          3.4201e-02,  3.4524e-02,  4.4623e-02,  2.6183e-02, -6.7946e-02,\n          5.6149e-02,  3.1389e-02,  2.0955e-02, -8.2281e-02,  4.9136e-02,\n          8.5703e-02, -8.2562e-02, -6.7133e-02, -1.2761e-02, -8.6855e-02,\n          3.2044e-02,  5.9312e-02,  2.5033e-02, -8.3099e-04,  3.6805e-02,\n         -5.6906e-02, -4.6063e-02, -7.0646e-02,  1.7308e-02, -2.7281e-02,\n          1.7717e-02,  1.7273e-02,  3.9075e-02,  6.4005e-03, -4.6749e-02,\n         -5.4179e-02,  2.3439e-02,  1.6492e-03, -2.6512e-02, -3.7744e-02,\n          2.2059e-02,  1.9105e-02, -4.7363e-02, -2.1792e-02, -8.5559e-02,\n         -8.6535e-02,  7.1785e-03,  3.6634e-02, -4.8074e-02,  2.5747e-02,\n          1.8634e-02,  2.4127e-02, -4.6877e-02,  2.8244e-02, -6.0144e-02,\n          7.7920e-02,  5.8718e-02, -6.9905e-02,  3.7311e-02, -4.8957e-02,\n          5.7240e-02,  1.7515e-02, -9.3112e-03]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0536,  0.0238, -0.0658,  0.0781], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x7fd29f0a0fd0>":	{
                    "alpha":	0.6,
                    "aux_buf_size":	5000,
                    "aux_buffer":	{
                        "act_buf":	"[0 0 0 ... 0 0 0]",
                        "done_buf":	"[False False False ... False False False]",
                        "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                        "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "priorities":	"[0. 0. 0. ... 0. 0. 0.]",
                        "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                        "timestamps":	"[0 0 0 ... 0 0 0]"
                    },
                    "aux_ptr":	0,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "capacity":	50000,
                    "current_segment":	0,
                    "epsilon":	1e-06,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	250,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "sample_decay":	0.8,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2066,  0.1574,  0.2937,  0.1923, -0.1586,  0.1466,  0.1221, -0.3135,\n        -0.0145, -0.0383,  0.2500, -0.1123, -0.2638,  0.1749,  0.3291, -0.1133,\n         0.0625, -0.3236, -0.3026, -0.0564,  0.0986,  0.1465,  0.1091, -0.3315,\n        -0.2391, -0.0671, -0.0548, -0.0014,  0.1550, -0.1515, -0.2847,  0.2292,\n         0.1882,  0.2194, -0.0784, -0.2333,  0.1190,  0.0986,  0.0905,  0.3251,\n        -0.0641,  0.0659, -0.0385, -0.0745, -0.1760, -0.0436,  0.0145,  0.0782,\n        -0.3020, -0.1318, -0.1934,  0.1594,  0.0621, -0.0111, -0.2862,  0.3134,\n         0.1289, -0.0332,  0.1865,  0.1066, -0.2808, -0.1742,  0.2231, -0.1010,\n         0.2802, -0.2557, -0.1477, -0.2671, -0.3304, -0.2942, -0.2097, -0.0808,\n         0.2910, -0.1228,  0.1160,  0.0785, -0.1880,  0.0475,  0.2814,  0.2692,\n        -0.0548, -0.3412, -0.0562,  0.2216,  0.1156,  0.0922, -0.1839, -0.2373,\n         0.0126,  0.3502, -0.2316,  0.0084,  0.3488, -0.1082, -0.1466,  0.2023,\n         0.0088,  0.2924, -0.3078,  0.0215,  0.0938,  0.1125,  0.2316,  0.0209,\n         0.2852,  0.3217, -0.3266, -0.0235,  0.1858, -0.0811,  0.0153, -0.0490,\n        -0.0766, -0.0112,  0.0860,  0.1240,  0.1250, -0.0562,  0.1055,  0.1463,\n         0.2457,  0.0183,  0.0367, -0.3477,  0.0007, -0.1706, -0.2625,  0.1896],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2750,  0.2990, -0.0396,  ...,  0.2689, -0.0796,  0.1215],\n        [-0.0052,  0.0496,  0.0037,  ..., -0.1555, -0.2903,  0.0081],\n        [ 0.3184, -0.3491, -0.1025,  ...,  0.1518, -0.1524, -0.2859],\n        ...,\n        [ 0.1860, -0.2224, -0.2530,  ..., -0.1708,  0.3477,  0.1364],\n        [-0.2240,  0.3074, -0.1292,  ..., -0.2202,  0.3393,  0.1936],\n        [-0.1370,  0.2358, -0.1709,  ..., -0.0406,  0.3015,  0.0341]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-4.8277e-02, -8.4242e-02,  5.2378e-05, -2.0259e-02, -7.1606e-02,\n        -1.7601e-02, -8.2586e-02, -1.7260e-02, -3.0118e-02, -7.7141e-02,\n         2.1366e-02,  5.0091e-02,  1.1663e-02, -1.7394e-02, -8.7220e-02,\n         4.2945e-02,  1.0616e-02, -5.2032e-02,  6.3205e-02,  5.3510e-02,\n         5.3621e-02, -5.7752e-02,  3.0098e-02, -3.9715e-02,  2.7979e-02,\n        -2.2543e-02,  3.7811e-02,  4.9159e-03,  8.0356e-02,  7.3807e-02,\n         5.4922e-02,  2.8098e-02, -8.6363e-02,  1.0008e-02,  8.2197e-02,\n         7.6747e-02,  1.8586e-02,  7.3866e-03, -3.1303e-03,  5.1687e-02,\n         7.5850e-02, -4.7679e-03, -4.8170e-02, -4.5465e-02, -5.7308e-02,\n         8.5989e-03, -5.8561e-02,  2.7018e-02,  6.5154e-02,  3.5533e-02,\n         5.7262e-02,  8.3401e-02,  2.4345e-02,  7.1569e-02,  2.6044e-02,\n        -7.3598e-03,  4.8476e-02,  1.5308e-02, -6.9788e-04, -4.8334e-02,\n         6.2478e-02,  1.3961e-02,  1.4283e-04,  4.5188e-02,  7.0604e-02,\n         4.9298e-02, -1.2938e-02,  1.9699e-02,  3.6992e-02, -7.6561e-02,\n         1.0603e-02,  1.0908e-02,  7.7345e-02,  4.3685e-02, -6.0095e-02,\n        -5.1424e-02,  1.1053e-03,  5.7017e-02, -7.2202e-02, -7.9147e-02,\n        -8.4170e-02,  2.7131e-02, -3.4847e-03, -3.6592e-02, -2.8945e-02,\n         2.5339e-02, -5.1328e-02, -7.2671e-03, -6.9480e-02,  4.5163e-02,\n        -4.4963e-02, -7.7465e-02,  4.0514e-03,  4.8947e-02,  7.0769e-02,\n        -1.5658e-02,  5.8550e-02, -3.2763e-02, -3.8357e-02, -3.8927e-02,\n         3.6598e-02, -6.5897e-03,  7.2850e-02, -7.3697e-02, -7.4113e-02,\n        -2.1735e-02, -8.4786e-02, -1.8825e-02, -3.7061e-02, -2.6121e-02,\n        -8.6749e-02,  3.1395e-02,  2.1357e-02, -8.1758e-03,  3.9698e-02,\n         7.3655e-02, -8.0701e-03, -2.3875e-02,  8.7334e-02, -3.8423e-02,\n        -5.3431e-02,  6.4656e-02,  2.9332e-02,  7.9109e-02,  5.5623e-02,\n         2.0697e-02, -2.4233e-02, -5.5066e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0279, -0.0874, -0.0437,  ..., -0.0091, -0.0579,  0.0594],\n        [ 0.0384,  0.0259, -0.0252,  ..., -0.0858,  0.0719, -0.0408],\n        [-0.0334,  0.0302, -0.0785,  ..., -0.0264, -0.0610, -0.0558],\n        ...,\n        [-0.0341, -0.0212,  0.0349,  ..., -0.0330,  0.0216, -0.0764],\n        [ 0.0823, -0.0292,  0.0238,  ...,  0.0308,  0.0754, -0.0646],\n        [ 0.0137, -0.0169, -0.0267,  ..., -0.0531, -0.0185,  0.0250]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0536,  0.0238, -0.0658,  0.0781], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-5.6237e-02, -7.7472e-02, -2.7705e-02,  4.2296e-02,  6.5902e-02,\n          8.5388e-02, -3.9716e-02, -6.9343e-02,  1.0369e-02,  5.7089e-02,\n         -7.8752e-02, -8.4844e-02,  1.5749e-02,  2.6977e-02, -6.4174e-03,\n          5.6892e-02,  1.5656e-03, -4.5576e-03, -3.5996e-02,  2.7118e-02,\n          6.9475e-02, -8.2710e-02,  2.4356e-02, -3.2846e-02,  3.8162e-02,\n          4.0543e-02, -5.9799e-02,  2.3425e-02,  4.8223e-02, -6.6100e-02,\n         -4.7293e-02, -4.5607e-02,  9.9235e-03,  3.6161e-02,  3.1167e-02,\n          2.2310e-02,  7.8038e-02, -4.7672e-02, -4.4009e-02, -4.7057e-02,\n          5.9551e-02, -6.8811e-02, -2.9543e-02,  2.1079e-02,  8.4609e-02,\n         -3.3825e-03, -6.8010e-02, -7.9188e-02,  7.5910e-02, -8.3342e-02,\n          4.1030e-02, -7.3948e-02, -5.2559e-02,  8.7348e-02, -3.8683e-02,\n          8.4983e-02, -4.5823e-02,  2.8027e-02, -6.8083e-02, -4.2776e-02,\n          8.6308e-02,  3.6107e-03, -3.9345e-02,  6.4164e-02, -5.4258e-02,\n         -4.6095e-02,  3.7557e-02, -1.0460e-02, -2.1554e-02,  5.8222e-02,\n          5.2416e-02, -9.8551e-03,  5.6103e-02, -2.6645e-02, -3.1935e-02,\n          3.2999e-02,  6.4683e-02, -9.9316e-03, -7.2754e-02,  1.0786e-02,\n         -5.7459e-02,  1.9946e-02,  3.8081e-02, -3.0618e-02, -4.1275e-02,\n         -2.6773e-02,  3.3178e-02,  7.6135e-02,  5.2770e-03,  6.3555e-02,\n         -8.7879e-03, -7.9921e-02,  6.5782e-03,  6.5957e-02,  1.7031e-02,\n         -6.5704e-03, -5.4391e-02,  2.8659e-02, -3.1725e-04, -5.5061e-02,\n         -1.0979e-02,  8.4450e-02,  4.0980e-02, -4.7349e-02, -6.3893e-02,\n         -5.6031e-02, -4.8037e-02,  1.4242e-02, -1.2344e-02, -2.8975e-02,\n          8.3626e-02,  3.2885e-02,  3.9192e-02,  8.2220e-02,  3.4081e-02,\n         -7.9384e-02, -4.5449e-03, -4.8517e-02, -5.6485e-03,  4.1660e-02,\n          6.9119e-02, -9.2252e-03,  2.3436e-02,  5.4927e-02, -5.1339e-02,\n          5.4906e-03, -8.6589e-02, -3.9084e-02],\n        [ 7.2780e-04, -5.7914e-02, -4.7222e-02,  8.4980e-02,  5.1617e-02,\n          3.2772e-02, -8.2243e-03, -3.0033e-02, -8.2802e-02, -8.0366e-02,\n          3.4399e-02,  9.9326e-03, -2.7259e-02,  5.9460e-02,  2.6539e-02,\n         -7.8355e-02,  1.4983e-03, -1.8667e-02,  1.4820e-02, -7.4333e-02,\n         -8.0218e-02,  1.0374e-02,  1.1204e-02,  2.3717e-02, -7.2962e-02,\n          1.3476e-02, -6.7522e-02, -8.5373e-02, -3.2513e-02,  8.8328e-02,\n         -7.2384e-02,  6.6588e-02,  4.7202e-02,  4.4240e-03,  2.2702e-02,\n         -5.6381e-02, -5.8953e-02,  6.5017e-02,  4.9509e-02,  2.4512e-03,\n          7.6804e-02, -3.8756e-02,  1.3873e-02, -4.2116e-02, -7.1869e-03,\n          3.6862e-02, -5.9248e-02, -5.9437e-02, -5.9983e-02, -4.2473e-02,\n         -1.5635e-02,  4.0171e-02,  5.7896e-02,  3.8986e-02,  2.7037e-03,\n         -7.1909e-02,  3.0274e-02, -3.4565e-02,  2.6469e-02,  1.8020e-02,\n          6.3191e-03,  3.8907e-02, -2.3091e-02,  1.1701e-02,  7.8280e-02,\n          8.5877e-02, -8.9961e-03, -3.2721e-02,  5.0250e-03,  6.1793e-02,\n         -4.8362e-02,  4.8954e-02, -8.1551e-02, -3.9306e-02, -6.1247e-02,\n          3.0094e-02,  5.5500e-02,  5.6797e-02, -7.8589e-02, -5.7316e-03,\n         -5.0912e-02,  1.1608e-02,  1.6413e-02,  1.6595e-02,  2.1669e-02,\n          3.9868e-02,  7.3800e-02,  1.4682e-02,  6.7864e-02,  2.3236e-03,\n         -1.4864e-02,  1.8635e-03, -7.3528e-03, -8.2590e-02,  8.5211e-02,\n         -6.8978e-02,  8.3664e-02,  3.7334e-02,  1.4413e-02,  1.2592e-02,\n         -4.7137e-02, -1.6167e-02,  5.3390e-02,  7.3296e-02,  5.3226e-02,\n         -6.2776e-02, -2.1236e-02,  5.0841e-02, -5.1350e-02,  2.0943e-02,\n          4.2106e-02, -1.7123e-02,  3.7255e-02, -6.5760e-02, -3.6652e-02,\n          2.2934e-02,  2.8446e-02,  4.9556e-02,  3.8557e-02, -6.4522e-02,\n          6.6098e-02, -4.0605e-02,  3.6877e-02, -1.2069e-02,  6.8800e-02,\n         -2.6602e-02,  3.6825e-02,  5.4986e-02],\n        [ 4.5651e-02, -2.4381e-02, -1.9070e-02,  5.4542e-02, -3.3742e-02,\n          3.8149e-02,  4.8648e-02,  7.6797e-02,  5.4566e-02,  3.6420e-02,\n          4.2031e-02, -8.3003e-02,  5.5911e-02, -3.6138e-02, -8.3197e-02,\n          1.5961e-02, -2.2656e-02, -4.9696e-02, -6.7424e-02,  4.3439e-02,\n          2.5768e-02,  7.5920e-02, -1.8085e-02,  6.5839e-02, -4.5083e-02,\n          3.4901e-02, -2.2620e-02, -6.6610e-02, -7.3244e-02, -8.4053e-02,\n         -2.7518e-02, -7.3610e-02,  5.9521e-02,  5.4597e-02,  1.0020e-02,\n          3.5771e-02,  2.3955e-02,  8.5264e-02, -6.7645e-02,  6.9966e-02,\n          6.2506e-02, -6.6990e-02, -7.4401e-02, -5.3720e-02,  6.4472e-02,\n          5.9486e-02, -1.8578e-02,  4.7616e-02, -7.3305e-02,  4.5236e-02,\n          4.1135e-02, -5.8091e-02,  3.6811e-02,  6.8200e-02,  3.7335e-03,\n          1.0964e-02, -4.7415e-06, -4.2127e-03,  6.9770e-02, -2.4708e-02,\n          1.5430e-02,  8.2802e-02,  6.5051e-02, -1.8832e-02,  1.9441e-02,\n          2.4384e-02, -3.3169e-03, -1.5227e-02, -7.0578e-02,  6.2831e-03,\n         -3.6984e-02, -2.2289e-02, -3.3068e-02,  7.1784e-03,  4.7002e-02,\n         -6.1500e-02, -8.6824e-02,  1.1812e-02, -4.9375e-02,  1.7629e-02,\n         -3.2380e-02,  2.0631e-03,  1.9033e-02, -5.6198e-02, -2.9311e-03,\n         -1.0358e-02,  6.5619e-02,  5.8873e-02,  9.2674e-04,  3.0950e-02,\n         -4.4072e-02, -1.1219e-02,  6.4781e-02, -6.4179e-02,  8.1278e-02,\n          1.6829e-02, -5.0409e-02, -7.2910e-02,  2.9316e-02, -2.0051e-02,\n          4.0246e-02, -2.8436e-03, -5.8265e-03, -2.9942e-02, -5.8797e-02,\n          5.7786e-02,  4.8160e-02,  4.8076e-02, -7.5157e-02, -2.3719e-02,\n          1.2378e-02, -3.3996e-02, -1.1493e-02, -5.4164e-02,  2.7601e-02,\n          3.3951e-02, -8.5460e-02, -5.2794e-02,  4.8190e-02,  6.5948e-02,\n          6.2227e-02, -6.0555e-03,  4.4262e-02,  6.4169e-02, -7.7532e-02,\n          4.6255e-04, -7.9796e-02,  3.5915e-02],\n        [-3.0525e-02,  4.9549e-03,  7.9379e-02,  3.6417e-03,  5.0397e-02,\n         -5.8514e-02, -3.6181e-03, -7.6562e-03,  1.4000e-02, -1.0942e-04,\n          7.8480e-02,  7.7050e-02,  2.2351e-02,  6.9525e-02,  5.9674e-03,\n          8.6249e-02,  8.1118e-02, -4.7843e-03,  9.5119e-03,  4.1550e-02,\n         -2.8497e-02, -6.1169e-02,  4.3036e-02,  8.3813e-02,  5.5025e-02,\n         -3.1644e-02,  4.2060e-02, -3.2089e-02,  6.6070e-03, -6.0397e-02,\n          4.3231e-02, -2.9860e-02,  3.8814e-02,  5.2265e-02,  7.9042e-02,\n          6.7571e-03,  4.3920e-02, -6.2394e-02, -8.8022e-02,  2.2975e-02,\n          4.8803e-03,  7.2694e-02, -4.5394e-02, -7.4097e-02, -5.3943e-02,\n         -1.4874e-02,  6.3319e-02, -1.7662e-02, -2.8573e-02,  6.3831e-02,\n          4.6546e-02,  3.5237e-02,  4.4235e-02,  8.1260e-02, -4.8561e-04,\n          1.4317e-02,  6.3401e-02,  5.4970e-02, -2.6692e-02,  3.3137e-02,\n         -4.1712e-02, -1.6915e-02,  6.0936e-02, -1.5719e-02,  3.6424e-02,\n          2.3551e-02,  5.5825e-02, -6.1410e-02, -5.6409e-02,  7.7923e-02,\n          3.4201e-02,  3.4524e-02,  4.4623e-02,  2.6183e-02, -6.7946e-02,\n          5.6149e-02,  3.1389e-02,  2.0955e-02, -8.2281e-02,  4.9136e-02,\n          8.5703e-02, -8.2562e-02, -6.7133e-02, -1.2761e-02, -8.6855e-02,\n          3.2044e-02,  5.9312e-02,  2.5033e-02, -8.3099e-04,  3.6805e-02,\n         -5.6906e-02, -4.6063e-02, -7.0646e-02,  1.7308e-02, -2.7281e-02,\n          1.7717e-02,  1.7273e-02,  3.9075e-02,  6.4005e-03, -4.6749e-02,\n         -5.4179e-02,  2.3439e-02,  1.6492e-03, -2.6512e-02, -3.7744e-02,\n          2.2059e-02,  1.9105e-02, -4.7363e-02, -2.1792e-02, -8.5559e-02,\n         -8.6535e-02,  7.1785e-03,  3.6634e-02, -4.8074e-02,  2.5747e-02,\n          1.8634e-02,  2.4127e-02, -4.6877e-02,  2.8244e-02, -6.0144e-02,\n          7.7920e-02,  5.8718e-02, -6.9905e-02,  3.7311e-02, -4.8957e-02,\n          5.7240e-02,  1.7515e-02, -9.3112e-03]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7fd29cd3fd50>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s398260000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s398260000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}