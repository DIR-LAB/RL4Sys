{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0003,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s400190000"
    },
    "max_sample_age":	250,
    "q_lr":	0.0003,
    "sample_decay":	0.8,
    "seed":	400190000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7b86333e11d0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0003,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0918,  0.2614,  0.1102,  0.2022, -0.1325, -0.3122, -0.0154, -0.1657,\n         0.1581, -0.3211,  0.2455,  0.0650, -0.2237, -0.1421,  0.1002,  0.0300,\n         0.2957, -0.0249, -0.0610,  0.0229, -0.2342,  0.0507, -0.0668, -0.0120,\n         0.3533,  0.3488,  0.1573,  0.1798,  0.2893, -0.1415, -0.0863,  0.2982,\n         0.2093, -0.0276, -0.0152, -0.1475,  0.2881, -0.3449,  0.2921, -0.2957,\n         0.3178,  0.1355,  0.1692,  0.2260,  0.0676,  0.1159, -0.0601, -0.3411,\n         0.0631, -0.1978,  0.3284, -0.0348,  0.0139,  0.2409,  0.0266,  0.2499,\n        -0.0667, -0.3287,  0.3257,  0.1018,  0.2172,  0.3301, -0.2354, -0.2910,\n        -0.0683, -0.2894, -0.0392, -0.1034,  0.0223,  0.2188, -0.2662,  0.2706,\n         0.1196,  0.2935, -0.3365,  0.0660,  0.2019, -0.2887, -0.0918, -0.1044,\n         0.3286,  0.3349,  0.0253, -0.1013, -0.0073,  0.0960,  0.0381, -0.1274,\n        -0.0435,  0.0466,  0.0148,  0.1642, -0.2999, -0.0210, -0.3513,  0.2078,\n        -0.0226, -0.2808, -0.0748,  0.0043, -0.1478, -0.1467, -0.2615,  0.0694,\n        -0.0842, -0.3294, -0.2960, -0.0363,  0.1638,  0.3234,  0.1421, -0.0552,\n        -0.1028, -0.2163,  0.0323,  0.0668, -0.2671,  0.1479, -0.0544, -0.1981,\n        -0.1311,  0.0096,  0.2521,  0.2139, -0.2956,  0.2505,  0.0553, -0.0442],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 9.6117e-02,  3.3575e-02,  5.7377e-03,  ...,  3.1259e-01,\n          2.4942e-01, -3.0645e-01],\n        [-3.1821e-01,  5.1874e-04, -8.7753e-02,  ...,  2.6711e-01,\n          6.8322e-02,  7.0950e-02],\n        [ 1.2014e-01, -1.7561e-01,  2.0875e-01,  ..., -3.3449e-01,\n         -6.5303e-02, -1.8729e-01],\n        ...,\n        [-2.5177e-01,  6.0232e-02, -2.8489e-01,  ..., -1.6430e-01,\n         -5.5727e-02,  2.8043e-01],\n        [-1.1115e-01,  1.9852e-01,  2.1394e-01,  ...,  8.6828e-02,\n          6.7459e-02, -2.4486e-01],\n        [-2.1078e-04,  2.3087e-01, -1.8767e-01,  ...,  9.0248e-02,\n          1.0604e-01,  2.0131e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0010, -0.0288, -0.0579, -0.0645,  0.0399,  0.0225,  0.0612, -0.0682,\n        -0.0817, -0.0014, -0.0608, -0.0749, -0.0865,  0.0074,  0.0118, -0.0599,\n         0.0495, -0.0773, -0.0710, -0.0405,  0.0824,  0.0188, -0.0806,  0.0099,\n         0.0484, -0.0754, -0.0487,  0.0459, -0.0741, -0.0222,  0.0222,  0.0210,\n        -0.0049, -0.0478,  0.0725, -0.0155,  0.0558,  0.0761, -0.0365, -0.0823,\n         0.0700, -0.0005, -0.0055, -0.0403, -0.0248, -0.0737,  0.0292, -0.0467,\n         0.0547, -0.0611, -0.0319, -0.0483, -0.0148,  0.0786,  0.0049, -0.0064,\n        -0.0807,  0.0844, -0.0573,  0.0323,  0.0028,  0.0391, -0.0613, -0.0882,\n         0.0633,  0.0575,  0.0080,  0.0469, -0.0691,  0.0798,  0.0749, -0.0867,\n         0.0297, -0.0298, -0.0153,  0.0291, -0.0157, -0.0070, -0.0876,  0.0138,\n         0.0147, -0.0802,  0.0124,  0.0272,  0.0731, -0.0314, -0.0257, -0.0699,\n        -0.0421, -0.0232, -0.0254,  0.0629,  0.0268, -0.0874, -0.0048, -0.0212,\n         0.0235,  0.0273, -0.0100, -0.0495,  0.0814, -0.0575,  0.0061, -0.0339,\n         0.0585,  0.0422, -0.0777,  0.0461,  0.0873,  0.0577,  0.0049,  0.0407,\n         0.0371, -0.0731,  0.0078,  0.0693,  0.0636,  0.0822,  0.0438, -0.0207,\n         0.0680,  0.0469,  0.0051,  0.0781, -0.0091, -0.0329, -0.0071,  0.0061],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0798,  0.0878, -0.0629,  ..., -0.0268,  0.0051, -0.0781],\n        [-0.0524,  0.0095, -0.0136,  ...,  0.0628,  0.0083,  0.0653],\n        [ 0.0188,  0.0760,  0.0133,  ...,  0.0781,  0.0081, -0.0338],\n        ...,\n        [ 0.0727, -0.0008,  0.0450,  ...,  0.0564,  0.0673,  0.0660],\n        [-0.0725, -0.0008, -0.0210,  ..., -0.0422,  0.0117,  0.0187],\n        [-0.0206, -0.0465, -0.0315,  ..., -0.0120, -0.0731,  0.0247]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0587,  0.0348,  0.0336, -0.0798], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 6.9576e-02,  4.2474e-02,  7.2192e-04,  5.4270e-02,  7.9220e-02,\n          4.4532e-02, -1.0158e-02, -8.2602e-03,  5.0923e-02, -6.6043e-02,\n         -7.1308e-02,  3.5365e-02, -9.0695e-03, -4.1621e-02, -1.1390e-02,\n          1.3113e-02,  5.5693e-02, -7.2619e-02, -3.3042e-02, -2.9538e-02,\n          4.8228e-02, -5.3530e-02,  6.5503e-02,  1.3881e-02,  6.5342e-02,\n         -4.8926e-02,  1.3413e-03, -1.6905e-02, -5.4249e-02, -1.8222e-02,\n          2.5176e-02, -7.8269e-02,  3.9474e-02,  3.7604e-02,  1.1644e-02,\n         -5.7487e-02,  8.2605e-03,  1.7766e-02,  8.0231e-02,  6.4900e-03,\n         -4.1721e-02, -3.6902e-02, -9.5754e-03,  4.2568e-03, -2.3953e-02,\n          8.1519e-02,  4.6304e-02, -8.5689e-02, -4.5381e-02, -4.8613e-02,\n         -3.4438e-02,  6.3197e-03,  4.7992e-02,  5.7803e-02,  8.1416e-02,\n         -3.7578e-02,  7.9222e-02, -6.3691e-02, -5.1998e-02,  4.7263e-02,\n          4.8816e-02,  8.4004e-02,  4.1697e-02, -6.2332e-03, -7.7397e-02,\n          2.8699e-02, -6.5757e-03,  8.2041e-02, -7.3723e-02,  8.3941e-03,\n          5.4450e-02, -4.0077e-02, -2.0849e-02,  4.5956e-02, -5.0576e-02,\n         -3.7525e-02, -7.0244e-03,  7.9236e-02, -8.4102e-02,  5.4396e-02,\n          9.2646e-03,  6.0266e-02,  4.1911e-02, -5.3750e-03,  3.7115e-02,\n          6.5386e-02,  1.6667e-02, -6.0684e-02,  3.3910e-02,  4.1098e-03,\n          7.3264e-02,  2.6706e-02, -1.6318e-02, -6.5055e-03, -1.9844e-02,\n          3.9902e-03,  4.1180e-03, -7.0792e-02,  6.3522e-02, -8.1222e-03,\n         -2.5247e-02, -7.4173e-03, -8.3854e-02,  8.8204e-03, -1.2468e-03,\n         -5.9653e-02, -4.2100e-02,  3.6699e-02,  4.7612e-02,  8.2127e-02,\n          4.8305e-02,  6.9135e-02, -6.8147e-03, -6.4671e-02,  4.9885e-02,\n          6.1440e-02,  3.7747e-03, -8.7838e-02,  1.2130e-02, -1.5214e-02,\n          4.2007e-02, -8.6717e-02,  1.2156e-02,  7.4698e-02,  7.5588e-02,\n         -8.3475e-02, -3.6997e-02, -9.3381e-04],\n        [ 4.8504e-02, -4.9898e-02, -4.1488e-02, -7.6533e-02, -4.3549e-02,\n         -7.4657e-02, -1.1039e-02, -6.4743e-02, -5.8999e-02,  1.2661e-02,\n          2.5026e-02, -5.2219e-02, -8.7323e-02, -3.8930e-02, -4.9903e-04,\n          5.9164e-02, -1.5840e-02,  6.2124e-02,  4.3249e-02,  3.6950e-02,\n          8.6150e-02,  4.4476e-02, -2.5593e-02, -5.2255e-02,  3.6110e-02,\n          3.4763e-02,  4.2768e-02,  2.9274e-02,  3.2703e-02,  5.5158e-02,\n         -7.7614e-02, -7.4417e-02, -1.1534e-03, -7.2799e-02,  5.8190e-02,\n         -4.5861e-02, -4.0309e-02,  7.2528e-02,  4.0720e-02,  1.0286e-02,\n          8.7121e-02, -2.7888e-02, -8.5805e-02, -5.7001e-02, -7.4561e-02,\n          2.1450e-02, -5.5504e-02, -4.6848e-02,  3.8400e-02, -7.3906e-03,\n          2.0664e-02, -5.1169e-02, -8.0404e-02, -1.7264e-02,  5.4696e-03,\n         -1.1107e-02, -6.3109e-02, -8.1110e-02,  5.8714e-02,  3.0589e-02,\n          4.4533e-02,  6.1070e-02, -4.2276e-02, -1.0979e-02, -2.9888e-02,\n          4.8598e-02, -7.2326e-02, -3.3930e-02, -6.7193e-02, -5.0769e-02,\n          3.7855e-02,  1.3114e-02, -1.7981e-02,  6.0714e-02,  4.3230e-03,\n          7.1817e-02, -4.8308e-02, -1.5161e-02,  8.0607e-02,  5.8545e-02,\n         -1.3821e-02, -8.5866e-02,  5.8675e-02,  3.4810e-02, -9.1336e-03,\n         -1.2304e-02,  5.4964e-02,  3.2920e-02,  5.3965e-03, -7.3495e-02,\n         -4.6199e-02, -8.6672e-02, -8.0175e-02,  2.3845e-02,  2.1116e-03,\n         -7.1013e-02, -6.1975e-02,  7.8053e-02, -6.8687e-02,  3.2219e-02,\n          5.5086e-02,  2.9094e-02, -6.0027e-02,  6.7930e-02, -2.6632e-02,\n         -5.3388e-02, -7.3205e-02, -9.5099e-03,  2.2206e-02, -6.6931e-02,\n         -4.5079e-02, -5.6357e-02,  4.6004e-02,  5.7779e-02, -3.4141e-02,\n         -6.1408e-02, -1.5974e-02, -4.0698e-02,  3.2748e-02,  1.8782e-02,\n         -6.5616e-02,  3.5058e-02, -1.7915e-02,  5.6655e-03,  4.7722e-03,\n          5.7936e-02,  3.8311e-02, -7.4468e-02],\n        [-7.9698e-02,  8.7585e-02, -4.1645e-02, -3.4176e-03, -1.9255e-03,\n         -7.5748e-03,  1.6780e-02,  1.1755e-02, -4.6409e-02,  3.4311e-02,\n          4.3533e-02, -2.1563e-02, -2.3047e-03, -6.1965e-02,  1.2090e-02,\n          6.7699e-02, -3.0065e-02,  4.2045e-02, -7.2536e-02,  7.8914e-02,\n         -6.3737e-02,  2.6286e-02, -3.6474e-02,  7.1681e-02, -7.7351e-02,\n         -6.9283e-02, -3.9667e-02, -4.0922e-02, -6.2066e-02, -2.0990e-03,\n         -1.4241e-02, -6.1206e-03, -7.6588e-02,  2.7949e-02, -7.1056e-02,\n         -3.3690e-02, -3.4594e-02, -6.4445e-02,  5.7078e-02,  1.0161e-02,\n         -1.1683e-03,  3.1718e-02,  4.7757e-02,  8.0154e-02, -2.5474e-02,\n          3.4392e-05,  3.9790e-02, -2.0259e-02, -5.6484e-02, -2.5168e-02,\n          4.4197e-02,  2.8722e-02, -2.9618e-02, -6.8782e-02, -6.9532e-02,\n         -6.0124e-02, -8.4221e-02, -1.7966e-02, -7.8811e-02, -5.1154e-02,\n          7.7393e-02, -5.8903e-02, -4.2785e-02,  5.9382e-02,  3.6863e-02,\n         -4.0522e-02,  3.8512e-02, -3.1269e-02, -4.6608e-02,  5.4503e-02,\n         -4.9904e-02,  5.3257e-02, -2.0212e-02,  4.8425e-02, -8.6951e-02,\n         -5.5203e-02,  5.9897e-03,  6.7126e-02,  2.9216e-03, -5.4980e-03,\n         -5.1667e-02,  7.7548e-02,  5.7707e-02,  2.9334e-02, -3.8072e-02,\n          8.4025e-02, -6.9460e-02,  3.5286e-02,  5.7815e-02, -5.9084e-02,\n         -2.0468e-02,  8.2555e-02,  5.1035e-02, -1.3088e-02, -5.1929e-02,\n          7.7186e-02,  4.1185e-02, -5.9200e-02, -7.4668e-02, -4.2174e-02,\n          3.4007e-02,  8.3571e-02,  4.6816e-02, -1.1884e-02, -4.1158e-02,\n         -6.0517e-02, -7.1875e-02, -7.6698e-02,  1.5998e-02,  8.3635e-02,\n         -1.4795e-02,  1.4974e-03, -2.5507e-02, -7.0284e-02,  8.3579e-02,\n         -1.2853e-02, -4.4010e-02, -1.9196e-02, -6.6817e-02,  7.5116e-02,\n         -5.6890e-02,  3.0268e-02,  8.2513e-02,  2.5873e-02,  3.9488e-02,\n         -3.5013e-02, -2.0282e-02, -4.3279e-02],\n        [-6.1375e-02,  5.5066e-02,  2.2869e-02,  5.7429e-02, -8.5334e-02,\n          7.7162e-02,  2.8384e-02, -3.8117e-02, -3.6673e-02,  5.5539e-02,\n          1.7913e-02,  6.7432e-02, -6.9840e-02, -3.5293e-02, -1.9829e-02,\n          1.4315e-02,  8.5095e-02,  7.3933e-02, -1.8061e-02,  9.2534e-03,\n         -4.4839e-02,  4.3266e-02,  6.6785e-02, -7.6805e-02, -5.5982e-02,\n          7.2163e-02,  3.8981e-02,  5.3926e-02, -1.6750e-02, -5.8166e-02,\n         -2.5603e-02,  6.6863e-02, -7.2432e-02,  7.5664e-02,  5.6350e-02,\n         -5.0209e-02,  8.3421e-02,  9.4447e-03, -3.7996e-02,  7.0741e-02,\n         -3.0925e-02,  1.6725e-02,  2.7814e-02, -7.2237e-02,  7.4724e-02,\n          5.7212e-02,  4.9690e-02, -8.3283e-02, -1.7521e-02,  8.2715e-02,\n          4.7797e-02, -3.8971e-02,  2.4227e-02, -1.4048e-02, -8.2690e-02,\n         -2.6449e-02,  7.3621e-02, -1.3431e-02,  5.2403e-02,  4.6296e-02,\n         -7.7520e-02,  4.0953e-02, -1.8217e-02, -8.3384e-02, -6.7982e-03,\n          2.0129e-02, -6.7942e-02,  7.1419e-02,  7.9274e-02, -7.9067e-02,\n         -6.6498e-02,  5.8281e-02, -2.0658e-03, -8.3433e-02,  5.5460e-02,\n          2.8301e-02,  5.8710e-02,  1.5652e-02, -5.5078e-02,  4.7495e-02,\n         -6.6099e-02, -2.5357e-02, -6.5628e-02, -4.1166e-02, -7.4189e-02,\n         -7.9363e-02,  5.7348e-02, -8.9669e-03,  2.2879e-02, -2.3355e-02,\n          1.0051e-02,  3.5225e-02,  5.1209e-02, -8.3140e-03,  2.4570e-02,\n         -1.8692e-02, -2.7377e-02, -3.7778e-02, -5.7516e-02, -2.2455e-02,\n         -7.3668e-03,  4.2262e-02,  5.1659e-02, -1.1209e-02, -7.6990e-02,\n         -4.0589e-02,  1.7668e-02,  5.9009e-02, -1.1419e-02, -8.7781e-02,\n         -7.0519e-02,  5.4473e-02, -5.8122e-02,  2.7829e-02,  5.2150e-02,\n         -7.7407e-02, -8.0151e-03,  2.2183e-02,  6.7812e-02,  1.3035e-02,\n         -4.8138e-02, -5.0440e-02, -7.3661e-02, -6.2685e-02,  3.9558e-02,\n         -6.1184e-02, -9.5410e-03, -2.6212e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 9.6117e-02,  3.3575e-02,  5.7377e-03,  ...,  3.1259e-01,\n          2.4942e-01, -3.0645e-01],\n        [-3.1821e-01,  5.1874e-04, -8.7753e-02,  ...,  2.6711e-01,\n          6.8322e-02,  7.0950e-02],\n        [ 1.2014e-01, -1.7561e-01,  2.0875e-01,  ..., -3.3449e-01,\n         -6.5303e-02, -1.8729e-01],\n        ...,\n        [-2.5177e-01,  6.0232e-02, -2.8489e-01,  ..., -1.6430e-01,\n         -5.5727e-02,  2.8043e-01],\n        [-1.1115e-01,  1.9852e-01,  2.1394e-01,  ...,  8.6828e-02,\n          6.7459e-02, -2.4486e-01],\n        [-2.1078e-04,  2.3087e-01, -1.8767e-01,  ...,  9.0248e-02,\n          1.0604e-01,  2.0131e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0918,  0.2614,  0.1102,  0.2022, -0.1325, -0.3122, -0.0154, -0.1657,\n         0.1581, -0.3211,  0.2455,  0.0650, -0.2237, -0.1421,  0.1002,  0.0300,\n         0.2957, -0.0249, -0.0610,  0.0229, -0.2342,  0.0507, -0.0668, -0.0120,\n         0.3533,  0.3488,  0.1573,  0.1798,  0.2893, -0.1415, -0.0863,  0.2982,\n         0.2093, -0.0276, -0.0152, -0.1475,  0.2881, -0.3449,  0.2921, -0.2957,\n         0.3178,  0.1355,  0.1692,  0.2260,  0.0676,  0.1159, -0.0601, -0.3411,\n         0.0631, -0.1978,  0.3284, -0.0348,  0.0139,  0.2409,  0.0266,  0.2499,\n        -0.0667, -0.3287,  0.3257,  0.1018,  0.2172,  0.3301, -0.2354, -0.2910,\n        -0.0683, -0.2894, -0.0392, -0.1034,  0.0223,  0.2188, -0.2662,  0.2706,\n         0.1196,  0.2935, -0.3365,  0.0660,  0.2019, -0.2887, -0.0918, -0.1044,\n         0.3286,  0.3349,  0.0253, -0.1013, -0.0073,  0.0960,  0.0381, -0.1274,\n        -0.0435,  0.0466,  0.0148,  0.1642, -0.2999, -0.0210, -0.3513,  0.2078,\n        -0.0226, -0.2808, -0.0748,  0.0043, -0.1478, -0.1467, -0.2615,  0.0694,\n        -0.0842, -0.3294, -0.2960, -0.0363,  0.1638,  0.3234,  0.1421, -0.0552,\n        -0.1028, -0.2163,  0.0323,  0.0668, -0.2671,  0.1479, -0.0544, -0.1981,\n        -0.1311,  0.0096,  0.2521,  0.2139, -0.2956,  0.2505,  0.0553, -0.0442],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0798,  0.0878, -0.0629,  ..., -0.0268,  0.0051, -0.0781],\n        [-0.0524,  0.0095, -0.0136,  ...,  0.0628,  0.0083,  0.0653],\n        [ 0.0188,  0.0760,  0.0133,  ...,  0.0781,  0.0081, -0.0338],\n        ...,\n        [ 0.0727, -0.0008,  0.0450,  ...,  0.0564,  0.0673,  0.0660],\n        [-0.0725, -0.0008, -0.0210,  ..., -0.0422,  0.0117,  0.0187],\n        [-0.0206, -0.0465, -0.0315,  ..., -0.0120, -0.0731,  0.0247]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0010, -0.0288, -0.0579, -0.0645,  0.0399,  0.0225,  0.0612, -0.0682,\n        -0.0817, -0.0014, -0.0608, -0.0749, -0.0865,  0.0074,  0.0118, -0.0599,\n         0.0495, -0.0773, -0.0710, -0.0405,  0.0824,  0.0188, -0.0806,  0.0099,\n         0.0484, -0.0754, -0.0487,  0.0459, -0.0741, -0.0222,  0.0222,  0.0210,\n        -0.0049, -0.0478,  0.0725, -0.0155,  0.0558,  0.0761, -0.0365, -0.0823,\n         0.0700, -0.0005, -0.0055, -0.0403, -0.0248, -0.0737,  0.0292, -0.0467,\n         0.0547, -0.0611, -0.0319, -0.0483, -0.0148,  0.0786,  0.0049, -0.0064,\n        -0.0807,  0.0844, -0.0573,  0.0323,  0.0028,  0.0391, -0.0613, -0.0882,\n         0.0633,  0.0575,  0.0080,  0.0469, -0.0691,  0.0798,  0.0749, -0.0867,\n         0.0297, -0.0298, -0.0153,  0.0291, -0.0157, -0.0070, -0.0876,  0.0138,\n         0.0147, -0.0802,  0.0124,  0.0272,  0.0731, -0.0314, -0.0257, -0.0699,\n        -0.0421, -0.0232, -0.0254,  0.0629,  0.0268, -0.0874, -0.0048, -0.0212,\n         0.0235,  0.0273, -0.0100, -0.0495,  0.0814, -0.0575,  0.0061, -0.0339,\n         0.0585,  0.0422, -0.0777,  0.0461,  0.0873,  0.0577,  0.0049,  0.0407,\n         0.0371, -0.0731,  0.0078,  0.0693,  0.0636,  0.0822,  0.0438, -0.0207,\n         0.0680,  0.0469,  0.0051,  0.0781, -0.0091, -0.0329, -0.0071,  0.0061],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 6.9576e-02,  4.2474e-02,  7.2192e-04,  5.4270e-02,  7.9220e-02,\n          4.4532e-02, -1.0158e-02, -8.2602e-03,  5.0923e-02, -6.6043e-02,\n         -7.1308e-02,  3.5365e-02, -9.0695e-03, -4.1621e-02, -1.1390e-02,\n          1.3113e-02,  5.5693e-02, -7.2619e-02, -3.3042e-02, -2.9538e-02,\n          4.8228e-02, -5.3530e-02,  6.5503e-02,  1.3881e-02,  6.5342e-02,\n         -4.8926e-02,  1.3413e-03, -1.6905e-02, -5.4249e-02, -1.8222e-02,\n          2.5176e-02, -7.8269e-02,  3.9474e-02,  3.7604e-02,  1.1644e-02,\n         -5.7487e-02,  8.2605e-03,  1.7766e-02,  8.0231e-02,  6.4900e-03,\n         -4.1721e-02, -3.6902e-02, -9.5754e-03,  4.2568e-03, -2.3953e-02,\n          8.1519e-02,  4.6304e-02, -8.5689e-02, -4.5381e-02, -4.8613e-02,\n         -3.4438e-02,  6.3197e-03,  4.7992e-02,  5.7803e-02,  8.1416e-02,\n         -3.7578e-02,  7.9222e-02, -6.3691e-02, -5.1998e-02,  4.7263e-02,\n          4.8816e-02,  8.4004e-02,  4.1697e-02, -6.2332e-03, -7.7397e-02,\n          2.8699e-02, -6.5757e-03,  8.2041e-02, -7.3723e-02,  8.3941e-03,\n          5.4450e-02, -4.0077e-02, -2.0849e-02,  4.5956e-02, -5.0576e-02,\n         -3.7525e-02, -7.0244e-03,  7.9236e-02, -8.4102e-02,  5.4396e-02,\n          9.2646e-03,  6.0266e-02,  4.1911e-02, -5.3750e-03,  3.7115e-02,\n          6.5386e-02,  1.6667e-02, -6.0684e-02,  3.3910e-02,  4.1098e-03,\n          7.3264e-02,  2.6706e-02, -1.6318e-02, -6.5055e-03, -1.9844e-02,\n          3.9902e-03,  4.1180e-03, -7.0792e-02,  6.3522e-02, -8.1222e-03,\n         -2.5247e-02, -7.4173e-03, -8.3854e-02,  8.8204e-03, -1.2468e-03,\n         -5.9653e-02, -4.2100e-02,  3.6699e-02,  4.7612e-02,  8.2127e-02,\n          4.8305e-02,  6.9135e-02, -6.8147e-03, -6.4671e-02,  4.9885e-02,\n          6.1440e-02,  3.7747e-03, -8.7838e-02,  1.2130e-02, -1.5214e-02,\n          4.2007e-02, -8.6717e-02,  1.2156e-02,  7.4698e-02,  7.5588e-02,\n         -8.3475e-02, -3.6997e-02, -9.3381e-04],\n        [ 4.8504e-02, -4.9898e-02, -4.1488e-02, -7.6533e-02, -4.3549e-02,\n         -7.4657e-02, -1.1039e-02, -6.4743e-02, -5.8999e-02,  1.2661e-02,\n          2.5026e-02, -5.2219e-02, -8.7323e-02, -3.8930e-02, -4.9903e-04,\n          5.9164e-02, -1.5840e-02,  6.2124e-02,  4.3249e-02,  3.6950e-02,\n          8.6150e-02,  4.4476e-02, -2.5593e-02, -5.2255e-02,  3.6110e-02,\n          3.4763e-02,  4.2768e-02,  2.9274e-02,  3.2703e-02,  5.5158e-02,\n         -7.7614e-02, -7.4417e-02, -1.1534e-03, -7.2799e-02,  5.8190e-02,\n         -4.5861e-02, -4.0309e-02,  7.2528e-02,  4.0720e-02,  1.0286e-02,\n          8.7121e-02, -2.7888e-02, -8.5805e-02, -5.7001e-02, -7.4561e-02,\n          2.1450e-02, -5.5504e-02, -4.6848e-02,  3.8400e-02, -7.3906e-03,\n          2.0664e-02, -5.1169e-02, -8.0404e-02, -1.7264e-02,  5.4696e-03,\n         -1.1107e-02, -6.3109e-02, -8.1110e-02,  5.8714e-02,  3.0589e-02,\n          4.4533e-02,  6.1070e-02, -4.2276e-02, -1.0979e-02, -2.9888e-02,\n          4.8598e-02, -7.2326e-02, -3.3930e-02, -6.7193e-02, -5.0769e-02,\n          3.7855e-02,  1.3114e-02, -1.7981e-02,  6.0714e-02,  4.3230e-03,\n          7.1817e-02, -4.8308e-02, -1.5161e-02,  8.0607e-02,  5.8545e-02,\n         -1.3821e-02, -8.5866e-02,  5.8675e-02,  3.4810e-02, -9.1336e-03,\n         -1.2304e-02,  5.4964e-02,  3.2920e-02,  5.3965e-03, -7.3495e-02,\n         -4.6199e-02, -8.6672e-02, -8.0175e-02,  2.3845e-02,  2.1116e-03,\n         -7.1013e-02, -6.1975e-02,  7.8053e-02, -6.8687e-02,  3.2219e-02,\n          5.5086e-02,  2.9094e-02, -6.0027e-02,  6.7930e-02, -2.6632e-02,\n         -5.3388e-02, -7.3205e-02, -9.5099e-03,  2.2206e-02, -6.6931e-02,\n         -4.5079e-02, -5.6357e-02,  4.6004e-02,  5.7779e-02, -3.4141e-02,\n         -6.1408e-02, -1.5974e-02, -4.0698e-02,  3.2748e-02,  1.8782e-02,\n         -6.5616e-02,  3.5058e-02, -1.7915e-02,  5.6655e-03,  4.7722e-03,\n          5.7936e-02,  3.8311e-02, -7.4468e-02],\n        [-7.9698e-02,  8.7585e-02, -4.1645e-02, -3.4176e-03, -1.9255e-03,\n         -7.5748e-03,  1.6780e-02,  1.1755e-02, -4.6409e-02,  3.4311e-02,\n          4.3533e-02, -2.1563e-02, -2.3047e-03, -6.1965e-02,  1.2090e-02,\n          6.7699e-02, -3.0065e-02,  4.2045e-02, -7.2536e-02,  7.8914e-02,\n         -6.3737e-02,  2.6286e-02, -3.6474e-02,  7.1681e-02, -7.7351e-02,\n         -6.9283e-02, -3.9667e-02, -4.0922e-02, -6.2066e-02, -2.0990e-03,\n         -1.4241e-02, -6.1206e-03, -7.6588e-02,  2.7949e-02, -7.1056e-02,\n         -3.3690e-02, -3.4594e-02, -6.4445e-02,  5.7078e-02,  1.0161e-02,\n         -1.1683e-03,  3.1718e-02,  4.7757e-02,  8.0154e-02, -2.5474e-02,\n          3.4392e-05,  3.9790e-02, -2.0259e-02, -5.6484e-02, -2.5168e-02,\n          4.4197e-02,  2.8722e-02, -2.9618e-02, -6.8782e-02, -6.9532e-02,\n         -6.0124e-02, -8.4221e-02, -1.7966e-02, -7.8811e-02, -5.1154e-02,\n          7.7393e-02, -5.8903e-02, -4.2785e-02,  5.9382e-02,  3.6863e-02,\n         -4.0522e-02,  3.8512e-02, -3.1269e-02, -4.6608e-02,  5.4503e-02,\n         -4.9904e-02,  5.3257e-02, -2.0212e-02,  4.8425e-02, -8.6951e-02,\n         -5.5203e-02,  5.9897e-03,  6.7126e-02,  2.9216e-03, -5.4980e-03,\n         -5.1667e-02,  7.7548e-02,  5.7707e-02,  2.9334e-02, -3.8072e-02,\n          8.4025e-02, -6.9460e-02,  3.5286e-02,  5.7815e-02, -5.9084e-02,\n         -2.0468e-02,  8.2555e-02,  5.1035e-02, -1.3088e-02, -5.1929e-02,\n          7.7186e-02,  4.1185e-02, -5.9200e-02, -7.4668e-02, -4.2174e-02,\n          3.4007e-02,  8.3571e-02,  4.6816e-02, -1.1884e-02, -4.1158e-02,\n         -6.0517e-02, -7.1875e-02, -7.6698e-02,  1.5998e-02,  8.3635e-02,\n         -1.4795e-02,  1.4974e-03, -2.5507e-02, -7.0284e-02,  8.3579e-02,\n         -1.2853e-02, -4.4010e-02, -1.9196e-02, -6.6817e-02,  7.5116e-02,\n         -5.6890e-02,  3.0268e-02,  8.2513e-02,  2.5873e-02,  3.9488e-02,\n         -3.5013e-02, -2.0282e-02, -4.3279e-02],\n        [-6.1375e-02,  5.5066e-02,  2.2869e-02,  5.7429e-02, -8.5334e-02,\n          7.7162e-02,  2.8384e-02, -3.8117e-02, -3.6673e-02,  5.5539e-02,\n          1.7913e-02,  6.7432e-02, -6.9840e-02, -3.5293e-02, -1.9829e-02,\n          1.4315e-02,  8.5095e-02,  7.3933e-02, -1.8061e-02,  9.2534e-03,\n         -4.4839e-02,  4.3266e-02,  6.6785e-02, -7.6805e-02, -5.5982e-02,\n          7.2163e-02,  3.8981e-02,  5.3926e-02, -1.6750e-02, -5.8166e-02,\n         -2.5603e-02,  6.6863e-02, -7.2432e-02,  7.5664e-02,  5.6350e-02,\n         -5.0209e-02,  8.3421e-02,  9.4447e-03, -3.7996e-02,  7.0741e-02,\n         -3.0925e-02,  1.6725e-02,  2.7814e-02, -7.2237e-02,  7.4724e-02,\n          5.7212e-02,  4.9690e-02, -8.3283e-02, -1.7521e-02,  8.2715e-02,\n          4.7797e-02, -3.8971e-02,  2.4227e-02, -1.4048e-02, -8.2690e-02,\n         -2.6449e-02,  7.3621e-02, -1.3431e-02,  5.2403e-02,  4.6296e-02,\n         -7.7520e-02,  4.0953e-02, -1.8217e-02, -8.3384e-02, -6.7982e-03,\n          2.0129e-02, -6.7942e-02,  7.1419e-02,  7.9274e-02, -7.9067e-02,\n         -6.6498e-02,  5.8281e-02, -2.0658e-03, -8.3433e-02,  5.5460e-02,\n          2.8301e-02,  5.8710e-02,  1.5652e-02, -5.5078e-02,  4.7495e-02,\n         -6.6099e-02, -2.5357e-02, -6.5628e-02, -4.1166e-02, -7.4189e-02,\n         -7.9363e-02,  5.7348e-02, -8.9669e-03,  2.2879e-02, -2.3355e-02,\n          1.0051e-02,  3.5225e-02,  5.1209e-02, -8.3140e-03,  2.4570e-02,\n         -1.8692e-02, -2.7377e-02, -3.7778e-02, -5.7516e-02, -2.2455e-02,\n         -7.3668e-03,  4.2262e-02,  5.1659e-02, -1.1209e-02, -7.6990e-02,\n         -4.0589e-02,  1.7668e-02,  5.9009e-02, -1.1419e-02, -8.7781e-02,\n         -7.0519e-02,  5.4473e-02, -5.8122e-02,  2.7829e-02,  5.2150e-02,\n         -7.7407e-02, -8.0151e-03,  2.2183e-02,  6.7812e-02,  1.3035e-02,\n         -4.8138e-02, -5.0440e-02, -7.3661e-02, -6.2685e-02,  3.9558e-02,\n         -6.1184e-02, -9.5410e-03, -2.6212e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0587,  0.0348,  0.0336, -0.0798], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x7b86abd06a90>":	{
                    "alpha":	0.6,
                    "aux_buf_size":	5000,
                    "aux_buffer":	{
                        "act_buf":	"[0 0 0 ... 0 0 0]",
                        "done_buf":	"[False False False ... False False False]",
                        "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                        "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "priorities":	"[0. 0. 0. ... 0. 0. 0.]",
                        "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                        "timestamps":	"[0 0 0 ... 0 0 0]"
                    },
                    "aux_ptr":	0,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "capacity":	50000,
                    "current_segment":	0,
                    "epsilon":	1e-06,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	250,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "sample_decay":	0.8,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0918,  0.2614,  0.1102,  0.2022, -0.1325, -0.3122, -0.0154, -0.1657,\n         0.1581, -0.3211,  0.2455,  0.0650, -0.2237, -0.1421,  0.1002,  0.0300,\n         0.2957, -0.0249, -0.0610,  0.0229, -0.2342,  0.0507, -0.0668, -0.0120,\n         0.3533,  0.3488,  0.1573,  0.1798,  0.2893, -0.1415, -0.0863,  0.2982,\n         0.2093, -0.0276, -0.0152, -0.1475,  0.2881, -0.3449,  0.2921, -0.2957,\n         0.3178,  0.1355,  0.1692,  0.2260,  0.0676,  0.1159, -0.0601, -0.3411,\n         0.0631, -0.1978,  0.3284, -0.0348,  0.0139,  0.2409,  0.0266,  0.2499,\n        -0.0667, -0.3287,  0.3257,  0.1018,  0.2172,  0.3301, -0.2354, -0.2910,\n        -0.0683, -0.2894, -0.0392, -0.1034,  0.0223,  0.2188, -0.2662,  0.2706,\n         0.1196,  0.2935, -0.3365,  0.0660,  0.2019, -0.2887, -0.0918, -0.1044,\n         0.3286,  0.3349,  0.0253, -0.1013, -0.0073,  0.0960,  0.0381, -0.1274,\n        -0.0435,  0.0466,  0.0148,  0.1642, -0.2999, -0.0210, -0.3513,  0.2078,\n        -0.0226, -0.2808, -0.0748,  0.0043, -0.1478, -0.1467, -0.2615,  0.0694,\n        -0.0842, -0.3294, -0.2960, -0.0363,  0.1638,  0.3234,  0.1421, -0.0552,\n        -0.1028, -0.2163,  0.0323,  0.0668, -0.2671,  0.1479, -0.0544, -0.1981,\n        -0.1311,  0.0096,  0.2521,  0.2139, -0.2956,  0.2505,  0.0553, -0.0442],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 9.6117e-02,  3.3575e-02,  5.7377e-03,  ...,  3.1259e-01,\n          2.4942e-01, -3.0645e-01],\n        [-3.1821e-01,  5.1874e-04, -8.7753e-02,  ...,  2.6711e-01,\n          6.8322e-02,  7.0950e-02],\n        [ 1.2014e-01, -1.7561e-01,  2.0875e-01,  ..., -3.3449e-01,\n         -6.5303e-02, -1.8729e-01],\n        ...,\n        [-2.5177e-01,  6.0232e-02, -2.8489e-01,  ..., -1.6430e-01,\n         -5.5727e-02,  2.8043e-01],\n        [-1.1115e-01,  1.9852e-01,  2.1394e-01,  ...,  8.6828e-02,\n          6.7459e-02, -2.4486e-01],\n        [-2.1078e-04,  2.3087e-01, -1.8767e-01,  ...,  9.0248e-02,\n          1.0604e-01,  2.0131e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0010, -0.0288, -0.0579, -0.0645,  0.0399,  0.0225,  0.0612, -0.0682,\n        -0.0817, -0.0014, -0.0608, -0.0749, -0.0865,  0.0074,  0.0118, -0.0599,\n         0.0495, -0.0773, -0.0710, -0.0405,  0.0824,  0.0188, -0.0806,  0.0099,\n         0.0484, -0.0754, -0.0487,  0.0459, -0.0741, -0.0222,  0.0222,  0.0210,\n        -0.0049, -0.0478,  0.0725, -0.0155,  0.0558,  0.0761, -0.0365, -0.0823,\n         0.0700, -0.0005, -0.0055, -0.0403, -0.0248, -0.0737,  0.0292, -0.0467,\n         0.0547, -0.0611, -0.0319, -0.0483, -0.0148,  0.0786,  0.0049, -0.0064,\n        -0.0807,  0.0844, -0.0573,  0.0323,  0.0028,  0.0391, -0.0613, -0.0882,\n         0.0633,  0.0575,  0.0080,  0.0469, -0.0691,  0.0798,  0.0749, -0.0867,\n         0.0297, -0.0298, -0.0153,  0.0291, -0.0157, -0.0070, -0.0876,  0.0138,\n         0.0147, -0.0802,  0.0124,  0.0272,  0.0731, -0.0314, -0.0257, -0.0699,\n        -0.0421, -0.0232, -0.0254,  0.0629,  0.0268, -0.0874, -0.0048, -0.0212,\n         0.0235,  0.0273, -0.0100, -0.0495,  0.0814, -0.0575,  0.0061, -0.0339,\n         0.0585,  0.0422, -0.0777,  0.0461,  0.0873,  0.0577,  0.0049,  0.0407,\n         0.0371, -0.0731,  0.0078,  0.0693,  0.0636,  0.0822,  0.0438, -0.0207,\n         0.0680,  0.0469,  0.0051,  0.0781, -0.0091, -0.0329, -0.0071,  0.0061],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0798,  0.0878, -0.0629,  ..., -0.0268,  0.0051, -0.0781],\n        [-0.0524,  0.0095, -0.0136,  ...,  0.0628,  0.0083,  0.0653],\n        [ 0.0188,  0.0760,  0.0133,  ...,  0.0781,  0.0081, -0.0338],\n        ...,\n        [ 0.0727, -0.0008,  0.0450,  ...,  0.0564,  0.0673,  0.0660],\n        [-0.0725, -0.0008, -0.0210,  ..., -0.0422,  0.0117,  0.0187],\n        [-0.0206, -0.0465, -0.0315,  ..., -0.0120, -0.0731,  0.0247]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0587,  0.0348,  0.0336, -0.0798], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 6.9576e-02,  4.2474e-02,  7.2192e-04,  5.4270e-02,  7.9220e-02,\n          4.4532e-02, -1.0158e-02, -8.2602e-03,  5.0923e-02, -6.6043e-02,\n         -7.1308e-02,  3.5365e-02, -9.0695e-03, -4.1621e-02, -1.1390e-02,\n          1.3113e-02,  5.5693e-02, -7.2619e-02, -3.3042e-02, -2.9538e-02,\n          4.8228e-02, -5.3530e-02,  6.5503e-02,  1.3881e-02,  6.5342e-02,\n         -4.8926e-02,  1.3413e-03, -1.6905e-02, -5.4249e-02, -1.8222e-02,\n          2.5176e-02, -7.8269e-02,  3.9474e-02,  3.7604e-02,  1.1644e-02,\n         -5.7487e-02,  8.2605e-03,  1.7766e-02,  8.0231e-02,  6.4900e-03,\n         -4.1721e-02, -3.6902e-02, -9.5754e-03,  4.2568e-03, -2.3953e-02,\n          8.1519e-02,  4.6304e-02, -8.5689e-02, -4.5381e-02, -4.8613e-02,\n         -3.4438e-02,  6.3197e-03,  4.7992e-02,  5.7803e-02,  8.1416e-02,\n         -3.7578e-02,  7.9222e-02, -6.3691e-02, -5.1998e-02,  4.7263e-02,\n          4.8816e-02,  8.4004e-02,  4.1697e-02, -6.2332e-03, -7.7397e-02,\n          2.8699e-02, -6.5757e-03,  8.2041e-02, -7.3723e-02,  8.3941e-03,\n          5.4450e-02, -4.0077e-02, -2.0849e-02,  4.5956e-02, -5.0576e-02,\n         -3.7525e-02, -7.0244e-03,  7.9236e-02, -8.4102e-02,  5.4396e-02,\n          9.2646e-03,  6.0266e-02,  4.1911e-02, -5.3750e-03,  3.7115e-02,\n          6.5386e-02,  1.6667e-02, -6.0684e-02,  3.3910e-02,  4.1098e-03,\n          7.3264e-02,  2.6706e-02, -1.6318e-02, -6.5055e-03, -1.9844e-02,\n          3.9902e-03,  4.1180e-03, -7.0792e-02,  6.3522e-02, -8.1222e-03,\n         -2.5247e-02, -7.4173e-03, -8.3854e-02,  8.8204e-03, -1.2468e-03,\n         -5.9653e-02, -4.2100e-02,  3.6699e-02,  4.7612e-02,  8.2127e-02,\n          4.8305e-02,  6.9135e-02, -6.8147e-03, -6.4671e-02,  4.9885e-02,\n          6.1440e-02,  3.7747e-03, -8.7838e-02,  1.2130e-02, -1.5214e-02,\n          4.2007e-02, -8.6717e-02,  1.2156e-02,  7.4698e-02,  7.5588e-02,\n         -8.3475e-02, -3.6997e-02, -9.3381e-04],\n        [ 4.8504e-02, -4.9898e-02, -4.1488e-02, -7.6533e-02, -4.3549e-02,\n         -7.4657e-02, -1.1039e-02, -6.4743e-02, -5.8999e-02,  1.2661e-02,\n          2.5026e-02, -5.2219e-02, -8.7323e-02, -3.8930e-02, -4.9903e-04,\n          5.9164e-02, -1.5840e-02,  6.2124e-02,  4.3249e-02,  3.6950e-02,\n          8.6150e-02,  4.4476e-02, -2.5593e-02, -5.2255e-02,  3.6110e-02,\n          3.4763e-02,  4.2768e-02,  2.9274e-02,  3.2703e-02,  5.5158e-02,\n         -7.7614e-02, -7.4417e-02, -1.1534e-03, -7.2799e-02,  5.8190e-02,\n         -4.5861e-02, -4.0309e-02,  7.2528e-02,  4.0720e-02,  1.0286e-02,\n          8.7121e-02, -2.7888e-02, -8.5805e-02, -5.7001e-02, -7.4561e-02,\n          2.1450e-02, -5.5504e-02, -4.6848e-02,  3.8400e-02, -7.3906e-03,\n          2.0664e-02, -5.1169e-02, -8.0404e-02, -1.7264e-02,  5.4696e-03,\n         -1.1107e-02, -6.3109e-02, -8.1110e-02,  5.8714e-02,  3.0589e-02,\n          4.4533e-02,  6.1070e-02, -4.2276e-02, -1.0979e-02, -2.9888e-02,\n          4.8598e-02, -7.2326e-02, -3.3930e-02, -6.7193e-02, -5.0769e-02,\n          3.7855e-02,  1.3114e-02, -1.7981e-02,  6.0714e-02,  4.3230e-03,\n          7.1817e-02, -4.8308e-02, -1.5161e-02,  8.0607e-02,  5.8545e-02,\n         -1.3821e-02, -8.5866e-02,  5.8675e-02,  3.4810e-02, -9.1336e-03,\n         -1.2304e-02,  5.4964e-02,  3.2920e-02,  5.3965e-03, -7.3495e-02,\n         -4.6199e-02, -8.6672e-02, -8.0175e-02,  2.3845e-02,  2.1116e-03,\n         -7.1013e-02, -6.1975e-02,  7.8053e-02, -6.8687e-02,  3.2219e-02,\n          5.5086e-02,  2.9094e-02, -6.0027e-02,  6.7930e-02, -2.6632e-02,\n         -5.3388e-02, -7.3205e-02, -9.5099e-03,  2.2206e-02, -6.6931e-02,\n         -4.5079e-02, -5.6357e-02,  4.6004e-02,  5.7779e-02, -3.4141e-02,\n         -6.1408e-02, -1.5974e-02, -4.0698e-02,  3.2748e-02,  1.8782e-02,\n         -6.5616e-02,  3.5058e-02, -1.7915e-02,  5.6655e-03,  4.7722e-03,\n          5.7936e-02,  3.8311e-02, -7.4468e-02],\n        [-7.9698e-02,  8.7585e-02, -4.1645e-02, -3.4176e-03, -1.9255e-03,\n         -7.5748e-03,  1.6780e-02,  1.1755e-02, -4.6409e-02,  3.4311e-02,\n          4.3533e-02, -2.1563e-02, -2.3047e-03, -6.1965e-02,  1.2090e-02,\n          6.7699e-02, -3.0065e-02,  4.2045e-02, -7.2536e-02,  7.8914e-02,\n         -6.3737e-02,  2.6286e-02, -3.6474e-02,  7.1681e-02, -7.7351e-02,\n         -6.9283e-02, -3.9667e-02, -4.0922e-02, -6.2066e-02, -2.0990e-03,\n         -1.4241e-02, -6.1206e-03, -7.6588e-02,  2.7949e-02, -7.1056e-02,\n         -3.3690e-02, -3.4594e-02, -6.4445e-02,  5.7078e-02,  1.0161e-02,\n         -1.1683e-03,  3.1718e-02,  4.7757e-02,  8.0154e-02, -2.5474e-02,\n          3.4392e-05,  3.9790e-02, -2.0259e-02, -5.6484e-02, -2.5168e-02,\n          4.4197e-02,  2.8722e-02, -2.9618e-02, -6.8782e-02, -6.9532e-02,\n         -6.0124e-02, -8.4221e-02, -1.7966e-02, -7.8811e-02, -5.1154e-02,\n          7.7393e-02, -5.8903e-02, -4.2785e-02,  5.9382e-02,  3.6863e-02,\n         -4.0522e-02,  3.8512e-02, -3.1269e-02, -4.6608e-02,  5.4503e-02,\n         -4.9904e-02,  5.3257e-02, -2.0212e-02,  4.8425e-02, -8.6951e-02,\n         -5.5203e-02,  5.9897e-03,  6.7126e-02,  2.9216e-03, -5.4980e-03,\n         -5.1667e-02,  7.7548e-02,  5.7707e-02,  2.9334e-02, -3.8072e-02,\n          8.4025e-02, -6.9460e-02,  3.5286e-02,  5.7815e-02, -5.9084e-02,\n         -2.0468e-02,  8.2555e-02,  5.1035e-02, -1.3088e-02, -5.1929e-02,\n          7.7186e-02,  4.1185e-02, -5.9200e-02, -7.4668e-02, -4.2174e-02,\n          3.4007e-02,  8.3571e-02,  4.6816e-02, -1.1884e-02, -4.1158e-02,\n         -6.0517e-02, -7.1875e-02, -7.6698e-02,  1.5998e-02,  8.3635e-02,\n         -1.4795e-02,  1.4974e-03, -2.5507e-02, -7.0284e-02,  8.3579e-02,\n         -1.2853e-02, -4.4010e-02, -1.9196e-02, -6.6817e-02,  7.5116e-02,\n         -5.6890e-02,  3.0268e-02,  8.2513e-02,  2.5873e-02,  3.9488e-02,\n         -3.5013e-02, -2.0282e-02, -4.3279e-02],\n        [-6.1375e-02,  5.5066e-02,  2.2869e-02,  5.7429e-02, -8.5334e-02,\n          7.7162e-02,  2.8384e-02, -3.8117e-02, -3.6673e-02,  5.5539e-02,\n          1.7913e-02,  6.7432e-02, -6.9840e-02, -3.5293e-02, -1.9829e-02,\n          1.4315e-02,  8.5095e-02,  7.3933e-02, -1.8061e-02,  9.2534e-03,\n         -4.4839e-02,  4.3266e-02,  6.6785e-02, -7.6805e-02, -5.5982e-02,\n          7.2163e-02,  3.8981e-02,  5.3926e-02, -1.6750e-02, -5.8166e-02,\n         -2.5603e-02,  6.6863e-02, -7.2432e-02,  7.5664e-02,  5.6350e-02,\n         -5.0209e-02,  8.3421e-02,  9.4447e-03, -3.7996e-02,  7.0741e-02,\n         -3.0925e-02,  1.6725e-02,  2.7814e-02, -7.2237e-02,  7.4724e-02,\n          5.7212e-02,  4.9690e-02, -8.3283e-02, -1.7521e-02,  8.2715e-02,\n          4.7797e-02, -3.8971e-02,  2.4227e-02, -1.4048e-02, -8.2690e-02,\n         -2.6449e-02,  7.3621e-02, -1.3431e-02,  5.2403e-02,  4.6296e-02,\n         -7.7520e-02,  4.0953e-02, -1.8217e-02, -8.3384e-02, -6.7982e-03,\n          2.0129e-02, -6.7942e-02,  7.1419e-02,  7.9274e-02, -7.9067e-02,\n         -6.6498e-02,  5.8281e-02, -2.0658e-03, -8.3433e-02,  5.5460e-02,\n          2.8301e-02,  5.8710e-02,  1.5652e-02, -5.5078e-02,  4.7495e-02,\n         -6.6099e-02, -2.5357e-02, -6.5628e-02, -4.1166e-02, -7.4189e-02,\n         -7.9363e-02,  5.7348e-02, -8.9669e-03,  2.2879e-02, -2.3355e-02,\n          1.0051e-02,  3.5225e-02,  5.1209e-02, -8.3140e-03,  2.4570e-02,\n         -1.8692e-02, -2.7377e-02, -3.7778e-02, -5.7516e-02, -2.2455e-02,\n         -7.3668e-03,  4.2262e-02,  5.1659e-02, -1.1209e-02, -7.6990e-02,\n         -4.0589e-02,  1.7668e-02,  5.9009e-02, -1.1419e-02, -8.7781e-02,\n         -7.0519e-02,  5.4473e-02, -5.8122e-02,  2.7829e-02,  5.2150e-02,\n         -7.7407e-02, -8.0151e-03,  2.2183e-02,  6.7812e-02,  1.3035e-02,\n         -4.8138e-02, -5.0440e-02, -7.3661e-02, -6.2685e-02,  3.9558e-02,\n         -6.1184e-02, -9.5410e-03, -2.6212e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7b8630cde550>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s400190000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s400190000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}