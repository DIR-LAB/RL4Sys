{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0003,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s402110000"
    },
    "max_sample_age":	-1,
    "q_lr":	0.0003,
    "sample_decay":	0.8,
    "seed":	402110000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x754da23d6f50>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0003,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0996,  0.2815,  0.0781, -0.2522, -0.2788, -0.2333,  0.0840,  0.1818,\n         0.1354,  0.2604,  0.0652,  0.2522, -0.2557,  0.1609, -0.0860, -0.0365,\n        -0.1846,  0.2041,  0.2406,  0.0994, -0.0159, -0.0176, -0.2941,  0.0148,\n         0.2548, -0.1794, -0.3172,  0.1944,  0.2917,  0.0561, -0.0295, -0.1850,\n        -0.3036, -0.2818, -0.2510,  0.2566,  0.3008,  0.0048, -0.0612,  0.1245,\n         0.0900,  0.1060, -0.0773, -0.0661, -0.1073,  0.2781,  0.1579,  0.2504,\n        -0.1628, -0.1091, -0.2311, -0.1653,  0.3461,  0.2680,  0.0417, -0.3325,\n        -0.2310,  0.2507,  0.1780, -0.3132, -0.0480,  0.1673, -0.0306,  0.1175,\n         0.2407, -0.1863, -0.1522, -0.2363, -0.0409, -0.1754, -0.2253, -0.2329,\n         0.1179, -0.0853,  0.2949, -0.0335, -0.0150, -0.1705, -0.1488,  0.1466,\n        -0.0271, -0.2085,  0.3109,  0.2350,  0.0448,  0.1635, -0.2093, -0.0749,\n        -0.2088,  0.2016, -0.3413,  0.1201, -0.1722,  0.0831,  0.3179,  0.2319,\n        -0.3363,  0.3001, -0.2510,  0.1760, -0.0296, -0.2259, -0.0146, -0.1296,\n         0.0987,  0.1449, -0.0789,  0.2807, -0.3382, -0.0337,  0.0459, -0.2943,\n        -0.1084, -0.0612, -0.1348, -0.0023,  0.2233,  0.0349,  0.0463,  0.1351,\n        -0.1945,  0.0390,  0.2499, -0.0729, -0.1936, -0.1713,  0.0213, -0.2001],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0447,  0.0338, -0.0037,  ...,  0.0218, -0.2121, -0.1948],\n        [ 0.0153, -0.2176, -0.1199,  ..., -0.1461,  0.0512,  0.3280],\n        [ 0.3048, -0.0725,  0.2409,  ...,  0.2675, -0.0839, -0.0958],\n        ...,\n        [ 0.2870,  0.0918, -0.2572,  ...,  0.1003,  0.1821, -0.1457],\n        [ 0.1740, -0.2549,  0.1692,  ...,  0.0485, -0.0476, -0.3174],\n        [-0.1876,  0.0716,  0.2928,  ..., -0.2354,  0.0412, -0.2839]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 4.5473e-02,  4.7622e-02,  3.1568e-02,  6.1609e-02, -1.8978e-02,\n         6.2199e-02,  7.7963e-02,  7.4545e-02, -6.4889e-02, -5.5010e-02,\n        -4.1552e-02,  4.0509e-02,  3.1716e-02,  4.4322e-02, -5.1574e-02,\n         6.3049e-02,  4.2396e-02,  2.9690e-02,  6.5155e-02,  5.9369e-02,\n         1.5394e-02, -5.8135e-02,  1.6339e-02,  6.9557e-02, -6.9481e-02,\n        -7.5967e-02,  8.6240e-03,  1.2045e-02,  4.9268e-02,  6.8827e-02,\n         1.3022e-02,  4.0491e-02, -8.3815e-02,  3.6850e-02,  1.6072e-02,\n        -7.9781e-02,  5.4845e-02,  7.8331e-02,  4.7194e-02,  1.6224e-02,\n        -1.4117e-02,  8.1836e-02, -7.0882e-02,  7.8729e-02, -8.6925e-02,\n         8.6477e-02, -2.3677e-02, -2.0124e-02,  6.5712e-02, -5.0825e-02,\n         3.8870e-02,  6.3811e-02,  6.2368e-02, -6.9282e-02,  7.2417e-02,\n        -2.0987e-02,  3.3137e-03, -3.9205e-03,  6.2732e-02, -5.6983e-02,\n         3.7618e-02, -3.4922e-03,  8.0969e-02,  4.3201e-02, -7.8421e-02,\n        -5.7730e-02,  6.9126e-03,  4.8493e-02,  3.6189e-02, -8.0014e-02,\n         1.0027e-02,  2.7604e-03,  8.2094e-02,  6.7533e-02,  5.2241e-02,\n         5.7539e-02,  7.7905e-02, -4.8264e-02, -2.9123e-05,  7.5276e-02,\n        -6.1326e-02,  2.0280e-02,  4.9516e-02, -3.2030e-02, -4.0888e-02,\n        -7.5112e-02, -3.5404e-02,  2.8850e-02,  6.0293e-02,  3.8220e-02,\n        -4.3435e-02,  2.4052e-02, -4.9834e-02, -5.6869e-02,  3.1752e-02,\n         8.5922e-02,  7.8697e-02,  8.0589e-02, -5.6149e-02,  7.2957e-02,\n        -3.6558e-02, -4.1028e-02, -3.7842e-03, -2.5315e-02, -8.9634e-04,\n         5.1651e-02,  4.2832e-02, -5.2167e-02, -8.3766e-02, -2.9197e-02,\n        -7.5250e-02,  4.1173e-02,  4.8907e-02, -5.6119e-02, -6.1119e-02,\n        -5.1152e-02,  1.6385e-02,  6.4654e-02,  8.0868e-02, -4.9489e-02,\n        -7.3225e-02, -4.7094e-02,  6.1023e-02,  6.2043e-02,  6.3435e-02,\n        -3.5828e-02, -1.2517e-02,  3.5198e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0379, -0.0478, -0.0863,  ..., -0.0229,  0.0473, -0.0412],\n        [-0.0759, -0.0650,  0.0812,  ..., -0.0467, -0.0118, -0.0075],\n        [ 0.0597, -0.0539, -0.0095,  ..., -0.0738,  0.0615, -0.0613],\n        ...,\n        [-0.0399, -0.0330, -0.0362,  ...,  0.0380, -0.0714, -0.0197],\n        [-0.0642,  0.0152,  0.0205,  ..., -0.0570,  0.0487,  0.0590],\n        [-0.0414,  0.0364, -0.0239,  ..., -0.0737,  0.0221, -0.0746]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0462,  0.0200, -0.0526, -0.0792], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.4531e-02,  8.7825e-02,  3.7837e-03, -8.5724e-02, -1.8775e-02,\n          2.5473e-02, -4.5610e-02, -8.7064e-03,  5.2735e-02, -1.0784e-02,\n          4.2604e-02,  3.6888e-02,  8.2260e-02,  1.7138e-02, -2.9678e-02,\n         -5.9311e-03, -8.2771e-02,  1.4892e-03, -8.6974e-02,  5.2528e-02,\n         -4.1441e-02,  3.4245e-02, -1.1158e-05, -2.6533e-03,  3.5071e-02,\n          6.7323e-02,  1.7750e-02, -8.6317e-02, -4.3830e-03, -7.1053e-02,\n          2.5591e-02, -6.6631e-02, -5.9848e-02, -2.2240e-02, -4.8437e-02,\n          6.2453e-02, -7.7587e-02,  2.3490e-02,  7.8964e-03, -6.7947e-02,\n         -2.2199e-03, -7.5885e-02,  6.0638e-02, -1.2530e-02, -7.7692e-03,\n          7.2849e-02, -1.1615e-02, -5.4460e-02,  6.5029e-02,  2.6888e-02,\n         -3.4538e-02,  5.1885e-02, -2.6820e-02, -2.2641e-02, -2.6597e-02,\n          5.9350e-02,  2.7165e-02,  2.5073e-02, -8.5805e-02, -4.7007e-02,\n          6.6282e-02,  8.6901e-02, -6.6191e-02,  5.8211e-02,  5.2427e-02,\n          5.5404e-03,  8.2839e-02,  4.9146e-02, -9.6029e-03,  5.0002e-02,\n         -7.9555e-02,  5.2042e-02, -6.2821e-02,  2.1462e-03,  7.1242e-02,\n         -8.7775e-02, -5.4785e-02, -4.7122e-02, -1.7475e-02,  2.8606e-02,\n         -7.4280e-02,  7.4003e-02, -8.4152e-02, -6.7220e-02,  2.1404e-02,\n          6.3119e-02, -5.5159e-02, -4.0304e-02, -5.7348e-02,  3.3914e-02,\n         -5.3901e-02, -6.8635e-02, -6.8296e-03,  1.0467e-02,  3.5222e-02,\n          2.2435e-02, -5.6249e-02,  5.2689e-02, -8.5678e-02, -8.0656e-03,\n         -7.0405e-02,  9.6911e-03,  7.0012e-02,  5.9618e-02, -4.5021e-02,\n         -4.0957e-02,  4.8003e-02, -1.9627e-02, -3.7234e-02,  8.7201e-02,\n         -7.8479e-02,  5.3068e-02,  4.3966e-03, -4.9027e-02,  1.3706e-02,\n         -5.9083e-02, -2.8291e-02, -3.8386e-03,  3.7624e-02,  3.8947e-02,\n          3.2027e-02,  2.9010e-02, -7.9826e-02, -8.3745e-02, -3.9942e-03,\n         -6.1203e-02,  2.2023e-02,  1.3698e-02],\n        [ 7.7586e-02,  7.9986e-02,  7.1722e-02,  7.3180e-02, -3.5023e-02,\n          6.2199e-02, -6.6531e-02,  4.4391e-02,  3.2325e-02,  2.6508e-02,\n         -7.3535e-02, -4.1865e-03,  4.9536e-02, -8.7298e-02,  3.4776e-02,\n          2.1290e-02, -7.9133e-02,  8.8263e-02,  2.7588e-02, -5.4220e-02,\n         -6.1802e-02,  7.9797e-02,  8.4676e-02, -4.7152e-02, -8.3749e-02,\n          6.8662e-02,  6.0217e-02, -8.1595e-02,  2.3702e-02,  1.0721e-02,\n          4.8638e-02, -7.9853e-02, -8.0177e-03,  4.6840e-02, -8.3400e-02,\n          2.9190e-02, -1.5183e-02, -5.5066e-02, -6.7697e-02, -2.5802e-02,\n          8.1224e-02,  1.4840e-02,  1.7464e-02, -4.9096e-02,  6.7886e-02,\n         -5.3289e-03,  4.4274e-02, -4.2258e-02, -2.8303e-02, -5.8923e-02,\n          7.5788e-02,  3.8433e-02,  3.8959e-02,  1.7292e-02,  4.1355e-02,\n          2.0379e-02, -2.6889e-02, -7.4881e-02,  3.2932e-02,  4.6620e-02,\n          2.7184e-02, -2.5981e-02,  4.1487e-02,  7.5904e-02, -1.6147e-02,\n          7.0837e-02, -8.3150e-02, -8.0985e-02, -6.6992e-02, -2.0342e-02,\n         -3.8392e-02, -1.7955e-02,  6.9520e-02,  4.8154e-02,  5.6026e-02,\n          4.4942e-02,  7.9644e-02,  2.9691e-03, -9.8619e-03, -7.8928e-02,\n          4.8308e-02,  9.9209e-04, -7.6906e-03, -8.5401e-02, -4.4155e-02,\n         -5.4975e-02,  3.1372e-02,  5.3668e-02, -8.2031e-02, -1.6559e-02,\n         -4.9920e-02,  2.3231e-02, -7.5739e-02,  6.9832e-02,  2.6304e-03,\n          4.1893e-03,  1.4490e-02, -2.4734e-02,  5.7758e-02, -4.6849e-03,\n         -8.7390e-02, -9.8651e-03,  9.4994e-03, -3.2075e-02, -8.7617e-02,\n         -6.9878e-02, -5.3417e-02,  8.5505e-03,  7.2610e-02, -7.7654e-02,\n          6.1501e-02, -2.5416e-02, -5.7613e-03, -6.4095e-02,  7.1727e-02,\n         -5.3665e-03,  4.7258e-02, -2.6902e-02, -1.5984e-02, -7.2288e-02,\n          6.6449e-02,  6.4592e-02, -8.8203e-02, -5.6878e-02, -5.3554e-03,\n         -7.1212e-02, -2.5844e-02,  5.5336e-02],\n        [-7.2969e-02,  7.0338e-03, -8.7564e-02, -4.0098e-02, -7.1237e-02,\n          2.4159e-02, -2.6028e-03, -5.8759e-02,  7.9524e-02,  5.5485e-02,\n         -1.8650e-02, -1.6813e-02,  2.2772e-02, -3.4707e-02, -7.5368e-02,\n          1.8086e-03,  1.2473e-02, -6.7353e-02, -6.0850e-02, -7.4253e-02,\n          6.2003e-02, -7.8795e-02,  1.9941e-04,  4.6044e-03,  4.6553e-02,\n          4.1115e-02,  1.6922e-02,  8.7631e-03,  3.2518e-02, -6.0858e-02,\n         -8.6550e-02,  4.4621e-02, -2.4354e-02,  6.7596e-02, -8.7394e-02,\n          3.2163e-03,  1.1283e-02,  3.0429e-02,  2.8992e-03,  5.0131e-02,\n         -2.6302e-04,  4.3389e-02,  3.2910e-02,  5.2572e-02,  2.1797e-02,\n         -6.1795e-04, -6.0834e-02,  9.4117e-04,  8.1438e-02, -4.3598e-02,\n         -3.0713e-02,  5.4188e-02, -5.6222e-02,  4.2151e-02, -5.5606e-02,\n          4.4125e-02, -5.2637e-02, -2.8671e-02, -6.4911e-02,  5.8554e-02,\n          2.7947e-02,  2.8888e-02,  7.3423e-02,  2.4563e-02, -7.9881e-02,\n          6.7995e-02, -1.9828e-02,  3.6689e-02, -1.0131e-02,  2.0726e-02,\n          4.1856e-02, -1.2245e-02, -1.0109e-02,  3.5321e-02,  5.5980e-02,\n         -1.2266e-02,  8.1410e-02,  3.8432e-02,  8.2759e-02,  2.9441e-03,\n          6.7110e-02,  7.6100e-02,  6.1605e-02,  6.4200e-02, -6.7140e-02,\n         -5.0973e-02,  6.1765e-02,  1.1643e-03,  7.0208e-02,  4.9604e-02,\n          3.1904e-02,  6.4244e-02, -4.8254e-03,  5.7048e-02, -6.2592e-02,\n          4.1614e-02,  3.7732e-02,  6.3766e-02, -6.1595e-02,  2.6786e-02,\n         -2.3679e-02,  1.2539e-02, -6.1569e-02, -3.0549e-03,  3.6616e-02,\n         -2.1933e-02, -5.1190e-02, -7.5644e-02, -2.4094e-02, -2.9981e-02,\n          3.0666e-02,  7.1586e-02, -5.6728e-02, -8.0158e-02,  2.7651e-02,\n          3.3655e-02, -2.2667e-02, -4.6621e-02, -3.9011e-02,  3.9828e-03,\n          2.2705e-02,  8.1266e-02, -5.7325e-02, -2.1453e-02, -1.9991e-02,\n          4.6121e-04, -2.4970e-02,  8.3886e-02],\n        [-6.3575e-02, -1.3054e-02, -6.8853e-02, -3.1772e-02,  4.7215e-02,\n          8.6940e-02, -3.8818e-02,  3.1580e-02,  3.6544e-02, -8.5338e-03,\n         -5.3466e-02, -7.1555e-02, -5.5766e-02, -1.1230e-02, -1.0329e-02,\n         -7.0229e-02,  6.6922e-02,  2.0834e-02, -1.2806e-02, -3.5231e-02,\n          3.4503e-02,  2.6669e-02,  6.3873e-02,  5.9246e-02, -2.6453e-02,\n         -3.5545e-02,  6.6557e-02, -3.8807e-03, -5.6074e-02,  6.5382e-02,\n         -4.7098e-03,  8.0705e-02, -5.5026e-03, -2.1011e-02, -7.4276e-02,\n         -2.6806e-02, -3.4717e-02, -6.5956e-02,  2.2292e-02,  3.0276e-02,\n         -8.0077e-02, -4.0179e-02,  6.8567e-02, -7.3787e-02, -8.1452e-03,\n          2.6369e-02, -4.9800e-02,  1.4786e-02,  7.5876e-02, -4.3929e-02,\n          5.4125e-02,  8.3270e-02, -5.8868e-02,  1.0274e-02, -2.6273e-02,\n          4.7976e-02, -8.4750e-02,  7.7673e-03,  4.8501e-02,  6.0909e-02,\n         -6.6124e-02,  5.3623e-03,  5.8939e-02,  7.6285e-02, -1.5792e-02,\n          7.4007e-02,  5.2684e-02, -3.8503e-02, -3.8674e-02,  7.2092e-03,\n         -7.1456e-03, -8.0367e-02,  4.3916e-02, -1.8832e-02,  8.8147e-02,\n          4.7315e-02, -4.6828e-02,  6.9238e-02, -2.1577e-02,  1.5541e-02,\n          5.5676e-02,  8.3418e-02, -8.3338e-02, -5.9371e-03,  2.6251e-02,\n         -9.0952e-03, -1.3155e-02,  5.4696e-02,  5.9996e-03, -6.9830e-02,\n         -7.2330e-02, -5.4331e-02, -7.1434e-02, -7.2423e-02,  6.8367e-02,\n         -5.5275e-02,  1.5381e-02,  2.0823e-02, -3.7458e-02, -8.7195e-02,\n          1.9799e-02,  6.2359e-02,  9.4033e-03,  6.1532e-02, -4.7005e-02,\n         -3.3659e-02,  1.1017e-02, -8.2563e-03, -8.5852e-02, -4.8125e-02,\n          1.5225e-02, -5.8348e-02,  5.7391e-02, -2.5284e-02,  3.2313e-02,\n         -8.7698e-02,  8.8467e-03,  7.0224e-02,  3.1689e-02, -7.1476e-02,\n          4.2276e-02, -3.4831e-02,  7.1361e-02, -7.0962e-02,  3.9202e-02,\n         -3.1061e-02, -7.3520e-02,  6.7949e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0447,  0.0338, -0.0037,  ...,  0.0218, -0.2121, -0.1948],\n        [ 0.0153, -0.2176, -0.1199,  ..., -0.1461,  0.0512,  0.3280],\n        [ 0.3048, -0.0725,  0.2409,  ...,  0.2675, -0.0839, -0.0958],\n        ...,\n        [ 0.2870,  0.0918, -0.2572,  ...,  0.1003,  0.1821, -0.1457],\n        [ 0.1740, -0.2549,  0.1692,  ...,  0.0485, -0.0476, -0.3174],\n        [-0.1876,  0.0716,  0.2928,  ..., -0.2354,  0.0412, -0.2839]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0996,  0.2815,  0.0781, -0.2522, -0.2788, -0.2333,  0.0840,  0.1818,\n         0.1354,  0.2604,  0.0652,  0.2522, -0.2557,  0.1609, -0.0860, -0.0365,\n        -0.1846,  0.2041,  0.2406,  0.0994, -0.0159, -0.0176, -0.2941,  0.0148,\n         0.2548, -0.1794, -0.3172,  0.1944,  0.2917,  0.0561, -0.0295, -0.1850,\n        -0.3036, -0.2818, -0.2510,  0.2566,  0.3008,  0.0048, -0.0612,  0.1245,\n         0.0900,  0.1060, -0.0773, -0.0661, -0.1073,  0.2781,  0.1579,  0.2504,\n        -0.1628, -0.1091, -0.2311, -0.1653,  0.3461,  0.2680,  0.0417, -0.3325,\n        -0.2310,  0.2507,  0.1780, -0.3132, -0.0480,  0.1673, -0.0306,  0.1175,\n         0.2407, -0.1863, -0.1522, -0.2363, -0.0409, -0.1754, -0.2253, -0.2329,\n         0.1179, -0.0853,  0.2949, -0.0335, -0.0150, -0.1705, -0.1488,  0.1466,\n        -0.0271, -0.2085,  0.3109,  0.2350,  0.0448,  0.1635, -0.2093, -0.0749,\n        -0.2088,  0.2016, -0.3413,  0.1201, -0.1722,  0.0831,  0.3179,  0.2319,\n        -0.3363,  0.3001, -0.2510,  0.1760, -0.0296, -0.2259, -0.0146, -0.1296,\n         0.0987,  0.1449, -0.0789,  0.2807, -0.3382, -0.0337,  0.0459, -0.2943,\n        -0.1084, -0.0612, -0.1348, -0.0023,  0.2233,  0.0349,  0.0463,  0.1351,\n        -0.1945,  0.0390,  0.2499, -0.0729, -0.1936, -0.1713,  0.0213, -0.2001],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0379, -0.0478, -0.0863,  ..., -0.0229,  0.0473, -0.0412],\n        [-0.0759, -0.0650,  0.0812,  ..., -0.0467, -0.0118, -0.0075],\n        [ 0.0597, -0.0539, -0.0095,  ..., -0.0738,  0.0615, -0.0613],\n        ...,\n        [-0.0399, -0.0330, -0.0362,  ...,  0.0380, -0.0714, -0.0197],\n        [-0.0642,  0.0152,  0.0205,  ..., -0.0570,  0.0487,  0.0590],\n        [-0.0414,  0.0364, -0.0239,  ..., -0.0737,  0.0221, -0.0746]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 4.5473e-02,  4.7622e-02,  3.1568e-02,  6.1609e-02, -1.8978e-02,\n         6.2199e-02,  7.7963e-02,  7.4545e-02, -6.4889e-02, -5.5010e-02,\n        -4.1552e-02,  4.0509e-02,  3.1716e-02,  4.4322e-02, -5.1574e-02,\n         6.3049e-02,  4.2396e-02,  2.9690e-02,  6.5155e-02,  5.9369e-02,\n         1.5394e-02, -5.8135e-02,  1.6339e-02,  6.9557e-02, -6.9481e-02,\n        -7.5967e-02,  8.6240e-03,  1.2045e-02,  4.9268e-02,  6.8827e-02,\n         1.3022e-02,  4.0491e-02, -8.3815e-02,  3.6850e-02,  1.6072e-02,\n        -7.9781e-02,  5.4845e-02,  7.8331e-02,  4.7194e-02,  1.6224e-02,\n        -1.4117e-02,  8.1836e-02, -7.0882e-02,  7.8729e-02, -8.6925e-02,\n         8.6477e-02, -2.3677e-02, -2.0124e-02,  6.5712e-02, -5.0825e-02,\n         3.8870e-02,  6.3811e-02,  6.2368e-02, -6.9282e-02,  7.2417e-02,\n        -2.0987e-02,  3.3137e-03, -3.9205e-03,  6.2732e-02, -5.6983e-02,\n         3.7618e-02, -3.4922e-03,  8.0969e-02,  4.3201e-02, -7.8421e-02,\n        -5.7730e-02,  6.9126e-03,  4.8493e-02,  3.6189e-02, -8.0014e-02,\n         1.0027e-02,  2.7604e-03,  8.2094e-02,  6.7533e-02,  5.2241e-02,\n         5.7539e-02,  7.7905e-02, -4.8264e-02, -2.9123e-05,  7.5276e-02,\n        -6.1326e-02,  2.0280e-02,  4.9516e-02, -3.2030e-02, -4.0888e-02,\n        -7.5112e-02, -3.5404e-02,  2.8850e-02,  6.0293e-02,  3.8220e-02,\n        -4.3435e-02,  2.4052e-02, -4.9834e-02, -5.6869e-02,  3.1752e-02,\n         8.5922e-02,  7.8697e-02,  8.0589e-02, -5.6149e-02,  7.2957e-02,\n        -3.6558e-02, -4.1028e-02, -3.7842e-03, -2.5315e-02, -8.9634e-04,\n         5.1651e-02,  4.2832e-02, -5.2167e-02, -8.3766e-02, -2.9197e-02,\n        -7.5250e-02,  4.1173e-02,  4.8907e-02, -5.6119e-02, -6.1119e-02,\n        -5.1152e-02,  1.6385e-02,  6.4654e-02,  8.0868e-02, -4.9489e-02,\n        -7.3225e-02, -4.7094e-02,  6.1023e-02,  6.2043e-02,  6.3435e-02,\n        -3.5828e-02, -1.2517e-02,  3.5198e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.4531e-02,  8.7825e-02,  3.7837e-03, -8.5724e-02, -1.8775e-02,\n          2.5473e-02, -4.5610e-02, -8.7064e-03,  5.2735e-02, -1.0784e-02,\n          4.2604e-02,  3.6888e-02,  8.2260e-02,  1.7138e-02, -2.9678e-02,\n         -5.9311e-03, -8.2771e-02,  1.4892e-03, -8.6974e-02,  5.2528e-02,\n         -4.1441e-02,  3.4245e-02, -1.1158e-05, -2.6533e-03,  3.5071e-02,\n          6.7323e-02,  1.7750e-02, -8.6317e-02, -4.3830e-03, -7.1053e-02,\n          2.5591e-02, -6.6631e-02, -5.9848e-02, -2.2240e-02, -4.8437e-02,\n          6.2453e-02, -7.7587e-02,  2.3490e-02,  7.8964e-03, -6.7947e-02,\n         -2.2199e-03, -7.5885e-02,  6.0638e-02, -1.2530e-02, -7.7692e-03,\n          7.2849e-02, -1.1615e-02, -5.4460e-02,  6.5029e-02,  2.6888e-02,\n         -3.4538e-02,  5.1885e-02, -2.6820e-02, -2.2641e-02, -2.6597e-02,\n          5.9350e-02,  2.7165e-02,  2.5073e-02, -8.5805e-02, -4.7007e-02,\n          6.6282e-02,  8.6901e-02, -6.6191e-02,  5.8211e-02,  5.2427e-02,\n          5.5404e-03,  8.2839e-02,  4.9146e-02, -9.6029e-03,  5.0002e-02,\n         -7.9555e-02,  5.2042e-02, -6.2821e-02,  2.1462e-03,  7.1242e-02,\n         -8.7775e-02, -5.4785e-02, -4.7122e-02, -1.7475e-02,  2.8606e-02,\n         -7.4280e-02,  7.4003e-02, -8.4152e-02, -6.7220e-02,  2.1404e-02,\n          6.3119e-02, -5.5159e-02, -4.0304e-02, -5.7348e-02,  3.3914e-02,\n         -5.3901e-02, -6.8635e-02, -6.8296e-03,  1.0467e-02,  3.5222e-02,\n          2.2435e-02, -5.6249e-02,  5.2689e-02, -8.5678e-02, -8.0656e-03,\n         -7.0405e-02,  9.6911e-03,  7.0012e-02,  5.9618e-02, -4.5021e-02,\n         -4.0957e-02,  4.8003e-02, -1.9627e-02, -3.7234e-02,  8.7201e-02,\n         -7.8479e-02,  5.3068e-02,  4.3966e-03, -4.9027e-02,  1.3706e-02,\n         -5.9083e-02, -2.8291e-02, -3.8386e-03,  3.7624e-02,  3.8947e-02,\n          3.2027e-02,  2.9010e-02, -7.9826e-02, -8.3745e-02, -3.9942e-03,\n         -6.1203e-02,  2.2023e-02,  1.3698e-02],\n        [ 7.7586e-02,  7.9986e-02,  7.1722e-02,  7.3180e-02, -3.5023e-02,\n          6.2199e-02, -6.6531e-02,  4.4391e-02,  3.2325e-02,  2.6508e-02,\n         -7.3535e-02, -4.1865e-03,  4.9536e-02, -8.7298e-02,  3.4776e-02,\n          2.1290e-02, -7.9133e-02,  8.8263e-02,  2.7588e-02, -5.4220e-02,\n         -6.1802e-02,  7.9797e-02,  8.4676e-02, -4.7152e-02, -8.3749e-02,\n          6.8662e-02,  6.0217e-02, -8.1595e-02,  2.3702e-02,  1.0721e-02,\n          4.8638e-02, -7.9853e-02, -8.0177e-03,  4.6840e-02, -8.3400e-02,\n          2.9190e-02, -1.5183e-02, -5.5066e-02, -6.7697e-02, -2.5802e-02,\n          8.1224e-02,  1.4840e-02,  1.7464e-02, -4.9096e-02,  6.7886e-02,\n         -5.3289e-03,  4.4274e-02, -4.2258e-02, -2.8303e-02, -5.8923e-02,\n          7.5788e-02,  3.8433e-02,  3.8959e-02,  1.7292e-02,  4.1355e-02,\n          2.0379e-02, -2.6889e-02, -7.4881e-02,  3.2932e-02,  4.6620e-02,\n          2.7184e-02, -2.5981e-02,  4.1487e-02,  7.5904e-02, -1.6147e-02,\n          7.0837e-02, -8.3150e-02, -8.0985e-02, -6.6992e-02, -2.0342e-02,\n         -3.8392e-02, -1.7955e-02,  6.9520e-02,  4.8154e-02,  5.6026e-02,\n          4.4942e-02,  7.9644e-02,  2.9691e-03, -9.8619e-03, -7.8928e-02,\n          4.8308e-02,  9.9209e-04, -7.6906e-03, -8.5401e-02, -4.4155e-02,\n         -5.4975e-02,  3.1372e-02,  5.3668e-02, -8.2031e-02, -1.6559e-02,\n         -4.9920e-02,  2.3231e-02, -7.5739e-02,  6.9832e-02,  2.6304e-03,\n          4.1893e-03,  1.4490e-02, -2.4734e-02,  5.7758e-02, -4.6849e-03,\n         -8.7390e-02, -9.8651e-03,  9.4994e-03, -3.2075e-02, -8.7617e-02,\n         -6.9878e-02, -5.3417e-02,  8.5505e-03,  7.2610e-02, -7.7654e-02,\n          6.1501e-02, -2.5416e-02, -5.7613e-03, -6.4095e-02,  7.1727e-02,\n         -5.3665e-03,  4.7258e-02, -2.6902e-02, -1.5984e-02, -7.2288e-02,\n          6.6449e-02,  6.4592e-02, -8.8203e-02, -5.6878e-02, -5.3554e-03,\n         -7.1212e-02, -2.5844e-02,  5.5336e-02],\n        [-7.2969e-02,  7.0338e-03, -8.7564e-02, -4.0098e-02, -7.1237e-02,\n          2.4159e-02, -2.6028e-03, -5.8759e-02,  7.9524e-02,  5.5485e-02,\n         -1.8650e-02, -1.6813e-02,  2.2772e-02, -3.4707e-02, -7.5368e-02,\n          1.8086e-03,  1.2473e-02, -6.7353e-02, -6.0850e-02, -7.4253e-02,\n          6.2003e-02, -7.8795e-02,  1.9941e-04,  4.6044e-03,  4.6553e-02,\n          4.1115e-02,  1.6922e-02,  8.7631e-03,  3.2518e-02, -6.0858e-02,\n         -8.6550e-02,  4.4621e-02, -2.4354e-02,  6.7596e-02, -8.7394e-02,\n          3.2163e-03,  1.1283e-02,  3.0429e-02,  2.8992e-03,  5.0131e-02,\n         -2.6302e-04,  4.3389e-02,  3.2910e-02,  5.2572e-02,  2.1797e-02,\n         -6.1795e-04, -6.0834e-02,  9.4117e-04,  8.1438e-02, -4.3598e-02,\n         -3.0713e-02,  5.4188e-02, -5.6222e-02,  4.2151e-02, -5.5606e-02,\n          4.4125e-02, -5.2637e-02, -2.8671e-02, -6.4911e-02,  5.8554e-02,\n          2.7947e-02,  2.8888e-02,  7.3423e-02,  2.4563e-02, -7.9881e-02,\n          6.7995e-02, -1.9828e-02,  3.6689e-02, -1.0131e-02,  2.0726e-02,\n          4.1856e-02, -1.2245e-02, -1.0109e-02,  3.5321e-02,  5.5980e-02,\n         -1.2266e-02,  8.1410e-02,  3.8432e-02,  8.2759e-02,  2.9441e-03,\n          6.7110e-02,  7.6100e-02,  6.1605e-02,  6.4200e-02, -6.7140e-02,\n         -5.0973e-02,  6.1765e-02,  1.1643e-03,  7.0208e-02,  4.9604e-02,\n          3.1904e-02,  6.4244e-02, -4.8254e-03,  5.7048e-02, -6.2592e-02,\n          4.1614e-02,  3.7732e-02,  6.3766e-02, -6.1595e-02,  2.6786e-02,\n         -2.3679e-02,  1.2539e-02, -6.1569e-02, -3.0549e-03,  3.6616e-02,\n         -2.1933e-02, -5.1190e-02, -7.5644e-02, -2.4094e-02, -2.9981e-02,\n          3.0666e-02,  7.1586e-02, -5.6728e-02, -8.0158e-02,  2.7651e-02,\n          3.3655e-02, -2.2667e-02, -4.6621e-02, -3.9011e-02,  3.9828e-03,\n          2.2705e-02,  8.1266e-02, -5.7325e-02, -2.1453e-02, -1.9991e-02,\n          4.6121e-04, -2.4970e-02,  8.3886e-02],\n        [-6.3575e-02, -1.3054e-02, -6.8853e-02, -3.1772e-02,  4.7215e-02,\n          8.6940e-02, -3.8818e-02,  3.1580e-02,  3.6544e-02, -8.5338e-03,\n         -5.3466e-02, -7.1555e-02, -5.5766e-02, -1.1230e-02, -1.0329e-02,\n         -7.0229e-02,  6.6922e-02,  2.0834e-02, -1.2806e-02, -3.5231e-02,\n          3.4503e-02,  2.6669e-02,  6.3873e-02,  5.9246e-02, -2.6453e-02,\n         -3.5545e-02,  6.6557e-02, -3.8807e-03, -5.6074e-02,  6.5382e-02,\n         -4.7098e-03,  8.0705e-02, -5.5026e-03, -2.1011e-02, -7.4276e-02,\n         -2.6806e-02, -3.4717e-02, -6.5956e-02,  2.2292e-02,  3.0276e-02,\n         -8.0077e-02, -4.0179e-02,  6.8567e-02, -7.3787e-02, -8.1452e-03,\n          2.6369e-02, -4.9800e-02,  1.4786e-02,  7.5876e-02, -4.3929e-02,\n          5.4125e-02,  8.3270e-02, -5.8868e-02,  1.0274e-02, -2.6273e-02,\n          4.7976e-02, -8.4750e-02,  7.7673e-03,  4.8501e-02,  6.0909e-02,\n         -6.6124e-02,  5.3623e-03,  5.8939e-02,  7.6285e-02, -1.5792e-02,\n          7.4007e-02,  5.2684e-02, -3.8503e-02, -3.8674e-02,  7.2092e-03,\n         -7.1456e-03, -8.0367e-02,  4.3916e-02, -1.8832e-02,  8.8147e-02,\n          4.7315e-02, -4.6828e-02,  6.9238e-02, -2.1577e-02,  1.5541e-02,\n          5.5676e-02,  8.3418e-02, -8.3338e-02, -5.9371e-03,  2.6251e-02,\n         -9.0952e-03, -1.3155e-02,  5.4696e-02,  5.9996e-03, -6.9830e-02,\n         -7.2330e-02, -5.4331e-02, -7.1434e-02, -7.2423e-02,  6.8367e-02,\n         -5.5275e-02,  1.5381e-02,  2.0823e-02, -3.7458e-02, -8.7195e-02,\n          1.9799e-02,  6.2359e-02,  9.4033e-03,  6.1532e-02, -4.7005e-02,\n         -3.3659e-02,  1.1017e-02, -8.2563e-03, -8.5852e-02, -4.8125e-02,\n          1.5225e-02, -5.8348e-02,  5.7391e-02, -2.5284e-02,  3.2313e-02,\n         -8.7698e-02,  8.8467e-03,  7.0224e-02,  3.1689e-02, -7.1476e-02,\n          4.2276e-02, -3.4831e-02,  7.1361e-02, -7.0962e-02,  3.9202e-02,\n         -3.1061e-02, -7.3520e-02,  6.7949e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0462,  0.0200, -0.0526, -0.0792], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.SegmentedReplayBuffer object at 0x754da4204b50>":	{
                    "alpha":	0.6,
                    "aux_buf_size":	5000,
                    "aux_buffer":	{
                        "act_buf":	"[0 0 0 ... 0 0 0]",
                        "done_buf":	"[False False False ... False False False]",
                        "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                        "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                        "priorities":	"[0. 0. 0. ... 0. 0. 0.]",
                        "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                        "timestamps":	"[0 0 0 ... 0 0 0]"
                    },
                    "aux_ptr":	0,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "capacity":	50000,
                    "current_segment":	0,
                    "epsilon":	1e-06,
                    "last_segment":	null,
                    "last_segment_ptr":	null,
                    "max_age":	50000,
                    "max_size":	50000,
                    "num_segments":	5,
                    "ptr":	0,
                    "sample_decay":	0.8,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "segments":	{
                        "0":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "1":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "2":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "3":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        },
                        "4":	{
                            "act_buf":	"[0 0 0 ... 0 0 0]",
                            "done_buf":	"[False False False ... False False False]",
                            "markers":	"[False False False ... False False False]",
                            "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                            "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                            "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                            "timestamps":	"[0 0 0 ... 0 0 0]"
                        }
                    },
                    "step":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0003,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0996,  0.2815,  0.0781, -0.2522, -0.2788, -0.2333,  0.0840,  0.1818,\n         0.1354,  0.2604,  0.0652,  0.2522, -0.2557,  0.1609, -0.0860, -0.0365,\n        -0.1846,  0.2041,  0.2406,  0.0994, -0.0159, -0.0176, -0.2941,  0.0148,\n         0.2548, -0.1794, -0.3172,  0.1944,  0.2917,  0.0561, -0.0295, -0.1850,\n        -0.3036, -0.2818, -0.2510,  0.2566,  0.3008,  0.0048, -0.0612,  0.1245,\n         0.0900,  0.1060, -0.0773, -0.0661, -0.1073,  0.2781,  0.1579,  0.2504,\n        -0.1628, -0.1091, -0.2311, -0.1653,  0.3461,  0.2680,  0.0417, -0.3325,\n        -0.2310,  0.2507,  0.1780, -0.3132, -0.0480,  0.1673, -0.0306,  0.1175,\n         0.2407, -0.1863, -0.1522, -0.2363, -0.0409, -0.1754, -0.2253, -0.2329,\n         0.1179, -0.0853,  0.2949, -0.0335, -0.0150, -0.1705, -0.1488,  0.1466,\n        -0.0271, -0.2085,  0.3109,  0.2350,  0.0448,  0.1635, -0.2093, -0.0749,\n        -0.2088,  0.2016, -0.3413,  0.1201, -0.1722,  0.0831,  0.3179,  0.2319,\n        -0.3363,  0.3001, -0.2510,  0.1760, -0.0296, -0.2259, -0.0146, -0.1296,\n         0.0987,  0.1449, -0.0789,  0.2807, -0.3382, -0.0337,  0.0459, -0.2943,\n        -0.1084, -0.0612, -0.1348, -0.0023,  0.2233,  0.0349,  0.0463,  0.1351,\n        -0.1945,  0.0390,  0.2499, -0.0729, -0.1936, -0.1713,  0.0213, -0.2001],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0447,  0.0338, -0.0037,  ...,  0.0218, -0.2121, -0.1948],\n        [ 0.0153, -0.2176, -0.1199,  ..., -0.1461,  0.0512,  0.3280],\n        [ 0.3048, -0.0725,  0.2409,  ...,  0.2675, -0.0839, -0.0958],\n        ...,\n        [ 0.2870,  0.0918, -0.2572,  ...,  0.1003,  0.1821, -0.1457],\n        [ 0.1740, -0.2549,  0.1692,  ...,  0.0485, -0.0476, -0.3174],\n        [-0.1876,  0.0716,  0.2928,  ..., -0.2354,  0.0412, -0.2839]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 4.5473e-02,  4.7622e-02,  3.1568e-02,  6.1609e-02, -1.8978e-02,\n         6.2199e-02,  7.7963e-02,  7.4545e-02, -6.4889e-02, -5.5010e-02,\n        -4.1552e-02,  4.0509e-02,  3.1716e-02,  4.4322e-02, -5.1574e-02,\n         6.3049e-02,  4.2396e-02,  2.9690e-02,  6.5155e-02,  5.9369e-02,\n         1.5394e-02, -5.8135e-02,  1.6339e-02,  6.9557e-02, -6.9481e-02,\n        -7.5967e-02,  8.6240e-03,  1.2045e-02,  4.9268e-02,  6.8827e-02,\n         1.3022e-02,  4.0491e-02, -8.3815e-02,  3.6850e-02,  1.6072e-02,\n        -7.9781e-02,  5.4845e-02,  7.8331e-02,  4.7194e-02,  1.6224e-02,\n        -1.4117e-02,  8.1836e-02, -7.0882e-02,  7.8729e-02, -8.6925e-02,\n         8.6477e-02, -2.3677e-02, -2.0124e-02,  6.5712e-02, -5.0825e-02,\n         3.8870e-02,  6.3811e-02,  6.2368e-02, -6.9282e-02,  7.2417e-02,\n        -2.0987e-02,  3.3137e-03, -3.9205e-03,  6.2732e-02, -5.6983e-02,\n         3.7618e-02, -3.4922e-03,  8.0969e-02,  4.3201e-02, -7.8421e-02,\n        -5.7730e-02,  6.9126e-03,  4.8493e-02,  3.6189e-02, -8.0014e-02,\n         1.0027e-02,  2.7604e-03,  8.2094e-02,  6.7533e-02,  5.2241e-02,\n         5.7539e-02,  7.7905e-02, -4.8264e-02, -2.9123e-05,  7.5276e-02,\n        -6.1326e-02,  2.0280e-02,  4.9516e-02, -3.2030e-02, -4.0888e-02,\n        -7.5112e-02, -3.5404e-02,  2.8850e-02,  6.0293e-02,  3.8220e-02,\n        -4.3435e-02,  2.4052e-02, -4.9834e-02, -5.6869e-02,  3.1752e-02,\n         8.5922e-02,  7.8697e-02,  8.0589e-02, -5.6149e-02,  7.2957e-02,\n        -3.6558e-02, -4.1028e-02, -3.7842e-03, -2.5315e-02, -8.9634e-04,\n         5.1651e-02,  4.2832e-02, -5.2167e-02, -8.3766e-02, -2.9197e-02,\n        -7.5250e-02,  4.1173e-02,  4.8907e-02, -5.6119e-02, -6.1119e-02,\n        -5.1152e-02,  1.6385e-02,  6.4654e-02,  8.0868e-02, -4.9489e-02,\n        -7.3225e-02, -4.7094e-02,  6.1023e-02,  6.2043e-02,  6.3435e-02,\n        -3.5828e-02, -1.2517e-02,  3.5198e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0379, -0.0478, -0.0863,  ..., -0.0229,  0.0473, -0.0412],\n        [-0.0759, -0.0650,  0.0812,  ..., -0.0467, -0.0118, -0.0075],\n        [ 0.0597, -0.0539, -0.0095,  ..., -0.0738,  0.0615, -0.0613],\n        ...,\n        [-0.0399, -0.0330, -0.0362,  ...,  0.0380, -0.0714, -0.0197],\n        [-0.0642,  0.0152,  0.0205,  ..., -0.0570,  0.0487,  0.0590],\n        [-0.0414,  0.0364, -0.0239,  ..., -0.0737,  0.0221, -0.0746]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0462,  0.0200, -0.0526, -0.0792], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.4531e-02,  8.7825e-02,  3.7837e-03, -8.5724e-02, -1.8775e-02,\n          2.5473e-02, -4.5610e-02, -8.7064e-03,  5.2735e-02, -1.0784e-02,\n          4.2604e-02,  3.6888e-02,  8.2260e-02,  1.7138e-02, -2.9678e-02,\n         -5.9311e-03, -8.2771e-02,  1.4892e-03, -8.6974e-02,  5.2528e-02,\n         -4.1441e-02,  3.4245e-02, -1.1158e-05, -2.6533e-03,  3.5071e-02,\n          6.7323e-02,  1.7750e-02, -8.6317e-02, -4.3830e-03, -7.1053e-02,\n          2.5591e-02, -6.6631e-02, -5.9848e-02, -2.2240e-02, -4.8437e-02,\n          6.2453e-02, -7.7587e-02,  2.3490e-02,  7.8964e-03, -6.7947e-02,\n         -2.2199e-03, -7.5885e-02,  6.0638e-02, -1.2530e-02, -7.7692e-03,\n          7.2849e-02, -1.1615e-02, -5.4460e-02,  6.5029e-02,  2.6888e-02,\n         -3.4538e-02,  5.1885e-02, -2.6820e-02, -2.2641e-02, -2.6597e-02,\n          5.9350e-02,  2.7165e-02,  2.5073e-02, -8.5805e-02, -4.7007e-02,\n          6.6282e-02,  8.6901e-02, -6.6191e-02,  5.8211e-02,  5.2427e-02,\n          5.5404e-03,  8.2839e-02,  4.9146e-02, -9.6029e-03,  5.0002e-02,\n         -7.9555e-02,  5.2042e-02, -6.2821e-02,  2.1462e-03,  7.1242e-02,\n         -8.7775e-02, -5.4785e-02, -4.7122e-02, -1.7475e-02,  2.8606e-02,\n         -7.4280e-02,  7.4003e-02, -8.4152e-02, -6.7220e-02,  2.1404e-02,\n          6.3119e-02, -5.5159e-02, -4.0304e-02, -5.7348e-02,  3.3914e-02,\n         -5.3901e-02, -6.8635e-02, -6.8296e-03,  1.0467e-02,  3.5222e-02,\n          2.2435e-02, -5.6249e-02,  5.2689e-02, -8.5678e-02, -8.0656e-03,\n         -7.0405e-02,  9.6911e-03,  7.0012e-02,  5.9618e-02, -4.5021e-02,\n         -4.0957e-02,  4.8003e-02, -1.9627e-02, -3.7234e-02,  8.7201e-02,\n         -7.8479e-02,  5.3068e-02,  4.3966e-03, -4.9027e-02,  1.3706e-02,\n         -5.9083e-02, -2.8291e-02, -3.8386e-03,  3.7624e-02,  3.8947e-02,\n          3.2027e-02,  2.9010e-02, -7.9826e-02, -8.3745e-02, -3.9942e-03,\n         -6.1203e-02,  2.2023e-02,  1.3698e-02],\n        [ 7.7586e-02,  7.9986e-02,  7.1722e-02,  7.3180e-02, -3.5023e-02,\n          6.2199e-02, -6.6531e-02,  4.4391e-02,  3.2325e-02,  2.6508e-02,\n         -7.3535e-02, -4.1865e-03,  4.9536e-02, -8.7298e-02,  3.4776e-02,\n          2.1290e-02, -7.9133e-02,  8.8263e-02,  2.7588e-02, -5.4220e-02,\n         -6.1802e-02,  7.9797e-02,  8.4676e-02, -4.7152e-02, -8.3749e-02,\n          6.8662e-02,  6.0217e-02, -8.1595e-02,  2.3702e-02,  1.0721e-02,\n          4.8638e-02, -7.9853e-02, -8.0177e-03,  4.6840e-02, -8.3400e-02,\n          2.9190e-02, -1.5183e-02, -5.5066e-02, -6.7697e-02, -2.5802e-02,\n          8.1224e-02,  1.4840e-02,  1.7464e-02, -4.9096e-02,  6.7886e-02,\n         -5.3289e-03,  4.4274e-02, -4.2258e-02, -2.8303e-02, -5.8923e-02,\n          7.5788e-02,  3.8433e-02,  3.8959e-02,  1.7292e-02,  4.1355e-02,\n          2.0379e-02, -2.6889e-02, -7.4881e-02,  3.2932e-02,  4.6620e-02,\n          2.7184e-02, -2.5981e-02,  4.1487e-02,  7.5904e-02, -1.6147e-02,\n          7.0837e-02, -8.3150e-02, -8.0985e-02, -6.6992e-02, -2.0342e-02,\n         -3.8392e-02, -1.7955e-02,  6.9520e-02,  4.8154e-02,  5.6026e-02,\n          4.4942e-02,  7.9644e-02,  2.9691e-03, -9.8619e-03, -7.8928e-02,\n          4.8308e-02,  9.9209e-04, -7.6906e-03, -8.5401e-02, -4.4155e-02,\n         -5.4975e-02,  3.1372e-02,  5.3668e-02, -8.2031e-02, -1.6559e-02,\n         -4.9920e-02,  2.3231e-02, -7.5739e-02,  6.9832e-02,  2.6304e-03,\n          4.1893e-03,  1.4490e-02, -2.4734e-02,  5.7758e-02, -4.6849e-03,\n         -8.7390e-02, -9.8651e-03,  9.4994e-03, -3.2075e-02, -8.7617e-02,\n         -6.9878e-02, -5.3417e-02,  8.5505e-03,  7.2610e-02, -7.7654e-02,\n          6.1501e-02, -2.5416e-02, -5.7613e-03, -6.4095e-02,  7.1727e-02,\n         -5.3665e-03,  4.7258e-02, -2.6902e-02, -1.5984e-02, -7.2288e-02,\n          6.6449e-02,  6.4592e-02, -8.8203e-02, -5.6878e-02, -5.3554e-03,\n         -7.1212e-02, -2.5844e-02,  5.5336e-02],\n        [-7.2969e-02,  7.0338e-03, -8.7564e-02, -4.0098e-02, -7.1237e-02,\n          2.4159e-02, -2.6028e-03, -5.8759e-02,  7.9524e-02,  5.5485e-02,\n         -1.8650e-02, -1.6813e-02,  2.2772e-02, -3.4707e-02, -7.5368e-02,\n          1.8086e-03,  1.2473e-02, -6.7353e-02, -6.0850e-02, -7.4253e-02,\n          6.2003e-02, -7.8795e-02,  1.9941e-04,  4.6044e-03,  4.6553e-02,\n          4.1115e-02,  1.6922e-02,  8.7631e-03,  3.2518e-02, -6.0858e-02,\n         -8.6550e-02,  4.4621e-02, -2.4354e-02,  6.7596e-02, -8.7394e-02,\n          3.2163e-03,  1.1283e-02,  3.0429e-02,  2.8992e-03,  5.0131e-02,\n         -2.6302e-04,  4.3389e-02,  3.2910e-02,  5.2572e-02,  2.1797e-02,\n         -6.1795e-04, -6.0834e-02,  9.4117e-04,  8.1438e-02, -4.3598e-02,\n         -3.0713e-02,  5.4188e-02, -5.6222e-02,  4.2151e-02, -5.5606e-02,\n          4.4125e-02, -5.2637e-02, -2.8671e-02, -6.4911e-02,  5.8554e-02,\n          2.7947e-02,  2.8888e-02,  7.3423e-02,  2.4563e-02, -7.9881e-02,\n          6.7995e-02, -1.9828e-02,  3.6689e-02, -1.0131e-02,  2.0726e-02,\n          4.1856e-02, -1.2245e-02, -1.0109e-02,  3.5321e-02,  5.5980e-02,\n         -1.2266e-02,  8.1410e-02,  3.8432e-02,  8.2759e-02,  2.9441e-03,\n          6.7110e-02,  7.6100e-02,  6.1605e-02,  6.4200e-02, -6.7140e-02,\n         -5.0973e-02,  6.1765e-02,  1.1643e-03,  7.0208e-02,  4.9604e-02,\n          3.1904e-02,  6.4244e-02, -4.8254e-03,  5.7048e-02, -6.2592e-02,\n          4.1614e-02,  3.7732e-02,  6.3766e-02, -6.1595e-02,  2.6786e-02,\n         -2.3679e-02,  1.2539e-02, -6.1569e-02, -3.0549e-03,  3.6616e-02,\n         -2.1933e-02, -5.1190e-02, -7.5644e-02, -2.4094e-02, -2.9981e-02,\n          3.0666e-02,  7.1586e-02, -5.6728e-02, -8.0158e-02,  2.7651e-02,\n          3.3655e-02, -2.2667e-02, -4.6621e-02, -3.9011e-02,  3.9828e-03,\n          2.2705e-02,  8.1266e-02, -5.7325e-02, -2.1453e-02, -1.9991e-02,\n          4.6121e-04, -2.4970e-02,  8.3886e-02],\n        [-6.3575e-02, -1.3054e-02, -6.8853e-02, -3.1772e-02,  4.7215e-02,\n          8.6940e-02, -3.8818e-02,  3.1580e-02,  3.6544e-02, -8.5338e-03,\n         -5.3466e-02, -7.1555e-02, -5.5766e-02, -1.1230e-02, -1.0329e-02,\n         -7.0229e-02,  6.6922e-02,  2.0834e-02, -1.2806e-02, -3.5231e-02,\n          3.4503e-02,  2.6669e-02,  6.3873e-02,  5.9246e-02, -2.6453e-02,\n         -3.5545e-02,  6.6557e-02, -3.8807e-03, -5.6074e-02,  6.5382e-02,\n         -4.7098e-03,  8.0705e-02, -5.5026e-03, -2.1011e-02, -7.4276e-02,\n         -2.6806e-02, -3.4717e-02, -6.5956e-02,  2.2292e-02,  3.0276e-02,\n         -8.0077e-02, -4.0179e-02,  6.8567e-02, -7.3787e-02, -8.1452e-03,\n          2.6369e-02, -4.9800e-02,  1.4786e-02,  7.5876e-02, -4.3929e-02,\n          5.4125e-02,  8.3270e-02, -5.8868e-02,  1.0274e-02, -2.6273e-02,\n          4.7976e-02, -8.4750e-02,  7.7673e-03,  4.8501e-02,  6.0909e-02,\n         -6.6124e-02,  5.3623e-03,  5.8939e-02,  7.6285e-02, -1.5792e-02,\n          7.4007e-02,  5.2684e-02, -3.8503e-02, -3.8674e-02,  7.2092e-03,\n         -7.1456e-03, -8.0367e-02,  4.3916e-02, -1.8832e-02,  8.8147e-02,\n          4.7315e-02, -4.6828e-02,  6.9238e-02, -2.1577e-02,  1.5541e-02,\n          5.5676e-02,  8.3418e-02, -8.3338e-02, -5.9371e-03,  2.6251e-02,\n         -9.0952e-03, -1.3155e-02,  5.4696e-02,  5.9996e-03, -6.9830e-02,\n         -7.2330e-02, -5.4331e-02, -7.1434e-02, -7.2423e-02,  6.8367e-02,\n         -5.5275e-02,  1.5381e-02,  2.0823e-02, -3.7458e-02, -8.7195e-02,\n          1.9799e-02,  6.2359e-02,  9.4033e-03,  6.1532e-02, -4.7005e-02,\n         -3.3659e-02,  1.1017e-02, -8.2563e-03, -8.5852e-02, -4.8125e-02,\n          1.5225e-02, -5.8348e-02,  5.7391e-02, -2.5284e-02,  3.2313e-02,\n         -8.7698e-02,  8.8467e-03,  7.0224e-02,  3.1689e-02, -7.1476e-02,\n          4.2276e-02, -3.4831e-02,  7.1361e-02, -7.0962e-02,  3.9202e-02,\n         -3.1061e-02, -7.3520e-02,  6.7949e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x754d993107d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s402110000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s402110000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}