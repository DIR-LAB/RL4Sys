{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.999,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s403410000"
    },
    "q_lr":	0.003,
    "seed":	403410000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7424db3e7350>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.005,
            "_epsilon_min":	0.01,
            "_gamma":	0.999,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1943, -0.2137, -0.0521, -0.2283, -0.2336, -0.2970,  0.3068, -0.3452,\n         0.1296, -0.1247, -0.0823,  0.1070, -0.1221,  0.0230, -0.0923,  0.2622,\n        -0.0848,  0.2878, -0.0503,  0.2728,  0.1963, -0.1189, -0.2313, -0.2590,\n         0.0444, -0.1356, -0.2201, -0.2173,  0.0693, -0.1156,  0.1974,  0.1360,\n         0.0562,  0.2798, -0.0628,  0.0061,  0.2596, -0.0818, -0.2776, -0.0365,\n         0.2862, -0.1222,  0.0878, -0.0451,  0.0974, -0.1690,  0.2991,  0.1091,\n        -0.1573,  0.2876,  0.3116,  0.2776, -0.2497, -0.2303,  0.3118, -0.0979,\n         0.1674, -0.1404, -0.1708,  0.0979,  0.1051, -0.0820,  0.0626, -0.3345,\n        -0.2111, -0.0317, -0.1772,  0.1364,  0.1736, -0.0684, -0.0535,  0.2563,\n        -0.1508,  0.1288, -0.0223,  0.0477, -0.2311,  0.0746,  0.2858,  0.0177,\n         0.1530,  0.2106,  0.2692,  0.3086,  0.3374, -0.0139,  0.2569, -0.1987,\n         0.2864,  0.0869, -0.1487,  0.0395, -0.2468,  0.1184, -0.0337,  0.2973,\n        -0.0501,  0.2826,  0.2831, -0.1168], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 2.3786e-01, -3.3695e-01, -2.7778e-01, -1.0028e-01, -2.7192e-01,\n          7.8111e-02, -2.3588e-01, -2.3396e-01],\n        [-4.6741e-02, -3.4661e-01,  2.3185e-01,  1.0339e-01,  6.0748e-02,\n          2.6564e-01,  1.6837e-01,  3.4258e-01],\n        [ 9.9601e-02,  1.4438e-01, -1.4036e-01,  9.2234e-02,  3.4580e-01,\n         -3.2772e-01, -3.3541e-01,  3.4030e-01],\n        [ 1.9645e-01,  1.8846e-01, -7.0983e-02, -9.9666e-03, -2.3549e-01,\n         -9.9795e-04,  2.9722e-01,  2.4172e-01],\n        [ 2.2840e-01,  2.8326e-01,  9.9706e-03, -3.1144e-01, -1.5334e-01,\n          1.1914e-01,  1.5865e-01, -1.5677e-01],\n        [-3.9509e-02, -1.4419e-01, -3.1681e-01,  9.3343e-02,  2.4650e-01,\n         -9.1356e-02,  1.9849e-02,  8.3491e-02],\n        [ 1.1443e-01,  6.1064e-02, -1.5601e-01,  1.9405e-02, -2.1911e-01,\n         -3.4978e-01,  1.2606e-01,  4.7999e-02],\n        [-3.0928e-01, -1.9328e-02, -8.4979e-02, -1.3256e-01,  1.3040e-01,\n          1.4391e-01,  2.8407e-01,  2.9739e-01],\n        [-3.4703e-01,  1.8555e-01, -2.4799e-01, -3.4244e-01, -1.2404e-01,\n         -6.0348e-02, -4.0491e-02,  3.1593e-01],\n        [ 4.7068e-02,  4.4928e-02,  2.1831e-01,  2.8646e-02,  1.2432e-01,\n         -1.4307e-01,  2.7172e-01, -8.7019e-02],\n        [-2.1682e-01, -7.3447e-02, -1.2332e-01,  1.4846e-01,  2.5999e-01,\n         -2.6813e-01, -1.5752e-01,  1.4771e-02],\n        [ 7.8016e-03, -2.3520e-01, -1.7066e-01,  3.3084e-01,  1.3401e-01,\n          2.7733e-01,  2.9895e-01, -1.4923e-01],\n        [-2.0286e-02, -2.8510e-01,  1.4618e-01, -2.9582e-01,  7.1923e-02,\n         -2.0751e-01,  1.1727e-01, -2.5925e-03],\n        [-3.3882e-01,  1.8057e-01,  3.2200e-01, -2.3994e-01, -1.2066e-01,\n          9.8882e-02,  3.0184e-01,  1.8843e-02],\n        [ 2.8447e-01,  1.8083e-02, -2.8121e-01,  1.7715e-01,  2.8377e-01,\n         -2.5305e-02,  4.8627e-02,  3.3687e-01],\n        [-8.8414e-02, -6.2196e-02, -2.8319e-01,  1.4241e-01, -2.3635e-01,\n          2.7149e-01, -3.1306e-01, -1.7346e-01],\n        [-3.1262e-01, -8.8543e-02,  4.8247e-02,  3.2345e-01, -2.6980e-01,\n          8.2512e-02,  1.9017e-01,  1.0449e-01],\n        [ 3.7943e-02, -1.0788e-01,  1.9062e-01,  2.5789e-01,  1.8441e-01,\n         -2.5654e-01, -3.2171e-01, -1.5282e-01],\n        [ 2.2928e-01,  2.5113e-01, -4.9448e-03,  2.2661e-01, -2.1058e-01,\n          1.4161e-01, -1.8508e-01,  2.1893e-01],\n        [-1.8252e-01, -4.1640e-02,  1.5845e-01,  2.3472e-01,  2.3106e-01,\n         -1.6581e-01,  6.4021e-02,  3.0600e-01],\n        [ 1.7575e-01,  2.1697e-01, -1.9469e-02,  1.7415e-01, -1.1850e-01,\n          1.4896e-01, -1.8818e-01,  3.3762e-01],\n        [-1.2795e-01, -1.7977e-01,  2.7968e-02,  2.1176e-01,  1.6351e-01,\n          1.6986e-01,  2.3131e-01, -2.5931e-01],\n        [-2.6499e-01, -4.0348e-02, -1.7272e-01, -3.0050e-01,  2.9789e-02,\n          2.1936e-01,  3.2064e-01,  2.0769e-01],\n        [ 7.9467e-02,  5.7345e-02,  1.6588e-01,  2.6117e-01,  2.7902e-01,\n          2.1390e-01, -1.6702e-01,  2.5091e-01],\n        [ 1.7969e-01, -2.0289e-01, -1.0799e-01, -1.2783e-01,  1.3008e-01,\n         -3.0817e-01, -1.7849e-01, -4.3477e-02],\n        [ 4.7696e-02, -3.1173e-01,  2.1207e-02, -2.4156e-01, -1.6762e-01,\n         -2.2644e-01,  7.6835e-02, -1.0709e-01],\n        [-7.0818e-02, -1.5372e-01,  2.4466e-01, -1.3022e-01,  2.1637e-01,\n          5.2210e-02, -2.0017e-01,  3.1267e-01],\n        [ 2.9155e-01,  1.3962e-01,  1.4653e-02,  4.6931e-03,  2.9417e-01,\n         -1.2964e-01,  2.8640e-01, -3.2754e-01],\n        [ 4.6483e-02,  1.9630e-01,  1.4409e-01,  1.0371e-01, -2.7270e-02,\n          3.3638e-02, -2.5158e-01,  1.3687e-01],\n        [ 3.1447e-01,  1.0372e-02, -8.5108e-02, -7.0669e-02,  2.6695e-01,\n          3.0441e-01,  2.0243e-01, -1.8007e-01],\n        [-1.2707e-01,  1.7096e-01,  5.2685e-02,  1.5898e-01,  1.8835e-01,\n          1.6306e-02, -3.5205e-01,  3.2814e-01],\n        [-2.8695e-02,  2.7322e-01,  3.0740e-01,  2.3510e-01,  6.6250e-02,\n          2.7725e-01,  2.3786e-01, -1.5365e-01],\n        [ 6.4055e-02, -2.1371e-01,  2.0939e-01, -1.8621e-02,  1.3681e-01,\n         -1.5099e-01, -1.6635e-01,  5.1625e-02],\n        [-3.4582e-01, -3.2455e-01,  1.3815e-01, -1.1118e-01,  8.4828e-02,\n          1.4488e-01, -2.1748e-01,  2.6668e-01],\n        [ 2.4892e-01, -1.7033e-02, -3.0584e-01, -2.7905e-01, -7.9689e-02,\n         -3.2328e-01,  2.2072e-01,  1.5311e-01],\n        [ 3.4001e-01,  2.6740e-01, -1.9334e-02, -8.7751e-02,  1.5607e-02,\n         -3.5299e-01,  2.6019e-01, -1.4504e-01],\n        [-8.9488e-02, -1.2198e-01,  1.1245e-01,  2.9139e-01, -1.2227e-01,\n         -3.0102e-01, -2.6509e-01, -2.8978e-01],\n        [-2.4283e-02, -6.8732e-02, -2.2441e-01, -1.0371e-01, -4.9223e-02,\n         -2.4676e-01,  6.5827e-02,  2.9504e-01],\n        [ 1.3585e-01, -2.9189e-01, -2.4316e-01, -9.9854e-02,  3.2229e-01,\n          5.6628e-02, -1.1114e-01,  2.1478e-01],\n        [ 8.9542e-02,  8.1477e-02,  1.3597e-01, -1.1872e-01,  3.0087e-01,\n          8.5292e-02, -3.3272e-01,  3.1617e-01],\n        [ 2.1978e-01,  1.2672e-01,  2.0938e-01,  1.9321e-01,  1.3548e-01,\n         -1.8912e-02,  2.9385e-01, -3.2620e-01],\n        [ 2.8557e-01, -4.2502e-02,  2.5404e-01,  1.6470e-01,  2.0931e-01,\n         -9.7700e-02,  2.4118e-01,  1.7433e-02],\n        [-2.6244e-01, -3.2662e-01, -2.5077e-01, -2.0759e-01,  1.8653e-01,\n         -3.4805e-01, -2.2947e-01,  1.0288e-01],\n        [ 1.7091e-01, -1.4558e-01, -1.2939e-01, -2.5124e-01,  5.4807e-03,\n         -3.0915e-01, -2.6641e-01,  1.4327e-01],\n        [ 6.8167e-02, -6.9519e-02, -2.4645e-01,  6.3859e-02, -2.0050e-01,\n          2.6715e-01,  2.4432e-01, -1.2337e-01],\n        [ 2.8281e-02,  2.3866e-02, -1.1658e-01,  2.2026e-01, -3.2112e-01,\n          1.1200e-01, -1.4003e-01, -1.4142e-02],\n        [-3.0210e-01, -1.4745e-01,  2.0858e-01, -2.3725e-01, -3.3768e-01,\n         -1.6075e-02,  8.7266e-02, -5.2643e-02],\n        [-2.1517e-01,  3.2023e-03, -1.4522e-01, -2.7214e-01,  2.2969e-01,\n          2.3851e-01, -2.3360e-01, -1.3335e-02],\n        [-9.0879e-02, -1.7921e-01, -1.7319e-01, -3.3473e-01,  7.3486e-02,\n          2.7444e-01,  1.4605e-01,  5.9907e-02],\n        [ 2.5930e-01, -3.3681e-01, -1.6697e-01,  1.0466e-01, -2.3346e-01,\n         -1.2416e-01,  3.5148e-01, -5.8547e-02],\n        [-2.4134e-03,  2.5862e-01,  1.9671e-02, -5.1762e-02,  1.9661e-01,\n         -3.3747e-01, -1.2906e-01,  3.2316e-01],\n        [-2.3357e-01, -1.5898e-01,  2.6603e-01,  1.6335e-01,  1.3384e-01,\n         -3.8961e-02, -5.0409e-02,  3.2988e-01],\n        [ 3.3015e-01, -2.1142e-01, -4.7153e-02, -2.4265e-01, -3.1149e-01,\n         -1.8226e-01,  3.1766e-01,  1.7969e-01],\n        [ 1.7471e-01, -1.0126e-02,  2.7644e-01,  1.1456e-02, -2.7981e-01,\n         -3.0570e-01,  2.7298e-01, -9.7109e-02],\n        [-2.3782e-01, -3.8177e-02,  6.9532e-02, -7.4362e-02,  2.4714e-01,\n         -5.0828e-02, -4.4460e-02,  1.9064e-01],\n        [-3.0242e-01,  2.2942e-01,  3.1918e-01, -5.1243e-02,  6.7436e-02,\n          3.4033e-01, -1.8452e-01,  4.9645e-02],\n        [-2.5258e-01, -3.1106e-01, -1.7916e-01,  1.7840e-01, -1.5664e-01,\n          1.0591e-01,  2.5946e-01, -1.9740e-01],\n        [ 1.0024e-01, -1.8763e-01, -2.7769e-01,  8.2441e-02,  1.8279e-01,\n          2.0343e-01,  2.6125e-01, -8.2968e-02],\n        [ 1.1980e-01, -2.6305e-01,  3.1886e-01, -2.1037e-01, -2.0454e-01,\n         -4.1857e-02, -1.7366e-01, -1.7799e-01],\n        [ 9.6042e-02, -2.3371e-01,  3.4815e-01, -4.9281e-02, -1.7081e-01,\n         -8.4994e-02,  8.2886e-03,  3.2892e-01],\n        [-1.5266e-01, -1.2127e-01,  3.3034e-01, -8.9182e-02,  3.4762e-01,\n          2.0993e-01,  1.8116e-01,  3.3125e-01],\n        [ 1.7061e-01, -1.1098e-01, -2.9474e-01, -1.1744e-01,  1.2745e-01,\n         -1.0925e-01, -1.7369e-01,  2.2886e-01],\n        [ 1.2205e-01, -4.0941e-02, -3.3259e-01, -1.0987e-01,  2.2759e-01,\n         -2.2319e-01,  3.3378e-01,  1.5962e-01],\n        [-2.7825e-02, -3.4669e-01, -8.5796e-02, -4.4771e-02, -1.1307e-01,\n          1.7582e-01, -1.4226e-02,  7.8595e-02],\n        [ 5.2915e-02,  2.5520e-01,  1.9859e-02,  1.2257e-01,  1.1652e-01,\n          1.8239e-01,  3.1370e-01, -4.5203e-02],\n        [-1.8345e-02,  1.2266e-01,  2.5254e-02, -3.4097e-01,  2.6765e-02,\n         -3.4836e-01,  1.3769e-01, -2.2312e-01],\n        [-2.1198e-01, -3.3421e-01, -7.4985e-02,  3.2045e-01,  1.5236e-02,\n          1.6249e-01,  1.3583e-01,  2.6117e-01],\n        [ 2.4334e-01,  2.9339e-01,  2.8616e-02, -1.9113e-01, -2.7370e-01,\n         -3.7568e-02,  2.3645e-01, -2.2037e-01],\n        [-8.4196e-02, -8.4006e-02,  2.1142e-01,  2.0337e-02,  2.8407e-01,\n         -1.5950e-01,  6.2578e-02,  1.2583e-01],\n        [-2.8732e-01,  2.7670e-01,  2.1537e-01,  2.0037e-01, -3.5299e-01,\n          6.5216e-03,  2.4880e-01, -2.0060e-01],\n        [ 2.7610e-01,  1.9586e-01,  9.3024e-02,  9.0800e-02, -7.3087e-02,\n         -1.5568e-01, -3.1608e-01, -2.2937e-01],\n        [ 2.5154e-02,  3.0536e-01, -1.6134e-01,  2.7636e-01,  8.4979e-02,\n          2.2038e-01,  3.3786e-01,  1.4387e-01],\n        [ 6.6869e-02, -2.1107e-02,  3.0141e-01, -3.3752e-01, -2.2307e-01,\n         -3.1684e-01, -1.9170e-01,  2.8548e-01],\n        [-1.9009e-01,  2.2495e-01, -3.9379e-02, -2.3843e-01,  1.8104e-01,\n          2.3655e-01,  3.0829e-03, -1.8878e-01],\n        [-2.1718e-01, -2.2795e-01, -5.8784e-02,  2.1202e-01,  1.3064e-01,\n          2.8897e-01, -8.7638e-02, -2.6231e-01],\n        [ 1.9839e-01, -3.2495e-01,  2.2087e-01, -1.9792e-01, -4.1318e-02,\n          3.1932e-01, -2.0996e-01, -2.4648e-01],\n        [-3.5307e-02, -3.2519e-01, -1.7319e-01,  2.6106e-01,  2.3824e-01,\n          1.5808e-01,  1.0332e-01,  7.2160e-02],\n        [ 3.0812e-01, -8.3106e-02,  1.2309e-02, -1.2996e-01, -1.9696e-02,\n          4.2894e-02, -2.5714e-01, -2.6573e-01],\n        [ 9.2589e-02,  3.1839e-01, -6.4920e-02, -3.3521e-01,  1.2979e-01,\n         -1.9667e-01,  2.3998e-01, -2.9798e-01],\n        [ 1.2658e-01, -1.1226e-01,  3.1374e-01, -1.4774e-01,  5.5658e-02,\n         -3.1200e-01,  1.9662e-01, -2.2572e-01],\n        [ 1.1568e-01,  2.1073e-01, -1.5965e-01, -2.9945e-01,  7.1639e-03,\n         -7.8863e-02, -2.6835e-01,  2.5270e-01],\n        [ 4.8671e-02,  2.9545e-01,  1.8002e-01, -2.1037e-01, -1.4093e-01,\n         -2.6853e-01, -1.8383e-01, -2.7265e-02],\n        [-3.1002e-01,  8.0955e-02,  1.9546e-01,  1.9233e-01,  1.9874e-01,\n         -2.4263e-01, -1.4901e-01,  1.4545e-02],\n        [ 2.2694e-01,  5.6593e-02, -1.8848e-01,  2.4377e-01, -1.2067e-01,\n          2.8553e-01,  1.7329e-02, -2.3512e-01],\n        [ 3.3123e-01, -1.7668e-01, -1.1729e-01, -6.6331e-02,  9.8048e-02,\n         -2.0282e-01, -8.9384e-02,  1.7855e-01],\n        [ 2.1368e-01, -3.2956e-01, -1.1871e-01, -2.7600e-01, -2.4916e-01,\n          1.6322e-01, -4.0335e-05,  1.9789e-01],\n        [ 1.6431e-02, -2.6831e-01, -2.7831e-01,  5.1965e-02, -2.8655e-01,\n          1.4089e-01,  3.2879e-01,  1.3356e-01],\n        [-8.6074e-02,  3.4376e-01, -3.4195e-01, -2.1122e-01,  2.7172e-02,\n         -1.4851e-01,  3.1145e-01, -1.9075e-01],\n        [ 2.5385e-01,  2.3836e-01,  3.9671e-02, -3.4933e-01, -8.5732e-02,\n          2.7287e-01, -2.0127e-01,  5.1378e-02],\n        [ 8.4103e-02, -3.9752e-02, -1.0161e-01,  3.2114e-01,  9.3732e-02,\n         -2.9155e-01,  1.9924e-01,  3.1052e-02],\n        [-3.7782e-02, -9.9962e-02,  1.9692e-01,  3.2935e-01, -5.4906e-02,\n          1.0556e-02,  1.9056e-01, -7.4897e-02],\n        [ 1.3422e-01,  1.2778e-02, -7.6695e-02,  1.5575e-01,  2.3641e-01,\n          2.6561e-01, -3.9373e-02,  3.7005e-02],\n        [ 1.5203e-01,  5.9329e-02, -8.5491e-02, -9.8959e-02, -3.3285e-01,\n          6.8445e-02, -2.4354e-01, -1.2161e-01],\n        [ 2.4042e-02,  7.0855e-02, -3.1948e-01,  3.1939e-01,  2.1194e-01,\n         -6.8790e-02,  2.7634e-02,  2.8092e-01],\n        [ 2.3918e-01, -1.3061e-01,  1.6576e-01,  8.2420e-02, -1.0612e-01,\n         -2.0142e-01, -3.3633e-01, -3.0123e-01],\n        [ 2.0839e-01, -3.3449e-01, -3.5937e-02,  3.0386e-01,  2.3566e-01,\n         -3.0950e-01, -1.4461e-01,  8.2345e-02],\n        [-9.0809e-02, -1.1787e-01, -2.3933e-01,  5.3010e-02,  4.3382e-02,\n          1.7242e-01,  1.6622e-01,  4.0364e-02],\n        [ 1.7792e-01,  4.9864e-02,  2.9932e-01, -1.7704e-01,  2.7456e-02,\n         -1.5989e-01, -2.6077e-01, -2.9783e-01],\n        [-3.1147e-01, -1.8784e-01, -2.7498e-01, -5.1076e-02, -2.2461e-01,\n         -6.0716e-03,  3.3511e-01, -1.6788e-01],\n        [-1.8731e-01, -1.2435e-01,  1.6181e-01,  1.3929e-01,  2.4502e-01,\n          3.1036e-01,  3.1022e-01,  7.5838e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0137, -0.0466,  0.0686, -0.0438, -0.0016, -0.0011, -0.0282, -0.0654,\n        -0.0091,  0.0107, -0.0862,  0.0454,  0.0706,  0.0959, -0.0910, -0.0061,\n        -0.0207, -0.0273,  0.0889,  0.0400, -0.0578, -0.0569, -0.0433,  0.0308,\n         0.0488, -0.0581,  0.0749, -0.0887,  0.0859,  0.0196,  0.0256,  0.0759,\n        -0.0071,  0.0840, -0.0110, -0.0598,  0.0360,  0.0521,  0.0231, -0.0734,\n        -0.0309,  0.0901,  0.0815,  0.0804,  0.0369,  0.0543,  0.0769,  0.0078,\n        -0.0519,  0.0527,  0.0698, -0.0899, -0.0351,  0.0578, -0.0413,  0.0061,\n         0.0521,  0.0482, -0.0268,  0.0698,  0.0915, -0.0730,  0.0752,  0.0012,\n        -0.0535,  0.0356,  0.0752, -0.0693, -0.0892, -0.0561, -0.0639, -0.0088,\n        -0.0722, -0.0216,  0.0563,  0.0006,  0.0680,  0.0607,  0.0569, -0.0511,\n         0.0040, -0.0925,  0.0974,  0.0260,  0.0479,  0.0742,  0.0624,  0.0078,\n        -0.0418, -0.0781,  0.0179, -0.0855, -0.0104,  0.0849,  0.0690, -0.0473,\n        -0.0803,  0.0033, -0.0961, -0.0732], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0619, -0.0581, -0.0619,  ..., -0.0600,  0.0532, -0.0920],\n        [ 0.0545,  0.0953, -0.0064,  ..., -0.0363, -0.0454, -0.0432],\n        [ 0.0119,  0.0114,  0.0620,  ...,  0.0787, -0.0431, -0.0748],\n        ...,\n        [-0.0830,  0.0892,  0.0575,  ...,  0.0552,  0.0458,  0.0389],\n        [-0.0032,  0.0686, -0.0990,  ...,  0.0014, -0.0294,  0.0535],\n        [-0.0169,  0.0314,  0.0246,  ...,  0.0453, -0.0282, -0.0123]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0025, -0.0616, -0.0824,  0.0761,  0.0857,  0.0335, -0.0240,  0.0985],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0293, -0.0535,  0.0291, -0.0801,  0.0548, -0.0134, -0.0926, -0.0694,\n         -0.0497, -0.0205,  0.0014, -0.0138,  0.0008, -0.0900, -0.0006, -0.0399,\n         -0.0849,  0.0152,  0.0011,  0.0959, -0.0080,  0.0397, -0.0397,  0.0526,\n         -0.0850,  0.0813,  0.0861,  0.0109,  0.0651,  0.0562,  0.0833, -0.0769,\n         -0.0621,  0.0158, -0.0712,  0.0418, -0.0055, -0.0982,  0.0746,  0.0227,\n         -0.0999,  0.0554,  0.0223,  0.0527, -0.0950,  0.0390, -0.0540, -0.0991,\n         -0.0248,  0.0958,  0.0205, -0.0906, -0.0312,  0.0803, -0.0033,  0.0895,\n          0.0092,  0.0118, -0.0229,  0.0415, -0.0002, -0.0133, -0.0737,  0.0984,\n         -0.0340,  0.0220,  0.0792, -0.0396,  0.0055, -0.0040, -0.0970, -0.0033,\n          0.0750, -0.0560,  0.0702,  0.0366,  0.0070, -0.0706,  0.0500,  0.0267,\n          0.0794, -0.0381,  0.0375, -0.0733, -0.0216,  0.0781,  0.0659,  0.0556,\n         -0.0589, -0.0095, -0.0702,  0.0075, -0.0408, -0.0401,  0.0139,  0.0120,\n         -0.0121, -0.0874,  0.0408, -0.0566],\n        [-0.0231,  0.0066,  0.0431, -0.0992,  0.0760,  0.0580, -0.0749,  0.0261,\n         -0.0969,  0.0662,  0.0295, -0.0342,  0.0492,  0.0859, -0.0341,  0.0335,\n          0.0206, -0.0229,  0.0624, -0.0645, -0.0473, -0.0787, -0.0278,  0.0023,\n          0.0685,  0.0724, -0.0111,  0.0212, -0.0600, -0.0896, -0.0163,  0.0879,\n         -0.0997,  0.0646, -0.0099,  0.0338,  0.0855,  0.0420, -0.0290, -0.0711,\n          0.0249,  0.0674,  0.0440,  0.0945, -0.0033,  0.0618,  0.0203,  0.0009,\n          0.0049,  0.1000,  0.0186,  0.0170,  0.0762, -0.0041,  0.0803, -0.0389,\n          0.0077,  0.0050,  0.0689,  0.0418,  0.0428,  0.0659,  0.0240, -0.0794,\n         -0.0824, -0.0713,  0.0878,  0.0421, -0.0193, -0.0457,  0.0194,  0.0524,\n         -0.0496,  0.0412,  0.0729, -0.0551, -0.0718, -0.0269,  0.0482, -0.0376,\n          0.0178, -0.0873,  0.0970,  0.0449, -0.0453,  0.0174, -0.0996, -0.0090,\n          0.0594,  0.0939,  0.0911, -0.0894, -0.0152,  0.0010,  0.0541,  0.0925,\n         -0.0561, -0.0373,  0.0099,  0.0081],\n        [-0.0586, -0.0999,  0.0577, -0.0309,  0.0008, -0.0322,  0.0549,  0.0230,\n         -0.0091,  0.0106,  0.0262,  0.0120,  0.0699, -0.0858,  0.0295, -0.0454,\n          0.0825, -0.0032, -0.0689, -0.0171,  0.0081,  0.0189,  0.0941, -0.0882,\n         -0.0300,  0.0567, -0.0767, -0.0746, -0.0260, -0.0210, -0.0221,  0.0532,\n         -0.0340,  0.0879,  0.0005,  0.0168,  0.0961,  0.0219,  0.0684,  0.0743,\n          0.0222,  0.0041, -0.0548, -0.0890, -0.0570,  0.0119,  0.0484, -0.0959,\n          0.0772, -0.0499,  0.0983,  0.0754,  0.0596, -0.0735,  0.0102, -0.0813,\n          0.0781, -0.0618, -0.0174,  0.0220, -0.0124,  0.0047, -0.0662,  0.0537,\n         -0.0328, -0.0017, -0.0488,  0.0245, -0.0696, -0.0865,  0.0835, -0.0665,\n         -0.0473, -0.0644,  0.0114, -0.0266, -0.0139,  0.0454,  0.0203, -0.0642,\n         -0.0702, -0.0832, -0.0481,  0.0470, -0.0899,  0.0724, -0.0104,  0.0292,\n          0.0886, -0.0575, -0.0768,  0.0551,  0.0474,  0.0228, -0.0665,  0.0482,\n         -0.0935,  0.0984,  0.0360,  0.0697],\n        [ 0.0361, -0.0559, -0.0301, -0.0410, -0.0054, -0.0649,  0.0608, -0.0982,\n         -0.0491,  0.0787, -0.0370,  0.0649, -0.0719, -0.0340, -0.0933,  0.0679,\n         -0.0932,  0.0243,  0.0322,  0.0712,  0.0860, -0.0372, -0.0848,  0.0813,\n          0.0295,  0.0285, -0.0814,  0.0456, -0.0375, -0.0231, -0.0511,  0.0027,\n          0.0104,  0.0642, -0.0426,  0.0552, -0.0803, -0.0675,  0.0532,  0.0450,\n         -0.0235, -0.0838,  0.0847,  0.0624,  0.0248, -0.0280,  0.0329, -0.0230,\n          0.0287, -0.0962,  0.0800,  0.0181, -0.0194, -0.0039, -0.0067, -0.0857,\n          0.0851,  0.0615,  0.0360, -0.0863,  0.0399, -0.0525, -0.0342,  0.0533,\n         -0.0848, -0.0575,  0.0954, -0.0510,  0.0180,  0.0876, -0.0680,  0.0406,\n         -0.0354, -0.0751, -0.0177,  0.0911, -0.0392,  0.0235, -0.0824, -0.0151,\n         -0.0086, -0.0576, -0.0709, -0.0840,  0.0053,  0.0563,  0.0707, -0.0388,\n         -0.0347, -0.0640,  0.0579, -0.0112, -0.0981,  0.0242, -0.0699, -0.0999,\n          0.0783, -0.0276,  0.0933,  0.0042],\n        [-0.0192,  0.0122,  0.0343, -0.0359, -0.0279,  0.0487, -0.0907,  0.0304,\n          0.0156,  0.0916, -0.0209,  0.0613, -0.0308, -0.0980, -0.0444,  0.0172,\n          0.0020,  0.0546, -0.0612, -0.0086,  0.0759,  0.0094,  0.0538, -0.0711,\n         -0.0286, -0.0389,  0.0195, -0.0536, -0.0046, -0.0174, -0.0945,  0.0451,\n         -0.0358,  0.0771, -0.0929,  0.0973,  0.0525,  0.0907, -0.0621,  0.0037,\n         -0.0730, -0.0732,  0.0435,  0.0083,  0.0248, -0.0803,  0.0957, -0.0505,\n          0.0180,  0.0656,  0.0665, -0.0988,  0.0370, -0.0232, -0.0275,  0.0956,\n         -0.0253,  0.0310,  0.0606, -0.0522, -0.0356, -0.0447,  0.0100, -0.0309,\n         -0.0923, -0.0614,  0.0962, -0.0647,  0.0924, -0.0096,  0.0180,  0.0405,\n          0.0757,  0.0722, -0.0419,  0.0474,  0.0092,  0.0256,  0.0317, -0.0347,\n          0.0685, -0.0720, -0.0458,  0.0833,  0.0459, -0.0018, -0.0104, -0.0324,\n         -0.0944, -0.0600,  0.0230, -0.0684,  0.0305,  0.0907, -0.0845,  0.0540,\n         -0.0271,  0.0609,  0.0095, -0.0526],\n        [ 0.0960, -0.0310,  0.0741, -0.0661,  0.0168,  0.0570,  0.0224,  0.0405,\n         -0.0889, -0.0801, -0.0260,  0.0474, -0.0820,  0.0393,  0.0648,  0.0410,\n          0.0957, -0.0237,  0.0313,  0.0629,  0.0141, -0.0116,  0.0646, -0.0563,\n         -0.0744, -0.0033, -0.0238, -0.0969, -0.0147,  0.0564, -0.0162,  0.0634,\n         -0.0367,  0.0770, -0.0459, -0.0360,  0.0714,  0.0275, -0.0190, -0.0283,\n          0.0291, -0.0421,  0.0688,  0.0580,  0.0068,  0.0607, -0.0883, -0.0698,\n          0.0662,  0.0846, -0.0536,  0.0552, -0.0498, -0.0466,  0.0358,  0.0956,\n          0.0864,  0.0112,  0.0450,  0.0238,  0.0166, -0.0328, -0.0681,  0.0218,\n         -0.0879, -0.0669, -0.0247, -0.0838,  0.0732, -0.0380,  0.0961, -0.0437,\n         -0.0086, -0.0742, -0.0691,  0.0440, -0.0996, -0.0062,  0.0277,  0.0673,\n          0.0142, -0.0173,  0.0544, -0.0790, -0.0347,  0.0567,  0.0436, -0.0976,\n          0.0219, -0.0179, -0.0546,  0.0395,  0.0317,  0.0243,  0.0567, -0.0094,\n          0.0556, -0.0851,  0.0545, -0.0691],\n        [ 0.0773,  0.0343, -0.0145,  0.0548, -0.0743,  0.0942, -0.0603, -0.0310,\n         -0.0783,  0.0233,  0.0396,  0.0139, -0.0955,  0.0077, -0.0660, -0.0231,\n          0.0391, -0.0282, -0.0831,  0.0006, -0.0672, -0.0937,  0.0232, -0.0962,\n         -0.0024, -0.0049, -0.0140,  0.0720,  0.0271, -0.0431, -0.0452,  0.0837,\n          0.0186, -0.0575,  0.0204,  0.0760, -0.0832,  0.0019,  0.0542, -0.0884,\n          0.0503, -0.0662, -0.0104, -0.0010, -0.0965,  0.0228,  0.0014, -0.0200,\n         -0.0014, -0.0505, -0.0844, -0.0560, -0.0954, -0.0808,  0.0144,  0.0883,\n          0.0437, -0.0296,  0.0947, -0.0591,  0.0517, -0.0740, -0.0763, -0.0064,\n         -0.0717, -0.0186,  0.0343, -0.0961,  0.0364,  0.0299,  0.0190,  0.0547,\n          0.0972, -0.0410,  0.0638, -0.0174, -0.0656, -0.0992,  0.0687,  0.0980,\n         -0.0212,  0.0994, -0.0281, -0.0063,  0.0574, -0.0671, -0.0768,  0.0906,\n         -0.0488, -0.0076, -0.0543, -0.0059, -0.0111, -0.0190, -0.0406,  0.0962,\n         -0.0914,  0.0618,  0.0063, -0.0045],\n        [-0.0027,  0.0075,  0.0269, -0.0191, -0.0402, -0.0627,  0.0002,  0.0730,\n         -0.0569, -0.0778, -0.0253, -0.0063,  0.0061, -0.0495, -0.0679, -0.0624,\n         -0.0125, -0.0475,  0.0948, -0.0910,  0.0358,  0.0800, -0.0626, -0.0188,\n          0.0504,  0.0717, -0.0143,  0.0183, -0.0098, -0.0296, -0.0775,  0.0937,\n          0.0602,  0.0792, -0.0290, -0.0849,  0.0121,  0.0681,  0.0570,  0.0048,\n         -0.0698,  0.0721,  0.0951, -0.0075, -0.0930, -0.0066,  0.0483, -0.0995,\n          0.0635, -0.0494, -0.0492,  0.0046,  0.0844,  0.0193, -0.0313, -0.0640,\n          0.0437, -0.0585, -0.0825, -0.0446, -0.0287,  0.0637,  0.0164,  0.0711,\n         -0.0760, -0.0897,  0.0456,  0.0729, -0.0415,  0.0081,  0.0352, -0.0059,\n         -0.0505, -0.0704,  0.0188,  0.0788,  0.0084,  0.0622, -0.0378,  0.0922,\n          0.0736, -0.0927,  0.0289, -0.0554, -0.0557, -0.0011, -0.0402, -0.0142,\n          0.0864,  0.0098,  0.0058, -0.0437,  0.0449,  0.0500, -0.0004,  0.0245,\n         -0.0074,  0.0310,  0.0938,  0.0122]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0479, -0.1544,  0.1857,  0.0056], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0469, -0.2518, -0.1288,  0.0693, -0.0229, -0.0514, -0.2109, -0.0811],\n        [ 0.0509,  0.0587, -0.2415, -0.3204,  0.0385,  0.1452, -0.1165,  0.0413],\n        [-0.0482,  0.2954,  0.0440, -0.1367,  0.1361, -0.0963,  0.3189, -0.0185],\n        [-0.2163, -0.0436,  0.2366,  0.3511,  0.3300, -0.0694, -0.0844, -0.2165]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 2.3786e-01, -3.3695e-01, -2.7778e-01, -1.0028e-01, -2.7192e-01,\n          7.8111e-02, -2.3588e-01, -2.3396e-01],\n        [-4.6741e-02, -3.4661e-01,  2.3185e-01,  1.0339e-01,  6.0748e-02,\n          2.6564e-01,  1.6837e-01,  3.4258e-01],\n        [ 9.9601e-02,  1.4438e-01, -1.4036e-01,  9.2234e-02,  3.4580e-01,\n         -3.2772e-01, -3.3541e-01,  3.4030e-01],\n        [ 1.9645e-01,  1.8846e-01, -7.0983e-02, -9.9666e-03, -2.3549e-01,\n         -9.9795e-04,  2.9722e-01,  2.4172e-01],\n        [ 2.2840e-01,  2.8326e-01,  9.9706e-03, -3.1144e-01, -1.5334e-01,\n          1.1914e-01,  1.5865e-01, -1.5677e-01],\n        [-3.9509e-02, -1.4419e-01, -3.1681e-01,  9.3343e-02,  2.4650e-01,\n         -9.1356e-02,  1.9849e-02,  8.3491e-02],\n        [ 1.1443e-01,  6.1064e-02, -1.5601e-01,  1.9405e-02, -2.1911e-01,\n         -3.4978e-01,  1.2606e-01,  4.7999e-02],\n        [-3.0928e-01, -1.9328e-02, -8.4979e-02, -1.3256e-01,  1.3040e-01,\n          1.4391e-01,  2.8407e-01,  2.9739e-01],\n        [-3.4703e-01,  1.8555e-01, -2.4799e-01, -3.4244e-01, -1.2404e-01,\n         -6.0348e-02, -4.0491e-02,  3.1593e-01],\n        [ 4.7068e-02,  4.4928e-02,  2.1831e-01,  2.8646e-02,  1.2432e-01,\n         -1.4307e-01,  2.7172e-01, -8.7019e-02],\n        [-2.1682e-01, -7.3447e-02, -1.2332e-01,  1.4846e-01,  2.5999e-01,\n         -2.6813e-01, -1.5752e-01,  1.4771e-02],\n        [ 7.8016e-03, -2.3520e-01, -1.7066e-01,  3.3084e-01,  1.3401e-01,\n          2.7733e-01,  2.9895e-01, -1.4923e-01],\n        [-2.0286e-02, -2.8510e-01,  1.4618e-01, -2.9582e-01,  7.1923e-02,\n         -2.0751e-01,  1.1727e-01, -2.5925e-03],\n        [-3.3882e-01,  1.8057e-01,  3.2200e-01, -2.3994e-01, -1.2066e-01,\n          9.8882e-02,  3.0184e-01,  1.8843e-02],\n        [ 2.8447e-01,  1.8083e-02, -2.8121e-01,  1.7715e-01,  2.8377e-01,\n         -2.5305e-02,  4.8627e-02,  3.3687e-01],\n        [-8.8414e-02, -6.2196e-02, -2.8319e-01,  1.4241e-01, -2.3635e-01,\n          2.7149e-01, -3.1306e-01, -1.7346e-01],\n        [-3.1262e-01, -8.8543e-02,  4.8247e-02,  3.2345e-01, -2.6980e-01,\n          8.2512e-02,  1.9017e-01,  1.0449e-01],\n        [ 3.7943e-02, -1.0788e-01,  1.9062e-01,  2.5789e-01,  1.8441e-01,\n         -2.5654e-01, -3.2171e-01, -1.5282e-01],\n        [ 2.2928e-01,  2.5113e-01, -4.9448e-03,  2.2661e-01, -2.1058e-01,\n          1.4161e-01, -1.8508e-01,  2.1893e-01],\n        [-1.8252e-01, -4.1640e-02,  1.5845e-01,  2.3472e-01,  2.3106e-01,\n         -1.6581e-01,  6.4021e-02,  3.0600e-01],\n        [ 1.7575e-01,  2.1697e-01, -1.9469e-02,  1.7415e-01, -1.1850e-01,\n          1.4896e-01, -1.8818e-01,  3.3762e-01],\n        [-1.2795e-01, -1.7977e-01,  2.7968e-02,  2.1176e-01,  1.6351e-01,\n          1.6986e-01,  2.3131e-01, -2.5931e-01],\n        [-2.6499e-01, -4.0348e-02, -1.7272e-01, -3.0050e-01,  2.9789e-02,\n          2.1936e-01,  3.2064e-01,  2.0769e-01],\n        [ 7.9467e-02,  5.7345e-02,  1.6588e-01,  2.6117e-01,  2.7902e-01,\n          2.1390e-01, -1.6702e-01,  2.5091e-01],\n        [ 1.7969e-01, -2.0289e-01, -1.0799e-01, -1.2783e-01,  1.3008e-01,\n         -3.0817e-01, -1.7849e-01, -4.3477e-02],\n        [ 4.7696e-02, -3.1173e-01,  2.1207e-02, -2.4156e-01, -1.6762e-01,\n         -2.2644e-01,  7.6835e-02, -1.0709e-01],\n        [-7.0818e-02, -1.5372e-01,  2.4466e-01, -1.3022e-01,  2.1637e-01,\n          5.2210e-02, -2.0017e-01,  3.1267e-01],\n        [ 2.9155e-01,  1.3962e-01,  1.4653e-02,  4.6931e-03,  2.9417e-01,\n         -1.2964e-01,  2.8640e-01, -3.2754e-01],\n        [ 4.6483e-02,  1.9630e-01,  1.4409e-01,  1.0371e-01, -2.7270e-02,\n          3.3638e-02, -2.5158e-01,  1.3687e-01],\n        [ 3.1447e-01,  1.0372e-02, -8.5108e-02, -7.0669e-02,  2.6695e-01,\n          3.0441e-01,  2.0243e-01, -1.8007e-01],\n        [-1.2707e-01,  1.7096e-01,  5.2685e-02,  1.5898e-01,  1.8835e-01,\n          1.6306e-02, -3.5205e-01,  3.2814e-01],\n        [-2.8695e-02,  2.7322e-01,  3.0740e-01,  2.3510e-01,  6.6250e-02,\n          2.7725e-01,  2.3786e-01, -1.5365e-01],\n        [ 6.4055e-02, -2.1371e-01,  2.0939e-01, -1.8621e-02,  1.3681e-01,\n         -1.5099e-01, -1.6635e-01,  5.1625e-02],\n        [-3.4582e-01, -3.2455e-01,  1.3815e-01, -1.1118e-01,  8.4828e-02,\n          1.4488e-01, -2.1748e-01,  2.6668e-01],\n        [ 2.4892e-01, -1.7033e-02, -3.0584e-01, -2.7905e-01, -7.9689e-02,\n         -3.2328e-01,  2.2072e-01,  1.5311e-01],\n        [ 3.4001e-01,  2.6740e-01, -1.9334e-02, -8.7751e-02,  1.5607e-02,\n         -3.5299e-01,  2.6019e-01, -1.4504e-01],\n        [-8.9488e-02, -1.2198e-01,  1.1245e-01,  2.9139e-01, -1.2227e-01,\n         -3.0102e-01, -2.6509e-01, -2.8978e-01],\n        [-2.4283e-02, -6.8732e-02, -2.2441e-01, -1.0371e-01, -4.9223e-02,\n         -2.4676e-01,  6.5827e-02,  2.9504e-01],\n        [ 1.3585e-01, -2.9189e-01, -2.4316e-01, -9.9854e-02,  3.2229e-01,\n          5.6628e-02, -1.1114e-01,  2.1478e-01],\n        [ 8.9542e-02,  8.1477e-02,  1.3597e-01, -1.1872e-01,  3.0087e-01,\n          8.5292e-02, -3.3272e-01,  3.1617e-01],\n        [ 2.1978e-01,  1.2672e-01,  2.0938e-01,  1.9321e-01,  1.3548e-01,\n         -1.8912e-02,  2.9385e-01, -3.2620e-01],\n        [ 2.8557e-01, -4.2502e-02,  2.5404e-01,  1.6470e-01,  2.0931e-01,\n         -9.7700e-02,  2.4118e-01,  1.7433e-02],\n        [-2.6244e-01, -3.2662e-01, -2.5077e-01, -2.0759e-01,  1.8653e-01,\n         -3.4805e-01, -2.2947e-01,  1.0288e-01],\n        [ 1.7091e-01, -1.4558e-01, -1.2939e-01, -2.5124e-01,  5.4807e-03,\n         -3.0915e-01, -2.6641e-01,  1.4327e-01],\n        [ 6.8167e-02, -6.9519e-02, -2.4645e-01,  6.3859e-02, -2.0050e-01,\n          2.6715e-01,  2.4432e-01, -1.2337e-01],\n        [ 2.8281e-02,  2.3866e-02, -1.1658e-01,  2.2026e-01, -3.2112e-01,\n          1.1200e-01, -1.4003e-01, -1.4142e-02],\n        [-3.0210e-01, -1.4745e-01,  2.0858e-01, -2.3725e-01, -3.3768e-01,\n         -1.6075e-02,  8.7266e-02, -5.2643e-02],\n        [-2.1517e-01,  3.2023e-03, -1.4522e-01, -2.7214e-01,  2.2969e-01,\n          2.3851e-01, -2.3360e-01, -1.3335e-02],\n        [-9.0879e-02, -1.7921e-01, -1.7319e-01, -3.3473e-01,  7.3486e-02,\n          2.7444e-01,  1.4605e-01,  5.9907e-02],\n        [ 2.5930e-01, -3.3681e-01, -1.6697e-01,  1.0466e-01, -2.3346e-01,\n         -1.2416e-01,  3.5148e-01, -5.8547e-02],\n        [-2.4134e-03,  2.5862e-01,  1.9671e-02, -5.1762e-02,  1.9661e-01,\n         -3.3747e-01, -1.2906e-01,  3.2316e-01],\n        [-2.3357e-01, -1.5898e-01,  2.6603e-01,  1.6335e-01,  1.3384e-01,\n         -3.8961e-02, -5.0409e-02,  3.2988e-01],\n        [ 3.3015e-01, -2.1142e-01, -4.7153e-02, -2.4265e-01, -3.1149e-01,\n         -1.8226e-01,  3.1766e-01,  1.7969e-01],\n        [ 1.7471e-01, -1.0126e-02,  2.7644e-01,  1.1456e-02, -2.7981e-01,\n         -3.0570e-01,  2.7298e-01, -9.7109e-02],\n        [-2.3782e-01, -3.8177e-02,  6.9532e-02, -7.4362e-02,  2.4714e-01,\n         -5.0828e-02, -4.4460e-02,  1.9064e-01],\n        [-3.0242e-01,  2.2942e-01,  3.1918e-01, -5.1243e-02,  6.7436e-02,\n          3.4033e-01, -1.8452e-01,  4.9645e-02],\n        [-2.5258e-01, -3.1106e-01, -1.7916e-01,  1.7840e-01, -1.5664e-01,\n          1.0591e-01,  2.5946e-01, -1.9740e-01],\n        [ 1.0024e-01, -1.8763e-01, -2.7769e-01,  8.2441e-02,  1.8279e-01,\n          2.0343e-01,  2.6125e-01, -8.2968e-02],\n        [ 1.1980e-01, -2.6305e-01,  3.1886e-01, -2.1037e-01, -2.0454e-01,\n         -4.1857e-02, -1.7366e-01, -1.7799e-01],\n        [ 9.6042e-02, -2.3371e-01,  3.4815e-01, -4.9281e-02, -1.7081e-01,\n         -8.4994e-02,  8.2886e-03,  3.2892e-01],\n        [-1.5266e-01, -1.2127e-01,  3.3034e-01, -8.9182e-02,  3.4762e-01,\n          2.0993e-01,  1.8116e-01,  3.3125e-01],\n        [ 1.7061e-01, -1.1098e-01, -2.9474e-01, -1.1744e-01,  1.2745e-01,\n         -1.0925e-01, -1.7369e-01,  2.2886e-01],\n        [ 1.2205e-01, -4.0941e-02, -3.3259e-01, -1.0987e-01,  2.2759e-01,\n         -2.2319e-01,  3.3378e-01,  1.5962e-01],\n        [-2.7825e-02, -3.4669e-01, -8.5796e-02, -4.4771e-02, -1.1307e-01,\n          1.7582e-01, -1.4226e-02,  7.8595e-02],\n        [ 5.2915e-02,  2.5520e-01,  1.9859e-02,  1.2257e-01,  1.1652e-01,\n          1.8239e-01,  3.1370e-01, -4.5203e-02],\n        [-1.8345e-02,  1.2266e-01,  2.5254e-02, -3.4097e-01,  2.6765e-02,\n         -3.4836e-01,  1.3769e-01, -2.2312e-01],\n        [-2.1198e-01, -3.3421e-01, -7.4985e-02,  3.2045e-01,  1.5236e-02,\n          1.6249e-01,  1.3583e-01,  2.6117e-01],\n        [ 2.4334e-01,  2.9339e-01,  2.8616e-02, -1.9113e-01, -2.7370e-01,\n         -3.7568e-02,  2.3645e-01, -2.2037e-01],\n        [-8.4196e-02, -8.4006e-02,  2.1142e-01,  2.0337e-02,  2.8407e-01,\n         -1.5950e-01,  6.2578e-02,  1.2583e-01],\n        [-2.8732e-01,  2.7670e-01,  2.1537e-01,  2.0037e-01, -3.5299e-01,\n          6.5216e-03,  2.4880e-01, -2.0060e-01],\n        [ 2.7610e-01,  1.9586e-01,  9.3024e-02,  9.0800e-02, -7.3087e-02,\n         -1.5568e-01, -3.1608e-01, -2.2937e-01],\n        [ 2.5154e-02,  3.0536e-01, -1.6134e-01,  2.7636e-01,  8.4979e-02,\n          2.2038e-01,  3.3786e-01,  1.4387e-01],\n        [ 6.6869e-02, -2.1107e-02,  3.0141e-01, -3.3752e-01, -2.2307e-01,\n         -3.1684e-01, -1.9170e-01,  2.8548e-01],\n        [-1.9009e-01,  2.2495e-01, -3.9379e-02, -2.3843e-01,  1.8104e-01,\n          2.3655e-01,  3.0829e-03, -1.8878e-01],\n        [-2.1718e-01, -2.2795e-01, -5.8784e-02,  2.1202e-01,  1.3064e-01,\n          2.8897e-01, -8.7638e-02, -2.6231e-01],\n        [ 1.9839e-01, -3.2495e-01,  2.2087e-01, -1.9792e-01, -4.1318e-02,\n          3.1932e-01, -2.0996e-01, -2.4648e-01],\n        [-3.5307e-02, -3.2519e-01, -1.7319e-01,  2.6106e-01,  2.3824e-01,\n          1.5808e-01,  1.0332e-01,  7.2160e-02],\n        [ 3.0812e-01, -8.3106e-02,  1.2309e-02, -1.2996e-01, -1.9696e-02,\n          4.2894e-02, -2.5714e-01, -2.6573e-01],\n        [ 9.2589e-02,  3.1839e-01, -6.4920e-02, -3.3521e-01,  1.2979e-01,\n         -1.9667e-01,  2.3998e-01, -2.9798e-01],\n        [ 1.2658e-01, -1.1226e-01,  3.1374e-01, -1.4774e-01,  5.5658e-02,\n         -3.1200e-01,  1.9662e-01, -2.2572e-01],\n        [ 1.1568e-01,  2.1073e-01, -1.5965e-01, -2.9945e-01,  7.1639e-03,\n         -7.8863e-02, -2.6835e-01,  2.5270e-01],\n        [ 4.8671e-02,  2.9545e-01,  1.8002e-01, -2.1037e-01, -1.4093e-01,\n         -2.6853e-01, -1.8383e-01, -2.7265e-02],\n        [-3.1002e-01,  8.0955e-02,  1.9546e-01,  1.9233e-01,  1.9874e-01,\n         -2.4263e-01, -1.4901e-01,  1.4545e-02],\n        [ 2.2694e-01,  5.6593e-02, -1.8848e-01,  2.4377e-01, -1.2067e-01,\n          2.8553e-01,  1.7329e-02, -2.3512e-01],\n        [ 3.3123e-01, -1.7668e-01, -1.1729e-01, -6.6331e-02,  9.8048e-02,\n         -2.0282e-01, -8.9384e-02,  1.7855e-01],\n        [ 2.1368e-01, -3.2956e-01, -1.1871e-01, -2.7600e-01, -2.4916e-01,\n          1.6322e-01, -4.0335e-05,  1.9789e-01],\n        [ 1.6431e-02, -2.6831e-01, -2.7831e-01,  5.1965e-02, -2.8655e-01,\n          1.4089e-01,  3.2879e-01,  1.3356e-01],\n        [-8.6074e-02,  3.4376e-01, -3.4195e-01, -2.1122e-01,  2.7172e-02,\n         -1.4851e-01,  3.1145e-01, -1.9075e-01],\n        [ 2.5385e-01,  2.3836e-01,  3.9671e-02, -3.4933e-01, -8.5732e-02,\n          2.7287e-01, -2.0127e-01,  5.1378e-02],\n        [ 8.4103e-02, -3.9752e-02, -1.0161e-01,  3.2114e-01,  9.3732e-02,\n         -2.9155e-01,  1.9924e-01,  3.1052e-02],\n        [-3.7782e-02, -9.9962e-02,  1.9692e-01,  3.2935e-01, -5.4906e-02,\n          1.0556e-02,  1.9056e-01, -7.4897e-02],\n        [ 1.3422e-01,  1.2778e-02, -7.6695e-02,  1.5575e-01,  2.3641e-01,\n          2.6561e-01, -3.9373e-02,  3.7005e-02],\n        [ 1.5203e-01,  5.9329e-02, -8.5491e-02, -9.8959e-02, -3.3285e-01,\n          6.8445e-02, -2.4354e-01, -1.2161e-01],\n        [ 2.4042e-02,  7.0855e-02, -3.1948e-01,  3.1939e-01,  2.1194e-01,\n         -6.8790e-02,  2.7634e-02,  2.8092e-01],\n        [ 2.3918e-01, -1.3061e-01,  1.6576e-01,  8.2420e-02, -1.0612e-01,\n         -2.0142e-01, -3.3633e-01, -3.0123e-01],\n        [ 2.0839e-01, -3.3449e-01, -3.5937e-02,  3.0386e-01,  2.3566e-01,\n         -3.0950e-01, -1.4461e-01,  8.2345e-02],\n        [-9.0809e-02, -1.1787e-01, -2.3933e-01,  5.3010e-02,  4.3382e-02,\n          1.7242e-01,  1.6622e-01,  4.0364e-02],\n        [ 1.7792e-01,  4.9864e-02,  2.9932e-01, -1.7704e-01,  2.7456e-02,\n         -1.5989e-01, -2.6077e-01, -2.9783e-01],\n        [-3.1147e-01, -1.8784e-01, -2.7498e-01, -5.1076e-02, -2.2461e-01,\n         -6.0716e-03,  3.3511e-01, -1.6788e-01],\n        [-1.8731e-01, -1.2435e-01,  1.6181e-01,  1.3929e-01,  2.4502e-01,\n          3.1036e-01,  3.1022e-01,  7.5838e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1943, -0.2137, -0.0521, -0.2283, -0.2336, -0.2970,  0.3068, -0.3452,\n         0.1296, -0.1247, -0.0823,  0.1070, -0.1221,  0.0230, -0.0923,  0.2622,\n        -0.0848,  0.2878, -0.0503,  0.2728,  0.1963, -0.1189, -0.2313, -0.2590,\n         0.0444, -0.1356, -0.2201, -0.2173,  0.0693, -0.1156,  0.1974,  0.1360,\n         0.0562,  0.2798, -0.0628,  0.0061,  0.2596, -0.0818, -0.2776, -0.0365,\n         0.2862, -0.1222,  0.0878, -0.0451,  0.0974, -0.1690,  0.2991,  0.1091,\n        -0.1573,  0.2876,  0.3116,  0.2776, -0.2497, -0.2303,  0.3118, -0.0979,\n         0.1674, -0.1404, -0.1708,  0.0979,  0.1051, -0.0820,  0.0626, -0.3345,\n        -0.2111, -0.0317, -0.1772,  0.1364,  0.1736, -0.0684, -0.0535,  0.2563,\n        -0.1508,  0.1288, -0.0223,  0.0477, -0.2311,  0.0746,  0.2858,  0.0177,\n         0.1530,  0.2106,  0.2692,  0.3086,  0.3374, -0.0139,  0.2569, -0.1987,\n         0.2864,  0.0869, -0.1487,  0.0395, -0.2468,  0.1184, -0.0337,  0.2973,\n        -0.0501,  0.2826,  0.2831, -0.1168], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0619, -0.0581, -0.0619,  ..., -0.0600,  0.0532, -0.0920],\n        [ 0.0545,  0.0953, -0.0064,  ..., -0.0363, -0.0454, -0.0432],\n        [ 0.0119,  0.0114,  0.0620,  ...,  0.0787, -0.0431, -0.0748],\n        ...,\n        [-0.0830,  0.0892,  0.0575,  ...,  0.0552,  0.0458,  0.0389],\n        [-0.0032,  0.0686, -0.0990,  ...,  0.0014, -0.0294,  0.0535],\n        [-0.0169,  0.0314,  0.0246,  ...,  0.0453, -0.0282, -0.0123]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0137, -0.0466,  0.0686, -0.0438, -0.0016, -0.0011, -0.0282, -0.0654,\n        -0.0091,  0.0107, -0.0862,  0.0454,  0.0706,  0.0959, -0.0910, -0.0061,\n        -0.0207, -0.0273,  0.0889,  0.0400, -0.0578, -0.0569, -0.0433,  0.0308,\n         0.0488, -0.0581,  0.0749, -0.0887,  0.0859,  0.0196,  0.0256,  0.0759,\n        -0.0071,  0.0840, -0.0110, -0.0598,  0.0360,  0.0521,  0.0231, -0.0734,\n        -0.0309,  0.0901,  0.0815,  0.0804,  0.0369,  0.0543,  0.0769,  0.0078,\n        -0.0519,  0.0527,  0.0698, -0.0899, -0.0351,  0.0578, -0.0413,  0.0061,\n         0.0521,  0.0482, -0.0268,  0.0698,  0.0915, -0.0730,  0.0752,  0.0012,\n        -0.0535,  0.0356,  0.0752, -0.0693, -0.0892, -0.0561, -0.0639, -0.0088,\n        -0.0722, -0.0216,  0.0563,  0.0006,  0.0680,  0.0607,  0.0569, -0.0511,\n         0.0040, -0.0925,  0.0974,  0.0260,  0.0479,  0.0742,  0.0624,  0.0078,\n        -0.0418, -0.0781,  0.0179, -0.0855, -0.0104,  0.0849,  0.0690, -0.0473,\n        -0.0803,  0.0033, -0.0961, -0.0732], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0293, -0.0535,  0.0291, -0.0801,  0.0548, -0.0134, -0.0926, -0.0694,\n         -0.0497, -0.0205,  0.0014, -0.0138,  0.0008, -0.0900, -0.0006, -0.0399,\n         -0.0849,  0.0152,  0.0011,  0.0959, -0.0080,  0.0397, -0.0397,  0.0526,\n         -0.0850,  0.0813,  0.0861,  0.0109,  0.0651,  0.0562,  0.0833, -0.0769,\n         -0.0621,  0.0158, -0.0712,  0.0418, -0.0055, -0.0982,  0.0746,  0.0227,\n         -0.0999,  0.0554,  0.0223,  0.0527, -0.0950,  0.0390, -0.0540, -0.0991,\n         -0.0248,  0.0958,  0.0205, -0.0906, -0.0312,  0.0803, -0.0033,  0.0895,\n          0.0092,  0.0118, -0.0229,  0.0415, -0.0002, -0.0133, -0.0737,  0.0984,\n         -0.0340,  0.0220,  0.0792, -0.0396,  0.0055, -0.0040, -0.0970, -0.0033,\n          0.0750, -0.0560,  0.0702,  0.0366,  0.0070, -0.0706,  0.0500,  0.0267,\n          0.0794, -0.0381,  0.0375, -0.0733, -0.0216,  0.0781,  0.0659,  0.0556,\n         -0.0589, -0.0095, -0.0702,  0.0075, -0.0408, -0.0401,  0.0139,  0.0120,\n         -0.0121, -0.0874,  0.0408, -0.0566],\n        [-0.0231,  0.0066,  0.0431, -0.0992,  0.0760,  0.0580, -0.0749,  0.0261,\n         -0.0969,  0.0662,  0.0295, -0.0342,  0.0492,  0.0859, -0.0341,  0.0335,\n          0.0206, -0.0229,  0.0624, -0.0645, -0.0473, -0.0787, -0.0278,  0.0023,\n          0.0685,  0.0724, -0.0111,  0.0212, -0.0600, -0.0896, -0.0163,  0.0879,\n         -0.0997,  0.0646, -0.0099,  0.0338,  0.0855,  0.0420, -0.0290, -0.0711,\n          0.0249,  0.0674,  0.0440,  0.0945, -0.0033,  0.0618,  0.0203,  0.0009,\n          0.0049,  0.1000,  0.0186,  0.0170,  0.0762, -0.0041,  0.0803, -0.0389,\n          0.0077,  0.0050,  0.0689,  0.0418,  0.0428,  0.0659,  0.0240, -0.0794,\n         -0.0824, -0.0713,  0.0878,  0.0421, -0.0193, -0.0457,  0.0194,  0.0524,\n         -0.0496,  0.0412,  0.0729, -0.0551, -0.0718, -0.0269,  0.0482, -0.0376,\n          0.0178, -0.0873,  0.0970,  0.0449, -0.0453,  0.0174, -0.0996, -0.0090,\n          0.0594,  0.0939,  0.0911, -0.0894, -0.0152,  0.0010,  0.0541,  0.0925,\n         -0.0561, -0.0373,  0.0099,  0.0081],\n        [-0.0586, -0.0999,  0.0577, -0.0309,  0.0008, -0.0322,  0.0549,  0.0230,\n         -0.0091,  0.0106,  0.0262,  0.0120,  0.0699, -0.0858,  0.0295, -0.0454,\n          0.0825, -0.0032, -0.0689, -0.0171,  0.0081,  0.0189,  0.0941, -0.0882,\n         -0.0300,  0.0567, -0.0767, -0.0746, -0.0260, -0.0210, -0.0221,  0.0532,\n         -0.0340,  0.0879,  0.0005,  0.0168,  0.0961,  0.0219,  0.0684,  0.0743,\n          0.0222,  0.0041, -0.0548, -0.0890, -0.0570,  0.0119,  0.0484, -0.0959,\n          0.0772, -0.0499,  0.0983,  0.0754,  0.0596, -0.0735,  0.0102, -0.0813,\n          0.0781, -0.0618, -0.0174,  0.0220, -0.0124,  0.0047, -0.0662,  0.0537,\n         -0.0328, -0.0017, -0.0488,  0.0245, -0.0696, -0.0865,  0.0835, -0.0665,\n         -0.0473, -0.0644,  0.0114, -0.0266, -0.0139,  0.0454,  0.0203, -0.0642,\n         -0.0702, -0.0832, -0.0481,  0.0470, -0.0899,  0.0724, -0.0104,  0.0292,\n          0.0886, -0.0575, -0.0768,  0.0551,  0.0474,  0.0228, -0.0665,  0.0482,\n         -0.0935,  0.0984,  0.0360,  0.0697],\n        [ 0.0361, -0.0559, -0.0301, -0.0410, -0.0054, -0.0649,  0.0608, -0.0982,\n         -0.0491,  0.0787, -0.0370,  0.0649, -0.0719, -0.0340, -0.0933,  0.0679,\n         -0.0932,  0.0243,  0.0322,  0.0712,  0.0860, -0.0372, -0.0848,  0.0813,\n          0.0295,  0.0285, -0.0814,  0.0456, -0.0375, -0.0231, -0.0511,  0.0027,\n          0.0104,  0.0642, -0.0426,  0.0552, -0.0803, -0.0675,  0.0532,  0.0450,\n         -0.0235, -0.0838,  0.0847,  0.0624,  0.0248, -0.0280,  0.0329, -0.0230,\n          0.0287, -0.0962,  0.0800,  0.0181, -0.0194, -0.0039, -0.0067, -0.0857,\n          0.0851,  0.0615,  0.0360, -0.0863,  0.0399, -0.0525, -0.0342,  0.0533,\n         -0.0848, -0.0575,  0.0954, -0.0510,  0.0180,  0.0876, -0.0680,  0.0406,\n         -0.0354, -0.0751, -0.0177,  0.0911, -0.0392,  0.0235, -0.0824, -0.0151,\n         -0.0086, -0.0576, -0.0709, -0.0840,  0.0053,  0.0563,  0.0707, -0.0388,\n         -0.0347, -0.0640,  0.0579, -0.0112, -0.0981,  0.0242, -0.0699, -0.0999,\n          0.0783, -0.0276,  0.0933,  0.0042],\n        [-0.0192,  0.0122,  0.0343, -0.0359, -0.0279,  0.0487, -0.0907,  0.0304,\n          0.0156,  0.0916, -0.0209,  0.0613, -0.0308, -0.0980, -0.0444,  0.0172,\n          0.0020,  0.0546, -0.0612, -0.0086,  0.0759,  0.0094,  0.0538, -0.0711,\n         -0.0286, -0.0389,  0.0195, -0.0536, -0.0046, -0.0174, -0.0945,  0.0451,\n         -0.0358,  0.0771, -0.0929,  0.0973,  0.0525,  0.0907, -0.0621,  0.0037,\n         -0.0730, -0.0732,  0.0435,  0.0083,  0.0248, -0.0803,  0.0957, -0.0505,\n          0.0180,  0.0656,  0.0665, -0.0988,  0.0370, -0.0232, -0.0275,  0.0956,\n         -0.0253,  0.0310,  0.0606, -0.0522, -0.0356, -0.0447,  0.0100, -0.0309,\n         -0.0923, -0.0614,  0.0962, -0.0647,  0.0924, -0.0096,  0.0180,  0.0405,\n          0.0757,  0.0722, -0.0419,  0.0474,  0.0092,  0.0256,  0.0317, -0.0347,\n          0.0685, -0.0720, -0.0458,  0.0833,  0.0459, -0.0018, -0.0104, -0.0324,\n         -0.0944, -0.0600,  0.0230, -0.0684,  0.0305,  0.0907, -0.0845,  0.0540,\n         -0.0271,  0.0609,  0.0095, -0.0526],\n        [ 0.0960, -0.0310,  0.0741, -0.0661,  0.0168,  0.0570,  0.0224,  0.0405,\n         -0.0889, -0.0801, -0.0260,  0.0474, -0.0820,  0.0393,  0.0648,  0.0410,\n          0.0957, -0.0237,  0.0313,  0.0629,  0.0141, -0.0116,  0.0646, -0.0563,\n         -0.0744, -0.0033, -0.0238, -0.0969, -0.0147,  0.0564, -0.0162,  0.0634,\n         -0.0367,  0.0770, -0.0459, -0.0360,  0.0714,  0.0275, -0.0190, -0.0283,\n          0.0291, -0.0421,  0.0688,  0.0580,  0.0068,  0.0607, -0.0883, -0.0698,\n          0.0662,  0.0846, -0.0536,  0.0552, -0.0498, -0.0466,  0.0358,  0.0956,\n          0.0864,  0.0112,  0.0450,  0.0238,  0.0166, -0.0328, -0.0681,  0.0218,\n         -0.0879, -0.0669, -0.0247, -0.0838,  0.0732, -0.0380,  0.0961, -0.0437,\n         -0.0086, -0.0742, -0.0691,  0.0440, -0.0996, -0.0062,  0.0277,  0.0673,\n          0.0142, -0.0173,  0.0544, -0.0790, -0.0347,  0.0567,  0.0436, -0.0976,\n          0.0219, -0.0179, -0.0546,  0.0395,  0.0317,  0.0243,  0.0567, -0.0094,\n          0.0556, -0.0851,  0.0545, -0.0691],\n        [ 0.0773,  0.0343, -0.0145,  0.0548, -0.0743,  0.0942, -0.0603, -0.0310,\n         -0.0783,  0.0233,  0.0396,  0.0139, -0.0955,  0.0077, -0.0660, -0.0231,\n          0.0391, -0.0282, -0.0831,  0.0006, -0.0672, -0.0937,  0.0232, -0.0962,\n         -0.0024, -0.0049, -0.0140,  0.0720,  0.0271, -0.0431, -0.0452,  0.0837,\n          0.0186, -0.0575,  0.0204,  0.0760, -0.0832,  0.0019,  0.0542, -0.0884,\n          0.0503, -0.0662, -0.0104, -0.0010, -0.0965,  0.0228,  0.0014, -0.0200,\n         -0.0014, -0.0505, -0.0844, -0.0560, -0.0954, -0.0808,  0.0144,  0.0883,\n          0.0437, -0.0296,  0.0947, -0.0591,  0.0517, -0.0740, -0.0763, -0.0064,\n         -0.0717, -0.0186,  0.0343, -0.0961,  0.0364,  0.0299,  0.0190,  0.0547,\n          0.0972, -0.0410,  0.0638, -0.0174, -0.0656, -0.0992,  0.0687,  0.0980,\n         -0.0212,  0.0994, -0.0281, -0.0063,  0.0574, -0.0671, -0.0768,  0.0906,\n         -0.0488, -0.0076, -0.0543, -0.0059, -0.0111, -0.0190, -0.0406,  0.0962,\n         -0.0914,  0.0618,  0.0063, -0.0045],\n        [-0.0027,  0.0075,  0.0269, -0.0191, -0.0402, -0.0627,  0.0002,  0.0730,\n         -0.0569, -0.0778, -0.0253, -0.0063,  0.0061, -0.0495, -0.0679, -0.0624,\n         -0.0125, -0.0475,  0.0948, -0.0910,  0.0358,  0.0800, -0.0626, -0.0188,\n          0.0504,  0.0717, -0.0143,  0.0183, -0.0098, -0.0296, -0.0775,  0.0937,\n          0.0602,  0.0792, -0.0290, -0.0849,  0.0121,  0.0681,  0.0570,  0.0048,\n         -0.0698,  0.0721,  0.0951, -0.0075, -0.0930, -0.0066,  0.0483, -0.0995,\n          0.0635, -0.0494, -0.0492,  0.0046,  0.0844,  0.0193, -0.0313, -0.0640,\n          0.0437, -0.0585, -0.0825, -0.0446, -0.0287,  0.0637,  0.0164,  0.0711,\n         -0.0760, -0.0897,  0.0456,  0.0729, -0.0415,  0.0081,  0.0352, -0.0059,\n         -0.0505, -0.0704,  0.0188,  0.0788,  0.0084,  0.0622, -0.0378,  0.0922,\n          0.0736, -0.0927,  0.0289, -0.0554, -0.0557, -0.0011, -0.0402, -0.0142,\n          0.0864,  0.0098,  0.0058, -0.0437,  0.0449,  0.0500, -0.0004,  0.0245,\n         -0.0074,  0.0310,  0.0938,  0.0122]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0025, -0.0616, -0.0824,  0.0761,  0.0857,  0.0335, -0.0240,  0.0985],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0469, -0.2518, -0.1288,  0.0693, -0.0229, -0.0514, -0.2109, -0.0811],\n        [ 0.0509,  0.0587, -0.2415, -0.3204,  0.0385,  0.1452, -0.1165,  0.0413],\n        [-0.0482,  0.2954,  0.0440, -0.1367,  0.1361, -0.0963,  0.3189, -0.0185],\n        [-0.2163, -0.0436,  0.2366,  0.3511,  0.3300, -0.0694, -0.0844, -0.2165]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0479, -0.1544,  0.1857,  0.0056], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x74255ddf0e50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.999,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1943, -0.2137, -0.0521, -0.2283, -0.2336, -0.2970,  0.3068, -0.3452,\n         0.1296, -0.1247, -0.0823,  0.1070, -0.1221,  0.0230, -0.0923,  0.2622,\n        -0.0848,  0.2878, -0.0503,  0.2728,  0.1963, -0.1189, -0.2313, -0.2590,\n         0.0444, -0.1356, -0.2201, -0.2173,  0.0693, -0.1156,  0.1974,  0.1360,\n         0.0562,  0.2798, -0.0628,  0.0061,  0.2596, -0.0818, -0.2776, -0.0365,\n         0.2862, -0.1222,  0.0878, -0.0451,  0.0974, -0.1690,  0.2991,  0.1091,\n        -0.1573,  0.2876,  0.3116,  0.2776, -0.2497, -0.2303,  0.3118, -0.0979,\n         0.1674, -0.1404, -0.1708,  0.0979,  0.1051, -0.0820,  0.0626, -0.3345,\n        -0.2111, -0.0317, -0.1772,  0.1364,  0.1736, -0.0684, -0.0535,  0.2563,\n        -0.1508,  0.1288, -0.0223,  0.0477, -0.2311,  0.0746,  0.2858,  0.0177,\n         0.1530,  0.2106,  0.2692,  0.3086,  0.3374, -0.0139,  0.2569, -0.1987,\n         0.2864,  0.0869, -0.1487,  0.0395, -0.2468,  0.1184, -0.0337,  0.2973,\n        -0.0501,  0.2826,  0.2831, -0.1168], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 2.3786e-01, -3.3695e-01, -2.7778e-01, -1.0028e-01, -2.7192e-01,\n          7.8111e-02, -2.3588e-01, -2.3396e-01],\n        [-4.6741e-02, -3.4661e-01,  2.3185e-01,  1.0339e-01,  6.0748e-02,\n          2.6564e-01,  1.6837e-01,  3.4258e-01],\n        [ 9.9601e-02,  1.4438e-01, -1.4036e-01,  9.2234e-02,  3.4580e-01,\n         -3.2772e-01, -3.3541e-01,  3.4030e-01],\n        [ 1.9645e-01,  1.8846e-01, -7.0983e-02, -9.9666e-03, -2.3549e-01,\n         -9.9795e-04,  2.9722e-01,  2.4172e-01],\n        [ 2.2840e-01,  2.8326e-01,  9.9706e-03, -3.1144e-01, -1.5334e-01,\n          1.1914e-01,  1.5865e-01, -1.5677e-01],\n        [-3.9509e-02, -1.4419e-01, -3.1681e-01,  9.3343e-02,  2.4650e-01,\n         -9.1356e-02,  1.9849e-02,  8.3491e-02],\n        [ 1.1443e-01,  6.1064e-02, -1.5601e-01,  1.9405e-02, -2.1911e-01,\n         -3.4978e-01,  1.2606e-01,  4.7999e-02],\n        [-3.0928e-01, -1.9328e-02, -8.4979e-02, -1.3256e-01,  1.3040e-01,\n          1.4391e-01,  2.8407e-01,  2.9739e-01],\n        [-3.4703e-01,  1.8555e-01, -2.4799e-01, -3.4244e-01, -1.2404e-01,\n         -6.0348e-02, -4.0491e-02,  3.1593e-01],\n        [ 4.7068e-02,  4.4928e-02,  2.1831e-01,  2.8646e-02,  1.2432e-01,\n         -1.4307e-01,  2.7172e-01, -8.7019e-02],\n        [-2.1682e-01, -7.3447e-02, -1.2332e-01,  1.4846e-01,  2.5999e-01,\n         -2.6813e-01, -1.5752e-01,  1.4771e-02],\n        [ 7.8016e-03, -2.3520e-01, -1.7066e-01,  3.3084e-01,  1.3401e-01,\n          2.7733e-01,  2.9895e-01, -1.4923e-01],\n        [-2.0286e-02, -2.8510e-01,  1.4618e-01, -2.9582e-01,  7.1923e-02,\n         -2.0751e-01,  1.1727e-01, -2.5925e-03],\n        [-3.3882e-01,  1.8057e-01,  3.2200e-01, -2.3994e-01, -1.2066e-01,\n          9.8882e-02,  3.0184e-01,  1.8843e-02],\n        [ 2.8447e-01,  1.8083e-02, -2.8121e-01,  1.7715e-01,  2.8377e-01,\n         -2.5305e-02,  4.8627e-02,  3.3687e-01],\n        [-8.8414e-02, -6.2196e-02, -2.8319e-01,  1.4241e-01, -2.3635e-01,\n          2.7149e-01, -3.1306e-01, -1.7346e-01],\n        [-3.1262e-01, -8.8543e-02,  4.8247e-02,  3.2345e-01, -2.6980e-01,\n          8.2512e-02,  1.9017e-01,  1.0449e-01],\n        [ 3.7943e-02, -1.0788e-01,  1.9062e-01,  2.5789e-01,  1.8441e-01,\n         -2.5654e-01, -3.2171e-01, -1.5282e-01],\n        [ 2.2928e-01,  2.5113e-01, -4.9448e-03,  2.2661e-01, -2.1058e-01,\n          1.4161e-01, -1.8508e-01,  2.1893e-01],\n        [-1.8252e-01, -4.1640e-02,  1.5845e-01,  2.3472e-01,  2.3106e-01,\n         -1.6581e-01,  6.4021e-02,  3.0600e-01],\n        [ 1.7575e-01,  2.1697e-01, -1.9469e-02,  1.7415e-01, -1.1850e-01,\n          1.4896e-01, -1.8818e-01,  3.3762e-01],\n        [-1.2795e-01, -1.7977e-01,  2.7968e-02,  2.1176e-01,  1.6351e-01,\n          1.6986e-01,  2.3131e-01, -2.5931e-01],\n        [-2.6499e-01, -4.0348e-02, -1.7272e-01, -3.0050e-01,  2.9789e-02,\n          2.1936e-01,  3.2064e-01,  2.0769e-01],\n        [ 7.9467e-02,  5.7345e-02,  1.6588e-01,  2.6117e-01,  2.7902e-01,\n          2.1390e-01, -1.6702e-01,  2.5091e-01],\n        [ 1.7969e-01, -2.0289e-01, -1.0799e-01, -1.2783e-01,  1.3008e-01,\n         -3.0817e-01, -1.7849e-01, -4.3477e-02],\n        [ 4.7696e-02, -3.1173e-01,  2.1207e-02, -2.4156e-01, -1.6762e-01,\n         -2.2644e-01,  7.6835e-02, -1.0709e-01],\n        [-7.0818e-02, -1.5372e-01,  2.4466e-01, -1.3022e-01,  2.1637e-01,\n          5.2210e-02, -2.0017e-01,  3.1267e-01],\n        [ 2.9155e-01,  1.3962e-01,  1.4653e-02,  4.6931e-03,  2.9417e-01,\n         -1.2964e-01,  2.8640e-01, -3.2754e-01],\n        [ 4.6483e-02,  1.9630e-01,  1.4409e-01,  1.0371e-01, -2.7270e-02,\n          3.3638e-02, -2.5158e-01,  1.3687e-01],\n        [ 3.1447e-01,  1.0372e-02, -8.5108e-02, -7.0669e-02,  2.6695e-01,\n          3.0441e-01,  2.0243e-01, -1.8007e-01],\n        [-1.2707e-01,  1.7096e-01,  5.2685e-02,  1.5898e-01,  1.8835e-01,\n          1.6306e-02, -3.5205e-01,  3.2814e-01],\n        [-2.8695e-02,  2.7322e-01,  3.0740e-01,  2.3510e-01,  6.6250e-02,\n          2.7725e-01,  2.3786e-01, -1.5365e-01],\n        [ 6.4055e-02, -2.1371e-01,  2.0939e-01, -1.8621e-02,  1.3681e-01,\n         -1.5099e-01, -1.6635e-01,  5.1625e-02],\n        [-3.4582e-01, -3.2455e-01,  1.3815e-01, -1.1118e-01,  8.4828e-02,\n          1.4488e-01, -2.1748e-01,  2.6668e-01],\n        [ 2.4892e-01, -1.7033e-02, -3.0584e-01, -2.7905e-01, -7.9689e-02,\n         -3.2328e-01,  2.2072e-01,  1.5311e-01],\n        [ 3.4001e-01,  2.6740e-01, -1.9334e-02, -8.7751e-02,  1.5607e-02,\n         -3.5299e-01,  2.6019e-01, -1.4504e-01],\n        [-8.9488e-02, -1.2198e-01,  1.1245e-01,  2.9139e-01, -1.2227e-01,\n         -3.0102e-01, -2.6509e-01, -2.8978e-01],\n        [-2.4283e-02, -6.8732e-02, -2.2441e-01, -1.0371e-01, -4.9223e-02,\n         -2.4676e-01,  6.5827e-02,  2.9504e-01],\n        [ 1.3585e-01, -2.9189e-01, -2.4316e-01, -9.9854e-02,  3.2229e-01,\n          5.6628e-02, -1.1114e-01,  2.1478e-01],\n        [ 8.9542e-02,  8.1477e-02,  1.3597e-01, -1.1872e-01,  3.0087e-01,\n          8.5292e-02, -3.3272e-01,  3.1617e-01],\n        [ 2.1978e-01,  1.2672e-01,  2.0938e-01,  1.9321e-01,  1.3548e-01,\n         -1.8912e-02,  2.9385e-01, -3.2620e-01],\n        [ 2.8557e-01, -4.2502e-02,  2.5404e-01,  1.6470e-01,  2.0931e-01,\n         -9.7700e-02,  2.4118e-01,  1.7433e-02],\n        [-2.6244e-01, -3.2662e-01, -2.5077e-01, -2.0759e-01,  1.8653e-01,\n         -3.4805e-01, -2.2947e-01,  1.0288e-01],\n        [ 1.7091e-01, -1.4558e-01, -1.2939e-01, -2.5124e-01,  5.4807e-03,\n         -3.0915e-01, -2.6641e-01,  1.4327e-01],\n        [ 6.8167e-02, -6.9519e-02, -2.4645e-01,  6.3859e-02, -2.0050e-01,\n          2.6715e-01,  2.4432e-01, -1.2337e-01],\n        [ 2.8281e-02,  2.3866e-02, -1.1658e-01,  2.2026e-01, -3.2112e-01,\n          1.1200e-01, -1.4003e-01, -1.4142e-02],\n        [-3.0210e-01, -1.4745e-01,  2.0858e-01, -2.3725e-01, -3.3768e-01,\n         -1.6075e-02,  8.7266e-02, -5.2643e-02],\n        [-2.1517e-01,  3.2023e-03, -1.4522e-01, -2.7214e-01,  2.2969e-01,\n          2.3851e-01, -2.3360e-01, -1.3335e-02],\n        [-9.0879e-02, -1.7921e-01, -1.7319e-01, -3.3473e-01,  7.3486e-02,\n          2.7444e-01,  1.4605e-01,  5.9907e-02],\n        [ 2.5930e-01, -3.3681e-01, -1.6697e-01,  1.0466e-01, -2.3346e-01,\n         -1.2416e-01,  3.5148e-01, -5.8547e-02],\n        [-2.4134e-03,  2.5862e-01,  1.9671e-02, -5.1762e-02,  1.9661e-01,\n         -3.3747e-01, -1.2906e-01,  3.2316e-01],\n        [-2.3357e-01, -1.5898e-01,  2.6603e-01,  1.6335e-01,  1.3384e-01,\n         -3.8961e-02, -5.0409e-02,  3.2988e-01],\n        [ 3.3015e-01, -2.1142e-01, -4.7153e-02, -2.4265e-01, -3.1149e-01,\n         -1.8226e-01,  3.1766e-01,  1.7969e-01],\n        [ 1.7471e-01, -1.0126e-02,  2.7644e-01,  1.1456e-02, -2.7981e-01,\n         -3.0570e-01,  2.7298e-01, -9.7109e-02],\n        [-2.3782e-01, -3.8177e-02,  6.9532e-02, -7.4362e-02,  2.4714e-01,\n         -5.0828e-02, -4.4460e-02,  1.9064e-01],\n        [-3.0242e-01,  2.2942e-01,  3.1918e-01, -5.1243e-02,  6.7436e-02,\n          3.4033e-01, -1.8452e-01,  4.9645e-02],\n        [-2.5258e-01, -3.1106e-01, -1.7916e-01,  1.7840e-01, -1.5664e-01,\n          1.0591e-01,  2.5946e-01, -1.9740e-01],\n        [ 1.0024e-01, -1.8763e-01, -2.7769e-01,  8.2441e-02,  1.8279e-01,\n          2.0343e-01,  2.6125e-01, -8.2968e-02],\n        [ 1.1980e-01, -2.6305e-01,  3.1886e-01, -2.1037e-01, -2.0454e-01,\n         -4.1857e-02, -1.7366e-01, -1.7799e-01],\n        [ 9.6042e-02, -2.3371e-01,  3.4815e-01, -4.9281e-02, -1.7081e-01,\n         -8.4994e-02,  8.2886e-03,  3.2892e-01],\n        [-1.5266e-01, -1.2127e-01,  3.3034e-01, -8.9182e-02,  3.4762e-01,\n          2.0993e-01,  1.8116e-01,  3.3125e-01],\n        [ 1.7061e-01, -1.1098e-01, -2.9474e-01, -1.1744e-01,  1.2745e-01,\n         -1.0925e-01, -1.7369e-01,  2.2886e-01],\n        [ 1.2205e-01, -4.0941e-02, -3.3259e-01, -1.0987e-01,  2.2759e-01,\n         -2.2319e-01,  3.3378e-01,  1.5962e-01],\n        [-2.7825e-02, -3.4669e-01, -8.5796e-02, -4.4771e-02, -1.1307e-01,\n          1.7582e-01, -1.4226e-02,  7.8595e-02],\n        [ 5.2915e-02,  2.5520e-01,  1.9859e-02,  1.2257e-01,  1.1652e-01,\n          1.8239e-01,  3.1370e-01, -4.5203e-02],\n        [-1.8345e-02,  1.2266e-01,  2.5254e-02, -3.4097e-01,  2.6765e-02,\n         -3.4836e-01,  1.3769e-01, -2.2312e-01],\n        [-2.1198e-01, -3.3421e-01, -7.4985e-02,  3.2045e-01,  1.5236e-02,\n          1.6249e-01,  1.3583e-01,  2.6117e-01],\n        [ 2.4334e-01,  2.9339e-01,  2.8616e-02, -1.9113e-01, -2.7370e-01,\n         -3.7568e-02,  2.3645e-01, -2.2037e-01],\n        [-8.4196e-02, -8.4006e-02,  2.1142e-01,  2.0337e-02,  2.8407e-01,\n         -1.5950e-01,  6.2578e-02,  1.2583e-01],\n        [-2.8732e-01,  2.7670e-01,  2.1537e-01,  2.0037e-01, -3.5299e-01,\n          6.5216e-03,  2.4880e-01, -2.0060e-01],\n        [ 2.7610e-01,  1.9586e-01,  9.3024e-02,  9.0800e-02, -7.3087e-02,\n         -1.5568e-01, -3.1608e-01, -2.2937e-01],\n        [ 2.5154e-02,  3.0536e-01, -1.6134e-01,  2.7636e-01,  8.4979e-02,\n          2.2038e-01,  3.3786e-01,  1.4387e-01],\n        [ 6.6869e-02, -2.1107e-02,  3.0141e-01, -3.3752e-01, -2.2307e-01,\n         -3.1684e-01, -1.9170e-01,  2.8548e-01],\n        [-1.9009e-01,  2.2495e-01, -3.9379e-02, -2.3843e-01,  1.8104e-01,\n          2.3655e-01,  3.0829e-03, -1.8878e-01],\n        [-2.1718e-01, -2.2795e-01, -5.8784e-02,  2.1202e-01,  1.3064e-01,\n          2.8897e-01, -8.7638e-02, -2.6231e-01],\n        [ 1.9839e-01, -3.2495e-01,  2.2087e-01, -1.9792e-01, -4.1318e-02,\n          3.1932e-01, -2.0996e-01, -2.4648e-01],\n        [-3.5307e-02, -3.2519e-01, -1.7319e-01,  2.6106e-01,  2.3824e-01,\n          1.5808e-01,  1.0332e-01,  7.2160e-02],\n        [ 3.0812e-01, -8.3106e-02,  1.2309e-02, -1.2996e-01, -1.9696e-02,\n          4.2894e-02, -2.5714e-01, -2.6573e-01],\n        [ 9.2589e-02,  3.1839e-01, -6.4920e-02, -3.3521e-01,  1.2979e-01,\n         -1.9667e-01,  2.3998e-01, -2.9798e-01],\n        [ 1.2658e-01, -1.1226e-01,  3.1374e-01, -1.4774e-01,  5.5658e-02,\n         -3.1200e-01,  1.9662e-01, -2.2572e-01],\n        [ 1.1568e-01,  2.1073e-01, -1.5965e-01, -2.9945e-01,  7.1639e-03,\n         -7.8863e-02, -2.6835e-01,  2.5270e-01],\n        [ 4.8671e-02,  2.9545e-01,  1.8002e-01, -2.1037e-01, -1.4093e-01,\n         -2.6853e-01, -1.8383e-01, -2.7265e-02],\n        [-3.1002e-01,  8.0955e-02,  1.9546e-01,  1.9233e-01,  1.9874e-01,\n         -2.4263e-01, -1.4901e-01,  1.4545e-02],\n        [ 2.2694e-01,  5.6593e-02, -1.8848e-01,  2.4377e-01, -1.2067e-01,\n          2.8553e-01,  1.7329e-02, -2.3512e-01],\n        [ 3.3123e-01, -1.7668e-01, -1.1729e-01, -6.6331e-02,  9.8048e-02,\n         -2.0282e-01, -8.9384e-02,  1.7855e-01],\n        [ 2.1368e-01, -3.2956e-01, -1.1871e-01, -2.7600e-01, -2.4916e-01,\n          1.6322e-01, -4.0335e-05,  1.9789e-01],\n        [ 1.6431e-02, -2.6831e-01, -2.7831e-01,  5.1965e-02, -2.8655e-01,\n          1.4089e-01,  3.2879e-01,  1.3356e-01],\n        [-8.6074e-02,  3.4376e-01, -3.4195e-01, -2.1122e-01,  2.7172e-02,\n         -1.4851e-01,  3.1145e-01, -1.9075e-01],\n        [ 2.5385e-01,  2.3836e-01,  3.9671e-02, -3.4933e-01, -8.5732e-02,\n          2.7287e-01, -2.0127e-01,  5.1378e-02],\n        [ 8.4103e-02, -3.9752e-02, -1.0161e-01,  3.2114e-01,  9.3732e-02,\n         -2.9155e-01,  1.9924e-01,  3.1052e-02],\n        [-3.7782e-02, -9.9962e-02,  1.9692e-01,  3.2935e-01, -5.4906e-02,\n          1.0556e-02,  1.9056e-01, -7.4897e-02],\n        [ 1.3422e-01,  1.2778e-02, -7.6695e-02,  1.5575e-01,  2.3641e-01,\n          2.6561e-01, -3.9373e-02,  3.7005e-02],\n        [ 1.5203e-01,  5.9329e-02, -8.5491e-02, -9.8959e-02, -3.3285e-01,\n          6.8445e-02, -2.4354e-01, -1.2161e-01],\n        [ 2.4042e-02,  7.0855e-02, -3.1948e-01,  3.1939e-01,  2.1194e-01,\n         -6.8790e-02,  2.7634e-02,  2.8092e-01],\n        [ 2.3918e-01, -1.3061e-01,  1.6576e-01,  8.2420e-02, -1.0612e-01,\n         -2.0142e-01, -3.3633e-01, -3.0123e-01],\n        [ 2.0839e-01, -3.3449e-01, -3.5937e-02,  3.0386e-01,  2.3566e-01,\n         -3.0950e-01, -1.4461e-01,  8.2345e-02],\n        [-9.0809e-02, -1.1787e-01, -2.3933e-01,  5.3010e-02,  4.3382e-02,\n          1.7242e-01,  1.6622e-01,  4.0364e-02],\n        [ 1.7792e-01,  4.9864e-02,  2.9932e-01, -1.7704e-01,  2.7456e-02,\n         -1.5989e-01, -2.6077e-01, -2.9783e-01],\n        [-3.1147e-01, -1.8784e-01, -2.7498e-01, -5.1076e-02, -2.2461e-01,\n         -6.0716e-03,  3.3511e-01, -1.6788e-01],\n        [-1.8731e-01, -1.2435e-01,  1.6181e-01,  1.3929e-01,  2.4502e-01,\n          3.1036e-01,  3.1022e-01,  7.5838e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0137, -0.0466,  0.0686, -0.0438, -0.0016, -0.0011, -0.0282, -0.0654,\n        -0.0091,  0.0107, -0.0862,  0.0454,  0.0706,  0.0959, -0.0910, -0.0061,\n        -0.0207, -0.0273,  0.0889,  0.0400, -0.0578, -0.0569, -0.0433,  0.0308,\n         0.0488, -0.0581,  0.0749, -0.0887,  0.0859,  0.0196,  0.0256,  0.0759,\n        -0.0071,  0.0840, -0.0110, -0.0598,  0.0360,  0.0521,  0.0231, -0.0734,\n        -0.0309,  0.0901,  0.0815,  0.0804,  0.0369,  0.0543,  0.0769,  0.0078,\n        -0.0519,  0.0527,  0.0698, -0.0899, -0.0351,  0.0578, -0.0413,  0.0061,\n         0.0521,  0.0482, -0.0268,  0.0698,  0.0915, -0.0730,  0.0752,  0.0012,\n        -0.0535,  0.0356,  0.0752, -0.0693, -0.0892, -0.0561, -0.0639, -0.0088,\n        -0.0722, -0.0216,  0.0563,  0.0006,  0.0680,  0.0607,  0.0569, -0.0511,\n         0.0040, -0.0925,  0.0974,  0.0260,  0.0479,  0.0742,  0.0624,  0.0078,\n        -0.0418, -0.0781,  0.0179, -0.0855, -0.0104,  0.0849,  0.0690, -0.0473,\n        -0.0803,  0.0033, -0.0961, -0.0732], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0619, -0.0581, -0.0619,  ..., -0.0600,  0.0532, -0.0920],\n        [ 0.0545,  0.0953, -0.0064,  ..., -0.0363, -0.0454, -0.0432],\n        [ 0.0119,  0.0114,  0.0620,  ...,  0.0787, -0.0431, -0.0748],\n        ...,\n        [-0.0830,  0.0892,  0.0575,  ...,  0.0552,  0.0458,  0.0389],\n        [-0.0032,  0.0686, -0.0990,  ...,  0.0014, -0.0294,  0.0535],\n        [-0.0169,  0.0314,  0.0246,  ...,  0.0453, -0.0282, -0.0123]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0025, -0.0616, -0.0824,  0.0761,  0.0857,  0.0335, -0.0240,  0.0985],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0293, -0.0535,  0.0291, -0.0801,  0.0548, -0.0134, -0.0926, -0.0694,\n         -0.0497, -0.0205,  0.0014, -0.0138,  0.0008, -0.0900, -0.0006, -0.0399,\n         -0.0849,  0.0152,  0.0011,  0.0959, -0.0080,  0.0397, -0.0397,  0.0526,\n         -0.0850,  0.0813,  0.0861,  0.0109,  0.0651,  0.0562,  0.0833, -0.0769,\n         -0.0621,  0.0158, -0.0712,  0.0418, -0.0055, -0.0982,  0.0746,  0.0227,\n         -0.0999,  0.0554,  0.0223,  0.0527, -0.0950,  0.0390, -0.0540, -0.0991,\n         -0.0248,  0.0958,  0.0205, -0.0906, -0.0312,  0.0803, -0.0033,  0.0895,\n          0.0092,  0.0118, -0.0229,  0.0415, -0.0002, -0.0133, -0.0737,  0.0984,\n         -0.0340,  0.0220,  0.0792, -0.0396,  0.0055, -0.0040, -0.0970, -0.0033,\n          0.0750, -0.0560,  0.0702,  0.0366,  0.0070, -0.0706,  0.0500,  0.0267,\n          0.0794, -0.0381,  0.0375, -0.0733, -0.0216,  0.0781,  0.0659,  0.0556,\n         -0.0589, -0.0095, -0.0702,  0.0075, -0.0408, -0.0401,  0.0139,  0.0120,\n         -0.0121, -0.0874,  0.0408, -0.0566],\n        [-0.0231,  0.0066,  0.0431, -0.0992,  0.0760,  0.0580, -0.0749,  0.0261,\n         -0.0969,  0.0662,  0.0295, -0.0342,  0.0492,  0.0859, -0.0341,  0.0335,\n          0.0206, -0.0229,  0.0624, -0.0645, -0.0473, -0.0787, -0.0278,  0.0023,\n          0.0685,  0.0724, -0.0111,  0.0212, -0.0600, -0.0896, -0.0163,  0.0879,\n         -0.0997,  0.0646, -0.0099,  0.0338,  0.0855,  0.0420, -0.0290, -0.0711,\n          0.0249,  0.0674,  0.0440,  0.0945, -0.0033,  0.0618,  0.0203,  0.0009,\n          0.0049,  0.1000,  0.0186,  0.0170,  0.0762, -0.0041,  0.0803, -0.0389,\n          0.0077,  0.0050,  0.0689,  0.0418,  0.0428,  0.0659,  0.0240, -0.0794,\n         -0.0824, -0.0713,  0.0878,  0.0421, -0.0193, -0.0457,  0.0194,  0.0524,\n         -0.0496,  0.0412,  0.0729, -0.0551, -0.0718, -0.0269,  0.0482, -0.0376,\n          0.0178, -0.0873,  0.0970,  0.0449, -0.0453,  0.0174, -0.0996, -0.0090,\n          0.0594,  0.0939,  0.0911, -0.0894, -0.0152,  0.0010,  0.0541,  0.0925,\n         -0.0561, -0.0373,  0.0099,  0.0081],\n        [-0.0586, -0.0999,  0.0577, -0.0309,  0.0008, -0.0322,  0.0549,  0.0230,\n         -0.0091,  0.0106,  0.0262,  0.0120,  0.0699, -0.0858,  0.0295, -0.0454,\n          0.0825, -0.0032, -0.0689, -0.0171,  0.0081,  0.0189,  0.0941, -0.0882,\n         -0.0300,  0.0567, -0.0767, -0.0746, -0.0260, -0.0210, -0.0221,  0.0532,\n         -0.0340,  0.0879,  0.0005,  0.0168,  0.0961,  0.0219,  0.0684,  0.0743,\n          0.0222,  0.0041, -0.0548, -0.0890, -0.0570,  0.0119,  0.0484, -0.0959,\n          0.0772, -0.0499,  0.0983,  0.0754,  0.0596, -0.0735,  0.0102, -0.0813,\n          0.0781, -0.0618, -0.0174,  0.0220, -0.0124,  0.0047, -0.0662,  0.0537,\n         -0.0328, -0.0017, -0.0488,  0.0245, -0.0696, -0.0865,  0.0835, -0.0665,\n         -0.0473, -0.0644,  0.0114, -0.0266, -0.0139,  0.0454,  0.0203, -0.0642,\n         -0.0702, -0.0832, -0.0481,  0.0470, -0.0899,  0.0724, -0.0104,  0.0292,\n          0.0886, -0.0575, -0.0768,  0.0551,  0.0474,  0.0228, -0.0665,  0.0482,\n         -0.0935,  0.0984,  0.0360,  0.0697],\n        [ 0.0361, -0.0559, -0.0301, -0.0410, -0.0054, -0.0649,  0.0608, -0.0982,\n         -0.0491,  0.0787, -0.0370,  0.0649, -0.0719, -0.0340, -0.0933,  0.0679,\n         -0.0932,  0.0243,  0.0322,  0.0712,  0.0860, -0.0372, -0.0848,  0.0813,\n          0.0295,  0.0285, -0.0814,  0.0456, -0.0375, -0.0231, -0.0511,  0.0027,\n          0.0104,  0.0642, -0.0426,  0.0552, -0.0803, -0.0675,  0.0532,  0.0450,\n         -0.0235, -0.0838,  0.0847,  0.0624,  0.0248, -0.0280,  0.0329, -0.0230,\n          0.0287, -0.0962,  0.0800,  0.0181, -0.0194, -0.0039, -0.0067, -0.0857,\n          0.0851,  0.0615,  0.0360, -0.0863,  0.0399, -0.0525, -0.0342,  0.0533,\n         -0.0848, -0.0575,  0.0954, -0.0510,  0.0180,  0.0876, -0.0680,  0.0406,\n         -0.0354, -0.0751, -0.0177,  0.0911, -0.0392,  0.0235, -0.0824, -0.0151,\n         -0.0086, -0.0576, -0.0709, -0.0840,  0.0053,  0.0563,  0.0707, -0.0388,\n         -0.0347, -0.0640,  0.0579, -0.0112, -0.0981,  0.0242, -0.0699, -0.0999,\n          0.0783, -0.0276,  0.0933,  0.0042],\n        [-0.0192,  0.0122,  0.0343, -0.0359, -0.0279,  0.0487, -0.0907,  0.0304,\n          0.0156,  0.0916, -0.0209,  0.0613, -0.0308, -0.0980, -0.0444,  0.0172,\n          0.0020,  0.0546, -0.0612, -0.0086,  0.0759,  0.0094,  0.0538, -0.0711,\n         -0.0286, -0.0389,  0.0195, -0.0536, -0.0046, -0.0174, -0.0945,  0.0451,\n         -0.0358,  0.0771, -0.0929,  0.0973,  0.0525,  0.0907, -0.0621,  0.0037,\n         -0.0730, -0.0732,  0.0435,  0.0083,  0.0248, -0.0803,  0.0957, -0.0505,\n          0.0180,  0.0656,  0.0665, -0.0988,  0.0370, -0.0232, -0.0275,  0.0956,\n         -0.0253,  0.0310,  0.0606, -0.0522, -0.0356, -0.0447,  0.0100, -0.0309,\n         -0.0923, -0.0614,  0.0962, -0.0647,  0.0924, -0.0096,  0.0180,  0.0405,\n          0.0757,  0.0722, -0.0419,  0.0474,  0.0092,  0.0256,  0.0317, -0.0347,\n          0.0685, -0.0720, -0.0458,  0.0833,  0.0459, -0.0018, -0.0104, -0.0324,\n         -0.0944, -0.0600,  0.0230, -0.0684,  0.0305,  0.0907, -0.0845,  0.0540,\n         -0.0271,  0.0609,  0.0095, -0.0526],\n        [ 0.0960, -0.0310,  0.0741, -0.0661,  0.0168,  0.0570,  0.0224,  0.0405,\n         -0.0889, -0.0801, -0.0260,  0.0474, -0.0820,  0.0393,  0.0648,  0.0410,\n          0.0957, -0.0237,  0.0313,  0.0629,  0.0141, -0.0116,  0.0646, -0.0563,\n         -0.0744, -0.0033, -0.0238, -0.0969, -0.0147,  0.0564, -0.0162,  0.0634,\n         -0.0367,  0.0770, -0.0459, -0.0360,  0.0714,  0.0275, -0.0190, -0.0283,\n          0.0291, -0.0421,  0.0688,  0.0580,  0.0068,  0.0607, -0.0883, -0.0698,\n          0.0662,  0.0846, -0.0536,  0.0552, -0.0498, -0.0466,  0.0358,  0.0956,\n          0.0864,  0.0112,  0.0450,  0.0238,  0.0166, -0.0328, -0.0681,  0.0218,\n         -0.0879, -0.0669, -0.0247, -0.0838,  0.0732, -0.0380,  0.0961, -0.0437,\n         -0.0086, -0.0742, -0.0691,  0.0440, -0.0996, -0.0062,  0.0277,  0.0673,\n          0.0142, -0.0173,  0.0544, -0.0790, -0.0347,  0.0567,  0.0436, -0.0976,\n          0.0219, -0.0179, -0.0546,  0.0395,  0.0317,  0.0243,  0.0567, -0.0094,\n          0.0556, -0.0851,  0.0545, -0.0691],\n        [ 0.0773,  0.0343, -0.0145,  0.0548, -0.0743,  0.0942, -0.0603, -0.0310,\n         -0.0783,  0.0233,  0.0396,  0.0139, -0.0955,  0.0077, -0.0660, -0.0231,\n          0.0391, -0.0282, -0.0831,  0.0006, -0.0672, -0.0937,  0.0232, -0.0962,\n         -0.0024, -0.0049, -0.0140,  0.0720,  0.0271, -0.0431, -0.0452,  0.0837,\n          0.0186, -0.0575,  0.0204,  0.0760, -0.0832,  0.0019,  0.0542, -0.0884,\n          0.0503, -0.0662, -0.0104, -0.0010, -0.0965,  0.0228,  0.0014, -0.0200,\n         -0.0014, -0.0505, -0.0844, -0.0560, -0.0954, -0.0808,  0.0144,  0.0883,\n          0.0437, -0.0296,  0.0947, -0.0591,  0.0517, -0.0740, -0.0763, -0.0064,\n         -0.0717, -0.0186,  0.0343, -0.0961,  0.0364,  0.0299,  0.0190,  0.0547,\n          0.0972, -0.0410,  0.0638, -0.0174, -0.0656, -0.0992,  0.0687,  0.0980,\n         -0.0212,  0.0994, -0.0281, -0.0063,  0.0574, -0.0671, -0.0768,  0.0906,\n         -0.0488, -0.0076, -0.0543, -0.0059, -0.0111, -0.0190, -0.0406,  0.0962,\n         -0.0914,  0.0618,  0.0063, -0.0045],\n        [-0.0027,  0.0075,  0.0269, -0.0191, -0.0402, -0.0627,  0.0002,  0.0730,\n         -0.0569, -0.0778, -0.0253, -0.0063,  0.0061, -0.0495, -0.0679, -0.0624,\n         -0.0125, -0.0475,  0.0948, -0.0910,  0.0358,  0.0800, -0.0626, -0.0188,\n          0.0504,  0.0717, -0.0143,  0.0183, -0.0098, -0.0296, -0.0775,  0.0937,\n          0.0602,  0.0792, -0.0290, -0.0849,  0.0121,  0.0681,  0.0570,  0.0048,\n         -0.0698,  0.0721,  0.0951, -0.0075, -0.0930, -0.0066,  0.0483, -0.0995,\n          0.0635, -0.0494, -0.0492,  0.0046,  0.0844,  0.0193, -0.0313, -0.0640,\n          0.0437, -0.0585, -0.0825, -0.0446, -0.0287,  0.0637,  0.0164,  0.0711,\n         -0.0760, -0.0897,  0.0456,  0.0729, -0.0415,  0.0081,  0.0352, -0.0059,\n         -0.0505, -0.0704,  0.0188,  0.0788,  0.0084,  0.0622, -0.0378,  0.0922,\n          0.0736, -0.0927,  0.0289, -0.0554, -0.0557, -0.0011, -0.0402, -0.0142,\n          0.0864,  0.0098,  0.0058, -0.0437,  0.0449,  0.0500, -0.0004,  0.0245,\n         -0.0074,  0.0310,  0.0938,  0.0122]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0479, -0.1544,  0.1857,  0.0056], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0469, -0.2518, -0.1288,  0.0693, -0.0229, -0.0514, -0.2109, -0.0811],\n        [ 0.0509,  0.0587, -0.2415, -0.3204,  0.0385,  0.1452, -0.1165,  0.0413],\n        [-0.0482,  0.2954,  0.0440, -0.1367,  0.1361, -0.0963,  0.3189, -0.0185],\n        [-0.2163, -0.0436,  0.2366,  0.3511,  0.3300, -0.0694, -0.0844, -0.2165]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7424da2d88d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s403410000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s403410000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}