{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.002,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.999,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s406970000"
    },
    "q_lr":	0.003,
    "seed":	406970000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x72cfc2ae6a50>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.002,
            "_epsilon_min":	0.01,
            "_gamma":	0.999,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.002,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2674, -0.1914, -0.3450, -0.2305, -0.2891,  0.1276,  0.3155, -0.2941,\n         0.1443, -0.0762,  0.2673, -0.0918,  0.1915,  0.2525,  0.0163,  0.2348,\n        -0.1313, -0.2167,  0.1248,  0.2567, -0.0709, -0.3101,  0.1968, -0.1565,\n         0.1972,  0.1577,  0.1105, -0.2734, -0.2855,  0.1158, -0.2678, -0.0871,\n         0.0903, -0.2490, -0.1881,  0.0033,  0.0809, -0.2950, -0.0256,  0.1762,\n        -0.0517, -0.0223, -0.1848, -0.2163, -0.2935,  0.2976, -0.1196, -0.1600,\n        -0.3227, -0.3395,  0.1042,  0.0076,  0.1544,  0.0064,  0.1493, -0.0854,\n        -0.0554,  0.3186,  0.1803, -0.2613,  0.3040,  0.2381, -0.1773,  0.0544,\n         0.2956,  0.0298, -0.1592, -0.2516, -0.1336,  0.1816, -0.3259, -0.2053,\n         0.2877, -0.2788,  0.0075, -0.2170,  0.3473, -0.1406,  0.0226,  0.2992,\n         0.1067,  0.1438,  0.0594, -0.3034,  0.0609,  0.2568, -0.1685,  0.2624,\n        -0.1578, -0.1486, -0.0226,  0.3153,  0.0190, -0.1009, -0.2742, -0.3365,\n         0.2210, -0.1853, -0.0124, -0.2465], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-3.4697e-01,  3.7044e-02, -1.2115e-01,  3.5075e-01, -3.0165e-01,\n         -5.0181e-02, -3.1486e-01, -7.1445e-02],\n        [-1.7023e-01,  2.0395e-02,  1.5096e-01, -5.2793e-02,  1.0288e-02,\n         -8.4125e-02,  2.9095e-01,  3.4953e-01],\n        [ 2.9611e-01,  1.7308e-01, -2.4746e-01, -9.0663e-03,  3.5308e-01,\n         -1.5451e-02, -1.0378e-01, -3.3220e-01],\n        [ 7.3217e-02,  1.7666e-01,  5.7330e-02, -1.1978e-01,  2.0175e-02,\n          2.2353e-01,  1.1763e-01,  2.5276e-01],\n        [ 9.6785e-02, -1.7273e-01,  2.6886e-01, -7.9670e-02, -2.6020e-01,\n         -2.8293e-01,  3.4171e-01,  3.1726e-01],\n        [-8.8809e-03, -3.3676e-01, -1.4238e-01,  2.5992e-01, -1.3999e-01,\n         -1.1421e-01,  3.3401e-01,  3.2127e-01],\n        [ 8.9419e-02,  2.1889e-01,  2.2993e-01,  9.3243e-02, -1.1973e-01,\n          1.1854e-01, -2.9885e-01,  1.3375e-01],\n        [ 2.6245e-01,  3.3365e-01,  1.0697e-01, -2.1563e-01, -2.5660e-01,\n          2.6082e-01, -4.1335e-02,  1.3381e-01],\n        [ 1.9653e-01,  3.9683e-02, -1.3610e-01,  5.9347e-02,  3.2795e-01,\n         -2.6775e-01, -9.2962e-02, -1.7982e-01],\n        [-2.8077e-01, -1.2343e-01, -2.4749e-01,  1.2939e-01, -6.5056e-02,\n         -8.3026e-02, -1.4209e-01, -3.3266e-01],\n        [-4.0037e-02,  6.1226e-02, -7.1620e-02, -2.3897e-02,  3.0075e-01,\n          2.1566e-01,  3.1927e-01, -5.0386e-02],\n        [ 6.6453e-02,  1.5740e-01,  6.5109e-02, -1.2474e-01,  4.1955e-02,\n         -2.8994e-01, -2.1635e-01,  2.6108e-01],\n        [ 1.8877e-01, -1.5982e-01,  1.1827e-01, -9.0328e-02, -2.2346e-01,\n         -2.9567e-02,  8.9819e-02, -4.3210e-02],\n        [-3.0383e-01,  2.2106e-01, -3.0461e-03, -3.3098e-01,  3.9086e-02,\n          2.7247e-01, -3.1299e-01,  2.0291e-01],\n        [-1.5454e-01,  2.6533e-02,  1.7153e-01, -1.6702e-01, -2.8040e-01,\n         -3.3110e-01,  1.9102e-02, -1.0429e-01],\n        [-2.2111e-01,  1.8838e-01,  1.5163e-01,  4.5974e-02, -2.7516e-01,\n          1.1762e-01, -9.8528e-02, -2.9432e-01],\n        [ 1.5902e-02, -1.5538e-01, -1.8302e-01, -6.1603e-02,  2.6117e-01,\n          1.7540e-01,  9.6014e-02, -2.7428e-02],\n        [ 4.6555e-02, -7.1814e-02,  2.1058e-01, -1.0653e-01,  1.0555e-01,\n          2.1701e-01, -2.0076e-01, -1.2482e-02],\n        [ 6.7895e-02, -2.9797e-01, -2.5280e-01,  2.6350e-01, -7.8190e-02,\n         -2.1538e-01, -1.6459e-01, -1.1273e-01],\n        [ 2.3908e-03,  3.5188e-01, -2.5317e-01,  7.0407e-03, -1.1756e-01,\n         -5.7509e-02, -2.6532e-01, -1.1697e-01],\n        [-1.5387e-01,  3.2946e-01, -2.5487e-01, -3.0401e-01, -1.9772e-01,\n         -1.4152e-01,  1.8366e-02, -1.3386e-01],\n        [ 1.3989e-01,  5.7430e-02, -6.0499e-02,  9.0147e-02,  1.3009e-01,\n         -1.2314e-01,  3.5338e-01,  3.1835e-01],\n        [-5.1420e-02, -8.1513e-02, -6.2830e-02,  1.7436e-01, -1.5588e-01,\n         -1.3453e-02, -3.2808e-01,  1.1344e-01],\n        [ 7.7083e-02,  8.1005e-02, -2.2668e-03, -3.4269e-01, -2.4155e-01,\n         -1.2811e-01, -2.4200e-01, -5.5241e-02],\n        [-2.5120e-01,  1.6607e-03,  2.2704e-01, -2.8465e-01,  3.7032e-02,\n          3.1750e-01,  3.2511e-01,  1.1702e-01],\n        [ 5.4826e-02,  2.1977e-01,  3.0609e-01, -1.9104e-01, -2.9363e-01,\n         -1.2303e-01, -3.3197e-01, -1.8040e-01],\n        [-2.9360e-01,  3.3252e-01,  3.1737e-02,  7.8009e-03,  2.7588e-01,\n          3.3468e-02,  4.2502e-02,  1.0969e-01],\n        [-1.3476e-01, -1.9893e-01, -2.9448e-01,  1.2716e-01, -7.0296e-02,\n          3.7740e-03, -9.0898e-02, -3.3451e-01],\n        [ 1.4238e-01, -6.5139e-02,  2.4963e-01, -2.8249e-01, -1.9771e-01,\n         -3.1238e-01,  3.4915e-02, -5.6821e-02],\n        [-2.0725e-01,  3.4341e-01, -3.4748e-01, -3.3188e-01,  9.4574e-02,\n          3.2233e-01,  1.3117e-01, -3.7512e-02],\n        [ 1.9425e-01, -1.1051e-01, -4.3320e-02,  6.1507e-03,  1.5577e-01,\n          2.5020e-01, -1.6512e-02,  1.8801e-01],\n        [-2.5415e-01,  1.2701e-01, -7.2332e-02,  3.0672e-01,  1.3507e-01,\n         -1.2095e-01, -1.8783e-01, -3.1069e-01],\n        [ 1.2361e-01,  2.1960e-01, -2.2625e-01, -1.1883e-02,  3.2747e-01,\n         -3.4776e-01, -2.1303e-01, -2.0980e-01],\n        [ 6.2142e-02, -3.3259e-01,  1.9323e-01,  2.5491e-01,  2.7642e-01,\n         -2.6628e-01,  1.8363e-02,  3.2084e-01],\n        [-1.2746e-01,  5.3717e-02,  2.9265e-01, -3.0026e-01, -1.1093e-01,\n         -1.8498e-01,  2.3238e-02, -1.1347e-01],\n        [-3.9494e-02,  3.5349e-01,  1.6213e-02, -2.7230e-01, -1.2595e-01,\n         -1.1406e-01,  1.5779e-01,  6.5291e-02],\n        [ 1.4848e-01,  2.8244e-01, -5.7893e-02, -7.4058e-02, -8.4909e-02,\n          3.2041e-01,  2.4364e-01, -2.3783e-01],\n        [-3.3212e-01, -3.4235e-01,  3.9090e-02,  5.0792e-02, -2.4055e-01,\n         -3.9708e-02, -2.9985e-01,  1.0574e-01],\n        [ 1.1797e-01,  2.0934e-01, -7.9681e-02,  1.1982e-01,  6.2951e-02,\n         -1.4796e-01,  3.0687e-01,  3.0509e-01],\n        [ 3.4885e-01, -2.1712e-01, -1.6653e-01,  7.0048e-02,  2.3468e-02,\n          1.1410e-01,  2.7052e-01, -2.0007e-01],\n        [ 1.6810e-02,  2.3302e-01,  1.3482e-01, -2.9534e-01, -1.8714e-01,\n          1.8906e-01,  3.0978e-01, -1.5531e-01],\n        [ 2.9013e-01, -2.9807e-02,  2.3517e-01, -1.2316e-01,  1.3980e-01,\n         -2.0984e-01, -2.3941e-01, -2.4152e-01],\n        [ 3.2309e-01,  7.8619e-02,  2.8150e-01, -2.5773e-01, -3.0960e-01,\n         -3.4258e-01, -2.0708e-01,  3.2672e-01],\n        [-1.3002e-01, -2.8752e-01, -1.8735e-01,  2.9237e-01, -2.1531e-02,\n         -1.6315e-01,  2.8696e-01,  7.1761e-02],\n        [-4.7083e-02,  2.2614e-01,  2.8473e-01, -3.3917e-01,  1.8509e-01,\n          2.2133e-01, -3.5080e-01, -2.6915e-01],\n        [-2.7485e-01,  7.6637e-02, -3.1224e-01, -3.1490e-01, -8.7235e-02,\n          1.7798e-01,  6.6187e-02, -2.7436e-01],\n        [-3.1959e-01,  2.1235e-02,  3.3361e-01,  7.9465e-02,  2.4489e-01,\n         -1.3348e-01,  4.1193e-02, -3.0464e-01],\n        [-1.3196e-01,  1.7495e-01,  9.0112e-02,  3.4914e-01,  8.2159e-02,\n          3.1381e-01,  8.0525e-03,  1.9682e-02],\n        [-7.4916e-02, -1.8040e-01,  2.5853e-01, -1.0059e-01, -3.0217e-01,\n         -1.5515e-01,  3.3493e-01, -3.4911e-01],\n        [-2.8490e-01,  2.3080e-01,  1.1785e-01, -1.0175e-01,  3.4646e-01,\n         -3.1840e-01,  3.8918e-02, -3.0412e-01],\n        [ 1.9405e-01,  2.4066e-01,  2.5372e-01,  7.8141e-02,  1.5976e-02,\n         -2.1487e-01,  1.2200e-01, -8.9266e-03],\n        [ 2.9361e-01,  2.6221e-01, -1.7452e-01, -2.8064e-01,  1.5941e-01,\n          1.5860e-01, -1.4241e-01,  1.0925e-01],\n        [ 3.1851e-01,  1.0312e-01, -8.5148e-02, -2.4504e-01, -2.3905e-01,\n         -3.6391e-02,  2.2341e-01, -1.5271e-01],\n        [-2.8653e-01,  2.1957e-01,  2.6021e-01, -2.3619e-01, -2.2112e-01,\n         -2.8924e-02,  2.2104e-02,  1.6661e-01],\n        [ 3.1581e-04, -9.5845e-02, -1.6743e-01, -3.1964e-01, -2.6778e-01,\n         -6.1070e-03, -1.8443e-01,  2.7874e-01],\n        [ 2.5373e-01, -9.4435e-02, -2.2113e-01,  3.6833e-02,  2.1586e-01,\n         -9.8340e-02, -2.0537e-01,  1.2566e-01],\n        [-4.8592e-02,  4.4804e-02, -2.1853e-01, -1.4247e-01,  3.3605e-01,\n         -1.3641e-01,  3.0699e-01,  2.6908e-01],\n        [-1.2910e-01,  2.6333e-01, -2.5702e-01, -2.0304e-01,  1.3332e-01,\n          1.3932e-01, -3.5020e-02, -3.4148e-01],\n        [-2.1893e-01,  1.3848e-01,  1.2292e-01,  2.4036e-01,  1.8446e-01,\n         -3.5157e-01,  1.6989e-01, -2.9183e-01],\n        [-1.5580e-01,  2.8288e-01,  9.9384e-02, -6.7757e-02,  1.1876e-01,\n         -2.9103e-02, -3.2095e-01,  1.7970e-01],\n        [-3.0058e-01,  8.6065e-02, -8.6417e-02, -4.5517e-02, -7.5914e-02,\n         -3.4094e-01,  1.6804e-01,  2.1303e-02],\n        [ 2.4668e-01,  1.1984e-01,  1.4664e-01, -2.8919e-01, -2.9638e-01,\n          1.3125e-01, -3.4810e-01,  1.4778e-02],\n        [-2.3845e-01,  2.1636e-01, -9.7665e-02,  2.5515e-01,  3.3028e-01,\n         -1.2340e-01, -2.1718e-01,  3.1684e-01],\n        [-1.9529e-01,  1.8643e-01,  1.6013e-01, -2.7117e-01, -1.0787e-01,\n          4.0899e-02,  7.0940e-02,  3.0962e-01],\n        [ 2.7121e-01, -2.6465e-02,  1.0758e-02,  3.0206e-02, -1.5605e-01,\n         -1.2019e-01, -1.4527e-01,  1.5114e-01],\n        [-1.1370e-01, -1.8478e-01,  1.6490e-01,  1.8778e-01, -2.2456e-01,\n          5.5565e-02, -2.6652e-01, -2.4703e-01],\n        [ 6.9539e-02, -2.2221e-01,  2.1291e-01,  1.4273e-01, -2.4993e-01,\n         -2.8337e-01,  1.7828e-01,  2.7272e-01],\n        [ 1.9369e-01,  1.9283e-01,  3.9960e-03, -2.5837e-01,  2.2960e-01,\n          2.4696e-01, -4.5845e-02, -2.1522e-01],\n        [-8.4526e-02,  3.3779e-01, -3.5232e-01,  1.6533e-01,  2.5640e-03,\n         -2.1274e-01, -1.3917e-01, -1.7016e-01],\n        [-2.2155e-02,  2.4072e-01, -1.1422e-01,  3.2399e-01,  1.5848e-01,\n          3.1797e-01, -2.9934e-01, -1.0591e-01],\n        [-2.0164e-01, -1.5295e-01,  2.1909e-01,  2.8604e-01,  2.1670e-01,\n         -3.1323e-01, -1.2171e-01,  2.4602e-01],\n        [ 6.7740e-02,  2.6428e-01,  1.6001e-01, -1.7930e-01,  2.2798e-01,\n          1.6000e-01,  3.2854e-01, -7.7044e-02],\n        [ 1.1355e-01, -3.0888e-01,  2.3466e-01, -4.2261e-02,  2.1727e-01,\n         -2.1542e-01, -2.3996e-01, -2.3681e-01],\n        [-3.4898e-02, -7.0322e-02, -8.8665e-03,  3.9006e-03, -3.4879e-01,\n          2.4320e-01, -3.2890e-02, -2.8652e-01],\n        [-3.1469e-01,  5.6899e-02, -5.2118e-02, -1.7801e-01,  3.4603e-01,\n         -2.1193e-01, -1.1448e-01,  2.8764e-01],\n        [ 2.2184e-01,  2.2463e-01,  6.7947e-02, -1.6458e-02, -2.1504e-01,\n         -1.0862e-01, -2.6282e-01, -1.6203e-01],\n        [ 5.7061e-02,  2.8419e-01, -2.3065e-01,  1.7690e-01, -2.7459e-01,\n         -2.0173e-02, -2.6231e-01, -2.7621e-01],\n        [-1.0231e-01, -2.3183e-03,  3.5209e-02, -8.8898e-03,  1.5395e-01,\n         -1.5104e-01, -2.3917e-02, -2.5290e-01],\n        [ 1.6381e-01,  3.1700e-01, -3.1217e-01,  2.2292e-02,  2.7193e-01,\n         -2.1886e-01,  2.7231e-01, -1.9788e-01],\n        [ 2.4006e-01, -3.3509e-01, -2.8277e-01, -3.4267e-01,  2.1961e-01,\n         -2.3739e-01, -3.1990e-02, -1.0081e-01],\n        [ 2.8050e-01,  1.2355e-01,  1.2801e-01,  2.3527e-01,  1.5257e-02,\n          2.7750e-01, -1.4957e-01,  1.0864e-02],\n        [ 2.5038e-01,  3.1802e-01,  2.2806e-01, -1.9457e-01,  2.2164e-01,\n          3.1273e-01, -1.9783e-01, -8.7348e-02],\n        [-2.8801e-01,  1.4101e-01,  8.9484e-02,  2.9289e-01,  2.4734e-01,\n         -4.5117e-02,  2.5431e-01,  8.5788e-02],\n        [ 9.5125e-02, -2.0469e-01, -2.7595e-01,  3.5095e-02, -3.0044e-01,\n          1.2310e-01, -2.0401e-01, -3.5981e-02],\n        [ 3.1399e-01, -3.2397e-01, -3.4404e-01, -2.4986e-01,  2.3563e-01,\n          6.9915e-03,  1.8493e-01,  3.0908e-02],\n        [-1.2521e-01,  3.2420e-01,  2.3288e-01,  2.1255e-01, -3.1551e-01,\n         -2.6317e-01,  3.4491e-02, -8.5009e-02],\n        [-2.7710e-02, -1.5870e-01,  2.3066e-01, -2.7250e-01,  1.9138e-01,\n         -1.5769e-01, -1.5050e-02, -2.5585e-01],\n        [-2.6774e-01,  2.0443e-01,  1.8179e-01, -1.8743e-01, -4.8891e-02,\n         -2.2430e-01, -1.4802e-01,  9.3049e-02],\n        [-1.8174e-01, -1.0410e-02,  3.2421e-01,  1.8392e-01,  2.1403e-01,\n         -2.7873e-01,  1.7608e-02, -8.3369e-02],\n        [-2.5245e-02,  3.8044e-03, -1.1305e-01, -3.4012e-02,  1.4310e-01,\n         -2.2650e-02,  2.7753e-01,  2.6201e-01],\n        [ 8.0029e-02,  2.4224e-01, -1.4273e-01,  2.5974e-01,  1.7796e-01,\n          2.4223e-01,  1.7528e-01, -8.3654e-02],\n        [ 2.1198e-01, -2.4865e-01,  1.9433e-01, -2.9642e-01, -9.1574e-02,\n         -1.3445e-01, -1.5966e-01,  2.5544e-01],\n        [-1.0570e-02,  1.8667e-02,  1.5129e-01,  1.9932e-01,  1.0999e-01,\n         -2.2191e-01,  3.8527e-02,  6.1533e-02],\n        [-3.3824e-01,  1.3450e-01, -1.3429e-01,  1.3016e-01, -1.1997e-01,\n          2.3880e-01, -3.2458e-01, -2.8829e-01],\n        [ 6.8559e-02, -2.7136e-01,  3.4608e-01, -2.2885e-02, -8.8418e-02,\n          1.7533e-01,  2.1732e-01, -4.7901e-02],\n        [ 7.9267e-02,  1.5599e-01,  3.0707e-01,  1.4641e-01,  2.1876e-01,\n          1.3458e-01, -2.7234e-01, -2.3136e-01],\n        [-6.7231e-03,  8.6355e-02, -9.1269e-03, -2.2629e-01,  3.1728e-01,\n          3.1949e-01, -1.2788e-01, -6.6622e-02],\n        [ 2.6923e-01,  7.8814e-02, -2.5857e-01, -2.9915e-03, -2.4970e-01,\n         -2.0531e-01,  1.0232e-01, -9.9353e-02],\n        [-7.1855e-02,  2.1602e-01, -1.1718e-01,  3.2425e-01,  2.4106e-01,\n          5.0524e-02, -1.3921e-01,  1.8390e-01],\n        [ 4.1050e-02, -1.3491e-01, -3.0509e-01,  2.4194e-01,  1.3501e-01,\n         -3.9380e-03,  3.6891e-02, -1.1310e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0825, -0.0097,  0.0367,  0.0078,  0.0534, -0.0921,  0.0798, -0.0927,\n         0.0417, -0.0765,  0.0597,  0.0242, -0.0636,  0.0187, -0.0660, -0.0697,\n        -0.0588,  0.0922,  0.0464,  0.0645,  0.0608, -0.0664,  0.0764,  0.0075,\n        -0.0893,  0.0323, -0.0371,  0.0915,  0.0565,  0.0010,  0.0221,  0.0879,\n         0.0185, -0.0528,  0.0958, -0.0269, -0.0070, -0.0157,  0.0840, -0.0808,\n         0.0387, -0.0050,  0.0113,  0.0742, -0.0821, -0.0321, -0.0101, -0.0578,\n        -0.0193,  0.0242, -0.0239,  0.0302, -0.0553, -0.0079, -0.0740,  0.0233,\n         0.0655, -0.0237,  0.0732, -0.0322, -0.0469, -0.0171, -0.0960,  0.0569,\n        -0.0508,  0.0090, -0.0032,  0.0202,  0.0028,  0.0051, -0.0775,  0.0846,\n         0.0065,  0.0182, -0.0301, -0.0590, -0.0036, -0.0279,  0.0755, -0.0246,\n         0.0808,  0.0241, -0.0821,  0.0426, -0.0705, -0.0293, -0.0210,  0.0848,\n        -0.0352, -0.0686, -0.0737, -0.0560,  0.0962,  0.0297, -0.0891, -0.0934,\n        -0.0075,  0.0831, -0.0073,  0.0935], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0313, -0.0570, -0.0359,  ...,  0.0663,  0.0846, -0.0949],\n        [-0.0780, -0.0700,  0.0758,  ...,  0.0604, -0.0463, -0.0934],\n        [ 0.0268, -0.0519,  0.0100,  ..., -0.0046, -0.0371,  0.0861],\n        ...,\n        [ 0.0789, -0.0155, -0.0303,  ..., -0.0921,  0.0172,  0.0315],\n        [-0.0346,  0.0090,  0.0270,  ..., -0.0912,  0.0634,  0.0895],\n        [-0.0110,  0.0525, -0.0365,  ...,  0.0775,  0.0262,  0.0310]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0017,  0.0821, -0.0173,  0.0262,  0.0136, -0.0306, -0.0925, -0.0551],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0554, -0.0781, -0.0421, -0.0691,  0.0608,  0.0678, -0.0038, -0.0714,\n          0.0338,  0.0273, -0.0654, -0.0571,  0.0606,  0.0078,  0.0712, -0.0674,\n          0.0982,  0.0561,  0.0050, -0.0017,  0.0417, -0.0379,  0.0239, -0.0790,\n          0.0056, -0.0860,  0.0015, -0.0827, -0.0829,  0.0085, -0.0605,  0.0239,\n          0.0514,  0.0840, -0.0022, -0.0771, -0.0395,  0.0020, -0.0158, -0.0122,\n          0.0460, -0.0551, -0.0926, -0.0120,  0.0846, -0.0857, -0.0208,  0.0074,\n         -0.0448,  0.0988, -0.0096, -0.0482,  0.0608,  0.0888, -0.0391,  0.0029,\n          0.0505, -0.0323,  0.0222, -0.0688,  0.0777,  0.0742, -0.0980,  0.0551,\n          0.0939, -0.0884, -0.0312,  0.0204,  0.0462, -0.0915,  0.0209, -0.0392,\n         -0.0654, -0.0344, -0.0489,  0.0731, -0.0975, -0.0087,  0.0749,  0.0342,\n         -0.0181,  0.0796, -0.0876,  0.0509,  0.0308, -0.0276, -0.0514,  0.0604,\n         -0.0230, -0.0144,  0.0116,  0.0902, -0.0882,  0.0744, -0.0509,  0.0014,\n         -0.0815, -0.0443,  0.0002,  0.0497],\n        [ 0.0253,  0.0884,  0.0431, -0.0099, -0.0344,  0.0211, -0.0459, -0.0108,\n          0.0850,  0.0332, -0.0913,  0.0744,  0.0671,  0.0975, -0.0784, -0.0819,\n          0.0967,  0.0100, -0.0957,  0.0688, -0.0300, -0.0510, -0.0071,  0.0531,\n          0.0053,  0.0103, -0.0819,  0.0588,  0.0146, -0.0435, -0.0789, -0.0363,\n         -0.0044, -0.0721, -0.0772, -0.0783, -0.0421,  0.0646, -0.0717,  0.0364,\n          0.0551, -0.0005, -0.0725, -0.0981,  0.0887, -0.0284, -0.0709, -0.0288,\n          0.0461, -0.0205, -0.0467,  0.0135,  0.0541,  0.0057,  0.0515, -0.0312,\n          0.0781, -0.0609,  0.0521, -0.0392, -0.0015, -0.0789, -0.0183,  0.0736,\n          0.0883, -0.0292, -0.0782,  0.0596, -0.0322,  0.0444,  0.0507,  0.0490,\n         -0.0487,  0.0543,  0.0083, -0.0547, -0.0808, -0.0036, -0.0346, -0.0261,\n          0.0131, -0.0779,  0.0485,  0.0568, -0.0042, -0.0461,  0.0915,  0.0866,\n         -0.0786, -0.0144, -0.0310, -0.0520, -0.0200, -0.0950, -0.0754,  0.0640,\n          0.0064, -0.0267, -0.0921, -0.0450],\n        [-0.0307, -0.0540,  0.0164,  0.0540, -0.0712, -0.0420, -0.0023,  0.0977,\n         -0.0610,  0.0496, -0.0879,  0.0931, -0.0506, -0.0310,  0.0519, -0.0702,\n          0.0966, -0.0085,  0.0874, -0.0177,  0.0426, -0.0991, -0.0806, -0.0024,\n         -0.0357, -0.0771, -0.0878, -0.0064, -0.0179,  0.0031, -0.0811, -0.0298,\n         -0.0136, -0.0141, -0.0471, -0.0733, -0.0587, -0.0064, -0.0949,  0.0063,\n          0.0751,  0.0175, -0.0146,  0.0332,  0.0716, -0.0214,  0.0835,  0.0603,\n         -0.0260,  0.0413,  0.0305, -0.0013,  0.0096,  0.0977,  0.0727,  0.0294,\n         -0.0228,  0.0801, -0.0681, -0.0245, -0.0296, -0.0037, -0.0035,  0.0592,\n          0.0695, -0.0642,  0.0106, -0.0823, -0.0181, -0.0151,  0.0171, -0.0270,\n         -0.0852,  0.0212,  0.0709, -0.0238, -0.0871,  0.0267, -0.0782,  0.0028,\n          0.0378,  0.0411, -0.0090, -0.0490, -0.0178,  0.0421, -0.0848,  0.0489,\n          0.0330, -0.0918,  0.0086, -0.0678,  0.0750,  0.0833,  0.0079,  0.0909,\n         -0.0005,  0.0162, -0.0838,  0.0768],\n        [-0.0197, -0.0767, -0.0964, -0.0135,  0.0020, -0.0503, -0.0179, -0.0125,\n          0.0542,  0.0119, -0.0465, -0.0197, -0.0581, -0.0826,  0.0450,  0.0986,\n         -0.0385,  0.0394, -0.0674, -0.0229, -0.0970,  0.0855, -0.0955, -0.0631,\n         -0.0963, -0.0310, -0.0957, -0.0253, -0.0720, -0.0131, -0.0065, -0.0707,\n          0.0244, -0.0256,  0.0929,  0.0069, -0.0424, -0.0219,  0.0855,  0.0059,\n         -0.0303,  0.0510, -0.0083, -0.0784, -0.0480, -0.0610,  0.0171,  0.0121,\n         -0.0950, -0.0500,  0.0181, -0.0310, -0.0986,  0.0919,  0.0660, -0.0380,\n         -0.0513,  0.0597,  0.0409,  0.0087,  0.0653, -0.0314, -0.0839, -0.0477,\n          0.0320, -0.0665,  0.0829, -0.0585,  0.0751, -0.0583,  0.0680, -0.0070,\n          0.0020,  0.0331,  0.0708, -0.0869, -0.0812, -0.0992,  0.0391, -0.0639,\n         -0.0575, -0.0312, -0.0611, -0.0789, -0.0439,  0.0878, -0.0558, -0.0136,\n          0.0193, -0.0067,  0.0044, -0.0252,  0.0067,  0.0753,  0.0701,  0.0303,\n         -0.0748, -0.0459, -0.0806,  0.0109],\n        [ 0.0741,  0.0756,  0.0794, -0.0039,  0.0099, -0.0367,  0.0349,  0.0014,\n         -0.0652,  0.0001, -0.0131,  0.0350,  0.0234, -0.0050, -0.0517, -0.0205,\n          0.0277, -0.0901,  0.0668, -0.0657, -0.0585, -0.0333, -0.0361, -0.0239,\n          0.0097, -0.0164, -0.0546, -0.0685, -0.0602, -0.0888, -0.0786,  0.0538,\n         -0.0749,  0.0332,  0.0822, -0.0047,  0.0739, -0.0432,  0.0441, -0.0380,\n         -0.0135, -0.0359, -0.0219, -0.0237, -0.0355, -0.0087,  0.0493,  0.0090,\n         -0.0252, -0.0379, -0.0913, -0.0013, -0.0863, -0.0373,  0.0703, -0.0280,\n         -0.0928, -0.0036, -0.0768,  0.0688, -0.0407,  0.0475, -0.0702, -0.0339,\n          0.0409,  0.0914,  0.0375,  0.0099,  0.0228, -0.0277,  0.0844, -0.0372,\n          0.0489,  0.0529,  0.0551, -0.0658,  0.0606, -0.0740, -0.0683,  0.0705,\n         -0.0497, -0.0048,  0.0409, -0.0469,  0.0992, -0.0588,  0.0566, -0.0852,\n         -0.0934, -0.0886,  0.0896, -0.0401, -0.0116, -0.0890,  0.0893, -0.0613,\n          0.0785, -0.0412,  0.0191,  0.0298],\n        [-0.0663, -0.0453,  0.0917, -0.0309, -0.0270, -0.0682, -0.0559, -0.0394,\n          0.0101, -0.0286,  0.0428, -0.0364,  0.0254, -0.0078,  0.0286, -0.0414,\n          0.0798, -0.0953, -0.0657,  0.0443,  0.0647, -0.0794, -0.0645, -0.0893,\n          0.0885, -0.0130, -0.0020, -0.0891, -0.0274,  0.0973, -0.0448, -0.0757,\n         -0.0857, -0.0160,  0.0924,  0.0913,  0.0573,  0.0061, -0.0455,  0.0659,\n         -0.0343,  0.0709, -0.0278,  0.0243,  0.0482, -0.0020,  0.0708,  0.0494,\n         -0.0551,  0.0730, -0.0083, -0.0082,  0.0742,  0.0533,  0.0360,  0.0170,\n          0.0413, -0.0090, -0.0607, -0.0934, -0.0498,  0.0406,  0.0079, -0.0221,\n         -0.0096,  0.0365,  0.0363, -0.0509,  0.0120, -0.0577, -0.0789, -0.0116,\n         -0.0188,  0.0664, -0.0125, -0.0117,  0.0536,  0.0079,  0.0431, -0.0877,\n         -0.0887,  0.0525, -0.0506,  0.0469, -0.0786, -0.0092, -0.0290,  0.0802,\n         -0.0362,  0.0485, -0.0478,  0.0055,  0.0626, -0.0234,  0.0850,  0.0286,\n         -0.0471,  0.0129,  0.0845,  0.0203],\n        [-0.0771, -0.0541,  0.0761, -0.0830, -0.0160,  0.0169,  0.0841,  0.0179,\n          0.0205,  0.0315,  0.0574,  0.0131,  0.0702, -0.0537, -0.0264,  0.0690,\n         -0.0378, -0.0318, -0.0019, -0.0639, -0.0963, -0.0743, -0.0886, -0.0677,\n         -0.0179, -0.0702, -0.0598, -0.0680, -0.0201,  0.0040, -0.0272, -0.0967,\n         -0.0348, -0.0851,  0.0341,  0.0664,  0.0173,  0.0109, -0.0476, -0.0708,\n         -0.0338, -0.0805, -0.0241,  0.0697, -0.0754,  0.0017, -0.0236, -0.0823,\n          0.0915, -0.0786, -0.0084, -0.0064,  0.0295, -0.0172, -0.0783, -0.0143,\n          0.0117,  0.0182, -0.0332, -0.0157,  0.0222, -0.0466,  0.0666, -0.0181,\n          0.0508,  0.0101, -0.0501,  0.0363, -0.0301,  0.0769,  0.0881, -0.0034,\n          0.0754, -0.0333,  0.0282,  0.0655,  0.0750,  0.0227,  0.0079, -0.0074,\n         -0.0782,  0.0701,  0.0687,  0.0495, -0.0324, -0.0457,  0.0657, -0.0936,\n         -0.0914, -0.0327, -0.0267,  0.0036, -0.0488,  0.0302,  0.0480, -0.0728,\n         -0.0065,  0.0524,  0.0182,  0.0163],\n        [-0.0837,  0.0887, -0.0170, -0.0438,  0.0730,  0.0750,  0.0982,  0.0231,\n          0.0509, -0.0638, -0.0635,  0.0338,  0.0809,  0.0382,  0.0046,  0.0841,\n         -0.0695,  0.0988,  0.0476, -0.0173, -0.0846,  0.0906,  0.0898, -0.0287,\n          0.0171, -0.0819, -0.0272, -0.0047,  0.0674, -0.0044,  0.0742, -0.0695,\n          0.0352,  0.0924,  0.0258, -0.0200, -0.0955, -0.0883,  0.0958, -0.0099,\n          0.0836, -0.0537,  0.0162, -0.0322, -0.0317,  0.0813,  0.0969, -0.0231,\n         -0.0459, -0.0497, -0.0251,  0.0410,  0.0148,  0.0411,  0.0057, -0.0812,\n          0.0705, -0.0805,  0.0925, -0.0731,  0.0586, -0.0198, -0.0972, -0.0824,\n          0.0384,  0.0897,  0.0104,  0.0504,  0.0434,  0.0883, -0.0229, -0.0414,\n          0.0505,  0.0649, -0.0294, -0.0388,  0.0353,  0.0290,  0.0062, -0.0392,\n         -0.0956, -0.0601,  0.0366,  0.0764,  0.0592,  0.0309, -0.0120,  0.0348,\n          0.0705,  0.0145,  0.0928,  0.0592, -0.0819,  0.0466,  0.0902,  0.0406,\n          0.0973, -0.0593, -0.0415,  0.0661]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2066,  0.2914, -0.3019, -0.0223], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0760, -0.2548, -0.1179, -0.2930,  0.2189,  0.2528, -0.0698, -0.1085],\n        [ 0.2765, -0.1230, -0.0594, -0.2404,  0.0091,  0.2113, -0.2937,  0.1121],\n        [ 0.1897, -0.3328,  0.0515, -0.0165, -0.1935,  0.2885, -0.1014, -0.0211],\n        [-0.2716, -0.0565, -0.1572,  0.0503,  0.2491,  0.0833, -0.2424, -0.2174]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-3.4697e-01,  3.7044e-02, -1.2115e-01,  3.5075e-01, -3.0165e-01,\n         -5.0181e-02, -3.1486e-01, -7.1445e-02],\n        [-1.7023e-01,  2.0395e-02,  1.5096e-01, -5.2793e-02,  1.0288e-02,\n         -8.4125e-02,  2.9095e-01,  3.4953e-01],\n        [ 2.9611e-01,  1.7308e-01, -2.4746e-01, -9.0663e-03,  3.5308e-01,\n         -1.5451e-02, -1.0378e-01, -3.3220e-01],\n        [ 7.3217e-02,  1.7666e-01,  5.7330e-02, -1.1978e-01,  2.0175e-02,\n          2.2353e-01,  1.1763e-01,  2.5276e-01],\n        [ 9.6785e-02, -1.7273e-01,  2.6886e-01, -7.9670e-02, -2.6020e-01,\n         -2.8293e-01,  3.4171e-01,  3.1726e-01],\n        [-8.8809e-03, -3.3676e-01, -1.4238e-01,  2.5992e-01, -1.3999e-01,\n         -1.1421e-01,  3.3401e-01,  3.2127e-01],\n        [ 8.9419e-02,  2.1889e-01,  2.2993e-01,  9.3243e-02, -1.1973e-01,\n          1.1854e-01, -2.9885e-01,  1.3375e-01],\n        [ 2.6245e-01,  3.3365e-01,  1.0697e-01, -2.1563e-01, -2.5660e-01,\n          2.6082e-01, -4.1335e-02,  1.3381e-01],\n        [ 1.9653e-01,  3.9683e-02, -1.3610e-01,  5.9347e-02,  3.2795e-01,\n         -2.6775e-01, -9.2962e-02, -1.7982e-01],\n        [-2.8077e-01, -1.2343e-01, -2.4749e-01,  1.2939e-01, -6.5056e-02,\n         -8.3026e-02, -1.4209e-01, -3.3266e-01],\n        [-4.0037e-02,  6.1226e-02, -7.1620e-02, -2.3897e-02,  3.0075e-01,\n          2.1566e-01,  3.1927e-01, -5.0386e-02],\n        [ 6.6453e-02,  1.5740e-01,  6.5109e-02, -1.2474e-01,  4.1955e-02,\n         -2.8994e-01, -2.1635e-01,  2.6108e-01],\n        [ 1.8877e-01, -1.5982e-01,  1.1827e-01, -9.0328e-02, -2.2346e-01,\n         -2.9567e-02,  8.9819e-02, -4.3210e-02],\n        [-3.0383e-01,  2.2106e-01, -3.0461e-03, -3.3098e-01,  3.9086e-02,\n          2.7247e-01, -3.1299e-01,  2.0291e-01],\n        [-1.5454e-01,  2.6533e-02,  1.7153e-01, -1.6702e-01, -2.8040e-01,\n         -3.3110e-01,  1.9102e-02, -1.0429e-01],\n        [-2.2111e-01,  1.8838e-01,  1.5163e-01,  4.5974e-02, -2.7516e-01,\n          1.1762e-01, -9.8528e-02, -2.9432e-01],\n        [ 1.5902e-02, -1.5538e-01, -1.8302e-01, -6.1603e-02,  2.6117e-01,\n          1.7540e-01,  9.6014e-02, -2.7428e-02],\n        [ 4.6555e-02, -7.1814e-02,  2.1058e-01, -1.0653e-01,  1.0555e-01,\n          2.1701e-01, -2.0076e-01, -1.2482e-02],\n        [ 6.7895e-02, -2.9797e-01, -2.5280e-01,  2.6350e-01, -7.8190e-02,\n         -2.1538e-01, -1.6459e-01, -1.1273e-01],\n        [ 2.3908e-03,  3.5188e-01, -2.5317e-01,  7.0407e-03, -1.1756e-01,\n         -5.7509e-02, -2.6532e-01, -1.1697e-01],\n        [-1.5387e-01,  3.2946e-01, -2.5487e-01, -3.0401e-01, -1.9772e-01,\n         -1.4152e-01,  1.8366e-02, -1.3386e-01],\n        [ 1.3989e-01,  5.7430e-02, -6.0499e-02,  9.0147e-02,  1.3009e-01,\n         -1.2314e-01,  3.5338e-01,  3.1835e-01],\n        [-5.1420e-02, -8.1513e-02, -6.2830e-02,  1.7436e-01, -1.5588e-01,\n         -1.3453e-02, -3.2808e-01,  1.1344e-01],\n        [ 7.7083e-02,  8.1005e-02, -2.2668e-03, -3.4269e-01, -2.4155e-01,\n         -1.2811e-01, -2.4200e-01, -5.5241e-02],\n        [-2.5120e-01,  1.6607e-03,  2.2704e-01, -2.8465e-01,  3.7032e-02,\n          3.1750e-01,  3.2511e-01,  1.1702e-01],\n        [ 5.4826e-02,  2.1977e-01,  3.0609e-01, -1.9104e-01, -2.9363e-01,\n         -1.2303e-01, -3.3197e-01, -1.8040e-01],\n        [-2.9360e-01,  3.3252e-01,  3.1737e-02,  7.8009e-03,  2.7588e-01,\n          3.3468e-02,  4.2502e-02,  1.0969e-01],\n        [-1.3476e-01, -1.9893e-01, -2.9448e-01,  1.2716e-01, -7.0296e-02,\n          3.7740e-03, -9.0898e-02, -3.3451e-01],\n        [ 1.4238e-01, -6.5139e-02,  2.4963e-01, -2.8249e-01, -1.9771e-01,\n         -3.1238e-01,  3.4915e-02, -5.6821e-02],\n        [-2.0725e-01,  3.4341e-01, -3.4748e-01, -3.3188e-01,  9.4574e-02,\n          3.2233e-01,  1.3117e-01, -3.7512e-02],\n        [ 1.9425e-01, -1.1051e-01, -4.3320e-02,  6.1507e-03,  1.5577e-01,\n          2.5020e-01, -1.6512e-02,  1.8801e-01],\n        [-2.5415e-01,  1.2701e-01, -7.2332e-02,  3.0672e-01,  1.3507e-01,\n         -1.2095e-01, -1.8783e-01, -3.1069e-01],\n        [ 1.2361e-01,  2.1960e-01, -2.2625e-01, -1.1883e-02,  3.2747e-01,\n         -3.4776e-01, -2.1303e-01, -2.0980e-01],\n        [ 6.2142e-02, -3.3259e-01,  1.9323e-01,  2.5491e-01,  2.7642e-01,\n         -2.6628e-01,  1.8363e-02,  3.2084e-01],\n        [-1.2746e-01,  5.3717e-02,  2.9265e-01, -3.0026e-01, -1.1093e-01,\n         -1.8498e-01,  2.3238e-02, -1.1347e-01],\n        [-3.9494e-02,  3.5349e-01,  1.6213e-02, -2.7230e-01, -1.2595e-01,\n         -1.1406e-01,  1.5779e-01,  6.5291e-02],\n        [ 1.4848e-01,  2.8244e-01, -5.7893e-02, -7.4058e-02, -8.4909e-02,\n          3.2041e-01,  2.4364e-01, -2.3783e-01],\n        [-3.3212e-01, -3.4235e-01,  3.9090e-02,  5.0792e-02, -2.4055e-01,\n         -3.9708e-02, -2.9985e-01,  1.0574e-01],\n        [ 1.1797e-01,  2.0934e-01, -7.9681e-02,  1.1982e-01,  6.2951e-02,\n         -1.4796e-01,  3.0687e-01,  3.0509e-01],\n        [ 3.4885e-01, -2.1712e-01, -1.6653e-01,  7.0048e-02,  2.3468e-02,\n          1.1410e-01,  2.7052e-01, -2.0007e-01],\n        [ 1.6810e-02,  2.3302e-01,  1.3482e-01, -2.9534e-01, -1.8714e-01,\n          1.8906e-01,  3.0978e-01, -1.5531e-01],\n        [ 2.9013e-01, -2.9807e-02,  2.3517e-01, -1.2316e-01,  1.3980e-01,\n         -2.0984e-01, -2.3941e-01, -2.4152e-01],\n        [ 3.2309e-01,  7.8619e-02,  2.8150e-01, -2.5773e-01, -3.0960e-01,\n         -3.4258e-01, -2.0708e-01,  3.2672e-01],\n        [-1.3002e-01, -2.8752e-01, -1.8735e-01,  2.9237e-01, -2.1531e-02,\n         -1.6315e-01,  2.8696e-01,  7.1761e-02],\n        [-4.7083e-02,  2.2614e-01,  2.8473e-01, -3.3917e-01,  1.8509e-01,\n          2.2133e-01, -3.5080e-01, -2.6915e-01],\n        [-2.7485e-01,  7.6637e-02, -3.1224e-01, -3.1490e-01, -8.7235e-02,\n          1.7798e-01,  6.6187e-02, -2.7436e-01],\n        [-3.1959e-01,  2.1235e-02,  3.3361e-01,  7.9465e-02,  2.4489e-01,\n         -1.3348e-01,  4.1193e-02, -3.0464e-01],\n        [-1.3196e-01,  1.7495e-01,  9.0112e-02,  3.4914e-01,  8.2159e-02,\n          3.1381e-01,  8.0525e-03,  1.9682e-02],\n        [-7.4916e-02, -1.8040e-01,  2.5853e-01, -1.0059e-01, -3.0217e-01,\n         -1.5515e-01,  3.3493e-01, -3.4911e-01],\n        [-2.8490e-01,  2.3080e-01,  1.1785e-01, -1.0175e-01,  3.4646e-01,\n         -3.1840e-01,  3.8918e-02, -3.0412e-01],\n        [ 1.9405e-01,  2.4066e-01,  2.5372e-01,  7.8141e-02,  1.5976e-02,\n         -2.1487e-01,  1.2200e-01, -8.9266e-03],\n        [ 2.9361e-01,  2.6221e-01, -1.7452e-01, -2.8064e-01,  1.5941e-01,\n          1.5860e-01, -1.4241e-01,  1.0925e-01],\n        [ 3.1851e-01,  1.0312e-01, -8.5148e-02, -2.4504e-01, -2.3905e-01,\n         -3.6391e-02,  2.2341e-01, -1.5271e-01],\n        [-2.8653e-01,  2.1957e-01,  2.6021e-01, -2.3619e-01, -2.2112e-01,\n         -2.8924e-02,  2.2104e-02,  1.6661e-01],\n        [ 3.1581e-04, -9.5845e-02, -1.6743e-01, -3.1964e-01, -2.6778e-01,\n         -6.1070e-03, -1.8443e-01,  2.7874e-01],\n        [ 2.5373e-01, -9.4435e-02, -2.2113e-01,  3.6833e-02,  2.1586e-01,\n         -9.8340e-02, -2.0537e-01,  1.2566e-01],\n        [-4.8592e-02,  4.4804e-02, -2.1853e-01, -1.4247e-01,  3.3605e-01,\n         -1.3641e-01,  3.0699e-01,  2.6908e-01],\n        [-1.2910e-01,  2.6333e-01, -2.5702e-01, -2.0304e-01,  1.3332e-01,\n          1.3932e-01, -3.5020e-02, -3.4148e-01],\n        [-2.1893e-01,  1.3848e-01,  1.2292e-01,  2.4036e-01,  1.8446e-01,\n         -3.5157e-01,  1.6989e-01, -2.9183e-01],\n        [-1.5580e-01,  2.8288e-01,  9.9384e-02, -6.7757e-02,  1.1876e-01,\n         -2.9103e-02, -3.2095e-01,  1.7970e-01],\n        [-3.0058e-01,  8.6065e-02, -8.6417e-02, -4.5517e-02, -7.5914e-02,\n         -3.4094e-01,  1.6804e-01,  2.1303e-02],\n        [ 2.4668e-01,  1.1984e-01,  1.4664e-01, -2.8919e-01, -2.9638e-01,\n          1.3125e-01, -3.4810e-01,  1.4778e-02],\n        [-2.3845e-01,  2.1636e-01, -9.7665e-02,  2.5515e-01,  3.3028e-01,\n         -1.2340e-01, -2.1718e-01,  3.1684e-01],\n        [-1.9529e-01,  1.8643e-01,  1.6013e-01, -2.7117e-01, -1.0787e-01,\n          4.0899e-02,  7.0940e-02,  3.0962e-01],\n        [ 2.7121e-01, -2.6465e-02,  1.0758e-02,  3.0206e-02, -1.5605e-01,\n         -1.2019e-01, -1.4527e-01,  1.5114e-01],\n        [-1.1370e-01, -1.8478e-01,  1.6490e-01,  1.8778e-01, -2.2456e-01,\n          5.5565e-02, -2.6652e-01, -2.4703e-01],\n        [ 6.9539e-02, -2.2221e-01,  2.1291e-01,  1.4273e-01, -2.4993e-01,\n         -2.8337e-01,  1.7828e-01,  2.7272e-01],\n        [ 1.9369e-01,  1.9283e-01,  3.9960e-03, -2.5837e-01,  2.2960e-01,\n          2.4696e-01, -4.5845e-02, -2.1522e-01],\n        [-8.4526e-02,  3.3779e-01, -3.5232e-01,  1.6533e-01,  2.5640e-03,\n         -2.1274e-01, -1.3917e-01, -1.7016e-01],\n        [-2.2155e-02,  2.4072e-01, -1.1422e-01,  3.2399e-01,  1.5848e-01,\n          3.1797e-01, -2.9934e-01, -1.0591e-01],\n        [-2.0164e-01, -1.5295e-01,  2.1909e-01,  2.8604e-01,  2.1670e-01,\n         -3.1323e-01, -1.2171e-01,  2.4602e-01],\n        [ 6.7740e-02,  2.6428e-01,  1.6001e-01, -1.7930e-01,  2.2798e-01,\n          1.6000e-01,  3.2854e-01, -7.7044e-02],\n        [ 1.1355e-01, -3.0888e-01,  2.3466e-01, -4.2261e-02,  2.1727e-01,\n         -2.1542e-01, -2.3996e-01, -2.3681e-01],\n        [-3.4898e-02, -7.0322e-02, -8.8665e-03,  3.9006e-03, -3.4879e-01,\n          2.4320e-01, -3.2890e-02, -2.8652e-01],\n        [-3.1469e-01,  5.6899e-02, -5.2118e-02, -1.7801e-01,  3.4603e-01,\n         -2.1193e-01, -1.1448e-01,  2.8764e-01],\n        [ 2.2184e-01,  2.2463e-01,  6.7947e-02, -1.6458e-02, -2.1504e-01,\n         -1.0862e-01, -2.6282e-01, -1.6203e-01],\n        [ 5.7061e-02,  2.8419e-01, -2.3065e-01,  1.7690e-01, -2.7459e-01,\n         -2.0173e-02, -2.6231e-01, -2.7621e-01],\n        [-1.0231e-01, -2.3183e-03,  3.5209e-02, -8.8898e-03,  1.5395e-01,\n         -1.5104e-01, -2.3917e-02, -2.5290e-01],\n        [ 1.6381e-01,  3.1700e-01, -3.1217e-01,  2.2292e-02,  2.7193e-01,\n         -2.1886e-01,  2.7231e-01, -1.9788e-01],\n        [ 2.4006e-01, -3.3509e-01, -2.8277e-01, -3.4267e-01,  2.1961e-01,\n         -2.3739e-01, -3.1990e-02, -1.0081e-01],\n        [ 2.8050e-01,  1.2355e-01,  1.2801e-01,  2.3527e-01,  1.5257e-02,\n          2.7750e-01, -1.4957e-01,  1.0864e-02],\n        [ 2.5038e-01,  3.1802e-01,  2.2806e-01, -1.9457e-01,  2.2164e-01,\n          3.1273e-01, -1.9783e-01, -8.7348e-02],\n        [-2.8801e-01,  1.4101e-01,  8.9484e-02,  2.9289e-01,  2.4734e-01,\n         -4.5117e-02,  2.5431e-01,  8.5788e-02],\n        [ 9.5125e-02, -2.0469e-01, -2.7595e-01,  3.5095e-02, -3.0044e-01,\n          1.2310e-01, -2.0401e-01, -3.5981e-02],\n        [ 3.1399e-01, -3.2397e-01, -3.4404e-01, -2.4986e-01,  2.3563e-01,\n          6.9915e-03,  1.8493e-01,  3.0908e-02],\n        [-1.2521e-01,  3.2420e-01,  2.3288e-01,  2.1255e-01, -3.1551e-01,\n         -2.6317e-01,  3.4491e-02, -8.5009e-02],\n        [-2.7710e-02, -1.5870e-01,  2.3066e-01, -2.7250e-01,  1.9138e-01,\n         -1.5769e-01, -1.5050e-02, -2.5585e-01],\n        [-2.6774e-01,  2.0443e-01,  1.8179e-01, -1.8743e-01, -4.8891e-02,\n         -2.2430e-01, -1.4802e-01,  9.3049e-02],\n        [-1.8174e-01, -1.0410e-02,  3.2421e-01,  1.8392e-01,  2.1403e-01,\n         -2.7873e-01,  1.7608e-02, -8.3369e-02],\n        [-2.5245e-02,  3.8044e-03, -1.1305e-01, -3.4012e-02,  1.4310e-01,\n         -2.2650e-02,  2.7753e-01,  2.6201e-01],\n        [ 8.0029e-02,  2.4224e-01, -1.4273e-01,  2.5974e-01,  1.7796e-01,\n          2.4223e-01,  1.7528e-01, -8.3654e-02],\n        [ 2.1198e-01, -2.4865e-01,  1.9433e-01, -2.9642e-01, -9.1574e-02,\n         -1.3445e-01, -1.5966e-01,  2.5544e-01],\n        [-1.0570e-02,  1.8667e-02,  1.5129e-01,  1.9932e-01,  1.0999e-01,\n         -2.2191e-01,  3.8527e-02,  6.1533e-02],\n        [-3.3824e-01,  1.3450e-01, -1.3429e-01,  1.3016e-01, -1.1997e-01,\n          2.3880e-01, -3.2458e-01, -2.8829e-01],\n        [ 6.8559e-02, -2.7136e-01,  3.4608e-01, -2.2885e-02, -8.8418e-02,\n          1.7533e-01,  2.1732e-01, -4.7901e-02],\n        [ 7.9267e-02,  1.5599e-01,  3.0707e-01,  1.4641e-01,  2.1876e-01,\n          1.3458e-01, -2.7234e-01, -2.3136e-01],\n        [-6.7231e-03,  8.6355e-02, -9.1269e-03, -2.2629e-01,  3.1728e-01,\n          3.1949e-01, -1.2788e-01, -6.6622e-02],\n        [ 2.6923e-01,  7.8814e-02, -2.5857e-01, -2.9915e-03, -2.4970e-01,\n         -2.0531e-01,  1.0232e-01, -9.9353e-02],\n        [-7.1855e-02,  2.1602e-01, -1.1718e-01,  3.2425e-01,  2.4106e-01,\n          5.0524e-02, -1.3921e-01,  1.8390e-01],\n        [ 4.1050e-02, -1.3491e-01, -3.0509e-01,  2.4194e-01,  1.3501e-01,\n         -3.9380e-03,  3.6891e-02, -1.1310e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2674, -0.1914, -0.3450, -0.2305, -0.2891,  0.1276,  0.3155, -0.2941,\n         0.1443, -0.0762,  0.2673, -0.0918,  0.1915,  0.2525,  0.0163,  0.2348,\n        -0.1313, -0.2167,  0.1248,  0.2567, -0.0709, -0.3101,  0.1968, -0.1565,\n         0.1972,  0.1577,  0.1105, -0.2734, -0.2855,  0.1158, -0.2678, -0.0871,\n         0.0903, -0.2490, -0.1881,  0.0033,  0.0809, -0.2950, -0.0256,  0.1762,\n        -0.0517, -0.0223, -0.1848, -0.2163, -0.2935,  0.2976, -0.1196, -0.1600,\n        -0.3227, -0.3395,  0.1042,  0.0076,  0.1544,  0.0064,  0.1493, -0.0854,\n        -0.0554,  0.3186,  0.1803, -0.2613,  0.3040,  0.2381, -0.1773,  0.0544,\n         0.2956,  0.0298, -0.1592, -0.2516, -0.1336,  0.1816, -0.3259, -0.2053,\n         0.2877, -0.2788,  0.0075, -0.2170,  0.3473, -0.1406,  0.0226,  0.2992,\n         0.1067,  0.1438,  0.0594, -0.3034,  0.0609,  0.2568, -0.1685,  0.2624,\n        -0.1578, -0.1486, -0.0226,  0.3153,  0.0190, -0.1009, -0.2742, -0.3365,\n         0.2210, -0.1853, -0.0124, -0.2465], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0313, -0.0570, -0.0359,  ...,  0.0663,  0.0846, -0.0949],\n        [-0.0780, -0.0700,  0.0758,  ...,  0.0604, -0.0463, -0.0934],\n        [ 0.0268, -0.0519,  0.0100,  ..., -0.0046, -0.0371,  0.0861],\n        ...,\n        [ 0.0789, -0.0155, -0.0303,  ..., -0.0921,  0.0172,  0.0315],\n        [-0.0346,  0.0090,  0.0270,  ..., -0.0912,  0.0634,  0.0895],\n        [-0.0110,  0.0525, -0.0365,  ...,  0.0775,  0.0262,  0.0310]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0825, -0.0097,  0.0367,  0.0078,  0.0534, -0.0921,  0.0798, -0.0927,\n         0.0417, -0.0765,  0.0597,  0.0242, -0.0636,  0.0187, -0.0660, -0.0697,\n        -0.0588,  0.0922,  0.0464,  0.0645,  0.0608, -0.0664,  0.0764,  0.0075,\n        -0.0893,  0.0323, -0.0371,  0.0915,  0.0565,  0.0010,  0.0221,  0.0879,\n         0.0185, -0.0528,  0.0958, -0.0269, -0.0070, -0.0157,  0.0840, -0.0808,\n         0.0387, -0.0050,  0.0113,  0.0742, -0.0821, -0.0321, -0.0101, -0.0578,\n        -0.0193,  0.0242, -0.0239,  0.0302, -0.0553, -0.0079, -0.0740,  0.0233,\n         0.0655, -0.0237,  0.0732, -0.0322, -0.0469, -0.0171, -0.0960,  0.0569,\n        -0.0508,  0.0090, -0.0032,  0.0202,  0.0028,  0.0051, -0.0775,  0.0846,\n         0.0065,  0.0182, -0.0301, -0.0590, -0.0036, -0.0279,  0.0755, -0.0246,\n         0.0808,  0.0241, -0.0821,  0.0426, -0.0705, -0.0293, -0.0210,  0.0848,\n        -0.0352, -0.0686, -0.0737, -0.0560,  0.0962,  0.0297, -0.0891, -0.0934,\n        -0.0075,  0.0831, -0.0073,  0.0935], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0554, -0.0781, -0.0421, -0.0691,  0.0608,  0.0678, -0.0038, -0.0714,\n          0.0338,  0.0273, -0.0654, -0.0571,  0.0606,  0.0078,  0.0712, -0.0674,\n          0.0982,  0.0561,  0.0050, -0.0017,  0.0417, -0.0379,  0.0239, -0.0790,\n          0.0056, -0.0860,  0.0015, -0.0827, -0.0829,  0.0085, -0.0605,  0.0239,\n          0.0514,  0.0840, -0.0022, -0.0771, -0.0395,  0.0020, -0.0158, -0.0122,\n          0.0460, -0.0551, -0.0926, -0.0120,  0.0846, -0.0857, -0.0208,  0.0074,\n         -0.0448,  0.0988, -0.0096, -0.0482,  0.0608,  0.0888, -0.0391,  0.0029,\n          0.0505, -0.0323,  0.0222, -0.0688,  0.0777,  0.0742, -0.0980,  0.0551,\n          0.0939, -0.0884, -0.0312,  0.0204,  0.0462, -0.0915,  0.0209, -0.0392,\n         -0.0654, -0.0344, -0.0489,  0.0731, -0.0975, -0.0087,  0.0749,  0.0342,\n         -0.0181,  0.0796, -0.0876,  0.0509,  0.0308, -0.0276, -0.0514,  0.0604,\n         -0.0230, -0.0144,  0.0116,  0.0902, -0.0882,  0.0744, -0.0509,  0.0014,\n         -0.0815, -0.0443,  0.0002,  0.0497],\n        [ 0.0253,  0.0884,  0.0431, -0.0099, -0.0344,  0.0211, -0.0459, -0.0108,\n          0.0850,  0.0332, -0.0913,  0.0744,  0.0671,  0.0975, -0.0784, -0.0819,\n          0.0967,  0.0100, -0.0957,  0.0688, -0.0300, -0.0510, -0.0071,  0.0531,\n          0.0053,  0.0103, -0.0819,  0.0588,  0.0146, -0.0435, -0.0789, -0.0363,\n         -0.0044, -0.0721, -0.0772, -0.0783, -0.0421,  0.0646, -0.0717,  0.0364,\n          0.0551, -0.0005, -0.0725, -0.0981,  0.0887, -0.0284, -0.0709, -0.0288,\n          0.0461, -0.0205, -0.0467,  0.0135,  0.0541,  0.0057,  0.0515, -0.0312,\n          0.0781, -0.0609,  0.0521, -0.0392, -0.0015, -0.0789, -0.0183,  0.0736,\n          0.0883, -0.0292, -0.0782,  0.0596, -0.0322,  0.0444,  0.0507,  0.0490,\n         -0.0487,  0.0543,  0.0083, -0.0547, -0.0808, -0.0036, -0.0346, -0.0261,\n          0.0131, -0.0779,  0.0485,  0.0568, -0.0042, -0.0461,  0.0915,  0.0866,\n         -0.0786, -0.0144, -0.0310, -0.0520, -0.0200, -0.0950, -0.0754,  0.0640,\n          0.0064, -0.0267, -0.0921, -0.0450],\n        [-0.0307, -0.0540,  0.0164,  0.0540, -0.0712, -0.0420, -0.0023,  0.0977,\n         -0.0610,  0.0496, -0.0879,  0.0931, -0.0506, -0.0310,  0.0519, -0.0702,\n          0.0966, -0.0085,  0.0874, -0.0177,  0.0426, -0.0991, -0.0806, -0.0024,\n         -0.0357, -0.0771, -0.0878, -0.0064, -0.0179,  0.0031, -0.0811, -0.0298,\n         -0.0136, -0.0141, -0.0471, -0.0733, -0.0587, -0.0064, -0.0949,  0.0063,\n          0.0751,  0.0175, -0.0146,  0.0332,  0.0716, -0.0214,  0.0835,  0.0603,\n         -0.0260,  0.0413,  0.0305, -0.0013,  0.0096,  0.0977,  0.0727,  0.0294,\n         -0.0228,  0.0801, -0.0681, -0.0245, -0.0296, -0.0037, -0.0035,  0.0592,\n          0.0695, -0.0642,  0.0106, -0.0823, -0.0181, -0.0151,  0.0171, -0.0270,\n         -0.0852,  0.0212,  0.0709, -0.0238, -0.0871,  0.0267, -0.0782,  0.0028,\n          0.0378,  0.0411, -0.0090, -0.0490, -0.0178,  0.0421, -0.0848,  0.0489,\n          0.0330, -0.0918,  0.0086, -0.0678,  0.0750,  0.0833,  0.0079,  0.0909,\n         -0.0005,  0.0162, -0.0838,  0.0768],\n        [-0.0197, -0.0767, -0.0964, -0.0135,  0.0020, -0.0503, -0.0179, -0.0125,\n          0.0542,  0.0119, -0.0465, -0.0197, -0.0581, -0.0826,  0.0450,  0.0986,\n         -0.0385,  0.0394, -0.0674, -0.0229, -0.0970,  0.0855, -0.0955, -0.0631,\n         -0.0963, -0.0310, -0.0957, -0.0253, -0.0720, -0.0131, -0.0065, -0.0707,\n          0.0244, -0.0256,  0.0929,  0.0069, -0.0424, -0.0219,  0.0855,  0.0059,\n         -0.0303,  0.0510, -0.0083, -0.0784, -0.0480, -0.0610,  0.0171,  0.0121,\n         -0.0950, -0.0500,  0.0181, -0.0310, -0.0986,  0.0919,  0.0660, -0.0380,\n         -0.0513,  0.0597,  0.0409,  0.0087,  0.0653, -0.0314, -0.0839, -0.0477,\n          0.0320, -0.0665,  0.0829, -0.0585,  0.0751, -0.0583,  0.0680, -0.0070,\n          0.0020,  0.0331,  0.0708, -0.0869, -0.0812, -0.0992,  0.0391, -0.0639,\n         -0.0575, -0.0312, -0.0611, -0.0789, -0.0439,  0.0878, -0.0558, -0.0136,\n          0.0193, -0.0067,  0.0044, -0.0252,  0.0067,  0.0753,  0.0701,  0.0303,\n         -0.0748, -0.0459, -0.0806,  0.0109],\n        [ 0.0741,  0.0756,  0.0794, -0.0039,  0.0099, -0.0367,  0.0349,  0.0014,\n         -0.0652,  0.0001, -0.0131,  0.0350,  0.0234, -0.0050, -0.0517, -0.0205,\n          0.0277, -0.0901,  0.0668, -0.0657, -0.0585, -0.0333, -0.0361, -0.0239,\n          0.0097, -0.0164, -0.0546, -0.0685, -0.0602, -0.0888, -0.0786,  0.0538,\n         -0.0749,  0.0332,  0.0822, -0.0047,  0.0739, -0.0432,  0.0441, -0.0380,\n         -0.0135, -0.0359, -0.0219, -0.0237, -0.0355, -0.0087,  0.0493,  0.0090,\n         -0.0252, -0.0379, -0.0913, -0.0013, -0.0863, -0.0373,  0.0703, -0.0280,\n         -0.0928, -0.0036, -0.0768,  0.0688, -0.0407,  0.0475, -0.0702, -0.0339,\n          0.0409,  0.0914,  0.0375,  0.0099,  0.0228, -0.0277,  0.0844, -0.0372,\n          0.0489,  0.0529,  0.0551, -0.0658,  0.0606, -0.0740, -0.0683,  0.0705,\n         -0.0497, -0.0048,  0.0409, -0.0469,  0.0992, -0.0588,  0.0566, -0.0852,\n         -0.0934, -0.0886,  0.0896, -0.0401, -0.0116, -0.0890,  0.0893, -0.0613,\n          0.0785, -0.0412,  0.0191,  0.0298],\n        [-0.0663, -0.0453,  0.0917, -0.0309, -0.0270, -0.0682, -0.0559, -0.0394,\n          0.0101, -0.0286,  0.0428, -0.0364,  0.0254, -0.0078,  0.0286, -0.0414,\n          0.0798, -0.0953, -0.0657,  0.0443,  0.0647, -0.0794, -0.0645, -0.0893,\n          0.0885, -0.0130, -0.0020, -0.0891, -0.0274,  0.0973, -0.0448, -0.0757,\n         -0.0857, -0.0160,  0.0924,  0.0913,  0.0573,  0.0061, -0.0455,  0.0659,\n         -0.0343,  0.0709, -0.0278,  0.0243,  0.0482, -0.0020,  0.0708,  0.0494,\n         -0.0551,  0.0730, -0.0083, -0.0082,  0.0742,  0.0533,  0.0360,  0.0170,\n          0.0413, -0.0090, -0.0607, -0.0934, -0.0498,  0.0406,  0.0079, -0.0221,\n         -0.0096,  0.0365,  0.0363, -0.0509,  0.0120, -0.0577, -0.0789, -0.0116,\n         -0.0188,  0.0664, -0.0125, -0.0117,  0.0536,  0.0079,  0.0431, -0.0877,\n         -0.0887,  0.0525, -0.0506,  0.0469, -0.0786, -0.0092, -0.0290,  0.0802,\n         -0.0362,  0.0485, -0.0478,  0.0055,  0.0626, -0.0234,  0.0850,  0.0286,\n         -0.0471,  0.0129,  0.0845,  0.0203],\n        [-0.0771, -0.0541,  0.0761, -0.0830, -0.0160,  0.0169,  0.0841,  0.0179,\n          0.0205,  0.0315,  0.0574,  0.0131,  0.0702, -0.0537, -0.0264,  0.0690,\n         -0.0378, -0.0318, -0.0019, -0.0639, -0.0963, -0.0743, -0.0886, -0.0677,\n         -0.0179, -0.0702, -0.0598, -0.0680, -0.0201,  0.0040, -0.0272, -0.0967,\n         -0.0348, -0.0851,  0.0341,  0.0664,  0.0173,  0.0109, -0.0476, -0.0708,\n         -0.0338, -0.0805, -0.0241,  0.0697, -0.0754,  0.0017, -0.0236, -0.0823,\n          0.0915, -0.0786, -0.0084, -0.0064,  0.0295, -0.0172, -0.0783, -0.0143,\n          0.0117,  0.0182, -0.0332, -0.0157,  0.0222, -0.0466,  0.0666, -0.0181,\n          0.0508,  0.0101, -0.0501,  0.0363, -0.0301,  0.0769,  0.0881, -0.0034,\n          0.0754, -0.0333,  0.0282,  0.0655,  0.0750,  0.0227,  0.0079, -0.0074,\n         -0.0782,  0.0701,  0.0687,  0.0495, -0.0324, -0.0457,  0.0657, -0.0936,\n         -0.0914, -0.0327, -0.0267,  0.0036, -0.0488,  0.0302,  0.0480, -0.0728,\n         -0.0065,  0.0524,  0.0182,  0.0163],\n        [-0.0837,  0.0887, -0.0170, -0.0438,  0.0730,  0.0750,  0.0982,  0.0231,\n          0.0509, -0.0638, -0.0635,  0.0338,  0.0809,  0.0382,  0.0046,  0.0841,\n         -0.0695,  0.0988,  0.0476, -0.0173, -0.0846,  0.0906,  0.0898, -0.0287,\n          0.0171, -0.0819, -0.0272, -0.0047,  0.0674, -0.0044,  0.0742, -0.0695,\n          0.0352,  0.0924,  0.0258, -0.0200, -0.0955, -0.0883,  0.0958, -0.0099,\n          0.0836, -0.0537,  0.0162, -0.0322, -0.0317,  0.0813,  0.0969, -0.0231,\n         -0.0459, -0.0497, -0.0251,  0.0410,  0.0148,  0.0411,  0.0057, -0.0812,\n          0.0705, -0.0805,  0.0925, -0.0731,  0.0586, -0.0198, -0.0972, -0.0824,\n          0.0384,  0.0897,  0.0104,  0.0504,  0.0434,  0.0883, -0.0229, -0.0414,\n          0.0505,  0.0649, -0.0294, -0.0388,  0.0353,  0.0290,  0.0062, -0.0392,\n         -0.0956, -0.0601,  0.0366,  0.0764,  0.0592,  0.0309, -0.0120,  0.0348,\n          0.0705,  0.0145,  0.0928,  0.0592, -0.0819,  0.0466,  0.0902,  0.0406,\n          0.0973, -0.0593, -0.0415,  0.0661]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0017,  0.0821, -0.0173,  0.0262,  0.0136, -0.0306, -0.0925, -0.0551],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0760, -0.2548, -0.1179, -0.2930,  0.2189,  0.2528, -0.0698, -0.1085],\n        [ 0.2765, -0.1230, -0.0594, -0.2404,  0.0091,  0.2113, -0.2937,  0.1121],\n        [ 0.1897, -0.3328,  0.0515, -0.0165, -0.1935,  0.2885, -0.1014, -0.0211],\n        [-0.2716, -0.0565, -0.1572,  0.0503,  0.2491,  0.0833, -0.2424, -0.2174]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2066,  0.2914, -0.3019, -0.0223], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x72cfc4091d10>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.999,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.002,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2674, -0.1914, -0.3450, -0.2305, -0.2891,  0.1276,  0.3155, -0.2941,\n         0.1443, -0.0762,  0.2673, -0.0918,  0.1915,  0.2525,  0.0163,  0.2348,\n        -0.1313, -0.2167,  0.1248,  0.2567, -0.0709, -0.3101,  0.1968, -0.1565,\n         0.1972,  0.1577,  0.1105, -0.2734, -0.2855,  0.1158, -0.2678, -0.0871,\n         0.0903, -0.2490, -0.1881,  0.0033,  0.0809, -0.2950, -0.0256,  0.1762,\n        -0.0517, -0.0223, -0.1848, -0.2163, -0.2935,  0.2976, -0.1196, -0.1600,\n        -0.3227, -0.3395,  0.1042,  0.0076,  0.1544,  0.0064,  0.1493, -0.0854,\n        -0.0554,  0.3186,  0.1803, -0.2613,  0.3040,  0.2381, -0.1773,  0.0544,\n         0.2956,  0.0298, -0.1592, -0.2516, -0.1336,  0.1816, -0.3259, -0.2053,\n         0.2877, -0.2788,  0.0075, -0.2170,  0.3473, -0.1406,  0.0226,  0.2992,\n         0.1067,  0.1438,  0.0594, -0.3034,  0.0609,  0.2568, -0.1685,  0.2624,\n        -0.1578, -0.1486, -0.0226,  0.3153,  0.0190, -0.1009, -0.2742, -0.3365,\n         0.2210, -0.1853, -0.0124, -0.2465], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-3.4697e-01,  3.7044e-02, -1.2115e-01,  3.5075e-01, -3.0165e-01,\n         -5.0181e-02, -3.1486e-01, -7.1445e-02],\n        [-1.7023e-01,  2.0395e-02,  1.5096e-01, -5.2793e-02,  1.0288e-02,\n         -8.4125e-02,  2.9095e-01,  3.4953e-01],\n        [ 2.9611e-01,  1.7308e-01, -2.4746e-01, -9.0663e-03,  3.5308e-01,\n         -1.5451e-02, -1.0378e-01, -3.3220e-01],\n        [ 7.3217e-02,  1.7666e-01,  5.7330e-02, -1.1978e-01,  2.0175e-02,\n          2.2353e-01,  1.1763e-01,  2.5276e-01],\n        [ 9.6785e-02, -1.7273e-01,  2.6886e-01, -7.9670e-02, -2.6020e-01,\n         -2.8293e-01,  3.4171e-01,  3.1726e-01],\n        [-8.8809e-03, -3.3676e-01, -1.4238e-01,  2.5992e-01, -1.3999e-01,\n         -1.1421e-01,  3.3401e-01,  3.2127e-01],\n        [ 8.9419e-02,  2.1889e-01,  2.2993e-01,  9.3243e-02, -1.1973e-01,\n          1.1854e-01, -2.9885e-01,  1.3375e-01],\n        [ 2.6245e-01,  3.3365e-01,  1.0697e-01, -2.1563e-01, -2.5660e-01,\n          2.6082e-01, -4.1335e-02,  1.3381e-01],\n        [ 1.9653e-01,  3.9683e-02, -1.3610e-01,  5.9347e-02,  3.2795e-01,\n         -2.6775e-01, -9.2962e-02, -1.7982e-01],\n        [-2.8077e-01, -1.2343e-01, -2.4749e-01,  1.2939e-01, -6.5056e-02,\n         -8.3026e-02, -1.4209e-01, -3.3266e-01],\n        [-4.0037e-02,  6.1226e-02, -7.1620e-02, -2.3897e-02,  3.0075e-01,\n          2.1566e-01,  3.1927e-01, -5.0386e-02],\n        [ 6.6453e-02,  1.5740e-01,  6.5109e-02, -1.2474e-01,  4.1955e-02,\n         -2.8994e-01, -2.1635e-01,  2.6108e-01],\n        [ 1.8877e-01, -1.5982e-01,  1.1827e-01, -9.0328e-02, -2.2346e-01,\n         -2.9567e-02,  8.9819e-02, -4.3210e-02],\n        [-3.0383e-01,  2.2106e-01, -3.0461e-03, -3.3098e-01,  3.9086e-02,\n          2.7247e-01, -3.1299e-01,  2.0291e-01],\n        [-1.5454e-01,  2.6533e-02,  1.7153e-01, -1.6702e-01, -2.8040e-01,\n         -3.3110e-01,  1.9102e-02, -1.0429e-01],\n        [-2.2111e-01,  1.8838e-01,  1.5163e-01,  4.5974e-02, -2.7516e-01,\n          1.1762e-01, -9.8528e-02, -2.9432e-01],\n        [ 1.5902e-02, -1.5538e-01, -1.8302e-01, -6.1603e-02,  2.6117e-01,\n          1.7540e-01,  9.6014e-02, -2.7428e-02],\n        [ 4.6555e-02, -7.1814e-02,  2.1058e-01, -1.0653e-01,  1.0555e-01,\n          2.1701e-01, -2.0076e-01, -1.2482e-02],\n        [ 6.7895e-02, -2.9797e-01, -2.5280e-01,  2.6350e-01, -7.8190e-02,\n         -2.1538e-01, -1.6459e-01, -1.1273e-01],\n        [ 2.3908e-03,  3.5188e-01, -2.5317e-01,  7.0407e-03, -1.1756e-01,\n         -5.7509e-02, -2.6532e-01, -1.1697e-01],\n        [-1.5387e-01,  3.2946e-01, -2.5487e-01, -3.0401e-01, -1.9772e-01,\n         -1.4152e-01,  1.8366e-02, -1.3386e-01],\n        [ 1.3989e-01,  5.7430e-02, -6.0499e-02,  9.0147e-02,  1.3009e-01,\n         -1.2314e-01,  3.5338e-01,  3.1835e-01],\n        [-5.1420e-02, -8.1513e-02, -6.2830e-02,  1.7436e-01, -1.5588e-01,\n         -1.3453e-02, -3.2808e-01,  1.1344e-01],\n        [ 7.7083e-02,  8.1005e-02, -2.2668e-03, -3.4269e-01, -2.4155e-01,\n         -1.2811e-01, -2.4200e-01, -5.5241e-02],\n        [-2.5120e-01,  1.6607e-03,  2.2704e-01, -2.8465e-01,  3.7032e-02,\n          3.1750e-01,  3.2511e-01,  1.1702e-01],\n        [ 5.4826e-02,  2.1977e-01,  3.0609e-01, -1.9104e-01, -2.9363e-01,\n         -1.2303e-01, -3.3197e-01, -1.8040e-01],\n        [-2.9360e-01,  3.3252e-01,  3.1737e-02,  7.8009e-03,  2.7588e-01,\n          3.3468e-02,  4.2502e-02,  1.0969e-01],\n        [-1.3476e-01, -1.9893e-01, -2.9448e-01,  1.2716e-01, -7.0296e-02,\n          3.7740e-03, -9.0898e-02, -3.3451e-01],\n        [ 1.4238e-01, -6.5139e-02,  2.4963e-01, -2.8249e-01, -1.9771e-01,\n         -3.1238e-01,  3.4915e-02, -5.6821e-02],\n        [-2.0725e-01,  3.4341e-01, -3.4748e-01, -3.3188e-01,  9.4574e-02,\n          3.2233e-01,  1.3117e-01, -3.7512e-02],\n        [ 1.9425e-01, -1.1051e-01, -4.3320e-02,  6.1507e-03,  1.5577e-01,\n          2.5020e-01, -1.6512e-02,  1.8801e-01],\n        [-2.5415e-01,  1.2701e-01, -7.2332e-02,  3.0672e-01,  1.3507e-01,\n         -1.2095e-01, -1.8783e-01, -3.1069e-01],\n        [ 1.2361e-01,  2.1960e-01, -2.2625e-01, -1.1883e-02,  3.2747e-01,\n         -3.4776e-01, -2.1303e-01, -2.0980e-01],\n        [ 6.2142e-02, -3.3259e-01,  1.9323e-01,  2.5491e-01,  2.7642e-01,\n         -2.6628e-01,  1.8363e-02,  3.2084e-01],\n        [-1.2746e-01,  5.3717e-02,  2.9265e-01, -3.0026e-01, -1.1093e-01,\n         -1.8498e-01,  2.3238e-02, -1.1347e-01],\n        [-3.9494e-02,  3.5349e-01,  1.6213e-02, -2.7230e-01, -1.2595e-01,\n         -1.1406e-01,  1.5779e-01,  6.5291e-02],\n        [ 1.4848e-01,  2.8244e-01, -5.7893e-02, -7.4058e-02, -8.4909e-02,\n          3.2041e-01,  2.4364e-01, -2.3783e-01],\n        [-3.3212e-01, -3.4235e-01,  3.9090e-02,  5.0792e-02, -2.4055e-01,\n         -3.9708e-02, -2.9985e-01,  1.0574e-01],\n        [ 1.1797e-01,  2.0934e-01, -7.9681e-02,  1.1982e-01,  6.2951e-02,\n         -1.4796e-01,  3.0687e-01,  3.0509e-01],\n        [ 3.4885e-01, -2.1712e-01, -1.6653e-01,  7.0048e-02,  2.3468e-02,\n          1.1410e-01,  2.7052e-01, -2.0007e-01],\n        [ 1.6810e-02,  2.3302e-01,  1.3482e-01, -2.9534e-01, -1.8714e-01,\n          1.8906e-01,  3.0978e-01, -1.5531e-01],\n        [ 2.9013e-01, -2.9807e-02,  2.3517e-01, -1.2316e-01,  1.3980e-01,\n         -2.0984e-01, -2.3941e-01, -2.4152e-01],\n        [ 3.2309e-01,  7.8619e-02,  2.8150e-01, -2.5773e-01, -3.0960e-01,\n         -3.4258e-01, -2.0708e-01,  3.2672e-01],\n        [-1.3002e-01, -2.8752e-01, -1.8735e-01,  2.9237e-01, -2.1531e-02,\n         -1.6315e-01,  2.8696e-01,  7.1761e-02],\n        [-4.7083e-02,  2.2614e-01,  2.8473e-01, -3.3917e-01,  1.8509e-01,\n          2.2133e-01, -3.5080e-01, -2.6915e-01],\n        [-2.7485e-01,  7.6637e-02, -3.1224e-01, -3.1490e-01, -8.7235e-02,\n          1.7798e-01,  6.6187e-02, -2.7436e-01],\n        [-3.1959e-01,  2.1235e-02,  3.3361e-01,  7.9465e-02,  2.4489e-01,\n         -1.3348e-01,  4.1193e-02, -3.0464e-01],\n        [-1.3196e-01,  1.7495e-01,  9.0112e-02,  3.4914e-01,  8.2159e-02,\n          3.1381e-01,  8.0525e-03,  1.9682e-02],\n        [-7.4916e-02, -1.8040e-01,  2.5853e-01, -1.0059e-01, -3.0217e-01,\n         -1.5515e-01,  3.3493e-01, -3.4911e-01],\n        [-2.8490e-01,  2.3080e-01,  1.1785e-01, -1.0175e-01,  3.4646e-01,\n         -3.1840e-01,  3.8918e-02, -3.0412e-01],\n        [ 1.9405e-01,  2.4066e-01,  2.5372e-01,  7.8141e-02,  1.5976e-02,\n         -2.1487e-01,  1.2200e-01, -8.9266e-03],\n        [ 2.9361e-01,  2.6221e-01, -1.7452e-01, -2.8064e-01,  1.5941e-01,\n          1.5860e-01, -1.4241e-01,  1.0925e-01],\n        [ 3.1851e-01,  1.0312e-01, -8.5148e-02, -2.4504e-01, -2.3905e-01,\n         -3.6391e-02,  2.2341e-01, -1.5271e-01],\n        [-2.8653e-01,  2.1957e-01,  2.6021e-01, -2.3619e-01, -2.2112e-01,\n         -2.8924e-02,  2.2104e-02,  1.6661e-01],\n        [ 3.1581e-04, -9.5845e-02, -1.6743e-01, -3.1964e-01, -2.6778e-01,\n         -6.1070e-03, -1.8443e-01,  2.7874e-01],\n        [ 2.5373e-01, -9.4435e-02, -2.2113e-01,  3.6833e-02,  2.1586e-01,\n         -9.8340e-02, -2.0537e-01,  1.2566e-01],\n        [-4.8592e-02,  4.4804e-02, -2.1853e-01, -1.4247e-01,  3.3605e-01,\n         -1.3641e-01,  3.0699e-01,  2.6908e-01],\n        [-1.2910e-01,  2.6333e-01, -2.5702e-01, -2.0304e-01,  1.3332e-01,\n          1.3932e-01, -3.5020e-02, -3.4148e-01],\n        [-2.1893e-01,  1.3848e-01,  1.2292e-01,  2.4036e-01,  1.8446e-01,\n         -3.5157e-01,  1.6989e-01, -2.9183e-01],\n        [-1.5580e-01,  2.8288e-01,  9.9384e-02, -6.7757e-02,  1.1876e-01,\n         -2.9103e-02, -3.2095e-01,  1.7970e-01],\n        [-3.0058e-01,  8.6065e-02, -8.6417e-02, -4.5517e-02, -7.5914e-02,\n         -3.4094e-01,  1.6804e-01,  2.1303e-02],\n        [ 2.4668e-01,  1.1984e-01,  1.4664e-01, -2.8919e-01, -2.9638e-01,\n          1.3125e-01, -3.4810e-01,  1.4778e-02],\n        [-2.3845e-01,  2.1636e-01, -9.7665e-02,  2.5515e-01,  3.3028e-01,\n         -1.2340e-01, -2.1718e-01,  3.1684e-01],\n        [-1.9529e-01,  1.8643e-01,  1.6013e-01, -2.7117e-01, -1.0787e-01,\n          4.0899e-02,  7.0940e-02,  3.0962e-01],\n        [ 2.7121e-01, -2.6465e-02,  1.0758e-02,  3.0206e-02, -1.5605e-01,\n         -1.2019e-01, -1.4527e-01,  1.5114e-01],\n        [-1.1370e-01, -1.8478e-01,  1.6490e-01,  1.8778e-01, -2.2456e-01,\n          5.5565e-02, -2.6652e-01, -2.4703e-01],\n        [ 6.9539e-02, -2.2221e-01,  2.1291e-01,  1.4273e-01, -2.4993e-01,\n         -2.8337e-01,  1.7828e-01,  2.7272e-01],\n        [ 1.9369e-01,  1.9283e-01,  3.9960e-03, -2.5837e-01,  2.2960e-01,\n          2.4696e-01, -4.5845e-02, -2.1522e-01],\n        [-8.4526e-02,  3.3779e-01, -3.5232e-01,  1.6533e-01,  2.5640e-03,\n         -2.1274e-01, -1.3917e-01, -1.7016e-01],\n        [-2.2155e-02,  2.4072e-01, -1.1422e-01,  3.2399e-01,  1.5848e-01,\n          3.1797e-01, -2.9934e-01, -1.0591e-01],\n        [-2.0164e-01, -1.5295e-01,  2.1909e-01,  2.8604e-01,  2.1670e-01,\n         -3.1323e-01, -1.2171e-01,  2.4602e-01],\n        [ 6.7740e-02,  2.6428e-01,  1.6001e-01, -1.7930e-01,  2.2798e-01,\n          1.6000e-01,  3.2854e-01, -7.7044e-02],\n        [ 1.1355e-01, -3.0888e-01,  2.3466e-01, -4.2261e-02,  2.1727e-01,\n         -2.1542e-01, -2.3996e-01, -2.3681e-01],\n        [-3.4898e-02, -7.0322e-02, -8.8665e-03,  3.9006e-03, -3.4879e-01,\n          2.4320e-01, -3.2890e-02, -2.8652e-01],\n        [-3.1469e-01,  5.6899e-02, -5.2118e-02, -1.7801e-01,  3.4603e-01,\n         -2.1193e-01, -1.1448e-01,  2.8764e-01],\n        [ 2.2184e-01,  2.2463e-01,  6.7947e-02, -1.6458e-02, -2.1504e-01,\n         -1.0862e-01, -2.6282e-01, -1.6203e-01],\n        [ 5.7061e-02,  2.8419e-01, -2.3065e-01,  1.7690e-01, -2.7459e-01,\n         -2.0173e-02, -2.6231e-01, -2.7621e-01],\n        [-1.0231e-01, -2.3183e-03,  3.5209e-02, -8.8898e-03,  1.5395e-01,\n         -1.5104e-01, -2.3917e-02, -2.5290e-01],\n        [ 1.6381e-01,  3.1700e-01, -3.1217e-01,  2.2292e-02,  2.7193e-01,\n         -2.1886e-01,  2.7231e-01, -1.9788e-01],\n        [ 2.4006e-01, -3.3509e-01, -2.8277e-01, -3.4267e-01,  2.1961e-01,\n         -2.3739e-01, -3.1990e-02, -1.0081e-01],\n        [ 2.8050e-01,  1.2355e-01,  1.2801e-01,  2.3527e-01,  1.5257e-02,\n          2.7750e-01, -1.4957e-01,  1.0864e-02],\n        [ 2.5038e-01,  3.1802e-01,  2.2806e-01, -1.9457e-01,  2.2164e-01,\n          3.1273e-01, -1.9783e-01, -8.7348e-02],\n        [-2.8801e-01,  1.4101e-01,  8.9484e-02,  2.9289e-01,  2.4734e-01,\n         -4.5117e-02,  2.5431e-01,  8.5788e-02],\n        [ 9.5125e-02, -2.0469e-01, -2.7595e-01,  3.5095e-02, -3.0044e-01,\n          1.2310e-01, -2.0401e-01, -3.5981e-02],\n        [ 3.1399e-01, -3.2397e-01, -3.4404e-01, -2.4986e-01,  2.3563e-01,\n          6.9915e-03,  1.8493e-01,  3.0908e-02],\n        [-1.2521e-01,  3.2420e-01,  2.3288e-01,  2.1255e-01, -3.1551e-01,\n         -2.6317e-01,  3.4491e-02, -8.5009e-02],\n        [-2.7710e-02, -1.5870e-01,  2.3066e-01, -2.7250e-01,  1.9138e-01,\n         -1.5769e-01, -1.5050e-02, -2.5585e-01],\n        [-2.6774e-01,  2.0443e-01,  1.8179e-01, -1.8743e-01, -4.8891e-02,\n         -2.2430e-01, -1.4802e-01,  9.3049e-02],\n        [-1.8174e-01, -1.0410e-02,  3.2421e-01,  1.8392e-01,  2.1403e-01,\n         -2.7873e-01,  1.7608e-02, -8.3369e-02],\n        [-2.5245e-02,  3.8044e-03, -1.1305e-01, -3.4012e-02,  1.4310e-01,\n         -2.2650e-02,  2.7753e-01,  2.6201e-01],\n        [ 8.0029e-02,  2.4224e-01, -1.4273e-01,  2.5974e-01,  1.7796e-01,\n          2.4223e-01,  1.7528e-01, -8.3654e-02],\n        [ 2.1198e-01, -2.4865e-01,  1.9433e-01, -2.9642e-01, -9.1574e-02,\n         -1.3445e-01, -1.5966e-01,  2.5544e-01],\n        [-1.0570e-02,  1.8667e-02,  1.5129e-01,  1.9932e-01,  1.0999e-01,\n         -2.2191e-01,  3.8527e-02,  6.1533e-02],\n        [-3.3824e-01,  1.3450e-01, -1.3429e-01,  1.3016e-01, -1.1997e-01,\n          2.3880e-01, -3.2458e-01, -2.8829e-01],\n        [ 6.8559e-02, -2.7136e-01,  3.4608e-01, -2.2885e-02, -8.8418e-02,\n          1.7533e-01,  2.1732e-01, -4.7901e-02],\n        [ 7.9267e-02,  1.5599e-01,  3.0707e-01,  1.4641e-01,  2.1876e-01,\n          1.3458e-01, -2.7234e-01, -2.3136e-01],\n        [-6.7231e-03,  8.6355e-02, -9.1269e-03, -2.2629e-01,  3.1728e-01,\n          3.1949e-01, -1.2788e-01, -6.6622e-02],\n        [ 2.6923e-01,  7.8814e-02, -2.5857e-01, -2.9915e-03, -2.4970e-01,\n         -2.0531e-01,  1.0232e-01, -9.9353e-02],\n        [-7.1855e-02,  2.1602e-01, -1.1718e-01,  3.2425e-01,  2.4106e-01,\n          5.0524e-02, -1.3921e-01,  1.8390e-01],\n        [ 4.1050e-02, -1.3491e-01, -3.0509e-01,  2.4194e-01,  1.3501e-01,\n         -3.9380e-03,  3.6891e-02, -1.1310e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0825, -0.0097,  0.0367,  0.0078,  0.0534, -0.0921,  0.0798, -0.0927,\n         0.0417, -0.0765,  0.0597,  0.0242, -0.0636,  0.0187, -0.0660, -0.0697,\n        -0.0588,  0.0922,  0.0464,  0.0645,  0.0608, -0.0664,  0.0764,  0.0075,\n        -0.0893,  0.0323, -0.0371,  0.0915,  0.0565,  0.0010,  0.0221,  0.0879,\n         0.0185, -0.0528,  0.0958, -0.0269, -0.0070, -0.0157,  0.0840, -0.0808,\n         0.0387, -0.0050,  0.0113,  0.0742, -0.0821, -0.0321, -0.0101, -0.0578,\n        -0.0193,  0.0242, -0.0239,  0.0302, -0.0553, -0.0079, -0.0740,  0.0233,\n         0.0655, -0.0237,  0.0732, -0.0322, -0.0469, -0.0171, -0.0960,  0.0569,\n        -0.0508,  0.0090, -0.0032,  0.0202,  0.0028,  0.0051, -0.0775,  0.0846,\n         0.0065,  0.0182, -0.0301, -0.0590, -0.0036, -0.0279,  0.0755, -0.0246,\n         0.0808,  0.0241, -0.0821,  0.0426, -0.0705, -0.0293, -0.0210,  0.0848,\n        -0.0352, -0.0686, -0.0737, -0.0560,  0.0962,  0.0297, -0.0891, -0.0934,\n        -0.0075,  0.0831, -0.0073,  0.0935], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0313, -0.0570, -0.0359,  ...,  0.0663,  0.0846, -0.0949],\n        [-0.0780, -0.0700,  0.0758,  ...,  0.0604, -0.0463, -0.0934],\n        [ 0.0268, -0.0519,  0.0100,  ..., -0.0046, -0.0371,  0.0861],\n        ...,\n        [ 0.0789, -0.0155, -0.0303,  ..., -0.0921,  0.0172,  0.0315],\n        [-0.0346,  0.0090,  0.0270,  ..., -0.0912,  0.0634,  0.0895],\n        [-0.0110,  0.0525, -0.0365,  ...,  0.0775,  0.0262,  0.0310]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0017,  0.0821, -0.0173,  0.0262,  0.0136, -0.0306, -0.0925, -0.0551],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0554, -0.0781, -0.0421, -0.0691,  0.0608,  0.0678, -0.0038, -0.0714,\n          0.0338,  0.0273, -0.0654, -0.0571,  0.0606,  0.0078,  0.0712, -0.0674,\n          0.0982,  0.0561,  0.0050, -0.0017,  0.0417, -0.0379,  0.0239, -0.0790,\n          0.0056, -0.0860,  0.0015, -0.0827, -0.0829,  0.0085, -0.0605,  0.0239,\n          0.0514,  0.0840, -0.0022, -0.0771, -0.0395,  0.0020, -0.0158, -0.0122,\n          0.0460, -0.0551, -0.0926, -0.0120,  0.0846, -0.0857, -0.0208,  0.0074,\n         -0.0448,  0.0988, -0.0096, -0.0482,  0.0608,  0.0888, -0.0391,  0.0029,\n          0.0505, -0.0323,  0.0222, -0.0688,  0.0777,  0.0742, -0.0980,  0.0551,\n          0.0939, -0.0884, -0.0312,  0.0204,  0.0462, -0.0915,  0.0209, -0.0392,\n         -0.0654, -0.0344, -0.0489,  0.0731, -0.0975, -0.0087,  0.0749,  0.0342,\n         -0.0181,  0.0796, -0.0876,  0.0509,  0.0308, -0.0276, -0.0514,  0.0604,\n         -0.0230, -0.0144,  0.0116,  0.0902, -0.0882,  0.0744, -0.0509,  0.0014,\n         -0.0815, -0.0443,  0.0002,  0.0497],\n        [ 0.0253,  0.0884,  0.0431, -0.0099, -0.0344,  0.0211, -0.0459, -0.0108,\n          0.0850,  0.0332, -0.0913,  0.0744,  0.0671,  0.0975, -0.0784, -0.0819,\n          0.0967,  0.0100, -0.0957,  0.0688, -0.0300, -0.0510, -0.0071,  0.0531,\n          0.0053,  0.0103, -0.0819,  0.0588,  0.0146, -0.0435, -0.0789, -0.0363,\n         -0.0044, -0.0721, -0.0772, -0.0783, -0.0421,  0.0646, -0.0717,  0.0364,\n          0.0551, -0.0005, -0.0725, -0.0981,  0.0887, -0.0284, -0.0709, -0.0288,\n          0.0461, -0.0205, -0.0467,  0.0135,  0.0541,  0.0057,  0.0515, -0.0312,\n          0.0781, -0.0609,  0.0521, -0.0392, -0.0015, -0.0789, -0.0183,  0.0736,\n          0.0883, -0.0292, -0.0782,  0.0596, -0.0322,  0.0444,  0.0507,  0.0490,\n         -0.0487,  0.0543,  0.0083, -0.0547, -0.0808, -0.0036, -0.0346, -0.0261,\n          0.0131, -0.0779,  0.0485,  0.0568, -0.0042, -0.0461,  0.0915,  0.0866,\n         -0.0786, -0.0144, -0.0310, -0.0520, -0.0200, -0.0950, -0.0754,  0.0640,\n          0.0064, -0.0267, -0.0921, -0.0450],\n        [-0.0307, -0.0540,  0.0164,  0.0540, -0.0712, -0.0420, -0.0023,  0.0977,\n         -0.0610,  0.0496, -0.0879,  0.0931, -0.0506, -0.0310,  0.0519, -0.0702,\n          0.0966, -0.0085,  0.0874, -0.0177,  0.0426, -0.0991, -0.0806, -0.0024,\n         -0.0357, -0.0771, -0.0878, -0.0064, -0.0179,  0.0031, -0.0811, -0.0298,\n         -0.0136, -0.0141, -0.0471, -0.0733, -0.0587, -0.0064, -0.0949,  0.0063,\n          0.0751,  0.0175, -0.0146,  0.0332,  0.0716, -0.0214,  0.0835,  0.0603,\n         -0.0260,  0.0413,  0.0305, -0.0013,  0.0096,  0.0977,  0.0727,  0.0294,\n         -0.0228,  0.0801, -0.0681, -0.0245, -0.0296, -0.0037, -0.0035,  0.0592,\n          0.0695, -0.0642,  0.0106, -0.0823, -0.0181, -0.0151,  0.0171, -0.0270,\n         -0.0852,  0.0212,  0.0709, -0.0238, -0.0871,  0.0267, -0.0782,  0.0028,\n          0.0378,  0.0411, -0.0090, -0.0490, -0.0178,  0.0421, -0.0848,  0.0489,\n          0.0330, -0.0918,  0.0086, -0.0678,  0.0750,  0.0833,  0.0079,  0.0909,\n         -0.0005,  0.0162, -0.0838,  0.0768],\n        [-0.0197, -0.0767, -0.0964, -0.0135,  0.0020, -0.0503, -0.0179, -0.0125,\n          0.0542,  0.0119, -0.0465, -0.0197, -0.0581, -0.0826,  0.0450,  0.0986,\n         -0.0385,  0.0394, -0.0674, -0.0229, -0.0970,  0.0855, -0.0955, -0.0631,\n         -0.0963, -0.0310, -0.0957, -0.0253, -0.0720, -0.0131, -0.0065, -0.0707,\n          0.0244, -0.0256,  0.0929,  0.0069, -0.0424, -0.0219,  0.0855,  0.0059,\n         -0.0303,  0.0510, -0.0083, -0.0784, -0.0480, -0.0610,  0.0171,  0.0121,\n         -0.0950, -0.0500,  0.0181, -0.0310, -0.0986,  0.0919,  0.0660, -0.0380,\n         -0.0513,  0.0597,  0.0409,  0.0087,  0.0653, -0.0314, -0.0839, -0.0477,\n          0.0320, -0.0665,  0.0829, -0.0585,  0.0751, -0.0583,  0.0680, -0.0070,\n          0.0020,  0.0331,  0.0708, -0.0869, -0.0812, -0.0992,  0.0391, -0.0639,\n         -0.0575, -0.0312, -0.0611, -0.0789, -0.0439,  0.0878, -0.0558, -0.0136,\n          0.0193, -0.0067,  0.0044, -0.0252,  0.0067,  0.0753,  0.0701,  0.0303,\n         -0.0748, -0.0459, -0.0806,  0.0109],\n        [ 0.0741,  0.0756,  0.0794, -0.0039,  0.0099, -0.0367,  0.0349,  0.0014,\n         -0.0652,  0.0001, -0.0131,  0.0350,  0.0234, -0.0050, -0.0517, -0.0205,\n          0.0277, -0.0901,  0.0668, -0.0657, -0.0585, -0.0333, -0.0361, -0.0239,\n          0.0097, -0.0164, -0.0546, -0.0685, -0.0602, -0.0888, -0.0786,  0.0538,\n         -0.0749,  0.0332,  0.0822, -0.0047,  0.0739, -0.0432,  0.0441, -0.0380,\n         -0.0135, -0.0359, -0.0219, -0.0237, -0.0355, -0.0087,  0.0493,  0.0090,\n         -0.0252, -0.0379, -0.0913, -0.0013, -0.0863, -0.0373,  0.0703, -0.0280,\n         -0.0928, -0.0036, -0.0768,  0.0688, -0.0407,  0.0475, -0.0702, -0.0339,\n          0.0409,  0.0914,  0.0375,  0.0099,  0.0228, -0.0277,  0.0844, -0.0372,\n          0.0489,  0.0529,  0.0551, -0.0658,  0.0606, -0.0740, -0.0683,  0.0705,\n         -0.0497, -0.0048,  0.0409, -0.0469,  0.0992, -0.0588,  0.0566, -0.0852,\n         -0.0934, -0.0886,  0.0896, -0.0401, -0.0116, -0.0890,  0.0893, -0.0613,\n          0.0785, -0.0412,  0.0191,  0.0298],\n        [-0.0663, -0.0453,  0.0917, -0.0309, -0.0270, -0.0682, -0.0559, -0.0394,\n          0.0101, -0.0286,  0.0428, -0.0364,  0.0254, -0.0078,  0.0286, -0.0414,\n          0.0798, -0.0953, -0.0657,  0.0443,  0.0647, -0.0794, -0.0645, -0.0893,\n          0.0885, -0.0130, -0.0020, -0.0891, -0.0274,  0.0973, -0.0448, -0.0757,\n         -0.0857, -0.0160,  0.0924,  0.0913,  0.0573,  0.0061, -0.0455,  0.0659,\n         -0.0343,  0.0709, -0.0278,  0.0243,  0.0482, -0.0020,  0.0708,  0.0494,\n         -0.0551,  0.0730, -0.0083, -0.0082,  0.0742,  0.0533,  0.0360,  0.0170,\n          0.0413, -0.0090, -0.0607, -0.0934, -0.0498,  0.0406,  0.0079, -0.0221,\n         -0.0096,  0.0365,  0.0363, -0.0509,  0.0120, -0.0577, -0.0789, -0.0116,\n         -0.0188,  0.0664, -0.0125, -0.0117,  0.0536,  0.0079,  0.0431, -0.0877,\n         -0.0887,  0.0525, -0.0506,  0.0469, -0.0786, -0.0092, -0.0290,  0.0802,\n         -0.0362,  0.0485, -0.0478,  0.0055,  0.0626, -0.0234,  0.0850,  0.0286,\n         -0.0471,  0.0129,  0.0845,  0.0203],\n        [-0.0771, -0.0541,  0.0761, -0.0830, -0.0160,  0.0169,  0.0841,  0.0179,\n          0.0205,  0.0315,  0.0574,  0.0131,  0.0702, -0.0537, -0.0264,  0.0690,\n         -0.0378, -0.0318, -0.0019, -0.0639, -0.0963, -0.0743, -0.0886, -0.0677,\n         -0.0179, -0.0702, -0.0598, -0.0680, -0.0201,  0.0040, -0.0272, -0.0967,\n         -0.0348, -0.0851,  0.0341,  0.0664,  0.0173,  0.0109, -0.0476, -0.0708,\n         -0.0338, -0.0805, -0.0241,  0.0697, -0.0754,  0.0017, -0.0236, -0.0823,\n          0.0915, -0.0786, -0.0084, -0.0064,  0.0295, -0.0172, -0.0783, -0.0143,\n          0.0117,  0.0182, -0.0332, -0.0157,  0.0222, -0.0466,  0.0666, -0.0181,\n          0.0508,  0.0101, -0.0501,  0.0363, -0.0301,  0.0769,  0.0881, -0.0034,\n          0.0754, -0.0333,  0.0282,  0.0655,  0.0750,  0.0227,  0.0079, -0.0074,\n         -0.0782,  0.0701,  0.0687,  0.0495, -0.0324, -0.0457,  0.0657, -0.0936,\n         -0.0914, -0.0327, -0.0267,  0.0036, -0.0488,  0.0302,  0.0480, -0.0728,\n         -0.0065,  0.0524,  0.0182,  0.0163],\n        [-0.0837,  0.0887, -0.0170, -0.0438,  0.0730,  0.0750,  0.0982,  0.0231,\n          0.0509, -0.0638, -0.0635,  0.0338,  0.0809,  0.0382,  0.0046,  0.0841,\n         -0.0695,  0.0988,  0.0476, -0.0173, -0.0846,  0.0906,  0.0898, -0.0287,\n          0.0171, -0.0819, -0.0272, -0.0047,  0.0674, -0.0044,  0.0742, -0.0695,\n          0.0352,  0.0924,  0.0258, -0.0200, -0.0955, -0.0883,  0.0958, -0.0099,\n          0.0836, -0.0537,  0.0162, -0.0322, -0.0317,  0.0813,  0.0969, -0.0231,\n         -0.0459, -0.0497, -0.0251,  0.0410,  0.0148,  0.0411,  0.0057, -0.0812,\n          0.0705, -0.0805,  0.0925, -0.0731,  0.0586, -0.0198, -0.0972, -0.0824,\n          0.0384,  0.0897,  0.0104,  0.0504,  0.0434,  0.0883, -0.0229, -0.0414,\n          0.0505,  0.0649, -0.0294, -0.0388,  0.0353,  0.0290,  0.0062, -0.0392,\n         -0.0956, -0.0601,  0.0366,  0.0764,  0.0592,  0.0309, -0.0120,  0.0348,\n          0.0705,  0.0145,  0.0928,  0.0592, -0.0819,  0.0466,  0.0902,  0.0406,\n          0.0973, -0.0593, -0.0415,  0.0661]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2066,  0.2914, -0.3019, -0.0223], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0760, -0.2548, -0.1179, -0.2930,  0.2189,  0.2528, -0.0698, -0.1085],\n        [ 0.2765, -0.1230, -0.0594, -0.2404,  0.0091,  0.2113, -0.2937,  0.1121],\n        [ 0.1897, -0.3328,  0.0515, -0.0165, -0.1935,  0.2885, -0.1014, -0.0211],\n        [-0.2716, -0.0565, -0.1572,  0.0503,  0.2491,  0.0833, -0.2424, -0.2174]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x72cfc03bcf50>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s406970000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s406970000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}