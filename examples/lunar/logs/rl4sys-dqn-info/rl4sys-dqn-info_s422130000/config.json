{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.15,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s422130000"
    },
    "q_lr":	0.003,
    "seed":	422130000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x73a92567dcd0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.15,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1983,  0.1963,  0.2181, -0.0633,  0.3252, -0.2442,  0.0586, -0.1999,\n         0.2604,  0.1868, -0.2714,  0.0826, -0.1372,  0.3066,  0.1519,  0.0898,\n        -0.0228,  0.1100, -0.2561, -0.1552,  0.3410, -0.3045,  0.0473, -0.1568,\n         0.0845,  0.0739,  0.0944, -0.1709, -0.3361, -0.0710, -0.0838,  0.1108],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1368, -0.1583, -0.3074,  0.1224, -0.3291,  0.2488, -0.1892,  0.2742],\n        [ 0.2243, -0.0126, -0.0766, -0.2036, -0.3388,  0.2513, -0.0895, -0.0897],\n        [-0.0120, -0.2259, -0.1893, -0.3511,  0.2049, -0.0552,  0.3130,  0.0072],\n        [ 0.3142,  0.1067, -0.1623,  0.1075, -0.2961,  0.2439,  0.1210, -0.2089],\n        [-0.0240, -0.1917,  0.1901, -0.2928,  0.2388,  0.1820,  0.3502, -0.0305],\n        [-0.3477,  0.2020,  0.2564, -0.0491,  0.0569, -0.0920,  0.1461,  0.1619],\n        [ 0.1215, -0.3288, -0.2201, -0.2714, -0.0430, -0.0375, -0.0848,  0.0769],\n        [ 0.2908,  0.3381, -0.2917,  0.3068,  0.2512, -0.0383,  0.1073, -0.0091],\n        [ 0.0531,  0.3515, -0.2050, -0.0217,  0.2476,  0.1826, -0.0866, -0.1014],\n        [ 0.1200, -0.2482, -0.0122,  0.2810,  0.0567, -0.1963,  0.0433, -0.1205],\n        [ 0.0891,  0.2942, -0.0856,  0.0323, -0.1919,  0.1965, -0.2618,  0.3038],\n        [ 0.2868,  0.0368,  0.1988, -0.1955,  0.1564, -0.2770,  0.1259, -0.2109],\n        [-0.0059, -0.0162,  0.2276,  0.1381, -0.1436, -0.2959, -0.0657, -0.2803],\n        [-0.3167, -0.0495, -0.2690,  0.0283, -0.0621, -0.0920, -0.0652, -0.2998],\n        [-0.1518, -0.0344, -0.0400,  0.1835,  0.3523, -0.1398, -0.1489, -0.1988],\n        [ 0.2260,  0.2280, -0.0165, -0.2532, -0.0078,  0.2438, -0.2584,  0.0110],\n        [-0.0504, -0.3228,  0.2914,  0.0604, -0.1493, -0.1964,  0.2408, -0.2948],\n        [ 0.0659,  0.0611, -0.2412,  0.2171, -0.2716, -0.0512, -0.3012, -0.0231],\n        [-0.0307, -0.2636,  0.0171, -0.2373, -0.0342, -0.2827,  0.2611,  0.1555],\n        [-0.0993, -0.1818, -0.0280, -0.1249, -0.3212,  0.1473, -0.2082,  0.1015],\n        [-0.1813,  0.0109, -0.0127, -0.3194, -0.2781, -0.0357,  0.3010,  0.0541],\n        [ 0.1148,  0.0683, -0.0189,  0.0588,  0.1810,  0.1337, -0.2481,  0.0422],\n        [ 0.2917,  0.1630,  0.2415,  0.3228,  0.1358,  0.1538, -0.1771,  0.2737],\n        [-0.3523, -0.2000, -0.3094,  0.2202,  0.1693,  0.0892, -0.1715,  0.1126],\n        [ 0.1526,  0.0658,  0.1121,  0.2329,  0.2779, -0.3372,  0.2355, -0.1600],\n        [ 0.1776, -0.2264,  0.1093,  0.0791, -0.0939, -0.1458, -0.2792, -0.1995],\n        [-0.0313, -0.2110,  0.1225,  0.2792, -0.1696, -0.1052, -0.1840,  0.0904],\n        [-0.2484,  0.0992,  0.3079, -0.0358, -0.2840, -0.0576,  0.2890,  0.2746],\n        [ 0.2178,  0.2784,  0.1792,  0.1438,  0.1489, -0.1056,  0.2981, -0.2340],\n        [-0.3141, -0.0270,  0.2298,  0.2141,  0.1582, -0.3030,  0.2555,  0.1406],\n        [-0.1099,  0.3372,  0.2521,  0.0924,  0.0421,  0.0642, -0.2379,  0.0043],\n        [-0.3496, -0.0517, -0.3265,  0.1908, -0.1839,  0.2242,  0.1684, -0.1227]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0975,  0.0009,  0.0119,  0.0100, -0.0047,  0.1270,  0.1049, -0.1759,\n         0.1290,  0.0459,  0.1152,  0.1572, -0.1187, -0.0984,  0.0323,  0.0325],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.7119e-01, -1.0331e-01,  1.6485e-01, -1.1380e-01,  1.6900e-01,\n         -5.8129e-02,  1.4365e-02,  1.5048e-01, -8.9872e-02, -3.7528e-02,\n         -1.3737e-01,  1.2825e-04,  1.2431e-01, -1.5879e-01, -1.0745e-01,\n         -4.1308e-02, -1.5831e-01, -3.4698e-03, -8.3827e-02, -2.7715e-02,\n         -5.6222e-02, -3.9718e-02,  1.2874e-01, -2.5753e-02, -4.1925e-02,\n         -1.3310e-01,  1.2990e-01, -4.1683e-02, -6.7250e-02,  1.6142e-02,\n          1.7308e-01,  6.5294e-02],\n        [ 5.3289e-02,  1.6221e-02,  1.3688e-01, -7.4019e-02, -5.3468e-02,\n         -1.5345e-01, -1.5532e-01,  1.4658e-01,  1.4675e-01,  1.0240e-01,\n         -4.4721e-02,  8.8815e-02, -7.5223e-02, -1.0718e-02,  1.0917e-01,\n          1.1481e-01,  7.5195e-02,  9.3881e-02,  8.8454e-02,  2.9084e-02,\n         -2.2217e-02,  3.3932e-02,  3.5179e-02,  7.2538e-02, -1.7267e-01,\n         -1.7523e-01, -8.4467e-02, -1.7407e-01,  1.9294e-02,  2.3356e-02,\n          1.6145e-01,  6.5534e-02],\n        [-4.5500e-02, -2.9423e-03, -6.4124e-02, -1.6813e-01, -1.3237e-01,\n         -2.0836e-02,  1.5800e-01, -4.5736e-02,  8.0793e-02, -1.5373e-01,\n          2.6747e-02,  5.5758e-02, -1.6813e-01,  1.5299e-01, -1.5858e-01,\n         -1.1976e-01,  1.5216e-01, -4.6390e-02, -3.4773e-02,  1.3775e-02,\n         -4.9708e-02, -5.3840e-02, -1.9565e-02, -1.5066e-01, -1.0185e-01,\n         -5.1132e-02, -1.6967e-01, -4.7009e-02,  1.0126e-01, -4.2788e-03,\n         -8.7881e-02, -5.6308e-02],\n        [ 7.4352e-02,  7.3097e-02, -1.6158e-01,  1.4876e-01, -2.1917e-02,\n          1.0592e-01, -3.1417e-03,  1.4543e-01, -1.1605e-01, -1.0345e-01,\n         -3.4566e-02, -1.0310e-01,  1.4979e-01, -1.6489e-01,  1.6366e-01,\n         -5.7291e-02, -7.8470e-02,  1.1808e-01,  1.1460e-01,  1.4725e-01,\n          4.9913e-02,  1.1306e-01, -1.9306e-02,  1.0541e-01,  1.3272e-01,\n         -1.2202e-01, -1.6500e-01, -3.1695e-02,  1.7188e-01, -7.2561e-03,\n         -6.1494e-02,  8.6384e-02],\n        [-9.5578e-02, -1.0440e-02,  1.1270e-01,  5.1168e-02,  9.6985e-02,\n          1.3985e-01,  4.7252e-02, -6.4342e-03, -1.2725e-01,  1.7192e-01,\n         -1.1386e-01,  7.3515e-02,  2.1891e-02, -1.0534e-01, -5.1123e-02,\n         -1.1772e-01, -4.2875e-02, -1.0462e-01,  1.1469e-01,  9.1932e-02,\n          5.0946e-02,  1.7460e-01,  1.7016e-01,  5.5475e-02,  1.4863e-01,\n          2.0707e-02, -1.7067e-01,  1.2519e-01,  6.2377e-02,  2.1063e-02,\n         -6.2741e-02,  1.7545e-01],\n        [-9.0051e-02, -6.2792e-02, -7.6244e-02, -6.1440e-02, -1.7134e-01,\n          1.9250e-02, -8.1455e-02,  1.7622e-01, -4.6596e-02, -1.1104e-02,\n         -5.0655e-03,  7.3715e-02, -9.8616e-03,  7.2997e-02, -1.5950e-01,\n         -6.1927e-02, -6.2004e-02, -1.0391e-01, -2.0202e-02, -9.7971e-02,\n         -4.9891e-02,  1.7231e-01,  1.6434e-01, -1.4694e-01, -1.5687e-01,\n          7.4669e-02, -1.7481e-01, -1.4294e-01, -6.4961e-02, -6.2057e-02,\n          1.5579e-01, -6.3189e-03],\n        [ 8.6642e-02, -1.6819e-02, -1.6383e-02, -5.4198e-02, -1.6402e-01,\n         -5.8833e-02,  9.0374e-02,  9.3486e-02, -1.7225e-01, -1.7596e-01,\n          9.7998e-02, -5.9716e-02, -3.5718e-02, -5.1948e-02,  1.0930e-01,\n         -9.1390e-03,  1.0491e-01,  1.1681e-01, -2.0267e-02,  2.9706e-02,\n          1.3287e-01,  3.2196e-02,  1.4298e-01,  8.2337e-02, -8.0416e-02,\n          2.7013e-02,  1.6950e-01,  1.3649e-01,  1.6897e-01,  6.3101e-03,\n         -1.7623e-01,  1.6236e-01],\n        [ 4.4583e-02, -1.1256e-01,  1.5917e-01, -3.6731e-02,  2.7712e-02,\n          6.7257e-03,  5.2780e-02, -1.6632e-01, -1.0742e-01, -1.1642e-01,\n          1.5273e-01, -6.8879e-02,  1.5682e-01,  2.2065e-02,  1.2779e-01,\n         -2.4801e-02,  6.9429e-02,  1.2403e-01, -8.5319e-02,  7.2372e-02,\n         -6.6496e-02,  1.1814e-01,  6.5856e-02, -6.2429e-03, -1.4136e-01,\n          5.6034e-02,  1.1905e-02, -1.0623e-01, -1.1986e-01, -9.3882e-02,\n         -1.4153e-01, -7.5564e-02],\n        [ 6.5965e-02,  3.2774e-02, -1.3624e-01, -1.2823e-01,  3.8435e-02,\n          5.3479e-02, -2.6772e-02,  6.0949e-02, -1.6339e-01, -7.4022e-02,\n         -1.1703e-01, -2.4161e-02,  2.2817e-03, -7.2965e-02,  1.7352e-01,\n          5.1516e-02,  5.6743e-02,  5.8147e-02,  1.6107e-01,  1.2667e-01,\n          9.0820e-02,  6.1631e-02,  7.7640e-02,  1.2978e-01,  1.0008e-01,\n          6.5551e-02,  1.1644e-01,  1.5695e-01, -6.9093e-02,  9.3514e-02,\n          1.6598e-01,  9.8402e-02],\n        [ 1.6416e-01, -1.2082e-01, -1.3604e-01, -3.2407e-02,  1.0535e-02,\n          1.1520e-01, -5.3580e-02,  7.3843e-02, -1.5987e-01,  1.3237e-01,\n          4.3526e-02,  1.4762e-01, -1.7500e-01, -9.9946e-02,  1.6763e-01,\n          1.6064e-02, -1.4925e-01,  1.0588e-02, -1.2311e-01, -1.0488e-01,\n         -7.9273e-02,  1.3450e-01, -1.2306e-01, -1.1589e-01,  8.9918e-02,\n          2.8481e-02,  1.2379e-01, -1.2233e-01,  1.2914e-01,  1.3978e-01,\n         -1.6445e-01,  1.0863e-01],\n        [ 2.4687e-02,  1.7303e-01,  1.5924e-01, -1.3399e-01,  1.0499e-01,\n          3.2050e-02, -5.9935e-02, -1.5772e-01,  7.1134e-02,  2.8767e-02,\n         -6.9536e-02,  1.1283e-01,  1.6979e-01, -4.3028e-02,  8.6632e-02,\n         -4.5533e-02,  1.4476e-02, -1.7230e-01,  1.4414e-01, -1.3365e-02,\n          7.4996e-02,  1.1670e-01,  4.6157e-02,  1.7392e-01,  9.7901e-02,\n         -1.3557e-01, -2.0095e-02,  1.0780e-01, -3.8025e-02, -2.9424e-02,\n         -9.8817e-02,  8.5811e-02],\n        [ 5.0523e-02,  1.5848e-01,  1.4900e-01, -4.2484e-02, -3.9262e-02,\n         -8.9524e-02, -2.8017e-02, -1.0619e-01, -4.3798e-02,  4.5912e-02,\n          1.2149e-01,  8.0271e-02,  9.6169e-02,  1.2027e-01,  2.5514e-02,\n          8.2754e-02, -1.3193e-01,  5.7062e-02,  2.9202e-02, -4.8415e-02,\n          7.4760e-02, -1.5183e-01,  9.8830e-02,  6.3117e-02, -1.4092e-01,\n          1.7175e-01,  1.4846e-01, -9.4582e-02, -9.1063e-02,  1.7323e-02,\n          2.5400e-02, -3.8283e-02],\n        [ 1.4764e-02,  1.5484e-01, -6.0860e-02, -9.1821e-02, -1.4063e-01,\n         -1.0448e-01, -1.0528e-01, -6.5286e-02, -1.2709e-01, -7.7990e-02,\n         -8.8477e-02, -1.1540e-01, -1.1379e-01, -7.2040e-02,  1.6900e-01,\n          8.1698e-03, -1.5875e-01,  1.4789e-01,  3.4280e-02, -6.7613e-03,\n          1.1643e-01,  7.8767e-02, -2.2670e-02, -7.5606e-02,  1.4892e-02,\n         -5.2950e-02,  7.2556e-02, -7.1549e-02, -1.3396e-01, -5.3128e-02,\n         -4.6786e-02, -7.5330e-02],\n        [ 8.5674e-02,  4.2263e-02, -1.6273e-02, -1.5033e-01, -7.7003e-02,\n         -1.3442e-01, -4.6091e-02,  8.4301e-02,  8.4942e-02,  9.4527e-02,\n          1.0007e-01,  6.7402e-02,  1.4664e-03, -5.6707e-02, -1.5396e-01,\n          9.9798e-02, -3.8288e-02, -1.4166e-01, -1.4113e-01, -1.3914e-01,\n          7.2835e-02, -1.0104e-01,  7.6178e-02, -1.6263e-01,  9.2809e-02,\n         -3.6425e-02, -1.0341e-01, -4.5064e-02,  1.9761e-02,  8.1520e-02,\n          1.3608e-01, -7.2467e-02],\n        [ 5.1423e-02,  1.5259e-01,  4.5631e-02, -4.6097e-03, -1.2425e-01,\n          1.4105e-01, -1.6364e-02, -2.1044e-02,  8.3701e-02, -6.1250e-02,\n          1.7081e-01,  2.1578e-02,  7.9669e-02,  9.3666e-02, -1.5951e-01,\n          9.0571e-02,  1.7057e-01,  2.1978e-02,  1.1809e-01, -4.8230e-02,\n         -2.7246e-02,  2.2902e-02,  3.7296e-02,  8.1399e-02, -8.0587e-02,\n          7.3746e-02, -1.7671e-01, -1.3566e-01,  1.5308e-01,  8.1894e-02,\n          2.2031e-02, -1.4794e-01],\n        [ 9.2269e-02,  1.4156e-01, -8.5579e-02, -1.2824e-01,  1.1703e-01,\n         -7.4234e-02, -3.9817e-02, -1.0460e-01, -9.1631e-02,  2.5465e-02,\n         -1.5668e-01,  7.6526e-02, -1.1739e-01, -1.6313e-01, -5.2938e-02,\n         -7.0213e-02, -1.6645e-01,  1.5570e-01,  6.0278e-03,  6.2479e-02,\n         -1.1810e-02,  1.5934e-02,  1.0559e-01, -1.2844e-01, -5.6755e-02,\n         -2.8374e-03, -1.0888e-01,  1.7579e-01, -2.1413e-02,  5.2184e-02,\n         -9.5474e-02,  1.0879e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0535, -0.0583,  0.0949,  0.1989,  0.0858,  0.1606, -0.0019,  0.0092],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2194,  0.0055, -0.1273,  0.1409,  0.0741,  0.1142,  0.1874, -0.2214,\n          0.1412,  0.2316, -0.0806, -0.0820,  0.0633, -0.0426,  0.1417, -0.1463],\n        [-0.1018, -0.1632,  0.0887, -0.2225,  0.1623, -0.0988,  0.0580,  0.0675,\n         -0.0756,  0.1910,  0.2204,  0.2434,  0.1147,  0.1370,  0.2031,  0.1079],\n        [ 0.0749,  0.1566,  0.2008, -0.1904, -0.0270, -0.0043,  0.2158,  0.0512,\n          0.2131,  0.0779, -0.1477, -0.1779, -0.1159,  0.0511,  0.2144,  0.2370],\n        [ 0.0240,  0.0615, -0.0329, -0.1764, -0.1063,  0.2416, -0.1898, -0.0045,\n         -0.0233, -0.0961,  0.0413, -0.1568, -0.2074,  0.0289,  0.2305, -0.0172],\n        [ 0.0171, -0.1542,  0.0285, -0.1793, -0.0290,  0.1906, -0.1660,  0.1311,\n         -0.2287, -0.0811, -0.1264, -0.1030,  0.1420, -0.0990,  0.2032,  0.1974],\n        [-0.1674, -0.1207,  0.1732, -0.1285, -0.2092, -0.0299, -0.0409,  0.1473,\n          0.1372,  0.0952, -0.2412,  0.1977, -0.1036,  0.2333, -0.2438, -0.0421],\n        [ 0.2072, -0.2060, -0.1663, -0.0885,  0.0171, -0.1005, -0.1388, -0.2444,\n         -0.0058,  0.1071, -0.0268, -0.0007,  0.0863,  0.0617, -0.0752,  0.0842],\n        [ 0.1793, -0.0087,  0.1430, -0.2418, -0.1851,  0.2490,  0.1370, -0.0585,\n         -0.0233,  0.0844,  0.2413,  0.0985, -0.1812,  0.1222,  0.1779, -0.0751]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2961, -0.0279, -0.0432,  0.0355], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3046, -0.2876,  0.1831, -0.1615,  0.1810, -0.3495, -0.0065, -0.3460],\n        [ 0.1395, -0.2873,  0.3445,  0.2166,  0.1895, -0.0351, -0.2437,  0.2686],\n        [-0.2214,  0.2424, -0.3417,  0.0277,  0.0989, -0.1809,  0.3483,  0.2324],\n        [-0.1872,  0.1899, -0.3089,  0.0503, -0.0331,  0.1038, -0.0058,  0.1759]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "RMSprop (\nParameter Group 0\n    alpha: 0.99\n    capturable: False\n    centered: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    lr: 0.003\n    maximize: False\n    momentum: 0\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#RMSprop.zero_grad",
                    "defaults":	{
                        "alpha":	0.99,
                        "capturable":	false,
                        "centered":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "momentum":	0,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "alpha":	0.99,
                            "capturable":	false,
                            "centered":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "momentum":	0,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1368, -0.1583, -0.3074,  0.1224, -0.3291,  0.2488, -0.1892,  0.2742],\n        [ 0.2243, -0.0126, -0.0766, -0.2036, -0.3388,  0.2513, -0.0895, -0.0897],\n        [-0.0120, -0.2259, -0.1893, -0.3511,  0.2049, -0.0552,  0.3130,  0.0072],\n        [ 0.3142,  0.1067, -0.1623,  0.1075, -0.2961,  0.2439,  0.1210, -0.2089],\n        [-0.0240, -0.1917,  0.1901, -0.2928,  0.2388,  0.1820,  0.3502, -0.0305],\n        [-0.3477,  0.2020,  0.2564, -0.0491,  0.0569, -0.0920,  0.1461,  0.1619],\n        [ 0.1215, -0.3288, -0.2201, -0.2714, -0.0430, -0.0375, -0.0848,  0.0769],\n        [ 0.2908,  0.3381, -0.2917,  0.3068,  0.2512, -0.0383,  0.1073, -0.0091],\n        [ 0.0531,  0.3515, -0.2050, -0.0217,  0.2476,  0.1826, -0.0866, -0.1014],\n        [ 0.1200, -0.2482, -0.0122,  0.2810,  0.0567, -0.1963,  0.0433, -0.1205],\n        [ 0.0891,  0.2942, -0.0856,  0.0323, -0.1919,  0.1965, -0.2618,  0.3038],\n        [ 0.2868,  0.0368,  0.1988, -0.1955,  0.1564, -0.2770,  0.1259, -0.2109],\n        [-0.0059, -0.0162,  0.2276,  0.1381, -0.1436, -0.2959, -0.0657, -0.2803],\n        [-0.3167, -0.0495, -0.2690,  0.0283, -0.0621, -0.0920, -0.0652, -0.2998],\n        [-0.1518, -0.0344, -0.0400,  0.1835,  0.3523, -0.1398, -0.1489, -0.1988],\n        [ 0.2260,  0.2280, -0.0165, -0.2532, -0.0078,  0.2438, -0.2584,  0.0110],\n        [-0.0504, -0.3228,  0.2914,  0.0604, -0.1493, -0.1964,  0.2408, -0.2948],\n        [ 0.0659,  0.0611, -0.2412,  0.2171, -0.2716, -0.0512, -0.3012, -0.0231],\n        [-0.0307, -0.2636,  0.0171, -0.2373, -0.0342, -0.2827,  0.2611,  0.1555],\n        [-0.0993, -0.1818, -0.0280, -0.1249, -0.3212,  0.1473, -0.2082,  0.1015],\n        [-0.1813,  0.0109, -0.0127, -0.3194, -0.2781, -0.0357,  0.3010,  0.0541],\n        [ 0.1148,  0.0683, -0.0189,  0.0588,  0.1810,  0.1337, -0.2481,  0.0422],\n        [ 0.2917,  0.1630,  0.2415,  0.3228,  0.1358,  0.1538, -0.1771,  0.2737],\n        [-0.3523, -0.2000, -0.3094,  0.2202,  0.1693,  0.0892, -0.1715,  0.1126],\n        [ 0.1526,  0.0658,  0.1121,  0.2329,  0.2779, -0.3372,  0.2355, -0.1600],\n        [ 0.1776, -0.2264,  0.1093,  0.0791, -0.0939, -0.1458, -0.2792, -0.1995],\n        [-0.0313, -0.2110,  0.1225,  0.2792, -0.1696, -0.1052, -0.1840,  0.0904],\n        [-0.2484,  0.0992,  0.3079, -0.0358, -0.2840, -0.0576,  0.2890,  0.2746],\n        [ 0.2178,  0.2784,  0.1792,  0.1438,  0.1489, -0.1056,  0.2981, -0.2340],\n        [-0.3141, -0.0270,  0.2298,  0.2141,  0.1582, -0.3030,  0.2555,  0.1406],\n        [-0.1099,  0.3372,  0.2521,  0.0924,  0.0421,  0.0642, -0.2379,  0.0043],\n        [-0.3496, -0.0517, -0.3265,  0.1908, -0.1839,  0.2242,  0.1684, -0.1227]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1983,  0.1963,  0.2181, -0.0633,  0.3252, -0.2442,  0.0586, -0.1999,\n         0.2604,  0.1868, -0.2714,  0.0826, -0.1372,  0.3066,  0.1519,  0.0898,\n        -0.0228,  0.1100, -0.2561, -0.1552,  0.3410, -0.3045,  0.0473, -0.1568,\n         0.0845,  0.0739,  0.0944, -0.1709, -0.3361, -0.0710, -0.0838,  0.1108],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.7119e-01, -1.0331e-01,  1.6485e-01, -1.1380e-01,  1.6900e-01,\n         -5.8129e-02,  1.4365e-02,  1.5048e-01, -8.9872e-02, -3.7528e-02,\n         -1.3737e-01,  1.2825e-04,  1.2431e-01, -1.5879e-01, -1.0745e-01,\n         -4.1308e-02, -1.5831e-01, -3.4698e-03, -8.3827e-02, -2.7715e-02,\n         -5.6222e-02, -3.9718e-02,  1.2874e-01, -2.5753e-02, -4.1925e-02,\n         -1.3310e-01,  1.2990e-01, -4.1683e-02, -6.7250e-02,  1.6142e-02,\n          1.7308e-01,  6.5294e-02],\n        [ 5.3289e-02,  1.6221e-02,  1.3688e-01, -7.4019e-02, -5.3468e-02,\n         -1.5345e-01, -1.5532e-01,  1.4658e-01,  1.4675e-01,  1.0240e-01,\n         -4.4721e-02,  8.8815e-02, -7.5223e-02, -1.0718e-02,  1.0917e-01,\n          1.1481e-01,  7.5195e-02,  9.3881e-02,  8.8454e-02,  2.9084e-02,\n         -2.2217e-02,  3.3932e-02,  3.5179e-02,  7.2538e-02, -1.7267e-01,\n         -1.7523e-01, -8.4467e-02, -1.7407e-01,  1.9294e-02,  2.3356e-02,\n          1.6145e-01,  6.5534e-02],\n        [-4.5500e-02, -2.9423e-03, -6.4124e-02, -1.6813e-01, -1.3237e-01,\n         -2.0836e-02,  1.5800e-01, -4.5736e-02,  8.0793e-02, -1.5373e-01,\n          2.6747e-02,  5.5758e-02, -1.6813e-01,  1.5299e-01, -1.5858e-01,\n         -1.1976e-01,  1.5216e-01, -4.6390e-02, -3.4773e-02,  1.3775e-02,\n         -4.9708e-02, -5.3840e-02, -1.9565e-02, -1.5066e-01, -1.0185e-01,\n         -5.1132e-02, -1.6967e-01, -4.7009e-02,  1.0126e-01, -4.2788e-03,\n         -8.7881e-02, -5.6308e-02],\n        [ 7.4352e-02,  7.3097e-02, -1.6158e-01,  1.4876e-01, -2.1917e-02,\n          1.0592e-01, -3.1417e-03,  1.4543e-01, -1.1605e-01, -1.0345e-01,\n         -3.4566e-02, -1.0310e-01,  1.4979e-01, -1.6489e-01,  1.6366e-01,\n         -5.7291e-02, -7.8470e-02,  1.1808e-01,  1.1460e-01,  1.4725e-01,\n          4.9913e-02,  1.1306e-01, -1.9306e-02,  1.0541e-01,  1.3272e-01,\n         -1.2202e-01, -1.6500e-01, -3.1695e-02,  1.7188e-01, -7.2561e-03,\n         -6.1494e-02,  8.6384e-02],\n        [-9.5578e-02, -1.0440e-02,  1.1270e-01,  5.1168e-02,  9.6985e-02,\n          1.3985e-01,  4.7252e-02, -6.4342e-03, -1.2725e-01,  1.7192e-01,\n         -1.1386e-01,  7.3515e-02,  2.1891e-02, -1.0534e-01, -5.1123e-02,\n         -1.1772e-01, -4.2875e-02, -1.0462e-01,  1.1469e-01,  9.1932e-02,\n          5.0946e-02,  1.7460e-01,  1.7016e-01,  5.5475e-02,  1.4863e-01,\n          2.0707e-02, -1.7067e-01,  1.2519e-01,  6.2377e-02,  2.1063e-02,\n         -6.2741e-02,  1.7545e-01],\n        [-9.0051e-02, -6.2792e-02, -7.6244e-02, -6.1440e-02, -1.7134e-01,\n          1.9250e-02, -8.1455e-02,  1.7622e-01, -4.6596e-02, -1.1104e-02,\n         -5.0655e-03,  7.3715e-02, -9.8616e-03,  7.2997e-02, -1.5950e-01,\n         -6.1927e-02, -6.2004e-02, -1.0391e-01, -2.0202e-02, -9.7971e-02,\n         -4.9891e-02,  1.7231e-01,  1.6434e-01, -1.4694e-01, -1.5687e-01,\n          7.4669e-02, -1.7481e-01, -1.4294e-01, -6.4961e-02, -6.2057e-02,\n          1.5579e-01, -6.3189e-03],\n        [ 8.6642e-02, -1.6819e-02, -1.6383e-02, -5.4198e-02, -1.6402e-01,\n         -5.8833e-02,  9.0374e-02,  9.3486e-02, -1.7225e-01, -1.7596e-01,\n          9.7998e-02, -5.9716e-02, -3.5718e-02, -5.1948e-02,  1.0930e-01,\n         -9.1390e-03,  1.0491e-01,  1.1681e-01, -2.0267e-02,  2.9706e-02,\n          1.3287e-01,  3.2196e-02,  1.4298e-01,  8.2337e-02, -8.0416e-02,\n          2.7013e-02,  1.6950e-01,  1.3649e-01,  1.6897e-01,  6.3101e-03,\n         -1.7623e-01,  1.6236e-01],\n        [ 4.4583e-02, -1.1256e-01,  1.5917e-01, -3.6731e-02,  2.7712e-02,\n          6.7257e-03,  5.2780e-02, -1.6632e-01, -1.0742e-01, -1.1642e-01,\n          1.5273e-01, -6.8879e-02,  1.5682e-01,  2.2065e-02,  1.2779e-01,\n         -2.4801e-02,  6.9429e-02,  1.2403e-01, -8.5319e-02,  7.2372e-02,\n         -6.6496e-02,  1.1814e-01,  6.5856e-02, -6.2429e-03, -1.4136e-01,\n          5.6034e-02,  1.1905e-02, -1.0623e-01, -1.1986e-01, -9.3882e-02,\n         -1.4153e-01, -7.5564e-02],\n        [ 6.5965e-02,  3.2774e-02, -1.3624e-01, -1.2823e-01,  3.8435e-02,\n          5.3479e-02, -2.6772e-02,  6.0949e-02, -1.6339e-01, -7.4022e-02,\n         -1.1703e-01, -2.4161e-02,  2.2817e-03, -7.2965e-02,  1.7352e-01,\n          5.1516e-02,  5.6743e-02,  5.8147e-02,  1.6107e-01,  1.2667e-01,\n          9.0820e-02,  6.1631e-02,  7.7640e-02,  1.2978e-01,  1.0008e-01,\n          6.5551e-02,  1.1644e-01,  1.5695e-01, -6.9093e-02,  9.3514e-02,\n          1.6598e-01,  9.8402e-02],\n        [ 1.6416e-01, -1.2082e-01, -1.3604e-01, -3.2407e-02,  1.0535e-02,\n          1.1520e-01, -5.3580e-02,  7.3843e-02, -1.5987e-01,  1.3237e-01,\n          4.3526e-02,  1.4762e-01, -1.7500e-01, -9.9946e-02,  1.6763e-01,\n          1.6064e-02, -1.4925e-01,  1.0588e-02, -1.2311e-01, -1.0488e-01,\n         -7.9273e-02,  1.3450e-01, -1.2306e-01, -1.1589e-01,  8.9918e-02,\n          2.8481e-02,  1.2379e-01, -1.2233e-01,  1.2914e-01,  1.3978e-01,\n         -1.6445e-01,  1.0863e-01],\n        [ 2.4687e-02,  1.7303e-01,  1.5924e-01, -1.3399e-01,  1.0499e-01,\n          3.2050e-02, -5.9935e-02, -1.5772e-01,  7.1134e-02,  2.8767e-02,\n         -6.9536e-02,  1.1283e-01,  1.6979e-01, -4.3028e-02,  8.6632e-02,\n         -4.5533e-02,  1.4476e-02, -1.7230e-01,  1.4414e-01, -1.3365e-02,\n          7.4996e-02,  1.1670e-01,  4.6157e-02,  1.7392e-01,  9.7901e-02,\n         -1.3557e-01, -2.0095e-02,  1.0780e-01, -3.8025e-02, -2.9424e-02,\n         -9.8817e-02,  8.5811e-02],\n        [ 5.0523e-02,  1.5848e-01,  1.4900e-01, -4.2484e-02, -3.9262e-02,\n         -8.9524e-02, -2.8017e-02, -1.0619e-01, -4.3798e-02,  4.5912e-02,\n          1.2149e-01,  8.0271e-02,  9.6169e-02,  1.2027e-01,  2.5514e-02,\n          8.2754e-02, -1.3193e-01,  5.7062e-02,  2.9202e-02, -4.8415e-02,\n          7.4760e-02, -1.5183e-01,  9.8830e-02,  6.3117e-02, -1.4092e-01,\n          1.7175e-01,  1.4846e-01, -9.4582e-02, -9.1063e-02,  1.7323e-02,\n          2.5400e-02, -3.8283e-02],\n        [ 1.4764e-02,  1.5484e-01, -6.0860e-02, -9.1821e-02, -1.4063e-01,\n         -1.0448e-01, -1.0528e-01, -6.5286e-02, -1.2709e-01, -7.7990e-02,\n         -8.8477e-02, -1.1540e-01, -1.1379e-01, -7.2040e-02,  1.6900e-01,\n          8.1698e-03, -1.5875e-01,  1.4789e-01,  3.4280e-02, -6.7613e-03,\n          1.1643e-01,  7.8767e-02, -2.2670e-02, -7.5606e-02,  1.4892e-02,\n         -5.2950e-02,  7.2556e-02, -7.1549e-02, -1.3396e-01, -5.3128e-02,\n         -4.6786e-02, -7.5330e-02],\n        [ 8.5674e-02,  4.2263e-02, -1.6273e-02, -1.5033e-01, -7.7003e-02,\n         -1.3442e-01, -4.6091e-02,  8.4301e-02,  8.4942e-02,  9.4527e-02,\n          1.0007e-01,  6.7402e-02,  1.4664e-03, -5.6707e-02, -1.5396e-01,\n          9.9798e-02, -3.8288e-02, -1.4166e-01, -1.4113e-01, -1.3914e-01,\n          7.2835e-02, -1.0104e-01,  7.6178e-02, -1.6263e-01,  9.2809e-02,\n         -3.6425e-02, -1.0341e-01, -4.5064e-02,  1.9761e-02,  8.1520e-02,\n          1.3608e-01, -7.2467e-02],\n        [ 5.1423e-02,  1.5259e-01,  4.5631e-02, -4.6097e-03, -1.2425e-01,\n          1.4105e-01, -1.6364e-02, -2.1044e-02,  8.3701e-02, -6.1250e-02,\n          1.7081e-01,  2.1578e-02,  7.9669e-02,  9.3666e-02, -1.5951e-01,\n          9.0571e-02,  1.7057e-01,  2.1978e-02,  1.1809e-01, -4.8230e-02,\n         -2.7246e-02,  2.2902e-02,  3.7296e-02,  8.1399e-02, -8.0587e-02,\n          7.3746e-02, -1.7671e-01, -1.3566e-01,  1.5308e-01,  8.1894e-02,\n          2.2031e-02, -1.4794e-01],\n        [ 9.2269e-02,  1.4156e-01, -8.5579e-02, -1.2824e-01,  1.1703e-01,\n         -7.4234e-02, -3.9817e-02, -1.0460e-01, -9.1631e-02,  2.5465e-02,\n         -1.5668e-01,  7.6526e-02, -1.1739e-01, -1.6313e-01, -5.2938e-02,\n         -7.0213e-02, -1.6645e-01,  1.5570e-01,  6.0278e-03,  6.2479e-02,\n         -1.1810e-02,  1.5934e-02,  1.0559e-01, -1.2844e-01, -5.6755e-02,\n         -2.8374e-03, -1.0888e-01,  1.7579e-01, -2.1413e-02,  5.2184e-02,\n         -9.5474e-02,  1.0879e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0975,  0.0009,  0.0119,  0.0100, -0.0047,  0.1270,  0.1049, -0.1759,\n         0.1290,  0.0459,  0.1152,  0.1572, -0.1187, -0.0984,  0.0323,  0.0325],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2194,  0.0055, -0.1273,  0.1409,  0.0741,  0.1142,  0.1874, -0.2214,\n          0.1412,  0.2316, -0.0806, -0.0820,  0.0633, -0.0426,  0.1417, -0.1463],\n        [-0.1018, -0.1632,  0.0887, -0.2225,  0.1623, -0.0988,  0.0580,  0.0675,\n         -0.0756,  0.1910,  0.2204,  0.2434,  0.1147,  0.1370,  0.2031,  0.1079],\n        [ 0.0749,  0.1566,  0.2008, -0.1904, -0.0270, -0.0043,  0.2158,  0.0512,\n          0.2131,  0.0779, -0.1477, -0.1779, -0.1159,  0.0511,  0.2144,  0.2370],\n        [ 0.0240,  0.0615, -0.0329, -0.1764, -0.1063,  0.2416, -0.1898, -0.0045,\n         -0.0233, -0.0961,  0.0413, -0.1568, -0.2074,  0.0289,  0.2305, -0.0172],\n        [ 0.0171, -0.1542,  0.0285, -0.1793, -0.0290,  0.1906, -0.1660,  0.1311,\n         -0.2287, -0.0811, -0.1264, -0.1030,  0.1420, -0.0990,  0.2032,  0.1974],\n        [-0.1674, -0.1207,  0.1732, -0.1285, -0.2092, -0.0299, -0.0409,  0.1473,\n          0.1372,  0.0952, -0.2412,  0.1977, -0.1036,  0.2333, -0.2438, -0.0421],\n        [ 0.2072, -0.2060, -0.1663, -0.0885,  0.0171, -0.1005, -0.1388, -0.2444,\n         -0.0058,  0.1071, -0.0268, -0.0007,  0.0863,  0.0617, -0.0752,  0.0842],\n        [ 0.1793, -0.0087,  0.1430, -0.2418, -0.1851,  0.2490,  0.1370, -0.0585,\n         -0.0233,  0.0844,  0.2413,  0.0985, -0.1812,  0.1222,  0.1779, -0.0751]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0535, -0.0583,  0.0949,  0.1989,  0.0858,  0.1606, -0.0019,  0.0092],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3046, -0.2876,  0.1831, -0.1615,  0.1810, -0.3495, -0.0065, -0.3460],\n        [ 0.1395, -0.2873,  0.3445,  0.2166,  0.1895, -0.0351, -0.2437,  0.2686],\n        [-0.2214,  0.2424, -0.3417,  0.0277,  0.0989, -0.1809,  0.3483,  0.2324],\n        [-0.1872,  0.1899, -0.3089,  0.0503, -0.0331,  0.1038, -0.0058,  0.1759]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2961, -0.0279, -0.0432,  0.0355], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.stale_replay_buffer.StaleReplayBuffer object at 0x73a923702810>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1983,  0.1963,  0.2181, -0.0633,  0.3252, -0.2442,  0.0586, -0.1999,\n         0.2604,  0.1868, -0.2714,  0.0826, -0.1372,  0.3066,  0.1519,  0.0898,\n        -0.0228,  0.1100, -0.2561, -0.1552,  0.3410, -0.3045,  0.0473, -0.1568,\n         0.0845,  0.0739,  0.0944, -0.1709, -0.3361, -0.0710, -0.0838,  0.1108],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1368, -0.1583, -0.3074,  0.1224, -0.3291,  0.2488, -0.1892,  0.2742],\n        [ 0.2243, -0.0126, -0.0766, -0.2036, -0.3388,  0.2513, -0.0895, -0.0897],\n        [-0.0120, -0.2259, -0.1893, -0.3511,  0.2049, -0.0552,  0.3130,  0.0072],\n        [ 0.3142,  0.1067, -0.1623,  0.1075, -0.2961,  0.2439,  0.1210, -0.2089],\n        [-0.0240, -0.1917,  0.1901, -0.2928,  0.2388,  0.1820,  0.3502, -0.0305],\n        [-0.3477,  0.2020,  0.2564, -0.0491,  0.0569, -0.0920,  0.1461,  0.1619],\n        [ 0.1215, -0.3288, -0.2201, -0.2714, -0.0430, -0.0375, -0.0848,  0.0769],\n        [ 0.2908,  0.3381, -0.2917,  0.3068,  0.2512, -0.0383,  0.1073, -0.0091],\n        [ 0.0531,  0.3515, -0.2050, -0.0217,  0.2476,  0.1826, -0.0866, -0.1014],\n        [ 0.1200, -0.2482, -0.0122,  0.2810,  0.0567, -0.1963,  0.0433, -0.1205],\n        [ 0.0891,  0.2942, -0.0856,  0.0323, -0.1919,  0.1965, -0.2618,  0.3038],\n        [ 0.2868,  0.0368,  0.1988, -0.1955,  0.1564, -0.2770,  0.1259, -0.2109],\n        [-0.0059, -0.0162,  0.2276,  0.1381, -0.1436, -0.2959, -0.0657, -0.2803],\n        [-0.3167, -0.0495, -0.2690,  0.0283, -0.0621, -0.0920, -0.0652, -0.2998],\n        [-0.1518, -0.0344, -0.0400,  0.1835,  0.3523, -0.1398, -0.1489, -0.1988],\n        [ 0.2260,  0.2280, -0.0165, -0.2532, -0.0078,  0.2438, -0.2584,  0.0110],\n        [-0.0504, -0.3228,  0.2914,  0.0604, -0.1493, -0.1964,  0.2408, -0.2948],\n        [ 0.0659,  0.0611, -0.2412,  0.2171, -0.2716, -0.0512, -0.3012, -0.0231],\n        [-0.0307, -0.2636,  0.0171, -0.2373, -0.0342, -0.2827,  0.2611,  0.1555],\n        [-0.0993, -0.1818, -0.0280, -0.1249, -0.3212,  0.1473, -0.2082,  0.1015],\n        [-0.1813,  0.0109, -0.0127, -0.3194, -0.2781, -0.0357,  0.3010,  0.0541],\n        [ 0.1148,  0.0683, -0.0189,  0.0588,  0.1810,  0.1337, -0.2481,  0.0422],\n        [ 0.2917,  0.1630,  0.2415,  0.3228,  0.1358,  0.1538, -0.1771,  0.2737],\n        [-0.3523, -0.2000, -0.3094,  0.2202,  0.1693,  0.0892, -0.1715,  0.1126],\n        [ 0.1526,  0.0658,  0.1121,  0.2329,  0.2779, -0.3372,  0.2355, -0.1600],\n        [ 0.1776, -0.2264,  0.1093,  0.0791, -0.0939, -0.1458, -0.2792, -0.1995],\n        [-0.0313, -0.2110,  0.1225,  0.2792, -0.1696, -0.1052, -0.1840,  0.0904],\n        [-0.2484,  0.0992,  0.3079, -0.0358, -0.2840, -0.0576,  0.2890,  0.2746],\n        [ 0.2178,  0.2784,  0.1792,  0.1438,  0.1489, -0.1056,  0.2981, -0.2340],\n        [-0.3141, -0.0270,  0.2298,  0.2141,  0.1582, -0.3030,  0.2555,  0.1406],\n        [-0.1099,  0.3372,  0.2521,  0.0924,  0.0421,  0.0642, -0.2379,  0.0043],\n        [-0.3496, -0.0517, -0.3265,  0.1908, -0.1839,  0.2242,  0.1684, -0.1227]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0975,  0.0009,  0.0119,  0.0100, -0.0047,  0.1270,  0.1049, -0.1759,\n         0.1290,  0.0459,  0.1152,  0.1572, -0.1187, -0.0984,  0.0323,  0.0325],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.7119e-01, -1.0331e-01,  1.6485e-01, -1.1380e-01,  1.6900e-01,\n         -5.8129e-02,  1.4365e-02,  1.5048e-01, -8.9872e-02, -3.7528e-02,\n         -1.3737e-01,  1.2825e-04,  1.2431e-01, -1.5879e-01, -1.0745e-01,\n         -4.1308e-02, -1.5831e-01, -3.4698e-03, -8.3827e-02, -2.7715e-02,\n         -5.6222e-02, -3.9718e-02,  1.2874e-01, -2.5753e-02, -4.1925e-02,\n         -1.3310e-01,  1.2990e-01, -4.1683e-02, -6.7250e-02,  1.6142e-02,\n          1.7308e-01,  6.5294e-02],\n        [ 5.3289e-02,  1.6221e-02,  1.3688e-01, -7.4019e-02, -5.3468e-02,\n         -1.5345e-01, -1.5532e-01,  1.4658e-01,  1.4675e-01,  1.0240e-01,\n         -4.4721e-02,  8.8815e-02, -7.5223e-02, -1.0718e-02,  1.0917e-01,\n          1.1481e-01,  7.5195e-02,  9.3881e-02,  8.8454e-02,  2.9084e-02,\n         -2.2217e-02,  3.3932e-02,  3.5179e-02,  7.2538e-02, -1.7267e-01,\n         -1.7523e-01, -8.4467e-02, -1.7407e-01,  1.9294e-02,  2.3356e-02,\n          1.6145e-01,  6.5534e-02],\n        [-4.5500e-02, -2.9423e-03, -6.4124e-02, -1.6813e-01, -1.3237e-01,\n         -2.0836e-02,  1.5800e-01, -4.5736e-02,  8.0793e-02, -1.5373e-01,\n          2.6747e-02,  5.5758e-02, -1.6813e-01,  1.5299e-01, -1.5858e-01,\n         -1.1976e-01,  1.5216e-01, -4.6390e-02, -3.4773e-02,  1.3775e-02,\n         -4.9708e-02, -5.3840e-02, -1.9565e-02, -1.5066e-01, -1.0185e-01,\n         -5.1132e-02, -1.6967e-01, -4.7009e-02,  1.0126e-01, -4.2788e-03,\n         -8.7881e-02, -5.6308e-02],\n        [ 7.4352e-02,  7.3097e-02, -1.6158e-01,  1.4876e-01, -2.1917e-02,\n          1.0592e-01, -3.1417e-03,  1.4543e-01, -1.1605e-01, -1.0345e-01,\n         -3.4566e-02, -1.0310e-01,  1.4979e-01, -1.6489e-01,  1.6366e-01,\n         -5.7291e-02, -7.8470e-02,  1.1808e-01,  1.1460e-01,  1.4725e-01,\n          4.9913e-02,  1.1306e-01, -1.9306e-02,  1.0541e-01,  1.3272e-01,\n         -1.2202e-01, -1.6500e-01, -3.1695e-02,  1.7188e-01, -7.2561e-03,\n         -6.1494e-02,  8.6384e-02],\n        [-9.5578e-02, -1.0440e-02,  1.1270e-01,  5.1168e-02,  9.6985e-02,\n          1.3985e-01,  4.7252e-02, -6.4342e-03, -1.2725e-01,  1.7192e-01,\n         -1.1386e-01,  7.3515e-02,  2.1891e-02, -1.0534e-01, -5.1123e-02,\n         -1.1772e-01, -4.2875e-02, -1.0462e-01,  1.1469e-01,  9.1932e-02,\n          5.0946e-02,  1.7460e-01,  1.7016e-01,  5.5475e-02,  1.4863e-01,\n          2.0707e-02, -1.7067e-01,  1.2519e-01,  6.2377e-02,  2.1063e-02,\n         -6.2741e-02,  1.7545e-01],\n        [-9.0051e-02, -6.2792e-02, -7.6244e-02, -6.1440e-02, -1.7134e-01,\n          1.9250e-02, -8.1455e-02,  1.7622e-01, -4.6596e-02, -1.1104e-02,\n         -5.0655e-03,  7.3715e-02, -9.8616e-03,  7.2997e-02, -1.5950e-01,\n         -6.1927e-02, -6.2004e-02, -1.0391e-01, -2.0202e-02, -9.7971e-02,\n         -4.9891e-02,  1.7231e-01,  1.6434e-01, -1.4694e-01, -1.5687e-01,\n          7.4669e-02, -1.7481e-01, -1.4294e-01, -6.4961e-02, -6.2057e-02,\n          1.5579e-01, -6.3189e-03],\n        [ 8.6642e-02, -1.6819e-02, -1.6383e-02, -5.4198e-02, -1.6402e-01,\n         -5.8833e-02,  9.0374e-02,  9.3486e-02, -1.7225e-01, -1.7596e-01,\n          9.7998e-02, -5.9716e-02, -3.5718e-02, -5.1948e-02,  1.0930e-01,\n         -9.1390e-03,  1.0491e-01,  1.1681e-01, -2.0267e-02,  2.9706e-02,\n          1.3287e-01,  3.2196e-02,  1.4298e-01,  8.2337e-02, -8.0416e-02,\n          2.7013e-02,  1.6950e-01,  1.3649e-01,  1.6897e-01,  6.3101e-03,\n         -1.7623e-01,  1.6236e-01],\n        [ 4.4583e-02, -1.1256e-01,  1.5917e-01, -3.6731e-02,  2.7712e-02,\n          6.7257e-03,  5.2780e-02, -1.6632e-01, -1.0742e-01, -1.1642e-01,\n          1.5273e-01, -6.8879e-02,  1.5682e-01,  2.2065e-02,  1.2779e-01,\n         -2.4801e-02,  6.9429e-02,  1.2403e-01, -8.5319e-02,  7.2372e-02,\n         -6.6496e-02,  1.1814e-01,  6.5856e-02, -6.2429e-03, -1.4136e-01,\n          5.6034e-02,  1.1905e-02, -1.0623e-01, -1.1986e-01, -9.3882e-02,\n         -1.4153e-01, -7.5564e-02],\n        [ 6.5965e-02,  3.2774e-02, -1.3624e-01, -1.2823e-01,  3.8435e-02,\n          5.3479e-02, -2.6772e-02,  6.0949e-02, -1.6339e-01, -7.4022e-02,\n         -1.1703e-01, -2.4161e-02,  2.2817e-03, -7.2965e-02,  1.7352e-01,\n          5.1516e-02,  5.6743e-02,  5.8147e-02,  1.6107e-01,  1.2667e-01,\n          9.0820e-02,  6.1631e-02,  7.7640e-02,  1.2978e-01,  1.0008e-01,\n          6.5551e-02,  1.1644e-01,  1.5695e-01, -6.9093e-02,  9.3514e-02,\n          1.6598e-01,  9.8402e-02],\n        [ 1.6416e-01, -1.2082e-01, -1.3604e-01, -3.2407e-02,  1.0535e-02,\n          1.1520e-01, -5.3580e-02,  7.3843e-02, -1.5987e-01,  1.3237e-01,\n          4.3526e-02,  1.4762e-01, -1.7500e-01, -9.9946e-02,  1.6763e-01,\n          1.6064e-02, -1.4925e-01,  1.0588e-02, -1.2311e-01, -1.0488e-01,\n         -7.9273e-02,  1.3450e-01, -1.2306e-01, -1.1589e-01,  8.9918e-02,\n          2.8481e-02,  1.2379e-01, -1.2233e-01,  1.2914e-01,  1.3978e-01,\n         -1.6445e-01,  1.0863e-01],\n        [ 2.4687e-02,  1.7303e-01,  1.5924e-01, -1.3399e-01,  1.0499e-01,\n          3.2050e-02, -5.9935e-02, -1.5772e-01,  7.1134e-02,  2.8767e-02,\n         -6.9536e-02,  1.1283e-01,  1.6979e-01, -4.3028e-02,  8.6632e-02,\n         -4.5533e-02,  1.4476e-02, -1.7230e-01,  1.4414e-01, -1.3365e-02,\n          7.4996e-02,  1.1670e-01,  4.6157e-02,  1.7392e-01,  9.7901e-02,\n         -1.3557e-01, -2.0095e-02,  1.0780e-01, -3.8025e-02, -2.9424e-02,\n         -9.8817e-02,  8.5811e-02],\n        [ 5.0523e-02,  1.5848e-01,  1.4900e-01, -4.2484e-02, -3.9262e-02,\n         -8.9524e-02, -2.8017e-02, -1.0619e-01, -4.3798e-02,  4.5912e-02,\n          1.2149e-01,  8.0271e-02,  9.6169e-02,  1.2027e-01,  2.5514e-02,\n          8.2754e-02, -1.3193e-01,  5.7062e-02,  2.9202e-02, -4.8415e-02,\n          7.4760e-02, -1.5183e-01,  9.8830e-02,  6.3117e-02, -1.4092e-01,\n          1.7175e-01,  1.4846e-01, -9.4582e-02, -9.1063e-02,  1.7323e-02,\n          2.5400e-02, -3.8283e-02],\n        [ 1.4764e-02,  1.5484e-01, -6.0860e-02, -9.1821e-02, -1.4063e-01,\n         -1.0448e-01, -1.0528e-01, -6.5286e-02, -1.2709e-01, -7.7990e-02,\n         -8.8477e-02, -1.1540e-01, -1.1379e-01, -7.2040e-02,  1.6900e-01,\n          8.1698e-03, -1.5875e-01,  1.4789e-01,  3.4280e-02, -6.7613e-03,\n          1.1643e-01,  7.8767e-02, -2.2670e-02, -7.5606e-02,  1.4892e-02,\n         -5.2950e-02,  7.2556e-02, -7.1549e-02, -1.3396e-01, -5.3128e-02,\n         -4.6786e-02, -7.5330e-02],\n        [ 8.5674e-02,  4.2263e-02, -1.6273e-02, -1.5033e-01, -7.7003e-02,\n         -1.3442e-01, -4.6091e-02,  8.4301e-02,  8.4942e-02,  9.4527e-02,\n          1.0007e-01,  6.7402e-02,  1.4664e-03, -5.6707e-02, -1.5396e-01,\n          9.9798e-02, -3.8288e-02, -1.4166e-01, -1.4113e-01, -1.3914e-01,\n          7.2835e-02, -1.0104e-01,  7.6178e-02, -1.6263e-01,  9.2809e-02,\n         -3.6425e-02, -1.0341e-01, -4.5064e-02,  1.9761e-02,  8.1520e-02,\n          1.3608e-01, -7.2467e-02],\n        [ 5.1423e-02,  1.5259e-01,  4.5631e-02, -4.6097e-03, -1.2425e-01,\n          1.4105e-01, -1.6364e-02, -2.1044e-02,  8.3701e-02, -6.1250e-02,\n          1.7081e-01,  2.1578e-02,  7.9669e-02,  9.3666e-02, -1.5951e-01,\n          9.0571e-02,  1.7057e-01,  2.1978e-02,  1.1809e-01, -4.8230e-02,\n         -2.7246e-02,  2.2902e-02,  3.7296e-02,  8.1399e-02, -8.0587e-02,\n          7.3746e-02, -1.7671e-01, -1.3566e-01,  1.5308e-01,  8.1894e-02,\n          2.2031e-02, -1.4794e-01],\n        [ 9.2269e-02,  1.4156e-01, -8.5579e-02, -1.2824e-01,  1.1703e-01,\n         -7.4234e-02, -3.9817e-02, -1.0460e-01, -9.1631e-02,  2.5465e-02,\n         -1.5668e-01,  7.6526e-02, -1.1739e-01, -1.6313e-01, -5.2938e-02,\n         -7.0213e-02, -1.6645e-01,  1.5570e-01,  6.0278e-03,  6.2479e-02,\n         -1.1810e-02,  1.5934e-02,  1.0559e-01, -1.2844e-01, -5.6755e-02,\n         -2.8374e-03, -1.0888e-01,  1.7579e-01, -2.1413e-02,  5.2184e-02,\n         -9.5474e-02,  1.0879e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0535, -0.0583,  0.0949,  0.1989,  0.0858,  0.1606, -0.0019,  0.0092],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2194,  0.0055, -0.1273,  0.1409,  0.0741,  0.1142,  0.1874, -0.2214,\n          0.1412,  0.2316, -0.0806, -0.0820,  0.0633, -0.0426,  0.1417, -0.1463],\n        [-0.1018, -0.1632,  0.0887, -0.2225,  0.1623, -0.0988,  0.0580,  0.0675,\n         -0.0756,  0.1910,  0.2204,  0.2434,  0.1147,  0.1370,  0.2031,  0.1079],\n        [ 0.0749,  0.1566,  0.2008, -0.1904, -0.0270, -0.0043,  0.2158,  0.0512,\n          0.2131,  0.0779, -0.1477, -0.1779, -0.1159,  0.0511,  0.2144,  0.2370],\n        [ 0.0240,  0.0615, -0.0329, -0.1764, -0.1063,  0.2416, -0.1898, -0.0045,\n         -0.0233, -0.0961,  0.0413, -0.1568, -0.2074,  0.0289,  0.2305, -0.0172],\n        [ 0.0171, -0.1542,  0.0285, -0.1793, -0.0290,  0.1906, -0.1660,  0.1311,\n         -0.2287, -0.0811, -0.1264, -0.1030,  0.1420, -0.0990,  0.2032,  0.1974],\n        [-0.1674, -0.1207,  0.1732, -0.1285, -0.2092, -0.0299, -0.0409,  0.1473,\n          0.1372,  0.0952, -0.2412,  0.1977, -0.1036,  0.2333, -0.2438, -0.0421],\n        [ 0.2072, -0.2060, -0.1663, -0.0885,  0.0171, -0.1005, -0.1388, -0.2444,\n         -0.0058,  0.1071, -0.0268, -0.0007,  0.0863,  0.0617, -0.0752,  0.0842],\n        [ 0.1793, -0.0087,  0.1430, -0.2418, -0.1851,  0.2490,  0.1370, -0.0585,\n         -0.0233,  0.0844,  0.2413,  0.0985, -0.1812,  0.1222,  0.1779, -0.0751]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2961, -0.0279, -0.0432,  0.0355], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3046, -0.2876,  0.1831, -0.1615,  0.1810, -0.3495, -0.0065, -0.3460],\n        [ 0.1395, -0.2873,  0.3445,  0.2166,  0.1895, -0.0351, -0.2437,  0.2686],\n        [-0.2214,  0.2424, -0.3417,  0.0277,  0.0989, -0.1809,  0.3483,  0.2324],\n        [-0.1872,  0.1899, -0.3089,  0.0503, -0.0331,  0.1038, -0.0058,  0.1759]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	6,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x73a921bee090>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s422130000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s422130000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	6,
    "traj_per_epoch":	3
}