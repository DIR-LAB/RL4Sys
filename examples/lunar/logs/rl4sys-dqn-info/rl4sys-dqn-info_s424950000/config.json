{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s424950000"
    },
    "q_lr":	0.003,
    "seed":	424950000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7e6c8bfd3350>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2696,  0.3372,  0.1362,  0.3155, -0.3345,  0.2465, -0.2765,  0.2562,\n         0.1020, -0.3111, -0.3265, -0.3038,  0.1851, -0.3230, -0.3160, -0.2045,\n         0.1727, -0.2105, -0.0520,  0.1177, -0.1006, -0.1189, -0.1319,  0.3154,\n         0.2140, -0.0124, -0.1878, -0.3266,  0.1126,  0.0435, -0.2781, -0.2871,\n        -0.0555,  0.2723,  0.0939, -0.2167,  0.2589,  0.1000,  0.0964,  0.0631,\n        -0.2206, -0.1245,  0.0487, -0.0180,  0.0073, -0.1975,  0.2111, -0.1470,\n        -0.1335, -0.0934,  0.1105, -0.1876,  0.3075,  0.3427, -0.1940,  0.0437,\n         0.3061, -0.0378, -0.1773, -0.1761, -0.0209, -0.3051, -0.1529,  0.2541,\n        -0.1346,  0.2204,  0.1418,  0.2420,  0.1689, -0.2588, -0.2540, -0.1447,\n        -0.3442,  0.2323, -0.2853, -0.2633,  0.1680,  0.0774,  0.1667,  0.0896,\n        -0.2460,  0.2362,  0.2888, -0.0983, -0.1412,  0.1480, -0.2093, -0.2713,\n        -0.0618,  0.0326, -0.1881, -0.3317,  0.2937,  0.0641,  0.0169,  0.2794,\n        -0.1529,  0.3414,  0.0080, -0.1123], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 2.9748e-03,  8.4294e-02,  1.2342e-01, -2.3507e-01,  1.9911e-01,\n         -1.7844e-01, -3.0797e-04, -1.4470e-01],\n        [-1.6318e-02, -5.3577e-02, -2.9744e-02, -3.0170e-01, -2.3799e-01,\n         -2.2034e-01, -6.8711e-02, -2.9936e-01],\n        [-1.6471e-01, -6.7591e-02, -5.3768e-02,  1.1793e-02, -1.2301e-01,\n         -2.0481e-01,  9.3542e-02,  1.4765e-01],\n        [-2.8194e-01,  1.9954e-02, -1.4080e-01, -2.6764e-01,  4.6485e-02,\n          3.4131e-01, -1.5602e-01,  5.3317e-02],\n        [ 2.8818e-01,  1.3701e-01, -2.4789e-02,  1.3483e-01, -7.3237e-02,\n         -2.3121e-01, -3.0718e-01,  2.4715e-02],\n        [ 4.9273e-03,  1.7114e-02,  3.3476e-01, -2.3572e-01,  1.9136e-01,\n          2.3175e-01, -3.5289e-01, -1.2585e-02],\n        [ 9.1889e-02,  1.9314e-01, -3.2886e-01, -3.5001e-01,  7.2053e-02,\n          3.2966e-01, -1.6632e-01,  9.3680e-02],\n        [ 1.3075e-01,  1.4838e-01,  2.9958e-01, -3.0006e-01,  1.5587e-01,\n          1.1268e-01, -3.2680e-01,  2.1581e-01],\n        [-3.4247e-01,  1.7037e-01,  8.7362e-02, -5.5735e-02, -1.1676e-01,\n         -3.1026e-01, -1.7033e-01,  7.7651e-02],\n        [-3.4650e-01,  2.1113e-01,  2.7016e-01,  3.0883e-01,  2.3230e-03,\n          1.4958e-01,  3.4897e-01, -2.2816e-01],\n        [ 2.4307e-01,  3.2930e-01, -1.2943e-01,  1.6384e-01, -1.1741e-01,\n         -2.9876e-01,  6.4873e-02,  1.9558e-01],\n        [ 4.0997e-02,  3.1267e-01, -1.8977e-01, -1.9898e-01, -4.9696e-02,\n         -1.1334e-01, -1.6273e-01,  3.0488e-01],\n        [-1.1870e-01,  1.6191e-01,  1.1881e-01,  1.2657e-01,  1.4564e-01,\n         -2.1125e-01, -8.9203e-02, -6.4772e-02],\n        [-9.1037e-02, -2.2079e-02, -2.9478e-01,  3.4186e-01,  6.4514e-02,\n         -2.4789e-01,  1.9748e-01, -1.7760e-01],\n        [-2.5457e-01,  9.0377e-02,  2.7305e-01, -2.6712e-01, -2.2855e-01,\n         -2.9081e-01,  3.3374e-01,  5.1282e-02],\n        [-1.2665e-01, -3.2786e-01,  3.3227e-01,  1.0945e-01,  9.9157e-02,\n         -9.3388e-02,  8.2819e-02, -2.1495e-01],\n        [ 2.6734e-01, -1.4983e-02, -7.1995e-02,  1.7520e-01, -9.0003e-02,\n          3.4062e-01,  1.5183e-02,  2.2339e-02],\n        [ 1.6998e-01, -3.1959e-01, -7.7686e-02, -7.2281e-03, -1.1206e-01,\n         -2.7663e-01, -1.3725e-01, -4.0634e-02],\n        [-1.1798e-01, -1.5320e-02,  7.0902e-02,  3.2417e-01, -2.1024e-02,\n          3.0407e-01, -2.9512e-01, -2.9494e-01],\n        [-2.1373e-01, -3.0382e-01,  2.0946e-01,  2.4969e-01,  3.3896e-01,\n         -9.3806e-02, -5.9223e-02, -2.2277e-01],\n        [ 5.6163e-02,  2.2929e-02,  9.5758e-02,  3.3325e-01,  1.6446e-01,\n         -2.1127e-01,  1.4649e-01,  2.2869e-01],\n        [-1.6861e-01, -5.7741e-02, -3.3408e-01, -8.2841e-02, -3.7632e-02,\n         -2.4311e-01,  9.6803e-02, -2.2977e-01],\n        [ 4.8957e-02, -2.7979e-01, -2.5172e-01, -2.9263e-01,  1.0765e-01,\n         -3.3201e-01,  4.5825e-02,  2.0991e-01],\n        [ 3.1083e-01,  1.1324e-01,  2.0094e-01, -1.8458e-01,  1.2394e-01,\n          6.7922e-02, -2.4921e-01,  2.0720e-01],\n        [-1.1495e-01,  2.8810e-01, -2.7190e-01,  1.8358e-01,  1.0612e-01,\n         -3.5446e-02, -9.8957e-02,  3.3169e-02],\n        [-2.2445e-01, -5.5246e-03, -8.7510e-02,  5.4309e-02, -2.5709e-01,\n          2.6061e-01,  3.3814e-01,  2.1284e-01],\n        [-1.7608e-01, -2.5626e-01,  3.2249e-01,  2.0347e-02,  7.4053e-02,\n         -3.1271e-01, -3.3199e-01,  1.4876e-01],\n        [-4.8731e-02, -2.5273e-01,  1.1464e-01, -3.2980e-01,  2.4633e-01,\n          1.7344e-01,  2.0913e-01, -2.0792e-01],\n        [-1.7462e-01, -2.1670e-01,  2.3393e-01, -3.3939e-01,  1.0218e-01,\n          3.3339e-01,  1.4037e-01, -1.5128e-01],\n        [ 1.5309e-01,  3.0055e-02,  1.3770e-01,  2.0537e-01,  6.8926e-02,\n         -1.9416e-01,  5.9202e-02,  2.5619e-01],\n        [ 2.0536e-01, -1.4683e-01, -6.0207e-02, -1.5521e-01, -2.8703e-01,\n          2.0850e-02, -2.5442e-01,  1.2948e-01],\n        [-4.4770e-02,  2.0350e-01, -1.2131e-01,  3.7323e-02, -1.1518e-01,\n         -2.8787e-01, -2.2356e-01,  2.7333e-01],\n        [ 1.2126e-01,  2.7364e-01,  2.0671e-02,  2.3846e-01, -1.3210e-01,\n          3.2329e-01, -2.0170e-01, -2.9788e-01],\n        [ 1.4936e-01,  2.1166e-01,  1.5605e-01, -1.3751e-01, -2.9802e-01,\n          8.7612e-02, -1.4326e-01, -1.3137e-01],\n        [ 1.2046e-01, -2.9449e-01, -1.5550e-01,  3.1717e-01, -3.0997e-01,\n          1.1207e-01, -3.3823e-01,  3.3996e-02],\n        [ 2.1001e-01, -2.1680e-01,  1.8490e-01,  1.0873e-01,  2.3209e-01,\n         -9.1216e-02,  6.7511e-02, -1.6732e-01],\n        [ 3.1658e-01, -8.9631e-03, -1.5562e-01, -6.7444e-02,  8.9129e-02,\n         -2.6642e-01, -9.6802e-02,  1.7079e-01],\n        [ 3.3049e-01,  2.8036e-01,  2.5519e-01, -2.9925e-01,  2.5454e-01,\n         -6.0795e-02, -2.7168e-01,  3.3064e-01],\n        [ 3.0721e-02,  5.9677e-02,  2.8974e-02, -2.2088e-01, -1.8133e-01,\n         -7.8193e-02, -2.7584e-01, -2.5852e-01],\n        [-2.2270e-01, -2.1661e-01, -5.0219e-02, -3.2975e-01,  1.0113e-01,\n          1.3781e-02, -2.6228e-01,  3.5128e-01],\n        [-2.6343e-01, -9.6972e-02,  2.4279e-01, -1.2919e-01,  2.6305e-01,\n          1.3798e-01, -3.5110e-01, -1.5422e-01],\n        [ 3.4177e-02,  2.0343e-01,  1.7650e-01, -3.4204e-01, -2.2546e-01,\n         -2.5950e-01,  6.7323e-02, -2.5696e-01],\n        [ 3.4346e-01,  4.9882e-03, -1.1842e-01, -1.5518e-01, -6.5704e-02,\n         -9.3659e-02,  2.7962e-01,  1.9876e-01],\n        [-2.7409e-02,  4.2623e-02,  3.5265e-01,  2.9270e-01, -2.2509e-01,\n          3.3587e-01,  3.3243e-01,  9.8178e-03],\n        [ 1.9930e-01,  7.3311e-02,  3.3093e-01,  2.6566e-01,  2.4261e-01,\n          3.4593e-01,  7.7094e-02,  2.8836e-01],\n        [ 1.0728e-01, -2.9835e-01, -6.1979e-02, -2.5607e-01, -9.0408e-02,\n         -2.3775e-01, -1.1306e-01,  8.2293e-02],\n        [-2.6252e-01, -6.6501e-02,  9.0545e-02, -2.9122e-01,  1.4649e-01,\n          1.1691e-02, -5.0900e-02,  2.4433e-01],\n        [ 2.0284e-01, -2.6161e-01, -3.0089e-01, -9.6077e-02,  2.5926e-01,\n         -1.1950e-01,  1.9879e-01, -2.7254e-01],\n        [ 1.6192e-01, -3.4880e-01,  4.8747e-02,  8.3803e-02, -2.8542e-02,\n          1.7947e-01,  2.9873e-01, -3.1933e-01],\n        [ 1.0290e-02,  2.7295e-01, -6.4525e-03, -1.4541e-01,  2.7870e-01,\n         -1.9935e-01,  1.0563e-01,  3.3262e-01],\n        [ 3.0726e-01, -1.0622e-01, -2.4209e-01, -1.2052e-01, -6.4249e-02,\n          1.5180e-02, -3.1551e-01, -3.0994e-02],\n        [-3.2063e-01, -2.9178e-01, -3.3405e-01,  2.4647e-02,  2.9219e-01,\n         -8.3673e-02,  1.9953e-01, -1.1562e-01],\n        [ 1.0353e-01, -3.5216e-01, -1.9727e-01,  2.4028e-01, -3.3500e-01,\n          2.1311e-01, -7.6660e-02,  1.9762e-01],\n        [ 2.9260e-01, -3.4170e-01, -1.7366e-02, -1.8494e-01,  2.7426e-01,\n         -1.5127e-01, -1.8822e-01,  1.6603e-01],\n        [-1.7101e-01,  6.4897e-03, -1.4058e-01, -5.0600e-02,  3.2030e-01,\n         -6.9281e-02,  2.2291e-01, -3.2560e-02],\n        [-2.2025e-01, -2.3697e-01,  5.7284e-02, -1.6236e-01, -2.5542e-01,\n         -1.6086e-01, -3.3915e-01, -6.8613e-02],\n        [-3.1419e-01,  1.0461e-01, -2.8124e-01, -2.9945e-01,  3.0467e-01,\n         -2.3638e-01, -2.4307e-01, -3.0507e-01],\n        [ 2.1683e-01, -1.5146e-01,  3.2550e-01, -3.0021e-01, -1.6487e-01,\n          3.4399e-01, -6.3326e-02,  2.2435e-01],\n        [ 1.4275e-01,  2.2930e-01,  7.7265e-02, -2.8608e-01,  1.6003e-01,\n          6.8398e-02,  9.9757e-02,  3.2378e-01],\n        [-1.4202e-01,  1.1559e-01, -2.5443e-01, -3.0391e-01,  2.0318e-01,\n         -2.3435e-01,  1.8671e-01, -1.9302e-01],\n        [-1.2553e-01,  1.9263e-01, -1.3234e-04, -3.4029e-01, -6.1130e-02,\n          3.6677e-02,  1.7147e-03, -2.6173e-01],\n        [-1.0794e-01,  1.5562e-01, -3.4950e-01, -1.9087e-01,  3.1597e-01,\n         -4.6895e-02, -2.0901e-01, -1.2571e-01],\n        [ 2.5603e-01, -7.4187e-03,  1.0655e-01,  1.7367e-01,  2.1377e-01,\n          7.1979e-02, -3.2086e-01,  7.5615e-03],\n        [ 1.6997e-01,  2.8458e-02,  1.4373e-01, -2.0391e-01, -2.8399e-01,\n          3.2587e-02, -2.0362e-01,  1.3325e-01],\n        [ 1.5328e-01,  3.1650e-01, -4.6866e-02, -1.4229e-01,  4.3488e-02,\n          1.5042e-01, -1.2573e-01,  6.0216e-03],\n        [-3.8210e-02,  1.5320e-01, -1.4535e-01, -2.3116e-02, -3.3057e-01,\n          3.2121e-01, -1.5131e-01, -1.6850e-01],\n        [ 3.1206e-01,  1.7131e-01,  2.1289e-01, -2.2693e-01, -3.2893e-01,\n          9.9833e-02, -1.0278e-01,  2.1343e-01],\n        [ 9.3682e-02, -3.4309e-01,  1.3344e-01,  2.8191e-01,  3.5931e-02,\n         -4.6633e-02,  3.2674e-01, -2.1794e-01],\n        [-3.4803e-01,  2.2826e-01,  4.3264e-02, -5.1727e-02,  1.6856e-01,\n         -4.5452e-03,  2.1259e-01,  2.8713e-01],\n        [-3.4436e-01, -2.8266e-01, -1.5329e-01,  1.7072e-01,  2.1504e-01,\n          2.7258e-01,  3.1801e-02, -8.2062e-02],\n        [ 2.0577e-01,  1.4494e-01,  1.9027e-01,  3.4635e-03, -1.3600e-02,\n          6.6173e-02,  2.3009e-01, -4.9726e-03],\n        [-2.1761e-01, -2.6366e-01,  1.9084e-01, -1.8838e-01,  2.3972e-01,\n          1.1051e-01,  7.3884e-02,  2.8657e-01],\n        [ 1.4377e-01, -1.1500e-02,  2.7471e-01, -3.3229e-01,  1.8392e-02,\n          4.7800e-02, -3.1278e-01, -2.2119e-01],\n        [-1.0321e-01, -1.1779e-01, -1.3728e-01, -1.4122e-01, -1.1727e-03,\n          3.4068e-01,  1.6562e-01, -2.1625e-01],\n        [-2.9516e-01, -1.4310e-01,  1.4610e-01, -8.0413e-02, -5.1622e-02,\n          7.3202e-02, -4.1596e-02, -2.8526e-01],\n        [ 3.4214e-01,  2.7706e-01,  3.0389e-01,  2.7959e-02, -3.3713e-01,\n          3.2179e-01,  2.3455e-01,  9.5487e-02],\n        [ 1.8262e-01, -3.1721e-02, -5.6968e-02,  1.0686e-01,  1.0088e-01,\n         -6.4817e-02,  2.0129e-02,  2.4146e-01],\n        [-3.1467e-01,  7.6873e-02,  2.2107e-01, -2.0486e-01,  2.0860e-01,\n          4.6781e-02,  2.2654e-01, -6.2381e-02],\n        [-3.1689e-01, -2.7719e-01, -5.0818e-02, -2.1167e-01, -4.2197e-02,\n         -4.4164e-02, -3.1812e-01, -3.6555e-02],\n        [-2.4730e-01, -8.8574e-02,  4.1595e-02, -3.2521e-03,  7.7103e-02,\n         -3.4934e-01,  1.9755e-01,  3.2707e-01],\n        [ 2.9266e-01, -5.7519e-02, -1.6678e-02,  3.3214e-01, -1.6091e-01,\n          2.2182e-01, -1.1333e-02,  2.0983e-02],\n        [-2.8545e-01, -1.6332e-01, -6.5055e-02, -1.0622e-01, -2.0003e-01,\n          3.1251e-01,  2.0465e-01,  8.4189e-02],\n        [ 2.5860e-01, -7.1029e-03,  8.9773e-03,  1.3475e-01, -2.7426e-01,\n         -1.8744e-01,  1.3798e-01, -2.8624e-01],\n        [-2.9940e-01, -3.0244e-01, -3.2043e-01,  3.3462e-01, -2.0026e-01,\n         -1.8243e-01,  3.4503e-02, -1.8499e-01],\n        [ 1.8973e-01,  1.0881e-01,  1.6871e-01,  1.0389e-01,  1.6782e-01,\n         -1.1762e-01, -2.7471e-01,  2.6984e-01],\n        [-2.0370e-01, -1.1529e-01, -1.2771e-01, -3.4310e-01, -1.8204e-01,\n         -2.2962e-01, -3.4577e-02,  2.4499e-02],\n        [ 3.4361e-01,  3.2521e-01,  2.8145e-01, -7.6356e-02, -3.0052e-01,\n         -8.6205e-02, -1.8254e-01,  1.3882e-01],\n        [ 1.5440e-01,  2.1700e-01, -2.1572e-01, -1.9210e-01, -1.3858e-01,\n         -1.8097e-01, -7.7166e-02, -1.7947e-01],\n        [-8.6220e-02,  1.4861e-01, -2.4767e-01,  4.1618e-02,  1.5087e-01,\n          2.8004e-01, -3.0776e-01, -1.7792e-01],\n        [-1.5001e-01,  8.3192e-02, -4.2597e-02,  2.8153e-02,  3.1864e-01,\n          7.3342e-02, -2.5658e-01, -1.2151e-01],\n        [-3.3923e-01, -3.1165e-01, -1.7816e-01, -2.7176e-02, -8.3294e-02,\n         -2.6840e-01, -1.8843e-01,  9.3536e-02],\n        [-2.8136e-01, -4.6687e-02, -1.8921e-01, -2.7253e-01, -2.4420e-02,\n         -2.2016e-01,  5.5825e-02,  2.6021e-01],\n        [-1.8755e-01, -2.1986e-01, -6.9860e-02, -2.2227e-01,  9.6423e-02,\n         -1.9041e-01,  6.4508e-02, -2.1323e-01],\n        [-1.1887e-01,  3.2179e-01,  3.1808e-01, -3.2546e-01, -7.7043e-02,\n          2.1398e-01, -3.3055e-01, -4.8600e-02],\n        [-1.2180e-01,  2.3578e-01,  1.6016e-01,  3.4857e-01, -2.3695e-02,\n          4.7390e-02, -2.3401e-01, -1.6219e-01],\n        [-2.5487e-01,  2.0314e-01, -9.9576e-02,  1.9684e-01,  2.6070e-02,\n          3.0887e-01, -2.6156e-02, -2.3339e-01],\n        [-1.2587e-01,  1.9311e-01, -2.1603e-01,  3.6672e-02, -2.2820e-01,\n         -1.7377e-01, -1.6555e-01, -2.8993e-01],\n        [-3.7663e-02, -1.9406e-01, -2.8988e-01,  1.9900e-02, -2.7452e-01,\n         -1.3828e-01,  2.9921e-01,  1.3650e-01],\n        [-2.8749e-01,  1.3586e-01,  1.9055e-01, -3.3404e-01,  1.0871e-01,\n          2.9443e-01, -2.7133e-01,  2.3806e-01],\n        [-6.7177e-02, -2.0834e-01, -2.1217e-01,  2.0642e-01, -1.8053e-01,\n          3.0821e-01, -2.9270e-01,  3.1194e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0169, -0.0183,  0.0275, -0.0626, -0.0779,  0.0446,  0.0335, -0.0501,\n        -0.0444, -0.0111,  0.0575, -0.0430,  0.0454, -0.0938, -0.0147, -0.0778,\n         0.0559,  0.0266, -0.0199, -0.0715, -0.0858,  0.0777, -0.0183, -0.0731,\n         0.0486, -0.0631, -0.0336,  0.0165,  0.0127, -0.0813,  0.0269, -0.0135,\n         0.0498,  0.0237,  0.0271, -0.0069,  0.0894, -0.0798,  0.0021,  0.0985,\n         0.0220,  0.0880,  0.0292, -0.0063,  0.0513,  0.0990, -0.0576,  0.0405,\n        -0.0449,  0.0086,  0.0270,  0.0651, -0.0184, -0.0766, -0.0573,  0.0475,\n        -0.0948, -0.0994, -0.0409,  0.0633,  0.0606, -0.0104, -0.0732,  0.0155,\n        -0.0223, -0.0933,  0.0313, -0.0622, -0.0237,  0.0364,  0.0744, -0.0466,\n        -0.0104, -0.0412, -0.0736,  0.0744,  0.0222,  0.0792,  0.0698,  0.0312,\n        -0.0654, -0.0100, -0.0159,  0.0343,  0.0260, -0.0544, -0.0831, -0.0550,\n        -0.0194, -0.0486,  0.0551, -0.0445, -0.0226,  0.0439, -0.0325, -0.0110,\n         0.0977, -0.0239,  0.0728, -0.0490], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0555, -0.0865, -0.0559,  ..., -0.0145, -0.0447,  0.0526],\n        [-0.0235,  0.0299,  0.0242,  ..., -0.0422, -0.0248,  0.0618],\n        [-0.0451, -0.0087, -0.0058,  ...,  0.0038,  0.0823, -0.0786],\n        ...,\n        [-0.0934,  0.0454,  0.0197,  ...,  0.0238, -0.0603,  0.0607],\n        [-0.0238,  0.0885,  0.0708,  ...,  0.0347,  0.0489,  0.0798],\n        [ 0.0984, -0.0474, -0.0824,  ..., -0.0830, -0.0116, -0.0196]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0742,  0.0891, -0.0438, -0.0536], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0492,  0.0685, -0.0778, -0.0896,  0.0387, -0.0949, -0.0276, -0.0958,\n         -0.0071, -0.0194,  0.0860, -0.0050,  0.0278,  0.0298, -0.0980,  0.0677,\n         -0.0180,  0.0334, -0.0418, -0.0407,  0.0697, -0.0749, -0.0675, -0.0706,\n          0.0168, -0.0862, -0.0417, -0.0927, -0.0747, -0.0349,  0.0894, -0.0003,\n          0.0054,  0.0061,  0.0761, -0.0931,  0.0105, -0.0614, -0.0172,  0.0687,\n         -0.0767,  0.0903, -0.0369,  0.0021,  0.0183,  0.0489,  0.0320,  0.0677,\n         -0.0337,  0.0528,  0.0948, -0.0934, -0.0099, -0.0729, -0.0240,  0.0811,\n          0.0549, -0.0445, -0.0340,  0.0402,  0.0750,  0.0463, -0.0119, -0.0507,\n          0.0507,  0.0885,  0.0189,  0.0673,  0.0912,  0.0591,  0.0781, -0.0348,\n         -0.0706,  0.0471,  0.0104,  0.0997,  0.0350, -0.0568,  0.0941, -0.0209,\n          0.0251,  0.0181,  0.0510, -0.0174, -0.0663,  0.0277, -0.0713, -0.0008,\n         -0.0413,  0.0184,  0.0420, -0.0418, -0.0154,  0.0735, -0.0486, -0.0479,\n         -0.0793, -0.0006, -0.0814,  0.0098],\n        [-0.0109,  0.0184, -0.0084, -0.0829,  0.0544, -0.0488,  0.0647, -0.0355,\n          0.0879,  0.0889,  0.0290, -0.0708, -0.0518,  0.0107,  0.0798,  0.0489,\n          0.0377, -0.0737,  0.0576,  0.0657,  0.0870,  0.0159,  0.0638,  0.0748,\n          0.0427,  0.0014,  0.0028, -0.0135, -0.0755, -0.0254,  0.0473, -0.0259,\n         -0.0848,  0.0346, -0.0341,  0.0210, -0.0777,  0.0910, -0.0056,  0.0351,\n         -0.0756, -0.0676,  0.0772,  0.0420, -0.0045, -0.0697,  0.0973,  0.0711,\n          0.0313, -0.0786,  0.0237,  0.0669, -0.0899,  0.0031,  0.0752,  0.0096,\n         -0.0622,  0.0390, -0.0909,  0.0797, -0.0065,  0.0698, -0.0879,  0.0559,\n         -0.0544, -0.0102, -0.0357,  0.0946,  0.0173, -0.0020,  0.0921,  0.0208,\n         -0.0431,  0.0930,  0.0524, -0.0441,  0.0432, -0.0067,  0.0294, -0.0972,\n         -0.0600,  0.0220,  0.0375, -0.0987,  0.0765, -0.0251,  0.0364, -0.0271,\n         -0.0818,  0.0823, -0.0985,  0.0572, -0.0914, -0.0646, -0.0044, -0.0632,\n          0.0044,  0.0610, -0.0492,  0.0127],\n        [ 0.0137, -0.0241,  0.0308,  0.0845,  0.0523, -0.0423, -0.0065, -0.0318,\n          0.0030, -0.0577, -0.0191,  0.0025,  0.0906,  0.0528,  0.0556,  0.0167,\n          0.0357,  0.0321,  0.0673, -0.0349,  0.0469, -0.0979, -0.0565, -0.0424,\n          0.0188, -0.0770, -0.0461,  0.0787,  0.0635, -0.0945, -0.0910,  0.0253,\n          0.0257, -0.0792, -0.0297,  0.0332,  0.0878, -0.0662,  0.0867, -0.0361,\n          0.0369,  0.0536, -0.0588,  0.0836,  0.0704,  0.0323, -0.0471,  0.0989,\n          0.0273,  0.0161,  0.0699, -0.0982, -0.0218,  0.0316,  0.0858, -0.0256,\n          0.0725, -0.0209,  0.0964,  0.0789, -0.0552, -0.0558, -0.0317, -0.0720,\n         -0.0428,  0.0987,  0.0687, -0.0147, -0.0428,  0.0455, -0.0706,  0.0934,\n         -0.0973,  0.0094,  0.0082, -0.0513, -0.0330, -0.0219, -0.0844,  0.0509,\n         -0.0523, -0.0589, -0.0610, -0.0883,  0.0724,  0.0239, -0.0043,  0.0527,\n         -0.0762, -0.0740, -0.0872, -0.0786, -0.0676, -0.0321,  0.0173,  0.0990,\n          0.0571, -0.0841, -0.0154, -0.0386],\n        [ 0.0956, -0.0702,  0.0689,  0.0625, -0.0865,  0.0220,  0.0595,  0.0406,\n          0.0578,  0.0334, -0.0888, -0.0229,  0.0546, -0.0294, -0.0029,  0.0901,\n         -0.0556, -0.0335,  0.0447, -0.0780,  0.0109,  0.0417, -0.0169,  0.0043,\n         -0.0721,  0.0199, -0.0558, -0.0915,  0.0559, -0.0244, -0.0770,  0.0391,\n         -0.0755, -0.0948, -0.0420,  0.0994, -0.0809, -0.0865, -0.0002,  0.0641,\n          0.0198, -0.0089, -0.0862, -0.0874,  0.0446,  0.0905, -0.0117,  0.0489,\n          0.0942,  0.0689,  0.0483,  0.0935, -0.0065,  0.0733, -0.0873,  0.0434,\n         -0.0137, -0.0333, -0.0167,  0.0314, -0.0709, -0.0530, -0.0778,  0.0174,\n          0.0688,  0.0336,  0.0005, -0.0366, -0.0125, -0.0083, -0.0629,  0.0516,\n          0.0923,  0.0555, -0.0955, -0.0353, -0.0064, -0.0216, -0.0891, -0.0333,\n          0.0605, -0.0938, -0.0642, -0.0840,  0.0219, -0.0392,  0.0954,  0.0571,\n          0.0488,  0.0523,  0.0765, -0.0250,  0.0681, -0.0593,  0.0774, -0.0964,\n         -0.0384, -0.0397,  0.0770,  0.0310]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 2.9748e-03,  8.4294e-02,  1.2342e-01, -2.3507e-01,  1.9911e-01,\n         -1.7844e-01, -3.0797e-04, -1.4470e-01],\n        [-1.6318e-02, -5.3577e-02, -2.9744e-02, -3.0170e-01, -2.3799e-01,\n         -2.2034e-01, -6.8711e-02, -2.9936e-01],\n        [-1.6471e-01, -6.7591e-02, -5.3768e-02,  1.1793e-02, -1.2301e-01,\n         -2.0481e-01,  9.3542e-02,  1.4765e-01],\n        [-2.8194e-01,  1.9954e-02, -1.4080e-01, -2.6764e-01,  4.6485e-02,\n          3.4131e-01, -1.5602e-01,  5.3317e-02],\n        [ 2.8818e-01,  1.3701e-01, -2.4789e-02,  1.3483e-01, -7.3237e-02,\n         -2.3121e-01, -3.0718e-01,  2.4715e-02],\n        [ 4.9273e-03,  1.7114e-02,  3.3476e-01, -2.3572e-01,  1.9136e-01,\n          2.3175e-01, -3.5289e-01, -1.2585e-02],\n        [ 9.1889e-02,  1.9314e-01, -3.2886e-01, -3.5001e-01,  7.2053e-02,\n          3.2966e-01, -1.6632e-01,  9.3680e-02],\n        [ 1.3075e-01,  1.4838e-01,  2.9958e-01, -3.0006e-01,  1.5587e-01,\n          1.1268e-01, -3.2680e-01,  2.1581e-01],\n        [-3.4247e-01,  1.7037e-01,  8.7362e-02, -5.5735e-02, -1.1676e-01,\n         -3.1026e-01, -1.7033e-01,  7.7651e-02],\n        [-3.4650e-01,  2.1113e-01,  2.7016e-01,  3.0883e-01,  2.3230e-03,\n          1.4958e-01,  3.4897e-01, -2.2816e-01],\n        [ 2.4307e-01,  3.2930e-01, -1.2943e-01,  1.6384e-01, -1.1741e-01,\n         -2.9876e-01,  6.4873e-02,  1.9558e-01],\n        [ 4.0997e-02,  3.1267e-01, -1.8977e-01, -1.9898e-01, -4.9696e-02,\n         -1.1334e-01, -1.6273e-01,  3.0488e-01],\n        [-1.1870e-01,  1.6191e-01,  1.1881e-01,  1.2657e-01,  1.4564e-01,\n         -2.1125e-01, -8.9203e-02, -6.4772e-02],\n        [-9.1037e-02, -2.2079e-02, -2.9478e-01,  3.4186e-01,  6.4514e-02,\n         -2.4789e-01,  1.9748e-01, -1.7760e-01],\n        [-2.5457e-01,  9.0377e-02,  2.7305e-01, -2.6712e-01, -2.2855e-01,\n         -2.9081e-01,  3.3374e-01,  5.1282e-02],\n        [-1.2665e-01, -3.2786e-01,  3.3227e-01,  1.0945e-01,  9.9157e-02,\n         -9.3388e-02,  8.2819e-02, -2.1495e-01],\n        [ 2.6734e-01, -1.4983e-02, -7.1995e-02,  1.7520e-01, -9.0003e-02,\n          3.4062e-01,  1.5183e-02,  2.2339e-02],\n        [ 1.6998e-01, -3.1959e-01, -7.7686e-02, -7.2281e-03, -1.1206e-01,\n         -2.7663e-01, -1.3725e-01, -4.0634e-02],\n        [-1.1798e-01, -1.5320e-02,  7.0902e-02,  3.2417e-01, -2.1024e-02,\n          3.0407e-01, -2.9512e-01, -2.9494e-01],\n        [-2.1373e-01, -3.0382e-01,  2.0946e-01,  2.4969e-01,  3.3896e-01,\n         -9.3806e-02, -5.9223e-02, -2.2277e-01],\n        [ 5.6163e-02,  2.2929e-02,  9.5758e-02,  3.3325e-01,  1.6446e-01,\n         -2.1127e-01,  1.4649e-01,  2.2869e-01],\n        [-1.6861e-01, -5.7741e-02, -3.3408e-01, -8.2841e-02, -3.7632e-02,\n         -2.4311e-01,  9.6803e-02, -2.2977e-01],\n        [ 4.8957e-02, -2.7979e-01, -2.5172e-01, -2.9263e-01,  1.0765e-01,\n         -3.3201e-01,  4.5825e-02,  2.0991e-01],\n        [ 3.1083e-01,  1.1324e-01,  2.0094e-01, -1.8458e-01,  1.2394e-01,\n          6.7922e-02, -2.4921e-01,  2.0720e-01],\n        [-1.1495e-01,  2.8810e-01, -2.7190e-01,  1.8358e-01,  1.0612e-01,\n         -3.5446e-02, -9.8957e-02,  3.3169e-02],\n        [-2.2445e-01, -5.5246e-03, -8.7510e-02,  5.4309e-02, -2.5709e-01,\n          2.6061e-01,  3.3814e-01,  2.1284e-01],\n        [-1.7608e-01, -2.5626e-01,  3.2249e-01,  2.0347e-02,  7.4053e-02,\n         -3.1271e-01, -3.3199e-01,  1.4876e-01],\n        [-4.8731e-02, -2.5273e-01,  1.1464e-01, -3.2980e-01,  2.4633e-01,\n          1.7344e-01,  2.0913e-01, -2.0792e-01],\n        [-1.7462e-01, -2.1670e-01,  2.3393e-01, -3.3939e-01,  1.0218e-01,\n          3.3339e-01,  1.4037e-01, -1.5128e-01],\n        [ 1.5309e-01,  3.0055e-02,  1.3770e-01,  2.0537e-01,  6.8926e-02,\n         -1.9416e-01,  5.9202e-02,  2.5619e-01],\n        [ 2.0536e-01, -1.4683e-01, -6.0207e-02, -1.5521e-01, -2.8703e-01,\n          2.0850e-02, -2.5442e-01,  1.2948e-01],\n        [-4.4770e-02,  2.0350e-01, -1.2131e-01,  3.7323e-02, -1.1518e-01,\n         -2.8787e-01, -2.2356e-01,  2.7333e-01],\n        [ 1.2126e-01,  2.7364e-01,  2.0671e-02,  2.3846e-01, -1.3210e-01,\n          3.2329e-01, -2.0170e-01, -2.9788e-01],\n        [ 1.4936e-01,  2.1166e-01,  1.5605e-01, -1.3751e-01, -2.9802e-01,\n          8.7612e-02, -1.4326e-01, -1.3137e-01],\n        [ 1.2046e-01, -2.9449e-01, -1.5550e-01,  3.1717e-01, -3.0997e-01,\n          1.1207e-01, -3.3823e-01,  3.3996e-02],\n        [ 2.1001e-01, -2.1680e-01,  1.8490e-01,  1.0873e-01,  2.3209e-01,\n         -9.1216e-02,  6.7511e-02, -1.6732e-01],\n        [ 3.1658e-01, -8.9631e-03, -1.5562e-01, -6.7444e-02,  8.9129e-02,\n         -2.6642e-01, -9.6802e-02,  1.7079e-01],\n        [ 3.3049e-01,  2.8036e-01,  2.5519e-01, -2.9925e-01,  2.5454e-01,\n         -6.0795e-02, -2.7168e-01,  3.3064e-01],\n        [ 3.0721e-02,  5.9677e-02,  2.8974e-02, -2.2088e-01, -1.8133e-01,\n         -7.8193e-02, -2.7584e-01, -2.5852e-01],\n        [-2.2270e-01, -2.1661e-01, -5.0219e-02, -3.2975e-01,  1.0113e-01,\n          1.3781e-02, -2.6228e-01,  3.5128e-01],\n        [-2.6343e-01, -9.6972e-02,  2.4279e-01, -1.2919e-01,  2.6305e-01,\n          1.3798e-01, -3.5110e-01, -1.5422e-01],\n        [ 3.4177e-02,  2.0343e-01,  1.7650e-01, -3.4204e-01, -2.2546e-01,\n         -2.5950e-01,  6.7323e-02, -2.5696e-01],\n        [ 3.4346e-01,  4.9882e-03, -1.1842e-01, -1.5518e-01, -6.5704e-02,\n         -9.3659e-02,  2.7962e-01,  1.9876e-01],\n        [-2.7409e-02,  4.2623e-02,  3.5265e-01,  2.9270e-01, -2.2509e-01,\n          3.3587e-01,  3.3243e-01,  9.8178e-03],\n        [ 1.9930e-01,  7.3311e-02,  3.3093e-01,  2.6566e-01,  2.4261e-01,\n          3.4593e-01,  7.7094e-02,  2.8836e-01],\n        [ 1.0728e-01, -2.9835e-01, -6.1979e-02, -2.5607e-01, -9.0408e-02,\n         -2.3775e-01, -1.1306e-01,  8.2293e-02],\n        [-2.6252e-01, -6.6501e-02,  9.0545e-02, -2.9122e-01,  1.4649e-01,\n          1.1691e-02, -5.0900e-02,  2.4433e-01],\n        [ 2.0284e-01, -2.6161e-01, -3.0089e-01, -9.6077e-02,  2.5926e-01,\n         -1.1950e-01,  1.9879e-01, -2.7254e-01],\n        [ 1.6192e-01, -3.4880e-01,  4.8747e-02,  8.3803e-02, -2.8542e-02,\n          1.7947e-01,  2.9873e-01, -3.1933e-01],\n        [ 1.0290e-02,  2.7295e-01, -6.4525e-03, -1.4541e-01,  2.7870e-01,\n         -1.9935e-01,  1.0563e-01,  3.3262e-01],\n        [ 3.0726e-01, -1.0622e-01, -2.4209e-01, -1.2052e-01, -6.4249e-02,\n          1.5180e-02, -3.1551e-01, -3.0994e-02],\n        [-3.2063e-01, -2.9178e-01, -3.3405e-01,  2.4647e-02,  2.9219e-01,\n         -8.3673e-02,  1.9953e-01, -1.1562e-01],\n        [ 1.0353e-01, -3.5216e-01, -1.9727e-01,  2.4028e-01, -3.3500e-01,\n          2.1311e-01, -7.6660e-02,  1.9762e-01],\n        [ 2.9260e-01, -3.4170e-01, -1.7366e-02, -1.8494e-01,  2.7426e-01,\n         -1.5127e-01, -1.8822e-01,  1.6603e-01],\n        [-1.7101e-01,  6.4897e-03, -1.4058e-01, -5.0600e-02,  3.2030e-01,\n         -6.9281e-02,  2.2291e-01, -3.2560e-02],\n        [-2.2025e-01, -2.3697e-01,  5.7284e-02, -1.6236e-01, -2.5542e-01,\n         -1.6086e-01, -3.3915e-01, -6.8613e-02],\n        [-3.1419e-01,  1.0461e-01, -2.8124e-01, -2.9945e-01,  3.0467e-01,\n         -2.3638e-01, -2.4307e-01, -3.0507e-01],\n        [ 2.1683e-01, -1.5146e-01,  3.2550e-01, -3.0021e-01, -1.6487e-01,\n          3.4399e-01, -6.3326e-02,  2.2435e-01],\n        [ 1.4275e-01,  2.2930e-01,  7.7265e-02, -2.8608e-01,  1.6003e-01,\n          6.8398e-02,  9.9757e-02,  3.2378e-01],\n        [-1.4202e-01,  1.1559e-01, -2.5443e-01, -3.0391e-01,  2.0318e-01,\n         -2.3435e-01,  1.8671e-01, -1.9302e-01],\n        [-1.2553e-01,  1.9263e-01, -1.3234e-04, -3.4029e-01, -6.1130e-02,\n          3.6677e-02,  1.7147e-03, -2.6173e-01],\n        [-1.0794e-01,  1.5562e-01, -3.4950e-01, -1.9087e-01,  3.1597e-01,\n         -4.6895e-02, -2.0901e-01, -1.2571e-01],\n        [ 2.5603e-01, -7.4187e-03,  1.0655e-01,  1.7367e-01,  2.1377e-01,\n          7.1979e-02, -3.2086e-01,  7.5615e-03],\n        [ 1.6997e-01,  2.8458e-02,  1.4373e-01, -2.0391e-01, -2.8399e-01,\n          3.2587e-02, -2.0362e-01,  1.3325e-01],\n        [ 1.5328e-01,  3.1650e-01, -4.6866e-02, -1.4229e-01,  4.3488e-02,\n          1.5042e-01, -1.2573e-01,  6.0216e-03],\n        [-3.8210e-02,  1.5320e-01, -1.4535e-01, -2.3116e-02, -3.3057e-01,\n          3.2121e-01, -1.5131e-01, -1.6850e-01],\n        [ 3.1206e-01,  1.7131e-01,  2.1289e-01, -2.2693e-01, -3.2893e-01,\n          9.9833e-02, -1.0278e-01,  2.1343e-01],\n        [ 9.3682e-02, -3.4309e-01,  1.3344e-01,  2.8191e-01,  3.5931e-02,\n         -4.6633e-02,  3.2674e-01, -2.1794e-01],\n        [-3.4803e-01,  2.2826e-01,  4.3264e-02, -5.1727e-02,  1.6856e-01,\n         -4.5452e-03,  2.1259e-01,  2.8713e-01],\n        [-3.4436e-01, -2.8266e-01, -1.5329e-01,  1.7072e-01,  2.1504e-01,\n          2.7258e-01,  3.1801e-02, -8.2062e-02],\n        [ 2.0577e-01,  1.4494e-01,  1.9027e-01,  3.4635e-03, -1.3600e-02,\n          6.6173e-02,  2.3009e-01, -4.9726e-03],\n        [-2.1761e-01, -2.6366e-01,  1.9084e-01, -1.8838e-01,  2.3972e-01,\n          1.1051e-01,  7.3884e-02,  2.8657e-01],\n        [ 1.4377e-01, -1.1500e-02,  2.7471e-01, -3.3229e-01,  1.8392e-02,\n          4.7800e-02, -3.1278e-01, -2.2119e-01],\n        [-1.0321e-01, -1.1779e-01, -1.3728e-01, -1.4122e-01, -1.1727e-03,\n          3.4068e-01,  1.6562e-01, -2.1625e-01],\n        [-2.9516e-01, -1.4310e-01,  1.4610e-01, -8.0413e-02, -5.1622e-02,\n          7.3202e-02, -4.1596e-02, -2.8526e-01],\n        [ 3.4214e-01,  2.7706e-01,  3.0389e-01,  2.7959e-02, -3.3713e-01,\n          3.2179e-01,  2.3455e-01,  9.5487e-02],\n        [ 1.8262e-01, -3.1721e-02, -5.6968e-02,  1.0686e-01,  1.0088e-01,\n         -6.4817e-02,  2.0129e-02,  2.4146e-01],\n        [-3.1467e-01,  7.6873e-02,  2.2107e-01, -2.0486e-01,  2.0860e-01,\n          4.6781e-02,  2.2654e-01, -6.2381e-02],\n        [-3.1689e-01, -2.7719e-01, -5.0818e-02, -2.1167e-01, -4.2197e-02,\n         -4.4164e-02, -3.1812e-01, -3.6555e-02],\n        [-2.4730e-01, -8.8574e-02,  4.1595e-02, -3.2521e-03,  7.7103e-02,\n         -3.4934e-01,  1.9755e-01,  3.2707e-01],\n        [ 2.9266e-01, -5.7519e-02, -1.6678e-02,  3.3214e-01, -1.6091e-01,\n          2.2182e-01, -1.1333e-02,  2.0983e-02],\n        [-2.8545e-01, -1.6332e-01, -6.5055e-02, -1.0622e-01, -2.0003e-01,\n          3.1251e-01,  2.0465e-01,  8.4189e-02],\n        [ 2.5860e-01, -7.1029e-03,  8.9773e-03,  1.3475e-01, -2.7426e-01,\n         -1.8744e-01,  1.3798e-01, -2.8624e-01],\n        [-2.9940e-01, -3.0244e-01, -3.2043e-01,  3.3462e-01, -2.0026e-01,\n         -1.8243e-01,  3.4503e-02, -1.8499e-01],\n        [ 1.8973e-01,  1.0881e-01,  1.6871e-01,  1.0389e-01,  1.6782e-01,\n         -1.1762e-01, -2.7471e-01,  2.6984e-01],\n        [-2.0370e-01, -1.1529e-01, -1.2771e-01, -3.4310e-01, -1.8204e-01,\n         -2.2962e-01, -3.4577e-02,  2.4499e-02],\n        [ 3.4361e-01,  3.2521e-01,  2.8145e-01, -7.6356e-02, -3.0052e-01,\n         -8.6205e-02, -1.8254e-01,  1.3882e-01],\n        [ 1.5440e-01,  2.1700e-01, -2.1572e-01, -1.9210e-01, -1.3858e-01,\n         -1.8097e-01, -7.7166e-02, -1.7947e-01],\n        [-8.6220e-02,  1.4861e-01, -2.4767e-01,  4.1618e-02,  1.5087e-01,\n          2.8004e-01, -3.0776e-01, -1.7792e-01],\n        [-1.5001e-01,  8.3192e-02, -4.2597e-02,  2.8153e-02,  3.1864e-01,\n          7.3342e-02, -2.5658e-01, -1.2151e-01],\n        [-3.3923e-01, -3.1165e-01, -1.7816e-01, -2.7176e-02, -8.3294e-02,\n         -2.6840e-01, -1.8843e-01,  9.3536e-02],\n        [-2.8136e-01, -4.6687e-02, -1.8921e-01, -2.7253e-01, -2.4420e-02,\n         -2.2016e-01,  5.5825e-02,  2.6021e-01],\n        [-1.8755e-01, -2.1986e-01, -6.9860e-02, -2.2227e-01,  9.6423e-02,\n         -1.9041e-01,  6.4508e-02, -2.1323e-01],\n        [-1.1887e-01,  3.2179e-01,  3.1808e-01, -3.2546e-01, -7.7043e-02,\n          2.1398e-01, -3.3055e-01, -4.8600e-02],\n        [-1.2180e-01,  2.3578e-01,  1.6016e-01,  3.4857e-01, -2.3695e-02,\n          4.7390e-02, -2.3401e-01, -1.6219e-01],\n        [-2.5487e-01,  2.0314e-01, -9.9576e-02,  1.9684e-01,  2.6070e-02,\n          3.0887e-01, -2.6156e-02, -2.3339e-01],\n        [-1.2587e-01,  1.9311e-01, -2.1603e-01,  3.6672e-02, -2.2820e-01,\n         -1.7377e-01, -1.6555e-01, -2.8993e-01],\n        [-3.7663e-02, -1.9406e-01, -2.8988e-01,  1.9900e-02, -2.7452e-01,\n         -1.3828e-01,  2.9921e-01,  1.3650e-01],\n        [-2.8749e-01,  1.3586e-01,  1.9055e-01, -3.3404e-01,  1.0871e-01,\n          2.9443e-01, -2.7133e-01,  2.3806e-01],\n        [-6.7177e-02, -2.0834e-01, -2.1217e-01,  2.0642e-01, -1.8053e-01,\n          3.0821e-01, -2.9270e-01,  3.1194e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2696,  0.3372,  0.1362,  0.3155, -0.3345,  0.2465, -0.2765,  0.2562,\n         0.1020, -0.3111, -0.3265, -0.3038,  0.1851, -0.3230, -0.3160, -0.2045,\n         0.1727, -0.2105, -0.0520,  0.1177, -0.1006, -0.1189, -0.1319,  0.3154,\n         0.2140, -0.0124, -0.1878, -0.3266,  0.1126,  0.0435, -0.2781, -0.2871,\n        -0.0555,  0.2723,  0.0939, -0.2167,  0.2589,  0.1000,  0.0964,  0.0631,\n        -0.2206, -0.1245,  0.0487, -0.0180,  0.0073, -0.1975,  0.2111, -0.1470,\n        -0.1335, -0.0934,  0.1105, -0.1876,  0.3075,  0.3427, -0.1940,  0.0437,\n         0.3061, -0.0378, -0.1773, -0.1761, -0.0209, -0.3051, -0.1529,  0.2541,\n        -0.1346,  0.2204,  0.1418,  0.2420,  0.1689, -0.2588, -0.2540, -0.1447,\n        -0.3442,  0.2323, -0.2853, -0.2633,  0.1680,  0.0774,  0.1667,  0.0896,\n        -0.2460,  0.2362,  0.2888, -0.0983, -0.1412,  0.1480, -0.2093, -0.2713,\n        -0.0618,  0.0326, -0.1881, -0.3317,  0.2937,  0.0641,  0.0169,  0.2794,\n        -0.1529,  0.3414,  0.0080, -0.1123], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0555, -0.0865, -0.0559,  ..., -0.0145, -0.0447,  0.0526],\n        [-0.0235,  0.0299,  0.0242,  ..., -0.0422, -0.0248,  0.0618],\n        [-0.0451, -0.0087, -0.0058,  ...,  0.0038,  0.0823, -0.0786],\n        ...,\n        [-0.0934,  0.0454,  0.0197,  ...,  0.0238, -0.0603,  0.0607],\n        [-0.0238,  0.0885,  0.0708,  ...,  0.0347,  0.0489,  0.0798],\n        [ 0.0984, -0.0474, -0.0824,  ..., -0.0830, -0.0116, -0.0196]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0169, -0.0183,  0.0275, -0.0626, -0.0779,  0.0446,  0.0335, -0.0501,\n        -0.0444, -0.0111,  0.0575, -0.0430,  0.0454, -0.0938, -0.0147, -0.0778,\n         0.0559,  0.0266, -0.0199, -0.0715, -0.0858,  0.0777, -0.0183, -0.0731,\n         0.0486, -0.0631, -0.0336,  0.0165,  0.0127, -0.0813,  0.0269, -0.0135,\n         0.0498,  0.0237,  0.0271, -0.0069,  0.0894, -0.0798,  0.0021,  0.0985,\n         0.0220,  0.0880,  0.0292, -0.0063,  0.0513,  0.0990, -0.0576,  0.0405,\n        -0.0449,  0.0086,  0.0270,  0.0651, -0.0184, -0.0766, -0.0573,  0.0475,\n        -0.0948, -0.0994, -0.0409,  0.0633,  0.0606, -0.0104, -0.0732,  0.0155,\n        -0.0223, -0.0933,  0.0313, -0.0622, -0.0237,  0.0364,  0.0744, -0.0466,\n        -0.0104, -0.0412, -0.0736,  0.0744,  0.0222,  0.0792,  0.0698,  0.0312,\n        -0.0654, -0.0100, -0.0159,  0.0343,  0.0260, -0.0544, -0.0831, -0.0550,\n        -0.0194, -0.0486,  0.0551, -0.0445, -0.0226,  0.0439, -0.0325, -0.0110,\n         0.0977, -0.0239,  0.0728, -0.0490], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0492,  0.0685, -0.0778, -0.0896,  0.0387, -0.0949, -0.0276, -0.0958,\n         -0.0071, -0.0194,  0.0860, -0.0050,  0.0278,  0.0298, -0.0980,  0.0677,\n         -0.0180,  0.0334, -0.0418, -0.0407,  0.0697, -0.0749, -0.0675, -0.0706,\n          0.0168, -0.0862, -0.0417, -0.0927, -0.0747, -0.0349,  0.0894, -0.0003,\n          0.0054,  0.0061,  0.0761, -0.0931,  0.0105, -0.0614, -0.0172,  0.0687,\n         -0.0767,  0.0903, -0.0369,  0.0021,  0.0183,  0.0489,  0.0320,  0.0677,\n         -0.0337,  0.0528,  0.0948, -0.0934, -0.0099, -0.0729, -0.0240,  0.0811,\n          0.0549, -0.0445, -0.0340,  0.0402,  0.0750,  0.0463, -0.0119, -0.0507,\n          0.0507,  0.0885,  0.0189,  0.0673,  0.0912,  0.0591,  0.0781, -0.0348,\n         -0.0706,  0.0471,  0.0104,  0.0997,  0.0350, -0.0568,  0.0941, -0.0209,\n          0.0251,  0.0181,  0.0510, -0.0174, -0.0663,  0.0277, -0.0713, -0.0008,\n         -0.0413,  0.0184,  0.0420, -0.0418, -0.0154,  0.0735, -0.0486, -0.0479,\n         -0.0793, -0.0006, -0.0814,  0.0098],\n        [-0.0109,  0.0184, -0.0084, -0.0829,  0.0544, -0.0488,  0.0647, -0.0355,\n          0.0879,  0.0889,  0.0290, -0.0708, -0.0518,  0.0107,  0.0798,  0.0489,\n          0.0377, -0.0737,  0.0576,  0.0657,  0.0870,  0.0159,  0.0638,  0.0748,\n          0.0427,  0.0014,  0.0028, -0.0135, -0.0755, -0.0254,  0.0473, -0.0259,\n         -0.0848,  0.0346, -0.0341,  0.0210, -0.0777,  0.0910, -0.0056,  0.0351,\n         -0.0756, -0.0676,  0.0772,  0.0420, -0.0045, -0.0697,  0.0973,  0.0711,\n          0.0313, -0.0786,  0.0237,  0.0669, -0.0899,  0.0031,  0.0752,  0.0096,\n         -0.0622,  0.0390, -0.0909,  0.0797, -0.0065,  0.0698, -0.0879,  0.0559,\n         -0.0544, -0.0102, -0.0357,  0.0946,  0.0173, -0.0020,  0.0921,  0.0208,\n         -0.0431,  0.0930,  0.0524, -0.0441,  0.0432, -0.0067,  0.0294, -0.0972,\n         -0.0600,  0.0220,  0.0375, -0.0987,  0.0765, -0.0251,  0.0364, -0.0271,\n         -0.0818,  0.0823, -0.0985,  0.0572, -0.0914, -0.0646, -0.0044, -0.0632,\n          0.0044,  0.0610, -0.0492,  0.0127],\n        [ 0.0137, -0.0241,  0.0308,  0.0845,  0.0523, -0.0423, -0.0065, -0.0318,\n          0.0030, -0.0577, -0.0191,  0.0025,  0.0906,  0.0528,  0.0556,  0.0167,\n          0.0357,  0.0321,  0.0673, -0.0349,  0.0469, -0.0979, -0.0565, -0.0424,\n          0.0188, -0.0770, -0.0461,  0.0787,  0.0635, -0.0945, -0.0910,  0.0253,\n          0.0257, -0.0792, -0.0297,  0.0332,  0.0878, -0.0662,  0.0867, -0.0361,\n          0.0369,  0.0536, -0.0588,  0.0836,  0.0704,  0.0323, -0.0471,  0.0989,\n          0.0273,  0.0161,  0.0699, -0.0982, -0.0218,  0.0316,  0.0858, -0.0256,\n          0.0725, -0.0209,  0.0964,  0.0789, -0.0552, -0.0558, -0.0317, -0.0720,\n         -0.0428,  0.0987,  0.0687, -0.0147, -0.0428,  0.0455, -0.0706,  0.0934,\n         -0.0973,  0.0094,  0.0082, -0.0513, -0.0330, -0.0219, -0.0844,  0.0509,\n         -0.0523, -0.0589, -0.0610, -0.0883,  0.0724,  0.0239, -0.0043,  0.0527,\n         -0.0762, -0.0740, -0.0872, -0.0786, -0.0676, -0.0321,  0.0173,  0.0990,\n          0.0571, -0.0841, -0.0154, -0.0386],\n        [ 0.0956, -0.0702,  0.0689,  0.0625, -0.0865,  0.0220,  0.0595,  0.0406,\n          0.0578,  0.0334, -0.0888, -0.0229,  0.0546, -0.0294, -0.0029,  0.0901,\n         -0.0556, -0.0335,  0.0447, -0.0780,  0.0109,  0.0417, -0.0169,  0.0043,\n         -0.0721,  0.0199, -0.0558, -0.0915,  0.0559, -0.0244, -0.0770,  0.0391,\n         -0.0755, -0.0948, -0.0420,  0.0994, -0.0809, -0.0865, -0.0002,  0.0641,\n          0.0198, -0.0089, -0.0862, -0.0874,  0.0446,  0.0905, -0.0117,  0.0489,\n          0.0942,  0.0689,  0.0483,  0.0935, -0.0065,  0.0733, -0.0873,  0.0434,\n         -0.0137, -0.0333, -0.0167,  0.0314, -0.0709, -0.0530, -0.0778,  0.0174,\n          0.0688,  0.0336,  0.0005, -0.0366, -0.0125, -0.0083, -0.0629,  0.0516,\n          0.0923,  0.0555, -0.0955, -0.0353, -0.0064, -0.0216, -0.0891, -0.0333,\n          0.0605, -0.0938, -0.0642, -0.0840,  0.0219, -0.0392,  0.0954,  0.0571,\n          0.0488,  0.0523,  0.0765, -0.0250,  0.0681, -0.0593,  0.0774, -0.0964,\n         -0.0384, -0.0397,  0.0770,  0.0310]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0742,  0.0891, -0.0438, -0.0536], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7e6c8be63250>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2696,  0.3372,  0.1362,  0.3155, -0.3345,  0.2465, -0.2765,  0.2562,\n         0.1020, -0.3111, -0.3265, -0.3038,  0.1851, -0.3230, -0.3160, -0.2045,\n         0.1727, -0.2105, -0.0520,  0.1177, -0.1006, -0.1189, -0.1319,  0.3154,\n         0.2140, -0.0124, -0.1878, -0.3266,  0.1126,  0.0435, -0.2781, -0.2871,\n        -0.0555,  0.2723,  0.0939, -0.2167,  0.2589,  0.1000,  0.0964,  0.0631,\n        -0.2206, -0.1245,  0.0487, -0.0180,  0.0073, -0.1975,  0.2111, -0.1470,\n        -0.1335, -0.0934,  0.1105, -0.1876,  0.3075,  0.3427, -0.1940,  0.0437,\n         0.3061, -0.0378, -0.1773, -0.1761, -0.0209, -0.3051, -0.1529,  0.2541,\n        -0.1346,  0.2204,  0.1418,  0.2420,  0.1689, -0.2588, -0.2540, -0.1447,\n        -0.3442,  0.2323, -0.2853, -0.2633,  0.1680,  0.0774,  0.1667,  0.0896,\n        -0.2460,  0.2362,  0.2888, -0.0983, -0.1412,  0.1480, -0.2093, -0.2713,\n        -0.0618,  0.0326, -0.1881, -0.3317,  0.2937,  0.0641,  0.0169,  0.2794,\n        -0.1529,  0.3414,  0.0080, -0.1123], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 2.9748e-03,  8.4294e-02,  1.2342e-01, -2.3507e-01,  1.9911e-01,\n         -1.7844e-01, -3.0797e-04, -1.4470e-01],\n        [-1.6318e-02, -5.3577e-02, -2.9744e-02, -3.0170e-01, -2.3799e-01,\n         -2.2034e-01, -6.8711e-02, -2.9936e-01],\n        [-1.6471e-01, -6.7591e-02, -5.3768e-02,  1.1793e-02, -1.2301e-01,\n         -2.0481e-01,  9.3542e-02,  1.4765e-01],\n        [-2.8194e-01,  1.9954e-02, -1.4080e-01, -2.6764e-01,  4.6485e-02,\n          3.4131e-01, -1.5602e-01,  5.3317e-02],\n        [ 2.8818e-01,  1.3701e-01, -2.4789e-02,  1.3483e-01, -7.3237e-02,\n         -2.3121e-01, -3.0718e-01,  2.4715e-02],\n        [ 4.9273e-03,  1.7114e-02,  3.3476e-01, -2.3572e-01,  1.9136e-01,\n          2.3175e-01, -3.5289e-01, -1.2585e-02],\n        [ 9.1889e-02,  1.9314e-01, -3.2886e-01, -3.5001e-01,  7.2053e-02,\n          3.2966e-01, -1.6632e-01,  9.3680e-02],\n        [ 1.3075e-01,  1.4838e-01,  2.9958e-01, -3.0006e-01,  1.5587e-01,\n          1.1268e-01, -3.2680e-01,  2.1581e-01],\n        [-3.4247e-01,  1.7037e-01,  8.7362e-02, -5.5735e-02, -1.1676e-01,\n         -3.1026e-01, -1.7033e-01,  7.7651e-02],\n        [-3.4650e-01,  2.1113e-01,  2.7016e-01,  3.0883e-01,  2.3230e-03,\n          1.4958e-01,  3.4897e-01, -2.2816e-01],\n        [ 2.4307e-01,  3.2930e-01, -1.2943e-01,  1.6384e-01, -1.1741e-01,\n         -2.9876e-01,  6.4873e-02,  1.9558e-01],\n        [ 4.0997e-02,  3.1267e-01, -1.8977e-01, -1.9898e-01, -4.9696e-02,\n         -1.1334e-01, -1.6273e-01,  3.0488e-01],\n        [-1.1870e-01,  1.6191e-01,  1.1881e-01,  1.2657e-01,  1.4564e-01,\n         -2.1125e-01, -8.9203e-02, -6.4772e-02],\n        [-9.1037e-02, -2.2079e-02, -2.9478e-01,  3.4186e-01,  6.4514e-02,\n         -2.4789e-01,  1.9748e-01, -1.7760e-01],\n        [-2.5457e-01,  9.0377e-02,  2.7305e-01, -2.6712e-01, -2.2855e-01,\n         -2.9081e-01,  3.3374e-01,  5.1282e-02],\n        [-1.2665e-01, -3.2786e-01,  3.3227e-01,  1.0945e-01,  9.9157e-02,\n         -9.3388e-02,  8.2819e-02, -2.1495e-01],\n        [ 2.6734e-01, -1.4983e-02, -7.1995e-02,  1.7520e-01, -9.0003e-02,\n          3.4062e-01,  1.5183e-02,  2.2339e-02],\n        [ 1.6998e-01, -3.1959e-01, -7.7686e-02, -7.2281e-03, -1.1206e-01,\n         -2.7663e-01, -1.3725e-01, -4.0634e-02],\n        [-1.1798e-01, -1.5320e-02,  7.0902e-02,  3.2417e-01, -2.1024e-02,\n          3.0407e-01, -2.9512e-01, -2.9494e-01],\n        [-2.1373e-01, -3.0382e-01,  2.0946e-01,  2.4969e-01,  3.3896e-01,\n         -9.3806e-02, -5.9223e-02, -2.2277e-01],\n        [ 5.6163e-02,  2.2929e-02,  9.5758e-02,  3.3325e-01,  1.6446e-01,\n         -2.1127e-01,  1.4649e-01,  2.2869e-01],\n        [-1.6861e-01, -5.7741e-02, -3.3408e-01, -8.2841e-02, -3.7632e-02,\n         -2.4311e-01,  9.6803e-02, -2.2977e-01],\n        [ 4.8957e-02, -2.7979e-01, -2.5172e-01, -2.9263e-01,  1.0765e-01,\n         -3.3201e-01,  4.5825e-02,  2.0991e-01],\n        [ 3.1083e-01,  1.1324e-01,  2.0094e-01, -1.8458e-01,  1.2394e-01,\n          6.7922e-02, -2.4921e-01,  2.0720e-01],\n        [-1.1495e-01,  2.8810e-01, -2.7190e-01,  1.8358e-01,  1.0612e-01,\n         -3.5446e-02, -9.8957e-02,  3.3169e-02],\n        [-2.2445e-01, -5.5246e-03, -8.7510e-02,  5.4309e-02, -2.5709e-01,\n          2.6061e-01,  3.3814e-01,  2.1284e-01],\n        [-1.7608e-01, -2.5626e-01,  3.2249e-01,  2.0347e-02,  7.4053e-02,\n         -3.1271e-01, -3.3199e-01,  1.4876e-01],\n        [-4.8731e-02, -2.5273e-01,  1.1464e-01, -3.2980e-01,  2.4633e-01,\n          1.7344e-01,  2.0913e-01, -2.0792e-01],\n        [-1.7462e-01, -2.1670e-01,  2.3393e-01, -3.3939e-01,  1.0218e-01,\n          3.3339e-01,  1.4037e-01, -1.5128e-01],\n        [ 1.5309e-01,  3.0055e-02,  1.3770e-01,  2.0537e-01,  6.8926e-02,\n         -1.9416e-01,  5.9202e-02,  2.5619e-01],\n        [ 2.0536e-01, -1.4683e-01, -6.0207e-02, -1.5521e-01, -2.8703e-01,\n          2.0850e-02, -2.5442e-01,  1.2948e-01],\n        [-4.4770e-02,  2.0350e-01, -1.2131e-01,  3.7323e-02, -1.1518e-01,\n         -2.8787e-01, -2.2356e-01,  2.7333e-01],\n        [ 1.2126e-01,  2.7364e-01,  2.0671e-02,  2.3846e-01, -1.3210e-01,\n          3.2329e-01, -2.0170e-01, -2.9788e-01],\n        [ 1.4936e-01,  2.1166e-01,  1.5605e-01, -1.3751e-01, -2.9802e-01,\n          8.7612e-02, -1.4326e-01, -1.3137e-01],\n        [ 1.2046e-01, -2.9449e-01, -1.5550e-01,  3.1717e-01, -3.0997e-01,\n          1.1207e-01, -3.3823e-01,  3.3996e-02],\n        [ 2.1001e-01, -2.1680e-01,  1.8490e-01,  1.0873e-01,  2.3209e-01,\n         -9.1216e-02,  6.7511e-02, -1.6732e-01],\n        [ 3.1658e-01, -8.9631e-03, -1.5562e-01, -6.7444e-02,  8.9129e-02,\n         -2.6642e-01, -9.6802e-02,  1.7079e-01],\n        [ 3.3049e-01,  2.8036e-01,  2.5519e-01, -2.9925e-01,  2.5454e-01,\n         -6.0795e-02, -2.7168e-01,  3.3064e-01],\n        [ 3.0721e-02,  5.9677e-02,  2.8974e-02, -2.2088e-01, -1.8133e-01,\n         -7.8193e-02, -2.7584e-01, -2.5852e-01],\n        [-2.2270e-01, -2.1661e-01, -5.0219e-02, -3.2975e-01,  1.0113e-01,\n          1.3781e-02, -2.6228e-01,  3.5128e-01],\n        [-2.6343e-01, -9.6972e-02,  2.4279e-01, -1.2919e-01,  2.6305e-01,\n          1.3798e-01, -3.5110e-01, -1.5422e-01],\n        [ 3.4177e-02,  2.0343e-01,  1.7650e-01, -3.4204e-01, -2.2546e-01,\n         -2.5950e-01,  6.7323e-02, -2.5696e-01],\n        [ 3.4346e-01,  4.9882e-03, -1.1842e-01, -1.5518e-01, -6.5704e-02,\n         -9.3659e-02,  2.7962e-01,  1.9876e-01],\n        [-2.7409e-02,  4.2623e-02,  3.5265e-01,  2.9270e-01, -2.2509e-01,\n          3.3587e-01,  3.3243e-01,  9.8178e-03],\n        [ 1.9930e-01,  7.3311e-02,  3.3093e-01,  2.6566e-01,  2.4261e-01,\n          3.4593e-01,  7.7094e-02,  2.8836e-01],\n        [ 1.0728e-01, -2.9835e-01, -6.1979e-02, -2.5607e-01, -9.0408e-02,\n         -2.3775e-01, -1.1306e-01,  8.2293e-02],\n        [-2.6252e-01, -6.6501e-02,  9.0545e-02, -2.9122e-01,  1.4649e-01,\n          1.1691e-02, -5.0900e-02,  2.4433e-01],\n        [ 2.0284e-01, -2.6161e-01, -3.0089e-01, -9.6077e-02,  2.5926e-01,\n         -1.1950e-01,  1.9879e-01, -2.7254e-01],\n        [ 1.6192e-01, -3.4880e-01,  4.8747e-02,  8.3803e-02, -2.8542e-02,\n          1.7947e-01,  2.9873e-01, -3.1933e-01],\n        [ 1.0290e-02,  2.7295e-01, -6.4525e-03, -1.4541e-01,  2.7870e-01,\n         -1.9935e-01,  1.0563e-01,  3.3262e-01],\n        [ 3.0726e-01, -1.0622e-01, -2.4209e-01, -1.2052e-01, -6.4249e-02,\n          1.5180e-02, -3.1551e-01, -3.0994e-02],\n        [-3.2063e-01, -2.9178e-01, -3.3405e-01,  2.4647e-02,  2.9219e-01,\n         -8.3673e-02,  1.9953e-01, -1.1562e-01],\n        [ 1.0353e-01, -3.5216e-01, -1.9727e-01,  2.4028e-01, -3.3500e-01,\n          2.1311e-01, -7.6660e-02,  1.9762e-01],\n        [ 2.9260e-01, -3.4170e-01, -1.7366e-02, -1.8494e-01,  2.7426e-01,\n         -1.5127e-01, -1.8822e-01,  1.6603e-01],\n        [-1.7101e-01,  6.4897e-03, -1.4058e-01, -5.0600e-02,  3.2030e-01,\n         -6.9281e-02,  2.2291e-01, -3.2560e-02],\n        [-2.2025e-01, -2.3697e-01,  5.7284e-02, -1.6236e-01, -2.5542e-01,\n         -1.6086e-01, -3.3915e-01, -6.8613e-02],\n        [-3.1419e-01,  1.0461e-01, -2.8124e-01, -2.9945e-01,  3.0467e-01,\n         -2.3638e-01, -2.4307e-01, -3.0507e-01],\n        [ 2.1683e-01, -1.5146e-01,  3.2550e-01, -3.0021e-01, -1.6487e-01,\n          3.4399e-01, -6.3326e-02,  2.2435e-01],\n        [ 1.4275e-01,  2.2930e-01,  7.7265e-02, -2.8608e-01,  1.6003e-01,\n          6.8398e-02,  9.9757e-02,  3.2378e-01],\n        [-1.4202e-01,  1.1559e-01, -2.5443e-01, -3.0391e-01,  2.0318e-01,\n         -2.3435e-01,  1.8671e-01, -1.9302e-01],\n        [-1.2553e-01,  1.9263e-01, -1.3234e-04, -3.4029e-01, -6.1130e-02,\n          3.6677e-02,  1.7147e-03, -2.6173e-01],\n        [-1.0794e-01,  1.5562e-01, -3.4950e-01, -1.9087e-01,  3.1597e-01,\n         -4.6895e-02, -2.0901e-01, -1.2571e-01],\n        [ 2.5603e-01, -7.4187e-03,  1.0655e-01,  1.7367e-01,  2.1377e-01,\n          7.1979e-02, -3.2086e-01,  7.5615e-03],\n        [ 1.6997e-01,  2.8458e-02,  1.4373e-01, -2.0391e-01, -2.8399e-01,\n          3.2587e-02, -2.0362e-01,  1.3325e-01],\n        [ 1.5328e-01,  3.1650e-01, -4.6866e-02, -1.4229e-01,  4.3488e-02,\n          1.5042e-01, -1.2573e-01,  6.0216e-03],\n        [-3.8210e-02,  1.5320e-01, -1.4535e-01, -2.3116e-02, -3.3057e-01,\n          3.2121e-01, -1.5131e-01, -1.6850e-01],\n        [ 3.1206e-01,  1.7131e-01,  2.1289e-01, -2.2693e-01, -3.2893e-01,\n          9.9833e-02, -1.0278e-01,  2.1343e-01],\n        [ 9.3682e-02, -3.4309e-01,  1.3344e-01,  2.8191e-01,  3.5931e-02,\n         -4.6633e-02,  3.2674e-01, -2.1794e-01],\n        [-3.4803e-01,  2.2826e-01,  4.3264e-02, -5.1727e-02,  1.6856e-01,\n         -4.5452e-03,  2.1259e-01,  2.8713e-01],\n        [-3.4436e-01, -2.8266e-01, -1.5329e-01,  1.7072e-01,  2.1504e-01,\n          2.7258e-01,  3.1801e-02, -8.2062e-02],\n        [ 2.0577e-01,  1.4494e-01,  1.9027e-01,  3.4635e-03, -1.3600e-02,\n          6.6173e-02,  2.3009e-01, -4.9726e-03],\n        [-2.1761e-01, -2.6366e-01,  1.9084e-01, -1.8838e-01,  2.3972e-01,\n          1.1051e-01,  7.3884e-02,  2.8657e-01],\n        [ 1.4377e-01, -1.1500e-02,  2.7471e-01, -3.3229e-01,  1.8392e-02,\n          4.7800e-02, -3.1278e-01, -2.2119e-01],\n        [-1.0321e-01, -1.1779e-01, -1.3728e-01, -1.4122e-01, -1.1727e-03,\n          3.4068e-01,  1.6562e-01, -2.1625e-01],\n        [-2.9516e-01, -1.4310e-01,  1.4610e-01, -8.0413e-02, -5.1622e-02,\n          7.3202e-02, -4.1596e-02, -2.8526e-01],\n        [ 3.4214e-01,  2.7706e-01,  3.0389e-01,  2.7959e-02, -3.3713e-01,\n          3.2179e-01,  2.3455e-01,  9.5487e-02],\n        [ 1.8262e-01, -3.1721e-02, -5.6968e-02,  1.0686e-01,  1.0088e-01,\n         -6.4817e-02,  2.0129e-02,  2.4146e-01],\n        [-3.1467e-01,  7.6873e-02,  2.2107e-01, -2.0486e-01,  2.0860e-01,\n          4.6781e-02,  2.2654e-01, -6.2381e-02],\n        [-3.1689e-01, -2.7719e-01, -5.0818e-02, -2.1167e-01, -4.2197e-02,\n         -4.4164e-02, -3.1812e-01, -3.6555e-02],\n        [-2.4730e-01, -8.8574e-02,  4.1595e-02, -3.2521e-03,  7.7103e-02,\n         -3.4934e-01,  1.9755e-01,  3.2707e-01],\n        [ 2.9266e-01, -5.7519e-02, -1.6678e-02,  3.3214e-01, -1.6091e-01,\n          2.2182e-01, -1.1333e-02,  2.0983e-02],\n        [-2.8545e-01, -1.6332e-01, -6.5055e-02, -1.0622e-01, -2.0003e-01,\n          3.1251e-01,  2.0465e-01,  8.4189e-02],\n        [ 2.5860e-01, -7.1029e-03,  8.9773e-03,  1.3475e-01, -2.7426e-01,\n         -1.8744e-01,  1.3798e-01, -2.8624e-01],\n        [-2.9940e-01, -3.0244e-01, -3.2043e-01,  3.3462e-01, -2.0026e-01,\n         -1.8243e-01,  3.4503e-02, -1.8499e-01],\n        [ 1.8973e-01,  1.0881e-01,  1.6871e-01,  1.0389e-01,  1.6782e-01,\n         -1.1762e-01, -2.7471e-01,  2.6984e-01],\n        [-2.0370e-01, -1.1529e-01, -1.2771e-01, -3.4310e-01, -1.8204e-01,\n         -2.2962e-01, -3.4577e-02,  2.4499e-02],\n        [ 3.4361e-01,  3.2521e-01,  2.8145e-01, -7.6356e-02, -3.0052e-01,\n         -8.6205e-02, -1.8254e-01,  1.3882e-01],\n        [ 1.5440e-01,  2.1700e-01, -2.1572e-01, -1.9210e-01, -1.3858e-01,\n         -1.8097e-01, -7.7166e-02, -1.7947e-01],\n        [-8.6220e-02,  1.4861e-01, -2.4767e-01,  4.1618e-02,  1.5087e-01,\n          2.8004e-01, -3.0776e-01, -1.7792e-01],\n        [-1.5001e-01,  8.3192e-02, -4.2597e-02,  2.8153e-02,  3.1864e-01,\n          7.3342e-02, -2.5658e-01, -1.2151e-01],\n        [-3.3923e-01, -3.1165e-01, -1.7816e-01, -2.7176e-02, -8.3294e-02,\n         -2.6840e-01, -1.8843e-01,  9.3536e-02],\n        [-2.8136e-01, -4.6687e-02, -1.8921e-01, -2.7253e-01, -2.4420e-02,\n         -2.2016e-01,  5.5825e-02,  2.6021e-01],\n        [-1.8755e-01, -2.1986e-01, -6.9860e-02, -2.2227e-01,  9.6423e-02,\n         -1.9041e-01,  6.4508e-02, -2.1323e-01],\n        [-1.1887e-01,  3.2179e-01,  3.1808e-01, -3.2546e-01, -7.7043e-02,\n          2.1398e-01, -3.3055e-01, -4.8600e-02],\n        [-1.2180e-01,  2.3578e-01,  1.6016e-01,  3.4857e-01, -2.3695e-02,\n          4.7390e-02, -2.3401e-01, -1.6219e-01],\n        [-2.5487e-01,  2.0314e-01, -9.9576e-02,  1.9684e-01,  2.6070e-02,\n          3.0887e-01, -2.6156e-02, -2.3339e-01],\n        [-1.2587e-01,  1.9311e-01, -2.1603e-01,  3.6672e-02, -2.2820e-01,\n         -1.7377e-01, -1.6555e-01, -2.8993e-01],\n        [-3.7663e-02, -1.9406e-01, -2.8988e-01,  1.9900e-02, -2.7452e-01,\n         -1.3828e-01,  2.9921e-01,  1.3650e-01],\n        [-2.8749e-01,  1.3586e-01,  1.9055e-01, -3.3404e-01,  1.0871e-01,\n          2.9443e-01, -2.7133e-01,  2.3806e-01],\n        [-6.7177e-02, -2.0834e-01, -2.1217e-01,  2.0642e-01, -1.8053e-01,\n          3.0821e-01, -2.9270e-01,  3.1194e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0169, -0.0183,  0.0275, -0.0626, -0.0779,  0.0446,  0.0335, -0.0501,\n        -0.0444, -0.0111,  0.0575, -0.0430,  0.0454, -0.0938, -0.0147, -0.0778,\n         0.0559,  0.0266, -0.0199, -0.0715, -0.0858,  0.0777, -0.0183, -0.0731,\n         0.0486, -0.0631, -0.0336,  0.0165,  0.0127, -0.0813,  0.0269, -0.0135,\n         0.0498,  0.0237,  0.0271, -0.0069,  0.0894, -0.0798,  0.0021,  0.0985,\n         0.0220,  0.0880,  0.0292, -0.0063,  0.0513,  0.0990, -0.0576,  0.0405,\n        -0.0449,  0.0086,  0.0270,  0.0651, -0.0184, -0.0766, -0.0573,  0.0475,\n        -0.0948, -0.0994, -0.0409,  0.0633,  0.0606, -0.0104, -0.0732,  0.0155,\n        -0.0223, -0.0933,  0.0313, -0.0622, -0.0237,  0.0364,  0.0744, -0.0466,\n        -0.0104, -0.0412, -0.0736,  0.0744,  0.0222,  0.0792,  0.0698,  0.0312,\n        -0.0654, -0.0100, -0.0159,  0.0343,  0.0260, -0.0544, -0.0831, -0.0550,\n        -0.0194, -0.0486,  0.0551, -0.0445, -0.0226,  0.0439, -0.0325, -0.0110,\n         0.0977, -0.0239,  0.0728, -0.0490], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0555, -0.0865, -0.0559,  ..., -0.0145, -0.0447,  0.0526],\n        [-0.0235,  0.0299,  0.0242,  ..., -0.0422, -0.0248,  0.0618],\n        [-0.0451, -0.0087, -0.0058,  ...,  0.0038,  0.0823, -0.0786],\n        ...,\n        [-0.0934,  0.0454,  0.0197,  ...,  0.0238, -0.0603,  0.0607],\n        [-0.0238,  0.0885,  0.0708,  ...,  0.0347,  0.0489,  0.0798],\n        [ 0.0984, -0.0474, -0.0824,  ..., -0.0830, -0.0116, -0.0196]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0742,  0.0891, -0.0438, -0.0536], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0492,  0.0685, -0.0778, -0.0896,  0.0387, -0.0949, -0.0276, -0.0958,\n         -0.0071, -0.0194,  0.0860, -0.0050,  0.0278,  0.0298, -0.0980,  0.0677,\n         -0.0180,  0.0334, -0.0418, -0.0407,  0.0697, -0.0749, -0.0675, -0.0706,\n          0.0168, -0.0862, -0.0417, -0.0927, -0.0747, -0.0349,  0.0894, -0.0003,\n          0.0054,  0.0061,  0.0761, -0.0931,  0.0105, -0.0614, -0.0172,  0.0687,\n         -0.0767,  0.0903, -0.0369,  0.0021,  0.0183,  0.0489,  0.0320,  0.0677,\n         -0.0337,  0.0528,  0.0948, -0.0934, -0.0099, -0.0729, -0.0240,  0.0811,\n          0.0549, -0.0445, -0.0340,  0.0402,  0.0750,  0.0463, -0.0119, -0.0507,\n          0.0507,  0.0885,  0.0189,  0.0673,  0.0912,  0.0591,  0.0781, -0.0348,\n         -0.0706,  0.0471,  0.0104,  0.0997,  0.0350, -0.0568,  0.0941, -0.0209,\n          0.0251,  0.0181,  0.0510, -0.0174, -0.0663,  0.0277, -0.0713, -0.0008,\n         -0.0413,  0.0184,  0.0420, -0.0418, -0.0154,  0.0735, -0.0486, -0.0479,\n         -0.0793, -0.0006, -0.0814,  0.0098],\n        [-0.0109,  0.0184, -0.0084, -0.0829,  0.0544, -0.0488,  0.0647, -0.0355,\n          0.0879,  0.0889,  0.0290, -0.0708, -0.0518,  0.0107,  0.0798,  0.0489,\n          0.0377, -0.0737,  0.0576,  0.0657,  0.0870,  0.0159,  0.0638,  0.0748,\n          0.0427,  0.0014,  0.0028, -0.0135, -0.0755, -0.0254,  0.0473, -0.0259,\n         -0.0848,  0.0346, -0.0341,  0.0210, -0.0777,  0.0910, -0.0056,  0.0351,\n         -0.0756, -0.0676,  0.0772,  0.0420, -0.0045, -0.0697,  0.0973,  0.0711,\n          0.0313, -0.0786,  0.0237,  0.0669, -0.0899,  0.0031,  0.0752,  0.0096,\n         -0.0622,  0.0390, -0.0909,  0.0797, -0.0065,  0.0698, -0.0879,  0.0559,\n         -0.0544, -0.0102, -0.0357,  0.0946,  0.0173, -0.0020,  0.0921,  0.0208,\n         -0.0431,  0.0930,  0.0524, -0.0441,  0.0432, -0.0067,  0.0294, -0.0972,\n         -0.0600,  0.0220,  0.0375, -0.0987,  0.0765, -0.0251,  0.0364, -0.0271,\n         -0.0818,  0.0823, -0.0985,  0.0572, -0.0914, -0.0646, -0.0044, -0.0632,\n          0.0044,  0.0610, -0.0492,  0.0127],\n        [ 0.0137, -0.0241,  0.0308,  0.0845,  0.0523, -0.0423, -0.0065, -0.0318,\n          0.0030, -0.0577, -0.0191,  0.0025,  0.0906,  0.0528,  0.0556,  0.0167,\n          0.0357,  0.0321,  0.0673, -0.0349,  0.0469, -0.0979, -0.0565, -0.0424,\n          0.0188, -0.0770, -0.0461,  0.0787,  0.0635, -0.0945, -0.0910,  0.0253,\n          0.0257, -0.0792, -0.0297,  0.0332,  0.0878, -0.0662,  0.0867, -0.0361,\n          0.0369,  0.0536, -0.0588,  0.0836,  0.0704,  0.0323, -0.0471,  0.0989,\n          0.0273,  0.0161,  0.0699, -0.0982, -0.0218,  0.0316,  0.0858, -0.0256,\n          0.0725, -0.0209,  0.0964,  0.0789, -0.0552, -0.0558, -0.0317, -0.0720,\n         -0.0428,  0.0987,  0.0687, -0.0147, -0.0428,  0.0455, -0.0706,  0.0934,\n         -0.0973,  0.0094,  0.0082, -0.0513, -0.0330, -0.0219, -0.0844,  0.0509,\n         -0.0523, -0.0589, -0.0610, -0.0883,  0.0724,  0.0239, -0.0043,  0.0527,\n         -0.0762, -0.0740, -0.0872, -0.0786, -0.0676, -0.0321,  0.0173,  0.0990,\n          0.0571, -0.0841, -0.0154, -0.0386],\n        [ 0.0956, -0.0702,  0.0689,  0.0625, -0.0865,  0.0220,  0.0595,  0.0406,\n          0.0578,  0.0334, -0.0888, -0.0229,  0.0546, -0.0294, -0.0029,  0.0901,\n         -0.0556, -0.0335,  0.0447, -0.0780,  0.0109,  0.0417, -0.0169,  0.0043,\n         -0.0721,  0.0199, -0.0558, -0.0915,  0.0559, -0.0244, -0.0770,  0.0391,\n         -0.0755, -0.0948, -0.0420,  0.0994, -0.0809, -0.0865, -0.0002,  0.0641,\n          0.0198, -0.0089, -0.0862, -0.0874,  0.0446,  0.0905, -0.0117,  0.0489,\n          0.0942,  0.0689,  0.0483,  0.0935, -0.0065,  0.0733, -0.0873,  0.0434,\n         -0.0137, -0.0333, -0.0167,  0.0314, -0.0709, -0.0530, -0.0778,  0.0174,\n          0.0688,  0.0336,  0.0005, -0.0366, -0.0125, -0.0083, -0.0629,  0.0516,\n          0.0923,  0.0555, -0.0955, -0.0353, -0.0064, -0.0216, -0.0891, -0.0333,\n          0.0605, -0.0938, -0.0642, -0.0840,  0.0219, -0.0392,  0.0954,  0.0571,\n          0.0488,  0.0523,  0.0765, -0.0250,  0.0681, -0.0593,  0.0774, -0.0964,\n         -0.0384, -0.0397,  0.0770,  0.0310]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7e6c82f09910>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s424950000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s424950000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}