{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s455100000"
    },
    "q_lr":	0.0005,
    "seed":	455100000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x79f51e2a2250>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1225,  0.2139, -0.2514,  0.0471, -0.2295,  0.0634, -0.0390,  0.1392,\n         0.3450,  0.1309,  0.0800, -0.0327,  0.2731, -0.0137, -0.0959,  0.3192,\n        -0.1248,  0.1339, -0.1576, -0.1771, -0.1591,  0.0274,  0.0813,  0.0448,\n        -0.0897,  0.0428,  0.2957, -0.0974, -0.2123,  0.2859, -0.2708,  0.1205],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.2169e-02, -3.7240e-02,  3.2130e-02, -2.7524e-01, -5.2899e-02,\n         -1.2201e-02,  7.3056e-02,  5.1237e-02],\n        [ 1.3907e-01,  2.0392e-01, -2.2503e-01, -8.8361e-02, -1.9422e-01,\n         -2.1250e-01,  2.8163e-01, -1.4157e-01],\n        [ 1.7613e-01,  3.3673e-02,  1.4031e-01,  3.2308e-01, -3.3514e-01,\n         -2.6686e-01,  1.5428e-01,  2.2109e-01],\n        [ 4.2349e-02, -9.3770e-03, -2.4299e-01,  1.6535e-01, -2.5992e-01,\n         -3.4414e-02, -4.3206e-02,  1.9025e-01],\n        [ 1.5535e-01, -7.5449e-03,  2.4124e-01,  2.1278e-01, -1.3541e-01,\n          3.4381e-01,  1.9749e-01,  1.3653e-02],\n        [-2.3710e-01,  3.1791e-01,  2.2633e-01, -8.7702e-02, -2.3470e-01,\n         -1.7252e-01, -2.8915e-01,  1.2844e-01],\n        [ 2.8451e-01, -3.6226e-02, -6.1589e-02,  1.8331e-01,  1.3816e-01,\n         -1.5072e-02, -1.4641e-01,  3.1312e-01],\n        [-3.4398e-02,  1.8052e-01,  1.3089e-01, -2.2021e-01, -6.0732e-02,\n          3.1822e-01, -1.4532e-01,  6.5263e-02],\n        [ 1.3380e-01, -1.6320e-01,  3.5353e-01,  3.0367e-01, -4.1794e-02,\n          1.3661e-01,  2.9553e-01, -3.4187e-02],\n        [ 2.6986e-01,  1.5991e-02,  2.4159e-01,  3.0563e-01, -8.2523e-02,\n          2.0387e-01,  1.5018e-01,  2.6500e-01],\n        [-3.1352e-01,  1.7699e-01,  1.7388e-01, -2.3162e-02, -1.3156e-01,\n          3.1725e-01, -9.8530e-02, -6.3193e-02],\n        [ 2.4469e-01,  2.5862e-01, -2.0555e-01, -2.5306e-01,  1.7883e-01,\n          1.7376e-01,  6.5487e-02,  1.4231e-01],\n        [ 3.2641e-01, -2.8050e-01,  1.4790e-01,  1.0937e-02, -1.9663e-01,\n         -3.0472e-01, -8.7616e-02,  1.1919e-01],\n        [ 1.4102e-01, -3.2701e-01,  1.3043e-01, -3.1010e-01,  2.3253e-01,\n         -9.1620e-02, -2.8434e-01, -1.8775e-01],\n        [-9.4077e-02, -1.6663e-01,  3.3611e-03, -1.7411e-01, -2.6093e-01,\n         -1.7402e-01,  3.2264e-01, -2.7133e-01],\n        [-9.1418e-02, -3.0633e-01,  9.4923e-02, -2.7935e-01,  3.1526e-01,\n          7.2177e-02,  2.4514e-03, -1.8862e-01],\n        [ 3.9883e-02,  1.8367e-01, -3.3434e-01, -2.0888e-02,  8.7942e-02,\n         -6.3690e-02,  1.1735e-01, -1.7142e-01],\n        [ 1.6011e-01, -2.7866e-01, -1.8605e-02,  2.5848e-01,  3.4774e-01,\n          2.0639e-01,  9.5743e-02,  7.5639e-02],\n        [ 1.7590e-01, -3.1002e-01,  1.2063e-01, -3.4979e-01, -1.8541e-01,\n          3.2746e-01,  2.7447e-01, -2.3457e-02],\n        [-1.6136e-01,  2.5889e-01,  1.6175e-01, -3.3612e-02,  9.2965e-02,\n          3.1748e-01,  2.8165e-01,  2.2160e-01],\n        [-1.9670e-01,  1.5755e-01,  4.8377e-02, -2.4495e-01,  9.4008e-02,\n          3.5305e-01, -1.5957e-01, -1.0501e-01],\n        [-3.2909e-01,  6.8571e-02,  2.8112e-01, -2.5486e-01,  3.1835e-01,\n         -2.0402e-01,  8.0902e-02,  1.1279e-01],\n        [ 3.8945e-03,  2.9087e-01, -1.9895e-01,  9.6848e-02,  1.3341e-01,\n          1.8030e-01, -2.5298e-01, -1.0049e-02],\n        [ 2.3292e-01,  1.2864e-01, -2.4850e-01,  2.3822e-01,  8.2431e-02,\n          3.2617e-01, -1.7952e-02, -3.2524e-01],\n        [ 2.7825e-01, -3.1546e-02,  1.8045e-02,  2.9293e-01, -5.4782e-02,\n         -3.2091e-02,  2.0075e-02, -1.2579e-01],\n        [ 1.8792e-01,  3.3691e-01, -2.6653e-01, -1.0861e-01,  9.1522e-02,\n         -2.9827e-01, -2.8012e-01, -1.3289e-01],\n        [-2.2024e-01,  1.3717e-01,  2.7069e-01, -3.2544e-01, -2.3888e-01,\n          2.5926e-01, -1.7235e-01,  2.6372e-01],\n        [-3.1288e-01,  1.9685e-02, -8.8262e-02,  2.6004e-01,  8.2731e-02,\n         -2.6872e-01, -1.4071e-01,  2.3044e-01],\n        [-3.0316e-04, -3.3191e-01,  7.9695e-03,  1.9623e-01, -2.0187e-01,\n         -3.0759e-01,  5.3183e-02,  1.2590e-02],\n        [-2.4192e-01, -2.1832e-01, -3.5124e-01, -5.6283e-02, -2.5258e-01,\n         -2.1614e-02, -5.3117e-02,  6.4190e-02],\n        [-2.7533e-01,  2.3579e-01,  1.9838e-01, -2.0661e-01,  2.3799e-01,\n          1.2025e-01,  2.9732e-01, -6.4400e-02],\n        [-1.8307e-01,  1.0855e-01, -2.3149e-01,  1.7659e-01, -1.7838e-01,\n         -4.8451e-02, -1.7220e-01, -8.9465e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0847,  0.1342,  0.0773,  0.0729,  0.0387,  0.1279,  0.1101, -0.1099,\n         0.1271, -0.1354, -0.1382,  0.0325,  0.1359,  0.0754,  0.0659,  0.1710],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1084, -0.0472, -0.1438, -0.1407, -0.1733, -0.0749,  0.1107,  0.1037,\n         -0.0413,  0.0524, -0.1267, -0.1229,  0.1391, -0.0428,  0.1692, -0.1532,\n         -0.0294, -0.0283, -0.1434,  0.0803, -0.0685,  0.0737, -0.0580,  0.1632,\n         -0.0887, -0.0882,  0.1394, -0.1638, -0.0384,  0.0882,  0.1138, -0.1688],\n        [ 0.1338, -0.1212,  0.1550,  0.1765, -0.0729,  0.0651,  0.1341, -0.0274,\n          0.1441, -0.0298,  0.0255,  0.0074,  0.0426, -0.0880, -0.0957,  0.0640,\n         -0.0158, -0.0871,  0.0429,  0.0831,  0.0767, -0.1460,  0.0868,  0.1659,\n          0.1593, -0.0673,  0.0836, -0.1008,  0.1404,  0.1252,  0.1062, -0.0681],\n        [ 0.1676,  0.1098,  0.0340,  0.0812,  0.0820, -0.1464,  0.0858,  0.1235,\n          0.0475,  0.0933, -0.0137, -0.0269,  0.0023,  0.0561,  0.1085,  0.0500,\n          0.1137,  0.1399,  0.0444, -0.0644,  0.0203, -0.0262,  0.1523, -0.1109,\n          0.0650, -0.1706,  0.0014, -0.0801, -0.0357,  0.0932,  0.1254,  0.0508],\n        [ 0.1722, -0.0746, -0.1181, -0.0444,  0.1736,  0.0237,  0.1698, -0.0925,\n         -0.0138, -0.1604,  0.0687, -0.1622,  0.1193, -0.0588, -0.1395, -0.0207,\n          0.0334, -0.0887,  0.0522, -0.0785, -0.0493,  0.1385,  0.1231, -0.0804,\n         -0.1235, -0.1576,  0.0193, -0.0613,  0.1135,  0.1213, -0.0557,  0.0042],\n        [-0.0244, -0.0956,  0.1678,  0.0240, -0.1734,  0.1164,  0.1100, -0.0130,\n         -0.1463,  0.0742,  0.0183,  0.0639, -0.0461,  0.1347,  0.0446,  0.1285,\n         -0.1440,  0.1423, -0.1256, -0.1656,  0.0688,  0.0856,  0.0255,  0.0653,\n         -0.0403,  0.1623,  0.1081, -0.1388,  0.1646,  0.0285, -0.0586, -0.1607],\n        [ 0.1411,  0.0559, -0.0455, -0.1427,  0.1193, -0.0428, -0.1387, -0.0926,\n         -0.0356,  0.0490,  0.0011,  0.0785, -0.0294, -0.0247, -0.1638, -0.0777,\n         -0.1675, -0.1718,  0.1137,  0.1587,  0.0160, -0.1541,  0.0829,  0.1089,\n          0.0504,  0.0831,  0.0892, -0.0185,  0.1408,  0.0967, -0.1334, -0.1097],\n        [-0.1100, -0.1262,  0.0026, -0.0537,  0.1617,  0.1630,  0.0112, -0.1456,\n         -0.1647,  0.0161, -0.0191,  0.0311,  0.0659,  0.1451, -0.1717,  0.1165,\n         -0.1389,  0.0487, -0.0465, -0.1579, -0.1296,  0.1254, -0.1340,  0.1201,\n         -0.1359,  0.1662,  0.0920,  0.0168, -0.0835, -0.0912, -0.1694,  0.0359],\n        [-0.0644,  0.0138,  0.0806,  0.0265, -0.0937, -0.1493, -0.1195,  0.1417,\n          0.0145,  0.1094,  0.0980,  0.1547,  0.1239,  0.0738, -0.0886,  0.0523,\n         -0.0463, -0.0054,  0.1654, -0.0313, -0.1213, -0.0626,  0.0561, -0.0487,\n          0.0406, -0.0269, -0.1734, -0.0730, -0.1477, -0.1740,  0.0461,  0.0102],\n        [-0.0389, -0.1654,  0.0103,  0.1346,  0.1121,  0.0803,  0.1699, -0.0498,\n         -0.1650, -0.1147, -0.0106,  0.0341,  0.0168, -0.0713, -0.0080,  0.0861,\n          0.0030, -0.1590, -0.0011,  0.0968,  0.1105,  0.1205, -0.0201,  0.1121,\n         -0.0006, -0.0469,  0.0975, -0.1738,  0.1438,  0.1324,  0.1364,  0.0720],\n        [ 0.1129, -0.1410, -0.1150,  0.1559,  0.1242, -0.0673, -0.0292,  0.0681,\n         -0.0278,  0.0976, -0.0713,  0.0634, -0.0586,  0.0575,  0.0067,  0.0868,\n          0.0013,  0.1605, -0.0508, -0.0416,  0.0272, -0.1262,  0.0121, -0.0215,\n         -0.0493,  0.1016, -0.1357, -0.0150,  0.0373, -0.1681, -0.1566, -0.1300],\n        [-0.0461, -0.1086,  0.1002, -0.0265,  0.0687,  0.0379,  0.0422,  0.0489,\n         -0.1439, -0.0345,  0.1070,  0.0620, -0.0594,  0.1540, -0.0319, -0.0849,\n         -0.1667,  0.1181, -0.1683,  0.0600,  0.0355, -0.0426,  0.0962,  0.0192,\n          0.1352,  0.1125,  0.0824,  0.1649, -0.0356,  0.0959,  0.0041, -0.0983],\n        [ 0.1332, -0.0115,  0.0779,  0.1193, -0.0279,  0.0254,  0.0898,  0.0053,\n          0.0159,  0.1518,  0.0511, -0.0692,  0.0574, -0.0035, -0.1405, -0.1426,\n         -0.0383,  0.0344,  0.0672,  0.1010, -0.1665, -0.1142,  0.1702,  0.1671,\n         -0.1131,  0.1077, -0.0613, -0.0076,  0.1029, -0.0331,  0.1450, -0.1728],\n        [-0.0181, -0.0536,  0.1580,  0.1229, -0.1715, -0.0381, -0.0580, -0.0416,\n          0.0565, -0.0056, -0.1518,  0.0906, -0.1046,  0.1589,  0.0264, -0.0157,\n         -0.1733, -0.0165,  0.1164,  0.0032,  0.0241, -0.1419, -0.1075,  0.1567,\n          0.0125,  0.1663,  0.0370, -0.0306,  0.0859, -0.0792, -0.0656, -0.1528],\n        [-0.0334, -0.0762, -0.0330, -0.1314, -0.1284, -0.0618,  0.0974, -0.1110,\n         -0.0161, -0.0657, -0.1176,  0.0006, -0.1725, -0.1514, -0.0590,  0.1535,\n          0.0683, -0.1702,  0.0237, -0.1272, -0.1764, -0.0058, -0.0180, -0.0181,\n          0.1647, -0.0613, -0.1030, -0.0756,  0.1530, -0.0219, -0.0473, -0.1513],\n        [ 0.0145, -0.1628,  0.1488, -0.0016, -0.1531, -0.0083,  0.1608, -0.0047,\n         -0.0808, -0.1325,  0.1600,  0.0479, -0.1208,  0.1254,  0.1429,  0.0876,\n         -0.0876,  0.0281, -0.1112,  0.1504,  0.0443,  0.1220, -0.1577, -0.0900,\n          0.1509,  0.1199,  0.0767, -0.1620, -0.0650,  0.0858,  0.1515,  0.1442],\n        [ 0.1569, -0.1275,  0.0811,  0.0760,  0.1075,  0.0176, -0.0425, -0.0140,\n         -0.0353, -0.1670, -0.0752, -0.0365, -0.0825, -0.0138, -0.1593, -0.1549,\n          0.1181,  0.1718, -0.1697,  0.1441, -0.0028,  0.0627, -0.1551, -0.0712,\n          0.0582,  0.1014, -0.0363, -0.0694,  0.0749, -0.0998,  0.0335, -0.0866]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0837,  0.0781, -0.1503, -0.0355,  0.2381,  0.0454,  0.1263,  0.1421],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 2.3304e-01,  5.0370e-02,  1.0931e-01,  5.2854e-02, -1.3494e-01,\n         -2.2295e-01, -1.6580e-01, -8.5488e-02, -2.3582e-01, -2.0600e-01,\n          7.9047e-02, -1.8154e-01,  1.9453e-01,  2.0889e-02,  7.6205e-02,\n         -1.0453e-01],\n        [ 1.3769e-01, -9.6085e-02, -1.2365e-01, -6.0714e-02, -1.6572e-01,\n          2.4498e-01, -1.9775e-01,  1.3692e-01, -1.7365e-02,  2.2121e-02,\n          2.1559e-01, -2.2450e-01, -7.4407e-02, -1.3364e-01, -1.9427e-01,\n         -2.5984e-02],\n        [ 9.1714e-02,  1.0557e-01,  1.3681e-01,  5.3075e-02, -7.9516e-02,\n          1.4715e-01, -2.3978e-01,  7.3202e-02, -1.4322e-02, -1.2373e-02,\n          1.9312e-01,  1.7447e-01, -1.5089e-04, -2.0236e-01, -1.4493e-01,\n          2.3502e-01],\n        [ 8.5147e-02,  2.0730e-01,  2.0122e-01,  3.4320e-02,  2.1478e-01,\n         -7.3416e-02, -3.7042e-03, -1.6384e-02,  2.8401e-02,  1.7898e-02,\n          6.4669e-02, -2.0202e-01, -5.1194e-02,  5.7548e-03, -1.1956e-01,\n         -2.1405e-01],\n        [ 1.6917e-01, -3.5129e-02, -2.2953e-01,  2.4469e-01, -6.6534e-02,\n          4.3682e-02,  8.3536e-02,  1.4942e-01,  2.2268e-01, -1.4651e-01,\n          3.0587e-02, -9.0796e-02, -3.9216e-02,  8.9576e-02, -3.7483e-02,\n         -2.0447e-01],\n        [-1.2979e-01,  8.3181e-02,  1.6803e-01,  5.0297e-02, -1.8962e-01,\n          9.6421e-02, -1.3662e-01, -1.8124e-01, -9.0029e-02, -4.0890e-02,\n         -4.4993e-02, -2.4829e-01, -2.4690e-01, -1.5769e-01,  1.5438e-01,\n         -1.3711e-01],\n        [ 2.2970e-01,  8.4645e-02, -2.0739e-01,  8.8554e-02, -6.1608e-03,\n          3.5409e-02,  1.7875e-01,  1.9074e-01,  1.2634e-01,  1.2503e-01,\n         -1.6906e-01, -1.3861e-01, -6.6103e-02,  6.1766e-02,  9.5459e-02,\n          2.2003e-01],\n        [ 8.3264e-02, -7.2795e-02,  3.2986e-02, -1.3983e-01, -1.1405e-01,\n         -2.1727e-01,  2.3628e-01,  5.7818e-02,  1.0733e-01,  5.7812e-02,\n         -2.6556e-02, -1.9964e-01,  1.5683e-01,  1.6548e-02, -2.1229e-01,\n         -1.2829e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=1, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0504], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0882, -0.1475,  0.2410,  0.2606,  0.2470, -0.0845,  0.0767,  0.2612]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	1,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 1.2169e-02, -3.7240e-02,  3.2130e-02, -2.7524e-01, -5.2899e-02,\n         -1.2201e-02,  7.3056e-02,  5.1237e-02],\n        [ 1.3907e-01,  2.0392e-01, -2.2503e-01, -8.8361e-02, -1.9422e-01,\n         -2.1250e-01,  2.8163e-01, -1.4157e-01],\n        [ 1.7613e-01,  3.3673e-02,  1.4031e-01,  3.2308e-01, -3.3514e-01,\n         -2.6686e-01,  1.5428e-01,  2.2109e-01],\n        [ 4.2349e-02, -9.3770e-03, -2.4299e-01,  1.6535e-01, -2.5992e-01,\n         -3.4414e-02, -4.3206e-02,  1.9025e-01],\n        [ 1.5535e-01, -7.5449e-03,  2.4124e-01,  2.1278e-01, -1.3541e-01,\n          3.4381e-01,  1.9749e-01,  1.3653e-02],\n        [-2.3710e-01,  3.1791e-01,  2.2633e-01, -8.7702e-02, -2.3470e-01,\n         -1.7252e-01, -2.8915e-01,  1.2844e-01],\n        [ 2.8451e-01, -3.6226e-02, -6.1589e-02,  1.8331e-01,  1.3816e-01,\n         -1.5072e-02, -1.4641e-01,  3.1312e-01],\n        [-3.4398e-02,  1.8052e-01,  1.3089e-01, -2.2021e-01, -6.0732e-02,\n          3.1822e-01, -1.4532e-01,  6.5263e-02],\n        [ 1.3380e-01, -1.6320e-01,  3.5353e-01,  3.0367e-01, -4.1794e-02,\n          1.3661e-01,  2.9553e-01, -3.4187e-02],\n        [ 2.6986e-01,  1.5991e-02,  2.4159e-01,  3.0563e-01, -8.2523e-02,\n          2.0387e-01,  1.5018e-01,  2.6500e-01],\n        [-3.1352e-01,  1.7699e-01,  1.7388e-01, -2.3162e-02, -1.3156e-01,\n          3.1725e-01, -9.8530e-02, -6.3193e-02],\n        [ 2.4469e-01,  2.5862e-01, -2.0555e-01, -2.5306e-01,  1.7883e-01,\n          1.7376e-01,  6.5487e-02,  1.4231e-01],\n        [ 3.2641e-01, -2.8050e-01,  1.4790e-01,  1.0937e-02, -1.9663e-01,\n         -3.0472e-01, -8.7616e-02,  1.1919e-01],\n        [ 1.4102e-01, -3.2701e-01,  1.3043e-01, -3.1010e-01,  2.3253e-01,\n         -9.1620e-02, -2.8434e-01, -1.8775e-01],\n        [-9.4077e-02, -1.6663e-01,  3.3611e-03, -1.7411e-01, -2.6093e-01,\n         -1.7402e-01,  3.2264e-01, -2.7133e-01],\n        [-9.1418e-02, -3.0633e-01,  9.4923e-02, -2.7935e-01,  3.1526e-01,\n          7.2177e-02,  2.4514e-03, -1.8862e-01],\n        [ 3.9883e-02,  1.8367e-01, -3.3434e-01, -2.0888e-02,  8.7942e-02,\n         -6.3690e-02,  1.1735e-01, -1.7142e-01],\n        [ 1.6011e-01, -2.7866e-01, -1.8605e-02,  2.5848e-01,  3.4774e-01,\n          2.0639e-01,  9.5743e-02,  7.5639e-02],\n        [ 1.7590e-01, -3.1002e-01,  1.2063e-01, -3.4979e-01, -1.8541e-01,\n          3.2746e-01,  2.7447e-01, -2.3457e-02],\n        [-1.6136e-01,  2.5889e-01,  1.6175e-01, -3.3612e-02,  9.2965e-02,\n          3.1748e-01,  2.8165e-01,  2.2160e-01],\n        [-1.9670e-01,  1.5755e-01,  4.8377e-02, -2.4495e-01,  9.4008e-02,\n          3.5305e-01, -1.5957e-01, -1.0501e-01],\n        [-3.2909e-01,  6.8571e-02,  2.8112e-01, -2.5486e-01,  3.1835e-01,\n         -2.0402e-01,  8.0902e-02,  1.1279e-01],\n        [ 3.8945e-03,  2.9087e-01, -1.9895e-01,  9.6848e-02,  1.3341e-01,\n          1.8030e-01, -2.5298e-01, -1.0049e-02],\n        [ 2.3292e-01,  1.2864e-01, -2.4850e-01,  2.3822e-01,  8.2431e-02,\n          3.2617e-01, -1.7952e-02, -3.2524e-01],\n        [ 2.7825e-01, -3.1546e-02,  1.8045e-02,  2.9293e-01, -5.4782e-02,\n         -3.2091e-02,  2.0075e-02, -1.2579e-01],\n        [ 1.8792e-01,  3.3691e-01, -2.6653e-01, -1.0861e-01,  9.1522e-02,\n         -2.9827e-01, -2.8012e-01, -1.3289e-01],\n        [-2.2024e-01,  1.3717e-01,  2.7069e-01, -3.2544e-01, -2.3888e-01,\n          2.5926e-01, -1.7235e-01,  2.6372e-01],\n        [-3.1288e-01,  1.9685e-02, -8.8262e-02,  2.6004e-01,  8.2731e-02,\n         -2.6872e-01, -1.4071e-01,  2.3044e-01],\n        [-3.0316e-04, -3.3191e-01,  7.9695e-03,  1.9623e-01, -2.0187e-01,\n         -3.0759e-01,  5.3183e-02,  1.2590e-02],\n        [-2.4192e-01, -2.1832e-01, -3.5124e-01, -5.6283e-02, -2.5258e-01,\n         -2.1614e-02, -5.3117e-02,  6.4190e-02],\n        [-2.7533e-01,  2.3579e-01,  1.9838e-01, -2.0661e-01,  2.3799e-01,\n          1.2025e-01,  2.9732e-01, -6.4400e-02],\n        [-1.8307e-01,  1.0855e-01, -2.3149e-01,  1.7659e-01, -1.7838e-01,\n         -4.8451e-02, -1.7220e-01, -8.9465e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1225,  0.2139, -0.2514,  0.0471, -0.2295,  0.0634, -0.0390,  0.1392,\n         0.3450,  0.1309,  0.0800, -0.0327,  0.2731, -0.0137, -0.0959,  0.3192,\n        -0.1248,  0.1339, -0.1576, -0.1771, -0.1591,  0.0274,  0.0813,  0.0448,\n        -0.0897,  0.0428,  0.2957, -0.0974, -0.2123,  0.2859, -0.2708,  0.1205],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1084, -0.0472, -0.1438, -0.1407, -0.1733, -0.0749,  0.1107,  0.1037,\n         -0.0413,  0.0524, -0.1267, -0.1229,  0.1391, -0.0428,  0.1692, -0.1532,\n         -0.0294, -0.0283, -0.1434,  0.0803, -0.0685,  0.0737, -0.0580,  0.1632,\n         -0.0887, -0.0882,  0.1394, -0.1638, -0.0384,  0.0882,  0.1138, -0.1688],\n        [ 0.1338, -0.1212,  0.1550,  0.1765, -0.0729,  0.0651,  0.1341, -0.0274,\n          0.1441, -0.0298,  0.0255,  0.0074,  0.0426, -0.0880, -0.0957,  0.0640,\n         -0.0158, -0.0871,  0.0429,  0.0831,  0.0767, -0.1460,  0.0868,  0.1659,\n          0.1593, -0.0673,  0.0836, -0.1008,  0.1404,  0.1252,  0.1062, -0.0681],\n        [ 0.1676,  0.1098,  0.0340,  0.0812,  0.0820, -0.1464,  0.0858,  0.1235,\n          0.0475,  0.0933, -0.0137, -0.0269,  0.0023,  0.0561,  0.1085,  0.0500,\n          0.1137,  0.1399,  0.0444, -0.0644,  0.0203, -0.0262,  0.1523, -0.1109,\n          0.0650, -0.1706,  0.0014, -0.0801, -0.0357,  0.0932,  0.1254,  0.0508],\n        [ 0.1722, -0.0746, -0.1181, -0.0444,  0.1736,  0.0237,  0.1698, -0.0925,\n         -0.0138, -0.1604,  0.0687, -0.1622,  0.1193, -0.0588, -0.1395, -0.0207,\n          0.0334, -0.0887,  0.0522, -0.0785, -0.0493,  0.1385,  0.1231, -0.0804,\n         -0.1235, -0.1576,  0.0193, -0.0613,  0.1135,  0.1213, -0.0557,  0.0042],\n        [-0.0244, -0.0956,  0.1678,  0.0240, -0.1734,  0.1164,  0.1100, -0.0130,\n         -0.1463,  0.0742,  0.0183,  0.0639, -0.0461,  0.1347,  0.0446,  0.1285,\n         -0.1440,  0.1423, -0.1256, -0.1656,  0.0688,  0.0856,  0.0255,  0.0653,\n         -0.0403,  0.1623,  0.1081, -0.1388,  0.1646,  0.0285, -0.0586, -0.1607],\n        [ 0.1411,  0.0559, -0.0455, -0.1427,  0.1193, -0.0428, -0.1387, -0.0926,\n         -0.0356,  0.0490,  0.0011,  0.0785, -0.0294, -0.0247, -0.1638, -0.0777,\n         -0.1675, -0.1718,  0.1137,  0.1587,  0.0160, -0.1541,  0.0829,  0.1089,\n          0.0504,  0.0831,  0.0892, -0.0185,  0.1408,  0.0967, -0.1334, -0.1097],\n        [-0.1100, -0.1262,  0.0026, -0.0537,  0.1617,  0.1630,  0.0112, -0.1456,\n         -0.1647,  0.0161, -0.0191,  0.0311,  0.0659,  0.1451, -0.1717,  0.1165,\n         -0.1389,  0.0487, -0.0465, -0.1579, -0.1296,  0.1254, -0.1340,  0.1201,\n         -0.1359,  0.1662,  0.0920,  0.0168, -0.0835, -0.0912, -0.1694,  0.0359],\n        [-0.0644,  0.0138,  0.0806,  0.0265, -0.0937, -0.1493, -0.1195,  0.1417,\n          0.0145,  0.1094,  0.0980,  0.1547,  0.1239,  0.0738, -0.0886,  0.0523,\n         -0.0463, -0.0054,  0.1654, -0.0313, -0.1213, -0.0626,  0.0561, -0.0487,\n          0.0406, -0.0269, -0.1734, -0.0730, -0.1477, -0.1740,  0.0461,  0.0102],\n        [-0.0389, -0.1654,  0.0103,  0.1346,  0.1121,  0.0803,  0.1699, -0.0498,\n         -0.1650, -0.1147, -0.0106,  0.0341,  0.0168, -0.0713, -0.0080,  0.0861,\n          0.0030, -0.1590, -0.0011,  0.0968,  0.1105,  0.1205, -0.0201,  0.1121,\n         -0.0006, -0.0469,  0.0975, -0.1738,  0.1438,  0.1324,  0.1364,  0.0720],\n        [ 0.1129, -0.1410, -0.1150,  0.1559,  0.1242, -0.0673, -0.0292,  0.0681,\n         -0.0278,  0.0976, -0.0713,  0.0634, -0.0586,  0.0575,  0.0067,  0.0868,\n          0.0013,  0.1605, -0.0508, -0.0416,  0.0272, -0.1262,  0.0121, -0.0215,\n         -0.0493,  0.1016, -0.1357, -0.0150,  0.0373, -0.1681, -0.1566, -0.1300],\n        [-0.0461, -0.1086,  0.1002, -0.0265,  0.0687,  0.0379,  0.0422,  0.0489,\n         -0.1439, -0.0345,  0.1070,  0.0620, -0.0594,  0.1540, -0.0319, -0.0849,\n         -0.1667,  0.1181, -0.1683,  0.0600,  0.0355, -0.0426,  0.0962,  0.0192,\n          0.1352,  0.1125,  0.0824,  0.1649, -0.0356,  0.0959,  0.0041, -0.0983],\n        [ 0.1332, -0.0115,  0.0779,  0.1193, -0.0279,  0.0254,  0.0898,  0.0053,\n          0.0159,  0.1518,  0.0511, -0.0692,  0.0574, -0.0035, -0.1405, -0.1426,\n         -0.0383,  0.0344,  0.0672,  0.1010, -0.1665, -0.1142,  0.1702,  0.1671,\n         -0.1131,  0.1077, -0.0613, -0.0076,  0.1029, -0.0331,  0.1450, -0.1728],\n        [-0.0181, -0.0536,  0.1580,  0.1229, -0.1715, -0.0381, -0.0580, -0.0416,\n          0.0565, -0.0056, -0.1518,  0.0906, -0.1046,  0.1589,  0.0264, -0.0157,\n         -0.1733, -0.0165,  0.1164,  0.0032,  0.0241, -0.1419, -0.1075,  0.1567,\n          0.0125,  0.1663,  0.0370, -0.0306,  0.0859, -0.0792, -0.0656, -0.1528],\n        [-0.0334, -0.0762, -0.0330, -0.1314, -0.1284, -0.0618,  0.0974, -0.1110,\n         -0.0161, -0.0657, -0.1176,  0.0006, -0.1725, -0.1514, -0.0590,  0.1535,\n          0.0683, -0.1702,  0.0237, -0.1272, -0.1764, -0.0058, -0.0180, -0.0181,\n          0.1647, -0.0613, -0.1030, -0.0756,  0.1530, -0.0219, -0.0473, -0.1513],\n        [ 0.0145, -0.1628,  0.1488, -0.0016, -0.1531, -0.0083,  0.1608, -0.0047,\n         -0.0808, -0.1325,  0.1600,  0.0479, -0.1208,  0.1254,  0.1429,  0.0876,\n         -0.0876,  0.0281, -0.1112,  0.1504,  0.0443,  0.1220, -0.1577, -0.0900,\n          0.1509,  0.1199,  0.0767, -0.1620, -0.0650,  0.0858,  0.1515,  0.1442],\n        [ 0.1569, -0.1275,  0.0811,  0.0760,  0.1075,  0.0176, -0.0425, -0.0140,\n         -0.0353, -0.1670, -0.0752, -0.0365, -0.0825, -0.0138, -0.1593, -0.1549,\n          0.1181,  0.1718, -0.1697,  0.1441, -0.0028,  0.0627, -0.1551, -0.0712,\n          0.0582,  0.1014, -0.0363, -0.0694,  0.0749, -0.0998,  0.0335, -0.0866]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0847,  0.1342,  0.0773,  0.0729,  0.0387,  0.1279,  0.1101, -0.1099,\n         0.1271, -0.1354, -0.1382,  0.0325,  0.1359,  0.0754,  0.0659,  0.1710],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 2.3304e-01,  5.0370e-02,  1.0931e-01,  5.2854e-02, -1.3494e-01,\n         -2.2295e-01, -1.6580e-01, -8.5488e-02, -2.3582e-01, -2.0600e-01,\n          7.9047e-02, -1.8154e-01,  1.9453e-01,  2.0889e-02,  7.6205e-02,\n         -1.0453e-01],\n        [ 1.3769e-01, -9.6085e-02, -1.2365e-01, -6.0714e-02, -1.6572e-01,\n          2.4498e-01, -1.9775e-01,  1.3692e-01, -1.7365e-02,  2.2121e-02,\n          2.1559e-01, -2.2450e-01, -7.4407e-02, -1.3364e-01, -1.9427e-01,\n         -2.5984e-02],\n        [ 9.1714e-02,  1.0557e-01,  1.3681e-01,  5.3075e-02, -7.9516e-02,\n          1.4715e-01, -2.3978e-01,  7.3202e-02, -1.4322e-02, -1.2373e-02,\n          1.9312e-01,  1.7447e-01, -1.5089e-04, -2.0236e-01, -1.4493e-01,\n          2.3502e-01],\n        [ 8.5147e-02,  2.0730e-01,  2.0122e-01,  3.4320e-02,  2.1478e-01,\n         -7.3416e-02, -3.7042e-03, -1.6384e-02,  2.8401e-02,  1.7898e-02,\n          6.4669e-02, -2.0202e-01, -5.1194e-02,  5.7548e-03, -1.1956e-01,\n         -2.1405e-01],\n        [ 1.6917e-01, -3.5129e-02, -2.2953e-01,  2.4469e-01, -6.6534e-02,\n          4.3682e-02,  8.3536e-02,  1.4942e-01,  2.2268e-01, -1.4651e-01,\n          3.0587e-02, -9.0796e-02, -3.9216e-02,  8.9576e-02, -3.7483e-02,\n         -2.0447e-01],\n        [-1.2979e-01,  8.3181e-02,  1.6803e-01,  5.0297e-02, -1.8962e-01,\n          9.6421e-02, -1.3662e-01, -1.8124e-01, -9.0029e-02, -4.0890e-02,\n         -4.4993e-02, -2.4829e-01, -2.4690e-01, -1.5769e-01,  1.5438e-01,\n         -1.3711e-01],\n        [ 2.2970e-01,  8.4645e-02, -2.0739e-01,  8.8554e-02, -6.1608e-03,\n          3.5409e-02,  1.7875e-01,  1.9074e-01,  1.2634e-01,  1.2503e-01,\n         -1.6906e-01, -1.3861e-01, -6.6103e-02,  6.1766e-02,  9.5459e-02,\n          2.2003e-01],\n        [ 8.3264e-02, -7.2795e-02,  3.2986e-02, -1.3983e-01, -1.1405e-01,\n         -2.1727e-01,  2.3628e-01,  5.7818e-02,  1.0733e-01,  5.7812e-02,\n         -2.6556e-02, -1.9964e-01,  1.5683e-01,  1.6548e-02, -2.1229e-01,\n         -1.2829e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0837,  0.0781, -0.1503, -0.0355,  0.2381,  0.0454,  0.1263,  0.1421],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0882, -0.1475,  0.2410,  0.2606,  0.2470, -0.0845,  0.0767,  0.2612]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0504], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x79f5a01d9e50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1225,  0.2139, -0.2514,  0.0471, -0.2295,  0.0634, -0.0390,  0.1392,\n         0.3450,  0.1309,  0.0800, -0.0327,  0.2731, -0.0137, -0.0959,  0.3192,\n        -0.1248,  0.1339, -0.1576, -0.1771, -0.1591,  0.0274,  0.0813,  0.0448,\n        -0.0897,  0.0428,  0.2957, -0.0974, -0.2123,  0.2859, -0.2708,  0.1205],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 1.2169e-02, -3.7240e-02,  3.2130e-02, -2.7524e-01, -5.2899e-02,\n         -1.2201e-02,  7.3056e-02,  5.1237e-02],\n        [ 1.3907e-01,  2.0392e-01, -2.2503e-01, -8.8361e-02, -1.9422e-01,\n         -2.1250e-01,  2.8163e-01, -1.4157e-01],\n        [ 1.7613e-01,  3.3673e-02,  1.4031e-01,  3.2308e-01, -3.3514e-01,\n         -2.6686e-01,  1.5428e-01,  2.2109e-01],\n        [ 4.2349e-02, -9.3770e-03, -2.4299e-01,  1.6535e-01, -2.5992e-01,\n         -3.4414e-02, -4.3206e-02,  1.9025e-01],\n        [ 1.5535e-01, -7.5449e-03,  2.4124e-01,  2.1278e-01, -1.3541e-01,\n          3.4381e-01,  1.9749e-01,  1.3653e-02],\n        [-2.3710e-01,  3.1791e-01,  2.2633e-01, -8.7702e-02, -2.3470e-01,\n         -1.7252e-01, -2.8915e-01,  1.2844e-01],\n        [ 2.8451e-01, -3.6226e-02, -6.1589e-02,  1.8331e-01,  1.3816e-01,\n         -1.5072e-02, -1.4641e-01,  3.1312e-01],\n        [-3.4398e-02,  1.8052e-01,  1.3089e-01, -2.2021e-01, -6.0732e-02,\n          3.1822e-01, -1.4532e-01,  6.5263e-02],\n        [ 1.3380e-01, -1.6320e-01,  3.5353e-01,  3.0367e-01, -4.1794e-02,\n          1.3661e-01,  2.9553e-01, -3.4187e-02],\n        [ 2.6986e-01,  1.5991e-02,  2.4159e-01,  3.0563e-01, -8.2523e-02,\n          2.0387e-01,  1.5018e-01,  2.6500e-01],\n        [-3.1352e-01,  1.7699e-01,  1.7388e-01, -2.3162e-02, -1.3156e-01,\n          3.1725e-01, -9.8530e-02, -6.3193e-02],\n        [ 2.4469e-01,  2.5862e-01, -2.0555e-01, -2.5306e-01,  1.7883e-01,\n          1.7376e-01,  6.5487e-02,  1.4231e-01],\n        [ 3.2641e-01, -2.8050e-01,  1.4790e-01,  1.0937e-02, -1.9663e-01,\n         -3.0472e-01, -8.7616e-02,  1.1919e-01],\n        [ 1.4102e-01, -3.2701e-01,  1.3043e-01, -3.1010e-01,  2.3253e-01,\n         -9.1620e-02, -2.8434e-01, -1.8775e-01],\n        [-9.4077e-02, -1.6663e-01,  3.3611e-03, -1.7411e-01, -2.6093e-01,\n         -1.7402e-01,  3.2264e-01, -2.7133e-01],\n        [-9.1418e-02, -3.0633e-01,  9.4923e-02, -2.7935e-01,  3.1526e-01,\n          7.2177e-02,  2.4514e-03, -1.8862e-01],\n        [ 3.9883e-02,  1.8367e-01, -3.3434e-01, -2.0888e-02,  8.7942e-02,\n         -6.3690e-02,  1.1735e-01, -1.7142e-01],\n        [ 1.6011e-01, -2.7866e-01, -1.8605e-02,  2.5848e-01,  3.4774e-01,\n          2.0639e-01,  9.5743e-02,  7.5639e-02],\n        [ 1.7590e-01, -3.1002e-01,  1.2063e-01, -3.4979e-01, -1.8541e-01,\n          3.2746e-01,  2.7447e-01, -2.3457e-02],\n        [-1.6136e-01,  2.5889e-01,  1.6175e-01, -3.3612e-02,  9.2965e-02,\n          3.1748e-01,  2.8165e-01,  2.2160e-01],\n        [-1.9670e-01,  1.5755e-01,  4.8377e-02, -2.4495e-01,  9.4008e-02,\n          3.5305e-01, -1.5957e-01, -1.0501e-01],\n        [-3.2909e-01,  6.8571e-02,  2.8112e-01, -2.5486e-01,  3.1835e-01,\n         -2.0402e-01,  8.0902e-02,  1.1279e-01],\n        [ 3.8945e-03,  2.9087e-01, -1.9895e-01,  9.6848e-02,  1.3341e-01,\n          1.8030e-01, -2.5298e-01, -1.0049e-02],\n        [ 2.3292e-01,  1.2864e-01, -2.4850e-01,  2.3822e-01,  8.2431e-02,\n          3.2617e-01, -1.7952e-02, -3.2524e-01],\n        [ 2.7825e-01, -3.1546e-02,  1.8045e-02,  2.9293e-01, -5.4782e-02,\n         -3.2091e-02,  2.0075e-02, -1.2579e-01],\n        [ 1.8792e-01,  3.3691e-01, -2.6653e-01, -1.0861e-01,  9.1522e-02,\n         -2.9827e-01, -2.8012e-01, -1.3289e-01],\n        [-2.2024e-01,  1.3717e-01,  2.7069e-01, -3.2544e-01, -2.3888e-01,\n          2.5926e-01, -1.7235e-01,  2.6372e-01],\n        [-3.1288e-01,  1.9685e-02, -8.8262e-02,  2.6004e-01,  8.2731e-02,\n         -2.6872e-01, -1.4071e-01,  2.3044e-01],\n        [-3.0316e-04, -3.3191e-01,  7.9695e-03,  1.9623e-01, -2.0187e-01,\n         -3.0759e-01,  5.3183e-02,  1.2590e-02],\n        [-2.4192e-01, -2.1832e-01, -3.5124e-01, -5.6283e-02, -2.5258e-01,\n         -2.1614e-02, -5.3117e-02,  6.4190e-02],\n        [-2.7533e-01,  2.3579e-01,  1.9838e-01, -2.0661e-01,  2.3799e-01,\n          1.2025e-01,  2.9732e-01, -6.4400e-02],\n        [-1.8307e-01,  1.0855e-01, -2.3149e-01,  1.7659e-01, -1.7838e-01,\n         -4.8451e-02, -1.7220e-01, -8.9465e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0847,  0.1342,  0.0773,  0.0729,  0.0387,  0.1279,  0.1101, -0.1099,\n         0.1271, -0.1354, -0.1382,  0.0325,  0.1359,  0.0754,  0.0659,  0.1710],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.1084, -0.0472, -0.1438, -0.1407, -0.1733, -0.0749,  0.1107,  0.1037,\n         -0.0413,  0.0524, -0.1267, -0.1229,  0.1391, -0.0428,  0.1692, -0.1532,\n         -0.0294, -0.0283, -0.1434,  0.0803, -0.0685,  0.0737, -0.0580,  0.1632,\n         -0.0887, -0.0882,  0.1394, -0.1638, -0.0384,  0.0882,  0.1138, -0.1688],\n        [ 0.1338, -0.1212,  0.1550,  0.1765, -0.0729,  0.0651,  0.1341, -0.0274,\n          0.1441, -0.0298,  0.0255,  0.0074,  0.0426, -0.0880, -0.0957,  0.0640,\n         -0.0158, -0.0871,  0.0429,  0.0831,  0.0767, -0.1460,  0.0868,  0.1659,\n          0.1593, -0.0673,  0.0836, -0.1008,  0.1404,  0.1252,  0.1062, -0.0681],\n        [ 0.1676,  0.1098,  0.0340,  0.0812,  0.0820, -0.1464,  0.0858,  0.1235,\n          0.0475,  0.0933, -0.0137, -0.0269,  0.0023,  0.0561,  0.1085,  0.0500,\n          0.1137,  0.1399,  0.0444, -0.0644,  0.0203, -0.0262,  0.1523, -0.1109,\n          0.0650, -0.1706,  0.0014, -0.0801, -0.0357,  0.0932,  0.1254,  0.0508],\n        [ 0.1722, -0.0746, -0.1181, -0.0444,  0.1736,  0.0237,  0.1698, -0.0925,\n         -0.0138, -0.1604,  0.0687, -0.1622,  0.1193, -0.0588, -0.1395, -0.0207,\n          0.0334, -0.0887,  0.0522, -0.0785, -0.0493,  0.1385,  0.1231, -0.0804,\n         -0.1235, -0.1576,  0.0193, -0.0613,  0.1135,  0.1213, -0.0557,  0.0042],\n        [-0.0244, -0.0956,  0.1678,  0.0240, -0.1734,  0.1164,  0.1100, -0.0130,\n         -0.1463,  0.0742,  0.0183,  0.0639, -0.0461,  0.1347,  0.0446,  0.1285,\n         -0.1440,  0.1423, -0.1256, -0.1656,  0.0688,  0.0856,  0.0255,  0.0653,\n         -0.0403,  0.1623,  0.1081, -0.1388,  0.1646,  0.0285, -0.0586, -0.1607],\n        [ 0.1411,  0.0559, -0.0455, -0.1427,  0.1193, -0.0428, -0.1387, -0.0926,\n         -0.0356,  0.0490,  0.0011,  0.0785, -0.0294, -0.0247, -0.1638, -0.0777,\n         -0.1675, -0.1718,  0.1137,  0.1587,  0.0160, -0.1541,  0.0829,  0.1089,\n          0.0504,  0.0831,  0.0892, -0.0185,  0.1408,  0.0967, -0.1334, -0.1097],\n        [-0.1100, -0.1262,  0.0026, -0.0537,  0.1617,  0.1630,  0.0112, -0.1456,\n         -0.1647,  0.0161, -0.0191,  0.0311,  0.0659,  0.1451, -0.1717,  0.1165,\n         -0.1389,  0.0487, -0.0465, -0.1579, -0.1296,  0.1254, -0.1340,  0.1201,\n         -0.1359,  0.1662,  0.0920,  0.0168, -0.0835, -0.0912, -0.1694,  0.0359],\n        [-0.0644,  0.0138,  0.0806,  0.0265, -0.0937, -0.1493, -0.1195,  0.1417,\n          0.0145,  0.1094,  0.0980,  0.1547,  0.1239,  0.0738, -0.0886,  0.0523,\n         -0.0463, -0.0054,  0.1654, -0.0313, -0.1213, -0.0626,  0.0561, -0.0487,\n          0.0406, -0.0269, -0.1734, -0.0730, -0.1477, -0.1740,  0.0461,  0.0102],\n        [-0.0389, -0.1654,  0.0103,  0.1346,  0.1121,  0.0803,  0.1699, -0.0498,\n         -0.1650, -0.1147, -0.0106,  0.0341,  0.0168, -0.0713, -0.0080,  0.0861,\n          0.0030, -0.1590, -0.0011,  0.0968,  0.1105,  0.1205, -0.0201,  0.1121,\n         -0.0006, -0.0469,  0.0975, -0.1738,  0.1438,  0.1324,  0.1364,  0.0720],\n        [ 0.1129, -0.1410, -0.1150,  0.1559,  0.1242, -0.0673, -0.0292,  0.0681,\n         -0.0278,  0.0976, -0.0713,  0.0634, -0.0586,  0.0575,  0.0067,  0.0868,\n          0.0013,  0.1605, -0.0508, -0.0416,  0.0272, -0.1262,  0.0121, -0.0215,\n         -0.0493,  0.1016, -0.1357, -0.0150,  0.0373, -0.1681, -0.1566, -0.1300],\n        [-0.0461, -0.1086,  0.1002, -0.0265,  0.0687,  0.0379,  0.0422,  0.0489,\n         -0.1439, -0.0345,  0.1070,  0.0620, -0.0594,  0.1540, -0.0319, -0.0849,\n         -0.1667,  0.1181, -0.1683,  0.0600,  0.0355, -0.0426,  0.0962,  0.0192,\n          0.1352,  0.1125,  0.0824,  0.1649, -0.0356,  0.0959,  0.0041, -0.0983],\n        [ 0.1332, -0.0115,  0.0779,  0.1193, -0.0279,  0.0254,  0.0898,  0.0053,\n          0.0159,  0.1518,  0.0511, -0.0692,  0.0574, -0.0035, -0.1405, -0.1426,\n         -0.0383,  0.0344,  0.0672,  0.1010, -0.1665, -0.1142,  0.1702,  0.1671,\n         -0.1131,  0.1077, -0.0613, -0.0076,  0.1029, -0.0331,  0.1450, -0.1728],\n        [-0.0181, -0.0536,  0.1580,  0.1229, -0.1715, -0.0381, -0.0580, -0.0416,\n          0.0565, -0.0056, -0.1518,  0.0906, -0.1046,  0.1589,  0.0264, -0.0157,\n         -0.1733, -0.0165,  0.1164,  0.0032,  0.0241, -0.1419, -0.1075,  0.1567,\n          0.0125,  0.1663,  0.0370, -0.0306,  0.0859, -0.0792, -0.0656, -0.1528],\n        [-0.0334, -0.0762, -0.0330, -0.1314, -0.1284, -0.0618,  0.0974, -0.1110,\n         -0.0161, -0.0657, -0.1176,  0.0006, -0.1725, -0.1514, -0.0590,  0.1535,\n          0.0683, -0.1702,  0.0237, -0.1272, -0.1764, -0.0058, -0.0180, -0.0181,\n          0.1647, -0.0613, -0.1030, -0.0756,  0.1530, -0.0219, -0.0473, -0.1513],\n        [ 0.0145, -0.1628,  0.1488, -0.0016, -0.1531, -0.0083,  0.1608, -0.0047,\n         -0.0808, -0.1325,  0.1600,  0.0479, -0.1208,  0.1254,  0.1429,  0.0876,\n         -0.0876,  0.0281, -0.1112,  0.1504,  0.0443,  0.1220, -0.1577, -0.0900,\n          0.1509,  0.1199,  0.0767, -0.1620, -0.0650,  0.0858,  0.1515,  0.1442],\n        [ 0.1569, -0.1275,  0.0811,  0.0760,  0.1075,  0.0176, -0.0425, -0.0140,\n         -0.0353, -0.1670, -0.0752, -0.0365, -0.0825, -0.0138, -0.1593, -0.1549,\n          0.1181,  0.1718, -0.1697,  0.1441, -0.0028,  0.0627, -0.1551, -0.0712,\n          0.0582,  0.1014, -0.0363, -0.0694,  0.0749, -0.0998,  0.0335, -0.0866]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0837,  0.0781, -0.1503, -0.0355,  0.2381,  0.0454,  0.1263,  0.1421],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 2.3304e-01,  5.0370e-02,  1.0931e-01,  5.2854e-02, -1.3494e-01,\n         -2.2295e-01, -1.6580e-01, -8.5488e-02, -2.3582e-01, -2.0600e-01,\n          7.9047e-02, -1.8154e-01,  1.9453e-01,  2.0889e-02,  7.6205e-02,\n         -1.0453e-01],\n        [ 1.3769e-01, -9.6085e-02, -1.2365e-01, -6.0714e-02, -1.6572e-01,\n          2.4498e-01, -1.9775e-01,  1.3692e-01, -1.7365e-02,  2.2121e-02,\n          2.1559e-01, -2.2450e-01, -7.4407e-02, -1.3364e-01, -1.9427e-01,\n         -2.5984e-02],\n        [ 9.1714e-02,  1.0557e-01,  1.3681e-01,  5.3075e-02, -7.9516e-02,\n          1.4715e-01, -2.3978e-01,  7.3202e-02, -1.4322e-02, -1.2373e-02,\n          1.9312e-01,  1.7447e-01, -1.5089e-04, -2.0236e-01, -1.4493e-01,\n          2.3502e-01],\n        [ 8.5147e-02,  2.0730e-01,  2.0122e-01,  3.4320e-02,  2.1478e-01,\n         -7.3416e-02, -3.7042e-03, -1.6384e-02,  2.8401e-02,  1.7898e-02,\n          6.4669e-02, -2.0202e-01, -5.1194e-02,  5.7548e-03, -1.1956e-01,\n         -2.1405e-01],\n        [ 1.6917e-01, -3.5129e-02, -2.2953e-01,  2.4469e-01, -6.6534e-02,\n          4.3682e-02,  8.3536e-02,  1.4942e-01,  2.2268e-01, -1.4651e-01,\n          3.0587e-02, -9.0796e-02, -3.9216e-02,  8.9576e-02, -3.7483e-02,\n         -2.0447e-01],\n        [-1.2979e-01,  8.3181e-02,  1.6803e-01,  5.0297e-02, -1.8962e-01,\n          9.6421e-02, -1.3662e-01, -1.8124e-01, -9.0029e-02, -4.0890e-02,\n         -4.4993e-02, -2.4829e-01, -2.4690e-01, -1.5769e-01,  1.5438e-01,\n         -1.3711e-01],\n        [ 2.2970e-01,  8.4645e-02, -2.0739e-01,  8.8554e-02, -6.1608e-03,\n          3.5409e-02,  1.7875e-01,  1.9074e-01,  1.2634e-01,  1.2503e-01,\n         -1.6906e-01, -1.3861e-01, -6.6103e-02,  6.1766e-02,  9.5459e-02,\n          2.2003e-01],\n        [ 8.3264e-02, -7.2795e-02,  3.2986e-02, -1.3983e-01, -1.1405e-01,\n         -2.1727e-01,  2.3628e-01,  5.7818e-02,  1.0733e-01,  5.7812e-02,\n         -2.6556e-02, -1.9964e-01,  1.5683e-01,  1.6548e-02, -2.1229e-01,\n         -1.2829e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=1, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0504], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0882, -0.1475,  0.2410,  0.2606,  0.2470, -0.0845,  0.0767,  0.2612]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	1,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x79f51dfee550>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s455100000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s455100000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}