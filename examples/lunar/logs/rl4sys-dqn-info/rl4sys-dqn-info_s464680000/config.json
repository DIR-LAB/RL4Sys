{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	10,
    "batch_size":	54,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s464680000"
    },
    "max_sample_age":	-1,
    "q_lr":	0.0003,
    "sample_decay":	0.8,
    "seed":	464680000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x74c121306f50>":	{
            "_act_dim":	4,
            "_aux_batch_size":	10,
            "_batch_size":	54,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1898, -0.1762, -0.2756, -0.1433, -0.3392, -0.2997,  0.2931,  0.1141,\n         0.1576,  0.1315, -0.2893, -0.1345,  0.0695,  0.1024, -0.1639, -0.0190,\n         0.0066, -0.2521,  0.1109,  0.0979,  0.0963, -0.2624, -0.0033, -0.0350,\n        -0.0637,  0.1352, -0.0151,  0.2778, -0.0893,  0.1623,  0.2928, -0.1537,\n         0.1506,  0.2784,  0.2961, -0.3204,  0.2190,  0.2507,  0.0419,  0.1441,\n        -0.1976,  0.1066, -0.3132, -0.0668, -0.0585, -0.1348,  0.0185, -0.1610,\n        -0.0929,  0.0552,  0.1856,  0.3135, -0.0572,  0.0423,  0.0451, -0.0225,\n        -0.1333, -0.2166, -0.2274,  0.3208,  0.2816, -0.0544, -0.1457, -0.1526,\n         0.1886, -0.1676, -0.1006, -0.1998,  0.0035, -0.2489, -0.0281,  0.2665,\n        -0.0690,  0.1979, -0.1354, -0.0185,  0.1758,  0.2106,  0.1329, -0.0281,\n        -0.1785, -0.1221, -0.3326, -0.2470,  0.1160,  0.3266,  0.2444, -0.1299,\n        -0.0468,  0.1469,  0.3495,  0.1794, -0.1104, -0.0520, -0.2222, -0.2577,\n        -0.2970,  0.2616,  0.0408, -0.2945, -0.2258, -0.1781,  0.1443,  0.0540,\n        -0.2155,  0.0980,  0.0988,  0.2985, -0.0988, -0.2504, -0.1618,  0.2862,\n        -0.1246, -0.1071,  0.0343, -0.3491,  0.3256,  0.0383, -0.1144, -0.2840,\n         0.1164, -0.2475,  0.0167, -0.2640,  0.0040, -0.2427, -0.2558, -0.0293],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2441, -0.1144, -0.2973,  ..., -0.2360, -0.3187,  0.2260],\n        [-0.3025, -0.0146,  0.1027,  ..., -0.1063,  0.2372, -0.1533],\n        [ 0.1218,  0.3444, -0.2032,  ...,  0.3120,  0.3127,  0.0752],\n        ...,\n        [-0.1815,  0.0115, -0.0781,  ..., -0.0994, -0.0329,  0.2246],\n        [ 0.3141, -0.2070, -0.0584,  ..., -0.0964,  0.0515,  0.0262],\n        [-0.1341, -0.3115, -0.2290,  ..., -0.3485, -0.0170, -0.1314]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-8.1626e-02,  4.6189e-03, -5.7454e-02, -5.8898e-02, -8.6482e-02,\n        -8.6703e-03, -4.8134e-02,  4.3289e-02, -4.9020e-02,  3.6812e-02,\n        -8.5084e-02,  7.8713e-02, -8.5649e-02, -6.3775e-02,  3.9930e-02,\n        -3.7520e-02,  4.0814e-02, -7.9666e-02, -4.4970e-02, -8.4976e-02,\n         3.3843e-02, -8.1197e-02,  3.6977e-02, -8.1920e-02, -2.7258e-02,\n         2.0597e-02, -2.4703e-02, -5.6231e-02,  2.2073e-02,  3.7791e-02,\n        -5.8747e-02, -3.8396e-02,  5.0315e-02, -2.2035e-02,  4.1238e-02,\n         5.2500e-02, -4.9572e-02,  3.6297e-02,  2.4907e-02, -2.9914e-02,\n        -5.3642e-03, -5.1459e-02,  3.6940e-02,  8.6720e-02, -4.0497e-02,\n         3.4964e-02,  3.8407e-02, -1.9832e-02, -5.2336e-05, -5.1224e-02,\n         3.2367e-02, -4.3331e-02,  8.7661e-03,  1.3746e-03,  5.2218e-02,\n         5.1938e-02,  3.0954e-02, -1.0932e-02, -3.1751e-02, -3.0222e-02,\n        -1.2379e-02,  8.1728e-02, -9.2435e-03, -3.6811e-02,  5.3266e-02,\n         7.8337e-02,  1.0274e-02, -4.3562e-02, -1.3803e-02, -7.4905e-02,\n         5.8984e-02, -8.1620e-02,  4.9671e-02,  5.1129e-02,  9.6338e-03,\n         5.3071e-02, -2.7081e-02,  5.7273e-03, -8.3127e-02,  4.7199e-02,\n        -3.1161e-02, -5.6304e-02, -2.5695e-02, -5.4725e-02, -4.7194e-02,\n         5.5571e-02, -2.8979e-02,  1.1736e-02, -4.0060e-02, -3.8274e-02,\n        -7.6433e-02, -8.3510e-02,  5.8277e-02, -9.2936e-04, -5.6439e-02,\n         3.4606e-04, -8.5581e-02,  6.3023e-03,  4.2315e-03,  3.9407e-02,\n         2.5725e-02,  9.4929e-03, -2.1267e-02, -2.0158e-02,  1.6974e-02,\n         4.5165e-02,  6.7878e-03, -4.3990e-02,  6.1921e-02, -5.4556e-02,\n        -4.7467e-02,  8.0408e-02,  6.7357e-02, -3.5305e-02,  7.3396e-02,\n        -4.0416e-02, -8.2922e-02,  1.1034e-02, -7.5220e-02,  8.5369e-02,\n         1.7071e-02,  2.7779e-04,  7.7184e-02,  4.7917e-02, -3.6622e-02,\n        -1.9836e-03, -3.3907e-02, -7.4223e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0144, -0.0368,  0.0882,  ..., -0.0587, -0.0615,  0.0725],\n        [ 0.0312,  0.0336,  0.0062,  ...,  0.0360,  0.0264, -0.0174],\n        [-0.0701,  0.0342,  0.0022,  ..., -0.0041,  0.0363,  0.0111],\n        ...,\n        [-0.0866, -0.0067,  0.0052,  ...,  0.0109, -0.0671,  0.0819],\n        [-0.0639, -0.0124,  0.0051,  ...,  0.0369, -0.0067, -0.0504],\n        [ 0.0472,  0.0876,  0.0268,  ..., -0.0471, -0.0614,  0.0142]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0474,  0.0443,  0.0837, -0.0396], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 4.4213e-02,  2.3532e-02,  5.1495e-02, -6.0928e-02, -7.5104e-02,\n         -6.5460e-02, -1.1634e-03, -2.0504e-02,  6.2599e-03,  6.7254e-02,\n          3.8722e-02, -2.4754e-02, -7.9002e-02,  7.3318e-02, -7.6518e-02,\n         -3.9405e-02, -3.7548e-02, -5.6858e-02,  6.0321e-02,  7.7403e-04,\n          5.2147e-02, -2.5313e-02,  7.4539e-02,  2.1057e-03, -6.5961e-02,\n         -2.6475e-02, -7.5117e-02, -7.2708e-04, -1.8861e-05, -4.4485e-02,\n         -2.5905e-02,  2.3714e-02, -4.7336e-02,  4.3315e-03, -6.7604e-02,\n         -7.1282e-02,  5.5818e-02,  1.2351e-02, -7.4180e-02, -2.5838e-02,\n          5.4618e-02, -8.2257e-02, -4.1973e-02, -5.2011e-02,  6.6260e-03,\n         -7.6699e-02,  8.0532e-02, -2.3358e-02, -5.7351e-02, -2.9597e-02,\n         -1.3639e-03,  7.2502e-02,  1.1382e-02, -7.1292e-02, -8.7947e-02,\n         -3.3941e-02, -3.5988e-02,  2.1222e-02, -3.1463e-02, -7.1939e-02,\n          3.2767e-02, -3.2814e-02,  2.2355e-02,  6.6292e-02, -6.6322e-02,\n         -2.9937e-03, -8.7816e-03,  7.1974e-02, -8.2160e-02,  6.1837e-02,\n         -3.6703e-02,  3.5821e-02,  7.0787e-02,  2.3715e-02, -8.0051e-02,\n         -5.8955e-02, -4.7485e-03,  8.4288e-02, -4.3984e-02,  2.2855e-02,\n         -6.4828e-02,  3.8610e-02,  3.9440e-02,  1.6234e-02, -4.6599e-02,\n         -6.9215e-02,  2.9270e-02,  7.2564e-02,  7.1984e-02,  6.9419e-02,\n          7.9521e-02, -5.2892e-03, -6.7627e-02,  8.5684e-02,  1.0242e-02,\n         -6.4964e-02,  3.8886e-02, -5.7354e-02, -2.6980e-02, -7.4866e-02,\n          6.8092e-02,  2.3044e-02, -3.3936e-02, -2.3106e-02,  5.2801e-02,\n         -5.5335e-02,  2.4707e-02,  1.4272e-02,  8.1458e-02, -7.9188e-02,\n         -7.2265e-02,  3.0093e-02,  8.6013e-02,  2.5092e-02,  6.5585e-02,\n         -3.6560e-03, -7.7345e-02,  6.0198e-02, -8.4372e-02,  8.1686e-04,\n          8.6284e-02,  6.3635e-02,  1.5740e-02,  6.3455e-02,  4.3993e-02,\n         -8.1472e-02,  3.2638e-02,  8.5901e-02],\n        [ 4.5471e-02,  5.6457e-02,  4.6354e-02, -7.6290e-02, -7.4786e-02,\n         -8.5459e-03,  4.4197e-02,  4.0828e-02, -1.3889e-02, -7.0082e-02,\n          8.7065e-02, -8.5317e-02, -4.3130e-02, -6.0264e-02, -8.7521e-02,\n         -8.0359e-02, -3.7467e-02, -5.2035e-02,  1.1499e-02, -7.6087e-02,\n          8.0937e-02, -3.7837e-03, -8.0661e-02,  1.3836e-02,  4.7401e-02,\n         -3.6186e-02,  4.0220e-03,  5.3675e-02,  1.9734e-02,  4.9867e-02,\n          4.7825e-02, -6.8573e-02,  2.9425e-02, -7.4259e-02,  7.9248e-02,\n          4.2586e-02, -4.1746e-02, -2.4868e-02,  8.2329e-02,  1.9104e-02,\n         -3.9679e-02,  8.7279e-03,  6.6248e-02, -5.6676e-02,  7.3536e-02,\n         -8.3793e-02, -7.3475e-02,  8.2233e-02, -2.4794e-02, -2.7564e-02,\n          5.9141e-02, -7.2236e-02, -8.4300e-02, -2.3245e-02,  4.6953e-02,\n         -4.1764e-02, -6.4652e-02,  1.5056e-02,  8.6397e-02,  6.7903e-03,\n         -8.6973e-02,  5.6686e-02, -8.7258e-02,  5.3730e-03, -3.3384e-02,\n          6.9534e-02, -8.3843e-02, -1.1143e-02, -4.7152e-02,  4.3443e-02,\n          7.4007e-02, -6.6164e-02,  3.8779e-02,  8.2638e-02, -5.2840e-02,\n         -6.4142e-03,  3.8120e-02,  3.5380e-02,  1.9663e-02,  4.2029e-02,\n         -5.0654e-02, -6.2182e-02,  7.9633e-02, -3.9923e-02,  8.2505e-02,\n          3.1083e-02, -1.4248e-02, -1.7432e-02,  6.4734e-02, -6.9835e-02,\n         -6.2200e-02, -8.0907e-02, -8.6471e-02, -2.2808e-02,  6.4780e-02,\n          5.2546e-02, -4.8724e-02, -5.2016e-02, -7.6465e-02, -5.1873e-02,\n          5.9932e-02,  6.4162e-02,  5.0483e-02, -8.2333e-02,  6.4252e-02,\n         -3.9450e-02, -7.7112e-02, -8.1451e-02, -4.3733e-02, -2.4902e-02,\n         -8.7455e-02,  6.3640e-02,  5.4532e-02,  1.8089e-02, -4.6038e-02,\n         -4.9215e-02,  3.0815e-02,  1.6948e-02, -5.8596e-02,  3.1918e-02,\n          8.2656e-02,  4.4904e-02,  7.9842e-02,  2.4173e-02,  7.6456e-02,\n         -7.4252e-02,  5.1734e-02,  4.1609e-02],\n        [ 4.7443e-02, -3.5590e-02, -8.4338e-04,  1.6504e-02,  7.0682e-02,\n          2.6467e-02,  4.6916e-02,  7.3811e-02, -8.1340e-03, -6.9402e-02,\n         -7.7164e-03,  4.2785e-02, -5.3308e-02, -6.0883e-02, -5.5359e-02,\n          4.5587e-02,  7.3842e-02,  3.6837e-02, -2.5091e-02,  6.6791e-03,\n         -2.1762e-03,  7.9501e-02,  4.7777e-02,  7.4142e-02,  5.8323e-02,\n         -3.7306e-02, -3.1029e-02, -3.0886e-02, -2.7014e-02, -2.7085e-02,\n         -8.6724e-02, -3.3810e-02, -4.3286e-02,  3.9551e-02,  7.4034e-02,\n          4.6028e-02, -6.2733e-02,  5.2159e-02,  4.5543e-02, -1.2821e-03,\n         -4.2525e-02, -4.3043e-02,  4.5238e-02, -1.4774e-02,  1.6698e-02,\n          8.4444e-02, -2.5943e-02,  3.7408e-02,  5.6376e-02, -2.8655e-02,\n          8.0375e-02,  3.3442e-02, -7.3454e-02,  8.0039e-02, -8.3253e-02,\n          7.2059e-02,  2.1136e-02,  7.1394e-02,  1.6399e-02, -6.2270e-02,\n         -7.7435e-02, -5.7245e-02, -6.0382e-02,  1.6311e-02, -1.3736e-03,\n          3.8919e-02,  5.0812e-02,  5.2758e-04, -4.8506e-02,  2.6571e-02,\n          6.7799e-02,  8.8069e-02, -1.0302e-02,  8.2866e-02, -3.1588e-03,\n          4.7271e-03,  1.9524e-02,  7.3491e-03, -5.7301e-02, -7.6441e-02,\n          4.6975e-02,  8.4648e-02, -7.9700e-02,  1.2654e-02,  7.6822e-02,\n          6.0430e-02, -2.4546e-02,  2.6773e-02, -7.9250e-02,  5.0873e-02,\n          6.4227e-02,  7.3452e-02,  7.6116e-02, -8.2679e-02,  5.2556e-02,\n         -3.3993e-02,  4.4440e-02,  8.2211e-02,  4.8283e-02, -8.3734e-02,\n         -2.6800e-02,  8.2669e-02, -4.7400e-02,  3.2502e-02,  5.5224e-02,\n         -5.2352e-02,  1.4794e-02,  7.4929e-02,  2.5429e-02,  8.1557e-02,\n          9.6243e-03,  2.3044e-02, -2.7301e-02,  4.8918e-03,  8.8384e-02,\n          3.1051e-02, -7.8250e-02, -5.0349e-02,  4.7338e-03,  2.5892e-02,\n          2.1299e-02, -2.2819e-02, -4.0448e-02,  4.7000e-02, -7.3501e-02,\n          4.1300e-02,  2.3710e-02, -4.8076e-02],\n        [-1.6907e-02,  7.3917e-03,  4.0655e-02, -3.5602e-02, -4.8719e-02,\n          1.3452e-02, -3.9705e-02,  6.6331e-02,  1.2007e-02,  1.8305e-02,\n          5.7293e-02,  5.5207e-02, -8.7773e-02,  1.8253e-02,  3.4154e-02,\n         -4.7908e-03,  3.7748e-03,  8.2314e-02, -7.0968e-02,  2.8806e-02,\n          1.5209e-02, -8.6172e-02, -2.8604e-02,  3.1754e-03, -3.6600e-02,\n         -6.2526e-02,  4.6814e-02,  3.7273e-02,  7.2121e-02, -8.0778e-02,\n         -7.1993e-02, -3.0191e-02, -6.4393e-03,  9.1311e-04, -6.7507e-02,\n          6.1929e-02,  5.1053e-02, -2.1370e-02,  4.6707e-03, -1.7907e-02,\n         -5.5903e-02,  2.5997e-02,  5.9479e-03,  5.5007e-02,  6.5374e-02,\n          2.0279e-02, -7.8289e-02, -4.3235e-02,  8.4036e-02,  3.1804e-02,\n         -8.1015e-02,  1.6515e-02,  4.8431e-02,  4.1822e-02,  7.5502e-02,\n         -4.7830e-02, -3.1827e-02,  5.3549e-02, -8.5610e-02, -6.0629e-02,\n         -5.1415e-02,  8.2731e-04, -3.9915e-02, -1.3948e-02,  8.2212e-02,\n         -2.2365e-02, -2.6390e-02,  5.3557e-02,  1.5210e-02,  5.7565e-02,\n          6.9745e-02, -5.5071e-02, -2.2013e-03, -2.7314e-03, -1.1537e-02,\n         -3.0702e-02,  4.4762e-02, -1.9559e-02,  1.3353e-02, -6.1246e-02,\n         -3.3803e-02, -1.0049e-02,  3.5887e-02,  4.4268e-02, -6.5785e-02,\n         -8.1787e-02,  1.3651e-02, -4.2918e-02, -8.4551e-02,  5.6919e-02,\n         -3.1441e-02, -5.9146e-02, -1.7649e-02, -8.4106e-02, -8.6021e-02,\n         -2.6451e-02,  6.9557e-02,  5.7963e-02,  8.0808e-02, -6.8755e-02,\n         -1.2529e-02, -4.4546e-02, -4.8240e-02,  5.7786e-02,  2.8103e-02,\n         -8.4968e-02, -7.9388e-02, -7.5387e-02,  3.1094e-02, -1.9826e-03,\n          5.3839e-02, -8.7160e-02, -8.1732e-02, -4.4456e-02, -3.8393e-02,\n          2.9854e-02, -7.8013e-02, -6.5006e-03, -1.9965e-02, -1.7319e-02,\n         -8.5326e-02, -6.4536e-02,  3.2653e-02, -3.3679e-02, -7.7082e-02,\n          6.3334e-02, -5.1311e-02, -8.8078e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2441, -0.1144, -0.2973,  ..., -0.2360, -0.3187,  0.2260],\n        [-0.3025, -0.0146,  0.1027,  ..., -0.1063,  0.2372, -0.1533],\n        [ 0.1218,  0.3444, -0.2032,  ...,  0.3120,  0.3127,  0.0752],\n        ...,\n        [-0.1815,  0.0115, -0.0781,  ..., -0.0994, -0.0329,  0.2246],\n        [ 0.3141, -0.2070, -0.0584,  ..., -0.0964,  0.0515,  0.0262],\n        [-0.1341, -0.3115, -0.2290,  ..., -0.3485, -0.0170, -0.1314]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1898, -0.1762, -0.2756, -0.1433, -0.3392, -0.2997,  0.2931,  0.1141,\n         0.1576,  0.1315, -0.2893, -0.1345,  0.0695,  0.1024, -0.1639, -0.0190,\n         0.0066, -0.2521,  0.1109,  0.0979,  0.0963, -0.2624, -0.0033, -0.0350,\n        -0.0637,  0.1352, -0.0151,  0.2778, -0.0893,  0.1623,  0.2928, -0.1537,\n         0.1506,  0.2784,  0.2961, -0.3204,  0.2190,  0.2507,  0.0419,  0.1441,\n        -0.1976,  0.1066, -0.3132, -0.0668, -0.0585, -0.1348,  0.0185, -0.1610,\n        -0.0929,  0.0552,  0.1856,  0.3135, -0.0572,  0.0423,  0.0451, -0.0225,\n        -0.1333, -0.2166, -0.2274,  0.3208,  0.2816, -0.0544, -0.1457, -0.1526,\n         0.1886, -0.1676, -0.1006, -0.1998,  0.0035, -0.2489, -0.0281,  0.2665,\n        -0.0690,  0.1979, -0.1354, -0.0185,  0.1758,  0.2106,  0.1329, -0.0281,\n        -0.1785, -0.1221, -0.3326, -0.2470,  0.1160,  0.3266,  0.2444, -0.1299,\n        -0.0468,  0.1469,  0.3495,  0.1794, -0.1104, -0.0520, -0.2222, -0.2577,\n        -0.2970,  0.2616,  0.0408, -0.2945, -0.2258, -0.1781,  0.1443,  0.0540,\n        -0.2155,  0.0980,  0.0988,  0.2985, -0.0988, -0.2504, -0.1618,  0.2862,\n        -0.1246, -0.1071,  0.0343, -0.3491,  0.3256,  0.0383, -0.1144, -0.2840,\n         0.1164, -0.2475,  0.0167, -0.2640,  0.0040, -0.2427, -0.2558, -0.0293],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0144, -0.0368,  0.0882,  ..., -0.0587, -0.0615,  0.0725],\n        [ 0.0312,  0.0336,  0.0062,  ...,  0.0360,  0.0264, -0.0174],\n        [-0.0701,  0.0342,  0.0022,  ..., -0.0041,  0.0363,  0.0111],\n        ...,\n        [-0.0866, -0.0067,  0.0052,  ...,  0.0109, -0.0671,  0.0819],\n        [-0.0639, -0.0124,  0.0051,  ...,  0.0369, -0.0067, -0.0504],\n        [ 0.0472,  0.0876,  0.0268,  ..., -0.0471, -0.0614,  0.0142]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-8.1626e-02,  4.6189e-03, -5.7454e-02, -5.8898e-02, -8.6482e-02,\n        -8.6703e-03, -4.8134e-02,  4.3289e-02, -4.9020e-02,  3.6812e-02,\n        -8.5084e-02,  7.8713e-02, -8.5649e-02, -6.3775e-02,  3.9930e-02,\n        -3.7520e-02,  4.0814e-02, -7.9666e-02, -4.4970e-02, -8.4976e-02,\n         3.3843e-02, -8.1197e-02,  3.6977e-02, -8.1920e-02, -2.7258e-02,\n         2.0597e-02, -2.4703e-02, -5.6231e-02,  2.2073e-02,  3.7791e-02,\n        -5.8747e-02, -3.8396e-02,  5.0315e-02, -2.2035e-02,  4.1238e-02,\n         5.2500e-02, -4.9572e-02,  3.6297e-02,  2.4907e-02, -2.9914e-02,\n        -5.3642e-03, -5.1459e-02,  3.6940e-02,  8.6720e-02, -4.0497e-02,\n         3.4964e-02,  3.8407e-02, -1.9832e-02, -5.2336e-05, -5.1224e-02,\n         3.2367e-02, -4.3331e-02,  8.7661e-03,  1.3746e-03,  5.2218e-02,\n         5.1938e-02,  3.0954e-02, -1.0932e-02, -3.1751e-02, -3.0222e-02,\n        -1.2379e-02,  8.1728e-02, -9.2435e-03, -3.6811e-02,  5.3266e-02,\n         7.8337e-02,  1.0274e-02, -4.3562e-02, -1.3803e-02, -7.4905e-02,\n         5.8984e-02, -8.1620e-02,  4.9671e-02,  5.1129e-02,  9.6338e-03,\n         5.3071e-02, -2.7081e-02,  5.7273e-03, -8.3127e-02,  4.7199e-02,\n        -3.1161e-02, -5.6304e-02, -2.5695e-02, -5.4725e-02, -4.7194e-02,\n         5.5571e-02, -2.8979e-02,  1.1736e-02, -4.0060e-02, -3.8274e-02,\n        -7.6433e-02, -8.3510e-02,  5.8277e-02, -9.2936e-04, -5.6439e-02,\n         3.4606e-04, -8.5581e-02,  6.3023e-03,  4.2315e-03,  3.9407e-02,\n         2.5725e-02,  9.4929e-03, -2.1267e-02, -2.0158e-02,  1.6974e-02,\n         4.5165e-02,  6.7878e-03, -4.3990e-02,  6.1921e-02, -5.4556e-02,\n        -4.7467e-02,  8.0408e-02,  6.7357e-02, -3.5305e-02,  7.3396e-02,\n        -4.0416e-02, -8.2922e-02,  1.1034e-02, -7.5220e-02,  8.5369e-02,\n         1.7071e-02,  2.7779e-04,  7.7184e-02,  4.7917e-02, -3.6622e-02,\n        -1.9836e-03, -3.3907e-02, -7.4223e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 4.4213e-02,  2.3532e-02,  5.1495e-02, -6.0928e-02, -7.5104e-02,\n         -6.5460e-02, -1.1634e-03, -2.0504e-02,  6.2599e-03,  6.7254e-02,\n          3.8722e-02, -2.4754e-02, -7.9002e-02,  7.3318e-02, -7.6518e-02,\n         -3.9405e-02, -3.7548e-02, -5.6858e-02,  6.0321e-02,  7.7403e-04,\n          5.2147e-02, -2.5313e-02,  7.4539e-02,  2.1057e-03, -6.5961e-02,\n         -2.6475e-02, -7.5117e-02, -7.2708e-04, -1.8861e-05, -4.4485e-02,\n         -2.5905e-02,  2.3714e-02, -4.7336e-02,  4.3315e-03, -6.7604e-02,\n         -7.1282e-02,  5.5818e-02,  1.2351e-02, -7.4180e-02, -2.5838e-02,\n          5.4618e-02, -8.2257e-02, -4.1973e-02, -5.2011e-02,  6.6260e-03,\n         -7.6699e-02,  8.0532e-02, -2.3358e-02, -5.7351e-02, -2.9597e-02,\n         -1.3639e-03,  7.2502e-02,  1.1382e-02, -7.1292e-02, -8.7947e-02,\n         -3.3941e-02, -3.5988e-02,  2.1222e-02, -3.1463e-02, -7.1939e-02,\n          3.2767e-02, -3.2814e-02,  2.2355e-02,  6.6292e-02, -6.6322e-02,\n         -2.9937e-03, -8.7816e-03,  7.1974e-02, -8.2160e-02,  6.1837e-02,\n         -3.6703e-02,  3.5821e-02,  7.0787e-02,  2.3715e-02, -8.0051e-02,\n         -5.8955e-02, -4.7485e-03,  8.4288e-02, -4.3984e-02,  2.2855e-02,\n         -6.4828e-02,  3.8610e-02,  3.9440e-02,  1.6234e-02, -4.6599e-02,\n         -6.9215e-02,  2.9270e-02,  7.2564e-02,  7.1984e-02,  6.9419e-02,\n          7.9521e-02, -5.2892e-03, -6.7627e-02,  8.5684e-02,  1.0242e-02,\n         -6.4964e-02,  3.8886e-02, -5.7354e-02, -2.6980e-02, -7.4866e-02,\n          6.8092e-02,  2.3044e-02, -3.3936e-02, -2.3106e-02,  5.2801e-02,\n         -5.5335e-02,  2.4707e-02,  1.4272e-02,  8.1458e-02, -7.9188e-02,\n         -7.2265e-02,  3.0093e-02,  8.6013e-02,  2.5092e-02,  6.5585e-02,\n         -3.6560e-03, -7.7345e-02,  6.0198e-02, -8.4372e-02,  8.1686e-04,\n          8.6284e-02,  6.3635e-02,  1.5740e-02,  6.3455e-02,  4.3993e-02,\n         -8.1472e-02,  3.2638e-02,  8.5901e-02],\n        [ 4.5471e-02,  5.6457e-02,  4.6354e-02, -7.6290e-02, -7.4786e-02,\n         -8.5459e-03,  4.4197e-02,  4.0828e-02, -1.3889e-02, -7.0082e-02,\n          8.7065e-02, -8.5317e-02, -4.3130e-02, -6.0264e-02, -8.7521e-02,\n         -8.0359e-02, -3.7467e-02, -5.2035e-02,  1.1499e-02, -7.6087e-02,\n          8.0937e-02, -3.7837e-03, -8.0661e-02,  1.3836e-02,  4.7401e-02,\n         -3.6186e-02,  4.0220e-03,  5.3675e-02,  1.9734e-02,  4.9867e-02,\n          4.7825e-02, -6.8573e-02,  2.9425e-02, -7.4259e-02,  7.9248e-02,\n          4.2586e-02, -4.1746e-02, -2.4868e-02,  8.2329e-02,  1.9104e-02,\n         -3.9679e-02,  8.7279e-03,  6.6248e-02, -5.6676e-02,  7.3536e-02,\n         -8.3793e-02, -7.3475e-02,  8.2233e-02, -2.4794e-02, -2.7564e-02,\n          5.9141e-02, -7.2236e-02, -8.4300e-02, -2.3245e-02,  4.6953e-02,\n         -4.1764e-02, -6.4652e-02,  1.5056e-02,  8.6397e-02,  6.7903e-03,\n         -8.6973e-02,  5.6686e-02, -8.7258e-02,  5.3730e-03, -3.3384e-02,\n          6.9534e-02, -8.3843e-02, -1.1143e-02, -4.7152e-02,  4.3443e-02,\n          7.4007e-02, -6.6164e-02,  3.8779e-02,  8.2638e-02, -5.2840e-02,\n         -6.4142e-03,  3.8120e-02,  3.5380e-02,  1.9663e-02,  4.2029e-02,\n         -5.0654e-02, -6.2182e-02,  7.9633e-02, -3.9923e-02,  8.2505e-02,\n          3.1083e-02, -1.4248e-02, -1.7432e-02,  6.4734e-02, -6.9835e-02,\n         -6.2200e-02, -8.0907e-02, -8.6471e-02, -2.2808e-02,  6.4780e-02,\n          5.2546e-02, -4.8724e-02, -5.2016e-02, -7.6465e-02, -5.1873e-02,\n          5.9932e-02,  6.4162e-02,  5.0483e-02, -8.2333e-02,  6.4252e-02,\n         -3.9450e-02, -7.7112e-02, -8.1451e-02, -4.3733e-02, -2.4902e-02,\n         -8.7455e-02,  6.3640e-02,  5.4532e-02,  1.8089e-02, -4.6038e-02,\n         -4.9215e-02,  3.0815e-02,  1.6948e-02, -5.8596e-02,  3.1918e-02,\n          8.2656e-02,  4.4904e-02,  7.9842e-02,  2.4173e-02,  7.6456e-02,\n         -7.4252e-02,  5.1734e-02,  4.1609e-02],\n        [ 4.7443e-02, -3.5590e-02, -8.4338e-04,  1.6504e-02,  7.0682e-02,\n          2.6467e-02,  4.6916e-02,  7.3811e-02, -8.1340e-03, -6.9402e-02,\n         -7.7164e-03,  4.2785e-02, -5.3308e-02, -6.0883e-02, -5.5359e-02,\n          4.5587e-02,  7.3842e-02,  3.6837e-02, -2.5091e-02,  6.6791e-03,\n         -2.1762e-03,  7.9501e-02,  4.7777e-02,  7.4142e-02,  5.8323e-02,\n         -3.7306e-02, -3.1029e-02, -3.0886e-02, -2.7014e-02, -2.7085e-02,\n         -8.6724e-02, -3.3810e-02, -4.3286e-02,  3.9551e-02,  7.4034e-02,\n          4.6028e-02, -6.2733e-02,  5.2159e-02,  4.5543e-02, -1.2821e-03,\n         -4.2525e-02, -4.3043e-02,  4.5238e-02, -1.4774e-02,  1.6698e-02,\n          8.4444e-02, -2.5943e-02,  3.7408e-02,  5.6376e-02, -2.8655e-02,\n          8.0375e-02,  3.3442e-02, -7.3454e-02,  8.0039e-02, -8.3253e-02,\n          7.2059e-02,  2.1136e-02,  7.1394e-02,  1.6399e-02, -6.2270e-02,\n         -7.7435e-02, -5.7245e-02, -6.0382e-02,  1.6311e-02, -1.3736e-03,\n          3.8919e-02,  5.0812e-02,  5.2758e-04, -4.8506e-02,  2.6571e-02,\n          6.7799e-02,  8.8069e-02, -1.0302e-02,  8.2866e-02, -3.1588e-03,\n          4.7271e-03,  1.9524e-02,  7.3491e-03, -5.7301e-02, -7.6441e-02,\n          4.6975e-02,  8.4648e-02, -7.9700e-02,  1.2654e-02,  7.6822e-02,\n          6.0430e-02, -2.4546e-02,  2.6773e-02, -7.9250e-02,  5.0873e-02,\n          6.4227e-02,  7.3452e-02,  7.6116e-02, -8.2679e-02,  5.2556e-02,\n         -3.3993e-02,  4.4440e-02,  8.2211e-02,  4.8283e-02, -8.3734e-02,\n         -2.6800e-02,  8.2669e-02, -4.7400e-02,  3.2502e-02,  5.5224e-02,\n         -5.2352e-02,  1.4794e-02,  7.4929e-02,  2.5429e-02,  8.1557e-02,\n          9.6243e-03,  2.3044e-02, -2.7301e-02,  4.8918e-03,  8.8384e-02,\n          3.1051e-02, -7.8250e-02, -5.0349e-02,  4.7338e-03,  2.5892e-02,\n          2.1299e-02, -2.2819e-02, -4.0448e-02,  4.7000e-02, -7.3501e-02,\n          4.1300e-02,  2.3710e-02, -4.8076e-02],\n        [-1.6907e-02,  7.3917e-03,  4.0655e-02, -3.5602e-02, -4.8719e-02,\n          1.3452e-02, -3.9705e-02,  6.6331e-02,  1.2007e-02,  1.8305e-02,\n          5.7293e-02,  5.5207e-02, -8.7773e-02,  1.8253e-02,  3.4154e-02,\n         -4.7908e-03,  3.7748e-03,  8.2314e-02, -7.0968e-02,  2.8806e-02,\n          1.5209e-02, -8.6172e-02, -2.8604e-02,  3.1754e-03, -3.6600e-02,\n         -6.2526e-02,  4.6814e-02,  3.7273e-02,  7.2121e-02, -8.0778e-02,\n         -7.1993e-02, -3.0191e-02, -6.4393e-03,  9.1311e-04, -6.7507e-02,\n          6.1929e-02,  5.1053e-02, -2.1370e-02,  4.6707e-03, -1.7907e-02,\n         -5.5903e-02,  2.5997e-02,  5.9479e-03,  5.5007e-02,  6.5374e-02,\n          2.0279e-02, -7.8289e-02, -4.3235e-02,  8.4036e-02,  3.1804e-02,\n         -8.1015e-02,  1.6515e-02,  4.8431e-02,  4.1822e-02,  7.5502e-02,\n         -4.7830e-02, -3.1827e-02,  5.3549e-02, -8.5610e-02, -6.0629e-02,\n         -5.1415e-02,  8.2731e-04, -3.9915e-02, -1.3948e-02,  8.2212e-02,\n         -2.2365e-02, -2.6390e-02,  5.3557e-02,  1.5210e-02,  5.7565e-02,\n          6.9745e-02, -5.5071e-02, -2.2013e-03, -2.7314e-03, -1.1537e-02,\n         -3.0702e-02,  4.4762e-02, -1.9559e-02,  1.3353e-02, -6.1246e-02,\n         -3.3803e-02, -1.0049e-02,  3.5887e-02,  4.4268e-02, -6.5785e-02,\n         -8.1787e-02,  1.3651e-02, -4.2918e-02, -8.4551e-02,  5.6919e-02,\n         -3.1441e-02, -5.9146e-02, -1.7649e-02, -8.4106e-02, -8.6021e-02,\n         -2.6451e-02,  6.9557e-02,  5.7963e-02,  8.0808e-02, -6.8755e-02,\n         -1.2529e-02, -4.4546e-02, -4.8240e-02,  5.7786e-02,  2.8103e-02,\n         -8.4968e-02, -7.9388e-02, -7.5387e-02,  3.1094e-02, -1.9826e-03,\n          5.3839e-02, -8.7160e-02, -8.1732e-02, -4.4456e-02, -3.8393e-02,\n          2.9854e-02, -7.8013e-02, -6.5006e-03, -1.9965e-02, -1.7319e-02,\n         -8.5326e-02, -6.4536e-02,  3.2653e-02, -3.3679e-02, -7.7082e-02,\n          6.3334e-02, -5.1311e-02, -8.8078e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0474,  0.0443,  0.0837, -0.0396], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.EnhancedReplayBuffer object at 0x74c123453010>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "aux_buf_size":	1000,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "current_segment":	0,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "max_age":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "num_segments":	5,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "sample_decay":	0.8,
                    "segment_ptr":	0,
                    "segment_size":	10000,
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x74c121353b90>":	{
                            "capacity":	1000,
                            "data":	"[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1898, -0.1762, -0.2756, -0.1433, -0.3392, -0.2997,  0.2931,  0.1141,\n         0.1576,  0.1315, -0.2893, -0.1345,  0.0695,  0.1024, -0.1639, -0.0190,\n         0.0066, -0.2521,  0.1109,  0.0979,  0.0963, -0.2624, -0.0033, -0.0350,\n        -0.0637,  0.1352, -0.0151,  0.2778, -0.0893,  0.1623,  0.2928, -0.1537,\n         0.1506,  0.2784,  0.2961, -0.3204,  0.2190,  0.2507,  0.0419,  0.1441,\n        -0.1976,  0.1066, -0.3132, -0.0668, -0.0585, -0.1348,  0.0185, -0.1610,\n        -0.0929,  0.0552,  0.1856,  0.3135, -0.0572,  0.0423,  0.0451, -0.0225,\n        -0.1333, -0.2166, -0.2274,  0.3208,  0.2816, -0.0544, -0.1457, -0.1526,\n         0.1886, -0.1676, -0.1006, -0.1998,  0.0035, -0.2489, -0.0281,  0.2665,\n        -0.0690,  0.1979, -0.1354, -0.0185,  0.1758,  0.2106,  0.1329, -0.0281,\n        -0.1785, -0.1221, -0.3326, -0.2470,  0.1160,  0.3266,  0.2444, -0.1299,\n        -0.0468,  0.1469,  0.3495,  0.1794, -0.1104, -0.0520, -0.2222, -0.2577,\n        -0.2970,  0.2616,  0.0408, -0.2945, -0.2258, -0.1781,  0.1443,  0.0540,\n        -0.2155,  0.0980,  0.0988,  0.2985, -0.0988, -0.2504, -0.1618,  0.2862,\n        -0.1246, -0.1071,  0.0343, -0.3491,  0.3256,  0.0383, -0.1144, -0.2840,\n         0.1164, -0.2475,  0.0167, -0.2640,  0.0040, -0.2427, -0.2558, -0.0293],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2441, -0.1144, -0.2973,  ..., -0.2360, -0.3187,  0.2260],\n        [-0.3025, -0.0146,  0.1027,  ..., -0.1063,  0.2372, -0.1533],\n        [ 0.1218,  0.3444, -0.2032,  ...,  0.3120,  0.3127,  0.0752],\n        ...,\n        [-0.1815,  0.0115, -0.0781,  ..., -0.0994, -0.0329,  0.2246],\n        [ 0.3141, -0.2070, -0.0584,  ..., -0.0964,  0.0515,  0.0262],\n        [-0.1341, -0.3115, -0.2290,  ..., -0.3485, -0.0170, -0.1314]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-8.1626e-02,  4.6189e-03, -5.7454e-02, -5.8898e-02, -8.6482e-02,\n        -8.6703e-03, -4.8134e-02,  4.3289e-02, -4.9020e-02,  3.6812e-02,\n        -8.5084e-02,  7.8713e-02, -8.5649e-02, -6.3775e-02,  3.9930e-02,\n        -3.7520e-02,  4.0814e-02, -7.9666e-02, -4.4970e-02, -8.4976e-02,\n         3.3843e-02, -8.1197e-02,  3.6977e-02, -8.1920e-02, -2.7258e-02,\n         2.0597e-02, -2.4703e-02, -5.6231e-02,  2.2073e-02,  3.7791e-02,\n        -5.8747e-02, -3.8396e-02,  5.0315e-02, -2.2035e-02,  4.1238e-02,\n         5.2500e-02, -4.9572e-02,  3.6297e-02,  2.4907e-02, -2.9914e-02,\n        -5.3642e-03, -5.1459e-02,  3.6940e-02,  8.6720e-02, -4.0497e-02,\n         3.4964e-02,  3.8407e-02, -1.9832e-02, -5.2336e-05, -5.1224e-02,\n         3.2367e-02, -4.3331e-02,  8.7661e-03,  1.3746e-03,  5.2218e-02,\n         5.1938e-02,  3.0954e-02, -1.0932e-02, -3.1751e-02, -3.0222e-02,\n        -1.2379e-02,  8.1728e-02, -9.2435e-03, -3.6811e-02,  5.3266e-02,\n         7.8337e-02,  1.0274e-02, -4.3562e-02, -1.3803e-02, -7.4905e-02,\n         5.8984e-02, -8.1620e-02,  4.9671e-02,  5.1129e-02,  9.6338e-03,\n         5.3071e-02, -2.7081e-02,  5.7273e-03, -8.3127e-02,  4.7199e-02,\n        -3.1161e-02, -5.6304e-02, -2.5695e-02, -5.4725e-02, -4.7194e-02,\n         5.5571e-02, -2.8979e-02,  1.1736e-02, -4.0060e-02, -3.8274e-02,\n        -7.6433e-02, -8.3510e-02,  5.8277e-02, -9.2936e-04, -5.6439e-02,\n         3.4606e-04, -8.5581e-02,  6.3023e-03,  4.2315e-03,  3.9407e-02,\n         2.5725e-02,  9.4929e-03, -2.1267e-02, -2.0158e-02,  1.6974e-02,\n         4.5165e-02,  6.7878e-03, -4.3990e-02,  6.1921e-02, -5.4556e-02,\n        -4.7467e-02,  8.0408e-02,  6.7357e-02, -3.5305e-02,  7.3396e-02,\n        -4.0416e-02, -8.2922e-02,  1.1034e-02, -7.5220e-02,  8.5369e-02,\n         1.7071e-02,  2.7779e-04,  7.7184e-02,  4.7917e-02, -3.6622e-02,\n        -1.9836e-03, -3.3907e-02, -7.4223e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0144, -0.0368,  0.0882,  ..., -0.0587, -0.0615,  0.0725],\n        [ 0.0312,  0.0336,  0.0062,  ...,  0.0360,  0.0264, -0.0174],\n        [-0.0701,  0.0342,  0.0022,  ..., -0.0041,  0.0363,  0.0111],\n        ...,\n        [-0.0866, -0.0067,  0.0052,  ...,  0.0109, -0.0671,  0.0819],\n        [-0.0639, -0.0124,  0.0051,  ...,  0.0369, -0.0067, -0.0504],\n        [ 0.0472,  0.0876,  0.0268,  ..., -0.0471, -0.0614,  0.0142]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0474,  0.0443,  0.0837, -0.0396], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 4.4213e-02,  2.3532e-02,  5.1495e-02, -6.0928e-02, -7.5104e-02,\n         -6.5460e-02, -1.1634e-03, -2.0504e-02,  6.2599e-03,  6.7254e-02,\n          3.8722e-02, -2.4754e-02, -7.9002e-02,  7.3318e-02, -7.6518e-02,\n         -3.9405e-02, -3.7548e-02, -5.6858e-02,  6.0321e-02,  7.7403e-04,\n          5.2147e-02, -2.5313e-02,  7.4539e-02,  2.1057e-03, -6.5961e-02,\n         -2.6475e-02, -7.5117e-02, -7.2708e-04, -1.8861e-05, -4.4485e-02,\n         -2.5905e-02,  2.3714e-02, -4.7336e-02,  4.3315e-03, -6.7604e-02,\n         -7.1282e-02,  5.5818e-02,  1.2351e-02, -7.4180e-02, -2.5838e-02,\n          5.4618e-02, -8.2257e-02, -4.1973e-02, -5.2011e-02,  6.6260e-03,\n         -7.6699e-02,  8.0532e-02, -2.3358e-02, -5.7351e-02, -2.9597e-02,\n         -1.3639e-03,  7.2502e-02,  1.1382e-02, -7.1292e-02, -8.7947e-02,\n         -3.3941e-02, -3.5988e-02,  2.1222e-02, -3.1463e-02, -7.1939e-02,\n          3.2767e-02, -3.2814e-02,  2.2355e-02,  6.6292e-02, -6.6322e-02,\n         -2.9937e-03, -8.7816e-03,  7.1974e-02, -8.2160e-02,  6.1837e-02,\n         -3.6703e-02,  3.5821e-02,  7.0787e-02,  2.3715e-02, -8.0051e-02,\n         -5.8955e-02, -4.7485e-03,  8.4288e-02, -4.3984e-02,  2.2855e-02,\n         -6.4828e-02,  3.8610e-02,  3.9440e-02,  1.6234e-02, -4.6599e-02,\n         -6.9215e-02,  2.9270e-02,  7.2564e-02,  7.1984e-02,  6.9419e-02,\n          7.9521e-02, -5.2892e-03, -6.7627e-02,  8.5684e-02,  1.0242e-02,\n         -6.4964e-02,  3.8886e-02, -5.7354e-02, -2.6980e-02, -7.4866e-02,\n          6.8092e-02,  2.3044e-02, -3.3936e-02, -2.3106e-02,  5.2801e-02,\n         -5.5335e-02,  2.4707e-02,  1.4272e-02,  8.1458e-02, -7.9188e-02,\n         -7.2265e-02,  3.0093e-02,  8.6013e-02,  2.5092e-02,  6.5585e-02,\n         -3.6560e-03, -7.7345e-02,  6.0198e-02, -8.4372e-02,  8.1686e-04,\n          8.6284e-02,  6.3635e-02,  1.5740e-02,  6.3455e-02,  4.3993e-02,\n         -8.1472e-02,  3.2638e-02,  8.5901e-02],\n        [ 4.5471e-02,  5.6457e-02,  4.6354e-02, -7.6290e-02, -7.4786e-02,\n         -8.5459e-03,  4.4197e-02,  4.0828e-02, -1.3889e-02, -7.0082e-02,\n          8.7065e-02, -8.5317e-02, -4.3130e-02, -6.0264e-02, -8.7521e-02,\n         -8.0359e-02, -3.7467e-02, -5.2035e-02,  1.1499e-02, -7.6087e-02,\n          8.0937e-02, -3.7837e-03, -8.0661e-02,  1.3836e-02,  4.7401e-02,\n         -3.6186e-02,  4.0220e-03,  5.3675e-02,  1.9734e-02,  4.9867e-02,\n          4.7825e-02, -6.8573e-02,  2.9425e-02, -7.4259e-02,  7.9248e-02,\n          4.2586e-02, -4.1746e-02, -2.4868e-02,  8.2329e-02,  1.9104e-02,\n         -3.9679e-02,  8.7279e-03,  6.6248e-02, -5.6676e-02,  7.3536e-02,\n         -8.3793e-02, -7.3475e-02,  8.2233e-02, -2.4794e-02, -2.7564e-02,\n          5.9141e-02, -7.2236e-02, -8.4300e-02, -2.3245e-02,  4.6953e-02,\n         -4.1764e-02, -6.4652e-02,  1.5056e-02,  8.6397e-02,  6.7903e-03,\n         -8.6973e-02,  5.6686e-02, -8.7258e-02,  5.3730e-03, -3.3384e-02,\n          6.9534e-02, -8.3843e-02, -1.1143e-02, -4.7152e-02,  4.3443e-02,\n          7.4007e-02, -6.6164e-02,  3.8779e-02,  8.2638e-02, -5.2840e-02,\n         -6.4142e-03,  3.8120e-02,  3.5380e-02,  1.9663e-02,  4.2029e-02,\n         -5.0654e-02, -6.2182e-02,  7.9633e-02, -3.9923e-02,  8.2505e-02,\n          3.1083e-02, -1.4248e-02, -1.7432e-02,  6.4734e-02, -6.9835e-02,\n         -6.2200e-02, -8.0907e-02, -8.6471e-02, -2.2808e-02,  6.4780e-02,\n          5.2546e-02, -4.8724e-02, -5.2016e-02, -7.6465e-02, -5.1873e-02,\n          5.9932e-02,  6.4162e-02,  5.0483e-02, -8.2333e-02,  6.4252e-02,\n         -3.9450e-02, -7.7112e-02, -8.1451e-02, -4.3733e-02, -2.4902e-02,\n         -8.7455e-02,  6.3640e-02,  5.4532e-02,  1.8089e-02, -4.6038e-02,\n         -4.9215e-02,  3.0815e-02,  1.6948e-02, -5.8596e-02,  3.1918e-02,\n          8.2656e-02,  4.4904e-02,  7.9842e-02,  2.4173e-02,  7.6456e-02,\n         -7.4252e-02,  5.1734e-02,  4.1609e-02],\n        [ 4.7443e-02, -3.5590e-02, -8.4338e-04,  1.6504e-02,  7.0682e-02,\n          2.6467e-02,  4.6916e-02,  7.3811e-02, -8.1340e-03, -6.9402e-02,\n         -7.7164e-03,  4.2785e-02, -5.3308e-02, -6.0883e-02, -5.5359e-02,\n          4.5587e-02,  7.3842e-02,  3.6837e-02, -2.5091e-02,  6.6791e-03,\n         -2.1762e-03,  7.9501e-02,  4.7777e-02,  7.4142e-02,  5.8323e-02,\n         -3.7306e-02, -3.1029e-02, -3.0886e-02, -2.7014e-02, -2.7085e-02,\n         -8.6724e-02, -3.3810e-02, -4.3286e-02,  3.9551e-02,  7.4034e-02,\n          4.6028e-02, -6.2733e-02,  5.2159e-02,  4.5543e-02, -1.2821e-03,\n         -4.2525e-02, -4.3043e-02,  4.5238e-02, -1.4774e-02,  1.6698e-02,\n          8.4444e-02, -2.5943e-02,  3.7408e-02,  5.6376e-02, -2.8655e-02,\n          8.0375e-02,  3.3442e-02, -7.3454e-02,  8.0039e-02, -8.3253e-02,\n          7.2059e-02,  2.1136e-02,  7.1394e-02,  1.6399e-02, -6.2270e-02,\n         -7.7435e-02, -5.7245e-02, -6.0382e-02,  1.6311e-02, -1.3736e-03,\n          3.8919e-02,  5.0812e-02,  5.2758e-04, -4.8506e-02,  2.6571e-02,\n          6.7799e-02,  8.8069e-02, -1.0302e-02,  8.2866e-02, -3.1588e-03,\n          4.7271e-03,  1.9524e-02,  7.3491e-03, -5.7301e-02, -7.6441e-02,\n          4.6975e-02,  8.4648e-02, -7.9700e-02,  1.2654e-02,  7.6822e-02,\n          6.0430e-02, -2.4546e-02,  2.6773e-02, -7.9250e-02,  5.0873e-02,\n          6.4227e-02,  7.3452e-02,  7.6116e-02, -8.2679e-02,  5.2556e-02,\n         -3.3993e-02,  4.4440e-02,  8.2211e-02,  4.8283e-02, -8.3734e-02,\n         -2.6800e-02,  8.2669e-02, -4.7400e-02,  3.2502e-02,  5.5224e-02,\n         -5.2352e-02,  1.4794e-02,  7.4929e-02,  2.5429e-02,  8.1557e-02,\n          9.6243e-03,  2.3044e-02, -2.7301e-02,  4.8918e-03,  8.8384e-02,\n          3.1051e-02, -7.8250e-02, -5.0349e-02,  4.7338e-03,  2.5892e-02,\n          2.1299e-02, -2.2819e-02, -4.0448e-02,  4.7000e-02, -7.3501e-02,\n          4.1300e-02,  2.3710e-02, -4.8076e-02],\n        [-1.6907e-02,  7.3917e-03,  4.0655e-02, -3.5602e-02, -4.8719e-02,\n          1.3452e-02, -3.9705e-02,  6.6331e-02,  1.2007e-02,  1.8305e-02,\n          5.7293e-02,  5.5207e-02, -8.7773e-02,  1.8253e-02,  3.4154e-02,\n         -4.7908e-03,  3.7748e-03,  8.2314e-02, -7.0968e-02,  2.8806e-02,\n          1.5209e-02, -8.6172e-02, -2.8604e-02,  3.1754e-03, -3.6600e-02,\n         -6.2526e-02,  4.6814e-02,  3.7273e-02,  7.2121e-02, -8.0778e-02,\n         -7.1993e-02, -3.0191e-02, -6.4393e-03,  9.1311e-04, -6.7507e-02,\n          6.1929e-02,  5.1053e-02, -2.1370e-02,  4.6707e-03, -1.7907e-02,\n         -5.5903e-02,  2.5997e-02,  5.9479e-03,  5.5007e-02,  6.5374e-02,\n          2.0279e-02, -7.8289e-02, -4.3235e-02,  8.4036e-02,  3.1804e-02,\n         -8.1015e-02,  1.6515e-02,  4.8431e-02,  4.1822e-02,  7.5502e-02,\n         -4.7830e-02, -3.1827e-02,  5.3549e-02, -8.5610e-02, -6.0629e-02,\n         -5.1415e-02,  8.2731e-04, -3.9915e-02, -1.3948e-02,  8.2212e-02,\n         -2.2365e-02, -2.6390e-02,  5.3557e-02,  1.5210e-02,  5.7565e-02,\n          6.9745e-02, -5.5071e-02, -2.2013e-03, -2.7314e-03, -1.1537e-02,\n         -3.0702e-02,  4.4762e-02, -1.9559e-02,  1.3353e-02, -6.1246e-02,\n         -3.3803e-02, -1.0049e-02,  3.5887e-02,  4.4268e-02, -6.5785e-02,\n         -8.1787e-02,  1.3651e-02, -4.2918e-02, -8.4551e-02,  5.6919e-02,\n         -3.1441e-02, -5.9146e-02, -1.7649e-02, -8.4106e-02, -8.6021e-02,\n         -2.6451e-02,  6.9557e-02,  5.7963e-02,  8.0808e-02, -6.8755e-02,\n         -1.2529e-02, -4.4546e-02, -4.8240e-02,  5.7786e-02,  2.8103e-02,\n         -8.4968e-02, -7.9388e-02, -7.5387e-02,  3.1094e-02, -1.9826e-03,\n          5.3839e-02, -8.7160e-02, -8.1732e-02, -4.4456e-02, -3.8393e-02,\n          2.9854e-02, -7.8013e-02, -6.5006e-03, -1.9965e-02, -1.7319e-02,\n         -8.5326e-02, -6.4536e-02,  3.2653e-02, -3.3679e-02, -7.7082e-02,\n          6.3334e-02, -5.1311e-02, -8.8078e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x74c11f8e8910>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s464680000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s464680000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}