{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.15,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s467580000"
    },
    "q_lr":	0.01,
    "seed":	467580000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x72dccf294fd0>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.15,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2640,  0.3006, -0.2530,  0.2887,  0.2442, -0.2129,  0.0199, -0.0794,\n        -0.1601,  0.2087, -0.2949, -0.0121, -0.0834, -0.1825, -0.1509,  0.2743,\n        -0.2163, -0.2933, -0.0058,  0.2672, -0.0138, -0.2566, -0.1874, -0.0119,\n         0.1594, -0.1896,  0.0019,  0.1540, -0.2299, -0.3304,  0.0502,  0.0779],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1382,  0.2216,  0.1692,  0.1255,  0.2520,  0.2456, -0.1064,  0.0410],\n        [ 0.3326, -0.1342,  0.3279, -0.2467, -0.3068, -0.2028, -0.1633, -0.2826],\n        [ 0.0301, -0.1547, -0.2966,  0.1119, -0.2031, -0.1592,  0.0475,  0.2795],\n        [ 0.1747,  0.2451,  0.2464, -0.1090, -0.2213,  0.1190, -0.3236, -0.2436],\n        [-0.2394,  0.1437, -0.1099, -0.0818,  0.2195,  0.3034,  0.1916,  0.0668],\n        [ 0.0864, -0.1205,  0.0515,  0.2931,  0.3058, -0.2316,  0.2881, -0.2718],\n        [ 0.2193,  0.1574,  0.1837, -0.2393,  0.2187, -0.0959, -0.1355,  0.1190],\n        [ 0.3378,  0.1477,  0.3474, -0.0974, -0.3308,  0.0128, -0.2334,  0.3359],\n        [ 0.2519, -0.0816, -0.2976,  0.1575,  0.2400,  0.2531,  0.1981, -0.2877],\n        [-0.3269,  0.2058, -0.2848, -0.1641, -0.1270, -0.1953, -0.1592,  0.1383],\n        [-0.1488, -0.0114, -0.1218,  0.3271,  0.0269, -0.2340,  0.3382,  0.3091],\n        [ 0.1851,  0.1754, -0.1986,  0.2622,  0.0604,  0.2355, -0.2334,  0.0683],\n        [-0.0807,  0.3402, -0.0462,  0.0512,  0.2234,  0.0874, -0.2449, -0.2815],\n        [ 0.1877, -0.3062,  0.0691,  0.0198,  0.1155, -0.1701, -0.1930,  0.2968],\n        [ 0.2008,  0.0137,  0.2827, -0.1452,  0.1807,  0.2682, -0.3404, -0.0652],\n        [ 0.1710, -0.1102, -0.2157,  0.3006,  0.3297, -0.2472, -0.1206,  0.2354],\n        [-0.3231,  0.0406, -0.0754, -0.0692,  0.0909, -0.1327,  0.1559, -0.0211],\n        [ 0.0630, -0.2676,  0.2612,  0.1516, -0.2525, -0.1309, -0.2123, -0.3404],\n        [ 0.1729, -0.1117, -0.3184, -0.1175,  0.3079,  0.0588,  0.2363, -0.3245],\n        [ 0.2199,  0.0759,  0.2645, -0.0545,  0.2971,  0.0380, -0.1737,  0.2739],\n        [ 0.2974, -0.3207,  0.2757,  0.0907,  0.1463,  0.1539,  0.1777, -0.2967],\n        [-0.0598, -0.0215,  0.0824,  0.2846, -0.3396, -0.3419,  0.2100,  0.3343],\n        [-0.0266,  0.0805,  0.2382, -0.0165,  0.2803, -0.2612,  0.0836,  0.1251],\n        [-0.2691, -0.0768, -0.1320,  0.1169, -0.0784,  0.2299, -0.3165, -0.0754],\n        [ 0.2372,  0.3344,  0.1607,  0.3324, -0.1950, -0.3354, -0.1975, -0.0529],\n        [-0.1169, -0.2244, -0.3335,  0.2761, -0.2144, -0.1090, -0.2755, -0.2785],\n        [ 0.0333, -0.0683, -0.0110,  0.3413, -0.2043, -0.0582, -0.0543,  0.3146],\n        [-0.1578,  0.0069, -0.1691,  0.3440, -0.1394,  0.1340, -0.1392, -0.1510],\n        [-0.2712, -0.2616,  0.3327, -0.0070,  0.2242,  0.1774,  0.2937, -0.2027],\n        [ 0.1525,  0.0100, -0.2507,  0.3071,  0.2393,  0.0258, -0.0255,  0.0097],\n        [ 0.2248, -0.0972,  0.1686, -0.0390, -0.2853, -0.1465, -0.3183, -0.1669],\n        [ 0.2986,  0.0136,  0.2461, -0.1136, -0.2806,  0.1771, -0.2878, -0.2732]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0536,  0.1426,  0.0127, -0.0574,  0.0338,  0.1019,  0.0330,  0.1260,\n         0.1061, -0.1553, -0.0431, -0.0653,  0.1164, -0.1593,  0.0240,  0.0122],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 8.7721e-02, -1.1011e-01,  9.1588e-02,  1.0038e-01,  2.5825e-02,\n         -5.5657e-03, -6.8747e-02, -1.7348e-01, -6.1835e-02,  9.2495e-02,\n         -1.3824e-01,  1.3325e-02, -1.1086e-02,  1.3154e-01, -3.8477e-02,\n         -7.6896e-02,  1.2488e-01, -4.1726e-02, -1.4407e-01, -3.2475e-02,\n         -1.5196e-01,  1.8094e-02,  4.9240e-02,  4.6340e-02,  9.0662e-02,\n          8.8097e-02, -1.5881e-01,  1.7644e-01, -3.9609e-02,  1.1193e-01,\n          8.6953e-02,  6.2420e-02],\n        [-6.2505e-02,  1.0097e-01, -1.6988e-01, -1.2659e-01,  8.3912e-02,\n          6.3428e-02,  4.5383e-02,  7.4379e-04,  8.1415e-02,  5.2164e-02,\n         -1.2952e-01,  1.1376e-01,  9.6115e-02, -1.1058e-02,  6.1890e-02,\n         -9.1939e-02, -2.2001e-02,  9.8027e-02, -1.8058e-02,  3.5164e-02,\n         -1.6439e-01, -4.4931e-02, -2.2255e-02, -1.5897e-01,  1.2544e-01,\n          1.7044e-01,  1.1986e-01,  1.7051e-02,  4.2043e-02,  9.3376e-03,\n         -5.8250e-02, -1.3352e-01],\n        [ 1.3851e-01,  1.6881e-01,  4.2258e-02,  3.0744e-02,  3.2135e-02,\n         -4.3600e-02,  1.3607e-01,  2.5591e-02,  2.7668e-02,  1.4992e-01,\n          1.7501e-01, -2.1695e-03, -1.4760e-01, -1.9651e-02,  1.2050e-01,\n         -5.4216e-02, -3.6729e-02,  6.9386e-02,  9.4550e-02, -1.7345e-01,\n         -7.7023e-03,  2.8922e-02, -1.1847e-01,  4.9721e-02, -9.4924e-02,\n          1.1655e-01,  1.7373e-01, -1.3524e-01,  2.7544e-02, -1.2765e-01,\n         -3.4543e-02,  3.8278e-02],\n        [-1.3543e-01,  5.0538e-02,  4.1044e-02,  8.5209e-02,  7.2077e-02,\n          6.5190e-02, -5.0015e-02,  3.0021e-02, -4.3477e-02, -7.2260e-02,\n          1.2085e-01,  7.2976e-02, -1.2370e-01, -1.1427e-01,  1.1890e-01,\n         -9.1511e-02, -9.0625e-02, -1.6075e-01,  6.8627e-02,  1.4905e-01,\n          1.2219e-01,  8.1318e-02, -8.5000e-02,  1.7333e-02,  7.1028e-02,\n          3.0208e-02, -5.2421e-02, -3.1377e-02, -3.1531e-02,  3.3039e-02,\n          1.4356e-01,  1.3955e-03],\n        [ 7.8977e-02, -1.5098e-01,  1.7067e-01,  1.0351e-01, -1.7267e-01,\n         -1.6077e-01, -7.9423e-02, -1.1135e-01, -9.9733e-03,  1.0980e-01,\n          7.5065e-02,  3.9964e-02, -2.7640e-02,  4.2040e-02, -1.3096e-01,\n          1.8326e-02, -2.5998e-02,  8.0312e-02, -8.5033e-04,  8.5046e-02,\n          1.6351e-01, -5.2527e-02,  1.4881e-01,  1.7204e-01,  1.0616e-01,\n          1.7525e-01, -6.5102e-02, -7.2096e-02, -1.0699e-01,  5.5952e-02,\n         -8.2585e-02, -4.0913e-03],\n        [-1.5776e-01,  5.7765e-02, -1.2552e-01, -5.6985e-02, -1.0564e-01,\n         -5.8287e-02, -4.0382e-02,  6.0316e-03,  7.8774e-02, -1.7514e-01,\n         -1.1268e-01, -5.2782e-02, -1.7398e-01, -7.7262e-02,  1.2211e-01,\n          1.2055e-01,  8.5443e-02, -1.2954e-01, -4.7189e-03,  1.4870e-01,\n         -2.7062e-02, -1.2219e-01,  4.5882e-02,  1.2240e-01,  4.9800e-02,\n         -6.5905e-02,  1.2094e-01, -1.1468e-01, -1.2704e-01, -1.1715e-01,\n         -1.7104e-01,  1.0753e-01],\n        [-1.4847e-01, -8.8086e-02,  3.3802e-05, -1.4041e-01,  1.6159e-02,\n         -3.4389e-02, -1.6575e-02,  9.6726e-02, -1.2807e-02,  1.6229e-01,\n         -5.2292e-02,  1.1857e-01, -7.1014e-02, -1.7253e-01,  1.1992e-01,\n          7.6032e-02, -1.5683e-01, -1.1439e-01,  1.3399e-01, -1.4773e-01,\n         -1.2415e-01,  1.6623e-01,  1.3920e-01, -5.8894e-02, -9.5041e-02,\n         -1.3742e-01, -1.1021e-01,  1.2432e-02, -1.5492e-01, -9.9045e-02,\n          4.9371e-02,  1.4110e-02],\n        [-5.1818e-03, -1.4927e-01, -4.8843e-02, -1.2562e-01, -2.3931e-02,\n          5.7833e-02, -9.6698e-02, -1.5133e-01, -3.2852e-02,  6.0322e-02,\n          9.0709e-02,  6.2956e-02,  3.8126e-02, -9.4919e-02, -1.4138e-01,\n          9.3526e-02, -7.4721e-02, -3.0535e-02,  1.3541e-01, -1.2578e-01,\n          1.0444e-01, -9.8565e-02,  1.5143e-01, -1.7098e-01,  9.3907e-02,\n         -1.4040e-01,  6.5888e-02,  1.3124e-01,  1.3423e-01, -7.2974e-02,\n          1.3553e-01,  1.2277e-01],\n        [-1.2614e-01, -1.6104e-01, -7.7870e-02, -6.4626e-02,  3.7710e-02,\n         -4.9485e-02, -3.0964e-02,  5.8382e-02, -8.9117e-02,  1.6724e-01,\n         -1.0940e-01, -1.6969e-01, -1.5843e-01, -1.0212e-01, -8.4399e-02,\n         -2.2004e-03, -2.3430e-02,  1.0349e-01,  1.5545e-01,  1.0813e-01,\n          7.3509e-02, -6.3694e-02,  9.8693e-02, -1.7186e-02,  1.2164e-01,\n          5.3168e-02, -4.9542e-02,  1.1488e-01, -6.3637e-02,  5.5799e-02,\n          1.6760e-01, -1.6031e-01],\n        [ 7.6675e-02, -8.4452e-02,  9.8237e-02,  2.3722e-02, -1.1946e-01,\n          2.0392e-02,  1.3555e-01, -5.0025e-02,  5.2262e-02, -1.4326e-01,\n         -3.3068e-02, -1.3244e-01, -3.5964e-02,  8.6160e-02, -1.4657e-01,\n         -1.6597e-01,  9.6220e-02, -1.1729e-01,  6.3498e-02,  2.8609e-02,\n         -4.9173e-02,  7.3025e-02,  1.2673e-01, -7.3904e-02,  6.0287e-02,\n         -1.6182e-01, -1.4903e-01, -8.0815e-03,  1.2537e-01, -1.2494e-01,\n          1.3678e-01, -1.5987e-01],\n        [ 1.3739e-02, -1.5070e-01, -1.7796e-02, -3.9853e-02,  2.4375e-03,\n          8.1368e-02,  1.2722e-01,  1.4943e-01,  1.4795e-01,  9.5030e-02,\n         -3.6986e-02, -1.2595e-01, -2.9366e-02,  5.1119e-02,  1.2069e-01,\n         -1.1648e-01,  8.8297e-02,  9.2278e-02,  1.2368e-01,  1.4209e-01,\n          6.1416e-03, -1.3878e-01,  1.7247e-01, -1.6770e-01,  1.6728e-01,\n         -1.5197e-01, -7.3893e-02,  1.3068e-01,  1.5410e-01,  8.9449e-02,\n         -1.2935e-01,  3.1567e-03],\n        [ 4.7666e-02,  7.9043e-02, -8.1519e-02, -1.2890e-01, -9.2679e-02,\n         -2.3558e-02,  1.6988e-01,  7.7669e-02,  1.6121e-01, -7.4298e-02,\n         -7.9192e-02, -7.7001e-02,  1.6485e-01,  1.2118e-01,  9.5387e-02,\n         -9.0031e-02, -4.6739e-02,  5.8369e-02, -1.4720e-01, -2.0793e-02,\n         -1.6128e-01, -4.8523e-02, -3.4714e-02,  2.8306e-02, -6.8370e-02,\n          1.6855e-01,  1.0844e-01, -1.1657e-01,  3.3098e-03,  1.3352e-01,\n          5.4856e-02,  5.5973e-02],\n        [ 4.8716e-02,  4.5497e-02,  5.0036e-02,  3.5891e-02,  2.8270e-02,\n          8.2208e-02, -5.8777e-02,  2.6360e-02,  1.3441e-01,  1.4571e-01,\n         -4.0536e-02, -9.8950e-02,  1.5183e-01, -1.4450e-01, -1.3122e-01,\n          3.0621e-03, -1.5067e-01,  1.4621e-01, -5.0543e-02,  1.4464e-01,\n         -8.6175e-02,  9.0745e-02,  1.3374e-01, -1.4185e-01,  1.6186e-02,\n          9.3218e-02, -1.2882e-01, -6.7023e-02, -4.4959e-02, -3.2799e-03,\n          1.4410e-01,  6.7680e-02],\n        [-7.4957e-02,  5.8147e-02, -7.6510e-02, -4.0679e-02, -1.3773e-01,\n         -1.1357e-01,  1.2137e-01, -1.1651e-01, -9.2002e-02,  1.7408e-01,\n          1.6460e-01, -1.7892e-02,  1.8860e-02, -1.3296e-01, -1.5168e-01,\n          6.9095e-02,  1.2842e-01,  1.4856e-01,  1.0468e-01, -3.5760e-02,\n          1.3009e-01, -6.3010e-02, -6.4363e-02,  2.8948e-02, -1.2299e-01,\n         -6.1724e-02, -1.5896e-01,  5.3091e-02,  1.3944e-01,  1.1927e-01,\n          7.0780e-02,  1.5052e-01],\n        [-1.2411e-01, -1.4573e-01, -5.0810e-02,  1.6911e-01, -3.3037e-02,\n         -1.5395e-01, -4.1081e-02, -2.3863e-02, -4.3525e-02, -1.4342e-01,\n         -4.7296e-02, -1.1282e-01, -1.6203e-01,  1.6892e-01, -1.9533e-02,\n         -1.5532e-01, -5.7805e-03,  1.0814e-01,  1.2959e-01, -1.7221e-01,\n         -4.1394e-02, -1.7249e-01, -7.5929e-02, -1.0425e-01, -5.4489e-02,\n          1.7271e-02, -1.6744e-03, -7.2249e-02, -1.1297e-01,  6.7567e-02,\n         -1.1981e-01, -1.7057e-01],\n        [-9.1608e-02, -1.1111e-01,  1.6482e-01, -1.4610e-01,  4.0045e-02,\n         -7.5680e-03, -1.5687e-01,  1.2183e-01, -3.3893e-02, -7.1758e-02,\n          9.6154e-02, -1.6695e-01,  9.4256e-03, -1.2520e-01,  2.0950e-02,\n          1.6379e-01,  1.3806e-01,  5.0138e-02,  1.7442e-01,  1.3744e-01,\n         -1.3039e-01, -8.3129e-02, -9.1543e-02,  1.6265e-01, -1.3455e-02,\n         -8.0036e-03,  1.7185e-01,  9.8260e-02,  8.0264e-02,  1.3252e-01,\n         -8.5124e-02,  7.6627e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0671,  0.1327, -0.0086,  0.2423, -0.0795,  0.1207,  0.2093, -0.0019],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0338, -0.1455,  0.0673, -0.0622, -0.0123, -0.1471,  0.0133, -0.1527,\n         -0.1579,  0.0380, -0.0839,  0.2282,  0.1852,  0.0681, -0.1960, -0.0090],\n        [ 0.2469, -0.0945, -0.1322,  0.0116,  0.1900,  0.0213, -0.0458, -0.1847,\n          0.2239,  0.2076,  0.0992,  0.2085,  0.0086, -0.2221, -0.1338, -0.2483],\n        [-0.0069, -0.0761,  0.0416,  0.0273,  0.1867, -0.1876,  0.1561, -0.2282,\n          0.1412, -0.0325, -0.1631,  0.0818, -0.1719, -0.0888, -0.0492, -0.2299],\n        [-0.1044,  0.1881, -0.1897,  0.0978, -0.1830,  0.2017, -0.1166, -0.0865,\n         -0.2017, -0.1916,  0.2296,  0.0094, -0.0668, -0.1000, -0.2188, -0.0497],\n        [ 0.1788, -0.2460,  0.0275, -0.0119, -0.0404,  0.2395,  0.1526,  0.2216,\n         -0.1934,  0.0775,  0.0509, -0.2406,  0.1030,  0.0014,  0.2411,  0.0525],\n        [ 0.0051,  0.0365, -0.1264, -0.1720, -0.0050,  0.1332,  0.2265, -0.2027,\n          0.0957,  0.0121,  0.1302,  0.0316, -0.1915,  0.0156,  0.0631,  0.2108],\n        [-0.1747,  0.0320,  0.0307,  0.2373,  0.0524, -0.0692,  0.0516, -0.2230,\n         -0.0651, -0.0634, -0.2287, -0.0422,  0.1875, -0.1733, -0.1028, -0.1425],\n        [-0.1545,  0.1275,  0.2466, -0.1553, -0.1384,  0.0597, -0.1268,  0.1243,\n          0.1964, -0.0998, -0.0788,  0.0765, -0.0923,  0.1163,  0.2289,  0.0349]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2444,  0.0377,  0.0081,  0.2093], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0226, -0.3349, -0.1366,  0.2168,  0.3395, -0.3103,  0.1971, -0.2801],\n        [-0.1416,  0.1621, -0.2996, -0.1903, -0.2154, -0.0575, -0.2164, -0.3050],\n        [ 0.1007, -0.1198, -0.1519, -0.2849,  0.1470,  0.2201, -0.1077, -0.3197],\n        [ 0.0752, -0.1096,  0.0535,  0.1180, -0.0556, -0.1579,  0.3391, -0.3437]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.01\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.01,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.01,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1382,  0.2216,  0.1692,  0.1255,  0.2520,  0.2456, -0.1064,  0.0410],\n        [ 0.3326, -0.1342,  0.3279, -0.2467, -0.3068, -0.2028, -0.1633, -0.2826],\n        [ 0.0301, -0.1547, -0.2966,  0.1119, -0.2031, -0.1592,  0.0475,  0.2795],\n        [ 0.1747,  0.2451,  0.2464, -0.1090, -0.2213,  0.1190, -0.3236, -0.2436],\n        [-0.2394,  0.1437, -0.1099, -0.0818,  0.2195,  0.3034,  0.1916,  0.0668],\n        [ 0.0864, -0.1205,  0.0515,  0.2931,  0.3058, -0.2316,  0.2881, -0.2718],\n        [ 0.2193,  0.1574,  0.1837, -0.2393,  0.2187, -0.0959, -0.1355,  0.1190],\n        [ 0.3378,  0.1477,  0.3474, -0.0974, -0.3308,  0.0128, -0.2334,  0.3359],\n        [ 0.2519, -0.0816, -0.2976,  0.1575,  0.2400,  0.2531,  0.1981, -0.2877],\n        [-0.3269,  0.2058, -0.2848, -0.1641, -0.1270, -0.1953, -0.1592,  0.1383],\n        [-0.1488, -0.0114, -0.1218,  0.3271,  0.0269, -0.2340,  0.3382,  0.3091],\n        [ 0.1851,  0.1754, -0.1986,  0.2622,  0.0604,  0.2355, -0.2334,  0.0683],\n        [-0.0807,  0.3402, -0.0462,  0.0512,  0.2234,  0.0874, -0.2449, -0.2815],\n        [ 0.1877, -0.3062,  0.0691,  0.0198,  0.1155, -0.1701, -0.1930,  0.2968],\n        [ 0.2008,  0.0137,  0.2827, -0.1452,  0.1807,  0.2682, -0.3404, -0.0652],\n        [ 0.1710, -0.1102, -0.2157,  0.3006,  0.3297, -0.2472, -0.1206,  0.2354],\n        [-0.3231,  0.0406, -0.0754, -0.0692,  0.0909, -0.1327,  0.1559, -0.0211],\n        [ 0.0630, -0.2676,  0.2612,  0.1516, -0.2525, -0.1309, -0.2123, -0.3404],\n        [ 0.1729, -0.1117, -0.3184, -0.1175,  0.3079,  0.0588,  0.2363, -0.3245],\n        [ 0.2199,  0.0759,  0.2645, -0.0545,  0.2971,  0.0380, -0.1737,  0.2739],\n        [ 0.2974, -0.3207,  0.2757,  0.0907,  0.1463,  0.1539,  0.1777, -0.2967],\n        [-0.0598, -0.0215,  0.0824,  0.2846, -0.3396, -0.3419,  0.2100,  0.3343],\n        [-0.0266,  0.0805,  0.2382, -0.0165,  0.2803, -0.2612,  0.0836,  0.1251],\n        [-0.2691, -0.0768, -0.1320,  0.1169, -0.0784,  0.2299, -0.3165, -0.0754],\n        [ 0.2372,  0.3344,  0.1607,  0.3324, -0.1950, -0.3354, -0.1975, -0.0529],\n        [-0.1169, -0.2244, -0.3335,  0.2761, -0.2144, -0.1090, -0.2755, -0.2785],\n        [ 0.0333, -0.0683, -0.0110,  0.3413, -0.2043, -0.0582, -0.0543,  0.3146],\n        [-0.1578,  0.0069, -0.1691,  0.3440, -0.1394,  0.1340, -0.1392, -0.1510],\n        [-0.2712, -0.2616,  0.3327, -0.0070,  0.2242,  0.1774,  0.2937, -0.2027],\n        [ 0.1525,  0.0100, -0.2507,  0.3071,  0.2393,  0.0258, -0.0255,  0.0097],\n        [ 0.2248, -0.0972,  0.1686, -0.0390, -0.2853, -0.1465, -0.3183, -0.1669],\n        [ 0.2986,  0.0136,  0.2461, -0.1136, -0.2806,  0.1771, -0.2878, -0.2732]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2640,  0.3006, -0.2530,  0.2887,  0.2442, -0.2129,  0.0199, -0.0794,\n        -0.1601,  0.2087, -0.2949, -0.0121, -0.0834, -0.1825, -0.1509,  0.2743,\n        -0.2163, -0.2933, -0.0058,  0.2672, -0.0138, -0.2566, -0.1874, -0.0119,\n         0.1594, -0.1896,  0.0019,  0.1540, -0.2299, -0.3304,  0.0502,  0.0779],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 8.7721e-02, -1.1011e-01,  9.1588e-02,  1.0038e-01,  2.5825e-02,\n         -5.5657e-03, -6.8747e-02, -1.7348e-01, -6.1835e-02,  9.2495e-02,\n         -1.3824e-01,  1.3325e-02, -1.1086e-02,  1.3154e-01, -3.8477e-02,\n         -7.6896e-02,  1.2488e-01, -4.1726e-02, -1.4407e-01, -3.2475e-02,\n         -1.5196e-01,  1.8094e-02,  4.9240e-02,  4.6340e-02,  9.0662e-02,\n          8.8097e-02, -1.5881e-01,  1.7644e-01, -3.9609e-02,  1.1193e-01,\n          8.6953e-02,  6.2420e-02],\n        [-6.2505e-02,  1.0097e-01, -1.6988e-01, -1.2659e-01,  8.3912e-02,\n          6.3428e-02,  4.5383e-02,  7.4379e-04,  8.1415e-02,  5.2164e-02,\n         -1.2952e-01,  1.1376e-01,  9.6115e-02, -1.1058e-02,  6.1890e-02,\n         -9.1939e-02, -2.2001e-02,  9.8027e-02, -1.8058e-02,  3.5164e-02,\n         -1.6439e-01, -4.4931e-02, -2.2255e-02, -1.5897e-01,  1.2544e-01,\n          1.7044e-01,  1.1986e-01,  1.7051e-02,  4.2043e-02,  9.3376e-03,\n         -5.8250e-02, -1.3352e-01],\n        [ 1.3851e-01,  1.6881e-01,  4.2258e-02,  3.0744e-02,  3.2135e-02,\n         -4.3600e-02,  1.3607e-01,  2.5591e-02,  2.7668e-02,  1.4992e-01,\n          1.7501e-01, -2.1695e-03, -1.4760e-01, -1.9651e-02,  1.2050e-01,\n         -5.4216e-02, -3.6729e-02,  6.9386e-02,  9.4550e-02, -1.7345e-01,\n         -7.7023e-03,  2.8922e-02, -1.1847e-01,  4.9721e-02, -9.4924e-02,\n          1.1655e-01,  1.7373e-01, -1.3524e-01,  2.7544e-02, -1.2765e-01,\n         -3.4543e-02,  3.8278e-02],\n        [-1.3543e-01,  5.0538e-02,  4.1044e-02,  8.5209e-02,  7.2077e-02,\n          6.5190e-02, -5.0015e-02,  3.0021e-02, -4.3477e-02, -7.2260e-02,\n          1.2085e-01,  7.2976e-02, -1.2370e-01, -1.1427e-01,  1.1890e-01,\n         -9.1511e-02, -9.0625e-02, -1.6075e-01,  6.8627e-02,  1.4905e-01,\n          1.2219e-01,  8.1318e-02, -8.5000e-02,  1.7333e-02,  7.1028e-02,\n          3.0208e-02, -5.2421e-02, -3.1377e-02, -3.1531e-02,  3.3039e-02,\n          1.4356e-01,  1.3955e-03],\n        [ 7.8977e-02, -1.5098e-01,  1.7067e-01,  1.0351e-01, -1.7267e-01,\n         -1.6077e-01, -7.9423e-02, -1.1135e-01, -9.9733e-03,  1.0980e-01,\n          7.5065e-02,  3.9964e-02, -2.7640e-02,  4.2040e-02, -1.3096e-01,\n          1.8326e-02, -2.5998e-02,  8.0312e-02, -8.5033e-04,  8.5046e-02,\n          1.6351e-01, -5.2527e-02,  1.4881e-01,  1.7204e-01,  1.0616e-01,\n          1.7525e-01, -6.5102e-02, -7.2096e-02, -1.0699e-01,  5.5952e-02,\n         -8.2585e-02, -4.0913e-03],\n        [-1.5776e-01,  5.7765e-02, -1.2552e-01, -5.6985e-02, -1.0564e-01,\n         -5.8287e-02, -4.0382e-02,  6.0316e-03,  7.8774e-02, -1.7514e-01,\n         -1.1268e-01, -5.2782e-02, -1.7398e-01, -7.7262e-02,  1.2211e-01,\n          1.2055e-01,  8.5443e-02, -1.2954e-01, -4.7189e-03,  1.4870e-01,\n         -2.7062e-02, -1.2219e-01,  4.5882e-02,  1.2240e-01,  4.9800e-02,\n         -6.5905e-02,  1.2094e-01, -1.1468e-01, -1.2704e-01, -1.1715e-01,\n         -1.7104e-01,  1.0753e-01],\n        [-1.4847e-01, -8.8086e-02,  3.3802e-05, -1.4041e-01,  1.6159e-02,\n         -3.4389e-02, -1.6575e-02,  9.6726e-02, -1.2807e-02,  1.6229e-01,\n         -5.2292e-02,  1.1857e-01, -7.1014e-02, -1.7253e-01,  1.1992e-01,\n          7.6032e-02, -1.5683e-01, -1.1439e-01,  1.3399e-01, -1.4773e-01,\n         -1.2415e-01,  1.6623e-01,  1.3920e-01, -5.8894e-02, -9.5041e-02,\n         -1.3742e-01, -1.1021e-01,  1.2432e-02, -1.5492e-01, -9.9045e-02,\n          4.9371e-02,  1.4110e-02],\n        [-5.1818e-03, -1.4927e-01, -4.8843e-02, -1.2562e-01, -2.3931e-02,\n          5.7833e-02, -9.6698e-02, -1.5133e-01, -3.2852e-02,  6.0322e-02,\n          9.0709e-02,  6.2956e-02,  3.8126e-02, -9.4919e-02, -1.4138e-01,\n          9.3526e-02, -7.4721e-02, -3.0535e-02,  1.3541e-01, -1.2578e-01,\n          1.0444e-01, -9.8565e-02,  1.5143e-01, -1.7098e-01,  9.3907e-02,\n         -1.4040e-01,  6.5888e-02,  1.3124e-01,  1.3423e-01, -7.2974e-02,\n          1.3553e-01,  1.2277e-01],\n        [-1.2614e-01, -1.6104e-01, -7.7870e-02, -6.4626e-02,  3.7710e-02,\n         -4.9485e-02, -3.0964e-02,  5.8382e-02, -8.9117e-02,  1.6724e-01,\n         -1.0940e-01, -1.6969e-01, -1.5843e-01, -1.0212e-01, -8.4399e-02,\n         -2.2004e-03, -2.3430e-02,  1.0349e-01,  1.5545e-01,  1.0813e-01,\n          7.3509e-02, -6.3694e-02,  9.8693e-02, -1.7186e-02,  1.2164e-01,\n          5.3168e-02, -4.9542e-02,  1.1488e-01, -6.3637e-02,  5.5799e-02,\n          1.6760e-01, -1.6031e-01],\n        [ 7.6675e-02, -8.4452e-02,  9.8237e-02,  2.3722e-02, -1.1946e-01,\n          2.0392e-02,  1.3555e-01, -5.0025e-02,  5.2262e-02, -1.4326e-01,\n         -3.3068e-02, -1.3244e-01, -3.5964e-02,  8.6160e-02, -1.4657e-01,\n         -1.6597e-01,  9.6220e-02, -1.1729e-01,  6.3498e-02,  2.8609e-02,\n         -4.9173e-02,  7.3025e-02,  1.2673e-01, -7.3904e-02,  6.0287e-02,\n         -1.6182e-01, -1.4903e-01, -8.0815e-03,  1.2537e-01, -1.2494e-01,\n          1.3678e-01, -1.5987e-01],\n        [ 1.3739e-02, -1.5070e-01, -1.7796e-02, -3.9853e-02,  2.4375e-03,\n          8.1368e-02,  1.2722e-01,  1.4943e-01,  1.4795e-01,  9.5030e-02,\n         -3.6986e-02, -1.2595e-01, -2.9366e-02,  5.1119e-02,  1.2069e-01,\n         -1.1648e-01,  8.8297e-02,  9.2278e-02,  1.2368e-01,  1.4209e-01,\n          6.1416e-03, -1.3878e-01,  1.7247e-01, -1.6770e-01,  1.6728e-01,\n         -1.5197e-01, -7.3893e-02,  1.3068e-01,  1.5410e-01,  8.9449e-02,\n         -1.2935e-01,  3.1567e-03],\n        [ 4.7666e-02,  7.9043e-02, -8.1519e-02, -1.2890e-01, -9.2679e-02,\n         -2.3558e-02,  1.6988e-01,  7.7669e-02,  1.6121e-01, -7.4298e-02,\n         -7.9192e-02, -7.7001e-02,  1.6485e-01,  1.2118e-01,  9.5387e-02,\n         -9.0031e-02, -4.6739e-02,  5.8369e-02, -1.4720e-01, -2.0793e-02,\n         -1.6128e-01, -4.8523e-02, -3.4714e-02,  2.8306e-02, -6.8370e-02,\n          1.6855e-01,  1.0844e-01, -1.1657e-01,  3.3098e-03,  1.3352e-01,\n          5.4856e-02,  5.5973e-02],\n        [ 4.8716e-02,  4.5497e-02,  5.0036e-02,  3.5891e-02,  2.8270e-02,\n          8.2208e-02, -5.8777e-02,  2.6360e-02,  1.3441e-01,  1.4571e-01,\n         -4.0536e-02, -9.8950e-02,  1.5183e-01, -1.4450e-01, -1.3122e-01,\n          3.0621e-03, -1.5067e-01,  1.4621e-01, -5.0543e-02,  1.4464e-01,\n         -8.6175e-02,  9.0745e-02,  1.3374e-01, -1.4185e-01,  1.6186e-02,\n          9.3218e-02, -1.2882e-01, -6.7023e-02, -4.4959e-02, -3.2799e-03,\n          1.4410e-01,  6.7680e-02],\n        [-7.4957e-02,  5.8147e-02, -7.6510e-02, -4.0679e-02, -1.3773e-01,\n         -1.1357e-01,  1.2137e-01, -1.1651e-01, -9.2002e-02,  1.7408e-01,\n          1.6460e-01, -1.7892e-02,  1.8860e-02, -1.3296e-01, -1.5168e-01,\n          6.9095e-02,  1.2842e-01,  1.4856e-01,  1.0468e-01, -3.5760e-02,\n          1.3009e-01, -6.3010e-02, -6.4363e-02,  2.8948e-02, -1.2299e-01,\n         -6.1724e-02, -1.5896e-01,  5.3091e-02,  1.3944e-01,  1.1927e-01,\n          7.0780e-02,  1.5052e-01],\n        [-1.2411e-01, -1.4573e-01, -5.0810e-02,  1.6911e-01, -3.3037e-02,\n         -1.5395e-01, -4.1081e-02, -2.3863e-02, -4.3525e-02, -1.4342e-01,\n         -4.7296e-02, -1.1282e-01, -1.6203e-01,  1.6892e-01, -1.9533e-02,\n         -1.5532e-01, -5.7805e-03,  1.0814e-01,  1.2959e-01, -1.7221e-01,\n         -4.1394e-02, -1.7249e-01, -7.5929e-02, -1.0425e-01, -5.4489e-02,\n          1.7271e-02, -1.6744e-03, -7.2249e-02, -1.1297e-01,  6.7567e-02,\n         -1.1981e-01, -1.7057e-01],\n        [-9.1608e-02, -1.1111e-01,  1.6482e-01, -1.4610e-01,  4.0045e-02,\n         -7.5680e-03, -1.5687e-01,  1.2183e-01, -3.3893e-02, -7.1758e-02,\n          9.6154e-02, -1.6695e-01,  9.4256e-03, -1.2520e-01,  2.0950e-02,\n          1.6379e-01,  1.3806e-01,  5.0138e-02,  1.7442e-01,  1.3744e-01,\n         -1.3039e-01, -8.3129e-02, -9.1543e-02,  1.6265e-01, -1.3455e-02,\n         -8.0036e-03,  1.7185e-01,  9.8260e-02,  8.0264e-02,  1.3252e-01,\n         -8.5124e-02,  7.6627e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0536,  0.1426,  0.0127, -0.0574,  0.0338,  0.1019,  0.0330,  0.1260,\n         0.1061, -0.1553, -0.0431, -0.0653,  0.1164, -0.1593,  0.0240,  0.0122],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0338, -0.1455,  0.0673, -0.0622, -0.0123, -0.1471,  0.0133, -0.1527,\n         -0.1579,  0.0380, -0.0839,  0.2282,  0.1852,  0.0681, -0.1960, -0.0090],\n        [ 0.2469, -0.0945, -0.1322,  0.0116,  0.1900,  0.0213, -0.0458, -0.1847,\n          0.2239,  0.2076,  0.0992,  0.2085,  0.0086, -0.2221, -0.1338, -0.2483],\n        [-0.0069, -0.0761,  0.0416,  0.0273,  0.1867, -0.1876,  0.1561, -0.2282,\n          0.1412, -0.0325, -0.1631,  0.0818, -0.1719, -0.0888, -0.0492, -0.2299],\n        [-0.1044,  0.1881, -0.1897,  0.0978, -0.1830,  0.2017, -0.1166, -0.0865,\n         -0.2017, -0.1916,  0.2296,  0.0094, -0.0668, -0.1000, -0.2188, -0.0497],\n        [ 0.1788, -0.2460,  0.0275, -0.0119, -0.0404,  0.2395,  0.1526,  0.2216,\n         -0.1934,  0.0775,  0.0509, -0.2406,  0.1030,  0.0014,  0.2411,  0.0525],\n        [ 0.0051,  0.0365, -0.1264, -0.1720, -0.0050,  0.1332,  0.2265, -0.2027,\n          0.0957,  0.0121,  0.1302,  0.0316, -0.1915,  0.0156,  0.0631,  0.2108],\n        [-0.1747,  0.0320,  0.0307,  0.2373,  0.0524, -0.0692,  0.0516, -0.2230,\n         -0.0651, -0.0634, -0.2287, -0.0422,  0.1875, -0.1733, -0.1028, -0.1425],\n        [-0.1545,  0.1275,  0.2466, -0.1553, -0.1384,  0.0597, -0.1268,  0.1243,\n          0.1964, -0.0998, -0.0788,  0.0765, -0.0923,  0.1163,  0.2289,  0.0349]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0671,  0.1327, -0.0086,  0.2423, -0.0795,  0.1207,  0.2093, -0.0019],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0226, -0.3349, -0.1366,  0.2168,  0.3395, -0.3103,  0.1971, -0.2801],\n        [-0.1416,  0.1621, -0.2996, -0.1903, -0.2154, -0.0575, -0.2164, -0.3050],\n        [ 0.1007, -0.1198, -0.1519, -0.2849,  0.1470,  0.2201, -0.1077, -0.3197],\n        [ 0.0752, -0.1096,  0.0535,  0.1180, -0.0556, -0.1579,  0.3391, -0.3437]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2444,  0.0377,  0.0081,  0.2093], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.stale_replay_buffer.StaleReplayBuffer object at 0x72dd51b41a50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2640,  0.3006, -0.2530,  0.2887,  0.2442, -0.2129,  0.0199, -0.0794,\n        -0.1601,  0.2087, -0.2949, -0.0121, -0.0834, -0.1825, -0.1509,  0.2743,\n        -0.2163, -0.2933, -0.0058,  0.2672, -0.0138, -0.2566, -0.1874, -0.0119,\n         0.1594, -0.1896,  0.0019,  0.1540, -0.2299, -0.3304,  0.0502,  0.0779],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1382,  0.2216,  0.1692,  0.1255,  0.2520,  0.2456, -0.1064,  0.0410],\n        [ 0.3326, -0.1342,  0.3279, -0.2467, -0.3068, -0.2028, -0.1633, -0.2826],\n        [ 0.0301, -0.1547, -0.2966,  0.1119, -0.2031, -0.1592,  0.0475,  0.2795],\n        [ 0.1747,  0.2451,  0.2464, -0.1090, -0.2213,  0.1190, -0.3236, -0.2436],\n        [-0.2394,  0.1437, -0.1099, -0.0818,  0.2195,  0.3034,  0.1916,  0.0668],\n        [ 0.0864, -0.1205,  0.0515,  0.2931,  0.3058, -0.2316,  0.2881, -0.2718],\n        [ 0.2193,  0.1574,  0.1837, -0.2393,  0.2187, -0.0959, -0.1355,  0.1190],\n        [ 0.3378,  0.1477,  0.3474, -0.0974, -0.3308,  0.0128, -0.2334,  0.3359],\n        [ 0.2519, -0.0816, -0.2976,  0.1575,  0.2400,  0.2531,  0.1981, -0.2877],\n        [-0.3269,  0.2058, -0.2848, -0.1641, -0.1270, -0.1953, -0.1592,  0.1383],\n        [-0.1488, -0.0114, -0.1218,  0.3271,  0.0269, -0.2340,  0.3382,  0.3091],\n        [ 0.1851,  0.1754, -0.1986,  0.2622,  0.0604,  0.2355, -0.2334,  0.0683],\n        [-0.0807,  0.3402, -0.0462,  0.0512,  0.2234,  0.0874, -0.2449, -0.2815],\n        [ 0.1877, -0.3062,  0.0691,  0.0198,  0.1155, -0.1701, -0.1930,  0.2968],\n        [ 0.2008,  0.0137,  0.2827, -0.1452,  0.1807,  0.2682, -0.3404, -0.0652],\n        [ 0.1710, -0.1102, -0.2157,  0.3006,  0.3297, -0.2472, -0.1206,  0.2354],\n        [-0.3231,  0.0406, -0.0754, -0.0692,  0.0909, -0.1327,  0.1559, -0.0211],\n        [ 0.0630, -0.2676,  0.2612,  0.1516, -0.2525, -0.1309, -0.2123, -0.3404],\n        [ 0.1729, -0.1117, -0.3184, -0.1175,  0.3079,  0.0588,  0.2363, -0.3245],\n        [ 0.2199,  0.0759,  0.2645, -0.0545,  0.2971,  0.0380, -0.1737,  0.2739],\n        [ 0.2974, -0.3207,  0.2757,  0.0907,  0.1463,  0.1539,  0.1777, -0.2967],\n        [-0.0598, -0.0215,  0.0824,  0.2846, -0.3396, -0.3419,  0.2100,  0.3343],\n        [-0.0266,  0.0805,  0.2382, -0.0165,  0.2803, -0.2612,  0.0836,  0.1251],\n        [-0.2691, -0.0768, -0.1320,  0.1169, -0.0784,  0.2299, -0.3165, -0.0754],\n        [ 0.2372,  0.3344,  0.1607,  0.3324, -0.1950, -0.3354, -0.1975, -0.0529],\n        [-0.1169, -0.2244, -0.3335,  0.2761, -0.2144, -0.1090, -0.2755, -0.2785],\n        [ 0.0333, -0.0683, -0.0110,  0.3413, -0.2043, -0.0582, -0.0543,  0.3146],\n        [-0.1578,  0.0069, -0.1691,  0.3440, -0.1394,  0.1340, -0.1392, -0.1510],\n        [-0.2712, -0.2616,  0.3327, -0.0070,  0.2242,  0.1774,  0.2937, -0.2027],\n        [ 0.1525,  0.0100, -0.2507,  0.3071,  0.2393,  0.0258, -0.0255,  0.0097],\n        [ 0.2248, -0.0972,  0.1686, -0.0390, -0.2853, -0.1465, -0.3183, -0.1669],\n        [ 0.2986,  0.0136,  0.2461, -0.1136, -0.2806,  0.1771, -0.2878, -0.2732]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0536,  0.1426,  0.0127, -0.0574,  0.0338,  0.1019,  0.0330,  0.1260,\n         0.1061, -0.1553, -0.0431, -0.0653,  0.1164, -0.1593,  0.0240,  0.0122],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 8.7721e-02, -1.1011e-01,  9.1588e-02,  1.0038e-01,  2.5825e-02,\n         -5.5657e-03, -6.8747e-02, -1.7348e-01, -6.1835e-02,  9.2495e-02,\n         -1.3824e-01,  1.3325e-02, -1.1086e-02,  1.3154e-01, -3.8477e-02,\n         -7.6896e-02,  1.2488e-01, -4.1726e-02, -1.4407e-01, -3.2475e-02,\n         -1.5196e-01,  1.8094e-02,  4.9240e-02,  4.6340e-02,  9.0662e-02,\n          8.8097e-02, -1.5881e-01,  1.7644e-01, -3.9609e-02,  1.1193e-01,\n          8.6953e-02,  6.2420e-02],\n        [-6.2505e-02,  1.0097e-01, -1.6988e-01, -1.2659e-01,  8.3912e-02,\n          6.3428e-02,  4.5383e-02,  7.4379e-04,  8.1415e-02,  5.2164e-02,\n         -1.2952e-01,  1.1376e-01,  9.6115e-02, -1.1058e-02,  6.1890e-02,\n         -9.1939e-02, -2.2001e-02,  9.8027e-02, -1.8058e-02,  3.5164e-02,\n         -1.6439e-01, -4.4931e-02, -2.2255e-02, -1.5897e-01,  1.2544e-01,\n          1.7044e-01,  1.1986e-01,  1.7051e-02,  4.2043e-02,  9.3376e-03,\n         -5.8250e-02, -1.3352e-01],\n        [ 1.3851e-01,  1.6881e-01,  4.2258e-02,  3.0744e-02,  3.2135e-02,\n         -4.3600e-02,  1.3607e-01,  2.5591e-02,  2.7668e-02,  1.4992e-01,\n          1.7501e-01, -2.1695e-03, -1.4760e-01, -1.9651e-02,  1.2050e-01,\n         -5.4216e-02, -3.6729e-02,  6.9386e-02,  9.4550e-02, -1.7345e-01,\n         -7.7023e-03,  2.8922e-02, -1.1847e-01,  4.9721e-02, -9.4924e-02,\n          1.1655e-01,  1.7373e-01, -1.3524e-01,  2.7544e-02, -1.2765e-01,\n         -3.4543e-02,  3.8278e-02],\n        [-1.3543e-01,  5.0538e-02,  4.1044e-02,  8.5209e-02,  7.2077e-02,\n          6.5190e-02, -5.0015e-02,  3.0021e-02, -4.3477e-02, -7.2260e-02,\n          1.2085e-01,  7.2976e-02, -1.2370e-01, -1.1427e-01,  1.1890e-01,\n         -9.1511e-02, -9.0625e-02, -1.6075e-01,  6.8627e-02,  1.4905e-01,\n          1.2219e-01,  8.1318e-02, -8.5000e-02,  1.7333e-02,  7.1028e-02,\n          3.0208e-02, -5.2421e-02, -3.1377e-02, -3.1531e-02,  3.3039e-02,\n          1.4356e-01,  1.3955e-03],\n        [ 7.8977e-02, -1.5098e-01,  1.7067e-01,  1.0351e-01, -1.7267e-01,\n         -1.6077e-01, -7.9423e-02, -1.1135e-01, -9.9733e-03,  1.0980e-01,\n          7.5065e-02,  3.9964e-02, -2.7640e-02,  4.2040e-02, -1.3096e-01,\n          1.8326e-02, -2.5998e-02,  8.0312e-02, -8.5033e-04,  8.5046e-02,\n          1.6351e-01, -5.2527e-02,  1.4881e-01,  1.7204e-01,  1.0616e-01,\n          1.7525e-01, -6.5102e-02, -7.2096e-02, -1.0699e-01,  5.5952e-02,\n         -8.2585e-02, -4.0913e-03],\n        [-1.5776e-01,  5.7765e-02, -1.2552e-01, -5.6985e-02, -1.0564e-01,\n         -5.8287e-02, -4.0382e-02,  6.0316e-03,  7.8774e-02, -1.7514e-01,\n         -1.1268e-01, -5.2782e-02, -1.7398e-01, -7.7262e-02,  1.2211e-01,\n          1.2055e-01,  8.5443e-02, -1.2954e-01, -4.7189e-03,  1.4870e-01,\n         -2.7062e-02, -1.2219e-01,  4.5882e-02,  1.2240e-01,  4.9800e-02,\n         -6.5905e-02,  1.2094e-01, -1.1468e-01, -1.2704e-01, -1.1715e-01,\n         -1.7104e-01,  1.0753e-01],\n        [-1.4847e-01, -8.8086e-02,  3.3802e-05, -1.4041e-01,  1.6159e-02,\n         -3.4389e-02, -1.6575e-02,  9.6726e-02, -1.2807e-02,  1.6229e-01,\n         -5.2292e-02,  1.1857e-01, -7.1014e-02, -1.7253e-01,  1.1992e-01,\n          7.6032e-02, -1.5683e-01, -1.1439e-01,  1.3399e-01, -1.4773e-01,\n         -1.2415e-01,  1.6623e-01,  1.3920e-01, -5.8894e-02, -9.5041e-02,\n         -1.3742e-01, -1.1021e-01,  1.2432e-02, -1.5492e-01, -9.9045e-02,\n          4.9371e-02,  1.4110e-02],\n        [-5.1818e-03, -1.4927e-01, -4.8843e-02, -1.2562e-01, -2.3931e-02,\n          5.7833e-02, -9.6698e-02, -1.5133e-01, -3.2852e-02,  6.0322e-02,\n          9.0709e-02,  6.2956e-02,  3.8126e-02, -9.4919e-02, -1.4138e-01,\n          9.3526e-02, -7.4721e-02, -3.0535e-02,  1.3541e-01, -1.2578e-01,\n          1.0444e-01, -9.8565e-02,  1.5143e-01, -1.7098e-01,  9.3907e-02,\n         -1.4040e-01,  6.5888e-02,  1.3124e-01,  1.3423e-01, -7.2974e-02,\n          1.3553e-01,  1.2277e-01],\n        [-1.2614e-01, -1.6104e-01, -7.7870e-02, -6.4626e-02,  3.7710e-02,\n         -4.9485e-02, -3.0964e-02,  5.8382e-02, -8.9117e-02,  1.6724e-01,\n         -1.0940e-01, -1.6969e-01, -1.5843e-01, -1.0212e-01, -8.4399e-02,\n         -2.2004e-03, -2.3430e-02,  1.0349e-01,  1.5545e-01,  1.0813e-01,\n          7.3509e-02, -6.3694e-02,  9.8693e-02, -1.7186e-02,  1.2164e-01,\n          5.3168e-02, -4.9542e-02,  1.1488e-01, -6.3637e-02,  5.5799e-02,\n          1.6760e-01, -1.6031e-01],\n        [ 7.6675e-02, -8.4452e-02,  9.8237e-02,  2.3722e-02, -1.1946e-01,\n          2.0392e-02,  1.3555e-01, -5.0025e-02,  5.2262e-02, -1.4326e-01,\n         -3.3068e-02, -1.3244e-01, -3.5964e-02,  8.6160e-02, -1.4657e-01,\n         -1.6597e-01,  9.6220e-02, -1.1729e-01,  6.3498e-02,  2.8609e-02,\n         -4.9173e-02,  7.3025e-02,  1.2673e-01, -7.3904e-02,  6.0287e-02,\n         -1.6182e-01, -1.4903e-01, -8.0815e-03,  1.2537e-01, -1.2494e-01,\n          1.3678e-01, -1.5987e-01],\n        [ 1.3739e-02, -1.5070e-01, -1.7796e-02, -3.9853e-02,  2.4375e-03,\n          8.1368e-02,  1.2722e-01,  1.4943e-01,  1.4795e-01,  9.5030e-02,\n         -3.6986e-02, -1.2595e-01, -2.9366e-02,  5.1119e-02,  1.2069e-01,\n         -1.1648e-01,  8.8297e-02,  9.2278e-02,  1.2368e-01,  1.4209e-01,\n          6.1416e-03, -1.3878e-01,  1.7247e-01, -1.6770e-01,  1.6728e-01,\n         -1.5197e-01, -7.3893e-02,  1.3068e-01,  1.5410e-01,  8.9449e-02,\n         -1.2935e-01,  3.1567e-03],\n        [ 4.7666e-02,  7.9043e-02, -8.1519e-02, -1.2890e-01, -9.2679e-02,\n         -2.3558e-02,  1.6988e-01,  7.7669e-02,  1.6121e-01, -7.4298e-02,\n         -7.9192e-02, -7.7001e-02,  1.6485e-01,  1.2118e-01,  9.5387e-02,\n         -9.0031e-02, -4.6739e-02,  5.8369e-02, -1.4720e-01, -2.0793e-02,\n         -1.6128e-01, -4.8523e-02, -3.4714e-02,  2.8306e-02, -6.8370e-02,\n          1.6855e-01,  1.0844e-01, -1.1657e-01,  3.3098e-03,  1.3352e-01,\n          5.4856e-02,  5.5973e-02],\n        [ 4.8716e-02,  4.5497e-02,  5.0036e-02,  3.5891e-02,  2.8270e-02,\n          8.2208e-02, -5.8777e-02,  2.6360e-02,  1.3441e-01,  1.4571e-01,\n         -4.0536e-02, -9.8950e-02,  1.5183e-01, -1.4450e-01, -1.3122e-01,\n          3.0621e-03, -1.5067e-01,  1.4621e-01, -5.0543e-02,  1.4464e-01,\n         -8.6175e-02,  9.0745e-02,  1.3374e-01, -1.4185e-01,  1.6186e-02,\n          9.3218e-02, -1.2882e-01, -6.7023e-02, -4.4959e-02, -3.2799e-03,\n          1.4410e-01,  6.7680e-02],\n        [-7.4957e-02,  5.8147e-02, -7.6510e-02, -4.0679e-02, -1.3773e-01,\n         -1.1357e-01,  1.2137e-01, -1.1651e-01, -9.2002e-02,  1.7408e-01,\n          1.6460e-01, -1.7892e-02,  1.8860e-02, -1.3296e-01, -1.5168e-01,\n          6.9095e-02,  1.2842e-01,  1.4856e-01,  1.0468e-01, -3.5760e-02,\n          1.3009e-01, -6.3010e-02, -6.4363e-02,  2.8948e-02, -1.2299e-01,\n         -6.1724e-02, -1.5896e-01,  5.3091e-02,  1.3944e-01,  1.1927e-01,\n          7.0780e-02,  1.5052e-01],\n        [-1.2411e-01, -1.4573e-01, -5.0810e-02,  1.6911e-01, -3.3037e-02,\n         -1.5395e-01, -4.1081e-02, -2.3863e-02, -4.3525e-02, -1.4342e-01,\n         -4.7296e-02, -1.1282e-01, -1.6203e-01,  1.6892e-01, -1.9533e-02,\n         -1.5532e-01, -5.7805e-03,  1.0814e-01,  1.2959e-01, -1.7221e-01,\n         -4.1394e-02, -1.7249e-01, -7.5929e-02, -1.0425e-01, -5.4489e-02,\n          1.7271e-02, -1.6744e-03, -7.2249e-02, -1.1297e-01,  6.7567e-02,\n         -1.1981e-01, -1.7057e-01],\n        [-9.1608e-02, -1.1111e-01,  1.6482e-01, -1.4610e-01,  4.0045e-02,\n         -7.5680e-03, -1.5687e-01,  1.2183e-01, -3.3893e-02, -7.1758e-02,\n          9.6154e-02, -1.6695e-01,  9.4256e-03, -1.2520e-01,  2.0950e-02,\n          1.6379e-01,  1.3806e-01,  5.0138e-02,  1.7442e-01,  1.3744e-01,\n         -1.3039e-01, -8.3129e-02, -9.1543e-02,  1.6265e-01, -1.3455e-02,\n         -8.0036e-03,  1.7185e-01,  9.8260e-02,  8.0264e-02,  1.3252e-01,\n         -8.5124e-02,  7.6627e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0671,  0.1327, -0.0086,  0.2423, -0.0795,  0.1207,  0.2093, -0.0019],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0338, -0.1455,  0.0673, -0.0622, -0.0123, -0.1471,  0.0133, -0.1527,\n         -0.1579,  0.0380, -0.0839,  0.2282,  0.1852,  0.0681, -0.1960, -0.0090],\n        [ 0.2469, -0.0945, -0.1322,  0.0116,  0.1900,  0.0213, -0.0458, -0.1847,\n          0.2239,  0.2076,  0.0992,  0.2085,  0.0086, -0.2221, -0.1338, -0.2483],\n        [-0.0069, -0.0761,  0.0416,  0.0273,  0.1867, -0.1876,  0.1561, -0.2282,\n          0.1412, -0.0325, -0.1631,  0.0818, -0.1719, -0.0888, -0.0492, -0.2299],\n        [-0.1044,  0.1881, -0.1897,  0.0978, -0.1830,  0.2017, -0.1166, -0.0865,\n         -0.2017, -0.1916,  0.2296,  0.0094, -0.0668, -0.1000, -0.2188, -0.0497],\n        [ 0.1788, -0.2460,  0.0275, -0.0119, -0.0404,  0.2395,  0.1526,  0.2216,\n         -0.1934,  0.0775,  0.0509, -0.2406,  0.1030,  0.0014,  0.2411,  0.0525],\n        [ 0.0051,  0.0365, -0.1264, -0.1720, -0.0050,  0.1332,  0.2265, -0.2027,\n          0.0957,  0.0121,  0.1302,  0.0316, -0.1915,  0.0156,  0.0631,  0.2108],\n        [-0.1747,  0.0320,  0.0307,  0.2373,  0.0524, -0.0692,  0.0516, -0.2230,\n         -0.0651, -0.0634, -0.2287, -0.0422,  0.1875, -0.1733, -0.1028, -0.1425],\n        [-0.1545,  0.1275,  0.2466, -0.1553, -0.1384,  0.0597, -0.1268,  0.1243,\n          0.1964, -0.0998, -0.0788,  0.0765, -0.0923,  0.1163,  0.2289,  0.0349]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2444,  0.0377,  0.0081,  0.2093], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0226, -0.3349, -0.1366,  0.2168,  0.3395, -0.3103,  0.1971, -0.2801],\n        [-0.1416,  0.1621, -0.2996, -0.1903, -0.2154, -0.0575, -0.2164, -0.3050],\n        [ 0.1007, -0.1198, -0.1519, -0.2849,  0.1470,  0.2201, -0.1077, -0.3197],\n        [ 0.0752, -0.1096,  0.0535,  0.1180, -0.0556, -0.1579,  0.3391, -0.3437]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	6,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x72dccd417e90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s467580000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s467580000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	6,
    "traj_per_epoch":	3
}