{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s474630000"
    },
    "q_lr":	0.003,
    "seed":	474630000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x744d8cb7db50>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1894,  0.2960,  0.1894,  0.1086,  0.1246, -0.3356,  0.2730, -0.2853,\n         0.1038,  0.2543, -0.0749, -0.2101, -0.2778,  0.1677, -0.0804, -0.2162,\n        -0.0342, -0.2349, -0.2286, -0.3367, -0.0174, -0.3398, -0.0064, -0.1049,\n        -0.2126,  0.1492,  0.2255, -0.2034, -0.2007,  0.2643, -0.0129, -0.2127,\n         0.1603,  0.3236, -0.0979,  0.2633,  0.2956, -0.0650, -0.3403,  0.0301,\n         0.2245, -0.1623, -0.3502, -0.1196, -0.0887, -0.1733, -0.0925, -0.1346,\n        -0.0365,  0.3513, -0.3455,  0.1886,  0.1947,  0.0717, -0.1860,  0.1772,\n         0.1498, -0.2110,  0.0819, -0.2151, -0.1972,  0.2806, -0.0143,  0.1414,\n         0.2317,  0.1196, -0.0843, -0.0820,  0.0701, -0.3084, -0.0973, -0.3080,\n         0.1188,  0.1968, -0.2217, -0.0941, -0.1112,  0.2099,  0.3128, -0.1882,\n        -0.0343,  0.3222,  0.0770, -0.1380, -0.0870,  0.2106, -0.1830, -0.3287,\n         0.1504, -0.1463, -0.2060,  0.2779, -0.0148, -0.0476, -0.2870,  0.0723,\n        -0.1656,  0.1509,  0.1590, -0.1193], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-4.2295e-02,  4.4614e-03, -1.9950e-01,  2.5360e-01,  1.7856e-03,\n          2.0822e-01,  2.4259e-01, -2.0242e-01],\n        [ 2.2641e-03, -3.7373e-02,  7.3109e-03, -2.9554e-01,  1.0959e-01,\n          2.9222e-01, -2.6984e-01,  2.4239e-02],\n        [ 3.4014e-02, -2.8066e-01,  1.2434e-01, -5.6314e-02,  2.1171e-01,\n         -5.7256e-02,  1.0706e-01, -2.9495e-01],\n        [ 1.4012e-01,  1.9175e-01,  2.4170e-01, -1.7512e-01,  1.4816e-01,\n         -2.0104e-01,  2.9338e-01,  3.3539e-01],\n        [-3.0843e-01,  8.4528e-02,  1.2593e-01, -2.4327e-01,  3.9978e-03,\n          1.0001e-01,  7.1526e-02,  1.3239e-01],\n        [ 5.7861e-02,  2.7733e-01,  3.1562e-01,  1.7696e-01, -2.3019e-01,\n         -3.2266e-02, -1.0383e-02,  3.4071e-01],\n        [ 1.9347e-01,  2.5921e-01, -1.9070e-01, -2.0373e-02, -6.1398e-02,\n         -1.1997e-01, -3.2255e-01,  2.6771e-02],\n        [-2.1854e-01, -1.5818e-01, -1.3732e-02,  4.0433e-02, -1.4600e-01,\n          5.2825e-02, -1.4315e-01, -3.1501e-01],\n        [-2.1185e-01, -3.2458e-01,  3.9647e-02, -1.2680e-01, -2.2112e-01,\n          1.3184e-01,  1.2649e-01,  3.2238e-01],\n        [ 3.4522e-01, -3.5206e-02,  1.4031e-01, -1.6975e-01, -2.6855e-01,\n         -8.1373e-03,  1.6069e-01, -1.6893e-02],\n        [-2.4639e-01,  1.8572e-01, -6.7456e-02,  3.3107e-01, -1.0658e-02,\n          3.3545e-01, -2.0799e-01, -1.9229e-01],\n        [ 1.0431e-01, -1.0203e-01, -2.7257e-02,  1.2513e-01, -1.4409e-01,\n         -7.2642e-02,  1.5112e-01, -8.0094e-02],\n        [-3.0269e-01, -1.3106e-01, -9.7329e-02,  2.3763e-01,  2.9940e-01,\n         -1.0839e-01, -1.6047e-01, -2.6036e-01],\n        [ 3.1976e-01,  4.5305e-02, -7.0691e-02, -3.2518e-01, -3.4190e-01,\n          2.1157e-01, -2.4642e-01, -1.2356e-01],\n        [-3.0204e-01,  3.3949e-01, -2.5568e-01, -3.1385e-01, -1.3533e-01,\n         -9.8217e-02, -2.4836e-01, -1.9956e-01],\n        [-2.4592e-01,  5.3204e-02,  2.6445e-01, -1.7024e-01, -2.2226e-01,\n          1.9785e-01,  2.1817e-01,  2.1621e-01],\n        [-7.8845e-02, -3.3797e-01,  2.9161e-01,  3.1055e-01, -6.2343e-02,\n          2.5747e-01,  3.1452e-02, -5.9098e-02],\n        [-3.1103e-01,  3.2658e-01,  2.4666e-01, -2.6603e-01,  1.2404e-01,\n         -2.4570e-01, -1.3117e-01, -1.7455e-01],\n        [-3.2477e-01,  1.0089e-01,  4.7304e-02,  2.2494e-01, -4.2880e-02,\n          1.7917e-01,  2.8553e-01, -3.4957e-01],\n        [ 4.2009e-02, -3.2295e-01, -2.6181e-01,  2.7504e-01, -2.7637e-01,\n          7.1132e-03, -1.5990e-01,  3.3542e-02],\n        [-3.1822e-01,  1.1757e-01, -3.1921e-01,  1.1758e-01,  1.1218e-01,\n         -1.9276e-01,  7.0778e-02, -3.2274e-02],\n        [-2.3830e-01, -2.2996e-01, -1.4566e-01, -1.1422e-01,  2.3698e-02,\n          1.3266e-02, -2.1687e-01,  1.1232e-01],\n        [-3.0114e-01, -3.0673e-01, -3.2293e-01,  2.2819e-01, -6.7261e-03,\n          1.1634e-01,  2.7908e-02,  3.4162e-01],\n        [ 2.3846e-01, -2.7268e-01, -3.3279e-01, -1.6912e-01,  7.1875e-03,\n          2.4061e-01,  2.2070e-01,  2.5925e-01],\n        [ 2.5127e-01,  3.0083e-01, -1.2410e-01, -6.7168e-02,  1.6944e-01,\n         -6.6613e-02,  2.7608e-01,  8.1315e-03],\n        [ 2.8458e-01, -1.4937e-01,  1.2350e-01, -2.3021e-01,  9.6869e-02,\n          2.6869e-01,  1.1858e-01, -8.6139e-02],\n        [-3.4550e-01,  2.9564e-01,  5.2612e-02,  1.0495e-01, -1.9142e-01,\n          3.0119e-01,  1.2294e-01,  2.0607e-01],\n        [-2.1937e-01,  7.1460e-02,  7.2259e-02,  9.5519e-02,  1.4851e-01,\n          7.5676e-02,  3.0525e-01, -2.9788e-01],\n        [-1.2563e-01,  2.4109e-01, -3.2795e-01, -1.5902e-01,  3.7867e-02,\n         -2.9668e-01, -4.9362e-03, -2.6018e-01],\n        [-6.7071e-02, -1.2443e-01, -2.0908e-01, -1.1397e-01,  1.9931e-01,\n         -8.9482e-02, -3.4669e-01, -5.8514e-02],\n        [-1.8883e-01, -1.9800e-01, -3.2918e-01, -1.5305e-01,  3.0030e-01,\n          3.4980e-01, -4.5647e-02, -3.3699e-01],\n        [ 4.1152e-02, -2.4406e-01, -2.7546e-01, -2.2091e-01, -1.5760e-01,\n         -1.2098e-01, -2.7136e-01,  1.1546e-01],\n        [ 2.7538e-01, -1.1888e-01,  1.2166e-01, -3.0133e-01,  1.7964e-01,\n          1.8301e-01, -3.2054e-01,  5.4282e-02],\n        [-2.2997e-01,  3.1622e-01, -2.8336e-01, -2.5428e-01,  6.5542e-02,\n         -1.0329e-02,  2.4472e-01,  2.0920e-01],\n        [ 3.0269e-01,  1.7226e-02,  9.7162e-02, -2.6107e-02,  1.7553e-01,\n          1.3184e-01, -4.8919e-02,  2.2231e-02],\n        [ 1.3584e-01,  4.2921e-02,  1.1298e-01, -1.6042e-02,  4.8595e-02,\n         -5.3362e-02, -6.0886e-02,  1.9012e-01],\n        [ 1.4935e-01, -7.0707e-02, -2.2615e-01,  1.2042e-01, -3.3998e-02,\n          7.1219e-02,  3.4427e-01, -1.0894e-01],\n        [-1.3651e-01,  2.6052e-01, -1.9416e-01,  4.6801e-02,  3.2398e-01,\n          2.0275e-01,  3.2548e-01,  2.1347e-01],\n        [ 1.2768e-01,  3.0877e-01, -2.1131e-02, -2.7674e-01,  1.8862e-01,\n         -3.3571e-01, -2.4398e-01,  2.9871e-01],\n        [-2.5707e-01, -1.7491e-01,  3.2155e-01, -7.3068e-02, -1.0119e-01,\n         -2.2218e-01,  2.1952e-01, -1.1230e-01],\n        [-3.4809e-01, -2.7901e-01,  2.7135e-01,  2.6541e-01,  3.4953e-01,\n          3.5346e-01, -7.2841e-02,  1.2226e-01],\n        [ 3.4930e-01,  4.7782e-02, -5.1312e-02, -3.3762e-01, -2.2969e-01,\n         -1.8821e-01,  3.0081e-01,  2.2188e-01],\n        [-2.3418e-01,  5.8537e-02, -1.5066e-01, -2.9958e-01, -2.9079e-01,\n          4.4694e-02,  6.2575e-02, -9.2204e-02],\n        [-1.2637e-01,  2.7530e-01, -1.3921e-01, -2.0713e-01,  2.4645e-01,\n         -3.5120e-02,  2.9395e-02,  9.2243e-02],\n        [-7.8160e-03, -2.0178e-01, -1.4656e-01, -6.9772e-02,  1.4061e-01,\n          8.3592e-02,  2.1626e-01,  1.2758e-01],\n        [-1.2455e-01, -2.4679e-01,  2.5787e-01,  1.7644e-01,  3.3304e-01,\n         -2.1765e-01,  1.8301e-02,  1.7714e-01],\n        [-3.5454e-02,  2.5901e-01, -2.3434e-01,  1.9202e-01, -1.5006e-01,\n         -8.1016e-03,  1.3548e-01, -3.4485e-01],\n        [ 2.1814e-01,  2.2498e-01, -3.1603e-01, -2.4319e-01, -3.5820e-02,\n         -1.7647e-01,  1.5713e-01, -3.2499e-01],\n        [ 2.7640e-01, -1.2704e-02,  5.2217e-02, -2.4941e-01, -2.9218e-01,\n          1.8012e-01,  1.7317e-01,  8.7270e-02],\n        [-1.0496e-02, -3.2553e-01,  3.2605e-01,  2.3202e-01, -3.4736e-01,\n         -3.2465e-01, -7.6030e-02,  2.7612e-01],\n        [-2.1293e-01, -2.2717e-01, -2.5691e-01, -1.0846e-01,  1.5377e-02,\n         -3.1250e-01, -4.5999e-02, -1.0799e-01],\n        [-1.3404e-01, -2.7545e-02,  2.8940e-01, -1.4813e-01,  1.4693e-01,\n         -2.1299e-01, -1.0299e-01, -2.9543e-01],\n        [-1.8752e-01,  6.0059e-02,  1.1939e-01, -4.3669e-02, -1.4240e-01,\n          1.5457e-01,  4.6300e-02, -2.8163e-01],\n        [ 3.0044e-01,  1.9746e-01,  1.8157e-04, -5.8570e-02,  2.9566e-01,\n         -1.8291e-01, -1.6687e-01, -2.5338e-01],\n        [-4.1195e-02, -2.1097e-01,  1.0884e-01,  2.1822e-01, -2.9363e-01,\n         -1.3063e-03, -7.6220e-02, -3.4611e-01],\n        [-1.4212e-01,  2.6627e-01,  2.7656e-01, -2.2308e-01, -2.1059e-02,\n         -8.2651e-02,  2.9799e-01, -3.0864e-01],\n        [ 3.4632e-01, -1.5373e-01,  1.5345e-01,  1.8935e-01, -3.1895e-01,\n          3.0703e-01,  1.1648e-01, -2.0079e-01],\n        [ 2.1438e-02, -2.0918e-01, -3.4188e-01,  3.3707e-01,  1.7909e-02,\n          1.5211e-01, -1.4692e-02,  4.1225e-02],\n        [ 1.8054e-01,  3.5122e-02, -9.5940e-02,  2.1496e-01, -2.0693e-02,\n          1.7021e-01, -5.7654e-02, -1.5553e-01],\n        [ 2.9456e-01, -2.4195e-01, -3.3823e-01,  3.4726e-01,  2.9608e-01,\n          2.7174e-02,  1.8592e-01, -5.1965e-02],\n        [ 1.6443e-01, -2.8752e-02,  3.3870e-01,  9.6019e-02, -3.1914e-01,\n          1.4174e-01,  4.2815e-02, -1.8539e-01],\n        [-8.6423e-02,  1.9850e-01,  3.7647e-02,  1.8637e-01,  2.8634e-01,\n         -1.8839e-01, -1.5477e-01, -1.1343e-01],\n        [-5.4698e-02,  3.1598e-01, -1.4844e-01,  1.2431e-02,  9.3883e-02,\n          1.8141e-01, -1.6025e-01,  1.1736e-01],\n        [-1.0456e-02,  1.6250e-01, -4.9706e-02,  2.3227e-01,  2.4183e-01,\n         -2.1123e-01,  3.8341e-02, -1.8003e-03],\n        [ 2.0838e-01, -1.9743e-01, -4.8026e-02,  2.3435e-01,  1.4418e-02,\n          8.7292e-02,  3.3619e-01,  2.0442e-01],\n        [-1.6460e-01,  1.7596e-01,  4.8910e-02, -2.8998e-01,  3.2744e-01,\n          7.8254e-02, -2.2288e-01, -2.9241e-01],\n        [ 2.2563e-01,  9.7379e-02,  2.3992e-01,  1.4799e-01, -1.4835e-02,\n         -1.1789e-01,  3.1054e-01,  1.5573e-01],\n        [-2.1359e-01, -2.9604e-01, -1.0662e-01,  2.1665e-01,  1.1956e-01,\n          1.8915e-01,  2.2885e-01,  2.0587e-01],\n        [ 1.3124e-01,  2.1433e-01, -1.6509e-01,  1.1279e-01, -2.7241e-03,\n         -3.2958e-01, -1.3773e-01,  8.2071e-02],\n        [-1.2484e-01,  8.9124e-02, -5.3845e-02, -3.3090e-02,  1.9232e-01,\n         -7.1540e-02,  2.3910e-01, -1.4105e-01],\n        [ 1.1254e-01,  2.2222e-01,  2.9234e-01, -2.1589e-01,  1.0230e-01,\n         -8.9160e-02, -6.5891e-02,  2.6137e-01],\n        [-1.7127e-01,  2.0859e-02, -1.7046e-01, -3.5134e-01, -2.1213e-01,\n          4.4167e-02, -6.3450e-02, -3.5289e-01],\n        [ 2.3313e-01, -2.2523e-01,  1.4640e-01,  6.9301e-02, -7.1739e-03,\n         -1.9256e-01, -2.3792e-01,  2.6157e-01],\n        [ 1.7342e-02, -3.4678e-01, -1.3527e-02,  1.8453e-02,  2.1345e-01,\n         -9.1212e-02,  3.2588e-01, -2.4376e-01],\n        [-1.6068e-01,  1.6660e-01, -2.8660e-01, -2.6582e-01, -3.9716e-02,\n         -3.2782e-02, -3.3210e-01,  3.6085e-02],\n        [ 1.7087e-01, -1.3986e-01,  8.7196e-02,  2.0461e-01,  1.8899e-01,\n         -4.9990e-02,  1.4653e-02, -1.5450e-03],\n        [-1.9298e-02, -2.6321e-01,  3.7222e-02,  3.0896e-01,  1.1976e-01,\n          3.1252e-01, -1.4771e-01, -2.6018e-01],\n        [ 3.4830e-01,  2.4347e-01,  2.1947e-01, -4.6469e-03, -2.7382e-01,\n         -2.2813e-02,  3.2635e-01,  1.5576e-01],\n        [ 8.2108e-02,  2.3004e-02,  2.6955e-01,  2.7174e-01,  4.6497e-02,\n         -3.1004e-01,  7.3879e-04, -2.5814e-01],\n        [ 1.1915e-01, -1.4122e-01, -2.5209e-03, -2.2899e-01,  1.9197e-01,\n         -8.6278e-02,  1.8825e-01, -3.3650e-01],\n        [ 2.7703e-01, -1.4251e-01,  2.8729e-01, -7.5515e-02,  2.4090e-01,\n          2.5237e-01, -2.7208e-01, -6.8922e-02],\n        [ 2.3510e-02,  2.0105e-01, -5.0509e-02,  5.2763e-02, -3.1703e-01,\n          3.1777e-01,  3.0607e-01, -1.5465e-01],\n        [ 2.6427e-01,  2.4208e-01,  3.2226e-01, -2.7304e-01, -1.4882e-02,\n         -3.2955e-01, -3.2724e-01,  1.3145e-01],\n        [ 2.0030e-01, -8.2377e-02,  2.1674e-01, -2.2939e-02,  3.4809e-01,\n         -1.8716e-01, -2.9874e-01, -2.9540e-01],\n        [ 1.8280e-01, -1.3056e-01,  1.5158e-01,  2.0336e-01, -1.2701e-01,\n          2.1324e-01,  2.0819e-02, -2.1302e-02],\n        [ 2.5407e-01, -4.4440e-03,  2.3308e-01,  2.4537e-01, -2.8071e-01,\n         -1.8264e-01,  2.4262e-01,  6.0199e-02],\n        [-1.1598e-02, -4.3266e-02, -1.3435e-01,  2.8856e-01, -1.7097e-02,\n          2.0774e-01,  2.1312e-01, -1.5863e-01],\n        [ 2.7924e-01, -1.2174e-01,  2.8556e-01, -3.0749e-01, -6.6450e-02,\n         -1.5411e-01, -2.0446e-01, -1.6445e-01],\n        [-2.2075e-01, -1.9157e-01,  1.7544e-01, -6.7479e-02,  3.2305e-02,\n         -7.7617e-03, -3.4582e-01,  3.5147e-01],\n        [-2.4349e-01, -2.8812e-04, -1.2630e-01, -1.3539e-01,  4.1153e-02,\n         -1.3515e-01, -3.0006e-01,  2.4358e-01],\n        [-5.2104e-02,  5.8588e-02, -2.8909e-03, -2.0342e-01, -3.5028e-01,\n         -3.2624e-01, -1.3445e-01,  2.0591e-02],\n        [-1.3109e-01,  2.5436e-01, -2.9415e-01,  1.5074e-02, -2.6369e-01,\n         -3.3870e-01,  2.0209e-01, -1.3518e-01],\n        [-7.5994e-02,  9.2467e-02,  3.1884e-01, -1.8517e-01, -1.9982e-01,\n          1.5263e-01, -2.2746e-01, -6.4833e-02],\n        [-3.5192e-01, -1.9887e-01, -4.0592e-02,  1.6873e-01,  2.6860e-01,\n         -2.8733e-01,  3.1926e-01, -1.8708e-01],\n        [ 2.9248e-01, -3.1001e-01, -2.2715e-01, -1.1556e-01, -3.3034e-01,\n         -1.3135e-01,  2.2346e-01, -2.9173e-01],\n        [-3.0677e-01, -1.0578e-01,  3.4553e-01, -1.5521e-02,  8.1017e-02,\n          2.2647e-02, -1.1085e-01, -3.1923e-01],\n        [ 1.1474e-03, -1.7935e-01,  2.5340e-01, -1.0311e-01, -5.9874e-02,\n         -2.4104e-01,  2.1856e-01,  7.5014e-02],\n        [ 3.5096e-01,  3.3933e-01,  2.9558e-01,  2.6145e-01,  3.2493e-01,\n         -1.9172e-02,  4.9707e-02, -2.4166e-01],\n        [-1.6565e-01, -2.6584e-01,  3.5952e-03,  1.9562e-01, -2.7122e-01,\n          6.4070e-02,  2.2073e-01,  2.1301e-01],\n        [ 3.3503e-01,  2.3524e-01, -8.4006e-02, -4.9891e-02,  3.4738e-01,\n          1.8649e-01,  1.9102e-01, -2.7994e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0755,  0.0814,  0.0364, -0.0850,  0.0664,  0.0381, -0.0629,  0.0814,\n         0.0754, -0.0520,  0.0419, -0.0564, -0.0515,  0.0030, -0.0705,  0.0706,\n        -0.0690, -0.0892, -0.0935, -0.0622,  0.0698, -0.0408, -0.0358,  0.0751,\n        -0.0901,  0.0744,  0.0711,  0.0336,  0.0966,  0.0923, -0.0130,  0.0208,\n         0.0763,  0.0619, -0.0537,  0.0233, -0.0035, -0.0665, -0.0543, -0.0263,\n        -0.0727,  0.0487,  0.0354, -0.0440, -0.0058, -0.0833, -0.0009, -0.0137,\n         0.0515,  0.0588, -0.0766,  0.0584,  0.0512,  0.0640,  0.0278, -0.0914,\n        -0.0564, -0.0101, -0.0816, -0.0267, -0.0847,  0.0983,  0.0645, -0.0853,\n         0.0927,  0.0051, -0.0639,  0.0059,  0.0907,  0.0137,  0.0920, -0.0581,\n        -0.0154, -0.0691, -0.0370,  0.0911,  0.0581,  0.0311, -0.0279,  0.0046,\n         0.0348,  0.0780, -0.0422, -0.0042, -0.0384,  0.0249, -0.0508,  0.0668,\n        -0.0026, -0.0143,  0.0095, -0.0459, -0.0437,  0.0864,  0.0914, -0.0772,\n         0.0492, -0.0802,  0.0310, -0.0140], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0712, -0.0782,  0.0776,  ...,  0.0858, -0.0774, -0.0148],\n        [-0.0408,  0.0859, -0.0990,  ..., -0.0719,  0.0694,  0.0811],\n        [ 0.0048, -0.0354,  0.0244,  ...,  0.0080,  0.0356,  0.0200],\n        ...,\n        [ 0.0029,  0.0737, -0.0736,  ..., -0.0279,  0.0697, -0.0745],\n        [ 0.0628,  0.0740,  0.0437,  ..., -0.0204,  0.0667,  0.0849],\n        [ 0.0065,  0.0376, -0.0084,  ..., -0.0949,  0.0324,  0.0184]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0777, -0.0386, -0.0559, -0.0776], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0412,  0.0116, -0.0162, -0.0359,  0.0713, -0.0919,  0.0168,  0.0448,\n         -0.0158,  0.0373,  0.0604, -0.0744,  0.0296, -0.0066, -0.0616,  0.0141,\n         -0.0080,  0.0498,  0.0033,  0.0684,  0.0826,  0.0581, -0.0289, -0.0205,\n         -0.0512,  0.0091, -0.0012,  0.0772,  0.0573, -0.0972, -0.0400, -0.0733,\n         -0.0730, -0.0332, -0.0803, -0.0633,  0.0092, -0.0037,  0.0678, -0.0867,\n          0.0212,  0.0488, -0.0233, -0.0802,  0.0897,  0.0131,  0.0394, -0.0976,\n         -0.0131, -0.0186, -0.0976,  0.0459, -0.0230, -0.0152,  0.0366, -0.0535,\n          0.0240, -0.0171,  0.0331,  0.0227,  0.0009,  0.0791, -0.0689, -0.0974,\n          0.0413,  0.0972, -0.0298, -0.0738, -0.0306, -0.0396,  0.0047,  0.0273,\n          0.0141,  0.0873, -0.0256, -0.0275,  0.0967, -0.0139,  0.0029, -0.0773,\n          0.0773,  0.0863,  0.0641, -0.0534,  0.0650, -0.0610,  0.0085, -0.0874,\n         -0.0683,  0.0756, -0.0184, -0.0154,  0.0424, -0.0543,  0.0102, -0.0382,\n          0.0277, -0.0453,  0.0934,  0.0255],\n        [ 0.0876, -0.0473,  0.0953,  0.0349,  0.0080, -0.0711,  0.0849,  0.0461,\n         -0.0075, -0.0894, -0.0025,  0.0227,  0.0214, -0.0014, -0.0115,  0.0798,\n         -0.0478,  0.0005,  0.0294, -0.0598, -0.0659, -0.0012,  0.0575, -0.0653,\n          0.0381, -0.0929, -0.0516,  0.0110, -0.0515,  0.0376, -0.0139, -0.0127,\n          0.0888,  0.0118, -0.0097,  0.0192, -0.0386,  0.0430,  0.0870, -0.0955,\n         -0.0478, -0.0783,  0.0708,  0.0654, -0.0124,  0.0893,  0.0702, -0.0445,\n         -0.0691, -0.0398, -0.0766, -0.0869, -0.0613, -0.0923,  0.0755, -0.0291,\n         -0.0350,  0.0390, -0.0675,  0.0400, -0.0546, -0.0522, -0.0922, -0.0122,\n          0.0917, -0.0307,  0.0829, -0.0389,  0.0469,  0.0320, -0.0854,  0.0755,\n         -0.0312,  0.0413,  0.0598, -0.0232, -0.0037, -0.0620, -0.0239, -0.0713,\n          0.0824, -0.0485, -0.0426, -0.0582,  0.0191,  0.0348, -0.0478, -0.0623,\n         -0.0080, -0.0729,  0.0157, -0.0955,  0.0784,  0.0555,  0.0284,  0.0962,\n          0.0629,  0.0341, -0.0257,  0.0786],\n        [-0.0460,  0.0261, -0.0945,  0.0334,  0.0418,  0.0019,  0.0233,  0.0584,\n          0.0282,  0.0705,  0.0334,  0.0592, -0.0206,  0.0168, -0.0632, -0.0122,\n          0.0731, -0.0025, -0.0116,  0.0622,  0.0284, -0.0828,  0.0073,  0.0778,\n          0.0394,  0.0024,  0.0920, -0.0153,  0.0767, -0.0663,  0.0630,  0.0304,\n         -0.0087,  0.0614, -0.0940, -0.0616, -0.0229,  0.0516, -0.0487,  0.0468,\n         -0.0288, -0.0142, -0.0765, -0.0481, -0.0330,  0.0777,  0.0134, -0.0986,\n          0.0003, -0.0861, -0.0991, -0.0212,  0.0680, -0.0703, -0.0996, -0.0458,\n         -0.0173,  0.0142,  0.0143, -0.0496, -0.0488, -0.0557,  0.0874,  0.0948,\n         -0.0053, -0.0814, -0.0874,  0.0633,  0.0885,  0.0908,  0.0403, -0.0778,\n         -0.0407, -0.0354,  0.0007, -0.0061, -0.0041,  0.0066, -0.0928, -0.0884,\n         -0.0895, -0.0552, -0.0205, -0.0212,  0.0377,  0.0603,  0.0833, -0.0988,\n         -0.0036,  0.0558,  0.0319, -0.0500, -0.0701, -0.0378,  0.0439,  0.0051,\n         -0.0982,  0.0011, -0.0594,  0.0916],\n        [-0.0067,  0.0082,  0.0032, -0.0045, -0.0963, -0.0254, -0.0487,  0.0435,\n          0.0572,  0.0976, -0.0827, -0.0476, -0.0494, -0.0696, -0.0919, -0.0995,\n         -0.0846,  0.0819, -0.0954, -0.0863, -0.0540, -0.0240,  0.0193,  0.0395,\n         -0.0069, -0.0604,  0.0681, -0.0094,  0.0579,  0.0399,  0.0123, -0.0736,\n         -0.0776,  0.0771,  0.0345, -0.0857, -0.0651,  0.0371,  0.0745,  0.0195,\n          0.0280, -0.0784, -0.0130, -0.0808, -0.0560, -0.0078,  0.0909,  0.0799,\n          0.0256,  0.0684,  0.0275, -0.0470,  0.0370, -0.0307,  0.0390, -0.0636,\n          0.0963,  0.0323,  0.0635, -0.0488,  0.0173, -0.0356, -0.0042,  0.0876,\n          0.0681,  0.0072, -0.0348, -0.0012, -0.0523, -0.0433, -0.0725,  0.0259,\n          0.0622, -0.0370, -0.0953,  0.0479, -0.0943, -0.0934,  0.0259, -0.0934,\n          0.0876,  0.0266,  0.0472, -0.0406, -0.0249,  0.0305, -0.0708, -0.0537,\n          0.0827, -0.0558, -0.0247,  0.0687, -0.0148, -0.0896, -0.0865, -0.0702,\n         -0.0162, -0.0475, -0.0300, -0.0609]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-4.2295e-02,  4.4614e-03, -1.9950e-01,  2.5360e-01,  1.7856e-03,\n          2.0822e-01,  2.4259e-01, -2.0242e-01],\n        [ 2.2641e-03, -3.7373e-02,  7.3109e-03, -2.9554e-01,  1.0959e-01,\n          2.9222e-01, -2.6984e-01,  2.4239e-02],\n        [ 3.4014e-02, -2.8066e-01,  1.2434e-01, -5.6314e-02,  2.1171e-01,\n         -5.7256e-02,  1.0706e-01, -2.9495e-01],\n        [ 1.4012e-01,  1.9175e-01,  2.4170e-01, -1.7512e-01,  1.4816e-01,\n         -2.0104e-01,  2.9338e-01,  3.3539e-01],\n        [-3.0843e-01,  8.4528e-02,  1.2593e-01, -2.4327e-01,  3.9978e-03,\n          1.0001e-01,  7.1526e-02,  1.3239e-01],\n        [ 5.7861e-02,  2.7733e-01,  3.1562e-01,  1.7696e-01, -2.3019e-01,\n         -3.2266e-02, -1.0383e-02,  3.4071e-01],\n        [ 1.9347e-01,  2.5921e-01, -1.9070e-01, -2.0373e-02, -6.1398e-02,\n         -1.1997e-01, -3.2255e-01,  2.6771e-02],\n        [-2.1854e-01, -1.5818e-01, -1.3732e-02,  4.0433e-02, -1.4600e-01,\n          5.2825e-02, -1.4315e-01, -3.1501e-01],\n        [-2.1185e-01, -3.2458e-01,  3.9647e-02, -1.2680e-01, -2.2112e-01,\n          1.3184e-01,  1.2649e-01,  3.2238e-01],\n        [ 3.4522e-01, -3.5206e-02,  1.4031e-01, -1.6975e-01, -2.6855e-01,\n         -8.1373e-03,  1.6069e-01, -1.6893e-02],\n        [-2.4639e-01,  1.8572e-01, -6.7456e-02,  3.3107e-01, -1.0658e-02,\n          3.3545e-01, -2.0799e-01, -1.9229e-01],\n        [ 1.0431e-01, -1.0203e-01, -2.7257e-02,  1.2513e-01, -1.4409e-01,\n         -7.2642e-02,  1.5112e-01, -8.0094e-02],\n        [-3.0269e-01, -1.3106e-01, -9.7329e-02,  2.3763e-01,  2.9940e-01,\n         -1.0839e-01, -1.6047e-01, -2.6036e-01],\n        [ 3.1976e-01,  4.5305e-02, -7.0691e-02, -3.2518e-01, -3.4190e-01,\n          2.1157e-01, -2.4642e-01, -1.2356e-01],\n        [-3.0204e-01,  3.3949e-01, -2.5568e-01, -3.1385e-01, -1.3533e-01,\n         -9.8217e-02, -2.4836e-01, -1.9956e-01],\n        [-2.4592e-01,  5.3204e-02,  2.6445e-01, -1.7024e-01, -2.2226e-01,\n          1.9785e-01,  2.1817e-01,  2.1621e-01],\n        [-7.8845e-02, -3.3797e-01,  2.9161e-01,  3.1055e-01, -6.2343e-02,\n          2.5747e-01,  3.1452e-02, -5.9098e-02],\n        [-3.1103e-01,  3.2658e-01,  2.4666e-01, -2.6603e-01,  1.2404e-01,\n         -2.4570e-01, -1.3117e-01, -1.7455e-01],\n        [-3.2477e-01,  1.0089e-01,  4.7304e-02,  2.2494e-01, -4.2880e-02,\n          1.7917e-01,  2.8553e-01, -3.4957e-01],\n        [ 4.2009e-02, -3.2295e-01, -2.6181e-01,  2.7504e-01, -2.7637e-01,\n          7.1132e-03, -1.5990e-01,  3.3542e-02],\n        [-3.1822e-01,  1.1757e-01, -3.1921e-01,  1.1758e-01,  1.1218e-01,\n         -1.9276e-01,  7.0778e-02, -3.2274e-02],\n        [-2.3830e-01, -2.2996e-01, -1.4566e-01, -1.1422e-01,  2.3698e-02,\n          1.3266e-02, -2.1687e-01,  1.1232e-01],\n        [-3.0114e-01, -3.0673e-01, -3.2293e-01,  2.2819e-01, -6.7261e-03,\n          1.1634e-01,  2.7908e-02,  3.4162e-01],\n        [ 2.3846e-01, -2.7268e-01, -3.3279e-01, -1.6912e-01,  7.1875e-03,\n          2.4061e-01,  2.2070e-01,  2.5925e-01],\n        [ 2.5127e-01,  3.0083e-01, -1.2410e-01, -6.7168e-02,  1.6944e-01,\n         -6.6613e-02,  2.7608e-01,  8.1315e-03],\n        [ 2.8458e-01, -1.4937e-01,  1.2350e-01, -2.3021e-01,  9.6869e-02,\n          2.6869e-01,  1.1858e-01, -8.6139e-02],\n        [-3.4550e-01,  2.9564e-01,  5.2612e-02,  1.0495e-01, -1.9142e-01,\n          3.0119e-01,  1.2294e-01,  2.0607e-01],\n        [-2.1937e-01,  7.1460e-02,  7.2259e-02,  9.5519e-02,  1.4851e-01,\n          7.5676e-02,  3.0525e-01, -2.9788e-01],\n        [-1.2563e-01,  2.4109e-01, -3.2795e-01, -1.5902e-01,  3.7867e-02,\n         -2.9668e-01, -4.9362e-03, -2.6018e-01],\n        [-6.7071e-02, -1.2443e-01, -2.0908e-01, -1.1397e-01,  1.9931e-01,\n         -8.9482e-02, -3.4669e-01, -5.8514e-02],\n        [-1.8883e-01, -1.9800e-01, -3.2918e-01, -1.5305e-01,  3.0030e-01,\n          3.4980e-01, -4.5647e-02, -3.3699e-01],\n        [ 4.1152e-02, -2.4406e-01, -2.7546e-01, -2.2091e-01, -1.5760e-01,\n         -1.2098e-01, -2.7136e-01,  1.1546e-01],\n        [ 2.7538e-01, -1.1888e-01,  1.2166e-01, -3.0133e-01,  1.7964e-01,\n          1.8301e-01, -3.2054e-01,  5.4282e-02],\n        [-2.2997e-01,  3.1622e-01, -2.8336e-01, -2.5428e-01,  6.5542e-02,\n         -1.0329e-02,  2.4472e-01,  2.0920e-01],\n        [ 3.0269e-01,  1.7226e-02,  9.7162e-02, -2.6107e-02,  1.7553e-01,\n          1.3184e-01, -4.8919e-02,  2.2231e-02],\n        [ 1.3584e-01,  4.2921e-02,  1.1298e-01, -1.6042e-02,  4.8595e-02,\n         -5.3362e-02, -6.0886e-02,  1.9012e-01],\n        [ 1.4935e-01, -7.0707e-02, -2.2615e-01,  1.2042e-01, -3.3998e-02,\n          7.1219e-02,  3.4427e-01, -1.0894e-01],\n        [-1.3651e-01,  2.6052e-01, -1.9416e-01,  4.6801e-02,  3.2398e-01,\n          2.0275e-01,  3.2548e-01,  2.1347e-01],\n        [ 1.2768e-01,  3.0877e-01, -2.1131e-02, -2.7674e-01,  1.8862e-01,\n         -3.3571e-01, -2.4398e-01,  2.9871e-01],\n        [-2.5707e-01, -1.7491e-01,  3.2155e-01, -7.3068e-02, -1.0119e-01,\n         -2.2218e-01,  2.1952e-01, -1.1230e-01],\n        [-3.4809e-01, -2.7901e-01,  2.7135e-01,  2.6541e-01,  3.4953e-01,\n          3.5346e-01, -7.2841e-02,  1.2226e-01],\n        [ 3.4930e-01,  4.7782e-02, -5.1312e-02, -3.3762e-01, -2.2969e-01,\n         -1.8821e-01,  3.0081e-01,  2.2188e-01],\n        [-2.3418e-01,  5.8537e-02, -1.5066e-01, -2.9958e-01, -2.9079e-01,\n          4.4694e-02,  6.2575e-02, -9.2204e-02],\n        [-1.2637e-01,  2.7530e-01, -1.3921e-01, -2.0713e-01,  2.4645e-01,\n         -3.5120e-02,  2.9395e-02,  9.2243e-02],\n        [-7.8160e-03, -2.0178e-01, -1.4656e-01, -6.9772e-02,  1.4061e-01,\n          8.3592e-02,  2.1626e-01,  1.2758e-01],\n        [-1.2455e-01, -2.4679e-01,  2.5787e-01,  1.7644e-01,  3.3304e-01,\n         -2.1765e-01,  1.8301e-02,  1.7714e-01],\n        [-3.5454e-02,  2.5901e-01, -2.3434e-01,  1.9202e-01, -1.5006e-01,\n         -8.1016e-03,  1.3548e-01, -3.4485e-01],\n        [ 2.1814e-01,  2.2498e-01, -3.1603e-01, -2.4319e-01, -3.5820e-02,\n         -1.7647e-01,  1.5713e-01, -3.2499e-01],\n        [ 2.7640e-01, -1.2704e-02,  5.2217e-02, -2.4941e-01, -2.9218e-01,\n          1.8012e-01,  1.7317e-01,  8.7270e-02],\n        [-1.0496e-02, -3.2553e-01,  3.2605e-01,  2.3202e-01, -3.4736e-01,\n         -3.2465e-01, -7.6030e-02,  2.7612e-01],\n        [-2.1293e-01, -2.2717e-01, -2.5691e-01, -1.0846e-01,  1.5377e-02,\n         -3.1250e-01, -4.5999e-02, -1.0799e-01],\n        [-1.3404e-01, -2.7545e-02,  2.8940e-01, -1.4813e-01,  1.4693e-01,\n         -2.1299e-01, -1.0299e-01, -2.9543e-01],\n        [-1.8752e-01,  6.0059e-02,  1.1939e-01, -4.3669e-02, -1.4240e-01,\n          1.5457e-01,  4.6300e-02, -2.8163e-01],\n        [ 3.0044e-01,  1.9746e-01,  1.8157e-04, -5.8570e-02,  2.9566e-01,\n         -1.8291e-01, -1.6687e-01, -2.5338e-01],\n        [-4.1195e-02, -2.1097e-01,  1.0884e-01,  2.1822e-01, -2.9363e-01,\n         -1.3063e-03, -7.6220e-02, -3.4611e-01],\n        [-1.4212e-01,  2.6627e-01,  2.7656e-01, -2.2308e-01, -2.1059e-02,\n         -8.2651e-02,  2.9799e-01, -3.0864e-01],\n        [ 3.4632e-01, -1.5373e-01,  1.5345e-01,  1.8935e-01, -3.1895e-01,\n          3.0703e-01,  1.1648e-01, -2.0079e-01],\n        [ 2.1438e-02, -2.0918e-01, -3.4188e-01,  3.3707e-01,  1.7909e-02,\n          1.5211e-01, -1.4692e-02,  4.1225e-02],\n        [ 1.8054e-01,  3.5122e-02, -9.5940e-02,  2.1496e-01, -2.0693e-02,\n          1.7021e-01, -5.7654e-02, -1.5553e-01],\n        [ 2.9456e-01, -2.4195e-01, -3.3823e-01,  3.4726e-01,  2.9608e-01,\n          2.7174e-02,  1.8592e-01, -5.1965e-02],\n        [ 1.6443e-01, -2.8752e-02,  3.3870e-01,  9.6019e-02, -3.1914e-01,\n          1.4174e-01,  4.2815e-02, -1.8539e-01],\n        [-8.6423e-02,  1.9850e-01,  3.7647e-02,  1.8637e-01,  2.8634e-01,\n         -1.8839e-01, -1.5477e-01, -1.1343e-01],\n        [-5.4698e-02,  3.1598e-01, -1.4844e-01,  1.2431e-02,  9.3883e-02,\n          1.8141e-01, -1.6025e-01,  1.1736e-01],\n        [-1.0456e-02,  1.6250e-01, -4.9706e-02,  2.3227e-01,  2.4183e-01,\n         -2.1123e-01,  3.8341e-02, -1.8003e-03],\n        [ 2.0838e-01, -1.9743e-01, -4.8026e-02,  2.3435e-01,  1.4418e-02,\n          8.7292e-02,  3.3619e-01,  2.0442e-01],\n        [-1.6460e-01,  1.7596e-01,  4.8910e-02, -2.8998e-01,  3.2744e-01,\n          7.8254e-02, -2.2288e-01, -2.9241e-01],\n        [ 2.2563e-01,  9.7379e-02,  2.3992e-01,  1.4799e-01, -1.4835e-02,\n         -1.1789e-01,  3.1054e-01,  1.5573e-01],\n        [-2.1359e-01, -2.9604e-01, -1.0662e-01,  2.1665e-01,  1.1956e-01,\n          1.8915e-01,  2.2885e-01,  2.0587e-01],\n        [ 1.3124e-01,  2.1433e-01, -1.6509e-01,  1.1279e-01, -2.7241e-03,\n         -3.2958e-01, -1.3773e-01,  8.2071e-02],\n        [-1.2484e-01,  8.9124e-02, -5.3845e-02, -3.3090e-02,  1.9232e-01,\n         -7.1540e-02,  2.3910e-01, -1.4105e-01],\n        [ 1.1254e-01,  2.2222e-01,  2.9234e-01, -2.1589e-01,  1.0230e-01,\n         -8.9160e-02, -6.5891e-02,  2.6137e-01],\n        [-1.7127e-01,  2.0859e-02, -1.7046e-01, -3.5134e-01, -2.1213e-01,\n          4.4167e-02, -6.3450e-02, -3.5289e-01],\n        [ 2.3313e-01, -2.2523e-01,  1.4640e-01,  6.9301e-02, -7.1739e-03,\n         -1.9256e-01, -2.3792e-01,  2.6157e-01],\n        [ 1.7342e-02, -3.4678e-01, -1.3527e-02,  1.8453e-02,  2.1345e-01,\n         -9.1212e-02,  3.2588e-01, -2.4376e-01],\n        [-1.6068e-01,  1.6660e-01, -2.8660e-01, -2.6582e-01, -3.9716e-02,\n         -3.2782e-02, -3.3210e-01,  3.6085e-02],\n        [ 1.7087e-01, -1.3986e-01,  8.7196e-02,  2.0461e-01,  1.8899e-01,\n         -4.9990e-02,  1.4653e-02, -1.5450e-03],\n        [-1.9298e-02, -2.6321e-01,  3.7222e-02,  3.0896e-01,  1.1976e-01,\n          3.1252e-01, -1.4771e-01, -2.6018e-01],\n        [ 3.4830e-01,  2.4347e-01,  2.1947e-01, -4.6469e-03, -2.7382e-01,\n         -2.2813e-02,  3.2635e-01,  1.5576e-01],\n        [ 8.2108e-02,  2.3004e-02,  2.6955e-01,  2.7174e-01,  4.6497e-02,\n         -3.1004e-01,  7.3879e-04, -2.5814e-01],\n        [ 1.1915e-01, -1.4122e-01, -2.5209e-03, -2.2899e-01,  1.9197e-01,\n         -8.6278e-02,  1.8825e-01, -3.3650e-01],\n        [ 2.7703e-01, -1.4251e-01,  2.8729e-01, -7.5515e-02,  2.4090e-01,\n          2.5237e-01, -2.7208e-01, -6.8922e-02],\n        [ 2.3510e-02,  2.0105e-01, -5.0509e-02,  5.2763e-02, -3.1703e-01,\n          3.1777e-01,  3.0607e-01, -1.5465e-01],\n        [ 2.6427e-01,  2.4208e-01,  3.2226e-01, -2.7304e-01, -1.4882e-02,\n         -3.2955e-01, -3.2724e-01,  1.3145e-01],\n        [ 2.0030e-01, -8.2377e-02,  2.1674e-01, -2.2939e-02,  3.4809e-01,\n         -1.8716e-01, -2.9874e-01, -2.9540e-01],\n        [ 1.8280e-01, -1.3056e-01,  1.5158e-01,  2.0336e-01, -1.2701e-01,\n          2.1324e-01,  2.0819e-02, -2.1302e-02],\n        [ 2.5407e-01, -4.4440e-03,  2.3308e-01,  2.4537e-01, -2.8071e-01,\n         -1.8264e-01,  2.4262e-01,  6.0199e-02],\n        [-1.1598e-02, -4.3266e-02, -1.3435e-01,  2.8856e-01, -1.7097e-02,\n          2.0774e-01,  2.1312e-01, -1.5863e-01],\n        [ 2.7924e-01, -1.2174e-01,  2.8556e-01, -3.0749e-01, -6.6450e-02,\n         -1.5411e-01, -2.0446e-01, -1.6445e-01],\n        [-2.2075e-01, -1.9157e-01,  1.7544e-01, -6.7479e-02,  3.2305e-02,\n         -7.7617e-03, -3.4582e-01,  3.5147e-01],\n        [-2.4349e-01, -2.8812e-04, -1.2630e-01, -1.3539e-01,  4.1153e-02,\n         -1.3515e-01, -3.0006e-01,  2.4358e-01],\n        [-5.2104e-02,  5.8588e-02, -2.8909e-03, -2.0342e-01, -3.5028e-01,\n         -3.2624e-01, -1.3445e-01,  2.0591e-02],\n        [-1.3109e-01,  2.5436e-01, -2.9415e-01,  1.5074e-02, -2.6369e-01,\n         -3.3870e-01,  2.0209e-01, -1.3518e-01],\n        [-7.5994e-02,  9.2467e-02,  3.1884e-01, -1.8517e-01, -1.9982e-01,\n          1.5263e-01, -2.2746e-01, -6.4833e-02],\n        [-3.5192e-01, -1.9887e-01, -4.0592e-02,  1.6873e-01,  2.6860e-01,\n         -2.8733e-01,  3.1926e-01, -1.8708e-01],\n        [ 2.9248e-01, -3.1001e-01, -2.2715e-01, -1.1556e-01, -3.3034e-01,\n         -1.3135e-01,  2.2346e-01, -2.9173e-01],\n        [-3.0677e-01, -1.0578e-01,  3.4553e-01, -1.5521e-02,  8.1017e-02,\n          2.2647e-02, -1.1085e-01, -3.1923e-01],\n        [ 1.1474e-03, -1.7935e-01,  2.5340e-01, -1.0311e-01, -5.9874e-02,\n         -2.4104e-01,  2.1856e-01,  7.5014e-02],\n        [ 3.5096e-01,  3.3933e-01,  2.9558e-01,  2.6145e-01,  3.2493e-01,\n         -1.9172e-02,  4.9707e-02, -2.4166e-01],\n        [-1.6565e-01, -2.6584e-01,  3.5952e-03,  1.9562e-01, -2.7122e-01,\n          6.4070e-02,  2.2073e-01,  2.1301e-01],\n        [ 3.3503e-01,  2.3524e-01, -8.4006e-02, -4.9891e-02,  3.4738e-01,\n          1.8649e-01,  1.9102e-01, -2.7994e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1894,  0.2960,  0.1894,  0.1086,  0.1246, -0.3356,  0.2730, -0.2853,\n         0.1038,  0.2543, -0.0749, -0.2101, -0.2778,  0.1677, -0.0804, -0.2162,\n        -0.0342, -0.2349, -0.2286, -0.3367, -0.0174, -0.3398, -0.0064, -0.1049,\n        -0.2126,  0.1492,  0.2255, -0.2034, -0.2007,  0.2643, -0.0129, -0.2127,\n         0.1603,  0.3236, -0.0979,  0.2633,  0.2956, -0.0650, -0.3403,  0.0301,\n         0.2245, -0.1623, -0.3502, -0.1196, -0.0887, -0.1733, -0.0925, -0.1346,\n        -0.0365,  0.3513, -0.3455,  0.1886,  0.1947,  0.0717, -0.1860,  0.1772,\n         0.1498, -0.2110,  0.0819, -0.2151, -0.1972,  0.2806, -0.0143,  0.1414,\n         0.2317,  0.1196, -0.0843, -0.0820,  0.0701, -0.3084, -0.0973, -0.3080,\n         0.1188,  0.1968, -0.2217, -0.0941, -0.1112,  0.2099,  0.3128, -0.1882,\n        -0.0343,  0.3222,  0.0770, -0.1380, -0.0870,  0.2106, -0.1830, -0.3287,\n         0.1504, -0.1463, -0.2060,  0.2779, -0.0148, -0.0476, -0.2870,  0.0723,\n        -0.1656,  0.1509,  0.1590, -0.1193], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0712, -0.0782,  0.0776,  ...,  0.0858, -0.0774, -0.0148],\n        [-0.0408,  0.0859, -0.0990,  ..., -0.0719,  0.0694,  0.0811],\n        [ 0.0048, -0.0354,  0.0244,  ...,  0.0080,  0.0356,  0.0200],\n        ...,\n        [ 0.0029,  0.0737, -0.0736,  ..., -0.0279,  0.0697, -0.0745],\n        [ 0.0628,  0.0740,  0.0437,  ..., -0.0204,  0.0667,  0.0849],\n        [ 0.0065,  0.0376, -0.0084,  ..., -0.0949,  0.0324,  0.0184]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0755,  0.0814,  0.0364, -0.0850,  0.0664,  0.0381, -0.0629,  0.0814,\n         0.0754, -0.0520,  0.0419, -0.0564, -0.0515,  0.0030, -0.0705,  0.0706,\n        -0.0690, -0.0892, -0.0935, -0.0622,  0.0698, -0.0408, -0.0358,  0.0751,\n        -0.0901,  0.0744,  0.0711,  0.0336,  0.0966,  0.0923, -0.0130,  0.0208,\n         0.0763,  0.0619, -0.0537,  0.0233, -0.0035, -0.0665, -0.0543, -0.0263,\n        -0.0727,  0.0487,  0.0354, -0.0440, -0.0058, -0.0833, -0.0009, -0.0137,\n         0.0515,  0.0588, -0.0766,  0.0584,  0.0512,  0.0640,  0.0278, -0.0914,\n        -0.0564, -0.0101, -0.0816, -0.0267, -0.0847,  0.0983,  0.0645, -0.0853,\n         0.0927,  0.0051, -0.0639,  0.0059,  0.0907,  0.0137,  0.0920, -0.0581,\n        -0.0154, -0.0691, -0.0370,  0.0911,  0.0581,  0.0311, -0.0279,  0.0046,\n         0.0348,  0.0780, -0.0422, -0.0042, -0.0384,  0.0249, -0.0508,  0.0668,\n        -0.0026, -0.0143,  0.0095, -0.0459, -0.0437,  0.0864,  0.0914, -0.0772,\n         0.0492, -0.0802,  0.0310, -0.0140], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0412,  0.0116, -0.0162, -0.0359,  0.0713, -0.0919,  0.0168,  0.0448,\n         -0.0158,  0.0373,  0.0604, -0.0744,  0.0296, -0.0066, -0.0616,  0.0141,\n         -0.0080,  0.0498,  0.0033,  0.0684,  0.0826,  0.0581, -0.0289, -0.0205,\n         -0.0512,  0.0091, -0.0012,  0.0772,  0.0573, -0.0972, -0.0400, -0.0733,\n         -0.0730, -0.0332, -0.0803, -0.0633,  0.0092, -0.0037,  0.0678, -0.0867,\n          0.0212,  0.0488, -0.0233, -0.0802,  0.0897,  0.0131,  0.0394, -0.0976,\n         -0.0131, -0.0186, -0.0976,  0.0459, -0.0230, -0.0152,  0.0366, -0.0535,\n          0.0240, -0.0171,  0.0331,  0.0227,  0.0009,  0.0791, -0.0689, -0.0974,\n          0.0413,  0.0972, -0.0298, -0.0738, -0.0306, -0.0396,  0.0047,  0.0273,\n          0.0141,  0.0873, -0.0256, -0.0275,  0.0967, -0.0139,  0.0029, -0.0773,\n          0.0773,  0.0863,  0.0641, -0.0534,  0.0650, -0.0610,  0.0085, -0.0874,\n         -0.0683,  0.0756, -0.0184, -0.0154,  0.0424, -0.0543,  0.0102, -0.0382,\n          0.0277, -0.0453,  0.0934,  0.0255],\n        [ 0.0876, -0.0473,  0.0953,  0.0349,  0.0080, -0.0711,  0.0849,  0.0461,\n         -0.0075, -0.0894, -0.0025,  0.0227,  0.0214, -0.0014, -0.0115,  0.0798,\n         -0.0478,  0.0005,  0.0294, -0.0598, -0.0659, -0.0012,  0.0575, -0.0653,\n          0.0381, -0.0929, -0.0516,  0.0110, -0.0515,  0.0376, -0.0139, -0.0127,\n          0.0888,  0.0118, -0.0097,  0.0192, -0.0386,  0.0430,  0.0870, -0.0955,\n         -0.0478, -0.0783,  0.0708,  0.0654, -0.0124,  0.0893,  0.0702, -0.0445,\n         -0.0691, -0.0398, -0.0766, -0.0869, -0.0613, -0.0923,  0.0755, -0.0291,\n         -0.0350,  0.0390, -0.0675,  0.0400, -0.0546, -0.0522, -0.0922, -0.0122,\n          0.0917, -0.0307,  0.0829, -0.0389,  0.0469,  0.0320, -0.0854,  0.0755,\n         -0.0312,  0.0413,  0.0598, -0.0232, -0.0037, -0.0620, -0.0239, -0.0713,\n          0.0824, -0.0485, -0.0426, -0.0582,  0.0191,  0.0348, -0.0478, -0.0623,\n         -0.0080, -0.0729,  0.0157, -0.0955,  0.0784,  0.0555,  0.0284,  0.0962,\n          0.0629,  0.0341, -0.0257,  0.0786],\n        [-0.0460,  0.0261, -0.0945,  0.0334,  0.0418,  0.0019,  0.0233,  0.0584,\n          0.0282,  0.0705,  0.0334,  0.0592, -0.0206,  0.0168, -0.0632, -0.0122,\n          0.0731, -0.0025, -0.0116,  0.0622,  0.0284, -0.0828,  0.0073,  0.0778,\n          0.0394,  0.0024,  0.0920, -0.0153,  0.0767, -0.0663,  0.0630,  0.0304,\n         -0.0087,  0.0614, -0.0940, -0.0616, -0.0229,  0.0516, -0.0487,  0.0468,\n         -0.0288, -0.0142, -0.0765, -0.0481, -0.0330,  0.0777,  0.0134, -0.0986,\n          0.0003, -0.0861, -0.0991, -0.0212,  0.0680, -0.0703, -0.0996, -0.0458,\n         -0.0173,  0.0142,  0.0143, -0.0496, -0.0488, -0.0557,  0.0874,  0.0948,\n         -0.0053, -0.0814, -0.0874,  0.0633,  0.0885,  0.0908,  0.0403, -0.0778,\n         -0.0407, -0.0354,  0.0007, -0.0061, -0.0041,  0.0066, -0.0928, -0.0884,\n         -0.0895, -0.0552, -0.0205, -0.0212,  0.0377,  0.0603,  0.0833, -0.0988,\n         -0.0036,  0.0558,  0.0319, -0.0500, -0.0701, -0.0378,  0.0439,  0.0051,\n         -0.0982,  0.0011, -0.0594,  0.0916],\n        [-0.0067,  0.0082,  0.0032, -0.0045, -0.0963, -0.0254, -0.0487,  0.0435,\n          0.0572,  0.0976, -0.0827, -0.0476, -0.0494, -0.0696, -0.0919, -0.0995,\n         -0.0846,  0.0819, -0.0954, -0.0863, -0.0540, -0.0240,  0.0193,  0.0395,\n         -0.0069, -0.0604,  0.0681, -0.0094,  0.0579,  0.0399,  0.0123, -0.0736,\n         -0.0776,  0.0771,  0.0345, -0.0857, -0.0651,  0.0371,  0.0745,  0.0195,\n          0.0280, -0.0784, -0.0130, -0.0808, -0.0560, -0.0078,  0.0909,  0.0799,\n          0.0256,  0.0684,  0.0275, -0.0470,  0.0370, -0.0307,  0.0390, -0.0636,\n          0.0963,  0.0323,  0.0635, -0.0488,  0.0173, -0.0356, -0.0042,  0.0876,\n          0.0681,  0.0072, -0.0348, -0.0012, -0.0523, -0.0433, -0.0725,  0.0259,\n          0.0622, -0.0370, -0.0953,  0.0479, -0.0943, -0.0934,  0.0259, -0.0934,\n          0.0876,  0.0266,  0.0472, -0.0406, -0.0249,  0.0305, -0.0708, -0.0537,\n          0.0827, -0.0558, -0.0247,  0.0687, -0.0148, -0.0896, -0.0865, -0.0702,\n         -0.0162, -0.0475, -0.0300, -0.0609]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0777, -0.0386, -0.0559, -0.0776], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x744d8eb04b90>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1894,  0.2960,  0.1894,  0.1086,  0.1246, -0.3356,  0.2730, -0.2853,\n         0.1038,  0.2543, -0.0749, -0.2101, -0.2778,  0.1677, -0.0804, -0.2162,\n        -0.0342, -0.2349, -0.2286, -0.3367, -0.0174, -0.3398, -0.0064, -0.1049,\n        -0.2126,  0.1492,  0.2255, -0.2034, -0.2007,  0.2643, -0.0129, -0.2127,\n         0.1603,  0.3236, -0.0979,  0.2633,  0.2956, -0.0650, -0.3403,  0.0301,\n         0.2245, -0.1623, -0.3502, -0.1196, -0.0887, -0.1733, -0.0925, -0.1346,\n        -0.0365,  0.3513, -0.3455,  0.1886,  0.1947,  0.0717, -0.1860,  0.1772,\n         0.1498, -0.2110,  0.0819, -0.2151, -0.1972,  0.2806, -0.0143,  0.1414,\n         0.2317,  0.1196, -0.0843, -0.0820,  0.0701, -0.3084, -0.0973, -0.3080,\n         0.1188,  0.1968, -0.2217, -0.0941, -0.1112,  0.2099,  0.3128, -0.1882,\n        -0.0343,  0.3222,  0.0770, -0.1380, -0.0870,  0.2106, -0.1830, -0.3287,\n         0.1504, -0.1463, -0.2060,  0.2779, -0.0148, -0.0476, -0.2870,  0.0723,\n        -0.1656,  0.1509,  0.1590, -0.1193], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-4.2295e-02,  4.4614e-03, -1.9950e-01,  2.5360e-01,  1.7856e-03,\n          2.0822e-01,  2.4259e-01, -2.0242e-01],\n        [ 2.2641e-03, -3.7373e-02,  7.3109e-03, -2.9554e-01,  1.0959e-01,\n          2.9222e-01, -2.6984e-01,  2.4239e-02],\n        [ 3.4014e-02, -2.8066e-01,  1.2434e-01, -5.6314e-02,  2.1171e-01,\n         -5.7256e-02,  1.0706e-01, -2.9495e-01],\n        [ 1.4012e-01,  1.9175e-01,  2.4170e-01, -1.7512e-01,  1.4816e-01,\n         -2.0104e-01,  2.9338e-01,  3.3539e-01],\n        [-3.0843e-01,  8.4528e-02,  1.2593e-01, -2.4327e-01,  3.9978e-03,\n          1.0001e-01,  7.1526e-02,  1.3239e-01],\n        [ 5.7861e-02,  2.7733e-01,  3.1562e-01,  1.7696e-01, -2.3019e-01,\n         -3.2266e-02, -1.0383e-02,  3.4071e-01],\n        [ 1.9347e-01,  2.5921e-01, -1.9070e-01, -2.0373e-02, -6.1398e-02,\n         -1.1997e-01, -3.2255e-01,  2.6771e-02],\n        [-2.1854e-01, -1.5818e-01, -1.3732e-02,  4.0433e-02, -1.4600e-01,\n          5.2825e-02, -1.4315e-01, -3.1501e-01],\n        [-2.1185e-01, -3.2458e-01,  3.9647e-02, -1.2680e-01, -2.2112e-01,\n          1.3184e-01,  1.2649e-01,  3.2238e-01],\n        [ 3.4522e-01, -3.5206e-02,  1.4031e-01, -1.6975e-01, -2.6855e-01,\n         -8.1373e-03,  1.6069e-01, -1.6893e-02],\n        [-2.4639e-01,  1.8572e-01, -6.7456e-02,  3.3107e-01, -1.0658e-02,\n          3.3545e-01, -2.0799e-01, -1.9229e-01],\n        [ 1.0431e-01, -1.0203e-01, -2.7257e-02,  1.2513e-01, -1.4409e-01,\n         -7.2642e-02,  1.5112e-01, -8.0094e-02],\n        [-3.0269e-01, -1.3106e-01, -9.7329e-02,  2.3763e-01,  2.9940e-01,\n         -1.0839e-01, -1.6047e-01, -2.6036e-01],\n        [ 3.1976e-01,  4.5305e-02, -7.0691e-02, -3.2518e-01, -3.4190e-01,\n          2.1157e-01, -2.4642e-01, -1.2356e-01],\n        [-3.0204e-01,  3.3949e-01, -2.5568e-01, -3.1385e-01, -1.3533e-01,\n         -9.8217e-02, -2.4836e-01, -1.9956e-01],\n        [-2.4592e-01,  5.3204e-02,  2.6445e-01, -1.7024e-01, -2.2226e-01,\n          1.9785e-01,  2.1817e-01,  2.1621e-01],\n        [-7.8845e-02, -3.3797e-01,  2.9161e-01,  3.1055e-01, -6.2343e-02,\n          2.5747e-01,  3.1452e-02, -5.9098e-02],\n        [-3.1103e-01,  3.2658e-01,  2.4666e-01, -2.6603e-01,  1.2404e-01,\n         -2.4570e-01, -1.3117e-01, -1.7455e-01],\n        [-3.2477e-01,  1.0089e-01,  4.7304e-02,  2.2494e-01, -4.2880e-02,\n          1.7917e-01,  2.8553e-01, -3.4957e-01],\n        [ 4.2009e-02, -3.2295e-01, -2.6181e-01,  2.7504e-01, -2.7637e-01,\n          7.1132e-03, -1.5990e-01,  3.3542e-02],\n        [-3.1822e-01,  1.1757e-01, -3.1921e-01,  1.1758e-01,  1.1218e-01,\n         -1.9276e-01,  7.0778e-02, -3.2274e-02],\n        [-2.3830e-01, -2.2996e-01, -1.4566e-01, -1.1422e-01,  2.3698e-02,\n          1.3266e-02, -2.1687e-01,  1.1232e-01],\n        [-3.0114e-01, -3.0673e-01, -3.2293e-01,  2.2819e-01, -6.7261e-03,\n          1.1634e-01,  2.7908e-02,  3.4162e-01],\n        [ 2.3846e-01, -2.7268e-01, -3.3279e-01, -1.6912e-01,  7.1875e-03,\n          2.4061e-01,  2.2070e-01,  2.5925e-01],\n        [ 2.5127e-01,  3.0083e-01, -1.2410e-01, -6.7168e-02,  1.6944e-01,\n         -6.6613e-02,  2.7608e-01,  8.1315e-03],\n        [ 2.8458e-01, -1.4937e-01,  1.2350e-01, -2.3021e-01,  9.6869e-02,\n          2.6869e-01,  1.1858e-01, -8.6139e-02],\n        [-3.4550e-01,  2.9564e-01,  5.2612e-02,  1.0495e-01, -1.9142e-01,\n          3.0119e-01,  1.2294e-01,  2.0607e-01],\n        [-2.1937e-01,  7.1460e-02,  7.2259e-02,  9.5519e-02,  1.4851e-01,\n          7.5676e-02,  3.0525e-01, -2.9788e-01],\n        [-1.2563e-01,  2.4109e-01, -3.2795e-01, -1.5902e-01,  3.7867e-02,\n         -2.9668e-01, -4.9362e-03, -2.6018e-01],\n        [-6.7071e-02, -1.2443e-01, -2.0908e-01, -1.1397e-01,  1.9931e-01,\n         -8.9482e-02, -3.4669e-01, -5.8514e-02],\n        [-1.8883e-01, -1.9800e-01, -3.2918e-01, -1.5305e-01,  3.0030e-01,\n          3.4980e-01, -4.5647e-02, -3.3699e-01],\n        [ 4.1152e-02, -2.4406e-01, -2.7546e-01, -2.2091e-01, -1.5760e-01,\n         -1.2098e-01, -2.7136e-01,  1.1546e-01],\n        [ 2.7538e-01, -1.1888e-01,  1.2166e-01, -3.0133e-01,  1.7964e-01,\n          1.8301e-01, -3.2054e-01,  5.4282e-02],\n        [-2.2997e-01,  3.1622e-01, -2.8336e-01, -2.5428e-01,  6.5542e-02,\n         -1.0329e-02,  2.4472e-01,  2.0920e-01],\n        [ 3.0269e-01,  1.7226e-02,  9.7162e-02, -2.6107e-02,  1.7553e-01,\n          1.3184e-01, -4.8919e-02,  2.2231e-02],\n        [ 1.3584e-01,  4.2921e-02,  1.1298e-01, -1.6042e-02,  4.8595e-02,\n         -5.3362e-02, -6.0886e-02,  1.9012e-01],\n        [ 1.4935e-01, -7.0707e-02, -2.2615e-01,  1.2042e-01, -3.3998e-02,\n          7.1219e-02,  3.4427e-01, -1.0894e-01],\n        [-1.3651e-01,  2.6052e-01, -1.9416e-01,  4.6801e-02,  3.2398e-01,\n          2.0275e-01,  3.2548e-01,  2.1347e-01],\n        [ 1.2768e-01,  3.0877e-01, -2.1131e-02, -2.7674e-01,  1.8862e-01,\n         -3.3571e-01, -2.4398e-01,  2.9871e-01],\n        [-2.5707e-01, -1.7491e-01,  3.2155e-01, -7.3068e-02, -1.0119e-01,\n         -2.2218e-01,  2.1952e-01, -1.1230e-01],\n        [-3.4809e-01, -2.7901e-01,  2.7135e-01,  2.6541e-01,  3.4953e-01,\n          3.5346e-01, -7.2841e-02,  1.2226e-01],\n        [ 3.4930e-01,  4.7782e-02, -5.1312e-02, -3.3762e-01, -2.2969e-01,\n         -1.8821e-01,  3.0081e-01,  2.2188e-01],\n        [-2.3418e-01,  5.8537e-02, -1.5066e-01, -2.9958e-01, -2.9079e-01,\n          4.4694e-02,  6.2575e-02, -9.2204e-02],\n        [-1.2637e-01,  2.7530e-01, -1.3921e-01, -2.0713e-01,  2.4645e-01,\n         -3.5120e-02,  2.9395e-02,  9.2243e-02],\n        [-7.8160e-03, -2.0178e-01, -1.4656e-01, -6.9772e-02,  1.4061e-01,\n          8.3592e-02,  2.1626e-01,  1.2758e-01],\n        [-1.2455e-01, -2.4679e-01,  2.5787e-01,  1.7644e-01,  3.3304e-01,\n         -2.1765e-01,  1.8301e-02,  1.7714e-01],\n        [-3.5454e-02,  2.5901e-01, -2.3434e-01,  1.9202e-01, -1.5006e-01,\n         -8.1016e-03,  1.3548e-01, -3.4485e-01],\n        [ 2.1814e-01,  2.2498e-01, -3.1603e-01, -2.4319e-01, -3.5820e-02,\n         -1.7647e-01,  1.5713e-01, -3.2499e-01],\n        [ 2.7640e-01, -1.2704e-02,  5.2217e-02, -2.4941e-01, -2.9218e-01,\n          1.8012e-01,  1.7317e-01,  8.7270e-02],\n        [-1.0496e-02, -3.2553e-01,  3.2605e-01,  2.3202e-01, -3.4736e-01,\n         -3.2465e-01, -7.6030e-02,  2.7612e-01],\n        [-2.1293e-01, -2.2717e-01, -2.5691e-01, -1.0846e-01,  1.5377e-02,\n         -3.1250e-01, -4.5999e-02, -1.0799e-01],\n        [-1.3404e-01, -2.7545e-02,  2.8940e-01, -1.4813e-01,  1.4693e-01,\n         -2.1299e-01, -1.0299e-01, -2.9543e-01],\n        [-1.8752e-01,  6.0059e-02,  1.1939e-01, -4.3669e-02, -1.4240e-01,\n          1.5457e-01,  4.6300e-02, -2.8163e-01],\n        [ 3.0044e-01,  1.9746e-01,  1.8157e-04, -5.8570e-02,  2.9566e-01,\n         -1.8291e-01, -1.6687e-01, -2.5338e-01],\n        [-4.1195e-02, -2.1097e-01,  1.0884e-01,  2.1822e-01, -2.9363e-01,\n         -1.3063e-03, -7.6220e-02, -3.4611e-01],\n        [-1.4212e-01,  2.6627e-01,  2.7656e-01, -2.2308e-01, -2.1059e-02,\n         -8.2651e-02,  2.9799e-01, -3.0864e-01],\n        [ 3.4632e-01, -1.5373e-01,  1.5345e-01,  1.8935e-01, -3.1895e-01,\n          3.0703e-01,  1.1648e-01, -2.0079e-01],\n        [ 2.1438e-02, -2.0918e-01, -3.4188e-01,  3.3707e-01,  1.7909e-02,\n          1.5211e-01, -1.4692e-02,  4.1225e-02],\n        [ 1.8054e-01,  3.5122e-02, -9.5940e-02,  2.1496e-01, -2.0693e-02,\n          1.7021e-01, -5.7654e-02, -1.5553e-01],\n        [ 2.9456e-01, -2.4195e-01, -3.3823e-01,  3.4726e-01,  2.9608e-01,\n          2.7174e-02,  1.8592e-01, -5.1965e-02],\n        [ 1.6443e-01, -2.8752e-02,  3.3870e-01,  9.6019e-02, -3.1914e-01,\n          1.4174e-01,  4.2815e-02, -1.8539e-01],\n        [-8.6423e-02,  1.9850e-01,  3.7647e-02,  1.8637e-01,  2.8634e-01,\n         -1.8839e-01, -1.5477e-01, -1.1343e-01],\n        [-5.4698e-02,  3.1598e-01, -1.4844e-01,  1.2431e-02,  9.3883e-02,\n          1.8141e-01, -1.6025e-01,  1.1736e-01],\n        [-1.0456e-02,  1.6250e-01, -4.9706e-02,  2.3227e-01,  2.4183e-01,\n         -2.1123e-01,  3.8341e-02, -1.8003e-03],\n        [ 2.0838e-01, -1.9743e-01, -4.8026e-02,  2.3435e-01,  1.4418e-02,\n          8.7292e-02,  3.3619e-01,  2.0442e-01],\n        [-1.6460e-01,  1.7596e-01,  4.8910e-02, -2.8998e-01,  3.2744e-01,\n          7.8254e-02, -2.2288e-01, -2.9241e-01],\n        [ 2.2563e-01,  9.7379e-02,  2.3992e-01,  1.4799e-01, -1.4835e-02,\n         -1.1789e-01,  3.1054e-01,  1.5573e-01],\n        [-2.1359e-01, -2.9604e-01, -1.0662e-01,  2.1665e-01,  1.1956e-01,\n          1.8915e-01,  2.2885e-01,  2.0587e-01],\n        [ 1.3124e-01,  2.1433e-01, -1.6509e-01,  1.1279e-01, -2.7241e-03,\n         -3.2958e-01, -1.3773e-01,  8.2071e-02],\n        [-1.2484e-01,  8.9124e-02, -5.3845e-02, -3.3090e-02,  1.9232e-01,\n         -7.1540e-02,  2.3910e-01, -1.4105e-01],\n        [ 1.1254e-01,  2.2222e-01,  2.9234e-01, -2.1589e-01,  1.0230e-01,\n         -8.9160e-02, -6.5891e-02,  2.6137e-01],\n        [-1.7127e-01,  2.0859e-02, -1.7046e-01, -3.5134e-01, -2.1213e-01,\n          4.4167e-02, -6.3450e-02, -3.5289e-01],\n        [ 2.3313e-01, -2.2523e-01,  1.4640e-01,  6.9301e-02, -7.1739e-03,\n         -1.9256e-01, -2.3792e-01,  2.6157e-01],\n        [ 1.7342e-02, -3.4678e-01, -1.3527e-02,  1.8453e-02,  2.1345e-01,\n         -9.1212e-02,  3.2588e-01, -2.4376e-01],\n        [-1.6068e-01,  1.6660e-01, -2.8660e-01, -2.6582e-01, -3.9716e-02,\n         -3.2782e-02, -3.3210e-01,  3.6085e-02],\n        [ 1.7087e-01, -1.3986e-01,  8.7196e-02,  2.0461e-01,  1.8899e-01,\n         -4.9990e-02,  1.4653e-02, -1.5450e-03],\n        [-1.9298e-02, -2.6321e-01,  3.7222e-02,  3.0896e-01,  1.1976e-01,\n          3.1252e-01, -1.4771e-01, -2.6018e-01],\n        [ 3.4830e-01,  2.4347e-01,  2.1947e-01, -4.6469e-03, -2.7382e-01,\n         -2.2813e-02,  3.2635e-01,  1.5576e-01],\n        [ 8.2108e-02,  2.3004e-02,  2.6955e-01,  2.7174e-01,  4.6497e-02,\n         -3.1004e-01,  7.3879e-04, -2.5814e-01],\n        [ 1.1915e-01, -1.4122e-01, -2.5209e-03, -2.2899e-01,  1.9197e-01,\n         -8.6278e-02,  1.8825e-01, -3.3650e-01],\n        [ 2.7703e-01, -1.4251e-01,  2.8729e-01, -7.5515e-02,  2.4090e-01,\n          2.5237e-01, -2.7208e-01, -6.8922e-02],\n        [ 2.3510e-02,  2.0105e-01, -5.0509e-02,  5.2763e-02, -3.1703e-01,\n          3.1777e-01,  3.0607e-01, -1.5465e-01],\n        [ 2.6427e-01,  2.4208e-01,  3.2226e-01, -2.7304e-01, -1.4882e-02,\n         -3.2955e-01, -3.2724e-01,  1.3145e-01],\n        [ 2.0030e-01, -8.2377e-02,  2.1674e-01, -2.2939e-02,  3.4809e-01,\n         -1.8716e-01, -2.9874e-01, -2.9540e-01],\n        [ 1.8280e-01, -1.3056e-01,  1.5158e-01,  2.0336e-01, -1.2701e-01,\n          2.1324e-01,  2.0819e-02, -2.1302e-02],\n        [ 2.5407e-01, -4.4440e-03,  2.3308e-01,  2.4537e-01, -2.8071e-01,\n         -1.8264e-01,  2.4262e-01,  6.0199e-02],\n        [-1.1598e-02, -4.3266e-02, -1.3435e-01,  2.8856e-01, -1.7097e-02,\n          2.0774e-01,  2.1312e-01, -1.5863e-01],\n        [ 2.7924e-01, -1.2174e-01,  2.8556e-01, -3.0749e-01, -6.6450e-02,\n         -1.5411e-01, -2.0446e-01, -1.6445e-01],\n        [-2.2075e-01, -1.9157e-01,  1.7544e-01, -6.7479e-02,  3.2305e-02,\n         -7.7617e-03, -3.4582e-01,  3.5147e-01],\n        [-2.4349e-01, -2.8812e-04, -1.2630e-01, -1.3539e-01,  4.1153e-02,\n         -1.3515e-01, -3.0006e-01,  2.4358e-01],\n        [-5.2104e-02,  5.8588e-02, -2.8909e-03, -2.0342e-01, -3.5028e-01,\n         -3.2624e-01, -1.3445e-01,  2.0591e-02],\n        [-1.3109e-01,  2.5436e-01, -2.9415e-01,  1.5074e-02, -2.6369e-01,\n         -3.3870e-01,  2.0209e-01, -1.3518e-01],\n        [-7.5994e-02,  9.2467e-02,  3.1884e-01, -1.8517e-01, -1.9982e-01,\n          1.5263e-01, -2.2746e-01, -6.4833e-02],\n        [-3.5192e-01, -1.9887e-01, -4.0592e-02,  1.6873e-01,  2.6860e-01,\n         -2.8733e-01,  3.1926e-01, -1.8708e-01],\n        [ 2.9248e-01, -3.1001e-01, -2.2715e-01, -1.1556e-01, -3.3034e-01,\n         -1.3135e-01,  2.2346e-01, -2.9173e-01],\n        [-3.0677e-01, -1.0578e-01,  3.4553e-01, -1.5521e-02,  8.1017e-02,\n          2.2647e-02, -1.1085e-01, -3.1923e-01],\n        [ 1.1474e-03, -1.7935e-01,  2.5340e-01, -1.0311e-01, -5.9874e-02,\n         -2.4104e-01,  2.1856e-01,  7.5014e-02],\n        [ 3.5096e-01,  3.3933e-01,  2.9558e-01,  2.6145e-01,  3.2493e-01,\n         -1.9172e-02,  4.9707e-02, -2.4166e-01],\n        [-1.6565e-01, -2.6584e-01,  3.5952e-03,  1.9562e-01, -2.7122e-01,\n          6.4070e-02,  2.2073e-01,  2.1301e-01],\n        [ 3.3503e-01,  2.3524e-01, -8.4006e-02, -4.9891e-02,  3.4738e-01,\n          1.8649e-01,  1.9102e-01, -2.7994e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0755,  0.0814,  0.0364, -0.0850,  0.0664,  0.0381, -0.0629,  0.0814,\n         0.0754, -0.0520,  0.0419, -0.0564, -0.0515,  0.0030, -0.0705,  0.0706,\n        -0.0690, -0.0892, -0.0935, -0.0622,  0.0698, -0.0408, -0.0358,  0.0751,\n        -0.0901,  0.0744,  0.0711,  0.0336,  0.0966,  0.0923, -0.0130,  0.0208,\n         0.0763,  0.0619, -0.0537,  0.0233, -0.0035, -0.0665, -0.0543, -0.0263,\n        -0.0727,  0.0487,  0.0354, -0.0440, -0.0058, -0.0833, -0.0009, -0.0137,\n         0.0515,  0.0588, -0.0766,  0.0584,  0.0512,  0.0640,  0.0278, -0.0914,\n        -0.0564, -0.0101, -0.0816, -0.0267, -0.0847,  0.0983,  0.0645, -0.0853,\n         0.0927,  0.0051, -0.0639,  0.0059,  0.0907,  0.0137,  0.0920, -0.0581,\n        -0.0154, -0.0691, -0.0370,  0.0911,  0.0581,  0.0311, -0.0279,  0.0046,\n         0.0348,  0.0780, -0.0422, -0.0042, -0.0384,  0.0249, -0.0508,  0.0668,\n        -0.0026, -0.0143,  0.0095, -0.0459, -0.0437,  0.0864,  0.0914, -0.0772,\n         0.0492, -0.0802,  0.0310, -0.0140], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0712, -0.0782,  0.0776,  ...,  0.0858, -0.0774, -0.0148],\n        [-0.0408,  0.0859, -0.0990,  ..., -0.0719,  0.0694,  0.0811],\n        [ 0.0048, -0.0354,  0.0244,  ...,  0.0080,  0.0356,  0.0200],\n        ...,\n        [ 0.0029,  0.0737, -0.0736,  ..., -0.0279,  0.0697, -0.0745],\n        [ 0.0628,  0.0740,  0.0437,  ..., -0.0204,  0.0667,  0.0849],\n        [ 0.0065,  0.0376, -0.0084,  ..., -0.0949,  0.0324,  0.0184]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0777, -0.0386, -0.0559, -0.0776], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0412,  0.0116, -0.0162, -0.0359,  0.0713, -0.0919,  0.0168,  0.0448,\n         -0.0158,  0.0373,  0.0604, -0.0744,  0.0296, -0.0066, -0.0616,  0.0141,\n         -0.0080,  0.0498,  0.0033,  0.0684,  0.0826,  0.0581, -0.0289, -0.0205,\n         -0.0512,  0.0091, -0.0012,  0.0772,  0.0573, -0.0972, -0.0400, -0.0733,\n         -0.0730, -0.0332, -0.0803, -0.0633,  0.0092, -0.0037,  0.0678, -0.0867,\n          0.0212,  0.0488, -0.0233, -0.0802,  0.0897,  0.0131,  0.0394, -0.0976,\n         -0.0131, -0.0186, -0.0976,  0.0459, -0.0230, -0.0152,  0.0366, -0.0535,\n          0.0240, -0.0171,  0.0331,  0.0227,  0.0009,  0.0791, -0.0689, -0.0974,\n          0.0413,  0.0972, -0.0298, -0.0738, -0.0306, -0.0396,  0.0047,  0.0273,\n          0.0141,  0.0873, -0.0256, -0.0275,  0.0967, -0.0139,  0.0029, -0.0773,\n          0.0773,  0.0863,  0.0641, -0.0534,  0.0650, -0.0610,  0.0085, -0.0874,\n         -0.0683,  0.0756, -0.0184, -0.0154,  0.0424, -0.0543,  0.0102, -0.0382,\n          0.0277, -0.0453,  0.0934,  0.0255],\n        [ 0.0876, -0.0473,  0.0953,  0.0349,  0.0080, -0.0711,  0.0849,  0.0461,\n         -0.0075, -0.0894, -0.0025,  0.0227,  0.0214, -0.0014, -0.0115,  0.0798,\n         -0.0478,  0.0005,  0.0294, -0.0598, -0.0659, -0.0012,  0.0575, -0.0653,\n          0.0381, -0.0929, -0.0516,  0.0110, -0.0515,  0.0376, -0.0139, -0.0127,\n          0.0888,  0.0118, -0.0097,  0.0192, -0.0386,  0.0430,  0.0870, -0.0955,\n         -0.0478, -0.0783,  0.0708,  0.0654, -0.0124,  0.0893,  0.0702, -0.0445,\n         -0.0691, -0.0398, -0.0766, -0.0869, -0.0613, -0.0923,  0.0755, -0.0291,\n         -0.0350,  0.0390, -0.0675,  0.0400, -0.0546, -0.0522, -0.0922, -0.0122,\n          0.0917, -0.0307,  0.0829, -0.0389,  0.0469,  0.0320, -0.0854,  0.0755,\n         -0.0312,  0.0413,  0.0598, -0.0232, -0.0037, -0.0620, -0.0239, -0.0713,\n          0.0824, -0.0485, -0.0426, -0.0582,  0.0191,  0.0348, -0.0478, -0.0623,\n         -0.0080, -0.0729,  0.0157, -0.0955,  0.0784,  0.0555,  0.0284,  0.0962,\n          0.0629,  0.0341, -0.0257,  0.0786],\n        [-0.0460,  0.0261, -0.0945,  0.0334,  0.0418,  0.0019,  0.0233,  0.0584,\n          0.0282,  0.0705,  0.0334,  0.0592, -0.0206,  0.0168, -0.0632, -0.0122,\n          0.0731, -0.0025, -0.0116,  0.0622,  0.0284, -0.0828,  0.0073,  0.0778,\n          0.0394,  0.0024,  0.0920, -0.0153,  0.0767, -0.0663,  0.0630,  0.0304,\n         -0.0087,  0.0614, -0.0940, -0.0616, -0.0229,  0.0516, -0.0487,  0.0468,\n         -0.0288, -0.0142, -0.0765, -0.0481, -0.0330,  0.0777,  0.0134, -0.0986,\n          0.0003, -0.0861, -0.0991, -0.0212,  0.0680, -0.0703, -0.0996, -0.0458,\n         -0.0173,  0.0142,  0.0143, -0.0496, -0.0488, -0.0557,  0.0874,  0.0948,\n         -0.0053, -0.0814, -0.0874,  0.0633,  0.0885,  0.0908,  0.0403, -0.0778,\n         -0.0407, -0.0354,  0.0007, -0.0061, -0.0041,  0.0066, -0.0928, -0.0884,\n         -0.0895, -0.0552, -0.0205, -0.0212,  0.0377,  0.0603,  0.0833, -0.0988,\n         -0.0036,  0.0558,  0.0319, -0.0500, -0.0701, -0.0378,  0.0439,  0.0051,\n         -0.0982,  0.0011, -0.0594,  0.0916],\n        [-0.0067,  0.0082,  0.0032, -0.0045, -0.0963, -0.0254, -0.0487,  0.0435,\n          0.0572,  0.0976, -0.0827, -0.0476, -0.0494, -0.0696, -0.0919, -0.0995,\n         -0.0846,  0.0819, -0.0954, -0.0863, -0.0540, -0.0240,  0.0193,  0.0395,\n         -0.0069, -0.0604,  0.0681, -0.0094,  0.0579,  0.0399,  0.0123, -0.0736,\n         -0.0776,  0.0771,  0.0345, -0.0857, -0.0651,  0.0371,  0.0745,  0.0195,\n          0.0280, -0.0784, -0.0130, -0.0808, -0.0560, -0.0078,  0.0909,  0.0799,\n          0.0256,  0.0684,  0.0275, -0.0470,  0.0370, -0.0307,  0.0390, -0.0636,\n          0.0963,  0.0323,  0.0635, -0.0488,  0.0173, -0.0356, -0.0042,  0.0876,\n          0.0681,  0.0072, -0.0348, -0.0012, -0.0523, -0.0433, -0.0725,  0.0259,\n          0.0622, -0.0370, -0.0953,  0.0479, -0.0943, -0.0934,  0.0259, -0.0934,\n          0.0876,  0.0266,  0.0472, -0.0406, -0.0249,  0.0305, -0.0708, -0.0537,\n          0.0827, -0.0558, -0.0247,  0.0687, -0.0148, -0.0896, -0.0865, -0.0702,\n         -0.0162, -0.0475, -0.0300, -0.0609]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x744d8ae097d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s474630000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s474630000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}