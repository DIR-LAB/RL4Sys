{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.01,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s480800000"
    },
    "q_lr":	0.003,
    "seed":	480800000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x72d82548d590>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.01,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1271,  0.2075, -0.1471, -0.0831,  0.2246,  0.0034, -0.0167, -0.2074,\n         0.3093, -0.2071, -0.3051,  0.1315,  0.1792, -0.3034, -0.0879,  0.2309,\n         0.2858,  0.0211,  0.3123,  0.2114, -0.0689, -0.0015,  0.0154,  0.2511,\n         0.2135,  0.0098, -0.3116,  0.0090,  0.0680, -0.2855,  0.1155,  0.3319,\n         0.1114,  0.2917,  0.2519, -0.0194, -0.1902, -0.2910,  0.1028, -0.0695,\n         0.0542,  0.0820,  0.2251,  0.0911,  0.0030, -0.3502, -0.0390,  0.0366,\n        -0.1958,  0.1330,  0.2847,  0.1442,  0.1453, -0.1450, -0.1911,  0.1024,\n         0.2283,  0.2269,  0.3487,  0.0356, -0.1823, -0.0307,  0.0553, -0.1936,\n         0.1081, -0.3127, -0.1360, -0.3465, -0.1461, -0.2488,  0.0407,  0.3034,\n        -0.2193,  0.1434, -0.3414, -0.1681,  0.2320,  0.1744,  0.1585,  0.0674,\n        -0.0412,  0.3299,  0.2614,  0.1331,  0.0873,  0.0182, -0.1711, -0.0509,\n         0.0660, -0.2072,  0.3023, -0.1433,  0.0269, -0.1858,  0.2540, -0.1045,\n        -0.2352, -0.2071,  0.3354, -0.0649], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.5598e-01, -3.0099e-01, -2.9326e-01,  3.1474e-02, -1.8454e-01,\n          5.5659e-02, -2.7353e-01, -1.2534e-01],\n        [-1.2121e-01,  1.3053e-01, -3.0932e-01,  2.8667e-01,  1.7327e-01,\n         -1.1870e-01,  1.8206e-01, -2.1928e-01],\n        [ 2.5708e-01, -8.9370e-02, -2.3468e-02,  3.0206e-01,  5.1940e-02,\n         -2.4576e-01,  2.5859e-01, -2.6470e-02],\n        [-1.1385e-01, -9.7045e-02,  1.8304e-01, -2.6268e-01, -3.4449e-01,\n          2.6078e-01, -1.3021e-01,  2.9423e-01],\n        [-2.3573e-01,  2.4967e-01, -1.7861e-01, -8.5291e-02, -1.8173e-01,\n          2.8449e-01, -6.4315e-02,  3.4267e-01],\n        [-9.6293e-02, -4.2617e-02,  9.7647e-02, -1.5066e-01,  6.2639e-02,\n         -2.0940e-01, -2.9695e-01,  2.5168e-01],\n        [ 8.8571e-02,  4.1620e-02, -2.9595e-02,  2.6437e-01,  9.3322e-02,\n         -2.5477e-01,  1.4506e-01,  2.9315e-01],\n        [-3.2447e-01,  1.1244e-01, -6.5442e-02, -1.0266e-01, -1.8203e-01,\n         -3.3914e-01,  2.5605e-03, -2.8075e-01],\n        [-2.7278e-01,  1.1694e-01,  2.7555e-01,  1.1946e-01,  1.0064e-01,\n         -2.9768e-01,  1.8189e-01, -1.3071e-01],\n        [ 3.2403e-01, -5.3375e-02, -1.5364e-01, -1.3991e-01, -6.8683e-03,\n          7.7970e-03, -1.0211e-01, -2.1217e-01],\n        [-3.4734e-01, -9.4071e-02, -1.7460e-01,  5.4786e-02,  1.5726e-01,\n          2.1793e-01, -9.4554e-02,  5.4456e-02],\n        [-3.4219e-01, -2.5021e-01, -1.1667e-01,  1.2315e-01,  2.8269e-01,\n         -2.7223e-01,  2.6421e-01, -2.5581e-02],\n        [ 3.0568e-01, -1.7804e-01,  2.8423e-01,  3.4089e-01,  6.8294e-02,\n         -1.4299e-01,  2.0273e-01,  1.8669e-01],\n        [ 1.8553e-01,  2.9842e-02,  3.0369e-01,  1.6752e-01,  2.5268e-01,\n         -1.9719e-01,  3.3461e-01, -5.4270e-02],\n        [ 2.7203e-01, -3.2242e-01, -5.7426e-03, -2.3155e-01,  3.8836e-02,\n         -1.5152e-01,  5.3070e-02, -2.7220e-01],\n        [-3.9289e-02,  2.7080e-01,  4.5924e-02,  1.1141e-01,  2.2820e-01,\n         -2.3195e-01, -2.1251e-02,  1.9848e-01],\n        [-2.5113e-02, -1.5282e-01, -7.8606e-02,  2.9973e-01, -3.3337e-01,\n          1.1461e-01, -2.3336e-01,  7.2714e-02],\n        [ 2.4375e-01,  2.1411e-01, -3.1400e-01, -1.1082e-01,  1.9912e-01,\n          1.8557e-01, -6.1920e-02, -3.0944e-01],\n        [-9.3738e-03,  1.9120e-01, -2.7795e-01,  3.1293e-01, -3.0041e-01,\n         -9.7273e-03, -2.7549e-01, -2.0713e-01],\n        [ 2.9003e-01, -3.9129e-02, -1.2661e-01,  1.4836e-01,  7.4434e-02,\n         -1.2162e-02,  2.9188e-02, -3.1994e-01],\n        [-1.0324e-01, -3.5168e-02,  3.3651e-01, -1.9018e-01, -3.4339e-01,\n         -3.0602e-01,  1.9042e-01,  2.6353e-01],\n        [-8.8535e-02, -3.5218e-01,  1.3642e-01,  1.3507e-01,  2.4807e-01,\n         -2.0946e-01, -1.5415e-01, -1.2485e-01],\n        [-2.5038e-01,  3.1205e-01,  3.9343e-02,  1.5970e-01,  1.7415e-01,\n          2.6627e-03,  2.9856e-02,  2.0457e-01],\n        [-6.6630e-02, -3.4606e-01,  7.2220e-02,  6.5882e-02, -2.3766e-01,\n         -2.4818e-01,  1.5072e-01,  3.1079e-01],\n        [-4.9753e-02,  2.6672e-01, -6.9782e-02, -3.1612e-01,  1.3457e-02,\n          1.4832e-01, -2.5775e-01,  2.5478e-01],\n        [-3.3467e-01, -3.5062e-01, -3.0031e-01,  1.2333e-01, -1.5802e-01,\n         -3.1066e-01, -3.4295e-01,  8.9088e-02],\n        [ 1.8393e-01,  2.6508e-01, -3.7786e-02,  6.7588e-02,  2.4390e-02,\n         -5.2164e-02, -2.6658e-01,  3.2638e-01],\n        [-1.8355e-01,  9.8692e-03,  1.4339e-01,  1.1150e-01, -2.4158e-01,\n         -3.1011e-01, -1.1040e-01, -3.0979e-01],\n        [ 2.0735e-02, -1.1490e-01, -2.9761e-01, -1.2019e-01, -1.9299e-02,\n          9.0661e-02, -1.1384e-01,  2.8843e-02],\n        [-3.4480e-01,  9.8749e-02,  1.0259e-04, -1.3197e-01, -5.7926e-02,\n         -1.6919e-01, -2.8898e-01,  1.0812e-01],\n        [-3.8207e-02,  3.0045e-01,  1.4505e-01, -1.5509e-01,  1.8151e-02,\n         -1.9584e-01,  2.2190e-01, -3.3512e-01],\n        [ 2.0161e-01,  1.4506e-01,  3.1519e-01,  1.8541e-01, -1.6184e-01,\n         -1.2764e-01,  5.1779e-02, -5.1317e-03],\n        [-7.1249e-02,  3.3140e-01, -2.6783e-01, -2.1022e-01, -3.3390e-01,\n         -7.5485e-02, -1.5076e-01, -2.6093e-01],\n        [-1.9038e-01, -9.9788e-02,  3.4857e-01,  1.1216e-01, -2.8092e-01,\n         -2.6164e-01,  1.5391e-01,  2.2825e-01],\n        [ 7.1679e-02, -2.5886e-01,  8.8757e-02,  3.2042e-01, -2.4658e-01,\n         -1.9474e-01,  2.6754e-02, -4.4401e-02],\n        [ 2.0330e-01,  1.6944e-01, -2.2389e-01,  8.1403e-02, -1.9750e-01,\n         -2.2359e-01,  1.2673e-01,  7.2547e-02],\n        [-2.3713e-01, -2.6153e-01, -2.0053e-01,  1.5421e-01, -9.4448e-02,\n         -2.3059e-01, -1.5144e-01, -3.3573e-01],\n        [ 4.5558e-02,  1.8764e-01,  1.4525e-01, -2.7626e-01,  2.3375e-01,\n         -2.3891e-01, -3.3609e-01, -3.5525e-02],\n        [ 4.7761e-02,  1.9631e-01,  1.8123e-01,  1.5663e-01, -1.5872e-01,\n         -6.8108e-02,  3.1006e-01, -1.5903e-01],\n        [ 2.2163e-01,  1.4097e-01, -3.4184e-01, -2.4842e-01, -1.9187e-01,\n          1.6609e-01,  8.7927e-02, -2.3631e-01],\n        [-1.9501e-02, -3.2305e-01, -1.4764e-01, -2.1163e-01, -1.5895e-01,\n         -9.4213e-03, -2.2316e-01, -1.4945e-01],\n        [-2.5642e-01, -1.0227e-01,  3.0523e-01, -2.7030e-03, -1.2348e-01,\n          2.7537e-01, -1.0461e-01,  3.5225e-01],\n        [-9.0018e-03,  9.3527e-02, -3.2562e-01,  1.5013e-01,  3.5062e-01,\n         -2.5874e-01, -7.4812e-02,  2.1117e-01],\n        [ 2.0594e-01,  3.2670e-01, -1.1324e-01, -2.8645e-03,  3.3214e-01,\n          3.4548e-01, -1.5988e-02, -1.7572e-01],\n        [-2.2948e-01,  6.8374e-02, -3.0331e-01,  3.1060e-01, -1.3352e-01,\n          6.0794e-02, -1.7058e-01,  1.7056e-01],\n        [-2.4450e-01, -1.5986e-01, -1.9113e-02, -6.7679e-02,  2.5192e-02,\n          2.7470e-01, -3.1972e-01, -2.8318e-01],\n        [-2.8108e-01,  2.0774e-01,  2.8815e-01, -2.9622e-01, -1.5852e-01,\n         -2.5688e-01,  6.1480e-02, -4.1972e-02],\n        [ 1.0148e-01, -3.2460e-02, -1.0369e-01,  2.4053e-01, -1.9449e-01,\n         -2.7994e-01, -1.1149e-01, -4.7537e-02],\n        [-2.1339e-02,  1.7218e-01, -2.9532e-01, -1.7316e-01,  6.0807e-02,\n         -6.4976e-02,  1.2703e-01, -4.4490e-02],\n        [ 2.0826e-01, -1.7215e-02, -1.0305e-01,  2.4996e-01,  9.6769e-02,\n          2.3138e-01, -2.6655e-01, -1.8788e-02],\n        [ 1.6551e-01, -1.7928e-01, -2.5768e-01,  7.6203e-02, -1.4544e-01,\n         -1.5516e-01, -3.3760e-01,  1.1063e-01],\n        [-3.0398e-01, -8.3862e-02, -1.5386e-01,  8.7272e-03, -6.8568e-02,\n         -1.1654e-01, -1.1179e-01, -1.1718e-01],\n        [-3.0293e-01, -1.4076e-01, -9.8619e-02, -1.4865e-01, -1.2219e-01,\n         -2.0758e-01,  1.9145e-01,  3.4505e-01],\n        [ 1.2936e-01, -6.7793e-02, -3.8054e-02,  8.6346e-02, -1.8065e-01,\n          2.2912e-01, -6.9902e-02, -3.0107e-01],\n        [-3.4807e-01, -3.4079e-01, -7.0089e-02,  2.8030e-01, -2.5730e-01,\n         -2.5842e-01, -2.2710e-01, -2.8169e-01],\n        [ 2.6490e-01, -1.4361e-01, -2.0837e-01, -3.2138e-01,  1.8523e-01,\n         -3.3304e-01,  3.1379e-01,  1.5206e-01],\n        [-1.9504e-01,  1.9182e-01, -2.1087e-01,  1.8325e-01,  3.1177e-01,\n          1.9970e-01, -3.3888e-01, -7.7813e-02],\n        [ 2.8510e-01,  5.4763e-02, -2.1489e-01,  2.4839e-01,  2.6793e-01,\n         -1.0310e-01, -2.0917e-01, -3.3495e-01],\n        [-1.5304e-01,  1.1914e-01,  2.9359e-02,  1.6057e-02,  1.8206e-01,\n          2.1235e-01,  7.7047e-02,  1.7106e-01],\n        [-2.5368e-01, -3.0460e-01, -2.3002e-01,  2.9500e-02,  7.3685e-03,\n         -7.5048e-02, -1.8398e-02,  2.7237e-01],\n        [ 2.3825e-01, -1.5854e-01,  2.3967e-01,  5.3618e-02, -3.4388e-01,\n          5.2562e-02,  9.1338e-02,  4.0347e-02],\n        [ 1.8178e-01, -3.0895e-01,  1.5459e-02, -2.2258e-01,  3.9166e-02,\n          6.6160e-03, -1.2512e-01,  2.4677e-01],\n        [-2.6667e-01, -9.1566e-02,  3.6928e-02, -3.4971e-01,  7.8712e-02,\n         -3.6623e-02,  3.2123e-01,  3.4287e-01],\n        [ 2.4404e-01,  1.0403e-01,  2.1778e-01,  1.3355e-01,  1.8468e-02,\n         -1.4683e-01, -2.7425e-01, -1.6322e-01],\n        [ 3.4556e-01, -1.9557e-01,  3.4767e-01,  3.2776e-02,  2.2006e-01,\n          1.6697e-02,  2.7581e-01, -1.8384e-01],\n        [ 1.8988e-01, -2.9508e-01, -1.8520e-01, -3.2878e-01, -2.9884e-01,\n         -2.7608e-01, -2.7269e-02,  2.2056e-01],\n        [ 9.8560e-02,  2.2339e-01, -2.9683e-01, -2.5393e-01,  4.3087e-02,\n         -2.7298e-01,  1.8686e-01, -2.3379e-01],\n        [ 3.0837e-01, -3.3320e-01,  8.9406e-02,  1.4946e-01, -2.7256e-01,\n          1.7244e-01,  9.8141e-02, -2.5413e-01],\n        [ 3.4336e-01,  1.5647e-01, -5.0506e-02,  3.3853e-01,  1.9272e-01,\n          1.7300e-01,  1.8994e-01,  2.7639e-01],\n        [-2.9966e-01, -2.6563e-01, -1.1578e-01, -6.9751e-02, -1.7167e-01,\n          2.0705e-01,  7.3627e-02, -3.0888e-01],\n        [ 1.7544e-01,  3.4615e-01,  1.2680e-01,  6.0797e-02,  1.1713e-01,\n         -1.4870e-02, -1.6568e-01,  2.0612e-01],\n        [-5.3151e-02,  1.0030e-02, -1.4634e-01,  2.9233e-01,  5.8484e-02,\n          1.4510e-02, -1.1585e-01,  1.4346e-01],\n        [ 2.6352e-01,  5.7373e-02,  1.0150e-01, -6.4162e-02, -2.0588e-01,\n          2.2283e-01,  3.4244e-01, -2.7314e-01],\n        [ 2.3152e-01,  2.7072e-01, -2.3505e-01, -3.1277e-01, -1.1945e-01,\n          1.4334e-01, -1.6326e-01, -1.5286e-01],\n        [ 1.0497e-01,  6.1306e-02,  2.3896e-01,  1.8319e-01, -1.9102e-02,\n         -2.3845e-01, -1.3288e-02,  2.8928e-01],\n        [ 1.8052e-01,  3.5178e-01, -2.0458e-01, -2.8842e-01, -3.2414e-01,\n          7.5499e-02,  8.1792e-02, -2.6351e-01],\n        [ 3.0981e-01, -2.7869e-01,  4.6513e-02,  2.6186e-01,  2.6509e-01,\n         -2.0375e-01,  2.9297e-01, -8.0528e-02],\n        [-1.9229e-01,  3.4885e-01, -1.1607e-02,  2.4606e-01,  3.2566e-01,\n         -2.4603e-01, -1.2083e-01,  1.1405e-01],\n        [-9.3578e-02,  1.1085e-02, -9.5389e-02, -9.7262e-02, -2.9010e-01,\n         -9.1161e-03,  2.2772e-01, -8.2062e-02],\n        [-1.2774e-02, -1.9184e-01, -6.9042e-02,  2.7988e-01, -1.5178e-01,\n         -2.7537e-01,  3.2982e-01,  2.6538e-01],\n        [ 2.7035e-01, -1.9080e-01,  1.1241e-01,  1.7202e-02,  1.1997e-01,\n         -2.2449e-01,  3.2811e-01, -2.0368e-01],\n        [-2.1338e-01, -2.5084e-01,  1.7792e-01, -1.9056e-01, -1.9033e-01,\n         -1.7338e-01, -2.4208e-01,  7.8922e-02],\n        [ 2.7424e-01,  2.3863e-01,  1.6264e-01, -1.0704e-01, -1.2138e-01,\n         -1.0146e-01, -7.2116e-02, -1.4134e-01],\n        [-2.0937e-01,  1.6128e-01, -1.3417e-01, -7.8315e-02,  1.0354e-01,\n         -2.1639e-01, -2.0475e-02, -2.8473e-01],\n        [-6.1529e-02, -2.2299e-01,  2.3304e-01, -2.1268e-01, -5.6665e-02,\n          4.2763e-02,  2.4605e-01, -1.1324e-01],\n        [-3.1389e-01, -2.5900e-01,  2.3669e-01, -2.0634e-01, -5.9854e-02,\n         -1.8085e-01, -9.9581e-02,  3.1288e-01],\n        [-6.1082e-02,  3.5837e-02, -1.7308e-01,  3.2516e-03, -3.0043e-01,\n          2.0556e-01, -2.3806e-02, -1.9219e-01],\n        [ 1.3729e-01,  6.6322e-02, -3.5026e-01, -2.3907e-01,  2.0389e-01,\n         -2.6039e-01,  1.0656e-01, -4.3837e-04],\n        [-3.2896e-01,  5.1711e-02,  3.1792e-01,  7.9727e-02, -1.3793e-01,\n         -1.5293e-01, -2.4513e-01, -1.7064e-01],\n        [ 8.6033e-02, -3.0314e-01, -2.8945e-01, -2.2719e-01, -1.2662e-01,\n          2.3399e-01, -8.0186e-02, -1.7946e-01],\n        [-3.2126e-01, -7.0643e-02, -3.3370e-01, -3.5002e-01, -3.3206e-02,\n          1.9336e-01,  1.1382e-01,  1.1214e-01],\n        [-1.5770e-01,  1.8227e-02, -2.8412e-01,  8.0047e-02, -3.4993e-02,\n         -2.6020e-01,  3.0071e-01, -2.1384e-01],\n        [ 2.2583e-01,  8.1394e-02, -2.6654e-01, -9.0914e-02,  1.6657e-01,\n          1.9020e-01,  2.3334e-01,  3.2647e-03],\n        [ 2.1211e-01, -2.7148e-01,  3.5303e-01, -4.1527e-02, -3.1466e-01,\n          1.9019e-01, -1.1765e-01,  2.8230e-01],\n        [ 3.3421e-01,  9.7885e-02,  7.6637e-02, -2.2730e-01,  3.2318e-01,\n          4.3574e-02, -1.9100e-02,  2.3913e-01],\n        [-1.2359e-01, -8.1210e-02,  1.5894e-02,  2.0074e-01,  3.5217e-02,\n          2.8286e-01, -2.9045e-01, -2.4619e-01],\n        [-1.2205e-01, -6.6623e-02, -3.2035e-01,  1.3626e-03, -1.1936e-01,\n          7.8536e-02, -3.5061e-01, -3.1136e-02],\n        [ 1.3043e-01, -3.2438e-01, -2.4063e-01, -6.9433e-02, -3.4560e-01,\n         -6.5277e-02, -1.4744e-02, -4.4847e-03],\n        [ 3.3641e-02, -3.0259e-02,  7.5978e-02,  3.2383e-02, -2.1644e-01,\n          1.8734e-01,  1.8450e-02,  3.2353e-01],\n        [ 1.2924e-01,  1.5500e-01, -7.7680e-02,  1.1270e-02, -2.1194e-01,\n          1.8712e-01, -2.9331e-02, -2.1688e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0511,  0.0734,  0.0383,  0.0922,  0.0584,  0.0574,  0.0655, -0.0951,\n         0.0838, -0.0997, -0.0868, -0.0767,  0.0855, -0.0994, -0.0740,  0.0358,\n         0.0432,  0.0666, -0.0533, -0.0848, -0.0101, -0.0554,  0.0467,  0.0372,\n         0.0167, -0.0404, -0.0390,  0.0301, -0.0010,  0.0003, -0.0445,  0.0909,\n         0.0846,  0.0827, -0.0622,  0.0667,  0.0977, -0.0611,  0.0607, -0.0729,\n        -0.0389,  0.0542, -0.0548, -0.0175, -0.0635, -0.0703, -0.0760, -0.0061,\n         0.0871,  0.0281, -0.0670,  0.0250, -0.0025,  0.0263,  0.0252,  0.0294,\n        -0.0037,  0.0697, -0.0164, -0.0463, -0.0637, -0.0223,  0.0495, -0.0050,\n         0.0102,  0.0778,  0.0834, -0.0812,  0.0924,  0.0859,  0.0227, -0.0288,\n         0.0487, -0.0243,  0.0284, -0.0635, -0.0779,  0.0291, -0.0355,  0.0918,\n         0.0598, -0.0671,  0.0747, -0.0354, -0.0810, -0.0181, -0.0513,  0.0456,\n        -0.0882,  0.0760,  0.0727, -0.0720, -0.0423, -0.0374,  0.0501,  0.0146,\n        -0.0877,  0.0069, -0.0755, -0.0859], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0402,  0.0811,  0.0491,  ...,  0.0433, -0.0354,  0.0450],\n        [ 0.0542, -0.0100, -0.0021,  ...,  0.0304,  0.0934,  0.0584],\n        [-0.0615, -0.0883,  0.0958,  ..., -0.0969, -0.0326, -0.0208],\n        ...,\n        [-0.0212,  0.0778, -0.0771,  ...,  0.0765,  0.0095, -0.0222],\n        [-0.0177,  0.0802,  0.0037,  ..., -0.0184, -0.0610, -0.0327],\n        [-0.0350,  0.0254,  0.0638,  ...,  0.0851, -0.0026,  0.0981]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0583, -0.0337,  0.0621,  0.0023], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0913,  0.0149,  0.0035, -0.0239, -0.0920, -0.0768, -0.0511,  0.0369,\n         -0.0410, -0.0506,  0.0987, -0.0953,  0.0055,  0.0704, -0.0545,  0.0354,\n         -0.0542,  0.0354, -0.0167,  0.0971,  0.0372, -0.0939, -0.0377,  0.0575,\n         -0.0951,  0.0464, -0.0675,  0.0328,  0.0198, -0.0046, -0.0836,  0.0441,\n          0.0391,  0.0415, -0.0485, -0.0035, -0.0631, -0.0593, -0.0473, -0.0986,\n          0.0525,  0.0820,  0.0742,  0.0948,  0.0917, -0.0049, -0.0389,  0.0521,\n          0.0942, -0.0031,  0.0103, -0.0824, -0.0760, -0.0318,  0.0996, -0.0173,\n         -0.0411, -0.0748, -0.0539, -0.0682, -0.0861,  0.0839,  0.0866,  0.0664,\n         -0.0673, -0.0061, -0.0324, -0.0067,  0.0915, -0.0048, -0.0260,  0.0612,\n          0.0176,  0.0380,  0.0006,  0.0486,  0.0698,  0.0873, -0.0447, -0.0631,\n          0.0697,  0.0249,  0.0690,  0.0628,  0.0289,  0.0931, -0.0098,  0.0641,\n          0.0294, -0.0006,  0.0942,  0.0174, -0.0546,  0.0191, -0.0200, -0.0732,\n          0.0847, -0.0522, -0.0668,  0.0967],\n        [ 0.0804,  0.0821, -0.0157, -0.0051, -0.0849, -0.0582,  0.0215, -0.0385,\n         -0.0156,  0.0519,  0.0122, -0.0330, -0.0488, -0.0051,  0.0757,  0.0024,\n         -0.0847,  0.0528,  0.0178, -0.1000,  0.0643,  0.0039, -0.0644,  0.0489,\n         -0.0943, -0.0676, -0.0385,  0.0554,  0.0196,  0.0195,  0.0560, -0.0511,\n         -0.0936, -0.0005, -0.0262, -0.0973,  0.0624,  0.0389,  0.0466,  0.0119,\n         -0.0638,  0.0930,  0.0328, -0.0665,  0.0549, -0.0148,  0.0519, -0.0527,\n          0.0074,  0.0359,  0.0444, -0.0736, -0.0004,  0.0624, -0.0549, -0.0924,\n          0.0295, -0.0962,  0.0441,  0.0540,  0.0637,  0.0560,  0.0173, -0.0596,\n         -0.0844, -0.0366,  0.0478, -0.0721,  0.0103, -0.0615, -0.0323, -0.0102,\n         -0.0450,  0.0648,  0.0945,  0.0476,  0.0505,  0.0111,  0.0148,  0.0018,\n         -0.0065,  0.0542, -0.0229, -0.0130,  0.0252, -0.0468,  0.0687,  0.0111,\n          0.0162,  0.0576, -0.0264, -0.0372,  0.0994,  0.0399, -0.0877, -0.0945,\n          0.0818, -0.0717, -0.0733, -0.0276],\n        [ 0.0167, -0.0785, -0.0306,  0.0369, -0.0314,  0.0875, -0.0837,  0.0523,\n         -0.0842, -0.0116,  0.0358,  0.0560,  0.0073,  0.0129, -0.0365, -0.0020,\n         -0.0956,  0.0527, -0.0596,  0.0571,  0.0856,  0.0779, -0.0099, -0.0878,\n         -0.0656, -0.0622,  0.0918, -0.0219, -0.0980, -0.0796, -0.0692, -0.0741,\n          0.0477,  0.0387,  0.0164, -0.0977,  0.0081, -0.0949, -0.0844,  0.0605,\n          0.0044,  0.0204, -0.0275, -0.0714,  0.0993,  0.0030,  0.0046,  0.0930,\n         -0.0265,  0.0205,  0.0638,  0.0126,  0.0089,  0.0825, -0.0307, -0.0228,\n         -0.0026,  0.0284,  0.0509,  0.0460,  0.0328,  0.0102,  0.0234,  0.0671,\n          0.0145, -0.0750, -0.0050,  0.0324,  0.0751,  0.0147,  0.0317, -0.0286,\n         -0.0094, -0.0293,  0.0264,  0.0180,  0.0095,  0.0169, -0.0033,  0.0993,\n         -0.0879,  0.0807, -0.0446,  0.0427,  0.0576,  0.0156,  0.0165, -0.0001,\n          0.0648, -0.0756,  0.0492, -0.0454,  0.0483, -0.0720, -0.0652, -0.0182,\n         -0.0505, -0.0008, -0.0933,  0.0362],\n        [ 0.0513,  0.0158, -0.0235,  0.0568,  0.0115,  0.0435,  0.0470, -0.0918,\n         -0.0106,  0.0333, -0.0130, -0.0914, -0.0404, -0.0201,  0.0427, -0.0580,\n          0.0425,  0.0683,  0.0920,  0.0757,  0.0466,  0.0425, -0.0111, -0.0332,\n         -0.0774,  0.0107, -0.0152, -0.0077, -0.0742, -0.0951, -0.0377, -0.0487,\n          0.0715,  0.0029,  0.0960,  0.0124,  0.0021, -0.0109,  0.0945,  0.0610,\n          0.0287, -0.0484,  0.0944, -0.0256,  0.0056,  0.0496, -0.0739, -0.0706,\n          0.0203, -0.0742,  0.0665, -0.0006, -0.0237, -0.0448,  0.0076, -0.0202,\n         -0.0881,  0.0669, -0.0953, -0.0644, -0.0163,  0.0254, -0.0904, -0.0449,\n          0.0178,  0.0565,  0.0398,  0.0456, -0.0494, -0.0355,  0.0391,  0.0314,\n         -0.0171,  0.0793, -0.0933,  0.0441,  0.0812,  0.0165,  0.0885,  0.0587,\n          0.0021,  0.0446,  0.0189,  0.0382, -0.0220, -0.0392,  0.0171, -0.0600,\n          0.0993,  0.0291,  0.0813,  0.0213, -0.0523, -0.0729,  0.0507, -0.0881,\n         -0.0559, -0.0190, -0.0963,  0.0157]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-1.5598e-01, -3.0099e-01, -2.9326e-01,  3.1474e-02, -1.8454e-01,\n          5.5659e-02, -2.7353e-01, -1.2534e-01],\n        [-1.2121e-01,  1.3053e-01, -3.0932e-01,  2.8667e-01,  1.7327e-01,\n         -1.1870e-01,  1.8206e-01, -2.1928e-01],\n        [ 2.5708e-01, -8.9370e-02, -2.3468e-02,  3.0206e-01,  5.1940e-02,\n         -2.4576e-01,  2.5859e-01, -2.6470e-02],\n        [-1.1385e-01, -9.7045e-02,  1.8304e-01, -2.6268e-01, -3.4449e-01,\n          2.6078e-01, -1.3021e-01,  2.9423e-01],\n        [-2.3573e-01,  2.4967e-01, -1.7861e-01, -8.5291e-02, -1.8173e-01,\n          2.8449e-01, -6.4315e-02,  3.4267e-01],\n        [-9.6293e-02, -4.2617e-02,  9.7647e-02, -1.5066e-01,  6.2639e-02,\n         -2.0940e-01, -2.9695e-01,  2.5168e-01],\n        [ 8.8571e-02,  4.1620e-02, -2.9595e-02,  2.6437e-01,  9.3322e-02,\n         -2.5477e-01,  1.4506e-01,  2.9315e-01],\n        [-3.2447e-01,  1.1244e-01, -6.5442e-02, -1.0266e-01, -1.8203e-01,\n         -3.3914e-01,  2.5605e-03, -2.8075e-01],\n        [-2.7278e-01,  1.1694e-01,  2.7555e-01,  1.1946e-01,  1.0064e-01,\n         -2.9768e-01,  1.8189e-01, -1.3071e-01],\n        [ 3.2403e-01, -5.3375e-02, -1.5364e-01, -1.3991e-01, -6.8683e-03,\n          7.7970e-03, -1.0211e-01, -2.1217e-01],\n        [-3.4734e-01, -9.4071e-02, -1.7460e-01,  5.4786e-02,  1.5726e-01,\n          2.1793e-01, -9.4554e-02,  5.4456e-02],\n        [-3.4219e-01, -2.5021e-01, -1.1667e-01,  1.2315e-01,  2.8269e-01,\n         -2.7223e-01,  2.6421e-01, -2.5581e-02],\n        [ 3.0568e-01, -1.7804e-01,  2.8423e-01,  3.4089e-01,  6.8294e-02,\n         -1.4299e-01,  2.0273e-01,  1.8669e-01],\n        [ 1.8553e-01,  2.9842e-02,  3.0369e-01,  1.6752e-01,  2.5268e-01,\n         -1.9719e-01,  3.3461e-01, -5.4270e-02],\n        [ 2.7203e-01, -3.2242e-01, -5.7426e-03, -2.3155e-01,  3.8836e-02,\n         -1.5152e-01,  5.3070e-02, -2.7220e-01],\n        [-3.9289e-02,  2.7080e-01,  4.5924e-02,  1.1141e-01,  2.2820e-01,\n         -2.3195e-01, -2.1251e-02,  1.9848e-01],\n        [-2.5113e-02, -1.5282e-01, -7.8606e-02,  2.9973e-01, -3.3337e-01,\n          1.1461e-01, -2.3336e-01,  7.2714e-02],\n        [ 2.4375e-01,  2.1411e-01, -3.1400e-01, -1.1082e-01,  1.9912e-01,\n          1.8557e-01, -6.1920e-02, -3.0944e-01],\n        [-9.3738e-03,  1.9120e-01, -2.7795e-01,  3.1293e-01, -3.0041e-01,\n         -9.7273e-03, -2.7549e-01, -2.0713e-01],\n        [ 2.9003e-01, -3.9129e-02, -1.2661e-01,  1.4836e-01,  7.4434e-02,\n         -1.2162e-02,  2.9188e-02, -3.1994e-01],\n        [-1.0324e-01, -3.5168e-02,  3.3651e-01, -1.9018e-01, -3.4339e-01,\n         -3.0602e-01,  1.9042e-01,  2.6353e-01],\n        [-8.8535e-02, -3.5218e-01,  1.3642e-01,  1.3507e-01,  2.4807e-01,\n         -2.0946e-01, -1.5415e-01, -1.2485e-01],\n        [-2.5038e-01,  3.1205e-01,  3.9343e-02,  1.5970e-01,  1.7415e-01,\n          2.6627e-03,  2.9856e-02,  2.0457e-01],\n        [-6.6630e-02, -3.4606e-01,  7.2220e-02,  6.5882e-02, -2.3766e-01,\n         -2.4818e-01,  1.5072e-01,  3.1079e-01],\n        [-4.9753e-02,  2.6672e-01, -6.9782e-02, -3.1612e-01,  1.3457e-02,\n          1.4832e-01, -2.5775e-01,  2.5478e-01],\n        [-3.3467e-01, -3.5062e-01, -3.0031e-01,  1.2333e-01, -1.5802e-01,\n         -3.1066e-01, -3.4295e-01,  8.9088e-02],\n        [ 1.8393e-01,  2.6508e-01, -3.7786e-02,  6.7588e-02,  2.4390e-02,\n         -5.2164e-02, -2.6658e-01,  3.2638e-01],\n        [-1.8355e-01,  9.8692e-03,  1.4339e-01,  1.1150e-01, -2.4158e-01,\n         -3.1011e-01, -1.1040e-01, -3.0979e-01],\n        [ 2.0735e-02, -1.1490e-01, -2.9761e-01, -1.2019e-01, -1.9299e-02,\n          9.0661e-02, -1.1384e-01,  2.8843e-02],\n        [-3.4480e-01,  9.8749e-02,  1.0259e-04, -1.3197e-01, -5.7926e-02,\n         -1.6919e-01, -2.8898e-01,  1.0812e-01],\n        [-3.8207e-02,  3.0045e-01,  1.4505e-01, -1.5509e-01,  1.8151e-02,\n         -1.9584e-01,  2.2190e-01, -3.3512e-01],\n        [ 2.0161e-01,  1.4506e-01,  3.1519e-01,  1.8541e-01, -1.6184e-01,\n         -1.2764e-01,  5.1779e-02, -5.1317e-03],\n        [-7.1249e-02,  3.3140e-01, -2.6783e-01, -2.1022e-01, -3.3390e-01,\n         -7.5485e-02, -1.5076e-01, -2.6093e-01],\n        [-1.9038e-01, -9.9788e-02,  3.4857e-01,  1.1216e-01, -2.8092e-01,\n         -2.6164e-01,  1.5391e-01,  2.2825e-01],\n        [ 7.1679e-02, -2.5886e-01,  8.8757e-02,  3.2042e-01, -2.4658e-01,\n         -1.9474e-01,  2.6754e-02, -4.4401e-02],\n        [ 2.0330e-01,  1.6944e-01, -2.2389e-01,  8.1403e-02, -1.9750e-01,\n         -2.2359e-01,  1.2673e-01,  7.2547e-02],\n        [-2.3713e-01, -2.6153e-01, -2.0053e-01,  1.5421e-01, -9.4448e-02,\n         -2.3059e-01, -1.5144e-01, -3.3573e-01],\n        [ 4.5558e-02,  1.8764e-01,  1.4525e-01, -2.7626e-01,  2.3375e-01,\n         -2.3891e-01, -3.3609e-01, -3.5525e-02],\n        [ 4.7761e-02,  1.9631e-01,  1.8123e-01,  1.5663e-01, -1.5872e-01,\n         -6.8108e-02,  3.1006e-01, -1.5903e-01],\n        [ 2.2163e-01,  1.4097e-01, -3.4184e-01, -2.4842e-01, -1.9187e-01,\n          1.6609e-01,  8.7927e-02, -2.3631e-01],\n        [-1.9501e-02, -3.2305e-01, -1.4764e-01, -2.1163e-01, -1.5895e-01,\n         -9.4213e-03, -2.2316e-01, -1.4945e-01],\n        [-2.5642e-01, -1.0227e-01,  3.0523e-01, -2.7030e-03, -1.2348e-01,\n          2.7537e-01, -1.0461e-01,  3.5225e-01],\n        [-9.0018e-03,  9.3527e-02, -3.2562e-01,  1.5013e-01,  3.5062e-01,\n         -2.5874e-01, -7.4812e-02,  2.1117e-01],\n        [ 2.0594e-01,  3.2670e-01, -1.1324e-01, -2.8645e-03,  3.3214e-01,\n          3.4548e-01, -1.5988e-02, -1.7572e-01],\n        [-2.2948e-01,  6.8374e-02, -3.0331e-01,  3.1060e-01, -1.3352e-01,\n          6.0794e-02, -1.7058e-01,  1.7056e-01],\n        [-2.4450e-01, -1.5986e-01, -1.9113e-02, -6.7679e-02,  2.5192e-02,\n          2.7470e-01, -3.1972e-01, -2.8318e-01],\n        [-2.8108e-01,  2.0774e-01,  2.8815e-01, -2.9622e-01, -1.5852e-01,\n         -2.5688e-01,  6.1480e-02, -4.1972e-02],\n        [ 1.0148e-01, -3.2460e-02, -1.0369e-01,  2.4053e-01, -1.9449e-01,\n         -2.7994e-01, -1.1149e-01, -4.7537e-02],\n        [-2.1339e-02,  1.7218e-01, -2.9532e-01, -1.7316e-01,  6.0807e-02,\n         -6.4976e-02,  1.2703e-01, -4.4490e-02],\n        [ 2.0826e-01, -1.7215e-02, -1.0305e-01,  2.4996e-01,  9.6769e-02,\n          2.3138e-01, -2.6655e-01, -1.8788e-02],\n        [ 1.6551e-01, -1.7928e-01, -2.5768e-01,  7.6203e-02, -1.4544e-01,\n         -1.5516e-01, -3.3760e-01,  1.1063e-01],\n        [-3.0398e-01, -8.3862e-02, -1.5386e-01,  8.7272e-03, -6.8568e-02,\n         -1.1654e-01, -1.1179e-01, -1.1718e-01],\n        [-3.0293e-01, -1.4076e-01, -9.8619e-02, -1.4865e-01, -1.2219e-01,\n         -2.0758e-01,  1.9145e-01,  3.4505e-01],\n        [ 1.2936e-01, -6.7793e-02, -3.8054e-02,  8.6346e-02, -1.8065e-01,\n          2.2912e-01, -6.9902e-02, -3.0107e-01],\n        [-3.4807e-01, -3.4079e-01, -7.0089e-02,  2.8030e-01, -2.5730e-01,\n         -2.5842e-01, -2.2710e-01, -2.8169e-01],\n        [ 2.6490e-01, -1.4361e-01, -2.0837e-01, -3.2138e-01,  1.8523e-01,\n         -3.3304e-01,  3.1379e-01,  1.5206e-01],\n        [-1.9504e-01,  1.9182e-01, -2.1087e-01,  1.8325e-01,  3.1177e-01,\n          1.9970e-01, -3.3888e-01, -7.7813e-02],\n        [ 2.8510e-01,  5.4763e-02, -2.1489e-01,  2.4839e-01,  2.6793e-01,\n         -1.0310e-01, -2.0917e-01, -3.3495e-01],\n        [-1.5304e-01,  1.1914e-01,  2.9359e-02,  1.6057e-02,  1.8206e-01,\n          2.1235e-01,  7.7047e-02,  1.7106e-01],\n        [-2.5368e-01, -3.0460e-01, -2.3002e-01,  2.9500e-02,  7.3685e-03,\n         -7.5048e-02, -1.8398e-02,  2.7237e-01],\n        [ 2.3825e-01, -1.5854e-01,  2.3967e-01,  5.3618e-02, -3.4388e-01,\n          5.2562e-02,  9.1338e-02,  4.0347e-02],\n        [ 1.8178e-01, -3.0895e-01,  1.5459e-02, -2.2258e-01,  3.9166e-02,\n          6.6160e-03, -1.2512e-01,  2.4677e-01],\n        [-2.6667e-01, -9.1566e-02,  3.6928e-02, -3.4971e-01,  7.8712e-02,\n         -3.6623e-02,  3.2123e-01,  3.4287e-01],\n        [ 2.4404e-01,  1.0403e-01,  2.1778e-01,  1.3355e-01,  1.8468e-02,\n         -1.4683e-01, -2.7425e-01, -1.6322e-01],\n        [ 3.4556e-01, -1.9557e-01,  3.4767e-01,  3.2776e-02,  2.2006e-01,\n          1.6697e-02,  2.7581e-01, -1.8384e-01],\n        [ 1.8988e-01, -2.9508e-01, -1.8520e-01, -3.2878e-01, -2.9884e-01,\n         -2.7608e-01, -2.7269e-02,  2.2056e-01],\n        [ 9.8560e-02,  2.2339e-01, -2.9683e-01, -2.5393e-01,  4.3087e-02,\n         -2.7298e-01,  1.8686e-01, -2.3379e-01],\n        [ 3.0837e-01, -3.3320e-01,  8.9406e-02,  1.4946e-01, -2.7256e-01,\n          1.7244e-01,  9.8141e-02, -2.5413e-01],\n        [ 3.4336e-01,  1.5647e-01, -5.0506e-02,  3.3853e-01,  1.9272e-01,\n          1.7300e-01,  1.8994e-01,  2.7639e-01],\n        [-2.9966e-01, -2.6563e-01, -1.1578e-01, -6.9751e-02, -1.7167e-01,\n          2.0705e-01,  7.3627e-02, -3.0888e-01],\n        [ 1.7544e-01,  3.4615e-01,  1.2680e-01,  6.0797e-02,  1.1713e-01,\n         -1.4870e-02, -1.6568e-01,  2.0612e-01],\n        [-5.3151e-02,  1.0030e-02, -1.4634e-01,  2.9233e-01,  5.8484e-02,\n          1.4510e-02, -1.1585e-01,  1.4346e-01],\n        [ 2.6352e-01,  5.7373e-02,  1.0150e-01, -6.4162e-02, -2.0588e-01,\n          2.2283e-01,  3.4244e-01, -2.7314e-01],\n        [ 2.3152e-01,  2.7072e-01, -2.3505e-01, -3.1277e-01, -1.1945e-01,\n          1.4334e-01, -1.6326e-01, -1.5286e-01],\n        [ 1.0497e-01,  6.1306e-02,  2.3896e-01,  1.8319e-01, -1.9102e-02,\n         -2.3845e-01, -1.3288e-02,  2.8928e-01],\n        [ 1.8052e-01,  3.5178e-01, -2.0458e-01, -2.8842e-01, -3.2414e-01,\n          7.5499e-02,  8.1792e-02, -2.6351e-01],\n        [ 3.0981e-01, -2.7869e-01,  4.6513e-02,  2.6186e-01,  2.6509e-01,\n         -2.0375e-01,  2.9297e-01, -8.0528e-02],\n        [-1.9229e-01,  3.4885e-01, -1.1607e-02,  2.4606e-01,  3.2566e-01,\n         -2.4603e-01, -1.2083e-01,  1.1405e-01],\n        [-9.3578e-02,  1.1085e-02, -9.5389e-02, -9.7262e-02, -2.9010e-01,\n         -9.1161e-03,  2.2772e-01, -8.2062e-02],\n        [-1.2774e-02, -1.9184e-01, -6.9042e-02,  2.7988e-01, -1.5178e-01,\n         -2.7537e-01,  3.2982e-01,  2.6538e-01],\n        [ 2.7035e-01, -1.9080e-01,  1.1241e-01,  1.7202e-02,  1.1997e-01,\n         -2.2449e-01,  3.2811e-01, -2.0368e-01],\n        [-2.1338e-01, -2.5084e-01,  1.7792e-01, -1.9056e-01, -1.9033e-01,\n         -1.7338e-01, -2.4208e-01,  7.8922e-02],\n        [ 2.7424e-01,  2.3863e-01,  1.6264e-01, -1.0704e-01, -1.2138e-01,\n         -1.0146e-01, -7.2116e-02, -1.4134e-01],\n        [-2.0937e-01,  1.6128e-01, -1.3417e-01, -7.8315e-02,  1.0354e-01,\n         -2.1639e-01, -2.0475e-02, -2.8473e-01],\n        [-6.1529e-02, -2.2299e-01,  2.3304e-01, -2.1268e-01, -5.6665e-02,\n          4.2763e-02,  2.4605e-01, -1.1324e-01],\n        [-3.1389e-01, -2.5900e-01,  2.3669e-01, -2.0634e-01, -5.9854e-02,\n         -1.8085e-01, -9.9581e-02,  3.1288e-01],\n        [-6.1082e-02,  3.5837e-02, -1.7308e-01,  3.2516e-03, -3.0043e-01,\n          2.0556e-01, -2.3806e-02, -1.9219e-01],\n        [ 1.3729e-01,  6.6322e-02, -3.5026e-01, -2.3907e-01,  2.0389e-01,\n         -2.6039e-01,  1.0656e-01, -4.3837e-04],\n        [-3.2896e-01,  5.1711e-02,  3.1792e-01,  7.9727e-02, -1.3793e-01,\n         -1.5293e-01, -2.4513e-01, -1.7064e-01],\n        [ 8.6033e-02, -3.0314e-01, -2.8945e-01, -2.2719e-01, -1.2662e-01,\n          2.3399e-01, -8.0186e-02, -1.7946e-01],\n        [-3.2126e-01, -7.0643e-02, -3.3370e-01, -3.5002e-01, -3.3206e-02,\n          1.9336e-01,  1.1382e-01,  1.1214e-01],\n        [-1.5770e-01,  1.8227e-02, -2.8412e-01,  8.0047e-02, -3.4993e-02,\n         -2.6020e-01,  3.0071e-01, -2.1384e-01],\n        [ 2.2583e-01,  8.1394e-02, -2.6654e-01, -9.0914e-02,  1.6657e-01,\n          1.9020e-01,  2.3334e-01,  3.2647e-03],\n        [ 2.1211e-01, -2.7148e-01,  3.5303e-01, -4.1527e-02, -3.1466e-01,\n          1.9019e-01, -1.1765e-01,  2.8230e-01],\n        [ 3.3421e-01,  9.7885e-02,  7.6637e-02, -2.2730e-01,  3.2318e-01,\n          4.3574e-02, -1.9100e-02,  2.3913e-01],\n        [-1.2359e-01, -8.1210e-02,  1.5894e-02,  2.0074e-01,  3.5217e-02,\n          2.8286e-01, -2.9045e-01, -2.4619e-01],\n        [-1.2205e-01, -6.6623e-02, -3.2035e-01,  1.3626e-03, -1.1936e-01,\n          7.8536e-02, -3.5061e-01, -3.1136e-02],\n        [ 1.3043e-01, -3.2438e-01, -2.4063e-01, -6.9433e-02, -3.4560e-01,\n         -6.5277e-02, -1.4744e-02, -4.4847e-03],\n        [ 3.3641e-02, -3.0259e-02,  7.5978e-02,  3.2383e-02, -2.1644e-01,\n          1.8734e-01,  1.8450e-02,  3.2353e-01],\n        [ 1.2924e-01,  1.5500e-01, -7.7680e-02,  1.1270e-02, -2.1194e-01,\n          1.8712e-01, -2.9331e-02, -2.1688e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1271,  0.2075, -0.1471, -0.0831,  0.2246,  0.0034, -0.0167, -0.2074,\n         0.3093, -0.2071, -0.3051,  0.1315,  0.1792, -0.3034, -0.0879,  0.2309,\n         0.2858,  0.0211,  0.3123,  0.2114, -0.0689, -0.0015,  0.0154,  0.2511,\n         0.2135,  0.0098, -0.3116,  0.0090,  0.0680, -0.2855,  0.1155,  0.3319,\n         0.1114,  0.2917,  0.2519, -0.0194, -0.1902, -0.2910,  0.1028, -0.0695,\n         0.0542,  0.0820,  0.2251,  0.0911,  0.0030, -0.3502, -0.0390,  0.0366,\n        -0.1958,  0.1330,  0.2847,  0.1442,  0.1453, -0.1450, -0.1911,  0.1024,\n         0.2283,  0.2269,  0.3487,  0.0356, -0.1823, -0.0307,  0.0553, -0.1936,\n         0.1081, -0.3127, -0.1360, -0.3465, -0.1461, -0.2488,  0.0407,  0.3034,\n        -0.2193,  0.1434, -0.3414, -0.1681,  0.2320,  0.1744,  0.1585,  0.0674,\n        -0.0412,  0.3299,  0.2614,  0.1331,  0.0873,  0.0182, -0.1711, -0.0509,\n         0.0660, -0.2072,  0.3023, -0.1433,  0.0269, -0.1858,  0.2540, -0.1045,\n        -0.2352, -0.2071,  0.3354, -0.0649], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0402,  0.0811,  0.0491,  ...,  0.0433, -0.0354,  0.0450],\n        [ 0.0542, -0.0100, -0.0021,  ...,  0.0304,  0.0934,  0.0584],\n        [-0.0615, -0.0883,  0.0958,  ..., -0.0969, -0.0326, -0.0208],\n        ...,\n        [-0.0212,  0.0778, -0.0771,  ...,  0.0765,  0.0095, -0.0222],\n        [-0.0177,  0.0802,  0.0037,  ..., -0.0184, -0.0610, -0.0327],\n        [-0.0350,  0.0254,  0.0638,  ...,  0.0851, -0.0026,  0.0981]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0511,  0.0734,  0.0383,  0.0922,  0.0584,  0.0574,  0.0655, -0.0951,\n         0.0838, -0.0997, -0.0868, -0.0767,  0.0855, -0.0994, -0.0740,  0.0358,\n         0.0432,  0.0666, -0.0533, -0.0848, -0.0101, -0.0554,  0.0467,  0.0372,\n         0.0167, -0.0404, -0.0390,  0.0301, -0.0010,  0.0003, -0.0445,  0.0909,\n         0.0846,  0.0827, -0.0622,  0.0667,  0.0977, -0.0611,  0.0607, -0.0729,\n        -0.0389,  0.0542, -0.0548, -0.0175, -0.0635, -0.0703, -0.0760, -0.0061,\n         0.0871,  0.0281, -0.0670,  0.0250, -0.0025,  0.0263,  0.0252,  0.0294,\n        -0.0037,  0.0697, -0.0164, -0.0463, -0.0637, -0.0223,  0.0495, -0.0050,\n         0.0102,  0.0778,  0.0834, -0.0812,  0.0924,  0.0859,  0.0227, -0.0288,\n         0.0487, -0.0243,  0.0284, -0.0635, -0.0779,  0.0291, -0.0355,  0.0918,\n         0.0598, -0.0671,  0.0747, -0.0354, -0.0810, -0.0181, -0.0513,  0.0456,\n        -0.0882,  0.0760,  0.0727, -0.0720, -0.0423, -0.0374,  0.0501,  0.0146,\n        -0.0877,  0.0069, -0.0755, -0.0859], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0913,  0.0149,  0.0035, -0.0239, -0.0920, -0.0768, -0.0511,  0.0369,\n         -0.0410, -0.0506,  0.0987, -0.0953,  0.0055,  0.0704, -0.0545,  0.0354,\n         -0.0542,  0.0354, -0.0167,  0.0971,  0.0372, -0.0939, -0.0377,  0.0575,\n         -0.0951,  0.0464, -0.0675,  0.0328,  0.0198, -0.0046, -0.0836,  0.0441,\n          0.0391,  0.0415, -0.0485, -0.0035, -0.0631, -0.0593, -0.0473, -0.0986,\n          0.0525,  0.0820,  0.0742,  0.0948,  0.0917, -0.0049, -0.0389,  0.0521,\n          0.0942, -0.0031,  0.0103, -0.0824, -0.0760, -0.0318,  0.0996, -0.0173,\n         -0.0411, -0.0748, -0.0539, -0.0682, -0.0861,  0.0839,  0.0866,  0.0664,\n         -0.0673, -0.0061, -0.0324, -0.0067,  0.0915, -0.0048, -0.0260,  0.0612,\n          0.0176,  0.0380,  0.0006,  0.0486,  0.0698,  0.0873, -0.0447, -0.0631,\n          0.0697,  0.0249,  0.0690,  0.0628,  0.0289,  0.0931, -0.0098,  0.0641,\n          0.0294, -0.0006,  0.0942,  0.0174, -0.0546,  0.0191, -0.0200, -0.0732,\n          0.0847, -0.0522, -0.0668,  0.0967],\n        [ 0.0804,  0.0821, -0.0157, -0.0051, -0.0849, -0.0582,  0.0215, -0.0385,\n         -0.0156,  0.0519,  0.0122, -0.0330, -0.0488, -0.0051,  0.0757,  0.0024,\n         -0.0847,  0.0528,  0.0178, -0.1000,  0.0643,  0.0039, -0.0644,  0.0489,\n         -0.0943, -0.0676, -0.0385,  0.0554,  0.0196,  0.0195,  0.0560, -0.0511,\n         -0.0936, -0.0005, -0.0262, -0.0973,  0.0624,  0.0389,  0.0466,  0.0119,\n         -0.0638,  0.0930,  0.0328, -0.0665,  0.0549, -0.0148,  0.0519, -0.0527,\n          0.0074,  0.0359,  0.0444, -0.0736, -0.0004,  0.0624, -0.0549, -0.0924,\n          0.0295, -0.0962,  0.0441,  0.0540,  0.0637,  0.0560,  0.0173, -0.0596,\n         -0.0844, -0.0366,  0.0478, -0.0721,  0.0103, -0.0615, -0.0323, -0.0102,\n         -0.0450,  0.0648,  0.0945,  0.0476,  0.0505,  0.0111,  0.0148,  0.0018,\n         -0.0065,  0.0542, -0.0229, -0.0130,  0.0252, -0.0468,  0.0687,  0.0111,\n          0.0162,  0.0576, -0.0264, -0.0372,  0.0994,  0.0399, -0.0877, -0.0945,\n          0.0818, -0.0717, -0.0733, -0.0276],\n        [ 0.0167, -0.0785, -0.0306,  0.0369, -0.0314,  0.0875, -0.0837,  0.0523,\n         -0.0842, -0.0116,  0.0358,  0.0560,  0.0073,  0.0129, -0.0365, -0.0020,\n         -0.0956,  0.0527, -0.0596,  0.0571,  0.0856,  0.0779, -0.0099, -0.0878,\n         -0.0656, -0.0622,  0.0918, -0.0219, -0.0980, -0.0796, -0.0692, -0.0741,\n          0.0477,  0.0387,  0.0164, -0.0977,  0.0081, -0.0949, -0.0844,  0.0605,\n          0.0044,  0.0204, -0.0275, -0.0714,  0.0993,  0.0030,  0.0046,  0.0930,\n         -0.0265,  0.0205,  0.0638,  0.0126,  0.0089,  0.0825, -0.0307, -0.0228,\n         -0.0026,  0.0284,  0.0509,  0.0460,  0.0328,  0.0102,  0.0234,  0.0671,\n          0.0145, -0.0750, -0.0050,  0.0324,  0.0751,  0.0147,  0.0317, -0.0286,\n         -0.0094, -0.0293,  0.0264,  0.0180,  0.0095,  0.0169, -0.0033,  0.0993,\n         -0.0879,  0.0807, -0.0446,  0.0427,  0.0576,  0.0156,  0.0165, -0.0001,\n          0.0648, -0.0756,  0.0492, -0.0454,  0.0483, -0.0720, -0.0652, -0.0182,\n         -0.0505, -0.0008, -0.0933,  0.0362],\n        [ 0.0513,  0.0158, -0.0235,  0.0568,  0.0115,  0.0435,  0.0470, -0.0918,\n         -0.0106,  0.0333, -0.0130, -0.0914, -0.0404, -0.0201,  0.0427, -0.0580,\n          0.0425,  0.0683,  0.0920,  0.0757,  0.0466,  0.0425, -0.0111, -0.0332,\n         -0.0774,  0.0107, -0.0152, -0.0077, -0.0742, -0.0951, -0.0377, -0.0487,\n          0.0715,  0.0029,  0.0960,  0.0124,  0.0021, -0.0109,  0.0945,  0.0610,\n          0.0287, -0.0484,  0.0944, -0.0256,  0.0056,  0.0496, -0.0739, -0.0706,\n          0.0203, -0.0742,  0.0665, -0.0006, -0.0237, -0.0448,  0.0076, -0.0202,\n         -0.0881,  0.0669, -0.0953, -0.0644, -0.0163,  0.0254, -0.0904, -0.0449,\n          0.0178,  0.0565,  0.0398,  0.0456, -0.0494, -0.0355,  0.0391,  0.0314,\n         -0.0171,  0.0793, -0.0933,  0.0441,  0.0812,  0.0165,  0.0885,  0.0587,\n          0.0021,  0.0446,  0.0189,  0.0382, -0.0220, -0.0392,  0.0171, -0.0600,\n          0.0993,  0.0291,  0.0813,  0.0213, -0.0523, -0.0729,  0.0507, -0.0881,\n         -0.0559, -0.0190, -0.0963,  0.0157]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0583, -0.0337,  0.0621,  0.0023], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x72d89d34ee50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=100, bias=True)\n  (fc2): Linear(in_features=100, out_features=100, bias=True)\n  (fc3): Linear(in_features=100, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1271,  0.2075, -0.1471, -0.0831,  0.2246,  0.0034, -0.0167, -0.2074,\n         0.3093, -0.2071, -0.3051,  0.1315,  0.1792, -0.3034, -0.0879,  0.2309,\n         0.2858,  0.0211,  0.3123,  0.2114, -0.0689, -0.0015,  0.0154,  0.2511,\n         0.2135,  0.0098, -0.3116,  0.0090,  0.0680, -0.2855,  0.1155,  0.3319,\n         0.1114,  0.2917,  0.2519, -0.0194, -0.1902, -0.2910,  0.1028, -0.0695,\n         0.0542,  0.0820,  0.2251,  0.0911,  0.0030, -0.3502, -0.0390,  0.0366,\n        -0.1958,  0.1330,  0.2847,  0.1442,  0.1453, -0.1450, -0.1911,  0.1024,\n         0.2283,  0.2269,  0.3487,  0.0356, -0.1823, -0.0307,  0.0553, -0.1936,\n         0.1081, -0.3127, -0.1360, -0.3465, -0.1461, -0.2488,  0.0407,  0.3034,\n        -0.2193,  0.1434, -0.3414, -0.1681,  0.2320,  0.1744,  0.1585,  0.0674,\n        -0.0412,  0.3299,  0.2614,  0.1331,  0.0873,  0.0182, -0.1711, -0.0509,\n         0.0660, -0.2072,  0.3023, -0.1433,  0.0269, -0.1858,  0.2540, -0.1045,\n        -0.2352, -0.2071,  0.3354, -0.0649], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-1.5598e-01, -3.0099e-01, -2.9326e-01,  3.1474e-02, -1.8454e-01,\n          5.5659e-02, -2.7353e-01, -1.2534e-01],\n        [-1.2121e-01,  1.3053e-01, -3.0932e-01,  2.8667e-01,  1.7327e-01,\n         -1.1870e-01,  1.8206e-01, -2.1928e-01],\n        [ 2.5708e-01, -8.9370e-02, -2.3468e-02,  3.0206e-01,  5.1940e-02,\n         -2.4576e-01,  2.5859e-01, -2.6470e-02],\n        [-1.1385e-01, -9.7045e-02,  1.8304e-01, -2.6268e-01, -3.4449e-01,\n          2.6078e-01, -1.3021e-01,  2.9423e-01],\n        [-2.3573e-01,  2.4967e-01, -1.7861e-01, -8.5291e-02, -1.8173e-01,\n          2.8449e-01, -6.4315e-02,  3.4267e-01],\n        [-9.6293e-02, -4.2617e-02,  9.7647e-02, -1.5066e-01,  6.2639e-02,\n         -2.0940e-01, -2.9695e-01,  2.5168e-01],\n        [ 8.8571e-02,  4.1620e-02, -2.9595e-02,  2.6437e-01,  9.3322e-02,\n         -2.5477e-01,  1.4506e-01,  2.9315e-01],\n        [-3.2447e-01,  1.1244e-01, -6.5442e-02, -1.0266e-01, -1.8203e-01,\n         -3.3914e-01,  2.5605e-03, -2.8075e-01],\n        [-2.7278e-01,  1.1694e-01,  2.7555e-01,  1.1946e-01,  1.0064e-01,\n         -2.9768e-01,  1.8189e-01, -1.3071e-01],\n        [ 3.2403e-01, -5.3375e-02, -1.5364e-01, -1.3991e-01, -6.8683e-03,\n          7.7970e-03, -1.0211e-01, -2.1217e-01],\n        [-3.4734e-01, -9.4071e-02, -1.7460e-01,  5.4786e-02,  1.5726e-01,\n          2.1793e-01, -9.4554e-02,  5.4456e-02],\n        [-3.4219e-01, -2.5021e-01, -1.1667e-01,  1.2315e-01,  2.8269e-01,\n         -2.7223e-01,  2.6421e-01, -2.5581e-02],\n        [ 3.0568e-01, -1.7804e-01,  2.8423e-01,  3.4089e-01,  6.8294e-02,\n         -1.4299e-01,  2.0273e-01,  1.8669e-01],\n        [ 1.8553e-01,  2.9842e-02,  3.0369e-01,  1.6752e-01,  2.5268e-01,\n         -1.9719e-01,  3.3461e-01, -5.4270e-02],\n        [ 2.7203e-01, -3.2242e-01, -5.7426e-03, -2.3155e-01,  3.8836e-02,\n         -1.5152e-01,  5.3070e-02, -2.7220e-01],\n        [-3.9289e-02,  2.7080e-01,  4.5924e-02,  1.1141e-01,  2.2820e-01,\n         -2.3195e-01, -2.1251e-02,  1.9848e-01],\n        [-2.5113e-02, -1.5282e-01, -7.8606e-02,  2.9973e-01, -3.3337e-01,\n          1.1461e-01, -2.3336e-01,  7.2714e-02],\n        [ 2.4375e-01,  2.1411e-01, -3.1400e-01, -1.1082e-01,  1.9912e-01,\n          1.8557e-01, -6.1920e-02, -3.0944e-01],\n        [-9.3738e-03,  1.9120e-01, -2.7795e-01,  3.1293e-01, -3.0041e-01,\n         -9.7273e-03, -2.7549e-01, -2.0713e-01],\n        [ 2.9003e-01, -3.9129e-02, -1.2661e-01,  1.4836e-01,  7.4434e-02,\n         -1.2162e-02,  2.9188e-02, -3.1994e-01],\n        [-1.0324e-01, -3.5168e-02,  3.3651e-01, -1.9018e-01, -3.4339e-01,\n         -3.0602e-01,  1.9042e-01,  2.6353e-01],\n        [-8.8535e-02, -3.5218e-01,  1.3642e-01,  1.3507e-01,  2.4807e-01,\n         -2.0946e-01, -1.5415e-01, -1.2485e-01],\n        [-2.5038e-01,  3.1205e-01,  3.9343e-02,  1.5970e-01,  1.7415e-01,\n          2.6627e-03,  2.9856e-02,  2.0457e-01],\n        [-6.6630e-02, -3.4606e-01,  7.2220e-02,  6.5882e-02, -2.3766e-01,\n         -2.4818e-01,  1.5072e-01,  3.1079e-01],\n        [-4.9753e-02,  2.6672e-01, -6.9782e-02, -3.1612e-01,  1.3457e-02,\n          1.4832e-01, -2.5775e-01,  2.5478e-01],\n        [-3.3467e-01, -3.5062e-01, -3.0031e-01,  1.2333e-01, -1.5802e-01,\n         -3.1066e-01, -3.4295e-01,  8.9088e-02],\n        [ 1.8393e-01,  2.6508e-01, -3.7786e-02,  6.7588e-02,  2.4390e-02,\n         -5.2164e-02, -2.6658e-01,  3.2638e-01],\n        [-1.8355e-01,  9.8692e-03,  1.4339e-01,  1.1150e-01, -2.4158e-01,\n         -3.1011e-01, -1.1040e-01, -3.0979e-01],\n        [ 2.0735e-02, -1.1490e-01, -2.9761e-01, -1.2019e-01, -1.9299e-02,\n          9.0661e-02, -1.1384e-01,  2.8843e-02],\n        [-3.4480e-01,  9.8749e-02,  1.0259e-04, -1.3197e-01, -5.7926e-02,\n         -1.6919e-01, -2.8898e-01,  1.0812e-01],\n        [-3.8207e-02,  3.0045e-01,  1.4505e-01, -1.5509e-01,  1.8151e-02,\n         -1.9584e-01,  2.2190e-01, -3.3512e-01],\n        [ 2.0161e-01,  1.4506e-01,  3.1519e-01,  1.8541e-01, -1.6184e-01,\n         -1.2764e-01,  5.1779e-02, -5.1317e-03],\n        [-7.1249e-02,  3.3140e-01, -2.6783e-01, -2.1022e-01, -3.3390e-01,\n         -7.5485e-02, -1.5076e-01, -2.6093e-01],\n        [-1.9038e-01, -9.9788e-02,  3.4857e-01,  1.1216e-01, -2.8092e-01,\n         -2.6164e-01,  1.5391e-01,  2.2825e-01],\n        [ 7.1679e-02, -2.5886e-01,  8.8757e-02,  3.2042e-01, -2.4658e-01,\n         -1.9474e-01,  2.6754e-02, -4.4401e-02],\n        [ 2.0330e-01,  1.6944e-01, -2.2389e-01,  8.1403e-02, -1.9750e-01,\n         -2.2359e-01,  1.2673e-01,  7.2547e-02],\n        [-2.3713e-01, -2.6153e-01, -2.0053e-01,  1.5421e-01, -9.4448e-02,\n         -2.3059e-01, -1.5144e-01, -3.3573e-01],\n        [ 4.5558e-02,  1.8764e-01,  1.4525e-01, -2.7626e-01,  2.3375e-01,\n         -2.3891e-01, -3.3609e-01, -3.5525e-02],\n        [ 4.7761e-02,  1.9631e-01,  1.8123e-01,  1.5663e-01, -1.5872e-01,\n         -6.8108e-02,  3.1006e-01, -1.5903e-01],\n        [ 2.2163e-01,  1.4097e-01, -3.4184e-01, -2.4842e-01, -1.9187e-01,\n          1.6609e-01,  8.7927e-02, -2.3631e-01],\n        [-1.9501e-02, -3.2305e-01, -1.4764e-01, -2.1163e-01, -1.5895e-01,\n         -9.4213e-03, -2.2316e-01, -1.4945e-01],\n        [-2.5642e-01, -1.0227e-01,  3.0523e-01, -2.7030e-03, -1.2348e-01,\n          2.7537e-01, -1.0461e-01,  3.5225e-01],\n        [-9.0018e-03,  9.3527e-02, -3.2562e-01,  1.5013e-01,  3.5062e-01,\n         -2.5874e-01, -7.4812e-02,  2.1117e-01],\n        [ 2.0594e-01,  3.2670e-01, -1.1324e-01, -2.8645e-03,  3.3214e-01,\n          3.4548e-01, -1.5988e-02, -1.7572e-01],\n        [-2.2948e-01,  6.8374e-02, -3.0331e-01,  3.1060e-01, -1.3352e-01,\n          6.0794e-02, -1.7058e-01,  1.7056e-01],\n        [-2.4450e-01, -1.5986e-01, -1.9113e-02, -6.7679e-02,  2.5192e-02,\n          2.7470e-01, -3.1972e-01, -2.8318e-01],\n        [-2.8108e-01,  2.0774e-01,  2.8815e-01, -2.9622e-01, -1.5852e-01,\n         -2.5688e-01,  6.1480e-02, -4.1972e-02],\n        [ 1.0148e-01, -3.2460e-02, -1.0369e-01,  2.4053e-01, -1.9449e-01,\n         -2.7994e-01, -1.1149e-01, -4.7537e-02],\n        [-2.1339e-02,  1.7218e-01, -2.9532e-01, -1.7316e-01,  6.0807e-02,\n         -6.4976e-02,  1.2703e-01, -4.4490e-02],\n        [ 2.0826e-01, -1.7215e-02, -1.0305e-01,  2.4996e-01,  9.6769e-02,\n          2.3138e-01, -2.6655e-01, -1.8788e-02],\n        [ 1.6551e-01, -1.7928e-01, -2.5768e-01,  7.6203e-02, -1.4544e-01,\n         -1.5516e-01, -3.3760e-01,  1.1063e-01],\n        [-3.0398e-01, -8.3862e-02, -1.5386e-01,  8.7272e-03, -6.8568e-02,\n         -1.1654e-01, -1.1179e-01, -1.1718e-01],\n        [-3.0293e-01, -1.4076e-01, -9.8619e-02, -1.4865e-01, -1.2219e-01,\n         -2.0758e-01,  1.9145e-01,  3.4505e-01],\n        [ 1.2936e-01, -6.7793e-02, -3.8054e-02,  8.6346e-02, -1.8065e-01,\n          2.2912e-01, -6.9902e-02, -3.0107e-01],\n        [-3.4807e-01, -3.4079e-01, -7.0089e-02,  2.8030e-01, -2.5730e-01,\n         -2.5842e-01, -2.2710e-01, -2.8169e-01],\n        [ 2.6490e-01, -1.4361e-01, -2.0837e-01, -3.2138e-01,  1.8523e-01,\n         -3.3304e-01,  3.1379e-01,  1.5206e-01],\n        [-1.9504e-01,  1.9182e-01, -2.1087e-01,  1.8325e-01,  3.1177e-01,\n          1.9970e-01, -3.3888e-01, -7.7813e-02],\n        [ 2.8510e-01,  5.4763e-02, -2.1489e-01,  2.4839e-01,  2.6793e-01,\n         -1.0310e-01, -2.0917e-01, -3.3495e-01],\n        [-1.5304e-01,  1.1914e-01,  2.9359e-02,  1.6057e-02,  1.8206e-01,\n          2.1235e-01,  7.7047e-02,  1.7106e-01],\n        [-2.5368e-01, -3.0460e-01, -2.3002e-01,  2.9500e-02,  7.3685e-03,\n         -7.5048e-02, -1.8398e-02,  2.7237e-01],\n        [ 2.3825e-01, -1.5854e-01,  2.3967e-01,  5.3618e-02, -3.4388e-01,\n          5.2562e-02,  9.1338e-02,  4.0347e-02],\n        [ 1.8178e-01, -3.0895e-01,  1.5459e-02, -2.2258e-01,  3.9166e-02,\n          6.6160e-03, -1.2512e-01,  2.4677e-01],\n        [-2.6667e-01, -9.1566e-02,  3.6928e-02, -3.4971e-01,  7.8712e-02,\n         -3.6623e-02,  3.2123e-01,  3.4287e-01],\n        [ 2.4404e-01,  1.0403e-01,  2.1778e-01,  1.3355e-01,  1.8468e-02,\n         -1.4683e-01, -2.7425e-01, -1.6322e-01],\n        [ 3.4556e-01, -1.9557e-01,  3.4767e-01,  3.2776e-02,  2.2006e-01,\n          1.6697e-02,  2.7581e-01, -1.8384e-01],\n        [ 1.8988e-01, -2.9508e-01, -1.8520e-01, -3.2878e-01, -2.9884e-01,\n         -2.7608e-01, -2.7269e-02,  2.2056e-01],\n        [ 9.8560e-02,  2.2339e-01, -2.9683e-01, -2.5393e-01,  4.3087e-02,\n         -2.7298e-01,  1.8686e-01, -2.3379e-01],\n        [ 3.0837e-01, -3.3320e-01,  8.9406e-02,  1.4946e-01, -2.7256e-01,\n          1.7244e-01,  9.8141e-02, -2.5413e-01],\n        [ 3.4336e-01,  1.5647e-01, -5.0506e-02,  3.3853e-01,  1.9272e-01,\n          1.7300e-01,  1.8994e-01,  2.7639e-01],\n        [-2.9966e-01, -2.6563e-01, -1.1578e-01, -6.9751e-02, -1.7167e-01,\n          2.0705e-01,  7.3627e-02, -3.0888e-01],\n        [ 1.7544e-01,  3.4615e-01,  1.2680e-01,  6.0797e-02,  1.1713e-01,\n         -1.4870e-02, -1.6568e-01,  2.0612e-01],\n        [-5.3151e-02,  1.0030e-02, -1.4634e-01,  2.9233e-01,  5.8484e-02,\n          1.4510e-02, -1.1585e-01,  1.4346e-01],\n        [ 2.6352e-01,  5.7373e-02,  1.0150e-01, -6.4162e-02, -2.0588e-01,\n          2.2283e-01,  3.4244e-01, -2.7314e-01],\n        [ 2.3152e-01,  2.7072e-01, -2.3505e-01, -3.1277e-01, -1.1945e-01,\n          1.4334e-01, -1.6326e-01, -1.5286e-01],\n        [ 1.0497e-01,  6.1306e-02,  2.3896e-01,  1.8319e-01, -1.9102e-02,\n         -2.3845e-01, -1.3288e-02,  2.8928e-01],\n        [ 1.8052e-01,  3.5178e-01, -2.0458e-01, -2.8842e-01, -3.2414e-01,\n          7.5499e-02,  8.1792e-02, -2.6351e-01],\n        [ 3.0981e-01, -2.7869e-01,  4.6513e-02,  2.6186e-01,  2.6509e-01,\n         -2.0375e-01,  2.9297e-01, -8.0528e-02],\n        [-1.9229e-01,  3.4885e-01, -1.1607e-02,  2.4606e-01,  3.2566e-01,\n         -2.4603e-01, -1.2083e-01,  1.1405e-01],\n        [-9.3578e-02,  1.1085e-02, -9.5389e-02, -9.7262e-02, -2.9010e-01,\n         -9.1161e-03,  2.2772e-01, -8.2062e-02],\n        [-1.2774e-02, -1.9184e-01, -6.9042e-02,  2.7988e-01, -1.5178e-01,\n         -2.7537e-01,  3.2982e-01,  2.6538e-01],\n        [ 2.7035e-01, -1.9080e-01,  1.1241e-01,  1.7202e-02,  1.1997e-01,\n         -2.2449e-01,  3.2811e-01, -2.0368e-01],\n        [-2.1338e-01, -2.5084e-01,  1.7792e-01, -1.9056e-01, -1.9033e-01,\n         -1.7338e-01, -2.4208e-01,  7.8922e-02],\n        [ 2.7424e-01,  2.3863e-01,  1.6264e-01, -1.0704e-01, -1.2138e-01,\n         -1.0146e-01, -7.2116e-02, -1.4134e-01],\n        [-2.0937e-01,  1.6128e-01, -1.3417e-01, -7.8315e-02,  1.0354e-01,\n         -2.1639e-01, -2.0475e-02, -2.8473e-01],\n        [-6.1529e-02, -2.2299e-01,  2.3304e-01, -2.1268e-01, -5.6665e-02,\n          4.2763e-02,  2.4605e-01, -1.1324e-01],\n        [-3.1389e-01, -2.5900e-01,  2.3669e-01, -2.0634e-01, -5.9854e-02,\n         -1.8085e-01, -9.9581e-02,  3.1288e-01],\n        [-6.1082e-02,  3.5837e-02, -1.7308e-01,  3.2516e-03, -3.0043e-01,\n          2.0556e-01, -2.3806e-02, -1.9219e-01],\n        [ 1.3729e-01,  6.6322e-02, -3.5026e-01, -2.3907e-01,  2.0389e-01,\n         -2.6039e-01,  1.0656e-01, -4.3837e-04],\n        [-3.2896e-01,  5.1711e-02,  3.1792e-01,  7.9727e-02, -1.3793e-01,\n         -1.5293e-01, -2.4513e-01, -1.7064e-01],\n        [ 8.6033e-02, -3.0314e-01, -2.8945e-01, -2.2719e-01, -1.2662e-01,\n          2.3399e-01, -8.0186e-02, -1.7946e-01],\n        [-3.2126e-01, -7.0643e-02, -3.3370e-01, -3.5002e-01, -3.3206e-02,\n          1.9336e-01,  1.1382e-01,  1.1214e-01],\n        [-1.5770e-01,  1.8227e-02, -2.8412e-01,  8.0047e-02, -3.4993e-02,\n         -2.6020e-01,  3.0071e-01, -2.1384e-01],\n        [ 2.2583e-01,  8.1394e-02, -2.6654e-01, -9.0914e-02,  1.6657e-01,\n          1.9020e-01,  2.3334e-01,  3.2647e-03],\n        [ 2.1211e-01, -2.7148e-01,  3.5303e-01, -4.1527e-02, -3.1466e-01,\n          1.9019e-01, -1.1765e-01,  2.8230e-01],\n        [ 3.3421e-01,  9.7885e-02,  7.6637e-02, -2.2730e-01,  3.2318e-01,\n          4.3574e-02, -1.9100e-02,  2.3913e-01],\n        [-1.2359e-01, -8.1210e-02,  1.5894e-02,  2.0074e-01,  3.5217e-02,\n          2.8286e-01, -2.9045e-01, -2.4619e-01],\n        [-1.2205e-01, -6.6623e-02, -3.2035e-01,  1.3626e-03, -1.1936e-01,\n          7.8536e-02, -3.5061e-01, -3.1136e-02],\n        [ 1.3043e-01, -3.2438e-01, -2.4063e-01, -6.9433e-02, -3.4560e-01,\n         -6.5277e-02, -1.4744e-02, -4.4847e-03],\n        [ 3.3641e-02, -3.0259e-02,  7.5978e-02,  3.2383e-02, -2.1644e-01,\n          1.8734e-01,  1.8450e-02,  3.2353e-01],\n        [ 1.2924e-01,  1.5500e-01, -7.7680e-02,  1.1270e-02, -2.1194e-01,\n          1.8712e-01, -2.9331e-02, -2.1688e-01]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=100, out_features=100, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0511,  0.0734,  0.0383,  0.0922,  0.0584,  0.0574,  0.0655, -0.0951,\n         0.0838, -0.0997, -0.0868, -0.0767,  0.0855, -0.0994, -0.0740,  0.0358,\n         0.0432,  0.0666, -0.0533, -0.0848, -0.0101, -0.0554,  0.0467,  0.0372,\n         0.0167, -0.0404, -0.0390,  0.0301, -0.0010,  0.0003, -0.0445,  0.0909,\n         0.0846,  0.0827, -0.0622,  0.0667,  0.0977, -0.0611,  0.0607, -0.0729,\n        -0.0389,  0.0542, -0.0548, -0.0175, -0.0635, -0.0703, -0.0760, -0.0061,\n         0.0871,  0.0281, -0.0670,  0.0250, -0.0025,  0.0263,  0.0252,  0.0294,\n        -0.0037,  0.0697, -0.0164, -0.0463, -0.0637, -0.0223,  0.0495, -0.0050,\n         0.0102,  0.0778,  0.0834, -0.0812,  0.0924,  0.0859,  0.0227, -0.0288,\n         0.0487, -0.0243,  0.0284, -0.0635, -0.0779,  0.0291, -0.0355,  0.0918,\n         0.0598, -0.0671,  0.0747, -0.0354, -0.0810, -0.0181, -0.0513,  0.0456,\n        -0.0882,  0.0760,  0.0727, -0.0720, -0.0423, -0.0374,  0.0501,  0.0146,\n        -0.0877,  0.0069, -0.0755, -0.0859], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0402,  0.0811,  0.0491,  ...,  0.0433, -0.0354,  0.0450],\n        [ 0.0542, -0.0100, -0.0021,  ...,  0.0304,  0.0934,  0.0584],\n        [-0.0615, -0.0883,  0.0958,  ..., -0.0969, -0.0326, -0.0208],\n        ...,\n        [-0.0212,  0.0778, -0.0771,  ...,  0.0765,  0.0095, -0.0222],\n        [-0.0177,  0.0802,  0.0037,  ..., -0.0184, -0.0610, -0.0327],\n        [-0.0350,  0.0254,  0.0638,  ...,  0.0851, -0.0026,  0.0981]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	100,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=100, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0583, -0.0337,  0.0621,  0.0023], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0913,  0.0149,  0.0035, -0.0239, -0.0920, -0.0768, -0.0511,  0.0369,\n         -0.0410, -0.0506,  0.0987, -0.0953,  0.0055,  0.0704, -0.0545,  0.0354,\n         -0.0542,  0.0354, -0.0167,  0.0971,  0.0372, -0.0939, -0.0377,  0.0575,\n         -0.0951,  0.0464, -0.0675,  0.0328,  0.0198, -0.0046, -0.0836,  0.0441,\n          0.0391,  0.0415, -0.0485, -0.0035, -0.0631, -0.0593, -0.0473, -0.0986,\n          0.0525,  0.0820,  0.0742,  0.0948,  0.0917, -0.0049, -0.0389,  0.0521,\n          0.0942, -0.0031,  0.0103, -0.0824, -0.0760, -0.0318,  0.0996, -0.0173,\n         -0.0411, -0.0748, -0.0539, -0.0682, -0.0861,  0.0839,  0.0866,  0.0664,\n         -0.0673, -0.0061, -0.0324, -0.0067,  0.0915, -0.0048, -0.0260,  0.0612,\n          0.0176,  0.0380,  0.0006,  0.0486,  0.0698,  0.0873, -0.0447, -0.0631,\n          0.0697,  0.0249,  0.0690,  0.0628,  0.0289,  0.0931, -0.0098,  0.0641,\n          0.0294, -0.0006,  0.0942,  0.0174, -0.0546,  0.0191, -0.0200, -0.0732,\n          0.0847, -0.0522, -0.0668,  0.0967],\n        [ 0.0804,  0.0821, -0.0157, -0.0051, -0.0849, -0.0582,  0.0215, -0.0385,\n         -0.0156,  0.0519,  0.0122, -0.0330, -0.0488, -0.0051,  0.0757,  0.0024,\n         -0.0847,  0.0528,  0.0178, -0.1000,  0.0643,  0.0039, -0.0644,  0.0489,\n         -0.0943, -0.0676, -0.0385,  0.0554,  0.0196,  0.0195,  0.0560, -0.0511,\n         -0.0936, -0.0005, -0.0262, -0.0973,  0.0624,  0.0389,  0.0466,  0.0119,\n         -0.0638,  0.0930,  0.0328, -0.0665,  0.0549, -0.0148,  0.0519, -0.0527,\n          0.0074,  0.0359,  0.0444, -0.0736, -0.0004,  0.0624, -0.0549, -0.0924,\n          0.0295, -0.0962,  0.0441,  0.0540,  0.0637,  0.0560,  0.0173, -0.0596,\n         -0.0844, -0.0366,  0.0478, -0.0721,  0.0103, -0.0615, -0.0323, -0.0102,\n         -0.0450,  0.0648,  0.0945,  0.0476,  0.0505,  0.0111,  0.0148,  0.0018,\n         -0.0065,  0.0542, -0.0229, -0.0130,  0.0252, -0.0468,  0.0687,  0.0111,\n          0.0162,  0.0576, -0.0264, -0.0372,  0.0994,  0.0399, -0.0877, -0.0945,\n          0.0818, -0.0717, -0.0733, -0.0276],\n        [ 0.0167, -0.0785, -0.0306,  0.0369, -0.0314,  0.0875, -0.0837,  0.0523,\n         -0.0842, -0.0116,  0.0358,  0.0560,  0.0073,  0.0129, -0.0365, -0.0020,\n         -0.0956,  0.0527, -0.0596,  0.0571,  0.0856,  0.0779, -0.0099, -0.0878,\n         -0.0656, -0.0622,  0.0918, -0.0219, -0.0980, -0.0796, -0.0692, -0.0741,\n          0.0477,  0.0387,  0.0164, -0.0977,  0.0081, -0.0949, -0.0844,  0.0605,\n          0.0044,  0.0204, -0.0275, -0.0714,  0.0993,  0.0030,  0.0046,  0.0930,\n         -0.0265,  0.0205,  0.0638,  0.0126,  0.0089,  0.0825, -0.0307, -0.0228,\n         -0.0026,  0.0284,  0.0509,  0.0460,  0.0328,  0.0102,  0.0234,  0.0671,\n          0.0145, -0.0750, -0.0050,  0.0324,  0.0751,  0.0147,  0.0317, -0.0286,\n         -0.0094, -0.0293,  0.0264,  0.0180,  0.0095,  0.0169, -0.0033,  0.0993,\n         -0.0879,  0.0807, -0.0446,  0.0427,  0.0576,  0.0156,  0.0165, -0.0001,\n          0.0648, -0.0756,  0.0492, -0.0454,  0.0483, -0.0720, -0.0652, -0.0182,\n         -0.0505, -0.0008, -0.0933,  0.0362],\n        [ 0.0513,  0.0158, -0.0235,  0.0568,  0.0115,  0.0435,  0.0470, -0.0918,\n         -0.0106,  0.0333, -0.0130, -0.0914, -0.0404, -0.0201,  0.0427, -0.0580,\n          0.0425,  0.0683,  0.0920,  0.0757,  0.0466,  0.0425, -0.0111, -0.0332,\n         -0.0774,  0.0107, -0.0152, -0.0077, -0.0742, -0.0951, -0.0377, -0.0487,\n          0.0715,  0.0029,  0.0960,  0.0124,  0.0021, -0.0109,  0.0945,  0.0610,\n          0.0287, -0.0484,  0.0944, -0.0256,  0.0056,  0.0496, -0.0739, -0.0706,\n          0.0203, -0.0742,  0.0665, -0.0006, -0.0237, -0.0448,  0.0076, -0.0202,\n         -0.0881,  0.0669, -0.0953, -0.0644, -0.0163,  0.0254, -0.0904, -0.0449,\n          0.0178,  0.0565,  0.0398,  0.0456, -0.0494, -0.0355,  0.0391,  0.0314,\n         -0.0171,  0.0793, -0.0933,  0.0441,  0.0812,  0.0165,  0.0885,  0.0587,\n          0.0021,  0.0446,  0.0189,  0.0382, -0.0220, -0.0392,  0.0171, -0.0600,\n          0.0993,  0.0291,  0.0813,  0.0213, -0.0523, -0.0729,  0.0507, -0.0881,\n         -0.0559, -0.0190, -0.0963,  0.0157]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	100,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x72d8218fccd0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s480800000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s480800000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}