{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	4,
    "batch_size":	60,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s483800000"
    },
    "max_sample_age":	-1,
    "q_lr":	0.0003,
    "sample_decay":	0.8,
    "seed":	483800000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x78e04cd976d0>":	{
            "_act_dim":	4,
            "_aux_batch_size":	4,
            "_batch_size":	60,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2481,  0.1460,  0.3189,  0.2109,  0.2911, -0.1706,  0.1271,  0.0710,\n         0.3093, -0.1496,  0.1553, -0.3034, -0.1284,  0.2133, -0.2817,  0.2823,\n         0.3413, -0.1782, -0.1186, -0.1153, -0.2617, -0.3101, -0.0191, -0.0393,\n         0.1140,  0.0862, -0.2892, -0.2382, -0.2501, -0.1586,  0.2625, -0.2977,\n         0.1418,  0.2557,  0.1808, -0.0162, -0.1791, -0.0349,  0.3006, -0.1446,\n         0.3145,  0.1585,  0.2507,  0.1375,  0.3116,  0.0105, -0.0758, -0.1695,\n         0.2251, -0.0154,  0.0480, -0.0682,  0.0647, -0.0477,  0.1862, -0.0243,\n        -0.0887, -0.3242, -0.1117,  0.3348, -0.2236,  0.1360,  0.0584,  0.0468,\n        -0.0968, -0.0172,  0.2433, -0.2566,  0.3089,  0.3030, -0.1944,  0.1588,\n         0.2368,  0.3294,  0.2567,  0.2572,  0.1462,  0.3179, -0.0234, -0.0574,\n         0.2203, -0.2959, -0.2473, -0.1535, -0.1382, -0.0803,  0.3373,  0.0246,\n        -0.2725,  0.0707,  0.1747, -0.2564,  0.3245, -0.0597, -0.1902, -0.0710,\n         0.1706,  0.2157,  0.3344,  0.2841, -0.1642, -0.3424, -0.0995,  0.1541,\n        -0.2546,  0.1965, -0.1110, -0.1253,  0.2103, -0.0491,  0.0498, -0.2645,\n        -0.2207,  0.1773, -0.0201,  0.3460, -0.3017,  0.2604, -0.3199,  0.2267,\n        -0.0462, -0.2444, -0.2517,  0.2292, -0.3216,  0.0222,  0.0168,  0.1616],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2821,  0.2486,  0.2666,  ...,  0.1522,  0.2984, -0.3152],\n        [-0.2244,  0.2417, -0.0899,  ...,  0.3128, -0.2165, -0.0592],\n        [ 0.2675,  0.0802, -0.0084,  ...,  0.2012,  0.0903,  0.0924],\n        ...,\n        [-0.3450, -0.1662,  0.1046,  ..., -0.0591,  0.2778, -0.2353],\n        [-0.2221, -0.1144, -0.2455,  ..., -0.2433, -0.1460,  0.1486],\n        [-0.1001,  0.0956, -0.2246,  ..., -0.1539, -0.3226, -0.1759]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0435, -0.0727,  0.0044,  0.0371, -0.0484, -0.0868, -0.0671, -0.0183,\n        -0.0018, -0.0055,  0.0666,  0.0808, -0.0074,  0.0021, -0.0523, -0.0254,\n         0.0172,  0.0346,  0.0076,  0.0860, -0.0334, -0.0582,  0.0078, -0.0348,\n         0.0446, -0.0508,  0.0191,  0.0385, -0.0279, -0.0420,  0.0061, -0.0357,\n        -0.0086,  0.0437,  0.0122,  0.0550,  0.0706,  0.0238,  0.0700,  0.0679,\n         0.0818, -0.0360, -0.0800, -0.0652, -0.0451, -0.0211,  0.0520, -0.0620,\n         0.0446,  0.0778, -0.0689,  0.0211,  0.0551,  0.0697,  0.0782, -0.0633,\n        -0.0270,  0.0060, -0.0803,  0.0839, -0.0422, -0.0493,  0.0444,  0.0363,\n         0.0126,  0.0404,  0.0743, -0.0792,  0.0738, -0.0713, -0.0329,  0.0492,\n         0.0498,  0.0401,  0.0554,  0.0316, -0.0837,  0.0037,  0.0372, -0.0384,\n         0.0566,  0.0760, -0.0798,  0.0195,  0.0295, -0.0277,  0.0839, -0.0335,\n        -0.0874,  0.0861,  0.0422, -0.0414,  0.0188, -0.0409, -0.0870,  0.0018,\n        -0.0568,  0.0781,  0.0058,  0.0168, -0.0401,  0.0411, -0.0134,  0.0118,\n        -0.0212, -0.0493,  0.0871, -0.0433,  0.0182, -0.0111,  0.0728, -0.0105,\n         0.0772, -0.0672,  0.0492,  0.0734,  0.0636,  0.0735, -0.0688, -0.0017,\n         0.0442, -0.0356,  0.0165,  0.0589,  0.0439, -0.0801, -0.0364,  0.0640],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0195, -0.0550,  0.0441,  ...,  0.0138,  0.0573, -0.0791],\n        [-0.0726,  0.0249, -0.0752,  ...,  0.0736,  0.0819,  0.0576],\n        [ 0.0164, -0.0800,  0.0167,  ...,  0.0006,  0.0602,  0.0284],\n        ...,\n        [ 0.0442, -0.0073, -0.0111,  ..., -0.0841, -0.0244, -0.0277],\n        [ 0.0652, -0.0226,  0.0821,  ...,  0.0534, -0.0666,  0.0233],\n        [-0.0781,  0.0090, -0.0356,  ...,  0.0328,  0.0710, -0.0486]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0556,  0.0871,  0.0843,  0.0325], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0522, -0.0667,  0.0481, -0.0591,  0.0176, -0.0401, -0.0215,  0.0746,\n         -0.0587, -0.0086, -0.0542,  0.0816, -0.0645, -0.0473,  0.0106,  0.0339,\n          0.0855, -0.0273, -0.0744, -0.0664, -0.0871, -0.0618, -0.0506,  0.0755,\n          0.0681,  0.0658, -0.0871,  0.0813, -0.0620, -0.0194,  0.0705,  0.0639,\n          0.0356,  0.0369,  0.0354, -0.0799, -0.0876, -0.0823,  0.0038, -0.0195,\n         -0.0785, -0.0208,  0.0641, -0.0031,  0.0608, -0.0024, -0.0098, -0.0557,\n         -0.0055, -0.0822, -0.0242, -0.0104,  0.0738, -0.0308,  0.0280, -0.0155,\n          0.0414, -0.0317, -0.0464, -0.0650, -0.0501, -0.0827,  0.0007,  0.0011,\n         -0.0386, -0.0786, -0.0691,  0.0709,  0.0168, -0.0399, -0.0807, -0.0850,\n          0.0267,  0.0852,  0.0562,  0.0152, -0.0582,  0.0670,  0.0329,  0.0693,\n          0.0447,  0.0658,  0.0375, -0.0323, -0.0550, -0.0366,  0.0525, -0.0746,\n         -0.0557,  0.0231,  0.0060,  0.0428,  0.0634,  0.0276, -0.0793,  0.0631,\n          0.0718, -0.0014, -0.0014, -0.0720,  0.0170, -0.0143, -0.0571, -0.0744,\n          0.0099, -0.0313, -0.0126,  0.0030, -0.0427,  0.0388, -0.0259,  0.0678,\n          0.0121,  0.0438,  0.0442,  0.0101, -0.0181, -0.0848, -0.0564,  0.0193,\n          0.0100, -0.0854, -0.0551,  0.0809, -0.0229,  0.0519, -0.0649, -0.0651],\n        [ 0.0262,  0.0191, -0.0349,  0.0828, -0.0323, -0.0156, -0.0224,  0.0300,\n          0.0294,  0.0311,  0.0328,  0.0154,  0.0088, -0.0154,  0.0164, -0.0285,\n         -0.0860, -0.0649, -0.0498, -0.0456,  0.0282,  0.0368,  0.0328, -0.0108,\n          0.0457,  0.0635,  0.0507, -0.0595,  0.0407,  0.0080, -0.0237, -0.0366,\n         -0.0694, -0.0199, -0.0184, -0.0773,  0.0047, -0.0701,  0.0435,  0.0413,\n         -0.0646, -0.0310,  0.0753, -0.0585,  0.0477, -0.0175,  0.0380, -0.0625,\n         -0.0115,  0.0446, -0.0578, -0.0669, -0.0575,  0.0406,  0.0803, -0.0439,\n         -0.0263,  0.0119, -0.0327,  0.0067, -0.0307, -0.0203,  0.0446,  0.0192,\n          0.0591,  0.0750,  0.0388,  0.0096,  0.0556,  0.0698,  0.0381, -0.0579,\n         -0.0524, -0.0089, -0.0340, -0.0839,  0.0626, -0.0062,  0.0846,  0.0601,\n         -0.0433,  0.0421,  0.0063,  0.0848,  0.0576,  0.0380, -0.0835, -0.0050,\n         -0.0822,  0.0183, -0.0720, -0.0222,  0.0543,  0.0652,  0.0227, -0.0456,\n          0.0091, -0.0727, -0.0072, -0.0508, -0.0366, -0.0583, -0.0736, -0.0411,\n         -0.0699,  0.0018,  0.0103, -0.0077,  0.0590,  0.0335,  0.0691, -0.0535,\n          0.0882,  0.0238,  0.0530,  0.0604,  0.0043, -0.0156, -0.0246, -0.0252,\n          0.0325,  0.0845,  0.0844,  0.0760,  0.0192,  0.0050,  0.0690,  0.0281],\n        [-0.0065, -0.0692,  0.0473, -0.0871, -0.0324,  0.0455,  0.0281, -0.0202,\n          0.0147,  0.0149, -0.0340, -0.0465,  0.0183, -0.0481, -0.0197, -0.0031,\n         -0.0661,  0.0845, -0.0701,  0.0637,  0.0838, -0.0469, -0.0207,  0.0203,\n          0.0869,  0.0721,  0.0124, -0.0282, -0.0831, -0.0848,  0.0389,  0.0616,\n         -0.0159, -0.0692, -0.0848, -0.0118, -0.0085, -0.0349,  0.0283,  0.0385,\n          0.0206,  0.0560,  0.0822,  0.0806, -0.0657,  0.0295,  0.0856, -0.0110,\n          0.0153, -0.0399, -0.0177,  0.0683,  0.0746, -0.0199, -0.0492, -0.0596,\n         -0.0608, -0.0433, -0.0470, -0.0550, -0.0431, -0.0869,  0.0710,  0.0357,\n         -0.0529, -0.0476, -0.0620,  0.0642,  0.0283,  0.0078, -0.0239,  0.0876,\n         -0.0196, -0.0296, -0.0852,  0.0300,  0.0157,  0.0803, -0.0718, -0.0043,\n          0.0536, -0.0368, -0.0812,  0.0173,  0.0532, -0.0579,  0.0128,  0.0645,\n         -0.0771, -0.0311,  0.0655,  0.0604, -0.0702,  0.0574, -0.0020, -0.0055,\n          0.0099,  0.0549, -0.0395, -0.0141, -0.0846,  0.0379, -0.0631, -0.0547,\n         -0.0236, -0.0540,  0.0620, -0.0096,  0.0007,  0.0082,  0.0135, -0.0671,\n         -0.0008,  0.0534,  0.0383,  0.0495,  0.0052,  0.0277,  0.0431, -0.0174,\n          0.0463, -0.0600, -0.0069,  0.0522,  0.0173, -0.0584,  0.0764, -0.0015],\n        [ 0.0306,  0.0527,  0.0163, -0.0372,  0.0602,  0.0463,  0.0358,  0.0234,\n          0.0051,  0.0550,  0.0181, -0.0599, -0.0723,  0.0443, -0.0142,  0.0355,\n          0.0386, -0.0328, -0.0026,  0.0295,  0.0656, -0.0336,  0.0315, -0.0653,\n         -0.0206,  0.0484, -0.0095,  0.0291, -0.0565, -0.0473, -0.0375,  0.0266,\n         -0.0308, -0.0474, -0.0070, -0.0742,  0.0038,  0.0768, -0.0722, -0.0076,\n         -0.0373,  0.0321, -0.0048,  0.0425,  0.0496,  0.0714, -0.0852,  0.0227,\n         -0.0051,  0.0094,  0.0860,  0.0783,  0.0083,  0.0390, -0.0658, -0.0776,\n          0.0781,  0.0522, -0.0836,  0.0674, -0.0673, -0.0534, -0.0195, -0.0333,\n          0.0518,  0.0843, -0.0628,  0.0738, -0.0500,  0.0803,  0.0536, -0.0623,\n          0.0197,  0.0754, -0.0821, -0.0579, -0.0866,  0.0139, -0.0391,  0.0472,\n          0.0014, -0.0375,  0.0227,  0.0769,  0.0470, -0.0827, -0.0774, -0.0088,\n          0.0300,  0.0200, -0.0522,  0.0188, -0.0640, -0.0065, -0.0800,  0.0116,\n         -0.0845, -0.0668,  0.0815, -0.0497, -0.0638,  0.0486,  0.0252,  0.0880,\n         -0.0572,  0.0276,  0.0726,  0.0578, -0.0395, -0.0480, -0.0107, -0.0465,\n          0.0714, -0.0328, -0.0038,  0.0667, -0.0861,  0.0396, -0.0281, -0.0608,\n          0.0776,  0.0225, -0.0470, -0.0642, -0.0331, -0.0234,  0.0639, -0.0604]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2821,  0.2486,  0.2666,  ...,  0.1522,  0.2984, -0.3152],\n        [-0.2244,  0.2417, -0.0899,  ...,  0.3128, -0.2165, -0.0592],\n        [ 0.2675,  0.0802, -0.0084,  ...,  0.2012,  0.0903,  0.0924],\n        ...,\n        [-0.3450, -0.1662,  0.1046,  ..., -0.0591,  0.2778, -0.2353],\n        [-0.2221, -0.1144, -0.2455,  ..., -0.2433, -0.1460,  0.1486],\n        [-0.1001,  0.0956, -0.2246,  ..., -0.1539, -0.3226, -0.1759]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2481,  0.1460,  0.3189,  0.2109,  0.2911, -0.1706,  0.1271,  0.0710,\n         0.3093, -0.1496,  0.1553, -0.3034, -0.1284,  0.2133, -0.2817,  0.2823,\n         0.3413, -0.1782, -0.1186, -0.1153, -0.2617, -0.3101, -0.0191, -0.0393,\n         0.1140,  0.0862, -0.2892, -0.2382, -0.2501, -0.1586,  0.2625, -0.2977,\n         0.1418,  0.2557,  0.1808, -0.0162, -0.1791, -0.0349,  0.3006, -0.1446,\n         0.3145,  0.1585,  0.2507,  0.1375,  0.3116,  0.0105, -0.0758, -0.1695,\n         0.2251, -0.0154,  0.0480, -0.0682,  0.0647, -0.0477,  0.1862, -0.0243,\n        -0.0887, -0.3242, -0.1117,  0.3348, -0.2236,  0.1360,  0.0584,  0.0468,\n        -0.0968, -0.0172,  0.2433, -0.2566,  0.3089,  0.3030, -0.1944,  0.1588,\n         0.2368,  0.3294,  0.2567,  0.2572,  0.1462,  0.3179, -0.0234, -0.0574,\n         0.2203, -0.2959, -0.2473, -0.1535, -0.1382, -0.0803,  0.3373,  0.0246,\n        -0.2725,  0.0707,  0.1747, -0.2564,  0.3245, -0.0597, -0.1902, -0.0710,\n         0.1706,  0.2157,  0.3344,  0.2841, -0.1642, -0.3424, -0.0995,  0.1541,\n        -0.2546,  0.1965, -0.1110, -0.1253,  0.2103, -0.0491,  0.0498, -0.2645,\n        -0.2207,  0.1773, -0.0201,  0.3460, -0.3017,  0.2604, -0.3199,  0.2267,\n        -0.0462, -0.2444, -0.2517,  0.2292, -0.3216,  0.0222,  0.0168,  0.1616],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0195, -0.0550,  0.0441,  ...,  0.0138,  0.0573, -0.0791],\n        [-0.0726,  0.0249, -0.0752,  ...,  0.0736,  0.0819,  0.0576],\n        [ 0.0164, -0.0800,  0.0167,  ...,  0.0006,  0.0602,  0.0284],\n        ...,\n        [ 0.0442, -0.0073, -0.0111,  ..., -0.0841, -0.0244, -0.0277],\n        [ 0.0652, -0.0226,  0.0821,  ...,  0.0534, -0.0666,  0.0233],\n        [-0.0781,  0.0090, -0.0356,  ...,  0.0328,  0.0710, -0.0486]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0435, -0.0727,  0.0044,  0.0371, -0.0484, -0.0868, -0.0671, -0.0183,\n        -0.0018, -0.0055,  0.0666,  0.0808, -0.0074,  0.0021, -0.0523, -0.0254,\n         0.0172,  0.0346,  0.0076,  0.0860, -0.0334, -0.0582,  0.0078, -0.0348,\n         0.0446, -0.0508,  0.0191,  0.0385, -0.0279, -0.0420,  0.0061, -0.0357,\n        -0.0086,  0.0437,  0.0122,  0.0550,  0.0706,  0.0238,  0.0700,  0.0679,\n         0.0818, -0.0360, -0.0800, -0.0652, -0.0451, -0.0211,  0.0520, -0.0620,\n         0.0446,  0.0778, -0.0689,  0.0211,  0.0551,  0.0697,  0.0782, -0.0633,\n        -0.0270,  0.0060, -0.0803,  0.0839, -0.0422, -0.0493,  0.0444,  0.0363,\n         0.0126,  0.0404,  0.0743, -0.0792,  0.0738, -0.0713, -0.0329,  0.0492,\n         0.0498,  0.0401,  0.0554,  0.0316, -0.0837,  0.0037,  0.0372, -0.0384,\n         0.0566,  0.0760, -0.0798,  0.0195,  0.0295, -0.0277,  0.0839, -0.0335,\n        -0.0874,  0.0861,  0.0422, -0.0414,  0.0188, -0.0409, -0.0870,  0.0018,\n        -0.0568,  0.0781,  0.0058,  0.0168, -0.0401,  0.0411, -0.0134,  0.0118,\n        -0.0212, -0.0493,  0.0871, -0.0433,  0.0182, -0.0111,  0.0728, -0.0105,\n         0.0772, -0.0672,  0.0492,  0.0734,  0.0636,  0.0735, -0.0688, -0.0017,\n         0.0442, -0.0356,  0.0165,  0.0589,  0.0439, -0.0801, -0.0364,  0.0640],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0522, -0.0667,  0.0481, -0.0591,  0.0176, -0.0401, -0.0215,  0.0746,\n         -0.0587, -0.0086, -0.0542,  0.0816, -0.0645, -0.0473,  0.0106,  0.0339,\n          0.0855, -0.0273, -0.0744, -0.0664, -0.0871, -0.0618, -0.0506,  0.0755,\n          0.0681,  0.0658, -0.0871,  0.0813, -0.0620, -0.0194,  0.0705,  0.0639,\n          0.0356,  0.0369,  0.0354, -0.0799, -0.0876, -0.0823,  0.0038, -0.0195,\n         -0.0785, -0.0208,  0.0641, -0.0031,  0.0608, -0.0024, -0.0098, -0.0557,\n         -0.0055, -0.0822, -0.0242, -0.0104,  0.0738, -0.0308,  0.0280, -0.0155,\n          0.0414, -0.0317, -0.0464, -0.0650, -0.0501, -0.0827,  0.0007,  0.0011,\n         -0.0386, -0.0786, -0.0691,  0.0709,  0.0168, -0.0399, -0.0807, -0.0850,\n          0.0267,  0.0852,  0.0562,  0.0152, -0.0582,  0.0670,  0.0329,  0.0693,\n          0.0447,  0.0658,  0.0375, -0.0323, -0.0550, -0.0366,  0.0525, -0.0746,\n         -0.0557,  0.0231,  0.0060,  0.0428,  0.0634,  0.0276, -0.0793,  0.0631,\n          0.0718, -0.0014, -0.0014, -0.0720,  0.0170, -0.0143, -0.0571, -0.0744,\n          0.0099, -0.0313, -0.0126,  0.0030, -0.0427,  0.0388, -0.0259,  0.0678,\n          0.0121,  0.0438,  0.0442,  0.0101, -0.0181, -0.0848, -0.0564,  0.0193,\n          0.0100, -0.0854, -0.0551,  0.0809, -0.0229,  0.0519, -0.0649, -0.0651],\n        [ 0.0262,  0.0191, -0.0349,  0.0828, -0.0323, -0.0156, -0.0224,  0.0300,\n          0.0294,  0.0311,  0.0328,  0.0154,  0.0088, -0.0154,  0.0164, -0.0285,\n         -0.0860, -0.0649, -0.0498, -0.0456,  0.0282,  0.0368,  0.0328, -0.0108,\n          0.0457,  0.0635,  0.0507, -0.0595,  0.0407,  0.0080, -0.0237, -0.0366,\n         -0.0694, -0.0199, -0.0184, -0.0773,  0.0047, -0.0701,  0.0435,  0.0413,\n         -0.0646, -0.0310,  0.0753, -0.0585,  0.0477, -0.0175,  0.0380, -0.0625,\n         -0.0115,  0.0446, -0.0578, -0.0669, -0.0575,  0.0406,  0.0803, -0.0439,\n         -0.0263,  0.0119, -0.0327,  0.0067, -0.0307, -0.0203,  0.0446,  0.0192,\n          0.0591,  0.0750,  0.0388,  0.0096,  0.0556,  0.0698,  0.0381, -0.0579,\n         -0.0524, -0.0089, -0.0340, -0.0839,  0.0626, -0.0062,  0.0846,  0.0601,\n         -0.0433,  0.0421,  0.0063,  0.0848,  0.0576,  0.0380, -0.0835, -0.0050,\n         -0.0822,  0.0183, -0.0720, -0.0222,  0.0543,  0.0652,  0.0227, -0.0456,\n          0.0091, -0.0727, -0.0072, -0.0508, -0.0366, -0.0583, -0.0736, -0.0411,\n         -0.0699,  0.0018,  0.0103, -0.0077,  0.0590,  0.0335,  0.0691, -0.0535,\n          0.0882,  0.0238,  0.0530,  0.0604,  0.0043, -0.0156, -0.0246, -0.0252,\n          0.0325,  0.0845,  0.0844,  0.0760,  0.0192,  0.0050,  0.0690,  0.0281],\n        [-0.0065, -0.0692,  0.0473, -0.0871, -0.0324,  0.0455,  0.0281, -0.0202,\n          0.0147,  0.0149, -0.0340, -0.0465,  0.0183, -0.0481, -0.0197, -0.0031,\n         -0.0661,  0.0845, -0.0701,  0.0637,  0.0838, -0.0469, -0.0207,  0.0203,\n          0.0869,  0.0721,  0.0124, -0.0282, -0.0831, -0.0848,  0.0389,  0.0616,\n         -0.0159, -0.0692, -0.0848, -0.0118, -0.0085, -0.0349,  0.0283,  0.0385,\n          0.0206,  0.0560,  0.0822,  0.0806, -0.0657,  0.0295,  0.0856, -0.0110,\n          0.0153, -0.0399, -0.0177,  0.0683,  0.0746, -0.0199, -0.0492, -0.0596,\n         -0.0608, -0.0433, -0.0470, -0.0550, -0.0431, -0.0869,  0.0710,  0.0357,\n         -0.0529, -0.0476, -0.0620,  0.0642,  0.0283,  0.0078, -0.0239,  0.0876,\n         -0.0196, -0.0296, -0.0852,  0.0300,  0.0157,  0.0803, -0.0718, -0.0043,\n          0.0536, -0.0368, -0.0812,  0.0173,  0.0532, -0.0579,  0.0128,  0.0645,\n         -0.0771, -0.0311,  0.0655,  0.0604, -0.0702,  0.0574, -0.0020, -0.0055,\n          0.0099,  0.0549, -0.0395, -0.0141, -0.0846,  0.0379, -0.0631, -0.0547,\n         -0.0236, -0.0540,  0.0620, -0.0096,  0.0007,  0.0082,  0.0135, -0.0671,\n         -0.0008,  0.0534,  0.0383,  0.0495,  0.0052,  0.0277,  0.0431, -0.0174,\n          0.0463, -0.0600, -0.0069,  0.0522,  0.0173, -0.0584,  0.0764, -0.0015],\n        [ 0.0306,  0.0527,  0.0163, -0.0372,  0.0602,  0.0463,  0.0358,  0.0234,\n          0.0051,  0.0550,  0.0181, -0.0599, -0.0723,  0.0443, -0.0142,  0.0355,\n          0.0386, -0.0328, -0.0026,  0.0295,  0.0656, -0.0336,  0.0315, -0.0653,\n         -0.0206,  0.0484, -0.0095,  0.0291, -0.0565, -0.0473, -0.0375,  0.0266,\n         -0.0308, -0.0474, -0.0070, -0.0742,  0.0038,  0.0768, -0.0722, -0.0076,\n         -0.0373,  0.0321, -0.0048,  0.0425,  0.0496,  0.0714, -0.0852,  0.0227,\n         -0.0051,  0.0094,  0.0860,  0.0783,  0.0083,  0.0390, -0.0658, -0.0776,\n          0.0781,  0.0522, -0.0836,  0.0674, -0.0673, -0.0534, -0.0195, -0.0333,\n          0.0518,  0.0843, -0.0628,  0.0738, -0.0500,  0.0803,  0.0536, -0.0623,\n          0.0197,  0.0754, -0.0821, -0.0579, -0.0866,  0.0139, -0.0391,  0.0472,\n          0.0014, -0.0375,  0.0227,  0.0769,  0.0470, -0.0827, -0.0774, -0.0088,\n          0.0300,  0.0200, -0.0522,  0.0188, -0.0640, -0.0065, -0.0800,  0.0116,\n         -0.0845, -0.0668,  0.0815, -0.0497, -0.0638,  0.0486,  0.0252,  0.0880,\n         -0.0572,  0.0276,  0.0726,  0.0578, -0.0395, -0.0480, -0.0107, -0.0465,\n          0.0714, -0.0328, -0.0038,  0.0667, -0.0861,  0.0396, -0.0281, -0.0608,\n          0.0776,  0.0225, -0.0470, -0.0642, -0.0331, -0.0234,  0.0639, -0.0604]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0556,  0.0871,  0.0843,  0.0325], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.EnhancedReplayBuffer object at 0x78e0cd3ecdd0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "aux_buf_size":	5000,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "current_segment":	0,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	-1,
                    "epsilon_per_priority":	1e-06,
                    "gamma":	5,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "max_age":	20000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "num_segments":	0,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "sample_decay":	0.5,
                    "segment_ptr":	0,
                    "segment_size":	62499.0,
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x78e04d35dad0>":	{
                            "capacity":	5000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2481,  0.1460,  0.3189,  0.2109,  0.2911, -0.1706,  0.1271,  0.0710,\n         0.3093, -0.1496,  0.1553, -0.3034, -0.1284,  0.2133, -0.2817,  0.2823,\n         0.3413, -0.1782, -0.1186, -0.1153, -0.2617, -0.3101, -0.0191, -0.0393,\n         0.1140,  0.0862, -0.2892, -0.2382, -0.2501, -0.1586,  0.2625, -0.2977,\n         0.1418,  0.2557,  0.1808, -0.0162, -0.1791, -0.0349,  0.3006, -0.1446,\n         0.3145,  0.1585,  0.2507,  0.1375,  0.3116,  0.0105, -0.0758, -0.1695,\n         0.2251, -0.0154,  0.0480, -0.0682,  0.0647, -0.0477,  0.1862, -0.0243,\n        -0.0887, -0.3242, -0.1117,  0.3348, -0.2236,  0.1360,  0.0584,  0.0468,\n        -0.0968, -0.0172,  0.2433, -0.2566,  0.3089,  0.3030, -0.1944,  0.1588,\n         0.2368,  0.3294,  0.2567,  0.2572,  0.1462,  0.3179, -0.0234, -0.0574,\n         0.2203, -0.2959, -0.2473, -0.1535, -0.1382, -0.0803,  0.3373,  0.0246,\n        -0.2725,  0.0707,  0.1747, -0.2564,  0.3245, -0.0597, -0.1902, -0.0710,\n         0.1706,  0.2157,  0.3344,  0.2841, -0.1642, -0.3424, -0.0995,  0.1541,\n        -0.2546,  0.1965, -0.1110, -0.1253,  0.2103, -0.0491,  0.0498, -0.2645,\n        -0.2207,  0.1773, -0.0201,  0.3460, -0.3017,  0.2604, -0.3199,  0.2267,\n        -0.0462, -0.2444, -0.2517,  0.2292, -0.3216,  0.0222,  0.0168,  0.1616],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2821,  0.2486,  0.2666,  ...,  0.1522,  0.2984, -0.3152],\n        [-0.2244,  0.2417, -0.0899,  ...,  0.3128, -0.2165, -0.0592],\n        [ 0.2675,  0.0802, -0.0084,  ...,  0.2012,  0.0903,  0.0924],\n        ...,\n        [-0.3450, -0.1662,  0.1046,  ..., -0.0591,  0.2778, -0.2353],\n        [-0.2221, -0.1144, -0.2455,  ..., -0.2433, -0.1460,  0.1486],\n        [-0.1001,  0.0956, -0.2246,  ..., -0.1539, -0.3226, -0.1759]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0435, -0.0727,  0.0044,  0.0371, -0.0484, -0.0868, -0.0671, -0.0183,\n        -0.0018, -0.0055,  0.0666,  0.0808, -0.0074,  0.0021, -0.0523, -0.0254,\n         0.0172,  0.0346,  0.0076,  0.0860, -0.0334, -0.0582,  0.0078, -0.0348,\n         0.0446, -0.0508,  0.0191,  0.0385, -0.0279, -0.0420,  0.0061, -0.0357,\n        -0.0086,  0.0437,  0.0122,  0.0550,  0.0706,  0.0238,  0.0700,  0.0679,\n         0.0818, -0.0360, -0.0800, -0.0652, -0.0451, -0.0211,  0.0520, -0.0620,\n         0.0446,  0.0778, -0.0689,  0.0211,  0.0551,  0.0697,  0.0782, -0.0633,\n        -0.0270,  0.0060, -0.0803,  0.0839, -0.0422, -0.0493,  0.0444,  0.0363,\n         0.0126,  0.0404,  0.0743, -0.0792,  0.0738, -0.0713, -0.0329,  0.0492,\n         0.0498,  0.0401,  0.0554,  0.0316, -0.0837,  0.0037,  0.0372, -0.0384,\n         0.0566,  0.0760, -0.0798,  0.0195,  0.0295, -0.0277,  0.0839, -0.0335,\n        -0.0874,  0.0861,  0.0422, -0.0414,  0.0188, -0.0409, -0.0870,  0.0018,\n        -0.0568,  0.0781,  0.0058,  0.0168, -0.0401,  0.0411, -0.0134,  0.0118,\n        -0.0212, -0.0493,  0.0871, -0.0433,  0.0182, -0.0111,  0.0728, -0.0105,\n         0.0772, -0.0672,  0.0492,  0.0734,  0.0636,  0.0735, -0.0688, -0.0017,\n         0.0442, -0.0356,  0.0165,  0.0589,  0.0439, -0.0801, -0.0364,  0.0640],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0195, -0.0550,  0.0441,  ...,  0.0138,  0.0573, -0.0791],\n        [-0.0726,  0.0249, -0.0752,  ...,  0.0736,  0.0819,  0.0576],\n        [ 0.0164, -0.0800,  0.0167,  ...,  0.0006,  0.0602,  0.0284],\n        ...,\n        [ 0.0442, -0.0073, -0.0111,  ..., -0.0841, -0.0244, -0.0277],\n        [ 0.0652, -0.0226,  0.0821,  ...,  0.0534, -0.0666,  0.0233],\n        [-0.0781,  0.0090, -0.0356,  ...,  0.0328,  0.0710, -0.0486]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0556,  0.0871,  0.0843,  0.0325], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0522, -0.0667,  0.0481, -0.0591,  0.0176, -0.0401, -0.0215,  0.0746,\n         -0.0587, -0.0086, -0.0542,  0.0816, -0.0645, -0.0473,  0.0106,  0.0339,\n          0.0855, -0.0273, -0.0744, -0.0664, -0.0871, -0.0618, -0.0506,  0.0755,\n          0.0681,  0.0658, -0.0871,  0.0813, -0.0620, -0.0194,  0.0705,  0.0639,\n          0.0356,  0.0369,  0.0354, -0.0799, -0.0876, -0.0823,  0.0038, -0.0195,\n         -0.0785, -0.0208,  0.0641, -0.0031,  0.0608, -0.0024, -0.0098, -0.0557,\n         -0.0055, -0.0822, -0.0242, -0.0104,  0.0738, -0.0308,  0.0280, -0.0155,\n          0.0414, -0.0317, -0.0464, -0.0650, -0.0501, -0.0827,  0.0007,  0.0011,\n         -0.0386, -0.0786, -0.0691,  0.0709,  0.0168, -0.0399, -0.0807, -0.0850,\n          0.0267,  0.0852,  0.0562,  0.0152, -0.0582,  0.0670,  0.0329,  0.0693,\n          0.0447,  0.0658,  0.0375, -0.0323, -0.0550, -0.0366,  0.0525, -0.0746,\n         -0.0557,  0.0231,  0.0060,  0.0428,  0.0634,  0.0276, -0.0793,  0.0631,\n          0.0718, -0.0014, -0.0014, -0.0720,  0.0170, -0.0143, -0.0571, -0.0744,\n          0.0099, -0.0313, -0.0126,  0.0030, -0.0427,  0.0388, -0.0259,  0.0678,\n          0.0121,  0.0438,  0.0442,  0.0101, -0.0181, -0.0848, -0.0564,  0.0193,\n          0.0100, -0.0854, -0.0551,  0.0809, -0.0229,  0.0519, -0.0649, -0.0651],\n        [ 0.0262,  0.0191, -0.0349,  0.0828, -0.0323, -0.0156, -0.0224,  0.0300,\n          0.0294,  0.0311,  0.0328,  0.0154,  0.0088, -0.0154,  0.0164, -0.0285,\n         -0.0860, -0.0649, -0.0498, -0.0456,  0.0282,  0.0368,  0.0328, -0.0108,\n          0.0457,  0.0635,  0.0507, -0.0595,  0.0407,  0.0080, -0.0237, -0.0366,\n         -0.0694, -0.0199, -0.0184, -0.0773,  0.0047, -0.0701,  0.0435,  0.0413,\n         -0.0646, -0.0310,  0.0753, -0.0585,  0.0477, -0.0175,  0.0380, -0.0625,\n         -0.0115,  0.0446, -0.0578, -0.0669, -0.0575,  0.0406,  0.0803, -0.0439,\n         -0.0263,  0.0119, -0.0327,  0.0067, -0.0307, -0.0203,  0.0446,  0.0192,\n          0.0591,  0.0750,  0.0388,  0.0096,  0.0556,  0.0698,  0.0381, -0.0579,\n         -0.0524, -0.0089, -0.0340, -0.0839,  0.0626, -0.0062,  0.0846,  0.0601,\n         -0.0433,  0.0421,  0.0063,  0.0848,  0.0576,  0.0380, -0.0835, -0.0050,\n         -0.0822,  0.0183, -0.0720, -0.0222,  0.0543,  0.0652,  0.0227, -0.0456,\n          0.0091, -0.0727, -0.0072, -0.0508, -0.0366, -0.0583, -0.0736, -0.0411,\n         -0.0699,  0.0018,  0.0103, -0.0077,  0.0590,  0.0335,  0.0691, -0.0535,\n          0.0882,  0.0238,  0.0530,  0.0604,  0.0043, -0.0156, -0.0246, -0.0252,\n          0.0325,  0.0845,  0.0844,  0.0760,  0.0192,  0.0050,  0.0690,  0.0281],\n        [-0.0065, -0.0692,  0.0473, -0.0871, -0.0324,  0.0455,  0.0281, -0.0202,\n          0.0147,  0.0149, -0.0340, -0.0465,  0.0183, -0.0481, -0.0197, -0.0031,\n         -0.0661,  0.0845, -0.0701,  0.0637,  0.0838, -0.0469, -0.0207,  0.0203,\n          0.0869,  0.0721,  0.0124, -0.0282, -0.0831, -0.0848,  0.0389,  0.0616,\n         -0.0159, -0.0692, -0.0848, -0.0118, -0.0085, -0.0349,  0.0283,  0.0385,\n          0.0206,  0.0560,  0.0822,  0.0806, -0.0657,  0.0295,  0.0856, -0.0110,\n          0.0153, -0.0399, -0.0177,  0.0683,  0.0746, -0.0199, -0.0492, -0.0596,\n         -0.0608, -0.0433, -0.0470, -0.0550, -0.0431, -0.0869,  0.0710,  0.0357,\n         -0.0529, -0.0476, -0.0620,  0.0642,  0.0283,  0.0078, -0.0239,  0.0876,\n         -0.0196, -0.0296, -0.0852,  0.0300,  0.0157,  0.0803, -0.0718, -0.0043,\n          0.0536, -0.0368, -0.0812,  0.0173,  0.0532, -0.0579,  0.0128,  0.0645,\n         -0.0771, -0.0311,  0.0655,  0.0604, -0.0702,  0.0574, -0.0020, -0.0055,\n          0.0099,  0.0549, -0.0395, -0.0141, -0.0846,  0.0379, -0.0631, -0.0547,\n         -0.0236, -0.0540,  0.0620, -0.0096,  0.0007,  0.0082,  0.0135, -0.0671,\n         -0.0008,  0.0534,  0.0383,  0.0495,  0.0052,  0.0277,  0.0431, -0.0174,\n          0.0463, -0.0600, -0.0069,  0.0522,  0.0173, -0.0584,  0.0764, -0.0015],\n        [ 0.0306,  0.0527,  0.0163, -0.0372,  0.0602,  0.0463,  0.0358,  0.0234,\n          0.0051,  0.0550,  0.0181, -0.0599, -0.0723,  0.0443, -0.0142,  0.0355,\n          0.0386, -0.0328, -0.0026,  0.0295,  0.0656, -0.0336,  0.0315, -0.0653,\n         -0.0206,  0.0484, -0.0095,  0.0291, -0.0565, -0.0473, -0.0375,  0.0266,\n         -0.0308, -0.0474, -0.0070, -0.0742,  0.0038,  0.0768, -0.0722, -0.0076,\n         -0.0373,  0.0321, -0.0048,  0.0425,  0.0496,  0.0714, -0.0852,  0.0227,\n         -0.0051,  0.0094,  0.0860,  0.0783,  0.0083,  0.0390, -0.0658, -0.0776,\n          0.0781,  0.0522, -0.0836,  0.0674, -0.0673, -0.0534, -0.0195, -0.0333,\n          0.0518,  0.0843, -0.0628,  0.0738, -0.0500,  0.0803,  0.0536, -0.0623,\n          0.0197,  0.0754, -0.0821, -0.0579, -0.0866,  0.0139, -0.0391,  0.0472,\n          0.0014, -0.0375,  0.0227,  0.0769,  0.0470, -0.0827, -0.0774, -0.0088,\n          0.0300,  0.0200, -0.0522,  0.0188, -0.0640, -0.0065, -0.0800,  0.0116,\n         -0.0845, -0.0668,  0.0815, -0.0497, -0.0638,  0.0486,  0.0252,  0.0880,\n         -0.0572,  0.0276,  0.0726,  0.0578, -0.0395, -0.0480, -0.0107, -0.0465,\n          0.0714, -0.0328, -0.0038,  0.0667, -0.0861,  0.0396, -0.0281, -0.0608,\n          0.0776,  0.0225, -0.0470, -0.0642, -0.0331, -0.0234,  0.0639, -0.0604]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x78e04d32e910>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s483800000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s483800000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}