{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s494940000"
    },
    "q_lr":	0.0005,
    "seed":	494940000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7c258d4c7790>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2325,  0.2449,  0.2634, -0.1845,  0.1658, -0.0281, -0.1516, -0.1240,\n         0.3342,  0.1340, -0.1613,  0.1398,  0.0301, -0.2084, -0.3173, -0.2599,\n         0.2729, -0.0093, -0.1568,  0.2544,  0.1680,  0.3529, -0.1880, -0.1721,\n        -0.2847,  0.0009, -0.2552, -0.2865, -0.1504,  0.2499,  0.1769,  0.2461],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2679, -0.3142,  0.0347, -0.2739,  0.3462,  0.1819,  0.2231, -0.2591],\n        [-0.0186,  0.1656,  0.1285, -0.0642,  0.0763, -0.1036, -0.2521, -0.2252],\n        [-0.2928, -0.0372, -0.0838, -0.1767, -0.3278, -0.2000, -0.1110,  0.0333],\n        [-0.2592, -0.0577, -0.1464, -0.3290,  0.0351,  0.0262,  0.2936, -0.0859],\n        [ 0.0632, -0.1539,  0.2378,  0.0970,  0.0246, -0.1225, -0.2446, -0.1853],\n        [-0.0278,  0.0989, -0.1562, -0.2114, -0.3493, -0.1541, -0.2050, -0.1383],\n        [ 0.1674, -0.1814, -0.1635,  0.0518,  0.0018,  0.2406, -0.1160, -0.0097],\n        [ 0.1677, -0.1519, -0.1307, -0.0234, -0.2745,  0.1648,  0.0042,  0.0852],\n        [-0.2863, -0.3022, -0.1681, -0.3534, -0.0550, -0.3410, -0.0398, -0.3476],\n        [ 0.3462,  0.2758, -0.1443, -0.2579,  0.0582, -0.1464,  0.0633, -0.2371],\n        [ 0.0267,  0.1704, -0.1968,  0.3327, -0.1030,  0.2749, -0.3340, -0.0915],\n        [ 0.1980,  0.1617,  0.0144, -0.2807, -0.1689, -0.1321,  0.1843, -0.3481],\n        [-0.0730, -0.1407, -0.3211, -0.0197,  0.3073,  0.2599,  0.0877, -0.1373],\n        [-0.2209,  0.2695,  0.2254,  0.3033, -0.3442, -0.1417, -0.3411,  0.0523],\n        [ 0.0971,  0.0023,  0.1721,  0.0379,  0.1546,  0.0609, -0.2263,  0.1446],\n        [ 0.1931, -0.2540,  0.3046,  0.2573, -0.0507,  0.3064,  0.2798, -0.0125],\n        [-0.1921, -0.0291, -0.1059, -0.1927, -0.0940, -0.3412, -0.0496, -0.1311],\n        [ 0.1738,  0.1063,  0.0277, -0.2219,  0.0621,  0.2454,  0.2981,  0.3339],\n        [-0.0046, -0.0872, -0.1026, -0.1336, -0.1669,  0.3283, -0.2733,  0.0441],\n        [-0.3064, -0.2662, -0.2509,  0.1637,  0.2379, -0.0069, -0.1378, -0.2158],\n        [ 0.3493,  0.1528,  0.2906, -0.0236,  0.3146, -0.0872,  0.1764,  0.2664],\n        [-0.1827,  0.2451, -0.3030,  0.2251, -0.3171,  0.0398, -0.2628,  0.0864],\n        [-0.2759, -0.2068, -0.0266,  0.1148,  0.0651, -0.1667,  0.0085, -0.2238],\n        [-0.2326, -0.0255, -0.2340,  0.3448,  0.2437, -0.1921, -0.2332,  0.3451],\n        [ 0.2913, -0.1039,  0.2761,  0.3339,  0.2292, -0.0317, -0.1461, -0.1113],\n        [ 0.2364,  0.1516, -0.0637,  0.0187,  0.1976, -0.1389, -0.1369, -0.2169],\n        [-0.2908,  0.3215,  0.1598, -0.2969,  0.1620,  0.1161,  0.0285, -0.0274],\n        [-0.0974,  0.2376, -0.3486,  0.0174, -0.1006, -0.1187,  0.0402, -0.2971],\n        [-0.0324, -0.3319,  0.0555, -0.0467, -0.0827,  0.0255,  0.2103, -0.1018],\n        [-0.0157, -0.2033, -0.1763, -0.1325, -0.0186, -0.2183, -0.2971, -0.2724],\n        [ 0.3165, -0.2606,  0.2356,  0.2198,  0.2547, -0.2656, -0.2030,  0.3400],\n        [-0.0232,  0.1385, -0.1008, -0.0945,  0.3161, -0.0683, -0.0676, -0.0007]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0963, -0.0282, -0.1743,  0.0046,  0.1118, -0.0590, -0.1656,  0.0770,\n        -0.1176,  0.1118, -0.0552, -0.0674,  0.1193,  0.1421, -0.1301,  0.1682],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 4.9228e-02,  4.1800e-02, -2.9842e-02,  7.8184e-02,  1.4869e-01,\n          8.4367e-02,  1.1176e-02,  7.1444e-02,  5.3381e-02, -1.3359e-01,\n          1.6661e-01, -8.6157e-02, -4.8881e-02,  8.7131e-02, -5.8943e-03,\n          1.0352e-01, -1.3050e-01, -1.6040e-01, -5.7726e-02,  7.0882e-02,\n          1.2508e-01,  6.2444e-02,  5.6152e-02, -9.0920e-02, -8.5294e-02,\n          5.0456e-02, -9.9192e-02,  1.0060e-02, -1.5047e-01, -1.7202e-01,\n          1.4840e-01,  9.7970e-02],\n        [-1.5483e-01,  1.5216e-01,  1.1437e-01, -1.2511e-01,  3.4712e-02,\n          7.6813e-02, -8.9251e-02,  6.1426e-02,  1.4149e-01,  1.5988e-01,\n         -4.9466e-02,  1.3507e-01, -1.1686e-01, -1.4833e-01, -1.7176e-01,\n          1.4216e-01, -1.1680e-01,  8.4914e-02,  2.6592e-02, -3.2602e-02,\n          3.8355e-02, -1.6361e-01,  6.0142e-03,  2.2272e-02,  8.4735e-02,\n         -1.8531e-02,  7.8044e-02,  2.3502e-02, -2.7026e-02,  1.6901e-01,\n          4.4197e-02, -1.6704e-01],\n        [-3.7678e-02,  6.7936e-02, -1.7612e-01, -5.3921e-02, -1.1982e-01,\n          2.1486e-03, -1.5085e-01,  6.8779e-02, -9.2308e-02,  5.3972e-02,\n         -5.2020e-02,  5.6603e-02,  2.7116e-02, -6.1902e-02,  7.9082e-02,\n          4.7136e-02,  6.2614e-02, -1.1242e-01,  6.4056e-02, -2.5612e-02,\n          1.0825e-01,  1.4188e-01,  1.6038e-01, -1.5254e-01,  1.3548e-01,\n         -6.2285e-02, -7.8855e-02,  1.7115e-01,  1.3140e-02,  1.0142e-01,\n         -1.6017e-01,  1.5194e-01],\n        [-1.5055e-01,  8.6235e-02, -1.7100e-01,  3.2197e-02, -3.2276e-02,\n         -1.0753e-01, -1.1794e-01,  1.5985e-01,  9.7344e-02,  1.4592e-01,\n          2.8309e-02, -1.6429e-01, -7.3821e-02,  6.1036e-02,  1.1741e-01,\n         -3.8874e-02,  7.2815e-02, -1.1580e-01, -2.3783e-02,  7.4807e-02,\n         -4.7388e-02, -1.6586e-02, -1.2632e-01,  1.6285e-01, -1.7928e-02,\n         -1.0717e-01,  1.3469e-01,  1.0427e-03, -1.2863e-01, -1.1039e-01,\n          5.1939e-02, -1.4713e-01],\n        [ 2.9619e-02, -6.6257e-03,  6.3259e-02, -1.2162e-01,  4.5172e-02,\n         -8.1988e-02, -5.1985e-03,  5.7782e-02,  4.4914e-03, -2.3974e-02,\n          5.1274e-02, -1.0174e-01,  6.1284e-02, -1.0418e-01,  6.5998e-02,\n         -3.6894e-02,  1.0689e-01,  3.6889e-02,  4.9796e-02,  1.5182e-01,\n         -1.5994e-02, -3.7095e-02,  1.4402e-01, -6.6819e-02, -9.5104e-05,\n         -1.7143e-01,  2.5420e-02, -1.2755e-01,  1.4783e-01, -6.7868e-02,\n          3.4851e-02,  1.3542e-01],\n        [-6.7878e-02, -1.1538e-02, -5.9653e-02, -5.3673e-02,  1.2033e-01,\n          8.4895e-02, -1.1454e-01,  6.7982e-02, -7.7124e-02,  1.5637e-01,\n          1.3405e-01,  8.7968e-02, -1.6471e-01, -6.5955e-02,  8.0439e-02,\n         -1.0821e-01,  8.9306e-03, -1.1354e-01,  1.6643e-01,  7.2576e-02,\n         -5.6003e-02, -9.8175e-02,  9.5639e-02, -1.3465e-01, -1.5148e-01,\n         -3.6106e-02,  3.2663e-02,  3.0612e-02, -1.3086e-01,  1.4552e-01,\n          1.2112e-01,  1.6176e-01],\n        [ 1.5854e-01, -7.0529e-02, -1.1454e-01, -3.5592e-02,  1.5893e-01,\n          7.4615e-02,  1.4620e-01,  1.5667e-01, -5.6251e-02,  2.4540e-02,\n         -4.6911e-02,  1.6250e-02,  1.2798e-02, -1.1852e-01, -1.6721e-01,\n          9.1491e-02, -1.1804e-01,  1.6686e-01,  1.3962e-01,  3.9252e-02,\n         -1.2763e-01,  6.3791e-02,  1.4522e-01, -1.5223e-01,  2.2214e-02,\n          1.7368e-01,  1.2341e-01,  6.8548e-02,  9.7077e-02,  1.0919e-01,\n         -1.4204e-01,  3.0851e-02],\n        [ 3.7358e-02,  6.7613e-02, -8.8426e-02, -1.0151e-01,  6.5282e-02,\n          7.4405e-02, -6.7004e-02, -1.4853e-01,  2.0935e-02, -7.3674e-02,\n          1.0870e-02, -1.7048e-01, -2.0793e-02, -1.1725e-01, -7.7993e-02,\n         -7.3074e-02, -4.0094e-02,  8.4223e-02, -1.3692e-01,  1.2880e-02,\n          5.5913e-02, -8.9326e-02,  1.0173e-01,  1.3167e-01, -1.5604e-01,\n         -1.7050e-01,  1.0291e-01,  4.7665e-02,  1.0518e-01,  1.5570e-01,\n          1.7080e-02, -1.3214e-01],\n        [-5.2695e-02, -1.1722e-01,  1.3774e-01, -9.7929e-02, -1.3594e-01,\n         -7.6041e-03,  1.4336e-01,  1.3659e-01, -1.0446e-01, -1.3083e-01,\n          1.8631e-02,  1.2227e-01, -1.0644e-01, -1.2309e-02,  4.5073e-02,\n         -1.5185e-01, -1.0832e-01,  1.4948e-01, -3.5808e-02, -6.1863e-02,\n          1.2797e-01,  1.4161e-01,  3.4177e-02, -1.2785e-01,  2.6170e-02,\n         -9.1171e-02,  5.1061e-02, -9.3306e-02, -7.8920e-02,  1.7104e-01,\n         -7.1550e-02,  1.5173e-01],\n        [-3.7709e-02, -6.9987e-02,  4.1799e-02,  3.8239e-02,  1.4888e-01,\n          4.9548e-02,  1.0166e-02,  1.5148e-01, -1.9257e-02,  2.0658e-02,\n         -5.6057e-02, -5.4959e-02,  1.3841e-01,  4.9889e-02, -4.3696e-02,\n         -1.4281e-01, -1.4412e-01, -1.5583e-01, -2.3070e-02,  6.6572e-02,\n          1.2882e-01,  3.0487e-02,  7.3650e-02,  2.6288e-02, -1.1205e-01,\n          7.4847e-02,  1.5148e-01,  1.9818e-02,  1.2624e-01,  6.9705e-02,\n          1.4669e-01,  1.5853e-01],\n        [-1.8768e-02, -7.4015e-02, -2.5416e-02,  1.5134e-01,  1.0808e-02,\n         -1.6030e-01, -8.2173e-02,  1.0125e-01,  1.4620e-01, -4.1737e-02,\n          1.0447e-01,  6.9832e-02,  1.4246e-03,  3.3785e-02,  6.3355e-02,\n          2.1898e-02, -1.6886e-01, -4.6469e-02, -1.3583e-01,  1.1749e-01,\n         -1.0562e-01,  1.1331e-01,  1.0604e-01, -1.2549e-01,  9.0071e-02,\n         -6.1269e-02,  7.5071e-02, -1.5599e-03,  7.1361e-03, -1.1717e-01,\n         -1.6083e-01, -1.0106e-01],\n        [-4.1767e-02,  3.0851e-02, -9.8629e-02,  6.3664e-02, -1.1481e-01,\n         -1.8367e-02,  1.0912e-01,  3.6259e-02,  1.0789e-02,  1.5625e-01,\n          1.0559e-01,  8.5795e-02, -1.4089e-01, -3.0964e-02, -1.0350e-01,\n         -1.5256e-01, -2.8163e-02,  1.1711e-02,  8.0267e-02, -9.9421e-02,\n          1.2508e-01,  1.4907e-01, -2.7208e-02,  8.0606e-02, -1.6109e-01,\n          1.2791e-02,  4.2626e-03,  1.5092e-01,  7.2152e-02,  2.1802e-02,\n          1.3952e-01, -1.5695e-01],\n        [-1.2593e-01,  3.0547e-02, -9.2513e-02, -5.6493e-02,  8.7051e-02,\n          6.9415e-02, -1.5583e-01, -1.3251e-02,  9.2937e-02, -4.7711e-02,\n         -3.0712e-02,  1.2310e-01, -7.0435e-02,  1.2197e-01,  1.6966e-01,\n         -1.3234e-01, -6.2475e-02,  1.4408e-01, -4.7524e-02,  1.6919e-02,\n          1.4926e-01, -2.6550e-02,  2.8448e-02, -9.3994e-02, -1.0383e-01,\n          1.6904e-01, -8.1131e-03, -1.2534e-01, -9.2452e-02,  2.7496e-02,\n          1.1545e-01, -1.6232e-01],\n        [ 2.6028e-02, -1.7032e-01, -1.4390e-02, -5.7410e-02, -2.8021e-02,\n          4.4662e-02,  1.5749e-01,  1.3501e-01, -2.5297e-02, -1.1716e-01,\n         -7.9237e-02, -1.0161e-01, -1.5601e-01,  1.9060e-02, -1.5147e-01,\n         -4.5302e-02, -5.9403e-02,  3.4729e-02, -8.7008e-03, -3.9436e-02,\n         -3.1517e-02, -9.1428e-02, -1.4154e-01,  1.7171e-01, -1.0964e-01,\n         -8.2675e-02,  1.7506e-01,  4.0534e-02, -1.0053e-01,  6.8842e-02,\n         -6.6020e-02,  7.9218e-02],\n        [-1.5637e-01, -2.7734e-02, -9.8745e-02, -3.6609e-02, -1.3772e-01,\n         -8.7183e-02,  7.8196e-02, -8.7198e-02,  6.0386e-02, -2.0422e-02,\n         -1.5034e-01,  2.5628e-02, -9.2707e-02, -1.1847e-01, -1.4903e-01,\n         -1.2527e-01, -6.1757e-02, -5.3071e-02, -1.2552e-01,  2.9910e-02,\n          4.4682e-04,  1.1288e-03, -4.3242e-02,  5.2829e-02, -1.7437e-01,\n         -1.3811e-01,  6.8319e-02, -1.4007e-01, -4.2988e-02,  5.9218e-02,\n          1.7099e-01,  4.1608e-02],\n        [-3.5718e-02, -1.6030e-01,  7.1511e-04, -1.3194e-02, -1.2271e-01,\n          4.1180e-02, -1.1763e-01,  1.5022e-01, -1.2107e-01,  7.6962e-02,\n         -1.0330e-01, -2.4259e-02, -7.5675e-02, -2.3683e-03,  2.9154e-02,\n         -5.7153e-02,  8.5241e-02,  1.2040e-01, -6.8680e-02, -9.6982e-02,\n         -1.7100e-02,  7.7730e-02,  1.0090e-02,  8.9848e-02,  4.2600e-02,\n          3.9154e-02,  3.3667e-02, -1.2384e-01, -1.1430e-01,  1.6543e-01,\n          3.1817e-02, -7.6489e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1148,  0.1572,  0.0810,  0.0471, -0.2216,  0.0677,  0.2306,  0.0513],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0747,  0.0181,  0.2422, -0.0152,  0.0487, -0.2222,  0.0576,  0.0683,\n         -0.1046, -0.2096, -0.1743,  0.0905,  0.0874, -0.2122, -0.1546, -0.0917],\n        [-0.2092, -0.0541, -0.1452,  0.1572, -0.2264, -0.2348,  0.0860,  0.0724,\n         -0.0295, -0.0345,  0.1400,  0.0417,  0.0483, -0.0515,  0.0172,  0.0588],\n        [ 0.0051, -0.1169, -0.0662, -0.1111, -0.0083, -0.2071,  0.0637,  0.0983,\n          0.2099, -0.2273, -0.0128, -0.0826, -0.2207, -0.1690, -0.1795,  0.0884],\n        [-0.0982,  0.0345,  0.0512, -0.2452, -0.2483, -0.1411, -0.1666,  0.0137,\n          0.0157,  0.1496,  0.1929,  0.0294, -0.0478,  0.0378,  0.0884, -0.0288],\n        [-0.0924,  0.0845, -0.2484,  0.1257,  0.0823,  0.1958,  0.1143,  0.2407,\n          0.2267,  0.2341, -0.1077, -0.1588, -0.0873,  0.0468, -0.0509, -0.0603],\n        [-0.1878,  0.1568,  0.1891,  0.1356, -0.1832,  0.0507, -0.0895,  0.2216,\n          0.2418, -0.1599, -0.0028,  0.1820,  0.0196, -0.0878, -0.1134, -0.0882],\n        [-0.2111, -0.1297, -0.2381,  0.2206, -0.1624, -0.0137,  0.1559,  0.0259,\n         -0.1093,  0.0380, -0.0078,  0.0376,  0.1692, -0.2488,  0.0227, -0.1046],\n        [-0.2089,  0.1179, -0.0497,  0.1882,  0.0626,  0.2415, -0.1741, -0.1625,\n         -0.1872, -0.2119,  0.1060, -0.1498, -0.0645, -0.1988, -0.0863,  0.1028]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	true
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2905, -0.0489,  0.2117,  0.1416], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.3023, -0.0154,  0.1856,  0.0516, -0.1252, -0.0944, -0.2111,  0.2245],\n        [ 0.0326,  0.2113,  0.2733, -0.3347,  0.2240, -0.1851,  0.2635, -0.3188],\n        [ 0.0782,  0.0944, -0.2706,  0.2475,  0.2297, -0.2477, -0.1413, -0.0070],\n        [ 0.0245,  0.0611, -0.2780,  0.1071,  0.0874, -0.0794, -0.2376,  0.1851]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2679, -0.3142,  0.0347, -0.2739,  0.3462,  0.1819,  0.2231, -0.2591],\n        [-0.0186,  0.1656,  0.1285, -0.0642,  0.0763, -0.1036, -0.2521, -0.2252],\n        [-0.2928, -0.0372, -0.0838, -0.1767, -0.3278, -0.2000, -0.1110,  0.0333],\n        [-0.2592, -0.0577, -0.1464, -0.3290,  0.0351,  0.0262,  0.2936, -0.0859],\n        [ 0.0632, -0.1539,  0.2378,  0.0970,  0.0246, -0.1225, -0.2446, -0.1853],\n        [-0.0278,  0.0989, -0.1562, -0.2114, -0.3493, -0.1541, -0.2050, -0.1383],\n        [ 0.1674, -0.1814, -0.1635,  0.0518,  0.0018,  0.2406, -0.1160, -0.0097],\n        [ 0.1677, -0.1519, -0.1307, -0.0234, -0.2745,  0.1648,  0.0042,  0.0852],\n        [-0.2863, -0.3022, -0.1681, -0.3534, -0.0550, -0.3410, -0.0398, -0.3476],\n        [ 0.3462,  0.2758, -0.1443, -0.2579,  0.0582, -0.1464,  0.0633, -0.2371],\n        [ 0.0267,  0.1704, -0.1968,  0.3327, -0.1030,  0.2749, -0.3340, -0.0915],\n        [ 0.1980,  0.1617,  0.0144, -0.2807, -0.1689, -0.1321,  0.1843, -0.3481],\n        [-0.0730, -0.1407, -0.3211, -0.0197,  0.3073,  0.2599,  0.0877, -0.1373],\n        [-0.2209,  0.2695,  0.2254,  0.3033, -0.3442, -0.1417, -0.3411,  0.0523],\n        [ 0.0971,  0.0023,  0.1721,  0.0379,  0.1546,  0.0609, -0.2263,  0.1446],\n        [ 0.1931, -0.2540,  0.3046,  0.2573, -0.0507,  0.3064,  0.2798, -0.0125],\n        [-0.1921, -0.0291, -0.1059, -0.1927, -0.0940, -0.3412, -0.0496, -0.1311],\n        [ 0.1738,  0.1063,  0.0277, -0.2219,  0.0621,  0.2454,  0.2981,  0.3339],\n        [-0.0046, -0.0872, -0.1026, -0.1336, -0.1669,  0.3283, -0.2733,  0.0441],\n        [-0.3064, -0.2662, -0.2509,  0.1637,  0.2379, -0.0069, -0.1378, -0.2158],\n        [ 0.3493,  0.1528,  0.2906, -0.0236,  0.3146, -0.0872,  0.1764,  0.2664],\n        [-0.1827,  0.2451, -0.3030,  0.2251, -0.3171,  0.0398, -0.2628,  0.0864],\n        [-0.2759, -0.2068, -0.0266,  0.1148,  0.0651, -0.1667,  0.0085, -0.2238],\n        [-0.2326, -0.0255, -0.2340,  0.3448,  0.2437, -0.1921, -0.2332,  0.3451],\n        [ 0.2913, -0.1039,  0.2761,  0.3339,  0.2292, -0.0317, -0.1461, -0.1113],\n        [ 0.2364,  0.1516, -0.0637,  0.0187,  0.1976, -0.1389, -0.1369, -0.2169],\n        [-0.2908,  0.3215,  0.1598, -0.2969,  0.1620,  0.1161,  0.0285, -0.0274],\n        [-0.0974,  0.2376, -0.3486,  0.0174, -0.1006, -0.1187,  0.0402, -0.2971],\n        [-0.0324, -0.3319,  0.0555, -0.0467, -0.0827,  0.0255,  0.2103, -0.1018],\n        [-0.0157, -0.2033, -0.1763, -0.1325, -0.0186, -0.2183, -0.2971, -0.2724],\n        [ 0.3165, -0.2606,  0.2356,  0.2198,  0.2547, -0.2656, -0.2030,  0.3400],\n        [-0.0232,  0.1385, -0.1008, -0.0945,  0.3161, -0.0683, -0.0676, -0.0007]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2325,  0.2449,  0.2634, -0.1845,  0.1658, -0.0281, -0.1516, -0.1240,\n         0.3342,  0.1340, -0.1613,  0.1398,  0.0301, -0.2084, -0.3173, -0.2599,\n         0.2729, -0.0093, -0.1568,  0.2544,  0.1680,  0.3529, -0.1880, -0.1721,\n        -0.2847,  0.0009, -0.2552, -0.2865, -0.1504,  0.2499,  0.1769,  0.2461],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 4.9228e-02,  4.1800e-02, -2.9842e-02,  7.8184e-02,  1.4869e-01,\n          8.4367e-02,  1.1176e-02,  7.1444e-02,  5.3381e-02, -1.3359e-01,\n          1.6661e-01, -8.6157e-02, -4.8881e-02,  8.7131e-02, -5.8943e-03,\n          1.0352e-01, -1.3050e-01, -1.6040e-01, -5.7726e-02,  7.0882e-02,\n          1.2508e-01,  6.2444e-02,  5.6152e-02, -9.0920e-02, -8.5294e-02,\n          5.0456e-02, -9.9192e-02,  1.0060e-02, -1.5047e-01, -1.7202e-01,\n          1.4840e-01,  9.7970e-02],\n        [-1.5483e-01,  1.5216e-01,  1.1437e-01, -1.2511e-01,  3.4712e-02,\n          7.6813e-02, -8.9251e-02,  6.1426e-02,  1.4149e-01,  1.5988e-01,\n         -4.9466e-02,  1.3507e-01, -1.1686e-01, -1.4833e-01, -1.7176e-01,\n          1.4216e-01, -1.1680e-01,  8.4914e-02,  2.6592e-02, -3.2602e-02,\n          3.8355e-02, -1.6361e-01,  6.0142e-03,  2.2272e-02,  8.4735e-02,\n         -1.8531e-02,  7.8044e-02,  2.3502e-02, -2.7026e-02,  1.6901e-01,\n          4.4197e-02, -1.6704e-01],\n        [-3.7678e-02,  6.7936e-02, -1.7612e-01, -5.3921e-02, -1.1982e-01,\n          2.1486e-03, -1.5085e-01,  6.8779e-02, -9.2308e-02,  5.3972e-02,\n         -5.2020e-02,  5.6603e-02,  2.7116e-02, -6.1902e-02,  7.9082e-02,\n          4.7136e-02,  6.2614e-02, -1.1242e-01,  6.4056e-02, -2.5612e-02,\n          1.0825e-01,  1.4188e-01,  1.6038e-01, -1.5254e-01,  1.3548e-01,\n         -6.2285e-02, -7.8855e-02,  1.7115e-01,  1.3140e-02,  1.0142e-01,\n         -1.6017e-01,  1.5194e-01],\n        [-1.5055e-01,  8.6235e-02, -1.7100e-01,  3.2197e-02, -3.2276e-02,\n         -1.0753e-01, -1.1794e-01,  1.5985e-01,  9.7344e-02,  1.4592e-01,\n          2.8309e-02, -1.6429e-01, -7.3821e-02,  6.1036e-02,  1.1741e-01,\n         -3.8874e-02,  7.2815e-02, -1.1580e-01, -2.3783e-02,  7.4807e-02,\n         -4.7388e-02, -1.6586e-02, -1.2632e-01,  1.6285e-01, -1.7928e-02,\n         -1.0717e-01,  1.3469e-01,  1.0427e-03, -1.2863e-01, -1.1039e-01,\n          5.1939e-02, -1.4713e-01],\n        [ 2.9619e-02, -6.6257e-03,  6.3259e-02, -1.2162e-01,  4.5172e-02,\n         -8.1988e-02, -5.1985e-03,  5.7782e-02,  4.4914e-03, -2.3974e-02,\n          5.1274e-02, -1.0174e-01,  6.1284e-02, -1.0418e-01,  6.5998e-02,\n         -3.6894e-02,  1.0689e-01,  3.6889e-02,  4.9796e-02,  1.5182e-01,\n         -1.5994e-02, -3.7095e-02,  1.4402e-01, -6.6819e-02, -9.5104e-05,\n         -1.7143e-01,  2.5420e-02, -1.2755e-01,  1.4783e-01, -6.7868e-02,\n          3.4851e-02,  1.3542e-01],\n        [-6.7878e-02, -1.1538e-02, -5.9653e-02, -5.3673e-02,  1.2033e-01,\n          8.4895e-02, -1.1454e-01,  6.7982e-02, -7.7124e-02,  1.5637e-01,\n          1.3405e-01,  8.7968e-02, -1.6471e-01, -6.5955e-02,  8.0439e-02,\n         -1.0821e-01,  8.9306e-03, -1.1354e-01,  1.6643e-01,  7.2576e-02,\n         -5.6003e-02, -9.8175e-02,  9.5639e-02, -1.3465e-01, -1.5148e-01,\n         -3.6106e-02,  3.2663e-02,  3.0612e-02, -1.3086e-01,  1.4552e-01,\n          1.2112e-01,  1.6176e-01],\n        [ 1.5854e-01, -7.0529e-02, -1.1454e-01, -3.5592e-02,  1.5893e-01,\n          7.4615e-02,  1.4620e-01,  1.5667e-01, -5.6251e-02,  2.4540e-02,\n         -4.6911e-02,  1.6250e-02,  1.2798e-02, -1.1852e-01, -1.6721e-01,\n          9.1491e-02, -1.1804e-01,  1.6686e-01,  1.3962e-01,  3.9252e-02,\n         -1.2763e-01,  6.3791e-02,  1.4522e-01, -1.5223e-01,  2.2214e-02,\n          1.7368e-01,  1.2341e-01,  6.8548e-02,  9.7077e-02,  1.0919e-01,\n         -1.4204e-01,  3.0851e-02],\n        [ 3.7358e-02,  6.7613e-02, -8.8426e-02, -1.0151e-01,  6.5282e-02,\n          7.4405e-02, -6.7004e-02, -1.4853e-01,  2.0935e-02, -7.3674e-02,\n          1.0870e-02, -1.7048e-01, -2.0793e-02, -1.1725e-01, -7.7993e-02,\n         -7.3074e-02, -4.0094e-02,  8.4223e-02, -1.3692e-01,  1.2880e-02,\n          5.5913e-02, -8.9326e-02,  1.0173e-01,  1.3167e-01, -1.5604e-01,\n         -1.7050e-01,  1.0291e-01,  4.7665e-02,  1.0518e-01,  1.5570e-01,\n          1.7080e-02, -1.3214e-01],\n        [-5.2695e-02, -1.1722e-01,  1.3774e-01, -9.7929e-02, -1.3594e-01,\n         -7.6041e-03,  1.4336e-01,  1.3659e-01, -1.0446e-01, -1.3083e-01,\n          1.8631e-02,  1.2227e-01, -1.0644e-01, -1.2309e-02,  4.5073e-02,\n         -1.5185e-01, -1.0832e-01,  1.4948e-01, -3.5808e-02, -6.1863e-02,\n          1.2797e-01,  1.4161e-01,  3.4177e-02, -1.2785e-01,  2.6170e-02,\n         -9.1171e-02,  5.1061e-02, -9.3306e-02, -7.8920e-02,  1.7104e-01,\n         -7.1550e-02,  1.5173e-01],\n        [-3.7709e-02, -6.9987e-02,  4.1799e-02,  3.8239e-02,  1.4888e-01,\n          4.9548e-02,  1.0166e-02,  1.5148e-01, -1.9257e-02,  2.0658e-02,\n         -5.6057e-02, -5.4959e-02,  1.3841e-01,  4.9889e-02, -4.3696e-02,\n         -1.4281e-01, -1.4412e-01, -1.5583e-01, -2.3070e-02,  6.6572e-02,\n          1.2882e-01,  3.0487e-02,  7.3650e-02,  2.6288e-02, -1.1205e-01,\n          7.4847e-02,  1.5148e-01,  1.9818e-02,  1.2624e-01,  6.9705e-02,\n          1.4669e-01,  1.5853e-01],\n        [-1.8768e-02, -7.4015e-02, -2.5416e-02,  1.5134e-01,  1.0808e-02,\n         -1.6030e-01, -8.2173e-02,  1.0125e-01,  1.4620e-01, -4.1737e-02,\n          1.0447e-01,  6.9832e-02,  1.4246e-03,  3.3785e-02,  6.3355e-02,\n          2.1898e-02, -1.6886e-01, -4.6469e-02, -1.3583e-01,  1.1749e-01,\n         -1.0562e-01,  1.1331e-01,  1.0604e-01, -1.2549e-01,  9.0071e-02,\n         -6.1269e-02,  7.5071e-02, -1.5599e-03,  7.1361e-03, -1.1717e-01,\n         -1.6083e-01, -1.0106e-01],\n        [-4.1767e-02,  3.0851e-02, -9.8629e-02,  6.3664e-02, -1.1481e-01,\n         -1.8367e-02,  1.0912e-01,  3.6259e-02,  1.0789e-02,  1.5625e-01,\n          1.0559e-01,  8.5795e-02, -1.4089e-01, -3.0964e-02, -1.0350e-01,\n         -1.5256e-01, -2.8163e-02,  1.1711e-02,  8.0267e-02, -9.9421e-02,\n          1.2508e-01,  1.4907e-01, -2.7208e-02,  8.0606e-02, -1.6109e-01,\n          1.2791e-02,  4.2626e-03,  1.5092e-01,  7.2152e-02,  2.1802e-02,\n          1.3952e-01, -1.5695e-01],\n        [-1.2593e-01,  3.0547e-02, -9.2513e-02, -5.6493e-02,  8.7051e-02,\n          6.9415e-02, -1.5583e-01, -1.3251e-02,  9.2937e-02, -4.7711e-02,\n         -3.0712e-02,  1.2310e-01, -7.0435e-02,  1.2197e-01,  1.6966e-01,\n         -1.3234e-01, -6.2475e-02,  1.4408e-01, -4.7524e-02,  1.6919e-02,\n          1.4926e-01, -2.6550e-02,  2.8448e-02, -9.3994e-02, -1.0383e-01,\n          1.6904e-01, -8.1131e-03, -1.2534e-01, -9.2452e-02,  2.7496e-02,\n          1.1545e-01, -1.6232e-01],\n        [ 2.6028e-02, -1.7032e-01, -1.4390e-02, -5.7410e-02, -2.8021e-02,\n          4.4662e-02,  1.5749e-01,  1.3501e-01, -2.5297e-02, -1.1716e-01,\n         -7.9237e-02, -1.0161e-01, -1.5601e-01,  1.9060e-02, -1.5147e-01,\n         -4.5302e-02, -5.9403e-02,  3.4729e-02, -8.7008e-03, -3.9436e-02,\n         -3.1517e-02, -9.1428e-02, -1.4154e-01,  1.7171e-01, -1.0964e-01,\n         -8.2675e-02,  1.7506e-01,  4.0534e-02, -1.0053e-01,  6.8842e-02,\n         -6.6020e-02,  7.9218e-02],\n        [-1.5637e-01, -2.7734e-02, -9.8745e-02, -3.6609e-02, -1.3772e-01,\n         -8.7183e-02,  7.8196e-02, -8.7198e-02,  6.0386e-02, -2.0422e-02,\n         -1.5034e-01,  2.5628e-02, -9.2707e-02, -1.1847e-01, -1.4903e-01,\n         -1.2527e-01, -6.1757e-02, -5.3071e-02, -1.2552e-01,  2.9910e-02,\n          4.4682e-04,  1.1288e-03, -4.3242e-02,  5.2829e-02, -1.7437e-01,\n         -1.3811e-01,  6.8319e-02, -1.4007e-01, -4.2988e-02,  5.9218e-02,\n          1.7099e-01,  4.1608e-02],\n        [-3.5718e-02, -1.6030e-01,  7.1511e-04, -1.3194e-02, -1.2271e-01,\n          4.1180e-02, -1.1763e-01,  1.5022e-01, -1.2107e-01,  7.6962e-02,\n         -1.0330e-01, -2.4259e-02, -7.5675e-02, -2.3683e-03,  2.9154e-02,\n         -5.7153e-02,  8.5241e-02,  1.2040e-01, -6.8680e-02, -9.6982e-02,\n         -1.7100e-02,  7.7730e-02,  1.0090e-02,  8.9848e-02,  4.2600e-02,\n          3.9154e-02,  3.3667e-02, -1.2384e-01, -1.1430e-01,  1.6543e-01,\n          3.1817e-02, -7.6489e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0963, -0.0282, -0.1743,  0.0046,  0.1118, -0.0590, -0.1656,  0.0770,\n        -0.1176,  0.1118, -0.0552, -0.0674,  0.1193,  0.1421, -0.1301,  0.1682],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0747,  0.0181,  0.2422, -0.0152,  0.0487, -0.2222,  0.0576,  0.0683,\n         -0.1046, -0.2096, -0.1743,  0.0905,  0.0874, -0.2122, -0.1546, -0.0917],\n        [-0.2092, -0.0541, -0.1452,  0.1572, -0.2264, -0.2348,  0.0860,  0.0724,\n         -0.0295, -0.0345,  0.1400,  0.0417,  0.0483, -0.0515,  0.0172,  0.0588],\n        [ 0.0051, -0.1169, -0.0662, -0.1111, -0.0083, -0.2071,  0.0637,  0.0983,\n          0.2099, -0.2273, -0.0128, -0.0826, -0.2207, -0.1690, -0.1795,  0.0884],\n        [-0.0982,  0.0345,  0.0512, -0.2452, -0.2483, -0.1411, -0.1666,  0.0137,\n          0.0157,  0.1496,  0.1929,  0.0294, -0.0478,  0.0378,  0.0884, -0.0288],\n        [-0.0924,  0.0845, -0.2484,  0.1257,  0.0823,  0.1958,  0.1143,  0.2407,\n          0.2267,  0.2341, -0.1077, -0.1588, -0.0873,  0.0468, -0.0509, -0.0603],\n        [-0.1878,  0.1568,  0.1891,  0.1356, -0.1832,  0.0507, -0.0895,  0.2216,\n          0.2418, -0.1599, -0.0028,  0.1820,  0.0196, -0.0878, -0.1134, -0.0882],\n        [-0.2111, -0.1297, -0.2381,  0.2206, -0.1624, -0.0137,  0.1559,  0.0259,\n         -0.1093,  0.0380, -0.0078,  0.0376,  0.1692, -0.2488,  0.0227, -0.1046],\n        [-0.2089,  0.1179, -0.0497,  0.1882,  0.0626,  0.2415, -0.1741, -0.1625,\n         -0.1872, -0.2119,  0.1060, -0.1498, -0.0645, -0.1988, -0.0863,  0.1028]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1148,  0.1572,  0.0810,  0.0471, -0.2216,  0.0677,  0.2306,  0.0513],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3023, -0.0154,  0.1856,  0.0516, -0.1252, -0.0944, -0.2111,  0.2245],\n        [ 0.0326,  0.2113,  0.2733, -0.3347,  0.2240, -0.1851,  0.2635, -0.3188],\n        [ 0.0782,  0.0944, -0.2706,  0.2475,  0.2297, -0.2477, -0.1413, -0.0070],\n        [ 0.0245,  0.0611, -0.2780,  0.1071,  0.0874, -0.0794, -0.2376,  0.1851]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2905, -0.0489,  0.2117,  0.1416], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7c25fc7da9d0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=32, bias=True)\n  (fc2): Linear(in_features=32, out_features=16, bias=True)\n  (fc3): Linear(in_features=16, out_features=8, bias=True)\n  (fc4): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=32, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2325,  0.2449,  0.2634, -0.1845,  0.1658, -0.0281, -0.1516, -0.1240,\n         0.3342,  0.1340, -0.1613,  0.1398,  0.0301, -0.2084, -0.3173, -0.2599,\n         0.2729, -0.0093, -0.1568,  0.2544,  0.1680,  0.3529, -0.1880, -0.1721,\n        -0.2847,  0.0009, -0.2552, -0.2865, -0.1504,  0.2499,  0.1769,  0.2461],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2679, -0.3142,  0.0347, -0.2739,  0.3462,  0.1819,  0.2231, -0.2591],\n        [-0.0186,  0.1656,  0.1285, -0.0642,  0.0763, -0.1036, -0.2521, -0.2252],\n        [-0.2928, -0.0372, -0.0838, -0.1767, -0.3278, -0.2000, -0.1110,  0.0333],\n        [-0.2592, -0.0577, -0.1464, -0.3290,  0.0351,  0.0262,  0.2936, -0.0859],\n        [ 0.0632, -0.1539,  0.2378,  0.0970,  0.0246, -0.1225, -0.2446, -0.1853],\n        [-0.0278,  0.0989, -0.1562, -0.2114, -0.3493, -0.1541, -0.2050, -0.1383],\n        [ 0.1674, -0.1814, -0.1635,  0.0518,  0.0018,  0.2406, -0.1160, -0.0097],\n        [ 0.1677, -0.1519, -0.1307, -0.0234, -0.2745,  0.1648,  0.0042,  0.0852],\n        [-0.2863, -0.3022, -0.1681, -0.3534, -0.0550, -0.3410, -0.0398, -0.3476],\n        [ 0.3462,  0.2758, -0.1443, -0.2579,  0.0582, -0.1464,  0.0633, -0.2371],\n        [ 0.0267,  0.1704, -0.1968,  0.3327, -0.1030,  0.2749, -0.3340, -0.0915],\n        [ 0.1980,  0.1617,  0.0144, -0.2807, -0.1689, -0.1321,  0.1843, -0.3481],\n        [-0.0730, -0.1407, -0.3211, -0.0197,  0.3073,  0.2599,  0.0877, -0.1373],\n        [-0.2209,  0.2695,  0.2254,  0.3033, -0.3442, -0.1417, -0.3411,  0.0523],\n        [ 0.0971,  0.0023,  0.1721,  0.0379,  0.1546,  0.0609, -0.2263,  0.1446],\n        [ 0.1931, -0.2540,  0.3046,  0.2573, -0.0507,  0.3064,  0.2798, -0.0125],\n        [-0.1921, -0.0291, -0.1059, -0.1927, -0.0940, -0.3412, -0.0496, -0.1311],\n        [ 0.1738,  0.1063,  0.0277, -0.2219,  0.0621,  0.2454,  0.2981,  0.3339],\n        [-0.0046, -0.0872, -0.1026, -0.1336, -0.1669,  0.3283, -0.2733,  0.0441],\n        [-0.3064, -0.2662, -0.2509,  0.1637,  0.2379, -0.0069, -0.1378, -0.2158],\n        [ 0.3493,  0.1528,  0.2906, -0.0236,  0.3146, -0.0872,  0.1764,  0.2664],\n        [-0.1827,  0.2451, -0.3030,  0.2251, -0.3171,  0.0398, -0.2628,  0.0864],\n        [-0.2759, -0.2068, -0.0266,  0.1148,  0.0651, -0.1667,  0.0085, -0.2238],\n        [-0.2326, -0.0255, -0.2340,  0.3448,  0.2437, -0.1921, -0.2332,  0.3451],\n        [ 0.2913, -0.1039,  0.2761,  0.3339,  0.2292, -0.0317, -0.1461, -0.1113],\n        [ 0.2364,  0.1516, -0.0637,  0.0187,  0.1976, -0.1389, -0.1369, -0.2169],\n        [-0.2908,  0.3215,  0.1598, -0.2969,  0.1620,  0.1161,  0.0285, -0.0274],\n        [-0.0974,  0.2376, -0.3486,  0.0174, -0.1006, -0.1187,  0.0402, -0.2971],\n        [-0.0324, -0.3319,  0.0555, -0.0467, -0.0827,  0.0255,  0.2103, -0.1018],\n        [-0.0157, -0.2033, -0.1763, -0.1325, -0.0186, -0.2183, -0.2971, -0.2724],\n        [ 0.3165, -0.2606,  0.2356,  0.2198,  0.2547, -0.2656, -0.2030,  0.3400],\n        [-0.0232,  0.1385, -0.1008, -0.0945,  0.3161, -0.0683, -0.0676, -0.0007]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	32,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=32, out_features=16, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0963, -0.0282, -0.1743,  0.0046,  0.1118, -0.0590, -0.1656,  0.0770,\n        -0.1176,  0.1118, -0.0552, -0.0674,  0.1193,  0.1421, -0.1301,  0.1682],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 4.9228e-02,  4.1800e-02, -2.9842e-02,  7.8184e-02,  1.4869e-01,\n          8.4367e-02,  1.1176e-02,  7.1444e-02,  5.3381e-02, -1.3359e-01,\n          1.6661e-01, -8.6157e-02, -4.8881e-02,  8.7131e-02, -5.8943e-03,\n          1.0352e-01, -1.3050e-01, -1.6040e-01, -5.7726e-02,  7.0882e-02,\n          1.2508e-01,  6.2444e-02,  5.6152e-02, -9.0920e-02, -8.5294e-02,\n          5.0456e-02, -9.9192e-02,  1.0060e-02, -1.5047e-01, -1.7202e-01,\n          1.4840e-01,  9.7970e-02],\n        [-1.5483e-01,  1.5216e-01,  1.1437e-01, -1.2511e-01,  3.4712e-02,\n          7.6813e-02, -8.9251e-02,  6.1426e-02,  1.4149e-01,  1.5988e-01,\n         -4.9466e-02,  1.3507e-01, -1.1686e-01, -1.4833e-01, -1.7176e-01,\n          1.4216e-01, -1.1680e-01,  8.4914e-02,  2.6592e-02, -3.2602e-02,\n          3.8355e-02, -1.6361e-01,  6.0142e-03,  2.2272e-02,  8.4735e-02,\n         -1.8531e-02,  7.8044e-02,  2.3502e-02, -2.7026e-02,  1.6901e-01,\n          4.4197e-02, -1.6704e-01],\n        [-3.7678e-02,  6.7936e-02, -1.7612e-01, -5.3921e-02, -1.1982e-01,\n          2.1486e-03, -1.5085e-01,  6.8779e-02, -9.2308e-02,  5.3972e-02,\n         -5.2020e-02,  5.6603e-02,  2.7116e-02, -6.1902e-02,  7.9082e-02,\n          4.7136e-02,  6.2614e-02, -1.1242e-01,  6.4056e-02, -2.5612e-02,\n          1.0825e-01,  1.4188e-01,  1.6038e-01, -1.5254e-01,  1.3548e-01,\n         -6.2285e-02, -7.8855e-02,  1.7115e-01,  1.3140e-02,  1.0142e-01,\n         -1.6017e-01,  1.5194e-01],\n        [-1.5055e-01,  8.6235e-02, -1.7100e-01,  3.2197e-02, -3.2276e-02,\n         -1.0753e-01, -1.1794e-01,  1.5985e-01,  9.7344e-02,  1.4592e-01,\n          2.8309e-02, -1.6429e-01, -7.3821e-02,  6.1036e-02,  1.1741e-01,\n         -3.8874e-02,  7.2815e-02, -1.1580e-01, -2.3783e-02,  7.4807e-02,\n         -4.7388e-02, -1.6586e-02, -1.2632e-01,  1.6285e-01, -1.7928e-02,\n         -1.0717e-01,  1.3469e-01,  1.0427e-03, -1.2863e-01, -1.1039e-01,\n          5.1939e-02, -1.4713e-01],\n        [ 2.9619e-02, -6.6257e-03,  6.3259e-02, -1.2162e-01,  4.5172e-02,\n         -8.1988e-02, -5.1985e-03,  5.7782e-02,  4.4914e-03, -2.3974e-02,\n          5.1274e-02, -1.0174e-01,  6.1284e-02, -1.0418e-01,  6.5998e-02,\n         -3.6894e-02,  1.0689e-01,  3.6889e-02,  4.9796e-02,  1.5182e-01,\n         -1.5994e-02, -3.7095e-02,  1.4402e-01, -6.6819e-02, -9.5104e-05,\n         -1.7143e-01,  2.5420e-02, -1.2755e-01,  1.4783e-01, -6.7868e-02,\n          3.4851e-02,  1.3542e-01],\n        [-6.7878e-02, -1.1538e-02, -5.9653e-02, -5.3673e-02,  1.2033e-01,\n          8.4895e-02, -1.1454e-01,  6.7982e-02, -7.7124e-02,  1.5637e-01,\n          1.3405e-01,  8.7968e-02, -1.6471e-01, -6.5955e-02,  8.0439e-02,\n         -1.0821e-01,  8.9306e-03, -1.1354e-01,  1.6643e-01,  7.2576e-02,\n         -5.6003e-02, -9.8175e-02,  9.5639e-02, -1.3465e-01, -1.5148e-01,\n         -3.6106e-02,  3.2663e-02,  3.0612e-02, -1.3086e-01,  1.4552e-01,\n          1.2112e-01,  1.6176e-01],\n        [ 1.5854e-01, -7.0529e-02, -1.1454e-01, -3.5592e-02,  1.5893e-01,\n          7.4615e-02,  1.4620e-01,  1.5667e-01, -5.6251e-02,  2.4540e-02,\n         -4.6911e-02,  1.6250e-02,  1.2798e-02, -1.1852e-01, -1.6721e-01,\n          9.1491e-02, -1.1804e-01,  1.6686e-01,  1.3962e-01,  3.9252e-02,\n         -1.2763e-01,  6.3791e-02,  1.4522e-01, -1.5223e-01,  2.2214e-02,\n          1.7368e-01,  1.2341e-01,  6.8548e-02,  9.7077e-02,  1.0919e-01,\n         -1.4204e-01,  3.0851e-02],\n        [ 3.7358e-02,  6.7613e-02, -8.8426e-02, -1.0151e-01,  6.5282e-02,\n          7.4405e-02, -6.7004e-02, -1.4853e-01,  2.0935e-02, -7.3674e-02,\n          1.0870e-02, -1.7048e-01, -2.0793e-02, -1.1725e-01, -7.7993e-02,\n         -7.3074e-02, -4.0094e-02,  8.4223e-02, -1.3692e-01,  1.2880e-02,\n          5.5913e-02, -8.9326e-02,  1.0173e-01,  1.3167e-01, -1.5604e-01,\n         -1.7050e-01,  1.0291e-01,  4.7665e-02,  1.0518e-01,  1.5570e-01,\n          1.7080e-02, -1.3214e-01],\n        [-5.2695e-02, -1.1722e-01,  1.3774e-01, -9.7929e-02, -1.3594e-01,\n         -7.6041e-03,  1.4336e-01,  1.3659e-01, -1.0446e-01, -1.3083e-01,\n          1.8631e-02,  1.2227e-01, -1.0644e-01, -1.2309e-02,  4.5073e-02,\n         -1.5185e-01, -1.0832e-01,  1.4948e-01, -3.5808e-02, -6.1863e-02,\n          1.2797e-01,  1.4161e-01,  3.4177e-02, -1.2785e-01,  2.6170e-02,\n         -9.1171e-02,  5.1061e-02, -9.3306e-02, -7.8920e-02,  1.7104e-01,\n         -7.1550e-02,  1.5173e-01],\n        [-3.7709e-02, -6.9987e-02,  4.1799e-02,  3.8239e-02,  1.4888e-01,\n          4.9548e-02,  1.0166e-02,  1.5148e-01, -1.9257e-02,  2.0658e-02,\n         -5.6057e-02, -5.4959e-02,  1.3841e-01,  4.9889e-02, -4.3696e-02,\n         -1.4281e-01, -1.4412e-01, -1.5583e-01, -2.3070e-02,  6.6572e-02,\n          1.2882e-01,  3.0487e-02,  7.3650e-02,  2.6288e-02, -1.1205e-01,\n          7.4847e-02,  1.5148e-01,  1.9818e-02,  1.2624e-01,  6.9705e-02,\n          1.4669e-01,  1.5853e-01],\n        [-1.8768e-02, -7.4015e-02, -2.5416e-02,  1.5134e-01,  1.0808e-02,\n         -1.6030e-01, -8.2173e-02,  1.0125e-01,  1.4620e-01, -4.1737e-02,\n          1.0447e-01,  6.9832e-02,  1.4246e-03,  3.3785e-02,  6.3355e-02,\n          2.1898e-02, -1.6886e-01, -4.6469e-02, -1.3583e-01,  1.1749e-01,\n         -1.0562e-01,  1.1331e-01,  1.0604e-01, -1.2549e-01,  9.0071e-02,\n         -6.1269e-02,  7.5071e-02, -1.5599e-03,  7.1361e-03, -1.1717e-01,\n         -1.6083e-01, -1.0106e-01],\n        [-4.1767e-02,  3.0851e-02, -9.8629e-02,  6.3664e-02, -1.1481e-01,\n         -1.8367e-02,  1.0912e-01,  3.6259e-02,  1.0789e-02,  1.5625e-01,\n          1.0559e-01,  8.5795e-02, -1.4089e-01, -3.0964e-02, -1.0350e-01,\n         -1.5256e-01, -2.8163e-02,  1.1711e-02,  8.0267e-02, -9.9421e-02,\n          1.2508e-01,  1.4907e-01, -2.7208e-02,  8.0606e-02, -1.6109e-01,\n          1.2791e-02,  4.2626e-03,  1.5092e-01,  7.2152e-02,  2.1802e-02,\n          1.3952e-01, -1.5695e-01],\n        [-1.2593e-01,  3.0547e-02, -9.2513e-02, -5.6493e-02,  8.7051e-02,\n          6.9415e-02, -1.5583e-01, -1.3251e-02,  9.2937e-02, -4.7711e-02,\n         -3.0712e-02,  1.2310e-01, -7.0435e-02,  1.2197e-01,  1.6966e-01,\n         -1.3234e-01, -6.2475e-02,  1.4408e-01, -4.7524e-02,  1.6919e-02,\n          1.4926e-01, -2.6550e-02,  2.8448e-02, -9.3994e-02, -1.0383e-01,\n          1.6904e-01, -8.1131e-03, -1.2534e-01, -9.2452e-02,  2.7496e-02,\n          1.1545e-01, -1.6232e-01],\n        [ 2.6028e-02, -1.7032e-01, -1.4390e-02, -5.7410e-02, -2.8021e-02,\n          4.4662e-02,  1.5749e-01,  1.3501e-01, -2.5297e-02, -1.1716e-01,\n         -7.9237e-02, -1.0161e-01, -1.5601e-01,  1.9060e-02, -1.5147e-01,\n         -4.5302e-02, -5.9403e-02,  3.4729e-02, -8.7008e-03, -3.9436e-02,\n         -3.1517e-02, -9.1428e-02, -1.4154e-01,  1.7171e-01, -1.0964e-01,\n         -8.2675e-02,  1.7506e-01,  4.0534e-02, -1.0053e-01,  6.8842e-02,\n         -6.6020e-02,  7.9218e-02],\n        [-1.5637e-01, -2.7734e-02, -9.8745e-02, -3.6609e-02, -1.3772e-01,\n         -8.7183e-02,  7.8196e-02, -8.7198e-02,  6.0386e-02, -2.0422e-02,\n         -1.5034e-01,  2.5628e-02, -9.2707e-02, -1.1847e-01, -1.4903e-01,\n         -1.2527e-01, -6.1757e-02, -5.3071e-02, -1.2552e-01,  2.9910e-02,\n          4.4682e-04,  1.1288e-03, -4.3242e-02,  5.2829e-02, -1.7437e-01,\n         -1.3811e-01,  6.8319e-02, -1.4007e-01, -4.2988e-02,  5.9218e-02,\n          1.7099e-01,  4.1608e-02],\n        [-3.5718e-02, -1.6030e-01,  7.1511e-04, -1.3194e-02, -1.2271e-01,\n          4.1180e-02, -1.1763e-01,  1.5022e-01, -1.2107e-01,  7.6962e-02,\n         -1.0330e-01, -2.4259e-02, -7.5675e-02, -2.3683e-03,  2.9154e-02,\n         -5.7153e-02,  8.5241e-02,  1.2040e-01, -6.8680e-02, -9.6982e-02,\n         -1.7100e-02,  7.7730e-02,  1.0090e-02,  8.9848e-02,  4.2600e-02,\n          3.9154e-02,  3.3667e-02, -1.2384e-01, -1.1430e-01,  1.6543e-01,\n          3.1817e-02, -7.6489e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	32,
                                "out_features":	16,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=16, out_features=8, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1148,  0.1572,  0.0810,  0.0471, -0.2216,  0.0677,  0.2306,  0.0513],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0747,  0.0181,  0.2422, -0.0152,  0.0487, -0.2222,  0.0576,  0.0683,\n         -0.1046, -0.2096, -0.1743,  0.0905,  0.0874, -0.2122, -0.1546, -0.0917],\n        [-0.2092, -0.0541, -0.1452,  0.1572, -0.2264, -0.2348,  0.0860,  0.0724,\n         -0.0295, -0.0345,  0.1400,  0.0417,  0.0483, -0.0515,  0.0172,  0.0588],\n        [ 0.0051, -0.1169, -0.0662, -0.1111, -0.0083, -0.2071,  0.0637,  0.0983,\n          0.2099, -0.2273, -0.0128, -0.0826, -0.2207, -0.1690, -0.1795,  0.0884],\n        [-0.0982,  0.0345,  0.0512, -0.2452, -0.2483, -0.1411, -0.1666,  0.0137,\n          0.0157,  0.1496,  0.1929,  0.0294, -0.0478,  0.0378,  0.0884, -0.0288],\n        [-0.0924,  0.0845, -0.2484,  0.1257,  0.0823,  0.1958,  0.1143,  0.2407,\n          0.2267,  0.2341, -0.1077, -0.1588, -0.0873,  0.0468, -0.0509, -0.0603],\n        [-0.1878,  0.1568,  0.1891,  0.1356, -0.1832,  0.0507, -0.0895,  0.2216,\n          0.2418, -0.1599, -0.0028,  0.1820,  0.0196, -0.0878, -0.1134, -0.0882],\n        [-0.2111, -0.1297, -0.2381,  0.2206, -0.1624, -0.0137,  0.1559,  0.0259,\n         -0.1093,  0.0380, -0.0078,  0.0376,  0.1692, -0.2488,  0.0227, -0.1046],\n        [-0.2089,  0.1179, -0.0497,  0.1882,  0.0626,  0.2415, -0.1741, -0.1625,\n         -0.1872, -0.2119,  0.1060, -0.1498, -0.0645, -0.1988, -0.0863,  0.1028]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	16,
                                "out_features":	8,
                                "training":	false
                            }
                        },
                        "fc4":	{
                            "Linear(in_features=8, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2905, -0.0489,  0.2117,  0.1416], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.3023, -0.0154,  0.1856,  0.0516, -0.1252, -0.0944, -0.2111,  0.2245],\n        [ 0.0326,  0.2113,  0.2733, -0.3347,  0.2240, -0.1851,  0.2635, -0.3188],\n        [ 0.0782,  0.0944, -0.2706,  0.2475,  0.2297, -0.2477, -0.1413, -0.0070],\n        [ 0.0245,  0.0611, -0.2780,  0.1071,  0.0874, -0.0794, -0.2376,  0.1851]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7c25896fad90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s494940000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s494940000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}