{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	4,
    "batch_size":	60,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s495210000"
    },
    "max_sample_age":	-1,
    "q_lr":	0.0003,
    "sample_decay":	0.8,
    "seed":	495210000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7e7fc0f0d010>":	{
            "_act_dim":	4,
            "_aux_batch_size":	4,
            "_batch_size":	60,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3155, -0.0389, -0.3300,  0.0416, -0.3523, -0.2764,  0.1968, -0.1802,\n        -0.1811,  0.1317, -0.0721,  0.0746, -0.2536,  0.1684,  0.2119,  0.1209,\n        -0.1526, -0.1199,  0.2575,  0.2377, -0.3245,  0.2554,  0.2698,  0.3168,\n        -0.0067, -0.0940,  0.2167,  0.1098, -0.1414, -0.0744, -0.3247, -0.2423,\n         0.1801,  0.0545, -0.3430, -0.3071,  0.0145, -0.0712,  0.1480, -0.3361,\n         0.0726,  0.0625,  0.1461,  0.1044,  0.3106, -0.1774,  0.3406, -0.2674,\n         0.0801,  0.0230,  0.3237, -0.2659, -0.0452, -0.0121, -0.3350,  0.3055,\n        -0.2967, -0.0880,  0.2248,  0.0282,  0.1476,  0.3135, -0.2357,  0.1064,\n         0.2699,  0.3105,  0.1410, -0.3070, -0.2749, -0.1308, -0.3104,  0.3492,\n         0.2655,  0.2632, -0.0665,  0.1458,  0.1945,  0.0315, -0.0460, -0.0697,\n        -0.2843,  0.2807,  0.1507, -0.3135,  0.1302,  0.0391, -0.3516,  0.1666,\n        -0.2778,  0.0978,  0.0126,  0.2929,  0.1768, -0.2638, -0.2872,  0.2763,\n         0.2459,  0.1794, -0.1560, -0.1406, -0.2895,  0.0061,  0.1464,  0.2574,\n         0.0724, -0.2178, -0.0058, -0.3400,  0.1867, -0.1686, -0.0420,  0.1687,\n        -0.2216, -0.1190, -0.1460,  0.1777, -0.2915, -0.3127, -0.2870,  0.0481,\n        -0.2023,  0.1033, -0.0534, -0.0205,  0.2536, -0.0305,  0.2463,  0.0687],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2502,  0.0365, -0.2252,  ...,  0.1498,  0.1389, -0.0681],\n        [ 0.1387, -0.2092, -0.3522,  ..., -0.3455,  0.3447,  0.0060],\n        [-0.1969,  0.3200,  0.0584,  ..., -0.1114, -0.2790,  0.2735],\n        ...,\n        [-0.1762, -0.2351,  0.2615,  ..., -0.2681,  0.2851,  0.1210],\n        [ 0.2103,  0.3079,  0.1874,  ...,  0.0037, -0.2789, -0.1707],\n        [-0.1437, -0.0494,  0.1073,  ..., -0.1371,  0.0015,  0.2300]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 4.4370e-02,  6.4878e-02, -4.0119e-02,  4.4847e-04, -2.3465e-02,\n        -1.6738e-02, -5.6096e-02, -8.2396e-02, -4.4058e-02,  3.4189e-02,\n        -6.4288e-02, -7.5513e-02, -2.0088e-02, -6.9763e-02,  1.6160e-02,\n        -7.4701e-02, -3.1684e-03, -8.0476e-02,  1.6374e-02, -3.3868e-02,\n         2.7967e-02,  6.6445e-02,  5.0485e-02, -2.1680e-02, -6.7779e-02,\n         6.5346e-02, -1.5083e-02, -4.3901e-02, -3.9729e-02,  4.8671e-02,\n        -3.5648e-02,  7.6952e-02, -3.1878e-02, -5.3509e-02, -1.1224e-02,\n         3.9288e-02, -4.7966e-02,  6.0488e-02, -5.7700e-02,  6.5804e-02,\n         5.7941e-02, -4.0056e-02, -7.6579e-02,  2.8197e-03,  3.2772e-02,\n         6.9360e-02,  4.2044e-02,  5.8692e-02,  6.6980e-02,  6.6403e-02,\n         1.4689e-02,  8.0458e-05, -2.5712e-02, -6.4401e-02, -4.4188e-02,\n         2.2139e-02,  5.6096e-02,  4.5315e-02, -7.0934e-02, -2.5589e-02,\n         2.3264e-02, -2.0987e-02,  3.2094e-02, -5.9258e-02,  4.6663e-02,\n        -8.3540e-02,  3.5806e-02, -4.6335e-02,  5.8413e-02, -5.5842e-02,\n         1.8774e-02, -6.3540e-02,  9.9236e-03,  3.5324e-02,  2.3517e-03,\n        -3.3173e-02, -2.4573e-02,  6.0627e-02, -2.9931e-02, -5.8150e-02,\n         2.4064e-02, -2.9798e-03, -1.9220e-02,  3.0005e-03, -5.6957e-02,\n        -7.8824e-02,  1.3231e-02,  6.2770e-02,  5.1438e-02, -8.0582e-02,\n         6.5070e-02,  3.4753e-02, -8.7977e-02, -1.5938e-02, -6.8862e-02,\n        -5.6407e-02, -8.7546e-02,  1.4159e-02,  8.4407e-02,  6.7315e-02,\n         1.0022e-02,  5.6319e-02,  6.8524e-02, -7.3142e-02,  6.8264e-02,\n        -7.3658e-02,  1.4163e-02,  9.6403e-03, -2.4748e-02, -7.1858e-02,\n        -1.0603e-02,  5.0081e-02,  2.7910e-02, -4.1149e-02, -8.6485e-02,\n        -4.1397e-03,  3.3330e-02,  4.5546e-02,  7.2970e-02,  8.1677e-02,\n         6.9689e-03,  6.8728e-02,  6.0044e-02,  7.5296e-02,  8.6720e-02,\n        -3.0090e-02, -8.8104e-02,  5.9595e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0711,  0.0607, -0.0686,  ...,  0.0613, -0.0226,  0.0781],\n        [ 0.0351, -0.0795,  0.0231,  ...,  0.0100, -0.0057,  0.0773],\n        [-0.0168, -0.0007, -0.0542,  ..., -0.0349,  0.0073, -0.0773],\n        ...,\n        [-0.0315, -0.0145, -0.0692,  ..., -0.0123, -0.0658,  0.0790],\n        [ 0.0707,  0.0683,  0.0589,  ..., -0.0035, -0.0864,  0.0313],\n        [-0.0167,  0.0502, -0.0250,  ..., -0.0440,  0.0035, -0.0232]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0011, -0.0634, -0.0796,  0.0376], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 2.4421e-02,  2.7138e-02, -6.8599e-02,  6.6863e-02,  8.5871e-02,\n         -6.9839e-02, -2.3322e-02, -8.4168e-02, -6.6199e-02,  1.2058e-02,\n          7.7013e-02,  1.7921e-03, -2.2621e-02, -7.2078e-02, -2.4161e-02,\n         -4.5017e-02,  2.7320e-02, -5.4864e-02,  7.2091e-02, -2.5032e-02,\n          7.4790e-02, -1.8587e-02, -2.5854e-02, -1.2681e-02,  6.1813e-02,\n          2.8951e-04,  8.6763e-02,  1.8947e-02,  7.1692e-02,  3.4369e-02,\n          2.3220e-02, -2.9149e-02,  5.6004e-02, -1.0307e-02,  2.3414e-02,\n         -5.6156e-04, -5.7581e-02, -4.9251e-02, -1.7022e-02,  4.4266e-03,\n          6.7556e-02, -8.2152e-02,  6.2762e-02,  1.7249e-03, -4.3868e-02,\n         -7.9716e-02,  3.7605e-02, -3.2992e-02,  2.0789e-02,  4.6890e-02,\n          8.1693e-02,  7.0143e-02,  1.7489e-02,  8.5652e-02, -6.0229e-02,\n         -9.9129e-03,  2.9474e-02, -2.6670e-03,  6.2380e-02, -7.8466e-02,\n         -9.5268e-04,  8.3218e-02, -1.5175e-02, -2.0281e-03, -7.8766e-02,\n          8.7225e-02, -1.8060e-02, -6.7581e-02, -3.6585e-02,  7.5059e-03,\n          8.2517e-02,  7.7962e-03, -5.3735e-02,  4.1230e-02, -3.9830e-02,\n          3.7132e-02, -8.5201e-02, -1.5740e-02, -7.0132e-02, -3.0139e-02,\n         -6.7430e-02, -8.3310e-02,  2.0247e-02,  4.4967e-02, -7.3317e-02,\n         -2.7062e-02,  5.5324e-02,  3.3261e-02, -9.1058e-05,  6.6511e-03,\n          1.0770e-02, -3.1534e-02,  5.0329e-02,  1.8882e-02,  5.0761e-02,\n         -4.6694e-02,  3.5373e-02,  5.7273e-02, -4.4005e-02, -5.5671e-02,\n         -8.6055e-02, -4.1178e-02, -1.4080e-02,  2.4047e-03,  2.0417e-02,\n         -5.6230e-02,  7.2016e-02, -2.4005e-02, -6.2448e-02,  3.3794e-02,\n          8.2029e-02,  1.7898e-02, -1.2806e-02, -3.6593e-02, -3.0906e-02,\n         -7.0245e-02,  1.8777e-02, -1.8888e-02,  5.7290e-02,  8.0065e-02,\n         -1.4646e-02,  6.3237e-02,  8.5183e-03, -4.0534e-02,  2.7947e-02,\n         -8.0986e-03,  5.6830e-02,  1.2954e-02],\n        [-3.9259e-02,  6.7994e-02,  6.4605e-02, -7.7256e-02,  4.5485e-02,\n         -7.5048e-02,  7.8979e-02,  1.1335e-02, -2.6075e-02, -4.0562e-03,\n          1.8212e-02,  2.1611e-02, -2.0613e-02,  7.8222e-02,  1.6890e-02,\n         -5.7215e-02, -8.5939e-02, -5.0318e-02, -6.7130e-02,  6.6999e-02,\n         -5.6041e-02, -4.7633e-02, -6.7739e-02,  3.7991e-02,  5.1743e-02,\n          7.4454e-02, -4.8289e-02, -1.6725e-02, -8.4649e-02,  2.3609e-02,\n         -3.0455e-02, -6.7078e-02,  8.1190e-02,  3.1774e-02, -3.4111e-02,\n          6.0662e-02, -4.8613e-02,  4.2174e-02, -6.6027e-02, -3.8183e-02,\n         -3.7524e-02, -1.1962e-03,  6.2853e-02, -4.9496e-03, -7.6068e-02,\n         -6.2790e-02,  1.3856e-02, -5.7405e-02, -7.7012e-02,  6.5768e-02,\n         -3.5593e-02,  8.6976e-02,  8.4549e-02,  8.3418e-02, -5.5592e-02,\n          1.4085e-02, -7.0121e-03, -8.4606e-02,  3.2633e-02,  3.0268e-02,\n         -3.8724e-02,  6.1540e-02, -5.5652e-02,  3.2288e-02,  6.8193e-02,\n         -7.7797e-02,  1.0909e-02,  4.5157e-02, -5.6385e-02, -4.8495e-02,\n          8.4437e-02,  5.3665e-02,  3.2583e-02, -1.1087e-02,  6.1649e-02,\n         -2.0172e-02,  8.1170e-02, -3.0263e-02, -4.4945e-02,  8.2023e-02,\n          5.1174e-02, -5.1464e-02, -7.2442e-02,  7.4138e-02, -1.2888e-02,\n         -1.7682e-02,  6.9233e-02, -3.8352e-03, -2.8571e-02,  4.8241e-02,\n          3.5597e-02,  3.5590e-02,  3.3355e-02, -2.4221e-02,  1.4743e-02,\n         -2.8846e-02, -1.4260e-03, -6.7637e-03,  4.2668e-02, -5.7985e-03,\n          1.5382e-02,  3.4283e-02, -3.2681e-02, -4.3464e-02, -7.5962e-02,\n         -2.0739e-02, -9.3524e-03,  2.7845e-03, -8.1959e-02,  5.3524e-02,\n          8.5707e-02, -8.5362e-02,  3.0694e-02, -4.8746e-02,  7.2948e-02,\n         -1.9909e-02,  4.4012e-02,  6.7270e-02, -4.1408e-02, -5.9092e-02,\n          4.1276e-02,  3.9474e-02,  4.8725e-02, -5.8022e-02,  4.8207e-02,\n         -6.3590e-02,  4.6524e-02,  2.7157e-02],\n        [-9.8022e-03, -3.9838e-02, -5.7910e-02,  2.1846e-02, -2.8256e-03,\n          9.8618e-03,  1.0878e-02,  7.1018e-02,  1.8129e-02, -8.7037e-02,\n          2.6861e-02,  2.5790e-02, -8.6281e-02,  4.1935e-02, -6.9165e-02,\n         -7.5115e-02,  4.3986e-02, -3.2327e-02, -2.0628e-02, -1.7719e-02,\n         -4.0887e-02,  4.1429e-02,  3.8951e-02,  8.0310e-02,  7.4047e-02,\n         -6.6079e-02,  5.1861e-02, -3.1231e-02,  7.4708e-02,  6.0157e-02,\n         -1.2814e-02,  3.4444e-02,  2.4119e-02, -8.7920e-02,  2.0268e-02,\n          5.2317e-02, -5.1574e-02,  3.5493e-02,  6.6770e-02,  8.8132e-02,\n         -7.9554e-02, -6.8884e-02, -5.1500e-02, -3.3718e-02,  2.7538e-03,\n          9.2709e-03, -5.7689e-02, -1.0770e-03,  5.9678e-02,  4.0057e-02,\n         -1.3274e-02,  7.9710e-03,  2.1416e-02, -4.3642e-02, -7.7882e-03,\n         -3.0761e-02, -1.4413e-02,  2.7100e-02, -5.7649e-02,  2.2627e-02,\n          8.3319e-03, -2.4125e-02, -4.9691e-02, -4.9804e-02,  7.7851e-02,\n         -2.5455e-02,  5.6078e-02, -2.7794e-02,  4.9154e-02,  1.8333e-02,\n          4.8254e-03,  4.1818e-02, -6.8991e-02, -8.7611e-02,  3.1590e-02,\n          2.9839e-02, -1.4171e-03, -3.5461e-02, -3.3854e-02,  8.5732e-02,\n          3.8687e-02,  2.2249e-02, -2.3404e-02,  7.1735e-02, -1.9051e-02,\n         -5.3549e-02,  8.0323e-02,  1.7085e-02, -4.2167e-02,  6.0394e-02,\n          9.1501e-03,  3.7278e-02,  6.0219e-02,  4.4765e-02,  8.5140e-02,\n         -3.4306e-02, -4.3651e-02,  7.4921e-03,  5.0493e-02,  6.6890e-02,\n         -8.5150e-02, -4.1423e-02,  1.1233e-02, -7.6051e-02,  2.4843e-02,\n          5.2286e-03,  1.2702e-02, -5.3120e-02,  1.1789e-02, -6.2491e-02,\n          7.3821e-02, -3.3348e-02, -1.2786e-02,  2.9999e-02,  6.2877e-02,\n         -2.1449e-02, -4.3580e-02, -2.9710e-02, -1.3881e-02, -3.2517e-02,\n          3.6486e-02, -4.6828e-03,  7.8054e-02, -5.7203e-03,  5.8596e-02,\n          4.4255e-03, -2.1213e-02,  1.3042e-02],\n        [-7.3402e-02,  6.3667e-02,  2.1294e-02,  1.8986e-02, -2.7823e-02,\n          3.9137e-02,  2.8287e-02,  6.7064e-03, -4.9702e-02,  7.5334e-02,\n          6.7367e-03, -2.6290e-02, -2.1108e-02,  5.9892e-02,  7.1583e-02,\n          7.6712e-02, -7.4535e-02, -3.3776e-02, -1.0379e-02,  2.1773e-02,\n          5.0594e-02, -2.4632e-02, -7.4537e-02, -5.4535e-02,  4.9364e-02,\n          3.7530e-04,  7.0767e-03,  2.5350e-02, -7.9056e-02, -3.7423e-02,\n         -5.6679e-02,  8.4202e-03, -3.4866e-02,  8.6825e-02,  2.2897e-02,\n         -3.3322e-02,  4.8179e-02, -1.1652e-02,  9.5659e-03,  8.0651e-02,\n          2.8301e-03, -8.2784e-02,  1.4823e-02,  3.6068e-02, -8.5675e-02,\n         -8.8341e-02,  5.2157e-02, -1.2107e-03,  8.8493e-03,  7.3485e-02,\n         -1.6162e-02,  5.7298e-02,  6.0185e-03, -8.2882e-02, -2.9792e-02,\n          6.2890e-02,  7.3558e-03, -8.4279e-02,  6.4424e-02,  3.6261e-02,\n          1.4436e-02,  7.6610e-02,  4.7657e-02,  6.5526e-02,  3.0869e-02,\n         -2.8102e-02,  7.9387e-02, -1.3699e-02, -7.7407e-03,  1.4021e-02,\n          8.3344e-02, -4.0828e-02,  4.0468e-02, -7.5615e-02, -5.6037e-02,\n         -1.6387e-02,  7.2803e-03, -9.0882e-03,  2.7110e-02, -4.4247e-02,\n         -8.8062e-02,  4.5229e-03, -1.6496e-02,  5.1969e-03, -2.6065e-02,\n         -5.4026e-02, -1.4540e-02, -5.5038e-02, -8.7405e-02, -2.6709e-02,\n         -8.0527e-02,  7.5164e-02, -2.9020e-02, -2.8515e-02, -5.7081e-02,\n         -7.4737e-02,  2.4357e-02,  3.6570e-02,  4.1887e-02,  5.4961e-03,\n         -4.8232e-02, -2.9238e-02,  5.4198e-02, -2.3961e-02, -1.9890e-02,\n         -3.8224e-02,  7.9549e-02,  8.4535e-02, -8.7439e-02,  3.6450e-03,\n          8.5346e-02,  2.7064e-02, -2.6950e-02,  2.9177e-02, -6.5418e-02,\n          8.8481e-03, -7.2905e-02, -4.4194e-02, -7.8399e-02, -8.5679e-02,\n          6.4507e-02,  2.3032e-03,  7.5128e-02,  8.1332e-02, -6.8904e-02,\n         -3.8234e-04,  2.3678e-02, -3.5573e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2502,  0.0365, -0.2252,  ...,  0.1498,  0.1389, -0.0681],\n        [ 0.1387, -0.2092, -0.3522,  ..., -0.3455,  0.3447,  0.0060],\n        [-0.1969,  0.3200,  0.0584,  ..., -0.1114, -0.2790,  0.2735],\n        ...,\n        [-0.1762, -0.2351,  0.2615,  ..., -0.2681,  0.2851,  0.1210],\n        [ 0.2103,  0.3079,  0.1874,  ...,  0.0037, -0.2789, -0.1707],\n        [-0.1437, -0.0494,  0.1073,  ..., -0.1371,  0.0015,  0.2300]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3155, -0.0389, -0.3300,  0.0416, -0.3523, -0.2764,  0.1968, -0.1802,\n        -0.1811,  0.1317, -0.0721,  0.0746, -0.2536,  0.1684,  0.2119,  0.1209,\n        -0.1526, -0.1199,  0.2575,  0.2377, -0.3245,  0.2554,  0.2698,  0.3168,\n        -0.0067, -0.0940,  0.2167,  0.1098, -0.1414, -0.0744, -0.3247, -0.2423,\n         0.1801,  0.0545, -0.3430, -0.3071,  0.0145, -0.0712,  0.1480, -0.3361,\n         0.0726,  0.0625,  0.1461,  0.1044,  0.3106, -0.1774,  0.3406, -0.2674,\n         0.0801,  0.0230,  0.3237, -0.2659, -0.0452, -0.0121, -0.3350,  0.3055,\n        -0.2967, -0.0880,  0.2248,  0.0282,  0.1476,  0.3135, -0.2357,  0.1064,\n         0.2699,  0.3105,  0.1410, -0.3070, -0.2749, -0.1308, -0.3104,  0.3492,\n         0.2655,  0.2632, -0.0665,  0.1458,  0.1945,  0.0315, -0.0460, -0.0697,\n        -0.2843,  0.2807,  0.1507, -0.3135,  0.1302,  0.0391, -0.3516,  0.1666,\n        -0.2778,  0.0978,  0.0126,  0.2929,  0.1768, -0.2638, -0.2872,  0.2763,\n         0.2459,  0.1794, -0.1560, -0.1406, -0.2895,  0.0061,  0.1464,  0.2574,\n         0.0724, -0.2178, -0.0058, -0.3400,  0.1867, -0.1686, -0.0420,  0.1687,\n        -0.2216, -0.1190, -0.1460,  0.1777, -0.2915, -0.3127, -0.2870,  0.0481,\n        -0.2023,  0.1033, -0.0534, -0.0205,  0.2536, -0.0305,  0.2463,  0.0687],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0711,  0.0607, -0.0686,  ...,  0.0613, -0.0226,  0.0781],\n        [ 0.0351, -0.0795,  0.0231,  ...,  0.0100, -0.0057,  0.0773],\n        [-0.0168, -0.0007, -0.0542,  ..., -0.0349,  0.0073, -0.0773],\n        ...,\n        [-0.0315, -0.0145, -0.0692,  ..., -0.0123, -0.0658,  0.0790],\n        [ 0.0707,  0.0683,  0.0589,  ..., -0.0035, -0.0864,  0.0313],\n        [-0.0167,  0.0502, -0.0250,  ..., -0.0440,  0.0035, -0.0232]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 4.4370e-02,  6.4878e-02, -4.0119e-02,  4.4847e-04, -2.3465e-02,\n        -1.6738e-02, -5.6096e-02, -8.2396e-02, -4.4058e-02,  3.4189e-02,\n        -6.4288e-02, -7.5513e-02, -2.0088e-02, -6.9763e-02,  1.6160e-02,\n        -7.4701e-02, -3.1684e-03, -8.0476e-02,  1.6374e-02, -3.3868e-02,\n         2.7967e-02,  6.6445e-02,  5.0485e-02, -2.1680e-02, -6.7779e-02,\n         6.5346e-02, -1.5083e-02, -4.3901e-02, -3.9729e-02,  4.8671e-02,\n        -3.5648e-02,  7.6952e-02, -3.1878e-02, -5.3509e-02, -1.1224e-02,\n         3.9288e-02, -4.7966e-02,  6.0488e-02, -5.7700e-02,  6.5804e-02,\n         5.7941e-02, -4.0056e-02, -7.6579e-02,  2.8197e-03,  3.2772e-02,\n         6.9360e-02,  4.2044e-02,  5.8692e-02,  6.6980e-02,  6.6403e-02,\n         1.4689e-02,  8.0458e-05, -2.5712e-02, -6.4401e-02, -4.4188e-02,\n         2.2139e-02,  5.6096e-02,  4.5315e-02, -7.0934e-02, -2.5589e-02,\n         2.3264e-02, -2.0987e-02,  3.2094e-02, -5.9258e-02,  4.6663e-02,\n        -8.3540e-02,  3.5806e-02, -4.6335e-02,  5.8413e-02, -5.5842e-02,\n         1.8774e-02, -6.3540e-02,  9.9236e-03,  3.5324e-02,  2.3517e-03,\n        -3.3173e-02, -2.4573e-02,  6.0627e-02, -2.9931e-02, -5.8150e-02,\n         2.4064e-02, -2.9798e-03, -1.9220e-02,  3.0005e-03, -5.6957e-02,\n        -7.8824e-02,  1.3231e-02,  6.2770e-02,  5.1438e-02, -8.0582e-02,\n         6.5070e-02,  3.4753e-02, -8.7977e-02, -1.5938e-02, -6.8862e-02,\n        -5.6407e-02, -8.7546e-02,  1.4159e-02,  8.4407e-02,  6.7315e-02,\n         1.0022e-02,  5.6319e-02,  6.8524e-02, -7.3142e-02,  6.8264e-02,\n        -7.3658e-02,  1.4163e-02,  9.6403e-03, -2.4748e-02, -7.1858e-02,\n        -1.0603e-02,  5.0081e-02,  2.7910e-02, -4.1149e-02, -8.6485e-02,\n        -4.1397e-03,  3.3330e-02,  4.5546e-02,  7.2970e-02,  8.1677e-02,\n         6.9689e-03,  6.8728e-02,  6.0044e-02,  7.5296e-02,  8.6720e-02,\n        -3.0090e-02, -8.8104e-02,  5.9595e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 2.4421e-02,  2.7138e-02, -6.8599e-02,  6.6863e-02,  8.5871e-02,\n         -6.9839e-02, -2.3322e-02, -8.4168e-02, -6.6199e-02,  1.2058e-02,\n          7.7013e-02,  1.7921e-03, -2.2621e-02, -7.2078e-02, -2.4161e-02,\n         -4.5017e-02,  2.7320e-02, -5.4864e-02,  7.2091e-02, -2.5032e-02,\n          7.4790e-02, -1.8587e-02, -2.5854e-02, -1.2681e-02,  6.1813e-02,\n          2.8951e-04,  8.6763e-02,  1.8947e-02,  7.1692e-02,  3.4369e-02,\n          2.3220e-02, -2.9149e-02,  5.6004e-02, -1.0307e-02,  2.3414e-02,\n         -5.6156e-04, -5.7581e-02, -4.9251e-02, -1.7022e-02,  4.4266e-03,\n          6.7556e-02, -8.2152e-02,  6.2762e-02,  1.7249e-03, -4.3868e-02,\n         -7.9716e-02,  3.7605e-02, -3.2992e-02,  2.0789e-02,  4.6890e-02,\n          8.1693e-02,  7.0143e-02,  1.7489e-02,  8.5652e-02, -6.0229e-02,\n         -9.9129e-03,  2.9474e-02, -2.6670e-03,  6.2380e-02, -7.8466e-02,\n         -9.5268e-04,  8.3218e-02, -1.5175e-02, -2.0281e-03, -7.8766e-02,\n          8.7225e-02, -1.8060e-02, -6.7581e-02, -3.6585e-02,  7.5059e-03,\n          8.2517e-02,  7.7962e-03, -5.3735e-02,  4.1230e-02, -3.9830e-02,\n          3.7132e-02, -8.5201e-02, -1.5740e-02, -7.0132e-02, -3.0139e-02,\n         -6.7430e-02, -8.3310e-02,  2.0247e-02,  4.4967e-02, -7.3317e-02,\n         -2.7062e-02,  5.5324e-02,  3.3261e-02, -9.1058e-05,  6.6511e-03,\n          1.0770e-02, -3.1534e-02,  5.0329e-02,  1.8882e-02,  5.0761e-02,\n         -4.6694e-02,  3.5373e-02,  5.7273e-02, -4.4005e-02, -5.5671e-02,\n         -8.6055e-02, -4.1178e-02, -1.4080e-02,  2.4047e-03,  2.0417e-02,\n         -5.6230e-02,  7.2016e-02, -2.4005e-02, -6.2448e-02,  3.3794e-02,\n          8.2029e-02,  1.7898e-02, -1.2806e-02, -3.6593e-02, -3.0906e-02,\n         -7.0245e-02,  1.8777e-02, -1.8888e-02,  5.7290e-02,  8.0065e-02,\n         -1.4646e-02,  6.3237e-02,  8.5183e-03, -4.0534e-02,  2.7947e-02,\n         -8.0986e-03,  5.6830e-02,  1.2954e-02],\n        [-3.9259e-02,  6.7994e-02,  6.4605e-02, -7.7256e-02,  4.5485e-02,\n         -7.5048e-02,  7.8979e-02,  1.1335e-02, -2.6075e-02, -4.0562e-03,\n          1.8212e-02,  2.1611e-02, -2.0613e-02,  7.8222e-02,  1.6890e-02,\n         -5.7215e-02, -8.5939e-02, -5.0318e-02, -6.7130e-02,  6.6999e-02,\n         -5.6041e-02, -4.7633e-02, -6.7739e-02,  3.7991e-02,  5.1743e-02,\n          7.4454e-02, -4.8289e-02, -1.6725e-02, -8.4649e-02,  2.3609e-02,\n         -3.0455e-02, -6.7078e-02,  8.1190e-02,  3.1774e-02, -3.4111e-02,\n          6.0662e-02, -4.8613e-02,  4.2174e-02, -6.6027e-02, -3.8183e-02,\n         -3.7524e-02, -1.1962e-03,  6.2853e-02, -4.9496e-03, -7.6068e-02,\n         -6.2790e-02,  1.3856e-02, -5.7405e-02, -7.7012e-02,  6.5768e-02,\n         -3.5593e-02,  8.6976e-02,  8.4549e-02,  8.3418e-02, -5.5592e-02,\n          1.4085e-02, -7.0121e-03, -8.4606e-02,  3.2633e-02,  3.0268e-02,\n         -3.8724e-02,  6.1540e-02, -5.5652e-02,  3.2288e-02,  6.8193e-02,\n         -7.7797e-02,  1.0909e-02,  4.5157e-02, -5.6385e-02, -4.8495e-02,\n          8.4437e-02,  5.3665e-02,  3.2583e-02, -1.1087e-02,  6.1649e-02,\n         -2.0172e-02,  8.1170e-02, -3.0263e-02, -4.4945e-02,  8.2023e-02,\n          5.1174e-02, -5.1464e-02, -7.2442e-02,  7.4138e-02, -1.2888e-02,\n         -1.7682e-02,  6.9233e-02, -3.8352e-03, -2.8571e-02,  4.8241e-02,\n          3.5597e-02,  3.5590e-02,  3.3355e-02, -2.4221e-02,  1.4743e-02,\n         -2.8846e-02, -1.4260e-03, -6.7637e-03,  4.2668e-02, -5.7985e-03,\n          1.5382e-02,  3.4283e-02, -3.2681e-02, -4.3464e-02, -7.5962e-02,\n         -2.0739e-02, -9.3524e-03,  2.7845e-03, -8.1959e-02,  5.3524e-02,\n          8.5707e-02, -8.5362e-02,  3.0694e-02, -4.8746e-02,  7.2948e-02,\n         -1.9909e-02,  4.4012e-02,  6.7270e-02, -4.1408e-02, -5.9092e-02,\n          4.1276e-02,  3.9474e-02,  4.8725e-02, -5.8022e-02,  4.8207e-02,\n         -6.3590e-02,  4.6524e-02,  2.7157e-02],\n        [-9.8022e-03, -3.9838e-02, -5.7910e-02,  2.1846e-02, -2.8256e-03,\n          9.8618e-03,  1.0878e-02,  7.1018e-02,  1.8129e-02, -8.7037e-02,\n          2.6861e-02,  2.5790e-02, -8.6281e-02,  4.1935e-02, -6.9165e-02,\n         -7.5115e-02,  4.3986e-02, -3.2327e-02, -2.0628e-02, -1.7719e-02,\n         -4.0887e-02,  4.1429e-02,  3.8951e-02,  8.0310e-02,  7.4047e-02,\n         -6.6079e-02,  5.1861e-02, -3.1231e-02,  7.4708e-02,  6.0157e-02,\n         -1.2814e-02,  3.4444e-02,  2.4119e-02, -8.7920e-02,  2.0268e-02,\n          5.2317e-02, -5.1574e-02,  3.5493e-02,  6.6770e-02,  8.8132e-02,\n         -7.9554e-02, -6.8884e-02, -5.1500e-02, -3.3718e-02,  2.7538e-03,\n          9.2709e-03, -5.7689e-02, -1.0770e-03,  5.9678e-02,  4.0057e-02,\n         -1.3274e-02,  7.9710e-03,  2.1416e-02, -4.3642e-02, -7.7882e-03,\n         -3.0761e-02, -1.4413e-02,  2.7100e-02, -5.7649e-02,  2.2627e-02,\n          8.3319e-03, -2.4125e-02, -4.9691e-02, -4.9804e-02,  7.7851e-02,\n         -2.5455e-02,  5.6078e-02, -2.7794e-02,  4.9154e-02,  1.8333e-02,\n          4.8254e-03,  4.1818e-02, -6.8991e-02, -8.7611e-02,  3.1590e-02,\n          2.9839e-02, -1.4171e-03, -3.5461e-02, -3.3854e-02,  8.5732e-02,\n          3.8687e-02,  2.2249e-02, -2.3404e-02,  7.1735e-02, -1.9051e-02,\n         -5.3549e-02,  8.0323e-02,  1.7085e-02, -4.2167e-02,  6.0394e-02,\n          9.1501e-03,  3.7278e-02,  6.0219e-02,  4.4765e-02,  8.5140e-02,\n         -3.4306e-02, -4.3651e-02,  7.4921e-03,  5.0493e-02,  6.6890e-02,\n         -8.5150e-02, -4.1423e-02,  1.1233e-02, -7.6051e-02,  2.4843e-02,\n          5.2286e-03,  1.2702e-02, -5.3120e-02,  1.1789e-02, -6.2491e-02,\n          7.3821e-02, -3.3348e-02, -1.2786e-02,  2.9999e-02,  6.2877e-02,\n         -2.1449e-02, -4.3580e-02, -2.9710e-02, -1.3881e-02, -3.2517e-02,\n          3.6486e-02, -4.6828e-03,  7.8054e-02, -5.7203e-03,  5.8596e-02,\n          4.4255e-03, -2.1213e-02,  1.3042e-02],\n        [-7.3402e-02,  6.3667e-02,  2.1294e-02,  1.8986e-02, -2.7823e-02,\n          3.9137e-02,  2.8287e-02,  6.7064e-03, -4.9702e-02,  7.5334e-02,\n          6.7367e-03, -2.6290e-02, -2.1108e-02,  5.9892e-02,  7.1583e-02,\n          7.6712e-02, -7.4535e-02, -3.3776e-02, -1.0379e-02,  2.1773e-02,\n          5.0594e-02, -2.4632e-02, -7.4537e-02, -5.4535e-02,  4.9364e-02,\n          3.7530e-04,  7.0767e-03,  2.5350e-02, -7.9056e-02, -3.7423e-02,\n         -5.6679e-02,  8.4202e-03, -3.4866e-02,  8.6825e-02,  2.2897e-02,\n         -3.3322e-02,  4.8179e-02, -1.1652e-02,  9.5659e-03,  8.0651e-02,\n          2.8301e-03, -8.2784e-02,  1.4823e-02,  3.6068e-02, -8.5675e-02,\n         -8.8341e-02,  5.2157e-02, -1.2107e-03,  8.8493e-03,  7.3485e-02,\n         -1.6162e-02,  5.7298e-02,  6.0185e-03, -8.2882e-02, -2.9792e-02,\n          6.2890e-02,  7.3558e-03, -8.4279e-02,  6.4424e-02,  3.6261e-02,\n          1.4436e-02,  7.6610e-02,  4.7657e-02,  6.5526e-02,  3.0869e-02,\n         -2.8102e-02,  7.9387e-02, -1.3699e-02, -7.7407e-03,  1.4021e-02,\n          8.3344e-02, -4.0828e-02,  4.0468e-02, -7.5615e-02, -5.6037e-02,\n         -1.6387e-02,  7.2803e-03, -9.0882e-03,  2.7110e-02, -4.4247e-02,\n         -8.8062e-02,  4.5229e-03, -1.6496e-02,  5.1969e-03, -2.6065e-02,\n         -5.4026e-02, -1.4540e-02, -5.5038e-02, -8.7405e-02, -2.6709e-02,\n         -8.0527e-02,  7.5164e-02, -2.9020e-02, -2.8515e-02, -5.7081e-02,\n         -7.4737e-02,  2.4357e-02,  3.6570e-02,  4.1887e-02,  5.4961e-03,\n         -4.8232e-02, -2.9238e-02,  5.4198e-02, -2.3961e-02, -1.9890e-02,\n         -3.8224e-02,  7.9549e-02,  8.4535e-02, -8.7439e-02,  3.6450e-03,\n          8.5346e-02,  2.7064e-02, -2.6950e-02,  2.9177e-02, -6.5418e-02,\n          8.8481e-03, -7.2905e-02, -4.4194e-02, -7.8399e-02, -8.5679e-02,\n          6.4507e-02,  2.3032e-03,  7.5128e-02,  8.1332e-02, -6.8904e-02,\n         -3.8234e-04,  2.3678e-02, -3.5573e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0011, -0.0634, -0.0796,  0.0376], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.EnhancedReplayBuffer object at 0x7e8031dca510>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "aux_buf_size":	5000,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	-1,
                    "epsilon_per_priority":	1e-06,
                    "gamma":	5,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "max_age":	20000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "num_segments":	0,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "sample_decay":	0.5,
                    "segment_size":	62499.0,
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x7e7fc295bc50>":	{
                            "capacity":	5000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3155, -0.0389, -0.3300,  0.0416, -0.3523, -0.2764,  0.1968, -0.1802,\n        -0.1811,  0.1317, -0.0721,  0.0746, -0.2536,  0.1684,  0.2119,  0.1209,\n        -0.1526, -0.1199,  0.2575,  0.2377, -0.3245,  0.2554,  0.2698,  0.3168,\n        -0.0067, -0.0940,  0.2167,  0.1098, -0.1414, -0.0744, -0.3247, -0.2423,\n         0.1801,  0.0545, -0.3430, -0.3071,  0.0145, -0.0712,  0.1480, -0.3361,\n         0.0726,  0.0625,  0.1461,  0.1044,  0.3106, -0.1774,  0.3406, -0.2674,\n         0.0801,  0.0230,  0.3237, -0.2659, -0.0452, -0.0121, -0.3350,  0.3055,\n        -0.2967, -0.0880,  0.2248,  0.0282,  0.1476,  0.3135, -0.2357,  0.1064,\n         0.2699,  0.3105,  0.1410, -0.3070, -0.2749, -0.1308, -0.3104,  0.3492,\n         0.2655,  0.2632, -0.0665,  0.1458,  0.1945,  0.0315, -0.0460, -0.0697,\n        -0.2843,  0.2807,  0.1507, -0.3135,  0.1302,  0.0391, -0.3516,  0.1666,\n        -0.2778,  0.0978,  0.0126,  0.2929,  0.1768, -0.2638, -0.2872,  0.2763,\n         0.2459,  0.1794, -0.1560, -0.1406, -0.2895,  0.0061,  0.1464,  0.2574,\n         0.0724, -0.2178, -0.0058, -0.3400,  0.1867, -0.1686, -0.0420,  0.1687,\n        -0.2216, -0.1190, -0.1460,  0.1777, -0.2915, -0.3127, -0.2870,  0.0481,\n        -0.2023,  0.1033, -0.0534, -0.0205,  0.2536, -0.0305,  0.2463,  0.0687],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2502,  0.0365, -0.2252,  ...,  0.1498,  0.1389, -0.0681],\n        [ 0.1387, -0.2092, -0.3522,  ..., -0.3455,  0.3447,  0.0060],\n        [-0.1969,  0.3200,  0.0584,  ..., -0.1114, -0.2790,  0.2735],\n        ...,\n        [-0.1762, -0.2351,  0.2615,  ..., -0.2681,  0.2851,  0.1210],\n        [ 0.2103,  0.3079,  0.1874,  ...,  0.0037, -0.2789, -0.1707],\n        [-0.1437, -0.0494,  0.1073,  ..., -0.1371,  0.0015,  0.2300]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 4.4370e-02,  6.4878e-02, -4.0119e-02,  4.4847e-04, -2.3465e-02,\n        -1.6738e-02, -5.6096e-02, -8.2396e-02, -4.4058e-02,  3.4189e-02,\n        -6.4288e-02, -7.5513e-02, -2.0088e-02, -6.9763e-02,  1.6160e-02,\n        -7.4701e-02, -3.1684e-03, -8.0476e-02,  1.6374e-02, -3.3868e-02,\n         2.7967e-02,  6.6445e-02,  5.0485e-02, -2.1680e-02, -6.7779e-02,\n         6.5346e-02, -1.5083e-02, -4.3901e-02, -3.9729e-02,  4.8671e-02,\n        -3.5648e-02,  7.6952e-02, -3.1878e-02, -5.3509e-02, -1.1224e-02,\n         3.9288e-02, -4.7966e-02,  6.0488e-02, -5.7700e-02,  6.5804e-02,\n         5.7941e-02, -4.0056e-02, -7.6579e-02,  2.8197e-03,  3.2772e-02,\n         6.9360e-02,  4.2044e-02,  5.8692e-02,  6.6980e-02,  6.6403e-02,\n         1.4689e-02,  8.0458e-05, -2.5712e-02, -6.4401e-02, -4.4188e-02,\n         2.2139e-02,  5.6096e-02,  4.5315e-02, -7.0934e-02, -2.5589e-02,\n         2.3264e-02, -2.0987e-02,  3.2094e-02, -5.9258e-02,  4.6663e-02,\n        -8.3540e-02,  3.5806e-02, -4.6335e-02,  5.8413e-02, -5.5842e-02,\n         1.8774e-02, -6.3540e-02,  9.9236e-03,  3.5324e-02,  2.3517e-03,\n        -3.3173e-02, -2.4573e-02,  6.0627e-02, -2.9931e-02, -5.8150e-02,\n         2.4064e-02, -2.9798e-03, -1.9220e-02,  3.0005e-03, -5.6957e-02,\n        -7.8824e-02,  1.3231e-02,  6.2770e-02,  5.1438e-02, -8.0582e-02,\n         6.5070e-02,  3.4753e-02, -8.7977e-02, -1.5938e-02, -6.8862e-02,\n        -5.6407e-02, -8.7546e-02,  1.4159e-02,  8.4407e-02,  6.7315e-02,\n         1.0022e-02,  5.6319e-02,  6.8524e-02, -7.3142e-02,  6.8264e-02,\n        -7.3658e-02,  1.4163e-02,  9.6403e-03, -2.4748e-02, -7.1858e-02,\n        -1.0603e-02,  5.0081e-02,  2.7910e-02, -4.1149e-02, -8.6485e-02,\n        -4.1397e-03,  3.3330e-02,  4.5546e-02,  7.2970e-02,  8.1677e-02,\n         6.9689e-03,  6.8728e-02,  6.0044e-02,  7.5296e-02,  8.6720e-02,\n        -3.0090e-02, -8.8104e-02,  5.9595e-02], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0711,  0.0607, -0.0686,  ...,  0.0613, -0.0226,  0.0781],\n        [ 0.0351, -0.0795,  0.0231,  ...,  0.0100, -0.0057,  0.0773],\n        [-0.0168, -0.0007, -0.0542,  ..., -0.0349,  0.0073, -0.0773],\n        ...,\n        [-0.0315, -0.0145, -0.0692,  ..., -0.0123, -0.0658,  0.0790],\n        [ 0.0707,  0.0683,  0.0589,  ..., -0.0035, -0.0864,  0.0313],\n        [-0.0167,  0.0502, -0.0250,  ..., -0.0440,  0.0035, -0.0232]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0011, -0.0634, -0.0796,  0.0376], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 2.4421e-02,  2.7138e-02, -6.8599e-02,  6.6863e-02,  8.5871e-02,\n         -6.9839e-02, -2.3322e-02, -8.4168e-02, -6.6199e-02,  1.2058e-02,\n          7.7013e-02,  1.7921e-03, -2.2621e-02, -7.2078e-02, -2.4161e-02,\n         -4.5017e-02,  2.7320e-02, -5.4864e-02,  7.2091e-02, -2.5032e-02,\n          7.4790e-02, -1.8587e-02, -2.5854e-02, -1.2681e-02,  6.1813e-02,\n          2.8951e-04,  8.6763e-02,  1.8947e-02,  7.1692e-02,  3.4369e-02,\n          2.3220e-02, -2.9149e-02,  5.6004e-02, -1.0307e-02,  2.3414e-02,\n         -5.6156e-04, -5.7581e-02, -4.9251e-02, -1.7022e-02,  4.4266e-03,\n          6.7556e-02, -8.2152e-02,  6.2762e-02,  1.7249e-03, -4.3868e-02,\n         -7.9716e-02,  3.7605e-02, -3.2992e-02,  2.0789e-02,  4.6890e-02,\n          8.1693e-02,  7.0143e-02,  1.7489e-02,  8.5652e-02, -6.0229e-02,\n         -9.9129e-03,  2.9474e-02, -2.6670e-03,  6.2380e-02, -7.8466e-02,\n         -9.5268e-04,  8.3218e-02, -1.5175e-02, -2.0281e-03, -7.8766e-02,\n          8.7225e-02, -1.8060e-02, -6.7581e-02, -3.6585e-02,  7.5059e-03,\n          8.2517e-02,  7.7962e-03, -5.3735e-02,  4.1230e-02, -3.9830e-02,\n          3.7132e-02, -8.5201e-02, -1.5740e-02, -7.0132e-02, -3.0139e-02,\n         -6.7430e-02, -8.3310e-02,  2.0247e-02,  4.4967e-02, -7.3317e-02,\n         -2.7062e-02,  5.5324e-02,  3.3261e-02, -9.1058e-05,  6.6511e-03,\n          1.0770e-02, -3.1534e-02,  5.0329e-02,  1.8882e-02,  5.0761e-02,\n         -4.6694e-02,  3.5373e-02,  5.7273e-02, -4.4005e-02, -5.5671e-02,\n         -8.6055e-02, -4.1178e-02, -1.4080e-02,  2.4047e-03,  2.0417e-02,\n         -5.6230e-02,  7.2016e-02, -2.4005e-02, -6.2448e-02,  3.3794e-02,\n          8.2029e-02,  1.7898e-02, -1.2806e-02, -3.6593e-02, -3.0906e-02,\n         -7.0245e-02,  1.8777e-02, -1.8888e-02,  5.7290e-02,  8.0065e-02,\n         -1.4646e-02,  6.3237e-02,  8.5183e-03, -4.0534e-02,  2.7947e-02,\n         -8.0986e-03,  5.6830e-02,  1.2954e-02],\n        [-3.9259e-02,  6.7994e-02,  6.4605e-02, -7.7256e-02,  4.5485e-02,\n         -7.5048e-02,  7.8979e-02,  1.1335e-02, -2.6075e-02, -4.0562e-03,\n          1.8212e-02,  2.1611e-02, -2.0613e-02,  7.8222e-02,  1.6890e-02,\n         -5.7215e-02, -8.5939e-02, -5.0318e-02, -6.7130e-02,  6.6999e-02,\n         -5.6041e-02, -4.7633e-02, -6.7739e-02,  3.7991e-02,  5.1743e-02,\n          7.4454e-02, -4.8289e-02, -1.6725e-02, -8.4649e-02,  2.3609e-02,\n         -3.0455e-02, -6.7078e-02,  8.1190e-02,  3.1774e-02, -3.4111e-02,\n          6.0662e-02, -4.8613e-02,  4.2174e-02, -6.6027e-02, -3.8183e-02,\n         -3.7524e-02, -1.1962e-03,  6.2853e-02, -4.9496e-03, -7.6068e-02,\n         -6.2790e-02,  1.3856e-02, -5.7405e-02, -7.7012e-02,  6.5768e-02,\n         -3.5593e-02,  8.6976e-02,  8.4549e-02,  8.3418e-02, -5.5592e-02,\n          1.4085e-02, -7.0121e-03, -8.4606e-02,  3.2633e-02,  3.0268e-02,\n         -3.8724e-02,  6.1540e-02, -5.5652e-02,  3.2288e-02,  6.8193e-02,\n         -7.7797e-02,  1.0909e-02,  4.5157e-02, -5.6385e-02, -4.8495e-02,\n          8.4437e-02,  5.3665e-02,  3.2583e-02, -1.1087e-02,  6.1649e-02,\n         -2.0172e-02,  8.1170e-02, -3.0263e-02, -4.4945e-02,  8.2023e-02,\n          5.1174e-02, -5.1464e-02, -7.2442e-02,  7.4138e-02, -1.2888e-02,\n         -1.7682e-02,  6.9233e-02, -3.8352e-03, -2.8571e-02,  4.8241e-02,\n          3.5597e-02,  3.5590e-02,  3.3355e-02, -2.4221e-02,  1.4743e-02,\n         -2.8846e-02, -1.4260e-03, -6.7637e-03,  4.2668e-02, -5.7985e-03,\n          1.5382e-02,  3.4283e-02, -3.2681e-02, -4.3464e-02, -7.5962e-02,\n         -2.0739e-02, -9.3524e-03,  2.7845e-03, -8.1959e-02,  5.3524e-02,\n          8.5707e-02, -8.5362e-02,  3.0694e-02, -4.8746e-02,  7.2948e-02,\n         -1.9909e-02,  4.4012e-02,  6.7270e-02, -4.1408e-02, -5.9092e-02,\n          4.1276e-02,  3.9474e-02,  4.8725e-02, -5.8022e-02,  4.8207e-02,\n         -6.3590e-02,  4.6524e-02,  2.7157e-02],\n        [-9.8022e-03, -3.9838e-02, -5.7910e-02,  2.1846e-02, -2.8256e-03,\n          9.8618e-03,  1.0878e-02,  7.1018e-02,  1.8129e-02, -8.7037e-02,\n          2.6861e-02,  2.5790e-02, -8.6281e-02,  4.1935e-02, -6.9165e-02,\n         -7.5115e-02,  4.3986e-02, -3.2327e-02, -2.0628e-02, -1.7719e-02,\n         -4.0887e-02,  4.1429e-02,  3.8951e-02,  8.0310e-02,  7.4047e-02,\n         -6.6079e-02,  5.1861e-02, -3.1231e-02,  7.4708e-02,  6.0157e-02,\n         -1.2814e-02,  3.4444e-02,  2.4119e-02, -8.7920e-02,  2.0268e-02,\n          5.2317e-02, -5.1574e-02,  3.5493e-02,  6.6770e-02,  8.8132e-02,\n         -7.9554e-02, -6.8884e-02, -5.1500e-02, -3.3718e-02,  2.7538e-03,\n          9.2709e-03, -5.7689e-02, -1.0770e-03,  5.9678e-02,  4.0057e-02,\n         -1.3274e-02,  7.9710e-03,  2.1416e-02, -4.3642e-02, -7.7882e-03,\n         -3.0761e-02, -1.4413e-02,  2.7100e-02, -5.7649e-02,  2.2627e-02,\n          8.3319e-03, -2.4125e-02, -4.9691e-02, -4.9804e-02,  7.7851e-02,\n         -2.5455e-02,  5.6078e-02, -2.7794e-02,  4.9154e-02,  1.8333e-02,\n          4.8254e-03,  4.1818e-02, -6.8991e-02, -8.7611e-02,  3.1590e-02,\n          2.9839e-02, -1.4171e-03, -3.5461e-02, -3.3854e-02,  8.5732e-02,\n          3.8687e-02,  2.2249e-02, -2.3404e-02,  7.1735e-02, -1.9051e-02,\n         -5.3549e-02,  8.0323e-02,  1.7085e-02, -4.2167e-02,  6.0394e-02,\n          9.1501e-03,  3.7278e-02,  6.0219e-02,  4.4765e-02,  8.5140e-02,\n         -3.4306e-02, -4.3651e-02,  7.4921e-03,  5.0493e-02,  6.6890e-02,\n         -8.5150e-02, -4.1423e-02,  1.1233e-02, -7.6051e-02,  2.4843e-02,\n          5.2286e-03,  1.2702e-02, -5.3120e-02,  1.1789e-02, -6.2491e-02,\n          7.3821e-02, -3.3348e-02, -1.2786e-02,  2.9999e-02,  6.2877e-02,\n         -2.1449e-02, -4.3580e-02, -2.9710e-02, -1.3881e-02, -3.2517e-02,\n          3.6486e-02, -4.6828e-03,  7.8054e-02, -5.7203e-03,  5.8596e-02,\n          4.4255e-03, -2.1213e-02,  1.3042e-02],\n        [-7.3402e-02,  6.3667e-02,  2.1294e-02,  1.8986e-02, -2.7823e-02,\n          3.9137e-02,  2.8287e-02,  6.7064e-03, -4.9702e-02,  7.5334e-02,\n          6.7367e-03, -2.6290e-02, -2.1108e-02,  5.9892e-02,  7.1583e-02,\n          7.6712e-02, -7.4535e-02, -3.3776e-02, -1.0379e-02,  2.1773e-02,\n          5.0594e-02, -2.4632e-02, -7.4537e-02, -5.4535e-02,  4.9364e-02,\n          3.7530e-04,  7.0767e-03,  2.5350e-02, -7.9056e-02, -3.7423e-02,\n         -5.6679e-02,  8.4202e-03, -3.4866e-02,  8.6825e-02,  2.2897e-02,\n         -3.3322e-02,  4.8179e-02, -1.1652e-02,  9.5659e-03,  8.0651e-02,\n          2.8301e-03, -8.2784e-02,  1.4823e-02,  3.6068e-02, -8.5675e-02,\n         -8.8341e-02,  5.2157e-02, -1.2107e-03,  8.8493e-03,  7.3485e-02,\n         -1.6162e-02,  5.7298e-02,  6.0185e-03, -8.2882e-02, -2.9792e-02,\n          6.2890e-02,  7.3558e-03, -8.4279e-02,  6.4424e-02,  3.6261e-02,\n          1.4436e-02,  7.6610e-02,  4.7657e-02,  6.5526e-02,  3.0869e-02,\n         -2.8102e-02,  7.9387e-02, -1.3699e-02, -7.7407e-03,  1.4021e-02,\n          8.3344e-02, -4.0828e-02,  4.0468e-02, -7.5615e-02, -5.6037e-02,\n         -1.6387e-02,  7.2803e-03, -9.0882e-03,  2.7110e-02, -4.4247e-02,\n         -8.8062e-02,  4.5229e-03, -1.6496e-02,  5.1969e-03, -2.6065e-02,\n         -5.4026e-02, -1.4540e-02, -5.5038e-02, -8.7405e-02, -2.6709e-02,\n         -8.0527e-02,  7.5164e-02, -2.9020e-02, -2.8515e-02, -5.7081e-02,\n         -7.4737e-02,  2.4357e-02,  3.6570e-02,  4.1887e-02,  5.4961e-03,\n         -4.8232e-02, -2.9238e-02,  5.4198e-02, -2.3961e-02, -1.9890e-02,\n         -3.8224e-02,  7.9549e-02,  8.4535e-02, -8.7439e-02,  3.6450e-03,\n          8.5346e-02,  2.7064e-02, -2.6950e-02,  2.9177e-02, -6.5418e-02,\n          8.8481e-03, -7.2905e-02, -4.4194e-02, -7.8399e-02, -8.5679e-02,\n          6.4507e-02,  2.3032e-03,  7.5128e-02,  8.1332e-02, -6.8904e-02,\n         -3.8234e-04,  2.3678e-02, -3.5573e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7e7fbf50dc90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s495210000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s495210000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}