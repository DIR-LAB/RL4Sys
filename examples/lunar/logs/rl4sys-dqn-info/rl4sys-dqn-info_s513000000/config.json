{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s513000000"
    },
    "q_lr":	0.001,
    "seed":	513000000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x715810c5bb10>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2241,  0.1951, -0.3221,  0.1965,  0.2301, -0.0376,  0.2636,  0.1976,\n         0.2743, -0.3402, -0.1061, -0.0383,  0.2918,  0.3227,  0.3490, -0.0793,\n        -0.0396, -0.1919,  0.1358,  0.1237, -0.0112,  0.1267, -0.0654,  0.1613,\n        -0.1419,  0.2954,  0.2394, -0.0918, -0.1531, -0.3201,  0.2527,  0.3503,\n         0.1284,  0.0905,  0.0009, -0.1981, -0.1395,  0.1690, -0.2814, -0.0633,\n        -0.2794, -0.1897,  0.2426, -0.1369, -0.0028,  0.2997,  0.1936, -0.3040,\n        -0.3302,  0.1384,  0.1580,  0.2175, -0.3420, -0.1898, -0.2291, -0.0192,\n         0.1317, -0.3003, -0.2770,  0.1045, -0.2265, -0.0661, -0.1782, -0.0040,\n         0.1410, -0.3034,  0.3184, -0.2524,  0.0458,  0.0827,  0.1690, -0.2386,\n        -0.0303,  0.0640, -0.1258, -0.1553,  0.2218, -0.3313, -0.1841, -0.1207,\n        -0.0091,  0.1774, -0.1905,  0.0258, -0.0132,  0.3164, -0.1211,  0.1945,\n        -0.0181,  0.1445, -0.0760, -0.3520, -0.3180, -0.1045,  0.0712,  0.3333,\n         0.3208, -0.0809,  0.2395, -0.1326, -0.0089, -0.1194, -0.0460, -0.2028,\n        -0.1779,  0.3465,  0.2787,  0.1029,  0.2357, -0.3251, -0.0140,  0.0706,\n         0.2380,  0.0464,  0.1558, -0.3144,  0.3329,  0.1714,  0.1429, -0.0811,\n         0.2777,  0.3493,  0.1420, -0.0724, -0.1444, -0.2440, -0.2825, -0.0671,\n         0.3096, -0.1140,  0.2286, -0.0998,  0.2752, -0.3081, -0.2178, -0.2768,\n         0.1521,  0.1934, -0.2752,  0.1886, -0.1087,  0.0945, -0.1380,  0.3431,\n        -0.0989, -0.0071,  0.1438, -0.0393,  0.0973,  0.2939, -0.3284,  0.1462,\n        -0.2936, -0.2679, -0.3028, -0.3332,  0.0895, -0.3524, -0.3301, -0.2120,\n         0.2050, -0.1502, -0.0409,  0.0389, -0.2526,  0.3076,  0.3436, -0.2231,\n        -0.0773,  0.3074,  0.0535, -0.2814, -0.0145, -0.0080, -0.0400, -0.2205,\n        -0.2998,  0.0658,  0.1559,  0.1373,  0.3207, -0.3272, -0.1367,  0.1498,\n        -0.1554, -0.0480, -0.0843, -0.0929, -0.2017, -0.1596,  0.3490,  0.3530,\n        -0.0804, -0.0468,  0.0822, -0.2010, -0.1986, -0.0708, -0.0273,  0.2494,\n        -0.3320,  0.1525,  0.1953, -0.2864, -0.0430,  0.3470, -0.2543, -0.0978,\n         0.0725,  0.0317, -0.3491, -0.1439, -0.2603,  0.0881,  0.3301, -0.2782,\n        -0.1260, -0.1553,  0.2976, -0.0746,  0.0948,  0.2267,  0.1547, -0.2026,\n        -0.0916,  0.1653, -0.2270, -0.0069, -0.1801, -0.0926, -0.0736, -0.2386,\n         0.0750, -0.1815, -0.1679,  0.2410,  0.1384,  0.2306,  0.3139, -0.2603,\n         0.3056,  0.0166,  0.0520, -0.0057, -0.3335, -0.0049, -0.1990, -0.2042,\n        -0.1851, -0.2689, -0.0605,  0.2375,  0.2051, -0.2814, -0.0020, -0.1136,\n        -0.3385,  0.0993,  0.2073,  0.3348, -0.0035, -0.1526, -0.1818,  0.2444,\n        -0.0331,  0.1949, -0.0579, -0.1670,  0.2805, -0.2228, -0.0228,  0.0773,\n        -0.1777,  0.1411, -0.2102,  0.2264,  0.3342, -0.3097, -0.2481,  0.1526,\n        -0.0214,  0.1117,  0.1275, -0.0454,  0.1170,  0.3045, -0.0351, -0.0232,\n         0.1676,  0.3259,  0.2989, -0.0210,  0.0890, -0.1051, -0.2950, -0.3402,\n         0.2631,  0.0219, -0.2063,  0.1318,  0.0708,  0.0594,  0.3116,  0.0956,\n         0.3483,  0.2791,  0.3406,  0.0239,  0.1854,  0.1221, -0.1022, -0.2817,\n         0.0433, -0.3434, -0.1892, -0.1291,  0.2108,  0.3284, -0.2176,  0.2247,\n        -0.1961, -0.3263, -0.3225,  0.0676, -0.1683,  0.1858,  0.2939,  0.1109,\n        -0.0796,  0.1581, -0.2724, -0.1815,  0.2156, -0.1810,  0.2716, -0.2960,\n         0.2563, -0.1453,  0.0809, -0.3138, -0.1182,  0.2610,  0.1794,  0.3434,\n        -0.3465,  0.2436, -0.2399,  0.0733, -0.2870, -0.1084, -0.2530, -0.1959,\n         0.3364,  0.2719,  0.0907, -0.0910, -0.2542,  0.3305,  0.1056,  0.0603,\n        -0.1326,  0.0352, -0.0800,  0.0323,  0.2208, -0.2370,  0.2243,  0.2602,\n         0.3033,  0.1605,  0.2131, -0.0342, -0.0439, -0.2337, -0.1697, -0.0744,\n        -0.1916,  0.2108,  0.3274,  0.3412,  0.0874, -0.2885,  0.2189, -0.3269,\n         0.3335, -0.0613,  0.1958, -0.3275, -0.0551, -0.0011,  0.2417,  0.2144,\n         0.1920, -0.3337, -0.1108,  0.0082, -0.0156,  0.3497, -0.2865, -0.0416],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0949, -0.2643,  0.3281,  ..., -0.1596,  0.2719,  0.1571],\n        [-0.0517, -0.0086, -0.2126,  ..., -0.2992, -0.2497,  0.0163],\n        [ 0.0921,  0.1312,  0.1395,  ..., -0.2723,  0.2053, -0.1156],\n        ...,\n        [-0.0148,  0.3321,  0.2732,  ..., -0.2816, -0.1081, -0.0465],\n        [ 0.2195,  0.0908, -0.3098,  ...,  0.2241, -0.0138,  0.2390],\n        [-0.2434,  0.2075, -0.1511,  ..., -0.3046, -0.0965, -0.1440]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 3.8619e-02, -4.7827e-02,  3.6686e-03,  1.7079e-02, -1.5934e-02,\n         1.7996e-02, -4.2292e-02,  3.0595e-02,  4.5218e-02, -4.8941e-02,\n         3.4493e-02,  4.9998e-02, -4.4015e-02, -1.0914e-02, -1.6911e-02,\n         3.0198e-02,  6.4841e-03,  1.7365e-02, -3.1497e-02,  1.8547e-02,\n         1.8550e-02,  2.6898e-02,  2.2271e-03,  3.0324e-02,  5.8883e-03,\n         1.8322e-02,  2.4126e-02,  3.3296e-02,  2.5929e-03,  1.8424e-02,\n         1.2504e-02,  1.0231e-02, -3.3679e-02, -1.0221e-02,  1.6066e-02,\n        -1.8933e-02,  6.9547e-03, -4.1976e-02,  8.5059e-03,  3.4569e-03,\n         2.2815e-02, -2.6657e-02, -4.5949e-02, -9.2128e-03, -2.7797e-03,\n         2.2923e-02, -3.1614e-02,  1.2042e-02,  3.7758e-02, -1.9312e-02,\n         2.9744e-02, -2.2559e-02,  3.3517e-02,  2.8468e-02,  1.5949e-02,\n         1.8273e-02, -3.6279e-02, -3.9597e-02,  3.3235e-02,  4.1997e-02,\n         4.5089e-02,  1.0622e-02, -4.0988e-03,  5.0492e-03,  2.5891e-02,\n        -2.4340e-02,  1.5739e-02, -1.0776e-02,  6.9735e-03, -3.0254e-02,\n        -5.6042e-03,  2.0552e-02, -4.0365e-02, -1.4123e-02,  1.8385e-02,\n         3.8048e-02, -4.8243e-03,  3.9213e-02,  3.9897e-02,  1.4245e-02,\n         8.8541e-03, -2.6763e-02,  1.3493e-02, -1.3771e-02, -6.5074e-03,\n        -4.6727e-02, -2.2987e-03, -1.6467e-03,  4.1850e-02,  1.2063e-02,\n        -4.0934e-02, -3.1253e-02,  4.1693e-03,  3.8052e-02, -4.8779e-02,\n        -1.2472e-03,  4.6259e-02,  1.0815e-02,  2.8279e-02,  3.1803e-02,\n         1.5466e-02,  4.2519e-03,  1.4141e-03, -1.5639e-02,  2.1348e-02,\n        -8.5281e-03,  1.5520e-02,  4.6594e-02, -2.8934e-02, -4.4888e-02,\n        -4.8915e-02, -4.2664e-03,  3.1420e-02,  3.0265e-02,  9.6052e-03,\n         2.1770e-02, -1.5406e-02, -2.0073e-02,  3.1756e-02,  2.2941e-02,\n         3.8833e-02, -4.7666e-02, -1.2490e-02, -1.2064e-02,  1.2629e-02,\n        -4.8549e-02,  2.5607e-02,  7.0635e-03,  3.8638e-02,  9.6433e-03,\n         1.2043e-02,  2.7156e-02,  1.3224e-03,  1.9063e-03, -4.4009e-02,\n         3.4051e-03, -1.4132e-02,  4.0942e-02, -2.3017e-02, -1.7982e-02,\n        -3.8338e-02, -4.0300e-02, -7.1338e-03, -3.3180e-02, -4.3626e-02,\n         2.2974e-02, -4.8122e-02, -2.7193e-02,  5.3503e-03,  3.1147e-02,\n        -2.8036e-02, -2.3257e-02, -3.9780e-02,  5.4128e-03, -3.7019e-02,\n        -3.6114e-03,  4.0646e-02, -2.8798e-02,  3.9283e-02,  3.1050e-02,\n         4.8231e-02, -1.0607e-02,  1.5713e-03, -1.6960e-02, -2.9874e-02,\n        -3.7644e-02,  4.0733e-02,  4.6590e-02, -2.0506e-02, -8.5341e-03,\n        -2.9816e-02, -5.9773e-03, -2.7412e-02,  4.3324e-02, -4.8741e-03,\n        -2.7758e-02,  2.5559e-02, -2.8954e-02, -2.0786e-02, -1.1286e-02,\n        -2.8890e-02,  1.9555e-02,  3.8110e-02,  4.9913e-05, -3.7402e-02,\n        -2.6687e-02,  4.2529e-02,  4.3355e-02,  1.1082e-02, -3.5808e-03,\n        -2.3303e-02, -4.8145e-02, -2.7159e-02, -3.7496e-02, -4.5206e-02,\n        -1.4094e-02, -3.4429e-02, -1.7183e-03, -1.1573e-02,  2.2069e-02,\n         4.0814e-02, -3.6042e-02,  1.3243e-02,  3.4703e-02,  3.8509e-02,\n        -7.1429e-03, -3.4715e-02, -1.3335e-02,  3.9212e-02,  1.7410e-03,\n         2.8380e-02,  3.9850e-02, -1.8448e-02, -2.1646e-02, -4.8911e-02,\n         4.4811e-02, -2.0789e-02,  6.1027e-03, -1.8726e-02,  3.4597e-02,\n        -2.1602e-02,  2.8060e-02, -2.2946e-02, -6.1576e-03, -2.5985e-02,\n        -3.0746e-02, -1.3428e-02, -1.5436e-02,  7.0199e-04, -1.5122e-02,\n         3.3634e-02, -1.5039e-02, -4.4281e-02,  2.5279e-02, -4.3608e-02,\n         4.7666e-02, -3.2164e-02, -3.6416e-02, -2.8812e-02,  1.4925e-02,\n         1.2270e-02, -1.1117e-02, -1.1793e-02, -4.8561e-02,  2.2566e-02,\n        -3.5275e-02,  1.1820e-02, -3.4497e-02,  9.1794e-03,  4.0328e-03,\n        -6.3293e-03, -4.6719e-02,  2.5558e-02, -2.4912e-02, -9.3929e-03,\n        -2.7185e-02,  7.8605e-04, -2.5934e-02, -2.3125e-02,  2.0175e-02,\n         2.0158e-02,  3.9421e-02, -4.0616e-02, -2.4290e-02,  1.8497e-02,\n        -4.9854e-02,  4.6944e-02, -4.8425e-02, -1.3163e-02,  2.5332e-02,\n        -3.6971e-02, -4.2454e-02,  4.2849e-02,  4.1396e-03,  2.4869e-02,\n        -1.5715e-02,  3.0090e-02, -3.8944e-02,  4.7690e-02,  4.4995e-02,\n        -4.0287e-02, -3.6684e-02,  1.9869e-02,  4.8615e-02, -4.3246e-02,\n        -2.5770e-02,  1.8154e-02,  1.4560e-02,  4.3994e-02,  1.5933e-02,\n        -2.8111e-02,  4.7238e-02,  3.4996e-02, -2.7609e-02,  3.8993e-02,\n        -4.8817e-02,  1.1639e-02,  1.7639e-02,  1.2923e-02,  2.9986e-03],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 3.1004e-02,  2.0721e-02, -4.9236e-02,  ..., -2.5684e-02,\n         -3.8384e-03, -8.0613e-03],\n        [ 3.2570e-02,  8.3369e-05, -7.5522e-03,  ..., -2.0606e-02,\n          4.4138e-02,  2.7399e-02],\n        [-1.5160e-02,  3.8488e-02,  4.8936e-02,  ..., -3.2806e-03,\n         -4.4168e-02, -3.6340e-04],\n        ...,\n        [-2.3765e-02,  1.2852e-02, -1.4721e-02,  ...,  2.2447e-02,\n         -4.7111e-02,  1.2932e-02],\n        [ 1.5354e-02,  4.4501e-02,  2.3791e-02,  ..., -1.7217e-02,\n          2.6952e-02,  2.9932e-02],\n        [ 8.9659e-03,  4.1539e-02,  9.5727e-04,  ..., -1.7955e-02,\n          6.9531e-03,  1.1254e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([0.0308, 0.0237, 0.0325, 0.0181], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0042,  0.0456,  0.0455,  ...,  0.0557, -0.0152, -0.0508],\n        [-0.0301, -0.0461,  0.0343,  ..., -0.0545,  0.0322,  0.0267],\n        [-0.0190,  0.0116, -0.0556,  ...,  0.0315,  0.0153,  0.0204],\n        [-0.0351,  0.0203,  0.0396,  ...,  0.0186, -0.0397,  0.0188]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.001,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.001,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0949, -0.2643,  0.3281,  ..., -0.1596,  0.2719,  0.1571],\n        [-0.0517, -0.0086, -0.2126,  ..., -0.2992, -0.2497,  0.0163],\n        [ 0.0921,  0.1312,  0.1395,  ..., -0.2723,  0.2053, -0.1156],\n        ...,\n        [-0.0148,  0.3321,  0.2732,  ..., -0.2816, -0.1081, -0.0465],\n        [ 0.2195,  0.0908, -0.3098,  ...,  0.2241, -0.0138,  0.2390],\n        [-0.2434,  0.2075, -0.1511,  ..., -0.3046, -0.0965, -0.1440]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2241,  0.1951, -0.3221,  0.1965,  0.2301, -0.0376,  0.2636,  0.1976,\n         0.2743, -0.3402, -0.1061, -0.0383,  0.2918,  0.3227,  0.3490, -0.0793,\n        -0.0396, -0.1919,  0.1358,  0.1237, -0.0112,  0.1267, -0.0654,  0.1613,\n        -0.1419,  0.2954,  0.2394, -0.0918, -0.1531, -0.3201,  0.2527,  0.3503,\n         0.1284,  0.0905,  0.0009, -0.1981, -0.1395,  0.1690, -0.2814, -0.0633,\n        -0.2794, -0.1897,  0.2426, -0.1369, -0.0028,  0.2997,  0.1936, -0.3040,\n        -0.3302,  0.1384,  0.1580,  0.2175, -0.3420, -0.1898, -0.2291, -0.0192,\n         0.1317, -0.3003, -0.2770,  0.1045, -0.2265, -0.0661, -0.1782, -0.0040,\n         0.1410, -0.3034,  0.3184, -0.2524,  0.0458,  0.0827,  0.1690, -0.2386,\n        -0.0303,  0.0640, -0.1258, -0.1553,  0.2218, -0.3313, -0.1841, -0.1207,\n        -0.0091,  0.1774, -0.1905,  0.0258, -0.0132,  0.3164, -0.1211,  0.1945,\n        -0.0181,  0.1445, -0.0760, -0.3520, -0.3180, -0.1045,  0.0712,  0.3333,\n         0.3208, -0.0809,  0.2395, -0.1326, -0.0089, -0.1194, -0.0460, -0.2028,\n        -0.1779,  0.3465,  0.2787,  0.1029,  0.2357, -0.3251, -0.0140,  0.0706,\n         0.2380,  0.0464,  0.1558, -0.3144,  0.3329,  0.1714,  0.1429, -0.0811,\n         0.2777,  0.3493,  0.1420, -0.0724, -0.1444, -0.2440, -0.2825, -0.0671,\n         0.3096, -0.1140,  0.2286, -0.0998,  0.2752, -0.3081, -0.2178, -0.2768,\n         0.1521,  0.1934, -0.2752,  0.1886, -0.1087,  0.0945, -0.1380,  0.3431,\n        -0.0989, -0.0071,  0.1438, -0.0393,  0.0973,  0.2939, -0.3284,  0.1462,\n        -0.2936, -0.2679, -0.3028, -0.3332,  0.0895, -0.3524, -0.3301, -0.2120,\n         0.2050, -0.1502, -0.0409,  0.0389, -0.2526,  0.3076,  0.3436, -0.2231,\n        -0.0773,  0.3074,  0.0535, -0.2814, -0.0145, -0.0080, -0.0400, -0.2205,\n        -0.2998,  0.0658,  0.1559,  0.1373,  0.3207, -0.3272, -0.1367,  0.1498,\n        -0.1554, -0.0480, -0.0843, -0.0929, -0.2017, -0.1596,  0.3490,  0.3530,\n        -0.0804, -0.0468,  0.0822, -0.2010, -0.1986, -0.0708, -0.0273,  0.2494,\n        -0.3320,  0.1525,  0.1953, -0.2864, -0.0430,  0.3470, -0.2543, -0.0978,\n         0.0725,  0.0317, -0.3491, -0.1439, -0.2603,  0.0881,  0.3301, -0.2782,\n        -0.1260, -0.1553,  0.2976, -0.0746,  0.0948,  0.2267,  0.1547, -0.2026,\n        -0.0916,  0.1653, -0.2270, -0.0069, -0.1801, -0.0926, -0.0736, -0.2386,\n         0.0750, -0.1815, -0.1679,  0.2410,  0.1384,  0.2306,  0.3139, -0.2603,\n         0.3056,  0.0166,  0.0520, -0.0057, -0.3335, -0.0049, -0.1990, -0.2042,\n        -0.1851, -0.2689, -0.0605,  0.2375,  0.2051, -0.2814, -0.0020, -0.1136,\n        -0.3385,  0.0993,  0.2073,  0.3348, -0.0035, -0.1526, -0.1818,  0.2444,\n        -0.0331,  0.1949, -0.0579, -0.1670,  0.2805, -0.2228, -0.0228,  0.0773,\n        -0.1777,  0.1411, -0.2102,  0.2264,  0.3342, -0.3097, -0.2481,  0.1526,\n        -0.0214,  0.1117,  0.1275, -0.0454,  0.1170,  0.3045, -0.0351, -0.0232,\n         0.1676,  0.3259,  0.2989, -0.0210,  0.0890, -0.1051, -0.2950, -0.3402,\n         0.2631,  0.0219, -0.2063,  0.1318,  0.0708,  0.0594,  0.3116,  0.0956,\n         0.3483,  0.2791,  0.3406,  0.0239,  0.1854,  0.1221, -0.1022, -0.2817,\n         0.0433, -0.3434, -0.1892, -0.1291,  0.2108,  0.3284, -0.2176,  0.2247,\n        -0.1961, -0.3263, -0.3225,  0.0676, -0.1683,  0.1858,  0.2939,  0.1109,\n        -0.0796,  0.1581, -0.2724, -0.1815,  0.2156, -0.1810,  0.2716, -0.2960,\n         0.2563, -0.1453,  0.0809, -0.3138, -0.1182,  0.2610,  0.1794,  0.3434,\n        -0.3465,  0.2436, -0.2399,  0.0733, -0.2870, -0.1084, -0.2530, -0.1959,\n         0.3364,  0.2719,  0.0907, -0.0910, -0.2542,  0.3305,  0.1056,  0.0603,\n        -0.1326,  0.0352, -0.0800,  0.0323,  0.2208, -0.2370,  0.2243,  0.2602,\n         0.3033,  0.1605,  0.2131, -0.0342, -0.0439, -0.2337, -0.1697, -0.0744,\n        -0.1916,  0.2108,  0.3274,  0.3412,  0.0874, -0.2885,  0.2189, -0.3269,\n         0.3335, -0.0613,  0.1958, -0.3275, -0.0551, -0.0011,  0.2417,  0.2144,\n         0.1920, -0.3337, -0.1108,  0.0082, -0.0156,  0.3497, -0.2865, -0.0416],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 3.1004e-02,  2.0721e-02, -4.9236e-02,  ..., -2.5684e-02,\n         -3.8384e-03, -8.0613e-03],\n        [ 3.2570e-02,  8.3369e-05, -7.5522e-03,  ..., -2.0606e-02,\n          4.4138e-02,  2.7399e-02],\n        [-1.5160e-02,  3.8488e-02,  4.8936e-02,  ..., -3.2806e-03,\n         -4.4168e-02, -3.6340e-04],\n        ...,\n        [-2.3765e-02,  1.2852e-02, -1.4721e-02,  ...,  2.2447e-02,\n         -4.7111e-02,  1.2932e-02],\n        [ 1.5354e-02,  4.4501e-02,  2.3791e-02,  ..., -1.7217e-02,\n          2.6952e-02,  2.9932e-02],\n        [ 8.9659e-03,  4.1539e-02,  9.5727e-04,  ..., -1.7955e-02,\n          6.9531e-03,  1.1254e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 3.8619e-02, -4.7827e-02,  3.6686e-03,  1.7079e-02, -1.5934e-02,\n         1.7996e-02, -4.2292e-02,  3.0595e-02,  4.5218e-02, -4.8941e-02,\n         3.4493e-02,  4.9998e-02, -4.4015e-02, -1.0914e-02, -1.6911e-02,\n         3.0198e-02,  6.4841e-03,  1.7365e-02, -3.1497e-02,  1.8547e-02,\n         1.8550e-02,  2.6898e-02,  2.2271e-03,  3.0324e-02,  5.8883e-03,\n         1.8322e-02,  2.4126e-02,  3.3296e-02,  2.5929e-03,  1.8424e-02,\n         1.2504e-02,  1.0231e-02, -3.3679e-02, -1.0221e-02,  1.6066e-02,\n        -1.8933e-02,  6.9547e-03, -4.1976e-02,  8.5059e-03,  3.4569e-03,\n         2.2815e-02, -2.6657e-02, -4.5949e-02, -9.2128e-03, -2.7797e-03,\n         2.2923e-02, -3.1614e-02,  1.2042e-02,  3.7758e-02, -1.9312e-02,\n         2.9744e-02, -2.2559e-02,  3.3517e-02,  2.8468e-02,  1.5949e-02,\n         1.8273e-02, -3.6279e-02, -3.9597e-02,  3.3235e-02,  4.1997e-02,\n         4.5089e-02,  1.0622e-02, -4.0988e-03,  5.0492e-03,  2.5891e-02,\n        -2.4340e-02,  1.5739e-02, -1.0776e-02,  6.9735e-03, -3.0254e-02,\n        -5.6042e-03,  2.0552e-02, -4.0365e-02, -1.4123e-02,  1.8385e-02,\n         3.8048e-02, -4.8243e-03,  3.9213e-02,  3.9897e-02,  1.4245e-02,\n         8.8541e-03, -2.6763e-02,  1.3493e-02, -1.3771e-02, -6.5074e-03,\n        -4.6727e-02, -2.2987e-03, -1.6467e-03,  4.1850e-02,  1.2063e-02,\n        -4.0934e-02, -3.1253e-02,  4.1693e-03,  3.8052e-02, -4.8779e-02,\n        -1.2472e-03,  4.6259e-02,  1.0815e-02,  2.8279e-02,  3.1803e-02,\n         1.5466e-02,  4.2519e-03,  1.4141e-03, -1.5639e-02,  2.1348e-02,\n        -8.5281e-03,  1.5520e-02,  4.6594e-02, -2.8934e-02, -4.4888e-02,\n        -4.8915e-02, -4.2664e-03,  3.1420e-02,  3.0265e-02,  9.6052e-03,\n         2.1770e-02, -1.5406e-02, -2.0073e-02,  3.1756e-02,  2.2941e-02,\n         3.8833e-02, -4.7666e-02, -1.2490e-02, -1.2064e-02,  1.2629e-02,\n        -4.8549e-02,  2.5607e-02,  7.0635e-03,  3.8638e-02,  9.6433e-03,\n         1.2043e-02,  2.7156e-02,  1.3224e-03,  1.9063e-03, -4.4009e-02,\n         3.4051e-03, -1.4132e-02,  4.0942e-02, -2.3017e-02, -1.7982e-02,\n        -3.8338e-02, -4.0300e-02, -7.1338e-03, -3.3180e-02, -4.3626e-02,\n         2.2974e-02, -4.8122e-02, -2.7193e-02,  5.3503e-03,  3.1147e-02,\n        -2.8036e-02, -2.3257e-02, -3.9780e-02,  5.4128e-03, -3.7019e-02,\n        -3.6114e-03,  4.0646e-02, -2.8798e-02,  3.9283e-02,  3.1050e-02,\n         4.8231e-02, -1.0607e-02,  1.5713e-03, -1.6960e-02, -2.9874e-02,\n        -3.7644e-02,  4.0733e-02,  4.6590e-02, -2.0506e-02, -8.5341e-03,\n        -2.9816e-02, -5.9773e-03, -2.7412e-02,  4.3324e-02, -4.8741e-03,\n        -2.7758e-02,  2.5559e-02, -2.8954e-02, -2.0786e-02, -1.1286e-02,\n        -2.8890e-02,  1.9555e-02,  3.8110e-02,  4.9913e-05, -3.7402e-02,\n        -2.6687e-02,  4.2529e-02,  4.3355e-02,  1.1082e-02, -3.5808e-03,\n        -2.3303e-02, -4.8145e-02, -2.7159e-02, -3.7496e-02, -4.5206e-02,\n        -1.4094e-02, -3.4429e-02, -1.7183e-03, -1.1573e-02,  2.2069e-02,\n         4.0814e-02, -3.6042e-02,  1.3243e-02,  3.4703e-02,  3.8509e-02,\n        -7.1429e-03, -3.4715e-02, -1.3335e-02,  3.9212e-02,  1.7410e-03,\n         2.8380e-02,  3.9850e-02, -1.8448e-02, -2.1646e-02, -4.8911e-02,\n         4.4811e-02, -2.0789e-02,  6.1027e-03, -1.8726e-02,  3.4597e-02,\n        -2.1602e-02,  2.8060e-02, -2.2946e-02, -6.1576e-03, -2.5985e-02,\n        -3.0746e-02, -1.3428e-02, -1.5436e-02,  7.0199e-04, -1.5122e-02,\n         3.3634e-02, -1.5039e-02, -4.4281e-02,  2.5279e-02, -4.3608e-02,\n         4.7666e-02, -3.2164e-02, -3.6416e-02, -2.8812e-02,  1.4925e-02,\n         1.2270e-02, -1.1117e-02, -1.1793e-02, -4.8561e-02,  2.2566e-02,\n        -3.5275e-02,  1.1820e-02, -3.4497e-02,  9.1794e-03,  4.0328e-03,\n        -6.3293e-03, -4.6719e-02,  2.5558e-02, -2.4912e-02, -9.3929e-03,\n        -2.7185e-02,  7.8605e-04, -2.5934e-02, -2.3125e-02,  2.0175e-02,\n         2.0158e-02,  3.9421e-02, -4.0616e-02, -2.4290e-02,  1.8497e-02,\n        -4.9854e-02,  4.6944e-02, -4.8425e-02, -1.3163e-02,  2.5332e-02,\n        -3.6971e-02, -4.2454e-02,  4.2849e-02,  4.1396e-03,  2.4869e-02,\n        -1.5715e-02,  3.0090e-02, -3.8944e-02,  4.7690e-02,  4.4995e-02,\n        -4.0287e-02, -3.6684e-02,  1.9869e-02,  4.8615e-02, -4.3246e-02,\n        -2.5770e-02,  1.8154e-02,  1.4560e-02,  4.3994e-02,  1.5933e-02,\n        -2.8111e-02,  4.7238e-02,  3.4996e-02, -2.7609e-02,  3.8993e-02,\n        -4.8817e-02,  1.1639e-02,  1.7639e-02,  1.2923e-02,  2.9986e-03],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0042,  0.0456,  0.0455,  ...,  0.0557, -0.0152, -0.0508],\n        [-0.0301, -0.0461,  0.0343,  ..., -0.0545,  0.0322,  0.0267],\n        [-0.0190,  0.0116, -0.0556,  ...,  0.0315,  0.0153,  0.0204],\n        [-0.0351,  0.0203,  0.0396,  ...,  0.0186, -0.0397,  0.0188]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0308, 0.0237, 0.0325, 0.0181], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7158966a81d0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.2241,  0.1951, -0.3221,  0.1965,  0.2301, -0.0376,  0.2636,  0.1976,\n         0.2743, -0.3402, -0.1061, -0.0383,  0.2918,  0.3227,  0.3490, -0.0793,\n        -0.0396, -0.1919,  0.1358,  0.1237, -0.0112,  0.1267, -0.0654,  0.1613,\n        -0.1419,  0.2954,  0.2394, -0.0918, -0.1531, -0.3201,  0.2527,  0.3503,\n         0.1284,  0.0905,  0.0009, -0.1981, -0.1395,  0.1690, -0.2814, -0.0633,\n        -0.2794, -0.1897,  0.2426, -0.1369, -0.0028,  0.2997,  0.1936, -0.3040,\n        -0.3302,  0.1384,  0.1580,  0.2175, -0.3420, -0.1898, -0.2291, -0.0192,\n         0.1317, -0.3003, -0.2770,  0.1045, -0.2265, -0.0661, -0.1782, -0.0040,\n         0.1410, -0.3034,  0.3184, -0.2524,  0.0458,  0.0827,  0.1690, -0.2386,\n        -0.0303,  0.0640, -0.1258, -0.1553,  0.2218, -0.3313, -0.1841, -0.1207,\n        -0.0091,  0.1774, -0.1905,  0.0258, -0.0132,  0.3164, -0.1211,  0.1945,\n        -0.0181,  0.1445, -0.0760, -0.3520, -0.3180, -0.1045,  0.0712,  0.3333,\n         0.3208, -0.0809,  0.2395, -0.1326, -0.0089, -0.1194, -0.0460, -0.2028,\n        -0.1779,  0.3465,  0.2787,  0.1029,  0.2357, -0.3251, -0.0140,  0.0706,\n         0.2380,  0.0464,  0.1558, -0.3144,  0.3329,  0.1714,  0.1429, -0.0811,\n         0.2777,  0.3493,  0.1420, -0.0724, -0.1444, -0.2440, -0.2825, -0.0671,\n         0.3096, -0.1140,  0.2286, -0.0998,  0.2752, -0.3081, -0.2178, -0.2768,\n         0.1521,  0.1934, -0.2752,  0.1886, -0.1087,  0.0945, -0.1380,  0.3431,\n        -0.0989, -0.0071,  0.1438, -0.0393,  0.0973,  0.2939, -0.3284,  0.1462,\n        -0.2936, -0.2679, -0.3028, -0.3332,  0.0895, -0.3524, -0.3301, -0.2120,\n         0.2050, -0.1502, -0.0409,  0.0389, -0.2526,  0.3076,  0.3436, -0.2231,\n        -0.0773,  0.3074,  0.0535, -0.2814, -0.0145, -0.0080, -0.0400, -0.2205,\n        -0.2998,  0.0658,  0.1559,  0.1373,  0.3207, -0.3272, -0.1367,  0.1498,\n        -0.1554, -0.0480, -0.0843, -0.0929, -0.2017, -0.1596,  0.3490,  0.3530,\n        -0.0804, -0.0468,  0.0822, -0.2010, -0.1986, -0.0708, -0.0273,  0.2494,\n        -0.3320,  0.1525,  0.1953, -0.2864, -0.0430,  0.3470, -0.2543, -0.0978,\n         0.0725,  0.0317, -0.3491, -0.1439, -0.2603,  0.0881,  0.3301, -0.2782,\n        -0.1260, -0.1553,  0.2976, -0.0746,  0.0948,  0.2267,  0.1547, -0.2026,\n        -0.0916,  0.1653, -0.2270, -0.0069, -0.1801, -0.0926, -0.0736, -0.2386,\n         0.0750, -0.1815, -0.1679,  0.2410,  0.1384,  0.2306,  0.3139, -0.2603,\n         0.3056,  0.0166,  0.0520, -0.0057, -0.3335, -0.0049, -0.1990, -0.2042,\n        -0.1851, -0.2689, -0.0605,  0.2375,  0.2051, -0.2814, -0.0020, -0.1136,\n        -0.3385,  0.0993,  0.2073,  0.3348, -0.0035, -0.1526, -0.1818,  0.2444,\n        -0.0331,  0.1949, -0.0579, -0.1670,  0.2805, -0.2228, -0.0228,  0.0773,\n        -0.1777,  0.1411, -0.2102,  0.2264,  0.3342, -0.3097, -0.2481,  0.1526,\n        -0.0214,  0.1117,  0.1275, -0.0454,  0.1170,  0.3045, -0.0351, -0.0232,\n         0.1676,  0.3259,  0.2989, -0.0210,  0.0890, -0.1051, -0.2950, -0.3402,\n         0.2631,  0.0219, -0.2063,  0.1318,  0.0708,  0.0594,  0.3116,  0.0956,\n         0.3483,  0.2791,  0.3406,  0.0239,  0.1854,  0.1221, -0.1022, -0.2817,\n         0.0433, -0.3434, -0.1892, -0.1291,  0.2108,  0.3284, -0.2176,  0.2247,\n        -0.1961, -0.3263, -0.3225,  0.0676, -0.1683,  0.1858,  0.2939,  0.1109,\n        -0.0796,  0.1581, -0.2724, -0.1815,  0.2156, -0.1810,  0.2716, -0.2960,\n         0.2563, -0.1453,  0.0809, -0.3138, -0.1182,  0.2610,  0.1794,  0.3434,\n        -0.3465,  0.2436, -0.2399,  0.0733, -0.2870, -0.1084, -0.2530, -0.1959,\n         0.3364,  0.2719,  0.0907, -0.0910, -0.2542,  0.3305,  0.1056,  0.0603,\n        -0.1326,  0.0352, -0.0800,  0.0323,  0.2208, -0.2370,  0.2243,  0.2602,\n         0.3033,  0.1605,  0.2131, -0.0342, -0.0439, -0.2337, -0.1697, -0.0744,\n        -0.1916,  0.2108,  0.3274,  0.3412,  0.0874, -0.2885,  0.2189, -0.3269,\n         0.3335, -0.0613,  0.1958, -0.3275, -0.0551, -0.0011,  0.2417,  0.2144,\n         0.1920, -0.3337, -0.1108,  0.0082, -0.0156,  0.3497, -0.2865, -0.0416],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0949, -0.2643,  0.3281,  ..., -0.1596,  0.2719,  0.1571],\n        [-0.0517, -0.0086, -0.2126,  ..., -0.2992, -0.2497,  0.0163],\n        [ 0.0921,  0.1312,  0.1395,  ..., -0.2723,  0.2053, -0.1156],\n        ...,\n        [-0.0148,  0.3321,  0.2732,  ..., -0.2816, -0.1081, -0.0465],\n        [ 0.2195,  0.0908, -0.3098,  ...,  0.2241, -0.0138,  0.2390],\n        [-0.2434,  0.2075, -0.1511,  ..., -0.3046, -0.0965, -0.1440]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 3.8619e-02, -4.7827e-02,  3.6686e-03,  1.7079e-02, -1.5934e-02,\n         1.7996e-02, -4.2292e-02,  3.0595e-02,  4.5218e-02, -4.8941e-02,\n         3.4493e-02,  4.9998e-02, -4.4015e-02, -1.0914e-02, -1.6911e-02,\n         3.0198e-02,  6.4841e-03,  1.7365e-02, -3.1497e-02,  1.8547e-02,\n         1.8550e-02,  2.6898e-02,  2.2271e-03,  3.0324e-02,  5.8883e-03,\n         1.8322e-02,  2.4126e-02,  3.3296e-02,  2.5929e-03,  1.8424e-02,\n         1.2504e-02,  1.0231e-02, -3.3679e-02, -1.0221e-02,  1.6066e-02,\n        -1.8933e-02,  6.9547e-03, -4.1976e-02,  8.5059e-03,  3.4569e-03,\n         2.2815e-02, -2.6657e-02, -4.5949e-02, -9.2128e-03, -2.7797e-03,\n         2.2923e-02, -3.1614e-02,  1.2042e-02,  3.7758e-02, -1.9312e-02,\n         2.9744e-02, -2.2559e-02,  3.3517e-02,  2.8468e-02,  1.5949e-02,\n         1.8273e-02, -3.6279e-02, -3.9597e-02,  3.3235e-02,  4.1997e-02,\n         4.5089e-02,  1.0622e-02, -4.0988e-03,  5.0492e-03,  2.5891e-02,\n        -2.4340e-02,  1.5739e-02, -1.0776e-02,  6.9735e-03, -3.0254e-02,\n        -5.6042e-03,  2.0552e-02, -4.0365e-02, -1.4123e-02,  1.8385e-02,\n         3.8048e-02, -4.8243e-03,  3.9213e-02,  3.9897e-02,  1.4245e-02,\n         8.8541e-03, -2.6763e-02,  1.3493e-02, -1.3771e-02, -6.5074e-03,\n        -4.6727e-02, -2.2987e-03, -1.6467e-03,  4.1850e-02,  1.2063e-02,\n        -4.0934e-02, -3.1253e-02,  4.1693e-03,  3.8052e-02, -4.8779e-02,\n        -1.2472e-03,  4.6259e-02,  1.0815e-02,  2.8279e-02,  3.1803e-02,\n         1.5466e-02,  4.2519e-03,  1.4141e-03, -1.5639e-02,  2.1348e-02,\n        -8.5281e-03,  1.5520e-02,  4.6594e-02, -2.8934e-02, -4.4888e-02,\n        -4.8915e-02, -4.2664e-03,  3.1420e-02,  3.0265e-02,  9.6052e-03,\n         2.1770e-02, -1.5406e-02, -2.0073e-02,  3.1756e-02,  2.2941e-02,\n         3.8833e-02, -4.7666e-02, -1.2490e-02, -1.2064e-02,  1.2629e-02,\n        -4.8549e-02,  2.5607e-02,  7.0635e-03,  3.8638e-02,  9.6433e-03,\n         1.2043e-02,  2.7156e-02,  1.3224e-03,  1.9063e-03, -4.4009e-02,\n         3.4051e-03, -1.4132e-02,  4.0942e-02, -2.3017e-02, -1.7982e-02,\n        -3.8338e-02, -4.0300e-02, -7.1338e-03, -3.3180e-02, -4.3626e-02,\n         2.2974e-02, -4.8122e-02, -2.7193e-02,  5.3503e-03,  3.1147e-02,\n        -2.8036e-02, -2.3257e-02, -3.9780e-02,  5.4128e-03, -3.7019e-02,\n        -3.6114e-03,  4.0646e-02, -2.8798e-02,  3.9283e-02,  3.1050e-02,\n         4.8231e-02, -1.0607e-02,  1.5713e-03, -1.6960e-02, -2.9874e-02,\n        -3.7644e-02,  4.0733e-02,  4.6590e-02, -2.0506e-02, -8.5341e-03,\n        -2.9816e-02, -5.9773e-03, -2.7412e-02,  4.3324e-02, -4.8741e-03,\n        -2.7758e-02,  2.5559e-02, -2.8954e-02, -2.0786e-02, -1.1286e-02,\n        -2.8890e-02,  1.9555e-02,  3.8110e-02,  4.9913e-05, -3.7402e-02,\n        -2.6687e-02,  4.2529e-02,  4.3355e-02,  1.1082e-02, -3.5808e-03,\n        -2.3303e-02, -4.8145e-02, -2.7159e-02, -3.7496e-02, -4.5206e-02,\n        -1.4094e-02, -3.4429e-02, -1.7183e-03, -1.1573e-02,  2.2069e-02,\n         4.0814e-02, -3.6042e-02,  1.3243e-02,  3.4703e-02,  3.8509e-02,\n        -7.1429e-03, -3.4715e-02, -1.3335e-02,  3.9212e-02,  1.7410e-03,\n         2.8380e-02,  3.9850e-02, -1.8448e-02, -2.1646e-02, -4.8911e-02,\n         4.4811e-02, -2.0789e-02,  6.1027e-03, -1.8726e-02,  3.4597e-02,\n        -2.1602e-02,  2.8060e-02, -2.2946e-02, -6.1576e-03, -2.5985e-02,\n        -3.0746e-02, -1.3428e-02, -1.5436e-02,  7.0199e-04, -1.5122e-02,\n         3.3634e-02, -1.5039e-02, -4.4281e-02,  2.5279e-02, -4.3608e-02,\n         4.7666e-02, -3.2164e-02, -3.6416e-02, -2.8812e-02,  1.4925e-02,\n         1.2270e-02, -1.1117e-02, -1.1793e-02, -4.8561e-02,  2.2566e-02,\n        -3.5275e-02,  1.1820e-02, -3.4497e-02,  9.1794e-03,  4.0328e-03,\n        -6.3293e-03, -4.6719e-02,  2.5558e-02, -2.4912e-02, -9.3929e-03,\n        -2.7185e-02,  7.8605e-04, -2.5934e-02, -2.3125e-02,  2.0175e-02,\n         2.0158e-02,  3.9421e-02, -4.0616e-02, -2.4290e-02,  1.8497e-02,\n        -4.9854e-02,  4.6944e-02, -4.8425e-02, -1.3163e-02,  2.5332e-02,\n        -3.6971e-02, -4.2454e-02,  4.2849e-02,  4.1396e-03,  2.4869e-02,\n        -1.5715e-02,  3.0090e-02, -3.8944e-02,  4.7690e-02,  4.4995e-02,\n        -4.0287e-02, -3.6684e-02,  1.9869e-02,  4.8615e-02, -4.3246e-02,\n        -2.5770e-02,  1.8154e-02,  1.4560e-02,  4.3994e-02,  1.5933e-02,\n        -2.8111e-02,  4.7238e-02,  3.4996e-02, -2.7609e-02,  3.8993e-02,\n        -4.8817e-02,  1.1639e-02,  1.7639e-02,  1.2923e-02,  2.9986e-03],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 3.1004e-02,  2.0721e-02, -4.9236e-02,  ..., -2.5684e-02,\n         -3.8384e-03, -8.0613e-03],\n        [ 3.2570e-02,  8.3369e-05, -7.5522e-03,  ..., -2.0606e-02,\n          4.4138e-02,  2.7399e-02],\n        [-1.5160e-02,  3.8488e-02,  4.8936e-02,  ..., -3.2806e-03,\n         -4.4168e-02, -3.6340e-04],\n        ...,\n        [-2.3765e-02,  1.2852e-02, -1.4721e-02,  ...,  2.2447e-02,\n         -4.7111e-02,  1.2932e-02],\n        [ 1.5354e-02,  4.4501e-02,  2.3791e-02,  ..., -1.7217e-02,\n          2.6952e-02,  2.9932e-02],\n        [ 8.9659e-03,  4.1539e-02,  9.5727e-04,  ..., -1.7955e-02,\n          6.9531e-03,  1.1254e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([0.0308, 0.0237, 0.0325, 0.0181], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0042,  0.0456,  0.0455,  ...,  0.0557, -0.0152, -0.0508],\n        [-0.0301, -0.0461,  0.0343,  ..., -0.0545,  0.0322,  0.0267],\n        [-0.0190,  0.0116, -0.0556,  ...,  0.0315,  0.0153,  0.0204],\n        [-0.0351,  0.0203,  0.0396,  ...,  0.0186, -0.0397,  0.0188]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x71580d5d7910>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s513000000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s513000000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}