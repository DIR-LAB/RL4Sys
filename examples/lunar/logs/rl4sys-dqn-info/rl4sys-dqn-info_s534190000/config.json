{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.03,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s534190000"
    },
    "q_lr":	0.01,
    "seed":	534190000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x732a5d48c190>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.03,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.9616e-01, -1.1139e-01, -1.1544e-01, -4.4423e-02, -4.1302e-02,\n         -2.3609e-01, -2.2522e-01, -5.7782e-02],\n        [ 2.6672e-01, -6.9371e-03,  1.1848e-01,  2.7065e-01,  3.5082e-01,\n         -3.3051e-01,  8.8653e-02, -5.1448e-02],\n        [ 1.3006e-01,  2.9991e-01,  3.0024e-01,  2.3282e-01, -1.3764e-01,\n         -3.0164e-01, -1.9494e-01,  1.6616e-01],\n        [-2.0345e-03,  4.3493e-02, -2.9214e-01, -7.1060e-03,  3.5580e-01,\n          6.0697e-02,  2.2966e-01, -6.7746e-02],\n        [ 1.5397e-01, -1.0494e-01, -3.1920e-01,  5.0877e-02,  2.0057e-01,\n          1.5385e-01, -1.3196e-01,  7.8931e-02],\n        [ 2.3172e-01, -3.5230e-01,  3.0987e-01, -1.5684e-01,  1.7487e-01,\n          1.0857e-01,  8.9654e-02,  9.6424e-02],\n        [ 2.7603e-01,  1.3297e-01,  6.8822e-03,  2.8114e-01,  1.2404e-01,\n         -2.6106e-01,  3.4250e-01,  1.1430e-02],\n        [-1.7420e-01,  1.8512e-01,  2.8431e-01, -3.1059e-01, -1.2891e-01,\n         -1.3774e-01, -2.0701e-01, -1.8840e-01],\n        [ 4.6144e-02,  1.0874e-01, -2.7578e-01,  2.2635e-01,  2.0821e-01,\n          3.3340e-01,  1.3511e-01,  1.7574e-01],\n        [-2.8144e-01,  1.4634e-01,  1.7068e-01, -1.6415e-01, -2.5001e-01,\n         -2.4416e-01, -3.5067e-01, -8.6501e-02],\n        [-2.9286e-01,  3.7325e-01, -1.5837e-01, -9.0676e-02, -6.5837e-02,\n          1.3082e-01, -2.4516e-02, -2.3268e-01],\n        [-7.9905e-02, -3.6500e-01,  2.1640e-01, -3.3709e-01, -2.2287e-01,\n         -2.8099e-01,  6.5225e-02, -2.8897e-01],\n        [-1.1660e-01, -1.9284e-01,  1.2223e-01, -1.6452e-01,  8.3565e-02,\n         -2.2717e-02,  6.0646e-02,  1.9976e-01],\n        [ 1.1418e-01, -1.9633e-01, -3.3592e-01,  2.8316e-01, -2.2864e-01,\n         -9.4971e-02,  1.8338e-01, -2.9975e-01],\n        [ 3.0422e-01, -2.9781e-01,  3.3605e-01,  2.3805e-01,  5.9832e-02,\n          3.2259e-01,  3.3667e-01, -1.7409e-02],\n        [-1.2413e-02, -3.3534e-01,  1.2942e-02,  2.5729e-01,  2.1029e-01,\n         -2.8224e-01,  2.0203e-01,  1.1971e-01],\n        [-1.6800e-01,  3.3475e-01,  2.4521e-01, -1.8991e-02,  3.7297e-01,\n         -2.9105e-02, -1.2351e-01, -2.0140e-01],\n        [-2.3900e-01,  2.7286e-01,  1.7976e-01, -2.3361e-01,  3.6933e-01,\n          1.4762e-01,  3.3709e-01,  2.1359e-01],\n        [ 1.3344e-01, -5.4342e-02, -8.3183e-02, -3.6709e-03, -2.6659e-02,\n          1.4228e-01, -2.4466e-01,  2.4833e-01],\n        [ 1.4136e-01,  3.8434e-01, -2.5752e-02, -1.0354e-01,  1.1355e-01,\n         -2.7241e-01,  7.9703e-02,  2.1108e-01],\n        [ 2.0755e-01, -1.7384e-01, -3.5606e-01, -3.5346e-01, -3.1112e-01,\n          1.8590e-01, -1.0890e-01,  3.2153e-01],\n        [-4.0025e-02, -3.1983e-01, -3.8190e-01, -1.8302e-01,  2.4922e-01,\n         -2.0377e-02, -1.7537e-01,  1.0784e-01],\n        [-1.9200e-01, -1.2157e-01, -4.6970e-02,  2.4747e-05,  2.3513e-01,\n         -2.2695e-01, -3.3748e-01, -2.5676e-01],\n        [-2.7093e-01,  3.7772e-01, -5.0221e-02, -1.1546e-02,  8.1848e-02,\n         -2.0648e-01,  9.7042e-02, -3.7584e-01],\n        [-3.2137e-02,  8.9480e-02,  7.4143e-02, -2.1577e-01,  3.0556e-01,\n          3.2712e-01,  2.0778e-01,  9.0318e-02],\n        [ 9.4130e-03,  3.4949e-01, -1.3290e-01, -2.3567e-01,  1.5464e-02,\n         -2.6361e-01, -4.1569e-02, -3.2648e-01],\n        [ 2.3316e-01, -1.2332e-01, -7.2090e-02, -1.1880e-01,  3.1035e-01,\n          3.6721e-01,  3.6971e-01, -2.0669e-01],\n        [ 2.0219e-02, -2.4547e-01,  3.0310e-01,  3.3210e-01, -3.2044e-03,\n          1.3384e-01, -6.1071e-02,  2.2940e-01],\n        [ 3.7163e-01,  1.4222e-01,  2.6392e-01, -2.6124e-01, -3.5727e-01,\n         -3.5027e-01,  3.7977e-02,  3.0978e-02],\n        [ 1.2561e-01, -1.9336e-01, -2.0550e-02,  1.1871e-01,  3.4760e-02,\n         -3.1071e-01,  3.9667e-02, -1.7524e-02],\n        [ 1.0411e-01, -2.2697e-01, -2.2324e-01,  3.6330e-01, -2.5517e-01,\n          1.3995e-01, -3.8419e-01,  2.4125e-01],\n        [-3.8547e-01,  1.2962e-01,  1.8093e-01, -2.2521e-01,  1.8438e-01,\n          3.1556e-01, -2.8808e-01,  2.0659e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 7.8901e-02,  2.7568e-01,  2.2499e-01,  2.1477e-01,  2.9854e-01,\n         -2.4538e-01, -3.0087e-01,  2.3425e-01,  2.2307e-01,  3.4785e-01,\n          1.2278e-01,  2.9548e-01,  9.0713e-02,  1.5815e-01,  2.9676e-01,\n          1.4319e-01, -2.7540e-02, -1.3511e-01, -1.5538e-02, -1.7332e-01,\n          2.9113e-01,  1.2065e-01,  8.6038e-02, -5.1814e-02, -8.2333e-02,\n         -2.6128e-01, -2.7658e-01,  5.7707e-02,  1.9059e-01, -1.1519e-01,\n         -1.0684e-01, -1.2740e-01],\n        [ 2.1472e-03, -7.9942e-02,  3.2875e-01,  1.9508e-01, -9.1506e-02,\n          4.7743e-02,  6.9961e-02, -4.7318e-02,  1.3725e-01,  2.6099e-02,\n          2.9975e-01,  1.4765e-01,  6.1593e-02,  2.6139e-01, -5.2703e-03,\n         -2.0730e-01, -2.5477e-01, -2.9844e-01, -2.9235e-01,  2.2979e-01,\n         -1.6315e-01, -1.1253e-01,  2.2584e-01, -1.9360e-01, -1.7440e-02,\n         -3.2231e-01, -1.2009e-01, -1.8306e-01,  1.1502e-01,  1.2565e-01,\n         -1.7556e-01, -2.6991e-01],\n        [ 1.2263e-01, -2.7600e-01, -2.5099e-01, -1.3088e-01, -3.3142e-01,\n          3.3598e-01,  2.5066e-01, -2.4394e-01,  1.1838e-01,  2.5757e-01,\n         -3.4993e-01, -1.6062e-01, -2.0099e-02,  2.4020e-01,  2.0749e-01,\n          2.7531e-01, -3.2657e-01, -3.4292e-01,  1.2910e-01, -4.1515e-02,\n          2.8147e-01, -3.4566e-01,  3.4807e-01,  3.0933e-01,  1.1931e-01,\n         -3.2365e-01, -1.8642e-01,  3.2157e-01,  7.0477e-02, -1.7834e-01,\n         -1.5313e-01,  2.3579e-01],\n        [ 2.4808e-01,  1.9021e-02,  1.7039e-01,  1.3234e-01,  3.1855e-02,\n          4.3532e-02, -4.4372e-03, -1.1725e-01, -4.5570e-02,  1.2121e-01,\n          3.3599e-01, -2.1228e-01,  2.4728e-01,  3.2369e-01,  7.3250e-02,\n          3.5392e-02,  6.4529e-02,  2.3776e-01,  1.7218e-01,  1.5699e-01,\n          3.2117e-01, -2.9640e-02, -2.1232e-01, -5.2667e-02,  1.6218e-01,\n          1.9850e-01,  1.0326e-01, -2.6705e-01,  2.6518e-01,  2.8136e-01,\n         -3.3554e-01, -4.4131e-02],\n        [-2.8787e-01, -1.6584e-01, -1.4864e-01,  3.0910e-01, -3.2158e-01,\n          2.6999e-01, -1.0194e-01,  1.4382e-01, -8.7147e-02,  3.2106e-01,\n          9.8822e-02,  2.4419e-01,  3.1190e-01, -1.2444e-01, -3.0346e-01,\n          1.5550e-01, -1.7343e-01, -3.4488e-01, -2.6207e-01,  2.5291e-01,\n         -5.7400e-02, -2.9177e-01, -2.0621e-01,  1.6353e-01, -3.0088e-01,\n         -2.8797e-01, -1.6027e-01, -2.4865e-01, -1.3979e-01, -2.8786e-02,\n         -1.9668e-02, -2.0684e-01],\n        [-5.7842e-02,  3.2388e-01, -8.4397e-02, -1.6411e-01, -2.1836e-01,\n         -2.7783e-01,  3.0397e-02,  3.2052e-01,  2.7645e-01, -1.1493e-01,\n          7.6126e-02, -5.3486e-02,  1.3743e-02, -2.7616e-01, -3.4719e-01,\n         -2.2009e-01, -4.5353e-02,  4.5321e-02,  2.7323e-01,  2.5624e-01,\n         -3.5285e-01, -3.2526e-01,  1.1267e-01,  4.7281e-02,  3.4393e-01,\n          8.1718e-02, -3.3931e-01, -1.5137e-01,  2.1158e-01, -1.3426e-01,\n          1.0190e-01, -4.4025e-02],\n        [-1.2551e-01,  1.2954e-01,  6.8064e-02,  2.1809e-01,  1.3847e-01,\n          3.4762e-01, -1.1160e-01,  1.2892e-01,  1.7796e-01, -3.0255e-01,\n         -1.0176e-03,  3.0744e-01, -3.4538e-01,  1.5856e-03,  3.1766e-01,\n         -2.2879e-01, -1.6756e-01, -1.9616e-01, -1.2601e-01,  2.0852e-01,\n         -1.1154e-01, -3.4392e-01, -6.3509e-02,  3.2483e-01, -1.3793e-02,\n         -1.7159e-01,  8.4322e-02,  2.3072e-01,  5.2938e-02, -1.6878e-01,\n          2.7052e-01,  1.2302e-01],\n        [ 4.7010e-02,  1.7386e-01,  1.5332e-01, -2.6898e-04,  2.4287e-01,\n          4.5773e-02, -1.7250e-01,  3.3417e-01, -1.5238e-01, -1.8718e-01,\n         -5.1378e-02,  2.3223e-01,  2.9444e-01,  3.9460e-02,  1.3492e-01,\n         -2.6569e-01, -1.7439e-01, -1.8648e-01,  3.2615e-01,  3.2057e-01,\n         -1.2209e-01, -8.9516e-02, -3.0594e-01, -6.2079e-02, -1.7817e-01,\n         -1.5694e-01, -3.4134e-01,  1.7008e-01, -1.8618e-01, -1.4150e-01,\n         -1.2762e-01, -1.7388e-01],\n        [-3.1982e-01,  4.9911e-03,  2.1736e-01, -2.5360e-01,  1.3877e-01,\n          2.5380e-01,  1.3023e-01,  2.1986e-01,  2.9904e-02,  1.8498e-01,\n         -7.3816e-02, -2.1572e-01,  2.9108e-01, -7.4989e-02, -3.0604e-01,\n         -9.1123e-02,  1.8347e-01,  3.0351e-01,  4.9522e-02,  1.8459e-01,\n         -1.3373e-01, -1.4324e-02,  2.9328e-01, -2.1270e-01,  1.9168e-02,\n         -9.7175e-02,  9.8076e-02, -1.9999e-01,  2.8687e-01, -2.6381e-01,\n          9.4768e-02,  4.3044e-02],\n        [-1.8898e-01, -5.4435e-02, -2.0701e-01, -3.1213e-01, -1.0774e-01,\n         -6.5842e-02, -1.5882e-02, -2.5547e-01,  8.5123e-02, -2.0349e-01,\n         -2.1676e-01,  1.1055e-01,  2.7095e-01,  9.6332e-02,  1.7756e-01,\n          1.4998e-01,  1.5569e-01, -9.7436e-02,  2.3245e-01, -2.8106e-01,\n          1.4878e-02,  2.3788e-01, -1.4050e-01, -2.3965e-01,  1.4326e-01,\n          3.0734e-01,  1.0627e-01, -1.7782e-02,  2.3027e-01, -2.3577e-01,\n         -2.3479e-01,  8.9380e-02],\n        [ 3.8862e-02,  9.2412e-02, -3.2446e-01,  7.2409e-02,  2.4633e-01,\n          2.6133e-01, -2.3290e-01, -1.5473e-01,  1.5227e-01, -2.4821e-02,\n         -2.0178e-01,  2.6790e-01, -1.6896e-01, -1.5042e-02,  1.7871e-01,\n         -3.4211e-01,  3.0784e-01,  3.3035e-01,  2.7694e-01, -1.5211e-02,\n          3.1706e-01, -2.3094e-01,  1.0658e-01, -1.4970e-01,  1.2764e-01,\n         -3.4774e-01,  1.6538e-01, -2.4557e-01,  2.5996e-01,  7.7293e-02,\n          1.7327e-01,  2.3313e-01],\n        [-1.2976e-01, -3.1156e-02,  5.4686e-02, -1.8511e-02, -2.4968e-01,\n         -3.1829e-01,  8.0778e-02, -1.7648e-01, -2.1500e-02, -3.3333e-01,\n          3.0116e-01, -2.1628e-01, -3.8760e-02, -1.4644e-01, -2.1557e-01,\n         -6.3652e-02,  2.5023e-01,  1.5781e-01,  4.8211e-02, -1.2281e-01,\n          1.5882e-01, -2.0911e-01, -2.0985e-01,  2.6591e-01,  3.5215e-01,\n         -1.2655e-01, -6.9196e-03, -3.4137e-01,  6.0777e-02, -1.1721e-01,\n          2.4634e-01,  3.1771e-01],\n        [-2.5638e-01, -1.3938e-01, -1.9200e-01,  2.8357e-01,  3.5445e-02,\n          2.4283e-01, -2.4196e-01,  9.0197e-02,  1.4955e-02, -3.3071e-01,\n          8.7840e-02, -2.8281e-02,  2.9671e-01, -1.5346e-01, -1.2732e-01,\n         -2.5328e-02,  2.5438e-01,  3.3714e-01, -2.7839e-01, -1.0785e-01,\n         -3.4484e-01, -3.7721e-03, -3.4965e-02,  3.4437e-01,  2.6619e-01,\n         -2.1096e-02, -3.2676e-01, -1.2857e-01, -1.9101e-01,  1.4985e-01,\n          6.5139e-02, -8.1315e-03],\n        [ 3.2505e-01,  7.9298e-02, -2.8147e-01,  1.2315e-01, -2.0459e-01,\n         -3.0807e-01,  1.7800e-01,  3.5254e-01, -7.1832e-02, -1.4103e-01,\n          3.4101e-01, -1.6534e-02, -2.9232e-01, -1.3922e-01, -1.6037e-01,\n         -3.2586e-01, -2.3235e-01, -2.7329e-01,  2.1403e-01,  3.3758e-01,\n         -7.9931e-03, -5.5461e-02,  4.8595e-02,  3.0743e-02, -9.1176e-02,\n         -1.7366e-01, -2.3825e-01,  3.4062e-01,  2.8961e-02,  6.4740e-02,\n          3.1042e-01, -3.4963e-01],\n        [ 1.3868e-01,  6.3387e-02,  1.8234e-01,  2.7139e-01,  3.3513e-01,\n         -2.8987e-01,  3.3257e-01,  2.6479e-01,  1.4427e-01, -2.1639e-01,\n          1.4517e-02, -1.0397e-01,  1.5774e-01,  2.9732e-01, -7.2767e-03,\n         -3.2234e-01,  2.3112e-01, -1.2707e-01, -1.8910e-01, -7.4545e-02,\n          6.0698e-02, -1.1448e-01,  2.2001e-01, -9.4767e-03,  1.7248e-01,\n          9.1839e-02,  5.2929e-02, -1.2555e-01, -2.5258e-01, -2.1237e-01,\n         -1.8558e-01,  7.3892e-02],\n        [-2.2311e-01,  1.4944e-02,  1.7759e-01, -2.5519e-01, -9.2195e-02,\n          2.7804e-01, -1.2990e-01, -1.8098e-01, -3.5236e-01,  1.2334e-01,\n          3.0678e-02, -1.8269e-01, -2.2077e-01,  3.4427e-01,  2.6470e-01,\n          4.9691e-02, -2.1421e-01,  2.4014e-01, -2.9099e-01, -2.8646e-01,\n         -1.4843e-01, -2.5827e-01, -2.4203e-01,  8.4135e-02,  8.6286e-02,\n         -5.5199e-03,  3.2053e-01,  4.8673e-02,  2.9855e-01, -2.0748e-02,\n          3.1686e-02,  2.0996e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1902,  0.0691,  0.1158, -0.1544, -0.0584,  0.0368, -0.3522, -0.1104,\n          0.4808,  0.0558, -0.2131, -0.4351, -0.3226,  0.4959,  0.0485,  0.1429],\n        [-0.0600,  0.2195,  0.3421, -0.4550,  0.1578,  0.1193,  0.1283, -0.2265,\n         -0.0637, -0.2886,  0.3769,  0.0731, -0.0813,  0.3778, -0.0665, -0.3117],\n        [ 0.2954, -0.0207,  0.4753,  0.3652, -0.2311, -0.4018,  0.2310,  0.2103,\n          0.1036,  0.0274, -0.0049,  0.3974, -0.2764,  0.2654, -0.3376,  0.3840],\n        [ 0.1278, -0.1702,  0.2486,  0.0396,  0.3804,  0.4712,  0.1482,  0.4366,\n         -0.0699, -0.2783, -0.0545,  0.3239,  0.1755,  0.2406, -0.4856, -0.4335],\n        [-0.2140, -0.4611, -0.2129,  0.2422, -0.0543,  0.4696, -0.1157, -0.3708,\n          0.2756, -0.1046, -0.3401,  0.0490, -0.3892, -0.4082, -0.2368, -0.0878],\n        [-0.1418, -0.0475, -0.3015, -0.1580, -0.3740, -0.3419,  0.0795, -0.3884,\n          0.3072,  0.0648, -0.2380,  0.2404,  0.4870, -0.4367, -0.1475,  0.4356],\n        [ 0.2016,  0.2133,  0.2424,  0.3846,  0.2805, -0.2308,  0.0133,  0.2576,\n         -0.0468, -0.0899,  0.2802,  0.2204, -0.3114,  0.3049,  0.3696, -0.2562],\n        [-0.3382,  0.4189,  0.0536,  0.3562, -0.0157, -0.3796, -0.4624,  0.2683,\n         -0.3609,  0.4543,  0.3868,  0.0151,  0.1573,  0.0831, -0.1628,  0.3527]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3096,  0.6365, -0.6337, -0.3564,  0.1410,  0.3416, -0.1233,  0.6806],\n        [-0.4444, -0.1400, -0.2764, -0.4944, -0.0852, -0.4982,  0.1039,  0.2114],\n        [ 0.6185,  0.5853, -0.4264,  0.0960, -0.0917, -0.4011, -0.0166,  0.6642],\n        [ 0.3982, -0.0734,  0.2314,  0.0401, -0.3466,  0.4507, -0.5727,  0.6714]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.01\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.01,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.01,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-1.9616e-01, -1.1139e-01, -1.1544e-01, -4.4423e-02, -4.1302e-02,\n         -2.3609e-01, -2.2522e-01, -5.7782e-02],\n        [ 2.6672e-01, -6.9371e-03,  1.1848e-01,  2.7065e-01,  3.5082e-01,\n         -3.3051e-01,  8.8653e-02, -5.1448e-02],\n        [ 1.3006e-01,  2.9991e-01,  3.0024e-01,  2.3282e-01, -1.3764e-01,\n         -3.0164e-01, -1.9494e-01,  1.6616e-01],\n        [-2.0345e-03,  4.3493e-02, -2.9214e-01, -7.1060e-03,  3.5580e-01,\n          6.0697e-02,  2.2966e-01, -6.7746e-02],\n        [ 1.5397e-01, -1.0494e-01, -3.1920e-01,  5.0877e-02,  2.0057e-01,\n          1.5385e-01, -1.3196e-01,  7.8931e-02],\n        [ 2.3172e-01, -3.5230e-01,  3.0987e-01, -1.5684e-01,  1.7487e-01,\n          1.0857e-01,  8.9654e-02,  9.6424e-02],\n        [ 2.7603e-01,  1.3297e-01,  6.8822e-03,  2.8114e-01,  1.2404e-01,\n         -2.6106e-01,  3.4250e-01,  1.1430e-02],\n        [-1.7420e-01,  1.8512e-01,  2.8431e-01, -3.1059e-01, -1.2891e-01,\n         -1.3774e-01, -2.0701e-01, -1.8840e-01],\n        [ 4.6144e-02,  1.0874e-01, -2.7578e-01,  2.2635e-01,  2.0821e-01,\n          3.3340e-01,  1.3511e-01,  1.7574e-01],\n        [-2.8144e-01,  1.4634e-01,  1.7068e-01, -1.6415e-01, -2.5001e-01,\n         -2.4416e-01, -3.5067e-01, -8.6501e-02],\n        [-2.9286e-01,  3.7325e-01, -1.5837e-01, -9.0676e-02, -6.5837e-02,\n          1.3082e-01, -2.4516e-02, -2.3268e-01],\n        [-7.9905e-02, -3.6500e-01,  2.1640e-01, -3.3709e-01, -2.2287e-01,\n         -2.8099e-01,  6.5225e-02, -2.8897e-01],\n        [-1.1660e-01, -1.9284e-01,  1.2223e-01, -1.6452e-01,  8.3565e-02,\n         -2.2717e-02,  6.0646e-02,  1.9976e-01],\n        [ 1.1418e-01, -1.9633e-01, -3.3592e-01,  2.8316e-01, -2.2864e-01,\n         -9.4971e-02,  1.8338e-01, -2.9975e-01],\n        [ 3.0422e-01, -2.9781e-01,  3.3605e-01,  2.3805e-01,  5.9832e-02,\n          3.2259e-01,  3.3667e-01, -1.7409e-02],\n        [-1.2413e-02, -3.3534e-01,  1.2942e-02,  2.5729e-01,  2.1029e-01,\n         -2.8224e-01,  2.0203e-01,  1.1971e-01],\n        [-1.6800e-01,  3.3475e-01,  2.4521e-01, -1.8991e-02,  3.7297e-01,\n         -2.9105e-02, -1.2351e-01, -2.0140e-01],\n        [-2.3900e-01,  2.7286e-01,  1.7976e-01, -2.3361e-01,  3.6933e-01,\n          1.4762e-01,  3.3709e-01,  2.1359e-01],\n        [ 1.3344e-01, -5.4342e-02, -8.3183e-02, -3.6709e-03, -2.6659e-02,\n          1.4228e-01, -2.4466e-01,  2.4833e-01],\n        [ 1.4136e-01,  3.8434e-01, -2.5752e-02, -1.0354e-01,  1.1355e-01,\n         -2.7241e-01,  7.9703e-02,  2.1108e-01],\n        [ 2.0755e-01, -1.7384e-01, -3.5606e-01, -3.5346e-01, -3.1112e-01,\n          1.8590e-01, -1.0890e-01,  3.2153e-01],\n        [-4.0025e-02, -3.1983e-01, -3.8190e-01, -1.8302e-01,  2.4922e-01,\n         -2.0377e-02, -1.7537e-01,  1.0784e-01],\n        [-1.9200e-01, -1.2157e-01, -4.6970e-02,  2.4747e-05,  2.3513e-01,\n         -2.2695e-01, -3.3748e-01, -2.5676e-01],\n        [-2.7093e-01,  3.7772e-01, -5.0221e-02, -1.1546e-02,  8.1848e-02,\n         -2.0648e-01,  9.7042e-02, -3.7584e-01],\n        [-3.2137e-02,  8.9480e-02,  7.4143e-02, -2.1577e-01,  3.0556e-01,\n          3.2712e-01,  2.0778e-01,  9.0318e-02],\n        [ 9.4130e-03,  3.4949e-01, -1.3290e-01, -2.3567e-01,  1.5464e-02,\n         -2.6361e-01, -4.1569e-02, -3.2648e-01],\n        [ 2.3316e-01, -1.2332e-01, -7.2090e-02, -1.1880e-01,  3.1035e-01,\n          3.6721e-01,  3.6971e-01, -2.0669e-01],\n        [ 2.0219e-02, -2.4547e-01,  3.0310e-01,  3.3210e-01, -3.2044e-03,\n          1.3384e-01, -6.1071e-02,  2.2940e-01],\n        [ 3.7163e-01,  1.4222e-01,  2.6392e-01, -2.6124e-01, -3.5727e-01,\n         -3.5027e-01,  3.7977e-02,  3.0978e-02],\n        [ 1.2561e-01, -1.9336e-01, -2.0550e-02,  1.1871e-01,  3.4760e-02,\n         -3.1071e-01,  3.9667e-02, -1.7524e-02],\n        [ 1.0411e-01, -2.2697e-01, -2.2324e-01,  3.6330e-01, -2.5517e-01,\n          1.3995e-01, -3.8419e-01,  2.4125e-01],\n        [-3.8547e-01,  1.2962e-01,  1.8093e-01, -2.2521e-01,  1.8438e-01,\n          3.1556e-01, -2.8808e-01,  2.0659e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 7.8901e-02,  2.7568e-01,  2.2499e-01,  2.1477e-01,  2.9854e-01,\n         -2.4538e-01, -3.0087e-01,  2.3425e-01,  2.2307e-01,  3.4785e-01,\n          1.2278e-01,  2.9548e-01,  9.0713e-02,  1.5815e-01,  2.9676e-01,\n          1.4319e-01, -2.7540e-02, -1.3511e-01, -1.5538e-02, -1.7332e-01,\n          2.9113e-01,  1.2065e-01,  8.6038e-02, -5.1814e-02, -8.2333e-02,\n         -2.6128e-01, -2.7658e-01,  5.7707e-02,  1.9059e-01, -1.1519e-01,\n         -1.0684e-01, -1.2740e-01],\n        [ 2.1472e-03, -7.9942e-02,  3.2875e-01,  1.9508e-01, -9.1506e-02,\n          4.7743e-02,  6.9961e-02, -4.7318e-02,  1.3725e-01,  2.6099e-02,\n          2.9975e-01,  1.4765e-01,  6.1593e-02,  2.6139e-01, -5.2703e-03,\n         -2.0730e-01, -2.5477e-01, -2.9844e-01, -2.9235e-01,  2.2979e-01,\n         -1.6315e-01, -1.1253e-01,  2.2584e-01, -1.9360e-01, -1.7440e-02,\n         -3.2231e-01, -1.2009e-01, -1.8306e-01,  1.1502e-01,  1.2565e-01,\n         -1.7556e-01, -2.6991e-01],\n        [ 1.2263e-01, -2.7600e-01, -2.5099e-01, -1.3088e-01, -3.3142e-01,\n          3.3598e-01,  2.5066e-01, -2.4394e-01,  1.1838e-01,  2.5757e-01,\n         -3.4993e-01, -1.6062e-01, -2.0099e-02,  2.4020e-01,  2.0749e-01,\n          2.7531e-01, -3.2657e-01, -3.4292e-01,  1.2910e-01, -4.1515e-02,\n          2.8147e-01, -3.4566e-01,  3.4807e-01,  3.0933e-01,  1.1931e-01,\n         -3.2365e-01, -1.8642e-01,  3.2157e-01,  7.0477e-02, -1.7834e-01,\n         -1.5313e-01,  2.3579e-01],\n        [ 2.4808e-01,  1.9021e-02,  1.7039e-01,  1.3234e-01,  3.1855e-02,\n          4.3532e-02, -4.4372e-03, -1.1725e-01, -4.5570e-02,  1.2121e-01,\n          3.3599e-01, -2.1228e-01,  2.4728e-01,  3.2369e-01,  7.3250e-02,\n          3.5392e-02,  6.4529e-02,  2.3776e-01,  1.7218e-01,  1.5699e-01,\n          3.2117e-01, -2.9640e-02, -2.1232e-01, -5.2667e-02,  1.6218e-01,\n          1.9850e-01,  1.0326e-01, -2.6705e-01,  2.6518e-01,  2.8136e-01,\n         -3.3554e-01, -4.4131e-02],\n        [-2.8787e-01, -1.6584e-01, -1.4864e-01,  3.0910e-01, -3.2158e-01,\n          2.6999e-01, -1.0194e-01,  1.4382e-01, -8.7147e-02,  3.2106e-01,\n          9.8822e-02,  2.4419e-01,  3.1190e-01, -1.2444e-01, -3.0346e-01,\n          1.5550e-01, -1.7343e-01, -3.4488e-01, -2.6207e-01,  2.5291e-01,\n         -5.7400e-02, -2.9177e-01, -2.0621e-01,  1.6353e-01, -3.0088e-01,\n         -2.8797e-01, -1.6027e-01, -2.4865e-01, -1.3979e-01, -2.8786e-02,\n         -1.9668e-02, -2.0684e-01],\n        [-5.7842e-02,  3.2388e-01, -8.4397e-02, -1.6411e-01, -2.1836e-01,\n         -2.7783e-01,  3.0397e-02,  3.2052e-01,  2.7645e-01, -1.1493e-01,\n          7.6126e-02, -5.3486e-02,  1.3743e-02, -2.7616e-01, -3.4719e-01,\n         -2.2009e-01, -4.5353e-02,  4.5321e-02,  2.7323e-01,  2.5624e-01,\n         -3.5285e-01, -3.2526e-01,  1.1267e-01,  4.7281e-02,  3.4393e-01,\n          8.1718e-02, -3.3931e-01, -1.5137e-01,  2.1158e-01, -1.3426e-01,\n          1.0190e-01, -4.4025e-02],\n        [-1.2551e-01,  1.2954e-01,  6.8064e-02,  2.1809e-01,  1.3847e-01,\n          3.4762e-01, -1.1160e-01,  1.2892e-01,  1.7796e-01, -3.0255e-01,\n         -1.0176e-03,  3.0744e-01, -3.4538e-01,  1.5856e-03,  3.1766e-01,\n         -2.2879e-01, -1.6756e-01, -1.9616e-01, -1.2601e-01,  2.0852e-01,\n         -1.1154e-01, -3.4392e-01, -6.3509e-02,  3.2483e-01, -1.3793e-02,\n         -1.7159e-01,  8.4322e-02,  2.3072e-01,  5.2938e-02, -1.6878e-01,\n          2.7052e-01,  1.2302e-01],\n        [ 4.7010e-02,  1.7386e-01,  1.5332e-01, -2.6898e-04,  2.4287e-01,\n          4.5773e-02, -1.7250e-01,  3.3417e-01, -1.5238e-01, -1.8718e-01,\n         -5.1378e-02,  2.3223e-01,  2.9444e-01,  3.9460e-02,  1.3492e-01,\n         -2.6569e-01, -1.7439e-01, -1.8648e-01,  3.2615e-01,  3.2057e-01,\n         -1.2209e-01, -8.9516e-02, -3.0594e-01, -6.2079e-02, -1.7817e-01,\n         -1.5694e-01, -3.4134e-01,  1.7008e-01, -1.8618e-01, -1.4150e-01,\n         -1.2762e-01, -1.7388e-01],\n        [-3.1982e-01,  4.9911e-03,  2.1736e-01, -2.5360e-01,  1.3877e-01,\n          2.5380e-01,  1.3023e-01,  2.1986e-01,  2.9904e-02,  1.8498e-01,\n         -7.3816e-02, -2.1572e-01,  2.9108e-01, -7.4989e-02, -3.0604e-01,\n         -9.1123e-02,  1.8347e-01,  3.0351e-01,  4.9522e-02,  1.8459e-01,\n         -1.3373e-01, -1.4324e-02,  2.9328e-01, -2.1270e-01,  1.9168e-02,\n         -9.7175e-02,  9.8076e-02, -1.9999e-01,  2.8687e-01, -2.6381e-01,\n          9.4768e-02,  4.3044e-02],\n        [-1.8898e-01, -5.4435e-02, -2.0701e-01, -3.1213e-01, -1.0774e-01,\n         -6.5842e-02, -1.5882e-02, -2.5547e-01,  8.5123e-02, -2.0349e-01,\n         -2.1676e-01,  1.1055e-01,  2.7095e-01,  9.6332e-02,  1.7756e-01,\n          1.4998e-01,  1.5569e-01, -9.7436e-02,  2.3245e-01, -2.8106e-01,\n          1.4878e-02,  2.3788e-01, -1.4050e-01, -2.3965e-01,  1.4326e-01,\n          3.0734e-01,  1.0627e-01, -1.7782e-02,  2.3027e-01, -2.3577e-01,\n         -2.3479e-01,  8.9380e-02],\n        [ 3.8862e-02,  9.2412e-02, -3.2446e-01,  7.2409e-02,  2.4633e-01,\n          2.6133e-01, -2.3290e-01, -1.5473e-01,  1.5227e-01, -2.4821e-02,\n         -2.0178e-01,  2.6790e-01, -1.6896e-01, -1.5042e-02,  1.7871e-01,\n         -3.4211e-01,  3.0784e-01,  3.3035e-01,  2.7694e-01, -1.5211e-02,\n          3.1706e-01, -2.3094e-01,  1.0658e-01, -1.4970e-01,  1.2764e-01,\n         -3.4774e-01,  1.6538e-01, -2.4557e-01,  2.5996e-01,  7.7293e-02,\n          1.7327e-01,  2.3313e-01],\n        [-1.2976e-01, -3.1156e-02,  5.4686e-02, -1.8511e-02, -2.4968e-01,\n         -3.1829e-01,  8.0778e-02, -1.7648e-01, -2.1500e-02, -3.3333e-01,\n          3.0116e-01, -2.1628e-01, -3.8760e-02, -1.4644e-01, -2.1557e-01,\n         -6.3652e-02,  2.5023e-01,  1.5781e-01,  4.8211e-02, -1.2281e-01,\n          1.5882e-01, -2.0911e-01, -2.0985e-01,  2.6591e-01,  3.5215e-01,\n         -1.2655e-01, -6.9196e-03, -3.4137e-01,  6.0777e-02, -1.1721e-01,\n          2.4634e-01,  3.1771e-01],\n        [-2.5638e-01, -1.3938e-01, -1.9200e-01,  2.8357e-01,  3.5445e-02,\n          2.4283e-01, -2.4196e-01,  9.0197e-02,  1.4955e-02, -3.3071e-01,\n          8.7840e-02, -2.8281e-02,  2.9671e-01, -1.5346e-01, -1.2732e-01,\n         -2.5328e-02,  2.5438e-01,  3.3714e-01, -2.7839e-01, -1.0785e-01,\n         -3.4484e-01, -3.7721e-03, -3.4965e-02,  3.4437e-01,  2.6619e-01,\n         -2.1096e-02, -3.2676e-01, -1.2857e-01, -1.9101e-01,  1.4985e-01,\n          6.5139e-02, -8.1315e-03],\n        [ 3.2505e-01,  7.9298e-02, -2.8147e-01,  1.2315e-01, -2.0459e-01,\n         -3.0807e-01,  1.7800e-01,  3.5254e-01, -7.1832e-02, -1.4103e-01,\n          3.4101e-01, -1.6534e-02, -2.9232e-01, -1.3922e-01, -1.6037e-01,\n         -3.2586e-01, -2.3235e-01, -2.7329e-01,  2.1403e-01,  3.3758e-01,\n         -7.9931e-03, -5.5461e-02,  4.8595e-02,  3.0743e-02, -9.1176e-02,\n         -1.7366e-01, -2.3825e-01,  3.4062e-01,  2.8961e-02,  6.4740e-02,\n          3.1042e-01, -3.4963e-01],\n        [ 1.3868e-01,  6.3387e-02,  1.8234e-01,  2.7139e-01,  3.3513e-01,\n         -2.8987e-01,  3.3257e-01,  2.6479e-01,  1.4427e-01, -2.1639e-01,\n          1.4517e-02, -1.0397e-01,  1.5774e-01,  2.9732e-01, -7.2767e-03,\n         -3.2234e-01,  2.3112e-01, -1.2707e-01, -1.8910e-01, -7.4545e-02,\n          6.0698e-02, -1.1448e-01,  2.2001e-01, -9.4767e-03,  1.7248e-01,\n          9.1839e-02,  5.2929e-02, -1.2555e-01, -2.5258e-01, -2.1237e-01,\n         -1.8558e-01,  7.3892e-02],\n        [-2.2311e-01,  1.4944e-02,  1.7759e-01, -2.5519e-01, -9.2195e-02,\n          2.7804e-01, -1.2990e-01, -1.8098e-01, -3.5236e-01,  1.2334e-01,\n          3.0678e-02, -1.8269e-01, -2.2077e-01,  3.4427e-01,  2.6470e-01,\n          4.9691e-02, -2.1421e-01,  2.4014e-01, -2.9099e-01, -2.8646e-01,\n         -1.4843e-01, -2.5827e-01, -2.4203e-01,  8.4135e-02,  8.6286e-02,\n         -5.5199e-03,  3.2053e-01,  4.8673e-02,  2.9855e-01, -2.0748e-02,\n          3.1686e-02,  2.0996e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1902,  0.0691,  0.1158, -0.1544, -0.0584,  0.0368, -0.3522, -0.1104,\n          0.4808,  0.0558, -0.2131, -0.4351, -0.3226,  0.4959,  0.0485,  0.1429],\n        [-0.0600,  0.2195,  0.3421, -0.4550,  0.1578,  0.1193,  0.1283, -0.2265,\n         -0.0637, -0.2886,  0.3769,  0.0731, -0.0813,  0.3778, -0.0665, -0.3117],\n        [ 0.2954, -0.0207,  0.4753,  0.3652, -0.2311, -0.4018,  0.2310,  0.2103,\n          0.1036,  0.0274, -0.0049,  0.3974, -0.2764,  0.2654, -0.3376,  0.3840],\n        [ 0.1278, -0.1702,  0.2486,  0.0396,  0.3804,  0.4712,  0.1482,  0.4366,\n         -0.0699, -0.2783, -0.0545,  0.3239,  0.1755,  0.2406, -0.4856, -0.4335],\n        [-0.2140, -0.4611, -0.2129,  0.2422, -0.0543,  0.4696, -0.1157, -0.3708,\n          0.2756, -0.1046, -0.3401,  0.0490, -0.3892, -0.4082, -0.2368, -0.0878],\n        [-0.1418, -0.0475, -0.3015, -0.1580, -0.3740, -0.3419,  0.0795, -0.3884,\n          0.3072,  0.0648, -0.2380,  0.2404,  0.4870, -0.4367, -0.1475,  0.4356],\n        [ 0.2016,  0.2133,  0.2424,  0.3846,  0.2805, -0.2308,  0.0133,  0.2576,\n         -0.0468, -0.0899,  0.2802,  0.2204, -0.3114,  0.3049,  0.3696, -0.2562],\n        [-0.3382,  0.4189,  0.0536,  0.3562, -0.0157, -0.3796, -0.4624,  0.2683,\n         -0.3609,  0.4543,  0.3868,  0.0151,  0.1573,  0.0831, -0.1628,  0.3527]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3096,  0.6365, -0.6337, -0.3564,  0.1410,  0.3416, -0.1233,  0.6806],\n        [-0.4444, -0.1400, -0.2764, -0.4944, -0.0852, -0.4982,  0.1039,  0.2114],\n        [ 0.6185,  0.5853, -0.4264,  0.0960, -0.0917, -0.4011, -0.0166,  0.6642],\n        [ 0.3982, -0.0734,  0.2314,  0.0401, -0.3466,  0.4507, -0.5727,  0.6714]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x732adc7ca790>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.9616e-01, -1.1139e-01, -1.1544e-01, -4.4423e-02, -4.1302e-02,\n         -2.3609e-01, -2.2522e-01, -5.7782e-02],\n        [ 2.6672e-01, -6.9371e-03,  1.1848e-01,  2.7065e-01,  3.5082e-01,\n         -3.3051e-01,  8.8653e-02, -5.1448e-02],\n        [ 1.3006e-01,  2.9991e-01,  3.0024e-01,  2.3282e-01, -1.3764e-01,\n         -3.0164e-01, -1.9494e-01,  1.6616e-01],\n        [-2.0345e-03,  4.3493e-02, -2.9214e-01, -7.1060e-03,  3.5580e-01,\n          6.0697e-02,  2.2966e-01, -6.7746e-02],\n        [ 1.5397e-01, -1.0494e-01, -3.1920e-01,  5.0877e-02,  2.0057e-01,\n          1.5385e-01, -1.3196e-01,  7.8931e-02],\n        [ 2.3172e-01, -3.5230e-01,  3.0987e-01, -1.5684e-01,  1.7487e-01,\n          1.0857e-01,  8.9654e-02,  9.6424e-02],\n        [ 2.7603e-01,  1.3297e-01,  6.8822e-03,  2.8114e-01,  1.2404e-01,\n         -2.6106e-01,  3.4250e-01,  1.1430e-02],\n        [-1.7420e-01,  1.8512e-01,  2.8431e-01, -3.1059e-01, -1.2891e-01,\n         -1.3774e-01, -2.0701e-01, -1.8840e-01],\n        [ 4.6144e-02,  1.0874e-01, -2.7578e-01,  2.2635e-01,  2.0821e-01,\n          3.3340e-01,  1.3511e-01,  1.7574e-01],\n        [-2.8144e-01,  1.4634e-01,  1.7068e-01, -1.6415e-01, -2.5001e-01,\n         -2.4416e-01, -3.5067e-01, -8.6501e-02],\n        [-2.9286e-01,  3.7325e-01, -1.5837e-01, -9.0676e-02, -6.5837e-02,\n          1.3082e-01, -2.4516e-02, -2.3268e-01],\n        [-7.9905e-02, -3.6500e-01,  2.1640e-01, -3.3709e-01, -2.2287e-01,\n         -2.8099e-01,  6.5225e-02, -2.8897e-01],\n        [-1.1660e-01, -1.9284e-01,  1.2223e-01, -1.6452e-01,  8.3565e-02,\n         -2.2717e-02,  6.0646e-02,  1.9976e-01],\n        [ 1.1418e-01, -1.9633e-01, -3.3592e-01,  2.8316e-01, -2.2864e-01,\n         -9.4971e-02,  1.8338e-01, -2.9975e-01],\n        [ 3.0422e-01, -2.9781e-01,  3.3605e-01,  2.3805e-01,  5.9832e-02,\n          3.2259e-01,  3.3667e-01, -1.7409e-02],\n        [-1.2413e-02, -3.3534e-01,  1.2942e-02,  2.5729e-01,  2.1029e-01,\n         -2.8224e-01,  2.0203e-01,  1.1971e-01],\n        [-1.6800e-01,  3.3475e-01,  2.4521e-01, -1.8991e-02,  3.7297e-01,\n         -2.9105e-02, -1.2351e-01, -2.0140e-01],\n        [-2.3900e-01,  2.7286e-01,  1.7976e-01, -2.3361e-01,  3.6933e-01,\n          1.4762e-01,  3.3709e-01,  2.1359e-01],\n        [ 1.3344e-01, -5.4342e-02, -8.3183e-02, -3.6709e-03, -2.6659e-02,\n          1.4228e-01, -2.4466e-01,  2.4833e-01],\n        [ 1.4136e-01,  3.8434e-01, -2.5752e-02, -1.0354e-01,  1.1355e-01,\n         -2.7241e-01,  7.9703e-02,  2.1108e-01],\n        [ 2.0755e-01, -1.7384e-01, -3.5606e-01, -3.5346e-01, -3.1112e-01,\n          1.8590e-01, -1.0890e-01,  3.2153e-01],\n        [-4.0025e-02, -3.1983e-01, -3.8190e-01, -1.8302e-01,  2.4922e-01,\n         -2.0377e-02, -1.7537e-01,  1.0784e-01],\n        [-1.9200e-01, -1.2157e-01, -4.6970e-02,  2.4747e-05,  2.3513e-01,\n         -2.2695e-01, -3.3748e-01, -2.5676e-01],\n        [-2.7093e-01,  3.7772e-01, -5.0221e-02, -1.1546e-02,  8.1848e-02,\n         -2.0648e-01,  9.7042e-02, -3.7584e-01],\n        [-3.2137e-02,  8.9480e-02,  7.4143e-02, -2.1577e-01,  3.0556e-01,\n          3.2712e-01,  2.0778e-01,  9.0318e-02],\n        [ 9.4130e-03,  3.4949e-01, -1.3290e-01, -2.3567e-01,  1.5464e-02,\n         -2.6361e-01, -4.1569e-02, -3.2648e-01],\n        [ 2.3316e-01, -1.2332e-01, -7.2090e-02, -1.1880e-01,  3.1035e-01,\n          3.6721e-01,  3.6971e-01, -2.0669e-01],\n        [ 2.0219e-02, -2.4547e-01,  3.0310e-01,  3.3210e-01, -3.2044e-03,\n          1.3384e-01, -6.1071e-02,  2.2940e-01],\n        [ 3.7163e-01,  1.4222e-01,  2.6392e-01, -2.6124e-01, -3.5727e-01,\n         -3.5027e-01,  3.7977e-02,  3.0978e-02],\n        [ 1.2561e-01, -1.9336e-01, -2.0550e-02,  1.1871e-01,  3.4760e-02,\n         -3.1071e-01,  3.9667e-02, -1.7524e-02],\n        [ 1.0411e-01, -2.2697e-01, -2.2324e-01,  3.6330e-01, -2.5517e-01,\n          1.3995e-01, -3.8419e-01,  2.4125e-01],\n        [-3.8547e-01,  1.2962e-01,  1.8093e-01, -2.2521e-01,  1.8438e-01,\n          3.1556e-01, -2.8808e-01,  2.0659e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 7.8901e-02,  2.7568e-01,  2.2499e-01,  2.1477e-01,  2.9854e-01,\n         -2.4538e-01, -3.0087e-01,  2.3425e-01,  2.2307e-01,  3.4785e-01,\n          1.2278e-01,  2.9548e-01,  9.0713e-02,  1.5815e-01,  2.9676e-01,\n          1.4319e-01, -2.7540e-02, -1.3511e-01, -1.5538e-02, -1.7332e-01,\n          2.9113e-01,  1.2065e-01,  8.6038e-02, -5.1814e-02, -8.2333e-02,\n         -2.6128e-01, -2.7658e-01,  5.7707e-02,  1.9059e-01, -1.1519e-01,\n         -1.0684e-01, -1.2740e-01],\n        [ 2.1472e-03, -7.9942e-02,  3.2875e-01,  1.9508e-01, -9.1506e-02,\n          4.7743e-02,  6.9961e-02, -4.7318e-02,  1.3725e-01,  2.6099e-02,\n          2.9975e-01,  1.4765e-01,  6.1593e-02,  2.6139e-01, -5.2703e-03,\n         -2.0730e-01, -2.5477e-01, -2.9844e-01, -2.9235e-01,  2.2979e-01,\n         -1.6315e-01, -1.1253e-01,  2.2584e-01, -1.9360e-01, -1.7440e-02,\n         -3.2231e-01, -1.2009e-01, -1.8306e-01,  1.1502e-01,  1.2565e-01,\n         -1.7556e-01, -2.6991e-01],\n        [ 1.2263e-01, -2.7600e-01, -2.5099e-01, -1.3088e-01, -3.3142e-01,\n          3.3598e-01,  2.5066e-01, -2.4394e-01,  1.1838e-01,  2.5757e-01,\n         -3.4993e-01, -1.6062e-01, -2.0099e-02,  2.4020e-01,  2.0749e-01,\n          2.7531e-01, -3.2657e-01, -3.4292e-01,  1.2910e-01, -4.1515e-02,\n          2.8147e-01, -3.4566e-01,  3.4807e-01,  3.0933e-01,  1.1931e-01,\n         -3.2365e-01, -1.8642e-01,  3.2157e-01,  7.0477e-02, -1.7834e-01,\n         -1.5313e-01,  2.3579e-01],\n        [ 2.4808e-01,  1.9021e-02,  1.7039e-01,  1.3234e-01,  3.1855e-02,\n          4.3532e-02, -4.4372e-03, -1.1725e-01, -4.5570e-02,  1.2121e-01,\n          3.3599e-01, -2.1228e-01,  2.4728e-01,  3.2369e-01,  7.3250e-02,\n          3.5392e-02,  6.4529e-02,  2.3776e-01,  1.7218e-01,  1.5699e-01,\n          3.2117e-01, -2.9640e-02, -2.1232e-01, -5.2667e-02,  1.6218e-01,\n          1.9850e-01,  1.0326e-01, -2.6705e-01,  2.6518e-01,  2.8136e-01,\n         -3.3554e-01, -4.4131e-02],\n        [-2.8787e-01, -1.6584e-01, -1.4864e-01,  3.0910e-01, -3.2158e-01,\n          2.6999e-01, -1.0194e-01,  1.4382e-01, -8.7147e-02,  3.2106e-01,\n          9.8822e-02,  2.4419e-01,  3.1190e-01, -1.2444e-01, -3.0346e-01,\n          1.5550e-01, -1.7343e-01, -3.4488e-01, -2.6207e-01,  2.5291e-01,\n         -5.7400e-02, -2.9177e-01, -2.0621e-01,  1.6353e-01, -3.0088e-01,\n         -2.8797e-01, -1.6027e-01, -2.4865e-01, -1.3979e-01, -2.8786e-02,\n         -1.9668e-02, -2.0684e-01],\n        [-5.7842e-02,  3.2388e-01, -8.4397e-02, -1.6411e-01, -2.1836e-01,\n         -2.7783e-01,  3.0397e-02,  3.2052e-01,  2.7645e-01, -1.1493e-01,\n          7.6126e-02, -5.3486e-02,  1.3743e-02, -2.7616e-01, -3.4719e-01,\n         -2.2009e-01, -4.5353e-02,  4.5321e-02,  2.7323e-01,  2.5624e-01,\n         -3.5285e-01, -3.2526e-01,  1.1267e-01,  4.7281e-02,  3.4393e-01,\n          8.1718e-02, -3.3931e-01, -1.5137e-01,  2.1158e-01, -1.3426e-01,\n          1.0190e-01, -4.4025e-02],\n        [-1.2551e-01,  1.2954e-01,  6.8064e-02,  2.1809e-01,  1.3847e-01,\n          3.4762e-01, -1.1160e-01,  1.2892e-01,  1.7796e-01, -3.0255e-01,\n         -1.0176e-03,  3.0744e-01, -3.4538e-01,  1.5856e-03,  3.1766e-01,\n         -2.2879e-01, -1.6756e-01, -1.9616e-01, -1.2601e-01,  2.0852e-01,\n         -1.1154e-01, -3.4392e-01, -6.3509e-02,  3.2483e-01, -1.3793e-02,\n         -1.7159e-01,  8.4322e-02,  2.3072e-01,  5.2938e-02, -1.6878e-01,\n          2.7052e-01,  1.2302e-01],\n        [ 4.7010e-02,  1.7386e-01,  1.5332e-01, -2.6898e-04,  2.4287e-01,\n          4.5773e-02, -1.7250e-01,  3.3417e-01, -1.5238e-01, -1.8718e-01,\n         -5.1378e-02,  2.3223e-01,  2.9444e-01,  3.9460e-02,  1.3492e-01,\n         -2.6569e-01, -1.7439e-01, -1.8648e-01,  3.2615e-01,  3.2057e-01,\n         -1.2209e-01, -8.9516e-02, -3.0594e-01, -6.2079e-02, -1.7817e-01,\n         -1.5694e-01, -3.4134e-01,  1.7008e-01, -1.8618e-01, -1.4150e-01,\n         -1.2762e-01, -1.7388e-01],\n        [-3.1982e-01,  4.9911e-03,  2.1736e-01, -2.5360e-01,  1.3877e-01,\n          2.5380e-01,  1.3023e-01,  2.1986e-01,  2.9904e-02,  1.8498e-01,\n         -7.3816e-02, -2.1572e-01,  2.9108e-01, -7.4989e-02, -3.0604e-01,\n         -9.1123e-02,  1.8347e-01,  3.0351e-01,  4.9522e-02,  1.8459e-01,\n         -1.3373e-01, -1.4324e-02,  2.9328e-01, -2.1270e-01,  1.9168e-02,\n         -9.7175e-02,  9.8076e-02, -1.9999e-01,  2.8687e-01, -2.6381e-01,\n          9.4768e-02,  4.3044e-02],\n        [-1.8898e-01, -5.4435e-02, -2.0701e-01, -3.1213e-01, -1.0774e-01,\n         -6.5842e-02, -1.5882e-02, -2.5547e-01,  8.5123e-02, -2.0349e-01,\n         -2.1676e-01,  1.1055e-01,  2.7095e-01,  9.6332e-02,  1.7756e-01,\n          1.4998e-01,  1.5569e-01, -9.7436e-02,  2.3245e-01, -2.8106e-01,\n          1.4878e-02,  2.3788e-01, -1.4050e-01, -2.3965e-01,  1.4326e-01,\n          3.0734e-01,  1.0627e-01, -1.7782e-02,  2.3027e-01, -2.3577e-01,\n         -2.3479e-01,  8.9380e-02],\n        [ 3.8862e-02,  9.2412e-02, -3.2446e-01,  7.2409e-02,  2.4633e-01,\n          2.6133e-01, -2.3290e-01, -1.5473e-01,  1.5227e-01, -2.4821e-02,\n         -2.0178e-01,  2.6790e-01, -1.6896e-01, -1.5042e-02,  1.7871e-01,\n         -3.4211e-01,  3.0784e-01,  3.3035e-01,  2.7694e-01, -1.5211e-02,\n          3.1706e-01, -2.3094e-01,  1.0658e-01, -1.4970e-01,  1.2764e-01,\n         -3.4774e-01,  1.6538e-01, -2.4557e-01,  2.5996e-01,  7.7293e-02,\n          1.7327e-01,  2.3313e-01],\n        [-1.2976e-01, -3.1156e-02,  5.4686e-02, -1.8511e-02, -2.4968e-01,\n         -3.1829e-01,  8.0778e-02, -1.7648e-01, -2.1500e-02, -3.3333e-01,\n          3.0116e-01, -2.1628e-01, -3.8760e-02, -1.4644e-01, -2.1557e-01,\n         -6.3652e-02,  2.5023e-01,  1.5781e-01,  4.8211e-02, -1.2281e-01,\n          1.5882e-01, -2.0911e-01, -2.0985e-01,  2.6591e-01,  3.5215e-01,\n         -1.2655e-01, -6.9196e-03, -3.4137e-01,  6.0777e-02, -1.1721e-01,\n          2.4634e-01,  3.1771e-01],\n        [-2.5638e-01, -1.3938e-01, -1.9200e-01,  2.8357e-01,  3.5445e-02,\n          2.4283e-01, -2.4196e-01,  9.0197e-02,  1.4955e-02, -3.3071e-01,\n          8.7840e-02, -2.8281e-02,  2.9671e-01, -1.5346e-01, -1.2732e-01,\n         -2.5328e-02,  2.5438e-01,  3.3714e-01, -2.7839e-01, -1.0785e-01,\n         -3.4484e-01, -3.7721e-03, -3.4965e-02,  3.4437e-01,  2.6619e-01,\n         -2.1096e-02, -3.2676e-01, -1.2857e-01, -1.9101e-01,  1.4985e-01,\n          6.5139e-02, -8.1315e-03],\n        [ 3.2505e-01,  7.9298e-02, -2.8147e-01,  1.2315e-01, -2.0459e-01,\n         -3.0807e-01,  1.7800e-01,  3.5254e-01, -7.1832e-02, -1.4103e-01,\n          3.4101e-01, -1.6534e-02, -2.9232e-01, -1.3922e-01, -1.6037e-01,\n         -3.2586e-01, -2.3235e-01, -2.7329e-01,  2.1403e-01,  3.3758e-01,\n         -7.9931e-03, -5.5461e-02,  4.8595e-02,  3.0743e-02, -9.1176e-02,\n         -1.7366e-01, -2.3825e-01,  3.4062e-01,  2.8961e-02,  6.4740e-02,\n          3.1042e-01, -3.4963e-01],\n        [ 1.3868e-01,  6.3387e-02,  1.8234e-01,  2.7139e-01,  3.3513e-01,\n         -2.8987e-01,  3.3257e-01,  2.6479e-01,  1.4427e-01, -2.1639e-01,\n          1.4517e-02, -1.0397e-01,  1.5774e-01,  2.9732e-01, -7.2767e-03,\n         -3.2234e-01,  2.3112e-01, -1.2707e-01, -1.8910e-01, -7.4545e-02,\n          6.0698e-02, -1.1448e-01,  2.2001e-01, -9.4767e-03,  1.7248e-01,\n          9.1839e-02,  5.2929e-02, -1.2555e-01, -2.5258e-01, -2.1237e-01,\n         -1.8558e-01,  7.3892e-02],\n        [-2.2311e-01,  1.4944e-02,  1.7759e-01, -2.5519e-01, -9.2195e-02,\n          2.7804e-01, -1.2990e-01, -1.8098e-01, -3.5236e-01,  1.2334e-01,\n          3.0678e-02, -1.8269e-01, -2.2077e-01,  3.4427e-01,  2.6470e-01,\n          4.9691e-02, -2.1421e-01,  2.4014e-01, -2.9099e-01, -2.8646e-01,\n         -1.4843e-01, -2.5827e-01, -2.4203e-01,  8.4135e-02,  8.6286e-02,\n         -5.5199e-03,  3.2053e-01,  4.8673e-02,  2.9855e-01, -2.0748e-02,\n          3.1686e-02,  2.0996e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1902,  0.0691,  0.1158, -0.1544, -0.0584,  0.0368, -0.3522, -0.1104,\n          0.4808,  0.0558, -0.2131, -0.4351, -0.3226,  0.4959,  0.0485,  0.1429],\n        [-0.0600,  0.2195,  0.3421, -0.4550,  0.1578,  0.1193,  0.1283, -0.2265,\n         -0.0637, -0.2886,  0.3769,  0.0731, -0.0813,  0.3778, -0.0665, -0.3117],\n        [ 0.2954, -0.0207,  0.4753,  0.3652, -0.2311, -0.4018,  0.2310,  0.2103,\n          0.1036,  0.0274, -0.0049,  0.3974, -0.2764,  0.2654, -0.3376,  0.3840],\n        [ 0.1278, -0.1702,  0.2486,  0.0396,  0.3804,  0.4712,  0.1482,  0.4366,\n         -0.0699, -0.2783, -0.0545,  0.3239,  0.1755,  0.2406, -0.4856, -0.4335],\n        [-0.2140, -0.4611, -0.2129,  0.2422, -0.0543,  0.4696, -0.1157, -0.3708,\n          0.2756, -0.1046, -0.3401,  0.0490, -0.3892, -0.4082, -0.2368, -0.0878],\n        [-0.1418, -0.0475, -0.3015, -0.1580, -0.3740, -0.3419,  0.0795, -0.3884,\n          0.3072,  0.0648, -0.2380,  0.2404,  0.4870, -0.4367, -0.1475,  0.4356],\n        [ 0.2016,  0.2133,  0.2424,  0.3846,  0.2805, -0.2308,  0.0133,  0.2576,\n         -0.0468, -0.0899,  0.2802,  0.2204, -0.3114,  0.3049,  0.3696, -0.2562],\n        [-0.3382,  0.4189,  0.0536,  0.3562, -0.0157, -0.3796, -0.4624,  0.2683,\n         -0.3609,  0.4543,  0.3868,  0.0151,  0.1573,  0.0831, -0.1628,  0.3527]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3096,  0.6365, -0.6337, -0.3564,  0.1410,  0.3416, -0.1233,  0.6806],\n        [-0.4444, -0.1400, -0.2764, -0.4944, -0.0852, -0.4982,  0.1039,  0.2114],\n        [ 0.6185,  0.5853, -0.4264,  0.0960, -0.0917, -0.4011, -0.0166,  0.6642],\n        [ 0.3982, -0.0734,  0.2314,  0.0401, -0.3466,  0.4507, -0.5727,  0.6714]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x732a5942e110>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s534190000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s534190000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}