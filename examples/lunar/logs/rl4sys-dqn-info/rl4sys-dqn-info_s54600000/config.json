{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s54600000"
    },
    "q_lr":	0.0005,
    "seed":	54600000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x0000019E359CD0F0>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0454,  0.2323, -0.0846, -0.0524, -0.3339, -0.2020,  0.3461, -0.0727,\n         0.0289, -0.1886,  0.0762, -0.3238, -0.2429, -0.2695, -0.2778,  0.2575,\n         0.0974, -0.2307,  0.0549, -0.2756,  0.2765, -0.2259,  0.1523,  0.0981,\n        -0.1424, -0.1056,  0.0719,  0.2303, -0.1003,  0.0727, -0.0105,  0.2861],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1261,  0.0478,  0.1836, -0.2139,  0.1339,  0.3165, -0.0668,  0.1384],\n        [ 0.0031, -0.0923,  0.0848,  0.0945, -0.2693, -0.2647,  0.2646, -0.1700],\n        [ 0.0854,  0.2620, -0.0367,  0.3024, -0.1975, -0.0456, -0.0380,  0.0069],\n        [ 0.1147,  0.2191, -0.3017,  0.3094, -0.0782, -0.0051, -0.0491, -0.0399],\n        [ 0.1695, -0.0819,  0.1618,  0.0849, -0.1790,  0.3282, -0.3280, -0.0104],\n        [ 0.3290,  0.3343, -0.1310,  0.1180, -0.0788, -0.3102,  0.0947,  0.2910],\n        [-0.1156, -0.3268,  0.2262,  0.3324,  0.2023, -0.2587, -0.0995,  0.2087],\n        [ 0.1300,  0.0231, -0.1715, -0.2287, -0.2756,  0.1915, -0.0511,  0.1696],\n        [-0.1203, -0.3315,  0.3307, -0.2049, -0.0417,  0.1160, -0.1022,  0.2043],\n        [-0.1186,  0.3283,  0.2070,  0.3072, -0.2785, -0.1946, -0.0325, -0.0541],\n        [-0.0022,  0.0004, -0.2431,  0.0617,  0.3241, -0.2947, -0.2200, -0.0800],\n        [-0.0818, -0.2111,  0.0097,  0.1281, -0.1939,  0.1062,  0.1551, -0.3428],\n        [-0.1356, -0.0144, -0.3282,  0.1976, -0.0455, -0.2286, -0.0517,  0.1714],\n        [-0.0427,  0.2706,  0.1001, -0.3276,  0.3505,  0.1563,  0.1006,  0.0261],\n        [ 0.0275,  0.3087,  0.2103, -0.2364, -0.1440,  0.0774, -0.2260, -0.1340],\n        [-0.1545, -0.2190,  0.0849,  0.1446,  0.1567, -0.2684,  0.1770,  0.0104],\n        [ 0.0754, -0.0014, -0.3135,  0.0903,  0.3109,  0.2628, -0.0533, -0.2387],\n        [-0.1563,  0.2400, -0.0582,  0.3410, -0.1956, -0.1237, -0.2439, -0.2825],\n        [-0.3529,  0.1391,  0.1991, -0.0447,  0.0462,  0.2356, -0.2659, -0.1496],\n        [ 0.0736,  0.0859, -0.2460,  0.0989, -0.2134,  0.2537, -0.0413,  0.0437],\n        [ 0.1141,  0.2401, -0.0148, -0.0760, -0.2608, -0.2684,  0.0905,  0.1851],\n        [ 0.0647,  0.2587, -0.1276, -0.1713,  0.1146, -0.0723,  0.2993,  0.2634],\n        [ 0.0869, -0.0282, -0.2498, -0.2969,  0.1825,  0.3094, -0.0194,  0.2460],\n        [ 0.3106,  0.2239, -0.2218, -0.1690,  0.2027, -0.0183,  0.1594, -0.0568],\n        [-0.1123,  0.3495,  0.2665,  0.0761, -0.0411, -0.0503, -0.0252,  0.1071],\n        [-0.2576, -0.2666, -0.0052,  0.2621, -0.2270, -0.0090, -0.0817,  0.2151],\n        [ 0.1287,  0.1774, -0.0516,  0.2375, -0.2540, -0.0391,  0.1076,  0.3239],\n        [-0.1657, -0.0445, -0.2935,  0.3047,  0.0783,  0.1303, -0.2653, -0.1084],\n        [ 0.1057, -0.1674,  0.3134,  0.0559,  0.0067, -0.1485, -0.1445, -0.3289],\n        [ 0.1508,  0.1230, -0.3270,  0.2351,  0.2173,  0.0719,  0.3096,  0.0230],\n        [ 0.0406,  0.2827, -0.3121, -0.1152,  0.2856, -0.1011,  0.1744, -0.0440],\n        [ 0.1164, -0.2881,  0.3183,  0.1634,  0.3059,  0.0301,  0.2998,  0.1891]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0659, -0.1162, -0.1686, -0.1216, -0.0630,  0.0206, -0.0380,  0.1090,\n        -0.1450, -0.0395,  0.0418,  0.1737,  0.0958,  0.0172, -0.1371, -0.1341],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 5.5955e-02, -4.8838e-02,  2.5411e-02, -1.1192e-01, -1.7552e-02,\n         -7.7809e-03, -1.7395e-01,  6.8456e-02, -2.5589e-02,  1.5921e-01,\n         -1.1459e-01, -5.3858e-03,  3.4237e-02, -3.3240e-02,  3.9394e-04,\n          9.7888e-02,  6.4960e-02, -6.8646e-02,  6.1315e-02,  5.1652e-02,\n          8.2759e-02, -3.2060e-02, -1.6009e-01, -1.0942e-01,  2.3385e-02,\n          9.5451e-02,  1.6659e-01,  1.2129e-01, -1.7520e-01,  5.1353e-02,\n          1.6520e-01, -1.4568e-01],\n        [ 5.6865e-02, -1.3060e-01,  1.1521e-01,  8.5403e-02,  9.0182e-02,\n          1.4703e-01, -1.0336e-01, -1.2384e-01,  1.4351e-01,  1.0421e-01,\n         -1.0105e-01, -1.0734e-01, -2.9535e-02, -1.0587e-01,  1.5337e-01,\n          2.5785e-02,  6.0585e-02, -7.7273e-02, -6.7815e-02,  5.4909e-02,\n         -1.9587e-02,  5.5668e-02,  3.1870e-02,  1.6409e-01,  5.2986e-02,\n         -3.3081e-02, -1.7025e-01,  6.2473e-02, -9.8708e-02,  1.1209e-01,\n         -8.2913e-02,  1.2006e-04],\n        [-6.9933e-02,  1.3995e-01,  1.3838e-01,  1.9442e-02,  1.5361e-01,\n          6.2984e-02,  1.4920e-01,  1.1579e-01, -7.3731e-02,  1.2325e-01,\n         -8.8597e-02,  1.2553e-01, -1.5593e-01,  7.0919e-02, -1.6762e-01,\n         -1.0360e-01, -7.8800e-04, -4.6478e-02, -1.7105e-01, -3.7987e-02,\n         -1.6856e-02,  5.3227e-03, -1.2815e-01,  2.5896e-02, -3.9262e-02,\n         -8.0698e-02, -1.6775e-01,  3.6155e-02, -8.7827e-02,  1.0120e-02,\n         -5.7842e-02,  1.3995e-01],\n        [-1.7481e-01,  1.1158e-01, -1.2553e-01,  1.3562e-01, -7.1850e-02,\n         -1.7139e-01, -6.9941e-02, -1.5991e-01, -1.0691e-01,  8.7952e-03,\n         -1.4832e-01, -1.6349e-01,  1.1897e-01, -1.7017e-01,  1.1540e-01,\n          1.6194e-01,  5.9151e-02,  1.1153e-01,  6.0410e-02,  1.4603e-01,\n         -1.1389e-01, -7.4656e-02,  1.2119e-02, -3.5383e-02, -7.3584e-03,\n          1.4643e-01, -1.1930e-01,  3.7643e-02, -7.3736e-02,  6.1099e-02,\n         -1.5303e-01,  2.7620e-02],\n        [ 1.6027e-01, -1.7181e-01, -1.0132e-01, -1.5851e-01,  1.4691e-01,\n          1.0994e-01, -7.1526e-02,  8.8035e-02,  1.3541e-01, -1.2870e-01,\n         -1.2157e-01,  1.3909e-01, -1.0851e-01, -6.5507e-02,  1.3581e-01,\n          3.4516e-02, -2.8776e-02, -1.2881e-01,  1.3606e-01, -1.3824e-01,\n         -1.0302e-01,  9.7377e-02, -3.8872e-02, -1.5031e-01,  1.7132e-01,\n         -3.6988e-02, -2.2414e-03, -1.3894e-01, -5.9189e-02,  5.8700e-02,\n         -6.1053e-02, -1.7570e-01],\n        [ 1.5902e-01, -9.5997e-02,  1.6670e-01,  3.4642e-03, -1.3564e-01,\n         -1.5599e-01, -1.1883e-02, -1.2556e-01,  8.9373e-02,  1.7040e-01,\n          2.0807e-02,  2.1029e-03,  6.6825e-02, -1.6336e-01, -6.3216e-02,\n         -1.5090e-01,  9.4552e-02,  6.4650e-02,  1.6817e-01, -7.7851e-02,\n         -1.3877e-01, -1.2503e-01,  3.3770e-02, -1.5834e-01,  1.4461e-01,\n          1.5154e-01,  3.8033e-02,  6.2576e-02, -1.6521e-01, -4.7569e-03,\n          7.1742e-02,  1.5300e-01],\n        [-1.5403e-01, -1.0079e-02, -2.4486e-02,  6.2374e-02,  1.3629e-01,\n         -3.9054e-02, -7.4888e-02, -6.2260e-02,  1.5374e-01, -8.1647e-02,\n         -1.4596e-01, -1.5679e-01,  1.4682e-01,  1.0741e-01,  1.4078e-02,\n          1.1638e-01,  7.1484e-02,  2.2875e-02,  1.2376e-01,  1.3719e-01,\n          1.2717e-01,  2.8949e-02, -1.4359e-02,  1.1654e-01,  9.0370e-02,\n         -1.3469e-01, -3.4815e-02, -1.6642e-01,  7.5236e-02,  1.3365e-01,\n          8.9055e-02, -1.0098e-01],\n        [ 1.6724e-01, -1.6944e-01,  1.7006e-01,  1.6351e-01,  1.3301e-01,\n          1.3547e-02, -6.8134e-02,  8.8992e-02,  8.6967e-02,  8.1338e-02,\n          4.5028e-02,  1.3898e-01,  1.1268e-01,  9.8419e-02,  1.2318e-01,\n         -4.8587e-02,  8.0119e-04,  1.2544e-01, -2.5722e-02, -7.4380e-02,\n          7.2714e-02,  6.1571e-02,  1.2843e-01,  5.3113e-02, -3.3029e-02,\n          1.5535e-01, -1.3871e-01,  4.6776e-02, -9.8329e-02,  1.4533e-01,\n         -3.8992e-03, -1.3114e-01],\n        [ 1.7552e-01,  2.7132e-02,  1.5797e-01, -1.5587e-01,  2.1835e-02,\n         -7.3654e-02, -1.3903e-01, -9.6219e-02, -4.0958e-02,  1.6794e-01,\n          1.5913e-01,  1.6411e-01, -1.6718e-01, -7.0531e-02,  1.1605e-01,\n          1.3291e-01, -5.7208e-02, -1.1341e-01, -7.6281e-02, -1.4359e-01,\n         -9.5078e-02,  2.1543e-02,  1.3016e-01, -3.9694e-02,  1.1687e-01,\n         -1.4471e-03, -3.2580e-02,  2.1924e-03,  1.3604e-01,  3.2440e-02,\n         -1.2958e-01, -1.7636e-01],\n        [ 1.1800e-01,  7.4597e-02, -1.2374e-01,  1.7367e-01, -6.9714e-02,\n         -2.2142e-02,  9.3051e-03,  6.5976e-02, -3.2351e-02,  1.4426e-01,\n          8.0634e-02, -4.0109e-02, -5.3542e-02,  1.4233e-01,  7.7195e-02,\n         -7.3768e-02, -7.4136e-02, -1.0788e-01,  4.2494e-03,  1.3448e-02,\n          5.6858e-02,  1.6676e-01,  4.3108e-02,  5.7400e-02,  2.6986e-02,\n          7.7306e-02, -1.1312e-01,  9.3332e-02, -1.1558e-02, -9.9499e-02,\n          3.3762e-02, -4.5968e-02],\n        [-6.4207e-02,  9.0553e-02,  1.2049e-02, -2.7528e-02, -1.0143e-02,\n         -4.6092e-02, -1.4210e-01, -1.4155e-01,  1.1939e-02,  7.0000e-02,\n         -2.8960e-02,  1.2126e-01, -1.0853e-01, -1.3750e-01,  6.0550e-02,\n          5.9103e-02,  1.3580e-01, -3.4603e-03,  2.1723e-02, -3.3220e-02,\n          6.1516e-03, -3.9949e-02,  1.6461e-01,  1.5314e-01,  1.4780e-01,\n          2.4461e-02, -1.4494e-01,  4.6058e-04, -1.5485e-01,  1.5836e-01,\n         -1.7683e-02,  8.9782e-02],\n        [ 1.2707e-01, -9.1949e-02, -6.6675e-03, -2.0874e-02,  8.1426e-02,\n          4.6398e-02,  2.5390e-02,  1.6556e-01,  1.1728e-01, -6.1375e-02,\n          8.3046e-02,  9.2385e-02, -4.0931e-02,  7.7701e-02,  1.0845e-01,\n          5.0828e-02, -4.1290e-02,  8.0308e-02, -3.4489e-02, -7.7563e-02,\n         -4.4116e-02, -6.4925e-02,  7.1080e-02, -1.2801e-01,  1.4582e-01,\n          1.6368e-01,  8.6457e-03,  1.2241e-03, -5.1827e-02, -6.8079e-02,\n          7.1264e-03,  1.0648e-03],\n        [ 5.7774e-02, -1.3944e-01,  1.2467e-01, -7.1187e-02,  6.0132e-02,\n         -7.3157e-02,  9.0994e-03,  2.0724e-02, -1.3336e-01,  9.8492e-02,\n          7.2287e-02,  9.7754e-02, -9.6947e-02, -1.7084e-01, -8.6000e-02,\n         -1.3341e-01, -6.3424e-02, -1.1061e-01, -9.7968e-02,  1.7471e-01,\n          4.2287e-02,  1.2371e-01, -1.1937e-01,  3.0290e-02,  1.0657e-01,\n         -1.1412e-02, -3.5179e-02, -1.4829e-01, -8.6011e-02, -4.7457e-02,\n         -9.1256e-02, -3.3118e-03],\n        [ 1.0873e-01, -1.3850e-01,  1.5810e-01,  4.9422e-02, -5.3713e-02,\n          1.8721e-02,  3.1090e-02,  5.7975e-02,  1.3035e-01, -3.2593e-02,\n         -9.2887e-02,  1.4880e-01, -4.0236e-02,  1.0415e-01, -1.1267e-02,\n         -1.0042e-01, -7.7123e-02, -1.4680e-01, -1.5633e-01, -1.4564e-01,\n          3.8607e-02,  7.2097e-02, -5.2479e-03, -1.7054e-01,  1.6299e-01,\n         -8.6432e-02,  1.5959e-01, -6.6679e-02, -7.3157e-02,  4.5307e-02,\n         -1.6385e-01,  2.8670e-02],\n        [ 9.4898e-02,  1.2579e-01,  1.6224e-01, -4.2509e-02, -1.1014e-01,\n          1.5916e-01, -9.6941e-02,  7.0014e-02,  4.2010e-02,  1.1922e-01,\n          3.4991e-02,  6.9439e-02, -1.2986e-01, -3.0648e-03, -1.0481e-01,\n         -1.0953e-01,  1.4980e-01,  2.6329e-02,  1.5840e-01, -1.3748e-01,\n          8.9018e-02,  5.1936e-02,  1.3921e-01, -5.9531e-02, -1.9668e-02,\n         -5.9335e-02,  1.6416e-01, -1.7102e-01, -3.9499e-03,  7.4330e-02,\n          1.6815e-01, -1.4114e-01],\n        [-1.1788e-01, -7.1823e-02, -1.4200e-01,  8.6229e-02,  2.7752e-02,\n         -7.2458e-02, -6.3289e-03, -8.2341e-02,  9.3432e-02,  1.4032e-01,\n         -6.6272e-02,  8.7828e-03, -6.4902e-02, -1.6823e-01, -2.5940e-02,\n         -1.3042e-01, -1.1403e-01, -1.5093e-01,  1.1521e-01,  1.7273e-01,\n         -1.3130e-01,  9.9065e-02, -6.1449e-02,  1.8923e-02,  1.6086e-01,\n         -2.8746e-02,  4.5754e-02, -5.2495e-02, -9.7220e-02, -4.4627e-03,\n          1.7078e-01,  4.8600e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0165, -0.1180,  0.2309, -0.0075,  0.1874, -0.1559,  0.0708,  0.0499],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1786,  0.1581, -0.0675,  0.2409,  0.1524, -0.1481,  0.1350,  0.0713,\n         -0.1597, -0.1542, -0.0278, -0.0514, -0.1206, -0.1549,  0.0908,  0.1394],\n        [ 0.1211,  0.0583,  0.1867,  0.0985, -0.1956,  0.0290,  0.2317, -0.1166,\n          0.2037, -0.2411,  0.2404,  0.2320, -0.0089, -0.2242,  0.0417,  0.0451],\n        [ 0.0757, -0.1375, -0.1732,  0.1973,  0.2028, -0.0035, -0.0165,  0.1826,\n         -0.0728,  0.0038,  0.2170,  0.1908,  0.2407, -0.2423, -0.2231,  0.0992],\n        [-0.0790, -0.0526,  0.1745,  0.0290,  0.1701, -0.2236, -0.2271,  0.0982,\n         -0.0790, -0.1481, -0.0588, -0.2121, -0.2494,  0.1574,  0.2286,  0.2432],\n        [ 0.1530, -0.1173,  0.0925,  0.0339,  0.1093,  0.0534,  0.0976,  0.0067,\n         -0.1532, -0.1494, -0.2189,  0.2432,  0.0388,  0.0539,  0.1555,  0.1775],\n        [-0.2136,  0.2462, -0.1613,  0.1220,  0.1785,  0.0996,  0.1961, -0.1609,\n          0.1807, -0.0469,  0.0648,  0.1753,  0.0996,  0.1052,  0.0237,  0.0897],\n        [-0.0278, -0.0202, -0.0375,  0.2412,  0.0118, -0.1476,  0.0193,  0.0932,\n         -0.1225, -0.1070, -0.1379,  0.0301, -0.0542,  0.1566, -0.2299,  0.1537],\n        [ 0.0523,  0.2402, -0.0891, -0.1274,  0.2464,  0.1024, -0.0216, -0.1846,\n          0.0577, -0.2221, -0.2179,  0.0445,  0.0942,  0.1216,  0.1588,  0.0433]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1705], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1910, -0.0856,  0.0155, -0.1783,  0.1436, -0.3443,  0.0729, -0.0539]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1261,  0.0478,  0.1836, -0.2139,  0.1339,  0.3165, -0.0668,  0.1384],\n        [ 0.0031, -0.0923,  0.0848,  0.0945, -0.2693, -0.2647,  0.2646, -0.1700],\n        [ 0.0854,  0.2620, -0.0367,  0.3024, -0.1975, -0.0456, -0.0380,  0.0069],\n        [ 0.1147,  0.2191, -0.3017,  0.3094, -0.0782, -0.0051, -0.0491, -0.0399],\n        [ 0.1695, -0.0819,  0.1618,  0.0849, -0.1790,  0.3282, -0.3280, -0.0104],\n        [ 0.3290,  0.3343, -0.1310,  0.1180, -0.0788, -0.3102,  0.0947,  0.2910],\n        [-0.1156, -0.3268,  0.2262,  0.3324,  0.2023, -0.2587, -0.0995,  0.2087],\n        [ 0.1300,  0.0231, -0.1715, -0.2287, -0.2756,  0.1915, -0.0511,  0.1696],\n        [-0.1203, -0.3315,  0.3307, -0.2049, -0.0417,  0.1160, -0.1022,  0.2043],\n        [-0.1186,  0.3283,  0.2070,  0.3072, -0.2785, -0.1946, -0.0325, -0.0541],\n        [-0.0022,  0.0004, -0.2431,  0.0617,  0.3241, -0.2947, -0.2200, -0.0800],\n        [-0.0818, -0.2111,  0.0097,  0.1281, -0.1939,  0.1062,  0.1551, -0.3428],\n        [-0.1356, -0.0144, -0.3282,  0.1976, -0.0455, -0.2286, -0.0517,  0.1714],\n        [-0.0427,  0.2706,  0.1001, -0.3276,  0.3505,  0.1563,  0.1006,  0.0261],\n        [ 0.0275,  0.3087,  0.2103, -0.2364, -0.1440,  0.0774, -0.2260, -0.1340],\n        [-0.1545, -0.2190,  0.0849,  0.1446,  0.1567, -0.2684,  0.1770,  0.0104],\n        [ 0.0754, -0.0014, -0.3135,  0.0903,  0.3109,  0.2628, -0.0533, -0.2387],\n        [-0.1563,  0.2400, -0.0582,  0.3410, -0.1956, -0.1237, -0.2439, -0.2825],\n        [-0.3529,  0.1391,  0.1991, -0.0447,  0.0462,  0.2356, -0.2659, -0.1496],\n        [ 0.0736,  0.0859, -0.2460,  0.0989, -0.2134,  0.2537, -0.0413,  0.0437],\n        [ 0.1141,  0.2401, -0.0148, -0.0760, -0.2608, -0.2684,  0.0905,  0.1851],\n        [ 0.0647,  0.2587, -0.1276, -0.1713,  0.1146, -0.0723,  0.2993,  0.2634],\n        [ 0.0869, -0.0282, -0.2498, -0.2969,  0.1825,  0.3094, -0.0194,  0.2460],\n        [ 0.3106,  0.2239, -0.2218, -0.1690,  0.2027, -0.0183,  0.1594, -0.0568],\n        [-0.1123,  0.3495,  0.2665,  0.0761, -0.0411, -0.0503, -0.0252,  0.1071],\n        [-0.2576, -0.2666, -0.0052,  0.2621, -0.2270, -0.0090, -0.0817,  0.2151],\n        [ 0.1287,  0.1774, -0.0516,  0.2375, -0.2540, -0.0391,  0.1076,  0.3239],\n        [-0.1657, -0.0445, -0.2935,  0.3047,  0.0783,  0.1303, -0.2653, -0.1084],\n        [ 0.1057, -0.1674,  0.3134,  0.0559,  0.0067, -0.1485, -0.1445, -0.3289],\n        [ 0.1508,  0.1230, -0.3270,  0.2351,  0.2173,  0.0719,  0.3096,  0.0230],\n        [ 0.0406,  0.2827, -0.3121, -0.1152,  0.2856, -0.1011,  0.1744, -0.0440],\n        [ 0.1164, -0.2881,  0.3183,  0.1634,  0.3059,  0.0301,  0.2998,  0.1891]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0454,  0.2323, -0.0846, -0.0524, -0.3339, -0.2020,  0.3461, -0.0727,\n         0.0289, -0.1886,  0.0762, -0.3238, -0.2429, -0.2695, -0.2778,  0.2575,\n         0.0974, -0.2307,  0.0549, -0.2756,  0.2765, -0.2259,  0.1523,  0.0981,\n        -0.1424, -0.1056,  0.0719,  0.2303, -0.1003,  0.0727, -0.0105,  0.2861],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 5.5955e-02, -4.8838e-02,  2.5411e-02, -1.1192e-01, -1.7552e-02,\n         -7.7809e-03, -1.7395e-01,  6.8456e-02, -2.5589e-02,  1.5921e-01,\n         -1.1459e-01, -5.3858e-03,  3.4237e-02, -3.3240e-02,  3.9394e-04,\n          9.7888e-02,  6.4960e-02, -6.8646e-02,  6.1315e-02,  5.1652e-02,\n          8.2759e-02, -3.2060e-02, -1.6009e-01, -1.0942e-01,  2.3385e-02,\n          9.5451e-02,  1.6659e-01,  1.2129e-01, -1.7520e-01,  5.1353e-02,\n          1.6520e-01, -1.4568e-01],\n        [ 5.6865e-02, -1.3060e-01,  1.1521e-01,  8.5403e-02,  9.0182e-02,\n          1.4703e-01, -1.0336e-01, -1.2384e-01,  1.4351e-01,  1.0421e-01,\n         -1.0105e-01, -1.0734e-01, -2.9535e-02, -1.0587e-01,  1.5337e-01,\n          2.5785e-02,  6.0585e-02, -7.7273e-02, -6.7815e-02,  5.4909e-02,\n         -1.9587e-02,  5.5668e-02,  3.1870e-02,  1.6409e-01,  5.2986e-02,\n         -3.3081e-02, -1.7025e-01,  6.2473e-02, -9.8708e-02,  1.1209e-01,\n         -8.2913e-02,  1.2006e-04],\n        [-6.9933e-02,  1.3995e-01,  1.3838e-01,  1.9442e-02,  1.5361e-01,\n          6.2984e-02,  1.4920e-01,  1.1579e-01, -7.3731e-02,  1.2325e-01,\n         -8.8597e-02,  1.2553e-01, -1.5593e-01,  7.0919e-02, -1.6762e-01,\n         -1.0360e-01, -7.8800e-04, -4.6478e-02, -1.7105e-01, -3.7987e-02,\n         -1.6856e-02,  5.3227e-03, -1.2815e-01,  2.5896e-02, -3.9262e-02,\n         -8.0698e-02, -1.6775e-01,  3.6155e-02, -8.7827e-02,  1.0120e-02,\n         -5.7842e-02,  1.3995e-01],\n        [-1.7481e-01,  1.1158e-01, -1.2553e-01,  1.3562e-01, -7.1850e-02,\n         -1.7139e-01, -6.9941e-02, -1.5991e-01, -1.0691e-01,  8.7952e-03,\n         -1.4832e-01, -1.6349e-01,  1.1897e-01, -1.7017e-01,  1.1540e-01,\n          1.6194e-01,  5.9151e-02,  1.1153e-01,  6.0410e-02,  1.4603e-01,\n         -1.1389e-01, -7.4656e-02,  1.2119e-02, -3.5383e-02, -7.3584e-03,\n          1.4643e-01, -1.1930e-01,  3.7643e-02, -7.3736e-02,  6.1099e-02,\n         -1.5303e-01,  2.7620e-02],\n        [ 1.6027e-01, -1.7181e-01, -1.0132e-01, -1.5851e-01,  1.4691e-01,\n          1.0994e-01, -7.1526e-02,  8.8035e-02,  1.3541e-01, -1.2870e-01,\n         -1.2157e-01,  1.3909e-01, -1.0851e-01, -6.5507e-02,  1.3581e-01,\n          3.4516e-02, -2.8776e-02, -1.2881e-01,  1.3606e-01, -1.3824e-01,\n         -1.0302e-01,  9.7377e-02, -3.8872e-02, -1.5031e-01,  1.7132e-01,\n         -3.6988e-02, -2.2414e-03, -1.3894e-01, -5.9189e-02,  5.8700e-02,\n         -6.1053e-02, -1.7570e-01],\n        [ 1.5902e-01, -9.5997e-02,  1.6670e-01,  3.4642e-03, -1.3564e-01,\n         -1.5599e-01, -1.1883e-02, -1.2556e-01,  8.9373e-02,  1.7040e-01,\n          2.0807e-02,  2.1029e-03,  6.6825e-02, -1.6336e-01, -6.3216e-02,\n         -1.5090e-01,  9.4552e-02,  6.4650e-02,  1.6817e-01, -7.7851e-02,\n         -1.3877e-01, -1.2503e-01,  3.3770e-02, -1.5834e-01,  1.4461e-01,\n          1.5154e-01,  3.8033e-02,  6.2576e-02, -1.6521e-01, -4.7569e-03,\n          7.1742e-02,  1.5300e-01],\n        [-1.5403e-01, -1.0079e-02, -2.4486e-02,  6.2374e-02,  1.3629e-01,\n         -3.9054e-02, -7.4888e-02, -6.2260e-02,  1.5374e-01, -8.1647e-02,\n         -1.4596e-01, -1.5679e-01,  1.4682e-01,  1.0741e-01,  1.4078e-02,\n          1.1638e-01,  7.1484e-02,  2.2875e-02,  1.2376e-01,  1.3719e-01,\n          1.2717e-01,  2.8949e-02, -1.4359e-02,  1.1654e-01,  9.0370e-02,\n         -1.3469e-01, -3.4815e-02, -1.6642e-01,  7.5236e-02,  1.3365e-01,\n          8.9055e-02, -1.0098e-01],\n        [ 1.6724e-01, -1.6944e-01,  1.7006e-01,  1.6351e-01,  1.3301e-01,\n          1.3547e-02, -6.8134e-02,  8.8992e-02,  8.6967e-02,  8.1338e-02,\n          4.5028e-02,  1.3898e-01,  1.1268e-01,  9.8419e-02,  1.2318e-01,\n         -4.8587e-02,  8.0119e-04,  1.2544e-01, -2.5722e-02, -7.4380e-02,\n          7.2714e-02,  6.1571e-02,  1.2843e-01,  5.3113e-02, -3.3029e-02,\n          1.5535e-01, -1.3871e-01,  4.6776e-02, -9.8329e-02,  1.4533e-01,\n         -3.8992e-03, -1.3114e-01],\n        [ 1.7552e-01,  2.7132e-02,  1.5797e-01, -1.5587e-01,  2.1835e-02,\n         -7.3654e-02, -1.3903e-01, -9.6219e-02, -4.0958e-02,  1.6794e-01,\n          1.5913e-01,  1.6411e-01, -1.6718e-01, -7.0531e-02,  1.1605e-01,\n          1.3291e-01, -5.7208e-02, -1.1341e-01, -7.6281e-02, -1.4359e-01,\n         -9.5078e-02,  2.1543e-02,  1.3016e-01, -3.9694e-02,  1.1687e-01,\n         -1.4471e-03, -3.2580e-02,  2.1924e-03,  1.3604e-01,  3.2440e-02,\n         -1.2958e-01, -1.7636e-01],\n        [ 1.1800e-01,  7.4597e-02, -1.2374e-01,  1.7367e-01, -6.9714e-02,\n         -2.2142e-02,  9.3051e-03,  6.5976e-02, -3.2351e-02,  1.4426e-01,\n          8.0634e-02, -4.0109e-02, -5.3542e-02,  1.4233e-01,  7.7195e-02,\n         -7.3768e-02, -7.4136e-02, -1.0788e-01,  4.2494e-03,  1.3448e-02,\n          5.6858e-02,  1.6676e-01,  4.3108e-02,  5.7400e-02,  2.6986e-02,\n          7.7306e-02, -1.1312e-01,  9.3332e-02, -1.1558e-02, -9.9499e-02,\n          3.3762e-02, -4.5968e-02],\n        [-6.4207e-02,  9.0553e-02,  1.2049e-02, -2.7528e-02, -1.0143e-02,\n         -4.6092e-02, -1.4210e-01, -1.4155e-01,  1.1939e-02,  7.0000e-02,\n         -2.8960e-02,  1.2126e-01, -1.0853e-01, -1.3750e-01,  6.0550e-02,\n          5.9103e-02,  1.3580e-01, -3.4603e-03,  2.1723e-02, -3.3220e-02,\n          6.1516e-03, -3.9949e-02,  1.6461e-01,  1.5314e-01,  1.4780e-01,\n          2.4461e-02, -1.4494e-01,  4.6058e-04, -1.5485e-01,  1.5836e-01,\n         -1.7683e-02,  8.9782e-02],\n        [ 1.2707e-01, -9.1949e-02, -6.6675e-03, -2.0874e-02,  8.1426e-02,\n          4.6398e-02,  2.5390e-02,  1.6556e-01,  1.1728e-01, -6.1375e-02,\n          8.3046e-02,  9.2385e-02, -4.0931e-02,  7.7701e-02,  1.0845e-01,\n          5.0828e-02, -4.1290e-02,  8.0308e-02, -3.4489e-02, -7.7563e-02,\n         -4.4116e-02, -6.4925e-02,  7.1080e-02, -1.2801e-01,  1.4582e-01,\n          1.6368e-01,  8.6457e-03,  1.2241e-03, -5.1827e-02, -6.8079e-02,\n          7.1264e-03,  1.0648e-03],\n        [ 5.7774e-02, -1.3944e-01,  1.2467e-01, -7.1187e-02,  6.0132e-02,\n         -7.3157e-02,  9.0994e-03,  2.0724e-02, -1.3336e-01,  9.8492e-02,\n          7.2287e-02,  9.7754e-02, -9.6947e-02, -1.7084e-01, -8.6000e-02,\n         -1.3341e-01, -6.3424e-02, -1.1061e-01, -9.7968e-02,  1.7471e-01,\n          4.2287e-02,  1.2371e-01, -1.1937e-01,  3.0290e-02,  1.0657e-01,\n         -1.1412e-02, -3.5179e-02, -1.4829e-01, -8.6011e-02, -4.7457e-02,\n         -9.1256e-02, -3.3118e-03],\n        [ 1.0873e-01, -1.3850e-01,  1.5810e-01,  4.9422e-02, -5.3713e-02,\n          1.8721e-02,  3.1090e-02,  5.7975e-02,  1.3035e-01, -3.2593e-02,\n         -9.2887e-02,  1.4880e-01, -4.0236e-02,  1.0415e-01, -1.1267e-02,\n         -1.0042e-01, -7.7123e-02, -1.4680e-01, -1.5633e-01, -1.4564e-01,\n          3.8607e-02,  7.2097e-02, -5.2479e-03, -1.7054e-01,  1.6299e-01,\n         -8.6432e-02,  1.5959e-01, -6.6679e-02, -7.3157e-02,  4.5307e-02,\n         -1.6385e-01,  2.8670e-02],\n        [ 9.4898e-02,  1.2579e-01,  1.6224e-01, -4.2509e-02, -1.1014e-01,\n          1.5916e-01, -9.6941e-02,  7.0014e-02,  4.2010e-02,  1.1922e-01,\n          3.4991e-02,  6.9439e-02, -1.2986e-01, -3.0648e-03, -1.0481e-01,\n         -1.0953e-01,  1.4980e-01,  2.6329e-02,  1.5840e-01, -1.3748e-01,\n          8.9018e-02,  5.1936e-02,  1.3921e-01, -5.9531e-02, -1.9668e-02,\n         -5.9335e-02,  1.6416e-01, -1.7102e-01, -3.9499e-03,  7.4330e-02,\n          1.6815e-01, -1.4114e-01],\n        [-1.1788e-01, -7.1823e-02, -1.4200e-01,  8.6229e-02,  2.7752e-02,\n         -7.2458e-02, -6.3289e-03, -8.2341e-02,  9.3432e-02,  1.4032e-01,\n         -6.6272e-02,  8.7828e-03, -6.4902e-02, -1.6823e-01, -2.5940e-02,\n         -1.3042e-01, -1.1403e-01, -1.5093e-01,  1.1521e-01,  1.7273e-01,\n         -1.3130e-01,  9.9065e-02, -6.1449e-02,  1.8923e-02,  1.6086e-01,\n         -2.8746e-02,  4.5754e-02, -5.2495e-02, -9.7220e-02, -4.4627e-03,\n          1.7078e-01,  4.8600e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0659, -0.1162, -0.1686, -0.1216, -0.0630,  0.0206, -0.0380,  0.1090,\n        -0.1450, -0.0395,  0.0418,  0.1737,  0.0958,  0.0172, -0.1371, -0.1341],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1786,  0.1581, -0.0675,  0.2409,  0.1524, -0.1481,  0.1350,  0.0713,\n         -0.1597, -0.1542, -0.0278, -0.0514, -0.1206, -0.1549,  0.0908,  0.1394],\n        [ 0.1211,  0.0583,  0.1867,  0.0985, -0.1956,  0.0290,  0.2317, -0.1166,\n          0.2037, -0.2411,  0.2404,  0.2320, -0.0089, -0.2242,  0.0417,  0.0451],\n        [ 0.0757, -0.1375, -0.1732,  0.1973,  0.2028, -0.0035, -0.0165,  0.1826,\n         -0.0728,  0.0038,  0.2170,  0.1908,  0.2407, -0.2423, -0.2231,  0.0992],\n        [-0.0790, -0.0526,  0.1745,  0.0290,  0.1701, -0.2236, -0.2271,  0.0982,\n         -0.0790, -0.1481, -0.0588, -0.2121, -0.2494,  0.1574,  0.2286,  0.2432],\n        [ 0.1530, -0.1173,  0.0925,  0.0339,  0.1093,  0.0534,  0.0976,  0.0067,\n         -0.1532, -0.1494, -0.2189,  0.2432,  0.0388,  0.0539,  0.1555,  0.1775],\n        [-0.2136,  0.2462, -0.1613,  0.1220,  0.1785,  0.0996,  0.1961, -0.1609,\n          0.1807, -0.0469,  0.0648,  0.1753,  0.0996,  0.1052,  0.0237,  0.0897],\n        [-0.0278, -0.0202, -0.0375,  0.2412,  0.0118, -0.1476,  0.0193,  0.0932,\n         -0.1225, -0.1070, -0.1379,  0.0301, -0.0542,  0.1566, -0.2299,  0.1537],\n        [ 0.0523,  0.2402, -0.0891, -0.1274,  0.2464,  0.1024, -0.0216, -0.1846,\n          0.0577, -0.2221, -0.2179,  0.0445,  0.0942,  0.1216,  0.1588,  0.0433]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0165, -0.1180,  0.2309, -0.0075,  0.1874, -0.1559,  0.0708,  0.0499],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1910, -0.0856,  0.0155, -0.1783,  0.1436, -0.3443,  0.0729, -0.0539]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1705], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x0000019E6D2862F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x0000019E359CCC40>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s54600000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s54600000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0454,  0.2323, -0.0846, -0.0524, -0.3339, -0.2020,  0.3461, -0.0727,\n         0.0289, -0.1886,  0.0762, -0.3238, -0.2429, -0.2695, -0.2778,  0.2575,\n         0.0974, -0.2307,  0.0549, -0.2756,  0.2765, -0.2259,  0.1523,  0.0981,\n        -0.1424, -0.1056,  0.0719,  0.2303, -0.1003,  0.0727, -0.0105,  0.2861],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1261,  0.0478,  0.1836, -0.2139,  0.1339,  0.3165, -0.0668,  0.1384],\n        [ 0.0031, -0.0923,  0.0848,  0.0945, -0.2693, -0.2647,  0.2646, -0.1700],\n        [ 0.0854,  0.2620, -0.0367,  0.3024, -0.1975, -0.0456, -0.0380,  0.0069],\n        [ 0.1147,  0.2191, -0.3017,  0.3094, -0.0782, -0.0051, -0.0491, -0.0399],\n        [ 0.1695, -0.0819,  0.1618,  0.0849, -0.1790,  0.3282, -0.3280, -0.0104],\n        [ 0.3290,  0.3343, -0.1310,  0.1180, -0.0788, -0.3102,  0.0947,  0.2910],\n        [-0.1156, -0.3268,  0.2262,  0.3324,  0.2023, -0.2587, -0.0995,  0.2087],\n        [ 0.1300,  0.0231, -0.1715, -0.2287, -0.2756,  0.1915, -0.0511,  0.1696],\n        [-0.1203, -0.3315,  0.3307, -0.2049, -0.0417,  0.1160, -0.1022,  0.2043],\n        [-0.1186,  0.3283,  0.2070,  0.3072, -0.2785, -0.1946, -0.0325, -0.0541],\n        [-0.0022,  0.0004, -0.2431,  0.0617,  0.3241, -0.2947, -0.2200, -0.0800],\n        [-0.0818, -0.2111,  0.0097,  0.1281, -0.1939,  0.1062,  0.1551, -0.3428],\n        [-0.1356, -0.0144, -0.3282,  0.1976, -0.0455, -0.2286, -0.0517,  0.1714],\n        [-0.0427,  0.2706,  0.1001, -0.3276,  0.3505,  0.1563,  0.1006,  0.0261],\n        [ 0.0275,  0.3087,  0.2103, -0.2364, -0.1440,  0.0774, -0.2260, -0.1340],\n        [-0.1545, -0.2190,  0.0849,  0.1446,  0.1567, -0.2684,  0.1770,  0.0104],\n        [ 0.0754, -0.0014, -0.3135,  0.0903,  0.3109,  0.2628, -0.0533, -0.2387],\n        [-0.1563,  0.2400, -0.0582,  0.3410, -0.1956, -0.1237, -0.2439, -0.2825],\n        [-0.3529,  0.1391,  0.1991, -0.0447,  0.0462,  0.2356, -0.2659, -0.1496],\n        [ 0.0736,  0.0859, -0.2460,  0.0989, -0.2134,  0.2537, -0.0413,  0.0437],\n        [ 0.1141,  0.2401, -0.0148, -0.0760, -0.2608, -0.2684,  0.0905,  0.1851],\n        [ 0.0647,  0.2587, -0.1276, -0.1713,  0.1146, -0.0723,  0.2993,  0.2634],\n        [ 0.0869, -0.0282, -0.2498, -0.2969,  0.1825,  0.3094, -0.0194,  0.2460],\n        [ 0.3106,  0.2239, -0.2218, -0.1690,  0.2027, -0.0183,  0.1594, -0.0568],\n        [-0.1123,  0.3495,  0.2665,  0.0761, -0.0411, -0.0503, -0.0252,  0.1071],\n        [-0.2576, -0.2666, -0.0052,  0.2621, -0.2270, -0.0090, -0.0817,  0.2151],\n        [ 0.1287,  0.1774, -0.0516,  0.2375, -0.2540, -0.0391,  0.1076,  0.3239],\n        [-0.1657, -0.0445, -0.2935,  0.3047,  0.0783,  0.1303, -0.2653, -0.1084],\n        [ 0.1057, -0.1674,  0.3134,  0.0559,  0.0067, -0.1485, -0.1445, -0.3289],\n        [ 0.1508,  0.1230, -0.3270,  0.2351,  0.2173,  0.0719,  0.3096,  0.0230],\n        [ 0.0406,  0.2827, -0.3121, -0.1152,  0.2856, -0.1011,  0.1744, -0.0440],\n        [ 0.1164, -0.2881,  0.3183,  0.1634,  0.3059,  0.0301,  0.2998,  0.1891]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0659, -0.1162, -0.1686, -0.1216, -0.0630,  0.0206, -0.0380,  0.1090,\n        -0.1450, -0.0395,  0.0418,  0.1737,  0.0958,  0.0172, -0.1371, -0.1341],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 5.5955e-02, -4.8838e-02,  2.5411e-02, -1.1192e-01, -1.7552e-02,\n         -7.7809e-03, -1.7395e-01,  6.8456e-02, -2.5589e-02,  1.5921e-01,\n         -1.1459e-01, -5.3858e-03,  3.4237e-02, -3.3240e-02,  3.9394e-04,\n          9.7888e-02,  6.4960e-02, -6.8646e-02,  6.1315e-02,  5.1652e-02,\n          8.2759e-02, -3.2060e-02, -1.6009e-01, -1.0942e-01,  2.3385e-02,\n          9.5451e-02,  1.6659e-01,  1.2129e-01, -1.7520e-01,  5.1353e-02,\n          1.6520e-01, -1.4568e-01],\n        [ 5.6865e-02, -1.3060e-01,  1.1521e-01,  8.5403e-02,  9.0182e-02,\n          1.4703e-01, -1.0336e-01, -1.2384e-01,  1.4351e-01,  1.0421e-01,\n         -1.0105e-01, -1.0734e-01, -2.9535e-02, -1.0587e-01,  1.5337e-01,\n          2.5785e-02,  6.0585e-02, -7.7273e-02, -6.7815e-02,  5.4909e-02,\n         -1.9587e-02,  5.5668e-02,  3.1870e-02,  1.6409e-01,  5.2986e-02,\n         -3.3081e-02, -1.7025e-01,  6.2473e-02, -9.8708e-02,  1.1209e-01,\n         -8.2913e-02,  1.2006e-04],\n        [-6.9933e-02,  1.3995e-01,  1.3838e-01,  1.9442e-02,  1.5361e-01,\n          6.2984e-02,  1.4920e-01,  1.1579e-01, -7.3731e-02,  1.2325e-01,\n         -8.8597e-02,  1.2553e-01, -1.5593e-01,  7.0919e-02, -1.6762e-01,\n         -1.0360e-01, -7.8800e-04, -4.6478e-02, -1.7105e-01, -3.7987e-02,\n         -1.6856e-02,  5.3227e-03, -1.2815e-01,  2.5896e-02, -3.9262e-02,\n         -8.0698e-02, -1.6775e-01,  3.6155e-02, -8.7827e-02,  1.0120e-02,\n         -5.7842e-02,  1.3995e-01],\n        [-1.7481e-01,  1.1158e-01, -1.2553e-01,  1.3562e-01, -7.1850e-02,\n         -1.7139e-01, -6.9941e-02, -1.5991e-01, -1.0691e-01,  8.7952e-03,\n         -1.4832e-01, -1.6349e-01,  1.1897e-01, -1.7017e-01,  1.1540e-01,\n          1.6194e-01,  5.9151e-02,  1.1153e-01,  6.0410e-02,  1.4603e-01,\n         -1.1389e-01, -7.4656e-02,  1.2119e-02, -3.5383e-02, -7.3584e-03,\n          1.4643e-01, -1.1930e-01,  3.7643e-02, -7.3736e-02,  6.1099e-02,\n         -1.5303e-01,  2.7620e-02],\n        [ 1.6027e-01, -1.7181e-01, -1.0132e-01, -1.5851e-01,  1.4691e-01,\n          1.0994e-01, -7.1526e-02,  8.8035e-02,  1.3541e-01, -1.2870e-01,\n         -1.2157e-01,  1.3909e-01, -1.0851e-01, -6.5507e-02,  1.3581e-01,\n          3.4516e-02, -2.8776e-02, -1.2881e-01,  1.3606e-01, -1.3824e-01,\n         -1.0302e-01,  9.7377e-02, -3.8872e-02, -1.5031e-01,  1.7132e-01,\n         -3.6988e-02, -2.2414e-03, -1.3894e-01, -5.9189e-02,  5.8700e-02,\n         -6.1053e-02, -1.7570e-01],\n        [ 1.5902e-01, -9.5997e-02,  1.6670e-01,  3.4642e-03, -1.3564e-01,\n         -1.5599e-01, -1.1883e-02, -1.2556e-01,  8.9373e-02,  1.7040e-01,\n          2.0807e-02,  2.1029e-03,  6.6825e-02, -1.6336e-01, -6.3216e-02,\n         -1.5090e-01,  9.4552e-02,  6.4650e-02,  1.6817e-01, -7.7851e-02,\n         -1.3877e-01, -1.2503e-01,  3.3770e-02, -1.5834e-01,  1.4461e-01,\n          1.5154e-01,  3.8033e-02,  6.2576e-02, -1.6521e-01, -4.7569e-03,\n          7.1742e-02,  1.5300e-01],\n        [-1.5403e-01, -1.0079e-02, -2.4486e-02,  6.2374e-02,  1.3629e-01,\n         -3.9054e-02, -7.4888e-02, -6.2260e-02,  1.5374e-01, -8.1647e-02,\n         -1.4596e-01, -1.5679e-01,  1.4682e-01,  1.0741e-01,  1.4078e-02,\n          1.1638e-01,  7.1484e-02,  2.2875e-02,  1.2376e-01,  1.3719e-01,\n          1.2717e-01,  2.8949e-02, -1.4359e-02,  1.1654e-01,  9.0370e-02,\n         -1.3469e-01, -3.4815e-02, -1.6642e-01,  7.5236e-02,  1.3365e-01,\n          8.9055e-02, -1.0098e-01],\n        [ 1.6724e-01, -1.6944e-01,  1.7006e-01,  1.6351e-01,  1.3301e-01,\n          1.3547e-02, -6.8134e-02,  8.8992e-02,  8.6967e-02,  8.1338e-02,\n          4.5028e-02,  1.3898e-01,  1.1268e-01,  9.8419e-02,  1.2318e-01,\n         -4.8587e-02,  8.0119e-04,  1.2544e-01, -2.5722e-02, -7.4380e-02,\n          7.2714e-02,  6.1571e-02,  1.2843e-01,  5.3113e-02, -3.3029e-02,\n          1.5535e-01, -1.3871e-01,  4.6776e-02, -9.8329e-02,  1.4533e-01,\n         -3.8992e-03, -1.3114e-01],\n        [ 1.7552e-01,  2.7132e-02,  1.5797e-01, -1.5587e-01,  2.1835e-02,\n         -7.3654e-02, -1.3903e-01, -9.6219e-02, -4.0958e-02,  1.6794e-01,\n          1.5913e-01,  1.6411e-01, -1.6718e-01, -7.0531e-02,  1.1605e-01,\n          1.3291e-01, -5.7208e-02, -1.1341e-01, -7.6281e-02, -1.4359e-01,\n         -9.5078e-02,  2.1543e-02,  1.3016e-01, -3.9694e-02,  1.1687e-01,\n         -1.4471e-03, -3.2580e-02,  2.1924e-03,  1.3604e-01,  3.2440e-02,\n         -1.2958e-01, -1.7636e-01],\n        [ 1.1800e-01,  7.4597e-02, -1.2374e-01,  1.7367e-01, -6.9714e-02,\n         -2.2142e-02,  9.3051e-03,  6.5976e-02, -3.2351e-02,  1.4426e-01,\n          8.0634e-02, -4.0109e-02, -5.3542e-02,  1.4233e-01,  7.7195e-02,\n         -7.3768e-02, -7.4136e-02, -1.0788e-01,  4.2494e-03,  1.3448e-02,\n          5.6858e-02,  1.6676e-01,  4.3108e-02,  5.7400e-02,  2.6986e-02,\n          7.7306e-02, -1.1312e-01,  9.3332e-02, -1.1558e-02, -9.9499e-02,\n          3.3762e-02, -4.5968e-02],\n        [-6.4207e-02,  9.0553e-02,  1.2049e-02, -2.7528e-02, -1.0143e-02,\n         -4.6092e-02, -1.4210e-01, -1.4155e-01,  1.1939e-02,  7.0000e-02,\n         -2.8960e-02,  1.2126e-01, -1.0853e-01, -1.3750e-01,  6.0550e-02,\n          5.9103e-02,  1.3580e-01, -3.4603e-03,  2.1723e-02, -3.3220e-02,\n          6.1516e-03, -3.9949e-02,  1.6461e-01,  1.5314e-01,  1.4780e-01,\n          2.4461e-02, -1.4494e-01,  4.6058e-04, -1.5485e-01,  1.5836e-01,\n         -1.7683e-02,  8.9782e-02],\n        [ 1.2707e-01, -9.1949e-02, -6.6675e-03, -2.0874e-02,  8.1426e-02,\n          4.6398e-02,  2.5390e-02,  1.6556e-01,  1.1728e-01, -6.1375e-02,\n          8.3046e-02,  9.2385e-02, -4.0931e-02,  7.7701e-02,  1.0845e-01,\n          5.0828e-02, -4.1290e-02,  8.0308e-02, -3.4489e-02, -7.7563e-02,\n         -4.4116e-02, -6.4925e-02,  7.1080e-02, -1.2801e-01,  1.4582e-01,\n          1.6368e-01,  8.6457e-03,  1.2241e-03, -5.1827e-02, -6.8079e-02,\n          7.1264e-03,  1.0648e-03],\n        [ 5.7774e-02, -1.3944e-01,  1.2467e-01, -7.1187e-02,  6.0132e-02,\n         -7.3157e-02,  9.0994e-03,  2.0724e-02, -1.3336e-01,  9.8492e-02,\n          7.2287e-02,  9.7754e-02, -9.6947e-02, -1.7084e-01, -8.6000e-02,\n         -1.3341e-01, -6.3424e-02, -1.1061e-01, -9.7968e-02,  1.7471e-01,\n          4.2287e-02,  1.2371e-01, -1.1937e-01,  3.0290e-02,  1.0657e-01,\n         -1.1412e-02, -3.5179e-02, -1.4829e-01, -8.6011e-02, -4.7457e-02,\n         -9.1256e-02, -3.3118e-03],\n        [ 1.0873e-01, -1.3850e-01,  1.5810e-01,  4.9422e-02, -5.3713e-02,\n          1.8721e-02,  3.1090e-02,  5.7975e-02,  1.3035e-01, -3.2593e-02,\n         -9.2887e-02,  1.4880e-01, -4.0236e-02,  1.0415e-01, -1.1267e-02,\n         -1.0042e-01, -7.7123e-02, -1.4680e-01, -1.5633e-01, -1.4564e-01,\n          3.8607e-02,  7.2097e-02, -5.2479e-03, -1.7054e-01,  1.6299e-01,\n         -8.6432e-02,  1.5959e-01, -6.6679e-02, -7.3157e-02,  4.5307e-02,\n         -1.6385e-01,  2.8670e-02],\n        [ 9.4898e-02,  1.2579e-01,  1.6224e-01, -4.2509e-02, -1.1014e-01,\n          1.5916e-01, -9.6941e-02,  7.0014e-02,  4.2010e-02,  1.1922e-01,\n          3.4991e-02,  6.9439e-02, -1.2986e-01, -3.0648e-03, -1.0481e-01,\n         -1.0953e-01,  1.4980e-01,  2.6329e-02,  1.5840e-01, -1.3748e-01,\n          8.9018e-02,  5.1936e-02,  1.3921e-01, -5.9531e-02, -1.9668e-02,\n         -5.9335e-02,  1.6416e-01, -1.7102e-01, -3.9499e-03,  7.4330e-02,\n          1.6815e-01, -1.4114e-01],\n        [-1.1788e-01, -7.1823e-02, -1.4200e-01,  8.6229e-02,  2.7752e-02,\n         -7.2458e-02, -6.3289e-03, -8.2341e-02,  9.3432e-02,  1.4032e-01,\n         -6.6272e-02,  8.7828e-03, -6.4902e-02, -1.6823e-01, -2.5940e-02,\n         -1.3042e-01, -1.1403e-01, -1.5093e-01,  1.1521e-01,  1.7273e-01,\n         -1.3130e-01,  9.9065e-02, -6.1449e-02,  1.8923e-02,  1.6086e-01,\n         -2.8746e-02,  4.5754e-02, -5.2495e-02, -9.7220e-02, -4.4627e-03,\n          1.7078e-01,  4.8600e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0165, -0.1180,  0.2309, -0.0075,  0.1874, -0.1559,  0.0708,  0.0499],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1786,  0.1581, -0.0675,  0.2409,  0.1524, -0.1481,  0.1350,  0.0713,\n         -0.1597, -0.1542, -0.0278, -0.0514, -0.1206, -0.1549,  0.0908,  0.1394],\n        [ 0.1211,  0.0583,  0.1867,  0.0985, -0.1956,  0.0290,  0.2317, -0.1166,\n          0.2037, -0.2411,  0.2404,  0.2320, -0.0089, -0.2242,  0.0417,  0.0451],\n        [ 0.0757, -0.1375, -0.1732,  0.1973,  0.2028, -0.0035, -0.0165,  0.1826,\n         -0.0728,  0.0038,  0.2170,  0.1908,  0.2407, -0.2423, -0.2231,  0.0992],\n        [-0.0790, -0.0526,  0.1745,  0.0290,  0.1701, -0.2236, -0.2271,  0.0982,\n         -0.0790, -0.1481, -0.0588, -0.2121, -0.2494,  0.1574,  0.2286,  0.2432],\n        [ 0.1530, -0.1173,  0.0925,  0.0339,  0.1093,  0.0534,  0.0976,  0.0067,\n         -0.1532, -0.1494, -0.2189,  0.2432,  0.0388,  0.0539,  0.1555,  0.1775],\n        [-0.2136,  0.2462, -0.1613,  0.1220,  0.1785,  0.0996,  0.1961, -0.1609,\n          0.1807, -0.0469,  0.0648,  0.1753,  0.0996,  0.1052,  0.0237,  0.0897],\n        [-0.0278, -0.0202, -0.0375,  0.2412,  0.0118, -0.1476,  0.0193,  0.0932,\n         -0.1225, -0.1070, -0.1379,  0.0301, -0.0542,  0.1566, -0.2299,  0.1537],\n        [ 0.0523,  0.2402, -0.0891, -0.1274,  0.2464,  0.1024, -0.0216, -0.1846,\n          0.0577, -0.2221, -0.2179,  0.0445,  0.0942,  0.1216,  0.1588,  0.0433]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1705], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1910, -0.0856,  0.0155, -0.1783,  0.1436, -0.3443,  0.0729, -0.0539]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}