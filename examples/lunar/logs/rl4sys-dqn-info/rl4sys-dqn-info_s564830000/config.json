{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s564830000"
    },
    "q_lr":	0.0005,
    "seed":	564830000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x726c6268e350>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1706,  0.2794,  0.1210,  0.1318, -0.1759, -0.0639,  0.0886, -0.2393,\n         0.2980,  0.3159,  0.0436, -0.2624,  0.1979,  0.0132, -0.2959,  0.0556,\n         0.0770,  0.1759,  0.1580, -0.0420, -0.0228,  0.3462,  0.0305,  0.2502,\n        -0.1419,  0.0592, -0.2797,  0.0568,  0.1956, -0.2109,  0.3501,  0.0439],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0764,  0.2017,  0.1628,  0.0760,  0.3230, -0.1783, -0.0004,  0.2780],\n        [-0.0939,  0.3197, -0.2518, -0.0249, -0.1606, -0.2666, -0.0255,  0.0674],\n        [ 0.0992,  0.1584, -0.1151, -0.0472, -0.0294, -0.1710,  0.0771,  0.0935],\n        [ 0.0777, -0.0964,  0.1735, -0.0943, -0.1061,  0.3330,  0.2307,  0.3068],\n        [-0.0300,  0.1826, -0.2488, -0.2611, -0.2322, -0.2661, -0.0004,  0.3312],\n        [ 0.1460, -0.2307,  0.0705,  0.1699, -0.0784, -0.2364,  0.0443,  0.2505],\n        [ 0.2054,  0.2132, -0.1427, -0.0920,  0.1192,  0.2829, -0.1204, -0.0724],\n        [ 0.2118, -0.1201,  0.1706, -0.1450, -0.1910, -0.1235, -0.2273,  0.1768],\n        [ 0.1854, -0.0461,  0.1241,  0.2351,  0.3438, -0.1898, -0.1148, -0.0631],\n        [-0.1341, -0.0100, -0.3018,  0.1886,  0.1758, -0.2094, -0.1044, -0.1000],\n        [ 0.0377,  0.0146, -0.0552,  0.3086,  0.2549,  0.3522,  0.2764, -0.2276],\n        [ 0.2739, -0.3339,  0.1480, -0.0582, -0.2347,  0.0347, -0.1787, -0.2770],\n        [ 0.2433, -0.2469, -0.1135, -0.1306, -0.0054, -0.1234, -0.0919,  0.1862],\n        [-0.0647,  0.0532,  0.1965, -0.1661,  0.1112, -0.3176, -0.1295, -0.1819],\n        [-0.3270,  0.3483, -0.1255, -0.1996, -0.0738,  0.0452,  0.0501,  0.0167],\n        [-0.2424, -0.2186,  0.0341,  0.1985, -0.2114,  0.1965, -0.3156, -0.0450],\n        [ 0.1597,  0.3320,  0.3409, -0.2622,  0.2621,  0.1335, -0.1175,  0.0797],\n        [ 0.3450, -0.3345, -0.1861, -0.2688, -0.1380, -0.0098,  0.1150,  0.2771],\n        [ 0.1004,  0.1992, -0.1363,  0.1158, -0.1920,  0.1329, -0.1330, -0.2652],\n        [ 0.0793,  0.3004,  0.1380, -0.1203, -0.0509,  0.1345, -0.1422,  0.0832],\n        [ 0.3028,  0.3212,  0.3216, -0.1325,  0.2267,  0.3115, -0.0814, -0.2291],\n        [-0.2947,  0.0650,  0.1679, -0.2350,  0.1523,  0.1952, -0.0731,  0.1073],\n        [ 0.2836, -0.1832, -0.0627, -0.0898,  0.0585,  0.3154,  0.3327, -0.1736],\n        [-0.1705,  0.3286,  0.1498,  0.0812, -0.1491,  0.2752, -0.2675,  0.1852],\n        [-0.0142, -0.2899, -0.0104, -0.0768, -0.1269,  0.1486, -0.3278,  0.2811],\n        [-0.0232, -0.1762, -0.1375, -0.2578,  0.2168,  0.1784,  0.0377,  0.1345],\n        [-0.0087,  0.2653, -0.2485,  0.1910, -0.1963,  0.2379, -0.2175, -0.0053],\n        [-0.1737, -0.0099, -0.2071,  0.0485, -0.0492,  0.0956,  0.2516,  0.0041],\n        [-0.2636,  0.1545,  0.2112,  0.1286, -0.3414,  0.2031, -0.0211,  0.3092],\n        [ 0.1295, -0.0910, -0.0477,  0.2593, -0.0712,  0.2756,  0.1535, -0.1222],\n        [-0.0212,  0.3493, -0.2050, -0.3385, -0.1816,  0.1516,  0.3060,  0.3395],\n        [-0.1833,  0.3221, -0.2983, -0.0510,  0.0056,  0.2810,  0.2937, -0.2529]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1179, -0.1661,  0.0383, -0.1052,  0.0070,  0.0138, -0.1643,  0.0196,\n         0.0924,  0.0369,  0.1675, -0.0585,  0.0259, -0.0470,  0.0856,  0.0646],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.5595e-01,  1.4789e-01, -9.4157e-03, -1.3239e-01, -9.0008e-02,\n         -9.4040e-02, -3.5029e-02,  1.3852e-01,  1.4959e-01, -8.0883e-02,\n         -9.6403e-02,  9.4120e-02, -9.1738e-02, -1.3373e-01,  1.2160e-01,\n         -1.3176e-01,  3.0945e-03,  7.2711e-02,  9.5197e-02, -1.7225e-01,\n         -7.5078e-02,  1.1855e-01, -1.8614e-02,  1.1298e-01,  3.6922e-03,\n          6.4849e-02, -1.6154e-01, -2.3347e-02,  4.8729e-02,  2.0551e-02,\n         -6.3098e-02, -5.7313e-02],\n        [ 3.6424e-02, -1.6669e-01,  1.4629e-01,  1.4548e-01,  5.3807e-02,\n          1.0348e-01,  1.0560e-02,  5.7877e-02,  4.5780e-02,  1.6248e-01,\n         -1.4445e-01, -1.5781e-02,  2.8430e-03, -3.8851e-02, -1.4179e-01,\n          1.2904e-01, -6.7786e-02, -6.2557e-02, -2.9046e-02,  1.3684e-01,\n          6.1758e-02, -1.4902e-01, -4.3160e-02,  1.7526e-01,  7.8978e-02,\n          1.4737e-01,  1.5940e-01, -2.1990e-02,  9.1273e-02,  2.3706e-02,\n          1.2707e-01, -1.3894e-02],\n        [ 2.0572e-02, -8.0632e-02, -5.8873e-02, -1.2166e-01, -7.7892e-02,\n         -5.6207e-02,  1.5020e-01,  6.6465e-02,  1.4388e-01,  3.2981e-02,\n          4.2587e-02,  3.8805e-02,  1.5330e-01,  1.6036e-01,  5.9961e-02,\n          1.3219e-01, -1.4501e-01,  5.6010e-02, -5.1924e-02,  1.2700e-01,\n         -6.4534e-02,  1.2170e-02, -1.5813e-01, -6.4521e-02, -9.7845e-02,\n          1.3899e-01,  1.2432e-01,  1.6242e-01, -3.7982e-03, -1.5269e-01,\n         -6.9683e-02, -3.4867e-02],\n        [-1.2972e-01, -9.4249e-02,  1.5108e-01, -1.2066e-01, -1.2514e-01,\n         -1.1164e-01,  4.3474e-04, -1.1181e-01, -1.1075e-01, -8.9160e-02,\n         -1.5537e-01,  1.0424e-01, -1.4834e-01, -1.1057e-01,  9.4935e-02,\n          1.6910e-01,  4.8231e-02, -8.4394e-02,  8.3813e-03, -2.5059e-02,\n          3.0329e-02,  5.2880e-02, -2.7946e-02, -2.1597e-02, -7.5227e-02,\n          1.7268e-01,  6.4889e-02, -1.0389e-01,  1.1365e-01, -9.7520e-02,\n         -6.3666e-02, -1.5142e-01],\n        [-1.2784e-01,  5.1795e-03, -1.2984e-01, -1.0686e-01,  1.6609e-01,\n         -8.4797e-02,  1.4647e-01,  1.6136e-01, -1.3375e-01, -1.2665e-01,\n         -2.2363e-02,  8.1929e-02,  1.6094e-01, -1.7399e-01,  1.0366e-01,\n          1.0118e-01, -8.6758e-02,  1.6791e-01,  1.2407e-01,  1.6863e-01,\n         -3.0378e-02,  1.2914e-01, -1.9651e-02, -7.7087e-02,  6.1195e-02,\n         -7.6669e-02,  1.7079e-02, -3.3846e-03, -1.4426e-01, -8.8094e-02,\n         -8.5791e-02,  5.8032e-02],\n        [ 3.6397e-02, -8.2689e-02, -1.6709e-02, -2.6656e-02, -7.8482e-02,\n          3.6443e-02, -1.0229e-01, -1.9056e-02, -1.1127e-01,  1.5489e-01,\n          7.3073e-02,  3.5036e-03, -1.5071e-01, -1.6888e-01, -2.7419e-02,\n         -1.5303e-01, -1.3199e-02, -1.7476e-01,  6.5715e-02,  1.5601e-02,\n          2.8761e-02,  5.6051e-02,  9.7995e-03, -1.5082e-01,  4.4165e-02,\n         -1.3417e-01, -6.1879e-02,  1.7514e-01, -6.4996e-02,  4.7176e-03,\n          7.2088e-02, -1.5455e-01],\n        [ 1.5264e-01, -1.8601e-02,  8.1022e-02, -6.0055e-02,  1.1793e-01,\n         -1.4082e-02, -1.2000e-01,  1.3840e-01, -2.6705e-02, -6.7510e-03,\n         -4.5289e-02, -1.6808e-01, -1.2564e-01, -1.5286e-01, -1.5167e-01,\n          1.5913e-01,  5.5901e-02,  1.5534e-01, -1.7092e-01,  9.1703e-02,\n         -8.5842e-02, -3.5910e-02, -1.2974e-01, -1.4856e-01, -1.1099e-01,\n          1.2904e-02,  5.0564e-02, -3.4773e-02, -1.3739e-01,  1.3721e-01,\n         -1.3936e-01,  5.2408e-02],\n        [-1.0497e-01, -1.2683e-01, -1.3957e-02, -4.4447e-02,  1.7553e-01,\n          1.3799e-02, -2.9006e-02,  9.5778e-02, -1.7559e-01, -7.8436e-02,\n          7.1324e-02,  1.6280e-01,  7.9081e-02,  1.6345e-01,  8.7620e-02,\n         -1.2195e-01,  8.7194e-02,  1.4012e-01, -1.1224e-01,  4.9181e-02,\n         -2.7854e-02,  6.8345e-02, -4.9644e-02, -6.7329e-02, -2.4349e-02,\n         -2.3427e-02,  3.2805e-02,  7.4517e-02, -1.3103e-02, -7.0245e-02,\n         -2.2039e-03,  7.5940e-02],\n        [-1.7527e-01,  1.6472e-01,  1.4557e-01, -2.1260e-02, -1.4252e-02,\n          2.8518e-02,  6.6751e-02,  1.0515e-01,  1.6927e-01, -1.1327e-01,\n          1.7437e-03, -2.3454e-02, -9.9403e-05,  9.7178e-02, -1.6527e-01,\n         -1.3711e-01, -9.0136e-02, -1.7469e-01,  1.4744e-01, -1.0356e-01,\n         -7.4816e-02, -5.7540e-02,  6.4011e-02,  1.6175e-02, -6.6593e-02,\n          8.4561e-02,  1.4027e-01,  3.9091e-02,  1.1033e-01,  2.0824e-03,\n          1.0661e-01,  7.5375e-02],\n        [-4.7892e-02, -1.2927e-03,  1.7196e-01, -1.0079e-01, -4.0911e-02,\n         -9.0859e-02, -1.1439e-02,  6.2813e-02, -1.3777e-01,  1.5794e-01,\n          1.4321e-01,  1.6853e-01, -1.3051e-02,  3.5616e-02, -3.7277e-02,\n         -1.6464e-01, -1.4195e-01,  1.3390e-01,  1.6716e-01, -1.1061e-01,\n         -1.3304e-01,  1.5346e-01, -2.1920e-02,  7.7837e-02, -6.2864e-02,\n          1.2445e-01, -1.5638e-01, -1.7197e-01, -9.9713e-02,  3.2300e-02,\n         -1.2013e-01,  3.0232e-03],\n        [ 3.2123e-02, -2.6800e-02,  1.4471e-01, -9.1671e-02, -2.2137e-02,\n         -2.3133e-02,  1.6839e-01,  9.7875e-02,  5.6659e-02, -8.9613e-02,\n         -1.2820e-01, -1.8173e-02,  1.2753e-01,  1.2025e-01, -1.4929e-01,\n         -1.0438e-01,  3.4069e-02, -1.2409e-01,  1.2566e-01,  8.5170e-02,\n         -1.4027e-01,  1.6049e-02,  3.0408e-02, -2.8255e-02,  6.0892e-02,\n         -1.0116e-01,  3.8976e-02,  1.2167e-01, -2.4549e-03,  7.8176e-02,\n          6.5484e-02,  7.1607e-02],\n        [-4.0089e-02, -7.8633e-02,  1.5721e-01,  1.7222e-01, -1.6681e-01,\n          1.0820e-01, -1.4025e-01,  6.8764e-02,  5.6427e-02, -1.4809e-01,\n          1.1314e-01, -2.3837e-02, -3.1561e-02, -7.7073e-02,  6.2466e-02,\n         -3.9311e-02, -9.2964e-02,  1.2535e-01,  4.3901e-02,  9.3471e-04,\n         -5.9492e-02, -5.3709e-02,  1.4055e-01, -6.8578e-03,  1.1618e-01,\n          4.3599e-02, -1.7362e-01, -1.2948e-01, -1.1557e-01, -1.7497e-01,\n          9.5038e-02, -5.7363e-03],\n        [-2.0181e-02, -5.4276e-02, -1.2421e-01, -4.5093e-02,  7.0993e-02,\n         -1.9387e-02,  1.6360e-01, -1.2814e-01, -8.1301e-02, -1.2322e-01,\n         -4.3689e-02, -7.0671e-02, -4.3901e-02, -9.4046e-02, -4.0133e-02,\n         -5.4478e-03, -1.6977e-01,  2.0736e-02,  1.3854e-01, -1.7528e-01,\n         -8.5660e-02, -1.2568e-01, -1.0220e-01,  2.0531e-02, -2.6353e-02,\n         -1.1383e-01,  1.1817e-01,  5.5552e-02, -1.4323e-01,  1.5341e-01,\n         -4.2767e-02, -2.9568e-03],\n        [ 7.0960e-03,  5.7285e-02, -9.2396e-02, -1.4873e-01, -9.5683e-02,\n          6.5938e-02, -1.6446e-01,  1.4363e-01, -6.7908e-02, -1.4017e-01,\n         -1.7033e-02,  7.5398e-02,  1.3947e-01,  1.6115e-01,  1.5401e-01,\n         -6.0826e-02,  1.3547e-02, -8.8609e-02,  3.3603e-02,  2.9369e-02,\n          3.4485e-02,  4.6036e-02, -2.3968e-02,  1.4241e-01,  4.7746e-02,\n         -8.1205e-02, -9.1248e-02, -8.7515e-02,  1.7052e-01,  4.2123e-02,\n          1.5463e-01,  1.1805e-01],\n        [-1.0057e-01, -6.9571e-02,  1.9144e-03, -1.1794e-01,  1.4152e-01,\n          9.9438e-02,  1.8060e-02,  4.2397e-02,  1.2122e-01,  1.5890e-01,\n         -2.5985e-02,  1.6365e-01,  1.3434e-01,  9.6824e-03, -9.1197e-02,\n          8.1810e-02,  7.8485e-02, -8.8207e-02, -1.6199e-01,  1.6059e-01,\n         -2.1356e-02, -1.3591e-01, -1.4091e-02,  1.4358e-01, -7.6237e-02,\n          4.0705e-02, -1.6640e-01,  1.4080e-01, -7.5185e-02,  1.6594e-01,\n          1.6971e-03,  7.6355e-02],\n        [ 9.6405e-02, -4.8954e-02,  9.2071e-02,  1.5525e-02,  1.4146e-01,\n          6.2311e-02,  1.1949e-01, -1.1903e-01,  7.5826e-02, -1.6025e-01,\n         -1.2632e-01,  9.4837e-02,  2.3396e-02, -1.1604e-01,  8.9973e-02,\n         -1.2395e-01,  7.5956e-02, -1.0740e-01,  1.5996e-01,  6.9014e-02,\n          1.4895e-01,  2.2967e-02,  4.9623e-03, -1.4073e-01,  6.0363e-02,\n         -1.5199e-02,  5.4995e-02,  1.3361e-01,  1.0204e-01,  1.0944e-01,\n          1.0554e-01,  6.5098e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1806,  0.1478,  0.1588,  0.1760,  0.0544,  0.2241, -0.0924, -0.0898],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0051, -0.1077, -0.1983, -0.1371,  0.0524, -0.0772, -0.0565, -0.0085,\n          0.2276, -0.1754,  0.1415,  0.0065,  0.1163,  0.0978, -0.2285,  0.1997],\n        [-0.0823, -0.1149,  0.2027, -0.0549,  0.0464, -0.1395,  0.0470,  0.0310,\n          0.1285,  0.1339, -0.2378, -0.0006,  0.0385, -0.1505,  0.0093,  0.0777],\n        [ 0.0591,  0.1685, -0.2006,  0.0355, -0.0433,  0.2378, -0.1106,  0.1991,\n         -0.1305,  0.2448, -0.0032,  0.0894,  0.2149,  0.1319,  0.1903,  0.1745],\n        [-0.1709,  0.2368, -0.2119,  0.2145, -0.2425, -0.1649,  0.1377, -0.0250,\n         -0.0041,  0.0393, -0.2016,  0.0639, -0.1222,  0.1101,  0.1165, -0.2388],\n        [-0.1518,  0.0339, -0.0911, -0.2237, -0.0938, -0.0899,  0.1050, -0.1280,\n          0.2085, -0.1711, -0.1633, -0.0119, -0.0957,  0.1914, -0.0392, -0.1167],\n        [-0.1132, -0.1678, -0.2345, -0.1758,  0.0599, -0.1121, -0.1413,  0.0706,\n          0.1502,  0.2138, -0.1994,  0.1100,  0.1273,  0.0291,  0.2038, -0.2107],\n        [-0.2149, -0.2227,  0.1049,  0.1262, -0.0843,  0.1544, -0.0034,  0.1417,\n         -0.1704,  0.1367,  0.1856, -0.2245, -0.1185,  0.0032, -0.1764, -0.2489],\n        [ 0.1618,  0.1922, -0.1649,  0.2300,  0.2466, -0.1400, -0.1935, -0.0681,\n         -0.0211, -0.1694, -0.2450, -0.2466,  0.2450,  0.1377,  0.1725, -0.2292]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0800,  0.0460, -0.0711,  0.3037], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2540, -0.3372,  0.0709,  0.0801,  0.1035,  0.2978,  0.0548, -0.0506],\n        [ 0.0706, -0.0862, -0.1735, -0.2642,  0.0640,  0.1592,  0.0841, -0.0525],\n        [-0.0130,  0.1595,  0.1552,  0.3293,  0.3416, -0.1122, -0.2688, -0.0519],\n        [ 0.0647, -0.0771,  0.1751, -0.1890,  0.0613, -0.3238,  0.0324,  0.1885]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0764,  0.2017,  0.1628,  0.0760,  0.3230, -0.1783, -0.0004,  0.2780],\n        [-0.0939,  0.3197, -0.2518, -0.0249, -0.1606, -0.2666, -0.0255,  0.0674],\n        [ 0.0992,  0.1584, -0.1151, -0.0472, -0.0294, -0.1710,  0.0771,  0.0935],\n        [ 0.0777, -0.0964,  0.1735, -0.0943, -0.1061,  0.3330,  0.2307,  0.3068],\n        [-0.0300,  0.1826, -0.2488, -0.2611, -0.2322, -0.2661, -0.0004,  0.3312],\n        [ 0.1460, -0.2307,  0.0705,  0.1699, -0.0784, -0.2364,  0.0443,  0.2505],\n        [ 0.2054,  0.2132, -0.1427, -0.0920,  0.1192,  0.2829, -0.1204, -0.0724],\n        [ 0.2118, -0.1201,  0.1706, -0.1450, -0.1910, -0.1235, -0.2273,  0.1768],\n        [ 0.1854, -0.0461,  0.1241,  0.2351,  0.3438, -0.1898, -0.1148, -0.0631],\n        [-0.1341, -0.0100, -0.3018,  0.1886,  0.1758, -0.2094, -0.1044, -0.1000],\n        [ 0.0377,  0.0146, -0.0552,  0.3086,  0.2549,  0.3522,  0.2764, -0.2276],\n        [ 0.2739, -0.3339,  0.1480, -0.0582, -0.2347,  0.0347, -0.1787, -0.2770],\n        [ 0.2433, -0.2469, -0.1135, -0.1306, -0.0054, -0.1234, -0.0919,  0.1862],\n        [-0.0647,  0.0532,  0.1965, -0.1661,  0.1112, -0.3176, -0.1295, -0.1819],\n        [-0.3270,  0.3483, -0.1255, -0.1996, -0.0738,  0.0452,  0.0501,  0.0167],\n        [-0.2424, -0.2186,  0.0341,  0.1985, -0.2114,  0.1965, -0.3156, -0.0450],\n        [ 0.1597,  0.3320,  0.3409, -0.2622,  0.2621,  0.1335, -0.1175,  0.0797],\n        [ 0.3450, -0.3345, -0.1861, -0.2688, -0.1380, -0.0098,  0.1150,  0.2771],\n        [ 0.1004,  0.1992, -0.1363,  0.1158, -0.1920,  0.1329, -0.1330, -0.2652],\n        [ 0.0793,  0.3004,  0.1380, -0.1203, -0.0509,  0.1345, -0.1422,  0.0832],\n        [ 0.3028,  0.3212,  0.3216, -0.1325,  0.2267,  0.3115, -0.0814, -0.2291],\n        [-0.2947,  0.0650,  0.1679, -0.2350,  0.1523,  0.1952, -0.0731,  0.1073],\n        [ 0.2836, -0.1832, -0.0627, -0.0898,  0.0585,  0.3154,  0.3327, -0.1736],\n        [-0.1705,  0.3286,  0.1498,  0.0812, -0.1491,  0.2752, -0.2675,  0.1852],\n        [-0.0142, -0.2899, -0.0104, -0.0768, -0.1269,  0.1486, -0.3278,  0.2811],\n        [-0.0232, -0.1762, -0.1375, -0.2578,  0.2168,  0.1784,  0.0377,  0.1345],\n        [-0.0087,  0.2653, -0.2485,  0.1910, -0.1963,  0.2379, -0.2175, -0.0053],\n        [-0.1737, -0.0099, -0.2071,  0.0485, -0.0492,  0.0956,  0.2516,  0.0041],\n        [-0.2636,  0.1545,  0.2112,  0.1286, -0.3414,  0.2031, -0.0211,  0.3092],\n        [ 0.1295, -0.0910, -0.0477,  0.2593, -0.0712,  0.2756,  0.1535, -0.1222],\n        [-0.0212,  0.3493, -0.2050, -0.3385, -0.1816,  0.1516,  0.3060,  0.3395],\n        [-0.1833,  0.3221, -0.2983, -0.0510,  0.0056,  0.2810,  0.2937, -0.2529]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1706,  0.2794,  0.1210,  0.1318, -0.1759, -0.0639,  0.0886, -0.2393,\n         0.2980,  0.3159,  0.0436, -0.2624,  0.1979,  0.0132, -0.2959,  0.0556,\n         0.0770,  0.1759,  0.1580, -0.0420, -0.0228,  0.3462,  0.0305,  0.2502,\n        -0.1419,  0.0592, -0.2797,  0.0568,  0.1956, -0.2109,  0.3501,  0.0439],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.5595e-01,  1.4789e-01, -9.4157e-03, -1.3239e-01, -9.0008e-02,\n         -9.4040e-02, -3.5029e-02,  1.3852e-01,  1.4959e-01, -8.0883e-02,\n         -9.6403e-02,  9.4120e-02, -9.1738e-02, -1.3373e-01,  1.2160e-01,\n         -1.3176e-01,  3.0945e-03,  7.2711e-02,  9.5197e-02, -1.7225e-01,\n         -7.5078e-02,  1.1855e-01, -1.8614e-02,  1.1298e-01,  3.6922e-03,\n          6.4849e-02, -1.6154e-01, -2.3347e-02,  4.8729e-02,  2.0551e-02,\n         -6.3098e-02, -5.7313e-02],\n        [ 3.6424e-02, -1.6669e-01,  1.4629e-01,  1.4548e-01,  5.3807e-02,\n          1.0348e-01,  1.0560e-02,  5.7877e-02,  4.5780e-02,  1.6248e-01,\n         -1.4445e-01, -1.5781e-02,  2.8430e-03, -3.8851e-02, -1.4179e-01,\n          1.2904e-01, -6.7786e-02, -6.2557e-02, -2.9046e-02,  1.3684e-01,\n          6.1758e-02, -1.4902e-01, -4.3160e-02,  1.7526e-01,  7.8978e-02,\n          1.4737e-01,  1.5940e-01, -2.1990e-02,  9.1273e-02,  2.3706e-02,\n          1.2707e-01, -1.3894e-02],\n        [ 2.0572e-02, -8.0632e-02, -5.8873e-02, -1.2166e-01, -7.7892e-02,\n         -5.6207e-02,  1.5020e-01,  6.6465e-02,  1.4388e-01,  3.2981e-02,\n          4.2587e-02,  3.8805e-02,  1.5330e-01,  1.6036e-01,  5.9961e-02,\n          1.3219e-01, -1.4501e-01,  5.6010e-02, -5.1924e-02,  1.2700e-01,\n         -6.4534e-02,  1.2170e-02, -1.5813e-01, -6.4521e-02, -9.7845e-02,\n          1.3899e-01,  1.2432e-01,  1.6242e-01, -3.7982e-03, -1.5269e-01,\n         -6.9683e-02, -3.4867e-02],\n        [-1.2972e-01, -9.4249e-02,  1.5108e-01, -1.2066e-01, -1.2514e-01,\n         -1.1164e-01,  4.3474e-04, -1.1181e-01, -1.1075e-01, -8.9160e-02,\n         -1.5537e-01,  1.0424e-01, -1.4834e-01, -1.1057e-01,  9.4935e-02,\n          1.6910e-01,  4.8231e-02, -8.4394e-02,  8.3813e-03, -2.5059e-02,\n          3.0329e-02,  5.2880e-02, -2.7946e-02, -2.1597e-02, -7.5227e-02,\n          1.7268e-01,  6.4889e-02, -1.0389e-01,  1.1365e-01, -9.7520e-02,\n         -6.3666e-02, -1.5142e-01],\n        [-1.2784e-01,  5.1795e-03, -1.2984e-01, -1.0686e-01,  1.6609e-01,\n         -8.4797e-02,  1.4647e-01,  1.6136e-01, -1.3375e-01, -1.2665e-01,\n         -2.2363e-02,  8.1929e-02,  1.6094e-01, -1.7399e-01,  1.0366e-01,\n          1.0118e-01, -8.6758e-02,  1.6791e-01,  1.2407e-01,  1.6863e-01,\n         -3.0378e-02,  1.2914e-01, -1.9651e-02, -7.7087e-02,  6.1195e-02,\n         -7.6669e-02,  1.7079e-02, -3.3846e-03, -1.4426e-01, -8.8094e-02,\n         -8.5791e-02,  5.8032e-02],\n        [ 3.6397e-02, -8.2689e-02, -1.6709e-02, -2.6656e-02, -7.8482e-02,\n          3.6443e-02, -1.0229e-01, -1.9056e-02, -1.1127e-01,  1.5489e-01,\n          7.3073e-02,  3.5036e-03, -1.5071e-01, -1.6888e-01, -2.7419e-02,\n         -1.5303e-01, -1.3199e-02, -1.7476e-01,  6.5715e-02,  1.5601e-02,\n          2.8761e-02,  5.6051e-02,  9.7995e-03, -1.5082e-01,  4.4165e-02,\n         -1.3417e-01, -6.1879e-02,  1.7514e-01, -6.4996e-02,  4.7176e-03,\n          7.2088e-02, -1.5455e-01],\n        [ 1.5264e-01, -1.8601e-02,  8.1022e-02, -6.0055e-02,  1.1793e-01,\n         -1.4082e-02, -1.2000e-01,  1.3840e-01, -2.6705e-02, -6.7510e-03,\n         -4.5289e-02, -1.6808e-01, -1.2564e-01, -1.5286e-01, -1.5167e-01,\n          1.5913e-01,  5.5901e-02,  1.5534e-01, -1.7092e-01,  9.1703e-02,\n         -8.5842e-02, -3.5910e-02, -1.2974e-01, -1.4856e-01, -1.1099e-01,\n          1.2904e-02,  5.0564e-02, -3.4773e-02, -1.3739e-01,  1.3721e-01,\n         -1.3936e-01,  5.2408e-02],\n        [-1.0497e-01, -1.2683e-01, -1.3957e-02, -4.4447e-02,  1.7553e-01,\n          1.3799e-02, -2.9006e-02,  9.5778e-02, -1.7559e-01, -7.8436e-02,\n          7.1324e-02,  1.6280e-01,  7.9081e-02,  1.6345e-01,  8.7620e-02,\n         -1.2195e-01,  8.7194e-02,  1.4012e-01, -1.1224e-01,  4.9181e-02,\n         -2.7854e-02,  6.8345e-02, -4.9644e-02, -6.7329e-02, -2.4349e-02,\n         -2.3427e-02,  3.2805e-02,  7.4517e-02, -1.3103e-02, -7.0245e-02,\n         -2.2039e-03,  7.5940e-02],\n        [-1.7527e-01,  1.6472e-01,  1.4557e-01, -2.1260e-02, -1.4252e-02,\n          2.8518e-02,  6.6751e-02,  1.0515e-01,  1.6927e-01, -1.1327e-01,\n          1.7437e-03, -2.3454e-02, -9.9403e-05,  9.7178e-02, -1.6527e-01,\n         -1.3711e-01, -9.0136e-02, -1.7469e-01,  1.4744e-01, -1.0356e-01,\n         -7.4816e-02, -5.7540e-02,  6.4011e-02,  1.6175e-02, -6.6593e-02,\n          8.4561e-02,  1.4027e-01,  3.9091e-02,  1.1033e-01,  2.0824e-03,\n          1.0661e-01,  7.5375e-02],\n        [-4.7892e-02, -1.2927e-03,  1.7196e-01, -1.0079e-01, -4.0911e-02,\n         -9.0859e-02, -1.1439e-02,  6.2813e-02, -1.3777e-01,  1.5794e-01,\n          1.4321e-01,  1.6853e-01, -1.3051e-02,  3.5616e-02, -3.7277e-02,\n         -1.6464e-01, -1.4195e-01,  1.3390e-01,  1.6716e-01, -1.1061e-01,\n         -1.3304e-01,  1.5346e-01, -2.1920e-02,  7.7837e-02, -6.2864e-02,\n          1.2445e-01, -1.5638e-01, -1.7197e-01, -9.9713e-02,  3.2300e-02,\n         -1.2013e-01,  3.0232e-03],\n        [ 3.2123e-02, -2.6800e-02,  1.4471e-01, -9.1671e-02, -2.2137e-02,\n         -2.3133e-02,  1.6839e-01,  9.7875e-02,  5.6659e-02, -8.9613e-02,\n         -1.2820e-01, -1.8173e-02,  1.2753e-01,  1.2025e-01, -1.4929e-01,\n         -1.0438e-01,  3.4069e-02, -1.2409e-01,  1.2566e-01,  8.5170e-02,\n         -1.4027e-01,  1.6049e-02,  3.0408e-02, -2.8255e-02,  6.0892e-02,\n         -1.0116e-01,  3.8976e-02,  1.2167e-01, -2.4549e-03,  7.8176e-02,\n          6.5484e-02,  7.1607e-02],\n        [-4.0089e-02, -7.8633e-02,  1.5721e-01,  1.7222e-01, -1.6681e-01,\n          1.0820e-01, -1.4025e-01,  6.8764e-02,  5.6427e-02, -1.4809e-01,\n          1.1314e-01, -2.3837e-02, -3.1561e-02, -7.7073e-02,  6.2466e-02,\n         -3.9311e-02, -9.2964e-02,  1.2535e-01,  4.3901e-02,  9.3471e-04,\n         -5.9492e-02, -5.3709e-02,  1.4055e-01, -6.8578e-03,  1.1618e-01,\n          4.3599e-02, -1.7362e-01, -1.2948e-01, -1.1557e-01, -1.7497e-01,\n          9.5038e-02, -5.7363e-03],\n        [-2.0181e-02, -5.4276e-02, -1.2421e-01, -4.5093e-02,  7.0993e-02,\n         -1.9387e-02,  1.6360e-01, -1.2814e-01, -8.1301e-02, -1.2322e-01,\n         -4.3689e-02, -7.0671e-02, -4.3901e-02, -9.4046e-02, -4.0133e-02,\n         -5.4478e-03, -1.6977e-01,  2.0736e-02,  1.3854e-01, -1.7528e-01,\n         -8.5660e-02, -1.2568e-01, -1.0220e-01,  2.0531e-02, -2.6353e-02,\n         -1.1383e-01,  1.1817e-01,  5.5552e-02, -1.4323e-01,  1.5341e-01,\n         -4.2767e-02, -2.9568e-03],\n        [ 7.0960e-03,  5.7285e-02, -9.2396e-02, -1.4873e-01, -9.5683e-02,\n          6.5938e-02, -1.6446e-01,  1.4363e-01, -6.7908e-02, -1.4017e-01,\n         -1.7033e-02,  7.5398e-02,  1.3947e-01,  1.6115e-01,  1.5401e-01,\n         -6.0826e-02,  1.3547e-02, -8.8609e-02,  3.3603e-02,  2.9369e-02,\n          3.4485e-02,  4.6036e-02, -2.3968e-02,  1.4241e-01,  4.7746e-02,\n         -8.1205e-02, -9.1248e-02, -8.7515e-02,  1.7052e-01,  4.2123e-02,\n          1.5463e-01,  1.1805e-01],\n        [-1.0057e-01, -6.9571e-02,  1.9144e-03, -1.1794e-01,  1.4152e-01,\n          9.9438e-02,  1.8060e-02,  4.2397e-02,  1.2122e-01,  1.5890e-01,\n         -2.5985e-02,  1.6365e-01,  1.3434e-01,  9.6824e-03, -9.1197e-02,\n          8.1810e-02,  7.8485e-02, -8.8207e-02, -1.6199e-01,  1.6059e-01,\n         -2.1356e-02, -1.3591e-01, -1.4091e-02,  1.4358e-01, -7.6237e-02,\n          4.0705e-02, -1.6640e-01,  1.4080e-01, -7.5185e-02,  1.6594e-01,\n          1.6971e-03,  7.6355e-02],\n        [ 9.6405e-02, -4.8954e-02,  9.2071e-02,  1.5525e-02,  1.4146e-01,\n          6.2311e-02,  1.1949e-01, -1.1903e-01,  7.5826e-02, -1.6025e-01,\n         -1.2632e-01,  9.4837e-02,  2.3396e-02, -1.1604e-01,  8.9973e-02,\n         -1.2395e-01,  7.5956e-02, -1.0740e-01,  1.5996e-01,  6.9014e-02,\n          1.4895e-01,  2.2967e-02,  4.9623e-03, -1.4073e-01,  6.0363e-02,\n         -1.5199e-02,  5.4995e-02,  1.3361e-01,  1.0204e-01,  1.0944e-01,\n          1.0554e-01,  6.5098e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1179, -0.1661,  0.0383, -0.1052,  0.0070,  0.0138, -0.1643,  0.0196,\n         0.0924,  0.0369,  0.1675, -0.0585,  0.0259, -0.0470,  0.0856,  0.0646],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0051, -0.1077, -0.1983, -0.1371,  0.0524, -0.0772, -0.0565, -0.0085,\n          0.2276, -0.1754,  0.1415,  0.0065,  0.1163,  0.0978, -0.2285,  0.1997],\n        [-0.0823, -0.1149,  0.2027, -0.0549,  0.0464, -0.1395,  0.0470,  0.0310,\n          0.1285,  0.1339, -0.2378, -0.0006,  0.0385, -0.1505,  0.0093,  0.0777],\n        [ 0.0591,  0.1685, -0.2006,  0.0355, -0.0433,  0.2378, -0.1106,  0.1991,\n         -0.1305,  0.2448, -0.0032,  0.0894,  0.2149,  0.1319,  0.1903,  0.1745],\n        [-0.1709,  0.2368, -0.2119,  0.2145, -0.2425, -0.1649,  0.1377, -0.0250,\n         -0.0041,  0.0393, -0.2016,  0.0639, -0.1222,  0.1101,  0.1165, -0.2388],\n        [-0.1518,  0.0339, -0.0911, -0.2237, -0.0938, -0.0899,  0.1050, -0.1280,\n          0.2085, -0.1711, -0.1633, -0.0119, -0.0957,  0.1914, -0.0392, -0.1167],\n        [-0.1132, -0.1678, -0.2345, -0.1758,  0.0599, -0.1121, -0.1413,  0.0706,\n          0.1502,  0.2138, -0.1994,  0.1100,  0.1273,  0.0291,  0.2038, -0.2107],\n        [-0.2149, -0.2227,  0.1049,  0.1262, -0.0843,  0.1544, -0.0034,  0.1417,\n         -0.1704,  0.1367,  0.1856, -0.2245, -0.1185,  0.0032, -0.1764, -0.2489],\n        [ 0.1618,  0.1922, -0.1649,  0.2300,  0.2466, -0.1400, -0.1935, -0.0681,\n         -0.0211, -0.1694, -0.2450, -0.2466,  0.2450,  0.1377,  0.1725, -0.2292]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1806,  0.1478,  0.1588,  0.1760,  0.0544,  0.2241, -0.0924, -0.0898],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2540, -0.3372,  0.0709,  0.0801,  0.1035,  0.2978,  0.0548, -0.0506],\n        [ 0.0706, -0.0862, -0.1735, -0.2642,  0.0640,  0.1592,  0.0841, -0.0525],\n        [-0.0130,  0.1595,  0.1552,  0.3293,  0.3416, -0.1122, -0.2688, -0.0519],\n        [ 0.0647, -0.0771,  0.1751, -0.1890,  0.0613, -0.3238,  0.0324,  0.1885]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0800,  0.0460, -0.0711,  0.3037], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x726c63e8ee90>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1706,  0.2794,  0.1210,  0.1318, -0.1759, -0.0639,  0.0886, -0.2393,\n         0.2980,  0.3159,  0.0436, -0.2624,  0.1979,  0.0132, -0.2959,  0.0556,\n         0.0770,  0.1759,  0.1580, -0.0420, -0.0228,  0.3462,  0.0305,  0.2502,\n        -0.1419,  0.0592, -0.2797,  0.0568,  0.1956, -0.2109,  0.3501,  0.0439],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0764,  0.2017,  0.1628,  0.0760,  0.3230, -0.1783, -0.0004,  0.2780],\n        [-0.0939,  0.3197, -0.2518, -0.0249, -0.1606, -0.2666, -0.0255,  0.0674],\n        [ 0.0992,  0.1584, -0.1151, -0.0472, -0.0294, -0.1710,  0.0771,  0.0935],\n        [ 0.0777, -0.0964,  0.1735, -0.0943, -0.1061,  0.3330,  0.2307,  0.3068],\n        [-0.0300,  0.1826, -0.2488, -0.2611, -0.2322, -0.2661, -0.0004,  0.3312],\n        [ 0.1460, -0.2307,  0.0705,  0.1699, -0.0784, -0.2364,  0.0443,  0.2505],\n        [ 0.2054,  0.2132, -0.1427, -0.0920,  0.1192,  0.2829, -0.1204, -0.0724],\n        [ 0.2118, -0.1201,  0.1706, -0.1450, -0.1910, -0.1235, -0.2273,  0.1768],\n        [ 0.1854, -0.0461,  0.1241,  0.2351,  0.3438, -0.1898, -0.1148, -0.0631],\n        [-0.1341, -0.0100, -0.3018,  0.1886,  0.1758, -0.2094, -0.1044, -0.1000],\n        [ 0.0377,  0.0146, -0.0552,  0.3086,  0.2549,  0.3522,  0.2764, -0.2276],\n        [ 0.2739, -0.3339,  0.1480, -0.0582, -0.2347,  0.0347, -0.1787, -0.2770],\n        [ 0.2433, -0.2469, -0.1135, -0.1306, -0.0054, -0.1234, -0.0919,  0.1862],\n        [-0.0647,  0.0532,  0.1965, -0.1661,  0.1112, -0.3176, -0.1295, -0.1819],\n        [-0.3270,  0.3483, -0.1255, -0.1996, -0.0738,  0.0452,  0.0501,  0.0167],\n        [-0.2424, -0.2186,  0.0341,  0.1985, -0.2114,  0.1965, -0.3156, -0.0450],\n        [ 0.1597,  0.3320,  0.3409, -0.2622,  0.2621,  0.1335, -0.1175,  0.0797],\n        [ 0.3450, -0.3345, -0.1861, -0.2688, -0.1380, -0.0098,  0.1150,  0.2771],\n        [ 0.1004,  0.1992, -0.1363,  0.1158, -0.1920,  0.1329, -0.1330, -0.2652],\n        [ 0.0793,  0.3004,  0.1380, -0.1203, -0.0509,  0.1345, -0.1422,  0.0832],\n        [ 0.3028,  0.3212,  0.3216, -0.1325,  0.2267,  0.3115, -0.0814, -0.2291],\n        [-0.2947,  0.0650,  0.1679, -0.2350,  0.1523,  0.1952, -0.0731,  0.1073],\n        [ 0.2836, -0.1832, -0.0627, -0.0898,  0.0585,  0.3154,  0.3327, -0.1736],\n        [-0.1705,  0.3286,  0.1498,  0.0812, -0.1491,  0.2752, -0.2675,  0.1852],\n        [-0.0142, -0.2899, -0.0104, -0.0768, -0.1269,  0.1486, -0.3278,  0.2811],\n        [-0.0232, -0.1762, -0.1375, -0.2578,  0.2168,  0.1784,  0.0377,  0.1345],\n        [-0.0087,  0.2653, -0.2485,  0.1910, -0.1963,  0.2379, -0.2175, -0.0053],\n        [-0.1737, -0.0099, -0.2071,  0.0485, -0.0492,  0.0956,  0.2516,  0.0041],\n        [-0.2636,  0.1545,  0.2112,  0.1286, -0.3414,  0.2031, -0.0211,  0.3092],\n        [ 0.1295, -0.0910, -0.0477,  0.2593, -0.0712,  0.2756,  0.1535, -0.1222],\n        [-0.0212,  0.3493, -0.2050, -0.3385, -0.1816,  0.1516,  0.3060,  0.3395],\n        [-0.1833,  0.3221, -0.2983, -0.0510,  0.0056,  0.2810,  0.2937, -0.2529]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1179, -0.1661,  0.0383, -0.1052,  0.0070,  0.0138, -0.1643,  0.0196,\n         0.0924,  0.0369,  0.1675, -0.0585,  0.0259, -0.0470,  0.0856,  0.0646],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.5595e-01,  1.4789e-01, -9.4157e-03, -1.3239e-01, -9.0008e-02,\n         -9.4040e-02, -3.5029e-02,  1.3852e-01,  1.4959e-01, -8.0883e-02,\n         -9.6403e-02,  9.4120e-02, -9.1738e-02, -1.3373e-01,  1.2160e-01,\n         -1.3176e-01,  3.0945e-03,  7.2711e-02,  9.5197e-02, -1.7225e-01,\n         -7.5078e-02,  1.1855e-01, -1.8614e-02,  1.1298e-01,  3.6922e-03,\n          6.4849e-02, -1.6154e-01, -2.3347e-02,  4.8729e-02,  2.0551e-02,\n         -6.3098e-02, -5.7313e-02],\n        [ 3.6424e-02, -1.6669e-01,  1.4629e-01,  1.4548e-01,  5.3807e-02,\n          1.0348e-01,  1.0560e-02,  5.7877e-02,  4.5780e-02,  1.6248e-01,\n         -1.4445e-01, -1.5781e-02,  2.8430e-03, -3.8851e-02, -1.4179e-01,\n          1.2904e-01, -6.7786e-02, -6.2557e-02, -2.9046e-02,  1.3684e-01,\n          6.1758e-02, -1.4902e-01, -4.3160e-02,  1.7526e-01,  7.8978e-02,\n          1.4737e-01,  1.5940e-01, -2.1990e-02,  9.1273e-02,  2.3706e-02,\n          1.2707e-01, -1.3894e-02],\n        [ 2.0572e-02, -8.0632e-02, -5.8873e-02, -1.2166e-01, -7.7892e-02,\n         -5.6207e-02,  1.5020e-01,  6.6465e-02,  1.4388e-01,  3.2981e-02,\n          4.2587e-02,  3.8805e-02,  1.5330e-01,  1.6036e-01,  5.9961e-02,\n          1.3219e-01, -1.4501e-01,  5.6010e-02, -5.1924e-02,  1.2700e-01,\n         -6.4534e-02,  1.2170e-02, -1.5813e-01, -6.4521e-02, -9.7845e-02,\n          1.3899e-01,  1.2432e-01,  1.6242e-01, -3.7982e-03, -1.5269e-01,\n         -6.9683e-02, -3.4867e-02],\n        [-1.2972e-01, -9.4249e-02,  1.5108e-01, -1.2066e-01, -1.2514e-01,\n         -1.1164e-01,  4.3474e-04, -1.1181e-01, -1.1075e-01, -8.9160e-02,\n         -1.5537e-01,  1.0424e-01, -1.4834e-01, -1.1057e-01,  9.4935e-02,\n          1.6910e-01,  4.8231e-02, -8.4394e-02,  8.3813e-03, -2.5059e-02,\n          3.0329e-02,  5.2880e-02, -2.7946e-02, -2.1597e-02, -7.5227e-02,\n          1.7268e-01,  6.4889e-02, -1.0389e-01,  1.1365e-01, -9.7520e-02,\n         -6.3666e-02, -1.5142e-01],\n        [-1.2784e-01,  5.1795e-03, -1.2984e-01, -1.0686e-01,  1.6609e-01,\n         -8.4797e-02,  1.4647e-01,  1.6136e-01, -1.3375e-01, -1.2665e-01,\n         -2.2363e-02,  8.1929e-02,  1.6094e-01, -1.7399e-01,  1.0366e-01,\n          1.0118e-01, -8.6758e-02,  1.6791e-01,  1.2407e-01,  1.6863e-01,\n         -3.0378e-02,  1.2914e-01, -1.9651e-02, -7.7087e-02,  6.1195e-02,\n         -7.6669e-02,  1.7079e-02, -3.3846e-03, -1.4426e-01, -8.8094e-02,\n         -8.5791e-02,  5.8032e-02],\n        [ 3.6397e-02, -8.2689e-02, -1.6709e-02, -2.6656e-02, -7.8482e-02,\n          3.6443e-02, -1.0229e-01, -1.9056e-02, -1.1127e-01,  1.5489e-01,\n          7.3073e-02,  3.5036e-03, -1.5071e-01, -1.6888e-01, -2.7419e-02,\n         -1.5303e-01, -1.3199e-02, -1.7476e-01,  6.5715e-02,  1.5601e-02,\n          2.8761e-02,  5.6051e-02,  9.7995e-03, -1.5082e-01,  4.4165e-02,\n         -1.3417e-01, -6.1879e-02,  1.7514e-01, -6.4996e-02,  4.7176e-03,\n          7.2088e-02, -1.5455e-01],\n        [ 1.5264e-01, -1.8601e-02,  8.1022e-02, -6.0055e-02,  1.1793e-01,\n         -1.4082e-02, -1.2000e-01,  1.3840e-01, -2.6705e-02, -6.7510e-03,\n         -4.5289e-02, -1.6808e-01, -1.2564e-01, -1.5286e-01, -1.5167e-01,\n          1.5913e-01,  5.5901e-02,  1.5534e-01, -1.7092e-01,  9.1703e-02,\n         -8.5842e-02, -3.5910e-02, -1.2974e-01, -1.4856e-01, -1.1099e-01,\n          1.2904e-02,  5.0564e-02, -3.4773e-02, -1.3739e-01,  1.3721e-01,\n         -1.3936e-01,  5.2408e-02],\n        [-1.0497e-01, -1.2683e-01, -1.3957e-02, -4.4447e-02,  1.7553e-01,\n          1.3799e-02, -2.9006e-02,  9.5778e-02, -1.7559e-01, -7.8436e-02,\n          7.1324e-02,  1.6280e-01,  7.9081e-02,  1.6345e-01,  8.7620e-02,\n         -1.2195e-01,  8.7194e-02,  1.4012e-01, -1.1224e-01,  4.9181e-02,\n         -2.7854e-02,  6.8345e-02, -4.9644e-02, -6.7329e-02, -2.4349e-02,\n         -2.3427e-02,  3.2805e-02,  7.4517e-02, -1.3103e-02, -7.0245e-02,\n         -2.2039e-03,  7.5940e-02],\n        [-1.7527e-01,  1.6472e-01,  1.4557e-01, -2.1260e-02, -1.4252e-02,\n          2.8518e-02,  6.6751e-02,  1.0515e-01,  1.6927e-01, -1.1327e-01,\n          1.7437e-03, -2.3454e-02, -9.9403e-05,  9.7178e-02, -1.6527e-01,\n         -1.3711e-01, -9.0136e-02, -1.7469e-01,  1.4744e-01, -1.0356e-01,\n         -7.4816e-02, -5.7540e-02,  6.4011e-02,  1.6175e-02, -6.6593e-02,\n          8.4561e-02,  1.4027e-01,  3.9091e-02,  1.1033e-01,  2.0824e-03,\n          1.0661e-01,  7.5375e-02],\n        [-4.7892e-02, -1.2927e-03,  1.7196e-01, -1.0079e-01, -4.0911e-02,\n         -9.0859e-02, -1.1439e-02,  6.2813e-02, -1.3777e-01,  1.5794e-01,\n          1.4321e-01,  1.6853e-01, -1.3051e-02,  3.5616e-02, -3.7277e-02,\n         -1.6464e-01, -1.4195e-01,  1.3390e-01,  1.6716e-01, -1.1061e-01,\n         -1.3304e-01,  1.5346e-01, -2.1920e-02,  7.7837e-02, -6.2864e-02,\n          1.2445e-01, -1.5638e-01, -1.7197e-01, -9.9713e-02,  3.2300e-02,\n         -1.2013e-01,  3.0232e-03],\n        [ 3.2123e-02, -2.6800e-02,  1.4471e-01, -9.1671e-02, -2.2137e-02,\n         -2.3133e-02,  1.6839e-01,  9.7875e-02,  5.6659e-02, -8.9613e-02,\n         -1.2820e-01, -1.8173e-02,  1.2753e-01,  1.2025e-01, -1.4929e-01,\n         -1.0438e-01,  3.4069e-02, -1.2409e-01,  1.2566e-01,  8.5170e-02,\n         -1.4027e-01,  1.6049e-02,  3.0408e-02, -2.8255e-02,  6.0892e-02,\n         -1.0116e-01,  3.8976e-02,  1.2167e-01, -2.4549e-03,  7.8176e-02,\n          6.5484e-02,  7.1607e-02],\n        [-4.0089e-02, -7.8633e-02,  1.5721e-01,  1.7222e-01, -1.6681e-01,\n          1.0820e-01, -1.4025e-01,  6.8764e-02,  5.6427e-02, -1.4809e-01,\n          1.1314e-01, -2.3837e-02, -3.1561e-02, -7.7073e-02,  6.2466e-02,\n         -3.9311e-02, -9.2964e-02,  1.2535e-01,  4.3901e-02,  9.3471e-04,\n         -5.9492e-02, -5.3709e-02,  1.4055e-01, -6.8578e-03,  1.1618e-01,\n          4.3599e-02, -1.7362e-01, -1.2948e-01, -1.1557e-01, -1.7497e-01,\n          9.5038e-02, -5.7363e-03],\n        [-2.0181e-02, -5.4276e-02, -1.2421e-01, -4.5093e-02,  7.0993e-02,\n         -1.9387e-02,  1.6360e-01, -1.2814e-01, -8.1301e-02, -1.2322e-01,\n         -4.3689e-02, -7.0671e-02, -4.3901e-02, -9.4046e-02, -4.0133e-02,\n         -5.4478e-03, -1.6977e-01,  2.0736e-02,  1.3854e-01, -1.7528e-01,\n         -8.5660e-02, -1.2568e-01, -1.0220e-01,  2.0531e-02, -2.6353e-02,\n         -1.1383e-01,  1.1817e-01,  5.5552e-02, -1.4323e-01,  1.5341e-01,\n         -4.2767e-02, -2.9568e-03],\n        [ 7.0960e-03,  5.7285e-02, -9.2396e-02, -1.4873e-01, -9.5683e-02,\n          6.5938e-02, -1.6446e-01,  1.4363e-01, -6.7908e-02, -1.4017e-01,\n         -1.7033e-02,  7.5398e-02,  1.3947e-01,  1.6115e-01,  1.5401e-01,\n         -6.0826e-02,  1.3547e-02, -8.8609e-02,  3.3603e-02,  2.9369e-02,\n          3.4485e-02,  4.6036e-02, -2.3968e-02,  1.4241e-01,  4.7746e-02,\n         -8.1205e-02, -9.1248e-02, -8.7515e-02,  1.7052e-01,  4.2123e-02,\n          1.5463e-01,  1.1805e-01],\n        [-1.0057e-01, -6.9571e-02,  1.9144e-03, -1.1794e-01,  1.4152e-01,\n          9.9438e-02,  1.8060e-02,  4.2397e-02,  1.2122e-01,  1.5890e-01,\n         -2.5985e-02,  1.6365e-01,  1.3434e-01,  9.6824e-03, -9.1197e-02,\n          8.1810e-02,  7.8485e-02, -8.8207e-02, -1.6199e-01,  1.6059e-01,\n         -2.1356e-02, -1.3591e-01, -1.4091e-02,  1.4358e-01, -7.6237e-02,\n          4.0705e-02, -1.6640e-01,  1.4080e-01, -7.5185e-02,  1.6594e-01,\n          1.6971e-03,  7.6355e-02],\n        [ 9.6405e-02, -4.8954e-02,  9.2071e-02,  1.5525e-02,  1.4146e-01,\n          6.2311e-02,  1.1949e-01, -1.1903e-01,  7.5826e-02, -1.6025e-01,\n         -1.2632e-01,  9.4837e-02,  2.3396e-02, -1.1604e-01,  8.9973e-02,\n         -1.2395e-01,  7.5956e-02, -1.0740e-01,  1.5996e-01,  6.9014e-02,\n          1.4895e-01,  2.2967e-02,  4.9623e-03, -1.4073e-01,  6.0363e-02,\n         -1.5199e-02,  5.4995e-02,  1.3361e-01,  1.0204e-01,  1.0944e-01,\n          1.0554e-01,  6.5098e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1806,  0.1478,  0.1588,  0.1760,  0.0544,  0.2241, -0.0924, -0.0898],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0051, -0.1077, -0.1983, -0.1371,  0.0524, -0.0772, -0.0565, -0.0085,\n          0.2276, -0.1754,  0.1415,  0.0065,  0.1163,  0.0978, -0.2285,  0.1997],\n        [-0.0823, -0.1149,  0.2027, -0.0549,  0.0464, -0.1395,  0.0470,  0.0310,\n          0.1285,  0.1339, -0.2378, -0.0006,  0.0385, -0.1505,  0.0093,  0.0777],\n        [ 0.0591,  0.1685, -0.2006,  0.0355, -0.0433,  0.2378, -0.1106,  0.1991,\n         -0.1305,  0.2448, -0.0032,  0.0894,  0.2149,  0.1319,  0.1903,  0.1745],\n        [-0.1709,  0.2368, -0.2119,  0.2145, -0.2425, -0.1649,  0.1377, -0.0250,\n         -0.0041,  0.0393, -0.2016,  0.0639, -0.1222,  0.1101,  0.1165, -0.2388],\n        [-0.1518,  0.0339, -0.0911, -0.2237, -0.0938, -0.0899,  0.1050, -0.1280,\n          0.2085, -0.1711, -0.1633, -0.0119, -0.0957,  0.1914, -0.0392, -0.1167],\n        [-0.1132, -0.1678, -0.2345, -0.1758,  0.0599, -0.1121, -0.1413,  0.0706,\n          0.1502,  0.2138, -0.1994,  0.1100,  0.1273,  0.0291,  0.2038, -0.2107],\n        [-0.2149, -0.2227,  0.1049,  0.1262, -0.0843,  0.1544, -0.0034,  0.1417,\n         -0.1704,  0.1367,  0.1856, -0.2245, -0.1185,  0.0032, -0.1764, -0.2489],\n        [ 0.1618,  0.1922, -0.1649,  0.2300,  0.2466, -0.1400, -0.1935, -0.0681,\n         -0.0211, -0.1694, -0.2450, -0.2466,  0.2450,  0.1377,  0.1725, -0.2292]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0800,  0.0460, -0.0711,  0.3037], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2540, -0.3372,  0.0709,  0.0801,  0.1035,  0.2978,  0.0548, -0.0506],\n        [ 0.0706, -0.0862, -0.1735, -0.2642,  0.0640,  0.1592,  0.0841, -0.0525],\n        [-0.0130,  0.1595,  0.1552,  0.3293,  0.3416, -0.1122, -0.2688, -0.0519],\n        [ 0.0647, -0.0771,  0.1751, -0.1890,  0.0613, -0.3238,  0.0324,  0.1885]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x726c58f19b50>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s564830000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s564830000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}