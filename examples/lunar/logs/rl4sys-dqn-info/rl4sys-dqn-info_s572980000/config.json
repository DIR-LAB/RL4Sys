{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.01,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s572980000"
    },
    "q_lr":	0.003,
    "seed":	572980000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7c643bd50b50>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.01,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 3.1424e-01, -2.9299e-01, -2.6561e-01,  2.7308e-01,  3.3502e-01,\n        -2.1068e-01,  1.8233e-01, -3.4753e-01, -2.1770e-01,  2.0177e-02,\n         1.4835e-01,  2.5856e-01, -9.8618e-02,  9.0789e-02, -2.6080e-02,\n        -3.3170e-02,  3.4954e-01,  3.1879e-01, -2.7288e-01, -3.1261e-01,\n         2.2854e-01, -3.4260e-01, -3.0635e-01, -6.0976e-02,  1.8639e-01,\n        -2.4452e-01,  2.3466e-01, -6.3190e-02, -2.0867e-01, -2.2811e-01,\n        -2.5017e-01, -2.4520e-02,  1.2897e-01,  2.4654e-01,  5.2946e-03,\n        -2.2895e-01, -1.3430e-02,  4.5341e-02, -2.8903e-01,  2.1277e-01,\n        -2.8415e-02, -3.4493e-01, -2.6895e-02,  1.9180e-01, -3.0721e-01,\n         1.2351e-01, -9.7314e-02, -1.1539e-01,  2.7875e-01,  1.9668e-01,\n        -5.0362e-02, -1.5353e-01,  1.4041e-01, -2.1582e-01, -1.2540e-01,\n        -1.7614e-03,  2.7033e-01,  1.4577e-01, -3.5106e-01,  1.7466e-01,\n        -2.6872e-01, -2.0906e-01, -2.1881e-01, -8.4999e-02, -2.2419e-01,\n         3.4014e-01,  1.5662e-01,  1.5062e-02,  3.5342e-01, -2.7638e-01,\n        -9.7310e-03,  1.5275e-01, -4.1576e-02, -1.5529e-01, -2.2849e-01,\n        -2.8487e-02, -4.5341e-02,  2.9316e-01, -1.4627e-01,  5.5386e-02,\n        -1.6610e-01,  2.4107e-01, -5.2409e-02, -3.1294e-02, -1.5872e-01,\n         1.6524e-01, -7.8958e-02, -3.2932e-01, -3.3595e-02,  2.9356e-01,\n         2.8908e-02, -1.8337e-01,  1.5397e-01, -2.7468e-01, -2.1899e-01,\n         2.7018e-01,  1.3544e-01, -2.9642e-01,  1.2129e-01, -2.0365e-01,\n        -2.0059e-01,  3.0542e-01,  6.4529e-02,  6.1609e-03,  3.0419e-02,\n         5.0107e-02, -1.7201e-01, -2.0558e-01,  8.7942e-02, -2.4759e-01,\n         2.1005e-01, -5.8628e-02,  2.6724e-01,  1.7471e-01,  1.0576e-01,\n         6.2272e-02,  2.2837e-01,  1.5729e-01, -1.1195e-01,  2.7189e-01,\n        -1.4186e-01,  1.7579e-02,  1.7516e-01,  3.0425e-01,  1.3822e-01,\n        -8.9519e-02,  3.0152e-01, -2.1572e-01, -2.8806e-01, -1.0070e-01,\n        -1.3240e-02,  7.9934e-02, -9.1210e-04,  2.4697e-01, -1.6086e-01,\n         7.8346e-02, -3.1499e-01, -9.2410e-02, -3.8152e-03, -2.1124e-01,\n        -1.6741e-01, -3.0142e-01,  3.5272e-01,  2.9870e-01,  7.8302e-02,\n        -2.6408e-01,  2.3208e-01, -2.2920e-02, -1.7554e-01,  2.1970e-01,\n        -2.0541e-02, -1.3373e-01,  8.4448e-02, -3.1756e-01,  2.6627e-01,\n        -2.5526e-01,  3.4972e-01,  5.7419e-02, -3.3606e-01, -1.4449e-01,\n         1.0242e-01, -1.9061e-01, -2.0911e-01, -3.6249e-02,  3.1826e-01,\n        -3.5299e-02,  1.6632e-02,  1.8320e-01,  5.0181e-02, -2.8789e-01,\n         7.1057e-02, -3.2185e-01,  1.2362e-01, -2.4925e-01,  6.9953e-02,\n        -2.7760e-01,  2.9624e-01, -6.5882e-02, -3.0441e-01,  3.3408e-02,\n        -1.9226e-01, -3.4524e-01, -1.3493e-01,  6.6577e-02, -3.7229e-02,\n         3.2293e-01, -2.0474e-02,  1.1252e-02, -3.0007e-01, -1.2708e-01,\n        -6.0158e-02, -1.1101e-01, -2.9569e-02, -1.2744e-01, -3.1296e-01,\n        -3.4118e-01,  2.4362e-01,  3.4350e-01, -2.5764e-01, -2.8600e-01,\n         3.3893e-01,  2.1233e-01,  1.4116e-01, -2.0125e-01,  7.8825e-03,\n        -1.9123e-02,  2.6520e-01, -3.0374e-01,  2.9025e-01,  1.0764e-01,\n        -2.7940e-01, -3.4656e-01,  3.0278e-01,  1.1207e-02,  3.6160e-02,\n        -2.6633e-01, -3.5343e-01,  6.5460e-02,  2.4982e-01,  8.0212e-02,\n        -1.0792e-01, -6.1982e-03, -4.6362e-06,  9.8417e-02,  1.0247e-01,\n        -2.8183e-02,  1.2473e-01,  1.2366e-01,  5.4273e-02, -1.4932e-01,\n         1.3439e-01,  2.5566e-01,  2.6622e-01,  5.3133e-03,  3.0029e-02,\n        -1.8740e-01,  6.4758e-02, -2.8537e-01, -1.0347e-01, -1.8569e-01,\n         3.3125e-01, -9.4403e-02,  1.2778e-01, -1.6326e-01,  2.3271e-01,\n        -3.4900e-01,  5.9675e-02,  3.2841e-01, -2.1088e-01, -3.3248e-01,\n        -1.6899e-01,  5.8792e-02,  6.7072e-02, -2.8996e-01, -1.3234e-01,\n         3.4022e-01,  1.8812e-01,  1.1002e-01, -3.2085e-02,  1.0023e-01,\n        -3.3868e-01,  1.7390e-01,  1.3698e-01,  2.0212e-02,  3.4815e-01,\n        -1.0738e-01, -1.2323e-01,  2.0325e-01, -3.1716e-01, -1.2838e-01,\n        -2.2690e-01,  1.1727e-01, -5.2998e-02, -1.4928e-01,  1.2912e-01,\n         9.0489e-02, -1.6150e-01, -1.1165e-01, -2.9473e-01, -4.5291e-02,\n        -1.8295e-01, -2.5056e-01, -1.8513e-01, -1.8286e-01, -6.5019e-02,\n        -3.0385e-02,  3.5249e-01,  2.4950e-01, -1.7473e-01, -2.4997e-01,\n        -3.3681e-02,  1.6087e-01, -1.7260e-01, -2.6019e-01,  2.3251e-01,\n         1.3905e-01,  1.3324e-01,  2.6815e-01, -2.5853e-01,  3.4527e-04,\n         3.2906e-01,  2.0397e-01,  7.6319e-02, -7.4678e-03, -1.1961e-01,\n         3.2060e-01,  2.7961e-01,  1.2481e-01, -1.3108e-01,  8.1911e-02,\n         2.9283e-01,  9.7922e-03,  9.8368e-02,  1.0776e-01, -2.4720e-02,\n        -1.0340e-01, -8.1260e-02, -8.7639e-02, -6.9470e-03, -2.2686e-01,\n        -1.9711e-01, -1.5583e-01, -2.1070e-01,  2.4864e-02, -1.2832e-01,\n        -3.0279e-01,  3.0473e-01,  2.2021e-01, -1.9995e-01, -3.1396e-01,\n        -1.8819e-01, -1.2242e-01,  2.4863e-01,  2.8643e-01,  1.1186e-01,\n         3.2468e-01,  1.4923e-01,  2.4477e-02,  2.1549e-01, -2.2933e-02,\n         1.5122e-01,  1.7906e-01,  8.8181e-02, -2.2013e-01, -2.8988e-01,\n         8.8596e-03, -1.3688e-01,  2.6394e-01, -3.4097e-01, -1.6517e-01,\n        -5.3427e-02, -1.8141e-01,  3.2772e-01,  8.8196e-02,  2.4445e-01,\n         5.8651e-02,  3.2796e-01,  2.2758e-01, -2.4177e-01,  1.1459e-01,\n        -3.0891e-02, -2.1479e-01,  1.7011e-01, -2.1615e-01, -2.1190e-01,\n        -1.9146e-01,  1.0358e-01,  2.9152e-01,  1.1159e-01, -1.0924e-01,\n        -2.6240e-02, -9.6119e-02,  2.7169e-01,  1.6973e-01,  2.3927e-01,\n         3.3546e-01,  1.0952e-01, -5.6399e-02,  1.3980e-01, -7.2233e-02,\n        -3.0502e-02, -3.1697e-02,  1.9971e-01,  2.0969e-01, -2.1822e-01,\n        -1.4711e-01,  9.3783e-02, -3.7185e-02,  1.7855e-01, -3.5206e-01,\n         3.3335e-01,  1.9633e-01, -2.9914e-01,  1.8812e-01,  1.3352e-01,\n         6.7935e-02, -1.7418e-01,  2.6814e-01,  1.3565e-01, -2.2913e-01],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2077,  0.3107,  0.3021,  ...,  0.1196,  0.3210,  0.3386],\n        [-0.3285,  0.0187, -0.3483,  ...,  0.1302, -0.1535, -0.2235],\n        [ 0.3136, -0.1538, -0.2537,  ...,  0.0066,  0.1387, -0.2423],\n        ...,\n        [-0.2798, -0.3503, -0.1843,  ..., -0.2176,  0.0633, -0.1385],\n        [-0.1188,  0.0530, -0.0073,  ...,  0.2256, -0.2232, -0.2681],\n        [-0.1987, -0.2680, -0.1910,  ...,  0.3458, -0.3140,  0.0769]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 4.6582e-02, -1.3973e-02,  4.9545e-02, -5.9337e-03, -3.6485e-03,\n        -3.6045e-02, -1.5522e-03,  4.4123e-02,  4.2590e-02, -3.4484e-02,\n         2.5590e-02, -1.3789e-02,  1.2637e-02,  3.6629e-02, -3.0676e-02,\n        -1.4680e-02, -3.9118e-02, -1.7224e-02,  3.4585e-02, -4.8581e-02,\n         4.9192e-02,  5.9606e-03, -3.1900e-02,  3.9788e-02, -7.2440e-03,\n         4.2748e-02, -5.4832e-03, -1.5227e-02,  1.0880e-02, -4.4874e-02,\n        -3.2010e-02,  1.6386e-02, -2.6189e-02,  2.9266e-02,  3.2018e-02,\n        -7.7361e-03,  4.2596e-02,  4.6289e-04, -6.1412e-04,  2.9180e-02,\n        -1.9150e-03,  2.4632e-02, -4.7883e-02, -2.4249e-02, -4.0790e-03,\n        -4.2915e-02, -2.5055e-02, -2.9957e-02, -3.3152e-03, -1.1512e-02,\n        -3.6228e-02, -1.1575e-02,  9.5361e-05, -3.0884e-02,  1.1900e-02,\n        -2.7291e-03, -3.9088e-02, -2.5047e-02, -3.7544e-02, -1.7797e-03,\n        -5.8855e-04,  3.0742e-02,  3.2296e-02,  4.1757e-02,  2.3021e-02,\n        -2.3180e-02,  3.2755e-02, -4.8342e-02, -2.1447e-02, -9.5391e-03,\n        -4.6721e-02, -1.2673e-03,  3.8634e-03, -1.3906e-02, -4.8128e-02,\n        -1.7085e-02, -4.0475e-02,  1.1544e-02,  2.8752e-02,  4.1605e-02,\n        -1.6230e-02, -3.4843e-02, -4.0176e-02,  1.9823e-02, -5.0892e-03,\n        -4.0753e-03,  5.0341e-03,  1.2913e-02, -1.8177e-03, -2.4967e-02,\n         4.7067e-02, -1.8532e-02,  1.7667e-02,  3.1410e-02, -4.6014e-02,\n        -1.1904e-02, -4.2887e-02, -1.7541e-02, -4.1720e-02,  3.5400e-02,\n        -3.8523e-02, -3.0776e-02, -6.3344e-03, -2.9821e-02, -7.2355e-03,\n        -3.1791e-02,  2.9244e-02, -3.1739e-02, -2.3092e-02,  4.0542e-03,\n         2.8093e-02, -1.7695e-02, -4.7213e-02, -8.5833e-03,  3.9221e-02,\n        -1.5642e-02,  4.5442e-02,  1.8187e-02,  3.5212e-02,  3.2097e-02,\n         4.3166e-02,  3.2171e-02,  1.1328e-02,  3.6720e-03, -4.9028e-02,\n         2.8642e-02,  2.7291e-02, -3.0460e-02, -1.2633e-02,  4.9531e-02,\n        -8.8450e-03,  4.8224e-02, -4.8008e-02, -4.0300e-02, -3.0598e-02,\n         1.1663e-02, -4.9321e-02, -2.4264e-02, -1.7991e-02,  5.2577e-04,\n        -4.3330e-02,  3.6589e-02, -3.1825e-02, -3.0370e-02,  8.6017e-03,\n         2.6167e-02, -1.5415e-03, -1.1337e-02,  4.3051e-02,  1.6929e-02,\n        -3.7413e-02,  4.4898e-02,  2.0555e-02, -4.0521e-02, -9.4569e-03,\n        -2.8433e-02, -1.6784e-02,  2.8896e-02,  1.4673e-03,  4.8458e-02,\n         1.7003e-02, -3.0628e-02, -1.1250e-02,  2.6184e-03, -4.0709e-02,\n         4.9276e-02, -4.1236e-02,  7.7563e-04, -4.8427e-02, -4.3295e-02,\n        -6.2459e-03, -2.7601e-03,  2.5277e-02,  2.1733e-03, -3.0821e-02,\n        -1.7443e-03, -1.4333e-03,  3.3035e-03,  2.8861e-04, -5.4651e-03,\n         4.5167e-02,  2.2986e-03, -2.3004e-02, -4.8280e-02,  3.1836e-02,\n        -3.9486e-03, -2.8705e-02, -6.7106e-03, -1.6773e-02, -3.6560e-02,\n         2.9089e-02,  5.3480e-03, -4.3125e-02, -3.1048e-02,  3.6518e-02,\n        -1.7489e-02,  3.6463e-03, -1.5681e-02, -3.1425e-02,  1.7990e-02,\n         3.8944e-02,  1.5872e-02, -3.3574e-02, -2.7199e-02, -9.0737e-03,\n         4.0531e-03,  4.3010e-02, -1.8614e-02, -3.7660e-02,  4.2386e-02,\n        -1.5218e-02,  4.2274e-02,  1.8713e-02, -1.3143e-02, -4.3980e-02,\n         1.3828e-05,  2.2606e-02,  4.4885e-02, -3.6572e-02, -2.5337e-02,\n        -1.9194e-02,  1.6877e-02, -4.5033e-02, -3.0968e-02,  4.6804e-02,\n        -3.5294e-02, -1.3512e-03,  1.3199e-02,  2.3380e-02, -1.3547e-02,\n        -4.2769e-02, -1.4850e-02, -3.0186e-02,  4.4095e-02, -1.5127e-02,\n        -2.2442e-02,  2.5187e-02,  1.4335e-03, -4.4806e-03,  4.1990e-02,\n         1.8593e-02, -1.8484e-02, -1.5633e-02, -1.9007e-02, -9.5980e-03,\n         9.9189e-03,  9.0304e-03, -4.0011e-02, -5.0736e-03,  4.1037e-02,\n         3.1828e-02,  2.8783e-02, -2.5859e-02, -2.0834e-02,  3.5230e-02,\n        -3.1199e-02,  3.5671e-02,  2.1437e-02,  1.8316e-02,  1.3140e-02,\n        -2.6511e-02,  3.4132e-02, -2.0282e-02, -2.9850e-02,  1.5597e-02,\n         7.5693e-03,  2.0290e-02,  5.9289e-03, -3.7229e-02, -3.9146e-02,\n        -1.2546e-02, -2.2513e-02,  2.8483e-02,  3.7651e-02, -1.3143e-02,\n         8.7629e-03,  3.2939e-02,  4.2185e-02,  4.4166e-02,  1.9343e-02,\n        -2.9037e-02, -7.8762e-03, -1.7264e-02,  3.4254e-02,  3.9638e-02,\n         2.9914e-02,  9.8539e-03,  4.8139e-02,  4.4565e-02, -4.7567e-02,\n        -1.9319e-02, -4.0278e-02, -3.0754e-02, -1.6163e-02, -3.5593e-02,\n        -4.9492e-02, -2.2784e-02, -1.2953e-03, -3.5105e-02, -4.9666e-02],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0124, -0.0037,  0.0070,  ...,  0.0011, -0.0498, -0.0114],\n        [-0.0128, -0.0407,  0.0099,  ...,  0.0082,  0.0113,  0.0088],\n        [-0.0066,  0.0068, -0.0302,  ...,  0.0004,  0.0049, -0.0048],\n        ...,\n        [-0.0408,  0.0192, -0.0130,  ...,  0.0241,  0.0251,  0.0320],\n        [-0.0376,  0.0356,  0.0190,  ...,  0.0341, -0.0403, -0.0061],\n        [-0.0482, -0.0125,  0.0388,  ...,  0.0060, -0.0196,  0.0299]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([0.0070, 0.0333, 0.0534, 0.0546], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0427,  0.0342, -0.0355,  ...,  0.0342,  0.0258, -0.0011],\n        [ 0.0089,  0.0058,  0.0289,  ...,  0.0330, -0.0516,  0.0343],\n        [ 0.0336,  0.0204,  0.0224,  ...,  0.0167, -0.0320,  0.0069],\n        [ 0.0171, -0.0215,  0.0425,  ..., -0.0251,  0.0530,  0.0289]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2077,  0.3107,  0.3021,  ...,  0.1196,  0.3210,  0.3386],\n        [-0.3285,  0.0187, -0.3483,  ...,  0.1302, -0.1535, -0.2235],\n        [ 0.3136, -0.1538, -0.2537,  ...,  0.0066,  0.1387, -0.2423],\n        ...,\n        [-0.2798, -0.3503, -0.1843,  ..., -0.2176,  0.0633, -0.1385],\n        [-0.1188,  0.0530, -0.0073,  ...,  0.2256, -0.2232, -0.2681],\n        [-0.1987, -0.2680, -0.1910,  ...,  0.3458, -0.3140,  0.0769]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 3.1424e-01, -2.9299e-01, -2.6561e-01,  2.7308e-01,  3.3502e-01,\n        -2.1068e-01,  1.8233e-01, -3.4753e-01, -2.1770e-01,  2.0177e-02,\n         1.4835e-01,  2.5856e-01, -9.8618e-02,  9.0789e-02, -2.6080e-02,\n        -3.3170e-02,  3.4954e-01,  3.1879e-01, -2.7288e-01, -3.1261e-01,\n         2.2854e-01, -3.4260e-01, -3.0635e-01, -6.0976e-02,  1.8639e-01,\n        -2.4452e-01,  2.3466e-01, -6.3190e-02, -2.0867e-01, -2.2811e-01,\n        -2.5017e-01, -2.4520e-02,  1.2897e-01,  2.4654e-01,  5.2946e-03,\n        -2.2895e-01, -1.3430e-02,  4.5341e-02, -2.8903e-01,  2.1277e-01,\n        -2.8415e-02, -3.4493e-01, -2.6895e-02,  1.9180e-01, -3.0721e-01,\n         1.2351e-01, -9.7314e-02, -1.1539e-01,  2.7875e-01,  1.9668e-01,\n        -5.0362e-02, -1.5353e-01,  1.4041e-01, -2.1582e-01, -1.2540e-01,\n        -1.7614e-03,  2.7033e-01,  1.4577e-01, -3.5106e-01,  1.7466e-01,\n        -2.6872e-01, -2.0906e-01, -2.1881e-01, -8.4999e-02, -2.2419e-01,\n         3.4014e-01,  1.5662e-01,  1.5062e-02,  3.5342e-01, -2.7638e-01,\n        -9.7310e-03,  1.5275e-01, -4.1576e-02, -1.5529e-01, -2.2849e-01,\n        -2.8487e-02, -4.5341e-02,  2.9316e-01, -1.4627e-01,  5.5386e-02,\n        -1.6610e-01,  2.4107e-01, -5.2409e-02, -3.1294e-02, -1.5872e-01,\n         1.6524e-01, -7.8958e-02, -3.2932e-01, -3.3595e-02,  2.9356e-01,\n         2.8908e-02, -1.8337e-01,  1.5397e-01, -2.7468e-01, -2.1899e-01,\n         2.7018e-01,  1.3544e-01, -2.9642e-01,  1.2129e-01, -2.0365e-01,\n        -2.0059e-01,  3.0542e-01,  6.4529e-02,  6.1609e-03,  3.0419e-02,\n         5.0107e-02, -1.7201e-01, -2.0558e-01,  8.7942e-02, -2.4759e-01,\n         2.1005e-01, -5.8628e-02,  2.6724e-01,  1.7471e-01,  1.0576e-01,\n         6.2272e-02,  2.2837e-01,  1.5729e-01, -1.1195e-01,  2.7189e-01,\n        -1.4186e-01,  1.7579e-02,  1.7516e-01,  3.0425e-01,  1.3822e-01,\n        -8.9519e-02,  3.0152e-01, -2.1572e-01, -2.8806e-01, -1.0070e-01,\n        -1.3240e-02,  7.9934e-02, -9.1210e-04,  2.4697e-01, -1.6086e-01,\n         7.8346e-02, -3.1499e-01, -9.2410e-02, -3.8152e-03, -2.1124e-01,\n        -1.6741e-01, -3.0142e-01,  3.5272e-01,  2.9870e-01,  7.8302e-02,\n        -2.6408e-01,  2.3208e-01, -2.2920e-02, -1.7554e-01,  2.1970e-01,\n        -2.0541e-02, -1.3373e-01,  8.4448e-02, -3.1756e-01,  2.6627e-01,\n        -2.5526e-01,  3.4972e-01,  5.7419e-02, -3.3606e-01, -1.4449e-01,\n         1.0242e-01, -1.9061e-01, -2.0911e-01, -3.6249e-02,  3.1826e-01,\n        -3.5299e-02,  1.6632e-02,  1.8320e-01,  5.0181e-02, -2.8789e-01,\n         7.1057e-02, -3.2185e-01,  1.2362e-01, -2.4925e-01,  6.9953e-02,\n        -2.7760e-01,  2.9624e-01, -6.5882e-02, -3.0441e-01,  3.3408e-02,\n        -1.9226e-01, -3.4524e-01, -1.3493e-01,  6.6577e-02, -3.7229e-02,\n         3.2293e-01, -2.0474e-02,  1.1252e-02, -3.0007e-01, -1.2708e-01,\n        -6.0158e-02, -1.1101e-01, -2.9569e-02, -1.2744e-01, -3.1296e-01,\n        -3.4118e-01,  2.4362e-01,  3.4350e-01, -2.5764e-01, -2.8600e-01,\n         3.3893e-01,  2.1233e-01,  1.4116e-01, -2.0125e-01,  7.8825e-03,\n        -1.9123e-02,  2.6520e-01, -3.0374e-01,  2.9025e-01,  1.0764e-01,\n        -2.7940e-01, -3.4656e-01,  3.0278e-01,  1.1207e-02,  3.6160e-02,\n        -2.6633e-01, -3.5343e-01,  6.5460e-02,  2.4982e-01,  8.0212e-02,\n        -1.0792e-01, -6.1982e-03, -4.6362e-06,  9.8417e-02,  1.0247e-01,\n        -2.8183e-02,  1.2473e-01,  1.2366e-01,  5.4273e-02, -1.4932e-01,\n         1.3439e-01,  2.5566e-01,  2.6622e-01,  5.3133e-03,  3.0029e-02,\n        -1.8740e-01,  6.4758e-02, -2.8537e-01, -1.0347e-01, -1.8569e-01,\n         3.3125e-01, -9.4403e-02,  1.2778e-01, -1.6326e-01,  2.3271e-01,\n        -3.4900e-01,  5.9675e-02,  3.2841e-01, -2.1088e-01, -3.3248e-01,\n        -1.6899e-01,  5.8792e-02,  6.7072e-02, -2.8996e-01, -1.3234e-01,\n         3.4022e-01,  1.8812e-01,  1.1002e-01, -3.2085e-02,  1.0023e-01,\n        -3.3868e-01,  1.7390e-01,  1.3698e-01,  2.0212e-02,  3.4815e-01,\n        -1.0738e-01, -1.2323e-01,  2.0325e-01, -3.1716e-01, -1.2838e-01,\n        -2.2690e-01,  1.1727e-01, -5.2998e-02, -1.4928e-01,  1.2912e-01,\n         9.0489e-02, -1.6150e-01, -1.1165e-01, -2.9473e-01, -4.5291e-02,\n        -1.8295e-01, -2.5056e-01, -1.8513e-01, -1.8286e-01, -6.5019e-02,\n        -3.0385e-02,  3.5249e-01,  2.4950e-01, -1.7473e-01, -2.4997e-01,\n        -3.3681e-02,  1.6087e-01, -1.7260e-01, -2.6019e-01,  2.3251e-01,\n         1.3905e-01,  1.3324e-01,  2.6815e-01, -2.5853e-01,  3.4527e-04,\n         3.2906e-01,  2.0397e-01,  7.6319e-02, -7.4678e-03, -1.1961e-01,\n         3.2060e-01,  2.7961e-01,  1.2481e-01, -1.3108e-01,  8.1911e-02,\n         2.9283e-01,  9.7922e-03,  9.8368e-02,  1.0776e-01, -2.4720e-02,\n        -1.0340e-01, -8.1260e-02, -8.7639e-02, -6.9470e-03, -2.2686e-01,\n        -1.9711e-01, -1.5583e-01, -2.1070e-01,  2.4864e-02, -1.2832e-01,\n        -3.0279e-01,  3.0473e-01,  2.2021e-01, -1.9995e-01, -3.1396e-01,\n        -1.8819e-01, -1.2242e-01,  2.4863e-01,  2.8643e-01,  1.1186e-01,\n         3.2468e-01,  1.4923e-01,  2.4477e-02,  2.1549e-01, -2.2933e-02,\n         1.5122e-01,  1.7906e-01,  8.8181e-02, -2.2013e-01, -2.8988e-01,\n         8.8596e-03, -1.3688e-01,  2.6394e-01, -3.4097e-01, -1.6517e-01,\n        -5.3427e-02, -1.8141e-01,  3.2772e-01,  8.8196e-02,  2.4445e-01,\n         5.8651e-02,  3.2796e-01,  2.2758e-01, -2.4177e-01,  1.1459e-01,\n        -3.0891e-02, -2.1479e-01,  1.7011e-01, -2.1615e-01, -2.1190e-01,\n        -1.9146e-01,  1.0358e-01,  2.9152e-01,  1.1159e-01, -1.0924e-01,\n        -2.6240e-02, -9.6119e-02,  2.7169e-01,  1.6973e-01,  2.3927e-01,\n         3.3546e-01,  1.0952e-01, -5.6399e-02,  1.3980e-01, -7.2233e-02,\n        -3.0502e-02, -3.1697e-02,  1.9971e-01,  2.0969e-01, -2.1822e-01,\n        -1.4711e-01,  9.3783e-02, -3.7185e-02,  1.7855e-01, -3.5206e-01,\n         3.3335e-01,  1.9633e-01, -2.9914e-01,  1.8812e-01,  1.3352e-01,\n         6.7935e-02, -1.7418e-01,  2.6814e-01,  1.3565e-01, -2.2913e-01],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0124, -0.0037,  0.0070,  ...,  0.0011, -0.0498, -0.0114],\n        [-0.0128, -0.0407,  0.0099,  ...,  0.0082,  0.0113,  0.0088],\n        [-0.0066,  0.0068, -0.0302,  ...,  0.0004,  0.0049, -0.0048],\n        ...,\n        [-0.0408,  0.0192, -0.0130,  ...,  0.0241,  0.0251,  0.0320],\n        [-0.0376,  0.0356,  0.0190,  ...,  0.0341, -0.0403, -0.0061],\n        [-0.0482, -0.0125,  0.0388,  ...,  0.0060, -0.0196,  0.0299]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 4.6582e-02, -1.3973e-02,  4.9545e-02, -5.9337e-03, -3.6485e-03,\n        -3.6045e-02, -1.5522e-03,  4.4123e-02,  4.2590e-02, -3.4484e-02,\n         2.5590e-02, -1.3789e-02,  1.2637e-02,  3.6629e-02, -3.0676e-02,\n        -1.4680e-02, -3.9118e-02, -1.7224e-02,  3.4585e-02, -4.8581e-02,\n         4.9192e-02,  5.9606e-03, -3.1900e-02,  3.9788e-02, -7.2440e-03,\n         4.2748e-02, -5.4832e-03, -1.5227e-02,  1.0880e-02, -4.4874e-02,\n        -3.2010e-02,  1.6386e-02, -2.6189e-02,  2.9266e-02,  3.2018e-02,\n        -7.7361e-03,  4.2596e-02,  4.6289e-04, -6.1412e-04,  2.9180e-02,\n        -1.9150e-03,  2.4632e-02, -4.7883e-02, -2.4249e-02, -4.0790e-03,\n        -4.2915e-02, -2.5055e-02, -2.9957e-02, -3.3152e-03, -1.1512e-02,\n        -3.6228e-02, -1.1575e-02,  9.5361e-05, -3.0884e-02,  1.1900e-02,\n        -2.7291e-03, -3.9088e-02, -2.5047e-02, -3.7544e-02, -1.7797e-03,\n        -5.8855e-04,  3.0742e-02,  3.2296e-02,  4.1757e-02,  2.3021e-02,\n        -2.3180e-02,  3.2755e-02, -4.8342e-02, -2.1447e-02, -9.5391e-03,\n        -4.6721e-02, -1.2673e-03,  3.8634e-03, -1.3906e-02, -4.8128e-02,\n        -1.7085e-02, -4.0475e-02,  1.1544e-02,  2.8752e-02,  4.1605e-02,\n        -1.6230e-02, -3.4843e-02, -4.0176e-02,  1.9823e-02, -5.0892e-03,\n        -4.0753e-03,  5.0341e-03,  1.2913e-02, -1.8177e-03, -2.4967e-02,\n         4.7067e-02, -1.8532e-02,  1.7667e-02,  3.1410e-02, -4.6014e-02,\n        -1.1904e-02, -4.2887e-02, -1.7541e-02, -4.1720e-02,  3.5400e-02,\n        -3.8523e-02, -3.0776e-02, -6.3344e-03, -2.9821e-02, -7.2355e-03,\n        -3.1791e-02,  2.9244e-02, -3.1739e-02, -2.3092e-02,  4.0542e-03,\n         2.8093e-02, -1.7695e-02, -4.7213e-02, -8.5833e-03,  3.9221e-02,\n        -1.5642e-02,  4.5442e-02,  1.8187e-02,  3.5212e-02,  3.2097e-02,\n         4.3166e-02,  3.2171e-02,  1.1328e-02,  3.6720e-03, -4.9028e-02,\n         2.8642e-02,  2.7291e-02, -3.0460e-02, -1.2633e-02,  4.9531e-02,\n        -8.8450e-03,  4.8224e-02, -4.8008e-02, -4.0300e-02, -3.0598e-02,\n         1.1663e-02, -4.9321e-02, -2.4264e-02, -1.7991e-02,  5.2577e-04,\n        -4.3330e-02,  3.6589e-02, -3.1825e-02, -3.0370e-02,  8.6017e-03,\n         2.6167e-02, -1.5415e-03, -1.1337e-02,  4.3051e-02,  1.6929e-02,\n        -3.7413e-02,  4.4898e-02,  2.0555e-02, -4.0521e-02, -9.4569e-03,\n        -2.8433e-02, -1.6784e-02,  2.8896e-02,  1.4673e-03,  4.8458e-02,\n         1.7003e-02, -3.0628e-02, -1.1250e-02,  2.6184e-03, -4.0709e-02,\n         4.9276e-02, -4.1236e-02,  7.7563e-04, -4.8427e-02, -4.3295e-02,\n        -6.2459e-03, -2.7601e-03,  2.5277e-02,  2.1733e-03, -3.0821e-02,\n        -1.7443e-03, -1.4333e-03,  3.3035e-03,  2.8861e-04, -5.4651e-03,\n         4.5167e-02,  2.2986e-03, -2.3004e-02, -4.8280e-02,  3.1836e-02,\n        -3.9486e-03, -2.8705e-02, -6.7106e-03, -1.6773e-02, -3.6560e-02,\n         2.9089e-02,  5.3480e-03, -4.3125e-02, -3.1048e-02,  3.6518e-02,\n        -1.7489e-02,  3.6463e-03, -1.5681e-02, -3.1425e-02,  1.7990e-02,\n         3.8944e-02,  1.5872e-02, -3.3574e-02, -2.7199e-02, -9.0737e-03,\n         4.0531e-03,  4.3010e-02, -1.8614e-02, -3.7660e-02,  4.2386e-02,\n        -1.5218e-02,  4.2274e-02,  1.8713e-02, -1.3143e-02, -4.3980e-02,\n         1.3828e-05,  2.2606e-02,  4.4885e-02, -3.6572e-02, -2.5337e-02,\n        -1.9194e-02,  1.6877e-02, -4.5033e-02, -3.0968e-02,  4.6804e-02,\n        -3.5294e-02, -1.3512e-03,  1.3199e-02,  2.3380e-02, -1.3547e-02,\n        -4.2769e-02, -1.4850e-02, -3.0186e-02,  4.4095e-02, -1.5127e-02,\n        -2.2442e-02,  2.5187e-02,  1.4335e-03, -4.4806e-03,  4.1990e-02,\n         1.8593e-02, -1.8484e-02, -1.5633e-02, -1.9007e-02, -9.5980e-03,\n         9.9189e-03,  9.0304e-03, -4.0011e-02, -5.0736e-03,  4.1037e-02,\n         3.1828e-02,  2.8783e-02, -2.5859e-02, -2.0834e-02,  3.5230e-02,\n        -3.1199e-02,  3.5671e-02,  2.1437e-02,  1.8316e-02,  1.3140e-02,\n        -2.6511e-02,  3.4132e-02, -2.0282e-02, -2.9850e-02,  1.5597e-02,\n         7.5693e-03,  2.0290e-02,  5.9289e-03, -3.7229e-02, -3.9146e-02,\n        -1.2546e-02, -2.2513e-02,  2.8483e-02,  3.7651e-02, -1.3143e-02,\n         8.7629e-03,  3.2939e-02,  4.2185e-02,  4.4166e-02,  1.9343e-02,\n        -2.9037e-02, -7.8762e-03, -1.7264e-02,  3.4254e-02,  3.9638e-02,\n         2.9914e-02,  9.8539e-03,  4.8139e-02,  4.4565e-02, -4.7567e-02,\n        -1.9319e-02, -4.0278e-02, -3.0754e-02, -1.6163e-02, -3.5593e-02,\n        -4.9492e-02, -2.2784e-02, -1.2953e-03, -3.5105e-02, -4.9666e-02],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0427,  0.0342, -0.0355,  ...,  0.0342,  0.0258, -0.0011],\n        [ 0.0089,  0.0058,  0.0289,  ...,  0.0330, -0.0516,  0.0343],\n        [ 0.0336,  0.0204,  0.0224,  ...,  0.0167, -0.0320,  0.0069],\n        [ 0.0171, -0.0215,  0.0425,  ..., -0.0251,  0.0530,  0.0289]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0070, 0.0333, 0.0534, 0.0546], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7c643df69290>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=400, bias=True)\n  (fc2): Linear(in_features=400, out_features=300, bias=True)\n  (fc3): Linear(in_features=300, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.01,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=400, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 3.1424e-01, -2.9299e-01, -2.6561e-01,  2.7308e-01,  3.3502e-01,\n        -2.1068e-01,  1.8233e-01, -3.4753e-01, -2.1770e-01,  2.0177e-02,\n         1.4835e-01,  2.5856e-01, -9.8618e-02,  9.0789e-02, -2.6080e-02,\n        -3.3170e-02,  3.4954e-01,  3.1879e-01, -2.7288e-01, -3.1261e-01,\n         2.2854e-01, -3.4260e-01, -3.0635e-01, -6.0976e-02,  1.8639e-01,\n        -2.4452e-01,  2.3466e-01, -6.3190e-02, -2.0867e-01, -2.2811e-01,\n        -2.5017e-01, -2.4520e-02,  1.2897e-01,  2.4654e-01,  5.2946e-03,\n        -2.2895e-01, -1.3430e-02,  4.5341e-02, -2.8903e-01,  2.1277e-01,\n        -2.8415e-02, -3.4493e-01, -2.6895e-02,  1.9180e-01, -3.0721e-01,\n         1.2351e-01, -9.7314e-02, -1.1539e-01,  2.7875e-01,  1.9668e-01,\n        -5.0362e-02, -1.5353e-01,  1.4041e-01, -2.1582e-01, -1.2540e-01,\n        -1.7614e-03,  2.7033e-01,  1.4577e-01, -3.5106e-01,  1.7466e-01,\n        -2.6872e-01, -2.0906e-01, -2.1881e-01, -8.4999e-02, -2.2419e-01,\n         3.4014e-01,  1.5662e-01,  1.5062e-02,  3.5342e-01, -2.7638e-01,\n        -9.7310e-03,  1.5275e-01, -4.1576e-02, -1.5529e-01, -2.2849e-01,\n        -2.8487e-02, -4.5341e-02,  2.9316e-01, -1.4627e-01,  5.5386e-02,\n        -1.6610e-01,  2.4107e-01, -5.2409e-02, -3.1294e-02, -1.5872e-01,\n         1.6524e-01, -7.8958e-02, -3.2932e-01, -3.3595e-02,  2.9356e-01,\n         2.8908e-02, -1.8337e-01,  1.5397e-01, -2.7468e-01, -2.1899e-01,\n         2.7018e-01,  1.3544e-01, -2.9642e-01,  1.2129e-01, -2.0365e-01,\n        -2.0059e-01,  3.0542e-01,  6.4529e-02,  6.1609e-03,  3.0419e-02,\n         5.0107e-02, -1.7201e-01, -2.0558e-01,  8.7942e-02, -2.4759e-01,\n         2.1005e-01, -5.8628e-02,  2.6724e-01,  1.7471e-01,  1.0576e-01,\n         6.2272e-02,  2.2837e-01,  1.5729e-01, -1.1195e-01,  2.7189e-01,\n        -1.4186e-01,  1.7579e-02,  1.7516e-01,  3.0425e-01,  1.3822e-01,\n        -8.9519e-02,  3.0152e-01, -2.1572e-01, -2.8806e-01, -1.0070e-01,\n        -1.3240e-02,  7.9934e-02, -9.1210e-04,  2.4697e-01, -1.6086e-01,\n         7.8346e-02, -3.1499e-01, -9.2410e-02, -3.8152e-03, -2.1124e-01,\n        -1.6741e-01, -3.0142e-01,  3.5272e-01,  2.9870e-01,  7.8302e-02,\n        -2.6408e-01,  2.3208e-01, -2.2920e-02, -1.7554e-01,  2.1970e-01,\n        -2.0541e-02, -1.3373e-01,  8.4448e-02, -3.1756e-01,  2.6627e-01,\n        -2.5526e-01,  3.4972e-01,  5.7419e-02, -3.3606e-01, -1.4449e-01,\n         1.0242e-01, -1.9061e-01, -2.0911e-01, -3.6249e-02,  3.1826e-01,\n        -3.5299e-02,  1.6632e-02,  1.8320e-01,  5.0181e-02, -2.8789e-01,\n         7.1057e-02, -3.2185e-01,  1.2362e-01, -2.4925e-01,  6.9953e-02,\n        -2.7760e-01,  2.9624e-01, -6.5882e-02, -3.0441e-01,  3.3408e-02,\n        -1.9226e-01, -3.4524e-01, -1.3493e-01,  6.6577e-02, -3.7229e-02,\n         3.2293e-01, -2.0474e-02,  1.1252e-02, -3.0007e-01, -1.2708e-01,\n        -6.0158e-02, -1.1101e-01, -2.9569e-02, -1.2744e-01, -3.1296e-01,\n        -3.4118e-01,  2.4362e-01,  3.4350e-01, -2.5764e-01, -2.8600e-01,\n         3.3893e-01,  2.1233e-01,  1.4116e-01, -2.0125e-01,  7.8825e-03,\n        -1.9123e-02,  2.6520e-01, -3.0374e-01,  2.9025e-01,  1.0764e-01,\n        -2.7940e-01, -3.4656e-01,  3.0278e-01,  1.1207e-02,  3.6160e-02,\n        -2.6633e-01, -3.5343e-01,  6.5460e-02,  2.4982e-01,  8.0212e-02,\n        -1.0792e-01, -6.1982e-03, -4.6362e-06,  9.8417e-02,  1.0247e-01,\n        -2.8183e-02,  1.2473e-01,  1.2366e-01,  5.4273e-02, -1.4932e-01,\n         1.3439e-01,  2.5566e-01,  2.6622e-01,  5.3133e-03,  3.0029e-02,\n        -1.8740e-01,  6.4758e-02, -2.8537e-01, -1.0347e-01, -1.8569e-01,\n         3.3125e-01, -9.4403e-02,  1.2778e-01, -1.6326e-01,  2.3271e-01,\n        -3.4900e-01,  5.9675e-02,  3.2841e-01, -2.1088e-01, -3.3248e-01,\n        -1.6899e-01,  5.8792e-02,  6.7072e-02, -2.8996e-01, -1.3234e-01,\n         3.4022e-01,  1.8812e-01,  1.1002e-01, -3.2085e-02,  1.0023e-01,\n        -3.3868e-01,  1.7390e-01,  1.3698e-01,  2.0212e-02,  3.4815e-01,\n        -1.0738e-01, -1.2323e-01,  2.0325e-01, -3.1716e-01, -1.2838e-01,\n        -2.2690e-01,  1.1727e-01, -5.2998e-02, -1.4928e-01,  1.2912e-01,\n         9.0489e-02, -1.6150e-01, -1.1165e-01, -2.9473e-01, -4.5291e-02,\n        -1.8295e-01, -2.5056e-01, -1.8513e-01, -1.8286e-01, -6.5019e-02,\n        -3.0385e-02,  3.5249e-01,  2.4950e-01, -1.7473e-01, -2.4997e-01,\n        -3.3681e-02,  1.6087e-01, -1.7260e-01, -2.6019e-01,  2.3251e-01,\n         1.3905e-01,  1.3324e-01,  2.6815e-01, -2.5853e-01,  3.4527e-04,\n         3.2906e-01,  2.0397e-01,  7.6319e-02, -7.4678e-03, -1.1961e-01,\n         3.2060e-01,  2.7961e-01,  1.2481e-01, -1.3108e-01,  8.1911e-02,\n         2.9283e-01,  9.7922e-03,  9.8368e-02,  1.0776e-01, -2.4720e-02,\n        -1.0340e-01, -8.1260e-02, -8.7639e-02, -6.9470e-03, -2.2686e-01,\n        -1.9711e-01, -1.5583e-01, -2.1070e-01,  2.4864e-02, -1.2832e-01,\n        -3.0279e-01,  3.0473e-01,  2.2021e-01, -1.9995e-01, -3.1396e-01,\n        -1.8819e-01, -1.2242e-01,  2.4863e-01,  2.8643e-01,  1.1186e-01,\n         3.2468e-01,  1.4923e-01,  2.4477e-02,  2.1549e-01, -2.2933e-02,\n         1.5122e-01,  1.7906e-01,  8.8181e-02, -2.2013e-01, -2.8988e-01,\n         8.8596e-03, -1.3688e-01,  2.6394e-01, -3.4097e-01, -1.6517e-01,\n        -5.3427e-02, -1.8141e-01,  3.2772e-01,  8.8196e-02,  2.4445e-01,\n         5.8651e-02,  3.2796e-01,  2.2758e-01, -2.4177e-01,  1.1459e-01,\n        -3.0891e-02, -2.1479e-01,  1.7011e-01, -2.1615e-01, -2.1190e-01,\n        -1.9146e-01,  1.0358e-01,  2.9152e-01,  1.1159e-01, -1.0924e-01,\n        -2.6240e-02, -9.6119e-02,  2.7169e-01,  1.6973e-01,  2.3927e-01,\n         3.3546e-01,  1.0952e-01, -5.6399e-02,  1.3980e-01, -7.2233e-02,\n        -3.0502e-02, -3.1697e-02,  1.9971e-01,  2.0969e-01, -2.1822e-01,\n        -1.4711e-01,  9.3783e-02, -3.7185e-02,  1.7855e-01, -3.5206e-01,\n         3.3335e-01,  1.9633e-01, -2.9914e-01,  1.8812e-01,  1.3352e-01,\n         6.7935e-02, -1.7418e-01,  2.6814e-01,  1.3565e-01, -2.2913e-01],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2077,  0.3107,  0.3021,  ...,  0.1196,  0.3210,  0.3386],\n        [-0.3285,  0.0187, -0.3483,  ...,  0.1302, -0.1535, -0.2235],\n        [ 0.3136, -0.1538, -0.2537,  ...,  0.0066,  0.1387, -0.2423],\n        ...,\n        [-0.2798, -0.3503, -0.1843,  ..., -0.2176,  0.0633, -0.1385],\n        [-0.1188,  0.0530, -0.0073,  ...,  0.2256, -0.2232, -0.2681],\n        [-0.1987, -0.2680, -0.1910,  ...,  0.3458, -0.3140,  0.0769]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	400,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=400, out_features=300, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 4.6582e-02, -1.3973e-02,  4.9545e-02, -5.9337e-03, -3.6485e-03,\n        -3.6045e-02, -1.5522e-03,  4.4123e-02,  4.2590e-02, -3.4484e-02,\n         2.5590e-02, -1.3789e-02,  1.2637e-02,  3.6629e-02, -3.0676e-02,\n        -1.4680e-02, -3.9118e-02, -1.7224e-02,  3.4585e-02, -4.8581e-02,\n         4.9192e-02,  5.9606e-03, -3.1900e-02,  3.9788e-02, -7.2440e-03,\n         4.2748e-02, -5.4832e-03, -1.5227e-02,  1.0880e-02, -4.4874e-02,\n        -3.2010e-02,  1.6386e-02, -2.6189e-02,  2.9266e-02,  3.2018e-02,\n        -7.7361e-03,  4.2596e-02,  4.6289e-04, -6.1412e-04,  2.9180e-02,\n        -1.9150e-03,  2.4632e-02, -4.7883e-02, -2.4249e-02, -4.0790e-03,\n        -4.2915e-02, -2.5055e-02, -2.9957e-02, -3.3152e-03, -1.1512e-02,\n        -3.6228e-02, -1.1575e-02,  9.5361e-05, -3.0884e-02,  1.1900e-02,\n        -2.7291e-03, -3.9088e-02, -2.5047e-02, -3.7544e-02, -1.7797e-03,\n        -5.8855e-04,  3.0742e-02,  3.2296e-02,  4.1757e-02,  2.3021e-02,\n        -2.3180e-02,  3.2755e-02, -4.8342e-02, -2.1447e-02, -9.5391e-03,\n        -4.6721e-02, -1.2673e-03,  3.8634e-03, -1.3906e-02, -4.8128e-02,\n        -1.7085e-02, -4.0475e-02,  1.1544e-02,  2.8752e-02,  4.1605e-02,\n        -1.6230e-02, -3.4843e-02, -4.0176e-02,  1.9823e-02, -5.0892e-03,\n        -4.0753e-03,  5.0341e-03,  1.2913e-02, -1.8177e-03, -2.4967e-02,\n         4.7067e-02, -1.8532e-02,  1.7667e-02,  3.1410e-02, -4.6014e-02,\n        -1.1904e-02, -4.2887e-02, -1.7541e-02, -4.1720e-02,  3.5400e-02,\n        -3.8523e-02, -3.0776e-02, -6.3344e-03, -2.9821e-02, -7.2355e-03,\n        -3.1791e-02,  2.9244e-02, -3.1739e-02, -2.3092e-02,  4.0542e-03,\n         2.8093e-02, -1.7695e-02, -4.7213e-02, -8.5833e-03,  3.9221e-02,\n        -1.5642e-02,  4.5442e-02,  1.8187e-02,  3.5212e-02,  3.2097e-02,\n         4.3166e-02,  3.2171e-02,  1.1328e-02,  3.6720e-03, -4.9028e-02,\n         2.8642e-02,  2.7291e-02, -3.0460e-02, -1.2633e-02,  4.9531e-02,\n        -8.8450e-03,  4.8224e-02, -4.8008e-02, -4.0300e-02, -3.0598e-02,\n         1.1663e-02, -4.9321e-02, -2.4264e-02, -1.7991e-02,  5.2577e-04,\n        -4.3330e-02,  3.6589e-02, -3.1825e-02, -3.0370e-02,  8.6017e-03,\n         2.6167e-02, -1.5415e-03, -1.1337e-02,  4.3051e-02,  1.6929e-02,\n        -3.7413e-02,  4.4898e-02,  2.0555e-02, -4.0521e-02, -9.4569e-03,\n        -2.8433e-02, -1.6784e-02,  2.8896e-02,  1.4673e-03,  4.8458e-02,\n         1.7003e-02, -3.0628e-02, -1.1250e-02,  2.6184e-03, -4.0709e-02,\n         4.9276e-02, -4.1236e-02,  7.7563e-04, -4.8427e-02, -4.3295e-02,\n        -6.2459e-03, -2.7601e-03,  2.5277e-02,  2.1733e-03, -3.0821e-02,\n        -1.7443e-03, -1.4333e-03,  3.3035e-03,  2.8861e-04, -5.4651e-03,\n         4.5167e-02,  2.2986e-03, -2.3004e-02, -4.8280e-02,  3.1836e-02,\n        -3.9486e-03, -2.8705e-02, -6.7106e-03, -1.6773e-02, -3.6560e-02,\n         2.9089e-02,  5.3480e-03, -4.3125e-02, -3.1048e-02,  3.6518e-02,\n        -1.7489e-02,  3.6463e-03, -1.5681e-02, -3.1425e-02,  1.7990e-02,\n         3.8944e-02,  1.5872e-02, -3.3574e-02, -2.7199e-02, -9.0737e-03,\n         4.0531e-03,  4.3010e-02, -1.8614e-02, -3.7660e-02,  4.2386e-02,\n        -1.5218e-02,  4.2274e-02,  1.8713e-02, -1.3143e-02, -4.3980e-02,\n         1.3828e-05,  2.2606e-02,  4.4885e-02, -3.6572e-02, -2.5337e-02,\n        -1.9194e-02,  1.6877e-02, -4.5033e-02, -3.0968e-02,  4.6804e-02,\n        -3.5294e-02, -1.3512e-03,  1.3199e-02,  2.3380e-02, -1.3547e-02,\n        -4.2769e-02, -1.4850e-02, -3.0186e-02,  4.4095e-02, -1.5127e-02,\n        -2.2442e-02,  2.5187e-02,  1.4335e-03, -4.4806e-03,  4.1990e-02,\n         1.8593e-02, -1.8484e-02, -1.5633e-02, -1.9007e-02, -9.5980e-03,\n         9.9189e-03,  9.0304e-03, -4.0011e-02, -5.0736e-03,  4.1037e-02,\n         3.1828e-02,  2.8783e-02, -2.5859e-02, -2.0834e-02,  3.5230e-02,\n        -3.1199e-02,  3.5671e-02,  2.1437e-02,  1.8316e-02,  1.3140e-02,\n        -2.6511e-02,  3.4132e-02, -2.0282e-02, -2.9850e-02,  1.5597e-02,\n         7.5693e-03,  2.0290e-02,  5.9289e-03, -3.7229e-02, -3.9146e-02,\n        -1.2546e-02, -2.2513e-02,  2.8483e-02,  3.7651e-02, -1.3143e-02,\n         8.7629e-03,  3.2939e-02,  4.2185e-02,  4.4166e-02,  1.9343e-02,\n        -2.9037e-02, -7.8762e-03, -1.7264e-02,  3.4254e-02,  3.9638e-02,\n         2.9914e-02,  9.8539e-03,  4.8139e-02,  4.4565e-02, -4.7567e-02,\n        -1.9319e-02, -4.0278e-02, -3.0754e-02, -1.6163e-02, -3.5593e-02,\n        -4.9492e-02, -2.2784e-02, -1.2953e-03, -3.5105e-02, -4.9666e-02],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0124, -0.0037,  0.0070,  ...,  0.0011, -0.0498, -0.0114],\n        [-0.0128, -0.0407,  0.0099,  ...,  0.0082,  0.0113,  0.0088],\n        [-0.0066,  0.0068, -0.0302,  ...,  0.0004,  0.0049, -0.0048],\n        ...,\n        [-0.0408,  0.0192, -0.0130,  ...,  0.0241,  0.0251,  0.0320],\n        [-0.0376,  0.0356,  0.0190,  ...,  0.0341, -0.0403, -0.0061],\n        [-0.0482, -0.0125,  0.0388,  ...,  0.0060, -0.0196,  0.0299]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	400,
                                "out_features":	300,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=300, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([0.0070, 0.0333, 0.0534, 0.0546], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0427,  0.0342, -0.0355,  ...,  0.0342,  0.0258, -0.0011],\n        [ 0.0089,  0.0058,  0.0289,  ...,  0.0330, -0.0516,  0.0343],\n        [ 0.0336,  0.0204,  0.0224,  ...,  0.0167, -0.0320,  0.0069],\n        [ 0.0171, -0.0215,  0.0425,  ..., -0.0251,  0.0530,  0.0289]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	300,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7c64388c9790>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s572980000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s572980000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}