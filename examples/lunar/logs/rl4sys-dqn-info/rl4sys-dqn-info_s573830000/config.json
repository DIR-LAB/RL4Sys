{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	4,
    "batch_size":	60,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s573830000"
    },
    "max_sample_age":	-1,
    "q_lr":	0.0005,
    "sample_decay":	0.8,
    "seed":	573830000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x708585977850>":	{
            "_act_dim":	4,
            "_aux_batch_size":	4,
            "_batch_size":	60,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1329,  0.1887, -0.1467, -0.2904, -0.2934,  0.3498, -0.2886, -0.0522,\n        -0.2703, -0.0856,  0.1648, -0.0214, -0.1712,  0.1517, -0.3215, -0.1177,\n        -0.0115,  0.0941,  0.2191,  0.3393,  0.0317,  0.0981,  0.2666, -0.1135,\n        -0.0440,  0.1120, -0.0505, -0.2043, -0.1131,  0.0417, -0.0573, -0.2889,\n        -0.1095,  0.3079, -0.3145, -0.3509, -0.0573,  0.2979, -0.0979,  0.1313,\n        -0.0845, -0.1580,  0.1565,  0.2573, -0.2989,  0.1033, -0.1706,  0.2831,\n        -0.0445,  0.0248, -0.0687,  0.0772,  0.1338, -0.1090, -0.1768,  0.2437,\n         0.3367, -0.1633,  0.2572,  0.0296, -0.2085, -0.2475,  0.2968,  0.0178,\n        -0.2686, -0.0300, -0.1599,  0.0335, -0.1237,  0.3379, -0.1078,  0.0708,\n         0.1292,  0.3351,  0.3136, -0.3533, -0.2001, -0.2094, -0.0249,  0.2160,\n        -0.0817, -0.0810,  0.1141, -0.1580, -0.1081, -0.3132,  0.3144,  0.1640,\n        -0.1650,  0.1026, -0.2288,  0.3090,  0.0081, -0.0410, -0.2268,  0.1683,\n         0.3367, -0.3349,  0.0013, -0.2670,  0.0031, -0.2798,  0.1800,  0.1512,\n        -0.2263, -0.0133, -0.1590,  0.3073,  0.0394, -0.2183, -0.0260, -0.2723,\n        -0.0706, -0.0899,  0.1595, -0.2457, -0.2632,  0.1495,  0.0558,  0.1159,\n        -0.1315,  0.3081,  0.0387, -0.1265, -0.1333, -0.2366, -0.1451, -0.2281],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0793,  0.3440,  0.3385,  ..., -0.1162,  0.0487,  0.1277],\n        [-0.1584,  0.2352, -0.0946,  ..., -0.2958, -0.2196,  0.0658],\n        [ 0.0573,  0.2813,  0.0764,  ..., -0.2359, -0.2145,  0.3497],\n        ...,\n        [ 0.2886, -0.0984, -0.2262,  ..., -0.3008,  0.2684,  0.2665],\n        [ 0.3107, -0.1982, -0.1343,  ...,  0.3215, -0.0439, -0.0430],\n        [ 0.1865, -0.1338, -0.0083,  ..., -0.1806,  0.1690,  0.2623]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0883, -0.0824, -0.0839, -0.0702,  0.0111, -0.0454, -0.0262,  0.0294,\n         0.0168,  0.0664, -0.0720,  0.0830, -0.0363, -0.0240,  0.0354, -0.0352,\n        -0.0588,  0.0230,  0.0606, -0.0403,  0.0188,  0.0805, -0.0275, -0.0358,\n        -0.0219,  0.0260, -0.0287, -0.0753,  0.0610, -0.0348,  0.0867,  0.0793,\n        -0.0260,  0.0704, -0.0255,  0.0295,  0.0140,  0.0875, -0.0657, -0.0311,\n        -0.0705, -0.0306,  0.0661,  0.0839, -0.0324, -0.0879,  0.0661, -0.0328,\n        -0.0057,  0.0176,  0.0028, -0.0382,  0.0075,  0.0481, -0.0599,  0.0652,\n         0.0093, -0.0799,  0.0083,  0.0577,  0.0144,  0.0499,  0.0296, -0.0133,\n        -0.0337,  0.0067,  0.0477, -0.0333,  0.0742,  0.0242, -0.0491, -0.0146,\n         0.0423,  0.0868, -0.0617, -0.0704,  0.0858, -0.0503,  0.0758,  0.0798,\n         0.0776,  0.0477,  0.0628, -0.0304, -0.0592, -0.0490,  0.0613, -0.0748,\n         0.0280, -0.0308,  0.0057, -0.0287,  0.0575,  0.0204, -0.0547, -0.0365,\n         0.0141,  0.0232,  0.0299,  0.0338, -0.0071,  0.0098,  0.0692,  0.0049,\n         0.0175,  0.0234,  0.0640, -0.0867, -0.0656, -0.0506, -0.0597,  0.0634,\n         0.0777,  0.0424, -0.0868,  0.0511,  0.0797,  0.0854, -0.0722,  0.0356,\n         0.0860,  0.0057,  0.0665,  0.0796,  0.0838, -0.0289, -0.0428, -0.0453],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0132,  0.0574, -0.0649,  ..., -0.0105, -0.0813,  0.0091],\n        [ 0.0310, -0.0680,  0.0360,  ..., -0.0158, -0.0657, -0.0212],\n        [-0.0651,  0.0798, -0.0862,  ...,  0.0838, -0.0457, -0.0252],\n        ...,\n        [ 0.0490,  0.0365,  0.0040,  ...,  0.0682, -0.0391, -0.0760],\n        [-0.0221,  0.0882, -0.0368,  ..., -0.0734, -0.0006,  0.0792],\n        [-0.0596,  0.0801,  0.0407,  ..., -0.0662,  0.0238,  0.0440]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0158, -0.0803, -0.0768,  0.0735], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0036, -0.0543,  0.0295, -0.0297, -0.0803,  0.0817,  0.0287,  0.0370,\n          0.0598, -0.0729,  0.0162, -0.0617, -0.0524,  0.0717, -0.0505, -0.0782,\n         -0.0427, -0.0659, -0.0195, -0.0385,  0.0044, -0.0561,  0.0282, -0.0333,\n         -0.0019, -0.0832,  0.0783,  0.0843, -0.0196, -0.0780,  0.0511, -0.0057,\n          0.0503,  0.0646,  0.0619, -0.0114, -0.0016,  0.0707,  0.0813, -0.0182,\n          0.0580,  0.0786, -0.0112, -0.0273,  0.0199, -0.0391,  0.0699, -0.0209,\n          0.0645, -0.0134,  0.0843, -0.0673, -0.0302,  0.0673,  0.0535, -0.0275,\n          0.0176, -0.0795,  0.0035, -0.0281,  0.0099, -0.0805, -0.0057, -0.0745,\n         -0.0802,  0.0229, -0.0236, -0.0358,  0.0119, -0.0541, -0.0017,  0.0714,\n         -0.0625,  0.0362, -0.0106,  0.0492,  0.0846,  0.0112,  0.0117,  0.0181,\n         -0.0159, -0.0125, -0.0463, -0.0612,  0.0120, -0.0649,  0.0269,  0.0845,\n         -0.0780,  0.0437, -0.0815,  0.0685,  0.0547,  0.0118, -0.0079,  0.0537,\n         -0.0361,  0.0753, -0.0692, -0.0023, -0.0369, -0.0517,  0.0248,  0.0248,\n          0.0312, -0.0803, -0.0652, -0.0042,  0.0554,  0.0348, -0.0347,  0.0499,\n         -0.0145,  0.0501, -0.0415, -0.0343,  0.0098, -0.0508, -0.0379, -0.0795,\n          0.0703,  0.0676, -0.0629, -0.0737,  0.0090, -0.0077, -0.0050, -0.0163],\n        [ 0.0428,  0.0658,  0.0019,  0.0184,  0.0307,  0.0451,  0.0203,  0.0204,\n         -0.0451, -0.0467,  0.0188,  0.0356, -0.0851, -0.0397,  0.0726,  0.0797,\n          0.0510, -0.0239,  0.0829,  0.0291,  0.0277, -0.0706, -0.0369, -0.0676,\n          0.0538,  0.0273,  0.0533, -0.0050, -0.0757,  0.0287,  0.0159,  0.0403,\n          0.0343,  0.0746,  0.0590,  0.0280, -0.0104,  0.0701, -0.0784,  0.0766,\n          0.0740, -0.0705, -0.0701,  0.0676, -0.0733, -0.0222, -0.0340, -0.0392,\n         -0.0321, -0.0133,  0.0292,  0.0195, -0.0357,  0.0718, -0.0250,  0.0793,\n          0.0591,  0.0475,  0.0546, -0.0187, -0.0446,  0.0407,  0.0463, -0.0095,\n         -0.0300, -0.0121,  0.0366,  0.0039,  0.0330,  0.0846,  0.0044,  0.0036,\n          0.0083,  0.0733,  0.0345,  0.0184, -0.0470, -0.0826, -0.0157,  0.0339,\n         -0.0476,  0.0032, -0.0033, -0.0563, -0.0445,  0.0323,  0.0473, -0.0234,\n         -0.0465,  0.0299,  0.0419,  0.0658,  0.0556,  0.0668,  0.0433,  0.0457,\n          0.0172,  0.0249,  0.0662, -0.0608,  0.0873, -0.0644,  0.0171, -0.0531,\n         -0.0577, -0.0744, -0.0032, -0.0533,  0.0065,  0.0080, -0.0712, -0.0337,\n          0.0814, -0.0146, -0.0158, -0.0688, -0.0686, -0.0127, -0.0147, -0.0632,\n         -0.0648,  0.0247,  0.0869,  0.0114,  0.0658,  0.0187,  0.0382, -0.0136],\n        [ 0.0193,  0.0870,  0.0503, -0.0324, -0.0798, -0.0128,  0.0226, -0.0611,\n          0.0628,  0.0414, -0.0692, -0.0679, -0.0822,  0.0281, -0.0168,  0.0473,\n          0.0858, -0.0106,  0.0251,  0.0753, -0.0732,  0.0198, -0.0517, -0.0394,\n         -0.0263, -0.0586,  0.0856, -0.0500,  0.0068,  0.0191,  0.0302,  0.0730,\n          0.0700, -0.0332, -0.0859,  0.0207,  0.0180, -0.0042, -0.0543, -0.0698,\n         -0.0445, -0.0798, -0.0612,  0.0044,  0.0838,  0.0788,  0.0365,  0.0115,\n          0.0290, -0.0607, -0.0062, -0.0807, -0.0538, -0.0333,  0.0215,  0.0115,\n         -0.0257, -0.0204,  0.0152, -0.0125, -0.0204,  0.0409, -0.0131,  0.0473,\n         -0.0584, -0.0603, -0.0101, -0.0473,  0.0796,  0.0083, -0.0038,  0.0491,\n         -0.0806, -0.0477, -0.0862,  0.0432, -0.0542, -0.0348,  0.0346,  0.0244,\n          0.0203,  0.0614,  0.0380,  0.0794, -0.0632, -0.0527, -0.0200,  0.0572,\n         -0.0680,  0.0879,  0.0798,  0.0376, -0.0372, -0.0851,  0.0151, -0.0769,\n         -0.0704,  0.0399, -0.0048, -0.0352,  0.0774, -0.0407, -0.0861, -0.0575,\n         -0.0509, -0.0423,  0.0205, -0.0603,  0.0434,  0.0868, -0.0380,  0.0485,\n          0.0686, -0.0140, -0.0467,  0.0350, -0.0592,  0.0523, -0.0392,  0.0616,\n          0.0197, -0.0639,  0.0302, -0.0161,  0.0119,  0.0803,  0.0370,  0.0013],\n        [ 0.0738, -0.0596, -0.0803,  0.0816, -0.0647,  0.0825, -0.0144,  0.0771,\n          0.0023,  0.0406,  0.0814,  0.0863, -0.0201, -0.0828,  0.0284, -0.0161,\n          0.0705, -0.0006, -0.0162,  0.0626,  0.0774, -0.0279,  0.0022,  0.0303,\n          0.0882,  0.0273,  0.0080, -0.0689,  0.0180,  0.0655,  0.0762,  0.0716,\n         -0.0767, -0.0459,  0.0524,  0.0245,  0.0811, -0.0352, -0.0728, -0.0002,\n         -0.0729, -0.0792, -0.0692,  0.0786, -0.0251,  0.0313,  0.0280, -0.0093,\n          0.0625, -0.0067, -0.0430, -0.0056,  0.0548,  0.0428, -0.0176,  0.0226,\n         -0.0804,  0.0520, -0.0638,  0.0757, -0.0696, -0.0099,  0.0483,  0.0008,\n          0.0479, -0.0789, -0.0487,  0.0244,  0.0040, -0.0161, -0.0658, -0.0527,\n          0.0275, -0.0252,  0.0638, -0.0106, -0.0709, -0.0843, -0.0191, -0.0347,\n         -0.0263, -0.0678, -0.0479, -0.0828, -0.0236,  0.0002,  0.0537,  0.0675,\n          0.0721, -0.0654,  0.0700, -0.0693, -0.0705,  0.0027,  0.0869,  0.0302,\n          0.0879,  0.0403,  0.0561,  0.0442, -0.0107,  0.0852, -0.0079,  0.0664,\n         -0.0786, -0.0342, -0.0136, -0.0291,  0.0323, -0.0367,  0.0685, -0.0293,\n          0.0642,  0.0442,  0.0475, -0.0808, -0.0210,  0.0599,  0.0464,  0.0087,\n         -0.0581, -0.0619,  0.0279,  0.0655,  0.0253, -0.0858, -0.0447,  0.0501]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0793,  0.3440,  0.3385,  ..., -0.1162,  0.0487,  0.1277],\n        [-0.1584,  0.2352, -0.0946,  ..., -0.2958, -0.2196,  0.0658],\n        [ 0.0573,  0.2813,  0.0764,  ..., -0.2359, -0.2145,  0.3497],\n        ...,\n        [ 0.2886, -0.0984, -0.2262,  ..., -0.3008,  0.2684,  0.2665],\n        [ 0.3107, -0.1982, -0.1343,  ...,  0.3215, -0.0439, -0.0430],\n        [ 0.1865, -0.1338, -0.0083,  ..., -0.1806,  0.1690,  0.2623]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1329,  0.1887, -0.1467, -0.2904, -0.2934,  0.3498, -0.2886, -0.0522,\n        -0.2703, -0.0856,  0.1648, -0.0214, -0.1712,  0.1517, -0.3215, -0.1177,\n        -0.0115,  0.0941,  0.2191,  0.3393,  0.0317,  0.0981,  0.2666, -0.1135,\n        -0.0440,  0.1120, -0.0505, -0.2043, -0.1131,  0.0417, -0.0573, -0.2889,\n        -0.1095,  0.3079, -0.3145, -0.3509, -0.0573,  0.2979, -0.0979,  0.1313,\n        -0.0845, -0.1580,  0.1565,  0.2573, -0.2989,  0.1033, -0.1706,  0.2831,\n        -0.0445,  0.0248, -0.0687,  0.0772,  0.1338, -0.1090, -0.1768,  0.2437,\n         0.3367, -0.1633,  0.2572,  0.0296, -0.2085, -0.2475,  0.2968,  0.0178,\n        -0.2686, -0.0300, -0.1599,  0.0335, -0.1237,  0.3379, -0.1078,  0.0708,\n         0.1292,  0.3351,  0.3136, -0.3533, -0.2001, -0.2094, -0.0249,  0.2160,\n        -0.0817, -0.0810,  0.1141, -0.1580, -0.1081, -0.3132,  0.3144,  0.1640,\n        -0.1650,  0.1026, -0.2288,  0.3090,  0.0081, -0.0410, -0.2268,  0.1683,\n         0.3367, -0.3349,  0.0013, -0.2670,  0.0031, -0.2798,  0.1800,  0.1512,\n        -0.2263, -0.0133, -0.1590,  0.3073,  0.0394, -0.2183, -0.0260, -0.2723,\n        -0.0706, -0.0899,  0.1595, -0.2457, -0.2632,  0.1495,  0.0558,  0.1159,\n        -0.1315,  0.3081,  0.0387, -0.1265, -0.1333, -0.2366, -0.1451, -0.2281],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0132,  0.0574, -0.0649,  ..., -0.0105, -0.0813,  0.0091],\n        [ 0.0310, -0.0680,  0.0360,  ..., -0.0158, -0.0657, -0.0212],\n        [-0.0651,  0.0798, -0.0862,  ...,  0.0838, -0.0457, -0.0252],\n        ...,\n        [ 0.0490,  0.0365,  0.0040,  ...,  0.0682, -0.0391, -0.0760],\n        [-0.0221,  0.0882, -0.0368,  ..., -0.0734, -0.0006,  0.0792],\n        [-0.0596,  0.0801,  0.0407,  ..., -0.0662,  0.0238,  0.0440]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0883, -0.0824, -0.0839, -0.0702,  0.0111, -0.0454, -0.0262,  0.0294,\n         0.0168,  0.0664, -0.0720,  0.0830, -0.0363, -0.0240,  0.0354, -0.0352,\n        -0.0588,  0.0230,  0.0606, -0.0403,  0.0188,  0.0805, -0.0275, -0.0358,\n        -0.0219,  0.0260, -0.0287, -0.0753,  0.0610, -0.0348,  0.0867,  0.0793,\n        -0.0260,  0.0704, -0.0255,  0.0295,  0.0140,  0.0875, -0.0657, -0.0311,\n        -0.0705, -0.0306,  0.0661,  0.0839, -0.0324, -0.0879,  0.0661, -0.0328,\n        -0.0057,  0.0176,  0.0028, -0.0382,  0.0075,  0.0481, -0.0599,  0.0652,\n         0.0093, -0.0799,  0.0083,  0.0577,  0.0144,  0.0499,  0.0296, -0.0133,\n        -0.0337,  0.0067,  0.0477, -0.0333,  0.0742,  0.0242, -0.0491, -0.0146,\n         0.0423,  0.0868, -0.0617, -0.0704,  0.0858, -0.0503,  0.0758,  0.0798,\n         0.0776,  0.0477,  0.0628, -0.0304, -0.0592, -0.0490,  0.0613, -0.0748,\n         0.0280, -0.0308,  0.0057, -0.0287,  0.0575,  0.0204, -0.0547, -0.0365,\n         0.0141,  0.0232,  0.0299,  0.0338, -0.0071,  0.0098,  0.0692,  0.0049,\n         0.0175,  0.0234,  0.0640, -0.0867, -0.0656, -0.0506, -0.0597,  0.0634,\n         0.0777,  0.0424, -0.0868,  0.0511,  0.0797,  0.0854, -0.0722,  0.0356,\n         0.0860,  0.0057,  0.0665,  0.0796,  0.0838, -0.0289, -0.0428, -0.0453],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0036, -0.0543,  0.0295, -0.0297, -0.0803,  0.0817,  0.0287,  0.0370,\n          0.0598, -0.0729,  0.0162, -0.0617, -0.0524,  0.0717, -0.0505, -0.0782,\n         -0.0427, -0.0659, -0.0195, -0.0385,  0.0044, -0.0561,  0.0282, -0.0333,\n         -0.0019, -0.0832,  0.0783,  0.0843, -0.0196, -0.0780,  0.0511, -0.0057,\n          0.0503,  0.0646,  0.0619, -0.0114, -0.0016,  0.0707,  0.0813, -0.0182,\n          0.0580,  0.0786, -0.0112, -0.0273,  0.0199, -0.0391,  0.0699, -0.0209,\n          0.0645, -0.0134,  0.0843, -0.0673, -0.0302,  0.0673,  0.0535, -0.0275,\n          0.0176, -0.0795,  0.0035, -0.0281,  0.0099, -0.0805, -0.0057, -0.0745,\n         -0.0802,  0.0229, -0.0236, -0.0358,  0.0119, -0.0541, -0.0017,  0.0714,\n         -0.0625,  0.0362, -0.0106,  0.0492,  0.0846,  0.0112,  0.0117,  0.0181,\n         -0.0159, -0.0125, -0.0463, -0.0612,  0.0120, -0.0649,  0.0269,  0.0845,\n         -0.0780,  0.0437, -0.0815,  0.0685,  0.0547,  0.0118, -0.0079,  0.0537,\n         -0.0361,  0.0753, -0.0692, -0.0023, -0.0369, -0.0517,  0.0248,  0.0248,\n          0.0312, -0.0803, -0.0652, -0.0042,  0.0554,  0.0348, -0.0347,  0.0499,\n         -0.0145,  0.0501, -0.0415, -0.0343,  0.0098, -0.0508, -0.0379, -0.0795,\n          0.0703,  0.0676, -0.0629, -0.0737,  0.0090, -0.0077, -0.0050, -0.0163],\n        [ 0.0428,  0.0658,  0.0019,  0.0184,  0.0307,  0.0451,  0.0203,  0.0204,\n         -0.0451, -0.0467,  0.0188,  0.0356, -0.0851, -0.0397,  0.0726,  0.0797,\n          0.0510, -0.0239,  0.0829,  0.0291,  0.0277, -0.0706, -0.0369, -0.0676,\n          0.0538,  0.0273,  0.0533, -0.0050, -0.0757,  0.0287,  0.0159,  0.0403,\n          0.0343,  0.0746,  0.0590,  0.0280, -0.0104,  0.0701, -0.0784,  0.0766,\n          0.0740, -0.0705, -0.0701,  0.0676, -0.0733, -0.0222, -0.0340, -0.0392,\n         -0.0321, -0.0133,  0.0292,  0.0195, -0.0357,  0.0718, -0.0250,  0.0793,\n          0.0591,  0.0475,  0.0546, -0.0187, -0.0446,  0.0407,  0.0463, -0.0095,\n         -0.0300, -0.0121,  0.0366,  0.0039,  0.0330,  0.0846,  0.0044,  0.0036,\n          0.0083,  0.0733,  0.0345,  0.0184, -0.0470, -0.0826, -0.0157,  0.0339,\n         -0.0476,  0.0032, -0.0033, -0.0563, -0.0445,  0.0323,  0.0473, -0.0234,\n         -0.0465,  0.0299,  0.0419,  0.0658,  0.0556,  0.0668,  0.0433,  0.0457,\n          0.0172,  0.0249,  0.0662, -0.0608,  0.0873, -0.0644,  0.0171, -0.0531,\n         -0.0577, -0.0744, -0.0032, -0.0533,  0.0065,  0.0080, -0.0712, -0.0337,\n          0.0814, -0.0146, -0.0158, -0.0688, -0.0686, -0.0127, -0.0147, -0.0632,\n         -0.0648,  0.0247,  0.0869,  0.0114,  0.0658,  0.0187,  0.0382, -0.0136],\n        [ 0.0193,  0.0870,  0.0503, -0.0324, -0.0798, -0.0128,  0.0226, -0.0611,\n          0.0628,  0.0414, -0.0692, -0.0679, -0.0822,  0.0281, -0.0168,  0.0473,\n          0.0858, -0.0106,  0.0251,  0.0753, -0.0732,  0.0198, -0.0517, -0.0394,\n         -0.0263, -0.0586,  0.0856, -0.0500,  0.0068,  0.0191,  0.0302,  0.0730,\n          0.0700, -0.0332, -0.0859,  0.0207,  0.0180, -0.0042, -0.0543, -0.0698,\n         -0.0445, -0.0798, -0.0612,  0.0044,  0.0838,  0.0788,  0.0365,  0.0115,\n          0.0290, -0.0607, -0.0062, -0.0807, -0.0538, -0.0333,  0.0215,  0.0115,\n         -0.0257, -0.0204,  0.0152, -0.0125, -0.0204,  0.0409, -0.0131,  0.0473,\n         -0.0584, -0.0603, -0.0101, -0.0473,  0.0796,  0.0083, -0.0038,  0.0491,\n         -0.0806, -0.0477, -0.0862,  0.0432, -0.0542, -0.0348,  0.0346,  0.0244,\n          0.0203,  0.0614,  0.0380,  0.0794, -0.0632, -0.0527, -0.0200,  0.0572,\n         -0.0680,  0.0879,  0.0798,  0.0376, -0.0372, -0.0851,  0.0151, -0.0769,\n         -0.0704,  0.0399, -0.0048, -0.0352,  0.0774, -0.0407, -0.0861, -0.0575,\n         -0.0509, -0.0423,  0.0205, -0.0603,  0.0434,  0.0868, -0.0380,  0.0485,\n          0.0686, -0.0140, -0.0467,  0.0350, -0.0592,  0.0523, -0.0392,  0.0616,\n          0.0197, -0.0639,  0.0302, -0.0161,  0.0119,  0.0803,  0.0370,  0.0013],\n        [ 0.0738, -0.0596, -0.0803,  0.0816, -0.0647,  0.0825, -0.0144,  0.0771,\n          0.0023,  0.0406,  0.0814,  0.0863, -0.0201, -0.0828,  0.0284, -0.0161,\n          0.0705, -0.0006, -0.0162,  0.0626,  0.0774, -0.0279,  0.0022,  0.0303,\n          0.0882,  0.0273,  0.0080, -0.0689,  0.0180,  0.0655,  0.0762,  0.0716,\n         -0.0767, -0.0459,  0.0524,  0.0245,  0.0811, -0.0352, -0.0728, -0.0002,\n         -0.0729, -0.0792, -0.0692,  0.0786, -0.0251,  0.0313,  0.0280, -0.0093,\n          0.0625, -0.0067, -0.0430, -0.0056,  0.0548,  0.0428, -0.0176,  0.0226,\n         -0.0804,  0.0520, -0.0638,  0.0757, -0.0696, -0.0099,  0.0483,  0.0008,\n          0.0479, -0.0789, -0.0487,  0.0244,  0.0040, -0.0161, -0.0658, -0.0527,\n          0.0275, -0.0252,  0.0638, -0.0106, -0.0709, -0.0843, -0.0191, -0.0347,\n         -0.0263, -0.0678, -0.0479, -0.0828, -0.0236,  0.0002,  0.0537,  0.0675,\n          0.0721, -0.0654,  0.0700, -0.0693, -0.0705,  0.0027,  0.0869,  0.0302,\n          0.0879,  0.0403,  0.0561,  0.0442, -0.0107,  0.0852, -0.0079,  0.0664,\n         -0.0786, -0.0342, -0.0136, -0.0291,  0.0323, -0.0367,  0.0685, -0.0293,\n          0.0642,  0.0442,  0.0475, -0.0808, -0.0210,  0.0599,  0.0464,  0.0087,\n         -0.0581, -0.0619,  0.0279,  0.0655,  0.0253, -0.0858, -0.0447,  0.0501]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0158, -0.0803, -0.0768,  0.0735], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.EnhancedReplayBuffer object at 0x7085872a95d0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "aux_buf_size":	5000,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	-1,
                    "epsilon_per_priority":	1e-06,
                    "gamma":	5,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "max_age":	20000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "num_segments":	0,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "sample_decay":	0.5,
                    "segment_size":	62499.0,
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x708584d0c290>":	{
                            "capacity":	5000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.1329,  0.1887, -0.1467, -0.2904, -0.2934,  0.3498, -0.2886, -0.0522,\n        -0.2703, -0.0856,  0.1648, -0.0214, -0.1712,  0.1517, -0.3215, -0.1177,\n        -0.0115,  0.0941,  0.2191,  0.3393,  0.0317,  0.0981,  0.2666, -0.1135,\n        -0.0440,  0.1120, -0.0505, -0.2043, -0.1131,  0.0417, -0.0573, -0.2889,\n        -0.1095,  0.3079, -0.3145, -0.3509, -0.0573,  0.2979, -0.0979,  0.1313,\n        -0.0845, -0.1580,  0.1565,  0.2573, -0.2989,  0.1033, -0.1706,  0.2831,\n        -0.0445,  0.0248, -0.0687,  0.0772,  0.1338, -0.1090, -0.1768,  0.2437,\n         0.3367, -0.1633,  0.2572,  0.0296, -0.2085, -0.2475,  0.2968,  0.0178,\n        -0.2686, -0.0300, -0.1599,  0.0335, -0.1237,  0.3379, -0.1078,  0.0708,\n         0.1292,  0.3351,  0.3136, -0.3533, -0.2001, -0.2094, -0.0249,  0.2160,\n        -0.0817, -0.0810,  0.1141, -0.1580, -0.1081, -0.3132,  0.3144,  0.1640,\n        -0.1650,  0.1026, -0.2288,  0.3090,  0.0081, -0.0410, -0.2268,  0.1683,\n         0.3367, -0.3349,  0.0013, -0.2670,  0.0031, -0.2798,  0.1800,  0.1512,\n        -0.2263, -0.0133, -0.1590,  0.3073,  0.0394, -0.2183, -0.0260, -0.2723,\n        -0.0706, -0.0899,  0.1595, -0.2457, -0.2632,  0.1495,  0.0558,  0.1159,\n        -0.1315,  0.3081,  0.0387, -0.1265, -0.1333, -0.2366, -0.1451, -0.2281],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0793,  0.3440,  0.3385,  ..., -0.1162,  0.0487,  0.1277],\n        [-0.1584,  0.2352, -0.0946,  ..., -0.2958, -0.2196,  0.0658],\n        [ 0.0573,  0.2813,  0.0764,  ..., -0.2359, -0.2145,  0.3497],\n        ...,\n        [ 0.2886, -0.0984, -0.2262,  ..., -0.3008,  0.2684,  0.2665],\n        [ 0.3107, -0.1982, -0.1343,  ...,  0.3215, -0.0439, -0.0430],\n        [ 0.1865, -0.1338, -0.0083,  ..., -0.1806,  0.1690,  0.2623]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0883, -0.0824, -0.0839, -0.0702,  0.0111, -0.0454, -0.0262,  0.0294,\n         0.0168,  0.0664, -0.0720,  0.0830, -0.0363, -0.0240,  0.0354, -0.0352,\n        -0.0588,  0.0230,  0.0606, -0.0403,  0.0188,  0.0805, -0.0275, -0.0358,\n        -0.0219,  0.0260, -0.0287, -0.0753,  0.0610, -0.0348,  0.0867,  0.0793,\n        -0.0260,  0.0704, -0.0255,  0.0295,  0.0140,  0.0875, -0.0657, -0.0311,\n        -0.0705, -0.0306,  0.0661,  0.0839, -0.0324, -0.0879,  0.0661, -0.0328,\n        -0.0057,  0.0176,  0.0028, -0.0382,  0.0075,  0.0481, -0.0599,  0.0652,\n         0.0093, -0.0799,  0.0083,  0.0577,  0.0144,  0.0499,  0.0296, -0.0133,\n        -0.0337,  0.0067,  0.0477, -0.0333,  0.0742,  0.0242, -0.0491, -0.0146,\n         0.0423,  0.0868, -0.0617, -0.0704,  0.0858, -0.0503,  0.0758,  0.0798,\n         0.0776,  0.0477,  0.0628, -0.0304, -0.0592, -0.0490,  0.0613, -0.0748,\n         0.0280, -0.0308,  0.0057, -0.0287,  0.0575,  0.0204, -0.0547, -0.0365,\n         0.0141,  0.0232,  0.0299,  0.0338, -0.0071,  0.0098,  0.0692,  0.0049,\n         0.0175,  0.0234,  0.0640, -0.0867, -0.0656, -0.0506, -0.0597,  0.0634,\n         0.0777,  0.0424, -0.0868,  0.0511,  0.0797,  0.0854, -0.0722,  0.0356,\n         0.0860,  0.0057,  0.0665,  0.0796,  0.0838, -0.0289, -0.0428, -0.0453],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0132,  0.0574, -0.0649,  ..., -0.0105, -0.0813,  0.0091],\n        [ 0.0310, -0.0680,  0.0360,  ..., -0.0158, -0.0657, -0.0212],\n        [-0.0651,  0.0798, -0.0862,  ...,  0.0838, -0.0457, -0.0252],\n        ...,\n        [ 0.0490,  0.0365,  0.0040,  ...,  0.0682, -0.0391, -0.0760],\n        [-0.0221,  0.0882, -0.0368,  ..., -0.0734, -0.0006,  0.0792],\n        [-0.0596,  0.0801,  0.0407,  ..., -0.0662,  0.0238,  0.0440]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0158, -0.0803, -0.0768,  0.0735], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0036, -0.0543,  0.0295, -0.0297, -0.0803,  0.0817,  0.0287,  0.0370,\n          0.0598, -0.0729,  0.0162, -0.0617, -0.0524,  0.0717, -0.0505, -0.0782,\n         -0.0427, -0.0659, -0.0195, -0.0385,  0.0044, -0.0561,  0.0282, -0.0333,\n         -0.0019, -0.0832,  0.0783,  0.0843, -0.0196, -0.0780,  0.0511, -0.0057,\n          0.0503,  0.0646,  0.0619, -0.0114, -0.0016,  0.0707,  0.0813, -0.0182,\n          0.0580,  0.0786, -0.0112, -0.0273,  0.0199, -0.0391,  0.0699, -0.0209,\n          0.0645, -0.0134,  0.0843, -0.0673, -0.0302,  0.0673,  0.0535, -0.0275,\n          0.0176, -0.0795,  0.0035, -0.0281,  0.0099, -0.0805, -0.0057, -0.0745,\n         -0.0802,  0.0229, -0.0236, -0.0358,  0.0119, -0.0541, -0.0017,  0.0714,\n         -0.0625,  0.0362, -0.0106,  0.0492,  0.0846,  0.0112,  0.0117,  0.0181,\n         -0.0159, -0.0125, -0.0463, -0.0612,  0.0120, -0.0649,  0.0269,  0.0845,\n         -0.0780,  0.0437, -0.0815,  0.0685,  0.0547,  0.0118, -0.0079,  0.0537,\n         -0.0361,  0.0753, -0.0692, -0.0023, -0.0369, -0.0517,  0.0248,  0.0248,\n          0.0312, -0.0803, -0.0652, -0.0042,  0.0554,  0.0348, -0.0347,  0.0499,\n         -0.0145,  0.0501, -0.0415, -0.0343,  0.0098, -0.0508, -0.0379, -0.0795,\n          0.0703,  0.0676, -0.0629, -0.0737,  0.0090, -0.0077, -0.0050, -0.0163],\n        [ 0.0428,  0.0658,  0.0019,  0.0184,  0.0307,  0.0451,  0.0203,  0.0204,\n         -0.0451, -0.0467,  0.0188,  0.0356, -0.0851, -0.0397,  0.0726,  0.0797,\n          0.0510, -0.0239,  0.0829,  0.0291,  0.0277, -0.0706, -0.0369, -0.0676,\n          0.0538,  0.0273,  0.0533, -0.0050, -0.0757,  0.0287,  0.0159,  0.0403,\n          0.0343,  0.0746,  0.0590,  0.0280, -0.0104,  0.0701, -0.0784,  0.0766,\n          0.0740, -0.0705, -0.0701,  0.0676, -0.0733, -0.0222, -0.0340, -0.0392,\n         -0.0321, -0.0133,  0.0292,  0.0195, -0.0357,  0.0718, -0.0250,  0.0793,\n          0.0591,  0.0475,  0.0546, -0.0187, -0.0446,  0.0407,  0.0463, -0.0095,\n         -0.0300, -0.0121,  0.0366,  0.0039,  0.0330,  0.0846,  0.0044,  0.0036,\n          0.0083,  0.0733,  0.0345,  0.0184, -0.0470, -0.0826, -0.0157,  0.0339,\n         -0.0476,  0.0032, -0.0033, -0.0563, -0.0445,  0.0323,  0.0473, -0.0234,\n         -0.0465,  0.0299,  0.0419,  0.0658,  0.0556,  0.0668,  0.0433,  0.0457,\n          0.0172,  0.0249,  0.0662, -0.0608,  0.0873, -0.0644,  0.0171, -0.0531,\n         -0.0577, -0.0744, -0.0032, -0.0533,  0.0065,  0.0080, -0.0712, -0.0337,\n          0.0814, -0.0146, -0.0158, -0.0688, -0.0686, -0.0127, -0.0147, -0.0632,\n         -0.0648,  0.0247,  0.0869,  0.0114,  0.0658,  0.0187,  0.0382, -0.0136],\n        [ 0.0193,  0.0870,  0.0503, -0.0324, -0.0798, -0.0128,  0.0226, -0.0611,\n          0.0628,  0.0414, -0.0692, -0.0679, -0.0822,  0.0281, -0.0168,  0.0473,\n          0.0858, -0.0106,  0.0251,  0.0753, -0.0732,  0.0198, -0.0517, -0.0394,\n         -0.0263, -0.0586,  0.0856, -0.0500,  0.0068,  0.0191,  0.0302,  0.0730,\n          0.0700, -0.0332, -0.0859,  0.0207,  0.0180, -0.0042, -0.0543, -0.0698,\n         -0.0445, -0.0798, -0.0612,  0.0044,  0.0838,  0.0788,  0.0365,  0.0115,\n          0.0290, -0.0607, -0.0062, -0.0807, -0.0538, -0.0333,  0.0215,  0.0115,\n         -0.0257, -0.0204,  0.0152, -0.0125, -0.0204,  0.0409, -0.0131,  0.0473,\n         -0.0584, -0.0603, -0.0101, -0.0473,  0.0796,  0.0083, -0.0038,  0.0491,\n         -0.0806, -0.0477, -0.0862,  0.0432, -0.0542, -0.0348,  0.0346,  0.0244,\n          0.0203,  0.0614,  0.0380,  0.0794, -0.0632, -0.0527, -0.0200,  0.0572,\n         -0.0680,  0.0879,  0.0798,  0.0376, -0.0372, -0.0851,  0.0151, -0.0769,\n         -0.0704,  0.0399, -0.0048, -0.0352,  0.0774, -0.0407, -0.0861, -0.0575,\n         -0.0509, -0.0423,  0.0205, -0.0603,  0.0434,  0.0868, -0.0380,  0.0485,\n          0.0686, -0.0140, -0.0467,  0.0350, -0.0592,  0.0523, -0.0392,  0.0616,\n          0.0197, -0.0639,  0.0302, -0.0161,  0.0119,  0.0803,  0.0370,  0.0013],\n        [ 0.0738, -0.0596, -0.0803,  0.0816, -0.0647,  0.0825, -0.0144,  0.0771,\n          0.0023,  0.0406,  0.0814,  0.0863, -0.0201, -0.0828,  0.0284, -0.0161,\n          0.0705, -0.0006, -0.0162,  0.0626,  0.0774, -0.0279,  0.0022,  0.0303,\n          0.0882,  0.0273,  0.0080, -0.0689,  0.0180,  0.0655,  0.0762,  0.0716,\n         -0.0767, -0.0459,  0.0524,  0.0245,  0.0811, -0.0352, -0.0728, -0.0002,\n         -0.0729, -0.0792, -0.0692,  0.0786, -0.0251,  0.0313,  0.0280, -0.0093,\n          0.0625, -0.0067, -0.0430, -0.0056,  0.0548,  0.0428, -0.0176,  0.0226,\n         -0.0804,  0.0520, -0.0638,  0.0757, -0.0696, -0.0099,  0.0483,  0.0008,\n          0.0479, -0.0789, -0.0487,  0.0244,  0.0040, -0.0161, -0.0658, -0.0527,\n          0.0275, -0.0252,  0.0638, -0.0106, -0.0709, -0.0843, -0.0191, -0.0347,\n         -0.0263, -0.0678, -0.0479, -0.0828, -0.0236,  0.0002,  0.0537,  0.0675,\n          0.0721, -0.0654,  0.0700, -0.0693, -0.0705,  0.0027,  0.0869,  0.0302,\n          0.0879,  0.0403,  0.0561,  0.0442, -0.0107,  0.0852, -0.0079,  0.0664,\n         -0.0786, -0.0342, -0.0136, -0.0291,  0.0323, -0.0367,  0.0685, -0.0293,\n          0.0642,  0.0442,  0.0475, -0.0808, -0.0210,  0.0599,  0.0464,  0.0087,\n         -0.0581, -0.0619,  0.0279,  0.0655,  0.0253, -0.0858, -0.0447,  0.0501]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x70857bf06790>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s573830000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s573830000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}