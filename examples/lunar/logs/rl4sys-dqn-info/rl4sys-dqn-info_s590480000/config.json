{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	4,
    "batch_size":	60,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0005,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s590480000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0005,
    "sample_decay":	0.5,
    "seed":	590480000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x73df4f635b50>":	{
            "_act_dim":	4,
            "_aux_batch_size":	4,
            "_batch_size":	60,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0005,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2752, -0.0482, -0.1560,  0.0097, -0.1279,  0.1432, -0.2256, -0.2335,\n         0.0576, -0.0405, -0.1886,  0.2522,  0.2896,  0.1081, -0.1530, -0.2045,\n         0.2441, -0.0943,  0.1437,  0.2702, -0.1360,  0.1371,  0.1628,  0.0415,\n         0.2321, -0.2520, -0.3505, -0.2994,  0.2914,  0.0818, -0.1342, -0.2167,\n        -0.2457, -0.0186, -0.3246,  0.2751, -0.3480,  0.3491,  0.1428,  0.0198,\n         0.3104, -0.2855, -0.2434, -0.0862,  0.3078, -0.0152,  0.2728,  0.1640,\n         0.1750, -0.0554, -0.0242,  0.1736, -0.2685, -0.1922,  0.2918, -0.1094,\n        -0.0549, -0.0231, -0.2281, -0.0212,  0.1311, -0.3436,  0.2738, -0.1720,\n        -0.2858, -0.1150, -0.3263,  0.2925,  0.1433,  0.2319, -0.2046, -0.2428,\n         0.2323, -0.2770, -0.0749,  0.2465, -0.1070,  0.1198,  0.0042, -0.2135,\n        -0.2612, -0.2160,  0.2440,  0.3241, -0.2564,  0.3491, -0.0284,  0.1720,\n        -0.1529,  0.2583,  0.3397, -0.1490,  0.1786, -0.3081,  0.2708, -0.0472,\n         0.2652, -0.2122, -0.0754,  0.0153, -0.3440, -0.0918,  0.2833, -0.2263,\n         0.1050, -0.2518, -0.3406, -0.2532,  0.0504, -0.0778, -0.1223,  0.1850,\n         0.3339,  0.1380,  0.2930,  0.1995, -0.1140,  0.3196,  0.1017, -0.0248,\n        -0.1500,  0.3457,  0.3379, -0.3100, -0.1279,  0.1827,  0.1313, -0.2813],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2795, -0.2874, -0.0348,  ..., -0.0318, -0.0254,  0.3143],\n        [-0.2208,  0.3025,  0.0531,  ..., -0.3450,  0.2838, -0.0517],\n        [-0.3330,  0.0905, -0.2677,  ...,  0.1137, -0.2665,  0.0591],\n        ...,\n        [ 0.3086, -0.2372,  0.0087,  ...,  0.1675,  0.2571,  0.1235],\n        [ 0.0700, -0.3279,  0.0664,  ...,  0.1834, -0.2663, -0.3138],\n        [-0.2417, -0.1996, -0.1899,  ..., -0.2596,  0.1411, -0.1112]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0552,  0.0697, -0.0758,  0.0455,  0.0768, -0.0818, -0.0211, -0.0551,\n        -0.0735, -0.0162, -0.0440, -0.0674,  0.0546,  0.0879, -0.0053, -0.0404,\n         0.0184, -0.0078,  0.0060,  0.0416,  0.0807, -0.0796,  0.0650,  0.0032,\n        -0.0210, -0.0181, -0.0213,  0.0758,  0.0574,  0.0063,  0.0488, -0.0155,\n         0.0041, -0.0565, -0.0313,  0.0810,  0.0205,  0.0234,  0.0425,  0.0602,\n         0.0299,  0.0045,  0.0375, -0.0403,  0.0832,  0.0606, -0.0461,  0.0624,\n         0.0402,  0.0552,  0.0378, -0.0535,  0.0221, -0.0004,  0.0072,  0.0517,\n         0.0518, -0.0189, -0.0413, -0.0583, -0.0200,  0.0394,  0.0048,  0.0694,\n        -0.0615, -0.0238, -0.0311, -0.0499, -0.0393, -0.0838, -0.0166,  0.0588,\n         0.0232,  0.0145, -0.0525, -0.0667, -0.0413, -0.0597,  0.0488, -0.0819,\n         0.0469, -0.0398,  0.0789,  0.0357, -0.0175,  0.0136, -0.0823,  0.0191,\n         0.0803, -0.0218,  0.0329,  0.0508,  0.0809,  0.0142, -0.0164,  0.0345,\n        -0.0167, -0.0404,  0.0850,  0.0628,  0.0238,  0.0609,  0.0860,  0.0848,\n         0.0447,  0.0498,  0.0711,  0.0605,  0.0007,  0.0706,  0.0228, -0.0362,\n        -0.0146, -0.0866, -0.0289, -0.0397, -0.0636,  0.0077, -0.0416, -0.0324,\n        -0.0390, -0.0883, -0.0558, -0.0247,  0.0248, -0.0476,  0.0382, -0.0227],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0752,  0.0455, -0.0713,  ...,  0.0175,  0.0209, -0.0079],\n        [-0.0647, -0.0569, -0.0604,  ..., -0.0312,  0.0002,  0.0795],\n        [-0.0870, -0.0494,  0.0753,  ..., -0.0199, -0.0612,  0.0477],\n        ...,\n        [-0.0448, -0.0333,  0.0763,  ...,  0.0423,  0.0627,  0.0114],\n        [ 0.0823,  0.0461, -0.0403,  ..., -0.0775, -0.0470,  0.0005],\n        [ 0.0158, -0.0752,  0.0702,  ..., -0.0628, -0.0305, -0.0249]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0878, -0.0194,  0.0191,  0.0094], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-4.8344e-02, -7.1635e-03,  8.3102e-02,  9.9401e-04, -7.6113e-02,\n          5.1773e-03, -2.1294e-02, -5.4226e-02,  2.5719e-03, -8.4372e-02,\n          2.3436e-02, -8.8172e-02,  4.8561e-03,  4.7096e-02, -7.4840e-03,\n         -2.5906e-02,  4.1596e-02, -4.3219e-02,  5.5893e-03, -1.4345e-02,\n          6.7662e-02, -1.6547e-02,  5.0081e-02,  6.9217e-02,  8.7575e-02,\n         -5.0959e-02, -4.9996e-02, -5.0988e-02,  1.6867e-02,  1.5444e-02,\n          8.1002e-02, -1.6014e-02,  6.3083e-02,  7.5930e-03, -2.8454e-02,\n          1.7740e-02,  1.0127e-02,  1.5625e-02,  8.8095e-02, -2.7008e-02,\n         -3.6810e-03, -8.9450e-03,  5.6695e-02,  3.2612e-02, -6.1511e-02,\n         -1.5349e-02, -8.7352e-02,  3.7852e-02, -2.9931e-02,  1.2936e-02,\n          8.0287e-02,  6.4691e-02,  5.3150e-02,  6.2671e-02,  8.2583e-02,\n         -8.6449e-02,  1.0292e-02,  4.3359e-02,  4.3292e-02,  7.4421e-02,\n         -4.1771e-02,  4.5749e-02, -1.3310e-02,  1.2965e-02,  3.2292e-02,\n          6.6368e-02,  3.3817e-02,  6.6080e-02, -5.4654e-03, -4.1513e-02,\n          3.0050e-02, -1.3708e-02, -4.4353e-02, -6.5941e-02, -6.3104e-02,\n          4.2593e-02, -8.2415e-02, -5.5757e-02, -2.3862e-02, -2.6937e-02,\n         -8.3631e-02, -5.4059e-02, -3.8731e-02,  1.4263e-02, -7.3122e-02,\n          2.4824e-02, -3.2139e-02, -2.5462e-02,  4.4151e-02,  1.8271e-02,\n          6.5421e-03,  4.9546e-02, -1.9013e-02, -4.6795e-02,  4.2014e-02,\n          5.3890e-02, -7.8610e-02,  4.3705e-02,  1.2948e-02,  1.9398e-03,\n         -3.2302e-02,  1.7287e-02, -3.0237e-02, -5.8430e-02, -5.8451e-03,\n          3.1637e-02, -3.5278e-02,  8.5843e-03, -7.2401e-02, -7.1353e-02,\n         -8.2719e-02, -7.5985e-02,  2.4936e-02, -6.7659e-02,  2.4308e-02,\n         -7.7245e-02,  5.6756e-02, -7.3170e-02, -5.9863e-02, -1.2130e-02,\n          5.3127e-02,  5.6507e-02, -3.4403e-02,  2.5764e-02,  2.4560e-02,\n         -8.0161e-02,  7.5429e-02,  2.2196e-02],\n        [ 2.1203e-02, -2.6935e-02,  3.1679e-02, -7.4109e-02, -5.1482e-02,\n          6.2891e-02, -2.2452e-02,  2.7393e-02,  2.1881e-02, -5.4822e-02,\n         -6.7383e-02, -4.7897e-03,  6.8626e-02, -1.1462e-02, -2.4510e-02,\n          9.3247e-03, -4.1356e-02, -4.3701e-02, -3.7725e-02, -7.6410e-02,\n         -1.7532e-04, -3.7712e-02, -1.5247e-03, -5.7236e-02,  1.4013e-02,\n         -3.5077e-02,  6.6921e-02,  3.5678e-02,  4.2997e-02,  5.5324e-02,\n          7.7523e-02,  8.3194e-02,  5.3908e-02,  1.4136e-02, -1.5089e-02,\n         -2.8938e-02,  5.4399e-02, -1.4618e-02,  5.0399e-02,  6.7097e-02,\n         -5.8753e-02, -7.1763e-02, -4.4653e-02, -1.6912e-02,  4.5219e-02,\n         -5.4543e-02,  8.1697e-02, -3.1199e-02,  2.8096e-02,  4.0189e-02,\n         -3.7882e-02, -2.8815e-02,  5.4357e-02, -7.4103e-03, -3.1660e-02,\n         -7.3394e-02, -8.5973e-02, -2.5144e-03, -2.8298e-03, -4.8211e-02,\n         -6.8070e-02,  6.7321e-03,  6.5877e-02, -3.9175e-02, -3.9304e-02,\n         -5.1130e-02,  2.3993e-02,  8.1889e-02, -2.3593e-02,  8.8297e-02,\n          2.5087e-02, -3.8599e-02, -9.5165e-04, -6.9372e-02, -4.5339e-02,\n         -3.5226e-02, -8.2207e-02,  2.4081e-02,  5.4570e-02, -6.9376e-04,\n         -3.2548e-02,  7.6904e-02,  6.8081e-03, -1.6782e-02, -5.9963e-02,\n          4.6409e-02,  7.7354e-02, -1.4873e-02, -5.8682e-02,  6.4588e-02,\n         -1.6308e-02,  5.6896e-02,  7.4687e-02, -3.9236e-02,  1.0583e-02,\n         -5.2165e-03, -7.8332e-02,  4.6369e-02,  1.9138e-02,  3.7332e-03,\n         -6.2325e-02,  8.3258e-02, -6.7318e-02, -7.1579e-02,  7.9625e-02,\n          1.2020e-02, -6.0456e-02,  6.2804e-02, -7.1519e-02, -5.6902e-02,\n         -1.5321e-03,  2.9032e-02, -5.9788e-02,  8.3498e-02, -3.3436e-02,\n         -7.6653e-02,  1.8009e-02, -2.9876e-02,  6.1404e-02,  6.8723e-02,\n         -6.9799e-02,  3.5441e-02, -2.8586e-02,  6.6134e-02, -5.6249e-02,\n         -1.2080e-02, -5.5854e-02, -5.5596e-02],\n        [ 4.7276e-02, -1.6995e-02, -1.0030e-02,  5.7020e-02, -6.8183e-02,\n          6.2363e-02,  6.2096e-02, -2.6436e-02, -8.1338e-02,  5.1791e-02,\n          3.0976e-02, -8.3786e-03, -2.9151e-02, -5.1623e-02,  7.7497e-02,\n         -8.1193e-02, -4.5230e-02, -5.5388e-03, -5.8793e-02, -2.9628e-02,\n         -3.6537e-03,  8.3364e-02, -5.2874e-02, -2.4133e-02, -2.6105e-02,\n          1.2856e-02,  5.2494e-02, -5.2706e-02, -8.7074e-02, -4.0248e-02,\n          1.1301e-02, -4.4015e-02,  2.6425e-02, -8.3892e-02,  4.2665e-02,\n         -5.9070e-02, -7.0146e-03,  5.5207e-02, -4.6978e-02, -2.5166e-02,\n          4.8629e-02,  5.7606e-02,  2.9882e-02, -1.5853e-02,  7.1354e-02,\n          2.8068e-02, -3.7466e-02,  7.4017e-02, -1.9875e-02, -2.3444e-02,\n          6.7071e-02,  7.8767e-02,  7.3023e-02, -6.6862e-02,  1.8492e-02,\n          8.0935e-02,  5.0441e-02, -9.8591e-03, -1.0860e-02, -5.4951e-02,\n         -6.7988e-02,  7.5717e-02, -6.6333e-02, -2.1679e-02,  9.0925e-03,\n          1.2978e-04,  6.3702e-02,  2.3009e-02,  3.1759e-02,  3.3717e-06,\n          5.4464e-02,  1.1179e-02,  1.4023e-02,  2.9862e-02, -5.3101e-02,\n         -7.8682e-02, -6.8608e-02,  5.4509e-02,  5.5974e-02,  8.3759e-02,\n          5.7962e-02,  2.9913e-02,  8.1573e-02, -6.4830e-02,  4.0757e-02,\n          4.2371e-02,  5.6789e-02,  2.0968e-02, -6.9116e-02,  5.5296e-02,\n         -2.7216e-02,  4.1509e-02, -1.8105e-02, -5.0710e-02, -7.6159e-02,\n          7.6661e-03, -3.6503e-02, -9.6526e-03, -2.4490e-02, -6.4502e-02,\n         -7.5981e-02,  9.0590e-03, -8.9362e-03, -1.9312e-03,  3.1805e-02,\n         -5.2796e-02,  3.9658e-02, -3.6686e-02, -6.9970e-02, -6.2070e-02,\n         -5.4480e-02,  3.2492e-03,  4.9875e-02, -2.1115e-02, -6.0164e-02,\n         -4.0670e-02, -8.6521e-03,  2.5166e-03, -7.2037e-02, -5.8314e-02,\n         -2.3026e-02, -2.1109e-02, -2.7626e-02, -5.2266e-02, -8.5232e-02,\n          5.8762e-02,  4.3106e-03,  3.7804e-02],\n        [-2.4418e-02,  1.5912e-02,  1.9332e-02,  3.0117e-02,  7.9954e-02,\n          8.6314e-02,  7.9994e-02,  5.2082e-02, -1.3571e-02,  8.8355e-02,\n          7.2238e-03,  8.2818e-02, -1.7904e-02, -2.8275e-02,  5.5543e-02,\n          8.3535e-02,  3.7976e-02,  7.4554e-02,  6.0616e-02,  1.8762e-02,\n         -5.1130e-02,  7.2982e-02, -1.6454e-02, -8.7462e-02, -9.9667e-03,\n          6.0122e-02, -4.9179e-03,  6.1871e-03, -8.5098e-02, -4.7935e-03,\n          1.8492e-02, -4.3149e-03,  7.6203e-02,  1.6054e-03,  7.4831e-03,\n          1.4139e-02, -8.7912e-02,  5.0049e-02,  7.5215e-02, -7.3597e-02,\n          2.9116e-02,  3.9337e-03, -6.3458e-02, -7.0111e-02, -2.8246e-03,\n         -3.1940e-02, -3.8354e-06, -6.7690e-02,  2.2779e-02, -3.8726e-02,\n          2.2008e-02,  5.3986e-02, -3.4194e-02,  4.1125e-02,  4.9022e-02,\n         -8.6755e-02,  4.6293e-02, -2.3038e-02,  3.1554e-02, -4.6877e-02,\n          1.3222e-02, -3.5423e-02, -4.3143e-02,  3.4517e-02,  3.1584e-02,\n          6.0926e-02,  2.4578e-02,  3.5583e-02,  8.7556e-02, -8.2187e-02,\n          5.5565e-02,  3.2940e-02, -5.8303e-02, -8.5680e-02,  1.1336e-02,\n          4.4244e-02, -7.1975e-02,  8.0286e-02, -1.0325e-02, -2.4210e-04,\n         -5.8350e-02,  8.5584e-02, -1.5683e-03,  7.7724e-02,  7.5217e-02,\n         -3.1275e-02,  6.1465e-02, -2.4539e-02, -5.4644e-02,  7.3335e-03,\n         -7.4342e-02, -4.5424e-02,  7.3014e-03,  1.7411e-02, -6.2356e-02,\n         -7.5644e-02,  5.5577e-02,  7.6247e-02, -6.7479e-02,  5.2519e-02,\n          3.9956e-02, -2.6947e-03,  2.5315e-02, -4.9476e-03, -1.0795e-02,\n         -4.9029e-02, -1.6182e-02,  4.5417e-02, -7.0748e-02, -3.9906e-03,\n         -6.9016e-03,  2.7753e-02, -6.5137e-02,  3.7326e-02, -1.0559e-02,\n          7.9448e-02,  8.8007e-02, -6.7856e-02, -5.6173e-02, -2.3198e-03,\n         -7.6381e-03,  4.6665e-02,  8.6603e-02,  6.3343e-02, -2.8949e-02,\n          8.6425e-02, -5.9958e-02,  3.1024e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2795, -0.2874, -0.0348,  ..., -0.0318, -0.0254,  0.3143],\n        [-0.2208,  0.3025,  0.0531,  ..., -0.3450,  0.2838, -0.0517],\n        [-0.3330,  0.0905, -0.2677,  ...,  0.1137, -0.2665,  0.0591],\n        ...,\n        [ 0.3086, -0.2372,  0.0087,  ...,  0.1675,  0.2571,  0.1235],\n        [ 0.0700, -0.3279,  0.0664,  ...,  0.1834, -0.2663, -0.3138],\n        [-0.2417, -0.1996, -0.1899,  ..., -0.2596,  0.1411, -0.1112]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2752, -0.0482, -0.1560,  0.0097, -0.1279,  0.1432, -0.2256, -0.2335,\n         0.0576, -0.0405, -0.1886,  0.2522,  0.2896,  0.1081, -0.1530, -0.2045,\n         0.2441, -0.0943,  0.1437,  0.2702, -0.1360,  0.1371,  0.1628,  0.0415,\n         0.2321, -0.2520, -0.3505, -0.2994,  0.2914,  0.0818, -0.1342, -0.2167,\n        -0.2457, -0.0186, -0.3246,  0.2751, -0.3480,  0.3491,  0.1428,  0.0198,\n         0.3104, -0.2855, -0.2434, -0.0862,  0.3078, -0.0152,  0.2728,  0.1640,\n         0.1750, -0.0554, -0.0242,  0.1736, -0.2685, -0.1922,  0.2918, -0.1094,\n        -0.0549, -0.0231, -0.2281, -0.0212,  0.1311, -0.3436,  0.2738, -0.1720,\n        -0.2858, -0.1150, -0.3263,  0.2925,  0.1433,  0.2319, -0.2046, -0.2428,\n         0.2323, -0.2770, -0.0749,  0.2465, -0.1070,  0.1198,  0.0042, -0.2135,\n        -0.2612, -0.2160,  0.2440,  0.3241, -0.2564,  0.3491, -0.0284,  0.1720,\n        -0.1529,  0.2583,  0.3397, -0.1490,  0.1786, -0.3081,  0.2708, -0.0472,\n         0.2652, -0.2122, -0.0754,  0.0153, -0.3440, -0.0918,  0.2833, -0.2263,\n         0.1050, -0.2518, -0.3406, -0.2532,  0.0504, -0.0778, -0.1223,  0.1850,\n         0.3339,  0.1380,  0.2930,  0.1995, -0.1140,  0.3196,  0.1017, -0.0248,\n        -0.1500,  0.3457,  0.3379, -0.3100, -0.1279,  0.1827,  0.1313, -0.2813],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0752,  0.0455, -0.0713,  ...,  0.0175,  0.0209, -0.0079],\n        [-0.0647, -0.0569, -0.0604,  ..., -0.0312,  0.0002,  0.0795],\n        [-0.0870, -0.0494,  0.0753,  ..., -0.0199, -0.0612,  0.0477],\n        ...,\n        [-0.0448, -0.0333,  0.0763,  ...,  0.0423,  0.0627,  0.0114],\n        [ 0.0823,  0.0461, -0.0403,  ..., -0.0775, -0.0470,  0.0005],\n        [ 0.0158, -0.0752,  0.0702,  ..., -0.0628, -0.0305, -0.0249]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0552,  0.0697, -0.0758,  0.0455,  0.0768, -0.0818, -0.0211, -0.0551,\n        -0.0735, -0.0162, -0.0440, -0.0674,  0.0546,  0.0879, -0.0053, -0.0404,\n         0.0184, -0.0078,  0.0060,  0.0416,  0.0807, -0.0796,  0.0650,  0.0032,\n        -0.0210, -0.0181, -0.0213,  0.0758,  0.0574,  0.0063,  0.0488, -0.0155,\n         0.0041, -0.0565, -0.0313,  0.0810,  0.0205,  0.0234,  0.0425,  0.0602,\n         0.0299,  0.0045,  0.0375, -0.0403,  0.0832,  0.0606, -0.0461,  0.0624,\n         0.0402,  0.0552,  0.0378, -0.0535,  0.0221, -0.0004,  0.0072,  0.0517,\n         0.0518, -0.0189, -0.0413, -0.0583, -0.0200,  0.0394,  0.0048,  0.0694,\n        -0.0615, -0.0238, -0.0311, -0.0499, -0.0393, -0.0838, -0.0166,  0.0588,\n         0.0232,  0.0145, -0.0525, -0.0667, -0.0413, -0.0597,  0.0488, -0.0819,\n         0.0469, -0.0398,  0.0789,  0.0357, -0.0175,  0.0136, -0.0823,  0.0191,\n         0.0803, -0.0218,  0.0329,  0.0508,  0.0809,  0.0142, -0.0164,  0.0345,\n        -0.0167, -0.0404,  0.0850,  0.0628,  0.0238,  0.0609,  0.0860,  0.0848,\n         0.0447,  0.0498,  0.0711,  0.0605,  0.0007,  0.0706,  0.0228, -0.0362,\n        -0.0146, -0.0866, -0.0289, -0.0397, -0.0636,  0.0077, -0.0416, -0.0324,\n        -0.0390, -0.0883, -0.0558, -0.0247,  0.0248, -0.0476,  0.0382, -0.0227],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-4.8344e-02, -7.1635e-03,  8.3102e-02,  9.9401e-04, -7.6113e-02,\n          5.1773e-03, -2.1294e-02, -5.4226e-02,  2.5719e-03, -8.4372e-02,\n          2.3436e-02, -8.8172e-02,  4.8561e-03,  4.7096e-02, -7.4840e-03,\n         -2.5906e-02,  4.1596e-02, -4.3219e-02,  5.5893e-03, -1.4345e-02,\n          6.7662e-02, -1.6547e-02,  5.0081e-02,  6.9217e-02,  8.7575e-02,\n         -5.0959e-02, -4.9996e-02, -5.0988e-02,  1.6867e-02,  1.5444e-02,\n          8.1002e-02, -1.6014e-02,  6.3083e-02,  7.5930e-03, -2.8454e-02,\n          1.7740e-02,  1.0127e-02,  1.5625e-02,  8.8095e-02, -2.7008e-02,\n         -3.6810e-03, -8.9450e-03,  5.6695e-02,  3.2612e-02, -6.1511e-02,\n         -1.5349e-02, -8.7352e-02,  3.7852e-02, -2.9931e-02,  1.2936e-02,\n          8.0287e-02,  6.4691e-02,  5.3150e-02,  6.2671e-02,  8.2583e-02,\n         -8.6449e-02,  1.0292e-02,  4.3359e-02,  4.3292e-02,  7.4421e-02,\n         -4.1771e-02,  4.5749e-02, -1.3310e-02,  1.2965e-02,  3.2292e-02,\n          6.6368e-02,  3.3817e-02,  6.6080e-02, -5.4654e-03, -4.1513e-02,\n          3.0050e-02, -1.3708e-02, -4.4353e-02, -6.5941e-02, -6.3104e-02,\n          4.2593e-02, -8.2415e-02, -5.5757e-02, -2.3862e-02, -2.6937e-02,\n         -8.3631e-02, -5.4059e-02, -3.8731e-02,  1.4263e-02, -7.3122e-02,\n          2.4824e-02, -3.2139e-02, -2.5462e-02,  4.4151e-02,  1.8271e-02,\n          6.5421e-03,  4.9546e-02, -1.9013e-02, -4.6795e-02,  4.2014e-02,\n          5.3890e-02, -7.8610e-02,  4.3705e-02,  1.2948e-02,  1.9398e-03,\n         -3.2302e-02,  1.7287e-02, -3.0237e-02, -5.8430e-02, -5.8451e-03,\n          3.1637e-02, -3.5278e-02,  8.5843e-03, -7.2401e-02, -7.1353e-02,\n         -8.2719e-02, -7.5985e-02,  2.4936e-02, -6.7659e-02,  2.4308e-02,\n         -7.7245e-02,  5.6756e-02, -7.3170e-02, -5.9863e-02, -1.2130e-02,\n          5.3127e-02,  5.6507e-02, -3.4403e-02,  2.5764e-02,  2.4560e-02,\n         -8.0161e-02,  7.5429e-02,  2.2196e-02],\n        [ 2.1203e-02, -2.6935e-02,  3.1679e-02, -7.4109e-02, -5.1482e-02,\n          6.2891e-02, -2.2452e-02,  2.7393e-02,  2.1881e-02, -5.4822e-02,\n         -6.7383e-02, -4.7897e-03,  6.8626e-02, -1.1462e-02, -2.4510e-02,\n          9.3247e-03, -4.1356e-02, -4.3701e-02, -3.7725e-02, -7.6410e-02,\n         -1.7532e-04, -3.7712e-02, -1.5247e-03, -5.7236e-02,  1.4013e-02,\n         -3.5077e-02,  6.6921e-02,  3.5678e-02,  4.2997e-02,  5.5324e-02,\n          7.7523e-02,  8.3194e-02,  5.3908e-02,  1.4136e-02, -1.5089e-02,\n         -2.8938e-02,  5.4399e-02, -1.4618e-02,  5.0399e-02,  6.7097e-02,\n         -5.8753e-02, -7.1763e-02, -4.4653e-02, -1.6912e-02,  4.5219e-02,\n         -5.4543e-02,  8.1697e-02, -3.1199e-02,  2.8096e-02,  4.0189e-02,\n         -3.7882e-02, -2.8815e-02,  5.4357e-02, -7.4103e-03, -3.1660e-02,\n         -7.3394e-02, -8.5973e-02, -2.5144e-03, -2.8298e-03, -4.8211e-02,\n         -6.8070e-02,  6.7321e-03,  6.5877e-02, -3.9175e-02, -3.9304e-02,\n         -5.1130e-02,  2.3993e-02,  8.1889e-02, -2.3593e-02,  8.8297e-02,\n          2.5087e-02, -3.8599e-02, -9.5165e-04, -6.9372e-02, -4.5339e-02,\n         -3.5226e-02, -8.2207e-02,  2.4081e-02,  5.4570e-02, -6.9376e-04,\n         -3.2548e-02,  7.6904e-02,  6.8081e-03, -1.6782e-02, -5.9963e-02,\n          4.6409e-02,  7.7354e-02, -1.4873e-02, -5.8682e-02,  6.4588e-02,\n         -1.6308e-02,  5.6896e-02,  7.4687e-02, -3.9236e-02,  1.0583e-02,\n         -5.2165e-03, -7.8332e-02,  4.6369e-02,  1.9138e-02,  3.7332e-03,\n         -6.2325e-02,  8.3258e-02, -6.7318e-02, -7.1579e-02,  7.9625e-02,\n          1.2020e-02, -6.0456e-02,  6.2804e-02, -7.1519e-02, -5.6902e-02,\n         -1.5321e-03,  2.9032e-02, -5.9788e-02,  8.3498e-02, -3.3436e-02,\n         -7.6653e-02,  1.8009e-02, -2.9876e-02,  6.1404e-02,  6.8723e-02,\n         -6.9799e-02,  3.5441e-02, -2.8586e-02,  6.6134e-02, -5.6249e-02,\n         -1.2080e-02, -5.5854e-02, -5.5596e-02],\n        [ 4.7276e-02, -1.6995e-02, -1.0030e-02,  5.7020e-02, -6.8183e-02,\n          6.2363e-02,  6.2096e-02, -2.6436e-02, -8.1338e-02,  5.1791e-02,\n          3.0976e-02, -8.3786e-03, -2.9151e-02, -5.1623e-02,  7.7497e-02,\n         -8.1193e-02, -4.5230e-02, -5.5388e-03, -5.8793e-02, -2.9628e-02,\n         -3.6537e-03,  8.3364e-02, -5.2874e-02, -2.4133e-02, -2.6105e-02,\n          1.2856e-02,  5.2494e-02, -5.2706e-02, -8.7074e-02, -4.0248e-02,\n          1.1301e-02, -4.4015e-02,  2.6425e-02, -8.3892e-02,  4.2665e-02,\n         -5.9070e-02, -7.0146e-03,  5.5207e-02, -4.6978e-02, -2.5166e-02,\n          4.8629e-02,  5.7606e-02,  2.9882e-02, -1.5853e-02,  7.1354e-02,\n          2.8068e-02, -3.7466e-02,  7.4017e-02, -1.9875e-02, -2.3444e-02,\n          6.7071e-02,  7.8767e-02,  7.3023e-02, -6.6862e-02,  1.8492e-02,\n          8.0935e-02,  5.0441e-02, -9.8591e-03, -1.0860e-02, -5.4951e-02,\n         -6.7988e-02,  7.5717e-02, -6.6333e-02, -2.1679e-02,  9.0925e-03,\n          1.2978e-04,  6.3702e-02,  2.3009e-02,  3.1759e-02,  3.3717e-06,\n          5.4464e-02,  1.1179e-02,  1.4023e-02,  2.9862e-02, -5.3101e-02,\n         -7.8682e-02, -6.8608e-02,  5.4509e-02,  5.5974e-02,  8.3759e-02,\n          5.7962e-02,  2.9913e-02,  8.1573e-02, -6.4830e-02,  4.0757e-02,\n          4.2371e-02,  5.6789e-02,  2.0968e-02, -6.9116e-02,  5.5296e-02,\n         -2.7216e-02,  4.1509e-02, -1.8105e-02, -5.0710e-02, -7.6159e-02,\n          7.6661e-03, -3.6503e-02, -9.6526e-03, -2.4490e-02, -6.4502e-02,\n         -7.5981e-02,  9.0590e-03, -8.9362e-03, -1.9312e-03,  3.1805e-02,\n         -5.2796e-02,  3.9658e-02, -3.6686e-02, -6.9970e-02, -6.2070e-02,\n         -5.4480e-02,  3.2492e-03,  4.9875e-02, -2.1115e-02, -6.0164e-02,\n         -4.0670e-02, -8.6521e-03,  2.5166e-03, -7.2037e-02, -5.8314e-02,\n         -2.3026e-02, -2.1109e-02, -2.7626e-02, -5.2266e-02, -8.5232e-02,\n          5.8762e-02,  4.3106e-03,  3.7804e-02],\n        [-2.4418e-02,  1.5912e-02,  1.9332e-02,  3.0117e-02,  7.9954e-02,\n          8.6314e-02,  7.9994e-02,  5.2082e-02, -1.3571e-02,  8.8355e-02,\n          7.2238e-03,  8.2818e-02, -1.7904e-02, -2.8275e-02,  5.5543e-02,\n          8.3535e-02,  3.7976e-02,  7.4554e-02,  6.0616e-02,  1.8762e-02,\n         -5.1130e-02,  7.2982e-02, -1.6454e-02, -8.7462e-02, -9.9667e-03,\n          6.0122e-02, -4.9179e-03,  6.1871e-03, -8.5098e-02, -4.7935e-03,\n          1.8492e-02, -4.3149e-03,  7.6203e-02,  1.6054e-03,  7.4831e-03,\n          1.4139e-02, -8.7912e-02,  5.0049e-02,  7.5215e-02, -7.3597e-02,\n          2.9116e-02,  3.9337e-03, -6.3458e-02, -7.0111e-02, -2.8246e-03,\n         -3.1940e-02, -3.8354e-06, -6.7690e-02,  2.2779e-02, -3.8726e-02,\n          2.2008e-02,  5.3986e-02, -3.4194e-02,  4.1125e-02,  4.9022e-02,\n         -8.6755e-02,  4.6293e-02, -2.3038e-02,  3.1554e-02, -4.6877e-02,\n          1.3222e-02, -3.5423e-02, -4.3143e-02,  3.4517e-02,  3.1584e-02,\n          6.0926e-02,  2.4578e-02,  3.5583e-02,  8.7556e-02, -8.2187e-02,\n          5.5565e-02,  3.2940e-02, -5.8303e-02, -8.5680e-02,  1.1336e-02,\n          4.4244e-02, -7.1975e-02,  8.0286e-02, -1.0325e-02, -2.4210e-04,\n         -5.8350e-02,  8.5584e-02, -1.5683e-03,  7.7724e-02,  7.5217e-02,\n         -3.1275e-02,  6.1465e-02, -2.4539e-02, -5.4644e-02,  7.3335e-03,\n         -7.4342e-02, -4.5424e-02,  7.3014e-03,  1.7411e-02, -6.2356e-02,\n         -7.5644e-02,  5.5577e-02,  7.6247e-02, -6.7479e-02,  5.2519e-02,\n          3.9956e-02, -2.6947e-03,  2.5315e-02, -4.9476e-03, -1.0795e-02,\n         -4.9029e-02, -1.6182e-02,  4.5417e-02, -7.0748e-02, -3.9906e-03,\n         -6.9016e-03,  2.7753e-02, -6.5137e-02,  3.7326e-02, -1.0559e-02,\n          7.9448e-02,  8.8007e-02, -6.7856e-02, -5.6173e-02, -2.3198e-03,\n         -7.6381e-03,  4.6665e-02,  8.6603e-02,  6.3343e-02, -2.8949e-02,\n          8.6425e-02, -5.9958e-02,  3.1024e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0878, -0.0194,  0.0191,  0.0094], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.EnhancedReplayBuffer object at 0x73df500a6b50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "aux_buf_size":	5000,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon":	200,
                    "epsilon_per_priority":	1e-06,
                    "gamma":	5,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "max_age":	20000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "num_segments":	0,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "sample_decay":	0.5,
                    "segment_size":	100000.0,
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x73df517f6050>":	{
                            "capacity":	5000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0005,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.2752, -0.0482, -0.1560,  0.0097, -0.1279,  0.1432, -0.2256, -0.2335,\n         0.0576, -0.0405, -0.1886,  0.2522,  0.2896,  0.1081, -0.1530, -0.2045,\n         0.2441, -0.0943,  0.1437,  0.2702, -0.1360,  0.1371,  0.1628,  0.0415,\n         0.2321, -0.2520, -0.3505, -0.2994,  0.2914,  0.0818, -0.1342, -0.2167,\n        -0.2457, -0.0186, -0.3246,  0.2751, -0.3480,  0.3491,  0.1428,  0.0198,\n         0.3104, -0.2855, -0.2434, -0.0862,  0.3078, -0.0152,  0.2728,  0.1640,\n         0.1750, -0.0554, -0.0242,  0.1736, -0.2685, -0.1922,  0.2918, -0.1094,\n        -0.0549, -0.0231, -0.2281, -0.0212,  0.1311, -0.3436,  0.2738, -0.1720,\n        -0.2858, -0.1150, -0.3263,  0.2925,  0.1433,  0.2319, -0.2046, -0.2428,\n         0.2323, -0.2770, -0.0749,  0.2465, -0.1070,  0.1198,  0.0042, -0.2135,\n        -0.2612, -0.2160,  0.2440,  0.3241, -0.2564,  0.3491, -0.0284,  0.1720,\n        -0.1529,  0.2583,  0.3397, -0.1490,  0.1786, -0.3081,  0.2708, -0.0472,\n         0.2652, -0.2122, -0.0754,  0.0153, -0.3440, -0.0918,  0.2833, -0.2263,\n         0.1050, -0.2518, -0.3406, -0.2532,  0.0504, -0.0778, -0.1223,  0.1850,\n         0.3339,  0.1380,  0.2930,  0.1995, -0.1140,  0.3196,  0.1017, -0.0248,\n        -0.1500,  0.3457,  0.3379, -0.3100, -0.1279,  0.1827,  0.1313, -0.2813],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.2795, -0.2874, -0.0348,  ..., -0.0318, -0.0254,  0.3143],\n        [-0.2208,  0.3025,  0.0531,  ..., -0.3450,  0.2838, -0.0517],\n        [-0.3330,  0.0905, -0.2677,  ...,  0.1137, -0.2665,  0.0591],\n        ...,\n        [ 0.3086, -0.2372,  0.0087,  ...,  0.1675,  0.2571,  0.1235],\n        [ 0.0700, -0.3279,  0.0664,  ...,  0.1834, -0.2663, -0.3138],\n        [-0.2417, -0.1996, -0.1899,  ..., -0.2596,  0.1411, -0.1112]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0552,  0.0697, -0.0758,  0.0455,  0.0768, -0.0818, -0.0211, -0.0551,\n        -0.0735, -0.0162, -0.0440, -0.0674,  0.0546,  0.0879, -0.0053, -0.0404,\n         0.0184, -0.0078,  0.0060,  0.0416,  0.0807, -0.0796,  0.0650,  0.0032,\n        -0.0210, -0.0181, -0.0213,  0.0758,  0.0574,  0.0063,  0.0488, -0.0155,\n         0.0041, -0.0565, -0.0313,  0.0810,  0.0205,  0.0234,  0.0425,  0.0602,\n         0.0299,  0.0045,  0.0375, -0.0403,  0.0832,  0.0606, -0.0461,  0.0624,\n         0.0402,  0.0552,  0.0378, -0.0535,  0.0221, -0.0004,  0.0072,  0.0517,\n         0.0518, -0.0189, -0.0413, -0.0583, -0.0200,  0.0394,  0.0048,  0.0694,\n        -0.0615, -0.0238, -0.0311, -0.0499, -0.0393, -0.0838, -0.0166,  0.0588,\n         0.0232,  0.0145, -0.0525, -0.0667, -0.0413, -0.0597,  0.0488, -0.0819,\n         0.0469, -0.0398,  0.0789,  0.0357, -0.0175,  0.0136, -0.0823,  0.0191,\n         0.0803, -0.0218,  0.0329,  0.0508,  0.0809,  0.0142, -0.0164,  0.0345,\n        -0.0167, -0.0404,  0.0850,  0.0628,  0.0238,  0.0609,  0.0860,  0.0848,\n         0.0447,  0.0498,  0.0711,  0.0605,  0.0007,  0.0706,  0.0228, -0.0362,\n        -0.0146, -0.0866, -0.0289, -0.0397, -0.0636,  0.0077, -0.0416, -0.0324,\n        -0.0390, -0.0883, -0.0558, -0.0247,  0.0248, -0.0476,  0.0382, -0.0227],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0752,  0.0455, -0.0713,  ...,  0.0175,  0.0209, -0.0079],\n        [-0.0647, -0.0569, -0.0604,  ..., -0.0312,  0.0002,  0.0795],\n        [-0.0870, -0.0494,  0.0753,  ..., -0.0199, -0.0612,  0.0477],\n        ...,\n        [-0.0448, -0.0333,  0.0763,  ...,  0.0423,  0.0627,  0.0114],\n        [ 0.0823,  0.0461, -0.0403,  ..., -0.0775, -0.0470,  0.0005],\n        [ 0.0158, -0.0752,  0.0702,  ..., -0.0628, -0.0305, -0.0249]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0878, -0.0194,  0.0191,  0.0094], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-4.8344e-02, -7.1635e-03,  8.3102e-02,  9.9401e-04, -7.6113e-02,\n          5.1773e-03, -2.1294e-02, -5.4226e-02,  2.5719e-03, -8.4372e-02,\n          2.3436e-02, -8.8172e-02,  4.8561e-03,  4.7096e-02, -7.4840e-03,\n         -2.5906e-02,  4.1596e-02, -4.3219e-02,  5.5893e-03, -1.4345e-02,\n          6.7662e-02, -1.6547e-02,  5.0081e-02,  6.9217e-02,  8.7575e-02,\n         -5.0959e-02, -4.9996e-02, -5.0988e-02,  1.6867e-02,  1.5444e-02,\n          8.1002e-02, -1.6014e-02,  6.3083e-02,  7.5930e-03, -2.8454e-02,\n          1.7740e-02,  1.0127e-02,  1.5625e-02,  8.8095e-02, -2.7008e-02,\n         -3.6810e-03, -8.9450e-03,  5.6695e-02,  3.2612e-02, -6.1511e-02,\n         -1.5349e-02, -8.7352e-02,  3.7852e-02, -2.9931e-02,  1.2936e-02,\n          8.0287e-02,  6.4691e-02,  5.3150e-02,  6.2671e-02,  8.2583e-02,\n         -8.6449e-02,  1.0292e-02,  4.3359e-02,  4.3292e-02,  7.4421e-02,\n         -4.1771e-02,  4.5749e-02, -1.3310e-02,  1.2965e-02,  3.2292e-02,\n          6.6368e-02,  3.3817e-02,  6.6080e-02, -5.4654e-03, -4.1513e-02,\n          3.0050e-02, -1.3708e-02, -4.4353e-02, -6.5941e-02, -6.3104e-02,\n          4.2593e-02, -8.2415e-02, -5.5757e-02, -2.3862e-02, -2.6937e-02,\n         -8.3631e-02, -5.4059e-02, -3.8731e-02,  1.4263e-02, -7.3122e-02,\n          2.4824e-02, -3.2139e-02, -2.5462e-02,  4.4151e-02,  1.8271e-02,\n          6.5421e-03,  4.9546e-02, -1.9013e-02, -4.6795e-02,  4.2014e-02,\n          5.3890e-02, -7.8610e-02,  4.3705e-02,  1.2948e-02,  1.9398e-03,\n         -3.2302e-02,  1.7287e-02, -3.0237e-02, -5.8430e-02, -5.8451e-03,\n          3.1637e-02, -3.5278e-02,  8.5843e-03, -7.2401e-02, -7.1353e-02,\n         -8.2719e-02, -7.5985e-02,  2.4936e-02, -6.7659e-02,  2.4308e-02,\n         -7.7245e-02,  5.6756e-02, -7.3170e-02, -5.9863e-02, -1.2130e-02,\n          5.3127e-02,  5.6507e-02, -3.4403e-02,  2.5764e-02,  2.4560e-02,\n         -8.0161e-02,  7.5429e-02,  2.2196e-02],\n        [ 2.1203e-02, -2.6935e-02,  3.1679e-02, -7.4109e-02, -5.1482e-02,\n          6.2891e-02, -2.2452e-02,  2.7393e-02,  2.1881e-02, -5.4822e-02,\n         -6.7383e-02, -4.7897e-03,  6.8626e-02, -1.1462e-02, -2.4510e-02,\n          9.3247e-03, -4.1356e-02, -4.3701e-02, -3.7725e-02, -7.6410e-02,\n         -1.7532e-04, -3.7712e-02, -1.5247e-03, -5.7236e-02,  1.4013e-02,\n         -3.5077e-02,  6.6921e-02,  3.5678e-02,  4.2997e-02,  5.5324e-02,\n          7.7523e-02,  8.3194e-02,  5.3908e-02,  1.4136e-02, -1.5089e-02,\n         -2.8938e-02,  5.4399e-02, -1.4618e-02,  5.0399e-02,  6.7097e-02,\n         -5.8753e-02, -7.1763e-02, -4.4653e-02, -1.6912e-02,  4.5219e-02,\n         -5.4543e-02,  8.1697e-02, -3.1199e-02,  2.8096e-02,  4.0189e-02,\n         -3.7882e-02, -2.8815e-02,  5.4357e-02, -7.4103e-03, -3.1660e-02,\n         -7.3394e-02, -8.5973e-02, -2.5144e-03, -2.8298e-03, -4.8211e-02,\n         -6.8070e-02,  6.7321e-03,  6.5877e-02, -3.9175e-02, -3.9304e-02,\n         -5.1130e-02,  2.3993e-02,  8.1889e-02, -2.3593e-02,  8.8297e-02,\n          2.5087e-02, -3.8599e-02, -9.5165e-04, -6.9372e-02, -4.5339e-02,\n         -3.5226e-02, -8.2207e-02,  2.4081e-02,  5.4570e-02, -6.9376e-04,\n         -3.2548e-02,  7.6904e-02,  6.8081e-03, -1.6782e-02, -5.9963e-02,\n          4.6409e-02,  7.7354e-02, -1.4873e-02, -5.8682e-02,  6.4588e-02,\n         -1.6308e-02,  5.6896e-02,  7.4687e-02, -3.9236e-02,  1.0583e-02,\n         -5.2165e-03, -7.8332e-02,  4.6369e-02,  1.9138e-02,  3.7332e-03,\n         -6.2325e-02,  8.3258e-02, -6.7318e-02, -7.1579e-02,  7.9625e-02,\n          1.2020e-02, -6.0456e-02,  6.2804e-02, -7.1519e-02, -5.6902e-02,\n         -1.5321e-03,  2.9032e-02, -5.9788e-02,  8.3498e-02, -3.3436e-02,\n         -7.6653e-02,  1.8009e-02, -2.9876e-02,  6.1404e-02,  6.8723e-02,\n         -6.9799e-02,  3.5441e-02, -2.8586e-02,  6.6134e-02, -5.6249e-02,\n         -1.2080e-02, -5.5854e-02, -5.5596e-02],\n        [ 4.7276e-02, -1.6995e-02, -1.0030e-02,  5.7020e-02, -6.8183e-02,\n          6.2363e-02,  6.2096e-02, -2.6436e-02, -8.1338e-02,  5.1791e-02,\n          3.0976e-02, -8.3786e-03, -2.9151e-02, -5.1623e-02,  7.7497e-02,\n         -8.1193e-02, -4.5230e-02, -5.5388e-03, -5.8793e-02, -2.9628e-02,\n         -3.6537e-03,  8.3364e-02, -5.2874e-02, -2.4133e-02, -2.6105e-02,\n          1.2856e-02,  5.2494e-02, -5.2706e-02, -8.7074e-02, -4.0248e-02,\n          1.1301e-02, -4.4015e-02,  2.6425e-02, -8.3892e-02,  4.2665e-02,\n         -5.9070e-02, -7.0146e-03,  5.5207e-02, -4.6978e-02, -2.5166e-02,\n          4.8629e-02,  5.7606e-02,  2.9882e-02, -1.5853e-02,  7.1354e-02,\n          2.8068e-02, -3.7466e-02,  7.4017e-02, -1.9875e-02, -2.3444e-02,\n          6.7071e-02,  7.8767e-02,  7.3023e-02, -6.6862e-02,  1.8492e-02,\n          8.0935e-02,  5.0441e-02, -9.8591e-03, -1.0860e-02, -5.4951e-02,\n         -6.7988e-02,  7.5717e-02, -6.6333e-02, -2.1679e-02,  9.0925e-03,\n          1.2978e-04,  6.3702e-02,  2.3009e-02,  3.1759e-02,  3.3717e-06,\n          5.4464e-02,  1.1179e-02,  1.4023e-02,  2.9862e-02, -5.3101e-02,\n         -7.8682e-02, -6.8608e-02,  5.4509e-02,  5.5974e-02,  8.3759e-02,\n          5.7962e-02,  2.9913e-02,  8.1573e-02, -6.4830e-02,  4.0757e-02,\n          4.2371e-02,  5.6789e-02,  2.0968e-02, -6.9116e-02,  5.5296e-02,\n         -2.7216e-02,  4.1509e-02, -1.8105e-02, -5.0710e-02, -7.6159e-02,\n          7.6661e-03, -3.6503e-02, -9.6526e-03, -2.4490e-02, -6.4502e-02,\n         -7.5981e-02,  9.0590e-03, -8.9362e-03, -1.9312e-03,  3.1805e-02,\n         -5.2796e-02,  3.9658e-02, -3.6686e-02, -6.9970e-02, -6.2070e-02,\n         -5.4480e-02,  3.2492e-03,  4.9875e-02, -2.1115e-02, -6.0164e-02,\n         -4.0670e-02, -8.6521e-03,  2.5166e-03, -7.2037e-02, -5.8314e-02,\n         -2.3026e-02, -2.1109e-02, -2.7626e-02, -5.2266e-02, -8.5232e-02,\n          5.8762e-02,  4.3106e-03,  3.7804e-02],\n        [-2.4418e-02,  1.5912e-02,  1.9332e-02,  3.0117e-02,  7.9954e-02,\n          8.6314e-02,  7.9994e-02,  5.2082e-02, -1.3571e-02,  8.8355e-02,\n          7.2238e-03,  8.2818e-02, -1.7904e-02, -2.8275e-02,  5.5543e-02,\n          8.3535e-02,  3.7976e-02,  7.4554e-02,  6.0616e-02,  1.8762e-02,\n         -5.1130e-02,  7.2982e-02, -1.6454e-02, -8.7462e-02, -9.9667e-03,\n          6.0122e-02, -4.9179e-03,  6.1871e-03, -8.5098e-02, -4.7935e-03,\n          1.8492e-02, -4.3149e-03,  7.6203e-02,  1.6054e-03,  7.4831e-03,\n          1.4139e-02, -8.7912e-02,  5.0049e-02,  7.5215e-02, -7.3597e-02,\n          2.9116e-02,  3.9337e-03, -6.3458e-02, -7.0111e-02, -2.8246e-03,\n         -3.1940e-02, -3.8354e-06, -6.7690e-02,  2.2779e-02, -3.8726e-02,\n          2.2008e-02,  5.3986e-02, -3.4194e-02,  4.1125e-02,  4.9022e-02,\n         -8.6755e-02,  4.6293e-02, -2.3038e-02,  3.1554e-02, -4.6877e-02,\n          1.3222e-02, -3.5423e-02, -4.3143e-02,  3.4517e-02,  3.1584e-02,\n          6.0926e-02,  2.4578e-02,  3.5583e-02,  8.7556e-02, -8.2187e-02,\n          5.5565e-02,  3.2940e-02, -5.8303e-02, -8.5680e-02,  1.1336e-02,\n          4.4244e-02, -7.1975e-02,  8.0286e-02, -1.0325e-02, -2.4210e-04,\n         -5.8350e-02,  8.5584e-02, -1.5683e-03,  7.7724e-02,  7.5217e-02,\n         -3.1275e-02,  6.1465e-02, -2.4539e-02, -5.4644e-02,  7.3335e-03,\n         -7.4342e-02, -4.5424e-02,  7.3014e-03,  1.7411e-02, -6.2356e-02,\n         -7.5644e-02,  5.5577e-02,  7.6247e-02, -6.7479e-02,  5.2519e-02,\n          3.9956e-02, -2.6947e-03,  2.5315e-02, -4.9476e-03, -1.0795e-02,\n         -4.9029e-02, -1.6182e-02,  4.5417e-02, -7.0748e-02, -3.9906e-03,\n         -6.9016e-03,  2.7753e-02, -6.5137e-02,  3.7326e-02, -1.0559e-02,\n          7.9448e-02,  8.8007e-02, -6.7856e-02, -5.6173e-02, -2.3198e-03,\n         -7.6381e-03,  4.6665e-02,  8.6603e-02,  6.3343e-02, -2.8949e-02,\n          8.6425e-02, -5.9958e-02,  3.1024e-02]], requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x73df4da2bc90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s590480000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s590480000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}