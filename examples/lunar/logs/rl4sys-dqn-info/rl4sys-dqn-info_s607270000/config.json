{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.03,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s607270000"
    },
    "q_lr":	0.01,
    "seed":	607270000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x72d7a645ea10>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.03,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1436, -0.3786,  0.3570,  0.3868, -0.3022, -0.3311,  0.1246,  0.2294],\n        [-0.2057, -0.3104, -0.0393,  0.2667,  0.1219,  0.0535,  0.0648,  0.3114],\n        [-0.2919, -0.2964, -0.0984,  0.0527,  0.0624,  0.3295, -0.0854,  0.3725],\n        [ 0.0299,  0.0764, -0.0416,  0.1610, -0.0112,  0.0218, -0.1301, -0.0534],\n        [ 0.3771, -0.2547, -0.3065,  0.0124, -0.0746, -0.2238, -0.2598,  0.1736],\n        [-0.1849, -0.1066,  0.3652, -0.3339,  0.1432,  0.2665,  0.2304, -0.2727],\n        [ 0.3689, -0.2559, -0.2768,  0.2716,  0.2356, -0.3173,  0.3576,  0.0216],\n        [-0.2055,  0.1740,  0.3676,  0.2540,  0.1764,  0.3438, -0.2210, -0.3037],\n        [ 0.3543, -0.0555, -0.1058,  0.2528,  0.2312, -0.1682,  0.2566,  0.1924],\n        [ 0.1066, -0.2824, -0.1692,  0.0923, -0.0600,  0.0123,  0.0725, -0.3248],\n        [-0.1318,  0.0975,  0.0886,  0.1934, -0.2652, -0.3457,  0.1358,  0.0952],\n        [-0.2787,  0.2657,  0.1468, -0.1619,  0.1600,  0.0869, -0.2050, -0.0087],\n        [-0.1370, -0.2763, -0.1999, -0.2557, -0.1422,  0.0926, -0.0987,  0.2405],\n        [ 0.2753,  0.2667,  0.1561,  0.3033,  0.0616, -0.0124,  0.1230,  0.3299],\n        [-0.0578, -0.1036,  0.1337,  0.0405, -0.2671, -0.0066,  0.1530,  0.1369],\n        [ 0.2730,  0.3709,  0.1576,  0.0406,  0.1978, -0.2620, -0.0829, -0.1140],\n        [ 0.1800,  0.1267,  0.0404,  0.1629, -0.3750, -0.1295,  0.3372, -0.0045],\n        [-0.1357,  0.2255,  0.2365,  0.1331, -0.0699, -0.0635, -0.2347, -0.2826],\n        [-0.2655, -0.3769, -0.1146,  0.1533,  0.1022,  0.1967, -0.0072,  0.3119],\n        [ 0.2252, -0.0314, -0.1214, -0.0421,  0.0411,  0.3847,  0.1334,  0.1282],\n        [ 0.2640,  0.0146,  0.2208, -0.0830, -0.2343, -0.0210,  0.1932, -0.1685],\n        [ 0.0180,  0.3030, -0.3416, -0.0023,  0.1469,  0.3850, -0.0392,  0.3454],\n        [-0.0140,  0.3675, -0.2431,  0.2696, -0.2500, -0.2978,  0.1316,  0.1694],\n        [-0.1680,  0.0024, -0.0018, -0.3008,  0.3099, -0.1361,  0.2402, -0.0431],\n        [ 0.2454, -0.1191,  0.0977, -0.1389,  0.1580,  0.1306,  0.2470,  0.1729],\n        [-0.0628,  0.1923,  0.1708, -0.1337, -0.1872,  0.0224, -0.1683, -0.3497],\n        [-0.3779, -0.2968, -0.3815, -0.1846,  0.2119,  0.0518, -0.0051,  0.2948],\n        [-0.2335,  0.1289,  0.0169,  0.3096,  0.1254,  0.1515,  0.2318, -0.0305],\n        [ 0.3554, -0.3318,  0.1539, -0.0506, -0.2006,  0.0062,  0.3746,  0.2094],\n        [-0.0411, -0.3204,  0.3588,  0.2668,  0.1607,  0.3622,  0.2808, -0.3264],\n        [ 0.0126,  0.1368, -0.3191, -0.3543, -0.1487,  0.3014,  0.3028,  0.0736],\n        [-0.1574, -0.3632, -0.0672, -0.0077, -0.3513, -0.1290,  0.2092,  0.0691]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.1263e-01, -2.0324e-01, -1.3710e-01,  1.6221e-01,  2.3235e-01,\n          9.9405e-02, -1.3332e-01, -2.0840e-01,  3.4776e-01,  3.3194e-01,\n          3.0935e-02, -3.9042e-02,  2.5146e-01,  2.2229e-01,  3.3380e-01,\n          1.4656e-01, -1.1246e-01, -5.3893e-02,  1.4492e-01,  3.3318e-01,\n          2.5543e-01, -6.3797e-03, -2.6490e-01,  8.3668e-02, -1.2213e-01,\n         -1.3961e-01,  1.2933e-01,  1.2082e-01, -1.3712e-01,  3.3804e-01,\n          2.6124e-01,  9.5977e-02],\n        [-7.2562e-03,  4.3599e-02, -2.7798e-01,  2.9370e-02, -3.8936e-02,\n         -4.1332e-02, -2.5957e-01, -2.7187e-01, -3.1911e-01, -9.0088e-02,\n          2.7025e-01, -2.6925e-01, -3.2015e-01,  1.1944e-01, -1.0566e-01,\n          4.6060e-03,  1.3245e-01,  1.0933e-04,  1.5617e-01,  3.2932e-01,\n          3.1985e-01, -1.7618e-01,  2.3935e-01, -2.6106e-01,  2.0978e-01,\n         -3.0939e-01, -1.4545e-01,  3.2757e-01, -1.8438e-01, -1.2230e-01,\n         -1.4837e-01, -6.6591e-02],\n        [-2.3896e-01,  3.2374e-01, -1.5686e-01,  1.2366e-01,  2.0716e-01,\n          2.6815e-01, -2.7997e-01,  1.9107e-01,  2.1997e-01, -1.1474e-01,\n          3.5306e-01, -2.3844e-01,  2.1334e-01,  7.1722e-02,  2.0218e-01,\n          2.9513e-01, -2.3123e-01,  1.0477e-01, -2.2737e-01,  2.2156e-01,\n          5.6188e-02, -1.5512e-01, -2.1106e-02, -3.3295e-01,  3.5300e-01,\n          8.6499e-02,  4.8215e-02,  1.5484e-01, -1.6957e-01, -7.1858e-02,\n         -9.4893e-02, -2.8050e-01],\n        [ 9.6733e-02, -3.4422e-01,  3.1588e-01,  1.2728e-01,  2.0622e-01,\n         -1.1714e-01,  2.8758e-01, -1.9295e-01,  4.7782e-02, -3.2500e-01,\n         -1.9053e-01,  2.3362e-01,  1.0773e-01,  1.0791e-01,  4.6156e-02,\n         -3.5281e-02, -2.6243e-01, -1.9595e-01,  1.7854e-01,  8.4089e-02,\n          3.8656e-02,  1.5186e-01, -7.9119e-02,  5.2222e-02,  3.9552e-02,\n          1.7025e-03,  5.3763e-02,  1.1388e-01,  3.0775e-01,  3.5134e-01,\n          2.3489e-01, -8.2194e-02],\n        [-1.4740e-01,  3.2085e-01, -2.7810e-02,  1.3541e-01, -1.0361e-01,\n          3.0945e-01, -2.3608e-01, -3.2012e-01,  5.7809e-02,  3.0089e-01,\n         -1.5308e-01,  3.3026e-03, -2.2037e-01, -3.3379e-01,  2.0967e-02,\n         -3.4956e-01, -1.1188e-01, -1.6581e-01, -2.2120e-01, -2.4489e-01,\n          1.3848e-01,  2.2455e-01, -2.1702e-01, -4.9102e-02,  1.4180e-01,\n          7.3047e-02,  2.2480e-01,  4.2600e-03, -1.0999e-01,  2.7862e-01,\n         -1.6713e-01,  1.7910e-01],\n        [ 3.0483e-01, -9.8210e-02, -2.4126e-01,  3.7637e-02, -2.9708e-01,\n          1.8161e-02,  2.3891e-01,  1.7418e-01, -2.2700e-01, -6.3540e-02,\n         -3.4093e-01,  6.4867e-02, -2.6929e-01, -1.7097e-01, -2.8223e-01,\n         -6.2777e-02,  7.0864e-02,  1.4001e-01, -4.1984e-02, -3.4543e-01,\n         -2.6810e-01,  3.9476e-02,  6.7152e-02, -6.0539e-02,  2.0521e-01,\n          3.3076e-01,  1.1890e-02,  1.4611e-01, -7.3809e-02, -2.7862e-01,\n          1.7215e-01,  1.9546e-01],\n        [ 2.3765e-01, -4.4059e-02, -2.3205e-01, -8.8454e-02,  2.2079e-01,\n         -1.6204e-01, -6.2797e-02,  3.0230e-01, -4.1573e-02,  3.5208e-01,\n         -1.2344e-01,  1.4794e-01,  3.3942e-01, -2.0469e-01, -1.2484e-01,\n         -2.1818e-02, -3.0745e-01,  2.8089e-01, -4.8962e-03,  2.3846e-01,\n          3.3011e-01, -1.8691e-01,  9.4325e-02,  6.9413e-02,  3.3960e-01,\n         -2.6503e-01,  1.9769e-01, -1.6818e-01, -2.9740e-01,  2.5175e-01,\n         -1.4999e-01,  3.1260e-01],\n        [-2.6732e-01, -3.5644e-02,  3.0547e-01, -1.1478e-01, -1.4067e-01,\n         -1.0766e-01,  1.7584e-01,  2.4706e-01,  2.1298e-01,  2.5241e-02,\n          2.9445e-01, -3.0035e-01, -5.4531e-02,  1.0838e-01, -1.2003e-01,\n         -1.7525e-01,  1.1318e-01,  4.8456e-02, -2.6692e-01, -1.0214e-01,\n          5.4230e-02, -2.6323e-01, -1.2943e-01, -1.1161e-01, -9.1599e-02,\n         -5.4224e-02, -1.3509e-01, -1.4121e-01, -1.0217e-01,  2.0240e-01,\n          3.3118e-01, -3.0146e-01],\n        [ 3.1764e-01,  8.4915e-02,  7.2434e-02,  2.7166e-01, -2.1614e-01,\n         -3.3505e-01, -2.8813e-01, -2.8861e-01,  4.4889e-02, -1.2584e-01,\n          2.0729e-02, -1.0598e-01, -2.4065e-01, -1.9420e-01,  2.5771e-01,\n          8.6285e-02, -1.2738e-01, -4.7265e-02,  2.4952e-01,  2.0536e-01,\n         -1.9419e-01, -1.3235e-02, -3.4204e-01, -2.9013e-01, -1.5780e-01,\n         -2.9587e-01,  5.9295e-02,  2.5226e-01,  3.1196e-01, -9.5268e-02,\n         -3.2794e-01,  2.5083e-01],\n        [-1.3627e-01,  9.9825e-02,  2.6203e-01,  1.7131e-01, -1.4079e-01,\n          1.5382e-01,  4.4490e-02,  3.1270e-01, -2.5540e-01,  8.4104e-02,\n         -2.0088e-01, -4.3432e-02,  1.3079e-01, -1.6408e-01,  5.6059e-02,\n          9.1579e-02, -1.6760e-01,  2.3739e-02, -1.5925e-01,  1.2630e-01,\n          2.9539e-01, -1.2433e-01,  2.8676e-01,  8.6704e-02, -3.3867e-01,\n         -2.8693e-01,  1.9517e-01, -2.1783e-01,  2.6780e-01, -2.2301e-01,\n          1.3685e-01, -6.0175e-02],\n        [-2.6790e-01, -2.9769e-01, -2.1350e-01, -1.2615e-02, -3.0887e-01,\n         -2.9826e-02,  2.5060e-01, -2.0185e-01, -1.0217e-01,  3.1702e-01,\n          1.6446e-01,  3.5139e-02,  2.7511e-01, -2.9250e-01, -3.8564e-02,\n          3.2651e-01,  2.6307e-01,  3.0618e-01, -3.5220e-01,  1.4898e-01,\n          8.2797e-02, -1.0811e-01,  3.2783e-01,  2.4856e-01, -6.2786e-02,\n          1.9490e-01,  2.4691e-02, -3.4734e-01,  2.5647e-01, -1.1362e-01,\n          5.1739e-02, -1.0242e-02],\n        [ 5.2918e-02, -1.7302e-01, -2.2357e-01, -5.9235e-02, -1.8088e-01,\n          2.0436e-01,  1.0833e-01, -3.4348e-01, -2.9276e-02,  1.1373e-01,\n          2.9528e-01, -6.1337e-02,  1.6216e-01, -2.6072e-01,  1.5259e-01,\n         -1.8071e-01, -2.1411e-01, -3.7236e-02, -5.9500e-02,  1.3084e-01,\n         -3.1976e-01, -1.7598e-02,  1.3410e-01, -1.7572e-01, -2.4974e-01,\n         -3.4654e-01,  1.0319e-01,  2.2565e-01,  9.1149e-02, -5.4037e-03,\n         -1.2555e-01, -1.4516e-01],\n        [ 1.0690e-01, -2.9968e-01,  4.1697e-02,  1.3199e-01, -1.2039e-01,\n          9.7989e-02,  2.0864e-01,  2.9340e-01, -1.0547e-01, -1.9061e-01,\n          2.6156e-01, -1.2500e-01,  2.2455e-01, -1.3005e-01, -1.7396e-01,\n         -2.2814e-01, -2.5362e-01,  7.1888e-02, -6.8048e-02,  1.2420e-01,\n         -9.9914e-02,  3.4649e-01, -2.0856e-01,  3.1068e-01, -2.6468e-01,\n          2.6938e-01,  1.9579e-01, -1.3712e-01,  2.0702e-01, -2.8871e-01,\n          1.2217e-01, -6.9851e-02],\n        [-3.1374e-01,  1.0660e-01, -6.5879e-02,  7.9046e-02,  1.6889e-01,\n         -2.5329e-02, -2.0935e-01,  2.1723e-01,  1.7246e-01, -2.0810e-01,\n         -3.4394e-01, -1.7376e-01,  1.2810e-01,  2.8166e-01,  6.8863e-03,\n         -1.6077e-01,  2.8751e-01, -1.0869e-01,  2.1896e-01,  6.3131e-03,\n         -3.1606e-01,  1.0128e-01,  2.5744e-01, -3.3096e-02, -2.1516e-01,\n         -3.3080e-01, -3.5490e-02,  2.3721e-01,  9.5114e-02, -9.8846e-02,\n          2.9038e-02, -3.3926e-01],\n        [-1.3420e-01, -1.8973e-01,  2.8306e-02, -1.6937e-01,  1.6587e-01,\n         -2.8320e-01,  3.4874e-02,  6.2674e-02, -3.6160e-02,  3.5142e-01,\n         -9.8885e-02,  1.7370e-01, -2.9072e-01,  2.5997e-01,  1.9885e-01,\n          2.9648e-01,  3.0736e-01,  2.8782e-01,  2.1409e-02,  3.1240e-01,\n         -4.9114e-02, -6.5055e-03, -2.9261e-01,  1.2826e-01,  1.5891e-01,\n         -1.8670e-01, -2.2213e-01, -1.2066e-01, -2.7205e-01,  2.8861e-01,\n          1.2767e-01,  1.0723e-01],\n        [-1.0430e-01, -2.8411e-01, -3.4618e-01,  2.3462e-01,  4.6421e-02,\n          2.1831e-01, -8.7621e-02, -1.9530e-01,  6.4070e-02, -3.0833e-01,\n          5.7945e-02,  1.5940e-01, -1.7053e-01,  2.0821e-01,  1.3254e-01,\n          2.9012e-02,  1.2605e-01,  2.2724e-01,  3.3793e-01,  1.8245e-01,\n         -1.2474e-01, -4.9065e-02,  1.3464e-02, -7.8353e-02, -4.5920e-02,\n          2.4500e-01,  1.9266e-02,  2.2891e-01, -4.8679e-02, -3.1767e-01,\n          6.9396e-02, -1.8241e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.4421, -0.2316, -0.2691, -0.4011,  0.4270, -0.2557,  0.2702,  0.2548,\n          0.3603, -0.4211,  0.0232, -0.4384,  0.1420,  0.3349, -0.1153,  0.4538],\n        [-0.0108,  0.3831,  0.1312,  0.2312,  0.2712,  0.4138,  0.1693, -0.3500,\n          0.0327,  0.0171,  0.4329, -0.4019, -0.3907,  0.1335,  0.3437, -0.0660],\n        [ 0.0394,  0.0238, -0.2254, -0.2453, -0.2210, -0.3167,  0.4962,  0.0029,\n          0.0658, -0.4997, -0.0241,  0.0259, -0.0520, -0.3632, -0.0940,  0.2764],\n        [-0.3185,  0.2672, -0.4457,  0.1833,  0.4043,  0.2273, -0.1812,  0.0620,\n         -0.0452, -0.3722, -0.0645, -0.1011,  0.0555, -0.2924, -0.3795, -0.4618],\n        [ 0.0908, -0.2102,  0.3828,  0.2256, -0.2369, -0.2272,  0.2952, -0.3849,\n         -0.3089,  0.2632,  0.2221, -0.4128,  0.3984, -0.4983,  0.4210, -0.1195],\n        [-0.2573, -0.4181, -0.3452,  0.4388,  0.2730, -0.0817,  0.2650,  0.0036,\n         -0.2323, -0.1056, -0.1019,  0.4754, -0.4286, -0.3661,  0.1480, -0.0560],\n        [ 0.4381,  0.4503,  0.4371,  0.3057, -0.1655, -0.2737, -0.3859, -0.2444,\n          0.2804,  0.4329, -0.3781, -0.3824,  0.3812,  0.0471, -0.4709,  0.3440],\n        [-0.2758,  0.3007,  0.3536,  0.2209, -0.3503, -0.4577, -0.4665, -0.2623,\n          0.0392,  0.4877, -0.4871,  0.2265, -0.4569,  0.0081, -0.0447,  0.3528]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1335, -0.6668, -0.5482, -0.1949,  0.6891, -0.4738,  0.5374,  0.6116],\n        [ 0.2728,  0.2920, -0.1179, -0.3488, -0.4515, -0.4172,  0.2556,  0.6595],\n        [-0.3650,  0.4794, -0.5217, -0.4643, -0.0287,  0.2363,  0.1611,  0.4560],\n        [-0.1149, -0.1994,  0.7036, -0.0026,  0.4540,  0.0930, -0.5987,  0.3239]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.01\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.01,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.01,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1436, -0.3786,  0.3570,  0.3868, -0.3022, -0.3311,  0.1246,  0.2294],\n        [-0.2057, -0.3104, -0.0393,  0.2667,  0.1219,  0.0535,  0.0648,  0.3114],\n        [-0.2919, -0.2964, -0.0984,  0.0527,  0.0624,  0.3295, -0.0854,  0.3725],\n        [ 0.0299,  0.0764, -0.0416,  0.1610, -0.0112,  0.0218, -0.1301, -0.0534],\n        [ 0.3771, -0.2547, -0.3065,  0.0124, -0.0746, -0.2238, -0.2598,  0.1736],\n        [-0.1849, -0.1066,  0.3652, -0.3339,  0.1432,  0.2665,  0.2304, -0.2727],\n        [ 0.3689, -0.2559, -0.2768,  0.2716,  0.2356, -0.3173,  0.3576,  0.0216],\n        [-0.2055,  0.1740,  0.3676,  0.2540,  0.1764,  0.3438, -0.2210, -0.3037],\n        [ 0.3543, -0.0555, -0.1058,  0.2528,  0.2312, -0.1682,  0.2566,  0.1924],\n        [ 0.1066, -0.2824, -0.1692,  0.0923, -0.0600,  0.0123,  0.0725, -0.3248],\n        [-0.1318,  0.0975,  0.0886,  0.1934, -0.2652, -0.3457,  0.1358,  0.0952],\n        [-0.2787,  0.2657,  0.1468, -0.1619,  0.1600,  0.0869, -0.2050, -0.0087],\n        [-0.1370, -0.2763, -0.1999, -0.2557, -0.1422,  0.0926, -0.0987,  0.2405],\n        [ 0.2753,  0.2667,  0.1561,  0.3033,  0.0616, -0.0124,  0.1230,  0.3299],\n        [-0.0578, -0.1036,  0.1337,  0.0405, -0.2671, -0.0066,  0.1530,  0.1369],\n        [ 0.2730,  0.3709,  0.1576,  0.0406,  0.1978, -0.2620, -0.0829, -0.1140],\n        [ 0.1800,  0.1267,  0.0404,  0.1629, -0.3750, -0.1295,  0.3372, -0.0045],\n        [-0.1357,  0.2255,  0.2365,  0.1331, -0.0699, -0.0635, -0.2347, -0.2826],\n        [-0.2655, -0.3769, -0.1146,  0.1533,  0.1022,  0.1967, -0.0072,  0.3119],\n        [ 0.2252, -0.0314, -0.1214, -0.0421,  0.0411,  0.3847,  0.1334,  0.1282],\n        [ 0.2640,  0.0146,  0.2208, -0.0830, -0.2343, -0.0210,  0.1932, -0.1685],\n        [ 0.0180,  0.3030, -0.3416, -0.0023,  0.1469,  0.3850, -0.0392,  0.3454],\n        [-0.0140,  0.3675, -0.2431,  0.2696, -0.2500, -0.2978,  0.1316,  0.1694],\n        [-0.1680,  0.0024, -0.0018, -0.3008,  0.3099, -0.1361,  0.2402, -0.0431],\n        [ 0.2454, -0.1191,  0.0977, -0.1389,  0.1580,  0.1306,  0.2470,  0.1729],\n        [-0.0628,  0.1923,  0.1708, -0.1337, -0.1872,  0.0224, -0.1683, -0.3497],\n        [-0.3779, -0.2968, -0.3815, -0.1846,  0.2119,  0.0518, -0.0051,  0.2948],\n        [-0.2335,  0.1289,  0.0169,  0.3096,  0.1254,  0.1515,  0.2318, -0.0305],\n        [ 0.3554, -0.3318,  0.1539, -0.0506, -0.2006,  0.0062,  0.3746,  0.2094],\n        [-0.0411, -0.3204,  0.3588,  0.2668,  0.1607,  0.3622,  0.2808, -0.3264],\n        [ 0.0126,  0.1368, -0.3191, -0.3543, -0.1487,  0.3014,  0.3028,  0.0736],\n        [-0.1574, -0.3632, -0.0672, -0.0077, -0.3513, -0.1290,  0.2092,  0.0691]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[-3.1263e-01, -2.0324e-01, -1.3710e-01,  1.6221e-01,  2.3235e-01,\n          9.9405e-02, -1.3332e-01, -2.0840e-01,  3.4776e-01,  3.3194e-01,\n          3.0935e-02, -3.9042e-02,  2.5146e-01,  2.2229e-01,  3.3380e-01,\n          1.4656e-01, -1.1246e-01, -5.3893e-02,  1.4492e-01,  3.3318e-01,\n          2.5543e-01, -6.3797e-03, -2.6490e-01,  8.3668e-02, -1.2213e-01,\n         -1.3961e-01,  1.2933e-01,  1.2082e-01, -1.3712e-01,  3.3804e-01,\n          2.6124e-01,  9.5977e-02],\n        [-7.2562e-03,  4.3599e-02, -2.7798e-01,  2.9370e-02, -3.8936e-02,\n         -4.1332e-02, -2.5957e-01, -2.7187e-01, -3.1911e-01, -9.0088e-02,\n          2.7025e-01, -2.6925e-01, -3.2015e-01,  1.1944e-01, -1.0566e-01,\n          4.6060e-03,  1.3245e-01,  1.0933e-04,  1.5617e-01,  3.2932e-01,\n          3.1985e-01, -1.7618e-01,  2.3935e-01, -2.6106e-01,  2.0978e-01,\n         -3.0939e-01, -1.4545e-01,  3.2757e-01, -1.8438e-01, -1.2230e-01,\n         -1.4837e-01, -6.6591e-02],\n        [-2.3896e-01,  3.2374e-01, -1.5686e-01,  1.2366e-01,  2.0716e-01,\n          2.6815e-01, -2.7997e-01,  1.9107e-01,  2.1997e-01, -1.1474e-01,\n          3.5306e-01, -2.3844e-01,  2.1334e-01,  7.1722e-02,  2.0218e-01,\n          2.9513e-01, -2.3123e-01,  1.0477e-01, -2.2737e-01,  2.2156e-01,\n          5.6188e-02, -1.5512e-01, -2.1106e-02, -3.3295e-01,  3.5300e-01,\n          8.6499e-02,  4.8215e-02,  1.5484e-01, -1.6957e-01, -7.1858e-02,\n         -9.4893e-02, -2.8050e-01],\n        [ 9.6733e-02, -3.4422e-01,  3.1588e-01,  1.2728e-01,  2.0622e-01,\n         -1.1714e-01,  2.8758e-01, -1.9295e-01,  4.7782e-02, -3.2500e-01,\n         -1.9053e-01,  2.3362e-01,  1.0773e-01,  1.0791e-01,  4.6156e-02,\n         -3.5281e-02, -2.6243e-01, -1.9595e-01,  1.7854e-01,  8.4089e-02,\n          3.8656e-02,  1.5186e-01, -7.9119e-02,  5.2222e-02,  3.9552e-02,\n          1.7025e-03,  5.3763e-02,  1.1388e-01,  3.0775e-01,  3.5134e-01,\n          2.3489e-01, -8.2194e-02],\n        [-1.4740e-01,  3.2085e-01, -2.7810e-02,  1.3541e-01, -1.0361e-01,\n          3.0945e-01, -2.3608e-01, -3.2012e-01,  5.7809e-02,  3.0089e-01,\n         -1.5308e-01,  3.3026e-03, -2.2037e-01, -3.3379e-01,  2.0967e-02,\n         -3.4956e-01, -1.1188e-01, -1.6581e-01, -2.2120e-01, -2.4489e-01,\n          1.3848e-01,  2.2455e-01, -2.1702e-01, -4.9102e-02,  1.4180e-01,\n          7.3047e-02,  2.2480e-01,  4.2600e-03, -1.0999e-01,  2.7862e-01,\n         -1.6713e-01,  1.7910e-01],\n        [ 3.0483e-01, -9.8210e-02, -2.4126e-01,  3.7637e-02, -2.9708e-01,\n          1.8161e-02,  2.3891e-01,  1.7418e-01, -2.2700e-01, -6.3540e-02,\n         -3.4093e-01,  6.4867e-02, -2.6929e-01, -1.7097e-01, -2.8223e-01,\n         -6.2777e-02,  7.0864e-02,  1.4001e-01, -4.1984e-02, -3.4543e-01,\n         -2.6810e-01,  3.9476e-02,  6.7152e-02, -6.0539e-02,  2.0521e-01,\n          3.3076e-01,  1.1890e-02,  1.4611e-01, -7.3809e-02, -2.7862e-01,\n          1.7215e-01,  1.9546e-01],\n        [ 2.3765e-01, -4.4059e-02, -2.3205e-01, -8.8454e-02,  2.2079e-01,\n         -1.6204e-01, -6.2797e-02,  3.0230e-01, -4.1573e-02,  3.5208e-01,\n         -1.2344e-01,  1.4794e-01,  3.3942e-01, -2.0469e-01, -1.2484e-01,\n         -2.1818e-02, -3.0745e-01,  2.8089e-01, -4.8962e-03,  2.3846e-01,\n          3.3011e-01, -1.8691e-01,  9.4325e-02,  6.9413e-02,  3.3960e-01,\n         -2.6503e-01,  1.9769e-01, -1.6818e-01, -2.9740e-01,  2.5175e-01,\n         -1.4999e-01,  3.1260e-01],\n        [-2.6732e-01, -3.5644e-02,  3.0547e-01, -1.1478e-01, -1.4067e-01,\n         -1.0766e-01,  1.7584e-01,  2.4706e-01,  2.1298e-01,  2.5241e-02,\n          2.9445e-01, -3.0035e-01, -5.4531e-02,  1.0838e-01, -1.2003e-01,\n         -1.7525e-01,  1.1318e-01,  4.8456e-02, -2.6692e-01, -1.0214e-01,\n          5.4230e-02, -2.6323e-01, -1.2943e-01, -1.1161e-01, -9.1599e-02,\n         -5.4224e-02, -1.3509e-01, -1.4121e-01, -1.0217e-01,  2.0240e-01,\n          3.3118e-01, -3.0146e-01],\n        [ 3.1764e-01,  8.4915e-02,  7.2434e-02,  2.7166e-01, -2.1614e-01,\n         -3.3505e-01, -2.8813e-01, -2.8861e-01,  4.4889e-02, -1.2584e-01,\n          2.0729e-02, -1.0598e-01, -2.4065e-01, -1.9420e-01,  2.5771e-01,\n          8.6285e-02, -1.2738e-01, -4.7265e-02,  2.4952e-01,  2.0536e-01,\n         -1.9419e-01, -1.3235e-02, -3.4204e-01, -2.9013e-01, -1.5780e-01,\n         -2.9587e-01,  5.9295e-02,  2.5226e-01,  3.1196e-01, -9.5268e-02,\n         -3.2794e-01,  2.5083e-01],\n        [-1.3627e-01,  9.9825e-02,  2.6203e-01,  1.7131e-01, -1.4079e-01,\n          1.5382e-01,  4.4490e-02,  3.1270e-01, -2.5540e-01,  8.4104e-02,\n         -2.0088e-01, -4.3432e-02,  1.3079e-01, -1.6408e-01,  5.6059e-02,\n          9.1579e-02, -1.6760e-01,  2.3739e-02, -1.5925e-01,  1.2630e-01,\n          2.9539e-01, -1.2433e-01,  2.8676e-01,  8.6704e-02, -3.3867e-01,\n         -2.8693e-01,  1.9517e-01, -2.1783e-01,  2.6780e-01, -2.2301e-01,\n          1.3685e-01, -6.0175e-02],\n        [-2.6790e-01, -2.9769e-01, -2.1350e-01, -1.2615e-02, -3.0887e-01,\n         -2.9826e-02,  2.5060e-01, -2.0185e-01, -1.0217e-01,  3.1702e-01,\n          1.6446e-01,  3.5139e-02,  2.7511e-01, -2.9250e-01, -3.8564e-02,\n          3.2651e-01,  2.6307e-01,  3.0618e-01, -3.5220e-01,  1.4898e-01,\n          8.2797e-02, -1.0811e-01,  3.2783e-01,  2.4856e-01, -6.2786e-02,\n          1.9490e-01,  2.4691e-02, -3.4734e-01,  2.5647e-01, -1.1362e-01,\n          5.1739e-02, -1.0242e-02],\n        [ 5.2918e-02, -1.7302e-01, -2.2357e-01, -5.9235e-02, -1.8088e-01,\n          2.0436e-01,  1.0833e-01, -3.4348e-01, -2.9276e-02,  1.1373e-01,\n          2.9528e-01, -6.1337e-02,  1.6216e-01, -2.6072e-01,  1.5259e-01,\n         -1.8071e-01, -2.1411e-01, -3.7236e-02, -5.9500e-02,  1.3084e-01,\n         -3.1976e-01, -1.7598e-02,  1.3410e-01, -1.7572e-01, -2.4974e-01,\n         -3.4654e-01,  1.0319e-01,  2.2565e-01,  9.1149e-02, -5.4037e-03,\n         -1.2555e-01, -1.4516e-01],\n        [ 1.0690e-01, -2.9968e-01,  4.1697e-02,  1.3199e-01, -1.2039e-01,\n          9.7989e-02,  2.0864e-01,  2.9340e-01, -1.0547e-01, -1.9061e-01,\n          2.6156e-01, -1.2500e-01,  2.2455e-01, -1.3005e-01, -1.7396e-01,\n         -2.2814e-01, -2.5362e-01,  7.1888e-02, -6.8048e-02,  1.2420e-01,\n         -9.9914e-02,  3.4649e-01, -2.0856e-01,  3.1068e-01, -2.6468e-01,\n          2.6938e-01,  1.9579e-01, -1.3712e-01,  2.0702e-01, -2.8871e-01,\n          1.2217e-01, -6.9851e-02],\n        [-3.1374e-01,  1.0660e-01, -6.5879e-02,  7.9046e-02,  1.6889e-01,\n         -2.5329e-02, -2.0935e-01,  2.1723e-01,  1.7246e-01, -2.0810e-01,\n         -3.4394e-01, -1.7376e-01,  1.2810e-01,  2.8166e-01,  6.8863e-03,\n         -1.6077e-01,  2.8751e-01, -1.0869e-01,  2.1896e-01,  6.3131e-03,\n         -3.1606e-01,  1.0128e-01,  2.5744e-01, -3.3096e-02, -2.1516e-01,\n         -3.3080e-01, -3.5490e-02,  2.3721e-01,  9.5114e-02, -9.8846e-02,\n          2.9038e-02, -3.3926e-01],\n        [-1.3420e-01, -1.8973e-01,  2.8306e-02, -1.6937e-01,  1.6587e-01,\n         -2.8320e-01,  3.4874e-02,  6.2674e-02, -3.6160e-02,  3.5142e-01,\n         -9.8885e-02,  1.7370e-01, -2.9072e-01,  2.5997e-01,  1.9885e-01,\n          2.9648e-01,  3.0736e-01,  2.8782e-01,  2.1409e-02,  3.1240e-01,\n         -4.9114e-02, -6.5055e-03, -2.9261e-01,  1.2826e-01,  1.5891e-01,\n         -1.8670e-01, -2.2213e-01, -1.2066e-01, -2.7205e-01,  2.8861e-01,\n          1.2767e-01,  1.0723e-01],\n        [-1.0430e-01, -2.8411e-01, -3.4618e-01,  2.3462e-01,  4.6421e-02,\n          2.1831e-01, -8.7621e-02, -1.9530e-01,  6.4070e-02, -3.0833e-01,\n          5.7945e-02,  1.5940e-01, -1.7053e-01,  2.0821e-01,  1.3254e-01,\n          2.9012e-02,  1.2605e-01,  2.2724e-01,  3.3793e-01,  1.8245e-01,\n         -1.2474e-01, -4.9065e-02,  1.3464e-02, -7.8353e-02, -4.5920e-02,\n          2.4500e-01,  1.9266e-02,  2.2891e-01, -4.8679e-02, -3.1767e-01,\n          6.9396e-02, -1.8241e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.4421, -0.2316, -0.2691, -0.4011,  0.4270, -0.2557,  0.2702,  0.2548,\n          0.3603, -0.4211,  0.0232, -0.4384,  0.1420,  0.3349, -0.1153,  0.4538],\n        [-0.0108,  0.3831,  0.1312,  0.2312,  0.2712,  0.4138,  0.1693, -0.3500,\n          0.0327,  0.0171,  0.4329, -0.4019, -0.3907,  0.1335,  0.3437, -0.0660],\n        [ 0.0394,  0.0238, -0.2254, -0.2453, -0.2210, -0.3167,  0.4962,  0.0029,\n          0.0658, -0.4997, -0.0241,  0.0259, -0.0520, -0.3632, -0.0940,  0.2764],\n        [-0.3185,  0.2672, -0.4457,  0.1833,  0.4043,  0.2273, -0.1812,  0.0620,\n         -0.0452, -0.3722, -0.0645, -0.1011,  0.0555, -0.2924, -0.3795, -0.4618],\n        [ 0.0908, -0.2102,  0.3828,  0.2256, -0.2369, -0.2272,  0.2952, -0.3849,\n         -0.3089,  0.2632,  0.2221, -0.4128,  0.3984, -0.4983,  0.4210, -0.1195],\n        [-0.2573, -0.4181, -0.3452,  0.4388,  0.2730, -0.0817,  0.2650,  0.0036,\n         -0.2323, -0.1056, -0.1019,  0.4754, -0.4286, -0.3661,  0.1480, -0.0560],\n        [ 0.4381,  0.4503,  0.4371,  0.3057, -0.1655, -0.2737, -0.3859, -0.2444,\n          0.2804,  0.4329, -0.3781, -0.3824,  0.3812,  0.0471, -0.4709,  0.3440],\n        [-0.2758,  0.3007,  0.3536,  0.2209, -0.3503, -0.4577, -0.4665, -0.2623,\n          0.0392,  0.4877, -0.4871,  0.2265, -0.4569,  0.0081, -0.0447,  0.3528]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1335, -0.6668, -0.5482, -0.1949,  0.6891, -0.4738,  0.5374,  0.6116],\n        [ 0.2728,  0.2920, -0.1179, -0.3488, -0.4515, -0.4172,  0.2556,  0.6595],\n        [-0.3650,  0.4794, -0.5217, -0.4643, -0.0287,  0.2363,  0.1611,  0.4560],\n        [-0.1149, -0.1994,  0.7036, -0.0026,  0.4540,  0.0930, -0.5987,  0.3239]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x72d7a64d1210>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1436, -0.3786,  0.3570,  0.3868, -0.3022, -0.3311,  0.1246,  0.2294],\n        [-0.2057, -0.3104, -0.0393,  0.2667,  0.1219,  0.0535,  0.0648,  0.3114],\n        [-0.2919, -0.2964, -0.0984,  0.0527,  0.0624,  0.3295, -0.0854,  0.3725],\n        [ 0.0299,  0.0764, -0.0416,  0.1610, -0.0112,  0.0218, -0.1301, -0.0534],\n        [ 0.3771, -0.2547, -0.3065,  0.0124, -0.0746, -0.2238, -0.2598,  0.1736],\n        [-0.1849, -0.1066,  0.3652, -0.3339,  0.1432,  0.2665,  0.2304, -0.2727],\n        [ 0.3689, -0.2559, -0.2768,  0.2716,  0.2356, -0.3173,  0.3576,  0.0216],\n        [-0.2055,  0.1740,  0.3676,  0.2540,  0.1764,  0.3438, -0.2210, -0.3037],\n        [ 0.3543, -0.0555, -0.1058,  0.2528,  0.2312, -0.1682,  0.2566,  0.1924],\n        [ 0.1066, -0.2824, -0.1692,  0.0923, -0.0600,  0.0123,  0.0725, -0.3248],\n        [-0.1318,  0.0975,  0.0886,  0.1934, -0.2652, -0.3457,  0.1358,  0.0952],\n        [-0.2787,  0.2657,  0.1468, -0.1619,  0.1600,  0.0869, -0.2050, -0.0087],\n        [-0.1370, -0.2763, -0.1999, -0.2557, -0.1422,  0.0926, -0.0987,  0.2405],\n        [ 0.2753,  0.2667,  0.1561,  0.3033,  0.0616, -0.0124,  0.1230,  0.3299],\n        [-0.0578, -0.1036,  0.1337,  0.0405, -0.2671, -0.0066,  0.1530,  0.1369],\n        [ 0.2730,  0.3709,  0.1576,  0.0406,  0.1978, -0.2620, -0.0829, -0.1140],\n        [ 0.1800,  0.1267,  0.0404,  0.1629, -0.3750, -0.1295,  0.3372, -0.0045],\n        [-0.1357,  0.2255,  0.2365,  0.1331, -0.0699, -0.0635, -0.2347, -0.2826],\n        [-0.2655, -0.3769, -0.1146,  0.1533,  0.1022,  0.1967, -0.0072,  0.3119],\n        [ 0.2252, -0.0314, -0.1214, -0.0421,  0.0411,  0.3847,  0.1334,  0.1282],\n        [ 0.2640,  0.0146,  0.2208, -0.0830, -0.2343, -0.0210,  0.1932, -0.1685],\n        [ 0.0180,  0.3030, -0.3416, -0.0023,  0.1469,  0.3850, -0.0392,  0.3454],\n        [-0.0140,  0.3675, -0.2431,  0.2696, -0.2500, -0.2978,  0.1316,  0.1694],\n        [-0.1680,  0.0024, -0.0018, -0.3008,  0.3099, -0.1361,  0.2402, -0.0431],\n        [ 0.2454, -0.1191,  0.0977, -0.1389,  0.1580,  0.1306,  0.2470,  0.1729],\n        [-0.0628,  0.1923,  0.1708, -0.1337, -0.1872,  0.0224, -0.1683, -0.3497],\n        [-0.3779, -0.2968, -0.3815, -0.1846,  0.2119,  0.0518, -0.0051,  0.2948],\n        [-0.2335,  0.1289,  0.0169,  0.3096,  0.1254,  0.1515,  0.2318, -0.0305],\n        [ 0.3554, -0.3318,  0.1539, -0.0506, -0.2006,  0.0062,  0.3746,  0.2094],\n        [-0.0411, -0.3204,  0.3588,  0.2668,  0.1607,  0.3622,  0.2808, -0.3264],\n        [ 0.0126,  0.1368, -0.3191, -0.3543, -0.1487,  0.3014,  0.3028,  0.0736],\n        [-0.1574, -0.3632, -0.0672, -0.0077, -0.3513, -0.1290,  0.2092,  0.0691]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.1263e-01, -2.0324e-01, -1.3710e-01,  1.6221e-01,  2.3235e-01,\n          9.9405e-02, -1.3332e-01, -2.0840e-01,  3.4776e-01,  3.3194e-01,\n          3.0935e-02, -3.9042e-02,  2.5146e-01,  2.2229e-01,  3.3380e-01,\n          1.4656e-01, -1.1246e-01, -5.3893e-02,  1.4492e-01,  3.3318e-01,\n          2.5543e-01, -6.3797e-03, -2.6490e-01,  8.3668e-02, -1.2213e-01,\n         -1.3961e-01,  1.2933e-01,  1.2082e-01, -1.3712e-01,  3.3804e-01,\n          2.6124e-01,  9.5977e-02],\n        [-7.2562e-03,  4.3599e-02, -2.7798e-01,  2.9370e-02, -3.8936e-02,\n         -4.1332e-02, -2.5957e-01, -2.7187e-01, -3.1911e-01, -9.0088e-02,\n          2.7025e-01, -2.6925e-01, -3.2015e-01,  1.1944e-01, -1.0566e-01,\n          4.6060e-03,  1.3245e-01,  1.0933e-04,  1.5617e-01,  3.2932e-01,\n          3.1985e-01, -1.7618e-01,  2.3935e-01, -2.6106e-01,  2.0978e-01,\n         -3.0939e-01, -1.4545e-01,  3.2757e-01, -1.8438e-01, -1.2230e-01,\n         -1.4837e-01, -6.6591e-02],\n        [-2.3896e-01,  3.2374e-01, -1.5686e-01,  1.2366e-01,  2.0716e-01,\n          2.6815e-01, -2.7997e-01,  1.9107e-01,  2.1997e-01, -1.1474e-01,\n          3.5306e-01, -2.3844e-01,  2.1334e-01,  7.1722e-02,  2.0218e-01,\n          2.9513e-01, -2.3123e-01,  1.0477e-01, -2.2737e-01,  2.2156e-01,\n          5.6188e-02, -1.5512e-01, -2.1106e-02, -3.3295e-01,  3.5300e-01,\n          8.6499e-02,  4.8215e-02,  1.5484e-01, -1.6957e-01, -7.1858e-02,\n         -9.4893e-02, -2.8050e-01],\n        [ 9.6733e-02, -3.4422e-01,  3.1588e-01,  1.2728e-01,  2.0622e-01,\n         -1.1714e-01,  2.8758e-01, -1.9295e-01,  4.7782e-02, -3.2500e-01,\n         -1.9053e-01,  2.3362e-01,  1.0773e-01,  1.0791e-01,  4.6156e-02,\n         -3.5281e-02, -2.6243e-01, -1.9595e-01,  1.7854e-01,  8.4089e-02,\n          3.8656e-02,  1.5186e-01, -7.9119e-02,  5.2222e-02,  3.9552e-02,\n          1.7025e-03,  5.3763e-02,  1.1388e-01,  3.0775e-01,  3.5134e-01,\n          2.3489e-01, -8.2194e-02],\n        [-1.4740e-01,  3.2085e-01, -2.7810e-02,  1.3541e-01, -1.0361e-01,\n          3.0945e-01, -2.3608e-01, -3.2012e-01,  5.7809e-02,  3.0089e-01,\n         -1.5308e-01,  3.3026e-03, -2.2037e-01, -3.3379e-01,  2.0967e-02,\n         -3.4956e-01, -1.1188e-01, -1.6581e-01, -2.2120e-01, -2.4489e-01,\n          1.3848e-01,  2.2455e-01, -2.1702e-01, -4.9102e-02,  1.4180e-01,\n          7.3047e-02,  2.2480e-01,  4.2600e-03, -1.0999e-01,  2.7862e-01,\n         -1.6713e-01,  1.7910e-01],\n        [ 3.0483e-01, -9.8210e-02, -2.4126e-01,  3.7637e-02, -2.9708e-01,\n          1.8161e-02,  2.3891e-01,  1.7418e-01, -2.2700e-01, -6.3540e-02,\n         -3.4093e-01,  6.4867e-02, -2.6929e-01, -1.7097e-01, -2.8223e-01,\n         -6.2777e-02,  7.0864e-02,  1.4001e-01, -4.1984e-02, -3.4543e-01,\n         -2.6810e-01,  3.9476e-02,  6.7152e-02, -6.0539e-02,  2.0521e-01,\n          3.3076e-01,  1.1890e-02,  1.4611e-01, -7.3809e-02, -2.7862e-01,\n          1.7215e-01,  1.9546e-01],\n        [ 2.3765e-01, -4.4059e-02, -2.3205e-01, -8.8454e-02,  2.2079e-01,\n         -1.6204e-01, -6.2797e-02,  3.0230e-01, -4.1573e-02,  3.5208e-01,\n         -1.2344e-01,  1.4794e-01,  3.3942e-01, -2.0469e-01, -1.2484e-01,\n         -2.1818e-02, -3.0745e-01,  2.8089e-01, -4.8962e-03,  2.3846e-01,\n          3.3011e-01, -1.8691e-01,  9.4325e-02,  6.9413e-02,  3.3960e-01,\n         -2.6503e-01,  1.9769e-01, -1.6818e-01, -2.9740e-01,  2.5175e-01,\n         -1.4999e-01,  3.1260e-01],\n        [-2.6732e-01, -3.5644e-02,  3.0547e-01, -1.1478e-01, -1.4067e-01,\n         -1.0766e-01,  1.7584e-01,  2.4706e-01,  2.1298e-01,  2.5241e-02,\n          2.9445e-01, -3.0035e-01, -5.4531e-02,  1.0838e-01, -1.2003e-01,\n         -1.7525e-01,  1.1318e-01,  4.8456e-02, -2.6692e-01, -1.0214e-01,\n          5.4230e-02, -2.6323e-01, -1.2943e-01, -1.1161e-01, -9.1599e-02,\n         -5.4224e-02, -1.3509e-01, -1.4121e-01, -1.0217e-01,  2.0240e-01,\n          3.3118e-01, -3.0146e-01],\n        [ 3.1764e-01,  8.4915e-02,  7.2434e-02,  2.7166e-01, -2.1614e-01,\n         -3.3505e-01, -2.8813e-01, -2.8861e-01,  4.4889e-02, -1.2584e-01,\n          2.0729e-02, -1.0598e-01, -2.4065e-01, -1.9420e-01,  2.5771e-01,\n          8.6285e-02, -1.2738e-01, -4.7265e-02,  2.4952e-01,  2.0536e-01,\n         -1.9419e-01, -1.3235e-02, -3.4204e-01, -2.9013e-01, -1.5780e-01,\n         -2.9587e-01,  5.9295e-02,  2.5226e-01,  3.1196e-01, -9.5268e-02,\n         -3.2794e-01,  2.5083e-01],\n        [-1.3627e-01,  9.9825e-02,  2.6203e-01,  1.7131e-01, -1.4079e-01,\n          1.5382e-01,  4.4490e-02,  3.1270e-01, -2.5540e-01,  8.4104e-02,\n         -2.0088e-01, -4.3432e-02,  1.3079e-01, -1.6408e-01,  5.6059e-02,\n          9.1579e-02, -1.6760e-01,  2.3739e-02, -1.5925e-01,  1.2630e-01,\n          2.9539e-01, -1.2433e-01,  2.8676e-01,  8.6704e-02, -3.3867e-01,\n         -2.8693e-01,  1.9517e-01, -2.1783e-01,  2.6780e-01, -2.2301e-01,\n          1.3685e-01, -6.0175e-02],\n        [-2.6790e-01, -2.9769e-01, -2.1350e-01, -1.2615e-02, -3.0887e-01,\n         -2.9826e-02,  2.5060e-01, -2.0185e-01, -1.0217e-01,  3.1702e-01,\n          1.6446e-01,  3.5139e-02,  2.7511e-01, -2.9250e-01, -3.8564e-02,\n          3.2651e-01,  2.6307e-01,  3.0618e-01, -3.5220e-01,  1.4898e-01,\n          8.2797e-02, -1.0811e-01,  3.2783e-01,  2.4856e-01, -6.2786e-02,\n          1.9490e-01,  2.4691e-02, -3.4734e-01,  2.5647e-01, -1.1362e-01,\n          5.1739e-02, -1.0242e-02],\n        [ 5.2918e-02, -1.7302e-01, -2.2357e-01, -5.9235e-02, -1.8088e-01,\n          2.0436e-01,  1.0833e-01, -3.4348e-01, -2.9276e-02,  1.1373e-01,\n          2.9528e-01, -6.1337e-02,  1.6216e-01, -2.6072e-01,  1.5259e-01,\n         -1.8071e-01, -2.1411e-01, -3.7236e-02, -5.9500e-02,  1.3084e-01,\n         -3.1976e-01, -1.7598e-02,  1.3410e-01, -1.7572e-01, -2.4974e-01,\n         -3.4654e-01,  1.0319e-01,  2.2565e-01,  9.1149e-02, -5.4037e-03,\n         -1.2555e-01, -1.4516e-01],\n        [ 1.0690e-01, -2.9968e-01,  4.1697e-02,  1.3199e-01, -1.2039e-01,\n          9.7989e-02,  2.0864e-01,  2.9340e-01, -1.0547e-01, -1.9061e-01,\n          2.6156e-01, -1.2500e-01,  2.2455e-01, -1.3005e-01, -1.7396e-01,\n         -2.2814e-01, -2.5362e-01,  7.1888e-02, -6.8048e-02,  1.2420e-01,\n         -9.9914e-02,  3.4649e-01, -2.0856e-01,  3.1068e-01, -2.6468e-01,\n          2.6938e-01,  1.9579e-01, -1.3712e-01,  2.0702e-01, -2.8871e-01,\n          1.2217e-01, -6.9851e-02],\n        [-3.1374e-01,  1.0660e-01, -6.5879e-02,  7.9046e-02,  1.6889e-01,\n         -2.5329e-02, -2.0935e-01,  2.1723e-01,  1.7246e-01, -2.0810e-01,\n         -3.4394e-01, -1.7376e-01,  1.2810e-01,  2.8166e-01,  6.8863e-03,\n         -1.6077e-01,  2.8751e-01, -1.0869e-01,  2.1896e-01,  6.3131e-03,\n         -3.1606e-01,  1.0128e-01,  2.5744e-01, -3.3096e-02, -2.1516e-01,\n         -3.3080e-01, -3.5490e-02,  2.3721e-01,  9.5114e-02, -9.8846e-02,\n          2.9038e-02, -3.3926e-01],\n        [-1.3420e-01, -1.8973e-01,  2.8306e-02, -1.6937e-01,  1.6587e-01,\n         -2.8320e-01,  3.4874e-02,  6.2674e-02, -3.6160e-02,  3.5142e-01,\n         -9.8885e-02,  1.7370e-01, -2.9072e-01,  2.5997e-01,  1.9885e-01,\n          2.9648e-01,  3.0736e-01,  2.8782e-01,  2.1409e-02,  3.1240e-01,\n         -4.9114e-02, -6.5055e-03, -2.9261e-01,  1.2826e-01,  1.5891e-01,\n         -1.8670e-01, -2.2213e-01, -1.2066e-01, -2.7205e-01,  2.8861e-01,\n          1.2767e-01,  1.0723e-01],\n        [-1.0430e-01, -2.8411e-01, -3.4618e-01,  2.3462e-01,  4.6421e-02,\n          2.1831e-01, -8.7621e-02, -1.9530e-01,  6.4070e-02, -3.0833e-01,\n          5.7945e-02,  1.5940e-01, -1.7053e-01,  2.0821e-01,  1.3254e-01,\n          2.9012e-02,  1.2605e-01,  2.2724e-01,  3.3793e-01,  1.8245e-01,\n         -1.2474e-01, -4.9065e-02,  1.3464e-02, -7.8353e-02, -4.5920e-02,\n          2.4500e-01,  1.9266e-02,  2.2891e-01, -4.8679e-02, -3.1767e-01,\n          6.9396e-02, -1.8241e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.4421, -0.2316, -0.2691, -0.4011,  0.4270, -0.2557,  0.2702,  0.2548,\n          0.3603, -0.4211,  0.0232, -0.4384,  0.1420,  0.3349, -0.1153,  0.4538],\n        [-0.0108,  0.3831,  0.1312,  0.2312,  0.2712,  0.4138,  0.1693, -0.3500,\n          0.0327,  0.0171,  0.4329, -0.4019, -0.3907,  0.1335,  0.3437, -0.0660],\n        [ 0.0394,  0.0238, -0.2254, -0.2453, -0.2210, -0.3167,  0.4962,  0.0029,\n          0.0658, -0.4997, -0.0241,  0.0259, -0.0520, -0.3632, -0.0940,  0.2764],\n        [-0.3185,  0.2672, -0.4457,  0.1833,  0.4043,  0.2273, -0.1812,  0.0620,\n         -0.0452, -0.3722, -0.0645, -0.1011,  0.0555, -0.2924, -0.3795, -0.4618],\n        [ 0.0908, -0.2102,  0.3828,  0.2256, -0.2369, -0.2272,  0.2952, -0.3849,\n         -0.3089,  0.2632,  0.2221, -0.4128,  0.3984, -0.4983,  0.4210, -0.1195],\n        [-0.2573, -0.4181, -0.3452,  0.4388,  0.2730, -0.0817,  0.2650,  0.0036,\n         -0.2323, -0.1056, -0.1019,  0.4754, -0.4286, -0.3661,  0.1480, -0.0560],\n        [ 0.4381,  0.4503,  0.4371,  0.3057, -0.1655, -0.2737, -0.3859, -0.2444,\n          0.2804,  0.4329, -0.3781, -0.3824,  0.3812,  0.0471, -0.4709,  0.3440],\n        [-0.2758,  0.3007,  0.3536,  0.2209, -0.3503, -0.4577, -0.4665, -0.2623,\n          0.0392,  0.4877, -0.4871,  0.2265, -0.4569,  0.0081, -0.0447,  0.3528]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1335, -0.6668, -0.5482, -0.1949,  0.6891, -0.4738,  0.5374,  0.6116],\n        [ 0.2728,  0.2920, -0.1179, -0.3488, -0.4515, -0.4172,  0.2556,  0.6595],\n        [-0.3650,  0.4794, -0.5217, -0.4643, -0.0287,  0.2363,  0.1611,  0.4560],\n        [-0.1149, -0.1994,  0.7036, -0.0026,  0.4540,  0.0930, -0.5987,  0.3239]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x72d7a4dbf5d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s607270000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s607270000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}