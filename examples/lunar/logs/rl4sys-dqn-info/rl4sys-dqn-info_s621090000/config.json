{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.03,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s621090000"
    },
    "q_lr":	0.01,
    "seed":	621090000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x72d918d1fed0>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.03,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0606, -0.0545,  0.0299, -0.0404,  0.1527, -0.3790,  0.0696,  0.1638],\n        [-0.2638,  0.2740, -0.0556, -0.1265,  0.3570,  0.0808, -0.2322,  0.0777],\n        [-0.2968,  0.2784, -0.3429,  0.2876, -0.1122,  0.0694,  0.0257,  0.3589],\n        [-0.1376, -0.3736,  0.2626,  0.0045, -0.1797,  0.2577,  0.0007,  0.0025],\n        [-0.0697,  0.3335,  0.3260, -0.3641, -0.0456,  0.3406,  0.1197,  0.3609],\n        [ 0.0658,  0.3620,  0.2330,  0.0526,  0.1664, -0.2537, -0.3788, -0.3570],\n        [-0.0423,  0.3726,  0.2421, -0.0365, -0.2902,  0.0054, -0.0965, -0.3064],\n        [ 0.1913, -0.3631, -0.2120,  0.0361, -0.2547, -0.0178, -0.0704, -0.2864],\n        [ 0.3550,  0.2901,  0.1356, -0.0430, -0.0611, -0.2631, -0.2970, -0.2571],\n        [ 0.2610,  0.0166,  0.2885,  0.1522, -0.0338,  0.2069,  0.3569,  0.3605],\n        [-0.3226, -0.3867, -0.0971,  0.1525, -0.1192,  0.0568, -0.1995,  0.1094],\n        [ 0.0646, -0.2605, -0.3428,  0.3682,  0.1492, -0.0424, -0.2888, -0.3169],\n        [ 0.0795,  0.3059,  0.3327,  0.2326, -0.3572,  0.0819, -0.0328, -0.2429],\n        [-0.0135, -0.3005,  0.2477, -0.1477, -0.1573, -0.2419, -0.3438,  0.3847],\n        [ 0.0297, -0.1210, -0.1608, -0.2443, -0.1351, -0.2848, -0.3826, -0.1827],\n        [-0.3659, -0.3390, -0.3867,  0.0750,  0.0452,  0.2766, -0.0091,  0.1183],\n        [-0.1715, -0.3137, -0.1422, -0.0690,  0.0516, -0.2907,  0.1558,  0.0104],\n        [ 0.1608, -0.3400, -0.0253,  0.1680, -0.0885,  0.1774,  0.0699,  0.1416],\n        [ 0.0612, -0.2171, -0.0521,  0.1539, -0.0689,  0.3091,  0.1276, -0.0031],\n        [ 0.1665, -0.2300, -0.0788, -0.0216, -0.1911, -0.2012,  0.0392, -0.1965],\n        [ 0.3029, -0.3439, -0.0367, -0.1153,  0.0761,  0.3859, -0.0841, -0.0593],\n        [-0.0448,  0.1501,  0.2943, -0.2184,  0.1897,  0.0509, -0.1734,  0.3128],\n        [-0.0524, -0.2275, -0.1490,  0.1768, -0.2992,  0.3556, -0.1369, -0.0772],\n        [-0.3487,  0.2288,  0.2946,  0.2010, -0.1066,  0.2674, -0.3797, -0.1647],\n        [ 0.1870,  0.1994, -0.0641, -0.3521, -0.2586,  0.2524,  0.3806, -0.3458],\n        [-0.0076, -0.0988,  0.0686,  0.2275, -0.0592,  0.3769, -0.1417, -0.2449],\n        [ 0.2998,  0.1131, -0.1326,  0.2204,  0.2774,  0.1252,  0.3317,  0.3041],\n        [-0.2823,  0.2041,  0.3173,  0.2850,  0.0515, -0.1582,  0.3734, -0.3091],\n        [ 0.3216,  0.1604,  0.0613, -0.2579, -0.1373,  0.0081, -0.3640,  0.1396],\n        [ 0.1855,  0.0049,  0.2955,  0.3665, -0.0718, -0.3071,  0.0516, -0.3635],\n        [-0.3261, -0.2703, -0.3588,  0.3597,  0.0140, -0.3049, -0.0523, -0.0264],\n        [ 0.2750,  0.3119, -0.2041, -0.0851,  0.2580, -0.3495, -0.0010, -0.3095]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-9.1028e-02, -2.1937e-01,  2.7281e-01,  2.7402e-01, -2.4025e-01,\n         -2.7322e-01, -7.3196e-02, -1.8955e-01,  1.5418e-02, -3.0258e-01,\n          2.7526e-01,  3.1031e-01, -2.7263e-01,  2.0806e-01,  2.2354e-01,\n          2.1825e-01,  2.0242e-01,  1.3518e-01, -1.4335e-01,  2.9741e-01,\n         -2.6553e-01, -1.8381e-01,  3.2773e-01, -2.6591e-02,  2.7794e-01,\n         -6.1035e-02, -2.2502e-01, -3.0609e-01, -2.8897e-01, -1.3668e-01,\n         -3.2588e-01,  3.0908e-01],\n        [ 1.4810e-01, -2.2066e-01,  1.6057e-01, -6.8841e-02, -1.7501e-01,\n         -2.9683e-01,  2.9107e-01, -1.5930e-01, -3.2996e-01, -2.2442e-01,\n          1.9875e-01,  3.2374e-01,  6.3666e-02, -1.0638e-01, -1.1292e-01,\n          8.6755e-02, -3.4113e-01, -1.7201e-01, -2.0496e-01, -1.5194e-01,\n         -5.6631e-03, -1.2483e-01, -1.9163e-01,  3.4442e-01, -2.7937e-01,\n         -1.1379e-01,  1.5487e-01,  3.2126e-01, -2.4088e-01, -2.3230e-01,\n         -7.3510e-02,  5.4272e-02],\n        [ 2.9307e-01, -2.0213e-01,  9.6729e-02,  1.4498e-01,  2.5385e-01,\n          3.0603e-01,  5.5028e-02, -2.5439e-01,  3.0724e-02, -6.4604e-02,\n          1.7002e-01,  1.8810e-01, -4.4897e-02,  3.4071e-01,  2.6311e-01,\n         -1.8048e-02, -1.0335e-01, -2.0611e-02,  3.2032e-01,  3.3843e-01,\n          2.8046e-01, -2.0544e-01, -1.5778e-01,  2.2886e-01,  1.5985e-01,\n         -8.5401e-02, -3.1969e-01,  3.1515e-01, -3.2517e-01, -1.3621e-01,\n         -8.6234e-02,  1.7478e-01],\n        [-7.4560e-02,  1.4288e-01,  1.8017e-01, -3.4804e-01,  2.2271e-01,\n          3.3080e-01,  3.0475e-01,  3.1878e-01,  1.3016e-01, -5.0222e-02,\n         -1.8441e-01, -3.7068e-02, -1.3279e-01, -1.0256e-01,  2.0456e-01,\n          5.5782e-02, -3.4071e-01, -3.0788e-01, -9.1565e-02,  2.2131e-01,\n         -1.9653e-02,  1.5882e-01, -1.1222e-01, -3.2609e-01, -2.8883e-01,\n          4.6172e-02,  3.1759e-01, -4.9720e-02, -9.9645e-02, -1.7474e-01,\n         -2.9219e-01, -3.0097e-01],\n        [ 2.3826e-02,  1.0129e-01, -1.7099e-02,  2.9505e-01,  1.5327e-01,\n          2.5505e-01,  1.5141e-01, -3.4997e-01,  3.0129e-01,  2.7865e-01,\n          1.0145e-01, -3.0546e-01, -2.2540e-01,  1.7127e-01,  1.2888e-01,\n         -2.5162e-01, -7.6052e-02, -1.3980e-02, -5.5664e-02, -2.2431e-01,\n         -3.5059e-01,  3.4771e-01,  2.2646e-01, -1.1684e-01, -3.0493e-03,\n          1.9772e-01, -6.6056e-02,  9.5332e-03, -2.5912e-01,  2.2052e-01,\n         -9.1823e-02,  1.0644e-01],\n        [-6.7889e-03,  2.7113e-01, -5.3304e-02, -2.7293e-01, -9.3748e-02,\n          3.5024e-01,  1.0843e-01, -2.8482e-01, -2.7961e-01, -2.2922e-01,\n         -2.9130e-01,  3.3456e-01, -8.3194e-02,  3.0772e-01,  2.9144e-01,\n         -2.2116e-01, -8.8084e-02,  1.0645e-01,  3.5240e-01, -7.2147e-02,\n          2.2722e-01, -2.5704e-01,  1.7733e-01,  3.1732e-01, -2.0548e-01,\n          1.8419e-01,  1.4937e-01, -1.5060e-02, -9.9214e-02, -1.5036e-01,\n          1.0706e-01, -1.4000e-01],\n        [-3.3687e-01,  8.5637e-02,  2.5938e-01,  2.9276e-01,  3.1567e-01,\n          2.5241e-01, -3.0693e-01,  1.6367e-01, -2.4321e-01, -3.4307e-01,\n          2.6610e-01, -1.0685e-01, -1.9898e-02,  1.9749e-01,  2.8365e-01,\n          4.0452e-02,  2.8525e-01, -9.0652e-02,  2.1131e-01,  9.6333e-02,\n          1.0579e-01,  3.3892e-01,  2.9442e-01, -6.7166e-03,  1.8549e-01,\n          9.6427e-03,  2.8201e-01,  9.9061e-02, -2.9499e-01,  1.3342e-01,\n         -2.0748e-01,  6.4994e-02],\n        [ 4.1134e-02,  7.5990e-02,  8.7339e-02,  1.8495e-01,  9.1125e-02,\n         -3.7731e-02,  2.1837e-01, -1.1880e-01, -6.7663e-02, -2.8449e-01,\n         -2.5921e-01,  1.4302e-01,  5.3613e-02,  8.0692e-02, -1.4930e-01,\n         -1.4743e-01,  2.3530e-01, -9.3326e-02, -1.8605e-01,  9.4791e-02,\n         -2.1545e-01,  1.9316e-01,  1.6244e-01,  2.9897e-01, -3.2867e-01,\n          2.2383e-01, -2.5392e-01, -3.4082e-01,  2.9337e-01,  2.3727e-01,\n         -1.7851e-01,  1.7874e-04],\n        [-2.1876e-02,  3.0532e-01, -3.2729e-01, -3.2291e-01,  2.2410e-01,\n         -1.3666e-01,  6.3610e-03,  1.9618e-01, -5.7693e-02,  1.7115e-01,\n          2.7897e-01,  2.9862e-01, -5.8739e-02,  2.1749e-01,  7.6128e-02,\n          1.4235e-01,  3.4230e-01,  2.5482e-01,  2.3254e-01,  5.6372e-02,\n          3.0165e-01, -2.1928e-01,  1.9527e-01, -3.0304e-01,  3.0931e-01,\n         -2.8743e-01, -2.0814e-01, -1.2595e-02, -1.5555e-01,  2.6511e-02,\n         -3.5068e-01,  2.6139e-01],\n        [ 2.5765e-01, -3.3397e-01, -2.3604e-01,  1.5248e-01,  3.3770e-01,\n          3.2109e-02, -2.4304e-01, -3.3863e-01,  2.1247e-01, -3.4731e-01,\n          2.9208e-01, -4.8782e-02, -3.4601e-01, -1.5321e-01, -3.1035e-01,\n          1.1622e-01,  9.1265e-02,  1.8154e-01,  3.4463e-02,  2.4837e-02,\n          1.3170e-01,  1.4070e-01, -2.3263e-01,  1.5074e-01,  1.8593e-01,\n         -2.9446e-01, -3.0252e-01,  4.4034e-02,  3.4144e-01, -1.2757e-01,\n          3.4147e-01,  2.6001e-01],\n        [-1.0727e-01, -3.1949e-01, -2.1015e-01, -1.0760e-01, -2.8522e-01,\n         -1.3014e-01, -1.4164e-01,  2.7234e-01,  1.9771e-01, -3.1113e-01,\n         -3.2137e-01, -9.3287e-02, -2.6226e-01, -1.4025e-01, -2.9018e-01,\n          1.3390e-01,  1.2499e-01, -1.3062e-01,  2.1602e-01,  8.6739e-02,\n          2.5805e-01,  1.5879e-01, -4.4671e-02, -3.0080e-01,  4.3529e-02,\n          6.0587e-03, -2.4943e-01, -2.5683e-02, -6.6069e-04, -1.9461e-01,\n          2.4171e-01, -1.9985e-01],\n        [-2.3627e-01,  2.0703e-02,  9.0138e-02, -4.7516e-02, -1.1754e-01,\n         -1.2604e-01,  2.4382e-01, -2.4077e-01, -2.2908e-01, -7.7195e-02,\n          1.6248e-01,  9.2505e-02,  5.4555e-02, -3.4787e-01,  6.4435e-02,\n          2.8208e-02, -9.6150e-02,  1.1338e-01,  1.4776e-01,  3.4013e-01,\n          3.1759e-01, -2.0575e-01,  2.2738e-04,  2.9444e-02, -3.4926e-01,\n          1.1015e-01,  2.5897e-01, -6.6161e-02,  1.5200e-01,  8.8309e-02,\n          2.1042e-01,  2.2027e-01],\n        [ 2.8804e-03,  2.5624e-01,  2.0373e-01,  2.4836e-01, -7.8981e-02,\n         -8.3590e-02, -9.7093e-02,  2.7096e-01, -1.3265e-02,  5.0300e-02,\n         -2.8583e-01, -2.0250e-01,  6.7159e-02, -7.1741e-02,  3.1505e-01,\n          3.1846e-01, -6.2707e-02, -3.0108e-01,  2.8806e-01,  2.0444e-01,\n          7.0990e-02,  1.8428e-01,  3.1798e-02,  2.2984e-01, -1.6326e-02,\n          1.9295e-01,  8.8146e-02, -1.3869e-01, -2.6234e-01,  2.8957e-01,\n         -4.6319e-02, -3.2182e-02],\n        [-3.4317e-01, -2.1716e-01,  5.7570e-02, -2.7165e-01, -3.3235e-01,\n          6.2074e-02, -1.2979e-01,  2.7477e-01, -8.1864e-02, -1.3435e-01,\n          2.9018e-01, -1.5304e-01,  2.6365e-01,  2.5918e-01,  1.6427e-01,\n          1.1232e-01, -2.6141e-01, -6.1396e-02,  3.0572e-01,  3.5323e-01,\n         -3.0757e-01, -2.2845e-01,  2.1334e-02, -1.2616e-01,  2.7938e-01,\n         -2.9406e-01, -1.1262e-01,  7.0332e-02,  2.5837e-01,  2.9787e-01,\n         -1.6273e-01,  8.2306e-02],\n        [ 3.2761e-01,  2.4082e-01,  1.5630e-02, -6.4711e-02,  8.6065e-02,\n         -7.1605e-02, -4.3589e-03,  2.5983e-01,  5.8040e-03, -4.6303e-03,\n          1.7552e-01,  3.1991e-01,  2.1924e-01,  2.0939e-02, -5.5001e-02,\n         -2.5897e-01, -2.2282e-01, -3.1977e-01, -6.8945e-02,  6.7192e-03,\n         -2.7935e-01, -2.6162e-01, -3.2415e-01, -2.0968e-01, -2.1915e-01,\n         -1.0146e-01,  2.7295e-02,  1.1795e-01,  4.5597e-02,  2.2550e-01,\n         -3.3877e-02, -1.3702e-01],\n        [ 1.0595e-01,  3.2981e-01,  2.4724e-01, -3.2157e-01, -1.2093e-01,\n         -1.6852e-01,  2.7863e-01, -2.4993e-01, -2.9923e-01,  2.2106e-01,\n          1.1868e-01,  5.4807e-02, -1.1766e-02,  2.6181e-01,  3.7525e-02,\n         -2.0138e-01, -1.8492e-01,  4.5105e-02,  5.9428e-02,  2.0702e-01,\n          3.2527e-01,  3.2177e-01,  2.3508e-01,  2.8102e-01, -1.9687e-01,\n          1.0231e-01,  1.7576e-01, -3.2846e-01, -2.8128e-01, -1.1946e-01,\n         -2.7585e-01, -1.1640e-03]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0435, -0.0591, -0.2210, -0.3435, -0.2303, -0.4664,  0.0370,  0.1110,\n         -0.3417,  0.1249,  0.4239, -0.4911, -0.4346,  0.3096, -0.4195, -0.1000],\n        [ 0.3127,  0.0356,  0.1179, -0.0475, -0.3916, -0.3146,  0.0291,  0.2244,\n         -0.3081, -0.0930, -0.2259,  0.4196,  0.1668, -0.1854, -0.3369,  0.3533],\n        [-0.4806,  0.2076, -0.3394,  0.1647, -0.3321, -0.0612, -0.0200, -0.4956,\n         -0.1526, -0.2547,  0.2754, -0.1505,  0.3230, -0.3843,  0.0138,  0.1902],\n        [-0.1724, -0.1797,  0.3950,  0.4150,  0.1816, -0.2618, -0.3240,  0.1812,\n          0.3838, -0.4768,  0.4004, -0.0439,  0.2096, -0.4373, -0.4516, -0.4182],\n        [ 0.3854, -0.2471,  0.3578, -0.2760, -0.4636, -0.0479, -0.2540,  0.4080,\n         -0.1761,  0.0265, -0.0802,  0.4987,  0.1602, -0.0571,  0.3533, -0.0536],\n        [-0.3579, -0.4951, -0.1715,  0.0055,  0.1519,  0.4885, -0.1149, -0.3068,\n         -0.4499, -0.1009, -0.3074, -0.4377, -0.0902,  0.2842,  0.1481,  0.2086],\n        [-0.0857,  0.4912,  0.0969,  0.1654, -0.3159, -0.1232, -0.0864, -0.2219,\n          0.1488, -0.1653, -0.2919, -0.4042,  0.2280,  0.0481,  0.0686,  0.1827],\n        [ 0.2207,  0.4035, -0.0294, -0.0987,  0.0546, -0.3975, -0.1928,  0.0006,\n         -0.4708,  0.4240, -0.1187,  0.2038,  0.4561,  0.1426,  0.1268, -0.2323]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3316,  0.0787,  0.5328,  0.2676,  0.3157,  0.2321,  0.2788, -0.3504],\n        [-0.4618, -0.2016, -0.5414, -0.2238,  0.0709, -0.6384, -0.3719,  0.2948],\n        [ 0.4094,  0.0098, -0.3898, -0.0597,  0.6974, -0.5410, -0.5697, -0.0890],\n        [ 0.5246, -0.0966,  0.5049, -0.5414, -0.3491, -0.0863,  0.1234, -0.0944]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.01\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.01,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.01,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0606, -0.0545,  0.0299, -0.0404,  0.1527, -0.3790,  0.0696,  0.1638],\n        [-0.2638,  0.2740, -0.0556, -0.1265,  0.3570,  0.0808, -0.2322,  0.0777],\n        [-0.2968,  0.2784, -0.3429,  0.2876, -0.1122,  0.0694,  0.0257,  0.3589],\n        [-0.1376, -0.3736,  0.2626,  0.0045, -0.1797,  0.2577,  0.0007,  0.0025],\n        [-0.0697,  0.3335,  0.3260, -0.3641, -0.0456,  0.3406,  0.1197,  0.3609],\n        [ 0.0658,  0.3620,  0.2330,  0.0526,  0.1664, -0.2537, -0.3788, -0.3570],\n        [-0.0423,  0.3726,  0.2421, -0.0365, -0.2902,  0.0054, -0.0965, -0.3064],\n        [ 0.1913, -0.3631, -0.2120,  0.0361, -0.2547, -0.0178, -0.0704, -0.2864],\n        [ 0.3550,  0.2901,  0.1356, -0.0430, -0.0611, -0.2631, -0.2970, -0.2571],\n        [ 0.2610,  0.0166,  0.2885,  0.1522, -0.0338,  0.2069,  0.3569,  0.3605],\n        [-0.3226, -0.3867, -0.0971,  0.1525, -0.1192,  0.0568, -0.1995,  0.1094],\n        [ 0.0646, -0.2605, -0.3428,  0.3682,  0.1492, -0.0424, -0.2888, -0.3169],\n        [ 0.0795,  0.3059,  0.3327,  0.2326, -0.3572,  0.0819, -0.0328, -0.2429],\n        [-0.0135, -0.3005,  0.2477, -0.1477, -0.1573, -0.2419, -0.3438,  0.3847],\n        [ 0.0297, -0.1210, -0.1608, -0.2443, -0.1351, -0.2848, -0.3826, -0.1827],\n        [-0.3659, -0.3390, -0.3867,  0.0750,  0.0452,  0.2766, -0.0091,  0.1183],\n        [-0.1715, -0.3137, -0.1422, -0.0690,  0.0516, -0.2907,  0.1558,  0.0104],\n        [ 0.1608, -0.3400, -0.0253,  0.1680, -0.0885,  0.1774,  0.0699,  0.1416],\n        [ 0.0612, -0.2171, -0.0521,  0.1539, -0.0689,  0.3091,  0.1276, -0.0031],\n        [ 0.1665, -0.2300, -0.0788, -0.0216, -0.1911, -0.2012,  0.0392, -0.1965],\n        [ 0.3029, -0.3439, -0.0367, -0.1153,  0.0761,  0.3859, -0.0841, -0.0593],\n        [-0.0448,  0.1501,  0.2943, -0.2184,  0.1897,  0.0509, -0.1734,  0.3128],\n        [-0.0524, -0.2275, -0.1490,  0.1768, -0.2992,  0.3556, -0.1369, -0.0772],\n        [-0.3487,  0.2288,  0.2946,  0.2010, -0.1066,  0.2674, -0.3797, -0.1647],\n        [ 0.1870,  0.1994, -0.0641, -0.3521, -0.2586,  0.2524,  0.3806, -0.3458],\n        [-0.0076, -0.0988,  0.0686,  0.2275, -0.0592,  0.3769, -0.1417, -0.2449],\n        [ 0.2998,  0.1131, -0.1326,  0.2204,  0.2774,  0.1252,  0.3317,  0.3041],\n        [-0.2823,  0.2041,  0.3173,  0.2850,  0.0515, -0.1582,  0.3734, -0.3091],\n        [ 0.3216,  0.1604,  0.0613, -0.2579, -0.1373,  0.0081, -0.3640,  0.1396],\n        [ 0.1855,  0.0049,  0.2955,  0.3665, -0.0718, -0.3071,  0.0516, -0.3635],\n        [-0.3261, -0.2703, -0.3588,  0.3597,  0.0140, -0.3049, -0.0523, -0.0264],\n        [ 0.2750,  0.3119, -0.2041, -0.0851,  0.2580, -0.3495, -0.0010, -0.3095]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[-9.1028e-02, -2.1937e-01,  2.7281e-01,  2.7402e-01, -2.4025e-01,\n         -2.7322e-01, -7.3196e-02, -1.8955e-01,  1.5418e-02, -3.0258e-01,\n          2.7526e-01,  3.1031e-01, -2.7263e-01,  2.0806e-01,  2.2354e-01,\n          2.1825e-01,  2.0242e-01,  1.3518e-01, -1.4335e-01,  2.9741e-01,\n         -2.6553e-01, -1.8381e-01,  3.2773e-01, -2.6591e-02,  2.7794e-01,\n         -6.1035e-02, -2.2502e-01, -3.0609e-01, -2.8897e-01, -1.3668e-01,\n         -3.2588e-01,  3.0908e-01],\n        [ 1.4810e-01, -2.2066e-01,  1.6057e-01, -6.8841e-02, -1.7501e-01,\n         -2.9683e-01,  2.9107e-01, -1.5930e-01, -3.2996e-01, -2.2442e-01,\n          1.9875e-01,  3.2374e-01,  6.3666e-02, -1.0638e-01, -1.1292e-01,\n          8.6755e-02, -3.4113e-01, -1.7201e-01, -2.0496e-01, -1.5194e-01,\n         -5.6631e-03, -1.2483e-01, -1.9163e-01,  3.4442e-01, -2.7937e-01,\n         -1.1379e-01,  1.5487e-01,  3.2126e-01, -2.4088e-01, -2.3230e-01,\n         -7.3510e-02,  5.4272e-02],\n        [ 2.9307e-01, -2.0213e-01,  9.6729e-02,  1.4498e-01,  2.5385e-01,\n          3.0603e-01,  5.5028e-02, -2.5439e-01,  3.0724e-02, -6.4604e-02,\n          1.7002e-01,  1.8810e-01, -4.4897e-02,  3.4071e-01,  2.6311e-01,\n         -1.8048e-02, -1.0335e-01, -2.0611e-02,  3.2032e-01,  3.3843e-01,\n          2.8046e-01, -2.0544e-01, -1.5778e-01,  2.2886e-01,  1.5985e-01,\n         -8.5401e-02, -3.1969e-01,  3.1515e-01, -3.2517e-01, -1.3621e-01,\n         -8.6234e-02,  1.7478e-01],\n        [-7.4560e-02,  1.4288e-01,  1.8017e-01, -3.4804e-01,  2.2271e-01,\n          3.3080e-01,  3.0475e-01,  3.1878e-01,  1.3016e-01, -5.0222e-02,\n         -1.8441e-01, -3.7068e-02, -1.3279e-01, -1.0256e-01,  2.0456e-01,\n          5.5782e-02, -3.4071e-01, -3.0788e-01, -9.1565e-02,  2.2131e-01,\n         -1.9653e-02,  1.5882e-01, -1.1222e-01, -3.2609e-01, -2.8883e-01,\n          4.6172e-02,  3.1759e-01, -4.9720e-02, -9.9645e-02, -1.7474e-01,\n         -2.9219e-01, -3.0097e-01],\n        [ 2.3826e-02,  1.0129e-01, -1.7099e-02,  2.9505e-01,  1.5327e-01,\n          2.5505e-01,  1.5141e-01, -3.4997e-01,  3.0129e-01,  2.7865e-01,\n          1.0145e-01, -3.0546e-01, -2.2540e-01,  1.7127e-01,  1.2888e-01,\n         -2.5162e-01, -7.6052e-02, -1.3980e-02, -5.5664e-02, -2.2431e-01,\n         -3.5059e-01,  3.4771e-01,  2.2646e-01, -1.1684e-01, -3.0493e-03,\n          1.9772e-01, -6.6056e-02,  9.5332e-03, -2.5912e-01,  2.2052e-01,\n         -9.1823e-02,  1.0644e-01],\n        [-6.7889e-03,  2.7113e-01, -5.3304e-02, -2.7293e-01, -9.3748e-02,\n          3.5024e-01,  1.0843e-01, -2.8482e-01, -2.7961e-01, -2.2922e-01,\n         -2.9130e-01,  3.3456e-01, -8.3194e-02,  3.0772e-01,  2.9144e-01,\n         -2.2116e-01, -8.8084e-02,  1.0645e-01,  3.5240e-01, -7.2147e-02,\n          2.2722e-01, -2.5704e-01,  1.7733e-01,  3.1732e-01, -2.0548e-01,\n          1.8419e-01,  1.4937e-01, -1.5060e-02, -9.9214e-02, -1.5036e-01,\n          1.0706e-01, -1.4000e-01],\n        [-3.3687e-01,  8.5637e-02,  2.5938e-01,  2.9276e-01,  3.1567e-01,\n          2.5241e-01, -3.0693e-01,  1.6367e-01, -2.4321e-01, -3.4307e-01,\n          2.6610e-01, -1.0685e-01, -1.9898e-02,  1.9749e-01,  2.8365e-01,\n          4.0452e-02,  2.8525e-01, -9.0652e-02,  2.1131e-01,  9.6333e-02,\n          1.0579e-01,  3.3892e-01,  2.9442e-01, -6.7166e-03,  1.8549e-01,\n          9.6427e-03,  2.8201e-01,  9.9061e-02, -2.9499e-01,  1.3342e-01,\n         -2.0748e-01,  6.4994e-02],\n        [ 4.1134e-02,  7.5990e-02,  8.7339e-02,  1.8495e-01,  9.1125e-02,\n         -3.7731e-02,  2.1837e-01, -1.1880e-01, -6.7663e-02, -2.8449e-01,\n         -2.5921e-01,  1.4302e-01,  5.3613e-02,  8.0692e-02, -1.4930e-01,\n         -1.4743e-01,  2.3530e-01, -9.3326e-02, -1.8605e-01,  9.4791e-02,\n         -2.1545e-01,  1.9316e-01,  1.6244e-01,  2.9897e-01, -3.2867e-01,\n          2.2383e-01, -2.5392e-01, -3.4082e-01,  2.9337e-01,  2.3727e-01,\n         -1.7851e-01,  1.7874e-04],\n        [-2.1876e-02,  3.0532e-01, -3.2729e-01, -3.2291e-01,  2.2410e-01,\n         -1.3666e-01,  6.3610e-03,  1.9618e-01, -5.7693e-02,  1.7115e-01,\n          2.7897e-01,  2.9862e-01, -5.8739e-02,  2.1749e-01,  7.6128e-02,\n          1.4235e-01,  3.4230e-01,  2.5482e-01,  2.3254e-01,  5.6372e-02,\n          3.0165e-01, -2.1928e-01,  1.9527e-01, -3.0304e-01,  3.0931e-01,\n         -2.8743e-01, -2.0814e-01, -1.2595e-02, -1.5555e-01,  2.6511e-02,\n         -3.5068e-01,  2.6139e-01],\n        [ 2.5765e-01, -3.3397e-01, -2.3604e-01,  1.5248e-01,  3.3770e-01,\n          3.2109e-02, -2.4304e-01, -3.3863e-01,  2.1247e-01, -3.4731e-01,\n          2.9208e-01, -4.8782e-02, -3.4601e-01, -1.5321e-01, -3.1035e-01,\n          1.1622e-01,  9.1265e-02,  1.8154e-01,  3.4463e-02,  2.4837e-02,\n          1.3170e-01,  1.4070e-01, -2.3263e-01,  1.5074e-01,  1.8593e-01,\n         -2.9446e-01, -3.0252e-01,  4.4034e-02,  3.4144e-01, -1.2757e-01,\n          3.4147e-01,  2.6001e-01],\n        [-1.0727e-01, -3.1949e-01, -2.1015e-01, -1.0760e-01, -2.8522e-01,\n         -1.3014e-01, -1.4164e-01,  2.7234e-01,  1.9771e-01, -3.1113e-01,\n         -3.2137e-01, -9.3287e-02, -2.6226e-01, -1.4025e-01, -2.9018e-01,\n          1.3390e-01,  1.2499e-01, -1.3062e-01,  2.1602e-01,  8.6739e-02,\n          2.5805e-01,  1.5879e-01, -4.4671e-02, -3.0080e-01,  4.3529e-02,\n          6.0587e-03, -2.4943e-01, -2.5683e-02, -6.6069e-04, -1.9461e-01,\n          2.4171e-01, -1.9985e-01],\n        [-2.3627e-01,  2.0703e-02,  9.0138e-02, -4.7516e-02, -1.1754e-01,\n         -1.2604e-01,  2.4382e-01, -2.4077e-01, -2.2908e-01, -7.7195e-02,\n          1.6248e-01,  9.2505e-02,  5.4555e-02, -3.4787e-01,  6.4435e-02,\n          2.8208e-02, -9.6150e-02,  1.1338e-01,  1.4776e-01,  3.4013e-01,\n          3.1759e-01, -2.0575e-01,  2.2738e-04,  2.9444e-02, -3.4926e-01,\n          1.1015e-01,  2.5897e-01, -6.6161e-02,  1.5200e-01,  8.8309e-02,\n          2.1042e-01,  2.2027e-01],\n        [ 2.8804e-03,  2.5624e-01,  2.0373e-01,  2.4836e-01, -7.8981e-02,\n         -8.3590e-02, -9.7093e-02,  2.7096e-01, -1.3265e-02,  5.0300e-02,\n         -2.8583e-01, -2.0250e-01,  6.7159e-02, -7.1741e-02,  3.1505e-01,\n          3.1846e-01, -6.2707e-02, -3.0108e-01,  2.8806e-01,  2.0444e-01,\n          7.0990e-02,  1.8428e-01,  3.1798e-02,  2.2984e-01, -1.6326e-02,\n          1.9295e-01,  8.8146e-02, -1.3869e-01, -2.6234e-01,  2.8957e-01,\n         -4.6319e-02, -3.2182e-02],\n        [-3.4317e-01, -2.1716e-01,  5.7570e-02, -2.7165e-01, -3.3235e-01,\n          6.2074e-02, -1.2979e-01,  2.7477e-01, -8.1864e-02, -1.3435e-01,\n          2.9018e-01, -1.5304e-01,  2.6365e-01,  2.5918e-01,  1.6427e-01,\n          1.1232e-01, -2.6141e-01, -6.1396e-02,  3.0572e-01,  3.5323e-01,\n         -3.0757e-01, -2.2845e-01,  2.1334e-02, -1.2616e-01,  2.7938e-01,\n         -2.9406e-01, -1.1262e-01,  7.0332e-02,  2.5837e-01,  2.9787e-01,\n         -1.6273e-01,  8.2306e-02],\n        [ 3.2761e-01,  2.4082e-01,  1.5630e-02, -6.4711e-02,  8.6065e-02,\n         -7.1605e-02, -4.3589e-03,  2.5983e-01,  5.8040e-03, -4.6303e-03,\n          1.7552e-01,  3.1991e-01,  2.1924e-01,  2.0939e-02, -5.5001e-02,\n         -2.5897e-01, -2.2282e-01, -3.1977e-01, -6.8945e-02,  6.7192e-03,\n         -2.7935e-01, -2.6162e-01, -3.2415e-01, -2.0968e-01, -2.1915e-01,\n         -1.0146e-01,  2.7295e-02,  1.1795e-01,  4.5597e-02,  2.2550e-01,\n         -3.3877e-02, -1.3702e-01],\n        [ 1.0595e-01,  3.2981e-01,  2.4724e-01, -3.2157e-01, -1.2093e-01,\n         -1.6852e-01,  2.7863e-01, -2.4993e-01, -2.9923e-01,  2.2106e-01,\n          1.1868e-01,  5.4807e-02, -1.1766e-02,  2.6181e-01,  3.7525e-02,\n         -2.0138e-01, -1.8492e-01,  4.5105e-02,  5.9428e-02,  2.0702e-01,\n          3.2527e-01,  3.2177e-01,  2.3508e-01,  2.8102e-01, -1.9687e-01,\n          1.0231e-01,  1.7576e-01, -3.2846e-01, -2.8128e-01, -1.1946e-01,\n         -2.7585e-01, -1.1640e-03]], requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0435, -0.0591, -0.2210, -0.3435, -0.2303, -0.4664,  0.0370,  0.1110,\n         -0.3417,  0.1249,  0.4239, -0.4911, -0.4346,  0.3096, -0.4195, -0.1000],\n        [ 0.3127,  0.0356,  0.1179, -0.0475, -0.3916, -0.3146,  0.0291,  0.2244,\n         -0.3081, -0.0930, -0.2259,  0.4196,  0.1668, -0.1854, -0.3369,  0.3533],\n        [-0.4806,  0.2076, -0.3394,  0.1647, -0.3321, -0.0612, -0.0200, -0.4956,\n         -0.1526, -0.2547,  0.2754, -0.1505,  0.3230, -0.3843,  0.0138,  0.1902],\n        [-0.1724, -0.1797,  0.3950,  0.4150,  0.1816, -0.2618, -0.3240,  0.1812,\n          0.3838, -0.4768,  0.4004, -0.0439,  0.2096, -0.4373, -0.4516, -0.4182],\n        [ 0.3854, -0.2471,  0.3578, -0.2760, -0.4636, -0.0479, -0.2540,  0.4080,\n         -0.1761,  0.0265, -0.0802,  0.4987,  0.1602, -0.0571,  0.3533, -0.0536],\n        [-0.3579, -0.4951, -0.1715,  0.0055,  0.1519,  0.4885, -0.1149, -0.3068,\n         -0.4499, -0.1009, -0.3074, -0.4377, -0.0902,  0.2842,  0.1481,  0.2086],\n        [-0.0857,  0.4912,  0.0969,  0.1654, -0.3159, -0.1232, -0.0864, -0.2219,\n          0.1488, -0.1653, -0.2919, -0.4042,  0.2280,  0.0481,  0.0686,  0.1827],\n        [ 0.2207,  0.4035, -0.0294, -0.0987,  0.0546, -0.3975, -0.1928,  0.0006,\n         -0.4708,  0.4240, -0.1187,  0.2038,  0.4561,  0.1426,  0.1268, -0.2323]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3316,  0.0787,  0.5328,  0.2676,  0.3157,  0.2321,  0.2788, -0.3504],\n        [-0.4618, -0.2016, -0.5414, -0.2238,  0.0709, -0.6384, -0.3719,  0.2948],\n        [ 0.4094,  0.0098, -0.3898, -0.0597,  0.6974, -0.5410, -0.5697, -0.0890],\n        [ 0.5246, -0.0966,  0.5049, -0.5414, -0.3491, -0.0863,  0.1234, -0.0944]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x72d91907dfd0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "full":	false,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0606, -0.0545,  0.0299, -0.0404,  0.1527, -0.3790,  0.0696,  0.1638],\n        [-0.2638,  0.2740, -0.0556, -0.1265,  0.3570,  0.0808, -0.2322,  0.0777],\n        [-0.2968,  0.2784, -0.3429,  0.2876, -0.1122,  0.0694,  0.0257,  0.3589],\n        [-0.1376, -0.3736,  0.2626,  0.0045, -0.1797,  0.2577,  0.0007,  0.0025],\n        [-0.0697,  0.3335,  0.3260, -0.3641, -0.0456,  0.3406,  0.1197,  0.3609],\n        [ 0.0658,  0.3620,  0.2330,  0.0526,  0.1664, -0.2537, -0.3788, -0.3570],\n        [-0.0423,  0.3726,  0.2421, -0.0365, -0.2902,  0.0054, -0.0965, -0.3064],\n        [ 0.1913, -0.3631, -0.2120,  0.0361, -0.2547, -0.0178, -0.0704, -0.2864],\n        [ 0.3550,  0.2901,  0.1356, -0.0430, -0.0611, -0.2631, -0.2970, -0.2571],\n        [ 0.2610,  0.0166,  0.2885,  0.1522, -0.0338,  0.2069,  0.3569,  0.3605],\n        [-0.3226, -0.3867, -0.0971,  0.1525, -0.1192,  0.0568, -0.1995,  0.1094],\n        [ 0.0646, -0.2605, -0.3428,  0.3682,  0.1492, -0.0424, -0.2888, -0.3169],\n        [ 0.0795,  0.3059,  0.3327,  0.2326, -0.3572,  0.0819, -0.0328, -0.2429],\n        [-0.0135, -0.3005,  0.2477, -0.1477, -0.1573, -0.2419, -0.3438,  0.3847],\n        [ 0.0297, -0.1210, -0.1608, -0.2443, -0.1351, -0.2848, -0.3826, -0.1827],\n        [-0.3659, -0.3390, -0.3867,  0.0750,  0.0452,  0.2766, -0.0091,  0.1183],\n        [-0.1715, -0.3137, -0.1422, -0.0690,  0.0516, -0.2907,  0.1558,  0.0104],\n        [ 0.1608, -0.3400, -0.0253,  0.1680, -0.0885,  0.1774,  0.0699,  0.1416],\n        [ 0.0612, -0.2171, -0.0521,  0.1539, -0.0689,  0.3091,  0.1276, -0.0031],\n        [ 0.1665, -0.2300, -0.0788, -0.0216, -0.1911, -0.2012,  0.0392, -0.1965],\n        [ 0.3029, -0.3439, -0.0367, -0.1153,  0.0761,  0.3859, -0.0841, -0.0593],\n        [-0.0448,  0.1501,  0.2943, -0.2184,  0.1897,  0.0509, -0.1734,  0.3128],\n        [-0.0524, -0.2275, -0.1490,  0.1768, -0.2992,  0.3556, -0.1369, -0.0772],\n        [-0.3487,  0.2288,  0.2946,  0.2010, -0.1066,  0.2674, -0.3797, -0.1647],\n        [ 0.1870,  0.1994, -0.0641, -0.3521, -0.2586,  0.2524,  0.3806, -0.3458],\n        [-0.0076, -0.0988,  0.0686,  0.2275, -0.0592,  0.3769, -0.1417, -0.2449],\n        [ 0.2998,  0.1131, -0.1326,  0.2204,  0.2774,  0.1252,  0.3317,  0.3041],\n        [-0.2823,  0.2041,  0.3173,  0.2850,  0.0515, -0.1582,  0.3734, -0.3091],\n        [ 0.3216,  0.1604,  0.0613, -0.2579, -0.1373,  0.0081, -0.3640,  0.1396],\n        [ 0.1855,  0.0049,  0.2955,  0.3665, -0.0718, -0.3071,  0.0516, -0.3635],\n        [-0.3261, -0.2703, -0.3588,  0.3597,  0.0140, -0.3049, -0.0523, -0.0264],\n        [ 0.2750,  0.3119, -0.2041, -0.0851,  0.2580, -0.3495, -0.0010, -0.3095]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-9.1028e-02, -2.1937e-01,  2.7281e-01,  2.7402e-01, -2.4025e-01,\n         -2.7322e-01, -7.3196e-02, -1.8955e-01,  1.5418e-02, -3.0258e-01,\n          2.7526e-01,  3.1031e-01, -2.7263e-01,  2.0806e-01,  2.2354e-01,\n          2.1825e-01,  2.0242e-01,  1.3518e-01, -1.4335e-01,  2.9741e-01,\n         -2.6553e-01, -1.8381e-01,  3.2773e-01, -2.6591e-02,  2.7794e-01,\n         -6.1035e-02, -2.2502e-01, -3.0609e-01, -2.8897e-01, -1.3668e-01,\n         -3.2588e-01,  3.0908e-01],\n        [ 1.4810e-01, -2.2066e-01,  1.6057e-01, -6.8841e-02, -1.7501e-01,\n         -2.9683e-01,  2.9107e-01, -1.5930e-01, -3.2996e-01, -2.2442e-01,\n          1.9875e-01,  3.2374e-01,  6.3666e-02, -1.0638e-01, -1.1292e-01,\n          8.6755e-02, -3.4113e-01, -1.7201e-01, -2.0496e-01, -1.5194e-01,\n         -5.6631e-03, -1.2483e-01, -1.9163e-01,  3.4442e-01, -2.7937e-01,\n         -1.1379e-01,  1.5487e-01,  3.2126e-01, -2.4088e-01, -2.3230e-01,\n         -7.3510e-02,  5.4272e-02],\n        [ 2.9307e-01, -2.0213e-01,  9.6729e-02,  1.4498e-01,  2.5385e-01,\n          3.0603e-01,  5.5028e-02, -2.5439e-01,  3.0724e-02, -6.4604e-02,\n          1.7002e-01,  1.8810e-01, -4.4897e-02,  3.4071e-01,  2.6311e-01,\n         -1.8048e-02, -1.0335e-01, -2.0611e-02,  3.2032e-01,  3.3843e-01,\n          2.8046e-01, -2.0544e-01, -1.5778e-01,  2.2886e-01,  1.5985e-01,\n         -8.5401e-02, -3.1969e-01,  3.1515e-01, -3.2517e-01, -1.3621e-01,\n         -8.6234e-02,  1.7478e-01],\n        [-7.4560e-02,  1.4288e-01,  1.8017e-01, -3.4804e-01,  2.2271e-01,\n          3.3080e-01,  3.0475e-01,  3.1878e-01,  1.3016e-01, -5.0222e-02,\n         -1.8441e-01, -3.7068e-02, -1.3279e-01, -1.0256e-01,  2.0456e-01,\n          5.5782e-02, -3.4071e-01, -3.0788e-01, -9.1565e-02,  2.2131e-01,\n         -1.9653e-02,  1.5882e-01, -1.1222e-01, -3.2609e-01, -2.8883e-01,\n          4.6172e-02,  3.1759e-01, -4.9720e-02, -9.9645e-02, -1.7474e-01,\n         -2.9219e-01, -3.0097e-01],\n        [ 2.3826e-02,  1.0129e-01, -1.7099e-02,  2.9505e-01,  1.5327e-01,\n          2.5505e-01,  1.5141e-01, -3.4997e-01,  3.0129e-01,  2.7865e-01,\n          1.0145e-01, -3.0546e-01, -2.2540e-01,  1.7127e-01,  1.2888e-01,\n         -2.5162e-01, -7.6052e-02, -1.3980e-02, -5.5664e-02, -2.2431e-01,\n         -3.5059e-01,  3.4771e-01,  2.2646e-01, -1.1684e-01, -3.0493e-03,\n          1.9772e-01, -6.6056e-02,  9.5332e-03, -2.5912e-01,  2.2052e-01,\n         -9.1823e-02,  1.0644e-01],\n        [-6.7889e-03,  2.7113e-01, -5.3304e-02, -2.7293e-01, -9.3748e-02,\n          3.5024e-01,  1.0843e-01, -2.8482e-01, -2.7961e-01, -2.2922e-01,\n         -2.9130e-01,  3.3456e-01, -8.3194e-02,  3.0772e-01,  2.9144e-01,\n         -2.2116e-01, -8.8084e-02,  1.0645e-01,  3.5240e-01, -7.2147e-02,\n          2.2722e-01, -2.5704e-01,  1.7733e-01,  3.1732e-01, -2.0548e-01,\n          1.8419e-01,  1.4937e-01, -1.5060e-02, -9.9214e-02, -1.5036e-01,\n          1.0706e-01, -1.4000e-01],\n        [-3.3687e-01,  8.5637e-02,  2.5938e-01,  2.9276e-01,  3.1567e-01,\n          2.5241e-01, -3.0693e-01,  1.6367e-01, -2.4321e-01, -3.4307e-01,\n          2.6610e-01, -1.0685e-01, -1.9898e-02,  1.9749e-01,  2.8365e-01,\n          4.0452e-02,  2.8525e-01, -9.0652e-02,  2.1131e-01,  9.6333e-02,\n          1.0579e-01,  3.3892e-01,  2.9442e-01, -6.7166e-03,  1.8549e-01,\n          9.6427e-03,  2.8201e-01,  9.9061e-02, -2.9499e-01,  1.3342e-01,\n         -2.0748e-01,  6.4994e-02],\n        [ 4.1134e-02,  7.5990e-02,  8.7339e-02,  1.8495e-01,  9.1125e-02,\n         -3.7731e-02,  2.1837e-01, -1.1880e-01, -6.7663e-02, -2.8449e-01,\n         -2.5921e-01,  1.4302e-01,  5.3613e-02,  8.0692e-02, -1.4930e-01,\n         -1.4743e-01,  2.3530e-01, -9.3326e-02, -1.8605e-01,  9.4791e-02,\n         -2.1545e-01,  1.9316e-01,  1.6244e-01,  2.9897e-01, -3.2867e-01,\n          2.2383e-01, -2.5392e-01, -3.4082e-01,  2.9337e-01,  2.3727e-01,\n         -1.7851e-01,  1.7874e-04],\n        [-2.1876e-02,  3.0532e-01, -3.2729e-01, -3.2291e-01,  2.2410e-01,\n         -1.3666e-01,  6.3610e-03,  1.9618e-01, -5.7693e-02,  1.7115e-01,\n          2.7897e-01,  2.9862e-01, -5.8739e-02,  2.1749e-01,  7.6128e-02,\n          1.4235e-01,  3.4230e-01,  2.5482e-01,  2.3254e-01,  5.6372e-02,\n          3.0165e-01, -2.1928e-01,  1.9527e-01, -3.0304e-01,  3.0931e-01,\n         -2.8743e-01, -2.0814e-01, -1.2595e-02, -1.5555e-01,  2.6511e-02,\n         -3.5068e-01,  2.6139e-01],\n        [ 2.5765e-01, -3.3397e-01, -2.3604e-01,  1.5248e-01,  3.3770e-01,\n          3.2109e-02, -2.4304e-01, -3.3863e-01,  2.1247e-01, -3.4731e-01,\n          2.9208e-01, -4.8782e-02, -3.4601e-01, -1.5321e-01, -3.1035e-01,\n          1.1622e-01,  9.1265e-02,  1.8154e-01,  3.4463e-02,  2.4837e-02,\n          1.3170e-01,  1.4070e-01, -2.3263e-01,  1.5074e-01,  1.8593e-01,\n         -2.9446e-01, -3.0252e-01,  4.4034e-02,  3.4144e-01, -1.2757e-01,\n          3.4147e-01,  2.6001e-01],\n        [-1.0727e-01, -3.1949e-01, -2.1015e-01, -1.0760e-01, -2.8522e-01,\n         -1.3014e-01, -1.4164e-01,  2.7234e-01,  1.9771e-01, -3.1113e-01,\n         -3.2137e-01, -9.3287e-02, -2.6226e-01, -1.4025e-01, -2.9018e-01,\n          1.3390e-01,  1.2499e-01, -1.3062e-01,  2.1602e-01,  8.6739e-02,\n          2.5805e-01,  1.5879e-01, -4.4671e-02, -3.0080e-01,  4.3529e-02,\n          6.0587e-03, -2.4943e-01, -2.5683e-02, -6.6069e-04, -1.9461e-01,\n          2.4171e-01, -1.9985e-01],\n        [-2.3627e-01,  2.0703e-02,  9.0138e-02, -4.7516e-02, -1.1754e-01,\n         -1.2604e-01,  2.4382e-01, -2.4077e-01, -2.2908e-01, -7.7195e-02,\n          1.6248e-01,  9.2505e-02,  5.4555e-02, -3.4787e-01,  6.4435e-02,\n          2.8208e-02, -9.6150e-02,  1.1338e-01,  1.4776e-01,  3.4013e-01,\n          3.1759e-01, -2.0575e-01,  2.2738e-04,  2.9444e-02, -3.4926e-01,\n          1.1015e-01,  2.5897e-01, -6.6161e-02,  1.5200e-01,  8.8309e-02,\n          2.1042e-01,  2.2027e-01],\n        [ 2.8804e-03,  2.5624e-01,  2.0373e-01,  2.4836e-01, -7.8981e-02,\n         -8.3590e-02, -9.7093e-02,  2.7096e-01, -1.3265e-02,  5.0300e-02,\n         -2.8583e-01, -2.0250e-01,  6.7159e-02, -7.1741e-02,  3.1505e-01,\n          3.1846e-01, -6.2707e-02, -3.0108e-01,  2.8806e-01,  2.0444e-01,\n          7.0990e-02,  1.8428e-01,  3.1798e-02,  2.2984e-01, -1.6326e-02,\n          1.9295e-01,  8.8146e-02, -1.3869e-01, -2.6234e-01,  2.8957e-01,\n         -4.6319e-02, -3.2182e-02],\n        [-3.4317e-01, -2.1716e-01,  5.7570e-02, -2.7165e-01, -3.3235e-01,\n          6.2074e-02, -1.2979e-01,  2.7477e-01, -8.1864e-02, -1.3435e-01,\n          2.9018e-01, -1.5304e-01,  2.6365e-01,  2.5918e-01,  1.6427e-01,\n          1.1232e-01, -2.6141e-01, -6.1396e-02,  3.0572e-01,  3.5323e-01,\n         -3.0757e-01, -2.2845e-01,  2.1334e-02, -1.2616e-01,  2.7938e-01,\n         -2.9406e-01, -1.1262e-01,  7.0332e-02,  2.5837e-01,  2.9787e-01,\n         -1.6273e-01,  8.2306e-02],\n        [ 3.2761e-01,  2.4082e-01,  1.5630e-02, -6.4711e-02,  8.6065e-02,\n         -7.1605e-02, -4.3589e-03,  2.5983e-01,  5.8040e-03, -4.6303e-03,\n          1.7552e-01,  3.1991e-01,  2.1924e-01,  2.0939e-02, -5.5001e-02,\n         -2.5897e-01, -2.2282e-01, -3.1977e-01, -6.8945e-02,  6.7192e-03,\n         -2.7935e-01, -2.6162e-01, -3.2415e-01, -2.0968e-01, -2.1915e-01,\n         -1.0146e-01,  2.7295e-02,  1.1795e-01,  4.5597e-02,  2.2550e-01,\n         -3.3877e-02, -1.3702e-01],\n        [ 1.0595e-01,  3.2981e-01,  2.4724e-01, -3.2157e-01, -1.2093e-01,\n         -1.6852e-01,  2.7863e-01, -2.4993e-01, -2.9923e-01,  2.2106e-01,\n          1.1868e-01,  5.4807e-02, -1.1766e-02,  2.6181e-01,  3.7525e-02,\n         -2.0138e-01, -1.8492e-01,  4.5105e-02,  5.9428e-02,  2.0702e-01,\n          3.2527e-01,  3.2177e-01,  2.3508e-01,  2.8102e-01, -1.9687e-01,\n          1.0231e-01,  1.7576e-01, -3.2846e-01, -2.8128e-01, -1.1946e-01,\n         -2.7585e-01, -1.1640e-03]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0435, -0.0591, -0.2210, -0.3435, -0.2303, -0.4664,  0.0370,  0.1110,\n         -0.3417,  0.1249,  0.4239, -0.4911, -0.4346,  0.3096, -0.4195, -0.1000],\n        [ 0.3127,  0.0356,  0.1179, -0.0475, -0.3916, -0.3146,  0.0291,  0.2244,\n         -0.3081, -0.0930, -0.2259,  0.4196,  0.1668, -0.1854, -0.3369,  0.3533],\n        [-0.4806,  0.2076, -0.3394,  0.1647, -0.3321, -0.0612, -0.0200, -0.4956,\n         -0.1526, -0.2547,  0.2754, -0.1505,  0.3230, -0.3843,  0.0138,  0.1902],\n        [-0.1724, -0.1797,  0.3950,  0.4150,  0.1816, -0.2618, -0.3240,  0.1812,\n          0.3838, -0.4768,  0.4004, -0.0439,  0.2096, -0.4373, -0.4516, -0.4182],\n        [ 0.3854, -0.2471,  0.3578, -0.2760, -0.4636, -0.0479, -0.2540,  0.4080,\n         -0.1761,  0.0265, -0.0802,  0.4987,  0.1602, -0.0571,  0.3533, -0.0536],\n        [-0.3579, -0.4951, -0.1715,  0.0055,  0.1519,  0.4885, -0.1149, -0.3068,\n         -0.4499, -0.1009, -0.3074, -0.4377, -0.0902,  0.2842,  0.1481,  0.2086],\n        [-0.0857,  0.4912,  0.0969,  0.1654, -0.3159, -0.1232, -0.0864, -0.2219,\n          0.1488, -0.1653, -0.2919, -0.4042,  0.2280,  0.0481,  0.0686,  0.1827],\n        [ 0.2207,  0.4035, -0.0294, -0.0987,  0.0546, -0.3975, -0.1928,  0.0006,\n         -0.4708,  0.4240, -0.1187,  0.2038,  0.4561,  0.1426,  0.1268, -0.2323]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3316,  0.0787,  0.5328,  0.2676,  0.3157,  0.2321,  0.2788, -0.3504],\n        [-0.4618, -0.2016, -0.5414, -0.2238,  0.0709, -0.6384, -0.3719,  0.2948],\n        [ 0.4094,  0.0098, -0.3898, -0.0597,  0.6974, -0.5410, -0.5697, -0.0890],\n        [ 0.5246, -0.0966,  0.5049, -0.5414, -0.3491, -0.0863,  0.1234, -0.0944]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x72d9171eac90>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s621090000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s621090000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}