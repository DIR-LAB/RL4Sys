{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	128,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.03,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s622160000"
    },
    "q_lr":	0.01,
    "seed":	622160000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x747a8cda3790>":	{
            "_act_dim":	4,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.03,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2604,  0.1751,  0.0190,  0.1176, -0.1911,  0.1697,  0.2951,  0.2801],\n        [ 0.3586, -0.3266,  0.0048, -0.2438, -0.2812,  0.2889,  0.1892, -0.0812],\n        [ 0.2312, -0.1492, -0.1859, -0.0128, -0.3743,  0.2731,  0.2139,  0.0084],\n        [ 0.2040, -0.2782,  0.0338,  0.0729,  0.0226, -0.0272, -0.2475,  0.1201],\n        [ 0.3128,  0.2669, -0.1867,  0.1495,  0.1047, -0.0363,  0.3781, -0.3526],\n        [ 0.3394,  0.1154, -0.2500,  0.2560, -0.0297, -0.1550,  0.0520, -0.0943],\n        [ 0.1895,  0.1097, -0.1899,  0.1605,  0.0791,  0.0303, -0.3868, -0.0924],\n        [-0.1619, -0.1768,  0.3599, -0.0463,  0.2055,  0.3770, -0.0056,  0.3680],\n        [-0.2987,  0.3423, -0.0038, -0.1990, -0.0063,  0.0298, -0.0144,  0.2840],\n        [-0.3188,  0.2982, -0.2426, -0.1668, -0.2807, -0.2749,  0.0837,  0.0719],\n        [ 0.3830, -0.2830, -0.1793,  0.0962, -0.0665,  0.3376,  0.2710, -0.1863],\n        [ 0.1417, -0.3724, -0.1153, -0.3282, -0.1975,  0.2360, -0.0109,  0.1820],\n        [ 0.2153,  0.2474,  0.2222,  0.3479, -0.1921,  0.1965,  0.1902, -0.2590],\n        [ 0.0871, -0.2563,  0.0702,  0.1444,  0.3480,  0.0942, -0.0814, -0.1904],\n        [ 0.0624,  0.1731, -0.1482, -0.0953, -0.2662,  0.0023, -0.3411, -0.1923],\n        [ 0.2214, -0.1340,  0.2414, -0.2289, -0.0375,  0.3543,  0.3155, -0.1623],\n        [-0.1481,  0.0989,  0.2238,  0.1024,  0.0588,  0.2895, -0.3645, -0.0102],\n        [ 0.3418,  0.0897, -0.1322,  0.3762, -0.3344,  0.1072, -0.0963,  0.1666],\n        [ 0.1522,  0.3657, -0.1694,  0.2396,  0.1667, -0.2319, -0.1989, -0.1910],\n        [-0.0043,  0.3095, -0.0836,  0.3494, -0.1777,  0.2560,  0.0611, -0.0281],\n        [ 0.1571, -0.1494, -0.0748,  0.3205,  0.3359, -0.1616, -0.2314,  0.2291],\n        [ 0.2472, -0.2012, -0.3738, -0.3321,  0.1692,  0.2005, -0.2165,  0.1274],\n        [ 0.1888,  0.0052,  0.0845,  0.2095, -0.1187, -0.2796,  0.2015,  0.1326],\n        [ 0.3543,  0.0016,  0.2271,  0.3682,  0.3746, -0.1742,  0.0442, -0.1920],\n        [ 0.2642, -0.3558,  0.2216,  0.0906, -0.3115,  0.1532, -0.3748,  0.0514],\n        [-0.1056,  0.2848, -0.1723,  0.2116, -0.1910,  0.3166, -0.2460,  0.2848],\n        [ 0.2512,  0.1316,  0.0441,  0.1101, -0.1283,  0.1609,  0.2142,  0.0545],\n        [ 0.0409, -0.0635, -0.1184, -0.3767,  0.0885, -0.1051,  0.1835, -0.3857],\n        [-0.2240, -0.1551, -0.3426, -0.2264,  0.0368, -0.3236,  0.1892, -0.0192],\n        [-0.2096, -0.1334, -0.2414,  0.3806, -0.2236, -0.3868, -0.3468,  0.1409],\n        [ 0.3707, -0.0937,  0.0115, -0.0544,  0.1269,  0.1483, -0.1450, -0.2963],\n        [ 0.0827, -0.0391, -0.2024,  0.2913, -0.2621, -0.0849,  0.1326,  0.0585]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 2.1223e-01, -1.8631e-01,  1.4961e-01, -1.1484e-01, -2.8741e-02,\n          2.7364e-01,  1.5276e-01, -4.3898e-02, -7.7411e-02,  1.6136e-01,\n          2.0775e-01,  6.7680e-03,  2.1563e-01,  3.2514e-01, -1.7688e-01,\n          8.9202e-02,  3.0550e-01,  2.0586e-01,  6.4262e-02,  2.9307e-01,\n         -2.8294e-01, -2.6307e-01, -7.0309e-02,  3.1748e-01, -1.4290e-01,\n          3.0801e-02, -3.0377e-01, -3.8732e-03,  5.6707e-02,  9.1886e-02,\n          1.9355e-01,  4.9634e-02],\n        [-3.1088e-01,  1.9875e-01,  3.5179e-01,  1.0751e-02, -2.6698e-01,\n         -1.0482e-01, -2.8935e-01, -1.9785e-01,  1.1027e-01,  6.3105e-02,\n         -2.5096e-01,  2.0224e-01,  1.2091e-01, -2.5909e-01,  2.4204e-01,\n         -3.4548e-01,  2.1570e-01,  1.4956e-01,  1.1021e-01,  1.1674e-01,\n         -1.5405e-02, -1.3620e-01,  2.7110e-02,  1.8755e-01, -8.8193e-02,\n          2.8704e-01,  1.3408e-01,  4.9665e-03, -2.9233e-01,  1.8231e-01,\n         -9.7407e-02, -2.0343e-01],\n        [-1.8185e-01, -5.8777e-02, -2.3246e-01, -2.8135e-01, -7.1481e-02,\n         -3.1228e-01,  5.4899e-02,  2.4233e-01,  1.7790e-01,  1.8413e-01,\n         -1.4225e-01, -2.7592e-01, -5.5666e-02, -9.8629e-02, -3.3286e-01,\n         -1.2282e-01,  1.2483e-01, -3.3941e-01, -2.5387e-01,  6.4155e-02,\n         -2.4780e-02,  4.8011e-02,  1.7194e-01, -1.4936e-01, -3.4684e-01,\n         -2.6460e-01, -1.5396e-01, -2.8752e-02, -7.5288e-02,  3.1348e-01,\n         -3.2833e-01, -1.0818e-01],\n        [ 2.8808e-01, -2.9418e-01,  9.1550e-02, -2.0305e-01, -8.0758e-02,\n          3.3870e-01,  1.1157e-01, -2.9828e-01,  2.0247e-01, -9.3257e-02,\n         -9.9778e-03, -1.5681e-01,  1.4607e-01, -3.6182e-02,  1.0004e-01,\n         -5.2389e-02, -7.7425e-02,  1.6176e-01,  1.2150e-02, -7.1113e-02,\n         -1.4707e-01, -1.6421e-01, -1.5402e-01, -2.3807e-01, -5.6367e-02,\n         -4.2590e-02,  2.9161e-01, -2.3344e-01, -2.8146e-01, -2.9187e-01,\n         -3.3935e-01, -7.6495e-02],\n        [-5.3560e-03,  1.7096e-01,  2.9315e-02, -9.3022e-03, -3.3193e-01,\n         -2.0743e-01,  2.8342e-01, -2.4387e-01,  9.4948e-02, -2.3866e-01,\n         -3.0419e-01,  1.2194e-01, -2.1111e-01, -2.7020e-01, -3.6536e-02,\n         -9.4404e-02, -3.0077e-01, -1.3411e-01,  2.7896e-01, -1.5323e-01,\n         -2.0203e-01,  1.5498e-01,  1.0900e-01, -3.3412e-01, -2.0792e-01,\n          2.0870e-01, -1.4868e-01,  1.5067e-01,  2.1368e-01, -3.1184e-01,\n          3.0281e-02, -3.1468e-01],\n        [-2.2527e-01,  3.3005e-01, -2.8523e-02, -2.2302e-01,  2.7081e-01,\n         -2.8375e-01, -1.5908e-02, -2.1086e-01, -1.9130e-01,  2.5077e-01,\n          2.2746e-01, -3.4728e-01, -3.3024e-01, -2.8705e-01,  1.5611e-01,\n          9.3902e-02, -4.0079e-02, -2.7189e-01, -1.0216e-01, -6.1285e-02,\n          1.8314e-01,  1.3023e-01,  1.3592e-01, -3.6604e-02,  2.9894e-01,\n         -1.8993e-01,  1.0404e-01,  8.9302e-02,  2.2891e-01,  1.9462e-01,\n         -1.0260e-01, -1.4790e-01],\n        [ 7.0552e-02,  8.8857e-02, -2.8353e-01,  2.6347e-01, -3.5091e-04,\n         -2.3703e-01,  2.7169e-02, -1.5902e-01,  1.6426e-01,  6.3382e-02,\n          1.8043e-01,  2.2251e-01,  2.1151e-01, -5.2888e-02, -1.8022e-01,\n         -6.6874e-03,  7.2629e-03,  2.8466e-02, -2.0975e-01, -3.4273e-01,\n         -5.6093e-02, -2.6024e-01,  1.4591e-01,  1.9524e-01,  2.9296e-01,\n         -3.3222e-01, -1.1036e-01, -2.1494e-01, -2.0870e-01,  2.5180e-02,\n         -1.2501e-01, -1.1820e-01],\n        [ 2.0356e-01, -1.1870e-01,  5.9004e-03, -2.2989e-01, -1.9796e-01,\n          2.5095e-01, -3.5256e-01, -1.9390e-01, -2.7415e-01,  7.0770e-02,\n         -1.4691e-01,  3.3864e-01,  3.6936e-02, -3.8162e-02,  3.6840e-02,\n         -1.1724e-02, -2.0422e-01,  7.7994e-02, -3.4240e-01,  6.6052e-02,\n         -1.4216e-02, -1.4171e-01, -9.6591e-02, -2.5478e-01,  2.6119e-01,\n         -2.6931e-01, -1.2015e-01,  4.8331e-02, -3.0587e-01,  3.2924e-01,\n          2.6687e-01,  6.5098e-02],\n        [ 2.4905e-01, -3.4037e-01, -1.9325e-01, -4.2373e-02,  5.1468e-02,\n         -3.1252e-01,  6.1822e-02, -3.5116e-01,  2.7372e-01,  1.0444e-02,\n         -2.3571e-01, -1.5018e-01, -1.4733e-01,  2.9159e-01,  2.2169e-01,\n         -3.4186e-01,  2.1366e-01,  1.8546e-01,  2.8727e-01, -2.3618e-01,\n         -1.4254e-01,  2.3392e-01, -3.9640e-02,  2.7193e-01,  2.0216e-02,\n         -3.2829e-01,  6.2485e-02, -3.1240e-01,  4.9977e-02,  2.9030e-01,\n          3.5104e-01,  2.3095e-01],\n        [ 3.4371e-01, -1.2837e-01,  7.5273e-02, -1.3646e-01, -1.0745e-01,\n          2.0729e-01, -6.9819e-02,  1.2791e-01, -7.5837e-02,  1.2083e-01,\n          2.4898e-01,  2.6309e-01, -7.1601e-02,  3.0899e-01,  3.3344e-01,\n         -8.1896e-02,  2.0806e-01, -2.5525e-01, -6.4956e-02, -3.3499e-01,\n         -3.2665e-01,  9.2341e-02, -1.9458e-01,  2.6728e-02, -6.7682e-02,\n          1.2839e-01,  2.8702e-01, -6.8303e-02, -1.7629e-01, -9.4430e-02,\n          2.5583e-04,  2.5011e-02],\n        [ 1.4566e-01, -8.5284e-02,  2.6679e-01, -3.0660e-01, -2.7063e-01,\n         -1.4192e-01,  2.9125e-01,  1.3351e-01,  2.9468e-01, -5.4790e-02,\n          4.4046e-02, -3.0622e-01,  2.8541e-01, -7.7883e-02,  1.6740e-01,\n          1.4238e-01,  3.3551e-02,  5.4334e-03,  9.7751e-04, -4.8405e-02,\n          6.1145e-02,  1.4791e-01,  1.5084e-01, -1.5714e-01, -2.4528e-01,\n         -2.8207e-02,  7.1852e-02, -8.3996e-02,  8.6267e-02,  1.0983e-01,\n          2.2173e-03, -1.4229e-01],\n        [-2.7939e-01,  1.4820e-02,  2.3732e-01, -9.2718e-02,  1.9610e-01,\n          9.4638e-02, -2.0004e-01, -3.4091e-01, -3.4162e-01, -1.3116e-01,\n         -8.1350e-02,  2.8776e-01, -1.4832e-01, -1.1704e-01, -2.6462e-01,\n         -2.5654e-01, -6.1212e-02, -2.3398e-01, -2.8859e-01, -3.2826e-01,\n          2.1074e-01,  6.1419e-02,  2.5485e-01, -8.1117e-02,  2.5163e-01,\n          2.2329e-02, -1.3498e-01, -2.7860e-01, -7.6134e-02,  9.0512e-03,\n          6.4912e-02,  4.2307e-02],\n        [ 1.6984e-01, -2.8314e-01,  8.8002e-02, -1.7212e-01,  3.2252e-01,\n         -6.3424e-02,  5.3111e-02, -2.7175e-01, -2.9705e-01,  2.3083e-01,\n         -3.4144e-02, -1.9243e-01,  3.1948e-01, -2.7865e-01, -2.2450e-01,\n          1.2376e-01,  2.1374e-01, -1.8341e-01,  3.4603e-03, -1.9714e-01,\n         -1.2574e-01, -7.5970e-02,  1.6274e-01, -1.7176e-01,  2.0088e-01,\n         -2.7645e-01, -1.3515e-01,  1.5901e-02, -3.1373e-01,  1.4547e-01,\n          4.8156e-02,  2.5283e-01],\n        [-2.1597e-01,  1.1016e-01, -1.6884e-01,  2.1078e-02, -2.9624e-01,\n         -1.9886e-01, -1.1240e-01, -7.2225e-02, -2.3132e-01,  3.0520e-01,\n          2.7810e-02,  4.4608e-02, -2.6450e-01, -1.8060e-01,  2.3508e-01,\n         -1.7574e-01,  2.8655e-01,  4.0011e-02,  3.5195e-01, -7.8986e-02,\n         -2.7728e-01, -2.8978e-01, -1.1946e-01, -2.4955e-01,  1.0110e-01,\n         -2.7224e-02, -2.3265e-01,  3.0334e-01,  1.3347e-01,  1.0746e-01,\n         -6.0050e-02,  4.6254e-02],\n        [ 1.1873e-01, -1.6831e-01,  2.6564e-01, -2.2020e-01, -2.6880e-01,\n         -1.8776e-01,  2.1210e-01, -2.2511e-01, -1.5002e-01, -1.7680e-01,\n          5.4706e-02, -9.4340e-02,  5.7831e-02,  2.9418e-02, -3.4825e-01,\n          3.4143e-01, -2.9872e-01, -1.1330e-01,  2.9510e-01,  5.5886e-02,\n         -5.2540e-02,  2.5785e-01, -1.9985e-01, -9.8770e-02,  3.0829e-01,\n         -3.0568e-01,  1.7364e-01,  7.2703e-02, -6.7299e-02,  2.2703e-01,\n          1.4427e-01, -2.0475e-01],\n        [ 2.1987e-01, -1.0833e-01,  3.0832e-01,  1.9281e-01,  1.6767e-01,\n         -2.0653e-01,  1.7095e-01,  6.3121e-02, -1.7365e-01, -3.5032e-02,\n          1.9094e-01,  3.1351e-01, -1.6940e-02, -1.8044e-01, -1.9076e-01,\n         -1.6814e-01, -6.7297e-03, -3.0369e-01, -2.9242e-02, -6.6310e-02,\n          3.1889e-01,  1.2400e-02,  5.0984e-02,  1.9457e-01, -2.2872e-01,\n          1.6606e-01, -3.2536e-02, -1.9881e-01,  3.0265e-01, -2.2286e-01,\n         -3.8413e-03, -6.5889e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1055, -0.2539, -0.2932,  0.3261,  0.2190,  0.2202,  0.4719,  0.4016,\n         -0.2439, -0.1540,  0.2876,  0.0565, -0.0379, -0.4497,  0.3937, -0.1209],\n        [ 0.2977, -0.3398,  0.4489, -0.3962, -0.0371,  0.4217,  0.2641, -0.3250,\n         -0.3849,  0.1158, -0.2647, -0.2670,  0.4345, -0.3707,  0.1829, -0.2548],\n        [ 0.1055,  0.1505, -0.4560, -0.3448,  0.4566, -0.4954, -0.0319,  0.4869,\n         -0.2957,  0.3469,  0.1999,  0.4975,  0.2196, -0.1721, -0.3283,  0.0894],\n        [-0.1463,  0.2806, -0.0531, -0.3215, -0.2189, -0.3009, -0.3748,  0.4883,\n         -0.2695,  0.3146, -0.2513, -0.2312, -0.0382, -0.4857,  0.3536,  0.2213],\n        [ 0.0666, -0.0924, -0.1763, -0.3435,  0.3379, -0.3519,  0.0751, -0.4946,\n         -0.4705,  0.0547, -0.3981, -0.2644,  0.1522, -0.2577, -0.1596, -0.2710],\n        [-0.2187, -0.3136, -0.1591,  0.4559, -0.3204, -0.3913,  0.4850, -0.3355,\n         -0.2656,  0.1562, -0.1426, -0.2241,  0.3720,  0.3243,  0.3854,  0.2261],\n        [-0.0231,  0.0219, -0.3130,  0.4054, -0.3197,  0.3355,  0.1608, -0.3330,\n         -0.3862,  0.0673, -0.3368, -0.4000, -0.3559, -0.4187, -0.1210,  0.4276],\n        [-0.3493,  0.4773,  0.2705, -0.3479,  0.3103,  0.4117,  0.3317, -0.1748,\n          0.2702, -0.1127, -0.1112,  0.1542,  0.0885,  0.2327,  0.3579, -0.3644]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.5913,  0.4045, -0.4509,  0.2816, -0.3037,  0.4422,  0.6197, -0.2070],\n        [-0.6408, -0.0573,  0.6819, -0.2595,  0.5993, -0.4224,  0.4087,  0.6832],\n        [-0.0440, -0.1045, -0.0536, -0.2771, -0.3929,  0.4257, -0.5544,  0.4859],\n        [-0.2039, -0.1643,  0.2616, -0.5785,  0.5021,  0.3236,  0.1779,  0.4392]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.01\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.01,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.01,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2604,  0.1751,  0.0190,  0.1176, -0.1911,  0.1697,  0.2951,  0.2801],\n        [ 0.3586, -0.3266,  0.0048, -0.2438, -0.2812,  0.2889,  0.1892, -0.0812],\n        [ 0.2312, -0.1492, -0.1859, -0.0128, -0.3743,  0.2731,  0.2139,  0.0084],\n        [ 0.2040, -0.2782,  0.0338,  0.0729,  0.0226, -0.0272, -0.2475,  0.1201],\n        [ 0.3128,  0.2669, -0.1867,  0.1495,  0.1047, -0.0363,  0.3781, -0.3526],\n        [ 0.3394,  0.1154, -0.2500,  0.2560, -0.0297, -0.1550,  0.0520, -0.0943],\n        [ 0.1895,  0.1097, -0.1899,  0.1605,  0.0791,  0.0303, -0.3868, -0.0924],\n        [-0.1619, -0.1768,  0.3599, -0.0463,  0.2055,  0.3770, -0.0056,  0.3680],\n        [-0.2987,  0.3423, -0.0038, -0.1990, -0.0063,  0.0298, -0.0144,  0.2840],\n        [-0.3188,  0.2982, -0.2426, -0.1668, -0.2807, -0.2749,  0.0837,  0.0719],\n        [ 0.3830, -0.2830, -0.1793,  0.0962, -0.0665,  0.3376,  0.2710, -0.1863],\n        [ 0.1417, -0.3724, -0.1153, -0.3282, -0.1975,  0.2360, -0.0109,  0.1820],\n        [ 0.2153,  0.2474,  0.2222,  0.3479, -0.1921,  0.1965,  0.1902, -0.2590],\n        [ 0.0871, -0.2563,  0.0702,  0.1444,  0.3480,  0.0942, -0.0814, -0.1904],\n        [ 0.0624,  0.1731, -0.1482, -0.0953, -0.2662,  0.0023, -0.3411, -0.1923],\n        [ 0.2214, -0.1340,  0.2414, -0.2289, -0.0375,  0.3543,  0.3155, -0.1623],\n        [-0.1481,  0.0989,  0.2238,  0.1024,  0.0588,  0.2895, -0.3645, -0.0102],\n        [ 0.3418,  0.0897, -0.1322,  0.3762, -0.3344,  0.1072, -0.0963,  0.1666],\n        [ 0.1522,  0.3657, -0.1694,  0.2396,  0.1667, -0.2319, -0.1989, -0.1910],\n        [-0.0043,  0.3095, -0.0836,  0.3494, -0.1777,  0.2560,  0.0611, -0.0281],\n        [ 0.1571, -0.1494, -0.0748,  0.3205,  0.3359, -0.1616, -0.2314,  0.2291],\n        [ 0.2472, -0.2012, -0.3738, -0.3321,  0.1692,  0.2005, -0.2165,  0.1274],\n        [ 0.1888,  0.0052,  0.0845,  0.2095, -0.1187, -0.2796,  0.2015,  0.1326],\n        [ 0.3543,  0.0016,  0.2271,  0.3682,  0.3746, -0.1742,  0.0442, -0.1920],\n        [ 0.2642, -0.3558,  0.2216,  0.0906, -0.3115,  0.1532, -0.3748,  0.0514],\n        [-0.1056,  0.2848, -0.1723,  0.2116, -0.1910,  0.3166, -0.2460,  0.2848],\n        [ 0.2512,  0.1316,  0.0441,  0.1101, -0.1283,  0.1609,  0.2142,  0.0545],\n        [ 0.0409, -0.0635, -0.1184, -0.3767,  0.0885, -0.1051,  0.1835, -0.3857],\n        [-0.2240, -0.1551, -0.3426, -0.2264,  0.0368, -0.3236,  0.1892, -0.0192],\n        [-0.2096, -0.1334, -0.2414,  0.3806, -0.2236, -0.3868, -0.3468,  0.1409],\n        [ 0.3707, -0.0937,  0.0115, -0.0544,  0.1269,  0.1483, -0.1450, -0.2963],\n        [ 0.0827, -0.0391, -0.2024,  0.2913, -0.2621, -0.0849,  0.1326,  0.0585]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 2.1223e-01, -1.8631e-01,  1.4961e-01, -1.1484e-01, -2.8741e-02,\n          2.7364e-01,  1.5276e-01, -4.3898e-02, -7.7411e-02,  1.6136e-01,\n          2.0775e-01,  6.7680e-03,  2.1563e-01,  3.2514e-01, -1.7688e-01,\n          8.9202e-02,  3.0550e-01,  2.0586e-01,  6.4262e-02,  2.9307e-01,\n         -2.8294e-01, -2.6307e-01, -7.0309e-02,  3.1748e-01, -1.4290e-01,\n          3.0801e-02, -3.0377e-01, -3.8732e-03,  5.6707e-02,  9.1886e-02,\n          1.9355e-01,  4.9634e-02],\n        [-3.1088e-01,  1.9875e-01,  3.5179e-01,  1.0751e-02, -2.6698e-01,\n         -1.0482e-01, -2.8935e-01, -1.9785e-01,  1.1027e-01,  6.3105e-02,\n         -2.5096e-01,  2.0224e-01,  1.2091e-01, -2.5909e-01,  2.4204e-01,\n         -3.4548e-01,  2.1570e-01,  1.4956e-01,  1.1021e-01,  1.1674e-01,\n         -1.5405e-02, -1.3620e-01,  2.7110e-02,  1.8755e-01, -8.8193e-02,\n          2.8704e-01,  1.3408e-01,  4.9665e-03, -2.9233e-01,  1.8231e-01,\n         -9.7407e-02, -2.0343e-01],\n        [-1.8185e-01, -5.8777e-02, -2.3246e-01, -2.8135e-01, -7.1481e-02,\n         -3.1228e-01,  5.4899e-02,  2.4233e-01,  1.7790e-01,  1.8413e-01,\n         -1.4225e-01, -2.7592e-01, -5.5666e-02, -9.8629e-02, -3.3286e-01,\n         -1.2282e-01,  1.2483e-01, -3.3941e-01, -2.5387e-01,  6.4155e-02,\n         -2.4780e-02,  4.8011e-02,  1.7194e-01, -1.4936e-01, -3.4684e-01,\n         -2.6460e-01, -1.5396e-01, -2.8752e-02, -7.5288e-02,  3.1348e-01,\n         -3.2833e-01, -1.0818e-01],\n        [ 2.8808e-01, -2.9418e-01,  9.1550e-02, -2.0305e-01, -8.0758e-02,\n          3.3870e-01,  1.1157e-01, -2.9828e-01,  2.0247e-01, -9.3257e-02,\n         -9.9778e-03, -1.5681e-01,  1.4607e-01, -3.6182e-02,  1.0004e-01,\n         -5.2389e-02, -7.7425e-02,  1.6176e-01,  1.2150e-02, -7.1113e-02,\n         -1.4707e-01, -1.6421e-01, -1.5402e-01, -2.3807e-01, -5.6367e-02,\n         -4.2590e-02,  2.9161e-01, -2.3344e-01, -2.8146e-01, -2.9187e-01,\n         -3.3935e-01, -7.6495e-02],\n        [-5.3560e-03,  1.7096e-01,  2.9315e-02, -9.3022e-03, -3.3193e-01,\n         -2.0743e-01,  2.8342e-01, -2.4387e-01,  9.4948e-02, -2.3866e-01,\n         -3.0419e-01,  1.2194e-01, -2.1111e-01, -2.7020e-01, -3.6536e-02,\n         -9.4404e-02, -3.0077e-01, -1.3411e-01,  2.7896e-01, -1.5323e-01,\n         -2.0203e-01,  1.5498e-01,  1.0900e-01, -3.3412e-01, -2.0792e-01,\n          2.0870e-01, -1.4868e-01,  1.5067e-01,  2.1368e-01, -3.1184e-01,\n          3.0281e-02, -3.1468e-01],\n        [-2.2527e-01,  3.3005e-01, -2.8523e-02, -2.2302e-01,  2.7081e-01,\n         -2.8375e-01, -1.5908e-02, -2.1086e-01, -1.9130e-01,  2.5077e-01,\n          2.2746e-01, -3.4728e-01, -3.3024e-01, -2.8705e-01,  1.5611e-01,\n          9.3902e-02, -4.0079e-02, -2.7189e-01, -1.0216e-01, -6.1285e-02,\n          1.8314e-01,  1.3023e-01,  1.3592e-01, -3.6604e-02,  2.9894e-01,\n         -1.8993e-01,  1.0404e-01,  8.9302e-02,  2.2891e-01,  1.9462e-01,\n         -1.0260e-01, -1.4790e-01],\n        [ 7.0552e-02,  8.8857e-02, -2.8353e-01,  2.6347e-01, -3.5091e-04,\n         -2.3703e-01,  2.7169e-02, -1.5902e-01,  1.6426e-01,  6.3382e-02,\n          1.8043e-01,  2.2251e-01,  2.1151e-01, -5.2888e-02, -1.8022e-01,\n         -6.6874e-03,  7.2629e-03,  2.8466e-02, -2.0975e-01, -3.4273e-01,\n         -5.6093e-02, -2.6024e-01,  1.4591e-01,  1.9524e-01,  2.9296e-01,\n         -3.3222e-01, -1.1036e-01, -2.1494e-01, -2.0870e-01,  2.5180e-02,\n         -1.2501e-01, -1.1820e-01],\n        [ 2.0356e-01, -1.1870e-01,  5.9004e-03, -2.2989e-01, -1.9796e-01,\n          2.5095e-01, -3.5256e-01, -1.9390e-01, -2.7415e-01,  7.0770e-02,\n         -1.4691e-01,  3.3864e-01,  3.6936e-02, -3.8162e-02,  3.6840e-02,\n         -1.1724e-02, -2.0422e-01,  7.7994e-02, -3.4240e-01,  6.6052e-02,\n         -1.4216e-02, -1.4171e-01, -9.6591e-02, -2.5478e-01,  2.6119e-01,\n         -2.6931e-01, -1.2015e-01,  4.8331e-02, -3.0587e-01,  3.2924e-01,\n          2.6687e-01,  6.5098e-02],\n        [ 2.4905e-01, -3.4037e-01, -1.9325e-01, -4.2373e-02,  5.1468e-02,\n         -3.1252e-01,  6.1822e-02, -3.5116e-01,  2.7372e-01,  1.0444e-02,\n         -2.3571e-01, -1.5018e-01, -1.4733e-01,  2.9159e-01,  2.2169e-01,\n         -3.4186e-01,  2.1366e-01,  1.8546e-01,  2.8727e-01, -2.3618e-01,\n         -1.4254e-01,  2.3392e-01, -3.9640e-02,  2.7193e-01,  2.0216e-02,\n         -3.2829e-01,  6.2485e-02, -3.1240e-01,  4.9977e-02,  2.9030e-01,\n          3.5104e-01,  2.3095e-01],\n        [ 3.4371e-01, -1.2837e-01,  7.5273e-02, -1.3646e-01, -1.0745e-01,\n          2.0729e-01, -6.9819e-02,  1.2791e-01, -7.5837e-02,  1.2083e-01,\n          2.4898e-01,  2.6309e-01, -7.1601e-02,  3.0899e-01,  3.3344e-01,\n         -8.1896e-02,  2.0806e-01, -2.5525e-01, -6.4956e-02, -3.3499e-01,\n         -3.2665e-01,  9.2341e-02, -1.9458e-01,  2.6728e-02, -6.7682e-02,\n          1.2839e-01,  2.8702e-01, -6.8303e-02, -1.7629e-01, -9.4430e-02,\n          2.5583e-04,  2.5011e-02],\n        [ 1.4566e-01, -8.5284e-02,  2.6679e-01, -3.0660e-01, -2.7063e-01,\n         -1.4192e-01,  2.9125e-01,  1.3351e-01,  2.9468e-01, -5.4790e-02,\n          4.4046e-02, -3.0622e-01,  2.8541e-01, -7.7883e-02,  1.6740e-01,\n          1.4238e-01,  3.3551e-02,  5.4334e-03,  9.7751e-04, -4.8405e-02,\n          6.1145e-02,  1.4791e-01,  1.5084e-01, -1.5714e-01, -2.4528e-01,\n         -2.8207e-02,  7.1852e-02, -8.3996e-02,  8.6267e-02,  1.0983e-01,\n          2.2173e-03, -1.4229e-01],\n        [-2.7939e-01,  1.4820e-02,  2.3732e-01, -9.2718e-02,  1.9610e-01,\n          9.4638e-02, -2.0004e-01, -3.4091e-01, -3.4162e-01, -1.3116e-01,\n         -8.1350e-02,  2.8776e-01, -1.4832e-01, -1.1704e-01, -2.6462e-01,\n         -2.5654e-01, -6.1212e-02, -2.3398e-01, -2.8859e-01, -3.2826e-01,\n          2.1074e-01,  6.1419e-02,  2.5485e-01, -8.1117e-02,  2.5163e-01,\n          2.2329e-02, -1.3498e-01, -2.7860e-01, -7.6134e-02,  9.0512e-03,\n          6.4912e-02,  4.2307e-02],\n        [ 1.6984e-01, -2.8314e-01,  8.8002e-02, -1.7212e-01,  3.2252e-01,\n         -6.3424e-02,  5.3111e-02, -2.7175e-01, -2.9705e-01,  2.3083e-01,\n         -3.4144e-02, -1.9243e-01,  3.1948e-01, -2.7865e-01, -2.2450e-01,\n          1.2376e-01,  2.1374e-01, -1.8341e-01,  3.4603e-03, -1.9714e-01,\n         -1.2574e-01, -7.5970e-02,  1.6274e-01, -1.7176e-01,  2.0088e-01,\n         -2.7645e-01, -1.3515e-01,  1.5901e-02, -3.1373e-01,  1.4547e-01,\n          4.8156e-02,  2.5283e-01],\n        [-2.1597e-01,  1.1016e-01, -1.6884e-01,  2.1078e-02, -2.9624e-01,\n         -1.9886e-01, -1.1240e-01, -7.2225e-02, -2.3132e-01,  3.0520e-01,\n          2.7810e-02,  4.4608e-02, -2.6450e-01, -1.8060e-01,  2.3508e-01,\n         -1.7574e-01,  2.8655e-01,  4.0011e-02,  3.5195e-01, -7.8986e-02,\n         -2.7728e-01, -2.8978e-01, -1.1946e-01, -2.4955e-01,  1.0110e-01,\n         -2.7224e-02, -2.3265e-01,  3.0334e-01,  1.3347e-01,  1.0746e-01,\n         -6.0050e-02,  4.6254e-02],\n        [ 1.1873e-01, -1.6831e-01,  2.6564e-01, -2.2020e-01, -2.6880e-01,\n         -1.8776e-01,  2.1210e-01, -2.2511e-01, -1.5002e-01, -1.7680e-01,\n          5.4706e-02, -9.4340e-02,  5.7831e-02,  2.9418e-02, -3.4825e-01,\n          3.4143e-01, -2.9872e-01, -1.1330e-01,  2.9510e-01,  5.5886e-02,\n         -5.2540e-02,  2.5785e-01, -1.9985e-01, -9.8770e-02,  3.0829e-01,\n         -3.0568e-01,  1.7364e-01,  7.2703e-02, -6.7299e-02,  2.2703e-01,\n          1.4427e-01, -2.0475e-01],\n        [ 2.1987e-01, -1.0833e-01,  3.0832e-01,  1.9281e-01,  1.6767e-01,\n         -2.0653e-01,  1.7095e-01,  6.3121e-02, -1.7365e-01, -3.5032e-02,\n          1.9094e-01,  3.1351e-01, -1.6940e-02, -1.8044e-01, -1.9076e-01,\n         -1.6814e-01, -6.7297e-03, -3.0369e-01, -2.9242e-02, -6.6310e-02,\n          3.1889e-01,  1.2400e-02,  5.0984e-02,  1.9457e-01, -2.2872e-01,\n          1.6606e-01, -3.2536e-02, -1.9881e-01,  3.0265e-01, -2.2286e-01,\n         -3.8413e-03, -6.5889e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1055, -0.2539, -0.2932,  0.3261,  0.2190,  0.2202,  0.4719,  0.4016,\n         -0.2439, -0.1540,  0.2876,  0.0565, -0.0379, -0.4497,  0.3937, -0.1209],\n        [ 0.2977, -0.3398,  0.4489, -0.3962, -0.0371,  0.4217,  0.2641, -0.3250,\n         -0.3849,  0.1158, -0.2647, -0.2670,  0.4345, -0.3707,  0.1829, -0.2548],\n        [ 0.1055,  0.1505, -0.4560, -0.3448,  0.4566, -0.4954, -0.0319,  0.4869,\n         -0.2957,  0.3469,  0.1999,  0.4975,  0.2196, -0.1721, -0.3283,  0.0894],\n        [-0.1463,  0.2806, -0.0531, -0.3215, -0.2189, -0.3009, -0.3748,  0.4883,\n         -0.2695,  0.3146, -0.2513, -0.2312, -0.0382, -0.4857,  0.3536,  0.2213],\n        [ 0.0666, -0.0924, -0.1763, -0.3435,  0.3379, -0.3519,  0.0751, -0.4946,\n         -0.4705,  0.0547, -0.3981, -0.2644,  0.1522, -0.2577, -0.1596, -0.2710],\n        [-0.2187, -0.3136, -0.1591,  0.4559, -0.3204, -0.3913,  0.4850, -0.3355,\n         -0.2656,  0.1562, -0.1426, -0.2241,  0.3720,  0.3243,  0.3854,  0.2261],\n        [-0.0231,  0.0219, -0.3130,  0.4054, -0.3197,  0.3355,  0.1608, -0.3330,\n         -0.3862,  0.0673, -0.3368, -0.4000, -0.3559, -0.4187, -0.1210,  0.4276],\n        [-0.3493,  0.4773,  0.2705, -0.3479,  0.3103,  0.4117,  0.3317, -0.1748,\n          0.2702, -0.1127, -0.1112,  0.1542,  0.0885,  0.2327,  0.3579, -0.3644]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.5913,  0.4045, -0.4509,  0.2816, -0.3037,  0.4422,  0.6197, -0.2070],\n        [-0.6408, -0.0573,  0.6819, -0.2595,  0.5993, -0.4224,  0.4087,  0.6832],\n        [-0.0440, -0.1045, -0.0536, -0.2771, -0.3929,  0.4257, -0.5544,  0.4859],\n        [-0.2039, -0.1643,  0.2616, -0.5785,  0.5021,  0.3236,  0.1779,  0.4392]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x747a8c5db290>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "full":	false,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2604,  0.1751,  0.0190,  0.1176, -0.1911,  0.1697,  0.2951,  0.2801],\n        [ 0.3586, -0.3266,  0.0048, -0.2438, -0.2812,  0.2889,  0.1892, -0.0812],\n        [ 0.2312, -0.1492, -0.1859, -0.0128, -0.3743,  0.2731,  0.2139,  0.0084],\n        [ 0.2040, -0.2782,  0.0338,  0.0729,  0.0226, -0.0272, -0.2475,  0.1201],\n        [ 0.3128,  0.2669, -0.1867,  0.1495,  0.1047, -0.0363,  0.3781, -0.3526],\n        [ 0.3394,  0.1154, -0.2500,  0.2560, -0.0297, -0.1550,  0.0520, -0.0943],\n        [ 0.1895,  0.1097, -0.1899,  0.1605,  0.0791,  0.0303, -0.3868, -0.0924],\n        [-0.1619, -0.1768,  0.3599, -0.0463,  0.2055,  0.3770, -0.0056,  0.3680],\n        [-0.2987,  0.3423, -0.0038, -0.1990, -0.0063,  0.0298, -0.0144,  0.2840],\n        [-0.3188,  0.2982, -0.2426, -0.1668, -0.2807, -0.2749,  0.0837,  0.0719],\n        [ 0.3830, -0.2830, -0.1793,  0.0962, -0.0665,  0.3376,  0.2710, -0.1863],\n        [ 0.1417, -0.3724, -0.1153, -0.3282, -0.1975,  0.2360, -0.0109,  0.1820],\n        [ 0.2153,  0.2474,  0.2222,  0.3479, -0.1921,  0.1965,  0.1902, -0.2590],\n        [ 0.0871, -0.2563,  0.0702,  0.1444,  0.3480,  0.0942, -0.0814, -0.1904],\n        [ 0.0624,  0.1731, -0.1482, -0.0953, -0.2662,  0.0023, -0.3411, -0.1923],\n        [ 0.2214, -0.1340,  0.2414, -0.2289, -0.0375,  0.3543,  0.3155, -0.1623],\n        [-0.1481,  0.0989,  0.2238,  0.1024,  0.0588,  0.2895, -0.3645, -0.0102],\n        [ 0.3418,  0.0897, -0.1322,  0.3762, -0.3344,  0.1072, -0.0963,  0.1666],\n        [ 0.1522,  0.3657, -0.1694,  0.2396,  0.1667, -0.2319, -0.1989, -0.1910],\n        [-0.0043,  0.3095, -0.0836,  0.3494, -0.1777,  0.2560,  0.0611, -0.0281],\n        [ 0.1571, -0.1494, -0.0748,  0.3205,  0.3359, -0.1616, -0.2314,  0.2291],\n        [ 0.2472, -0.2012, -0.3738, -0.3321,  0.1692,  0.2005, -0.2165,  0.1274],\n        [ 0.1888,  0.0052,  0.0845,  0.2095, -0.1187, -0.2796,  0.2015,  0.1326],\n        [ 0.3543,  0.0016,  0.2271,  0.3682,  0.3746, -0.1742,  0.0442, -0.1920],\n        [ 0.2642, -0.3558,  0.2216,  0.0906, -0.3115,  0.1532, -0.3748,  0.0514],\n        [-0.1056,  0.2848, -0.1723,  0.2116, -0.1910,  0.3166, -0.2460,  0.2848],\n        [ 0.2512,  0.1316,  0.0441,  0.1101, -0.1283,  0.1609,  0.2142,  0.0545],\n        [ 0.0409, -0.0635, -0.1184, -0.3767,  0.0885, -0.1051,  0.1835, -0.3857],\n        [-0.2240, -0.1551, -0.3426, -0.2264,  0.0368, -0.3236,  0.1892, -0.0192],\n        [-0.2096, -0.1334, -0.2414,  0.3806, -0.2236, -0.3868, -0.3468,  0.1409],\n        [ 0.3707, -0.0937,  0.0115, -0.0544,  0.1269,  0.1483, -0.1450, -0.2963],\n        [ 0.0827, -0.0391, -0.2024,  0.2913, -0.2621, -0.0849,  0.1326,  0.0585]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 2.1223e-01, -1.8631e-01,  1.4961e-01, -1.1484e-01, -2.8741e-02,\n          2.7364e-01,  1.5276e-01, -4.3898e-02, -7.7411e-02,  1.6136e-01,\n          2.0775e-01,  6.7680e-03,  2.1563e-01,  3.2514e-01, -1.7688e-01,\n          8.9202e-02,  3.0550e-01,  2.0586e-01,  6.4262e-02,  2.9307e-01,\n         -2.8294e-01, -2.6307e-01, -7.0309e-02,  3.1748e-01, -1.4290e-01,\n          3.0801e-02, -3.0377e-01, -3.8732e-03,  5.6707e-02,  9.1886e-02,\n          1.9355e-01,  4.9634e-02],\n        [-3.1088e-01,  1.9875e-01,  3.5179e-01,  1.0751e-02, -2.6698e-01,\n         -1.0482e-01, -2.8935e-01, -1.9785e-01,  1.1027e-01,  6.3105e-02,\n         -2.5096e-01,  2.0224e-01,  1.2091e-01, -2.5909e-01,  2.4204e-01,\n         -3.4548e-01,  2.1570e-01,  1.4956e-01,  1.1021e-01,  1.1674e-01,\n         -1.5405e-02, -1.3620e-01,  2.7110e-02,  1.8755e-01, -8.8193e-02,\n          2.8704e-01,  1.3408e-01,  4.9665e-03, -2.9233e-01,  1.8231e-01,\n         -9.7407e-02, -2.0343e-01],\n        [-1.8185e-01, -5.8777e-02, -2.3246e-01, -2.8135e-01, -7.1481e-02,\n         -3.1228e-01,  5.4899e-02,  2.4233e-01,  1.7790e-01,  1.8413e-01,\n         -1.4225e-01, -2.7592e-01, -5.5666e-02, -9.8629e-02, -3.3286e-01,\n         -1.2282e-01,  1.2483e-01, -3.3941e-01, -2.5387e-01,  6.4155e-02,\n         -2.4780e-02,  4.8011e-02,  1.7194e-01, -1.4936e-01, -3.4684e-01,\n         -2.6460e-01, -1.5396e-01, -2.8752e-02, -7.5288e-02,  3.1348e-01,\n         -3.2833e-01, -1.0818e-01],\n        [ 2.8808e-01, -2.9418e-01,  9.1550e-02, -2.0305e-01, -8.0758e-02,\n          3.3870e-01,  1.1157e-01, -2.9828e-01,  2.0247e-01, -9.3257e-02,\n         -9.9778e-03, -1.5681e-01,  1.4607e-01, -3.6182e-02,  1.0004e-01,\n         -5.2389e-02, -7.7425e-02,  1.6176e-01,  1.2150e-02, -7.1113e-02,\n         -1.4707e-01, -1.6421e-01, -1.5402e-01, -2.3807e-01, -5.6367e-02,\n         -4.2590e-02,  2.9161e-01, -2.3344e-01, -2.8146e-01, -2.9187e-01,\n         -3.3935e-01, -7.6495e-02],\n        [-5.3560e-03,  1.7096e-01,  2.9315e-02, -9.3022e-03, -3.3193e-01,\n         -2.0743e-01,  2.8342e-01, -2.4387e-01,  9.4948e-02, -2.3866e-01,\n         -3.0419e-01,  1.2194e-01, -2.1111e-01, -2.7020e-01, -3.6536e-02,\n         -9.4404e-02, -3.0077e-01, -1.3411e-01,  2.7896e-01, -1.5323e-01,\n         -2.0203e-01,  1.5498e-01,  1.0900e-01, -3.3412e-01, -2.0792e-01,\n          2.0870e-01, -1.4868e-01,  1.5067e-01,  2.1368e-01, -3.1184e-01,\n          3.0281e-02, -3.1468e-01],\n        [-2.2527e-01,  3.3005e-01, -2.8523e-02, -2.2302e-01,  2.7081e-01,\n         -2.8375e-01, -1.5908e-02, -2.1086e-01, -1.9130e-01,  2.5077e-01,\n          2.2746e-01, -3.4728e-01, -3.3024e-01, -2.8705e-01,  1.5611e-01,\n          9.3902e-02, -4.0079e-02, -2.7189e-01, -1.0216e-01, -6.1285e-02,\n          1.8314e-01,  1.3023e-01,  1.3592e-01, -3.6604e-02,  2.9894e-01,\n         -1.8993e-01,  1.0404e-01,  8.9302e-02,  2.2891e-01,  1.9462e-01,\n         -1.0260e-01, -1.4790e-01],\n        [ 7.0552e-02,  8.8857e-02, -2.8353e-01,  2.6347e-01, -3.5091e-04,\n         -2.3703e-01,  2.7169e-02, -1.5902e-01,  1.6426e-01,  6.3382e-02,\n          1.8043e-01,  2.2251e-01,  2.1151e-01, -5.2888e-02, -1.8022e-01,\n         -6.6874e-03,  7.2629e-03,  2.8466e-02, -2.0975e-01, -3.4273e-01,\n         -5.6093e-02, -2.6024e-01,  1.4591e-01,  1.9524e-01,  2.9296e-01,\n         -3.3222e-01, -1.1036e-01, -2.1494e-01, -2.0870e-01,  2.5180e-02,\n         -1.2501e-01, -1.1820e-01],\n        [ 2.0356e-01, -1.1870e-01,  5.9004e-03, -2.2989e-01, -1.9796e-01,\n          2.5095e-01, -3.5256e-01, -1.9390e-01, -2.7415e-01,  7.0770e-02,\n         -1.4691e-01,  3.3864e-01,  3.6936e-02, -3.8162e-02,  3.6840e-02,\n         -1.1724e-02, -2.0422e-01,  7.7994e-02, -3.4240e-01,  6.6052e-02,\n         -1.4216e-02, -1.4171e-01, -9.6591e-02, -2.5478e-01,  2.6119e-01,\n         -2.6931e-01, -1.2015e-01,  4.8331e-02, -3.0587e-01,  3.2924e-01,\n          2.6687e-01,  6.5098e-02],\n        [ 2.4905e-01, -3.4037e-01, -1.9325e-01, -4.2373e-02,  5.1468e-02,\n         -3.1252e-01,  6.1822e-02, -3.5116e-01,  2.7372e-01,  1.0444e-02,\n         -2.3571e-01, -1.5018e-01, -1.4733e-01,  2.9159e-01,  2.2169e-01,\n         -3.4186e-01,  2.1366e-01,  1.8546e-01,  2.8727e-01, -2.3618e-01,\n         -1.4254e-01,  2.3392e-01, -3.9640e-02,  2.7193e-01,  2.0216e-02,\n         -3.2829e-01,  6.2485e-02, -3.1240e-01,  4.9977e-02,  2.9030e-01,\n          3.5104e-01,  2.3095e-01],\n        [ 3.4371e-01, -1.2837e-01,  7.5273e-02, -1.3646e-01, -1.0745e-01,\n          2.0729e-01, -6.9819e-02,  1.2791e-01, -7.5837e-02,  1.2083e-01,\n          2.4898e-01,  2.6309e-01, -7.1601e-02,  3.0899e-01,  3.3344e-01,\n         -8.1896e-02,  2.0806e-01, -2.5525e-01, -6.4956e-02, -3.3499e-01,\n         -3.2665e-01,  9.2341e-02, -1.9458e-01,  2.6728e-02, -6.7682e-02,\n          1.2839e-01,  2.8702e-01, -6.8303e-02, -1.7629e-01, -9.4430e-02,\n          2.5583e-04,  2.5011e-02],\n        [ 1.4566e-01, -8.5284e-02,  2.6679e-01, -3.0660e-01, -2.7063e-01,\n         -1.4192e-01,  2.9125e-01,  1.3351e-01,  2.9468e-01, -5.4790e-02,\n          4.4046e-02, -3.0622e-01,  2.8541e-01, -7.7883e-02,  1.6740e-01,\n          1.4238e-01,  3.3551e-02,  5.4334e-03,  9.7751e-04, -4.8405e-02,\n          6.1145e-02,  1.4791e-01,  1.5084e-01, -1.5714e-01, -2.4528e-01,\n         -2.8207e-02,  7.1852e-02, -8.3996e-02,  8.6267e-02,  1.0983e-01,\n          2.2173e-03, -1.4229e-01],\n        [-2.7939e-01,  1.4820e-02,  2.3732e-01, -9.2718e-02,  1.9610e-01,\n          9.4638e-02, -2.0004e-01, -3.4091e-01, -3.4162e-01, -1.3116e-01,\n         -8.1350e-02,  2.8776e-01, -1.4832e-01, -1.1704e-01, -2.6462e-01,\n         -2.5654e-01, -6.1212e-02, -2.3398e-01, -2.8859e-01, -3.2826e-01,\n          2.1074e-01,  6.1419e-02,  2.5485e-01, -8.1117e-02,  2.5163e-01,\n          2.2329e-02, -1.3498e-01, -2.7860e-01, -7.6134e-02,  9.0512e-03,\n          6.4912e-02,  4.2307e-02],\n        [ 1.6984e-01, -2.8314e-01,  8.8002e-02, -1.7212e-01,  3.2252e-01,\n         -6.3424e-02,  5.3111e-02, -2.7175e-01, -2.9705e-01,  2.3083e-01,\n         -3.4144e-02, -1.9243e-01,  3.1948e-01, -2.7865e-01, -2.2450e-01,\n          1.2376e-01,  2.1374e-01, -1.8341e-01,  3.4603e-03, -1.9714e-01,\n         -1.2574e-01, -7.5970e-02,  1.6274e-01, -1.7176e-01,  2.0088e-01,\n         -2.7645e-01, -1.3515e-01,  1.5901e-02, -3.1373e-01,  1.4547e-01,\n          4.8156e-02,  2.5283e-01],\n        [-2.1597e-01,  1.1016e-01, -1.6884e-01,  2.1078e-02, -2.9624e-01,\n         -1.9886e-01, -1.1240e-01, -7.2225e-02, -2.3132e-01,  3.0520e-01,\n          2.7810e-02,  4.4608e-02, -2.6450e-01, -1.8060e-01,  2.3508e-01,\n         -1.7574e-01,  2.8655e-01,  4.0011e-02,  3.5195e-01, -7.8986e-02,\n         -2.7728e-01, -2.8978e-01, -1.1946e-01, -2.4955e-01,  1.0110e-01,\n         -2.7224e-02, -2.3265e-01,  3.0334e-01,  1.3347e-01,  1.0746e-01,\n         -6.0050e-02,  4.6254e-02],\n        [ 1.1873e-01, -1.6831e-01,  2.6564e-01, -2.2020e-01, -2.6880e-01,\n         -1.8776e-01,  2.1210e-01, -2.2511e-01, -1.5002e-01, -1.7680e-01,\n          5.4706e-02, -9.4340e-02,  5.7831e-02,  2.9418e-02, -3.4825e-01,\n          3.4143e-01, -2.9872e-01, -1.1330e-01,  2.9510e-01,  5.5886e-02,\n         -5.2540e-02,  2.5785e-01, -1.9985e-01, -9.8770e-02,  3.0829e-01,\n         -3.0568e-01,  1.7364e-01,  7.2703e-02, -6.7299e-02,  2.2703e-01,\n          1.4427e-01, -2.0475e-01],\n        [ 2.1987e-01, -1.0833e-01,  3.0832e-01,  1.9281e-01,  1.6767e-01,\n         -2.0653e-01,  1.7095e-01,  6.3121e-02, -1.7365e-01, -3.5032e-02,\n          1.9094e-01,  3.1351e-01, -1.6940e-02, -1.8044e-01, -1.9076e-01,\n         -1.6814e-01, -6.7297e-03, -3.0369e-01, -2.9242e-02, -6.6310e-02,\n          3.1889e-01,  1.2400e-02,  5.0984e-02,  1.9457e-01, -2.2872e-01,\n          1.6606e-01, -3.2536e-02, -1.9881e-01,  3.0265e-01, -2.2286e-01,\n         -3.8413e-03, -6.5889e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1055, -0.2539, -0.2932,  0.3261,  0.2190,  0.2202,  0.4719,  0.4016,\n         -0.2439, -0.1540,  0.2876,  0.0565, -0.0379, -0.4497,  0.3937, -0.1209],\n        [ 0.2977, -0.3398,  0.4489, -0.3962, -0.0371,  0.4217,  0.2641, -0.3250,\n         -0.3849,  0.1158, -0.2647, -0.2670,  0.4345, -0.3707,  0.1829, -0.2548],\n        [ 0.1055,  0.1505, -0.4560, -0.3448,  0.4566, -0.4954, -0.0319,  0.4869,\n         -0.2957,  0.3469,  0.1999,  0.4975,  0.2196, -0.1721, -0.3283,  0.0894],\n        [-0.1463,  0.2806, -0.0531, -0.3215, -0.2189, -0.3009, -0.3748,  0.4883,\n         -0.2695,  0.3146, -0.2513, -0.2312, -0.0382, -0.4857,  0.3536,  0.2213],\n        [ 0.0666, -0.0924, -0.1763, -0.3435,  0.3379, -0.3519,  0.0751, -0.4946,\n         -0.4705,  0.0547, -0.3981, -0.2644,  0.1522, -0.2577, -0.1596, -0.2710],\n        [-0.2187, -0.3136, -0.1591,  0.4559, -0.3204, -0.3913,  0.4850, -0.3355,\n         -0.2656,  0.1562, -0.1426, -0.2241,  0.3720,  0.3243,  0.3854,  0.2261],\n        [-0.0231,  0.0219, -0.3130,  0.4054, -0.3197,  0.3355,  0.1608, -0.3330,\n         -0.3862,  0.0673, -0.3368, -0.4000, -0.3559, -0.4187, -0.1210,  0.4276],\n        [-0.3493,  0.4773,  0.2705, -0.3479,  0.3103,  0.4117,  0.3317, -0.1748,\n          0.2702, -0.1127, -0.1112,  0.1542,  0.0885,  0.2327,  0.3579, -0.3644]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.5913,  0.4045, -0.4509,  0.2816, -0.3037,  0.4422,  0.6197, -0.2070],\n        [-0.6408, -0.0573,  0.6819, -0.2595,  0.5993, -0.4224,  0.4087,  0.6832],\n        [-0.0440, -0.1045, -0.0536, -0.2771, -0.3929,  0.4257, -0.5544,  0.4859],\n        [-0.2039, -0.1643,  0.2616, -0.5785,  0.5021,  0.3236,  0.1779,  0.4392]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x747a8a6e5910>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s622160000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s622160000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}