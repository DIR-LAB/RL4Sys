{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.15,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s65060000"
    },
    "q_lr":	0.003,
    "seed":	65060000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x70ea3ef519d0>":	{
            "_act_dim":	4,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.15,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1396,  0.2023, -0.3178, -0.2144, -0.3343, -0.2807, -0.0672, -0.0562,\n        -0.1490, -0.3467,  0.2269, -0.2511,  0.1059,  0.2479, -0.1311, -0.0220,\n        -0.1023, -0.1613, -0.0748,  0.0920, -0.0245,  0.1211, -0.2351, -0.0288,\n        -0.2705, -0.1660, -0.3041,  0.0916,  0.3399,  0.1611, -0.2953,  0.3057],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0724,  0.2410,  0.1868, -0.2251, -0.1390,  0.1966,  0.2940, -0.3299],\n        [ 0.1191, -0.2701, -0.2541,  0.1588, -0.0120,  0.2693,  0.0375, -0.0606],\n        [ 0.1613,  0.0071, -0.1417,  0.0876,  0.1920,  0.3087,  0.2638, -0.2351],\n        [ 0.1149,  0.1487, -0.0848,  0.1872, -0.0029,  0.0411,  0.1893,  0.3329],\n        [-0.2557,  0.0028,  0.2276, -0.0454, -0.1586,  0.3000, -0.2238,  0.0860],\n        [ 0.0573,  0.2282,  0.3051, -0.3257, -0.3515, -0.3010,  0.2031, -0.1685],\n        [ 0.0684,  0.2826, -0.0219,  0.2635, -0.2834,  0.3312,  0.0395,  0.2248],\n        [-0.1442, -0.3428,  0.0362, -0.1652, -0.0812, -0.1864,  0.1058,  0.1342],\n        [-0.0474, -0.0173, -0.0277,  0.3411, -0.3201,  0.1851,  0.1723, -0.2781],\n        [ 0.2013, -0.2927, -0.2340, -0.3376, -0.0372,  0.1732, -0.1833, -0.2272],\n        [ 0.2669,  0.1038,  0.1859, -0.1941,  0.0966, -0.2306,  0.1453, -0.3436],\n        [-0.0482,  0.0448,  0.1374,  0.2660,  0.0233, -0.1890, -0.2549, -0.1462],\n        [-0.2672, -0.1432,  0.1176,  0.0355, -0.2750,  0.2419, -0.3270, -0.1544],\n        [-0.0206, -0.0425, -0.1424,  0.0936, -0.2455, -0.0402, -0.0045, -0.0967],\n        [-0.1152,  0.0790, -0.0294, -0.1709,  0.2375, -0.3356, -0.2901,  0.0079],\n        [-0.0061, -0.1548,  0.2852,  0.3071, -0.2831,  0.2405, -0.1756,  0.0479],\n        [ 0.1783, -0.0257, -0.1694,  0.1057,  0.2148,  0.0736,  0.0520,  0.1897],\n        [-0.3135, -0.2580,  0.2531, -0.2458,  0.1235, -0.1413, -0.3020, -0.1900],\n        [-0.0304, -0.0641, -0.0952, -0.2804, -0.2920,  0.2607,  0.1145, -0.1998],\n        [-0.2499,  0.0635, -0.2999, -0.0923, -0.2710,  0.0682, -0.1362,  0.1781],\n        [-0.3058,  0.3373, -0.3162, -0.2807, -0.1940, -0.2915,  0.3521, -0.1172],\n        [-0.1649, -0.2044,  0.0987, -0.2789,  0.2902,  0.2932, -0.1519,  0.1849],\n        [ 0.1376, -0.3342,  0.2834,  0.0059, -0.1388, -0.1419,  0.0602, -0.0142],\n        [ 0.1193,  0.1393,  0.3001,  0.0872, -0.1388, -0.0082,  0.2848,  0.2566],\n        [ 0.1880,  0.2125, -0.2320, -0.3015,  0.1504,  0.2222, -0.2643,  0.0052],\n        [ 0.2775,  0.1454, -0.1268,  0.2892, -0.0097, -0.0270, -0.1078, -0.2556],\n        [ 0.2482, -0.2757,  0.1391,  0.0814,  0.0458,  0.2613,  0.3039, -0.0414],\n        [ 0.2840, -0.2946, -0.0894, -0.2020, -0.1957, -0.0751, -0.2229, -0.0207],\n        [ 0.2457, -0.1297,  0.2041, -0.3116, -0.1606,  0.1705,  0.2874,  0.2464],\n        [ 0.2427, -0.2435,  0.0610,  0.3527, -0.2570, -0.3255,  0.0419, -0.2541],\n        [-0.3398,  0.3512,  0.1205, -0.2340, -0.0394, -0.0543, -0.2195,  0.1725],\n        [-0.0664, -0.1768, -0.1152, -0.3530,  0.0176,  0.3008, -0.1434,  0.0655]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1622, -0.0921, -0.0773, -0.0124, -0.1203, -0.1197, -0.0743,  0.0685,\n         0.1048,  0.1238, -0.0259, -0.0880,  0.1747,  0.0230,  0.0517, -0.1615],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.2658e-01, -5.7756e-02, -1.7676e-01, -1.3982e-01, -1.0845e-01,\n         -9.6450e-02,  1.6473e-01,  1.3951e-01,  1.1504e-01, -1.6193e-01,\n          9.0220e-02,  1.2041e-01, -1.6583e-01,  1.3481e-01, -1.7339e-01,\n         -2.4037e-03,  1.2261e-01, -9.5006e-02, -1.4075e-01,  1.6835e-01,\n         -3.5390e-02,  1.5931e-01, -4.4245e-02,  9.7534e-02,  4.8252e-02,\n          1.4667e-03,  2.3583e-02,  1.0374e-01,  1.3820e-01,  5.5884e-02,\n          3.0268e-02,  1.6991e-01],\n        [-8.6294e-03,  1.5623e-01,  1.6793e-01, -1.5772e-01,  2.4077e-02,\n          1.7556e-01,  5.3219e-02, -1.0951e-01,  6.5653e-03, -1.6328e-01,\n          1.5203e-01, -2.1116e-02,  3.0810e-02,  1.0235e-01, -3.9682e-02,\n          1.3695e-01, -1.6138e-01, -4.7389e-02,  5.2664e-02, -3.4510e-03,\n          1.4060e-02, -9.3372e-02, -2.6307e-02, -1.2615e-01,  6.9029e-02,\n          8.8857e-02, -4.8308e-02, -1.2385e-01,  2.2240e-02,  9.9201e-02,\n         -1.2408e-01, -2.6329e-02],\n        [-1.0498e-01,  1.0192e-01,  3.9944e-02, -1.6711e-01, -9.9635e-02,\n         -1.6822e-01, -1.0584e-02,  1.1578e-01, -1.4665e-03, -6.3387e-02,\n         -3.3772e-02,  8.6352e-02,  1.5553e-01,  1.1295e-01,  1.7401e-01,\n          1.7413e-01, -2.0583e-03,  1.5531e-01,  1.2688e-01, -9.2877e-02,\n         -4.5427e-02,  2.4431e-02, -8.0939e-02, -7.3703e-02, -1.7149e-01,\n          1.6166e-01,  2.5907e-02, -1.5006e-01, -1.2347e-01,  5.3197e-02,\n         -4.3722e-02,  1.9081e-02],\n        [-4.7417e-02,  7.6177e-02, -8.6815e-02,  7.5989e-02, -6.5246e-02,\n         -1.2357e-01,  1.6916e-01, -1.2077e-01, -6.7677e-02,  1.4578e-01,\n          5.2635e-02, -1.5472e-01, -1.0043e-01,  5.7940e-02, -6.1770e-02,\n          8.7019e-02,  1.2707e-01, -1.2228e-01, -1.6781e-02, -1.0192e-01,\n          1.5510e-01,  1.6555e-01, -3.9697e-02,  1.6240e-01, -2.9366e-02,\n          9.2244e-02,  5.6614e-02, -8.6380e-02,  1.2099e-01, -1.0913e-02,\n         -4.2752e-02, -4.0837e-02],\n        [-6.2264e-02, -1.0294e-01,  1.4511e-01,  3.6837e-02, -8.9633e-02,\n         -3.7058e-02,  9.7022e-02,  1.3126e-01, -7.0524e-02,  1.2713e-01,\n          9.5179e-02,  7.5532e-02, -1.0865e-01, -1.0676e-01, -1.2889e-01,\n         -1.2242e-01, -1.4546e-01, -5.7317e-02, -9.3227e-03, -8.6255e-02,\n         -7.7027e-02, -7.5597e-02, -7.5826e-02,  9.6134e-02,  2.9265e-02,\n          2.0825e-03,  7.2099e-02, -5.3046e-03, -6.6112e-02, -1.0290e-01,\n         -7.1275e-02,  5.6255e-02],\n        [ 3.8893e-02, -9.2349e-02, -3.0027e-02,  1.6994e-01, -6.0953e-02,\n         -1.0807e-01, -4.7036e-02,  9.3489e-02, -5.6778e-02,  1.3039e-01,\n          6.5326e-02,  1.2315e-01, -1.6359e-02,  1.4901e-01, -9.1114e-02,\n         -6.9898e-03, -1.4570e-01,  1.9174e-03, -1.3433e-01,  4.0509e-02,\n          1.5169e-01,  1.2300e-01, -3.9440e-02, -1.0531e-01, -1.4285e-01,\n          1.3138e-01,  8.6261e-02, -1.7390e-01, -9.9983e-02, -6.5866e-02,\n          1.7050e-01, -2.4767e-02],\n        [-1.3509e-02,  6.3329e-02,  8.3949e-02,  1.3988e-01,  5.1252e-02,\n          4.5800e-02,  1.2562e-01,  6.8419e-02,  7.1820e-02,  1.1747e-01,\n         -1.5229e-01, -1.1086e-01,  1.5552e-01,  1.3413e-02, -1.3931e-01,\n          7.7599e-02, -3.5239e-02, -1.7319e-01,  1.4484e-01, -1.6037e-01,\n          2.0139e-02, -6.4692e-03,  6.7718e-02, -1.6736e-01, -1.3675e-01,\n         -1.4952e-01,  7.8522e-02, -2.6735e-02,  8.2241e-02, -1.2422e-01,\n          1.5985e-01,  9.9390e-02],\n        [ 1.3368e-01, -2.0920e-02, -1.6035e-01, -5.0226e-02,  1.1809e-01,\n         -9.7886e-02, -1.0522e-01, -5.4992e-02, -5.5209e-02,  1.7534e-01,\n         -4.1666e-02,  1.5715e-01, -4.3073e-02,  1.4128e-01, -4.5439e-03,\n          5.0208e-02,  4.8554e-02, -1.0057e-01,  3.5119e-02,  1.6534e-01,\n         -3.5285e-02, -5.6675e-03,  4.6585e-02,  6.8654e-02, -1.2781e-01,\n         -1.1957e-01, -3.4043e-02, -1.1415e-02,  7.3863e-02, -1.2528e-01,\n         -1.5541e-01,  1.4923e-01],\n        [-1.3839e-01, -3.7708e-02, -1.3759e-01,  1.2336e-01, -6.4504e-02,\n         -4.5453e-02, -9.4229e-02,  8.9892e-02, -9.7813e-02,  1.6596e-01,\n         -6.0862e-02,  1.7279e-01,  2.1331e-02,  1.7060e-01, -7.1778e-02,\n         -1.0137e-01, -5.8927e-02,  7.8987e-03, -9.0765e-02,  2.1175e-02,\n         -6.0648e-02, -1.7667e-01,  1.1116e-01, -1.1991e-01,  1.2175e-01,\n         -1.1024e-01, -1.6067e-01, -1.1933e-02,  5.8610e-03,  4.3272e-02,\n          2.8678e-02, -8.2363e-02],\n        [-6.7118e-02, -9.0029e-03,  5.0767e-02, -1.9492e-02,  9.4598e-02,\n          4.4591e-02,  1.5234e-01,  7.9531e-02, -1.5210e-01, -8.2392e-02,\n          9.3969e-02, -1.2020e-01,  8.4450e-02,  1.2061e-01,  1.2567e-01,\n          1.1604e-01, -1.0332e-01,  1.5191e-01,  1.2090e-01,  9.2025e-02,\n          1.1169e-01, -1.3456e-01,  1.7352e-01, -1.4006e-02,  1.5533e-01,\n         -1.1015e-01, -4.8926e-02,  1.7255e-01,  8.4028e-02, -2.0665e-03,\n          8.0182e-02, -1.2223e-01],\n        [ 1.0831e-01,  1.4585e-01,  1.5708e-01,  8.3241e-02,  1.6901e-01,\n          6.1363e-02,  6.2255e-02,  9.9532e-02, -9.5639e-02,  2.0979e-02,\n         -3.2519e-02, -3.1691e-02, -1.3449e-01,  5.8789e-02, -9.3853e-02,\n          1.5631e-01,  5.1821e-02, -1.7194e-01,  1.0904e-01,  5.4834e-02,\n         -7.2332e-02,  8.1888e-02,  3.5371e-02,  1.3255e-01, -1.6410e-01,\n          1.5730e-01, -1.6508e-01, -1.3417e-01, -5.7233e-02,  1.3197e-02,\n         -4.3789e-02, -1.6394e-02],\n        [ 6.1793e-02,  1.7251e-01, -8.4022e-02, -9.0776e-02,  7.7475e-02,\n         -6.9814e-02,  1.5630e-02, -9.8705e-02, -1.5130e-01,  1.7649e-01,\n         -6.4379e-02, -1.2628e-01, -1.3767e-01, -3.4358e-02,  9.1274e-02,\n         -9.2831e-02, -6.5501e-02,  1.3051e-01, -4.8225e-02,  5.7923e-02,\n          1.3527e-01, -1.3084e-01,  1.0036e-01, -1.0725e-01,  1.2758e-01,\n         -1.6985e-01, -7.0999e-02,  1.0374e-01,  1.3821e-01, -4.4827e-02,\n          4.2149e-02,  1.6805e-01],\n        [-1.4830e-02,  8.3903e-02, -1.1914e-01,  7.8316e-03,  9.3264e-02,\n          7.2094e-02, -8.0219e-02, -3.3176e-02,  1.5716e-01, -1.4682e-01,\n          1.5400e-01, -1.6019e-02,  1.3424e-01,  1.6350e-01, -1.0586e-01,\n         -4.9216e-02, -4.4601e-02, -1.1481e-01,  7.6888e-02,  1.6808e-01,\n         -1.0213e-01,  3.3869e-02, -9.8825e-02,  1.4482e-01, -1.4124e-01,\n          1.0551e-01, -1.6758e-01,  4.0836e-02,  1.6255e-01,  6.3358e-02,\n         -4.6069e-02, -1.1938e-01],\n        [ 8.5827e-02, -1.1493e-01,  1.4469e-01, -1.0831e-01, -1.5438e-01,\n         -3.7165e-02, -6.8631e-02, -4.5956e-02, -1.5358e-01,  5.0531e-03,\n         -7.0561e-02, -9.5017e-02,  1.0774e-01,  8.2065e-02,  8.0258e-02,\n          3.0072e-02, -9.4350e-02, -1.1498e-01, -9.9080e-02,  1.1058e-01,\n         -1.5566e-01,  1.8286e-02, -9.4034e-02, -1.4154e-01,  1.7567e-01,\n          5.6906e-02,  2.5826e-02, -1.2265e-01,  5.9768e-02, -1.6764e-01,\n          1.6388e-02, -5.0802e-02],\n        [-1.6050e-01, -9.1656e-02, -3.4148e-02, -2.1707e-02,  1.1753e-01,\n         -9.2735e-02, -1.5228e-01,  1.6193e-01, -1.3039e-01, -7.0375e-02,\n         -6.1334e-02, -5.4884e-03, -2.5949e-03,  1.4613e-01,  1.1730e-01,\n         -2.4071e-02,  1.0849e-01, -2.5391e-02, -5.6790e-02,  1.4266e-01,\n         -1.1962e-02,  9.9294e-02,  1.7632e-01,  4.7181e-02,  5.1630e-03,\n         -6.2527e-02,  1.0201e-01, -1.0866e-01, -2.6264e-02, -7.4962e-03,\n          1.9499e-02, -1.2991e-01],\n        [ 5.0472e-02,  5.8748e-02,  4.3511e-02, -1.6475e-01,  1.3155e-01,\n          9.8854e-02, -1.2526e-01, -1.4610e-01, -7.7087e-02, -5.1219e-02,\n          1.4906e-01, -4.2128e-02, -1.2361e-01, -8.1949e-02,  1.1532e-01,\n          1.5823e-01, -2.0390e-03, -1.4364e-02, -7.8572e-03, -1.4703e-01,\n         -1.6689e-01,  1.5870e-01, -1.6077e-01,  8.6136e-02,  9.8758e-02,\n         -1.3271e-01,  7.3813e-02,  5.3895e-03, -8.0374e-05, -6.5987e-03,\n          3.1927e-02, -1.2380e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0591,  0.0059,  0.2122,  0.1266, -0.0608, -0.0759,  0.1675, -0.0804],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0282,  0.0550,  0.0360, -0.0670, -0.1046,  0.0550, -0.1268,  0.1250,\n          0.1669, -0.0308, -0.0771,  0.1115, -0.0279,  0.0402, -0.1135,  0.1747],\n        [ 0.1677, -0.0039,  0.1184,  0.2078,  0.1343,  0.2478, -0.1711,  0.2330,\n         -0.2467, -0.1412,  0.0318, -0.2384, -0.1188, -0.1631, -0.2322, -0.2308],\n        [-0.2174,  0.1216,  0.2271, -0.1654, -0.2390,  0.0259,  0.0008, -0.1346,\n          0.1576,  0.0340,  0.0187, -0.0269, -0.0822,  0.0972, -0.2142,  0.1570],\n        [-0.1737,  0.2137,  0.2102, -0.0733, -0.1850, -0.0960, -0.2384,  0.0129,\n          0.1803, -0.2431, -0.1803,  0.0630,  0.1418, -0.1032,  0.1567, -0.1721],\n        [-0.1069,  0.1650, -0.0685, -0.0272,  0.2270, -0.1683, -0.1527, -0.1474,\n          0.0686,  0.0865,  0.2242, -0.1965, -0.2217, -0.1934,  0.2172,  0.2469],\n        [ 0.1462, -0.1814, -0.2458, -0.0967, -0.1456,  0.0088,  0.0249,  0.2498,\n         -0.0618, -0.2106, -0.2479,  0.1826, -0.1941, -0.1100, -0.2068, -0.1209],\n        [-0.0314,  0.0560, -0.0137, -0.0117, -0.0335, -0.0814,  0.0681, -0.0986,\n         -0.0358,  0.1386,  0.0185,  0.0017,  0.1711,  0.0047,  0.0712,  0.0584],\n        [-0.1707,  0.2122,  0.1284, -0.1392, -0.0129, -0.0420, -0.1894, -0.0431,\n          0.2286, -0.1102, -0.0916,  0.0946, -0.1941,  0.1107, -0.1383, -0.1279]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1651,  0.3457, -0.1841, -0.1584], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1022,  0.2728,  0.1955, -0.3045,  0.0471, -0.0607, -0.2077,  0.1316],\n        [-0.1461,  0.3256,  0.1140,  0.1774,  0.1685,  0.0165,  0.1823,  0.3330],\n        [-0.1628,  0.1011, -0.1357, -0.2022, -0.0448, -0.1916, -0.3448, -0.0118],\n        [-0.0021, -0.2649, -0.3097,  0.2487,  0.1871, -0.1194, -0.1648, -0.2569]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0724,  0.2410,  0.1868, -0.2251, -0.1390,  0.1966,  0.2940, -0.3299],\n        [ 0.1191, -0.2701, -0.2541,  0.1588, -0.0120,  0.2693,  0.0375, -0.0606],\n        [ 0.1613,  0.0071, -0.1417,  0.0876,  0.1920,  0.3087,  0.2638, -0.2351],\n        [ 0.1149,  0.1487, -0.0848,  0.1872, -0.0029,  0.0411,  0.1893,  0.3329],\n        [-0.2557,  0.0028,  0.2276, -0.0454, -0.1586,  0.3000, -0.2238,  0.0860],\n        [ 0.0573,  0.2282,  0.3051, -0.3257, -0.3515, -0.3010,  0.2031, -0.1685],\n        [ 0.0684,  0.2826, -0.0219,  0.2635, -0.2834,  0.3312,  0.0395,  0.2248],\n        [-0.1442, -0.3428,  0.0362, -0.1652, -0.0812, -0.1864,  0.1058,  0.1342],\n        [-0.0474, -0.0173, -0.0277,  0.3411, -0.3201,  0.1851,  0.1723, -0.2781],\n        [ 0.2013, -0.2927, -0.2340, -0.3376, -0.0372,  0.1732, -0.1833, -0.2272],\n        [ 0.2669,  0.1038,  0.1859, -0.1941,  0.0966, -0.2306,  0.1453, -0.3436],\n        [-0.0482,  0.0448,  0.1374,  0.2660,  0.0233, -0.1890, -0.2549, -0.1462],\n        [-0.2672, -0.1432,  0.1176,  0.0355, -0.2750,  0.2419, -0.3270, -0.1544],\n        [-0.0206, -0.0425, -0.1424,  0.0936, -0.2455, -0.0402, -0.0045, -0.0967],\n        [-0.1152,  0.0790, -0.0294, -0.1709,  0.2375, -0.3356, -0.2901,  0.0079],\n        [-0.0061, -0.1548,  0.2852,  0.3071, -0.2831,  0.2405, -0.1756,  0.0479],\n        [ 0.1783, -0.0257, -0.1694,  0.1057,  0.2148,  0.0736,  0.0520,  0.1897],\n        [-0.3135, -0.2580,  0.2531, -0.2458,  0.1235, -0.1413, -0.3020, -0.1900],\n        [-0.0304, -0.0641, -0.0952, -0.2804, -0.2920,  0.2607,  0.1145, -0.1998],\n        [-0.2499,  0.0635, -0.2999, -0.0923, -0.2710,  0.0682, -0.1362,  0.1781],\n        [-0.3058,  0.3373, -0.3162, -0.2807, -0.1940, -0.2915,  0.3521, -0.1172],\n        [-0.1649, -0.2044,  0.0987, -0.2789,  0.2902,  0.2932, -0.1519,  0.1849],\n        [ 0.1376, -0.3342,  0.2834,  0.0059, -0.1388, -0.1419,  0.0602, -0.0142],\n        [ 0.1193,  0.1393,  0.3001,  0.0872, -0.1388, -0.0082,  0.2848,  0.2566],\n        [ 0.1880,  0.2125, -0.2320, -0.3015,  0.1504,  0.2222, -0.2643,  0.0052],\n        [ 0.2775,  0.1454, -0.1268,  0.2892, -0.0097, -0.0270, -0.1078, -0.2556],\n        [ 0.2482, -0.2757,  0.1391,  0.0814,  0.0458,  0.2613,  0.3039, -0.0414],\n        [ 0.2840, -0.2946, -0.0894, -0.2020, -0.1957, -0.0751, -0.2229, -0.0207],\n        [ 0.2457, -0.1297,  0.2041, -0.3116, -0.1606,  0.1705,  0.2874,  0.2464],\n        [ 0.2427, -0.2435,  0.0610,  0.3527, -0.2570, -0.3255,  0.0419, -0.2541],\n        [-0.3398,  0.3512,  0.1205, -0.2340, -0.0394, -0.0543, -0.2195,  0.1725],\n        [-0.0664, -0.1768, -0.1152, -0.3530,  0.0176,  0.3008, -0.1434,  0.0655]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1396,  0.2023, -0.3178, -0.2144, -0.3343, -0.2807, -0.0672, -0.0562,\n        -0.1490, -0.3467,  0.2269, -0.2511,  0.1059,  0.2479, -0.1311, -0.0220,\n        -0.1023, -0.1613, -0.0748,  0.0920, -0.0245,  0.1211, -0.2351, -0.0288,\n        -0.2705, -0.1660, -0.3041,  0.0916,  0.3399,  0.1611, -0.2953,  0.3057],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.2658e-01, -5.7756e-02, -1.7676e-01, -1.3982e-01, -1.0845e-01,\n         -9.6450e-02,  1.6473e-01,  1.3951e-01,  1.1504e-01, -1.6193e-01,\n          9.0220e-02,  1.2041e-01, -1.6583e-01,  1.3481e-01, -1.7339e-01,\n         -2.4037e-03,  1.2261e-01, -9.5006e-02, -1.4075e-01,  1.6835e-01,\n         -3.5390e-02,  1.5931e-01, -4.4245e-02,  9.7534e-02,  4.8252e-02,\n          1.4667e-03,  2.3583e-02,  1.0374e-01,  1.3820e-01,  5.5884e-02,\n          3.0268e-02,  1.6991e-01],\n        [-8.6294e-03,  1.5623e-01,  1.6793e-01, -1.5772e-01,  2.4077e-02,\n          1.7556e-01,  5.3219e-02, -1.0951e-01,  6.5653e-03, -1.6328e-01,\n          1.5203e-01, -2.1116e-02,  3.0810e-02,  1.0235e-01, -3.9682e-02,\n          1.3695e-01, -1.6138e-01, -4.7389e-02,  5.2664e-02, -3.4510e-03,\n          1.4060e-02, -9.3372e-02, -2.6307e-02, -1.2615e-01,  6.9029e-02,\n          8.8857e-02, -4.8308e-02, -1.2385e-01,  2.2240e-02,  9.9201e-02,\n         -1.2408e-01, -2.6329e-02],\n        [-1.0498e-01,  1.0192e-01,  3.9944e-02, -1.6711e-01, -9.9635e-02,\n         -1.6822e-01, -1.0584e-02,  1.1578e-01, -1.4665e-03, -6.3387e-02,\n         -3.3772e-02,  8.6352e-02,  1.5553e-01,  1.1295e-01,  1.7401e-01,\n          1.7413e-01, -2.0583e-03,  1.5531e-01,  1.2688e-01, -9.2877e-02,\n         -4.5427e-02,  2.4431e-02, -8.0939e-02, -7.3703e-02, -1.7149e-01,\n          1.6166e-01,  2.5907e-02, -1.5006e-01, -1.2347e-01,  5.3197e-02,\n         -4.3722e-02,  1.9081e-02],\n        [-4.7417e-02,  7.6177e-02, -8.6815e-02,  7.5989e-02, -6.5246e-02,\n         -1.2357e-01,  1.6916e-01, -1.2077e-01, -6.7677e-02,  1.4578e-01,\n          5.2635e-02, -1.5472e-01, -1.0043e-01,  5.7940e-02, -6.1770e-02,\n          8.7019e-02,  1.2707e-01, -1.2228e-01, -1.6781e-02, -1.0192e-01,\n          1.5510e-01,  1.6555e-01, -3.9697e-02,  1.6240e-01, -2.9366e-02,\n          9.2244e-02,  5.6614e-02, -8.6380e-02,  1.2099e-01, -1.0913e-02,\n         -4.2752e-02, -4.0837e-02],\n        [-6.2264e-02, -1.0294e-01,  1.4511e-01,  3.6837e-02, -8.9633e-02,\n         -3.7058e-02,  9.7022e-02,  1.3126e-01, -7.0524e-02,  1.2713e-01,\n          9.5179e-02,  7.5532e-02, -1.0865e-01, -1.0676e-01, -1.2889e-01,\n         -1.2242e-01, -1.4546e-01, -5.7317e-02, -9.3227e-03, -8.6255e-02,\n         -7.7027e-02, -7.5597e-02, -7.5826e-02,  9.6134e-02,  2.9265e-02,\n          2.0825e-03,  7.2099e-02, -5.3046e-03, -6.6112e-02, -1.0290e-01,\n         -7.1275e-02,  5.6255e-02],\n        [ 3.8893e-02, -9.2349e-02, -3.0027e-02,  1.6994e-01, -6.0953e-02,\n         -1.0807e-01, -4.7036e-02,  9.3489e-02, -5.6778e-02,  1.3039e-01,\n          6.5326e-02,  1.2315e-01, -1.6359e-02,  1.4901e-01, -9.1114e-02,\n         -6.9898e-03, -1.4570e-01,  1.9174e-03, -1.3433e-01,  4.0509e-02,\n          1.5169e-01,  1.2300e-01, -3.9440e-02, -1.0531e-01, -1.4285e-01,\n          1.3138e-01,  8.6261e-02, -1.7390e-01, -9.9983e-02, -6.5866e-02,\n          1.7050e-01, -2.4767e-02],\n        [-1.3509e-02,  6.3329e-02,  8.3949e-02,  1.3988e-01,  5.1252e-02,\n          4.5800e-02,  1.2562e-01,  6.8419e-02,  7.1820e-02,  1.1747e-01,\n         -1.5229e-01, -1.1086e-01,  1.5552e-01,  1.3413e-02, -1.3931e-01,\n          7.7599e-02, -3.5239e-02, -1.7319e-01,  1.4484e-01, -1.6037e-01,\n          2.0139e-02, -6.4692e-03,  6.7718e-02, -1.6736e-01, -1.3675e-01,\n         -1.4952e-01,  7.8522e-02, -2.6735e-02,  8.2241e-02, -1.2422e-01,\n          1.5985e-01,  9.9390e-02],\n        [ 1.3368e-01, -2.0920e-02, -1.6035e-01, -5.0226e-02,  1.1809e-01,\n         -9.7886e-02, -1.0522e-01, -5.4992e-02, -5.5209e-02,  1.7534e-01,\n         -4.1666e-02,  1.5715e-01, -4.3073e-02,  1.4128e-01, -4.5439e-03,\n          5.0208e-02,  4.8554e-02, -1.0057e-01,  3.5119e-02,  1.6534e-01,\n         -3.5285e-02, -5.6675e-03,  4.6585e-02,  6.8654e-02, -1.2781e-01,\n         -1.1957e-01, -3.4043e-02, -1.1415e-02,  7.3863e-02, -1.2528e-01,\n         -1.5541e-01,  1.4923e-01],\n        [-1.3839e-01, -3.7708e-02, -1.3759e-01,  1.2336e-01, -6.4504e-02,\n         -4.5453e-02, -9.4229e-02,  8.9892e-02, -9.7813e-02,  1.6596e-01,\n         -6.0862e-02,  1.7279e-01,  2.1331e-02,  1.7060e-01, -7.1778e-02,\n         -1.0137e-01, -5.8927e-02,  7.8987e-03, -9.0765e-02,  2.1175e-02,\n         -6.0648e-02, -1.7667e-01,  1.1116e-01, -1.1991e-01,  1.2175e-01,\n         -1.1024e-01, -1.6067e-01, -1.1933e-02,  5.8610e-03,  4.3272e-02,\n          2.8678e-02, -8.2363e-02],\n        [-6.7118e-02, -9.0029e-03,  5.0767e-02, -1.9492e-02,  9.4598e-02,\n          4.4591e-02,  1.5234e-01,  7.9531e-02, -1.5210e-01, -8.2392e-02,\n          9.3969e-02, -1.2020e-01,  8.4450e-02,  1.2061e-01,  1.2567e-01,\n          1.1604e-01, -1.0332e-01,  1.5191e-01,  1.2090e-01,  9.2025e-02,\n          1.1169e-01, -1.3456e-01,  1.7352e-01, -1.4006e-02,  1.5533e-01,\n         -1.1015e-01, -4.8926e-02,  1.7255e-01,  8.4028e-02, -2.0665e-03,\n          8.0182e-02, -1.2223e-01],\n        [ 1.0831e-01,  1.4585e-01,  1.5708e-01,  8.3241e-02,  1.6901e-01,\n          6.1363e-02,  6.2255e-02,  9.9532e-02, -9.5639e-02,  2.0979e-02,\n         -3.2519e-02, -3.1691e-02, -1.3449e-01,  5.8789e-02, -9.3853e-02,\n          1.5631e-01,  5.1821e-02, -1.7194e-01,  1.0904e-01,  5.4834e-02,\n         -7.2332e-02,  8.1888e-02,  3.5371e-02,  1.3255e-01, -1.6410e-01,\n          1.5730e-01, -1.6508e-01, -1.3417e-01, -5.7233e-02,  1.3197e-02,\n         -4.3789e-02, -1.6394e-02],\n        [ 6.1793e-02,  1.7251e-01, -8.4022e-02, -9.0776e-02,  7.7475e-02,\n         -6.9814e-02,  1.5630e-02, -9.8705e-02, -1.5130e-01,  1.7649e-01,\n         -6.4379e-02, -1.2628e-01, -1.3767e-01, -3.4358e-02,  9.1274e-02,\n         -9.2831e-02, -6.5501e-02,  1.3051e-01, -4.8225e-02,  5.7923e-02,\n          1.3527e-01, -1.3084e-01,  1.0036e-01, -1.0725e-01,  1.2758e-01,\n         -1.6985e-01, -7.0999e-02,  1.0374e-01,  1.3821e-01, -4.4827e-02,\n          4.2149e-02,  1.6805e-01],\n        [-1.4830e-02,  8.3903e-02, -1.1914e-01,  7.8316e-03,  9.3264e-02,\n          7.2094e-02, -8.0219e-02, -3.3176e-02,  1.5716e-01, -1.4682e-01,\n          1.5400e-01, -1.6019e-02,  1.3424e-01,  1.6350e-01, -1.0586e-01,\n         -4.9216e-02, -4.4601e-02, -1.1481e-01,  7.6888e-02,  1.6808e-01,\n         -1.0213e-01,  3.3869e-02, -9.8825e-02,  1.4482e-01, -1.4124e-01,\n          1.0551e-01, -1.6758e-01,  4.0836e-02,  1.6255e-01,  6.3358e-02,\n         -4.6069e-02, -1.1938e-01],\n        [ 8.5827e-02, -1.1493e-01,  1.4469e-01, -1.0831e-01, -1.5438e-01,\n         -3.7165e-02, -6.8631e-02, -4.5956e-02, -1.5358e-01,  5.0531e-03,\n         -7.0561e-02, -9.5017e-02,  1.0774e-01,  8.2065e-02,  8.0258e-02,\n          3.0072e-02, -9.4350e-02, -1.1498e-01, -9.9080e-02,  1.1058e-01,\n         -1.5566e-01,  1.8286e-02, -9.4034e-02, -1.4154e-01,  1.7567e-01,\n          5.6906e-02,  2.5826e-02, -1.2265e-01,  5.9768e-02, -1.6764e-01,\n          1.6388e-02, -5.0802e-02],\n        [-1.6050e-01, -9.1656e-02, -3.4148e-02, -2.1707e-02,  1.1753e-01,\n         -9.2735e-02, -1.5228e-01,  1.6193e-01, -1.3039e-01, -7.0375e-02,\n         -6.1334e-02, -5.4884e-03, -2.5949e-03,  1.4613e-01,  1.1730e-01,\n         -2.4071e-02,  1.0849e-01, -2.5391e-02, -5.6790e-02,  1.4266e-01,\n         -1.1962e-02,  9.9294e-02,  1.7632e-01,  4.7181e-02,  5.1630e-03,\n         -6.2527e-02,  1.0201e-01, -1.0866e-01, -2.6264e-02, -7.4962e-03,\n          1.9499e-02, -1.2991e-01],\n        [ 5.0472e-02,  5.8748e-02,  4.3511e-02, -1.6475e-01,  1.3155e-01,\n          9.8854e-02, -1.2526e-01, -1.4610e-01, -7.7087e-02, -5.1219e-02,\n          1.4906e-01, -4.2128e-02, -1.2361e-01, -8.1949e-02,  1.1532e-01,\n          1.5823e-01, -2.0390e-03, -1.4364e-02, -7.8572e-03, -1.4703e-01,\n         -1.6689e-01,  1.5870e-01, -1.6077e-01,  8.6136e-02,  9.8758e-02,\n         -1.3271e-01,  7.3813e-02,  5.3895e-03, -8.0374e-05, -6.5987e-03,\n          3.1927e-02, -1.2380e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1622, -0.0921, -0.0773, -0.0124, -0.1203, -0.1197, -0.0743,  0.0685,\n         0.1048,  0.1238, -0.0259, -0.0880,  0.1747,  0.0230,  0.0517, -0.1615],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0282,  0.0550,  0.0360, -0.0670, -0.1046,  0.0550, -0.1268,  0.1250,\n          0.1669, -0.0308, -0.0771,  0.1115, -0.0279,  0.0402, -0.1135,  0.1747],\n        [ 0.1677, -0.0039,  0.1184,  0.2078,  0.1343,  0.2478, -0.1711,  0.2330,\n         -0.2467, -0.1412,  0.0318, -0.2384, -0.1188, -0.1631, -0.2322, -0.2308],\n        [-0.2174,  0.1216,  0.2271, -0.1654, -0.2390,  0.0259,  0.0008, -0.1346,\n          0.1576,  0.0340,  0.0187, -0.0269, -0.0822,  0.0972, -0.2142,  0.1570],\n        [-0.1737,  0.2137,  0.2102, -0.0733, -0.1850, -0.0960, -0.2384,  0.0129,\n          0.1803, -0.2431, -0.1803,  0.0630,  0.1418, -0.1032,  0.1567, -0.1721],\n        [-0.1069,  0.1650, -0.0685, -0.0272,  0.2270, -0.1683, -0.1527, -0.1474,\n          0.0686,  0.0865,  0.2242, -0.1965, -0.2217, -0.1934,  0.2172,  0.2469],\n        [ 0.1462, -0.1814, -0.2458, -0.0967, -0.1456,  0.0088,  0.0249,  0.2498,\n         -0.0618, -0.2106, -0.2479,  0.1826, -0.1941, -0.1100, -0.2068, -0.1209],\n        [-0.0314,  0.0560, -0.0137, -0.0117, -0.0335, -0.0814,  0.0681, -0.0986,\n         -0.0358,  0.1386,  0.0185,  0.0017,  0.1711,  0.0047,  0.0712,  0.0584],\n        [-0.1707,  0.2122,  0.1284, -0.1392, -0.0129, -0.0420, -0.1894, -0.0431,\n          0.2286, -0.1102, -0.0916,  0.0946, -0.1941,  0.1107, -0.1383, -0.1279]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0591,  0.0059,  0.2122,  0.1266, -0.0608, -0.0759,  0.1675, -0.0804],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1022,  0.2728,  0.1955, -0.3045,  0.0471, -0.0607, -0.2077,  0.1316],\n        [-0.1461,  0.3256,  0.1140,  0.1774,  0.1685,  0.0165,  0.1823,  0.3330],\n        [-0.1628,  0.1011, -0.1357, -0.2022, -0.0448, -0.1916, -0.3448, -0.0118],\n        [-0.0021, -0.2649, -0.3097,  0.2487,  0.1871, -0.1194, -0.1648, -0.2569]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1651,  0.3457, -0.1841, -0.1584], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.stale_replay_buffer.StaleReplayBuffer object at 0x70ea40a97350>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1396,  0.2023, -0.3178, -0.2144, -0.3343, -0.2807, -0.0672, -0.0562,\n        -0.1490, -0.3467,  0.2269, -0.2511,  0.1059,  0.2479, -0.1311, -0.0220,\n        -0.1023, -0.1613, -0.0748,  0.0920, -0.0245,  0.1211, -0.2351, -0.0288,\n        -0.2705, -0.1660, -0.3041,  0.0916,  0.3399,  0.1611, -0.2953,  0.3057],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0724,  0.2410,  0.1868, -0.2251, -0.1390,  0.1966,  0.2940, -0.3299],\n        [ 0.1191, -0.2701, -0.2541,  0.1588, -0.0120,  0.2693,  0.0375, -0.0606],\n        [ 0.1613,  0.0071, -0.1417,  0.0876,  0.1920,  0.3087,  0.2638, -0.2351],\n        [ 0.1149,  0.1487, -0.0848,  0.1872, -0.0029,  0.0411,  0.1893,  0.3329],\n        [-0.2557,  0.0028,  0.2276, -0.0454, -0.1586,  0.3000, -0.2238,  0.0860],\n        [ 0.0573,  0.2282,  0.3051, -0.3257, -0.3515, -0.3010,  0.2031, -0.1685],\n        [ 0.0684,  0.2826, -0.0219,  0.2635, -0.2834,  0.3312,  0.0395,  0.2248],\n        [-0.1442, -0.3428,  0.0362, -0.1652, -0.0812, -0.1864,  0.1058,  0.1342],\n        [-0.0474, -0.0173, -0.0277,  0.3411, -0.3201,  0.1851,  0.1723, -0.2781],\n        [ 0.2013, -0.2927, -0.2340, -0.3376, -0.0372,  0.1732, -0.1833, -0.2272],\n        [ 0.2669,  0.1038,  0.1859, -0.1941,  0.0966, -0.2306,  0.1453, -0.3436],\n        [-0.0482,  0.0448,  0.1374,  0.2660,  0.0233, -0.1890, -0.2549, -0.1462],\n        [-0.2672, -0.1432,  0.1176,  0.0355, -0.2750,  0.2419, -0.3270, -0.1544],\n        [-0.0206, -0.0425, -0.1424,  0.0936, -0.2455, -0.0402, -0.0045, -0.0967],\n        [-0.1152,  0.0790, -0.0294, -0.1709,  0.2375, -0.3356, -0.2901,  0.0079],\n        [-0.0061, -0.1548,  0.2852,  0.3071, -0.2831,  0.2405, -0.1756,  0.0479],\n        [ 0.1783, -0.0257, -0.1694,  0.1057,  0.2148,  0.0736,  0.0520,  0.1897],\n        [-0.3135, -0.2580,  0.2531, -0.2458,  0.1235, -0.1413, -0.3020, -0.1900],\n        [-0.0304, -0.0641, -0.0952, -0.2804, -0.2920,  0.2607,  0.1145, -0.1998],\n        [-0.2499,  0.0635, -0.2999, -0.0923, -0.2710,  0.0682, -0.1362,  0.1781],\n        [-0.3058,  0.3373, -0.3162, -0.2807, -0.1940, -0.2915,  0.3521, -0.1172],\n        [-0.1649, -0.2044,  0.0987, -0.2789,  0.2902,  0.2932, -0.1519,  0.1849],\n        [ 0.1376, -0.3342,  0.2834,  0.0059, -0.1388, -0.1419,  0.0602, -0.0142],\n        [ 0.1193,  0.1393,  0.3001,  0.0872, -0.1388, -0.0082,  0.2848,  0.2566],\n        [ 0.1880,  0.2125, -0.2320, -0.3015,  0.1504,  0.2222, -0.2643,  0.0052],\n        [ 0.2775,  0.1454, -0.1268,  0.2892, -0.0097, -0.0270, -0.1078, -0.2556],\n        [ 0.2482, -0.2757,  0.1391,  0.0814,  0.0458,  0.2613,  0.3039, -0.0414],\n        [ 0.2840, -0.2946, -0.0894, -0.2020, -0.1957, -0.0751, -0.2229, -0.0207],\n        [ 0.2457, -0.1297,  0.2041, -0.3116, -0.1606,  0.1705,  0.2874,  0.2464],\n        [ 0.2427, -0.2435,  0.0610,  0.3527, -0.2570, -0.3255,  0.0419, -0.2541],\n        [-0.3398,  0.3512,  0.1205, -0.2340, -0.0394, -0.0543, -0.2195,  0.1725],\n        [-0.0664, -0.1768, -0.1152, -0.3530,  0.0176,  0.3008, -0.1434,  0.0655]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1622, -0.0921, -0.0773, -0.0124, -0.1203, -0.1197, -0.0743,  0.0685,\n         0.1048,  0.1238, -0.0259, -0.0880,  0.1747,  0.0230,  0.0517, -0.1615],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.2658e-01, -5.7756e-02, -1.7676e-01, -1.3982e-01, -1.0845e-01,\n         -9.6450e-02,  1.6473e-01,  1.3951e-01,  1.1504e-01, -1.6193e-01,\n          9.0220e-02,  1.2041e-01, -1.6583e-01,  1.3481e-01, -1.7339e-01,\n         -2.4037e-03,  1.2261e-01, -9.5006e-02, -1.4075e-01,  1.6835e-01,\n         -3.5390e-02,  1.5931e-01, -4.4245e-02,  9.7534e-02,  4.8252e-02,\n          1.4667e-03,  2.3583e-02,  1.0374e-01,  1.3820e-01,  5.5884e-02,\n          3.0268e-02,  1.6991e-01],\n        [-8.6294e-03,  1.5623e-01,  1.6793e-01, -1.5772e-01,  2.4077e-02,\n          1.7556e-01,  5.3219e-02, -1.0951e-01,  6.5653e-03, -1.6328e-01,\n          1.5203e-01, -2.1116e-02,  3.0810e-02,  1.0235e-01, -3.9682e-02,\n          1.3695e-01, -1.6138e-01, -4.7389e-02,  5.2664e-02, -3.4510e-03,\n          1.4060e-02, -9.3372e-02, -2.6307e-02, -1.2615e-01,  6.9029e-02,\n          8.8857e-02, -4.8308e-02, -1.2385e-01,  2.2240e-02,  9.9201e-02,\n         -1.2408e-01, -2.6329e-02],\n        [-1.0498e-01,  1.0192e-01,  3.9944e-02, -1.6711e-01, -9.9635e-02,\n         -1.6822e-01, -1.0584e-02,  1.1578e-01, -1.4665e-03, -6.3387e-02,\n         -3.3772e-02,  8.6352e-02,  1.5553e-01,  1.1295e-01,  1.7401e-01,\n          1.7413e-01, -2.0583e-03,  1.5531e-01,  1.2688e-01, -9.2877e-02,\n         -4.5427e-02,  2.4431e-02, -8.0939e-02, -7.3703e-02, -1.7149e-01,\n          1.6166e-01,  2.5907e-02, -1.5006e-01, -1.2347e-01,  5.3197e-02,\n         -4.3722e-02,  1.9081e-02],\n        [-4.7417e-02,  7.6177e-02, -8.6815e-02,  7.5989e-02, -6.5246e-02,\n         -1.2357e-01,  1.6916e-01, -1.2077e-01, -6.7677e-02,  1.4578e-01,\n          5.2635e-02, -1.5472e-01, -1.0043e-01,  5.7940e-02, -6.1770e-02,\n          8.7019e-02,  1.2707e-01, -1.2228e-01, -1.6781e-02, -1.0192e-01,\n          1.5510e-01,  1.6555e-01, -3.9697e-02,  1.6240e-01, -2.9366e-02,\n          9.2244e-02,  5.6614e-02, -8.6380e-02,  1.2099e-01, -1.0913e-02,\n         -4.2752e-02, -4.0837e-02],\n        [-6.2264e-02, -1.0294e-01,  1.4511e-01,  3.6837e-02, -8.9633e-02,\n         -3.7058e-02,  9.7022e-02,  1.3126e-01, -7.0524e-02,  1.2713e-01,\n          9.5179e-02,  7.5532e-02, -1.0865e-01, -1.0676e-01, -1.2889e-01,\n         -1.2242e-01, -1.4546e-01, -5.7317e-02, -9.3227e-03, -8.6255e-02,\n         -7.7027e-02, -7.5597e-02, -7.5826e-02,  9.6134e-02,  2.9265e-02,\n          2.0825e-03,  7.2099e-02, -5.3046e-03, -6.6112e-02, -1.0290e-01,\n         -7.1275e-02,  5.6255e-02],\n        [ 3.8893e-02, -9.2349e-02, -3.0027e-02,  1.6994e-01, -6.0953e-02,\n         -1.0807e-01, -4.7036e-02,  9.3489e-02, -5.6778e-02,  1.3039e-01,\n          6.5326e-02,  1.2315e-01, -1.6359e-02,  1.4901e-01, -9.1114e-02,\n         -6.9898e-03, -1.4570e-01,  1.9174e-03, -1.3433e-01,  4.0509e-02,\n          1.5169e-01,  1.2300e-01, -3.9440e-02, -1.0531e-01, -1.4285e-01,\n          1.3138e-01,  8.6261e-02, -1.7390e-01, -9.9983e-02, -6.5866e-02,\n          1.7050e-01, -2.4767e-02],\n        [-1.3509e-02,  6.3329e-02,  8.3949e-02,  1.3988e-01,  5.1252e-02,\n          4.5800e-02,  1.2562e-01,  6.8419e-02,  7.1820e-02,  1.1747e-01,\n         -1.5229e-01, -1.1086e-01,  1.5552e-01,  1.3413e-02, -1.3931e-01,\n          7.7599e-02, -3.5239e-02, -1.7319e-01,  1.4484e-01, -1.6037e-01,\n          2.0139e-02, -6.4692e-03,  6.7718e-02, -1.6736e-01, -1.3675e-01,\n         -1.4952e-01,  7.8522e-02, -2.6735e-02,  8.2241e-02, -1.2422e-01,\n          1.5985e-01,  9.9390e-02],\n        [ 1.3368e-01, -2.0920e-02, -1.6035e-01, -5.0226e-02,  1.1809e-01,\n         -9.7886e-02, -1.0522e-01, -5.4992e-02, -5.5209e-02,  1.7534e-01,\n         -4.1666e-02,  1.5715e-01, -4.3073e-02,  1.4128e-01, -4.5439e-03,\n          5.0208e-02,  4.8554e-02, -1.0057e-01,  3.5119e-02,  1.6534e-01,\n         -3.5285e-02, -5.6675e-03,  4.6585e-02,  6.8654e-02, -1.2781e-01,\n         -1.1957e-01, -3.4043e-02, -1.1415e-02,  7.3863e-02, -1.2528e-01,\n         -1.5541e-01,  1.4923e-01],\n        [-1.3839e-01, -3.7708e-02, -1.3759e-01,  1.2336e-01, -6.4504e-02,\n         -4.5453e-02, -9.4229e-02,  8.9892e-02, -9.7813e-02,  1.6596e-01,\n         -6.0862e-02,  1.7279e-01,  2.1331e-02,  1.7060e-01, -7.1778e-02,\n         -1.0137e-01, -5.8927e-02,  7.8987e-03, -9.0765e-02,  2.1175e-02,\n         -6.0648e-02, -1.7667e-01,  1.1116e-01, -1.1991e-01,  1.2175e-01,\n         -1.1024e-01, -1.6067e-01, -1.1933e-02,  5.8610e-03,  4.3272e-02,\n          2.8678e-02, -8.2363e-02],\n        [-6.7118e-02, -9.0029e-03,  5.0767e-02, -1.9492e-02,  9.4598e-02,\n          4.4591e-02,  1.5234e-01,  7.9531e-02, -1.5210e-01, -8.2392e-02,\n          9.3969e-02, -1.2020e-01,  8.4450e-02,  1.2061e-01,  1.2567e-01,\n          1.1604e-01, -1.0332e-01,  1.5191e-01,  1.2090e-01,  9.2025e-02,\n          1.1169e-01, -1.3456e-01,  1.7352e-01, -1.4006e-02,  1.5533e-01,\n         -1.1015e-01, -4.8926e-02,  1.7255e-01,  8.4028e-02, -2.0665e-03,\n          8.0182e-02, -1.2223e-01],\n        [ 1.0831e-01,  1.4585e-01,  1.5708e-01,  8.3241e-02,  1.6901e-01,\n          6.1363e-02,  6.2255e-02,  9.9532e-02, -9.5639e-02,  2.0979e-02,\n         -3.2519e-02, -3.1691e-02, -1.3449e-01,  5.8789e-02, -9.3853e-02,\n          1.5631e-01,  5.1821e-02, -1.7194e-01,  1.0904e-01,  5.4834e-02,\n         -7.2332e-02,  8.1888e-02,  3.5371e-02,  1.3255e-01, -1.6410e-01,\n          1.5730e-01, -1.6508e-01, -1.3417e-01, -5.7233e-02,  1.3197e-02,\n         -4.3789e-02, -1.6394e-02],\n        [ 6.1793e-02,  1.7251e-01, -8.4022e-02, -9.0776e-02,  7.7475e-02,\n         -6.9814e-02,  1.5630e-02, -9.8705e-02, -1.5130e-01,  1.7649e-01,\n         -6.4379e-02, -1.2628e-01, -1.3767e-01, -3.4358e-02,  9.1274e-02,\n         -9.2831e-02, -6.5501e-02,  1.3051e-01, -4.8225e-02,  5.7923e-02,\n          1.3527e-01, -1.3084e-01,  1.0036e-01, -1.0725e-01,  1.2758e-01,\n         -1.6985e-01, -7.0999e-02,  1.0374e-01,  1.3821e-01, -4.4827e-02,\n          4.2149e-02,  1.6805e-01],\n        [-1.4830e-02,  8.3903e-02, -1.1914e-01,  7.8316e-03,  9.3264e-02,\n          7.2094e-02, -8.0219e-02, -3.3176e-02,  1.5716e-01, -1.4682e-01,\n          1.5400e-01, -1.6019e-02,  1.3424e-01,  1.6350e-01, -1.0586e-01,\n         -4.9216e-02, -4.4601e-02, -1.1481e-01,  7.6888e-02,  1.6808e-01,\n         -1.0213e-01,  3.3869e-02, -9.8825e-02,  1.4482e-01, -1.4124e-01,\n          1.0551e-01, -1.6758e-01,  4.0836e-02,  1.6255e-01,  6.3358e-02,\n         -4.6069e-02, -1.1938e-01],\n        [ 8.5827e-02, -1.1493e-01,  1.4469e-01, -1.0831e-01, -1.5438e-01,\n         -3.7165e-02, -6.8631e-02, -4.5956e-02, -1.5358e-01,  5.0531e-03,\n         -7.0561e-02, -9.5017e-02,  1.0774e-01,  8.2065e-02,  8.0258e-02,\n          3.0072e-02, -9.4350e-02, -1.1498e-01, -9.9080e-02,  1.1058e-01,\n         -1.5566e-01,  1.8286e-02, -9.4034e-02, -1.4154e-01,  1.7567e-01,\n          5.6906e-02,  2.5826e-02, -1.2265e-01,  5.9768e-02, -1.6764e-01,\n          1.6388e-02, -5.0802e-02],\n        [-1.6050e-01, -9.1656e-02, -3.4148e-02, -2.1707e-02,  1.1753e-01,\n         -9.2735e-02, -1.5228e-01,  1.6193e-01, -1.3039e-01, -7.0375e-02,\n         -6.1334e-02, -5.4884e-03, -2.5949e-03,  1.4613e-01,  1.1730e-01,\n         -2.4071e-02,  1.0849e-01, -2.5391e-02, -5.6790e-02,  1.4266e-01,\n         -1.1962e-02,  9.9294e-02,  1.7632e-01,  4.7181e-02,  5.1630e-03,\n         -6.2527e-02,  1.0201e-01, -1.0866e-01, -2.6264e-02, -7.4962e-03,\n          1.9499e-02, -1.2991e-01],\n        [ 5.0472e-02,  5.8748e-02,  4.3511e-02, -1.6475e-01,  1.3155e-01,\n          9.8854e-02, -1.2526e-01, -1.4610e-01, -7.7087e-02, -5.1219e-02,\n          1.4906e-01, -4.2128e-02, -1.2361e-01, -8.1949e-02,  1.1532e-01,\n          1.5823e-01, -2.0390e-03, -1.4364e-02, -7.8572e-03, -1.4703e-01,\n         -1.6689e-01,  1.5870e-01, -1.6077e-01,  8.6136e-02,  9.8758e-02,\n         -1.3271e-01,  7.3813e-02,  5.3895e-03, -8.0374e-05, -6.5987e-03,\n          3.1927e-02, -1.2380e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0591,  0.0059,  0.2122,  0.1266, -0.0608, -0.0759,  0.1675, -0.0804],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0282,  0.0550,  0.0360, -0.0670, -0.1046,  0.0550, -0.1268,  0.1250,\n          0.1669, -0.0308, -0.0771,  0.1115, -0.0279,  0.0402, -0.1135,  0.1747],\n        [ 0.1677, -0.0039,  0.1184,  0.2078,  0.1343,  0.2478, -0.1711,  0.2330,\n         -0.2467, -0.1412,  0.0318, -0.2384, -0.1188, -0.1631, -0.2322, -0.2308],\n        [-0.2174,  0.1216,  0.2271, -0.1654, -0.2390,  0.0259,  0.0008, -0.1346,\n          0.1576,  0.0340,  0.0187, -0.0269, -0.0822,  0.0972, -0.2142,  0.1570],\n        [-0.1737,  0.2137,  0.2102, -0.0733, -0.1850, -0.0960, -0.2384,  0.0129,\n          0.1803, -0.2431, -0.1803,  0.0630,  0.1418, -0.1032,  0.1567, -0.1721],\n        [-0.1069,  0.1650, -0.0685, -0.0272,  0.2270, -0.1683, -0.1527, -0.1474,\n          0.0686,  0.0865,  0.2242, -0.1965, -0.2217, -0.1934,  0.2172,  0.2469],\n        [ 0.1462, -0.1814, -0.2458, -0.0967, -0.1456,  0.0088,  0.0249,  0.2498,\n         -0.0618, -0.2106, -0.2479,  0.1826, -0.1941, -0.1100, -0.2068, -0.1209],\n        [-0.0314,  0.0560, -0.0137, -0.0117, -0.0335, -0.0814,  0.0681, -0.0986,\n         -0.0358,  0.1386,  0.0185,  0.0017,  0.1711,  0.0047,  0.0712,  0.0584],\n        [-0.1707,  0.2122,  0.1284, -0.1392, -0.0129, -0.0420, -0.1894, -0.0431,\n          0.2286, -0.1102, -0.0916,  0.0946, -0.1941,  0.1107, -0.1383, -0.1279]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1651,  0.3457, -0.1841, -0.1584], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1022,  0.2728,  0.1955, -0.3045,  0.0471, -0.0607, -0.2077,  0.1316],\n        [-0.1461,  0.3256,  0.1140,  0.1774,  0.1685,  0.0165,  0.1823,  0.3330],\n        [-0.1628,  0.1011, -0.1357, -0.2022, -0.0448, -0.1916, -0.3448, -0.0118],\n        [-0.0021, -0.2649, -0.3097,  0.2487,  0.1871, -0.1194, -0.1648, -0.2569]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x70ea3d9932d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s65060000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s65060000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}