{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s686510000"
    },
    "q_lr":	0.0005,
    "seed":	686510000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x75278e5cdc50>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1444, -0.2816, -0.0689, -0.0642,  0.1921,  0.1317,  0.2368, -0.1638,\n        -0.1067,  0.1300,  0.3167, -0.0926, -0.2322, -0.0753,  0.2971, -0.0855,\n        -0.1318,  0.2158,  0.3322, -0.2840, -0.3304, -0.1217,  0.1863, -0.3237,\n         0.0624,  0.1743,  0.3521, -0.2439, -0.1278, -0.2533,  0.0726,  0.3130],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2020,  0.1032, -0.0609,  0.1640,  0.0529, -0.3519, -0.1818, -0.1278],\n        [ 0.1582,  0.0695, -0.0535, -0.3316, -0.2062,  0.0571,  0.0952,  0.0480],\n        [ 0.3479, -0.1003, -0.0798,  0.1981,  0.2691,  0.1035,  0.0480, -0.0203],\n        [ 0.0589,  0.3374,  0.0136, -0.0441, -0.0636, -0.0097,  0.1025, -0.1333],\n        [ 0.2502, -0.2443,  0.1127,  0.2476,  0.1350, -0.3119,  0.2533,  0.0587],\n        [-0.2569, -0.3066, -0.1966, -0.0792,  0.0773,  0.1152,  0.1113,  0.3080],\n        [-0.2933, -0.3206,  0.2630,  0.1820, -0.2266, -0.1692, -0.2222,  0.1891],\n        [-0.1607, -0.3129,  0.0790, -0.1957, -0.2328, -0.2554,  0.1077, -0.3118],\n        [ 0.1621,  0.1294,  0.0151,  0.0778, -0.1156, -0.2006,  0.1480, -0.1085],\n        [-0.2892, -0.1188, -0.1476,  0.1997,  0.2590, -0.2644,  0.3361, -0.3462],\n        [-0.2778,  0.2848, -0.3494, -0.3299, -0.0756, -0.0365, -0.0808, -0.2002],\n        [-0.1744,  0.1629, -0.3483, -0.1121, -0.1550,  0.1863,  0.2943,  0.1641],\n        [-0.3157,  0.2658, -0.0489,  0.2196,  0.0787,  0.1594, -0.1977,  0.2706],\n        [ 0.0151, -0.0783,  0.1818, -0.0255,  0.3303, -0.3035,  0.3334, -0.2041],\n        [ 0.2539,  0.0220, -0.3225, -0.2230, -0.0634,  0.1325,  0.1866, -0.2378],\n        [-0.2921,  0.0848, -0.2135, -0.0555,  0.0275,  0.2558,  0.2325, -0.2560],\n        [-0.1999,  0.0468, -0.2567, -0.2916, -0.3433,  0.1193, -0.1167,  0.2705],\n        [ 0.1335,  0.2336, -0.3092, -0.1670,  0.0831,  0.2323, -0.1946, -0.1011],\n        [-0.2072,  0.0315,  0.0236,  0.2149,  0.1737, -0.2003,  0.0048,  0.0809],\n        [ 0.2291, -0.0184,  0.3038, -0.0233,  0.1086,  0.0828, -0.3111, -0.3212],\n        [-0.2920, -0.1246, -0.0408,  0.2049,  0.0126, -0.1655, -0.2239, -0.2083],\n        [ 0.0256, -0.2431, -0.2583, -0.3156,  0.3089,  0.1871, -0.0718, -0.1700],\n        [ 0.0006, -0.0060, -0.3060,  0.2882,  0.3203,  0.3380,  0.1774, -0.2323],\n        [ 0.0833,  0.3133,  0.0296, -0.1415, -0.2102,  0.1558,  0.1848, -0.2650],\n        [ 0.2518,  0.2322,  0.2037,  0.2580,  0.2807,  0.1891, -0.2453,  0.2168],\n        [ 0.2379,  0.0900,  0.1205,  0.3524, -0.2234,  0.0207, -0.2915, -0.1673],\n        [ 0.2499,  0.2839,  0.2136, -0.3025, -0.0007,  0.0837, -0.1389,  0.0423],\n        [ 0.0319,  0.2666,  0.0091, -0.2129,  0.0211, -0.0926,  0.1440,  0.2161],\n        [ 0.1656, -0.1406,  0.1709, -0.0054, -0.1940,  0.2434, -0.1242,  0.2198],\n        [ 0.1714,  0.0572, -0.2043,  0.3398, -0.0739,  0.1263,  0.0781,  0.3261],\n        [ 0.2662,  0.3041,  0.0907,  0.1554,  0.2194, -0.3507, -0.2642, -0.1117],\n        [ 0.0991,  0.0076,  0.0659,  0.3266, -0.2578, -0.2258,  0.2282,  0.2761]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1033,  0.0494,  0.0626, -0.1508, -0.0437,  0.0234,  0.0159, -0.0280,\n         0.1549, -0.1251,  0.0085, -0.0139,  0.0721, -0.0728, -0.1019, -0.0014],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.7291e-01,  4.9913e-02,  1.1325e-01,  1.8636e-03,  2.2517e-02,\n          3.4888e-02,  1.4740e-01,  1.0076e-01, -1.5632e-01, -2.1240e-02,\n          1.4235e-01, -1.1558e-01, -1.5241e-01, -6.6463e-02, -1.6374e-03,\n         -1.2060e-01,  1.0759e-02, -4.0620e-02, -5.3431e-02, -5.9220e-02,\n         -8.3322e-02, -5.6065e-02, -7.0856e-02,  1.4425e-01,  1.0627e-01,\n          5.6370e-02, -1.0465e-01,  6.6382e-02, -1.5643e-03, -1.3357e-01,\n          7.0589e-02,  4.5323e-02],\n        [-9.5644e-02, -1.4898e-01, -5.5077e-02,  1.2118e-02, -7.6960e-02,\n         -1.3718e-01,  1.4605e-01,  1.3850e-01, -1.1418e-01,  6.2328e-02,\n          2.9125e-02,  1.4520e-01, -1.5943e-01,  3.3786e-03, -1.5588e-01,\n          1.0403e-01, -5.6819e-02, -1.8891e-02,  1.6088e-01, -1.1029e-01,\n         -1.7047e-01,  1.3818e-01,  1.2611e-01,  1.0365e-01,  4.1376e-02,\n          3.9743e-02, -1.2407e-01,  1.7191e-01,  1.2385e-01, -1.0985e-01,\n          8.8098e-02,  1.1270e-01],\n        [ 1.2588e-01, -5.4282e-03,  6.0471e-02, -3.0155e-02, -1.1667e-01,\n          1.5291e-01,  8.2349e-02,  7.9883e-02, -6.1957e-02, -3.0897e-02,\n         -8.6533e-02, -1.7207e-01, -1.5050e-01,  8.5949e-02, -3.6826e-02,\n          8.5562e-02,  7.3819e-02,  9.2375e-02,  1.2235e-01, -2.8101e-02,\n         -4.3172e-02,  4.1574e-02, -2.8359e-02, -9.4960e-02,  1.7320e-01,\n         -1.5340e-01,  1.0400e-01,  9.5849e-02,  2.2825e-02,  9.9605e-02,\n         -1.3037e-01,  1.4584e-01],\n        [-1.6385e-01,  1.6991e-01, -5.5121e-02,  8.4279e-02, -5.9473e-02,\n         -1.2452e-01,  1.5600e-01,  4.1685e-02,  6.4434e-02, -1.2630e-01,\n          1.6785e-01,  5.0109e-02,  9.4229e-02,  1.4992e-01,  1.0548e-01,\n         -1.6077e-02,  4.0265e-02, -6.1069e-02, -1.2166e-01,  4.1860e-02,\n          2.5213e-02, -4.1652e-03,  9.1648e-02, -1.1632e-01, -2.4017e-02,\n          4.2794e-02, -9.2659e-02,  9.4345e-02,  1.5238e-02,  1.1935e-01,\n          6.7804e-02,  6.1131e-02],\n        [-5.5836e-02, -2.4904e-03, -4.5115e-02, -5.2314e-02, -4.9689e-02,\n          1.5264e-01,  4.4489e-02,  9.1400e-02, -1.5548e-01,  8.1763e-02,\n         -8.8202e-03, -1.5279e-02,  1.0798e-01, -1.7241e-01, -1.6662e-01,\n         -8.6732e-02, -2.7079e-02,  1.3644e-01,  1.5609e-01, -1.1806e-01,\n         -7.5350e-02, -1.4470e-01, -1.3510e-01, -3.6436e-02, -5.7262e-02,\n         -1.3670e-01,  1.3302e-01, -4.0947e-02, -3.1007e-02,  1.2313e-01,\n         -8.6668e-02, -7.0586e-02],\n        [ 1.2618e-02,  6.1674e-02,  7.4193e-02,  1.0873e-01,  7.5334e-02,\n          8.8463e-02,  9.8119e-02,  7.2998e-02,  1.1354e-02,  1.3593e-01,\n         -4.1832e-02,  1.1615e-01, -1.5608e-01, -6.3270e-02, -9.5192e-02,\n         -3.4796e-02,  4.6434e-02,  9.2504e-02, -5.8951e-02,  8.3141e-02,\n          1.4854e-01,  3.0803e-02,  1.6529e-01,  3.4531e-02,  1.0077e-01,\n          1.1680e-01, -1.4685e-01, -1.3887e-01,  8.5657e-02,  6.4342e-02,\n         -1.4410e-01,  7.0825e-03],\n        [-1.4890e-01, -1.6169e-01, -1.7008e-01, -1.7776e-02, -9.4089e-02,\n          1.0166e-01,  4.4193e-02, -1.4155e-01,  1.0067e-01, -7.3086e-02,\n         -8.5009e-03,  1.5842e-01, -9.4956e-02,  1.0775e-01,  1.1244e-01,\n         -1.2450e-01, -7.5143e-03, -1.2697e-01,  9.9427e-02, -2.7322e-04,\n          1.3141e-01,  8.2545e-02,  1.0759e-02,  3.8448e-02, -3.3762e-02,\n          9.6221e-02,  8.2616e-02,  6.6326e-03, -1.1201e-01, -1.1312e-01,\n          1.6874e-01,  1.6644e-01],\n        [ 9.6480e-02, -3.2454e-03, -1.6353e-01,  1.3726e-01,  1.1441e-01,\n         -3.6333e-03,  1.0036e-01, -5.3778e-02, -1.6687e-01, -1.1326e-01,\n         -1.0377e-01, -3.4196e-02,  8.5986e-02,  3.0122e-02, -1.4418e-01,\n          1.1501e-01, -7.2557e-02, -2.2252e-03, -7.6373e-02, -1.5703e-01,\n          1.7440e-01,  1.4207e-01, -3.2271e-03, -1.6194e-01, -5.4371e-02,\n         -1.1939e-01,  1.1794e-02, -3.7548e-02, -5.8517e-02,  1.4335e-01,\n         -4.0060e-02, -1.5299e-02],\n        [-5.2453e-02,  4.3081e-02,  9.7895e-02, -1.3368e-01,  1.0244e-01,\n          9.6582e-02, -9.7072e-03, -3.8958e-03,  4.8973e-02,  7.3830e-02,\n         -3.3513e-02, -8.1744e-03, -1.1170e-01,  1.5315e-01,  4.3826e-02,\n         -1.5656e-01, -8.8388e-02, -6.0285e-02, -1.1588e-01, -4.9839e-02,\n          2.1705e-03, -7.3366e-02,  4.3787e-02, -9.7626e-02,  9.8790e-02,\n          1.7262e-01,  7.9544e-02, -6.6320e-03, -6.5748e-02, -1.0552e-01,\n         -1.7389e-01, -2.1542e-02],\n        [ 1.3354e-01,  5.0573e-02,  4.6959e-02,  1.3072e-01, -9.9303e-02,\n         -4.6155e-02, -7.5537e-02,  1.3042e-01,  1.2120e-01,  1.7089e-01,\n          1.4249e-01,  1.0159e-01,  7.5930e-02,  1.7947e-02, -1.6069e-01,\n          4.0454e-02,  1.4148e-01, -1.0193e-01,  7.7459e-02, -3.0028e-02,\n         -7.7904e-02, -3.1010e-02,  6.9236e-02,  1.0901e-01, -3.2481e-02,\n          1.5038e-01,  2.6350e-02,  1.6005e-02,  3.3119e-02, -1.0873e-01,\n          6.6156e-02,  9.3881e-02],\n        [-6.7759e-02,  5.2247e-02, -6.5328e-03, -3.7185e-02, -1.9428e-02,\n         -1.3924e-01, -5.6414e-03,  1.1261e-01, -1.1500e-01,  3.9576e-02,\n          1.3500e-01, -4.5646e-02,  4.1245e-02, -4.1790e-02,  1.0665e-01,\n         -1.2525e-01, -8.0552e-02, -5.2596e-02, -9.0462e-02,  3.4370e-02,\n          1.2151e-02, -1.4797e-01, -8.1736e-03,  1.3906e-01,  1.4690e-01,\n         -1.3575e-01, -1.0318e-01, -1.5189e-01, -2.6002e-02, -2.6138e-02,\n          1.8343e-02,  3.6535e-03],\n        [-1.3946e-01,  1.4567e-01,  1.4800e-01, -1.6137e-01,  1.1737e-01,\n         -9.5232e-02, -1.0963e-01, -8.2913e-02,  7.0739e-02, -8.8229e-03,\n         -5.8955e-02, -8.4781e-02, -4.5450e-02, -3.7627e-02,  8.1353e-03,\n         -6.1541e-02,  6.0803e-02,  4.4101e-02, -3.9121e-02, -5.7675e-02,\n          9.4296e-02,  3.4771e-02, -4.8231e-02, -3.7204e-02, -6.7514e-02,\n          1.2935e-01, -2.5414e-02,  5.9997e-03, -1.1739e-02, -1.6605e-01,\n          7.7840e-02, -7.8568e-03],\n        [-1.2998e-01, -8.7167e-02, -7.7603e-02,  2.6327e-02,  1.3248e-01,\n          1.5813e-01, -1.5942e-01,  2.3937e-02, -1.0675e-01,  4.4786e-02,\n         -1.3559e-01,  6.7552e-02,  1.2207e-01,  1.6874e-01, -1.4514e-01,\n          1.5831e-01,  1.7576e-02, -8.8775e-02,  1.6416e-01,  4.7437e-02,\n          6.4773e-02, -7.9177e-02, -9.2837e-02, -9.1917e-02,  1.3850e-02,\n         -1.3483e-01, -9.1897e-02,  1.3729e-01, -1.1774e-01, -3.6536e-02,\n         -1.6949e-01, -8.4878e-02],\n        [ 8.3769e-02, -2.6096e-02, -1.1642e-01,  1.4409e-01, -1.6912e-01,\n          7.1837e-02, -7.1295e-03, -8.8752e-02, -1.5270e-04, -7.5127e-02,\n          1.0437e-01,  1.4118e-01,  2.0628e-02, -1.0144e-02, -1.7285e-01,\n          2.6795e-02, -1.0548e-01,  6.7946e-02, -1.2013e-01, -9.0129e-02,\n         -1.7531e-01,  1.1348e-01,  1.6544e-01, -7.4951e-02, -1.6417e-01,\n          1.7630e-01,  1.7331e-01, -4.2560e-03,  6.9896e-02, -3.2066e-02,\n          1.0605e-01, -4.8280e-02],\n        [ 1.2388e-01,  1.6293e-01,  4.2094e-02,  1.3440e-01,  1.7469e-01,\n         -1.5906e-01,  9.2223e-02, -7.1856e-02,  1.5096e-01, -5.9471e-02,\n          1.4619e-01,  3.8533e-02,  2.3950e-02, -1.5877e-01, -1.6587e-01,\n          1.5238e-01, -1.3293e-01, -4.9042e-02,  5.6901e-02, -1.4572e-01,\n         -8.2833e-02,  6.3131e-02,  1.1996e-01,  3.7861e-02, -5.9390e-02,\n          6.7563e-02,  1.1845e-01, -8.5194e-02, -1.6143e-01, -4.5853e-02,\n         -2.4152e-02, -8.0005e-02],\n        [ 8.8404e-02, -1.5291e-02,  4.5839e-02,  8.9150e-02,  1.8194e-02,\n         -1.8057e-02,  8.9121e-02,  1.2895e-01,  7.0263e-02,  9.6807e-02,\n          2.7997e-02,  1.6971e-01, -1.1236e-01,  1.2196e-01, -1.2809e-01,\n         -6.2195e-02, -1.3354e-01,  1.0148e-01,  4.3609e-02, -8.7330e-02,\n          1.5503e-01,  9.0615e-02, -1.6486e-01, -1.0659e-01,  1.2232e-01,\n          6.7802e-02, -8.7827e-02, -4.2107e-02, -3.5076e-02,  8.1697e-03,\n         -8.9423e-02,  1.4830e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0670,  0.2073,  0.1694, -0.0731, -0.1037, -0.1234, -0.0342,  0.2330],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0407, -0.1624, -0.0683,  0.0598, -0.0978,  0.2279, -0.1769, -0.0551,\n         -0.0246,  0.2249, -0.2340,  0.0992,  0.1227, -0.0029,  0.0250,  0.0195],\n        [ 0.2286,  0.1004, -0.1778,  0.1085,  0.0199, -0.1626, -0.1651, -0.1705,\n          0.1597,  0.0692,  0.1488, -0.0806,  0.0919, -0.1407, -0.1034, -0.2280],\n        [ 0.0183, -0.0030,  0.0120, -0.2012,  0.0575, -0.0192,  0.1374, -0.0503,\n         -0.1857,  0.0098, -0.1998, -0.0423, -0.2355,  0.0966, -0.2011, -0.1136],\n        [ 0.2431, -0.1242,  0.0451, -0.2063,  0.2319,  0.2499,  0.0509, -0.0235,\n          0.2308, -0.0610,  0.1662,  0.0388, -0.1608, -0.1936, -0.2079, -0.0288],\n        [-0.1379, -0.2407,  0.0268, -0.1379,  0.0680,  0.1288,  0.2115, -0.1400,\n         -0.0493,  0.2046, -0.0499, -0.1543,  0.1085,  0.0979,  0.0768, -0.0503],\n        [ 0.0104, -0.0397, -0.1759,  0.0782,  0.0682, -0.2439, -0.0075,  0.1276,\n         -0.0644,  0.1957,  0.0700, -0.0152, -0.0529, -0.2060,  0.0323,  0.1853],\n        [ 0.1735,  0.0346, -0.1689,  0.2086,  0.0691, -0.2361,  0.1474, -0.0538,\n         -0.0118,  0.0887, -0.1972, -0.2144, -0.0251,  0.1230,  0.0259,  0.2048],\n        [-0.1509,  0.1906, -0.0516, -0.0767, -0.0170,  0.0183, -0.0727,  0.2009,\n          0.1101,  0.2171,  0.1757, -0.0789, -0.2208, -0.0825, -0.1123,  0.2237]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0159,  0.1590,  0.0962,  0.1405], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3449,  0.0593,  0.1502, -0.2564,  0.2860,  0.2031,  0.1830, -0.0950],\n        [ 0.0617, -0.1636,  0.3159,  0.3526, -0.1642, -0.1455, -0.0272, -0.3189],\n        [-0.1067,  0.0182, -0.1230,  0.0535, -0.2648,  0.2046,  0.2148, -0.0819],\n        [ 0.1621,  0.3532,  0.3203,  0.2319,  0.0604,  0.2090, -0.1610, -0.2899]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2020,  0.1032, -0.0609,  0.1640,  0.0529, -0.3519, -0.1818, -0.1278],\n        [ 0.1582,  0.0695, -0.0535, -0.3316, -0.2062,  0.0571,  0.0952,  0.0480],\n        [ 0.3479, -0.1003, -0.0798,  0.1981,  0.2691,  0.1035,  0.0480, -0.0203],\n        [ 0.0589,  0.3374,  0.0136, -0.0441, -0.0636, -0.0097,  0.1025, -0.1333],\n        [ 0.2502, -0.2443,  0.1127,  0.2476,  0.1350, -0.3119,  0.2533,  0.0587],\n        [-0.2569, -0.3066, -0.1966, -0.0792,  0.0773,  0.1152,  0.1113,  0.3080],\n        [-0.2933, -0.3206,  0.2630,  0.1820, -0.2266, -0.1692, -0.2222,  0.1891],\n        [-0.1607, -0.3129,  0.0790, -0.1957, -0.2328, -0.2554,  0.1077, -0.3118],\n        [ 0.1621,  0.1294,  0.0151,  0.0778, -0.1156, -0.2006,  0.1480, -0.1085],\n        [-0.2892, -0.1188, -0.1476,  0.1997,  0.2590, -0.2644,  0.3361, -0.3462],\n        [-0.2778,  0.2848, -0.3494, -0.3299, -0.0756, -0.0365, -0.0808, -0.2002],\n        [-0.1744,  0.1629, -0.3483, -0.1121, -0.1550,  0.1863,  0.2943,  0.1641],\n        [-0.3157,  0.2658, -0.0489,  0.2196,  0.0787,  0.1594, -0.1977,  0.2706],\n        [ 0.0151, -0.0783,  0.1818, -0.0255,  0.3303, -0.3035,  0.3334, -0.2041],\n        [ 0.2539,  0.0220, -0.3225, -0.2230, -0.0634,  0.1325,  0.1866, -0.2378],\n        [-0.2921,  0.0848, -0.2135, -0.0555,  0.0275,  0.2558,  0.2325, -0.2560],\n        [-0.1999,  0.0468, -0.2567, -0.2916, -0.3433,  0.1193, -0.1167,  0.2705],\n        [ 0.1335,  0.2336, -0.3092, -0.1670,  0.0831,  0.2323, -0.1946, -0.1011],\n        [-0.2072,  0.0315,  0.0236,  0.2149,  0.1737, -0.2003,  0.0048,  0.0809],\n        [ 0.2291, -0.0184,  0.3038, -0.0233,  0.1086,  0.0828, -0.3111, -0.3212],\n        [-0.2920, -0.1246, -0.0408,  0.2049,  0.0126, -0.1655, -0.2239, -0.2083],\n        [ 0.0256, -0.2431, -0.2583, -0.3156,  0.3089,  0.1871, -0.0718, -0.1700],\n        [ 0.0006, -0.0060, -0.3060,  0.2882,  0.3203,  0.3380,  0.1774, -0.2323],\n        [ 0.0833,  0.3133,  0.0296, -0.1415, -0.2102,  0.1558,  0.1848, -0.2650],\n        [ 0.2518,  0.2322,  0.2037,  0.2580,  0.2807,  0.1891, -0.2453,  0.2168],\n        [ 0.2379,  0.0900,  0.1205,  0.3524, -0.2234,  0.0207, -0.2915, -0.1673],\n        [ 0.2499,  0.2839,  0.2136, -0.3025, -0.0007,  0.0837, -0.1389,  0.0423],\n        [ 0.0319,  0.2666,  0.0091, -0.2129,  0.0211, -0.0926,  0.1440,  0.2161],\n        [ 0.1656, -0.1406,  0.1709, -0.0054, -0.1940,  0.2434, -0.1242,  0.2198],\n        [ 0.1714,  0.0572, -0.2043,  0.3398, -0.0739,  0.1263,  0.0781,  0.3261],\n        [ 0.2662,  0.3041,  0.0907,  0.1554,  0.2194, -0.3507, -0.2642, -0.1117],\n        [ 0.0991,  0.0076,  0.0659,  0.3266, -0.2578, -0.2258,  0.2282,  0.2761]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1444, -0.2816, -0.0689, -0.0642,  0.1921,  0.1317,  0.2368, -0.1638,\n        -0.1067,  0.1300,  0.3167, -0.0926, -0.2322, -0.0753,  0.2971, -0.0855,\n        -0.1318,  0.2158,  0.3322, -0.2840, -0.3304, -0.1217,  0.1863, -0.3237,\n         0.0624,  0.1743,  0.3521, -0.2439, -0.1278, -0.2533,  0.0726,  0.3130],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.7291e-01,  4.9913e-02,  1.1325e-01,  1.8636e-03,  2.2517e-02,\n          3.4888e-02,  1.4740e-01,  1.0076e-01, -1.5632e-01, -2.1240e-02,\n          1.4235e-01, -1.1558e-01, -1.5241e-01, -6.6463e-02, -1.6374e-03,\n         -1.2060e-01,  1.0759e-02, -4.0620e-02, -5.3431e-02, -5.9220e-02,\n         -8.3322e-02, -5.6065e-02, -7.0856e-02,  1.4425e-01,  1.0627e-01,\n          5.6370e-02, -1.0465e-01,  6.6382e-02, -1.5643e-03, -1.3357e-01,\n          7.0589e-02,  4.5323e-02],\n        [-9.5644e-02, -1.4898e-01, -5.5077e-02,  1.2118e-02, -7.6960e-02,\n         -1.3718e-01,  1.4605e-01,  1.3850e-01, -1.1418e-01,  6.2328e-02,\n          2.9125e-02,  1.4520e-01, -1.5943e-01,  3.3786e-03, -1.5588e-01,\n          1.0403e-01, -5.6819e-02, -1.8891e-02,  1.6088e-01, -1.1029e-01,\n         -1.7047e-01,  1.3818e-01,  1.2611e-01,  1.0365e-01,  4.1376e-02,\n          3.9743e-02, -1.2407e-01,  1.7191e-01,  1.2385e-01, -1.0985e-01,\n          8.8098e-02,  1.1270e-01],\n        [ 1.2588e-01, -5.4282e-03,  6.0471e-02, -3.0155e-02, -1.1667e-01,\n          1.5291e-01,  8.2349e-02,  7.9883e-02, -6.1957e-02, -3.0897e-02,\n         -8.6533e-02, -1.7207e-01, -1.5050e-01,  8.5949e-02, -3.6826e-02,\n          8.5562e-02,  7.3819e-02,  9.2375e-02,  1.2235e-01, -2.8101e-02,\n         -4.3172e-02,  4.1574e-02, -2.8359e-02, -9.4960e-02,  1.7320e-01,\n         -1.5340e-01,  1.0400e-01,  9.5849e-02,  2.2825e-02,  9.9605e-02,\n         -1.3037e-01,  1.4584e-01],\n        [-1.6385e-01,  1.6991e-01, -5.5121e-02,  8.4279e-02, -5.9473e-02,\n         -1.2452e-01,  1.5600e-01,  4.1685e-02,  6.4434e-02, -1.2630e-01,\n          1.6785e-01,  5.0109e-02,  9.4229e-02,  1.4992e-01,  1.0548e-01,\n         -1.6077e-02,  4.0265e-02, -6.1069e-02, -1.2166e-01,  4.1860e-02,\n          2.5213e-02, -4.1652e-03,  9.1648e-02, -1.1632e-01, -2.4017e-02,\n          4.2794e-02, -9.2659e-02,  9.4345e-02,  1.5238e-02,  1.1935e-01,\n          6.7804e-02,  6.1131e-02],\n        [-5.5836e-02, -2.4904e-03, -4.5115e-02, -5.2314e-02, -4.9689e-02,\n          1.5264e-01,  4.4489e-02,  9.1400e-02, -1.5548e-01,  8.1763e-02,\n         -8.8202e-03, -1.5279e-02,  1.0798e-01, -1.7241e-01, -1.6662e-01,\n         -8.6732e-02, -2.7079e-02,  1.3644e-01,  1.5609e-01, -1.1806e-01,\n         -7.5350e-02, -1.4470e-01, -1.3510e-01, -3.6436e-02, -5.7262e-02,\n         -1.3670e-01,  1.3302e-01, -4.0947e-02, -3.1007e-02,  1.2313e-01,\n         -8.6668e-02, -7.0586e-02],\n        [ 1.2618e-02,  6.1674e-02,  7.4193e-02,  1.0873e-01,  7.5334e-02,\n          8.8463e-02,  9.8119e-02,  7.2998e-02,  1.1354e-02,  1.3593e-01,\n         -4.1832e-02,  1.1615e-01, -1.5608e-01, -6.3270e-02, -9.5192e-02,\n         -3.4796e-02,  4.6434e-02,  9.2504e-02, -5.8951e-02,  8.3141e-02,\n          1.4854e-01,  3.0803e-02,  1.6529e-01,  3.4531e-02,  1.0077e-01,\n          1.1680e-01, -1.4685e-01, -1.3887e-01,  8.5657e-02,  6.4342e-02,\n         -1.4410e-01,  7.0825e-03],\n        [-1.4890e-01, -1.6169e-01, -1.7008e-01, -1.7776e-02, -9.4089e-02,\n          1.0166e-01,  4.4193e-02, -1.4155e-01,  1.0067e-01, -7.3086e-02,\n         -8.5009e-03,  1.5842e-01, -9.4956e-02,  1.0775e-01,  1.1244e-01,\n         -1.2450e-01, -7.5143e-03, -1.2697e-01,  9.9427e-02, -2.7322e-04,\n          1.3141e-01,  8.2545e-02,  1.0759e-02,  3.8448e-02, -3.3762e-02,\n          9.6221e-02,  8.2616e-02,  6.6326e-03, -1.1201e-01, -1.1312e-01,\n          1.6874e-01,  1.6644e-01],\n        [ 9.6480e-02, -3.2454e-03, -1.6353e-01,  1.3726e-01,  1.1441e-01,\n         -3.6333e-03,  1.0036e-01, -5.3778e-02, -1.6687e-01, -1.1326e-01,\n         -1.0377e-01, -3.4196e-02,  8.5986e-02,  3.0122e-02, -1.4418e-01,\n          1.1501e-01, -7.2557e-02, -2.2252e-03, -7.6373e-02, -1.5703e-01,\n          1.7440e-01,  1.4207e-01, -3.2271e-03, -1.6194e-01, -5.4371e-02,\n         -1.1939e-01,  1.1794e-02, -3.7548e-02, -5.8517e-02,  1.4335e-01,\n         -4.0060e-02, -1.5299e-02],\n        [-5.2453e-02,  4.3081e-02,  9.7895e-02, -1.3368e-01,  1.0244e-01,\n          9.6582e-02, -9.7072e-03, -3.8958e-03,  4.8973e-02,  7.3830e-02,\n         -3.3513e-02, -8.1744e-03, -1.1170e-01,  1.5315e-01,  4.3826e-02,\n         -1.5656e-01, -8.8388e-02, -6.0285e-02, -1.1588e-01, -4.9839e-02,\n          2.1705e-03, -7.3366e-02,  4.3787e-02, -9.7626e-02,  9.8790e-02,\n          1.7262e-01,  7.9544e-02, -6.6320e-03, -6.5748e-02, -1.0552e-01,\n         -1.7389e-01, -2.1542e-02],\n        [ 1.3354e-01,  5.0573e-02,  4.6959e-02,  1.3072e-01, -9.9303e-02,\n         -4.6155e-02, -7.5537e-02,  1.3042e-01,  1.2120e-01,  1.7089e-01,\n          1.4249e-01,  1.0159e-01,  7.5930e-02,  1.7947e-02, -1.6069e-01,\n          4.0454e-02,  1.4148e-01, -1.0193e-01,  7.7459e-02, -3.0028e-02,\n         -7.7904e-02, -3.1010e-02,  6.9236e-02,  1.0901e-01, -3.2481e-02,\n          1.5038e-01,  2.6350e-02,  1.6005e-02,  3.3119e-02, -1.0873e-01,\n          6.6156e-02,  9.3881e-02],\n        [-6.7759e-02,  5.2247e-02, -6.5328e-03, -3.7185e-02, -1.9428e-02,\n         -1.3924e-01, -5.6414e-03,  1.1261e-01, -1.1500e-01,  3.9576e-02,\n          1.3500e-01, -4.5646e-02,  4.1245e-02, -4.1790e-02,  1.0665e-01,\n         -1.2525e-01, -8.0552e-02, -5.2596e-02, -9.0462e-02,  3.4370e-02,\n          1.2151e-02, -1.4797e-01, -8.1736e-03,  1.3906e-01,  1.4690e-01,\n         -1.3575e-01, -1.0318e-01, -1.5189e-01, -2.6002e-02, -2.6138e-02,\n          1.8343e-02,  3.6535e-03],\n        [-1.3946e-01,  1.4567e-01,  1.4800e-01, -1.6137e-01,  1.1737e-01,\n         -9.5232e-02, -1.0963e-01, -8.2913e-02,  7.0739e-02, -8.8229e-03,\n         -5.8955e-02, -8.4781e-02, -4.5450e-02, -3.7627e-02,  8.1353e-03,\n         -6.1541e-02,  6.0803e-02,  4.4101e-02, -3.9121e-02, -5.7675e-02,\n          9.4296e-02,  3.4771e-02, -4.8231e-02, -3.7204e-02, -6.7514e-02,\n          1.2935e-01, -2.5414e-02,  5.9997e-03, -1.1739e-02, -1.6605e-01,\n          7.7840e-02, -7.8568e-03],\n        [-1.2998e-01, -8.7167e-02, -7.7603e-02,  2.6327e-02,  1.3248e-01,\n          1.5813e-01, -1.5942e-01,  2.3937e-02, -1.0675e-01,  4.4786e-02,\n         -1.3559e-01,  6.7552e-02,  1.2207e-01,  1.6874e-01, -1.4514e-01,\n          1.5831e-01,  1.7576e-02, -8.8775e-02,  1.6416e-01,  4.7437e-02,\n          6.4773e-02, -7.9177e-02, -9.2837e-02, -9.1917e-02,  1.3850e-02,\n         -1.3483e-01, -9.1897e-02,  1.3729e-01, -1.1774e-01, -3.6536e-02,\n         -1.6949e-01, -8.4878e-02],\n        [ 8.3769e-02, -2.6096e-02, -1.1642e-01,  1.4409e-01, -1.6912e-01,\n          7.1837e-02, -7.1295e-03, -8.8752e-02, -1.5270e-04, -7.5127e-02,\n          1.0437e-01,  1.4118e-01,  2.0628e-02, -1.0144e-02, -1.7285e-01,\n          2.6795e-02, -1.0548e-01,  6.7946e-02, -1.2013e-01, -9.0129e-02,\n         -1.7531e-01,  1.1348e-01,  1.6544e-01, -7.4951e-02, -1.6417e-01,\n          1.7630e-01,  1.7331e-01, -4.2560e-03,  6.9896e-02, -3.2066e-02,\n          1.0605e-01, -4.8280e-02],\n        [ 1.2388e-01,  1.6293e-01,  4.2094e-02,  1.3440e-01,  1.7469e-01,\n         -1.5906e-01,  9.2223e-02, -7.1856e-02,  1.5096e-01, -5.9471e-02,\n          1.4619e-01,  3.8533e-02,  2.3950e-02, -1.5877e-01, -1.6587e-01,\n          1.5238e-01, -1.3293e-01, -4.9042e-02,  5.6901e-02, -1.4572e-01,\n         -8.2833e-02,  6.3131e-02,  1.1996e-01,  3.7861e-02, -5.9390e-02,\n          6.7563e-02,  1.1845e-01, -8.5194e-02, -1.6143e-01, -4.5853e-02,\n         -2.4152e-02, -8.0005e-02],\n        [ 8.8404e-02, -1.5291e-02,  4.5839e-02,  8.9150e-02,  1.8194e-02,\n         -1.8057e-02,  8.9121e-02,  1.2895e-01,  7.0263e-02,  9.6807e-02,\n          2.7997e-02,  1.6971e-01, -1.1236e-01,  1.2196e-01, -1.2809e-01,\n         -6.2195e-02, -1.3354e-01,  1.0148e-01,  4.3609e-02, -8.7330e-02,\n          1.5503e-01,  9.0615e-02, -1.6486e-01, -1.0659e-01,  1.2232e-01,\n          6.7802e-02, -8.7827e-02, -4.2107e-02, -3.5076e-02,  8.1697e-03,\n         -8.9423e-02,  1.4830e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1033,  0.0494,  0.0626, -0.1508, -0.0437,  0.0234,  0.0159, -0.0280,\n         0.1549, -0.1251,  0.0085, -0.0139,  0.0721, -0.0728, -0.1019, -0.0014],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0407, -0.1624, -0.0683,  0.0598, -0.0978,  0.2279, -0.1769, -0.0551,\n         -0.0246,  0.2249, -0.2340,  0.0992,  0.1227, -0.0029,  0.0250,  0.0195],\n        [ 0.2286,  0.1004, -0.1778,  0.1085,  0.0199, -0.1626, -0.1651, -0.1705,\n          0.1597,  0.0692,  0.1488, -0.0806,  0.0919, -0.1407, -0.1034, -0.2280],\n        [ 0.0183, -0.0030,  0.0120, -0.2012,  0.0575, -0.0192,  0.1374, -0.0503,\n         -0.1857,  0.0098, -0.1998, -0.0423, -0.2355,  0.0966, -0.2011, -0.1136],\n        [ 0.2431, -0.1242,  0.0451, -0.2063,  0.2319,  0.2499,  0.0509, -0.0235,\n          0.2308, -0.0610,  0.1662,  0.0388, -0.1608, -0.1936, -0.2079, -0.0288],\n        [-0.1379, -0.2407,  0.0268, -0.1379,  0.0680,  0.1288,  0.2115, -0.1400,\n         -0.0493,  0.2046, -0.0499, -0.1543,  0.1085,  0.0979,  0.0768, -0.0503],\n        [ 0.0104, -0.0397, -0.1759,  0.0782,  0.0682, -0.2439, -0.0075,  0.1276,\n         -0.0644,  0.1957,  0.0700, -0.0152, -0.0529, -0.2060,  0.0323,  0.1853],\n        [ 0.1735,  0.0346, -0.1689,  0.2086,  0.0691, -0.2361,  0.1474, -0.0538,\n         -0.0118,  0.0887, -0.1972, -0.2144, -0.0251,  0.1230,  0.0259,  0.2048],\n        [-0.1509,  0.1906, -0.0516, -0.0767, -0.0170,  0.0183, -0.0727,  0.2009,\n          0.1101,  0.2171,  0.1757, -0.0789, -0.2208, -0.0825, -0.1123,  0.2237]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0670,  0.2073,  0.1694, -0.0731, -0.1037, -0.1234, -0.0342,  0.2330],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3449,  0.0593,  0.1502, -0.2564,  0.2860,  0.2031,  0.1830, -0.0950],\n        [ 0.0617, -0.1636,  0.3159,  0.3526, -0.1642, -0.1455, -0.0272, -0.3189],\n        [-0.1067,  0.0182, -0.1230,  0.0535, -0.2648,  0.2046,  0.2148, -0.0819],\n        [ 0.1621,  0.3532,  0.3203,  0.2319,  0.0604,  0.2090, -0.1610, -0.2899]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0159,  0.1590,  0.0962,  0.1405], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x752806dc6e50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1444, -0.2816, -0.0689, -0.0642,  0.1921,  0.1317,  0.2368, -0.1638,\n        -0.1067,  0.1300,  0.3167, -0.0926, -0.2322, -0.0753,  0.2971, -0.0855,\n        -0.1318,  0.2158,  0.3322, -0.2840, -0.3304, -0.1217,  0.1863, -0.3237,\n         0.0624,  0.1743,  0.3521, -0.2439, -0.1278, -0.2533,  0.0726,  0.3130],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2020,  0.1032, -0.0609,  0.1640,  0.0529, -0.3519, -0.1818, -0.1278],\n        [ 0.1582,  0.0695, -0.0535, -0.3316, -0.2062,  0.0571,  0.0952,  0.0480],\n        [ 0.3479, -0.1003, -0.0798,  0.1981,  0.2691,  0.1035,  0.0480, -0.0203],\n        [ 0.0589,  0.3374,  0.0136, -0.0441, -0.0636, -0.0097,  0.1025, -0.1333],\n        [ 0.2502, -0.2443,  0.1127,  0.2476,  0.1350, -0.3119,  0.2533,  0.0587],\n        [-0.2569, -0.3066, -0.1966, -0.0792,  0.0773,  0.1152,  0.1113,  0.3080],\n        [-0.2933, -0.3206,  0.2630,  0.1820, -0.2266, -0.1692, -0.2222,  0.1891],\n        [-0.1607, -0.3129,  0.0790, -0.1957, -0.2328, -0.2554,  0.1077, -0.3118],\n        [ 0.1621,  0.1294,  0.0151,  0.0778, -0.1156, -0.2006,  0.1480, -0.1085],\n        [-0.2892, -0.1188, -0.1476,  0.1997,  0.2590, -0.2644,  0.3361, -0.3462],\n        [-0.2778,  0.2848, -0.3494, -0.3299, -0.0756, -0.0365, -0.0808, -0.2002],\n        [-0.1744,  0.1629, -0.3483, -0.1121, -0.1550,  0.1863,  0.2943,  0.1641],\n        [-0.3157,  0.2658, -0.0489,  0.2196,  0.0787,  0.1594, -0.1977,  0.2706],\n        [ 0.0151, -0.0783,  0.1818, -0.0255,  0.3303, -0.3035,  0.3334, -0.2041],\n        [ 0.2539,  0.0220, -0.3225, -0.2230, -0.0634,  0.1325,  0.1866, -0.2378],\n        [-0.2921,  0.0848, -0.2135, -0.0555,  0.0275,  0.2558,  0.2325, -0.2560],\n        [-0.1999,  0.0468, -0.2567, -0.2916, -0.3433,  0.1193, -0.1167,  0.2705],\n        [ 0.1335,  0.2336, -0.3092, -0.1670,  0.0831,  0.2323, -0.1946, -0.1011],\n        [-0.2072,  0.0315,  0.0236,  0.2149,  0.1737, -0.2003,  0.0048,  0.0809],\n        [ 0.2291, -0.0184,  0.3038, -0.0233,  0.1086,  0.0828, -0.3111, -0.3212],\n        [-0.2920, -0.1246, -0.0408,  0.2049,  0.0126, -0.1655, -0.2239, -0.2083],\n        [ 0.0256, -0.2431, -0.2583, -0.3156,  0.3089,  0.1871, -0.0718, -0.1700],\n        [ 0.0006, -0.0060, -0.3060,  0.2882,  0.3203,  0.3380,  0.1774, -0.2323],\n        [ 0.0833,  0.3133,  0.0296, -0.1415, -0.2102,  0.1558,  0.1848, -0.2650],\n        [ 0.2518,  0.2322,  0.2037,  0.2580,  0.2807,  0.1891, -0.2453,  0.2168],\n        [ 0.2379,  0.0900,  0.1205,  0.3524, -0.2234,  0.0207, -0.2915, -0.1673],\n        [ 0.2499,  0.2839,  0.2136, -0.3025, -0.0007,  0.0837, -0.1389,  0.0423],\n        [ 0.0319,  0.2666,  0.0091, -0.2129,  0.0211, -0.0926,  0.1440,  0.2161],\n        [ 0.1656, -0.1406,  0.1709, -0.0054, -0.1940,  0.2434, -0.1242,  0.2198],\n        [ 0.1714,  0.0572, -0.2043,  0.3398, -0.0739,  0.1263,  0.0781,  0.3261],\n        [ 0.2662,  0.3041,  0.0907,  0.1554,  0.2194, -0.3507, -0.2642, -0.1117],\n        [ 0.0991,  0.0076,  0.0659,  0.3266, -0.2578, -0.2258,  0.2282,  0.2761]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1033,  0.0494,  0.0626, -0.1508, -0.0437,  0.0234,  0.0159, -0.0280,\n         0.1549, -0.1251,  0.0085, -0.0139,  0.0721, -0.0728, -0.1019, -0.0014],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.7291e-01,  4.9913e-02,  1.1325e-01,  1.8636e-03,  2.2517e-02,\n          3.4888e-02,  1.4740e-01,  1.0076e-01, -1.5632e-01, -2.1240e-02,\n          1.4235e-01, -1.1558e-01, -1.5241e-01, -6.6463e-02, -1.6374e-03,\n         -1.2060e-01,  1.0759e-02, -4.0620e-02, -5.3431e-02, -5.9220e-02,\n         -8.3322e-02, -5.6065e-02, -7.0856e-02,  1.4425e-01,  1.0627e-01,\n          5.6370e-02, -1.0465e-01,  6.6382e-02, -1.5643e-03, -1.3357e-01,\n          7.0589e-02,  4.5323e-02],\n        [-9.5644e-02, -1.4898e-01, -5.5077e-02,  1.2118e-02, -7.6960e-02,\n         -1.3718e-01,  1.4605e-01,  1.3850e-01, -1.1418e-01,  6.2328e-02,\n          2.9125e-02,  1.4520e-01, -1.5943e-01,  3.3786e-03, -1.5588e-01,\n          1.0403e-01, -5.6819e-02, -1.8891e-02,  1.6088e-01, -1.1029e-01,\n         -1.7047e-01,  1.3818e-01,  1.2611e-01,  1.0365e-01,  4.1376e-02,\n          3.9743e-02, -1.2407e-01,  1.7191e-01,  1.2385e-01, -1.0985e-01,\n          8.8098e-02,  1.1270e-01],\n        [ 1.2588e-01, -5.4282e-03,  6.0471e-02, -3.0155e-02, -1.1667e-01,\n          1.5291e-01,  8.2349e-02,  7.9883e-02, -6.1957e-02, -3.0897e-02,\n         -8.6533e-02, -1.7207e-01, -1.5050e-01,  8.5949e-02, -3.6826e-02,\n          8.5562e-02,  7.3819e-02,  9.2375e-02,  1.2235e-01, -2.8101e-02,\n         -4.3172e-02,  4.1574e-02, -2.8359e-02, -9.4960e-02,  1.7320e-01,\n         -1.5340e-01,  1.0400e-01,  9.5849e-02,  2.2825e-02,  9.9605e-02,\n         -1.3037e-01,  1.4584e-01],\n        [-1.6385e-01,  1.6991e-01, -5.5121e-02,  8.4279e-02, -5.9473e-02,\n         -1.2452e-01,  1.5600e-01,  4.1685e-02,  6.4434e-02, -1.2630e-01,\n          1.6785e-01,  5.0109e-02,  9.4229e-02,  1.4992e-01,  1.0548e-01,\n         -1.6077e-02,  4.0265e-02, -6.1069e-02, -1.2166e-01,  4.1860e-02,\n          2.5213e-02, -4.1652e-03,  9.1648e-02, -1.1632e-01, -2.4017e-02,\n          4.2794e-02, -9.2659e-02,  9.4345e-02,  1.5238e-02,  1.1935e-01,\n          6.7804e-02,  6.1131e-02],\n        [-5.5836e-02, -2.4904e-03, -4.5115e-02, -5.2314e-02, -4.9689e-02,\n          1.5264e-01,  4.4489e-02,  9.1400e-02, -1.5548e-01,  8.1763e-02,\n         -8.8202e-03, -1.5279e-02,  1.0798e-01, -1.7241e-01, -1.6662e-01,\n         -8.6732e-02, -2.7079e-02,  1.3644e-01,  1.5609e-01, -1.1806e-01,\n         -7.5350e-02, -1.4470e-01, -1.3510e-01, -3.6436e-02, -5.7262e-02,\n         -1.3670e-01,  1.3302e-01, -4.0947e-02, -3.1007e-02,  1.2313e-01,\n         -8.6668e-02, -7.0586e-02],\n        [ 1.2618e-02,  6.1674e-02,  7.4193e-02,  1.0873e-01,  7.5334e-02,\n          8.8463e-02,  9.8119e-02,  7.2998e-02,  1.1354e-02,  1.3593e-01,\n         -4.1832e-02,  1.1615e-01, -1.5608e-01, -6.3270e-02, -9.5192e-02,\n         -3.4796e-02,  4.6434e-02,  9.2504e-02, -5.8951e-02,  8.3141e-02,\n          1.4854e-01,  3.0803e-02,  1.6529e-01,  3.4531e-02,  1.0077e-01,\n          1.1680e-01, -1.4685e-01, -1.3887e-01,  8.5657e-02,  6.4342e-02,\n         -1.4410e-01,  7.0825e-03],\n        [-1.4890e-01, -1.6169e-01, -1.7008e-01, -1.7776e-02, -9.4089e-02,\n          1.0166e-01,  4.4193e-02, -1.4155e-01,  1.0067e-01, -7.3086e-02,\n         -8.5009e-03,  1.5842e-01, -9.4956e-02,  1.0775e-01,  1.1244e-01,\n         -1.2450e-01, -7.5143e-03, -1.2697e-01,  9.9427e-02, -2.7322e-04,\n          1.3141e-01,  8.2545e-02,  1.0759e-02,  3.8448e-02, -3.3762e-02,\n          9.6221e-02,  8.2616e-02,  6.6326e-03, -1.1201e-01, -1.1312e-01,\n          1.6874e-01,  1.6644e-01],\n        [ 9.6480e-02, -3.2454e-03, -1.6353e-01,  1.3726e-01,  1.1441e-01,\n         -3.6333e-03,  1.0036e-01, -5.3778e-02, -1.6687e-01, -1.1326e-01,\n         -1.0377e-01, -3.4196e-02,  8.5986e-02,  3.0122e-02, -1.4418e-01,\n          1.1501e-01, -7.2557e-02, -2.2252e-03, -7.6373e-02, -1.5703e-01,\n          1.7440e-01,  1.4207e-01, -3.2271e-03, -1.6194e-01, -5.4371e-02,\n         -1.1939e-01,  1.1794e-02, -3.7548e-02, -5.8517e-02,  1.4335e-01,\n         -4.0060e-02, -1.5299e-02],\n        [-5.2453e-02,  4.3081e-02,  9.7895e-02, -1.3368e-01,  1.0244e-01,\n          9.6582e-02, -9.7072e-03, -3.8958e-03,  4.8973e-02,  7.3830e-02,\n         -3.3513e-02, -8.1744e-03, -1.1170e-01,  1.5315e-01,  4.3826e-02,\n         -1.5656e-01, -8.8388e-02, -6.0285e-02, -1.1588e-01, -4.9839e-02,\n          2.1705e-03, -7.3366e-02,  4.3787e-02, -9.7626e-02,  9.8790e-02,\n          1.7262e-01,  7.9544e-02, -6.6320e-03, -6.5748e-02, -1.0552e-01,\n         -1.7389e-01, -2.1542e-02],\n        [ 1.3354e-01,  5.0573e-02,  4.6959e-02,  1.3072e-01, -9.9303e-02,\n         -4.6155e-02, -7.5537e-02,  1.3042e-01,  1.2120e-01,  1.7089e-01,\n          1.4249e-01,  1.0159e-01,  7.5930e-02,  1.7947e-02, -1.6069e-01,\n          4.0454e-02,  1.4148e-01, -1.0193e-01,  7.7459e-02, -3.0028e-02,\n         -7.7904e-02, -3.1010e-02,  6.9236e-02,  1.0901e-01, -3.2481e-02,\n          1.5038e-01,  2.6350e-02,  1.6005e-02,  3.3119e-02, -1.0873e-01,\n          6.6156e-02,  9.3881e-02],\n        [-6.7759e-02,  5.2247e-02, -6.5328e-03, -3.7185e-02, -1.9428e-02,\n         -1.3924e-01, -5.6414e-03,  1.1261e-01, -1.1500e-01,  3.9576e-02,\n          1.3500e-01, -4.5646e-02,  4.1245e-02, -4.1790e-02,  1.0665e-01,\n         -1.2525e-01, -8.0552e-02, -5.2596e-02, -9.0462e-02,  3.4370e-02,\n          1.2151e-02, -1.4797e-01, -8.1736e-03,  1.3906e-01,  1.4690e-01,\n         -1.3575e-01, -1.0318e-01, -1.5189e-01, -2.6002e-02, -2.6138e-02,\n          1.8343e-02,  3.6535e-03],\n        [-1.3946e-01,  1.4567e-01,  1.4800e-01, -1.6137e-01,  1.1737e-01,\n         -9.5232e-02, -1.0963e-01, -8.2913e-02,  7.0739e-02, -8.8229e-03,\n         -5.8955e-02, -8.4781e-02, -4.5450e-02, -3.7627e-02,  8.1353e-03,\n         -6.1541e-02,  6.0803e-02,  4.4101e-02, -3.9121e-02, -5.7675e-02,\n          9.4296e-02,  3.4771e-02, -4.8231e-02, -3.7204e-02, -6.7514e-02,\n          1.2935e-01, -2.5414e-02,  5.9997e-03, -1.1739e-02, -1.6605e-01,\n          7.7840e-02, -7.8568e-03],\n        [-1.2998e-01, -8.7167e-02, -7.7603e-02,  2.6327e-02,  1.3248e-01,\n          1.5813e-01, -1.5942e-01,  2.3937e-02, -1.0675e-01,  4.4786e-02,\n         -1.3559e-01,  6.7552e-02,  1.2207e-01,  1.6874e-01, -1.4514e-01,\n          1.5831e-01,  1.7576e-02, -8.8775e-02,  1.6416e-01,  4.7437e-02,\n          6.4773e-02, -7.9177e-02, -9.2837e-02, -9.1917e-02,  1.3850e-02,\n         -1.3483e-01, -9.1897e-02,  1.3729e-01, -1.1774e-01, -3.6536e-02,\n         -1.6949e-01, -8.4878e-02],\n        [ 8.3769e-02, -2.6096e-02, -1.1642e-01,  1.4409e-01, -1.6912e-01,\n          7.1837e-02, -7.1295e-03, -8.8752e-02, -1.5270e-04, -7.5127e-02,\n          1.0437e-01,  1.4118e-01,  2.0628e-02, -1.0144e-02, -1.7285e-01,\n          2.6795e-02, -1.0548e-01,  6.7946e-02, -1.2013e-01, -9.0129e-02,\n         -1.7531e-01,  1.1348e-01,  1.6544e-01, -7.4951e-02, -1.6417e-01,\n          1.7630e-01,  1.7331e-01, -4.2560e-03,  6.9896e-02, -3.2066e-02,\n          1.0605e-01, -4.8280e-02],\n        [ 1.2388e-01,  1.6293e-01,  4.2094e-02,  1.3440e-01,  1.7469e-01,\n         -1.5906e-01,  9.2223e-02, -7.1856e-02,  1.5096e-01, -5.9471e-02,\n          1.4619e-01,  3.8533e-02,  2.3950e-02, -1.5877e-01, -1.6587e-01,\n          1.5238e-01, -1.3293e-01, -4.9042e-02,  5.6901e-02, -1.4572e-01,\n         -8.2833e-02,  6.3131e-02,  1.1996e-01,  3.7861e-02, -5.9390e-02,\n          6.7563e-02,  1.1845e-01, -8.5194e-02, -1.6143e-01, -4.5853e-02,\n         -2.4152e-02, -8.0005e-02],\n        [ 8.8404e-02, -1.5291e-02,  4.5839e-02,  8.9150e-02,  1.8194e-02,\n         -1.8057e-02,  8.9121e-02,  1.2895e-01,  7.0263e-02,  9.6807e-02,\n          2.7997e-02,  1.6971e-01, -1.1236e-01,  1.2196e-01, -1.2809e-01,\n         -6.2195e-02, -1.3354e-01,  1.0148e-01,  4.3609e-02, -8.7330e-02,\n          1.5503e-01,  9.0615e-02, -1.6486e-01, -1.0659e-01,  1.2232e-01,\n          6.7802e-02, -8.7827e-02, -4.2107e-02, -3.5076e-02,  8.1697e-03,\n         -8.9423e-02,  1.4830e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0670,  0.2073,  0.1694, -0.0731, -0.1037, -0.1234, -0.0342,  0.2330],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0407, -0.1624, -0.0683,  0.0598, -0.0978,  0.2279, -0.1769, -0.0551,\n         -0.0246,  0.2249, -0.2340,  0.0992,  0.1227, -0.0029,  0.0250,  0.0195],\n        [ 0.2286,  0.1004, -0.1778,  0.1085,  0.0199, -0.1626, -0.1651, -0.1705,\n          0.1597,  0.0692,  0.1488, -0.0806,  0.0919, -0.1407, -0.1034, -0.2280],\n        [ 0.0183, -0.0030,  0.0120, -0.2012,  0.0575, -0.0192,  0.1374, -0.0503,\n         -0.1857,  0.0098, -0.1998, -0.0423, -0.2355,  0.0966, -0.2011, -0.1136],\n        [ 0.2431, -0.1242,  0.0451, -0.2063,  0.2319,  0.2499,  0.0509, -0.0235,\n          0.2308, -0.0610,  0.1662,  0.0388, -0.1608, -0.1936, -0.2079, -0.0288],\n        [-0.1379, -0.2407,  0.0268, -0.1379,  0.0680,  0.1288,  0.2115, -0.1400,\n         -0.0493,  0.2046, -0.0499, -0.1543,  0.1085,  0.0979,  0.0768, -0.0503],\n        [ 0.0104, -0.0397, -0.1759,  0.0782,  0.0682, -0.2439, -0.0075,  0.1276,\n         -0.0644,  0.1957,  0.0700, -0.0152, -0.0529, -0.2060,  0.0323,  0.1853],\n        [ 0.1735,  0.0346, -0.1689,  0.2086,  0.0691, -0.2361,  0.1474, -0.0538,\n         -0.0118,  0.0887, -0.1972, -0.2144, -0.0251,  0.1230,  0.0259,  0.2048],\n        [-0.1509,  0.1906, -0.0516, -0.0767, -0.0170,  0.0183, -0.0727,  0.2009,\n          0.1101,  0.2171,  0.1757, -0.0789, -0.2208, -0.0825, -0.1123,  0.2237]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0159,  0.1590,  0.0962,  0.1405], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3449,  0.0593,  0.1502, -0.2564,  0.2860,  0.2031,  0.1830, -0.0950],\n        [ 0.0617, -0.1636,  0.3159,  0.3526, -0.1642, -0.1455, -0.0272, -0.3189],\n        [-0.1067,  0.0182, -0.1230,  0.0535, -0.2648,  0.2046,  0.2148, -0.0819],\n        [ 0.1621,  0.3532,  0.3203,  0.2319,  0.0604,  0.2090, -0.1610, -0.2899]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x75278b1ba750>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s686510000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s686510000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}