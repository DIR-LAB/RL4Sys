{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	4,
    "batch_size":	60,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0007,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s689630000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0005,
    "sample_decay":	0.5,
    "seed":	689630000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7dc3f968ec10>":	{
            "_act_dim":	4,
            "_aux_batch_size":	4,
            "_batch_size":	60,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0007,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3269, -0.1038,  0.2448,  0.3392,  0.2116,  0.3530, -0.0835,  0.2147,\n        -0.2863,  0.3202,  0.2067,  0.0970,  0.3000, -0.1009, -0.0375,  0.0022,\n         0.2824,  0.1574,  0.1726,  0.1831,  0.0339,  0.3027, -0.1381, -0.2887,\n         0.0993,  0.0286,  0.0506, -0.2150, -0.0443, -0.1770,  0.3399, -0.3224,\n         0.2035, -0.1119, -0.1238,  0.1795,  0.2590,  0.1241,  0.3496, -0.0311,\n        -0.0671,  0.2544, -0.0742, -0.1686,  0.0394,  0.3501,  0.3356, -0.2263,\n        -0.2274,  0.3189,  0.1810, -0.0240,  0.2523,  0.3151,  0.1104,  0.3360,\n        -0.2743,  0.2935, -0.3253, -0.3416,  0.1141,  0.1240, -0.1237, -0.2446,\n         0.0992, -0.2013, -0.3080,  0.2544,  0.1640, -0.0630, -0.0309, -0.3105,\n         0.0080, -0.3183,  0.0518,  0.2276, -0.2894,  0.2435, -0.0258,  0.1822,\n        -0.2393,  0.0236,  0.2806,  0.1491,  0.0385,  0.3357, -0.0154,  0.2083,\n        -0.2554, -0.0260,  0.0773, -0.3192, -0.0564, -0.1492, -0.0324,  0.1154,\n        -0.0495, -0.2984, -0.2389, -0.0526,  0.3218, -0.3193,  0.1725, -0.0745,\n         0.1274,  0.2287,  0.2687, -0.2121, -0.3017,  0.1352,  0.2726, -0.2024,\n        -0.1277,  0.1608, -0.1632,  0.0536,  0.3008,  0.1382, -0.3162, -0.2321,\n        -0.0916, -0.0680, -0.2078, -0.2151,  0.2233, -0.1251,  0.1421, -0.0309],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2924, -0.2418, -0.0114,  ..., -0.2116,  0.2324,  0.1244],\n        [-0.0849,  0.1232, -0.2255,  ..., -0.0169,  0.3389, -0.0138],\n        [-0.0408,  0.1581, -0.3370,  ..., -0.0261, -0.0020,  0.2297],\n        ...,\n        [ 0.2094,  0.0249, -0.1378,  ..., -0.2564, -0.0364,  0.1010],\n        [-0.2993, -0.2500,  0.0265,  ...,  0.1137, -0.1550,  0.0366],\n        [-0.2695,  0.0118, -0.2670,  ..., -0.0883,  0.0067, -0.1926]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0459, -0.0368, -0.0414,  0.0697,  0.0337,  0.0143,  0.0344,  0.0162,\n        -0.0336, -0.0246,  0.0198, -0.0046,  0.0664,  0.0701,  0.0398,  0.0567,\n        -0.0843, -0.0387,  0.0406,  0.0054,  0.0368, -0.0734, -0.0759,  0.0030,\n         0.0476,  0.0018, -0.0384,  0.0814, -0.0123, -0.0413,  0.0351, -0.0426,\n        -0.0841,  0.0662, -0.0705, -0.0277, -0.0379,  0.0088,  0.0854,  0.0164,\n         0.0237, -0.0106, -0.0342, -0.0561, -0.0472,  0.0644, -0.0709, -0.0872,\n        -0.0651, -0.0735,  0.0820, -0.0225,  0.0209,  0.0458,  0.0673, -0.0211,\n         0.0682, -0.0542,  0.0315, -0.0638,  0.0720,  0.0127, -0.0543,  0.0736,\n        -0.0732, -0.0535,  0.0014, -0.0086,  0.0688, -0.0640, -0.0359,  0.0727,\n         0.0171, -0.0183, -0.0649,  0.0155,  0.0200,  0.0717, -0.0780, -0.0707,\n         0.0454,  0.0098,  0.0474, -0.0367, -0.0570,  0.0722,  0.0449, -0.0523,\n        -0.0049, -0.0514,  0.0566,  0.0724, -0.0146,  0.0632,  0.0426, -0.0037,\n         0.0717, -0.0193,  0.0364,  0.0092,  0.0829, -0.0813, -0.0873,  0.0807,\n         0.0735, -0.0348, -0.0864,  0.0434, -0.0617,  0.0795,  0.0649,  0.0544,\n        -0.0674, -0.0330,  0.0813,  0.0006, -0.0628, -0.0631,  0.0453,  0.0830,\n         0.0685,  0.0551,  0.0366,  0.0347,  0.0277,  0.0600,  0.0770,  0.0382],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0590, -0.0211, -0.0431,  ...,  0.0198,  0.0759, -0.0322],\n        [ 0.0547, -0.0435,  0.0644,  ..., -0.0413, -0.0576,  0.0046],\n        [ 0.0193,  0.0442, -0.0767,  ...,  0.0550, -0.0285,  0.0376],\n        ...,\n        [-0.0437,  0.0430, -0.0219,  ..., -0.0838, -0.0850,  0.0553],\n        [ 0.0680, -0.0130,  0.0133,  ..., -0.0354,  0.0112, -0.0620],\n        [-0.0170, -0.0109,  0.0255,  ...,  0.0861,  0.0299, -0.0546]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0082, -0.0087,  0.0025,  0.0708], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0615, -0.0276,  0.0614,  0.0408,  0.0752, -0.0735,  0.0434,  0.0495,\n         -0.0620,  0.0476,  0.0819, -0.0649,  0.0235,  0.0799,  0.0115, -0.0730,\n          0.0448, -0.0184, -0.0331, -0.0456,  0.0331,  0.0307,  0.0771, -0.0056,\n          0.0784, -0.0506,  0.0010,  0.0238, -0.0795, -0.0145, -0.0678,  0.0093,\n          0.0027, -0.0191,  0.0752,  0.0120, -0.0615,  0.0608, -0.0119,  0.0322,\n         -0.0607,  0.0740, -0.0774,  0.0806, -0.0773,  0.0090, -0.0194,  0.0271,\n          0.0804, -0.0049,  0.0828, -0.0260, -0.0698,  0.0200,  0.0384, -0.0390,\n         -0.0592, -0.0007,  0.0843, -0.0608,  0.0474,  0.0797,  0.0835, -0.0492,\n         -0.0255, -0.0854,  0.0670, -0.0420, -0.0758, -0.0825, -0.0649,  0.0738,\n         -0.0484,  0.0883, -0.0206, -0.0020, -0.0774, -0.0231, -0.0204, -0.0451,\n         -0.0832,  0.0341, -0.0338, -0.0285,  0.0064,  0.0323,  0.0230, -0.0394,\n         -0.0332,  0.0035,  0.0792,  0.0320, -0.0726, -0.0480,  0.0218, -0.0550,\n         -0.0651,  0.0106, -0.0783,  0.0335, -0.0190,  0.0231,  0.0057, -0.0566,\n          0.0452, -0.0171, -0.0260,  0.0749, -0.0051, -0.0094,  0.0199, -0.0651,\n          0.0308,  0.0855,  0.0093,  0.0671, -0.0741, -0.0230,  0.0454, -0.0575,\n          0.0358, -0.0539,  0.0263, -0.0695,  0.0739,  0.0347,  0.0503, -0.0249],\n        [ 0.0210, -0.0431,  0.0074, -0.0727, -0.0667,  0.0225,  0.0864, -0.0346,\n         -0.0017,  0.0458,  0.0524, -0.0835, -0.0637,  0.0563, -0.0861,  0.0122,\n          0.0806,  0.0783, -0.0662,  0.0086, -0.0054, -0.0069, -0.0434, -0.0808,\n          0.0580, -0.0129,  0.0328,  0.0779, -0.0448, -0.0735,  0.0185, -0.0275,\n          0.0597, -0.0062, -0.0239,  0.0877,  0.0086, -0.0189,  0.0219,  0.0228,\n         -0.0242,  0.0103, -0.0731, -0.0824,  0.0816,  0.0771, -0.0717, -0.0517,\n         -0.0473, -0.0216, -0.0721,  0.0759, -0.0402,  0.0318, -0.0444,  0.0573,\n         -0.0149,  0.0689,  0.0525,  0.0482, -0.0306,  0.0785,  0.0148, -0.0237,\n          0.0308, -0.0164,  0.0365,  0.0291, -0.0726, -0.0352,  0.0574,  0.0052,\n          0.0188,  0.0225, -0.0216,  0.0653, -0.0292, -0.0525,  0.0060, -0.0460,\n         -0.0066, -0.0880, -0.0838, -0.0703, -0.0578,  0.0262,  0.0311,  0.0847,\n         -0.0118,  0.0006, -0.0313, -0.0684,  0.0152,  0.0636, -0.0315, -0.0551,\n          0.0366, -0.0120,  0.0356, -0.0248, -0.0189, -0.0613,  0.0501, -0.0608,\n         -0.0083, -0.0319, -0.0600, -0.0177, -0.0510, -0.0048, -0.0320, -0.0568,\n         -0.0279, -0.0413, -0.0251,  0.0256,  0.0130, -0.0836, -0.0440, -0.0883,\n          0.0805, -0.0555,  0.0236, -0.0774,  0.0262, -0.0208,  0.0063,  0.0792],\n        [ 0.0106, -0.0655,  0.0713, -0.0728, -0.0003,  0.0277, -0.0209, -0.0026,\n          0.0441,  0.0733,  0.0234,  0.0788, -0.0378,  0.0004, -0.0037,  0.0034,\n         -0.0280, -0.0590, -0.0150,  0.0108,  0.0757, -0.0544,  0.0690,  0.0367,\n          0.0300,  0.0693, -0.0310, -0.0395,  0.0320,  0.0600,  0.0532, -0.0659,\n          0.0509,  0.0255,  0.0670,  0.0328, -0.0240,  0.0053, -0.0530,  0.0338,\n         -0.0715,  0.0507, -0.0582, -0.0531, -0.0786, -0.0634, -0.0807, -0.0534,\n         -0.0456,  0.0882,  0.0448,  0.0777,  0.0799,  0.0573,  0.0019,  0.0171,\n         -0.0612, -0.0276,  0.0157,  0.0691, -0.0147,  0.0501, -0.0201,  0.0169,\n          0.0268,  0.0733,  0.0082,  0.0686, -0.0070, -0.0215,  0.0164,  0.0832,\n         -0.0596, -0.0856, -0.0489,  0.0867,  0.0804,  0.0556,  0.0040, -0.0230,\n         -0.0765, -0.0569,  0.0209,  0.0040,  0.0469, -0.0187,  0.0414, -0.0237,\n         -0.0874,  0.0345,  0.0694,  0.0097, -0.0827,  0.0696,  0.0522, -0.0158,\n          0.0389, -0.0764, -0.0732, -0.0580,  0.0495,  0.0566,  0.0679,  0.0103,\n         -0.0786,  0.0324,  0.0380, -0.0287,  0.0684,  0.0642,  0.0578, -0.0301,\n          0.0613, -0.0633, -0.0326, -0.0158,  0.0049, -0.0529,  0.0135, -0.0602,\n         -0.0645,  0.0748, -0.0871,  0.0088,  0.0020,  0.0464,  0.0391, -0.0441],\n        [ 0.0644,  0.0449, -0.0785, -0.0536,  0.0282,  0.0580,  0.0551,  0.0708,\n          0.0644, -0.0225,  0.0087,  0.0378,  0.0272, -0.0099,  0.0687, -0.0847,\n         -0.0406,  0.0692,  0.0545, -0.0798, -0.0614, -0.0645, -0.0122, -0.0419,\n         -0.0439, -0.0221,  0.0850,  0.0348,  0.0709,  0.0471,  0.0368, -0.0309,\n          0.0002,  0.0268, -0.0076, -0.0115, -0.0210,  0.0494, -0.0179,  0.0470,\n          0.0082,  0.0008, -0.0434, -0.0774,  0.0349, -0.0124, -0.0282, -0.0366,\n         -0.0134, -0.0876, -0.0752, -0.0137, -0.0798,  0.0020, -0.0249, -0.0022,\n         -0.0251,  0.0343,  0.0646, -0.0453,  0.0298,  0.0238, -0.0249, -0.0602,\n          0.0691, -0.0827, -0.0347, -0.0523,  0.0360,  0.0747,  0.0439,  0.0309,\n          0.0071,  0.0178,  0.0706, -0.0122,  0.0520,  0.0106,  0.0859, -0.0790,\n          0.0258,  0.0031,  0.0493,  0.0557, -0.0382,  0.0764,  0.0337,  0.0327,\n          0.0563, -0.0267,  0.0683, -0.0108, -0.0236,  0.0042, -0.0331,  0.0585,\n          0.0794, -0.0414,  0.0725, -0.0093, -0.0842,  0.0664,  0.0001, -0.0077,\n         -0.0170,  0.0534, -0.0138,  0.0611, -0.0811, -0.0644, -0.0546, -0.0234,\n         -0.0394, -0.0812,  0.0113,  0.0392, -0.0684,  0.0699,  0.0829, -0.0693,\n         -0.0697, -0.0408, -0.0134,  0.0405, -0.0675, -0.0759, -0.0143,  0.0247]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2924, -0.2418, -0.0114,  ..., -0.2116,  0.2324,  0.1244],\n        [-0.0849,  0.1232, -0.2255,  ..., -0.0169,  0.3389, -0.0138],\n        [-0.0408,  0.1581, -0.3370,  ..., -0.0261, -0.0020,  0.2297],\n        ...,\n        [ 0.2094,  0.0249, -0.1378,  ..., -0.2564, -0.0364,  0.1010],\n        [-0.2993, -0.2500,  0.0265,  ...,  0.1137, -0.1550,  0.0366],\n        [-0.2695,  0.0118, -0.2670,  ..., -0.0883,  0.0067, -0.1926]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3269, -0.1038,  0.2448,  0.3392,  0.2116,  0.3530, -0.0835,  0.2147,\n        -0.2863,  0.3202,  0.2067,  0.0970,  0.3000, -0.1009, -0.0375,  0.0022,\n         0.2824,  0.1574,  0.1726,  0.1831,  0.0339,  0.3027, -0.1381, -0.2887,\n         0.0993,  0.0286,  0.0506, -0.2150, -0.0443, -0.1770,  0.3399, -0.3224,\n         0.2035, -0.1119, -0.1238,  0.1795,  0.2590,  0.1241,  0.3496, -0.0311,\n        -0.0671,  0.2544, -0.0742, -0.1686,  0.0394,  0.3501,  0.3356, -0.2263,\n        -0.2274,  0.3189,  0.1810, -0.0240,  0.2523,  0.3151,  0.1104,  0.3360,\n        -0.2743,  0.2935, -0.3253, -0.3416,  0.1141,  0.1240, -0.1237, -0.2446,\n         0.0992, -0.2013, -0.3080,  0.2544,  0.1640, -0.0630, -0.0309, -0.3105,\n         0.0080, -0.3183,  0.0518,  0.2276, -0.2894,  0.2435, -0.0258,  0.1822,\n        -0.2393,  0.0236,  0.2806,  0.1491,  0.0385,  0.3357, -0.0154,  0.2083,\n        -0.2554, -0.0260,  0.0773, -0.3192, -0.0564, -0.1492, -0.0324,  0.1154,\n        -0.0495, -0.2984, -0.2389, -0.0526,  0.3218, -0.3193,  0.1725, -0.0745,\n         0.1274,  0.2287,  0.2687, -0.2121, -0.3017,  0.1352,  0.2726, -0.2024,\n        -0.1277,  0.1608, -0.1632,  0.0536,  0.3008,  0.1382, -0.3162, -0.2321,\n        -0.0916, -0.0680, -0.2078, -0.2151,  0.2233, -0.1251,  0.1421, -0.0309],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0590, -0.0211, -0.0431,  ...,  0.0198,  0.0759, -0.0322],\n        [ 0.0547, -0.0435,  0.0644,  ..., -0.0413, -0.0576,  0.0046],\n        [ 0.0193,  0.0442, -0.0767,  ...,  0.0550, -0.0285,  0.0376],\n        ...,\n        [-0.0437,  0.0430, -0.0219,  ..., -0.0838, -0.0850,  0.0553],\n        [ 0.0680, -0.0130,  0.0133,  ..., -0.0354,  0.0112, -0.0620],\n        [-0.0170, -0.0109,  0.0255,  ...,  0.0861,  0.0299, -0.0546]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0459, -0.0368, -0.0414,  0.0697,  0.0337,  0.0143,  0.0344,  0.0162,\n        -0.0336, -0.0246,  0.0198, -0.0046,  0.0664,  0.0701,  0.0398,  0.0567,\n        -0.0843, -0.0387,  0.0406,  0.0054,  0.0368, -0.0734, -0.0759,  0.0030,\n         0.0476,  0.0018, -0.0384,  0.0814, -0.0123, -0.0413,  0.0351, -0.0426,\n        -0.0841,  0.0662, -0.0705, -0.0277, -0.0379,  0.0088,  0.0854,  0.0164,\n         0.0237, -0.0106, -0.0342, -0.0561, -0.0472,  0.0644, -0.0709, -0.0872,\n        -0.0651, -0.0735,  0.0820, -0.0225,  0.0209,  0.0458,  0.0673, -0.0211,\n         0.0682, -0.0542,  0.0315, -0.0638,  0.0720,  0.0127, -0.0543,  0.0736,\n        -0.0732, -0.0535,  0.0014, -0.0086,  0.0688, -0.0640, -0.0359,  0.0727,\n         0.0171, -0.0183, -0.0649,  0.0155,  0.0200,  0.0717, -0.0780, -0.0707,\n         0.0454,  0.0098,  0.0474, -0.0367, -0.0570,  0.0722,  0.0449, -0.0523,\n        -0.0049, -0.0514,  0.0566,  0.0724, -0.0146,  0.0632,  0.0426, -0.0037,\n         0.0717, -0.0193,  0.0364,  0.0092,  0.0829, -0.0813, -0.0873,  0.0807,\n         0.0735, -0.0348, -0.0864,  0.0434, -0.0617,  0.0795,  0.0649,  0.0544,\n        -0.0674, -0.0330,  0.0813,  0.0006, -0.0628, -0.0631,  0.0453,  0.0830,\n         0.0685,  0.0551,  0.0366,  0.0347,  0.0277,  0.0600,  0.0770,  0.0382],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0615, -0.0276,  0.0614,  0.0408,  0.0752, -0.0735,  0.0434,  0.0495,\n         -0.0620,  0.0476,  0.0819, -0.0649,  0.0235,  0.0799,  0.0115, -0.0730,\n          0.0448, -0.0184, -0.0331, -0.0456,  0.0331,  0.0307,  0.0771, -0.0056,\n          0.0784, -0.0506,  0.0010,  0.0238, -0.0795, -0.0145, -0.0678,  0.0093,\n          0.0027, -0.0191,  0.0752,  0.0120, -0.0615,  0.0608, -0.0119,  0.0322,\n         -0.0607,  0.0740, -0.0774,  0.0806, -0.0773,  0.0090, -0.0194,  0.0271,\n          0.0804, -0.0049,  0.0828, -0.0260, -0.0698,  0.0200,  0.0384, -0.0390,\n         -0.0592, -0.0007,  0.0843, -0.0608,  0.0474,  0.0797,  0.0835, -0.0492,\n         -0.0255, -0.0854,  0.0670, -0.0420, -0.0758, -0.0825, -0.0649,  0.0738,\n         -0.0484,  0.0883, -0.0206, -0.0020, -0.0774, -0.0231, -0.0204, -0.0451,\n         -0.0832,  0.0341, -0.0338, -0.0285,  0.0064,  0.0323,  0.0230, -0.0394,\n         -0.0332,  0.0035,  0.0792,  0.0320, -0.0726, -0.0480,  0.0218, -0.0550,\n         -0.0651,  0.0106, -0.0783,  0.0335, -0.0190,  0.0231,  0.0057, -0.0566,\n          0.0452, -0.0171, -0.0260,  0.0749, -0.0051, -0.0094,  0.0199, -0.0651,\n          0.0308,  0.0855,  0.0093,  0.0671, -0.0741, -0.0230,  0.0454, -0.0575,\n          0.0358, -0.0539,  0.0263, -0.0695,  0.0739,  0.0347,  0.0503, -0.0249],\n        [ 0.0210, -0.0431,  0.0074, -0.0727, -0.0667,  0.0225,  0.0864, -0.0346,\n         -0.0017,  0.0458,  0.0524, -0.0835, -0.0637,  0.0563, -0.0861,  0.0122,\n          0.0806,  0.0783, -0.0662,  0.0086, -0.0054, -0.0069, -0.0434, -0.0808,\n          0.0580, -0.0129,  0.0328,  0.0779, -0.0448, -0.0735,  0.0185, -0.0275,\n          0.0597, -0.0062, -0.0239,  0.0877,  0.0086, -0.0189,  0.0219,  0.0228,\n         -0.0242,  0.0103, -0.0731, -0.0824,  0.0816,  0.0771, -0.0717, -0.0517,\n         -0.0473, -0.0216, -0.0721,  0.0759, -0.0402,  0.0318, -0.0444,  0.0573,\n         -0.0149,  0.0689,  0.0525,  0.0482, -0.0306,  0.0785,  0.0148, -0.0237,\n          0.0308, -0.0164,  0.0365,  0.0291, -0.0726, -0.0352,  0.0574,  0.0052,\n          0.0188,  0.0225, -0.0216,  0.0653, -0.0292, -0.0525,  0.0060, -0.0460,\n         -0.0066, -0.0880, -0.0838, -0.0703, -0.0578,  0.0262,  0.0311,  0.0847,\n         -0.0118,  0.0006, -0.0313, -0.0684,  0.0152,  0.0636, -0.0315, -0.0551,\n          0.0366, -0.0120,  0.0356, -0.0248, -0.0189, -0.0613,  0.0501, -0.0608,\n         -0.0083, -0.0319, -0.0600, -0.0177, -0.0510, -0.0048, -0.0320, -0.0568,\n         -0.0279, -0.0413, -0.0251,  0.0256,  0.0130, -0.0836, -0.0440, -0.0883,\n          0.0805, -0.0555,  0.0236, -0.0774,  0.0262, -0.0208,  0.0063,  0.0792],\n        [ 0.0106, -0.0655,  0.0713, -0.0728, -0.0003,  0.0277, -0.0209, -0.0026,\n          0.0441,  0.0733,  0.0234,  0.0788, -0.0378,  0.0004, -0.0037,  0.0034,\n         -0.0280, -0.0590, -0.0150,  0.0108,  0.0757, -0.0544,  0.0690,  0.0367,\n          0.0300,  0.0693, -0.0310, -0.0395,  0.0320,  0.0600,  0.0532, -0.0659,\n          0.0509,  0.0255,  0.0670,  0.0328, -0.0240,  0.0053, -0.0530,  0.0338,\n         -0.0715,  0.0507, -0.0582, -0.0531, -0.0786, -0.0634, -0.0807, -0.0534,\n         -0.0456,  0.0882,  0.0448,  0.0777,  0.0799,  0.0573,  0.0019,  0.0171,\n         -0.0612, -0.0276,  0.0157,  0.0691, -0.0147,  0.0501, -0.0201,  0.0169,\n          0.0268,  0.0733,  0.0082,  0.0686, -0.0070, -0.0215,  0.0164,  0.0832,\n         -0.0596, -0.0856, -0.0489,  0.0867,  0.0804,  0.0556,  0.0040, -0.0230,\n         -0.0765, -0.0569,  0.0209,  0.0040,  0.0469, -0.0187,  0.0414, -0.0237,\n         -0.0874,  0.0345,  0.0694,  0.0097, -0.0827,  0.0696,  0.0522, -0.0158,\n          0.0389, -0.0764, -0.0732, -0.0580,  0.0495,  0.0566,  0.0679,  0.0103,\n         -0.0786,  0.0324,  0.0380, -0.0287,  0.0684,  0.0642,  0.0578, -0.0301,\n          0.0613, -0.0633, -0.0326, -0.0158,  0.0049, -0.0529,  0.0135, -0.0602,\n         -0.0645,  0.0748, -0.0871,  0.0088,  0.0020,  0.0464,  0.0391, -0.0441],\n        [ 0.0644,  0.0449, -0.0785, -0.0536,  0.0282,  0.0580,  0.0551,  0.0708,\n          0.0644, -0.0225,  0.0087,  0.0378,  0.0272, -0.0099,  0.0687, -0.0847,\n         -0.0406,  0.0692,  0.0545, -0.0798, -0.0614, -0.0645, -0.0122, -0.0419,\n         -0.0439, -0.0221,  0.0850,  0.0348,  0.0709,  0.0471,  0.0368, -0.0309,\n          0.0002,  0.0268, -0.0076, -0.0115, -0.0210,  0.0494, -0.0179,  0.0470,\n          0.0082,  0.0008, -0.0434, -0.0774,  0.0349, -0.0124, -0.0282, -0.0366,\n         -0.0134, -0.0876, -0.0752, -0.0137, -0.0798,  0.0020, -0.0249, -0.0022,\n         -0.0251,  0.0343,  0.0646, -0.0453,  0.0298,  0.0238, -0.0249, -0.0602,\n          0.0691, -0.0827, -0.0347, -0.0523,  0.0360,  0.0747,  0.0439,  0.0309,\n          0.0071,  0.0178,  0.0706, -0.0122,  0.0520,  0.0106,  0.0859, -0.0790,\n          0.0258,  0.0031,  0.0493,  0.0557, -0.0382,  0.0764,  0.0337,  0.0327,\n          0.0563, -0.0267,  0.0683, -0.0108, -0.0236,  0.0042, -0.0331,  0.0585,\n          0.0794, -0.0414,  0.0725, -0.0093, -0.0842,  0.0664,  0.0001, -0.0077,\n         -0.0170,  0.0534, -0.0138,  0.0611, -0.0811, -0.0644, -0.0546, -0.0234,\n         -0.0394, -0.0812,  0.0113,  0.0392, -0.0684,  0.0699,  0.0829, -0.0693,\n         -0.0697, -0.0408, -0.0134,  0.0405, -0.0675, -0.0759, -0.0143,  0.0247]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0082, -0.0087,  0.0025,  0.0708], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7dc3fa1e0090>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x7dc3fb85fc90>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.3269, -0.1038,  0.2448,  0.3392,  0.2116,  0.3530, -0.0835,  0.2147,\n        -0.2863,  0.3202,  0.2067,  0.0970,  0.3000, -0.1009, -0.0375,  0.0022,\n         0.2824,  0.1574,  0.1726,  0.1831,  0.0339,  0.3027, -0.1381, -0.2887,\n         0.0993,  0.0286,  0.0506, -0.2150, -0.0443, -0.1770,  0.3399, -0.3224,\n         0.2035, -0.1119, -0.1238,  0.1795,  0.2590,  0.1241,  0.3496, -0.0311,\n        -0.0671,  0.2544, -0.0742, -0.1686,  0.0394,  0.3501,  0.3356, -0.2263,\n        -0.2274,  0.3189,  0.1810, -0.0240,  0.2523,  0.3151,  0.1104,  0.3360,\n        -0.2743,  0.2935, -0.3253, -0.3416,  0.1141,  0.1240, -0.1237, -0.2446,\n         0.0992, -0.2013, -0.3080,  0.2544,  0.1640, -0.0630, -0.0309, -0.3105,\n         0.0080, -0.3183,  0.0518,  0.2276, -0.2894,  0.2435, -0.0258,  0.1822,\n        -0.2393,  0.0236,  0.2806,  0.1491,  0.0385,  0.3357, -0.0154,  0.2083,\n        -0.2554, -0.0260,  0.0773, -0.3192, -0.0564, -0.1492, -0.0324,  0.1154,\n        -0.0495, -0.2984, -0.2389, -0.0526,  0.3218, -0.3193,  0.1725, -0.0745,\n         0.1274,  0.2287,  0.2687, -0.2121, -0.3017,  0.1352,  0.2726, -0.2024,\n        -0.1277,  0.1608, -0.1632,  0.0536,  0.3008,  0.1382, -0.3162, -0.2321,\n        -0.0916, -0.0680, -0.2078, -0.2151,  0.2233, -0.1251,  0.1421, -0.0309],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.2924, -0.2418, -0.0114,  ..., -0.2116,  0.2324,  0.1244],\n        [-0.0849,  0.1232, -0.2255,  ..., -0.0169,  0.3389, -0.0138],\n        [-0.0408,  0.1581, -0.3370,  ..., -0.0261, -0.0020,  0.2297],\n        ...,\n        [ 0.2094,  0.0249, -0.1378,  ..., -0.2564, -0.0364,  0.1010],\n        [-0.2993, -0.2500,  0.0265,  ...,  0.1137, -0.1550,  0.0366],\n        [-0.2695,  0.0118, -0.2670,  ..., -0.0883,  0.0067, -0.1926]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0459, -0.0368, -0.0414,  0.0697,  0.0337,  0.0143,  0.0344,  0.0162,\n        -0.0336, -0.0246,  0.0198, -0.0046,  0.0664,  0.0701,  0.0398,  0.0567,\n        -0.0843, -0.0387,  0.0406,  0.0054,  0.0368, -0.0734, -0.0759,  0.0030,\n         0.0476,  0.0018, -0.0384,  0.0814, -0.0123, -0.0413,  0.0351, -0.0426,\n        -0.0841,  0.0662, -0.0705, -0.0277, -0.0379,  0.0088,  0.0854,  0.0164,\n         0.0237, -0.0106, -0.0342, -0.0561, -0.0472,  0.0644, -0.0709, -0.0872,\n        -0.0651, -0.0735,  0.0820, -0.0225,  0.0209,  0.0458,  0.0673, -0.0211,\n         0.0682, -0.0542,  0.0315, -0.0638,  0.0720,  0.0127, -0.0543,  0.0736,\n        -0.0732, -0.0535,  0.0014, -0.0086,  0.0688, -0.0640, -0.0359,  0.0727,\n         0.0171, -0.0183, -0.0649,  0.0155,  0.0200,  0.0717, -0.0780, -0.0707,\n         0.0454,  0.0098,  0.0474, -0.0367, -0.0570,  0.0722,  0.0449, -0.0523,\n        -0.0049, -0.0514,  0.0566,  0.0724, -0.0146,  0.0632,  0.0426, -0.0037,\n         0.0717, -0.0193,  0.0364,  0.0092,  0.0829, -0.0813, -0.0873,  0.0807,\n         0.0735, -0.0348, -0.0864,  0.0434, -0.0617,  0.0795,  0.0649,  0.0544,\n        -0.0674, -0.0330,  0.0813,  0.0006, -0.0628, -0.0631,  0.0453,  0.0830,\n         0.0685,  0.0551,  0.0366,  0.0347,  0.0277,  0.0600,  0.0770,  0.0382],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0590, -0.0211, -0.0431,  ...,  0.0198,  0.0759, -0.0322],\n        [ 0.0547, -0.0435,  0.0644,  ..., -0.0413, -0.0576,  0.0046],\n        [ 0.0193,  0.0442, -0.0767,  ...,  0.0550, -0.0285,  0.0376],\n        ...,\n        [-0.0437,  0.0430, -0.0219,  ..., -0.0838, -0.0850,  0.0553],\n        [ 0.0680, -0.0130,  0.0133,  ..., -0.0354,  0.0112, -0.0620],\n        [-0.0170, -0.0109,  0.0255,  ...,  0.0861,  0.0299, -0.0546]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0082, -0.0087,  0.0025,  0.0708], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0615, -0.0276,  0.0614,  0.0408,  0.0752, -0.0735,  0.0434,  0.0495,\n         -0.0620,  0.0476,  0.0819, -0.0649,  0.0235,  0.0799,  0.0115, -0.0730,\n          0.0448, -0.0184, -0.0331, -0.0456,  0.0331,  0.0307,  0.0771, -0.0056,\n          0.0784, -0.0506,  0.0010,  0.0238, -0.0795, -0.0145, -0.0678,  0.0093,\n          0.0027, -0.0191,  0.0752,  0.0120, -0.0615,  0.0608, -0.0119,  0.0322,\n         -0.0607,  0.0740, -0.0774,  0.0806, -0.0773,  0.0090, -0.0194,  0.0271,\n          0.0804, -0.0049,  0.0828, -0.0260, -0.0698,  0.0200,  0.0384, -0.0390,\n         -0.0592, -0.0007,  0.0843, -0.0608,  0.0474,  0.0797,  0.0835, -0.0492,\n         -0.0255, -0.0854,  0.0670, -0.0420, -0.0758, -0.0825, -0.0649,  0.0738,\n         -0.0484,  0.0883, -0.0206, -0.0020, -0.0774, -0.0231, -0.0204, -0.0451,\n         -0.0832,  0.0341, -0.0338, -0.0285,  0.0064,  0.0323,  0.0230, -0.0394,\n         -0.0332,  0.0035,  0.0792,  0.0320, -0.0726, -0.0480,  0.0218, -0.0550,\n         -0.0651,  0.0106, -0.0783,  0.0335, -0.0190,  0.0231,  0.0057, -0.0566,\n          0.0452, -0.0171, -0.0260,  0.0749, -0.0051, -0.0094,  0.0199, -0.0651,\n          0.0308,  0.0855,  0.0093,  0.0671, -0.0741, -0.0230,  0.0454, -0.0575,\n          0.0358, -0.0539,  0.0263, -0.0695,  0.0739,  0.0347,  0.0503, -0.0249],\n        [ 0.0210, -0.0431,  0.0074, -0.0727, -0.0667,  0.0225,  0.0864, -0.0346,\n         -0.0017,  0.0458,  0.0524, -0.0835, -0.0637,  0.0563, -0.0861,  0.0122,\n          0.0806,  0.0783, -0.0662,  0.0086, -0.0054, -0.0069, -0.0434, -0.0808,\n          0.0580, -0.0129,  0.0328,  0.0779, -0.0448, -0.0735,  0.0185, -0.0275,\n          0.0597, -0.0062, -0.0239,  0.0877,  0.0086, -0.0189,  0.0219,  0.0228,\n         -0.0242,  0.0103, -0.0731, -0.0824,  0.0816,  0.0771, -0.0717, -0.0517,\n         -0.0473, -0.0216, -0.0721,  0.0759, -0.0402,  0.0318, -0.0444,  0.0573,\n         -0.0149,  0.0689,  0.0525,  0.0482, -0.0306,  0.0785,  0.0148, -0.0237,\n          0.0308, -0.0164,  0.0365,  0.0291, -0.0726, -0.0352,  0.0574,  0.0052,\n          0.0188,  0.0225, -0.0216,  0.0653, -0.0292, -0.0525,  0.0060, -0.0460,\n         -0.0066, -0.0880, -0.0838, -0.0703, -0.0578,  0.0262,  0.0311,  0.0847,\n         -0.0118,  0.0006, -0.0313, -0.0684,  0.0152,  0.0636, -0.0315, -0.0551,\n          0.0366, -0.0120,  0.0356, -0.0248, -0.0189, -0.0613,  0.0501, -0.0608,\n         -0.0083, -0.0319, -0.0600, -0.0177, -0.0510, -0.0048, -0.0320, -0.0568,\n         -0.0279, -0.0413, -0.0251,  0.0256,  0.0130, -0.0836, -0.0440, -0.0883,\n          0.0805, -0.0555,  0.0236, -0.0774,  0.0262, -0.0208,  0.0063,  0.0792],\n        [ 0.0106, -0.0655,  0.0713, -0.0728, -0.0003,  0.0277, -0.0209, -0.0026,\n          0.0441,  0.0733,  0.0234,  0.0788, -0.0378,  0.0004, -0.0037,  0.0034,\n         -0.0280, -0.0590, -0.0150,  0.0108,  0.0757, -0.0544,  0.0690,  0.0367,\n          0.0300,  0.0693, -0.0310, -0.0395,  0.0320,  0.0600,  0.0532, -0.0659,\n          0.0509,  0.0255,  0.0670,  0.0328, -0.0240,  0.0053, -0.0530,  0.0338,\n         -0.0715,  0.0507, -0.0582, -0.0531, -0.0786, -0.0634, -0.0807, -0.0534,\n         -0.0456,  0.0882,  0.0448,  0.0777,  0.0799,  0.0573,  0.0019,  0.0171,\n         -0.0612, -0.0276,  0.0157,  0.0691, -0.0147,  0.0501, -0.0201,  0.0169,\n          0.0268,  0.0733,  0.0082,  0.0686, -0.0070, -0.0215,  0.0164,  0.0832,\n         -0.0596, -0.0856, -0.0489,  0.0867,  0.0804,  0.0556,  0.0040, -0.0230,\n         -0.0765, -0.0569,  0.0209,  0.0040,  0.0469, -0.0187,  0.0414, -0.0237,\n         -0.0874,  0.0345,  0.0694,  0.0097, -0.0827,  0.0696,  0.0522, -0.0158,\n          0.0389, -0.0764, -0.0732, -0.0580,  0.0495,  0.0566,  0.0679,  0.0103,\n         -0.0786,  0.0324,  0.0380, -0.0287,  0.0684,  0.0642,  0.0578, -0.0301,\n          0.0613, -0.0633, -0.0326, -0.0158,  0.0049, -0.0529,  0.0135, -0.0602,\n         -0.0645,  0.0748, -0.0871,  0.0088,  0.0020,  0.0464,  0.0391, -0.0441],\n        [ 0.0644,  0.0449, -0.0785, -0.0536,  0.0282,  0.0580,  0.0551,  0.0708,\n          0.0644, -0.0225,  0.0087,  0.0378,  0.0272, -0.0099,  0.0687, -0.0847,\n         -0.0406,  0.0692,  0.0545, -0.0798, -0.0614, -0.0645, -0.0122, -0.0419,\n         -0.0439, -0.0221,  0.0850,  0.0348,  0.0709,  0.0471,  0.0368, -0.0309,\n          0.0002,  0.0268, -0.0076, -0.0115, -0.0210,  0.0494, -0.0179,  0.0470,\n          0.0082,  0.0008, -0.0434, -0.0774,  0.0349, -0.0124, -0.0282, -0.0366,\n         -0.0134, -0.0876, -0.0752, -0.0137, -0.0798,  0.0020, -0.0249, -0.0022,\n         -0.0251,  0.0343,  0.0646, -0.0453,  0.0298,  0.0238, -0.0249, -0.0602,\n          0.0691, -0.0827, -0.0347, -0.0523,  0.0360,  0.0747,  0.0439,  0.0309,\n          0.0071,  0.0178,  0.0706, -0.0122,  0.0520,  0.0106,  0.0859, -0.0790,\n          0.0258,  0.0031,  0.0493,  0.0557, -0.0382,  0.0764,  0.0337,  0.0327,\n          0.0563, -0.0267,  0.0683, -0.0108, -0.0236,  0.0042, -0.0331,  0.0585,\n          0.0794, -0.0414,  0.0725, -0.0093, -0.0842,  0.0664,  0.0001, -0.0077,\n         -0.0170,  0.0534, -0.0138,  0.0611, -0.0811, -0.0644, -0.0546, -0.0234,\n         -0.0394, -0.0812,  0.0113,  0.0392, -0.0684,  0.0699,  0.0829, -0.0693,\n         -0.0697, -0.0408, -0.0134,  0.0405, -0.0675, -0.0759, -0.0143,  0.0247]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7dc3f864c1d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s689630000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s689630000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}