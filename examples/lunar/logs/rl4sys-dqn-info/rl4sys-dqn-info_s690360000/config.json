{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	4,
    "batch_size":	60,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0007,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s690360000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0005,
    "sample_decay":	0.5,
    "seed":	690360000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x78e87d885d10>":	{
            "_act_dim":	4,
            "_aux_batch_size":	4,
            "_batch_size":	60,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0007,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0503,  0.3070, -0.3107, -0.2437,  0.1624,  0.1975,  0.2240, -0.3059,\n         0.0885, -0.1494,  0.0878, -0.1648,  0.2681, -0.1555,  0.1208, -0.0896,\n        -0.2893, -0.0961, -0.2659,  0.1963, -0.1772, -0.2812, -0.0540,  0.2291,\n         0.1294, -0.2947,  0.2073, -0.3159, -0.2241,  0.3020, -0.0501,  0.1399,\n        -0.0737,  0.0656,  0.2735,  0.0360,  0.1437, -0.2421, -0.0919,  0.2563,\n         0.0046, -0.1481, -0.3351, -0.3316, -0.2588, -0.3261, -0.2294, -0.2933,\n        -0.3418,  0.1729,  0.1795,  0.1875,  0.1824, -0.1210, -0.2329, -0.0448,\n        -0.1704,  0.0994,  0.2489,  0.0480,  0.1302,  0.1312,  0.1781,  0.2730,\n        -0.3260,  0.1947,  0.2257,  0.2890,  0.0323,  0.1722, -0.0074, -0.2226,\n        -0.3510,  0.0827, -0.1001, -0.2642,  0.2034, -0.2849,  0.1065,  0.0623,\n        -0.1514,  0.3341, -0.3182,  0.0992,  0.0218,  0.2389, -0.2863,  0.1477,\n         0.3028, -0.3214,  0.1919,  0.3007,  0.1616, -0.0885, -0.3511,  0.0019,\n        -0.0581,  0.0139,  0.0947, -0.0813, -0.1953, -0.1158,  0.0666, -0.2640,\n         0.0976,  0.2707, -0.2875, -0.2400, -0.2461,  0.1037, -0.0689,  0.0278,\n         0.3327, -0.1377,  0.0547, -0.0845,  0.0474, -0.0609, -0.1855, -0.0048,\n        -0.1789, -0.2877,  0.2344, -0.2144, -0.1406,  0.3429,  0.2359,  0.3147],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0113,  0.1649,  0.1170,  ..., -0.0297,  0.3463,  0.2514],\n        [-0.1688, -0.3083, -0.3227,  ...,  0.1062,  0.1643, -0.2903],\n        [-0.0443,  0.0518,  0.2408,  ...,  0.1080, -0.0984, -0.2184],\n        ...,\n        [-0.2110,  0.2933, -0.1718,  ...,  0.0205, -0.3027, -0.1108],\n        [ 0.1682,  0.2218,  0.2637,  ...,  0.1650,  0.0789, -0.0624],\n        [-0.2748,  0.0850, -0.2944,  ...,  0.2847, -0.0053, -0.1241]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0532, -0.0343, -0.0182,  0.0550, -0.0591,  0.0103, -0.0144,  0.0712,\n        -0.0128, -0.0105, -0.0440, -0.0395,  0.0617, -0.0164,  0.0790, -0.0316,\n         0.0029, -0.0037, -0.0676,  0.0495, -0.0832,  0.0199,  0.0664, -0.0714,\n        -0.0140, -0.0209, -0.0867, -0.0152, -0.0346, -0.0246, -0.0694, -0.0122,\n         0.0636,  0.0881, -0.0459,  0.0400, -0.0090,  0.0803,  0.0589, -0.0454,\n        -0.0375, -0.0417,  0.0095,  0.0129,  0.0543,  0.0204, -0.0185, -0.0728,\n        -0.0550, -0.0258, -0.0374, -0.0207,  0.0274,  0.0119,  0.0103,  0.0112,\n        -0.0354, -0.0341, -0.0259,  0.0390,  0.0185, -0.0500, -0.0704, -0.0869,\n        -0.0603,  0.0174, -0.0060, -0.0843, -0.0307,  0.0046,  0.0408, -0.0720,\n        -0.0738, -0.0021,  0.0087, -0.0715,  0.0761,  0.0755, -0.0377, -0.0795,\n         0.0322,  0.0587,  0.0878,  0.0197, -0.0163,  0.0863, -0.0320,  0.0551,\n         0.0056, -0.0007, -0.0440,  0.0441, -0.0021, -0.0129,  0.0152,  0.0816,\n         0.0336,  0.0508, -0.0089,  0.0490, -0.0750,  0.0172, -0.0468,  0.0061,\n         0.0334,  0.0514,  0.0414,  0.0725,  0.0670,  0.0528,  0.0400,  0.0863,\n         0.0474, -0.0234, -0.0770, -0.0402,  0.0302,  0.0576,  0.0018,  0.0721,\n        -0.0100,  0.0239,  0.0215,  0.0006,  0.0392,  0.0187,  0.0787, -0.0193],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0423,  0.0240,  0.0592,  ..., -0.0213,  0.0850,  0.0738],\n        [-0.0041,  0.0456,  0.0851,  ...,  0.0288, -0.0104,  0.0592],\n        [-0.0700,  0.0066, -0.0802,  ...,  0.0394, -0.0603,  0.0058],\n        ...,\n        [-0.0803, -0.0188,  0.0539,  ..., -0.0710,  0.0025,  0.0060],\n        [-0.0425,  0.0703, -0.0386,  ...,  0.0035,  0.0184, -0.0537],\n        [-0.0151, -0.0788, -0.0878,  ..., -0.0343,  0.0025,  0.0120]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0763,  0.0641, -0.0140,  0.0313], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0813,  0.0211, -0.0004, -0.0877,  0.0721, -0.0059,  0.0368, -0.0350,\n         -0.0356,  0.0637,  0.0381, -0.0421, -0.0635,  0.0015,  0.0263, -0.0600,\n         -0.0206,  0.0810, -0.0537, -0.0511,  0.0473,  0.0464,  0.0383, -0.0709,\n         -0.0217,  0.0842, -0.0412,  0.0495,  0.0233,  0.0016,  0.0298,  0.0480,\n         -0.0405,  0.0444,  0.0355, -0.0708, -0.0511,  0.0841,  0.0116,  0.0673,\n         -0.0383,  0.0349,  0.0199,  0.0139, -0.0102, -0.0254,  0.0501, -0.0224,\n         -0.0572,  0.0518, -0.0071,  0.0843, -0.0262,  0.0872,  0.0858, -0.0519,\n         -0.0608, -0.0790, -0.0442, -0.0015, -0.0546,  0.0397, -0.0029, -0.0042,\n         -0.0663, -0.0656, -0.0584, -0.0453,  0.0750, -0.0031,  0.0740,  0.0209,\n         -0.0050,  0.0090, -0.0732, -0.0816,  0.0792,  0.0714,  0.0726, -0.0570,\n          0.0738,  0.0064, -0.0026,  0.0823,  0.0352,  0.0517,  0.0506, -0.0200,\n          0.0832, -0.0504,  0.0597, -0.0252, -0.0568,  0.0643,  0.0068,  0.0185,\n         -0.0339, -0.0801,  0.0785, -0.0163,  0.0505,  0.0364, -0.0610,  0.0290,\n          0.0204, -0.0312, -0.0202,  0.0782,  0.0297,  0.0763,  0.0013,  0.0861,\n         -0.0561, -0.0159,  0.0759,  0.0467, -0.0569,  0.0141,  0.0230,  0.0627,\n         -0.0271, -0.0817, -0.0180,  0.0543,  0.0096, -0.0827,  0.0595, -0.0453],\n        [ 0.0778, -0.0262, -0.0650, -0.0143,  0.0523,  0.0830,  0.0201,  0.0184,\n         -0.0833,  0.0225,  0.0154,  0.0563, -0.0846,  0.0605,  0.0064,  0.0586,\n          0.0821,  0.0180, -0.0438, -0.0352, -0.0366,  0.0428, -0.0698, -0.0526,\n         -0.0181,  0.0036, -0.0636,  0.0307,  0.0772, -0.0663, -0.0058, -0.0080,\n          0.0599, -0.0682,  0.0202, -0.0636,  0.0114,  0.0771,  0.0541, -0.0377,\n          0.0677,  0.0203, -0.0091, -0.0730, -0.0741,  0.0277, -0.0477,  0.0634,\n          0.0149,  0.0822, -0.0264, -0.0275, -0.0259, -0.0004,  0.0087,  0.0658,\n          0.0224,  0.0163, -0.0791, -0.0729, -0.0808,  0.0867,  0.0465, -0.0564,\n         -0.0377,  0.0291, -0.0211, -0.0235, -0.0779, -0.0114, -0.0031,  0.0855,\n          0.0576,  0.0637, -0.0652,  0.0564, -0.0312, -0.0868,  0.0152,  0.0551,\n          0.0883,  0.0096, -0.0462,  0.0374, -0.0659, -0.0548,  0.0605,  0.0035,\n         -0.0876,  0.0373, -0.0287,  0.0748, -0.0571,  0.0570, -0.0277, -0.0431,\n         -0.0670,  0.0337,  0.0445,  0.0553, -0.0364,  0.0539, -0.0229,  0.0458,\n         -0.0179, -0.0598, -0.0144,  0.0387,  0.0559, -0.0101,  0.0407,  0.0630,\n          0.0383, -0.0411, -0.0042, -0.0571,  0.0256, -0.0443, -0.0204, -0.0329,\n         -0.0816, -0.0418,  0.0851, -0.0329, -0.0061,  0.0680, -0.0369, -0.0709],\n        [-0.0844, -0.0284, -0.0166, -0.0438,  0.0716, -0.0410, -0.0779,  0.0162,\n          0.0239,  0.0627,  0.0579,  0.0219, -0.0087,  0.0767,  0.0142, -0.0264,\n         -0.0544, -0.0791,  0.0678,  0.0062,  0.0605,  0.0287, -0.0070, -0.0742,\n         -0.0820,  0.0547,  0.0645, -0.0644,  0.0716,  0.0562,  0.0175,  0.0022,\n          0.0623,  0.0761, -0.0081,  0.0211,  0.0250, -0.0882, -0.0733, -0.0780,\n         -0.0146, -0.0206,  0.0389, -0.0349, -0.0564, -0.0749,  0.0506, -0.0778,\n          0.0178,  0.0318,  0.0815, -0.0293,  0.0462,  0.0467,  0.0828,  0.0720,\n         -0.0712, -0.0351, -0.0702,  0.0775,  0.0204,  0.0367, -0.0198,  0.0410,\n          0.0878,  0.0366,  0.0639,  0.0719, -0.0633, -0.0112,  0.0509,  0.0118,\n         -0.0354, -0.0372,  0.0794,  0.0223,  0.0156, -0.0250, -0.0232, -0.0580,\n          0.0004, -0.0206, -0.0837,  0.0782,  0.0815, -0.0509, -0.0491,  0.0715,\n          0.0231,  0.0470, -0.0652,  0.0578,  0.0726, -0.0158, -0.0881,  0.0151,\n         -0.0414, -0.0210, -0.0005, -0.0066, -0.0221, -0.0203, -0.0588, -0.0207,\n          0.0284, -0.0551,  0.0011,  0.0788,  0.0734,  0.0304,  0.0821,  0.0417,\n          0.0796,  0.0357,  0.0552,  0.0155, -0.0116,  0.0198, -0.0065,  0.0539,\n          0.0784,  0.0378, -0.0162, -0.0423, -0.0010, -0.0572, -0.0485, -0.0702],\n        [-0.0265, -0.0776, -0.0576, -0.0025, -0.0316, -0.0031, -0.0657, -0.0248,\n          0.0088, -0.0694, -0.0406, -0.0741, -0.0083, -0.0326,  0.0513, -0.0119,\n          0.0641, -0.0861, -0.0559,  0.0033,  0.0789,  0.0594,  0.0250,  0.0097,\n          0.0304, -0.0734,  0.0299,  0.0168, -0.0632,  0.0203, -0.0013, -0.0555,\n          0.0235,  0.0165, -0.0585,  0.0141, -0.0139, -0.0608,  0.0853, -0.0490,\n         -0.0191,  0.0866,  0.0514,  0.0448, -0.0539, -0.0161,  0.0542,  0.0659,\n          0.0277,  0.0499,  0.0610,  0.0853, -0.0810, -0.0413,  0.0608, -0.0128,\n          0.0542, -0.0133, -0.0493,  0.0064,  0.0433,  0.0762,  0.0793, -0.0291,\n          0.0491,  0.0651,  0.0775,  0.0145, -0.0351,  0.0428,  0.0628,  0.0350,\n          0.0757, -0.0521, -0.0730,  0.0504, -0.0026, -0.0513, -0.0214, -0.0691,\n         -0.0061,  0.0166, -0.0086, -0.0615, -0.0879, -0.0458, -0.0671,  0.0425,\n         -0.0049, -0.0749, -0.0064, -0.0556,  0.0803, -0.0029,  0.0235,  0.0200,\n          0.0700, -0.0587, -0.0110, -0.0411, -0.0168,  0.0552,  0.0592,  0.0544,\n          0.0254,  0.0610,  0.0405,  0.0591,  0.0543, -0.0453,  0.0097,  0.0103,\n          0.0843,  0.0057, -0.0786, -0.0222,  0.0815, -0.0865, -0.0466, -0.0882,\n         -0.0212, -0.0142,  0.0859, -0.0090,  0.0603, -0.0848, -0.0558, -0.0648]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0113,  0.1649,  0.1170,  ..., -0.0297,  0.3463,  0.2514],\n        [-0.1688, -0.3083, -0.3227,  ...,  0.1062,  0.1643, -0.2903],\n        [-0.0443,  0.0518,  0.2408,  ...,  0.1080, -0.0984, -0.2184],\n        ...,\n        [-0.2110,  0.2933, -0.1718,  ...,  0.0205, -0.3027, -0.1108],\n        [ 0.1682,  0.2218,  0.2637,  ...,  0.1650,  0.0789, -0.0624],\n        [-0.2748,  0.0850, -0.2944,  ...,  0.2847, -0.0053, -0.1241]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0503,  0.3070, -0.3107, -0.2437,  0.1624,  0.1975,  0.2240, -0.3059,\n         0.0885, -0.1494,  0.0878, -0.1648,  0.2681, -0.1555,  0.1208, -0.0896,\n        -0.2893, -0.0961, -0.2659,  0.1963, -0.1772, -0.2812, -0.0540,  0.2291,\n         0.1294, -0.2947,  0.2073, -0.3159, -0.2241,  0.3020, -0.0501,  0.1399,\n        -0.0737,  0.0656,  0.2735,  0.0360,  0.1437, -0.2421, -0.0919,  0.2563,\n         0.0046, -0.1481, -0.3351, -0.3316, -0.2588, -0.3261, -0.2294, -0.2933,\n        -0.3418,  0.1729,  0.1795,  0.1875,  0.1824, -0.1210, -0.2329, -0.0448,\n        -0.1704,  0.0994,  0.2489,  0.0480,  0.1302,  0.1312,  0.1781,  0.2730,\n        -0.3260,  0.1947,  0.2257,  0.2890,  0.0323,  0.1722, -0.0074, -0.2226,\n        -0.3510,  0.0827, -0.1001, -0.2642,  0.2034, -0.2849,  0.1065,  0.0623,\n        -0.1514,  0.3341, -0.3182,  0.0992,  0.0218,  0.2389, -0.2863,  0.1477,\n         0.3028, -0.3214,  0.1919,  0.3007,  0.1616, -0.0885, -0.3511,  0.0019,\n        -0.0581,  0.0139,  0.0947, -0.0813, -0.1953, -0.1158,  0.0666, -0.2640,\n         0.0976,  0.2707, -0.2875, -0.2400, -0.2461,  0.1037, -0.0689,  0.0278,\n         0.3327, -0.1377,  0.0547, -0.0845,  0.0474, -0.0609, -0.1855, -0.0048,\n        -0.1789, -0.2877,  0.2344, -0.2144, -0.1406,  0.3429,  0.2359,  0.3147],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0423,  0.0240,  0.0592,  ..., -0.0213,  0.0850,  0.0738],\n        [-0.0041,  0.0456,  0.0851,  ...,  0.0288, -0.0104,  0.0592],\n        [-0.0700,  0.0066, -0.0802,  ...,  0.0394, -0.0603,  0.0058],\n        ...,\n        [-0.0803, -0.0188,  0.0539,  ..., -0.0710,  0.0025,  0.0060],\n        [-0.0425,  0.0703, -0.0386,  ...,  0.0035,  0.0184, -0.0537],\n        [-0.0151, -0.0788, -0.0878,  ..., -0.0343,  0.0025,  0.0120]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0532, -0.0343, -0.0182,  0.0550, -0.0591,  0.0103, -0.0144,  0.0712,\n        -0.0128, -0.0105, -0.0440, -0.0395,  0.0617, -0.0164,  0.0790, -0.0316,\n         0.0029, -0.0037, -0.0676,  0.0495, -0.0832,  0.0199,  0.0664, -0.0714,\n        -0.0140, -0.0209, -0.0867, -0.0152, -0.0346, -0.0246, -0.0694, -0.0122,\n         0.0636,  0.0881, -0.0459,  0.0400, -0.0090,  0.0803,  0.0589, -0.0454,\n        -0.0375, -0.0417,  0.0095,  0.0129,  0.0543,  0.0204, -0.0185, -0.0728,\n        -0.0550, -0.0258, -0.0374, -0.0207,  0.0274,  0.0119,  0.0103,  0.0112,\n        -0.0354, -0.0341, -0.0259,  0.0390,  0.0185, -0.0500, -0.0704, -0.0869,\n        -0.0603,  0.0174, -0.0060, -0.0843, -0.0307,  0.0046,  0.0408, -0.0720,\n        -0.0738, -0.0021,  0.0087, -0.0715,  0.0761,  0.0755, -0.0377, -0.0795,\n         0.0322,  0.0587,  0.0878,  0.0197, -0.0163,  0.0863, -0.0320,  0.0551,\n         0.0056, -0.0007, -0.0440,  0.0441, -0.0021, -0.0129,  0.0152,  0.0816,\n         0.0336,  0.0508, -0.0089,  0.0490, -0.0750,  0.0172, -0.0468,  0.0061,\n         0.0334,  0.0514,  0.0414,  0.0725,  0.0670,  0.0528,  0.0400,  0.0863,\n         0.0474, -0.0234, -0.0770, -0.0402,  0.0302,  0.0576,  0.0018,  0.0721,\n        -0.0100,  0.0239,  0.0215,  0.0006,  0.0392,  0.0187,  0.0787, -0.0193],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0813,  0.0211, -0.0004, -0.0877,  0.0721, -0.0059,  0.0368, -0.0350,\n         -0.0356,  0.0637,  0.0381, -0.0421, -0.0635,  0.0015,  0.0263, -0.0600,\n         -0.0206,  0.0810, -0.0537, -0.0511,  0.0473,  0.0464,  0.0383, -0.0709,\n         -0.0217,  0.0842, -0.0412,  0.0495,  0.0233,  0.0016,  0.0298,  0.0480,\n         -0.0405,  0.0444,  0.0355, -0.0708, -0.0511,  0.0841,  0.0116,  0.0673,\n         -0.0383,  0.0349,  0.0199,  0.0139, -0.0102, -0.0254,  0.0501, -0.0224,\n         -0.0572,  0.0518, -0.0071,  0.0843, -0.0262,  0.0872,  0.0858, -0.0519,\n         -0.0608, -0.0790, -0.0442, -0.0015, -0.0546,  0.0397, -0.0029, -0.0042,\n         -0.0663, -0.0656, -0.0584, -0.0453,  0.0750, -0.0031,  0.0740,  0.0209,\n         -0.0050,  0.0090, -0.0732, -0.0816,  0.0792,  0.0714,  0.0726, -0.0570,\n          0.0738,  0.0064, -0.0026,  0.0823,  0.0352,  0.0517,  0.0506, -0.0200,\n          0.0832, -0.0504,  0.0597, -0.0252, -0.0568,  0.0643,  0.0068,  0.0185,\n         -0.0339, -0.0801,  0.0785, -0.0163,  0.0505,  0.0364, -0.0610,  0.0290,\n          0.0204, -0.0312, -0.0202,  0.0782,  0.0297,  0.0763,  0.0013,  0.0861,\n         -0.0561, -0.0159,  0.0759,  0.0467, -0.0569,  0.0141,  0.0230,  0.0627,\n         -0.0271, -0.0817, -0.0180,  0.0543,  0.0096, -0.0827,  0.0595, -0.0453],\n        [ 0.0778, -0.0262, -0.0650, -0.0143,  0.0523,  0.0830,  0.0201,  0.0184,\n         -0.0833,  0.0225,  0.0154,  0.0563, -0.0846,  0.0605,  0.0064,  0.0586,\n          0.0821,  0.0180, -0.0438, -0.0352, -0.0366,  0.0428, -0.0698, -0.0526,\n         -0.0181,  0.0036, -0.0636,  0.0307,  0.0772, -0.0663, -0.0058, -0.0080,\n          0.0599, -0.0682,  0.0202, -0.0636,  0.0114,  0.0771,  0.0541, -0.0377,\n          0.0677,  0.0203, -0.0091, -0.0730, -0.0741,  0.0277, -0.0477,  0.0634,\n          0.0149,  0.0822, -0.0264, -0.0275, -0.0259, -0.0004,  0.0087,  0.0658,\n          0.0224,  0.0163, -0.0791, -0.0729, -0.0808,  0.0867,  0.0465, -0.0564,\n         -0.0377,  0.0291, -0.0211, -0.0235, -0.0779, -0.0114, -0.0031,  0.0855,\n          0.0576,  0.0637, -0.0652,  0.0564, -0.0312, -0.0868,  0.0152,  0.0551,\n          0.0883,  0.0096, -0.0462,  0.0374, -0.0659, -0.0548,  0.0605,  0.0035,\n         -0.0876,  0.0373, -0.0287,  0.0748, -0.0571,  0.0570, -0.0277, -0.0431,\n         -0.0670,  0.0337,  0.0445,  0.0553, -0.0364,  0.0539, -0.0229,  0.0458,\n         -0.0179, -0.0598, -0.0144,  0.0387,  0.0559, -0.0101,  0.0407,  0.0630,\n          0.0383, -0.0411, -0.0042, -0.0571,  0.0256, -0.0443, -0.0204, -0.0329,\n         -0.0816, -0.0418,  0.0851, -0.0329, -0.0061,  0.0680, -0.0369, -0.0709],\n        [-0.0844, -0.0284, -0.0166, -0.0438,  0.0716, -0.0410, -0.0779,  0.0162,\n          0.0239,  0.0627,  0.0579,  0.0219, -0.0087,  0.0767,  0.0142, -0.0264,\n         -0.0544, -0.0791,  0.0678,  0.0062,  0.0605,  0.0287, -0.0070, -0.0742,\n         -0.0820,  0.0547,  0.0645, -0.0644,  0.0716,  0.0562,  0.0175,  0.0022,\n          0.0623,  0.0761, -0.0081,  0.0211,  0.0250, -0.0882, -0.0733, -0.0780,\n         -0.0146, -0.0206,  0.0389, -0.0349, -0.0564, -0.0749,  0.0506, -0.0778,\n          0.0178,  0.0318,  0.0815, -0.0293,  0.0462,  0.0467,  0.0828,  0.0720,\n         -0.0712, -0.0351, -0.0702,  0.0775,  0.0204,  0.0367, -0.0198,  0.0410,\n          0.0878,  0.0366,  0.0639,  0.0719, -0.0633, -0.0112,  0.0509,  0.0118,\n         -0.0354, -0.0372,  0.0794,  0.0223,  0.0156, -0.0250, -0.0232, -0.0580,\n          0.0004, -0.0206, -0.0837,  0.0782,  0.0815, -0.0509, -0.0491,  0.0715,\n          0.0231,  0.0470, -0.0652,  0.0578,  0.0726, -0.0158, -0.0881,  0.0151,\n         -0.0414, -0.0210, -0.0005, -0.0066, -0.0221, -0.0203, -0.0588, -0.0207,\n          0.0284, -0.0551,  0.0011,  0.0788,  0.0734,  0.0304,  0.0821,  0.0417,\n          0.0796,  0.0357,  0.0552,  0.0155, -0.0116,  0.0198, -0.0065,  0.0539,\n          0.0784,  0.0378, -0.0162, -0.0423, -0.0010, -0.0572, -0.0485, -0.0702],\n        [-0.0265, -0.0776, -0.0576, -0.0025, -0.0316, -0.0031, -0.0657, -0.0248,\n          0.0088, -0.0694, -0.0406, -0.0741, -0.0083, -0.0326,  0.0513, -0.0119,\n          0.0641, -0.0861, -0.0559,  0.0033,  0.0789,  0.0594,  0.0250,  0.0097,\n          0.0304, -0.0734,  0.0299,  0.0168, -0.0632,  0.0203, -0.0013, -0.0555,\n          0.0235,  0.0165, -0.0585,  0.0141, -0.0139, -0.0608,  0.0853, -0.0490,\n         -0.0191,  0.0866,  0.0514,  0.0448, -0.0539, -0.0161,  0.0542,  0.0659,\n          0.0277,  0.0499,  0.0610,  0.0853, -0.0810, -0.0413,  0.0608, -0.0128,\n          0.0542, -0.0133, -0.0493,  0.0064,  0.0433,  0.0762,  0.0793, -0.0291,\n          0.0491,  0.0651,  0.0775,  0.0145, -0.0351,  0.0428,  0.0628,  0.0350,\n          0.0757, -0.0521, -0.0730,  0.0504, -0.0026, -0.0513, -0.0214, -0.0691,\n         -0.0061,  0.0166, -0.0086, -0.0615, -0.0879, -0.0458, -0.0671,  0.0425,\n         -0.0049, -0.0749, -0.0064, -0.0556,  0.0803, -0.0029,  0.0235,  0.0200,\n          0.0700, -0.0587, -0.0110, -0.0411, -0.0168,  0.0552,  0.0592,  0.0544,\n          0.0254,  0.0610,  0.0405,  0.0591,  0.0543, -0.0453,  0.0097,  0.0103,\n          0.0843,  0.0057, -0.0786, -0.0222,  0.0815, -0.0865, -0.0466, -0.0882,\n         -0.0212, -0.0142,  0.0859, -0.0090,  0.0603, -0.0848, -0.0558, -0.0648]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0763,  0.0641, -0.0140,  0.0313], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x78e8febdc0d0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x78e87d851990>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0503,  0.3070, -0.3107, -0.2437,  0.1624,  0.1975,  0.2240, -0.3059,\n         0.0885, -0.1494,  0.0878, -0.1648,  0.2681, -0.1555,  0.1208, -0.0896,\n        -0.2893, -0.0961, -0.2659,  0.1963, -0.1772, -0.2812, -0.0540,  0.2291,\n         0.1294, -0.2947,  0.2073, -0.3159, -0.2241,  0.3020, -0.0501,  0.1399,\n        -0.0737,  0.0656,  0.2735,  0.0360,  0.1437, -0.2421, -0.0919,  0.2563,\n         0.0046, -0.1481, -0.3351, -0.3316, -0.2588, -0.3261, -0.2294, -0.2933,\n        -0.3418,  0.1729,  0.1795,  0.1875,  0.1824, -0.1210, -0.2329, -0.0448,\n        -0.1704,  0.0994,  0.2489,  0.0480,  0.1302,  0.1312,  0.1781,  0.2730,\n        -0.3260,  0.1947,  0.2257,  0.2890,  0.0323,  0.1722, -0.0074, -0.2226,\n        -0.3510,  0.0827, -0.1001, -0.2642,  0.2034, -0.2849,  0.1065,  0.0623,\n        -0.1514,  0.3341, -0.3182,  0.0992,  0.0218,  0.2389, -0.2863,  0.1477,\n         0.3028, -0.3214,  0.1919,  0.3007,  0.1616, -0.0885, -0.3511,  0.0019,\n        -0.0581,  0.0139,  0.0947, -0.0813, -0.1953, -0.1158,  0.0666, -0.2640,\n         0.0976,  0.2707, -0.2875, -0.2400, -0.2461,  0.1037, -0.0689,  0.0278,\n         0.3327, -0.1377,  0.0547, -0.0845,  0.0474, -0.0609, -0.1855, -0.0048,\n        -0.1789, -0.2877,  0.2344, -0.2144, -0.1406,  0.3429,  0.2359,  0.3147],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0113,  0.1649,  0.1170,  ..., -0.0297,  0.3463,  0.2514],\n        [-0.1688, -0.3083, -0.3227,  ...,  0.1062,  0.1643, -0.2903],\n        [-0.0443,  0.0518,  0.2408,  ...,  0.1080, -0.0984, -0.2184],\n        ...,\n        [-0.2110,  0.2933, -0.1718,  ...,  0.0205, -0.3027, -0.1108],\n        [ 0.1682,  0.2218,  0.2637,  ...,  0.1650,  0.0789, -0.0624],\n        [-0.2748,  0.0850, -0.2944,  ...,  0.2847, -0.0053, -0.1241]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0532, -0.0343, -0.0182,  0.0550, -0.0591,  0.0103, -0.0144,  0.0712,\n        -0.0128, -0.0105, -0.0440, -0.0395,  0.0617, -0.0164,  0.0790, -0.0316,\n         0.0029, -0.0037, -0.0676,  0.0495, -0.0832,  0.0199,  0.0664, -0.0714,\n        -0.0140, -0.0209, -0.0867, -0.0152, -0.0346, -0.0246, -0.0694, -0.0122,\n         0.0636,  0.0881, -0.0459,  0.0400, -0.0090,  0.0803,  0.0589, -0.0454,\n        -0.0375, -0.0417,  0.0095,  0.0129,  0.0543,  0.0204, -0.0185, -0.0728,\n        -0.0550, -0.0258, -0.0374, -0.0207,  0.0274,  0.0119,  0.0103,  0.0112,\n        -0.0354, -0.0341, -0.0259,  0.0390,  0.0185, -0.0500, -0.0704, -0.0869,\n        -0.0603,  0.0174, -0.0060, -0.0843, -0.0307,  0.0046,  0.0408, -0.0720,\n        -0.0738, -0.0021,  0.0087, -0.0715,  0.0761,  0.0755, -0.0377, -0.0795,\n         0.0322,  0.0587,  0.0878,  0.0197, -0.0163,  0.0863, -0.0320,  0.0551,\n         0.0056, -0.0007, -0.0440,  0.0441, -0.0021, -0.0129,  0.0152,  0.0816,\n         0.0336,  0.0508, -0.0089,  0.0490, -0.0750,  0.0172, -0.0468,  0.0061,\n         0.0334,  0.0514,  0.0414,  0.0725,  0.0670,  0.0528,  0.0400,  0.0863,\n         0.0474, -0.0234, -0.0770, -0.0402,  0.0302,  0.0576,  0.0018,  0.0721,\n        -0.0100,  0.0239,  0.0215,  0.0006,  0.0392,  0.0187,  0.0787, -0.0193],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0423,  0.0240,  0.0592,  ..., -0.0213,  0.0850,  0.0738],\n        [-0.0041,  0.0456,  0.0851,  ...,  0.0288, -0.0104,  0.0592],\n        [-0.0700,  0.0066, -0.0802,  ...,  0.0394, -0.0603,  0.0058],\n        ...,\n        [-0.0803, -0.0188,  0.0539,  ..., -0.0710,  0.0025,  0.0060],\n        [-0.0425,  0.0703, -0.0386,  ...,  0.0035,  0.0184, -0.0537],\n        [-0.0151, -0.0788, -0.0878,  ..., -0.0343,  0.0025,  0.0120]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0763,  0.0641, -0.0140,  0.0313], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[ 0.0813,  0.0211, -0.0004, -0.0877,  0.0721, -0.0059,  0.0368, -0.0350,\n         -0.0356,  0.0637,  0.0381, -0.0421, -0.0635,  0.0015,  0.0263, -0.0600,\n         -0.0206,  0.0810, -0.0537, -0.0511,  0.0473,  0.0464,  0.0383, -0.0709,\n         -0.0217,  0.0842, -0.0412,  0.0495,  0.0233,  0.0016,  0.0298,  0.0480,\n         -0.0405,  0.0444,  0.0355, -0.0708, -0.0511,  0.0841,  0.0116,  0.0673,\n         -0.0383,  0.0349,  0.0199,  0.0139, -0.0102, -0.0254,  0.0501, -0.0224,\n         -0.0572,  0.0518, -0.0071,  0.0843, -0.0262,  0.0872,  0.0858, -0.0519,\n         -0.0608, -0.0790, -0.0442, -0.0015, -0.0546,  0.0397, -0.0029, -0.0042,\n         -0.0663, -0.0656, -0.0584, -0.0453,  0.0750, -0.0031,  0.0740,  0.0209,\n         -0.0050,  0.0090, -0.0732, -0.0816,  0.0792,  0.0714,  0.0726, -0.0570,\n          0.0738,  0.0064, -0.0026,  0.0823,  0.0352,  0.0517,  0.0506, -0.0200,\n          0.0832, -0.0504,  0.0597, -0.0252, -0.0568,  0.0643,  0.0068,  0.0185,\n         -0.0339, -0.0801,  0.0785, -0.0163,  0.0505,  0.0364, -0.0610,  0.0290,\n          0.0204, -0.0312, -0.0202,  0.0782,  0.0297,  0.0763,  0.0013,  0.0861,\n         -0.0561, -0.0159,  0.0759,  0.0467, -0.0569,  0.0141,  0.0230,  0.0627,\n         -0.0271, -0.0817, -0.0180,  0.0543,  0.0096, -0.0827,  0.0595, -0.0453],\n        [ 0.0778, -0.0262, -0.0650, -0.0143,  0.0523,  0.0830,  0.0201,  0.0184,\n         -0.0833,  0.0225,  0.0154,  0.0563, -0.0846,  0.0605,  0.0064,  0.0586,\n          0.0821,  0.0180, -0.0438, -0.0352, -0.0366,  0.0428, -0.0698, -0.0526,\n         -0.0181,  0.0036, -0.0636,  0.0307,  0.0772, -0.0663, -0.0058, -0.0080,\n          0.0599, -0.0682,  0.0202, -0.0636,  0.0114,  0.0771,  0.0541, -0.0377,\n          0.0677,  0.0203, -0.0091, -0.0730, -0.0741,  0.0277, -0.0477,  0.0634,\n          0.0149,  0.0822, -0.0264, -0.0275, -0.0259, -0.0004,  0.0087,  0.0658,\n          0.0224,  0.0163, -0.0791, -0.0729, -0.0808,  0.0867,  0.0465, -0.0564,\n         -0.0377,  0.0291, -0.0211, -0.0235, -0.0779, -0.0114, -0.0031,  0.0855,\n          0.0576,  0.0637, -0.0652,  0.0564, -0.0312, -0.0868,  0.0152,  0.0551,\n          0.0883,  0.0096, -0.0462,  0.0374, -0.0659, -0.0548,  0.0605,  0.0035,\n         -0.0876,  0.0373, -0.0287,  0.0748, -0.0571,  0.0570, -0.0277, -0.0431,\n         -0.0670,  0.0337,  0.0445,  0.0553, -0.0364,  0.0539, -0.0229,  0.0458,\n         -0.0179, -0.0598, -0.0144,  0.0387,  0.0559, -0.0101,  0.0407,  0.0630,\n          0.0383, -0.0411, -0.0042, -0.0571,  0.0256, -0.0443, -0.0204, -0.0329,\n         -0.0816, -0.0418,  0.0851, -0.0329, -0.0061,  0.0680, -0.0369, -0.0709],\n        [-0.0844, -0.0284, -0.0166, -0.0438,  0.0716, -0.0410, -0.0779,  0.0162,\n          0.0239,  0.0627,  0.0579,  0.0219, -0.0087,  0.0767,  0.0142, -0.0264,\n         -0.0544, -0.0791,  0.0678,  0.0062,  0.0605,  0.0287, -0.0070, -0.0742,\n         -0.0820,  0.0547,  0.0645, -0.0644,  0.0716,  0.0562,  0.0175,  0.0022,\n          0.0623,  0.0761, -0.0081,  0.0211,  0.0250, -0.0882, -0.0733, -0.0780,\n         -0.0146, -0.0206,  0.0389, -0.0349, -0.0564, -0.0749,  0.0506, -0.0778,\n          0.0178,  0.0318,  0.0815, -0.0293,  0.0462,  0.0467,  0.0828,  0.0720,\n         -0.0712, -0.0351, -0.0702,  0.0775,  0.0204,  0.0367, -0.0198,  0.0410,\n          0.0878,  0.0366,  0.0639,  0.0719, -0.0633, -0.0112,  0.0509,  0.0118,\n         -0.0354, -0.0372,  0.0794,  0.0223,  0.0156, -0.0250, -0.0232, -0.0580,\n          0.0004, -0.0206, -0.0837,  0.0782,  0.0815, -0.0509, -0.0491,  0.0715,\n          0.0231,  0.0470, -0.0652,  0.0578,  0.0726, -0.0158, -0.0881,  0.0151,\n         -0.0414, -0.0210, -0.0005, -0.0066, -0.0221, -0.0203, -0.0588, -0.0207,\n          0.0284, -0.0551,  0.0011,  0.0788,  0.0734,  0.0304,  0.0821,  0.0417,\n          0.0796,  0.0357,  0.0552,  0.0155, -0.0116,  0.0198, -0.0065,  0.0539,\n          0.0784,  0.0378, -0.0162, -0.0423, -0.0010, -0.0572, -0.0485, -0.0702],\n        [-0.0265, -0.0776, -0.0576, -0.0025, -0.0316, -0.0031, -0.0657, -0.0248,\n          0.0088, -0.0694, -0.0406, -0.0741, -0.0083, -0.0326,  0.0513, -0.0119,\n          0.0641, -0.0861, -0.0559,  0.0033,  0.0789,  0.0594,  0.0250,  0.0097,\n          0.0304, -0.0734,  0.0299,  0.0168, -0.0632,  0.0203, -0.0013, -0.0555,\n          0.0235,  0.0165, -0.0585,  0.0141, -0.0139, -0.0608,  0.0853, -0.0490,\n         -0.0191,  0.0866,  0.0514,  0.0448, -0.0539, -0.0161,  0.0542,  0.0659,\n          0.0277,  0.0499,  0.0610,  0.0853, -0.0810, -0.0413,  0.0608, -0.0128,\n          0.0542, -0.0133, -0.0493,  0.0064,  0.0433,  0.0762,  0.0793, -0.0291,\n          0.0491,  0.0651,  0.0775,  0.0145, -0.0351,  0.0428,  0.0628,  0.0350,\n          0.0757, -0.0521, -0.0730,  0.0504, -0.0026, -0.0513, -0.0214, -0.0691,\n         -0.0061,  0.0166, -0.0086, -0.0615, -0.0879, -0.0458, -0.0671,  0.0425,\n         -0.0049, -0.0749, -0.0064, -0.0556,  0.0803, -0.0029,  0.0235,  0.0200,\n          0.0700, -0.0587, -0.0110, -0.0411, -0.0168,  0.0552,  0.0592,  0.0544,\n          0.0254,  0.0610,  0.0405,  0.0591,  0.0543, -0.0453,  0.0097,  0.0103,\n          0.0843,  0.0057, -0.0786, -0.0222,  0.0815, -0.0865, -0.0466, -0.0882,\n         -0.0212, -0.0142,  0.0859, -0.0090,  0.0603, -0.0848, -0.0558, -0.0648]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x78e87b9d41d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s690360000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s690360000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}