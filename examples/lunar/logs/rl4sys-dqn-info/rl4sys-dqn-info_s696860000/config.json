{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	4,
    "batch_size":	60,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0007,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s696860000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0005,
    "sample_decay":	0.5,
    "seed":	696860000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7f685c582d10>":	{
            "_act_dim":	4,
            "_aux_batch_size":	4,
            "_batch_size":	60,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0007,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1724, -0.1034, -0.1490,  0.1010, -0.0059, -0.1018, -0.3140, -0.1427,\n         0.1863,  0.0263,  0.2255,  0.3199,  0.2658, -0.3429,  0.2779,  0.2383,\n         0.0538, -0.0203,  0.0325, -0.0103, -0.3456,  0.2507,  0.0189, -0.2354,\n         0.0645, -0.1868,  0.0181, -0.2108, -0.1249, -0.3450,  0.1348,  0.1883,\n        -0.2079,  0.2146, -0.1788, -0.3385,  0.3425,  0.2047,  0.2246,  0.0042,\n        -0.0699,  0.2676,  0.0623,  0.0789,  0.2287, -0.0155, -0.2941,  0.0414,\n         0.0417,  0.3388,  0.1847,  0.2339, -0.2205,  0.3315, -0.2620, -0.0608,\n        -0.1217,  0.0536,  0.1723,  0.3309, -0.3001,  0.2247, -0.3034, -0.2871,\n         0.1479, -0.2772,  0.1605,  0.3426,  0.2329,  0.2784,  0.0248,  0.2927,\n         0.0600,  0.2556, -0.2646,  0.1119,  0.0074,  0.1742, -0.2650, -0.1748,\n        -0.1589, -0.1062, -0.2213, -0.3463,  0.1003,  0.1508,  0.0966, -0.2144,\n        -0.2558,  0.2313,  0.0206,  0.0879,  0.2358, -0.2173,  0.0859, -0.2452,\n        -0.1101,  0.1279, -0.2624, -0.2400,  0.0687, -0.1267,  0.1884, -0.1181,\n         0.2380,  0.0961,  0.3296,  0.3186,  0.2501, -0.1978, -0.0029,  0.0759,\n        -0.0934,  0.2204, -0.1432, -0.0682,  0.1061, -0.2925,  0.1708,  0.0702,\n        -0.3362,  0.0398, -0.0670,  0.2329,  0.1199, -0.1223,  0.2917,  0.2189],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.3242,  0.0015,  0.1932,  ..., -0.0654, -0.1830, -0.3019],\n        [ 0.2245,  0.0497,  0.0219,  ...,  0.2072,  0.2893,  0.2486],\n        [ 0.1612,  0.0423,  0.2194,  ..., -0.2533,  0.0574, -0.2926],\n        ...,\n        [-0.0868,  0.2269,  0.2117,  ..., -0.0043,  0.2951, -0.2025],\n        [ 0.1943,  0.0725, -0.1064,  ..., -0.2828, -0.0705,  0.1485],\n        [ 0.1193, -0.2957, -0.1393,  ..., -0.3208, -0.1977,  0.3418]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0410,  0.0806,  0.0116, -0.0142, -0.0446,  0.0267, -0.0577, -0.0440,\n        -0.0132,  0.0436, -0.0649,  0.0491, -0.0434, -0.0412, -0.0339, -0.0001,\n         0.0807, -0.0544,  0.0314, -0.0214,  0.0538,  0.0484, -0.0266,  0.0547,\n        -0.0116,  0.0339, -0.0149,  0.0010,  0.0418, -0.0703,  0.0786,  0.0629,\n        -0.0490,  0.0411,  0.0048,  0.0171,  0.0095, -0.0489,  0.0249, -0.0445,\n         0.0468,  0.0220,  0.0339,  0.0658,  0.0520,  0.0284, -0.0334,  0.0814,\n        -0.0565, -0.0333, -0.0815,  0.0201,  0.0348,  0.0098, -0.0498, -0.0165,\n         0.0827,  0.0366,  0.0142,  0.0355, -0.0401, -0.0150, -0.0430, -0.0304,\n        -0.0575, -0.0043,  0.0565,  0.0186, -0.0459,  0.0681, -0.0312,  0.0218,\n        -0.0638, -0.0594, -0.0093, -0.0002,  0.0474, -0.0627, -0.0325, -0.0398,\n        -0.0711, -0.0056,  0.0535,  0.0079, -0.0063,  0.0508,  0.0283, -0.0766,\n        -0.0421,  0.0826,  0.0164, -0.0102, -0.0299,  0.0832, -0.0548,  0.0862,\n         0.0827,  0.0348,  0.0412,  0.0753,  0.0553,  0.0325, -0.0478, -0.0825,\n        -0.0787,  0.0202,  0.0004,  0.0089, -0.0581, -0.0646, -0.0805,  0.0724,\n         0.0707, -0.0167,  0.0007,  0.0807, -0.0544,  0.0163, -0.0728,  0.0709,\n         0.0022, -0.0313, -0.0096,  0.0288, -0.0491,  0.0081,  0.0536,  0.0020],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0651,  0.0467,  0.0157,  ...,  0.0448, -0.0496, -0.0620],\n        [ 0.0232,  0.0032, -0.0477,  ..., -0.0627, -0.0109,  0.0647],\n        [ 0.0515, -0.0819, -0.0455,  ...,  0.0863, -0.0626,  0.0516],\n        ...,\n        [ 0.0071, -0.0793,  0.0803,  ..., -0.0545, -0.0270, -0.0353],\n        [ 0.0597, -0.0322, -0.0533,  ..., -0.0755,  0.0079, -0.0704],\n        [ 0.0155,  0.0318, -0.0011,  ...,  0.0144,  0.0160,  0.0365]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	true
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0372, -0.0383, -0.0456, -0.0760], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0641, -0.0208, -0.0841,  0.0030, -0.0240, -0.0037,  0.0253, -0.0733,\n         -0.0499,  0.0012,  0.0781,  0.0704,  0.0296, -0.0427,  0.0788, -0.0236,\n          0.0443,  0.0332, -0.0829,  0.0305,  0.0767, -0.0034,  0.0010,  0.0100,\n         -0.0519, -0.0241, -0.0713, -0.0196, -0.0420, -0.0633,  0.0570,  0.0345,\n          0.0524,  0.0389, -0.0070,  0.0315,  0.0186,  0.0849, -0.0444,  0.0605,\n          0.0485,  0.0691, -0.0527,  0.0250,  0.0681,  0.0207, -0.0815,  0.0568,\n         -0.0741,  0.0022,  0.0455, -0.0492, -0.0397, -0.0247, -0.0028,  0.0312,\n          0.0697, -0.0705,  0.0411,  0.0698,  0.0537, -0.0145,  0.0309, -0.0453,\n          0.0460, -0.0370, -0.0807,  0.0545, -0.0651, -0.0217, -0.0260,  0.0047,\n         -0.0456,  0.0113, -0.0590,  0.0543, -0.0662,  0.0315,  0.0232, -0.0682,\n         -0.0052,  0.0277, -0.0838, -0.0681,  0.0076,  0.0754,  0.0555, -0.0642,\n          0.0856, -0.0310, -0.0297, -0.0834, -0.0184, -0.0247,  0.0171,  0.0711,\n         -0.0117, -0.0495,  0.0035,  0.0357, -0.0556,  0.0870,  0.0514, -0.0532,\n         -0.0049, -0.0739, -0.0354, -0.0551,  0.0485, -0.0209, -0.0335,  0.0013,\n         -0.0605,  0.0036,  0.0041, -0.0494,  0.0715,  0.0271, -0.0774,  0.0446,\n          0.0546, -0.0379,  0.0332,  0.0862, -0.0015,  0.0549,  0.0207,  0.0432],\n        [ 0.0343, -0.0508, -0.0433, -0.0437,  0.0112,  0.0066, -0.0617, -0.0297,\n         -0.0392,  0.0837,  0.0484, -0.0840, -0.0085,  0.0584, -0.0470, -0.0663,\n          0.0511,  0.0240, -0.0087, -0.0518, -0.0822,  0.0518,  0.0266, -0.0022,\n         -0.0583, -0.0019,  0.0253,  0.0663, -0.0148, -0.0257, -0.0027, -0.0475,\n         -0.0106, -0.0736, -0.0441, -0.0057,  0.0851,  0.0620, -0.0781, -0.0497,\n         -0.0393,  0.0499,  0.0466, -0.0148, -0.0466,  0.0868, -0.0445, -0.0416,\n         -0.0700, -0.0714,  0.0414,  0.0288, -0.0199, -0.0552,  0.0772, -0.0717,\n          0.0827, -0.0646,  0.0818,  0.0141,  0.0471,  0.0308,  0.0564,  0.0748,\n          0.0304, -0.0747, -0.0204, -0.0857, -0.0296, -0.0176,  0.0833,  0.0089,\n          0.0302,  0.0562, -0.0127, -0.0622, -0.0343,  0.0216,  0.0146, -0.0563,\n          0.0850,  0.0403, -0.0604, -0.0018, -0.0583,  0.0327, -0.0443, -0.0201,\n         -0.0690,  0.0581,  0.0302,  0.0774, -0.0137, -0.0409,  0.0585,  0.0186,\n         -0.0214,  0.0734,  0.0766, -0.0116,  0.0492,  0.0283, -0.0050,  0.0194,\n         -0.0416, -0.0865, -0.0301, -0.0059, -0.0716,  0.0520, -0.0070, -0.0845,\n          0.0778, -0.0185, -0.0022, -0.0136,  0.0053, -0.0825, -0.0329,  0.0682,\n         -0.0273, -0.0759,  0.0104, -0.0419, -0.0010,  0.0662, -0.0092, -0.0581],\n        [-0.0018, -0.0180, -0.0849,  0.0730,  0.0646, -0.0589,  0.0591,  0.0094,\n          0.0337, -0.0818, -0.0484, -0.0365,  0.0707,  0.0325, -0.0840, -0.0627,\n          0.0399, -0.0710,  0.0371,  0.0101, -0.0306, -0.0349,  0.0755,  0.0253,\n         -0.0734,  0.0298,  0.0524,  0.0290,  0.0047, -0.0490, -0.0390, -0.0497,\n          0.0073, -0.0052, -0.0186, -0.0663,  0.0632,  0.0282, -0.0015,  0.0873,\n          0.0649, -0.0833,  0.0537,  0.0157,  0.0758, -0.0007,  0.0854,  0.0432,\n         -0.0179, -0.0854,  0.0710,  0.0416,  0.0333,  0.0121, -0.0544,  0.0819,\n         -0.0424,  0.0718, -0.0720,  0.0113, -0.0307, -0.0228, -0.0251, -0.0054,\n          0.0478, -0.0123, -0.0602, -0.0477, -0.0343,  0.0395,  0.0414, -0.0622,\n          0.0615,  0.0298,  0.0266, -0.0798,  0.0169, -0.0546, -0.0477, -0.0466,\n          0.0085, -0.0072, -0.0133,  0.0134,  0.0708,  0.0591, -0.0709,  0.0153,\n         -0.0292,  0.0558,  0.0787,  0.0039,  0.0077,  0.0306,  0.0661, -0.0495,\n         -0.0671, -0.0134,  0.0088,  0.0815,  0.0229, -0.0619,  0.0135, -0.0576,\n         -0.0402,  0.0826,  0.0255,  0.0063, -0.0479,  0.0645, -0.0151, -0.0489,\n          0.0182, -0.0710, -0.0037,  0.0441,  0.0854, -0.0030, -0.0535, -0.0520,\n          0.0538,  0.0064, -0.0859, -0.0494, -0.0462, -0.0310,  0.0190, -0.0271],\n        [-0.0505,  0.0211,  0.0300, -0.0472, -0.0796, -0.0078,  0.0248,  0.0806,\n         -0.0621,  0.0690, -0.0530,  0.0284,  0.0386,  0.0447, -0.0593,  0.0030,\n         -0.0232, -0.0311, -0.0474, -0.0212,  0.0600,  0.0030, -0.0352,  0.0285,\n          0.0537, -0.0020,  0.0151, -0.0578,  0.0054, -0.0213, -0.0314,  0.0193,\n          0.0418,  0.0144,  0.0378, -0.0167, -0.0184,  0.0387,  0.0226,  0.0554,\n          0.0071, -0.0370, -0.0472, -0.0353,  0.0527, -0.0196,  0.0798, -0.0784,\n         -0.0383,  0.0092,  0.0700,  0.0871,  0.0079, -0.0859, -0.0479,  0.0552,\n          0.0503, -0.0550,  0.0595,  0.0293,  0.0343,  0.0614,  0.0192, -0.0328,\n          0.0867,  0.0156, -0.0453, -0.0253, -0.0665,  0.0314, -0.0354, -0.0401,\n          0.0324,  0.0316,  0.0249, -0.0488,  0.0421, -0.0221, -0.0815, -0.0665,\n          0.0060,  0.0864,  0.0838,  0.0391,  0.0048, -0.0749,  0.0171, -0.0856,\n          0.0510, -0.0361, -0.0761,  0.0756, -0.0591,  0.0243, -0.0328,  0.0856,\n          0.0039, -0.0700, -0.0346,  0.0161, -0.0765, -0.0703,  0.0619,  0.0362,\n         -0.0251, -0.0009, -0.0533,  0.0463,  0.0542, -0.0800, -0.0502,  0.0374,\n         -0.0333, -0.0758, -0.0004,  0.0796, -0.0409, -0.0268,  0.0337, -0.0001,\n         -0.0119,  0.0610,  0.0566,  0.0504,  0.0652,  0.0680,  0.0673,  0.0149]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.3242,  0.0015,  0.1932,  ..., -0.0654, -0.1830, -0.3019],\n        [ 0.2245,  0.0497,  0.0219,  ...,  0.2072,  0.2893,  0.2486],\n        [ 0.1612,  0.0423,  0.2194,  ..., -0.2533,  0.0574, -0.2926],\n        ...,\n        [-0.0868,  0.2269,  0.2117,  ..., -0.0043,  0.2951, -0.2025],\n        [ 0.1943,  0.0725, -0.1064,  ..., -0.2828, -0.0705,  0.1485],\n        [ 0.1193, -0.2957, -0.1393,  ..., -0.3208, -0.1977,  0.3418]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1724, -0.1034, -0.1490,  0.1010, -0.0059, -0.1018, -0.3140, -0.1427,\n         0.1863,  0.0263,  0.2255,  0.3199,  0.2658, -0.3429,  0.2779,  0.2383,\n         0.0538, -0.0203,  0.0325, -0.0103, -0.3456,  0.2507,  0.0189, -0.2354,\n         0.0645, -0.1868,  0.0181, -0.2108, -0.1249, -0.3450,  0.1348,  0.1883,\n        -0.2079,  0.2146, -0.1788, -0.3385,  0.3425,  0.2047,  0.2246,  0.0042,\n        -0.0699,  0.2676,  0.0623,  0.0789,  0.2287, -0.0155, -0.2941,  0.0414,\n         0.0417,  0.3388,  0.1847,  0.2339, -0.2205,  0.3315, -0.2620, -0.0608,\n        -0.1217,  0.0536,  0.1723,  0.3309, -0.3001,  0.2247, -0.3034, -0.2871,\n         0.1479, -0.2772,  0.1605,  0.3426,  0.2329,  0.2784,  0.0248,  0.2927,\n         0.0600,  0.2556, -0.2646,  0.1119,  0.0074,  0.1742, -0.2650, -0.1748,\n        -0.1589, -0.1062, -0.2213, -0.3463,  0.1003,  0.1508,  0.0966, -0.2144,\n        -0.2558,  0.2313,  0.0206,  0.0879,  0.2358, -0.2173,  0.0859, -0.2452,\n        -0.1101,  0.1279, -0.2624, -0.2400,  0.0687, -0.1267,  0.1884, -0.1181,\n         0.2380,  0.0961,  0.3296,  0.3186,  0.2501, -0.1978, -0.0029,  0.0759,\n        -0.0934,  0.2204, -0.1432, -0.0682,  0.1061, -0.2925,  0.1708,  0.0702,\n        -0.3362,  0.0398, -0.0670,  0.2329,  0.1199, -0.1223,  0.2917,  0.2189],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0651,  0.0467,  0.0157,  ...,  0.0448, -0.0496, -0.0620],\n        [ 0.0232,  0.0032, -0.0477,  ..., -0.0627, -0.0109,  0.0647],\n        [ 0.0515, -0.0819, -0.0455,  ...,  0.0863, -0.0626,  0.0516],\n        ...,\n        [ 0.0071, -0.0793,  0.0803,  ..., -0.0545, -0.0270, -0.0353],\n        [ 0.0597, -0.0322, -0.0533,  ..., -0.0755,  0.0079, -0.0704],\n        [ 0.0155,  0.0318, -0.0011,  ...,  0.0144,  0.0160,  0.0365]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0410,  0.0806,  0.0116, -0.0142, -0.0446,  0.0267, -0.0577, -0.0440,\n        -0.0132,  0.0436, -0.0649,  0.0491, -0.0434, -0.0412, -0.0339, -0.0001,\n         0.0807, -0.0544,  0.0314, -0.0214,  0.0538,  0.0484, -0.0266,  0.0547,\n        -0.0116,  0.0339, -0.0149,  0.0010,  0.0418, -0.0703,  0.0786,  0.0629,\n        -0.0490,  0.0411,  0.0048,  0.0171,  0.0095, -0.0489,  0.0249, -0.0445,\n         0.0468,  0.0220,  0.0339,  0.0658,  0.0520,  0.0284, -0.0334,  0.0814,\n        -0.0565, -0.0333, -0.0815,  0.0201,  0.0348,  0.0098, -0.0498, -0.0165,\n         0.0827,  0.0366,  0.0142,  0.0355, -0.0401, -0.0150, -0.0430, -0.0304,\n        -0.0575, -0.0043,  0.0565,  0.0186, -0.0459,  0.0681, -0.0312,  0.0218,\n        -0.0638, -0.0594, -0.0093, -0.0002,  0.0474, -0.0627, -0.0325, -0.0398,\n        -0.0711, -0.0056,  0.0535,  0.0079, -0.0063,  0.0508,  0.0283, -0.0766,\n        -0.0421,  0.0826,  0.0164, -0.0102, -0.0299,  0.0832, -0.0548,  0.0862,\n         0.0827,  0.0348,  0.0412,  0.0753,  0.0553,  0.0325, -0.0478, -0.0825,\n        -0.0787,  0.0202,  0.0004,  0.0089, -0.0581, -0.0646, -0.0805,  0.0724,\n         0.0707, -0.0167,  0.0007,  0.0807, -0.0544,  0.0163, -0.0728,  0.0709,\n         0.0022, -0.0313, -0.0096,  0.0288, -0.0491,  0.0081,  0.0536,  0.0020],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0641, -0.0208, -0.0841,  0.0030, -0.0240, -0.0037,  0.0253, -0.0733,\n         -0.0499,  0.0012,  0.0781,  0.0704,  0.0296, -0.0427,  0.0788, -0.0236,\n          0.0443,  0.0332, -0.0829,  0.0305,  0.0767, -0.0034,  0.0010,  0.0100,\n         -0.0519, -0.0241, -0.0713, -0.0196, -0.0420, -0.0633,  0.0570,  0.0345,\n          0.0524,  0.0389, -0.0070,  0.0315,  0.0186,  0.0849, -0.0444,  0.0605,\n          0.0485,  0.0691, -0.0527,  0.0250,  0.0681,  0.0207, -0.0815,  0.0568,\n         -0.0741,  0.0022,  0.0455, -0.0492, -0.0397, -0.0247, -0.0028,  0.0312,\n          0.0697, -0.0705,  0.0411,  0.0698,  0.0537, -0.0145,  0.0309, -0.0453,\n          0.0460, -0.0370, -0.0807,  0.0545, -0.0651, -0.0217, -0.0260,  0.0047,\n         -0.0456,  0.0113, -0.0590,  0.0543, -0.0662,  0.0315,  0.0232, -0.0682,\n         -0.0052,  0.0277, -0.0838, -0.0681,  0.0076,  0.0754,  0.0555, -0.0642,\n          0.0856, -0.0310, -0.0297, -0.0834, -0.0184, -0.0247,  0.0171,  0.0711,\n         -0.0117, -0.0495,  0.0035,  0.0357, -0.0556,  0.0870,  0.0514, -0.0532,\n         -0.0049, -0.0739, -0.0354, -0.0551,  0.0485, -0.0209, -0.0335,  0.0013,\n         -0.0605,  0.0036,  0.0041, -0.0494,  0.0715,  0.0271, -0.0774,  0.0446,\n          0.0546, -0.0379,  0.0332,  0.0862, -0.0015,  0.0549,  0.0207,  0.0432],\n        [ 0.0343, -0.0508, -0.0433, -0.0437,  0.0112,  0.0066, -0.0617, -0.0297,\n         -0.0392,  0.0837,  0.0484, -0.0840, -0.0085,  0.0584, -0.0470, -0.0663,\n          0.0511,  0.0240, -0.0087, -0.0518, -0.0822,  0.0518,  0.0266, -0.0022,\n         -0.0583, -0.0019,  0.0253,  0.0663, -0.0148, -0.0257, -0.0027, -0.0475,\n         -0.0106, -0.0736, -0.0441, -0.0057,  0.0851,  0.0620, -0.0781, -0.0497,\n         -0.0393,  0.0499,  0.0466, -0.0148, -0.0466,  0.0868, -0.0445, -0.0416,\n         -0.0700, -0.0714,  0.0414,  0.0288, -0.0199, -0.0552,  0.0772, -0.0717,\n          0.0827, -0.0646,  0.0818,  0.0141,  0.0471,  0.0308,  0.0564,  0.0748,\n          0.0304, -0.0747, -0.0204, -0.0857, -0.0296, -0.0176,  0.0833,  0.0089,\n          0.0302,  0.0562, -0.0127, -0.0622, -0.0343,  0.0216,  0.0146, -0.0563,\n          0.0850,  0.0403, -0.0604, -0.0018, -0.0583,  0.0327, -0.0443, -0.0201,\n         -0.0690,  0.0581,  0.0302,  0.0774, -0.0137, -0.0409,  0.0585,  0.0186,\n         -0.0214,  0.0734,  0.0766, -0.0116,  0.0492,  0.0283, -0.0050,  0.0194,\n         -0.0416, -0.0865, -0.0301, -0.0059, -0.0716,  0.0520, -0.0070, -0.0845,\n          0.0778, -0.0185, -0.0022, -0.0136,  0.0053, -0.0825, -0.0329,  0.0682,\n         -0.0273, -0.0759,  0.0104, -0.0419, -0.0010,  0.0662, -0.0092, -0.0581],\n        [-0.0018, -0.0180, -0.0849,  0.0730,  0.0646, -0.0589,  0.0591,  0.0094,\n          0.0337, -0.0818, -0.0484, -0.0365,  0.0707,  0.0325, -0.0840, -0.0627,\n          0.0399, -0.0710,  0.0371,  0.0101, -0.0306, -0.0349,  0.0755,  0.0253,\n         -0.0734,  0.0298,  0.0524,  0.0290,  0.0047, -0.0490, -0.0390, -0.0497,\n          0.0073, -0.0052, -0.0186, -0.0663,  0.0632,  0.0282, -0.0015,  0.0873,\n          0.0649, -0.0833,  0.0537,  0.0157,  0.0758, -0.0007,  0.0854,  0.0432,\n         -0.0179, -0.0854,  0.0710,  0.0416,  0.0333,  0.0121, -0.0544,  0.0819,\n         -0.0424,  0.0718, -0.0720,  0.0113, -0.0307, -0.0228, -0.0251, -0.0054,\n          0.0478, -0.0123, -0.0602, -0.0477, -0.0343,  0.0395,  0.0414, -0.0622,\n          0.0615,  0.0298,  0.0266, -0.0798,  0.0169, -0.0546, -0.0477, -0.0466,\n          0.0085, -0.0072, -0.0133,  0.0134,  0.0708,  0.0591, -0.0709,  0.0153,\n         -0.0292,  0.0558,  0.0787,  0.0039,  0.0077,  0.0306,  0.0661, -0.0495,\n         -0.0671, -0.0134,  0.0088,  0.0815,  0.0229, -0.0619,  0.0135, -0.0576,\n         -0.0402,  0.0826,  0.0255,  0.0063, -0.0479,  0.0645, -0.0151, -0.0489,\n          0.0182, -0.0710, -0.0037,  0.0441,  0.0854, -0.0030, -0.0535, -0.0520,\n          0.0538,  0.0064, -0.0859, -0.0494, -0.0462, -0.0310,  0.0190, -0.0271],\n        [-0.0505,  0.0211,  0.0300, -0.0472, -0.0796, -0.0078,  0.0248,  0.0806,\n         -0.0621,  0.0690, -0.0530,  0.0284,  0.0386,  0.0447, -0.0593,  0.0030,\n         -0.0232, -0.0311, -0.0474, -0.0212,  0.0600,  0.0030, -0.0352,  0.0285,\n          0.0537, -0.0020,  0.0151, -0.0578,  0.0054, -0.0213, -0.0314,  0.0193,\n          0.0418,  0.0144,  0.0378, -0.0167, -0.0184,  0.0387,  0.0226,  0.0554,\n          0.0071, -0.0370, -0.0472, -0.0353,  0.0527, -0.0196,  0.0798, -0.0784,\n         -0.0383,  0.0092,  0.0700,  0.0871,  0.0079, -0.0859, -0.0479,  0.0552,\n          0.0503, -0.0550,  0.0595,  0.0293,  0.0343,  0.0614,  0.0192, -0.0328,\n          0.0867,  0.0156, -0.0453, -0.0253, -0.0665,  0.0314, -0.0354, -0.0401,\n          0.0324,  0.0316,  0.0249, -0.0488,  0.0421, -0.0221, -0.0815, -0.0665,\n          0.0060,  0.0864,  0.0838,  0.0391,  0.0048, -0.0749,  0.0171, -0.0856,\n          0.0510, -0.0361, -0.0761,  0.0756, -0.0591,  0.0243, -0.0328,  0.0856,\n          0.0039, -0.0700, -0.0346,  0.0161, -0.0765, -0.0703,  0.0619,  0.0362,\n         -0.0251, -0.0009, -0.0533,  0.0463,  0.0542, -0.0800, -0.0502,  0.0374,\n         -0.0333, -0.0758, -0.0004,  0.0796, -0.0409, -0.0268,  0.0337, -0.0001,\n         -0.0119,  0.0610,  0.0566,  0.0504,  0.0652,  0.0680,  0.0673,  0.0149]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0372, -0.0383, -0.0456, -0.0760], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7f68d4fde510>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x7f685bb769d0>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (fc1): Linear(in_features=8, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=128, bias=True)\n  (fc3): Linear(in_features=128, out_features=4, bias=True)\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "fc1":	{
                            "Linear(in_features=8, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.1724, -0.1034, -0.1490,  0.1010, -0.0059, -0.1018, -0.3140, -0.1427,\n         0.1863,  0.0263,  0.2255,  0.3199,  0.2658, -0.3429,  0.2779,  0.2383,\n         0.0538, -0.0203,  0.0325, -0.0103, -0.3456,  0.2507,  0.0189, -0.2354,\n         0.0645, -0.1868,  0.0181, -0.2108, -0.1249, -0.3450,  0.1348,  0.1883,\n        -0.2079,  0.2146, -0.1788, -0.3385,  0.3425,  0.2047,  0.2246,  0.0042,\n        -0.0699,  0.2676,  0.0623,  0.0789,  0.2287, -0.0155, -0.2941,  0.0414,\n         0.0417,  0.3388,  0.1847,  0.2339, -0.2205,  0.3315, -0.2620, -0.0608,\n        -0.1217,  0.0536,  0.1723,  0.3309, -0.3001,  0.2247, -0.3034, -0.2871,\n         0.1479, -0.2772,  0.1605,  0.3426,  0.2329,  0.2784,  0.0248,  0.2927,\n         0.0600,  0.2556, -0.2646,  0.1119,  0.0074,  0.1742, -0.2650, -0.1748,\n        -0.1589, -0.1062, -0.2213, -0.3463,  0.1003,  0.1508,  0.0966, -0.2144,\n        -0.2558,  0.2313,  0.0206,  0.0879,  0.2358, -0.2173,  0.0859, -0.2452,\n        -0.1101,  0.1279, -0.2624, -0.2400,  0.0687, -0.1267,  0.1884, -0.1181,\n         0.2380,  0.0961,  0.3296,  0.3186,  0.2501, -0.1978, -0.0029,  0.0759,\n        -0.0934,  0.2204, -0.1432, -0.0682,  0.1061, -0.2925,  0.1708,  0.0702,\n        -0.3362,  0.0398, -0.0670,  0.2329,  0.1199, -0.1223,  0.2917,  0.2189],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.3242,  0.0015,  0.1932,  ..., -0.0654, -0.1830, -0.3019],\n        [ 0.2245,  0.0497,  0.0219,  ...,  0.2072,  0.2893,  0.2486],\n        [ 0.1612,  0.0423,  0.2194,  ..., -0.2533,  0.0574, -0.2926],\n        ...,\n        [-0.0868,  0.2269,  0.2117,  ..., -0.0043,  0.2951, -0.2025],\n        [ 0.1943,  0.0725, -0.1064,  ..., -0.2828, -0.0705,  0.1485],\n        [ 0.1193, -0.2957, -0.1393,  ..., -0.3208, -0.1977,  0.3418]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	8,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc2":	{
                            "Linear(in_features=128, out_features=128, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([ 0.0410,  0.0806,  0.0116, -0.0142, -0.0446,  0.0267, -0.0577, -0.0440,\n        -0.0132,  0.0436, -0.0649,  0.0491, -0.0434, -0.0412, -0.0339, -0.0001,\n         0.0807, -0.0544,  0.0314, -0.0214,  0.0538,  0.0484, -0.0266,  0.0547,\n        -0.0116,  0.0339, -0.0149,  0.0010,  0.0418, -0.0703,  0.0786,  0.0629,\n        -0.0490,  0.0411,  0.0048,  0.0171,  0.0095, -0.0489,  0.0249, -0.0445,\n         0.0468,  0.0220,  0.0339,  0.0658,  0.0520,  0.0284, -0.0334,  0.0814,\n        -0.0565, -0.0333, -0.0815,  0.0201,  0.0348,  0.0098, -0.0498, -0.0165,\n         0.0827,  0.0366,  0.0142,  0.0355, -0.0401, -0.0150, -0.0430, -0.0304,\n        -0.0575, -0.0043,  0.0565,  0.0186, -0.0459,  0.0681, -0.0312,  0.0218,\n        -0.0638, -0.0594, -0.0093, -0.0002,  0.0474, -0.0627, -0.0325, -0.0398,\n        -0.0711, -0.0056,  0.0535,  0.0079, -0.0063,  0.0508,  0.0283, -0.0766,\n        -0.0421,  0.0826,  0.0164, -0.0102, -0.0299,  0.0832, -0.0548,  0.0862,\n         0.0827,  0.0348,  0.0412,  0.0753,  0.0553,  0.0325, -0.0478, -0.0825,\n        -0.0787,  0.0202,  0.0004,  0.0089, -0.0581, -0.0646, -0.0805,  0.0724,\n         0.0707, -0.0167,  0.0007,  0.0807, -0.0544,  0.0163, -0.0728,  0.0709,\n         0.0022, -0.0313, -0.0096,  0.0288, -0.0491,  0.0081,  0.0536,  0.0020],\n       requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0651,  0.0467,  0.0157,  ...,  0.0448, -0.0496, -0.0620],\n        [ 0.0232,  0.0032, -0.0477,  ..., -0.0627, -0.0109,  0.0647],\n        [ 0.0515, -0.0819, -0.0455,  ...,  0.0863, -0.0626,  0.0516],\n        ...,\n        [ 0.0071, -0.0793,  0.0803,  ..., -0.0545, -0.0270, -0.0353],\n        [ 0.0597, -0.0322, -0.0533,  ..., -0.0755,  0.0079, -0.0704],\n        [ 0.0155,  0.0318, -0.0011,  ...,  0.0144,  0.0160,  0.0365]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	128,
                                "training":	false
                            }
                        },
                        "fc3":	{
                            "Linear(in_features=128, out_features=4, bias=True)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{},
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{
                                    "bias":	"Parameter containing:\ntensor([-0.0372, -0.0383, -0.0456, -0.0760], requires_grad=True)",
                                    "weight":	"Parameter containing:\ntensor([[-0.0641, -0.0208, -0.0841,  0.0030, -0.0240, -0.0037,  0.0253, -0.0733,\n         -0.0499,  0.0012,  0.0781,  0.0704,  0.0296, -0.0427,  0.0788, -0.0236,\n          0.0443,  0.0332, -0.0829,  0.0305,  0.0767, -0.0034,  0.0010,  0.0100,\n         -0.0519, -0.0241, -0.0713, -0.0196, -0.0420, -0.0633,  0.0570,  0.0345,\n          0.0524,  0.0389, -0.0070,  0.0315,  0.0186,  0.0849, -0.0444,  0.0605,\n          0.0485,  0.0691, -0.0527,  0.0250,  0.0681,  0.0207, -0.0815,  0.0568,\n         -0.0741,  0.0022,  0.0455, -0.0492, -0.0397, -0.0247, -0.0028,  0.0312,\n          0.0697, -0.0705,  0.0411,  0.0698,  0.0537, -0.0145,  0.0309, -0.0453,\n          0.0460, -0.0370, -0.0807,  0.0545, -0.0651, -0.0217, -0.0260,  0.0047,\n         -0.0456,  0.0113, -0.0590,  0.0543, -0.0662,  0.0315,  0.0232, -0.0682,\n         -0.0052,  0.0277, -0.0838, -0.0681,  0.0076,  0.0754,  0.0555, -0.0642,\n          0.0856, -0.0310, -0.0297, -0.0834, -0.0184, -0.0247,  0.0171,  0.0711,\n         -0.0117, -0.0495,  0.0035,  0.0357, -0.0556,  0.0870,  0.0514, -0.0532,\n         -0.0049, -0.0739, -0.0354, -0.0551,  0.0485, -0.0209, -0.0335,  0.0013,\n         -0.0605,  0.0036,  0.0041, -0.0494,  0.0715,  0.0271, -0.0774,  0.0446,\n          0.0546, -0.0379,  0.0332,  0.0862, -0.0015,  0.0549,  0.0207,  0.0432],\n        [ 0.0343, -0.0508, -0.0433, -0.0437,  0.0112,  0.0066, -0.0617, -0.0297,\n         -0.0392,  0.0837,  0.0484, -0.0840, -0.0085,  0.0584, -0.0470, -0.0663,\n          0.0511,  0.0240, -0.0087, -0.0518, -0.0822,  0.0518,  0.0266, -0.0022,\n         -0.0583, -0.0019,  0.0253,  0.0663, -0.0148, -0.0257, -0.0027, -0.0475,\n         -0.0106, -0.0736, -0.0441, -0.0057,  0.0851,  0.0620, -0.0781, -0.0497,\n         -0.0393,  0.0499,  0.0466, -0.0148, -0.0466,  0.0868, -0.0445, -0.0416,\n         -0.0700, -0.0714,  0.0414,  0.0288, -0.0199, -0.0552,  0.0772, -0.0717,\n          0.0827, -0.0646,  0.0818,  0.0141,  0.0471,  0.0308,  0.0564,  0.0748,\n          0.0304, -0.0747, -0.0204, -0.0857, -0.0296, -0.0176,  0.0833,  0.0089,\n          0.0302,  0.0562, -0.0127, -0.0622, -0.0343,  0.0216,  0.0146, -0.0563,\n          0.0850,  0.0403, -0.0604, -0.0018, -0.0583,  0.0327, -0.0443, -0.0201,\n         -0.0690,  0.0581,  0.0302,  0.0774, -0.0137, -0.0409,  0.0585,  0.0186,\n         -0.0214,  0.0734,  0.0766, -0.0116,  0.0492,  0.0283, -0.0050,  0.0194,\n         -0.0416, -0.0865, -0.0301, -0.0059, -0.0716,  0.0520, -0.0070, -0.0845,\n          0.0778, -0.0185, -0.0022, -0.0136,  0.0053, -0.0825, -0.0329,  0.0682,\n         -0.0273, -0.0759,  0.0104, -0.0419, -0.0010,  0.0662, -0.0092, -0.0581],\n        [-0.0018, -0.0180, -0.0849,  0.0730,  0.0646, -0.0589,  0.0591,  0.0094,\n          0.0337, -0.0818, -0.0484, -0.0365,  0.0707,  0.0325, -0.0840, -0.0627,\n          0.0399, -0.0710,  0.0371,  0.0101, -0.0306, -0.0349,  0.0755,  0.0253,\n         -0.0734,  0.0298,  0.0524,  0.0290,  0.0047, -0.0490, -0.0390, -0.0497,\n          0.0073, -0.0052, -0.0186, -0.0663,  0.0632,  0.0282, -0.0015,  0.0873,\n          0.0649, -0.0833,  0.0537,  0.0157,  0.0758, -0.0007,  0.0854,  0.0432,\n         -0.0179, -0.0854,  0.0710,  0.0416,  0.0333,  0.0121, -0.0544,  0.0819,\n         -0.0424,  0.0718, -0.0720,  0.0113, -0.0307, -0.0228, -0.0251, -0.0054,\n          0.0478, -0.0123, -0.0602, -0.0477, -0.0343,  0.0395,  0.0414, -0.0622,\n          0.0615,  0.0298,  0.0266, -0.0798,  0.0169, -0.0546, -0.0477, -0.0466,\n          0.0085, -0.0072, -0.0133,  0.0134,  0.0708,  0.0591, -0.0709,  0.0153,\n         -0.0292,  0.0558,  0.0787,  0.0039,  0.0077,  0.0306,  0.0661, -0.0495,\n         -0.0671, -0.0134,  0.0088,  0.0815,  0.0229, -0.0619,  0.0135, -0.0576,\n         -0.0402,  0.0826,  0.0255,  0.0063, -0.0479,  0.0645, -0.0151, -0.0489,\n          0.0182, -0.0710, -0.0037,  0.0441,  0.0854, -0.0030, -0.0535, -0.0520,\n          0.0538,  0.0064, -0.0859, -0.0494, -0.0462, -0.0310,  0.0190, -0.0271],\n        [-0.0505,  0.0211,  0.0300, -0.0472, -0.0796, -0.0078,  0.0248,  0.0806,\n         -0.0621,  0.0690, -0.0530,  0.0284,  0.0386,  0.0447, -0.0593,  0.0030,\n         -0.0232, -0.0311, -0.0474, -0.0212,  0.0600,  0.0030, -0.0352,  0.0285,\n          0.0537, -0.0020,  0.0151, -0.0578,  0.0054, -0.0213, -0.0314,  0.0193,\n          0.0418,  0.0144,  0.0378, -0.0167, -0.0184,  0.0387,  0.0226,  0.0554,\n          0.0071, -0.0370, -0.0472, -0.0353,  0.0527, -0.0196,  0.0798, -0.0784,\n         -0.0383,  0.0092,  0.0700,  0.0871,  0.0079, -0.0859, -0.0479,  0.0552,\n          0.0503, -0.0550,  0.0595,  0.0293,  0.0343,  0.0614,  0.0192, -0.0328,\n          0.0867,  0.0156, -0.0453, -0.0253, -0.0665,  0.0314, -0.0354, -0.0401,\n          0.0324,  0.0316,  0.0249, -0.0488,  0.0421, -0.0221, -0.0815, -0.0665,\n          0.0060,  0.0864,  0.0838,  0.0391,  0.0048, -0.0749,  0.0171, -0.0856,\n          0.0510, -0.0361, -0.0761,  0.0756, -0.0591,  0.0243, -0.0328,  0.0856,\n          0.0039, -0.0700, -0.0346,  0.0161, -0.0765, -0.0703,  0.0619,  0.0362,\n         -0.0251, -0.0009, -0.0533,  0.0463,  0.0542, -0.0800, -0.0502,  0.0374,\n         -0.0333, -0.0758, -0.0004,  0.0796, -0.0409, -0.0268,  0.0337, -0.0001,\n         -0.0119,  0.0610,  0.0566,  0.0504,  0.0652,  0.0680,  0.0673,  0.0149]],\n       requires_grad=True)"
                                },
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "in_features":	128,
                                "out_features":	4,
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "custom_network_flag":	false,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7f6859eed7d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s696860000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s696860000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}