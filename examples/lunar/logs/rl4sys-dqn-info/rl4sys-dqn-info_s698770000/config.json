{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.03,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s698770000"
    },
    "q_lr":	0.0005,
    "seed":	698770000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x708076600f50>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.03,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 3.6206e-01, -2.4179e-01,  8.3130e-03, -3.1396e-01, -5.8916e-02,\n         -1.9949e-01,  2.8725e-01,  1.1083e-02],\n        [ 3.4462e-01,  3.5823e-01,  2.6249e-01, -1.1016e-01, -2.5096e-01,\n         -1.8290e-01,  2.8231e-01,  1.6665e-02],\n        [-3.8611e-01,  5.3618e-02, -6.0799e-02, -3.8091e-01,  1.7506e-01,\n          2.0313e-01,  3.7983e-01, -6.3418e-02],\n        [ 1.4741e-02, -3.1850e-01,  5.9679e-02,  3.2634e-01, -3.6274e-01,\n          1.6926e-02,  1.0734e-01,  1.8061e-01],\n        [-3.3080e-01, -2.1624e-01, -2.1024e-01, -3.3560e-01, -4.1734e-02,\n          1.1992e-01, -3.0921e-01, -1.1636e-01],\n        [-1.5014e-01,  2.1123e-01, -1.7658e-01, -2.5022e-01,  4.8982e-02,\n         -7.9517e-02, -3.5440e-01,  2.7158e-01],\n        [-5.0995e-02,  3.8691e-01, -1.0901e-01,  2.3537e-01, -1.7857e-01,\n         -5.4888e-02,  6.3779e-02, -3.7190e-04],\n        [-1.6251e-01, -1.0975e-01,  1.0024e-01, -2.6572e-01,  1.0920e-01,\n         -1.5125e-01, -2.9411e-01,  1.7682e-01],\n        [ 3.5604e-01,  1.1001e-01,  2.5867e-02,  2.4757e-01, -5.5019e-02,\n         -1.1493e-01, -7.7457e-02, -1.2871e-01],\n        [ 3.8567e-01, -3.3275e-01, -3.2955e-01,  2.6830e-01, -3.1372e-01,\n          1.0851e-01, -2.4696e-01, -3.3653e-01],\n        [ 2.0609e-01, -2.0017e-02, -3.0712e-01, -1.3679e-01, -3.4617e-01,\n          1.8443e-01, -3.3246e-01,  1.0232e-01],\n        [ 3.3215e-01,  1.5008e-01, -1.0427e-01, -3.0242e-01,  2.2068e-02,\n          3.1748e-01, -2.7927e-01,  3.6547e-01],\n        [ 1.9883e-01, -1.7154e-01,  3.2219e-01,  3.7546e-01,  1.6836e-01,\n         -2.2658e-01,  2.5375e-01, -2.1408e-01],\n        [ 3.2055e-02, -3.5793e-01, -1.5849e-01, -1.5660e-01, -3.2330e-01,\n         -1.4497e-01, -3.0270e-01, -2.6678e-01],\n        [ 2.4573e-01, -7.1739e-02,  3.6247e-01, -1.4469e-01,  3.5623e-01,\n         -1.6685e-01,  3.4022e-01,  1.7554e-01],\n        [-3.3382e-01,  1.9630e-01,  3.3738e-01,  2.9590e-01, -1.2423e-01,\n          2.8543e-01, -1.4256e-01,  3.6379e-01],\n        [ 1.8111e-01,  6.4946e-02,  1.0394e-01, -1.9609e-01,  2.0478e-01,\n          2.8871e-01, -2.0955e-01,  2.6251e-01],\n        [ 1.8288e-01, -6.8235e-02,  2.7888e-01,  1.1553e-03, -2.0799e-01,\n         -3.2775e-01, -7.7868e-02, -2.6579e-01],\n        [-3.6875e-01, -3.1683e-01,  1.5547e-01, -1.9209e-01, -4.1889e-02,\n          2.1072e-01, -2.7551e-02, -1.0404e-01],\n        [ 1.8724e-01, -3.4437e-03,  3.5937e-01,  3.5644e-01, -1.6074e-01,\n         -1.3665e-01, -3.7254e-01, -2.6110e-01],\n        [ 1.0668e-01,  4.6886e-02,  1.3166e-01,  3.4078e-01, -5.0498e-02,\n          3.2584e-01,  2.3644e-01,  3.2745e-01],\n        [ 2.9403e-01,  8.1665e-02,  1.0127e-01,  6.9379e-02,  1.6169e-01,\n         -1.3662e-01, -8.7063e-03,  2.0031e-01],\n        [ 1.9468e-01, -1.0331e-01, -1.6527e-01,  4.1725e-02,  2.0391e-01,\n          2.9233e-01, -2.2216e-01,  2.6838e-01],\n        [-1.7558e-01,  9.9655e-02, -2.1725e-01,  3.1863e-01,  3.4536e-01,\n          7.9924e-03, -8.6755e-03,  1.3643e-01],\n        [ 3.2767e-01, -2.4374e-01,  7.0530e-02, -1.4356e-01, -2.8631e-01,\n         -1.3375e-01,  3.4361e-02, -3.2221e-02],\n        [ 1.6075e-01,  2.8151e-01,  1.8701e-01, -3.7001e-01, -3.3126e-02,\n         -1.1720e-02, -1.2324e-01,  3.4292e-01],\n        [ 1.1130e-01, -1.2587e-01,  5.9809e-02,  7.1176e-02,  2.1271e-01,\n         -8.4024e-03, -3.0383e-01,  7.7543e-02],\n        [-6.7299e-02,  2.0938e-01, -2.9648e-01, -9.5617e-04, -3.4238e-01,\n         -2.4765e-01,  3.5454e-01, -3.0527e-01],\n        [ 1.7266e-01,  1.2161e-01,  3.0995e-01,  2.0239e-01, -6.4115e-02,\n          1.9410e-01, -1.7522e-01,  3.1549e-02],\n        [-6.0224e-02, -1.7216e-01,  1.2480e-01, -1.7731e-01, -1.5646e-01,\n         -1.3219e-01,  2.6561e-01,  3.7179e-01],\n        [ 2.8336e-01,  7.7230e-02, -3.7811e-01, -1.1468e-02, -3.3734e-01,\n          1.3256e-01,  1.6472e-01, -9.9622e-02],\n        [ 2.0418e-01,  5.8670e-02,  1.0029e-01,  5.0355e-02, -3.8208e-01,\n         -4.7651e-02,  3.3918e-01,  2.1936e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.6078e-01,  9.1708e-02,  2.4263e-01,  2.7857e-01, -5.6773e-02,\n          7.3895e-02, -1.4553e-01, -9.8339e-02,  2.3843e-01, -2.5088e-01,\n         -2.7867e-01,  8.3495e-03,  2.6695e-01,  5.7061e-02,  2.0031e-01,\n         -3.4100e-01, -8.4037e-03, -3.7926e-02, -1.4192e-01, -1.5787e-01,\n          2.2239e-01,  1.7240e-02, -3.3697e-01, -1.8571e-01, -3.3439e-01,\n         -1.6095e-01,  2.4959e-01,  1.4109e-01,  2.3738e-02, -2.7670e-01,\n          2.0396e-01,  2.2650e-01],\n        [-1.4809e-01,  6.6944e-02, -3.4243e-01, -1.1862e-01,  2.0035e-01,\n         -2.9640e-01, -3.3970e-02, -3.3351e-01, -2.0983e-01, -9.9357e-02,\n         -1.8720e-01, -1.7470e-01, -2.3424e-01,  1.1359e-01, -1.2243e-01,\n         -3.0750e-01,  6.4649e-04,  3.0054e-01,  1.5525e-01,  3.2427e-02,\n         -3.1426e-01,  1.8298e-01,  1.4891e-01, -1.6251e-01, -1.4247e-01,\n         -3.1206e-02,  1.0668e-01, -8.3322e-02,  9.8112e-02,  2.3533e-01,\n          1.0907e-02,  2.5674e-01],\n        [-1.9838e-02,  2.6648e-01, -2.8287e-01, -2.4778e-01,  8.7064e-02,\n          1.3055e-01,  1.7428e-01,  2.8894e-01, -2.3266e-01,  3.7954e-02,\n          2.9048e-01,  3.3234e-01,  1.4814e-01,  3.0363e-01,  2.2416e-01,\n          2.1286e-02,  6.3776e-02, -1.8675e-02,  1.1600e-01, -1.6479e-01,\n          2.1998e-02,  3.2926e-01,  3.4663e-01,  1.3802e-01, -1.8036e-01,\n         -5.3496e-02, -4.7610e-02, -1.8515e-01,  2.6719e-01,  3.3320e-01,\n         -1.3801e-02, -1.6865e-01],\n        [-4.6526e-02, -1.5463e-01, -4.2546e-02,  1.9165e-02, -1.5302e-01,\n         -1.5196e-01,  1.1003e-02, -1.1083e-01, -2.1080e-01,  1.2394e-01,\n         -1.3327e-01,  2.5004e-01, -3.4507e-01, -1.5851e-01,  1.2439e-01,\n         -5.8765e-02,  3.2354e-01, -3.4769e-02, -3.2090e-01,  3.0966e-01,\n         -3.0981e-01, -2.2865e-01, -1.2937e-01,  1.8534e-01, -2.3341e-01,\n          2.1894e-01,  3.8059e-02, -7.9466e-02,  1.3079e-01, -7.5292e-02,\n          3.0872e-01,  3.3116e-01],\n        [-1.3126e-01, -2.8708e-01,  1.1358e-01, -7.0520e-02, -2.2795e-01,\n         -3.0950e-02, -1.4509e-01,  6.0766e-02, -1.5210e-01,  3.2508e-01,\n         -3.5823e-02, -3.1757e-01,  4.4725e-02,  2.3222e-01,  3.0121e-01,\n          3.3980e-01,  6.6793e-03, -1.8395e-02,  6.7537e-02, -1.3389e-01,\n          3.3834e-01,  1.1599e-01,  8.6113e-02, -1.0010e-01,  1.5940e-02,\n         -3.5229e-01, -2.0151e-01,  1.0488e-01,  5.7720e-02, -5.7572e-02,\n          9.9704e-02, -5.5198e-02],\n        [-1.6468e-01, -8.8286e-02, -2.4043e-01, -2.6567e-01,  2.5274e-01,\n         -1.4811e-01, -3.5297e-01, -1.2592e-01,  3.2579e-01, -1.0998e-01,\n          3.5125e-01,  4.1868e-02, -5.3050e-02, -1.5798e-01, -8.9816e-02,\n         -6.8696e-02, -2.7198e-01, -1.1286e-01, -1.0349e-01, -3.4439e-01,\n          1.2568e-01, -4.2927e-02, -1.6074e-01,  2.4752e-01,  3.1598e-01,\n         -1.2862e-01,  1.3918e-01,  1.3889e-01,  2.4686e-01, -7.3183e-02,\n          2.6580e-01, -6.4337e-02],\n        [-3.0331e-02,  6.0155e-02, -2.2940e-01, -2.0764e-01, -3.1900e-01,\n          2.9496e-01, -1.8617e-01,  2.6928e-01,  8.0830e-02, -1.7862e-01,\n          1.0845e-02,  2.8947e-02, -2.5955e-01,  2.0422e-01, -2.3847e-01,\n          2.1550e-01, -2.0180e-01, -1.8709e-01,  6.0942e-03, -1.1390e-01,\n          2.3815e-01, -1.7276e-01,  3.4583e-01,  1.2217e-01,  3.3984e-01,\n          3.3893e-01, -1.7459e-01, -1.4394e-01,  3.3036e-02, -2.7749e-01,\n          5.2319e-02,  5.1587e-02],\n        [-2.2027e-01,  1.2021e-02,  1.9504e-01,  2.4949e-01,  5.6771e-02,\n         -2.4546e-02,  3.4287e-01,  2.8154e-01,  2.8554e-01, -2.2690e-01,\n         -1.3038e-01, -3.0145e-01, -8.4579e-02,  2.5467e-01, -1.7040e-02,\n          1.5689e-02,  1.0895e-01,  2.2271e-01,  1.4437e-01, -1.1821e-01,\n         -1.6818e-01,  1.0757e-01, -2.7838e-02,  3.2484e-01,  3.2412e-02,\n          6.4991e-02,  3.4096e-01,  2.0325e-01, -2.4958e-01,  2.2863e-01,\n          1.7564e-01, -1.4672e-01],\n        [-2.6281e-01,  1.8293e-01, -6.7932e-02, -3.4094e-01, -2.9894e-01,\n         -1.4586e-01, -3.6136e-02,  8.8592e-02,  2.9512e-02, -1.2835e-01,\n         -8.6055e-04,  4.6071e-02, -8.1791e-02,  3.0372e-01, -8.8169e-02,\n         -1.7597e-02, -3.5025e-01, -4.3805e-02, -1.2559e-01,  3.0095e-01,\n         -1.6017e-01,  1.8879e-02,  5.9750e-02,  9.2689e-02,  1.2524e-01,\n         -2.3060e-02,  1.2964e-02, -2.8777e-01, -8.1392e-02, -3.3949e-02,\n         -3.3678e-01,  1.5063e-04],\n        [-3.1898e-01,  3.0260e-01, -6.8962e-02,  1.3365e-01,  1.1881e-01,\n         -1.9811e-01, -5.4387e-02, -2.0603e-01, -1.1597e-01, -1.3656e-02,\n         -1.4434e-01,  2.4420e-01,  3.2019e-01, -2.8308e-01,  1.2809e-01,\n         -3.5078e-01, -1.6360e-01, -1.0157e-01, -2.9800e-01, -2.3284e-01,\n          3.4432e-01,  1.0615e-01,  1.2061e-02,  2.2805e-01,  3.3557e-01,\n         -3.3060e-01,  1.6039e-01,  4.3560e-02, -2.7788e-01,  2.8678e-01,\n          2.1078e-01, -1.1363e-01],\n        [-3.0185e-01, -9.5201e-02, -7.4418e-03, -3.5188e-01, -2.8922e-01,\n         -1.0083e-01, -1.1651e-01,  1.8080e-01, -9.0479e-02,  4.7373e-02,\n         -5.9096e-02,  1.1384e-03,  8.7183e-02,  6.9367e-02,  6.4685e-03,\n          5.7127e-02, -2.8206e-01, -2.8004e-01,  3.0185e-01, -2.1918e-01,\n          3.3621e-01, -1.5707e-01,  6.0800e-02,  1.4904e-01, -4.5196e-02,\n          3.2990e-01,  2.6754e-01, -3.2208e-02,  2.0601e-01, -8.1762e-02,\n          2.5625e-01, -1.5446e-01],\n        [ 4.6195e-02, -8.0144e-02,  3.5798e-02, -9.2900e-02,  2.5828e-01,\n         -2.8473e-01,  2.0788e-01,  9.7660e-02, -2.1873e-01,  1.7811e-01,\n          7.5858e-02, -2.5584e-01,  2.0081e-01, -2.3807e-01, -3.2461e-01,\n          5.5112e-02, -1.0778e-01, -3.5698e-02, -1.6867e-01,  8.8626e-04,\n          2.7479e-01, -1.6937e-01,  2.4599e-02, -3.2402e-01,  2.2383e-01,\n          2.0485e-01,  9.0047e-02, -1.3958e-01,  1.7532e-01,  3.1841e-01,\n          3.0982e-01,  1.4337e-01],\n        [ 3.4454e-01,  3.3312e-01, -3.0764e-01, -3.6040e-02,  9.5678e-02,\n         -2.0880e-02, -1.9354e-01, -1.3098e-01, -2.6379e-01,  1.5464e-01,\n         -1.7307e-01, -1.6923e-01,  1.5882e-01,  3.5031e-01,  2.5797e-01,\n         -1.5034e-01, -3.7252e-02,  3.0736e-01, -2.4428e-02,  8.1671e-02,\n         -8.5992e-02, -1.2145e-01,  3.2153e-01, -1.7519e-01,  1.0559e-01,\n         -1.1478e-01,  3.1511e-01,  1.8825e-01, -1.5156e-02, -2.1483e-02,\n         -7.9903e-02, -1.6000e-01],\n        [-3.5053e-01, -1.6365e-01, -1.3513e-01, -2.7036e-01, -2.5208e-01,\n         -1.9777e-01, -3.2312e-02, -3.0585e-01, -3.2818e-01, -8.9979e-02,\n         -1.6330e-01,  1.8338e-01, -2.8195e-01, -3.9955e-02,  2.3192e-01,\n          5.7204e-03, -1.4712e-01,  1.5346e-02, -3.1239e-01, -1.6484e-01,\n         -1.7460e-02,  1.6221e-01,  1.5570e-01, -2.6645e-01, -1.4276e-01,\n         -1.3079e-01,  2.5027e-01, -1.4505e-01, -3.0997e-01,  7.0784e-02,\n         -9.8726e-02,  1.1810e-03],\n        [ 1.7641e-01, -5.3821e-02,  4.7283e-02,  2.4383e-02,  8.0260e-02,\n         -6.2765e-02, -2.4865e-01, -1.8855e-01,  3.4698e-01,  2.6013e-01,\n         -1.9261e-01,  1.6110e-01,  8.0097e-02, -1.3594e-01,  3.0605e-01,\n         -2.4212e-01,  1.9027e-01, -2.4486e-01,  3.1378e-01,  1.3528e-01,\n         -2.3045e-01, -2.1573e-01, -1.4899e-01, -1.3160e-01, -2.9432e-02,\n          3.2543e-01, -2.8039e-01, -2.7455e-01, -2.8099e-01, -2.2921e-01,\n          2.2911e-01,  1.8181e-01],\n        [-5.5603e-02, -5.8396e-02, -2.6798e-01,  4.2378e-03,  1.3672e-01,\n         -9.7766e-02, -1.6543e-01,  6.8915e-02,  7.8599e-02, -3.2569e-01,\n          3.0156e-01, -5.0531e-02,  3.0031e-01,  2.7060e-01,  9.8870e-02,\n         -1.8186e-01,  3.0612e-01, -5.2308e-02, -3.0907e-01, -2.7472e-02,\n          2.5299e-01, -6.5632e-02, -3.5275e-01, -1.8172e-01, -2.7803e-01,\n          3.1360e-01, -3.1243e-01, -1.3145e-01, -1.5549e-01, -1.8804e-02,\n         -4.8206e-02,  9.2735e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.4178, -0.1977,  0.1107, -0.4868, -0.3706,  0.2522,  0.1190, -0.0511,\n          0.3879,  0.1619, -0.2528,  0.2861, -0.4195, -0.0891, -0.2913, -0.0826],\n        [-0.2697, -0.0140, -0.4796, -0.1748,  0.4290, -0.1367,  0.4959, -0.4404,\n          0.2284, -0.1117, -0.0906,  0.1928,  0.3156,  0.0450,  0.1335,  0.3555],\n        [ 0.2959,  0.2014,  0.1213,  0.0899, -0.2077, -0.4121,  0.1230, -0.0067,\n          0.2116,  0.1881,  0.4882, -0.4518,  0.2079,  0.4218,  0.2356, -0.0162],\n        [-0.2670, -0.0879,  0.2188,  0.4029, -0.0741,  0.4874, -0.4413,  0.1808,\n          0.1455,  0.3117,  0.4819, -0.3773, -0.0214, -0.3570, -0.4935, -0.1221],\n        [ 0.4234,  0.4767,  0.0109, -0.3309,  0.3852,  0.4715, -0.1547,  0.1218,\n          0.3324,  0.4720,  0.0404,  0.2646,  0.0745,  0.4179,  0.4217, -0.4114],\n        [-0.1380, -0.2260, -0.2553,  0.0678,  0.0386, -0.2347,  0.4099, -0.3228,\n          0.3041, -0.0690, -0.0828, -0.3702,  0.4561, -0.2979, -0.3012,  0.3880],\n        [ 0.3297, -0.2481, -0.0642,  0.1073, -0.1907, -0.3891, -0.1881,  0.0532,\n         -0.3861, -0.4574,  0.2250,  0.0237,  0.1706,  0.1963, -0.4836, -0.2381],\n        [-0.0842,  0.1247, -0.4225, -0.1504, -0.0121, -0.1560, -0.0370, -0.2524,\n          0.0615,  0.0471, -0.3241, -0.2159, -0.2646, -0.3897, -0.3555, -0.4940]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.7012,  0.2520,  0.5735,  0.1042,  0.6031, -0.0347, -0.4178, -0.4532],\n        [ 0.5132,  0.6407,  0.0569,  0.5809, -0.5645,  0.3426,  0.1242, -0.0795],\n        [ 0.6584,  0.1670, -0.7053, -0.2425,  0.4347, -0.4352,  0.3945,  0.3562],\n        [-0.7036,  0.7045, -0.3596,  0.2289,  0.0083,  0.1309,  0.1318, -0.4873]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 3.6206e-01, -2.4179e-01,  8.3130e-03, -3.1396e-01, -5.8916e-02,\n         -1.9949e-01,  2.8725e-01,  1.1083e-02],\n        [ 3.4462e-01,  3.5823e-01,  2.6249e-01, -1.1016e-01, -2.5096e-01,\n         -1.8290e-01,  2.8231e-01,  1.6665e-02],\n        [-3.8611e-01,  5.3618e-02, -6.0799e-02, -3.8091e-01,  1.7506e-01,\n          2.0313e-01,  3.7983e-01, -6.3418e-02],\n        [ 1.4741e-02, -3.1850e-01,  5.9679e-02,  3.2634e-01, -3.6274e-01,\n          1.6926e-02,  1.0734e-01,  1.8061e-01],\n        [-3.3080e-01, -2.1624e-01, -2.1024e-01, -3.3560e-01, -4.1734e-02,\n          1.1992e-01, -3.0921e-01, -1.1636e-01],\n        [-1.5014e-01,  2.1123e-01, -1.7658e-01, -2.5022e-01,  4.8982e-02,\n         -7.9517e-02, -3.5440e-01,  2.7158e-01],\n        [-5.0995e-02,  3.8691e-01, -1.0901e-01,  2.3537e-01, -1.7857e-01,\n         -5.4888e-02,  6.3779e-02, -3.7190e-04],\n        [-1.6251e-01, -1.0975e-01,  1.0024e-01, -2.6572e-01,  1.0920e-01,\n         -1.5125e-01, -2.9411e-01,  1.7682e-01],\n        [ 3.5604e-01,  1.1001e-01,  2.5867e-02,  2.4757e-01, -5.5019e-02,\n         -1.1493e-01, -7.7457e-02, -1.2871e-01],\n        [ 3.8567e-01, -3.3275e-01, -3.2955e-01,  2.6830e-01, -3.1372e-01,\n          1.0851e-01, -2.4696e-01, -3.3653e-01],\n        [ 2.0609e-01, -2.0017e-02, -3.0712e-01, -1.3679e-01, -3.4617e-01,\n          1.8443e-01, -3.3246e-01,  1.0232e-01],\n        [ 3.3215e-01,  1.5008e-01, -1.0427e-01, -3.0242e-01,  2.2068e-02,\n          3.1748e-01, -2.7927e-01,  3.6547e-01],\n        [ 1.9883e-01, -1.7154e-01,  3.2219e-01,  3.7546e-01,  1.6836e-01,\n         -2.2658e-01,  2.5375e-01, -2.1408e-01],\n        [ 3.2055e-02, -3.5793e-01, -1.5849e-01, -1.5660e-01, -3.2330e-01,\n         -1.4497e-01, -3.0270e-01, -2.6678e-01],\n        [ 2.4573e-01, -7.1739e-02,  3.6247e-01, -1.4469e-01,  3.5623e-01,\n         -1.6685e-01,  3.4022e-01,  1.7554e-01],\n        [-3.3382e-01,  1.9630e-01,  3.3738e-01,  2.9590e-01, -1.2423e-01,\n          2.8543e-01, -1.4256e-01,  3.6379e-01],\n        [ 1.8111e-01,  6.4946e-02,  1.0394e-01, -1.9609e-01,  2.0478e-01,\n          2.8871e-01, -2.0955e-01,  2.6251e-01],\n        [ 1.8288e-01, -6.8235e-02,  2.7888e-01,  1.1553e-03, -2.0799e-01,\n         -3.2775e-01, -7.7868e-02, -2.6579e-01],\n        [-3.6875e-01, -3.1683e-01,  1.5547e-01, -1.9209e-01, -4.1889e-02,\n          2.1072e-01, -2.7551e-02, -1.0404e-01],\n        [ 1.8724e-01, -3.4437e-03,  3.5937e-01,  3.5644e-01, -1.6074e-01,\n         -1.3665e-01, -3.7254e-01, -2.6110e-01],\n        [ 1.0668e-01,  4.6886e-02,  1.3166e-01,  3.4078e-01, -5.0498e-02,\n          3.2584e-01,  2.3644e-01,  3.2745e-01],\n        [ 2.9403e-01,  8.1665e-02,  1.0127e-01,  6.9379e-02,  1.6169e-01,\n         -1.3662e-01, -8.7063e-03,  2.0031e-01],\n        [ 1.9468e-01, -1.0331e-01, -1.6527e-01,  4.1725e-02,  2.0391e-01,\n          2.9233e-01, -2.2216e-01,  2.6838e-01],\n        [-1.7558e-01,  9.9655e-02, -2.1725e-01,  3.1863e-01,  3.4536e-01,\n          7.9924e-03, -8.6755e-03,  1.3643e-01],\n        [ 3.2767e-01, -2.4374e-01,  7.0530e-02, -1.4356e-01, -2.8631e-01,\n         -1.3375e-01,  3.4361e-02, -3.2221e-02],\n        [ 1.6075e-01,  2.8151e-01,  1.8701e-01, -3.7001e-01, -3.3126e-02,\n         -1.1720e-02, -1.2324e-01,  3.4292e-01],\n        [ 1.1130e-01, -1.2587e-01,  5.9809e-02,  7.1176e-02,  2.1271e-01,\n         -8.4024e-03, -3.0383e-01,  7.7543e-02],\n        [-6.7299e-02,  2.0938e-01, -2.9648e-01, -9.5617e-04, -3.4238e-01,\n         -2.4765e-01,  3.5454e-01, -3.0527e-01],\n        [ 1.7266e-01,  1.2161e-01,  3.0995e-01,  2.0239e-01, -6.4115e-02,\n          1.9410e-01, -1.7522e-01,  3.1549e-02],\n        [-6.0224e-02, -1.7216e-01,  1.2480e-01, -1.7731e-01, -1.5646e-01,\n         -1.3219e-01,  2.6561e-01,  3.7179e-01],\n        [ 2.8336e-01,  7.7230e-02, -3.7811e-01, -1.1468e-02, -3.3734e-01,\n          1.3256e-01,  1.6472e-01, -9.9622e-02],\n        [ 2.0418e-01,  5.8670e-02,  1.0029e-01,  5.0355e-02, -3.8208e-01,\n         -4.7651e-02,  3.3918e-01,  2.1936e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.6078e-01,  9.1708e-02,  2.4263e-01,  2.7857e-01, -5.6773e-02,\n          7.3895e-02, -1.4553e-01, -9.8339e-02,  2.3843e-01, -2.5088e-01,\n         -2.7867e-01,  8.3495e-03,  2.6695e-01,  5.7061e-02,  2.0031e-01,\n         -3.4100e-01, -8.4037e-03, -3.7926e-02, -1.4192e-01, -1.5787e-01,\n          2.2239e-01,  1.7240e-02, -3.3697e-01, -1.8571e-01, -3.3439e-01,\n         -1.6095e-01,  2.4959e-01,  1.4109e-01,  2.3738e-02, -2.7670e-01,\n          2.0396e-01,  2.2650e-01],\n        [-1.4809e-01,  6.6944e-02, -3.4243e-01, -1.1862e-01,  2.0035e-01,\n         -2.9640e-01, -3.3970e-02, -3.3351e-01, -2.0983e-01, -9.9357e-02,\n         -1.8720e-01, -1.7470e-01, -2.3424e-01,  1.1359e-01, -1.2243e-01,\n         -3.0750e-01,  6.4649e-04,  3.0054e-01,  1.5525e-01,  3.2427e-02,\n         -3.1426e-01,  1.8298e-01,  1.4891e-01, -1.6251e-01, -1.4247e-01,\n         -3.1206e-02,  1.0668e-01, -8.3322e-02,  9.8112e-02,  2.3533e-01,\n          1.0907e-02,  2.5674e-01],\n        [-1.9838e-02,  2.6648e-01, -2.8287e-01, -2.4778e-01,  8.7064e-02,\n          1.3055e-01,  1.7428e-01,  2.8894e-01, -2.3266e-01,  3.7954e-02,\n          2.9048e-01,  3.3234e-01,  1.4814e-01,  3.0363e-01,  2.2416e-01,\n          2.1286e-02,  6.3776e-02, -1.8675e-02,  1.1600e-01, -1.6479e-01,\n          2.1998e-02,  3.2926e-01,  3.4663e-01,  1.3802e-01, -1.8036e-01,\n         -5.3496e-02, -4.7610e-02, -1.8515e-01,  2.6719e-01,  3.3320e-01,\n         -1.3801e-02, -1.6865e-01],\n        [-4.6526e-02, -1.5463e-01, -4.2546e-02,  1.9165e-02, -1.5302e-01,\n         -1.5196e-01,  1.1003e-02, -1.1083e-01, -2.1080e-01,  1.2394e-01,\n         -1.3327e-01,  2.5004e-01, -3.4507e-01, -1.5851e-01,  1.2439e-01,\n         -5.8765e-02,  3.2354e-01, -3.4769e-02, -3.2090e-01,  3.0966e-01,\n         -3.0981e-01, -2.2865e-01, -1.2937e-01,  1.8534e-01, -2.3341e-01,\n          2.1894e-01,  3.8059e-02, -7.9466e-02,  1.3079e-01, -7.5292e-02,\n          3.0872e-01,  3.3116e-01],\n        [-1.3126e-01, -2.8708e-01,  1.1358e-01, -7.0520e-02, -2.2795e-01,\n         -3.0950e-02, -1.4509e-01,  6.0766e-02, -1.5210e-01,  3.2508e-01,\n         -3.5823e-02, -3.1757e-01,  4.4725e-02,  2.3222e-01,  3.0121e-01,\n          3.3980e-01,  6.6793e-03, -1.8395e-02,  6.7537e-02, -1.3389e-01,\n          3.3834e-01,  1.1599e-01,  8.6113e-02, -1.0010e-01,  1.5940e-02,\n         -3.5229e-01, -2.0151e-01,  1.0488e-01,  5.7720e-02, -5.7572e-02,\n          9.9704e-02, -5.5198e-02],\n        [-1.6468e-01, -8.8286e-02, -2.4043e-01, -2.6567e-01,  2.5274e-01,\n         -1.4811e-01, -3.5297e-01, -1.2592e-01,  3.2579e-01, -1.0998e-01,\n          3.5125e-01,  4.1868e-02, -5.3050e-02, -1.5798e-01, -8.9816e-02,\n         -6.8696e-02, -2.7198e-01, -1.1286e-01, -1.0349e-01, -3.4439e-01,\n          1.2568e-01, -4.2927e-02, -1.6074e-01,  2.4752e-01,  3.1598e-01,\n         -1.2862e-01,  1.3918e-01,  1.3889e-01,  2.4686e-01, -7.3183e-02,\n          2.6580e-01, -6.4337e-02],\n        [-3.0331e-02,  6.0155e-02, -2.2940e-01, -2.0764e-01, -3.1900e-01,\n          2.9496e-01, -1.8617e-01,  2.6928e-01,  8.0830e-02, -1.7862e-01,\n          1.0845e-02,  2.8947e-02, -2.5955e-01,  2.0422e-01, -2.3847e-01,\n          2.1550e-01, -2.0180e-01, -1.8709e-01,  6.0942e-03, -1.1390e-01,\n          2.3815e-01, -1.7276e-01,  3.4583e-01,  1.2217e-01,  3.3984e-01,\n          3.3893e-01, -1.7459e-01, -1.4394e-01,  3.3036e-02, -2.7749e-01,\n          5.2319e-02,  5.1587e-02],\n        [-2.2027e-01,  1.2021e-02,  1.9504e-01,  2.4949e-01,  5.6771e-02,\n         -2.4546e-02,  3.4287e-01,  2.8154e-01,  2.8554e-01, -2.2690e-01,\n         -1.3038e-01, -3.0145e-01, -8.4579e-02,  2.5467e-01, -1.7040e-02,\n          1.5689e-02,  1.0895e-01,  2.2271e-01,  1.4437e-01, -1.1821e-01,\n         -1.6818e-01,  1.0757e-01, -2.7838e-02,  3.2484e-01,  3.2412e-02,\n          6.4991e-02,  3.4096e-01,  2.0325e-01, -2.4958e-01,  2.2863e-01,\n          1.7564e-01, -1.4672e-01],\n        [-2.6281e-01,  1.8293e-01, -6.7932e-02, -3.4094e-01, -2.9894e-01,\n         -1.4586e-01, -3.6136e-02,  8.8592e-02,  2.9512e-02, -1.2835e-01,\n         -8.6055e-04,  4.6071e-02, -8.1791e-02,  3.0372e-01, -8.8169e-02,\n         -1.7597e-02, -3.5025e-01, -4.3805e-02, -1.2559e-01,  3.0095e-01,\n         -1.6017e-01,  1.8879e-02,  5.9750e-02,  9.2689e-02,  1.2524e-01,\n         -2.3060e-02,  1.2964e-02, -2.8777e-01, -8.1392e-02, -3.3949e-02,\n         -3.3678e-01,  1.5063e-04],\n        [-3.1898e-01,  3.0260e-01, -6.8962e-02,  1.3365e-01,  1.1881e-01,\n         -1.9811e-01, -5.4387e-02, -2.0603e-01, -1.1597e-01, -1.3656e-02,\n         -1.4434e-01,  2.4420e-01,  3.2019e-01, -2.8308e-01,  1.2809e-01,\n         -3.5078e-01, -1.6360e-01, -1.0157e-01, -2.9800e-01, -2.3284e-01,\n          3.4432e-01,  1.0615e-01,  1.2061e-02,  2.2805e-01,  3.3557e-01,\n         -3.3060e-01,  1.6039e-01,  4.3560e-02, -2.7788e-01,  2.8678e-01,\n          2.1078e-01, -1.1363e-01],\n        [-3.0185e-01, -9.5201e-02, -7.4418e-03, -3.5188e-01, -2.8922e-01,\n         -1.0083e-01, -1.1651e-01,  1.8080e-01, -9.0479e-02,  4.7373e-02,\n         -5.9096e-02,  1.1384e-03,  8.7183e-02,  6.9367e-02,  6.4685e-03,\n          5.7127e-02, -2.8206e-01, -2.8004e-01,  3.0185e-01, -2.1918e-01,\n          3.3621e-01, -1.5707e-01,  6.0800e-02,  1.4904e-01, -4.5196e-02,\n          3.2990e-01,  2.6754e-01, -3.2208e-02,  2.0601e-01, -8.1762e-02,\n          2.5625e-01, -1.5446e-01],\n        [ 4.6195e-02, -8.0144e-02,  3.5798e-02, -9.2900e-02,  2.5828e-01,\n         -2.8473e-01,  2.0788e-01,  9.7660e-02, -2.1873e-01,  1.7811e-01,\n          7.5858e-02, -2.5584e-01,  2.0081e-01, -2.3807e-01, -3.2461e-01,\n          5.5112e-02, -1.0778e-01, -3.5698e-02, -1.6867e-01,  8.8626e-04,\n          2.7479e-01, -1.6937e-01,  2.4599e-02, -3.2402e-01,  2.2383e-01,\n          2.0485e-01,  9.0047e-02, -1.3958e-01,  1.7532e-01,  3.1841e-01,\n          3.0982e-01,  1.4337e-01],\n        [ 3.4454e-01,  3.3312e-01, -3.0764e-01, -3.6040e-02,  9.5678e-02,\n         -2.0880e-02, -1.9354e-01, -1.3098e-01, -2.6379e-01,  1.5464e-01,\n         -1.7307e-01, -1.6923e-01,  1.5882e-01,  3.5031e-01,  2.5797e-01,\n         -1.5034e-01, -3.7252e-02,  3.0736e-01, -2.4428e-02,  8.1671e-02,\n         -8.5992e-02, -1.2145e-01,  3.2153e-01, -1.7519e-01,  1.0559e-01,\n         -1.1478e-01,  3.1511e-01,  1.8825e-01, -1.5156e-02, -2.1483e-02,\n         -7.9903e-02, -1.6000e-01],\n        [-3.5053e-01, -1.6365e-01, -1.3513e-01, -2.7036e-01, -2.5208e-01,\n         -1.9777e-01, -3.2312e-02, -3.0585e-01, -3.2818e-01, -8.9979e-02,\n         -1.6330e-01,  1.8338e-01, -2.8195e-01, -3.9955e-02,  2.3192e-01,\n          5.7204e-03, -1.4712e-01,  1.5346e-02, -3.1239e-01, -1.6484e-01,\n         -1.7460e-02,  1.6221e-01,  1.5570e-01, -2.6645e-01, -1.4276e-01,\n         -1.3079e-01,  2.5027e-01, -1.4505e-01, -3.0997e-01,  7.0784e-02,\n         -9.8726e-02,  1.1810e-03],\n        [ 1.7641e-01, -5.3821e-02,  4.7283e-02,  2.4383e-02,  8.0260e-02,\n         -6.2765e-02, -2.4865e-01, -1.8855e-01,  3.4698e-01,  2.6013e-01,\n         -1.9261e-01,  1.6110e-01,  8.0097e-02, -1.3594e-01,  3.0605e-01,\n         -2.4212e-01,  1.9027e-01, -2.4486e-01,  3.1378e-01,  1.3528e-01,\n         -2.3045e-01, -2.1573e-01, -1.4899e-01, -1.3160e-01, -2.9432e-02,\n          3.2543e-01, -2.8039e-01, -2.7455e-01, -2.8099e-01, -2.2921e-01,\n          2.2911e-01,  1.8181e-01],\n        [-5.5603e-02, -5.8396e-02, -2.6798e-01,  4.2378e-03,  1.3672e-01,\n         -9.7766e-02, -1.6543e-01,  6.8915e-02,  7.8599e-02, -3.2569e-01,\n          3.0156e-01, -5.0531e-02,  3.0031e-01,  2.7060e-01,  9.8870e-02,\n         -1.8186e-01,  3.0612e-01, -5.2308e-02, -3.0907e-01, -2.7472e-02,\n          2.5299e-01, -6.5632e-02, -3.5275e-01, -1.8172e-01, -2.7803e-01,\n          3.1360e-01, -3.1243e-01, -1.3145e-01, -1.5549e-01, -1.8804e-02,\n         -4.8206e-02,  9.2735e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.4178, -0.1977,  0.1107, -0.4868, -0.3706,  0.2522,  0.1190, -0.0511,\n          0.3879,  0.1619, -0.2528,  0.2861, -0.4195, -0.0891, -0.2913, -0.0826],\n        [-0.2697, -0.0140, -0.4796, -0.1748,  0.4290, -0.1367,  0.4959, -0.4404,\n          0.2284, -0.1117, -0.0906,  0.1928,  0.3156,  0.0450,  0.1335,  0.3555],\n        [ 0.2959,  0.2014,  0.1213,  0.0899, -0.2077, -0.4121,  0.1230, -0.0067,\n          0.2116,  0.1881,  0.4882, -0.4518,  0.2079,  0.4218,  0.2356, -0.0162],\n        [-0.2670, -0.0879,  0.2188,  0.4029, -0.0741,  0.4874, -0.4413,  0.1808,\n          0.1455,  0.3117,  0.4819, -0.3773, -0.0214, -0.3570, -0.4935, -0.1221],\n        [ 0.4234,  0.4767,  0.0109, -0.3309,  0.3852,  0.4715, -0.1547,  0.1218,\n          0.3324,  0.4720,  0.0404,  0.2646,  0.0745,  0.4179,  0.4217, -0.4114],\n        [-0.1380, -0.2260, -0.2553,  0.0678,  0.0386, -0.2347,  0.4099, -0.3228,\n          0.3041, -0.0690, -0.0828, -0.3702,  0.4561, -0.2979, -0.3012,  0.3880],\n        [ 0.3297, -0.2481, -0.0642,  0.1073, -0.1907, -0.3891, -0.1881,  0.0532,\n         -0.3861, -0.4574,  0.2250,  0.0237,  0.1706,  0.1963, -0.4836, -0.2381],\n        [-0.0842,  0.1247, -0.4225, -0.1504, -0.0121, -0.1560, -0.0370, -0.2524,\n          0.0615,  0.0471, -0.3241, -0.2159, -0.2646, -0.3897, -0.3555, -0.4940]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.7012,  0.2520,  0.5735,  0.1042,  0.6031, -0.0347, -0.4178, -0.4532],\n        [ 0.5132,  0.6407,  0.0569,  0.5809, -0.5645,  0.3426,  0.1242, -0.0795],\n        [ 0.6584,  0.1670, -0.7053, -0.2425,  0.4347, -0.4352,  0.3945,  0.3562],\n        [-0.7036,  0.7045, -0.3596,  0.2289,  0.0083,  0.1309,  0.1318, -0.4873]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7080758db750>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "full":	false,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.03,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 3.6206e-01, -2.4179e-01,  8.3130e-03, -3.1396e-01, -5.8916e-02,\n         -1.9949e-01,  2.8725e-01,  1.1083e-02],\n        [ 3.4462e-01,  3.5823e-01,  2.6249e-01, -1.1016e-01, -2.5096e-01,\n         -1.8290e-01,  2.8231e-01,  1.6665e-02],\n        [-3.8611e-01,  5.3618e-02, -6.0799e-02, -3.8091e-01,  1.7506e-01,\n          2.0313e-01,  3.7983e-01, -6.3418e-02],\n        [ 1.4741e-02, -3.1850e-01,  5.9679e-02,  3.2634e-01, -3.6274e-01,\n          1.6926e-02,  1.0734e-01,  1.8061e-01],\n        [-3.3080e-01, -2.1624e-01, -2.1024e-01, -3.3560e-01, -4.1734e-02,\n          1.1992e-01, -3.0921e-01, -1.1636e-01],\n        [-1.5014e-01,  2.1123e-01, -1.7658e-01, -2.5022e-01,  4.8982e-02,\n         -7.9517e-02, -3.5440e-01,  2.7158e-01],\n        [-5.0995e-02,  3.8691e-01, -1.0901e-01,  2.3537e-01, -1.7857e-01,\n         -5.4888e-02,  6.3779e-02, -3.7190e-04],\n        [-1.6251e-01, -1.0975e-01,  1.0024e-01, -2.6572e-01,  1.0920e-01,\n         -1.5125e-01, -2.9411e-01,  1.7682e-01],\n        [ 3.5604e-01,  1.1001e-01,  2.5867e-02,  2.4757e-01, -5.5019e-02,\n         -1.1493e-01, -7.7457e-02, -1.2871e-01],\n        [ 3.8567e-01, -3.3275e-01, -3.2955e-01,  2.6830e-01, -3.1372e-01,\n          1.0851e-01, -2.4696e-01, -3.3653e-01],\n        [ 2.0609e-01, -2.0017e-02, -3.0712e-01, -1.3679e-01, -3.4617e-01,\n          1.8443e-01, -3.3246e-01,  1.0232e-01],\n        [ 3.3215e-01,  1.5008e-01, -1.0427e-01, -3.0242e-01,  2.2068e-02,\n          3.1748e-01, -2.7927e-01,  3.6547e-01],\n        [ 1.9883e-01, -1.7154e-01,  3.2219e-01,  3.7546e-01,  1.6836e-01,\n         -2.2658e-01,  2.5375e-01, -2.1408e-01],\n        [ 3.2055e-02, -3.5793e-01, -1.5849e-01, -1.5660e-01, -3.2330e-01,\n         -1.4497e-01, -3.0270e-01, -2.6678e-01],\n        [ 2.4573e-01, -7.1739e-02,  3.6247e-01, -1.4469e-01,  3.5623e-01,\n         -1.6685e-01,  3.4022e-01,  1.7554e-01],\n        [-3.3382e-01,  1.9630e-01,  3.3738e-01,  2.9590e-01, -1.2423e-01,\n          2.8543e-01, -1.4256e-01,  3.6379e-01],\n        [ 1.8111e-01,  6.4946e-02,  1.0394e-01, -1.9609e-01,  2.0478e-01,\n          2.8871e-01, -2.0955e-01,  2.6251e-01],\n        [ 1.8288e-01, -6.8235e-02,  2.7888e-01,  1.1553e-03, -2.0799e-01,\n         -3.2775e-01, -7.7868e-02, -2.6579e-01],\n        [-3.6875e-01, -3.1683e-01,  1.5547e-01, -1.9209e-01, -4.1889e-02,\n          2.1072e-01, -2.7551e-02, -1.0404e-01],\n        [ 1.8724e-01, -3.4437e-03,  3.5937e-01,  3.5644e-01, -1.6074e-01,\n         -1.3665e-01, -3.7254e-01, -2.6110e-01],\n        [ 1.0668e-01,  4.6886e-02,  1.3166e-01,  3.4078e-01, -5.0498e-02,\n          3.2584e-01,  2.3644e-01,  3.2745e-01],\n        [ 2.9403e-01,  8.1665e-02,  1.0127e-01,  6.9379e-02,  1.6169e-01,\n         -1.3662e-01, -8.7063e-03,  2.0031e-01],\n        [ 1.9468e-01, -1.0331e-01, -1.6527e-01,  4.1725e-02,  2.0391e-01,\n          2.9233e-01, -2.2216e-01,  2.6838e-01],\n        [-1.7558e-01,  9.9655e-02, -2.1725e-01,  3.1863e-01,  3.4536e-01,\n          7.9924e-03, -8.6755e-03,  1.3643e-01],\n        [ 3.2767e-01, -2.4374e-01,  7.0530e-02, -1.4356e-01, -2.8631e-01,\n         -1.3375e-01,  3.4361e-02, -3.2221e-02],\n        [ 1.6075e-01,  2.8151e-01,  1.8701e-01, -3.7001e-01, -3.3126e-02,\n         -1.1720e-02, -1.2324e-01,  3.4292e-01],\n        [ 1.1130e-01, -1.2587e-01,  5.9809e-02,  7.1176e-02,  2.1271e-01,\n         -8.4024e-03, -3.0383e-01,  7.7543e-02],\n        [-6.7299e-02,  2.0938e-01, -2.9648e-01, -9.5617e-04, -3.4238e-01,\n         -2.4765e-01,  3.5454e-01, -3.0527e-01],\n        [ 1.7266e-01,  1.2161e-01,  3.0995e-01,  2.0239e-01, -6.4115e-02,\n          1.9410e-01, -1.7522e-01,  3.1549e-02],\n        [-6.0224e-02, -1.7216e-01,  1.2480e-01, -1.7731e-01, -1.5646e-01,\n         -1.3219e-01,  2.6561e-01,  3.7179e-01],\n        [ 2.8336e-01,  7.7230e-02, -3.7811e-01, -1.1468e-02, -3.3734e-01,\n          1.3256e-01,  1.6472e-01, -9.9622e-02],\n        [ 2.0418e-01,  5.8670e-02,  1.0029e-01,  5.0355e-02, -3.8208e-01,\n         -4.7651e-02,  3.3918e-01,  2.1936e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.6078e-01,  9.1708e-02,  2.4263e-01,  2.7857e-01, -5.6773e-02,\n          7.3895e-02, -1.4553e-01, -9.8339e-02,  2.3843e-01, -2.5088e-01,\n         -2.7867e-01,  8.3495e-03,  2.6695e-01,  5.7061e-02,  2.0031e-01,\n         -3.4100e-01, -8.4037e-03, -3.7926e-02, -1.4192e-01, -1.5787e-01,\n          2.2239e-01,  1.7240e-02, -3.3697e-01, -1.8571e-01, -3.3439e-01,\n         -1.6095e-01,  2.4959e-01,  1.4109e-01,  2.3738e-02, -2.7670e-01,\n          2.0396e-01,  2.2650e-01],\n        [-1.4809e-01,  6.6944e-02, -3.4243e-01, -1.1862e-01,  2.0035e-01,\n         -2.9640e-01, -3.3970e-02, -3.3351e-01, -2.0983e-01, -9.9357e-02,\n         -1.8720e-01, -1.7470e-01, -2.3424e-01,  1.1359e-01, -1.2243e-01,\n         -3.0750e-01,  6.4649e-04,  3.0054e-01,  1.5525e-01,  3.2427e-02,\n         -3.1426e-01,  1.8298e-01,  1.4891e-01, -1.6251e-01, -1.4247e-01,\n         -3.1206e-02,  1.0668e-01, -8.3322e-02,  9.8112e-02,  2.3533e-01,\n          1.0907e-02,  2.5674e-01],\n        [-1.9838e-02,  2.6648e-01, -2.8287e-01, -2.4778e-01,  8.7064e-02,\n          1.3055e-01,  1.7428e-01,  2.8894e-01, -2.3266e-01,  3.7954e-02,\n          2.9048e-01,  3.3234e-01,  1.4814e-01,  3.0363e-01,  2.2416e-01,\n          2.1286e-02,  6.3776e-02, -1.8675e-02,  1.1600e-01, -1.6479e-01,\n          2.1998e-02,  3.2926e-01,  3.4663e-01,  1.3802e-01, -1.8036e-01,\n         -5.3496e-02, -4.7610e-02, -1.8515e-01,  2.6719e-01,  3.3320e-01,\n         -1.3801e-02, -1.6865e-01],\n        [-4.6526e-02, -1.5463e-01, -4.2546e-02,  1.9165e-02, -1.5302e-01,\n         -1.5196e-01,  1.1003e-02, -1.1083e-01, -2.1080e-01,  1.2394e-01,\n         -1.3327e-01,  2.5004e-01, -3.4507e-01, -1.5851e-01,  1.2439e-01,\n         -5.8765e-02,  3.2354e-01, -3.4769e-02, -3.2090e-01,  3.0966e-01,\n         -3.0981e-01, -2.2865e-01, -1.2937e-01,  1.8534e-01, -2.3341e-01,\n          2.1894e-01,  3.8059e-02, -7.9466e-02,  1.3079e-01, -7.5292e-02,\n          3.0872e-01,  3.3116e-01],\n        [-1.3126e-01, -2.8708e-01,  1.1358e-01, -7.0520e-02, -2.2795e-01,\n         -3.0950e-02, -1.4509e-01,  6.0766e-02, -1.5210e-01,  3.2508e-01,\n         -3.5823e-02, -3.1757e-01,  4.4725e-02,  2.3222e-01,  3.0121e-01,\n          3.3980e-01,  6.6793e-03, -1.8395e-02,  6.7537e-02, -1.3389e-01,\n          3.3834e-01,  1.1599e-01,  8.6113e-02, -1.0010e-01,  1.5940e-02,\n         -3.5229e-01, -2.0151e-01,  1.0488e-01,  5.7720e-02, -5.7572e-02,\n          9.9704e-02, -5.5198e-02],\n        [-1.6468e-01, -8.8286e-02, -2.4043e-01, -2.6567e-01,  2.5274e-01,\n         -1.4811e-01, -3.5297e-01, -1.2592e-01,  3.2579e-01, -1.0998e-01,\n          3.5125e-01,  4.1868e-02, -5.3050e-02, -1.5798e-01, -8.9816e-02,\n         -6.8696e-02, -2.7198e-01, -1.1286e-01, -1.0349e-01, -3.4439e-01,\n          1.2568e-01, -4.2927e-02, -1.6074e-01,  2.4752e-01,  3.1598e-01,\n         -1.2862e-01,  1.3918e-01,  1.3889e-01,  2.4686e-01, -7.3183e-02,\n          2.6580e-01, -6.4337e-02],\n        [-3.0331e-02,  6.0155e-02, -2.2940e-01, -2.0764e-01, -3.1900e-01,\n          2.9496e-01, -1.8617e-01,  2.6928e-01,  8.0830e-02, -1.7862e-01,\n          1.0845e-02,  2.8947e-02, -2.5955e-01,  2.0422e-01, -2.3847e-01,\n          2.1550e-01, -2.0180e-01, -1.8709e-01,  6.0942e-03, -1.1390e-01,\n          2.3815e-01, -1.7276e-01,  3.4583e-01,  1.2217e-01,  3.3984e-01,\n          3.3893e-01, -1.7459e-01, -1.4394e-01,  3.3036e-02, -2.7749e-01,\n          5.2319e-02,  5.1587e-02],\n        [-2.2027e-01,  1.2021e-02,  1.9504e-01,  2.4949e-01,  5.6771e-02,\n         -2.4546e-02,  3.4287e-01,  2.8154e-01,  2.8554e-01, -2.2690e-01,\n         -1.3038e-01, -3.0145e-01, -8.4579e-02,  2.5467e-01, -1.7040e-02,\n          1.5689e-02,  1.0895e-01,  2.2271e-01,  1.4437e-01, -1.1821e-01,\n         -1.6818e-01,  1.0757e-01, -2.7838e-02,  3.2484e-01,  3.2412e-02,\n          6.4991e-02,  3.4096e-01,  2.0325e-01, -2.4958e-01,  2.2863e-01,\n          1.7564e-01, -1.4672e-01],\n        [-2.6281e-01,  1.8293e-01, -6.7932e-02, -3.4094e-01, -2.9894e-01,\n         -1.4586e-01, -3.6136e-02,  8.8592e-02,  2.9512e-02, -1.2835e-01,\n         -8.6055e-04,  4.6071e-02, -8.1791e-02,  3.0372e-01, -8.8169e-02,\n         -1.7597e-02, -3.5025e-01, -4.3805e-02, -1.2559e-01,  3.0095e-01,\n         -1.6017e-01,  1.8879e-02,  5.9750e-02,  9.2689e-02,  1.2524e-01,\n         -2.3060e-02,  1.2964e-02, -2.8777e-01, -8.1392e-02, -3.3949e-02,\n         -3.3678e-01,  1.5063e-04],\n        [-3.1898e-01,  3.0260e-01, -6.8962e-02,  1.3365e-01,  1.1881e-01,\n         -1.9811e-01, -5.4387e-02, -2.0603e-01, -1.1597e-01, -1.3656e-02,\n         -1.4434e-01,  2.4420e-01,  3.2019e-01, -2.8308e-01,  1.2809e-01,\n         -3.5078e-01, -1.6360e-01, -1.0157e-01, -2.9800e-01, -2.3284e-01,\n          3.4432e-01,  1.0615e-01,  1.2061e-02,  2.2805e-01,  3.3557e-01,\n         -3.3060e-01,  1.6039e-01,  4.3560e-02, -2.7788e-01,  2.8678e-01,\n          2.1078e-01, -1.1363e-01],\n        [-3.0185e-01, -9.5201e-02, -7.4418e-03, -3.5188e-01, -2.8922e-01,\n         -1.0083e-01, -1.1651e-01,  1.8080e-01, -9.0479e-02,  4.7373e-02,\n         -5.9096e-02,  1.1384e-03,  8.7183e-02,  6.9367e-02,  6.4685e-03,\n          5.7127e-02, -2.8206e-01, -2.8004e-01,  3.0185e-01, -2.1918e-01,\n          3.3621e-01, -1.5707e-01,  6.0800e-02,  1.4904e-01, -4.5196e-02,\n          3.2990e-01,  2.6754e-01, -3.2208e-02,  2.0601e-01, -8.1762e-02,\n          2.5625e-01, -1.5446e-01],\n        [ 4.6195e-02, -8.0144e-02,  3.5798e-02, -9.2900e-02,  2.5828e-01,\n         -2.8473e-01,  2.0788e-01,  9.7660e-02, -2.1873e-01,  1.7811e-01,\n          7.5858e-02, -2.5584e-01,  2.0081e-01, -2.3807e-01, -3.2461e-01,\n          5.5112e-02, -1.0778e-01, -3.5698e-02, -1.6867e-01,  8.8626e-04,\n          2.7479e-01, -1.6937e-01,  2.4599e-02, -3.2402e-01,  2.2383e-01,\n          2.0485e-01,  9.0047e-02, -1.3958e-01,  1.7532e-01,  3.1841e-01,\n          3.0982e-01,  1.4337e-01],\n        [ 3.4454e-01,  3.3312e-01, -3.0764e-01, -3.6040e-02,  9.5678e-02,\n         -2.0880e-02, -1.9354e-01, -1.3098e-01, -2.6379e-01,  1.5464e-01,\n         -1.7307e-01, -1.6923e-01,  1.5882e-01,  3.5031e-01,  2.5797e-01,\n         -1.5034e-01, -3.7252e-02,  3.0736e-01, -2.4428e-02,  8.1671e-02,\n         -8.5992e-02, -1.2145e-01,  3.2153e-01, -1.7519e-01,  1.0559e-01,\n         -1.1478e-01,  3.1511e-01,  1.8825e-01, -1.5156e-02, -2.1483e-02,\n         -7.9903e-02, -1.6000e-01],\n        [-3.5053e-01, -1.6365e-01, -1.3513e-01, -2.7036e-01, -2.5208e-01,\n         -1.9777e-01, -3.2312e-02, -3.0585e-01, -3.2818e-01, -8.9979e-02,\n         -1.6330e-01,  1.8338e-01, -2.8195e-01, -3.9955e-02,  2.3192e-01,\n          5.7204e-03, -1.4712e-01,  1.5346e-02, -3.1239e-01, -1.6484e-01,\n         -1.7460e-02,  1.6221e-01,  1.5570e-01, -2.6645e-01, -1.4276e-01,\n         -1.3079e-01,  2.5027e-01, -1.4505e-01, -3.0997e-01,  7.0784e-02,\n         -9.8726e-02,  1.1810e-03],\n        [ 1.7641e-01, -5.3821e-02,  4.7283e-02,  2.4383e-02,  8.0260e-02,\n         -6.2765e-02, -2.4865e-01, -1.8855e-01,  3.4698e-01,  2.6013e-01,\n         -1.9261e-01,  1.6110e-01,  8.0097e-02, -1.3594e-01,  3.0605e-01,\n         -2.4212e-01,  1.9027e-01, -2.4486e-01,  3.1378e-01,  1.3528e-01,\n         -2.3045e-01, -2.1573e-01, -1.4899e-01, -1.3160e-01, -2.9432e-02,\n          3.2543e-01, -2.8039e-01, -2.7455e-01, -2.8099e-01, -2.2921e-01,\n          2.2911e-01,  1.8181e-01],\n        [-5.5603e-02, -5.8396e-02, -2.6798e-01,  4.2378e-03,  1.3672e-01,\n         -9.7766e-02, -1.6543e-01,  6.8915e-02,  7.8599e-02, -3.2569e-01,\n          3.0156e-01, -5.0531e-02,  3.0031e-01,  2.7060e-01,  9.8870e-02,\n         -1.8186e-01,  3.0612e-01, -5.2308e-02, -3.0907e-01, -2.7472e-02,\n          2.5299e-01, -6.5632e-02, -3.5275e-01, -1.8172e-01, -2.7803e-01,\n          3.1360e-01, -3.1243e-01, -1.3145e-01, -1.5549e-01, -1.8804e-02,\n         -4.8206e-02,  9.2735e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.4178, -0.1977,  0.1107, -0.4868, -0.3706,  0.2522,  0.1190, -0.0511,\n          0.3879,  0.1619, -0.2528,  0.2861, -0.4195, -0.0891, -0.2913, -0.0826],\n        [-0.2697, -0.0140, -0.4796, -0.1748,  0.4290, -0.1367,  0.4959, -0.4404,\n          0.2284, -0.1117, -0.0906,  0.1928,  0.3156,  0.0450,  0.1335,  0.3555],\n        [ 0.2959,  0.2014,  0.1213,  0.0899, -0.2077, -0.4121,  0.1230, -0.0067,\n          0.2116,  0.1881,  0.4882, -0.4518,  0.2079,  0.4218,  0.2356, -0.0162],\n        [-0.2670, -0.0879,  0.2188,  0.4029, -0.0741,  0.4874, -0.4413,  0.1808,\n          0.1455,  0.3117,  0.4819, -0.3773, -0.0214, -0.3570, -0.4935, -0.1221],\n        [ 0.4234,  0.4767,  0.0109, -0.3309,  0.3852,  0.4715, -0.1547,  0.1218,\n          0.3324,  0.4720,  0.0404,  0.2646,  0.0745,  0.4179,  0.4217, -0.4114],\n        [-0.1380, -0.2260, -0.2553,  0.0678,  0.0386, -0.2347,  0.4099, -0.3228,\n          0.3041, -0.0690, -0.0828, -0.3702,  0.4561, -0.2979, -0.3012,  0.3880],\n        [ 0.3297, -0.2481, -0.0642,  0.1073, -0.1907, -0.3891, -0.1881,  0.0532,\n         -0.3861, -0.4574,  0.2250,  0.0237,  0.1706,  0.1963, -0.4836, -0.2381],\n        [-0.0842,  0.1247, -0.4225, -0.1504, -0.0121, -0.1560, -0.0370, -0.2524,\n          0.0615,  0.0471, -0.3241, -0.2159, -0.2646, -0.3897, -0.3555, -0.4940]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0., 0., 0., 0.], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.7012,  0.2520,  0.5735,  0.1042,  0.6031, -0.0347, -0.4178, -0.4532],\n        [ 0.5132,  0.6407,  0.0569,  0.5809, -0.5645,  0.3426,  0.1242, -0.0795],\n        [ 0.6584,  0.1670, -0.7053, -0.2425,  0.4347, -0.4352,  0.3945,  0.3562],\n        [-0.7036,  0.7045, -0.3596,  0.2289,  0.0083,  0.1309,  0.1318, -0.4873]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x708073246210>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s698770000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s698770000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}