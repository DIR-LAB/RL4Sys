{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s728410000"
    },
    "q_lr":	0.003,
    "seed":	728410000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x706f05b62d90>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1904,  0.1951,  0.2551,  0.0987, -0.2394, -0.2118,  0.0664,  0.2351,\n         0.2707,  0.0793,  0.0227,  0.0836, -0.2698, -0.2166,  0.0676,  0.1771,\n         0.3096, -0.2220,  0.0990, -0.2275,  0.2974,  0.3142, -0.0636,  0.2658,\n        -0.0700,  0.2809,  0.3182,  0.2130,  0.1374,  0.1069, -0.2119, -0.3237],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1786,  0.0526, -0.1247,  0.2936,  0.0055,  0.1875, -0.0438, -0.2772],\n        [ 0.2456,  0.3238,  0.0198,  0.2909, -0.2090, -0.2538, -0.1077, -0.0323],\n        [ 0.0061,  0.0077, -0.1758, -0.0162, -0.2553,  0.0633, -0.1988,  0.2453],\n        [-0.0198,  0.1260, -0.1966, -0.0955,  0.2249, -0.3522,  0.1046, -0.0750],\n        [-0.0716, -0.2882, -0.1314,  0.2529,  0.0154, -0.3413, -0.1151, -0.2280],\n        [ 0.3215, -0.0067, -0.0926, -0.1042,  0.2986, -0.0102, -0.2759,  0.3034],\n        [ 0.2646,  0.1608,  0.1559, -0.1678, -0.2062, -0.1021, -0.0054,  0.0686],\n        [ 0.2730,  0.0763, -0.0721,  0.2007,  0.2448,  0.0528,  0.0469,  0.1000],\n        [-0.1070, -0.2530,  0.1666,  0.2941,  0.2203, -0.2003,  0.1802, -0.1170],\n        [ 0.2929, -0.1155, -0.0113, -0.1673,  0.1935,  0.0175,  0.3068, -0.2802],\n        [ 0.1555,  0.2852,  0.2574, -0.1859, -0.1965, -0.2284, -0.0682,  0.2063],\n        [ 0.3456, -0.1390,  0.1192,  0.2503, -0.1937,  0.0383, -0.2134,  0.2377],\n        [-0.1504,  0.3399, -0.1962,  0.2901, -0.0145,  0.1031,  0.2856, -0.0633],\n        [ 0.2741, -0.3060,  0.2053, -0.0542,  0.2914, -0.0873,  0.3370,  0.3196],\n        [-0.0637,  0.0098, -0.0347,  0.1263, -0.2621,  0.3307, -0.2536,  0.2726],\n        [ 0.1928,  0.0048, -0.2635, -0.0376, -0.0980, -0.0771,  0.0498, -0.2044],\n        [ 0.3029,  0.0521, -0.3069, -0.2360,  0.1452, -0.0850,  0.1544, -0.3060],\n        [ 0.0675,  0.1247,  0.2817, -0.1818,  0.0656,  0.2390,  0.2914,  0.3116],\n        [-0.1172, -0.0986,  0.2664,  0.2644, -0.2841, -0.0274, -0.0330, -0.0049],\n        [ 0.2160,  0.2759,  0.1326, -0.0569,  0.3381,  0.2407,  0.0761,  0.2112],\n        [ 0.1261, -0.0664, -0.3158, -0.3006,  0.1498,  0.2574, -0.1992, -0.0742],\n        [-0.0828,  0.0271, -0.2672, -0.2726, -0.0085,  0.1712,  0.3286, -0.1272],\n        [-0.0792, -0.2759,  0.2721, -0.3305,  0.3015,  0.0601,  0.2351, -0.1706],\n        [ 0.0021,  0.2347,  0.1265,  0.0204,  0.3082,  0.0756, -0.1687, -0.1410],\n        [ 0.0992, -0.2216,  0.3230,  0.2907,  0.0879, -0.2159, -0.3358,  0.0926],\n        [-0.1759,  0.2021, -0.0865, -0.3085,  0.1076, -0.2306, -0.2539,  0.2483],\n        [ 0.1661, -0.0101, -0.0430, -0.2088,  0.3472,  0.0039,  0.2193,  0.1373],\n        [-0.0720, -0.1670, -0.0268,  0.2750,  0.3193, -0.0610, -0.0485, -0.2652],\n        [-0.1158, -0.3358,  0.0310, -0.0081,  0.1164,  0.0780, -0.1812, -0.0243],\n        [-0.2270, -0.0459, -0.0287, -0.1710,  0.2912,  0.0408,  0.2285, -0.0316],\n        [-0.2924, -0.0104,  0.3265,  0.1953, -0.2371, -0.2916,  0.3096,  0.0522],\n        [-0.1656,  0.1162,  0.0712,  0.2241, -0.2779, -0.2214, -0.1246,  0.2428]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0893,  0.0182, -0.1448,  0.0858,  0.1667,  0.0264,  0.1275,  0.1566,\n         0.0650,  0.0861, -0.1448,  0.0326,  0.0780, -0.0774, -0.1268,  0.0353],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 7.0337e-02, -7.2843e-03, -1.4081e-01, -7.4900e-02, -1.6036e-01,\n          1.3288e-01,  6.0668e-03, -1.0135e-01, -8.1253e-03, -1.6369e-01,\n          2.1859e-02, -3.4039e-02,  1.1800e-01,  6.3463e-03, -4.2068e-02,\n          4.4211e-03,  4.4570e-02,  8.2910e-02,  5.8894e-02,  3.5011e-02,\n         -1.3984e-01,  1.2822e-01, -1.1422e-01, -1.6615e-01, -8.6761e-02,\n         -1.2950e-01, -1.1966e-01,  5.9931e-02,  1.1935e-01, -1.7478e-01,\n          1.6231e-01, -1.1709e-01],\n        [-1.6438e-02,  2.3848e-02,  1.8446e-02,  5.8931e-02, -7.5104e-02,\n          2.1794e-02,  2.5043e-03,  2.6979e-02, -9.6244e-02,  9.1775e-02,\n          1.4972e-01, -1.7005e-01,  1.6620e-01,  1.6623e-04,  1.7562e-01,\n         -1.4709e-01, -6.1449e-02, -2.4492e-02,  1.2899e-01, -1.3730e-01,\n         -1.3388e-01, -2.9739e-02, -1.4371e-01, -1.0660e-01, -1.2247e-01,\n          2.9645e-02, -6.8354e-03, -1.1642e-01,  2.3986e-03,  4.6153e-02,\n         -8.2167e-02,  1.3745e-01],\n        [ 1.1407e-01, -1.2495e-03,  3.7081e-02, -1.2401e-01, -6.9025e-02,\n          1.1726e-01,  2.4563e-02,  1.0404e-01,  6.6278e-02, -3.6027e-02,\n          1.5617e-01, -6.8796e-02, -1.5315e-01,  1.0591e-01,  4.5198e-02,\n          1.2086e-01, -8.2137e-02,  5.7511e-02,  1.0573e-01,  7.9390e-02,\n          1.6399e-01,  9.1423e-02, -3.2842e-02,  7.9453e-02,  1.4839e-01,\n          8.6458e-02,  9.0045e-02, -4.0564e-02,  7.4894e-02,  1.3362e-01,\n          9.4167e-02, -1.6835e-01],\n        [ 1.0766e-01, -4.6062e-03, -5.7358e-02,  7.5270e-02,  1.8551e-02,\n         -1.4268e-01,  7.1249e-02, -1.0565e-02, -6.7221e-02,  4.7437e-02,\n          9.1313e-02, -1.2062e-01, -1.0320e-01,  1.1731e-01,  7.0650e-02,\n          1.4678e-01, -5.8353e-02, -6.0803e-02, -1.0889e-01, -1.1941e-01,\n          2.3316e-02,  4.7790e-02,  3.5677e-02,  1.0537e-01, -6.1991e-02,\n          3.1225e-02,  1.4642e-01, -9.9423e-02,  7.8914e-02,  1.7413e-01,\n         -2.3050e-03,  1.3050e-01],\n        [ 9.4874e-02, -4.9433e-02,  1.4571e-01,  1.8675e-02,  7.5907e-02,\n          5.2772e-02,  3.9850e-03,  1.6918e-01, -2.9536e-02,  6.2925e-02,\n         -1.7280e-01, -8.2857e-02, -1.7497e-03,  7.5332e-02, -1.4717e-02,\n          1.3402e-01,  3.9792e-02,  2.1073e-02, -1.6651e-01, -8.7852e-03,\n         -8.1180e-02, -6.2206e-02,  6.2069e-03,  1.2243e-01, -1.7078e-01,\n          1.6971e-01,  1.2538e-01,  1.7910e-02, -1.1142e-01, -3.7305e-02,\n         -1.5925e-02,  1.1227e-01],\n        [-2.5021e-02, -3.6577e-02, -1.0776e-01, -1.5525e-01,  1.3732e-01,\n         -5.7077e-02,  1.4325e-01,  4.4454e-02, -1.0493e-01,  5.8609e-02,\n         -1.6079e-01,  4.6107e-02,  7.4261e-02,  1.6743e-01, -1.0645e-01,\n         -5.0543e-02, -5.9120e-02,  2.6018e-02, -4.4221e-02,  1.7878e-02,\n          1.5007e-01, -3.1215e-02,  1.6728e-01, -1.3090e-01,  2.7799e-02,\n          1.5384e-02,  9.9649e-02,  1.3858e-01, -1.3462e-01,  2.8841e-02,\n          1.5317e-01,  5.5364e-02],\n        [ 1.1978e-01, -5.0576e-06, -7.4279e-02,  8.4797e-02,  1.7379e-01,\n         -1.1270e-04,  1.5253e-01,  7.2753e-02,  7.3412e-02,  1.1589e-01,\n          1.2658e-01,  1.7471e-01,  1.2045e-01, -9.1640e-02,  2.1383e-02,\n          1.3271e-01,  1.2758e-01,  2.4401e-02,  4.7498e-03, -1.2215e-01,\n         -8.1559e-02, -1.0490e-01, -1.1167e-01,  7.5757e-02,  7.6105e-02,\n         -1.3585e-01, -1.4356e-01,  1.0437e-02,  1.5436e-02,  6.7384e-02,\n          9.0530e-03, -1.5901e-01],\n        [-7.4864e-02, -1.0131e-01, -1.4204e-01, -1.7408e-01, -4.9628e-02,\n         -1.4173e-01,  5.7262e-02, -1.3485e-01, -9.3833e-02, -1.2433e-01,\n         -2.9991e-03,  1.6605e-01,  5.4528e-02, -1.4355e-01, -7.2400e-02,\n          1.3941e-01, -5.8145e-02,  5.9352e-02,  1.6494e-01, -1.5869e-01,\n         -7.5065e-02,  1.2435e-01, -1.3903e-01,  4.6065e-02, -9.2085e-03,\n          1.1111e-01,  8.2084e-02,  6.3400e-02, -1.1415e-01,  6.7717e-02,\n          1.3889e-01, -1.2980e-01],\n        [ 1.1693e-02,  3.8411e-02,  9.6880e-02,  5.6392e-02,  6.4460e-02,\n         -1.6069e-01, -7.9826e-02,  1.0767e-02, -2.2445e-02, -1.4941e-01,\n         -1.2588e-01,  4.8334e-02,  1.6378e-01, -1.1006e-01, -1.7442e-01,\n          8.4989e-03,  1.2282e-01,  1.6888e-01, -1.5198e-01,  7.8085e-02,\n          4.6968e-02, -7.3876e-02,  9.4494e-02,  2.7866e-02,  1.4102e-01,\n          1.1076e-01,  4.1989e-02,  1.4849e-01, -1.5479e-01, -6.4988e-02,\n          1.4351e-01,  1.2415e-02],\n        [ 1.7577e-01,  1.3219e-01, -2.4874e-02,  1.1716e-01,  7.4106e-02,\n         -3.1981e-03, -6.3192e-02,  5.2860e-02,  1.6009e-01, -4.4120e-02,\n          1.1380e-01, -1.2384e-01, -9.7434e-02, -1.5264e-01, -1.7529e-01,\n          1.4089e-01,  9.1310e-02,  8.0820e-02, -1.0015e-01, -5.2636e-02,\n         -1.1171e-01,  8.6440e-02,  2.6204e-02,  1.3193e-01, -1.5174e-01,\n          2.2805e-02, -3.1887e-02, -1.2374e-01,  9.2140e-02,  5.5473e-02,\n          2.2397e-02,  7.5334e-02],\n        [-1.1206e-01,  4.0358e-02,  5.0987e-02, -4.8553e-02, -5.7515e-02,\n          1.2756e-02, -1.8280e-02, -7.8635e-02,  1.2683e-01,  1.6627e-01,\n          8.3229e-02, -1.4303e-01, -1.2886e-01,  3.9078e-02, -1.0799e-01,\n         -5.6993e-03, -6.7154e-02,  3.6149e-02, -9.2751e-02,  1.0983e-01,\n          1.3605e-01, -2.0451e-02,  9.0969e-03, -1.7077e-01, -1.5374e-01,\n          1.8510e-03, -1.7490e-01,  1.4127e-01,  9.6709e-02,  7.9280e-02,\n          1.5994e-01, -1.4525e-01],\n        [-7.4100e-02,  4.4718e-02,  1.4910e-01, -1.4516e-01,  5.8268e-02,\n          1.1333e-01, -1.1329e-01,  1.7599e-01,  1.0866e-01,  9.3997e-02,\n         -1.4921e-01,  1.4145e-01, -9.1240e-02,  6.4706e-02,  3.4280e-02,\n         -7.1233e-02, -4.4488e-02, -9.7545e-02, -1.5363e-02, -3.9356e-02,\n          1.7099e-01,  2.6532e-02,  1.1372e-01,  4.1869e-02,  3.2085e-03,\n          1.5529e-02, -2.5980e-02,  1.0613e-01,  8.7744e-02, -4.4700e-03,\n         -8.6329e-03, -3.9479e-02],\n        [ 1.5764e-01, -2.8896e-04,  1.6895e-01, -1.4941e-01, -1.1469e-01,\n          6.4765e-03,  1.7091e-01,  1.5761e-01,  8.0036e-02,  5.7575e-02,\n         -1.2451e-01, -7.7731e-02, -9.7324e-02,  7.8857e-02, -9.1395e-02,\n         -1.1331e-02,  1.4673e-03, -7.7409e-02, -1.4565e-01, -9.3908e-03,\n          4.7476e-02, -6.0431e-02,  1.6900e-01, -1.6494e-01,  8.3935e-02,\n          1.2262e-02,  5.4052e-02,  2.2732e-02,  5.8026e-02,  6.9543e-02,\n         -1.4130e-01, -3.7340e-02],\n        [ 1.0833e-01,  1.3191e-02,  6.8599e-02,  1.6924e-01,  1.3210e-01,\n         -5.9867e-02,  6.7282e-02,  2.6698e-02,  6.0550e-02, -1.5571e-01,\n          1.0063e-01,  7.4876e-02,  1.3127e-01,  8.3307e-02, -9.3941e-02,\n         -2.0022e-02, -1.5070e-01, -1.7245e-01,  1.5846e-01,  1.3779e-01,\n         -9.8585e-03,  9.3260e-02,  1.0841e-01,  1.6471e-01, -5.8010e-02,\n         -8.0549e-02, -1.4734e-01, -1.6018e-01,  4.4954e-02, -5.7041e-02,\n          2.9110e-02, -8.2445e-02],\n        [-6.0149e-02, -5.8066e-02,  1.3784e-01, -1.7019e-01, -7.6269e-02,\n          2.5935e-02,  1.6535e-01, -1.2477e-01, -1.3686e-01, -6.4422e-02,\n          1.5872e-01, -1.0453e-01,  1.6318e-01,  1.0547e-01,  1.6171e-01,\n          1.0413e-01, -1.5131e-01,  3.1648e-02,  3.9845e-02, -9.7351e-02,\n          2.6140e-02, -3.3583e-02, -9.2358e-02,  8.5547e-02, -7.5193e-02,\n         -2.4442e-02, -4.0483e-02, -7.1240e-02,  7.0425e-02, -2.9076e-02,\n         -7.1802e-02, -1.4732e-01],\n        [-8.3093e-02,  1.3411e-01,  9.2190e-02, -3.7482e-02, -1.4093e-01,\n          1.0903e-02,  1.4017e-01, -1.6609e-01,  1.4413e-01,  7.1346e-02,\n          1.2493e-01, -1.6127e-01,  1.5729e-01,  1.5973e-02, -1.2982e-01,\n          1.6808e-01,  7.4502e-02,  3.0644e-03, -1.1397e-01, -1.4486e-01,\n          7.5759e-02, -4.2031e-03,  1.3449e-01, -1.5945e-01,  1.3800e-01,\n          1.0201e-01, -1.0921e-01, -1.1735e-01, -5.6933e-02, -7.5313e-02,\n         -1.2595e-01, -5.8295e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2497,  0.2115, -0.0934, -0.2313, -0.1986, -0.0831, -0.0780,  0.1406],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1701,  0.0309,  0.2436,  0.0629,  0.1758, -0.2495,  0.2377,  0.1989,\n         -0.1184,  0.1171, -0.1144,  0.2097,  0.1884, -0.1054,  0.1481, -0.1972],\n        [-0.1221,  0.0349, -0.0188,  0.0360, -0.2205,  0.1584,  0.2229, -0.1709,\n          0.0977, -0.1749,  0.0979,  0.0009,  0.0544, -0.2011,  0.0756, -0.1310],\n        [-0.2461,  0.1144, -0.1897,  0.1629,  0.1132,  0.2480,  0.0698,  0.1030,\n          0.1209,  0.2333, -0.1779,  0.0260,  0.0887,  0.0921,  0.2163, -0.0383],\n        [-0.0841,  0.1220,  0.1172, -0.0063, -0.2275, -0.1222,  0.1111, -0.2465,\n         -0.0937, -0.1028, -0.0714,  0.0007,  0.2028,  0.0619, -0.2327,  0.0087],\n        [-0.2095,  0.1162, -0.0623, -0.0549,  0.1535,  0.0561, -0.1977,  0.1267,\n         -0.1841,  0.0262, -0.1866,  0.0090,  0.0521,  0.1040,  0.0136,  0.0038],\n        [-0.2207,  0.1636, -0.2194, -0.2230, -0.2494, -0.2439,  0.1502,  0.2489,\n          0.1849, -0.0462, -0.1574,  0.2500, -0.0703,  0.2182,  0.0095,  0.0506],\n        [ 0.1747, -0.2020,  0.0373,  0.0710, -0.1969, -0.1308, -0.1706,  0.2394,\n          0.1519,  0.0811,  0.0725, -0.1664,  0.1506, -0.0220,  0.0235,  0.0011],\n        [-0.0739,  0.2319,  0.2151,  0.1102,  0.1880, -0.1746,  0.1710, -0.1780,\n         -0.1750, -0.2005,  0.0597, -0.2235, -0.0533,  0.0897,  0.0155,  0.1310]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0466, -0.2805, -0.0967, -0.1406], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1130,  0.0972,  0.1177, -0.2343, -0.3485,  0.0805,  0.0623,  0.3453],\n        [ 0.0733, -0.1227, -0.2604, -0.0996,  0.2715, -0.3016, -0.2110, -0.2069],\n        [ 0.2912, -0.3282, -0.2659,  0.1198,  0.2495, -0.3367, -0.2031, -0.0681],\n        [ 0.1325, -0.1809, -0.1500,  0.2793,  0.3016,  0.3272,  0.1237, -0.1997]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1786,  0.0526, -0.1247,  0.2936,  0.0055,  0.1875, -0.0438, -0.2772],\n        [ 0.2456,  0.3238,  0.0198,  0.2909, -0.2090, -0.2538, -0.1077, -0.0323],\n        [ 0.0061,  0.0077, -0.1758, -0.0162, -0.2553,  0.0633, -0.1988,  0.2453],\n        [-0.0198,  0.1260, -0.1966, -0.0955,  0.2249, -0.3522,  0.1046, -0.0750],\n        [-0.0716, -0.2882, -0.1314,  0.2529,  0.0154, -0.3413, -0.1151, -0.2280],\n        [ 0.3215, -0.0067, -0.0926, -0.1042,  0.2986, -0.0102, -0.2759,  0.3034],\n        [ 0.2646,  0.1608,  0.1559, -0.1678, -0.2062, -0.1021, -0.0054,  0.0686],\n        [ 0.2730,  0.0763, -0.0721,  0.2007,  0.2448,  0.0528,  0.0469,  0.1000],\n        [-0.1070, -0.2530,  0.1666,  0.2941,  0.2203, -0.2003,  0.1802, -0.1170],\n        [ 0.2929, -0.1155, -0.0113, -0.1673,  0.1935,  0.0175,  0.3068, -0.2802],\n        [ 0.1555,  0.2852,  0.2574, -0.1859, -0.1965, -0.2284, -0.0682,  0.2063],\n        [ 0.3456, -0.1390,  0.1192,  0.2503, -0.1937,  0.0383, -0.2134,  0.2377],\n        [-0.1504,  0.3399, -0.1962,  0.2901, -0.0145,  0.1031,  0.2856, -0.0633],\n        [ 0.2741, -0.3060,  0.2053, -0.0542,  0.2914, -0.0873,  0.3370,  0.3196],\n        [-0.0637,  0.0098, -0.0347,  0.1263, -0.2621,  0.3307, -0.2536,  0.2726],\n        [ 0.1928,  0.0048, -0.2635, -0.0376, -0.0980, -0.0771,  0.0498, -0.2044],\n        [ 0.3029,  0.0521, -0.3069, -0.2360,  0.1452, -0.0850,  0.1544, -0.3060],\n        [ 0.0675,  0.1247,  0.2817, -0.1818,  0.0656,  0.2390,  0.2914,  0.3116],\n        [-0.1172, -0.0986,  0.2664,  0.2644, -0.2841, -0.0274, -0.0330, -0.0049],\n        [ 0.2160,  0.2759,  0.1326, -0.0569,  0.3381,  0.2407,  0.0761,  0.2112],\n        [ 0.1261, -0.0664, -0.3158, -0.3006,  0.1498,  0.2574, -0.1992, -0.0742],\n        [-0.0828,  0.0271, -0.2672, -0.2726, -0.0085,  0.1712,  0.3286, -0.1272],\n        [-0.0792, -0.2759,  0.2721, -0.3305,  0.3015,  0.0601,  0.2351, -0.1706],\n        [ 0.0021,  0.2347,  0.1265,  0.0204,  0.3082,  0.0756, -0.1687, -0.1410],\n        [ 0.0992, -0.2216,  0.3230,  0.2907,  0.0879, -0.2159, -0.3358,  0.0926],\n        [-0.1759,  0.2021, -0.0865, -0.3085,  0.1076, -0.2306, -0.2539,  0.2483],\n        [ 0.1661, -0.0101, -0.0430, -0.2088,  0.3472,  0.0039,  0.2193,  0.1373],\n        [-0.0720, -0.1670, -0.0268,  0.2750,  0.3193, -0.0610, -0.0485, -0.2652],\n        [-0.1158, -0.3358,  0.0310, -0.0081,  0.1164,  0.0780, -0.1812, -0.0243],\n        [-0.2270, -0.0459, -0.0287, -0.1710,  0.2912,  0.0408,  0.2285, -0.0316],\n        [-0.2924, -0.0104,  0.3265,  0.1953, -0.2371, -0.2916,  0.3096,  0.0522],\n        [-0.1656,  0.1162,  0.0712,  0.2241, -0.2779, -0.2214, -0.1246,  0.2428]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1904,  0.1951,  0.2551,  0.0987, -0.2394, -0.2118,  0.0664,  0.2351,\n         0.2707,  0.0793,  0.0227,  0.0836, -0.2698, -0.2166,  0.0676,  0.1771,\n         0.3096, -0.2220,  0.0990, -0.2275,  0.2974,  0.3142, -0.0636,  0.2658,\n        -0.0700,  0.2809,  0.3182,  0.2130,  0.1374,  0.1069, -0.2119, -0.3237],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 7.0337e-02, -7.2843e-03, -1.4081e-01, -7.4900e-02, -1.6036e-01,\n          1.3288e-01,  6.0668e-03, -1.0135e-01, -8.1253e-03, -1.6369e-01,\n          2.1859e-02, -3.4039e-02,  1.1800e-01,  6.3463e-03, -4.2068e-02,\n          4.4211e-03,  4.4570e-02,  8.2910e-02,  5.8894e-02,  3.5011e-02,\n         -1.3984e-01,  1.2822e-01, -1.1422e-01, -1.6615e-01, -8.6761e-02,\n         -1.2950e-01, -1.1966e-01,  5.9931e-02,  1.1935e-01, -1.7478e-01,\n          1.6231e-01, -1.1709e-01],\n        [-1.6438e-02,  2.3848e-02,  1.8446e-02,  5.8931e-02, -7.5104e-02,\n          2.1794e-02,  2.5043e-03,  2.6979e-02, -9.6244e-02,  9.1775e-02,\n          1.4972e-01, -1.7005e-01,  1.6620e-01,  1.6623e-04,  1.7562e-01,\n         -1.4709e-01, -6.1449e-02, -2.4492e-02,  1.2899e-01, -1.3730e-01,\n         -1.3388e-01, -2.9739e-02, -1.4371e-01, -1.0660e-01, -1.2247e-01,\n          2.9645e-02, -6.8354e-03, -1.1642e-01,  2.3986e-03,  4.6153e-02,\n         -8.2167e-02,  1.3745e-01],\n        [ 1.1407e-01, -1.2495e-03,  3.7081e-02, -1.2401e-01, -6.9025e-02,\n          1.1726e-01,  2.4563e-02,  1.0404e-01,  6.6278e-02, -3.6027e-02,\n          1.5617e-01, -6.8796e-02, -1.5315e-01,  1.0591e-01,  4.5198e-02,\n          1.2086e-01, -8.2137e-02,  5.7511e-02,  1.0573e-01,  7.9390e-02,\n          1.6399e-01,  9.1423e-02, -3.2842e-02,  7.9453e-02,  1.4839e-01,\n          8.6458e-02,  9.0045e-02, -4.0564e-02,  7.4894e-02,  1.3362e-01,\n          9.4167e-02, -1.6835e-01],\n        [ 1.0766e-01, -4.6062e-03, -5.7358e-02,  7.5270e-02,  1.8551e-02,\n         -1.4268e-01,  7.1249e-02, -1.0565e-02, -6.7221e-02,  4.7437e-02,\n          9.1313e-02, -1.2062e-01, -1.0320e-01,  1.1731e-01,  7.0650e-02,\n          1.4678e-01, -5.8353e-02, -6.0803e-02, -1.0889e-01, -1.1941e-01,\n          2.3316e-02,  4.7790e-02,  3.5677e-02,  1.0537e-01, -6.1991e-02,\n          3.1225e-02,  1.4642e-01, -9.9423e-02,  7.8914e-02,  1.7413e-01,\n         -2.3050e-03,  1.3050e-01],\n        [ 9.4874e-02, -4.9433e-02,  1.4571e-01,  1.8675e-02,  7.5907e-02,\n          5.2772e-02,  3.9850e-03,  1.6918e-01, -2.9536e-02,  6.2925e-02,\n         -1.7280e-01, -8.2857e-02, -1.7497e-03,  7.5332e-02, -1.4717e-02,\n          1.3402e-01,  3.9792e-02,  2.1073e-02, -1.6651e-01, -8.7852e-03,\n         -8.1180e-02, -6.2206e-02,  6.2069e-03,  1.2243e-01, -1.7078e-01,\n          1.6971e-01,  1.2538e-01,  1.7910e-02, -1.1142e-01, -3.7305e-02,\n         -1.5925e-02,  1.1227e-01],\n        [-2.5021e-02, -3.6577e-02, -1.0776e-01, -1.5525e-01,  1.3732e-01,\n         -5.7077e-02,  1.4325e-01,  4.4454e-02, -1.0493e-01,  5.8609e-02,\n         -1.6079e-01,  4.6107e-02,  7.4261e-02,  1.6743e-01, -1.0645e-01,\n         -5.0543e-02, -5.9120e-02,  2.6018e-02, -4.4221e-02,  1.7878e-02,\n          1.5007e-01, -3.1215e-02,  1.6728e-01, -1.3090e-01,  2.7799e-02,\n          1.5384e-02,  9.9649e-02,  1.3858e-01, -1.3462e-01,  2.8841e-02,\n          1.5317e-01,  5.5364e-02],\n        [ 1.1978e-01, -5.0576e-06, -7.4279e-02,  8.4797e-02,  1.7379e-01,\n         -1.1270e-04,  1.5253e-01,  7.2753e-02,  7.3412e-02,  1.1589e-01,\n          1.2658e-01,  1.7471e-01,  1.2045e-01, -9.1640e-02,  2.1383e-02,\n          1.3271e-01,  1.2758e-01,  2.4401e-02,  4.7498e-03, -1.2215e-01,\n         -8.1559e-02, -1.0490e-01, -1.1167e-01,  7.5757e-02,  7.6105e-02,\n         -1.3585e-01, -1.4356e-01,  1.0437e-02,  1.5436e-02,  6.7384e-02,\n          9.0530e-03, -1.5901e-01],\n        [-7.4864e-02, -1.0131e-01, -1.4204e-01, -1.7408e-01, -4.9628e-02,\n         -1.4173e-01,  5.7262e-02, -1.3485e-01, -9.3833e-02, -1.2433e-01,\n         -2.9991e-03,  1.6605e-01,  5.4528e-02, -1.4355e-01, -7.2400e-02,\n          1.3941e-01, -5.8145e-02,  5.9352e-02,  1.6494e-01, -1.5869e-01,\n         -7.5065e-02,  1.2435e-01, -1.3903e-01,  4.6065e-02, -9.2085e-03,\n          1.1111e-01,  8.2084e-02,  6.3400e-02, -1.1415e-01,  6.7717e-02,\n          1.3889e-01, -1.2980e-01],\n        [ 1.1693e-02,  3.8411e-02,  9.6880e-02,  5.6392e-02,  6.4460e-02,\n         -1.6069e-01, -7.9826e-02,  1.0767e-02, -2.2445e-02, -1.4941e-01,\n         -1.2588e-01,  4.8334e-02,  1.6378e-01, -1.1006e-01, -1.7442e-01,\n          8.4989e-03,  1.2282e-01,  1.6888e-01, -1.5198e-01,  7.8085e-02,\n          4.6968e-02, -7.3876e-02,  9.4494e-02,  2.7866e-02,  1.4102e-01,\n          1.1076e-01,  4.1989e-02,  1.4849e-01, -1.5479e-01, -6.4988e-02,\n          1.4351e-01,  1.2415e-02],\n        [ 1.7577e-01,  1.3219e-01, -2.4874e-02,  1.1716e-01,  7.4106e-02,\n         -3.1981e-03, -6.3192e-02,  5.2860e-02,  1.6009e-01, -4.4120e-02,\n          1.1380e-01, -1.2384e-01, -9.7434e-02, -1.5264e-01, -1.7529e-01,\n          1.4089e-01,  9.1310e-02,  8.0820e-02, -1.0015e-01, -5.2636e-02,\n         -1.1171e-01,  8.6440e-02,  2.6204e-02,  1.3193e-01, -1.5174e-01,\n          2.2805e-02, -3.1887e-02, -1.2374e-01,  9.2140e-02,  5.5473e-02,\n          2.2397e-02,  7.5334e-02],\n        [-1.1206e-01,  4.0358e-02,  5.0987e-02, -4.8553e-02, -5.7515e-02,\n          1.2756e-02, -1.8280e-02, -7.8635e-02,  1.2683e-01,  1.6627e-01,\n          8.3229e-02, -1.4303e-01, -1.2886e-01,  3.9078e-02, -1.0799e-01,\n         -5.6993e-03, -6.7154e-02,  3.6149e-02, -9.2751e-02,  1.0983e-01,\n          1.3605e-01, -2.0451e-02,  9.0969e-03, -1.7077e-01, -1.5374e-01,\n          1.8510e-03, -1.7490e-01,  1.4127e-01,  9.6709e-02,  7.9280e-02,\n          1.5994e-01, -1.4525e-01],\n        [-7.4100e-02,  4.4718e-02,  1.4910e-01, -1.4516e-01,  5.8268e-02,\n          1.1333e-01, -1.1329e-01,  1.7599e-01,  1.0866e-01,  9.3997e-02,\n         -1.4921e-01,  1.4145e-01, -9.1240e-02,  6.4706e-02,  3.4280e-02,\n         -7.1233e-02, -4.4488e-02, -9.7545e-02, -1.5363e-02, -3.9356e-02,\n          1.7099e-01,  2.6532e-02,  1.1372e-01,  4.1869e-02,  3.2085e-03,\n          1.5529e-02, -2.5980e-02,  1.0613e-01,  8.7744e-02, -4.4700e-03,\n         -8.6329e-03, -3.9479e-02],\n        [ 1.5764e-01, -2.8896e-04,  1.6895e-01, -1.4941e-01, -1.1469e-01,\n          6.4765e-03,  1.7091e-01,  1.5761e-01,  8.0036e-02,  5.7575e-02,\n         -1.2451e-01, -7.7731e-02, -9.7324e-02,  7.8857e-02, -9.1395e-02,\n         -1.1331e-02,  1.4673e-03, -7.7409e-02, -1.4565e-01, -9.3908e-03,\n          4.7476e-02, -6.0431e-02,  1.6900e-01, -1.6494e-01,  8.3935e-02,\n          1.2262e-02,  5.4052e-02,  2.2732e-02,  5.8026e-02,  6.9543e-02,\n         -1.4130e-01, -3.7340e-02],\n        [ 1.0833e-01,  1.3191e-02,  6.8599e-02,  1.6924e-01,  1.3210e-01,\n         -5.9867e-02,  6.7282e-02,  2.6698e-02,  6.0550e-02, -1.5571e-01,\n          1.0063e-01,  7.4876e-02,  1.3127e-01,  8.3307e-02, -9.3941e-02,\n         -2.0022e-02, -1.5070e-01, -1.7245e-01,  1.5846e-01,  1.3779e-01,\n         -9.8585e-03,  9.3260e-02,  1.0841e-01,  1.6471e-01, -5.8010e-02,\n         -8.0549e-02, -1.4734e-01, -1.6018e-01,  4.4954e-02, -5.7041e-02,\n          2.9110e-02, -8.2445e-02],\n        [-6.0149e-02, -5.8066e-02,  1.3784e-01, -1.7019e-01, -7.6269e-02,\n          2.5935e-02,  1.6535e-01, -1.2477e-01, -1.3686e-01, -6.4422e-02,\n          1.5872e-01, -1.0453e-01,  1.6318e-01,  1.0547e-01,  1.6171e-01,\n          1.0413e-01, -1.5131e-01,  3.1648e-02,  3.9845e-02, -9.7351e-02,\n          2.6140e-02, -3.3583e-02, -9.2358e-02,  8.5547e-02, -7.5193e-02,\n         -2.4442e-02, -4.0483e-02, -7.1240e-02,  7.0425e-02, -2.9076e-02,\n         -7.1802e-02, -1.4732e-01],\n        [-8.3093e-02,  1.3411e-01,  9.2190e-02, -3.7482e-02, -1.4093e-01,\n          1.0903e-02,  1.4017e-01, -1.6609e-01,  1.4413e-01,  7.1346e-02,\n          1.2493e-01, -1.6127e-01,  1.5729e-01,  1.5973e-02, -1.2982e-01,\n          1.6808e-01,  7.4502e-02,  3.0644e-03, -1.1397e-01, -1.4486e-01,\n          7.5759e-02, -4.2031e-03,  1.3449e-01, -1.5945e-01,  1.3800e-01,\n          1.0201e-01, -1.0921e-01, -1.1735e-01, -5.6933e-02, -7.5313e-02,\n         -1.2595e-01, -5.8295e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0893,  0.0182, -0.1448,  0.0858,  0.1667,  0.0264,  0.1275,  0.1566,\n         0.0650,  0.0861, -0.1448,  0.0326,  0.0780, -0.0774, -0.1268,  0.0353],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1701,  0.0309,  0.2436,  0.0629,  0.1758, -0.2495,  0.2377,  0.1989,\n         -0.1184,  0.1171, -0.1144,  0.2097,  0.1884, -0.1054,  0.1481, -0.1972],\n        [-0.1221,  0.0349, -0.0188,  0.0360, -0.2205,  0.1584,  0.2229, -0.1709,\n          0.0977, -0.1749,  0.0979,  0.0009,  0.0544, -0.2011,  0.0756, -0.1310],\n        [-0.2461,  0.1144, -0.1897,  0.1629,  0.1132,  0.2480,  0.0698,  0.1030,\n          0.1209,  0.2333, -0.1779,  0.0260,  0.0887,  0.0921,  0.2163, -0.0383],\n        [-0.0841,  0.1220,  0.1172, -0.0063, -0.2275, -0.1222,  0.1111, -0.2465,\n         -0.0937, -0.1028, -0.0714,  0.0007,  0.2028,  0.0619, -0.2327,  0.0087],\n        [-0.2095,  0.1162, -0.0623, -0.0549,  0.1535,  0.0561, -0.1977,  0.1267,\n         -0.1841,  0.0262, -0.1866,  0.0090,  0.0521,  0.1040,  0.0136,  0.0038],\n        [-0.2207,  0.1636, -0.2194, -0.2230, -0.2494, -0.2439,  0.1502,  0.2489,\n          0.1849, -0.0462, -0.1574,  0.2500, -0.0703,  0.2182,  0.0095,  0.0506],\n        [ 0.1747, -0.2020,  0.0373,  0.0710, -0.1969, -0.1308, -0.1706,  0.2394,\n          0.1519,  0.0811,  0.0725, -0.1664,  0.1506, -0.0220,  0.0235,  0.0011],\n        [-0.0739,  0.2319,  0.2151,  0.1102,  0.1880, -0.1746,  0.1710, -0.1780,\n         -0.1750, -0.2005,  0.0597, -0.2235, -0.0533,  0.0897,  0.0155,  0.1310]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2497,  0.2115, -0.0934, -0.2313, -0.1986, -0.0831, -0.0780,  0.1406],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1130,  0.0972,  0.1177, -0.2343, -0.3485,  0.0805,  0.0623,  0.3453],\n        [ 0.0733, -0.1227, -0.2604, -0.0996,  0.2715, -0.3016, -0.2110, -0.2069],\n        [ 0.2912, -0.3282, -0.2659,  0.1198,  0.2495, -0.3367, -0.2031, -0.0681],\n        [ 0.1325, -0.1809, -0.1500,  0.2793,  0.3016,  0.3272,  0.1237, -0.1997]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0466, -0.2805, -0.0967, -0.1406], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x706f869e4390>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1904,  0.1951,  0.2551,  0.0987, -0.2394, -0.2118,  0.0664,  0.2351,\n         0.2707,  0.0793,  0.0227,  0.0836, -0.2698, -0.2166,  0.0676,  0.1771,\n         0.3096, -0.2220,  0.0990, -0.2275,  0.2974,  0.3142, -0.0636,  0.2658,\n        -0.0700,  0.2809,  0.3182,  0.2130,  0.1374,  0.1069, -0.2119, -0.3237],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1786,  0.0526, -0.1247,  0.2936,  0.0055,  0.1875, -0.0438, -0.2772],\n        [ 0.2456,  0.3238,  0.0198,  0.2909, -0.2090, -0.2538, -0.1077, -0.0323],\n        [ 0.0061,  0.0077, -0.1758, -0.0162, -0.2553,  0.0633, -0.1988,  0.2453],\n        [-0.0198,  0.1260, -0.1966, -0.0955,  0.2249, -0.3522,  0.1046, -0.0750],\n        [-0.0716, -0.2882, -0.1314,  0.2529,  0.0154, -0.3413, -0.1151, -0.2280],\n        [ 0.3215, -0.0067, -0.0926, -0.1042,  0.2986, -0.0102, -0.2759,  0.3034],\n        [ 0.2646,  0.1608,  0.1559, -0.1678, -0.2062, -0.1021, -0.0054,  0.0686],\n        [ 0.2730,  0.0763, -0.0721,  0.2007,  0.2448,  0.0528,  0.0469,  0.1000],\n        [-0.1070, -0.2530,  0.1666,  0.2941,  0.2203, -0.2003,  0.1802, -0.1170],\n        [ 0.2929, -0.1155, -0.0113, -0.1673,  0.1935,  0.0175,  0.3068, -0.2802],\n        [ 0.1555,  0.2852,  0.2574, -0.1859, -0.1965, -0.2284, -0.0682,  0.2063],\n        [ 0.3456, -0.1390,  0.1192,  0.2503, -0.1937,  0.0383, -0.2134,  0.2377],\n        [-0.1504,  0.3399, -0.1962,  0.2901, -0.0145,  0.1031,  0.2856, -0.0633],\n        [ 0.2741, -0.3060,  0.2053, -0.0542,  0.2914, -0.0873,  0.3370,  0.3196],\n        [-0.0637,  0.0098, -0.0347,  0.1263, -0.2621,  0.3307, -0.2536,  0.2726],\n        [ 0.1928,  0.0048, -0.2635, -0.0376, -0.0980, -0.0771,  0.0498, -0.2044],\n        [ 0.3029,  0.0521, -0.3069, -0.2360,  0.1452, -0.0850,  0.1544, -0.3060],\n        [ 0.0675,  0.1247,  0.2817, -0.1818,  0.0656,  0.2390,  0.2914,  0.3116],\n        [-0.1172, -0.0986,  0.2664,  0.2644, -0.2841, -0.0274, -0.0330, -0.0049],\n        [ 0.2160,  0.2759,  0.1326, -0.0569,  0.3381,  0.2407,  0.0761,  0.2112],\n        [ 0.1261, -0.0664, -0.3158, -0.3006,  0.1498,  0.2574, -0.1992, -0.0742],\n        [-0.0828,  0.0271, -0.2672, -0.2726, -0.0085,  0.1712,  0.3286, -0.1272],\n        [-0.0792, -0.2759,  0.2721, -0.3305,  0.3015,  0.0601,  0.2351, -0.1706],\n        [ 0.0021,  0.2347,  0.1265,  0.0204,  0.3082,  0.0756, -0.1687, -0.1410],\n        [ 0.0992, -0.2216,  0.3230,  0.2907,  0.0879, -0.2159, -0.3358,  0.0926],\n        [-0.1759,  0.2021, -0.0865, -0.3085,  0.1076, -0.2306, -0.2539,  0.2483],\n        [ 0.1661, -0.0101, -0.0430, -0.2088,  0.3472,  0.0039,  0.2193,  0.1373],\n        [-0.0720, -0.1670, -0.0268,  0.2750,  0.3193, -0.0610, -0.0485, -0.2652],\n        [-0.1158, -0.3358,  0.0310, -0.0081,  0.1164,  0.0780, -0.1812, -0.0243],\n        [-0.2270, -0.0459, -0.0287, -0.1710,  0.2912,  0.0408,  0.2285, -0.0316],\n        [-0.2924, -0.0104,  0.3265,  0.1953, -0.2371, -0.2916,  0.3096,  0.0522],\n        [-0.1656,  0.1162,  0.0712,  0.2241, -0.2779, -0.2214, -0.1246,  0.2428]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0893,  0.0182, -0.1448,  0.0858,  0.1667,  0.0264,  0.1275,  0.1566,\n         0.0650,  0.0861, -0.1448,  0.0326,  0.0780, -0.0774, -0.1268,  0.0353],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 7.0337e-02, -7.2843e-03, -1.4081e-01, -7.4900e-02, -1.6036e-01,\n          1.3288e-01,  6.0668e-03, -1.0135e-01, -8.1253e-03, -1.6369e-01,\n          2.1859e-02, -3.4039e-02,  1.1800e-01,  6.3463e-03, -4.2068e-02,\n          4.4211e-03,  4.4570e-02,  8.2910e-02,  5.8894e-02,  3.5011e-02,\n         -1.3984e-01,  1.2822e-01, -1.1422e-01, -1.6615e-01, -8.6761e-02,\n         -1.2950e-01, -1.1966e-01,  5.9931e-02,  1.1935e-01, -1.7478e-01,\n          1.6231e-01, -1.1709e-01],\n        [-1.6438e-02,  2.3848e-02,  1.8446e-02,  5.8931e-02, -7.5104e-02,\n          2.1794e-02,  2.5043e-03,  2.6979e-02, -9.6244e-02,  9.1775e-02,\n          1.4972e-01, -1.7005e-01,  1.6620e-01,  1.6623e-04,  1.7562e-01,\n         -1.4709e-01, -6.1449e-02, -2.4492e-02,  1.2899e-01, -1.3730e-01,\n         -1.3388e-01, -2.9739e-02, -1.4371e-01, -1.0660e-01, -1.2247e-01,\n          2.9645e-02, -6.8354e-03, -1.1642e-01,  2.3986e-03,  4.6153e-02,\n         -8.2167e-02,  1.3745e-01],\n        [ 1.1407e-01, -1.2495e-03,  3.7081e-02, -1.2401e-01, -6.9025e-02,\n          1.1726e-01,  2.4563e-02,  1.0404e-01,  6.6278e-02, -3.6027e-02,\n          1.5617e-01, -6.8796e-02, -1.5315e-01,  1.0591e-01,  4.5198e-02,\n          1.2086e-01, -8.2137e-02,  5.7511e-02,  1.0573e-01,  7.9390e-02,\n          1.6399e-01,  9.1423e-02, -3.2842e-02,  7.9453e-02,  1.4839e-01,\n          8.6458e-02,  9.0045e-02, -4.0564e-02,  7.4894e-02,  1.3362e-01,\n          9.4167e-02, -1.6835e-01],\n        [ 1.0766e-01, -4.6062e-03, -5.7358e-02,  7.5270e-02,  1.8551e-02,\n         -1.4268e-01,  7.1249e-02, -1.0565e-02, -6.7221e-02,  4.7437e-02,\n          9.1313e-02, -1.2062e-01, -1.0320e-01,  1.1731e-01,  7.0650e-02,\n          1.4678e-01, -5.8353e-02, -6.0803e-02, -1.0889e-01, -1.1941e-01,\n          2.3316e-02,  4.7790e-02,  3.5677e-02,  1.0537e-01, -6.1991e-02,\n          3.1225e-02,  1.4642e-01, -9.9423e-02,  7.8914e-02,  1.7413e-01,\n         -2.3050e-03,  1.3050e-01],\n        [ 9.4874e-02, -4.9433e-02,  1.4571e-01,  1.8675e-02,  7.5907e-02,\n          5.2772e-02,  3.9850e-03,  1.6918e-01, -2.9536e-02,  6.2925e-02,\n         -1.7280e-01, -8.2857e-02, -1.7497e-03,  7.5332e-02, -1.4717e-02,\n          1.3402e-01,  3.9792e-02,  2.1073e-02, -1.6651e-01, -8.7852e-03,\n         -8.1180e-02, -6.2206e-02,  6.2069e-03,  1.2243e-01, -1.7078e-01,\n          1.6971e-01,  1.2538e-01,  1.7910e-02, -1.1142e-01, -3.7305e-02,\n         -1.5925e-02,  1.1227e-01],\n        [-2.5021e-02, -3.6577e-02, -1.0776e-01, -1.5525e-01,  1.3732e-01,\n         -5.7077e-02,  1.4325e-01,  4.4454e-02, -1.0493e-01,  5.8609e-02,\n         -1.6079e-01,  4.6107e-02,  7.4261e-02,  1.6743e-01, -1.0645e-01,\n         -5.0543e-02, -5.9120e-02,  2.6018e-02, -4.4221e-02,  1.7878e-02,\n          1.5007e-01, -3.1215e-02,  1.6728e-01, -1.3090e-01,  2.7799e-02,\n          1.5384e-02,  9.9649e-02,  1.3858e-01, -1.3462e-01,  2.8841e-02,\n          1.5317e-01,  5.5364e-02],\n        [ 1.1978e-01, -5.0576e-06, -7.4279e-02,  8.4797e-02,  1.7379e-01,\n         -1.1270e-04,  1.5253e-01,  7.2753e-02,  7.3412e-02,  1.1589e-01,\n          1.2658e-01,  1.7471e-01,  1.2045e-01, -9.1640e-02,  2.1383e-02,\n          1.3271e-01,  1.2758e-01,  2.4401e-02,  4.7498e-03, -1.2215e-01,\n         -8.1559e-02, -1.0490e-01, -1.1167e-01,  7.5757e-02,  7.6105e-02,\n         -1.3585e-01, -1.4356e-01,  1.0437e-02,  1.5436e-02,  6.7384e-02,\n          9.0530e-03, -1.5901e-01],\n        [-7.4864e-02, -1.0131e-01, -1.4204e-01, -1.7408e-01, -4.9628e-02,\n         -1.4173e-01,  5.7262e-02, -1.3485e-01, -9.3833e-02, -1.2433e-01,\n         -2.9991e-03,  1.6605e-01,  5.4528e-02, -1.4355e-01, -7.2400e-02,\n          1.3941e-01, -5.8145e-02,  5.9352e-02,  1.6494e-01, -1.5869e-01,\n         -7.5065e-02,  1.2435e-01, -1.3903e-01,  4.6065e-02, -9.2085e-03,\n          1.1111e-01,  8.2084e-02,  6.3400e-02, -1.1415e-01,  6.7717e-02,\n          1.3889e-01, -1.2980e-01],\n        [ 1.1693e-02,  3.8411e-02,  9.6880e-02,  5.6392e-02,  6.4460e-02,\n         -1.6069e-01, -7.9826e-02,  1.0767e-02, -2.2445e-02, -1.4941e-01,\n         -1.2588e-01,  4.8334e-02,  1.6378e-01, -1.1006e-01, -1.7442e-01,\n          8.4989e-03,  1.2282e-01,  1.6888e-01, -1.5198e-01,  7.8085e-02,\n          4.6968e-02, -7.3876e-02,  9.4494e-02,  2.7866e-02,  1.4102e-01,\n          1.1076e-01,  4.1989e-02,  1.4849e-01, -1.5479e-01, -6.4988e-02,\n          1.4351e-01,  1.2415e-02],\n        [ 1.7577e-01,  1.3219e-01, -2.4874e-02,  1.1716e-01,  7.4106e-02,\n         -3.1981e-03, -6.3192e-02,  5.2860e-02,  1.6009e-01, -4.4120e-02,\n          1.1380e-01, -1.2384e-01, -9.7434e-02, -1.5264e-01, -1.7529e-01,\n          1.4089e-01,  9.1310e-02,  8.0820e-02, -1.0015e-01, -5.2636e-02,\n         -1.1171e-01,  8.6440e-02,  2.6204e-02,  1.3193e-01, -1.5174e-01,\n          2.2805e-02, -3.1887e-02, -1.2374e-01,  9.2140e-02,  5.5473e-02,\n          2.2397e-02,  7.5334e-02],\n        [-1.1206e-01,  4.0358e-02,  5.0987e-02, -4.8553e-02, -5.7515e-02,\n          1.2756e-02, -1.8280e-02, -7.8635e-02,  1.2683e-01,  1.6627e-01,\n          8.3229e-02, -1.4303e-01, -1.2886e-01,  3.9078e-02, -1.0799e-01,\n         -5.6993e-03, -6.7154e-02,  3.6149e-02, -9.2751e-02,  1.0983e-01,\n          1.3605e-01, -2.0451e-02,  9.0969e-03, -1.7077e-01, -1.5374e-01,\n          1.8510e-03, -1.7490e-01,  1.4127e-01,  9.6709e-02,  7.9280e-02,\n          1.5994e-01, -1.4525e-01],\n        [-7.4100e-02,  4.4718e-02,  1.4910e-01, -1.4516e-01,  5.8268e-02,\n          1.1333e-01, -1.1329e-01,  1.7599e-01,  1.0866e-01,  9.3997e-02,\n         -1.4921e-01,  1.4145e-01, -9.1240e-02,  6.4706e-02,  3.4280e-02,\n         -7.1233e-02, -4.4488e-02, -9.7545e-02, -1.5363e-02, -3.9356e-02,\n          1.7099e-01,  2.6532e-02,  1.1372e-01,  4.1869e-02,  3.2085e-03,\n          1.5529e-02, -2.5980e-02,  1.0613e-01,  8.7744e-02, -4.4700e-03,\n         -8.6329e-03, -3.9479e-02],\n        [ 1.5764e-01, -2.8896e-04,  1.6895e-01, -1.4941e-01, -1.1469e-01,\n          6.4765e-03,  1.7091e-01,  1.5761e-01,  8.0036e-02,  5.7575e-02,\n         -1.2451e-01, -7.7731e-02, -9.7324e-02,  7.8857e-02, -9.1395e-02,\n         -1.1331e-02,  1.4673e-03, -7.7409e-02, -1.4565e-01, -9.3908e-03,\n          4.7476e-02, -6.0431e-02,  1.6900e-01, -1.6494e-01,  8.3935e-02,\n          1.2262e-02,  5.4052e-02,  2.2732e-02,  5.8026e-02,  6.9543e-02,\n         -1.4130e-01, -3.7340e-02],\n        [ 1.0833e-01,  1.3191e-02,  6.8599e-02,  1.6924e-01,  1.3210e-01,\n         -5.9867e-02,  6.7282e-02,  2.6698e-02,  6.0550e-02, -1.5571e-01,\n          1.0063e-01,  7.4876e-02,  1.3127e-01,  8.3307e-02, -9.3941e-02,\n         -2.0022e-02, -1.5070e-01, -1.7245e-01,  1.5846e-01,  1.3779e-01,\n         -9.8585e-03,  9.3260e-02,  1.0841e-01,  1.6471e-01, -5.8010e-02,\n         -8.0549e-02, -1.4734e-01, -1.6018e-01,  4.4954e-02, -5.7041e-02,\n          2.9110e-02, -8.2445e-02],\n        [-6.0149e-02, -5.8066e-02,  1.3784e-01, -1.7019e-01, -7.6269e-02,\n          2.5935e-02,  1.6535e-01, -1.2477e-01, -1.3686e-01, -6.4422e-02,\n          1.5872e-01, -1.0453e-01,  1.6318e-01,  1.0547e-01,  1.6171e-01,\n          1.0413e-01, -1.5131e-01,  3.1648e-02,  3.9845e-02, -9.7351e-02,\n          2.6140e-02, -3.3583e-02, -9.2358e-02,  8.5547e-02, -7.5193e-02,\n         -2.4442e-02, -4.0483e-02, -7.1240e-02,  7.0425e-02, -2.9076e-02,\n         -7.1802e-02, -1.4732e-01],\n        [-8.3093e-02,  1.3411e-01,  9.2190e-02, -3.7482e-02, -1.4093e-01,\n          1.0903e-02,  1.4017e-01, -1.6609e-01,  1.4413e-01,  7.1346e-02,\n          1.2493e-01, -1.6127e-01,  1.5729e-01,  1.5973e-02, -1.2982e-01,\n          1.6808e-01,  7.4502e-02,  3.0644e-03, -1.1397e-01, -1.4486e-01,\n          7.5759e-02, -4.2031e-03,  1.3449e-01, -1.5945e-01,  1.3800e-01,\n          1.0201e-01, -1.0921e-01, -1.1735e-01, -5.6933e-02, -7.5313e-02,\n         -1.2595e-01, -5.8295e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2497,  0.2115, -0.0934, -0.2313, -0.1986, -0.0831, -0.0780,  0.1406],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1701,  0.0309,  0.2436,  0.0629,  0.1758, -0.2495,  0.2377,  0.1989,\n         -0.1184,  0.1171, -0.1144,  0.2097,  0.1884, -0.1054,  0.1481, -0.1972],\n        [-0.1221,  0.0349, -0.0188,  0.0360, -0.2205,  0.1584,  0.2229, -0.1709,\n          0.0977, -0.1749,  0.0979,  0.0009,  0.0544, -0.2011,  0.0756, -0.1310],\n        [-0.2461,  0.1144, -0.1897,  0.1629,  0.1132,  0.2480,  0.0698,  0.1030,\n          0.1209,  0.2333, -0.1779,  0.0260,  0.0887,  0.0921,  0.2163, -0.0383],\n        [-0.0841,  0.1220,  0.1172, -0.0063, -0.2275, -0.1222,  0.1111, -0.2465,\n         -0.0937, -0.1028, -0.0714,  0.0007,  0.2028,  0.0619, -0.2327,  0.0087],\n        [-0.2095,  0.1162, -0.0623, -0.0549,  0.1535,  0.0561, -0.1977,  0.1267,\n         -0.1841,  0.0262, -0.1866,  0.0090,  0.0521,  0.1040,  0.0136,  0.0038],\n        [-0.2207,  0.1636, -0.2194, -0.2230, -0.2494, -0.2439,  0.1502,  0.2489,\n          0.1849, -0.0462, -0.1574,  0.2500, -0.0703,  0.2182,  0.0095,  0.0506],\n        [ 0.1747, -0.2020,  0.0373,  0.0710, -0.1969, -0.1308, -0.1706,  0.2394,\n          0.1519,  0.0811,  0.0725, -0.1664,  0.1506, -0.0220,  0.0235,  0.0011],\n        [-0.0739,  0.2319,  0.2151,  0.1102,  0.1880, -0.1746,  0.1710, -0.1780,\n         -0.1750, -0.2005,  0.0597, -0.2235, -0.0533,  0.0897,  0.0155,  0.1310]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0466, -0.2805, -0.0967, -0.1406], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1130,  0.0972,  0.1177, -0.2343, -0.3485,  0.0805,  0.0623,  0.3453],\n        [ 0.0733, -0.1227, -0.2604, -0.0996,  0.2715, -0.3016, -0.2110, -0.2069],\n        [ 0.2912, -0.3282, -0.2659,  0.1198,  0.2495, -0.3367, -0.2031, -0.0681],\n        [ 0.1325, -0.1809, -0.1500,  0.2793,  0.3016,  0.3272,  0.1237, -0.1997]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x706f024e4150>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s728410000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s728410000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}