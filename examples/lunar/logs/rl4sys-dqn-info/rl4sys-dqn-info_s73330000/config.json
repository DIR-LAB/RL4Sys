{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s73330000"
    },
    "q_lr":	0.0005,
    "seed":	73330000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x75abfa458590>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2298, -0.1021, -0.3415, -0.1139,  0.1864,  0.0931, -0.0892, -0.2854,\n         0.1327, -0.0825,  0.1752, -0.2840,  0.1224,  0.1622, -0.0747,  0.2756,\n         0.2352,  0.2183,  0.1485,  0.1027,  0.1666, -0.0785,  0.1326, -0.0665,\n         0.1674,  0.2186,  0.1177,  0.3064, -0.0784, -0.2773,  0.2504, -0.1977],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3476, -0.0060, -0.2032, -0.1648,  0.1007, -0.0060,  0.2224, -0.0739],\n        [-0.2694,  0.3343,  0.1849, -0.2365, -0.0305,  0.0013, -0.0609,  0.0949],\n        [ 0.2209,  0.0984, -0.2769,  0.2850, -0.3249,  0.1098,  0.1511,  0.0203],\n        [-0.0735, -0.1391, -0.1985, -0.2510,  0.2656,  0.2770,  0.2854, -0.2968],\n        [ 0.2121, -0.1051,  0.0568, -0.0290, -0.1137,  0.1093,  0.0685,  0.1116],\n        [ 0.2979,  0.1839,  0.0641, -0.1837,  0.1451,  0.0174, -0.3386, -0.2808],\n        [-0.0708, -0.3362,  0.1171, -0.2828, -0.0041, -0.0827, -0.2929,  0.2541],\n        [ 0.0291, -0.0640,  0.0980,  0.1294,  0.0390, -0.2117,  0.1609, -0.0664],\n        [-0.2118,  0.0767,  0.1691,  0.3457, -0.3217,  0.1381,  0.1454,  0.0799],\n        [-0.3480,  0.0862, -0.1020, -0.0999,  0.0078, -0.3287, -0.3128, -0.1849],\n        [ 0.0860, -0.2428, -0.3312, -0.3078, -0.3259,  0.2849, -0.1117,  0.3432],\n        [ 0.3454,  0.2621,  0.0445, -0.1804, -0.2218, -0.3414,  0.1971, -0.3397],\n        [-0.2971, -0.2813, -0.1855,  0.0026, -0.0036, -0.0846, -0.2974, -0.0210],\n        [ 0.2769,  0.0587, -0.2095, -0.1980, -0.0978,  0.3452, -0.3109, -0.0538],\n        [ 0.1669,  0.2881, -0.3047,  0.0142,  0.3096, -0.0327, -0.2628, -0.1960],\n        [ 0.0576, -0.3209, -0.2869, -0.0765,  0.2694,  0.2469, -0.0745,  0.0497],\n        [ 0.1113, -0.3421, -0.2145, -0.2881, -0.2532,  0.1163,  0.1918, -0.1244],\n        [-0.0168, -0.2445,  0.0411,  0.3183, -0.0484,  0.3060, -0.2006,  0.1114],\n        [-0.1427,  0.0593, -0.2969,  0.3242, -0.1779,  0.2177, -0.1384, -0.3288],\n        [-0.3350, -0.2197,  0.3191, -0.0743,  0.0408, -0.0288,  0.1365,  0.2795],\n        [ 0.0670,  0.0554, -0.1229,  0.0830,  0.3203,  0.0925, -0.0131,  0.0867],\n        [-0.0401,  0.3445, -0.2807, -0.2174, -0.3502,  0.2620, -0.3468,  0.2346],\n        [ 0.2527,  0.3317,  0.2950,  0.2509,  0.2535,  0.0679,  0.3185, -0.0503],\n        [-0.1152, -0.3309,  0.1637,  0.1182,  0.3057, -0.1484,  0.2961, -0.2323],\n        [ 0.0235, -0.3424, -0.0546,  0.0341,  0.1949,  0.1527,  0.1609, -0.1879],\n        [-0.0164, -0.1892, -0.0402, -0.1587,  0.0291,  0.1085, -0.1854, -0.1490],\n        [ 0.0877,  0.1067,  0.1612,  0.2970,  0.2095,  0.0905,  0.3458,  0.1963],\n        [ 0.1114, -0.1578, -0.1657, -0.0566,  0.0655,  0.1612, -0.2019,  0.0020],\n        [-0.0392,  0.2131,  0.1304,  0.1013, -0.0985,  0.1547, -0.1238, -0.2792],\n        [ 0.0986, -0.0957,  0.0652, -0.1958, -0.1260,  0.0901, -0.0495, -0.3207],\n        [-0.2035,  0.2344, -0.0965,  0.1285,  0.2476,  0.1338,  0.0845,  0.1456],\n        [-0.1701,  0.1243,  0.2442,  0.0329, -0.1522,  0.1941, -0.1489, -0.3050]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1687,  0.1036, -0.0307, -0.1571, -0.0925,  0.0471, -0.0998,  0.1739,\n        -0.1564, -0.0532,  0.1217, -0.1114,  0.1151,  0.1157, -0.1625,  0.0354],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0584e-01,  5.1775e-02, -4.1572e-03, -1.2939e-01,  1.7209e-01,\n          1.7524e-01, -2.9442e-02, -1.0252e-01,  1.2741e-01, -3.5343e-02,\n          1.3833e-01,  9.3242e-02, -8.7898e-02, -9.3299e-02,  1.6960e-02,\n          1.3564e-01,  6.6143e-02, -1.3126e-01, -1.1717e-01,  4.8557e-02,\n         -9.7739e-04,  7.8794e-02,  2.2151e-02, -7.6178e-02,  7.0016e-02,\n          1.0697e-01, -7.7733e-02, -1.3323e-01, -1.3394e-01,  1.1723e-01,\n          1.1116e-01,  4.9958e-02],\n        [-1.0947e-01,  7.9491e-02, -1.7526e-01, -1.4989e-01,  1.7123e-02,\n         -9.4730e-03, -1.2368e-01, -9.4338e-02, -1.0737e-01, -1.0191e-01,\n          1.6858e-01, -2.0906e-02,  1.5965e-01, -8.4241e-04, -8.9246e-02,\n         -2.5376e-02, -1.0182e-01,  1.7220e-01,  9.4621e-02,  1.5395e-01,\n         -1.0332e-01,  1.6337e-01,  2.5547e-03,  6.9305e-02, -1.3093e-01,\n         -2.3275e-02,  4.0810e-02,  4.6784e-02,  6.6554e-02,  1.8631e-02,\n         -7.6637e-02, -1.5727e-01],\n        [ 7.5053e-02,  1.6333e-01, -4.7346e-02,  1.2112e-02, -1.5718e-01,\n         -1.5170e-02,  1.4047e-02, -1.3227e-01,  1.0377e-01, -1.4085e-01,\n          1.9262e-02,  1.0630e-01,  9.9930e-03,  6.2812e-02,  1.1466e-01,\n         -1.4047e-01,  6.9409e-02, -1.6465e-02,  1.6051e-01, -1.1413e-01,\n         -1.6669e-01,  4.6102e-02,  1.3512e-01, -8.2826e-02, -1.3584e-01,\n          1.1274e-01,  7.8862e-02,  1.0710e-01,  8.6418e-02, -1.6735e-01,\n         -1.5926e-01, -4.1868e-02],\n        [ 4.7673e-02, -1.5318e-02,  1.7031e-01, -1.1693e-01, -1.0446e-01,\n         -1.7378e-01, -8.8283e-02, -1.6369e-01,  3.3777e-02, -1.6936e-01,\n          7.5988e-02,  1.1255e-01, -6.9495e-02,  7.8159e-02, -1.5194e-01,\n         -2.8469e-03, -1.0315e-01,  4.2765e-02, -1.3781e-01, -1.3841e-01,\n         -1.3039e-01, -7.8004e-02, -5.6215e-02,  2.1758e-02,  8.6269e-02,\n          8.7185e-02, -1.4703e-01,  5.4193e-03,  6.4243e-03,  5.5705e-02,\n         -1.7499e-01, -7.7116e-02],\n        [-1.1677e-01, -4.4203e-02,  2.9757e-02,  1.1634e-01,  3.3011e-02,\n         -1.6077e-01,  6.1549e-02,  1.3973e-01,  4.1005e-02, -8.4567e-02,\n         -1.5102e-01, -7.7328e-02,  5.2792e-02, -8.7746e-02, -1.6554e-01,\n         -2.3587e-02, -5.2256e-02,  7.4739e-02,  4.9549e-02,  1.6016e-01,\n          1.1301e-01,  1.1657e-01,  1.3570e-01,  9.0190e-02, -1.3232e-01,\n         -9.0883e-02, -1.1528e-01, -6.6072e-02,  5.7898e-03, -1.1015e-01,\n          1.3854e-01, -9.2760e-02],\n        [ 1.3296e-01, -9.1603e-02, -1.1782e-02,  8.1977e-02,  1.4043e-01,\n         -1.4852e-01, -5.4800e-03, -7.1591e-02, -3.4608e-02,  1.4128e-01,\n         -2.2369e-02, -4.4358e-02, -1.6067e-01,  1.5582e-02, -1.5161e-02,\n         -2.7132e-02,  1.7944e-03,  3.7460e-02, -1.6694e-01, -8.4937e-02,\n         -1.4147e-01,  1.1972e-01, -1.6844e-01,  9.2642e-02,  1.0340e-01,\n         -2.4463e-02,  2.9378e-02,  1.3864e-02,  1.6947e-01,  1.6699e-01,\n         -8.8137e-02,  1.2416e-01],\n        [ 1.3598e-01, -1.2852e-01,  9.1664e-02, -1.5647e-01,  8.8416e-02,\n          1.6348e-01, -8.3561e-02,  1.2349e-01, -6.1849e-02,  1.0111e-01,\n          1.0984e-03, -1.0614e-01, -1.0400e-01, -3.5058e-02,  5.9091e-02,\n         -2.9583e-02,  8.0339e-02, -1.1969e-01,  1.3505e-01, -3.0170e-02,\n          2.7202e-02,  1.3083e-01, -1.5127e-01, -5.9248e-03, -3.9104e-02,\n         -1.3452e-01,  7.4199e-02,  1.2663e-01, -3.9495e-02, -7.1889e-03,\n          6.2429e-02,  6.9855e-02],\n        [-1.3507e-02, -1.5275e-01, -1.3384e-01, -2.3855e-02, -7.8618e-02,\n         -9.9220e-02, -1.7272e-01,  1.1265e-01, -1.6562e-01,  2.5845e-02,\n          9.4714e-02, -1.7663e-02,  1.7520e-01, -1.4744e-01,  4.1937e-02,\n         -1.6059e-01,  1.0029e-02,  7.8450e-02, -8.2536e-02,  7.6369e-02,\n          7.4321e-02,  1.1067e-01, -1.4265e-01,  6.3615e-02, -1.5171e-01,\n         -1.0502e-01,  2.4302e-02, -1.1882e-01, -1.6625e-01, -1.1920e-01,\n          1.6251e-01,  2.6295e-02],\n        [-9.2813e-02,  1.5759e-01, -1.2724e-01, -1.5937e-01,  1.6317e-01,\n         -1.7214e-01, -1.6643e-01, -7.7025e-02, -8.9948e-02,  1.0636e-01,\n          5.4883e-02, -1.2785e-01,  1.2071e-01, -1.0564e-01, -8.2293e-02,\n          7.6465e-02, -9.0570e-02,  1.0275e-01, -1.4500e-01, -2.9218e-02,\n         -1.1894e-01,  4.6922e-02, -1.3397e-02,  1.5464e-01,  2.6726e-02,\n         -1.5596e-01,  1.3702e-01,  7.3529e-02,  7.7955e-02,  1.4553e-01,\n         -1.0728e-01,  4.5078e-02],\n        [-1.5408e-02, -4.9628e-02, -1.1850e-01,  7.6261e-02, -1.5573e-01,\n         -2.7237e-02,  9.1830e-03, -1.5583e-01,  1.3958e-01, -1.2307e-02,\n         -1.9061e-02,  1.4300e-01,  1.1888e-01, -1.6517e-01,  7.9904e-02,\n          4.1807e-02, -2.2585e-03,  9.1119e-02,  5.5980e-02, -1.0940e-01,\n          5.2345e-02,  6.0135e-02, -1.0485e-01,  1.2015e-01,  5.6990e-02,\n         -1.5334e-01, -8.6038e-02, -7.0751e-02, -5.0154e-02, -7.2222e-02,\n          5.3970e-02,  1.1711e-01],\n        [ 1.2501e-01, -9.1790e-02,  1.1211e-01,  4.9036e-02,  1.2540e-01,\n          8.7031e-02, -4.5215e-02,  2.9959e-02, -1.7027e-01,  5.5561e-02,\n         -4.4928e-02,  4.9764e-02, -1.6556e-03,  8.2297e-02, -2.5654e-02,\n          5.8249e-03, -5.9223e-02,  1.5198e-02,  2.4084e-02, -1.0809e-01,\n          1.6274e-01, -8.8641e-03,  1.6331e-01,  7.0007e-02, -1.8370e-02,\n         -6.5493e-02,  1.7591e-01,  8.3791e-02,  1.6597e-01, -1.3522e-01,\n          1.2975e-01,  6.3752e-02],\n        [-1.9136e-02, -1.9853e-03,  4.4324e-02,  3.7803e-02, -4.4973e-02,\n          2.6919e-02,  1.4606e-02,  8.1968e-02,  1.0869e-03, -1.4135e-01,\n         -1.5571e-01, -1.7897e-02, -8.0869e-04,  8.5934e-02,  1.5845e-01,\n         -6.3723e-02,  3.6831e-02,  5.6027e-02, -6.3953e-02, -1.0882e-01,\n          1.3493e-01, -1.0117e-01, -9.3355e-06, -2.2144e-02,  9.9711e-02,\n          7.3427e-02, -2.0253e-02, -8.5156e-03, -3.5172e-02, -3.7118e-02,\n          1.4301e-01,  6.0188e-03],\n        [-4.9282e-02,  1.4949e-02, -1.3316e-01,  6.7714e-02, -1.4048e-01,\n          1.7662e-01, -1.5958e-01,  4.7346e-02, -8.6668e-02,  1.6336e-01,\n         -1.1487e-01, -1.4875e-01, -1.3886e-01,  1.4761e-01, -7.1200e-02,\n          1.6389e-01,  1.3384e-01,  1.4753e-01,  3.3946e-02,  8.1267e-03,\n          2.9669e-02,  7.9774e-03,  1.6374e-01,  4.2043e-02, -5.3578e-02,\n          2.8057e-02, -1.5155e-01,  6.8321e-02,  6.1202e-02,  8.0513e-03,\n          1.1260e-01, -2.8371e-02],\n        [-1.4206e-01, -1.2002e-01, -4.6691e-02,  7.1901e-02,  4.1488e-02,\n         -1.3504e-01,  4.8808e-02, -1.6215e-01,  1.5506e-01,  2.8087e-03,\n         -7.4378e-02,  3.4534e-02,  9.5676e-02, -1.1341e-01, -9.6694e-02,\n          1.2918e-01, -2.3567e-02, -5.0195e-02, -6.6166e-02, -1.5292e-01,\n          1.3606e-01, -5.9224e-02, -7.7583e-02, -1.0613e-01, -1.2216e-01,\n         -1.7677e-01,  1.4492e-01, -5.1086e-02,  1.3987e-02,  6.5582e-02,\n          1.1319e-01, -6.3745e-02],\n        [ 1.1846e-01,  7.6851e-02, -4.4564e-02,  9.3559e-02,  3.9546e-03,\n          3.3927e-02, -1.3691e-01, -1.4723e-01, -2.5196e-02,  1.4302e-01,\n         -1.1636e-01, -1.4873e-01,  1.1699e-01,  8.8007e-02,  4.3365e-02,\n          1.5203e-01,  1.1528e-01,  1.1476e-01, -1.2558e-01, -1.2119e-01,\n         -1.3615e-01, -9.8912e-03,  7.0718e-02,  1.0548e-01,  1.3193e-01,\n          9.4390e-02, -1.4692e-01,  1.1347e-01, -7.3391e-03, -1.5156e-01,\n          6.5293e-02,  1.7528e-01],\n        [-8.4813e-02,  6.4178e-02,  1.1050e-01, -5.3369e-03,  3.2634e-02,\n          2.1586e-02,  1.6704e-01,  1.7515e-01,  1.1739e-01, -2.9045e-02,\n         -1.1667e-01, -1.0355e-01,  1.7002e-01,  7.0088e-02, -1.3180e-01,\n         -3.7194e-02, -1.3292e-03,  8.8885e-02, -1.4296e-01,  1.4092e-03,\n          1.2594e-01, -1.4584e-01, -3.9990e-02, -5.1294e-02, -1.3249e-01,\n          3.3723e-02,  1.6934e-01, -1.2521e-02, -1.2015e-01,  2.8988e-02,\n          2.9872e-02,  5.7721e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0885, -0.2392,  0.1659,  0.0437,  0.0755,  0.0054,  0.0964,  0.0233],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2373,  0.1309,  0.0292,  0.2279,  0.0447, -0.2170,  0.0842,  0.0363,\n         -0.0400,  0.1872, -0.1322, -0.0796, -0.1451,  0.0614, -0.0192, -0.2244],\n        [-0.2448,  0.0116,  0.1089, -0.2495,  0.0074,  0.1790, -0.0375, -0.2392,\n         -0.2411,  0.2200, -0.1997,  0.0033, -0.1664, -0.0697, -0.0361, -0.1553],\n        [ 0.1593, -0.0307, -0.1016, -0.1872, -0.1288,  0.0660, -0.2379, -0.0689,\n          0.0652,  0.0723, -0.0696, -0.1430,  0.0892,  0.1942, -0.1818, -0.2012],\n        [ 0.0546,  0.2092, -0.0485, -0.2127, -0.0212,  0.2241, -0.1771, -0.0116,\n          0.0770,  0.0781, -0.0900,  0.2067, -0.0133,  0.2136,  0.2264, -0.1023],\n        [ 0.1483, -0.1458, -0.0073, -0.0142, -0.0788, -0.0629, -0.2129,  0.0055,\n         -0.2358, -0.1808,  0.0199, -0.1880,  0.2051,  0.1016,  0.1079, -0.1190],\n        [ 0.0618, -0.1016, -0.1383,  0.1322,  0.2014, -0.0315, -0.2365, -0.0870,\n          0.1000,  0.1165,  0.0066, -0.0072,  0.1796, -0.1097,  0.0293, -0.1336],\n        [-0.1517,  0.1594, -0.1783, -0.1119, -0.0469, -0.1394, -0.2432, -0.0265,\n         -0.0772, -0.1166,  0.2279, -0.0704, -0.1986, -0.1250, -0.2304,  0.0809],\n        [ 0.1886, -0.0822, -0.0981,  0.1431,  0.0052, -0.2424, -0.2007, -0.1828,\n         -0.0596,  0.2326,  0.2101, -0.1861, -0.0391,  0.2399,  0.0741,  0.1242]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3244,  0.0347, -0.1024, -0.1981], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0754,  0.3271,  0.2650, -0.0411,  0.2786, -0.3053, -0.0661, -0.3326],\n        [-0.3307,  0.2912,  0.0628,  0.2704, -0.0503,  0.1659,  0.0247,  0.1982],\n        [-0.2890,  0.1209,  0.1369, -0.0970, -0.0831,  0.2348, -0.0096, -0.2274],\n        [-0.3017,  0.0585, -0.0656, -0.3369,  0.1801,  0.2950, -0.0114, -0.2637]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.3476, -0.0060, -0.2032, -0.1648,  0.1007, -0.0060,  0.2224, -0.0739],\n        [-0.2694,  0.3343,  0.1849, -0.2365, -0.0305,  0.0013, -0.0609,  0.0949],\n        [ 0.2209,  0.0984, -0.2769,  0.2850, -0.3249,  0.1098,  0.1511,  0.0203],\n        [-0.0735, -0.1391, -0.1985, -0.2510,  0.2656,  0.2770,  0.2854, -0.2968],\n        [ 0.2121, -0.1051,  0.0568, -0.0290, -0.1137,  0.1093,  0.0685,  0.1116],\n        [ 0.2979,  0.1839,  0.0641, -0.1837,  0.1451,  0.0174, -0.3386, -0.2808],\n        [-0.0708, -0.3362,  0.1171, -0.2828, -0.0041, -0.0827, -0.2929,  0.2541],\n        [ 0.0291, -0.0640,  0.0980,  0.1294,  0.0390, -0.2117,  0.1609, -0.0664],\n        [-0.2118,  0.0767,  0.1691,  0.3457, -0.3217,  0.1381,  0.1454,  0.0799],\n        [-0.3480,  0.0862, -0.1020, -0.0999,  0.0078, -0.3287, -0.3128, -0.1849],\n        [ 0.0860, -0.2428, -0.3312, -0.3078, -0.3259,  0.2849, -0.1117,  0.3432],\n        [ 0.3454,  0.2621,  0.0445, -0.1804, -0.2218, -0.3414,  0.1971, -0.3397],\n        [-0.2971, -0.2813, -0.1855,  0.0026, -0.0036, -0.0846, -0.2974, -0.0210],\n        [ 0.2769,  0.0587, -0.2095, -0.1980, -0.0978,  0.3452, -0.3109, -0.0538],\n        [ 0.1669,  0.2881, -0.3047,  0.0142,  0.3096, -0.0327, -0.2628, -0.1960],\n        [ 0.0576, -0.3209, -0.2869, -0.0765,  0.2694,  0.2469, -0.0745,  0.0497],\n        [ 0.1113, -0.3421, -0.2145, -0.2881, -0.2532,  0.1163,  0.1918, -0.1244],\n        [-0.0168, -0.2445,  0.0411,  0.3183, -0.0484,  0.3060, -0.2006,  0.1114],\n        [-0.1427,  0.0593, -0.2969,  0.3242, -0.1779,  0.2177, -0.1384, -0.3288],\n        [-0.3350, -0.2197,  0.3191, -0.0743,  0.0408, -0.0288,  0.1365,  0.2795],\n        [ 0.0670,  0.0554, -0.1229,  0.0830,  0.3203,  0.0925, -0.0131,  0.0867],\n        [-0.0401,  0.3445, -0.2807, -0.2174, -0.3502,  0.2620, -0.3468,  0.2346],\n        [ 0.2527,  0.3317,  0.2950,  0.2509,  0.2535,  0.0679,  0.3185, -0.0503],\n        [-0.1152, -0.3309,  0.1637,  0.1182,  0.3057, -0.1484,  0.2961, -0.2323],\n        [ 0.0235, -0.3424, -0.0546,  0.0341,  0.1949,  0.1527,  0.1609, -0.1879],\n        [-0.0164, -0.1892, -0.0402, -0.1587,  0.0291,  0.1085, -0.1854, -0.1490],\n        [ 0.0877,  0.1067,  0.1612,  0.2970,  0.2095,  0.0905,  0.3458,  0.1963],\n        [ 0.1114, -0.1578, -0.1657, -0.0566,  0.0655,  0.1612, -0.2019,  0.0020],\n        [-0.0392,  0.2131,  0.1304,  0.1013, -0.0985,  0.1547, -0.1238, -0.2792],\n        [ 0.0986, -0.0957,  0.0652, -0.1958, -0.1260,  0.0901, -0.0495, -0.3207],\n        [-0.2035,  0.2344, -0.0965,  0.1285,  0.2476,  0.1338,  0.0845,  0.1456],\n        [-0.1701,  0.1243,  0.2442,  0.0329, -0.1522,  0.1941, -0.1489, -0.3050]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2298, -0.1021, -0.3415, -0.1139,  0.1864,  0.0931, -0.0892, -0.2854,\n         0.1327, -0.0825,  0.1752, -0.2840,  0.1224,  0.1622, -0.0747,  0.2756,\n         0.2352,  0.2183,  0.1485,  0.1027,  0.1666, -0.0785,  0.1326, -0.0665,\n         0.1674,  0.2186,  0.1177,  0.3064, -0.0784, -0.2773,  0.2504, -0.1977],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.0584e-01,  5.1775e-02, -4.1572e-03, -1.2939e-01,  1.7209e-01,\n          1.7524e-01, -2.9442e-02, -1.0252e-01,  1.2741e-01, -3.5343e-02,\n          1.3833e-01,  9.3242e-02, -8.7898e-02, -9.3299e-02,  1.6960e-02,\n          1.3564e-01,  6.6143e-02, -1.3126e-01, -1.1717e-01,  4.8557e-02,\n         -9.7739e-04,  7.8794e-02,  2.2151e-02, -7.6178e-02,  7.0016e-02,\n          1.0697e-01, -7.7733e-02, -1.3323e-01, -1.3394e-01,  1.1723e-01,\n          1.1116e-01,  4.9958e-02],\n        [-1.0947e-01,  7.9491e-02, -1.7526e-01, -1.4989e-01,  1.7123e-02,\n         -9.4730e-03, -1.2368e-01, -9.4338e-02, -1.0737e-01, -1.0191e-01,\n          1.6858e-01, -2.0906e-02,  1.5965e-01, -8.4241e-04, -8.9246e-02,\n         -2.5376e-02, -1.0182e-01,  1.7220e-01,  9.4621e-02,  1.5395e-01,\n         -1.0332e-01,  1.6337e-01,  2.5547e-03,  6.9305e-02, -1.3093e-01,\n         -2.3275e-02,  4.0810e-02,  4.6784e-02,  6.6554e-02,  1.8631e-02,\n         -7.6637e-02, -1.5727e-01],\n        [ 7.5053e-02,  1.6333e-01, -4.7346e-02,  1.2112e-02, -1.5718e-01,\n         -1.5170e-02,  1.4047e-02, -1.3227e-01,  1.0377e-01, -1.4085e-01,\n          1.9262e-02,  1.0630e-01,  9.9930e-03,  6.2812e-02,  1.1466e-01,\n         -1.4047e-01,  6.9409e-02, -1.6465e-02,  1.6051e-01, -1.1413e-01,\n         -1.6669e-01,  4.6102e-02,  1.3512e-01, -8.2826e-02, -1.3584e-01,\n          1.1274e-01,  7.8862e-02,  1.0710e-01,  8.6418e-02, -1.6735e-01,\n         -1.5926e-01, -4.1868e-02],\n        [ 4.7673e-02, -1.5318e-02,  1.7031e-01, -1.1693e-01, -1.0446e-01,\n         -1.7378e-01, -8.8283e-02, -1.6369e-01,  3.3777e-02, -1.6936e-01,\n          7.5988e-02,  1.1255e-01, -6.9495e-02,  7.8159e-02, -1.5194e-01,\n         -2.8469e-03, -1.0315e-01,  4.2765e-02, -1.3781e-01, -1.3841e-01,\n         -1.3039e-01, -7.8004e-02, -5.6215e-02,  2.1758e-02,  8.6269e-02,\n          8.7185e-02, -1.4703e-01,  5.4193e-03,  6.4243e-03,  5.5705e-02,\n         -1.7499e-01, -7.7116e-02],\n        [-1.1677e-01, -4.4203e-02,  2.9757e-02,  1.1634e-01,  3.3011e-02,\n         -1.6077e-01,  6.1549e-02,  1.3973e-01,  4.1005e-02, -8.4567e-02,\n         -1.5102e-01, -7.7328e-02,  5.2792e-02, -8.7746e-02, -1.6554e-01,\n         -2.3587e-02, -5.2256e-02,  7.4739e-02,  4.9549e-02,  1.6016e-01,\n          1.1301e-01,  1.1657e-01,  1.3570e-01,  9.0190e-02, -1.3232e-01,\n         -9.0883e-02, -1.1528e-01, -6.6072e-02,  5.7898e-03, -1.1015e-01,\n          1.3854e-01, -9.2760e-02],\n        [ 1.3296e-01, -9.1603e-02, -1.1782e-02,  8.1977e-02,  1.4043e-01,\n         -1.4852e-01, -5.4800e-03, -7.1591e-02, -3.4608e-02,  1.4128e-01,\n         -2.2369e-02, -4.4358e-02, -1.6067e-01,  1.5582e-02, -1.5161e-02,\n         -2.7132e-02,  1.7944e-03,  3.7460e-02, -1.6694e-01, -8.4937e-02,\n         -1.4147e-01,  1.1972e-01, -1.6844e-01,  9.2642e-02,  1.0340e-01,\n         -2.4463e-02,  2.9378e-02,  1.3864e-02,  1.6947e-01,  1.6699e-01,\n         -8.8137e-02,  1.2416e-01],\n        [ 1.3598e-01, -1.2852e-01,  9.1664e-02, -1.5647e-01,  8.8416e-02,\n          1.6348e-01, -8.3561e-02,  1.2349e-01, -6.1849e-02,  1.0111e-01,\n          1.0984e-03, -1.0614e-01, -1.0400e-01, -3.5058e-02,  5.9091e-02,\n         -2.9583e-02,  8.0339e-02, -1.1969e-01,  1.3505e-01, -3.0170e-02,\n          2.7202e-02,  1.3083e-01, -1.5127e-01, -5.9248e-03, -3.9104e-02,\n         -1.3452e-01,  7.4199e-02,  1.2663e-01, -3.9495e-02, -7.1889e-03,\n          6.2429e-02,  6.9855e-02],\n        [-1.3507e-02, -1.5275e-01, -1.3384e-01, -2.3855e-02, -7.8618e-02,\n         -9.9220e-02, -1.7272e-01,  1.1265e-01, -1.6562e-01,  2.5845e-02,\n          9.4714e-02, -1.7663e-02,  1.7520e-01, -1.4744e-01,  4.1937e-02,\n         -1.6059e-01,  1.0029e-02,  7.8450e-02, -8.2536e-02,  7.6369e-02,\n          7.4321e-02,  1.1067e-01, -1.4265e-01,  6.3615e-02, -1.5171e-01,\n         -1.0502e-01,  2.4302e-02, -1.1882e-01, -1.6625e-01, -1.1920e-01,\n          1.6251e-01,  2.6295e-02],\n        [-9.2813e-02,  1.5759e-01, -1.2724e-01, -1.5937e-01,  1.6317e-01,\n         -1.7214e-01, -1.6643e-01, -7.7025e-02, -8.9948e-02,  1.0636e-01,\n          5.4883e-02, -1.2785e-01,  1.2071e-01, -1.0564e-01, -8.2293e-02,\n          7.6465e-02, -9.0570e-02,  1.0275e-01, -1.4500e-01, -2.9218e-02,\n         -1.1894e-01,  4.6922e-02, -1.3397e-02,  1.5464e-01,  2.6726e-02,\n         -1.5596e-01,  1.3702e-01,  7.3529e-02,  7.7955e-02,  1.4553e-01,\n         -1.0728e-01,  4.5078e-02],\n        [-1.5408e-02, -4.9628e-02, -1.1850e-01,  7.6261e-02, -1.5573e-01,\n         -2.7237e-02,  9.1830e-03, -1.5583e-01,  1.3958e-01, -1.2307e-02,\n         -1.9061e-02,  1.4300e-01,  1.1888e-01, -1.6517e-01,  7.9904e-02,\n          4.1807e-02, -2.2585e-03,  9.1119e-02,  5.5980e-02, -1.0940e-01,\n          5.2345e-02,  6.0135e-02, -1.0485e-01,  1.2015e-01,  5.6990e-02,\n         -1.5334e-01, -8.6038e-02, -7.0751e-02, -5.0154e-02, -7.2222e-02,\n          5.3970e-02,  1.1711e-01],\n        [ 1.2501e-01, -9.1790e-02,  1.1211e-01,  4.9036e-02,  1.2540e-01,\n          8.7031e-02, -4.5215e-02,  2.9959e-02, -1.7027e-01,  5.5561e-02,\n         -4.4928e-02,  4.9764e-02, -1.6556e-03,  8.2297e-02, -2.5654e-02,\n          5.8249e-03, -5.9223e-02,  1.5198e-02,  2.4084e-02, -1.0809e-01,\n          1.6274e-01, -8.8641e-03,  1.6331e-01,  7.0007e-02, -1.8370e-02,\n         -6.5493e-02,  1.7591e-01,  8.3791e-02,  1.6597e-01, -1.3522e-01,\n          1.2975e-01,  6.3752e-02],\n        [-1.9136e-02, -1.9853e-03,  4.4324e-02,  3.7803e-02, -4.4973e-02,\n          2.6919e-02,  1.4606e-02,  8.1968e-02,  1.0869e-03, -1.4135e-01,\n         -1.5571e-01, -1.7897e-02, -8.0869e-04,  8.5934e-02,  1.5845e-01,\n         -6.3723e-02,  3.6831e-02,  5.6027e-02, -6.3953e-02, -1.0882e-01,\n          1.3493e-01, -1.0117e-01, -9.3355e-06, -2.2144e-02,  9.9711e-02,\n          7.3427e-02, -2.0253e-02, -8.5156e-03, -3.5172e-02, -3.7118e-02,\n          1.4301e-01,  6.0188e-03],\n        [-4.9282e-02,  1.4949e-02, -1.3316e-01,  6.7714e-02, -1.4048e-01,\n          1.7662e-01, -1.5958e-01,  4.7346e-02, -8.6668e-02,  1.6336e-01,\n         -1.1487e-01, -1.4875e-01, -1.3886e-01,  1.4761e-01, -7.1200e-02,\n          1.6389e-01,  1.3384e-01,  1.4753e-01,  3.3946e-02,  8.1267e-03,\n          2.9669e-02,  7.9774e-03,  1.6374e-01,  4.2043e-02, -5.3578e-02,\n          2.8057e-02, -1.5155e-01,  6.8321e-02,  6.1202e-02,  8.0513e-03,\n          1.1260e-01, -2.8371e-02],\n        [-1.4206e-01, -1.2002e-01, -4.6691e-02,  7.1901e-02,  4.1488e-02,\n         -1.3504e-01,  4.8808e-02, -1.6215e-01,  1.5506e-01,  2.8087e-03,\n         -7.4378e-02,  3.4534e-02,  9.5676e-02, -1.1341e-01, -9.6694e-02,\n          1.2918e-01, -2.3567e-02, -5.0195e-02, -6.6166e-02, -1.5292e-01,\n          1.3606e-01, -5.9224e-02, -7.7583e-02, -1.0613e-01, -1.2216e-01,\n         -1.7677e-01,  1.4492e-01, -5.1086e-02,  1.3987e-02,  6.5582e-02,\n          1.1319e-01, -6.3745e-02],\n        [ 1.1846e-01,  7.6851e-02, -4.4564e-02,  9.3559e-02,  3.9546e-03,\n          3.3927e-02, -1.3691e-01, -1.4723e-01, -2.5196e-02,  1.4302e-01,\n         -1.1636e-01, -1.4873e-01,  1.1699e-01,  8.8007e-02,  4.3365e-02,\n          1.5203e-01,  1.1528e-01,  1.1476e-01, -1.2558e-01, -1.2119e-01,\n         -1.3615e-01, -9.8912e-03,  7.0718e-02,  1.0548e-01,  1.3193e-01,\n          9.4390e-02, -1.4692e-01,  1.1347e-01, -7.3391e-03, -1.5156e-01,\n          6.5293e-02,  1.7528e-01],\n        [-8.4813e-02,  6.4178e-02,  1.1050e-01, -5.3369e-03,  3.2634e-02,\n          2.1586e-02,  1.6704e-01,  1.7515e-01,  1.1739e-01, -2.9045e-02,\n         -1.1667e-01, -1.0355e-01,  1.7002e-01,  7.0088e-02, -1.3180e-01,\n         -3.7194e-02, -1.3292e-03,  8.8885e-02, -1.4296e-01,  1.4092e-03,\n          1.2594e-01, -1.4584e-01, -3.9990e-02, -5.1294e-02, -1.3249e-01,\n          3.3723e-02,  1.6934e-01, -1.2521e-02, -1.2015e-01,  2.8988e-02,\n          2.9872e-02,  5.7721e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1687,  0.1036, -0.0307, -0.1571, -0.0925,  0.0471, -0.0998,  0.1739,\n        -0.1564, -0.0532,  0.1217, -0.1114,  0.1151,  0.1157, -0.1625,  0.0354],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2373,  0.1309,  0.0292,  0.2279,  0.0447, -0.2170,  0.0842,  0.0363,\n         -0.0400,  0.1872, -0.1322, -0.0796, -0.1451,  0.0614, -0.0192, -0.2244],\n        [-0.2448,  0.0116,  0.1089, -0.2495,  0.0074,  0.1790, -0.0375, -0.2392,\n         -0.2411,  0.2200, -0.1997,  0.0033, -0.1664, -0.0697, -0.0361, -0.1553],\n        [ 0.1593, -0.0307, -0.1016, -0.1872, -0.1288,  0.0660, -0.2379, -0.0689,\n          0.0652,  0.0723, -0.0696, -0.1430,  0.0892,  0.1942, -0.1818, -0.2012],\n        [ 0.0546,  0.2092, -0.0485, -0.2127, -0.0212,  0.2241, -0.1771, -0.0116,\n          0.0770,  0.0781, -0.0900,  0.2067, -0.0133,  0.2136,  0.2264, -0.1023],\n        [ 0.1483, -0.1458, -0.0073, -0.0142, -0.0788, -0.0629, -0.2129,  0.0055,\n         -0.2358, -0.1808,  0.0199, -0.1880,  0.2051,  0.1016,  0.1079, -0.1190],\n        [ 0.0618, -0.1016, -0.1383,  0.1322,  0.2014, -0.0315, -0.2365, -0.0870,\n          0.1000,  0.1165,  0.0066, -0.0072,  0.1796, -0.1097,  0.0293, -0.1336],\n        [-0.1517,  0.1594, -0.1783, -0.1119, -0.0469, -0.1394, -0.2432, -0.0265,\n         -0.0772, -0.1166,  0.2279, -0.0704, -0.1986, -0.1250, -0.2304,  0.0809],\n        [ 0.1886, -0.0822, -0.0981,  0.1431,  0.0052, -0.2424, -0.2007, -0.1828,\n         -0.0596,  0.2326,  0.2101, -0.1861, -0.0391,  0.2399,  0.0741,  0.1242]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0885, -0.2392,  0.1659,  0.0437,  0.0755,  0.0054,  0.0964,  0.0233],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0754,  0.3271,  0.2650, -0.0411,  0.2786, -0.3053, -0.0661, -0.3326],\n        [-0.3307,  0.2912,  0.0628,  0.2704, -0.0503,  0.1659,  0.0247,  0.1982],\n        [-0.2890,  0.1209,  0.1369, -0.0970, -0.0831,  0.2348, -0.0096, -0.2274],\n        [-0.3017,  0.0585, -0.0656, -0.3369,  0.1801,  0.2950, -0.0114, -0.2637]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3244,  0.0347, -0.1024, -0.1981], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x75abf874eb10>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "time":	0,
                    "timestamp_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2298, -0.1021, -0.3415, -0.1139,  0.1864,  0.0931, -0.0892, -0.2854,\n         0.1327, -0.0825,  0.1752, -0.2840,  0.1224,  0.1622, -0.0747,  0.2756,\n         0.2352,  0.2183,  0.1485,  0.1027,  0.1666, -0.0785,  0.1326, -0.0665,\n         0.1674,  0.2186,  0.1177,  0.3064, -0.0784, -0.2773,  0.2504, -0.1977],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3476, -0.0060, -0.2032, -0.1648,  0.1007, -0.0060,  0.2224, -0.0739],\n        [-0.2694,  0.3343,  0.1849, -0.2365, -0.0305,  0.0013, -0.0609,  0.0949],\n        [ 0.2209,  0.0984, -0.2769,  0.2850, -0.3249,  0.1098,  0.1511,  0.0203],\n        [-0.0735, -0.1391, -0.1985, -0.2510,  0.2656,  0.2770,  0.2854, -0.2968],\n        [ 0.2121, -0.1051,  0.0568, -0.0290, -0.1137,  0.1093,  0.0685,  0.1116],\n        [ 0.2979,  0.1839,  0.0641, -0.1837,  0.1451,  0.0174, -0.3386, -0.2808],\n        [-0.0708, -0.3362,  0.1171, -0.2828, -0.0041, -0.0827, -0.2929,  0.2541],\n        [ 0.0291, -0.0640,  0.0980,  0.1294,  0.0390, -0.2117,  0.1609, -0.0664],\n        [-0.2118,  0.0767,  0.1691,  0.3457, -0.3217,  0.1381,  0.1454,  0.0799],\n        [-0.3480,  0.0862, -0.1020, -0.0999,  0.0078, -0.3287, -0.3128, -0.1849],\n        [ 0.0860, -0.2428, -0.3312, -0.3078, -0.3259,  0.2849, -0.1117,  0.3432],\n        [ 0.3454,  0.2621,  0.0445, -0.1804, -0.2218, -0.3414,  0.1971, -0.3397],\n        [-0.2971, -0.2813, -0.1855,  0.0026, -0.0036, -0.0846, -0.2974, -0.0210],\n        [ 0.2769,  0.0587, -0.2095, -0.1980, -0.0978,  0.3452, -0.3109, -0.0538],\n        [ 0.1669,  0.2881, -0.3047,  0.0142,  0.3096, -0.0327, -0.2628, -0.1960],\n        [ 0.0576, -0.3209, -0.2869, -0.0765,  0.2694,  0.2469, -0.0745,  0.0497],\n        [ 0.1113, -0.3421, -0.2145, -0.2881, -0.2532,  0.1163,  0.1918, -0.1244],\n        [-0.0168, -0.2445,  0.0411,  0.3183, -0.0484,  0.3060, -0.2006,  0.1114],\n        [-0.1427,  0.0593, -0.2969,  0.3242, -0.1779,  0.2177, -0.1384, -0.3288],\n        [-0.3350, -0.2197,  0.3191, -0.0743,  0.0408, -0.0288,  0.1365,  0.2795],\n        [ 0.0670,  0.0554, -0.1229,  0.0830,  0.3203,  0.0925, -0.0131,  0.0867],\n        [-0.0401,  0.3445, -0.2807, -0.2174, -0.3502,  0.2620, -0.3468,  0.2346],\n        [ 0.2527,  0.3317,  0.2950,  0.2509,  0.2535,  0.0679,  0.3185, -0.0503],\n        [-0.1152, -0.3309,  0.1637,  0.1182,  0.3057, -0.1484,  0.2961, -0.2323],\n        [ 0.0235, -0.3424, -0.0546,  0.0341,  0.1949,  0.1527,  0.1609, -0.1879],\n        [-0.0164, -0.1892, -0.0402, -0.1587,  0.0291,  0.1085, -0.1854, -0.1490],\n        [ 0.0877,  0.1067,  0.1612,  0.2970,  0.2095,  0.0905,  0.3458,  0.1963],\n        [ 0.1114, -0.1578, -0.1657, -0.0566,  0.0655,  0.1612, -0.2019,  0.0020],\n        [-0.0392,  0.2131,  0.1304,  0.1013, -0.0985,  0.1547, -0.1238, -0.2792],\n        [ 0.0986, -0.0957,  0.0652, -0.1958, -0.1260,  0.0901, -0.0495, -0.3207],\n        [-0.2035,  0.2344, -0.0965,  0.1285,  0.2476,  0.1338,  0.0845,  0.1456],\n        [-0.1701,  0.1243,  0.2442,  0.0329, -0.1522,  0.1941, -0.1489, -0.3050]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1687,  0.1036, -0.0307, -0.1571, -0.0925,  0.0471, -0.0998,  0.1739,\n        -0.1564, -0.0532,  0.1217, -0.1114,  0.1151,  0.1157, -0.1625,  0.0354],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0584e-01,  5.1775e-02, -4.1572e-03, -1.2939e-01,  1.7209e-01,\n          1.7524e-01, -2.9442e-02, -1.0252e-01,  1.2741e-01, -3.5343e-02,\n          1.3833e-01,  9.3242e-02, -8.7898e-02, -9.3299e-02,  1.6960e-02,\n          1.3564e-01,  6.6143e-02, -1.3126e-01, -1.1717e-01,  4.8557e-02,\n         -9.7739e-04,  7.8794e-02,  2.2151e-02, -7.6178e-02,  7.0016e-02,\n          1.0697e-01, -7.7733e-02, -1.3323e-01, -1.3394e-01,  1.1723e-01,\n          1.1116e-01,  4.9958e-02],\n        [-1.0947e-01,  7.9491e-02, -1.7526e-01, -1.4989e-01,  1.7123e-02,\n         -9.4730e-03, -1.2368e-01, -9.4338e-02, -1.0737e-01, -1.0191e-01,\n          1.6858e-01, -2.0906e-02,  1.5965e-01, -8.4241e-04, -8.9246e-02,\n         -2.5376e-02, -1.0182e-01,  1.7220e-01,  9.4621e-02,  1.5395e-01,\n         -1.0332e-01,  1.6337e-01,  2.5547e-03,  6.9305e-02, -1.3093e-01,\n         -2.3275e-02,  4.0810e-02,  4.6784e-02,  6.6554e-02,  1.8631e-02,\n         -7.6637e-02, -1.5727e-01],\n        [ 7.5053e-02,  1.6333e-01, -4.7346e-02,  1.2112e-02, -1.5718e-01,\n         -1.5170e-02,  1.4047e-02, -1.3227e-01,  1.0377e-01, -1.4085e-01,\n          1.9262e-02,  1.0630e-01,  9.9930e-03,  6.2812e-02,  1.1466e-01,\n         -1.4047e-01,  6.9409e-02, -1.6465e-02,  1.6051e-01, -1.1413e-01,\n         -1.6669e-01,  4.6102e-02,  1.3512e-01, -8.2826e-02, -1.3584e-01,\n          1.1274e-01,  7.8862e-02,  1.0710e-01,  8.6418e-02, -1.6735e-01,\n         -1.5926e-01, -4.1868e-02],\n        [ 4.7673e-02, -1.5318e-02,  1.7031e-01, -1.1693e-01, -1.0446e-01,\n         -1.7378e-01, -8.8283e-02, -1.6369e-01,  3.3777e-02, -1.6936e-01,\n          7.5988e-02,  1.1255e-01, -6.9495e-02,  7.8159e-02, -1.5194e-01,\n         -2.8469e-03, -1.0315e-01,  4.2765e-02, -1.3781e-01, -1.3841e-01,\n         -1.3039e-01, -7.8004e-02, -5.6215e-02,  2.1758e-02,  8.6269e-02,\n          8.7185e-02, -1.4703e-01,  5.4193e-03,  6.4243e-03,  5.5705e-02,\n         -1.7499e-01, -7.7116e-02],\n        [-1.1677e-01, -4.4203e-02,  2.9757e-02,  1.1634e-01,  3.3011e-02,\n         -1.6077e-01,  6.1549e-02,  1.3973e-01,  4.1005e-02, -8.4567e-02,\n         -1.5102e-01, -7.7328e-02,  5.2792e-02, -8.7746e-02, -1.6554e-01,\n         -2.3587e-02, -5.2256e-02,  7.4739e-02,  4.9549e-02,  1.6016e-01,\n          1.1301e-01,  1.1657e-01,  1.3570e-01,  9.0190e-02, -1.3232e-01,\n         -9.0883e-02, -1.1528e-01, -6.6072e-02,  5.7898e-03, -1.1015e-01,\n          1.3854e-01, -9.2760e-02],\n        [ 1.3296e-01, -9.1603e-02, -1.1782e-02,  8.1977e-02,  1.4043e-01,\n         -1.4852e-01, -5.4800e-03, -7.1591e-02, -3.4608e-02,  1.4128e-01,\n         -2.2369e-02, -4.4358e-02, -1.6067e-01,  1.5582e-02, -1.5161e-02,\n         -2.7132e-02,  1.7944e-03,  3.7460e-02, -1.6694e-01, -8.4937e-02,\n         -1.4147e-01,  1.1972e-01, -1.6844e-01,  9.2642e-02,  1.0340e-01,\n         -2.4463e-02,  2.9378e-02,  1.3864e-02,  1.6947e-01,  1.6699e-01,\n         -8.8137e-02,  1.2416e-01],\n        [ 1.3598e-01, -1.2852e-01,  9.1664e-02, -1.5647e-01,  8.8416e-02,\n          1.6348e-01, -8.3561e-02,  1.2349e-01, -6.1849e-02,  1.0111e-01,\n          1.0984e-03, -1.0614e-01, -1.0400e-01, -3.5058e-02,  5.9091e-02,\n         -2.9583e-02,  8.0339e-02, -1.1969e-01,  1.3505e-01, -3.0170e-02,\n          2.7202e-02,  1.3083e-01, -1.5127e-01, -5.9248e-03, -3.9104e-02,\n         -1.3452e-01,  7.4199e-02,  1.2663e-01, -3.9495e-02, -7.1889e-03,\n          6.2429e-02,  6.9855e-02],\n        [-1.3507e-02, -1.5275e-01, -1.3384e-01, -2.3855e-02, -7.8618e-02,\n         -9.9220e-02, -1.7272e-01,  1.1265e-01, -1.6562e-01,  2.5845e-02,\n          9.4714e-02, -1.7663e-02,  1.7520e-01, -1.4744e-01,  4.1937e-02,\n         -1.6059e-01,  1.0029e-02,  7.8450e-02, -8.2536e-02,  7.6369e-02,\n          7.4321e-02,  1.1067e-01, -1.4265e-01,  6.3615e-02, -1.5171e-01,\n         -1.0502e-01,  2.4302e-02, -1.1882e-01, -1.6625e-01, -1.1920e-01,\n          1.6251e-01,  2.6295e-02],\n        [-9.2813e-02,  1.5759e-01, -1.2724e-01, -1.5937e-01,  1.6317e-01,\n         -1.7214e-01, -1.6643e-01, -7.7025e-02, -8.9948e-02,  1.0636e-01,\n          5.4883e-02, -1.2785e-01,  1.2071e-01, -1.0564e-01, -8.2293e-02,\n          7.6465e-02, -9.0570e-02,  1.0275e-01, -1.4500e-01, -2.9218e-02,\n         -1.1894e-01,  4.6922e-02, -1.3397e-02,  1.5464e-01,  2.6726e-02,\n         -1.5596e-01,  1.3702e-01,  7.3529e-02,  7.7955e-02,  1.4553e-01,\n         -1.0728e-01,  4.5078e-02],\n        [-1.5408e-02, -4.9628e-02, -1.1850e-01,  7.6261e-02, -1.5573e-01,\n         -2.7237e-02,  9.1830e-03, -1.5583e-01,  1.3958e-01, -1.2307e-02,\n         -1.9061e-02,  1.4300e-01,  1.1888e-01, -1.6517e-01,  7.9904e-02,\n          4.1807e-02, -2.2585e-03,  9.1119e-02,  5.5980e-02, -1.0940e-01,\n          5.2345e-02,  6.0135e-02, -1.0485e-01,  1.2015e-01,  5.6990e-02,\n         -1.5334e-01, -8.6038e-02, -7.0751e-02, -5.0154e-02, -7.2222e-02,\n          5.3970e-02,  1.1711e-01],\n        [ 1.2501e-01, -9.1790e-02,  1.1211e-01,  4.9036e-02,  1.2540e-01,\n          8.7031e-02, -4.5215e-02,  2.9959e-02, -1.7027e-01,  5.5561e-02,\n         -4.4928e-02,  4.9764e-02, -1.6556e-03,  8.2297e-02, -2.5654e-02,\n          5.8249e-03, -5.9223e-02,  1.5198e-02,  2.4084e-02, -1.0809e-01,\n          1.6274e-01, -8.8641e-03,  1.6331e-01,  7.0007e-02, -1.8370e-02,\n         -6.5493e-02,  1.7591e-01,  8.3791e-02,  1.6597e-01, -1.3522e-01,\n          1.2975e-01,  6.3752e-02],\n        [-1.9136e-02, -1.9853e-03,  4.4324e-02,  3.7803e-02, -4.4973e-02,\n          2.6919e-02,  1.4606e-02,  8.1968e-02,  1.0869e-03, -1.4135e-01,\n         -1.5571e-01, -1.7897e-02, -8.0869e-04,  8.5934e-02,  1.5845e-01,\n         -6.3723e-02,  3.6831e-02,  5.6027e-02, -6.3953e-02, -1.0882e-01,\n          1.3493e-01, -1.0117e-01, -9.3355e-06, -2.2144e-02,  9.9711e-02,\n          7.3427e-02, -2.0253e-02, -8.5156e-03, -3.5172e-02, -3.7118e-02,\n          1.4301e-01,  6.0188e-03],\n        [-4.9282e-02,  1.4949e-02, -1.3316e-01,  6.7714e-02, -1.4048e-01,\n          1.7662e-01, -1.5958e-01,  4.7346e-02, -8.6668e-02,  1.6336e-01,\n         -1.1487e-01, -1.4875e-01, -1.3886e-01,  1.4761e-01, -7.1200e-02,\n          1.6389e-01,  1.3384e-01,  1.4753e-01,  3.3946e-02,  8.1267e-03,\n          2.9669e-02,  7.9774e-03,  1.6374e-01,  4.2043e-02, -5.3578e-02,\n          2.8057e-02, -1.5155e-01,  6.8321e-02,  6.1202e-02,  8.0513e-03,\n          1.1260e-01, -2.8371e-02],\n        [-1.4206e-01, -1.2002e-01, -4.6691e-02,  7.1901e-02,  4.1488e-02,\n         -1.3504e-01,  4.8808e-02, -1.6215e-01,  1.5506e-01,  2.8087e-03,\n         -7.4378e-02,  3.4534e-02,  9.5676e-02, -1.1341e-01, -9.6694e-02,\n          1.2918e-01, -2.3567e-02, -5.0195e-02, -6.6166e-02, -1.5292e-01,\n          1.3606e-01, -5.9224e-02, -7.7583e-02, -1.0613e-01, -1.2216e-01,\n         -1.7677e-01,  1.4492e-01, -5.1086e-02,  1.3987e-02,  6.5582e-02,\n          1.1319e-01, -6.3745e-02],\n        [ 1.1846e-01,  7.6851e-02, -4.4564e-02,  9.3559e-02,  3.9546e-03,\n          3.3927e-02, -1.3691e-01, -1.4723e-01, -2.5196e-02,  1.4302e-01,\n         -1.1636e-01, -1.4873e-01,  1.1699e-01,  8.8007e-02,  4.3365e-02,\n          1.5203e-01,  1.1528e-01,  1.1476e-01, -1.2558e-01, -1.2119e-01,\n         -1.3615e-01, -9.8912e-03,  7.0718e-02,  1.0548e-01,  1.3193e-01,\n          9.4390e-02, -1.4692e-01,  1.1347e-01, -7.3391e-03, -1.5156e-01,\n          6.5293e-02,  1.7528e-01],\n        [-8.4813e-02,  6.4178e-02,  1.1050e-01, -5.3369e-03,  3.2634e-02,\n          2.1586e-02,  1.6704e-01,  1.7515e-01,  1.1739e-01, -2.9045e-02,\n         -1.1667e-01, -1.0355e-01,  1.7002e-01,  7.0088e-02, -1.3180e-01,\n         -3.7194e-02, -1.3292e-03,  8.8885e-02, -1.4296e-01,  1.4092e-03,\n          1.2594e-01, -1.4584e-01, -3.9990e-02, -5.1294e-02, -1.3249e-01,\n          3.3723e-02,  1.6934e-01, -1.2521e-02, -1.2015e-01,  2.8988e-02,\n          2.9872e-02,  5.7721e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0885, -0.2392,  0.1659,  0.0437,  0.0755,  0.0054,  0.0964,  0.0233],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2373,  0.1309,  0.0292,  0.2279,  0.0447, -0.2170,  0.0842,  0.0363,\n         -0.0400,  0.1872, -0.1322, -0.0796, -0.1451,  0.0614, -0.0192, -0.2244],\n        [-0.2448,  0.0116,  0.1089, -0.2495,  0.0074,  0.1790, -0.0375, -0.2392,\n         -0.2411,  0.2200, -0.1997,  0.0033, -0.1664, -0.0697, -0.0361, -0.1553],\n        [ 0.1593, -0.0307, -0.1016, -0.1872, -0.1288,  0.0660, -0.2379, -0.0689,\n          0.0652,  0.0723, -0.0696, -0.1430,  0.0892,  0.1942, -0.1818, -0.2012],\n        [ 0.0546,  0.2092, -0.0485, -0.2127, -0.0212,  0.2241, -0.1771, -0.0116,\n          0.0770,  0.0781, -0.0900,  0.2067, -0.0133,  0.2136,  0.2264, -0.1023],\n        [ 0.1483, -0.1458, -0.0073, -0.0142, -0.0788, -0.0629, -0.2129,  0.0055,\n         -0.2358, -0.1808,  0.0199, -0.1880,  0.2051,  0.1016,  0.1079, -0.1190],\n        [ 0.0618, -0.1016, -0.1383,  0.1322,  0.2014, -0.0315, -0.2365, -0.0870,\n          0.1000,  0.1165,  0.0066, -0.0072,  0.1796, -0.1097,  0.0293, -0.1336],\n        [-0.1517,  0.1594, -0.1783, -0.1119, -0.0469, -0.1394, -0.2432, -0.0265,\n         -0.0772, -0.1166,  0.2279, -0.0704, -0.1986, -0.1250, -0.2304,  0.0809],\n        [ 0.1886, -0.0822, -0.0981,  0.1431,  0.0052, -0.2424, -0.2007, -0.1828,\n         -0.0596,  0.2326,  0.2101, -0.1861, -0.0391,  0.2399,  0.0741,  0.1242]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3244,  0.0347, -0.1024, -0.1981], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0754,  0.3271,  0.2650, -0.0411,  0.2786, -0.3053, -0.0661, -0.3326],\n        [-0.3307,  0.2912,  0.0628,  0.2704, -0.0503,  0.1659,  0.0247,  0.1982],\n        [-0.2890,  0.1209,  0.1369, -0.0970, -0.0831,  0.2348, -0.0096, -0.2274],\n        [-0.3017,  0.0585, -0.0656, -0.3369,  0.1801,  0.2950, -0.0114, -0.2637]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x75abef503fd0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s73330000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s73330000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}