{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s773730000"
    },
    "q_lr":	0.003,
    "seed":	773730000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7985825c3310>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2177, -0.0794, -0.1663, -0.0704, -0.3425, -0.1152,  0.2951,  0.1166,\n         0.2818,  0.3366,  0.0521,  0.1526,  0.1702, -0.2124, -0.0796, -0.2804,\n        -0.2777,  0.0389,  0.1834, -0.2229,  0.0636, -0.1158, -0.2611,  0.0931,\n        -0.0471, -0.1868,  0.3289,  0.1040,  0.3282, -0.1972,  0.3117, -0.1242],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2727, -0.2390, -0.2973,  0.0787, -0.1416,  0.0634,  0.1755, -0.3077],\n        [-0.0618, -0.1301,  0.1731, -0.3056, -0.3393,  0.1226,  0.1853, -0.1044],\n        [-0.1518,  0.1888, -0.0986,  0.1504,  0.0941,  0.3360,  0.3452, -0.1357],\n        [ 0.2938, -0.0350, -0.2943, -0.0118,  0.1980,  0.1284,  0.0813, -0.1410],\n        [ 0.2163, -0.3144, -0.1755,  0.1472,  0.1439, -0.0843, -0.1455,  0.1382],\n        [ 0.0860, -0.2647,  0.2012,  0.3313,  0.0276, -0.1880, -0.0616,  0.0798],\n        [ 0.1015,  0.0521,  0.2713,  0.1569,  0.2047,  0.0126,  0.1754, -0.1810],\n        [-0.3279,  0.1981,  0.0106,  0.2888, -0.3042, -0.3000,  0.1411,  0.2309],\n        [ 0.2618,  0.3521, -0.0578,  0.1236, -0.3260,  0.3059, -0.1768, -0.2849],\n        [-0.3413,  0.2542,  0.1442, -0.2779,  0.2083,  0.2563, -0.1751,  0.2927],\n        [-0.1203,  0.0399, -0.2160, -0.1255,  0.0243, -0.0236, -0.0364,  0.1779],\n        [-0.0619,  0.2609, -0.0249, -0.2720, -0.0926,  0.1373, -0.0010, -0.2352],\n        [-0.2244,  0.2358, -0.1121,  0.0506,  0.3336, -0.2608,  0.1683, -0.0297],\n        [-0.3179, -0.3113,  0.0514, -0.2011,  0.3205,  0.1790,  0.1529, -0.0022],\n        [ 0.2068,  0.0908,  0.2413, -0.2235,  0.1272,  0.1083,  0.1292,  0.1463],\n        [-0.0999,  0.2970,  0.1185,  0.1099, -0.0413,  0.1434,  0.0459, -0.2217],\n        [-0.1374,  0.2744,  0.2756, -0.1505, -0.1596,  0.3243, -0.3123,  0.0935],\n        [-0.2847,  0.2592,  0.0895, -0.1365,  0.0099, -0.0847, -0.1996, -0.2767],\n        [-0.0384, -0.2307, -0.1642,  0.0514,  0.0043, -0.2886,  0.1213, -0.0019],\n        [-0.0759,  0.2535, -0.3145, -0.2922, -0.1073,  0.3321, -0.1694, -0.2843],\n        [-0.1444,  0.3455, -0.2648,  0.1125,  0.1231,  0.1263, -0.3297,  0.1097],\n        [ 0.2898, -0.0285,  0.3386, -0.0812, -0.1465, -0.0987,  0.0859,  0.0739],\n        [ 0.1980,  0.1483,  0.2172,  0.1192,  0.3399, -0.3184,  0.3241, -0.1432],\n        [-0.1363,  0.3215,  0.1595, -0.2188,  0.1935, -0.3083, -0.0848, -0.0818],\n        [-0.1993, -0.2374,  0.0684, -0.1173,  0.3366,  0.0462,  0.1282, -0.1313],\n        [ 0.2026, -0.1285, -0.1939, -0.0946, -0.3307, -0.2839, -0.0214, -0.1583],\n        [-0.2015,  0.1810, -0.1618, -0.0606,  0.0281,  0.2228,  0.0559, -0.3025],\n        [-0.0397,  0.1113, -0.0352, -0.1434,  0.1816,  0.0466,  0.2386, -0.1541],\n        [-0.1893,  0.0436,  0.3103,  0.1373,  0.1616, -0.0883,  0.3491,  0.2483],\n        [-0.1654,  0.0491, -0.2832, -0.0618,  0.0547, -0.1008, -0.1063,  0.2673],\n        [ 0.1673,  0.1143,  0.3478,  0.2483, -0.2993, -0.0910,  0.1591, -0.0367],\n        [ 0.0218,  0.2757, -0.1840,  0.2338,  0.1536, -0.3313,  0.2812, -0.2544]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1569,  0.0894,  0.1094, -0.0234,  0.0468, -0.1685, -0.0245,  0.1203,\n         0.0179, -0.0211, -0.1719,  0.0522, -0.1100,  0.0063, -0.0475, -0.0017],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.7062e-01, -1.5860e-02,  8.3632e-02,  6.3608e-02,  3.2389e-03,\n         -5.1927e-02, -5.0199e-02,  6.1248e-02, -2.4498e-02, -6.0278e-02,\n         -7.2851e-02,  1.7640e-01, -2.2330e-02, -1.1740e-01, -1.5069e-01,\n          1.3840e-01,  1.5695e-01, -6.9002e-02,  9.7821e-02, -1.3104e-01,\n         -9.3251e-02,  6.7500e-02, -1.6303e-01,  1.2128e-01, -8.7529e-02,\n         -1.6772e-01,  1.2970e-01, -2.5430e-02,  9.6357e-02, -1.1667e-01,\n          1.1129e-01,  1.3851e-01],\n        [ 1.7281e-01,  5.4481e-02,  8.6031e-02,  1.7282e-02, -1.9236e-02,\n         -2.6464e-02,  5.6409e-02,  1.7975e-02,  3.3310e-02, -4.7285e-02,\n          6.4201e-02, -4.8752e-02, -1.5614e-01,  2.3022e-02,  1.5985e-01,\n         -9.0016e-02, -3.8817e-02, -7.0480e-02,  6.2624e-02, -8.4681e-02,\n         -1.6327e-01,  1.5331e-02, -6.8477e-02,  5.1086e-02, -4.8555e-02,\n          7.4695e-02, -8.9747e-02, -2.5793e-02, -2.8117e-02, -2.7442e-02,\n         -1.3388e-02,  1.2922e-02],\n        [ 1.5530e-01, -1.2911e-01, -3.7374e-03, -2.3600e-02,  1.1447e-01,\n         -1.3505e-02, -7.3265e-02, -1.4054e-01, -3.6779e-02, -2.0100e-02,\n         -1.1494e-01,  1.6263e-01,  1.2411e-01,  2.6011e-02,  3.8014e-02,\n          1.2235e-01, -1.3844e-01,  9.3501e-02, -6.3538e-02, -1.6982e-02,\n          4.7145e-02, -1.5355e-01, -7.7197e-02,  1.0498e-01, -9.4507e-02,\n          1.3866e-02, -1.0386e-01,  1.3075e-01, -1.0552e-01,  1.5316e-01,\n          2.8368e-02, -1.6508e-01],\n        [-4.8221e-02, -1.3709e-01,  9.7605e-02, -1.1889e-01,  1.6428e-01,\n          9.2442e-02,  1.3538e-01,  1.2631e-01, -8.6577e-02, -9.1178e-02,\n         -9.3547e-02,  1.6602e-01,  1.4283e-01,  2.9646e-02,  1.1534e-01,\n          1.6802e-01,  3.2374e-02,  1.5810e-01,  1.1879e-01,  1.0508e-01,\n          8.7005e-02, -6.4365e-02, -7.9771e-02, -1.2108e-01,  1.6253e-01,\n         -1.0446e-01,  1.2501e-01, -4.7977e-02, -1.3531e-01,  9.5009e-02,\n          1.3951e-01, -1.1747e-01],\n        [ 1.6793e-01, -3.5202e-02, -1.4134e-01,  1.2917e-01,  4.5434e-02,\n          1.4933e-01,  1.1497e-01, -6.5914e-02,  1.3979e-01, -1.4474e-01,\n          6.7135e-02,  1.6368e-01,  1.5071e-01,  8.5023e-02,  9.8243e-02,\n          7.9346e-02, -9.2841e-02,  1.1649e-01,  5.4252e-02,  1.1865e-01,\n         -6.7962e-02,  5.6528e-02, -8.8272e-02,  1.3685e-01,  1.1851e-01,\n          2.5752e-02,  2.6114e-02, -1.2565e-01,  1.9826e-02, -1.2206e-01,\n         -1.2352e-01,  1.6789e-01],\n        [-1.5204e-01, -2.8045e-02, -3.1236e-02,  3.7483e-02,  4.6886e-02,\n         -9.2257e-02,  6.6597e-02, -9.2083e-02, -5.5713e-02, -1.4924e-01,\n         -6.5232e-03, -1.1198e-01, -5.2942e-02, -9.4027e-02, -2.3160e-03,\n         -9.0061e-02, -5.8336e-02,  7.0679e-02,  8.2518e-02, -1.7658e-01,\n          1.2393e-01, -9.7058e-04, -1.0693e-01,  2.9394e-02, -6.7717e-02,\n         -1.7167e-02, -1.6927e-01, -8.3553e-02, -1.2435e-01,  1.0748e-01,\n          3.3668e-02,  7.4238e-02],\n        [ 5.9937e-02, -1.5103e-01, -8.7721e-02, -1.4642e-01, -8.1468e-02,\n         -3.0135e-02, -2.3291e-03,  4.6255e-02,  1.1208e-01, -1.4276e-01,\n          1.0923e-01,  4.7371e-02,  5.8605e-02, -7.4234e-02, -1.5461e-01,\n          1.6378e-01,  6.7158e-02, -1.8493e-02, -7.2009e-02,  1.3745e-01,\n         -4.5415e-02, -1.1125e-01, -4.8030e-02,  1.5606e-01, -8.1576e-02,\n         -4.2921e-02,  1.2129e-01, -1.5111e-01,  5.5098e-02, -9.3186e-02,\n          2.8704e-02,  7.3279e-02],\n        [ 1.7153e-01, -1.5022e-01, -1.1302e-01,  1.6636e-02,  7.3725e-02,\n          2.0495e-03, -1.4622e-01, -1.3213e-04,  1.1082e-01,  1.5734e-02,\n          3.1432e-02,  1.5655e-01, -7.8673e-02, -9.6981e-02, -9.2736e-02,\n         -1.4068e-02, -1.2375e-01, -1.3286e-01, -1.2117e-01, -7.1124e-02,\n         -2.6061e-02, -9.2846e-02, -9.0204e-02,  9.7533e-02,  6.9172e-02,\n         -8.9572e-03, -1.3640e-01, -7.3643e-02,  1.7651e-01,  8.7258e-02,\n         -2.8908e-02, -1.4643e-01],\n        [ 1.2984e-01, -4.5396e-02, -1.7073e-01, -1.3387e-02,  3.9685e-02,\n          1.7777e-02, -1.4946e-01, -1.0069e-01,  1.1909e-01,  1.1964e-01,\n         -1.2105e-01,  1.2887e-01, -9.8097e-02,  1.6080e-01,  1.0130e-01,\n          1.5506e-01,  5.5072e-02, -8.2291e-02, -1.6174e-01,  1.0473e-01,\n          1.3202e-01, -9.2445e-02, -4.3940e-02, -1.3554e-01, -3.5574e-02,\n         -1.4228e-01, -7.9993e-02,  1.7615e-01,  3.6925e-02, -1.1248e-01,\n          1.3060e-01, -9.2093e-02],\n        [ 1.0012e-01, -6.6754e-02,  5.1775e-02, -1.0888e-01,  1.5078e-01,\n         -1.5760e-01,  1.4426e-02,  1.2686e-02,  1.6623e-01,  1.3871e-01,\n          1.5530e-02, -1.6144e-01, -6.9271e-02,  1.4506e-01,  9.4568e-02,\n          3.8760e-02, -1.5516e-02, -2.5311e-02, -1.4156e-01,  4.1999e-02,\n         -1.6709e-01,  8.1825e-02,  1.0305e-01,  1.1003e-01, -9.4188e-02,\n          6.0100e-02, -1.7288e-01,  1.6859e-01,  2.2104e-04,  1.3156e-01,\n         -1.3929e-01, -5.3694e-02],\n        [ 6.9512e-02, -1.4193e-01, -1.5379e-01,  4.7930e-03,  8.4758e-02,\n          2.4324e-02, -1.3856e-02, -3.2097e-02, -1.5646e-01, -1.5055e-01,\n         -5.7491e-02,  1.5561e-01,  1.0127e-01,  2.9156e-02, -1.0933e-01,\n          1.0490e-02, -1.4690e-01, -1.8357e-02,  3.7025e-02, -3.2603e-02,\n         -1.4665e-01,  1.2754e-01,  7.6219e-02,  2.4931e-02, -1.2385e-01,\n         -1.7577e-01, -6.8333e-02, -3.3615e-03, -3.4572e-02,  1.5136e-01,\n          1.7223e-01,  2.8692e-02],\n        [ 1.5406e-01, -9.8870e-02,  3.1453e-02, -1.2488e-02, -2.4670e-02,\n         -1.9102e-02, -6.2591e-02,  1.2958e-01, -3.7105e-02, -1.6329e-01,\n          2.1619e-02, -1.3873e-01, -4.9218e-02, -8.4221e-02, -1.7529e-01,\n          4.6392e-02,  1.2179e-01, -5.5804e-02, -1.0431e-01, -1.4092e-01,\n         -5.3717e-02,  1.0675e-01, -5.9063e-02, -1.0396e-01,  7.0477e-02,\n         -1.2353e-01, -1.1572e-01,  1.7597e-01, -1.0260e-01, -4.8639e-02,\n          3.0724e-02, -5.4745e-02],\n        [-1.3636e-01,  1.1155e-01,  9.4589e-02,  1.5133e-01, -2.2046e-02,\n          4.2989e-02,  8.6466e-02,  4.2510e-02,  1.2251e-01,  1.6421e-01,\n         -1.2816e-01, -8.4026e-02,  1.7128e-01,  1.5894e-01, -1.2345e-03,\n         -1.6119e-01, -9.6354e-02,  5.7850e-02, -8.5617e-02, -1.1979e-01,\n          7.1932e-02, -1.4301e-01,  7.1608e-02,  1.1737e-01,  1.3429e-01,\n          3.3108e-02,  1.0633e-01, -1.0685e-02, -1.2341e-01,  1.0721e-01,\n          1.7207e-01,  9.4224e-02],\n        [-1.3295e-01, -1.0836e-01,  5.6306e-02, -1.5669e-01,  1.1722e-01,\n          1.5656e-01, -9.6424e-02, -6.4275e-02,  5.9004e-02,  1.7624e-03,\n         -1.1657e-01,  4.8212e-02, -1.7066e-01, -1.7459e-01, -5.9195e-02,\n         -7.4498e-02, -1.3270e-01,  1.6510e-01, -9.8583e-02,  1.3723e-01,\n         -1.1514e-01,  9.2743e-02, -6.4683e-03,  1.2476e-01,  9.0133e-02,\n          7.5294e-02,  4.3545e-03, -1.3093e-01, -1.3832e-01,  1.7193e-01,\n         -2.1889e-02,  1.4917e-01],\n        [ 9.4593e-02, -1.1429e-01, -1.1805e-01,  1.4257e-01,  1.0173e-01,\n          6.5634e-02,  5.1084e-02,  8.7575e-02,  1.3721e-01, -1.0631e-01,\n         -2.1725e-02, -7.8554e-03, -1.6535e-01,  6.9885e-02,  5.8860e-02,\n         -1.3330e-01, -1.5342e-01, -1.4143e-01,  1.3670e-01, -1.5106e-01,\n          2.0288e-02, -3.8711e-02,  2.4645e-02,  8.2229e-02, -5.8300e-02,\n         -7.8269e-02, -1.7670e-01, -7.4131e-02,  7.3944e-02, -4.6643e-02,\n         -2.7860e-02, -8.5129e-02],\n        [-1.4008e-01, -9.4062e-02, -1.7178e-01, -1.5398e-03,  1.4412e-01,\n         -1.6274e-01,  1.5244e-01,  1.0801e-01, -1.1781e-01, -1.5508e-01,\n         -1.4884e-01, -1.2183e-01, -9.1162e-02,  1.4590e-01, -9.2717e-02,\n          1.0233e-04,  1.3563e-02,  2.3597e-02, -1.4049e-01,  1.1931e-01,\n         -5.4791e-02,  9.3319e-02,  1.2761e-01, -1.0395e-01, -8.5146e-02,\n         -6.8335e-03,  2.1630e-02,  6.3097e-02,  1.6566e-01, -9.0117e-03,\n          8.7611e-02, -1.8664e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1302, -0.1181,  0.0178, -0.0997,  0.0249,  0.1595,  0.0144, -0.0732],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1479,  0.2214, -0.0737, -0.0264,  0.1544, -0.0022, -0.0828,  0.0327,\n         -0.1733,  0.1572,  0.1064,  0.2137, -0.0955, -0.0975,  0.0051, -0.1410],\n        [-0.1632, -0.0524, -0.2357,  0.1410, -0.0046, -0.2039,  0.1082,  0.0163,\n          0.1277, -0.1744, -0.0913,  0.2438,  0.2454,  0.1268,  0.0569, -0.0022],\n        [-0.0247, -0.2453, -0.1911, -0.0181, -0.0881,  0.1990, -0.1185,  0.0606,\n         -0.1758,  0.0286,  0.2450, -0.1764,  0.0401, -0.0639, -0.0135,  0.2055],\n        [-0.0217, -0.1207,  0.0814,  0.1066, -0.2173, -0.2187,  0.1418,  0.0485,\n          0.2234,  0.1719, -0.2171, -0.0166, -0.2203, -0.1031,  0.2037,  0.2020],\n        [ 0.0792,  0.0253,  0.1982, -0.1376,  0.0882,  0.0432,  0.0663,  0.0791,\n          0.0831, -0.0335,  0.0509, -0.0557,  0.0728, -0.1479,  0.0546, -0.2400],\n        [-0.1902,  0.2052,  0.0878,  0.0223, -0.1910, -0.0852,  0.0902,  0.2394,\n         -0.0237,  0.1872,  0.2374,  0.1948, -0.1969, -0.1632,  0.2286,  0.0250],\n        [-0.2303,  0.1895,  0.2158, -0.1182,  0.0114,  0.0249, -0.0590, -0.1878,\n          0.0810,  0.0378,  0.2466, -0.1352,  0.0654, -0.1693, -0.0556, -0.2481],\n        [ 0.2337,  0.2263, -0.1297, -0.2098, -0.2372,  0.1229,  0.2119,  0.1848,\n          0.0352, -0.1768,  0.2479, -0.1572,  0.0103, -0.2106,  0.0917,  0.0646]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3042,  0.0201,  0.2840,  0.2053], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3462,  0.1190,  0.1460,  0.2842,  0.1425, -0.0356, -0.3400,  0.3038],\n        [-0.0088,  0.0951,  0.2348,  0.2067, -0.3156,  0.2241,  0.2493, -0.0968],\n        [ 0.2560, -0.1305, -0.2948,  0.2103, -0.1749,  0.1237,  0.2455,  0.0967],\n        [ 0.3256,  0.1622, -0.3463, -0.1966,  0.1584, -0.2245,  0.0134, -0.2836]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2727, -0.2390, -0.2973,  0.0787, -0.1416,  0.0634,  0.1755, -0.3077],\n        [-0.0618, -0.1301,  0.1731, -0.3056, -0.3393,  0.1226,  0.1853, -0.1044],\n        [-0.1518,  0.1888, -0.0986,  0.1504,  0.0941,  0.3360,  0.3452, -0.1357],\n        [ 0.2938, -0.0350, -0.2943, -0.0118,  0.1980,  0.1284,  0.0813, -0.1410],\n        [ 0.2163, -0.3144, -0.1755,  0.1472,  0.1439, -0.0843, -0.1455,  0.1382],\n        [ 0.0860, -0.2647,  0.2012,  0.3313,  0.0276, -0.1880, -0.0616,  0.0798],\n        [ 0.1015,  0.0521,  0.2713,  0.1569,  0.2047,  0.0126,  0.1754, -0.1810],\n        [-0.3279,  0.1981,  0.0106,  0.2888, -0.3042, -0.3000,  0.1411,  0.2309],\n        [ 0.2618,  0.3521, -0.0578,  0.1236, -0.3260,  0.3059, -0.1768, -0.2849],\n        [-0.3413,  0.2542,  0.1442, -0.2779,  0.2083,  0.2563, -0.1751,  0.2927],\n        [-0.1203,  0.0399, -0.2160, -0.1255,  0.0243, -0.0236, -0.0364,  0.1779],\n        [-0.0619,  0.2609, -0.0249, -0.2720, -0.0926,  0.1373, -0.0010, -0.2352],\n        [-0.2244,  0.2358, -0.1121,  0.0506,  0.3336, -0.2608,  0.1683, -0.0297],\n        [-0.3179, -0.3113,  0.0514, -0.2011,  0.3205,  0.1790,  0.1529, -0.0022],\n        [ 0.2068,  0.0908,  0.2413, -0.2235,  0.1272,  0.1083,  0.1292,  0.1463],\n        [-0.0999,  0.2970,  0.1185,  0.1099, -0.0413,  0.1434,  0.0459, -0.2217],\n        [-0.1374,  0.2744,  0.2756, -0.1505, -0.1596,  0.3243, -0.3123,  0.0935],\n        [-0.2847,  0.2592,  0.0895, -0.1365,  0.0099, -0.0847, -0.1996, -0.2767],\n        [-0.0384, -0.2307, -0.1642,  0.0514,  0.0043, -0.2886,  0.1213, -0.0019],\n        [-0.0759,  0.2535, -0.3145, -0.2922, -0.1073,  0.3321, -0.1694, -0.2843],\n        [-0.1444,  0.3455, -0.2648,  0.1125,  0.1231,  0.1263, -0.3297,  0.1097],\n        [ 0.2898, -0.0285,  0.3386, -0.0812, -0.1465, -0.0987,  0.0859,  0.0739],\n        [ 0.1980,  0.1483,  0.2172,  0.1192,  0.3399, -0.3184,  0.3241, -0.1432],\n        [-0.1363,  0.3215,  0.1595, -0.2188,  0.1935, -0.3083, -0.0848, -0.0818],\n        [-0.1993, -0.2374,  0.0684, -0.1173,  0.3366,  0.0462,  0.1282, -0.1313],\n        [ 0.2026, -0.1285, -0.1939, -0.0946, -0.3307, -0.2839, -0.0214, -0.1583],\n        [-0.2015,  0.1810, -0.1618, -0.0606,  0.0281,  0.2228,  0.0559, -0.3025],\n        [-0.0397,  0.1113, -0.0352, -0.1434,  0.1816,  0.0466,  0.2386, -0.1541],\n        [-0.1893,  0.0436,  0.3103,  0.1373,  0.1616, -0.0883,  0.3491,  0.2483],\n        [-0.1654,  0.0491, -0.2832, -0.0618,  0.0547, -0.1008, -0.1063,  0.2673],\n        [ 0.1673,  0.1143,  0.3478,  0.2483, -0.2993, -0.0910,  0.1591, -0.0367],\n        [ 0.0218,  0.2757, -0.1840,  0.2338,  0.1536, -0.3313,  0.2812, -0.2544]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2177, -0.0794, -0.1663, -0.0704, -0.3425, -0.1152,  0.2951,  0.1166,\n         0.2818,  0.3366,  0.0521,  0.1526,  0.1702, -0.2124, -0.0796, -0.2804,\n        -0.2777,  0.0389,  0.1834, -0.2229,  0.0636, -0.1158, -0.2611,  0.0931,\n        -0.0471, -0.1868,  0.3289,  0.1040,  0.3282, -0.1972,  0.3117, -0.1242],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.7062e-01, -1.5860e-02,  8.3632e-02,  6.3608e-02,  3.2389e-03,\n         -5.1927e-02, -5.0199e-02,  6.1248e-02, -2.4498e-02, -6.0278e-02,\n         -7.2851e-02,  1.7640e-01, -2.2330e-02, -1.1740e-01, -1.5069e-01,\n          1.3840e-01,  1.5695e-01, -6.9002e-02,  9.7821e-02, -1.3104e-01,\n         -9.3251e-02,  6.7500e-02, -1.6303e-01,  1.2128e-01, -8.7529e-02,\n         -1.6772e-01,  1.2970e-01, -2.5430e-02,  9.6357e-02, -1.1667e-01,\n          1.1129e-01,  1.3851e-01],\n        [ 1.7281e-01,  5.4481e-02,  8.6031e-02,  1.7282e-02, -1.9236e-02,\n         -2.6464e-02,  5.6409e-02,  1.7975e-02,  3.3310e-02, -4.7285e-02,\n          6.4201e-02, -4.8752e-02, -1.5614e-01,  2.3022e-02,  1.5985e-01,\n         -9.0016e-02, -3.8817e-02, -7.0480e-02,  6.2624e-02, -8.4681e-02,\n         -1.6327e-01,  1.5331e-02, -6.8477e-02,  5.1086e-02, -4.8555e-02,\n          7.4695e-02, -8.9747e-02, -2.5793e-02, -2.8117e-02, -2.7442e-02,\n         -1.3388e-02,  1.2922e-02],\n        [ 1.5530e-01, -1.2911e-01, -3.7374e-03, -2.3600e-02,  1.1447e-01,\n         -1.3505e-02, -7.3265e-02, -1.4054e-01, -3.6779e-02, -2.0100e-02,\n         -1.1494e-01,  1.6263e-01,  1.2411e-01,  2.6011e-02,  3.8014e-02,\n          1.2235e-01, -1.3844e-01,  9.3501e-02, -6.3538e-02, -1.6982e-02,\n          4.7145e-02, -1.5355e-01, -7.7197e-02,  1.0498e-01, -9.4507e-02,\n          1.3866e-02, -1.0386e-01,  1.3075e-01, -1.0552e-01,  1.5316e-01,\n          2.8368e-02, -1.6508e-01],\n        [-4.8221e-02, -1.3709e-01,  9.7605e-02, -1.1889e-01,  1.6428e-01,\n          9.2442e-02,  1.3538e-01,  1.2631e-01, -8.6577e-02, -9.1178e-02,\n         -9.3547e-02,  1.6602e-01,  1.4283e-01,  2.9646e-02,  1.1534e-01,\n          1.6802e-01,  3.2374e-02,  1.5810e-01,  1.1879e-01,  1.0508e-01,\n          8.7005e-02, -6.4365e-02, -7.9771e-02, -1.2108e-01,  1.6253e-01,\n         -1.0446e-01,  1.2501e-01, -4.7977e-02, -1.3531e-01,  9.5009e-02,\n          1.3951e-01, -1.1747e-01],\n        [ 1.6793e-01, -3.5202e-02, -1.4134e-01,  1.2917e-01,  4.5434e-02,\n          1.4933e-01,  1.1497e-01, -6.5914e-02,  1.3979e-01, -1.4474e-01,\n          6.7135e-02,  1.6368e-01,  1.5071e-01,  8.5023e-02,  9.8243e-02,\n          7.9346e-02, -9.2841e-02,  1.1649e-01,  5.4252e-02,  1.1865e-01,\n         -6.7962e-02,  5.6528e-02, -8.8272e-02,  1.3685e-01,  1.1851e-01,\n          2.5752e-02,  2.6114e-02, -1.2565e-01,  1.9826e-02, -1.2206e-01,\n         -1.2352e-01,  1.6789e-01],\n        [-1.5204e-01, -2.8045e-02, -3.1236e-02,  3.7483e-02,  4.6886e-02,\n         -9.2257e-02,  6.6597e-02, -9.2083e-02, -5.5713e-02, -1.4924e-01,\n         -6.5232e-03, -1.1198e-01, -5.2942e-02, -9.4027e-02, -2.3160e-03,\n         -9.0061e-02, -5.8336e-02,  7.0679e-02,  8.2518e-02, -1.7658e-01,\n          1.2393e-01, -9.7058e-04, -1.0693e-01,  2.9394e-02, -6.7717e-02,\n         -1.7167e-02, -1.6927e-01, -8.3553e-02, -1.2435e-01,  1.0748e-01,\n          3.3668e-02,  7.4238e-02],\n        [ 5.9937e-02, -1.5103e-01, -8.7721e-02, -1.4642e-01, -8.1468e-02,\n         -3.0135e-02, -2.3291e-03,  4.6255e-02,  1.1208e-01, -1.4276e-01,\n          1.0923e-01,  4.7371e-02,  5.8605e-02, -7.4234e-02, -1.5461e-01,\n          1.6378e-01,  6.7158e-02, -1.8493e-02, -7.2009e-02,  1.3745e-01,\n         -4.5415e-02, -1.1125e-01, -4.8030e-02,  1.5606e-01, -8.1576e-02,\n         -4.2921e-02,  1.2129e-01, -1.5111e-01,  5.5098e-02, -9.3186e-02,\n          2.8704e-02,  7.3279e-02],\n        [ 1.7153e-01, -1.5022e-01, -1.1302e-01,  1.6636e-02,  7.3725e-02,\n          2.0495e-03, -1.4622e-01, -1.3213e-04,  1.1082e-01,  1.5734e-02,\n          3.1432e-02,  1.5655e-01, -7.8673e-02, -9.6981e-02, -9.2736e-02,\n         -1.4068e-02, -1.2375e-01, -1.3286e-01, -1.2117e-01, -7.1124e-02,\n         -2.6061e-02, -9.2846e-02, -9.0204e-02,  9.7533e-02,  6.9172e-02,\n         -8.9572e-03, -1.3640e-01, -7.3643e-02,  1.7651e-01,  8.7258e-02,\n         -2.8908e-02, -1.4643e-01],\n        [ 1.2984e-01, -4.5396e-02, -1.7073e-01, -1.3387e-02,  3.9685e-02,\n          1.7777e-02, -1.4946e-01, -1.0069e-01,  1.1909e-01,  1.1964e-01,\n         -1.2105e-01,  1.2887e-01, -9.8097e-02,  1.6080e-01,  1.0130e-01,\n          1.5506e-01,  5.5072e-02, -8.2291e-02, -1.6174e-01,  1.0473e-01,\n          1.3202e-01, -9.2445e-02, -4.3940e-02, -1.3554e-01, -3.5574e-02,\n         -1.4228e-01, -7.9993e-02,  1.7615e-01,  3.6925e-02, -1.1248e-01,\n          1.3060e-01, -9.2093e-02],\n        [ 1.0012e-01, -6.6754e-02,  5.1775e-02, -1.0888e-01,  1.5078e-01,\n         -1.5760e-01,  1.4426e-02,  1.2686e-02,  1.6623e-01,  1.3871e-01,\n          1.5530e-02, -1.6144e-01, -6.9271e-02,  1.4506e-01,  9.4568e-02,\n          3.8760e-02, -1.5516e-02, -2.5311e-02, -1.4156e-01,  4.1999e-02,\n         -1.6709e-01,  8.1825e-02,  1.0305e-01,  1.1003e-01, -9.4188e-02,\n          6.0100e-02, -1.7288e-01,  1.6859e-01,  2.2104e-04,  1.3156e-01,\n         -1.3929e-01, -5.3694e-02],\n        [ 6.9512e-02, -1.4193e-01, -1.5379e-01,  4.7930e-03,  8.4758e-02,\n          2.4324e-02, -1.3856e-02, -3.2097e-02, -1.5646e-01, -1.5055e-01,\n         -5.7491e-02,  1.5561e-01,  1.0127e-01,  2.9156e-02, -1.0933e-01,\n          1.0490e-02, -1.4690e-01, -1.8357e-02,  3.7025e-02, -3.2603e-02,\n         -1.4665e-01,  1.2754e-01,  7.6219e-02,  2.4931e-02, -1.2385e-01,\n         -1.7577e-01, -6.8333e-02, -3.3615e-03, -3.4572e-02,  1.5136e-01,\n          1.7223e-01,  2.8692e-02],\n        [ 1.5406e-01, -9.8870e-02,  3.1453e-02, -1.2488e-02, -2.4670e-02,\n         -1.9102e-02, -6.2591e-02,  1.2958e-01, -3.7105e-02, -1.6329e-01,\n          2.1619e-02, -1.3873e-01, -4.9218e-02, -8.4221e-02, -1.7529e-01,\n          4.6392e-02,  1.2179e-01, -5.5804e-02, -1.0431e-01, -1.4092e-01,\n         -5.3717e-02,  1.0675e-01, -5.9063e-02, -1.0396e-01,  7.0477e-02,\n         -1.2353e-01, -1.1572e-01,  1.7597e-01, -1.0260e-01, -4.8639e-02,\n          3.0724e-02, -5.4745e-02],\n        [-1.3636e-01,  1.1155e-01,  9.4589e-02,  1.5133e-01, -2.2046e-02,\n          4.2989e-02,  8.6466e-02,  4.2510e-02,  1.2251e-01,  1.6421e-01,\n         -1.2816e-01, -8.4026e-02,  1.7128e-01,  1.5894e-01, -1.2345e-03,\n         -1.6119e-01, -9.6354e-02,  5.7850e-02, -8.5617e-02, -1.1979e-01,\n          7.1932e-02, -1.4301e-01,  7.1608e-02,  1.1737e-01,  1.3429e-01,\n          3.3108e-02,  1.0633e-01, -1.0685e-02, -1.2341e-01,  1.0721e-01,\n          1.7207e-01,  9.4224e-02],\n        [-1.3295e-01, -1.0836e-01,  5.6306e-02, -1.5669e-01,  1.1722e-01,\n          1.5656e-01, -9.6424e-02, -6.4275e-02,  5.9004e-02,  1.7624e-03,\n         -1.1657e-01,  4.8212e-02, -1.7066e-01, -1.7459e-01, -5.9195e-02,\n         -7.4498e-02, -1.3270e-01,  1.6510e-01, -9.8583e-02,  1.3723e-01,\n         -1.1514e-01,  9.2743e-02, -6.4683e-03,  1.2476e-01,  9.0133e-02,\n          7.5294e-02,  4.3545e-03, -1.3093e-01, -1.3832e-01,  1.7193e-01,\n         -2.1889e-02,  1.4917e-01],\n        [ 9.4593e-02, -1.1429e-01, -1.1805e-01,  1.4257e-01,  1.0173e-01,\n          6.5634e-02,  5.1084e-02,  8.7575e-02,  1.3721e-01, -1.0631e-01,\n         -2.1725e-02, -7.8554e-03, -1.6535e-01,  6.9885e-02,  5.8860e-02,\n         -1.3330e-01, -1.5342e-01, -1.4143e-01,  1.3670e-01, -1.5106e-01,\n          2.0288e-02, -3.8711e-02,  2.4645e-02,  8.2229e-02, -5.8300e-02,\n         -7.8269e-02, -1.7670e-01, -7.4131e-02,  7.3944e-02, -4.6643e-02,\n         -2.7860e-02, -8.5129e-02],\n        [-1.4008e-01, -9.4062e-02, -1.7178e-01, -1.5398e-03,  1.4412e-01,\n         -1.6274e-01,  1.5244e-01,  1.0801e-01, -1.1781e-01, -1.5508e-01,\n         -1.4884e-01, -1.2183e-01, -9.1162e-02,  1.4590e-01, -9.2717e-02,\n          1.0233e-04,  1.3563e-02,  2.3597e-02, -1.4049e-01,  1.1931e-01,\n         -5.4791e-02,  9.3319e-02,  1.2761e-01, -1.0395e-01, -8.5146e-02,\n         -6.8335e-03,  2.1630e-02,  6.3097e-02,  1.6566e-01, -9.0117e-03,\n          8.7611e-02, -1.8664e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1569,  0.0894,  0.1094, -0.0234,  0.0468, -0.1685, -0.0245,  0.1203,\n         0.0179, -0.0211, -0.1719,  0.0522, -0.1100,  0.0063, -0.0475, -0.0017],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1479,  0.2214, -0.0737, -0.0264,  0.1544, -0.0022, -0.0828,  0.0327,\n         -0.1733,  0.1572,  0.1064,  0.2137, -0.0955, -0.0975,  0.0051, -0.1410],\n        [-0.1632, -0.0524, -0.2357,  0.1410, -0.0046, -0.2039,  0.1082,  0.0163,\n          0.1277, -0.1744, -0.0913,  0.2438,  0.2454,  0.1268,  0.0569, -0.0022],\n        [-0.0247, -0.2453, -0.1911, -0.0181, -0.0881,  0.1990, -0.1185,  0.0606,\n         -0.1758,  0.0286,  0.2450, -0.1764,  0.0401, -0.0639, -0.0135,  0.2055],\n        [-0.0217, -0.1207,  0.0814,  0.1066, -0.2173, -0.2187,  0.1418,  0.0485,\n          0.2234,  0.1719, -0.2171, -0.0166, -0.2203, -0.1031,  0.2037,  0.2020],\n        [ 0.0792,  0.0253,  0.1982, -0.1376,  0.0882,  0.0432,  0.0663,  0.0791,\n          0.0831, -0.0335,  0.0509, -0.0557,  0.0728, -0.1479,  0.0546, -0.2400],\n        [-0.1902,  0.2052,  0.0878,  0.0223, -0.1910, -0.0852,  0.0902,  0.2394,\n         -0.0237,  0.1872,  0.2374,  0.1948, -0.1969, -0.1632,  0.2286,  0.0250],\n        [-0.2303,  0.1895,  0.2158, -0.1182,  0.0114,  0.0249, -0.0590, -0.1878,\n          0.0810,  0.0378,  0.2466, -0.1352,  0.0654, -0.1693, -0.0556, -0.2481],\n        [ 0.2337,  0.2263, -0.1297, -0.2098, -0.2372,  0.1229,  0.2119,  0.1848,\n          0.0352, -0.1768,  0.2479, -0.1572,  0.0103, -0.2106,  0.0917,  0.0646]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1302, -0.1181,  0.0178, -0.0997,  0.0249,  0.1595,  0.0144, -0.0732],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3462,  0.1190,  0.1460,  0.2842,  0.1425, -0.0356, -0.3400,  0.3038],\n        [-0.0088,  0.0951,  0.2348,  0.2067, -0.3156,  0.2241,  0.2493, -0.0968],\n        [ 0.2560, -0.1305, -0.2948,  0.2103, -0.1749,  0.1237,  0.2455,  0.0967],\n        [ 0.3256,  0.1622, -0.3463, -0.1966,  0.1584, -0.2245,  0.0134, -0.2836]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3042,  0.0201,  0.2840,  0.2053], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7985829f0250>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2177, -0.0794, -0.1663, -0.0704, -0.3425, -0.1152,  0.2951,  0.1166,\n         0.2818,  0.3366,  0.0521,  0.1526,  0.1702, -0.2124, -0.0796, -0.2804,\n        -0.2777,  0.0389,  0.1834, -0.2229,  0.0636, -0.1158, -0.2611,  0.0931,\n        -0.0471, -0.1868,  0.3289,  0.1040,  0.3282, -0.1972,  0.3117, -0.1242],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2727, -0.2390, -0.2973,  0.0787, -0.1416,  0.0634,  0.1755, -0.3077],\n        [-0.0618, -0.1301,  0.1731, -0.3056, -0.3393,  0.1226,  0.1853, -0.1044],\n        [-0.1518,  0.1888, -0.0986,  0.1504,  0.0941,  0.3360,  0.3452, -0.1357],\n        [ 0.2938, -0.0350, -0.2943, -0.0118,  0.1980,  0.1284,  0.0813, -0.1410],\n        [ 0.2163, -0.3144, -0.1755,  0.1472,  0.1439, -0.0843, -0.1455,  0.1382],\n        [ 0.0860, -0.2647,  0.2012,  0.3313,  0.0276, -0.1880, -0.0616,  0.0798],\n        [ 0.1015,  0.0521,  0.2713,  0.1569,  0.2047,  0.0126,  0.1754, -0.1810],\n        [-0.3279,  0.1981,  0.0106,  0.2888, -0.3042, -0.3000,  0.1411,  0.2309],\n        [ 0.2618,  0.3521, -0.0578,  0.1236, -0.3260,  0.3059, -0.1768, -0.2849],\n        [-0.3413,  0.2542,  0.1442, -0.2779,  0.2083,  0.2563, -0.1751,  0.2927],\n        [-0.1203,  0.0399, -0.2160, -0.1255,  0.0243, -0.0236, -0.0364,  0.1779],\n        [-0.0619,  0.2609, -0.0249, -0.2720, -0.0926,  0.1373, -0.0010, -0.2352],\n        [-0.2244,  0.2358, -0.1121,  0.0506,  0.3336, -0.2608,  0.1683, -0.0297],\n        [-0.3179, -0.3113,  0.0514, -0.2011,  0.3205,  0.1790,  0.1529, -0.0022],\n        [ 0.2068,  0.0908,  0.2413, -0.2235,  0.1272,  0.1083,  0.1292,  0.1463],\n        [-0.0999,  0.2970,  0.1185,  0.1099, -0.0413,  0.1434,  0.0459, -0.2217],\n        [-0.1374,  0.2744,  0.2756, -0.1505, -0.1596,  0.3243, -0.3123,  0.0935],\n        [-0.2847,  0.2592,  0.0895, -0.1365,  0.0099, -0.0847, -0.1996, -0.2767],\n        [-0.0384, -0.2307, -0.1642,  0.0514,  0.0043, -0.2886,  0.1213, -0.0019],\n        [-0.0759,  0.2535, -0.3145, -0.2922, -0.1073,  0.3321, -0.1694, -0.2843],\n        [-0.1444,  0.3455, -0.2648,  0.1125,  0.1231,  0.1263, -0.3297,  0.1097],\n        [ 0.2898, -0.0285,  0.3386, -0.0812, -0.1465, -0.0987,  0.0859,  0.0739],\n        [ 0.1980,  0.1483,  0.2172,  0.1192,  0.3399, -0.3184,  0.3241, -0.1432],\n        [-0.1363,  0.3215,  0.1595, -0.2188,  0.1935, -0.3083, -0.0848, -0.0818],\n        [-0.1993, -0.2374,  0.0684, -0.1173,  0.3366,  0.0462,  0.1282, -0.1313],\n        [ 0.2026, -0.1285, -0.1939, -0.0946, -0.3307, -0.2839, -0.0214, -0.1583],\n        [-0.2015,  0.1810, -0.1618, -0.0606,  0.0281,  0.2228,  0.0559, -0.3025],\n        [-0.0397,  0.1113, -0.0352, -0.1434,  0.1816,  0.0466,  0.2386, -0.1541],\n        [-0.1893,  0.0436,  0.3103,  0.1373,  0.1616, -0.0883,  0.3491,  0.2483],\n        [-0.1654,  0.0491, -0.2832, -0.0618,  0.0547, -0.1008, -0.1063,  0.2673],\n        [ 0.1673,  0.1143,  0.3478,  0.2483, -0.2993, -0.0910,  0.1591, -0.0367],\n        [ 0.0218,  0.2757, -0.1840,  0.2338,  0.1536, -0.3313,  0.2812, -0.2544]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1569,  0.0894,  0.1094, -0.0234,  0.0468, -0.1685, -0.0245,  0.1203,\n         0.0179, -0.0211, -0.1719,  0.0522, -0.1100,  0.0063, -0.0475, -0.0017],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.7062e-01, -1.5860e-02,  8.3632e-02,  6.3608e-02,  3.2389e-03,\n         -5.1927e-02, -5.0199e-02,  6.1248e-02, -2.4498e-02, -6.0278e-02,\n         -7.2851e-02,  1.7640e-01, -2.2330e-02, -1.1740e-01, -1.5069e-01,\n          1.3840e-01,  1.5695e-01, -6.9002e-02,  9.7821e-02, -1.3104e-01,\n         -9.3251e-02,  6.7500e-02, -1.6303e-01,  1.2128e-01, -8.7529e-02,\n         -1.6772e-01,  1.2970e-01, -2.5430e-02,  9.6357e-02, -1.1667e-01,\n          1.1129e-01,  1.3851e-01],\n        [ 1.7281e-01,  5.4481e-02,  8.6031e-02,  1.7282e-02, -1.9236e-02,\n         -2.6464e-02,  5.6409e-02,  1.7975e-02,  3.3310e-02, -4.7285e-02,\n          6.4201e-02, -4.8752e-02, -1.5614e-01,  2.3022e-02,  1.5985e-01,\n         -9.0016e-02, -3.8817e-02, -7.0480e-02,  6.2624e-02, -8.4681e-02,\n         -1.6327e-01,  1.5331e-02, -6.8477e-02,  5.1086e-02, -4.8555e-02,\n          7.4695e-02, -8.9747e-02, -2.5793e-02, -2.8117e-02, -2.7442e-02,\n         -1.3388e-02,  1.2922e-02],\n        [ 1.5530e-01, -1.2911e-01, -3.7374e-03, -2.3600e-02,  1.1447e-01,\n         -1.3505e-02, -7.3265e-02, -1.4054e-01, -3.6779e-02, -2.0100e-02,\n         -1.1494e-01,  1.6263e-01,  1.2411e-01,  2.6011e-02,  3.8014e-02,\n          1.2235e-01, -1.3844e-01,  9.3501e-02, -6.3538e-02, -1.6982e-02,\n          4.7145e-02, -1.5355e-01, -7.7197e-02,  1.0498e-01, -9.4507e-02,\n          1.3866e-02, -1.0386e-01,  1.3075e-01, -1.0552e-01,  1.5316e-01,\n          2.8368e-02, -1.6508e-01],\n        [-4.8221e-02, -1.3709e-01,  9.7605e-02, -1.1889e-01,  1.6428e-01,\n          9.2442e-02,  1.3538e-01,  1.2631e-01, -8.6577e-02, -9.1178e-02,\n         -9.3547e-02,  1.6602e-01,  1.4283e-01,  2.9646e-02,  1.1534e-01,\n          1.6802e-01,  3.2374e-02,  1.5810e-01,  1.1879e-01,  1.0508e-01,\n          8.7005e-02, -6.4365e-02, -7.9771e-02, -1.2108e-01,  1.6253e-01,\n         -1.0446e-01,  1.2501e-01, -4.7977e-02, -1.3531e-01,  9.5009e-02,\n          1.3951e-01, -1.1747e-01],\n        [ 1.6793e-01, -3.5202e-02, -1.4134e-01,  1.2917e-01,  4.5434e-02,\n          1.4933e-01,  1.1497e-01, -6.5914e-02,  1.3979e-01, -1.4474e-01,\n          6.7135e-02,  1.6368e-01,  1.5071e-01,  8.5023e-02,  9.8243e-02,\n          7.9346e-02, -9.2841e-02,  1.1649e-01,  5.4252e-02,  1.1865e-01,\n         -6.7962e-02,  5.6528e-02, -8.8272e-02,  1.3685e-01,  1.1851e-01,\n          2.5752e-02,  2.6114e-02, -1.2565e-01,  1.9826e-02, -1.2206e-01,\n         -1.2352e-01,  1.6789e-01],\n        [-1.5204e-01, -2.8045e-02, -3.1236e-02,  3.7483e-02,  4.6886e-02,\n         -9.2257e-02,  6.6597e-02, -9.2083e-02, -5.5713e-02, -1.4924e-01,\n         -6.5232e-03, -1.1198e-01, -5.2942e-02, -9.4027e-02, -2.3160e-03,\n         -9.0061e-02, -5.8336e-02,  7.0679e-02,  8.2518e-02, -1.7658e-01,\n          1.2393e-01, -9.7058e-04, -1.0693e-01,  2.9394e-02, -6.7717e-02,\n         -1.7167e-02, -1.6927e-01, -8.3553e-02, -1.2435e-01,  1.0748e-01,\n          3.3668e-02,  7.4238e-02],\n        [ 5.9937e-02, -1.5103e-01, -8.7721e-02, -1.4642e-01, -8.1468e-02,\n         -3.0135e-02, -2.3291e-03,  4.6255e-02,  1.1208e-01, -1.4276e-01,\n          1.0923e-01,  4.7371e-02,  5.8605e-02, -7.4234e-02, -1.5461e-01,\n          1.6378e-01,  6.7158e-02, -1.8493e-02, -7.2009e-02,  1.3745e-01,\n         -4.5415e-02, -1.1125e-01, -4.8030e-02,  1.5606e-01, -8.1576e-02,\n         -4.2921e-02,  1.2129e-01, -1.5111e-01,  5.5098e-02, -9.3186e-02,\n          2.8704e-02,  7.3279e-02],\n        [ 1.7153e-01, -1.5022e-01, -1.1302e-01,  1.6636e-02,  7.3725e-02,\n          2.0495e-03, -1.4622e-01, -1.3213e-04,  1.1082e-01,  1.5734e-02,\n          3.1432e-02,  1.5655e-01, -7.8673e-02, -9.6981e-02, -9.2736e-02,\n         -1.4068e-02, -1.2375e-01, -1.3286e-01, -1.2117e-01, -7.1124e-02,\n         -2.6061e-02, -9.2846e-02, -9.0204e-02,  9.7533e-02,  6.9172e-02,\n         -8.9572e-03, -1.3640e-01, -7.3643e-02,  1.7651e-01,  8.7258e-02,\n         -2.8908e-02, -1.4643e-01],\n        [ 1.2984e-01, -4.5396e-02, -1.7073e-01, -1.3387e-02,  3.9685e-02,\n          1.7777e-02, -1.4946e-01, -1.0069e-01,  1.1909e-01,  1.1964e-01,\n         -1.2105e-01,  1.2887e-01, -9.8097e-02,  1.6080e-01,  1.0130e-01,\n          1.5506e-01,  5.5072e-02, -8.2291e-02, -1.6174e-01,  1.0473e-01,\n          1.3202e-01, -9.2445e-02, -4.3940e-02, -1.3554e-01, -3.5574e-02,\n         -1.4228e-01, -7.9993e-02,  1.7615e-01,  3.6925e-02, -1.1248e-01,\n          1.3060e-01, -9.2093e-02],\n        [ 1.0012e-01, -6.6754e-02,  5.1775e-02, -1.0888e-01,  1.5078e-01,\n         -1.5760e-01,  1.4426e-02,  1.2686e-02,  1.6623e-01,  1.3871e-01,\n          1.5530e-02, -1.6144e-01, -6.9271e-02,  1.4506e-01,  9.4568e-02,\n          3.8760e-02, -1.5516e-02, -2.5311e-02, -1.4156e-01,  4.1999e-02,\n         -1.6709e-01,  8.1825e-02,  1.0305e-01,  1.1003e-01, -9.4188e-02,\n          6.0100e-02, -1.7288e-01,  1.6859e-01,  2.2104e-04,  1.3156e-01,\n         -1.3929e-01, -5.3694e-02],\n        [ 6.9512e-02, -1.4193e-01, -1.5379e-01,  4.7930e-03,  8.4758e-02,\n          2.4324e-02, -1.3856e-02, -3.2097e-02, -1.5646e-01, -1.5055e-01,\n         -5.7491e-02,  1.5561e-01,  1.0127e-01,  2.9156e-02, -1.0933e-01,\n          1.0490e-02, -1.4690e-01, -1.8357e-02,  3.7025e-02, -3.2603e-02,\n         -1.4665e-01,  1.2754e-01,  7.6219e-02,  2.4931e-02, -1.2385e-01,\n         -1.7577e-01, -6.8333e-02, -3.3615e-03, -3.4572e-02,  1.5136e-01,\n          1.7223e-01,  2.8692e-02],\n        [ 1.5406e-01, -9.8870e-02,  3.1453e-02, -1.2488e-02, -2.4670e-02,\n         -1.9102e-02, -6.2591e-02,  1.2958e-01, -3.7105e-02, -1.6329e-01,\n          2.1619e-02, -1.3873e-01, -4.9218e-02, -8.4221e-02, -1.7529e-01,\n          4.6392e-02,  1.2179e-01, -5.5804e-02, -1.0431e-01, -1.4092e-01,\n         -5.3717e-02,  1.0675e-01, -5.9063e-02, -1.0396e-01,  7.0477e-02,\n         -1.2353e-01, -1.1572e-01,  1.7597e-01, -1.0260e-01, -4.8639e-02,\n          3.0724e-02, -5.4745e-02],\n        [-1.3636e-01,  1.1155e-01,  9.4589e-02,  1.5133e-01, -2.2046e-02,\n          4.2989e-02,  8.6466e-02,  4.2510e-02,  1.2251e-01,  1.6421e-01,\n         -1.2816e-01, -8.4026e-02,  1.7128e-01,  1.5894e-01, -1.2345e-03,\n         -1.6119e-01, -9.6354e-02,  5.7850e-02, -8.5617e-02, -1.1979e-01,\n          7.1932e-02, -1.4301e-01,  7.1608e-02,  1.1737e-01,  1.3429e-01,\n          3.3108e-02,  1.0633e-01, -1.0685e-02, -1.2341e-01,  1.0721e-01,\n          1.7207e-01,  9.4224e-02],\n        [-1.3295e-01, -1.0836e-01,  5.6306e-02, -1.5669e-01,  1.1722e-01,\n          1.5656e-01, -9.6424e-02, -6.4275e-02,  5.9004e-02,  1.7624e-03,\n         -1.1657e-01,  4.8212e-02, -1.7066e-01, -1.7459e-01, -5.9195e-02,\n         -7.4498e-02, -1.3270e-01,  1.6510e-01, -9.8583e-02,  1.3723e-01,\n         -1.1514e-01,  9.2743e-02, -6.4683e-03,  1.2476e-01,  9.0133e-02,\n          7.5294e-02,  4.3545e-03, -1.3093e-01, -1.3832e-01,  1.7193e-01,\n         -2.1889e-02,  1.4917e-01],\n        [ 9.4593e-02, -1.1429e-01, -1.1805e-01,  1.4257e-01,  1.0173e-01,\n          6.5634e-02,  5.1084e-02,  8.7575e-02,  1.3721e-01, -1.0631e-01,\n         -2.1725e-02, -7.8554e-03, -1.6535e-01,  6.9885e-02,  5.8860e-02,\n         -1.3330e-01, -1.5342e-01, -1.4143e-01,  1.3670e-01, -1.5106e-01,\n          2.0288e-02, -3.8711e-02,  2.4645e-02,  8.2229e-02, -5.8300e-02,\n         -7.8269e-02, -1.7670e-01, -7.4131e-02,  7.3944e-02, -4.6643e-02,\n         -2.7860e-02, -8.5129e-02],\n        [-1.4008e-01, -9.4062e-02, -1.7178e-01, -1.5398e-03,  1.4412e-01,\n         -1.6274e-01,  1.5244e-01,  1.0801e-01, -1.1781e-01, -1.5508e-01,\n         -1.4884e-01, -1.2183e-01, -9.1162e-02,  1.4590e-01, -9.2717e-02,\n          1.0233e-04,  1.3563e-02,  2.3597e-02, -1.4049e-01,  1.1931e-01,\n         -5.4791e-02,  9.3319e-02,  1.2761e-01, -1.0395e-01, -8.5146e-02,\n         -6.8335e-03,  2.1630e-02,  6.3097e-02,  1.6566e-01, -9.0117e-03,\n          8.7611e-02, -1.8664e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1302, -0.1181,  0.0178, -0.0997,  0.0249,  0.1595,  0.0144, -0.0732],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1479,  0.2214, -0.0737, -0.0264,  0.1544, -0.0022, -0.0828,  0.0327,\n         -0.1733,  0.1572,  0.1064,  0.2137, -0.0955, -0.0975,  0.0051, -0.1410],\n        [-0.1632, -0.0524, -0.2357,  0.1410, -0.0046, -0.2039,  0.1082,  0.0163,\n          0.1277, -0.1744, -0.0913,  0.2438,  0.2454,  0.1268,  0.0569, -0.0022],\n        [-0.0247, -0.2453, -0.1911, -0.0181, -0.0881,  0.1990, -0.1185,  0.0606,\n         -0.1758,  0.0286,  0.2450, -0.1764,  0.0401, -0.0639, -0.0135,  0.2055],\n        [-0.0217, -0.1207,  0.0814,  0.1066, -0.2173, -0.2187,  0.1418,  0.0485,\n          0.2234,  0.1719, -0.2171, -0.0166, -0.2203, -0.1031,  0.2037,  0.2020],\n        [ 0.0792,  0.0253,  0.1982, -0.1376,  0.0882,  0.0432,  0.0663,  0.0791,\n          0.0831, -0.0335,  0.0509, -0.0557,  0.0728, -0.1479,  0.0546, -0.2400],\n        [-0.1902,  0.2052,  0.0878,  0.0223, -0.1910, -0.0852,  0.0902,  0.2394,\n         -0.0237,  0.1872,  0.2374,  0.1948, -0.1969, -0.1632,  0.2286,  0.0250],\n        [-0.2303,  0.1895,  0.2158, -0.1182,  0.0114,  0.0249, -0.0590, -0.1878,\n          0.0810,  0.0378,  0.2466, -0.1352,  0.0654, -0.1693, -0.0556, -0.2481],\n        [ 0.2337,  0.2263, -0.1297, -0.2098, -0.2372,  0.1229,  0.2119,  0.1848,\n          0.0352, -0.1768,  0.2479, -0.1572,  0.0103, -0.2106,  0.0917,  0.0646]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3042,  0.0201,  0.2840,  0.2053], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3462,  0.1190,  0.1460,  0.2842,  0.1425, -0.0356, -0.3400,  0.3038],\n        [-0.0088,  0.0951,  0.2348,  0.2067, -0.3156,  0.2241,  0.2493, -0.0968],\n        [ 0.2560, -0.1305, -0.2948,  0.2103, -0.1749,  0.1237,  0.2455,  0.0967],\n        [ 0.3256,  0.1622, -0.3463, -0.1966,  0.1584, -0.2245,  0.0134, -0.2836]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x79857ecec050>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s773730000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s773730000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}