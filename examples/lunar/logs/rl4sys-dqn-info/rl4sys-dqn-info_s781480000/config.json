{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	4,
    "batch_size":	60,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0007,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s781480000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0005,
    "sample_decay":	0.5,
    "seed":	781480000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x70f5c02a1950>":	{
            "_act_dim":	4,
            "_aux_batch_size":	4,
            "_batch_size":	60,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0007,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1163, -0.1897,  0.3391, -0.0824,  0.0100, -0.2804, -0.3181,  0.2312,\n         0.2908,  0.0010, -0.2238, -0.1223, -0.3343,  0.0566, -0.3231, -0.0472,\n        -0.1415,  0.2322, -0.1642, -0.1065, -0.1487, -0.2135,  0.3177, -0.1602,\n        -0.2804, -0.0371, -0.0555,  0.0882,  0.2827,  0.0368,  0.2363, -0.1940],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3119, -0.3009, -0.3352, -0.0547, -0.3272,  0.3437,  0.1048,  0.0220],\n        [-0.0908, -0.0738, -0.3161, -0.3214,  0.0087, -0.2129, -0.2908,  0.2597],\n        [-0.0417,  0.1636,  0.3348, -0.1159, -0.2003,  0.2764, -0.2179, -0.0824],\n        [-0.2909,  0.1911,  0.2547,  0.1707, -0.3159,  0.0417, -0.0338, -0.1535],\n        [ 0.3227, -0.0627, -0.0487,  0.1875, -0.0264, -0.1323,  0.2462, -0.3349],\n        [ 0.1545,  0.1163,  0.3455,  0.2620, -0.1885, -0.1549, -0.0729, -0.2430],\n        [ 0.2457,  0.1006,  0.0690,  0.3324, -0.3022, -0.2500,  0.2270,  0.1814],\n        [-0.2386, -0.0044,  0.3527, -0.1021,  0.1592,  0.1374,  0.3232, -0.2941],\n        [ 0.0268, -0.0581,  0.1743, -0.2441, -0.1090,  0.2073,  0.1202, -0.2345],\n        [-0.3319,  0.3236, -0.2345,  0.2989, -0.2219, -0.2139, -0.0889, -0.3354],\n        [ 0.1108, -0.1632, -0.1647,  0.0171,  0.2898,  0.1441,  0.1722,  0.1728],\n        [ 0.1103,  0.3060, -0.0456, -0.1649, -0.0578,  0.2224,  0.2959, -0.1549],\n        [-0.2946,  0.2924,  0.3376,  0.1190,  0.3223,  0.2781, -0.2640,  0.3121],\n        [ 0.2393,  0.0194, -0.0531, -0.3002,  0.0351,  0.1047,  0.3533,  0.2845],\n        [ 0.2207,  0.1095, -0.0878,  0.3118,  0.3167, -0.0586, -0.1093,  0.0264],\n        [ 0.1472,  0.0986, -0.1028,  0.2367, -0.0785,  0.0498,  0.3046, -0.0292],\n        [-0.0937,  0.2753,  0.2857,  0.2605, -0.1606, -0.1124,  0.2594,  0.0997],\n        [ 0.0863,  0.3096, -0.2570, -0.1087, -0.0100,  0.0164,  0.1632,  0.1235],\n        [ 0.0837,  0.2731,  0.0930, -0.0540,  0.1305,  0.2536,  0.0574,  0.1232],\n        [ 0.1571, -0.1742, -0.1624,  0.0893,  0.1418,  0.3282, -0.1847,  0.0934],\n        [ 0.3442,  0.1133,  0.2867,  0.2244,  0.0322,  0.1804, -0.2709,  0.0469],\n        [ 0.0641,  0.2400, -0.1040, -0.0482, -0.1700, -0.3215,  0.2751,  0.3062],\n        [-0.2816,  0.1486, -0.3196,  0.2381, -0.1839, -0.2133, -0.3394,  0.3502],\n        [ 0.3489, -0.2321,  0.3291, -0.0092,  0.2831, -0.0669,  0.0305,  0.3364],\n        [ 0.0395,  0.1881, -0.0355,  0.2611, -0.1915, -0.3114,  0.2171,  0.3329],\n        [ 0.1455, -0.2352,  0.1890,  0.2587, -0.1360,  0.3115,  0.2209,  0.0321],\n        [-0.0932,  0.2685, -0.1394,  0.2668,  0.0972,  0.0729,  0.0391,  0.2681],\n        [ 0.2997, -0.3259, -0.3109,  0.3098,  0.2075,  0.1307,  0.1189, -0.2295],\n        [-0.2221, -0.1954,  0.2399,  0.1335,  0.1823,  0.1012, -0.1618, -0.1929],\n        [-0.0645,  0.2883,  0.2614, -0.3524,  0.2555,  0.1158, -0.3284,  0.1694],\n        [ 0.1904, -0.1860,  0.3360, -0.2014, -0.0181, -0.0909, -0.2772, -0.1199],\n        [ 0.0262, -0.2328, -0.1350,  0.3285,  0.2629, -0.2326, -0.2388,  0.0918]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0624,  0.0522,  0.0841, -0.0332,  0.1341, -0.0589, -0.0301,  0.1659,\n        -0.0895, -0.1734,  0.1597,  0.0179, -0.0094, -0.0580,  0.1426, -0.0901],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.4506e-01, -3.3023e-02,  1.5083e-01,  4.2600e-02,  6.9502e-02,\n          7.4130e-02,  1.6896e-01, -7.0079e-02,  1.4326e-01, -1.0406e-01,\n         -7.3032e-02, -1.1064e-01,  1.9508e-02,  1.3496e-01,  1.2230e-01,\n          7.2568e-02,  9.2025e-02, -1.2329e-03, -1.6340e-01,  5.0325e-02,\n         -1.6191e-01,  1.0729e-01, -9.5063e-02, -8.0434e-02,  1.2595e-01,\n          1.5625e-01,  1.2302e-01, -1.4631e-01,  9.5534e-02,  1.4828e-01,\n         -9.9438e-02,  3.2774e-02],\n        [ 1.2540e-01, -7.0139e-02, -1.1220e-01,  1.1426e-01,  1.3979e-01,\n         -6.3179e-02, -4.4513e-02, -1.7426e-01,  1.4194e-01,  7.0977e-02,\n          4.6848e-02, -1.5560e-01, -8.4906e-02, -1.0623e-01, -1.2899e-02,\n          1.0974e-02, -8.3827e-02, -1.4658e-02,  2.4288e-03, -6.8656e-02,\n         -1.3746e-01,  1.2144e-02,  1.3845e-01,  7.6877e-02,  5.1345e-02,\n          3.1676e-02, -1.5576e-01, -5.2973e-02,  4.1011e-02, -4.5240e-02,\n          1.9527e-02,  1.5173e-01],\n        [ 2.9469e-02, -9.1602e-02, -1.2938e-02,  6.1534e-02,  4.3165e-02,\n         -8.3638e-03,  1.6321e-01,  4.2041e-02,  1.4023e-01, -3.2004e-02,\n         -9.1581e-02,  4.1644e-02,  1.8372e-02,  2.5361e-02,  1.7000e-02,\n          9.0723e-02,  4.9873e-02,  1.7494e-01, -1.4283e-01,  1.1242e-01,\n         -1.7286e-02,  1.6219e-01, -3.4011e-02,  1.6962e-01,  1.6262e-01,\n         -3.8879e-02,  6.8057e-02, -1.5705e-01,  1.5758e-01, -4.5007e-02,\n          5.9624e-02,  4.1995e-02],\n        [ 3.1446e-02, -7.8564e-02, -1.2437e-01, -1.1431e-01,  1.0884e-01,\n          1.7659e-01,  1.8734e-02,  9.2661e-02, -3.0919e-02,  5.0567e-02,\n         -6.5514e-02, -7.4076e-02, -2.5050e-02, -1.5132e-01, -1.7357e-01,\n         -1.5699e-01, -4.9016e-02,  8.3777e-02,  6.0797e-04,  1.2676e-01,\n          1.1902e-01, -1.5237e-01, -1.2124e-02,  4.0042e-02, -1.1866e-01,\n          1.2825e-01,  1.4559e-01, -1.3460e-01,  1.2265e-01, -5.0395e-02,\n         -5.0766e-02,  5.7287e-02],\n        [ 7.6983e-02, -1.1261e-01, -7.3071e-02, -8.9636e-02, -6.7674e-02,\n          1.0434e-01, -1.2850e-01, -1.1680e-01,  1.7232e-02, -1.1496e-01,\n          8.2798e-03,  2.9198e-02, -1.3345e-01, -6.5045e-02, -1.3767e-01,\n          1.2100e-01, -1.7136e-01,  7.9999e-02, -4.6822e-02,  7.5201e-02,\n          9.9843e-02,  4.2809e-02,  2.3287e-02,  1.3594e-01,  1.0570e-01,\n         -1.2907e-01,  5.8956e-02, -5.5556e-02, -6.6045e-02,  1.6686e-01,\n         -7.9149e-02,  2.9924e-02],\n        [ 1.3401e-01,  1.5651e-01,  3.3880e-02, -1.3877e-01, -1.1328e-01,\n         -8.2767e-02, -1.6371e-01, -2.4021e-02, -1.3001e-01, -2.2352e-02,\n         -1.4455e-01, -1.5148e-01,  1.6301e-01, -1.4217e-01, -6.1404e-02,\n          5.0677e-02,  9.4647e-02, -1.7143e-01, -1.4299e-01,  5.4222e-05,\n         -5.8787e-03,  1.5294e-01,  7.2290e-02, -1.6049e-01,  3.8849e-04,\n          1.7301e-01,  1.7066e-01,  1.5186e-01, -5.0523e-02, -3.9825e-02,\n          3.1870e-02, -1.1957e-01],\n        [-5.9057e-02,  1.0385e-01,  1.4660e-01, -1.1578e-01,  9.2267e-02,\n         -2.4084e-02,  1.7580e-01,  4.9496e-02,  1.4254e-01, -7.9621e-02,\n         -7.2261e-02, -4.0980e-03, -7.4662e-02,  1.3190e-01,  1.4914e-01,\n         -6.5072e-02, -1.5094e-01,  1.1036e-01,  1.4760e-01, -1.6423e-02,\n          3.4964e-02, -5.9032e-02,  1.0668e-01,  1.6106e-01,  8.5299e-02,\n         -7.4048e-02,  1.5736e-03, -3.7444e-02,  1.4316e-01, -1.6498e-01,\n         -4.2141e-02,  4.7693e-02],\n        [ 1.0324e-01,  5.1189e-02,  1.0799e-01, -1.2045e-01, -9.7438e-02,\n         -2.1219e-02,  1.7225e-01, -6.0477e-02, -5.0180e-02,  1.3704e-01,\n          1.7450e-01, -1.3035e-01,  1.2643e-02,  5.0700e-02, -6.8216e-02,\n          6.1300e-02, -2.4375e-02,  1.5185e-01,  9.2762e-03, -2.3648e-02,\n          9.9124e-03,  1.6991e-01, -1.6993e-01, -2.6340e-02, -1.7655e-01,\n          1.5934e-01,  1.5085e-02, -1.2928e-01,  1.5789e-01, -1.7320e-01,\n          5.7344e-02,  3.5740e-02],\n        [ 3.0209e-02,  1.3592e-01,  5.2482e-02, -1.2748e-01, -4.4095e-02,\n         -1.4240e-01, -1.2931e-01, -1.6955e-02, -2.3849e-02, -4.6008e-02,\n         -2.2948e-02, -1.5313e-01, -1.0163e-02,  4.1831e-02,  1.1764e-01,\n          6.0436e-02, -2.8353e-02, -4.0858e-02,  1.4154e-01,  1.0072e-02,\n          4.6179e-02,  2.0462e-02, -6.2573e-02, -1.7561e-01, -1.1116e-01,\n         -8.1556e-02,  1.0731e-01,  1.2630e-01,  5.9387e-03,  1.2357e-01,\n          1.2760e-01,  4.9892e-02],\n        [-1.1643e-01, -1.5483e-01,  9.3198e-02, -1.6119e-02, -4.4316e-02,\n         -1.7568e-01, -1.5433e-01,  1.5907e-01, -9.5416e-02, -5.8142e-02,\n          1.6746e-01,  1.4236e-02, -3.4802e-03,  7.4517e-03, -1.1156e-01,\n          8.1469e-02, -5.2147e-02,  3.0356e-02, -1.3747e-01,  1.0055e-02,\n          2.2054e-02,  7.8217e-02,  1.6166e-02,  9.3342e-02, -5.2661e-02,\n         -3.4216e-02,  9.8899e-02,  8.9374e-02, -1.4216e-01, -4.9442e-02,\n          1.0213e-01,  4.6187e-02],\n        [-7.7043e-02, -2.1115e-02,  1.0841e-01,  9.2279e-03,  6.6809e-02,\n         -5.3956e-02, -1.8019e-02, -1.3255e-01, -8.0687e-02,  3.2569e-02,\n         -1.6924e-01, -7.2637e-03,  9.6763e-03,  2.0505e-02,  1.4819e-01,\n          7.0613e-02,  3.3021e-02, -1.2516e-01,  6.9592e-02,  3.0014e-03,\n          1.3417e-01,  6.6034e-02,  1.6158e-01, -1.0536e-02,  6.9794e-02,\n         -1.5615e-01,  2.7372e-02,  1.6102e-03,  1.6435e-01, -4.4485e-02,\n          9.8292e-02, -1.6835e-01],\n        [-4.1885e-02, -1.4197e-01,  4.7649e-02, -4.1829e-02,  7.5012e-02,\n          1.8989e-02, -1.3818e-02,  7.8350e-03,  3.8006e-02,  4.2920e-02,\n          1.4989e-01,  1.4764e-01,  9.8519e-02,  4.5083e-03,  7.5327e-02,\n          5.6856e-02, -1.7312e-01, -1.4427e-01,  3.9519e-02, -3.1097e-02,\n         -6.9218e-02, -1.5964e-01,  7.9934e-02,  1.7356e-01,  3.2043e-02,\n          1.4558e-01, -1.3217e-01, -1.6537e-01, -3.7027e-02, -1.6519e-01,\n          1.4538e-01,  3.9140e-02],\n        [ 8.4593e-02, -9.9699e-02, -9.4351e-03, -9.2735e-02, -2.1295e-03,\n         -1.2061e-01, -8.5779e-02, -1.6822e-01, -1.2748e-01,  1.1354e-01,\n         -1.4682e-01, -1.6445e-01,  1.6439e-01,  7.2734e-02, -1.0625e-01,\n         -9.0455e-02,  4.1820e-02,  7.4040e-02,  1.2843e-01, -6.6889e-02,\n         -8.9748e-02, -1.4982e-01,  8.5365e-02,  3.8847e-03,  6.9031e-02,\n         -1.5096e-01, -1.5453e-01, -1.3297e-01, -7.3212e-02,  7.3783e-02,\n          1.5083e-01, -7.5039e-03],\n        [-2.7511e-03,  8.2786e-02, -1.2430e-01, -4.3622e-02, -1.7036e-01,\n          5.1208e-02,  1.2839e-01, -1.1763e-01,  1.6317e-01,  1.4127e-01,\n         -1.6263e-01, -1.3355e-01, -3.3112e-02, -1.6141e-01, -3.7721e-02,\n          1.6866e-01, -4.4685e-02,  1.3036e-01,  1.4312e-01, -1.1191e-01,\n          9.5055e-02, -1.7677e-01,  1.4558e-01,  1.3687e-01,  1.4303e-02,\n         -1.8947e-02, -8.7509e-03, -1.3852e-01,  1.6399e-01,  1.3363e-01,\n         -3.4397e-02,  1.7549e-01],\n        [-9.2699e-02,  6.0914e-03, -1.1510e-01,  5.6753e-02,  2.3974e-02,\n         -1.6277e-01, -1.3527e-02,  5.7772e-02, -1.1952e-01, -1.1551e-01,\n         -9.6869e-03, -7.8096e-04, -1.6581e-02,  6.2632e-02, -1.7186e-01,\n         -4.8576e-02,  3.5102e-03,  1.5367e-01,  1.6227e-01, -7.6368e-02,\n         -1.2961e-01,  1.3144e-01,  1.1819e-01, -5.4768e-02, -9.4620e-02,\n         -1.1917e-01,  5.3195e-02, -1.6505e-01,  4.0109e-02, -1.4097e-01,\n         -3.1890e-02,  1.6157e-01],\n        [ 3.7252e-02, -1.8756e-03,  1.0324e-01,  5.6423e-02, -3.3327e-02,\n         -7.4793e-02, -8.2347e-02, -6.3388e-02,  7.3010e-02,  4.1654e-02,\n         -3.9906e-03,  7.3435e-02,  2.7366e-02,  1.4619e-02,  9.3388e-02,\n          9.8383e-02, -8.8057e-02,  3.2091e-02,  1.5770e-01,  1.5441e-01,\n         -1.5343e-01,  1.2407e-01, -1.5511e-01,  1.0473e-01,  1.4643e-01,\n          1.4280e-01, -1.3590e-02,  1.3145e-01,  1.1361e-01,  2.3141e-02,\n         -1.0230e-01,  1.7597e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2425, -0.0199,  0.2071, -0.2205,  0.1132,  0.2454,  0.0981, -0.0437],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0609, -0.0489,  0.1436, -0.2460, -0.1508, -0.0435, -0.1477, -0.0062,\n          0.0401,  0.2196,  0.0877, -0.1331, -0.0845, -0.1176, -0.1295,  0.0704],\n        [-0.0440,  0.0652,  0.0761,  0.0426,  0.0569, -0.2318,  0.0386, -0.1993,\n         -0.0822, -0.0539, -0.0871,  0.0145, -0.0405, -0.0174, -0.0523,  0.1539],\n        [ 0.0621,  0.1252,  0.1763,  0.1057,  0.0355, -0.0746,  0.1981,  0.0160,\n          0.1010, -0.0042, -0.1444, -0.0390,  0.1070,  0.0502, -0.0685, -0.1490],\n        [ 0.0496,  0.2303,  0.0839,  0.1725,  0.1331, -0.2306,  0.1094, -0.0043,\n          0.1726,  0.2429, -0.0243,  0.1608, -0.1491,  0.1567,  0.1609, -0.2419],\n        [ 0.1896, -0.0824, -0.1941,  0.0926, -0.2431, -0.1025, -0.0059,  0.0571,\n         -0.0134, -0.1403,  0.1385,  0.1978, -0.1539,  0.2169, -0.2154,  0.0111],\n        [ 0.0504, -0.2063,  0.2028, -0.0392, -0.1521, -0.2042,  0.2310,  0.0524,\n          0.0059, -0.0593,  0.1058,  0.1208,  0.1715,  0.0117, -0.1176, -0.0668],\n        [-0.2173, -0.0748,  0.1098,  0.2437,  0.1419, -0.2226,  0.2306,  0.1507,\n          0.1668,  0.1063, -0.0014,  0.0219,  0.0949,  0.1476, -0.1679, -0.1035],\n        [-0.2331, -0.1814, -0.2002,  0.0110,  0.0883,  0.0636, -0.1170,  0.0336,\n          0.1501,  0.2382, -0.0257,  0.1168, -0.0006, -0.0260, -0.0553,  0.1880]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2903, -0.0885,  0.3257, -0.2294], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2327, -0.0991,  0.2370, -0.1790,  0.1677, -0.2989, -0.1231, -0.3325],\n        [-0.1430, -0.2597, -0.2598,  0.1389, -0.1488,  0.0005,  0.3498,  0.2877],\n        [-0.2366, -0.0241,  0.0382, -0.2005,  0.0240, -0.1672, -0.2689, -0.0802],\n        [ 0.2248,  0.1257,  0.2088, -0.2090,  0.0136,  0.0748, -0.2947, -0.0413]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.3119, -0.3009, -0.3352, -0.0547, -0.3272,  0.3437,  0.1048,  0.0220],\n        [-0.0908, -0.0738, -0.3161, -0.3214,  0.0087, -0.2129, -0.2908,  0.2597],\n        [-0.0417,  0.1636,  0.3348, -0.1159, -0.2003,  0.2764, -0.2179, -0.0824],\n        [-0.2909,  0.1911,  0.2547,  0.1707, -0.3159,  0.0417, -0.0338, -0.1535],\n        [ 0.3227, -0.0627, -0.0487,  0.1875, -0.0264, -0.1323,  0.2462, -0.3349],\n        [ 0.1545,  0.1163,  0.3455,  0.2620, -0.1885, -0.1549, -0.0729, -0.2430],\n        [ 0.2457,  0.1006,  0.0690,  0.3324, -0.3022, -0.2500,  0.2270,  0.1814],\n        [-0.2386, -0.0044,  0.3527, -0.1021,  0.1592,  0.1374,  0.3232, -0.2941],\n        [ 0.0268, -0.0581,  0.1743, -0.2441, -0.1090,  0.2073,  0.1202, -0.2345],\n        [-0.3319,  0.3236, -0.2345,  0.2989, -0.2219, -0.2139, -0.0889, -0.3354],\n        [ 0.1108, -0.1632, -0.1647,  0.0171,  0.2898,  0.1441,  0.1722,  0.1728],\n        [ 0.1103,  0.3060, -0.0456, -0.1649, -0.0578,  0.2224,  0.2959, -0.1549],\n        [-0.2946,  0.2924,  0.3376,  0.1190,  0.3223,  0.2781, -0.2640,  0.3121],\n        [ 0.2393,  0.0194, -0.0531, -0.3002,  0.0351,  0.1047,  0.3533,  0.2845],\n        [ 0.2207,  0.1095, -0.0878,  0.3118,  0.3167, -0.0586, -0.1093,  0.0264],\n        [ 0.1472,  0.0986, -0.1028,  0.2367, -0.0785,  0.0498,  0.3046, -0.0292],\n        [-0.0937,  0.2753,  0.2857,  0.2605, -0.1606, -0.1124,  0.2594,  0.0997],\n        [ 0.0863,  0.3096, -0.2570, -0.1087, -0.0100,  0.0164,  0.1632,  0.1235],\n        [ 0.0837,  0.2731,  0.0930, -0.0540,  0.1305,  0.2536,  0.0574,  0.1232],\n        [ 0.1571, -0.1742, -0.1624,  0.0893,  0.1418,  0.3282, -0.1847,  0.0934],\n        [ 0.3442,  0.1133,  0.2867,  0.2244,  0.0322,  0.1804, -0.2709,  0.0469],\n        [ 0.0641,  0.2400, -0.1040, -0.0482, -0.1700, -0.3215,  0.2751,  0.3062],\n        [-0.2816,  0.1486, -0.3196,  0.2381, -0.1839, -0.2133, -0.3394,  0.3502],\n        [ 0.3489, -0.2321,  0.3291, -0.0092,  0.2831, -0.0669,  0.0305,  0.3364],\n        [ 0.0395,  0.1881, -0.0355,  0.2611, -0.1915, -0.3114,  0.2171,  0.3329],\n        [ 0.1455, -0.2352,  0.1890,  0.2587, -0.1360,  0.3115,  0.2209,  0.0321],\n        [-0.0932,  0.2685, -0.1394,  0.2668,  0.0972,  0.0729,  0.0391,  0.2681],\n        [ 0.2997, -0.3259, -0.3109,  0.3098,  0.2075,  0.1307,  0.1189, -0.2295],\n        [-0.2221, -0.1954,  0.2399,  0.1335,  0.1823,  0.1012, -0.1618, -0.1929],\n        [-0.0645,  0.2883,  0.2614, -0.3524,  0.2555,  0.1158, -0.3284,  0.1694],\n        [ 0.1904, -0.1860,  0.3360, -0.2014, -0.0181, -0.0909, -0.2772, -0.1199],\n        [ 0.0262, -0.2328, -0.1350,  0.3285,  0.2629, -0.2326, -0.2388,  0.0918]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1163, -0.1897,  0.3391, -0.0824,  0.0100, -0.2804, -0.3181,  0.2312,\n         0.2908,  0.0010, -0.2238, -0.1223, -0.3343,  0.0566, -0.3231, -0.0472,\n        -0.1415,  0.2322, -0.1642, -0.1065, -0.1487, -0.2135,  0.3177, -0.1602,\n        -0.2804, -0.0371, -0.0555,  0.0882,  0.2827,  0.0368,  0.2363, -0.1940],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.4506e-01, -3.3023e-02,  1.5083e-01,  4.2600e-02,  6.9502e-02,\n          7.4130e-02,  1.6896e-01, -7.0079e-02,  1.4326e-01, -1.0406e-01,\n         -7.3032e-02, -1.1064e-01,  1.9508e-02,  1.3496e-01,  1.2230e-01,\n          7.2568e-02,  9.2025e-02, -1.2329e-03, -1.6340e-01,  5.0325e-02,\n         -1.6191e-01,  1.0729e-01, -9.5063e-02, -8.0434e-02,  1.2595e-01,\n          1.5625e-01,  1.2302e-01, -1.4631e-01,  9.5534e-02,  1.4828e-01,\n         -9.9438e-02,  3.2774e-02],\n        [ 1.2540e-01, -7.0139e-02, -1.1220e-01,  1.1426e-01,  1.3979e-01,\n         -6.3179e-02, -4.4513e-02, -1.7426e-01,  1.4194e-01,  7.0977e-02,\n          4.6848e-02, -1.5560e-01, -8.4906e-02, -1.0623e-01, -1.2899e-02,\n          1.0974e-02, -8.3827e-02, -1.4658e-02,  2.4288e-03, -6.8656e-02,\n         -1.3746e-01,  1.2144e-02,  1.3845e-01,  7.6877e-02,  5.1345e-02,\n          3.1676e-02, -1.5576e-01, -5.2973e-02,  4.1011e-02, -4.5240e-02,\n          1.9527e-02,  1.5173e-01],\n        [ 2.9469e-02, -9.1602e-02, -1.2938e-02,  6.1534e-02,  4.3165e-02,\n         -8.3638e-03,  1.6321e-01,  4.2041e-02,  1.4023e-01, -3.2004e-02,\n         -9.1581e-02,  4.1644e-02,  1.8372e-02,  2.5361e-02,  1.7000e-02,\n          9.0723e-02,  4.9873e-02,  1.7494e-01, -1.4283e-01,  1.1242e-01,\n         -1.7286e-02,  1.6219e-01, -3.4011e-02,  1.6962e-01,  1.6262e-01,\n         -3.8879e-02,  6.8057e-02, -1.5705e-01,  1.5758e-01, -4.5007e-02,\n          5.9624e-02,  4.1995e-02],\n        [ 3.1446e-02, -7.8564e-02, -1.2437e-01, -1.1431e-01,  1.0884e-01,\n          1.7659e-01,  1.8734e-02,  9.2661e-02, -3.0919e-02,  5.0567e-02,\n         -6.5514e-02, -7.4076e-02, -2.5050e-02, -1.5132e-01, -1.7357e-01,\n         -1.5699e-01, -4.9016e-02,  8.3777e-02,  6.0797e-04,  1.2676e-01,\n          1.1902e-01, -1.5237e-01, -1.2124e-02,  4.0042e-02, -1.1866e-01,\n          1.2825e-01,  1.4559e-01, -1.3460e-01,  1.2265e-01, -5.0395e-02,\n         -5.0766e-02,  5.7287e-02],\n        [ 7.6983e-02, -1.1261e-01, -7.3071e-02, -8.9636e-02, -6.7674e-02,\n          1.0434e-01, -1.2850e-01, -1.1680e-01,  1.7232e-02, -1.1496e-01,\n          8.2798e-03,  2.9198e-02, -1.3345e-01, -6.5045e-02, -1.3767e-01,\n          1.2100e-01, -1.7136e-01,  7.9999e-02, -4.6822e-02,  7.5201e-02,\n          9.9843e-02,  4.2809e-02,  2.3287e-02,  1.3594e-01,  1.0570e-01,\n         -1.2907e-01,  5.8956e-02, -5.5556e-02, -6.6045e-02,  1.6686e-01,\n         -7.9149e-02,  2.9924e-02],\n        [ 1.3401e-01,  1.5651e-01,  3.3880e-02, -1.3877e-01, -1.1328e-01,\n         -8.2767e-02, -1.6371e-01, -2.4021e-02, -1.3001e-01, -2.2352e-02,\n         -1.4455e-01, -1.5148e-01,  1.6301e-01, -1.4217e-01, -6.1404e-02,\n          5.0677e-02,  9.4647e-02, -1.7143e-01, -1.4299e-01,  5.4222e-05,\n         -5.8787e-03,  1.5294e-01,  7.2290e-02, -1.6049e-01,  3.8849e-04,\n          1.7301e-01,  1.7066e-01,  1.5186e-01, -5.0523e-02, -3.9825e-02,\n          3.1870e-02, -1.1957e-01],\n        [-5.9057e-02,  1.0385e-01,  1.4660e-01, -1.1578e-01,  9.2267e-02,\n         -2.4084e-02,  1.7580e-01,  4.9496e-02,  1.4254e-01, -7.9621e-02,\n         -7.2261e-02, -4.0980e-03, -7.4662e-02,  1.3190e-01,  1.4914e-01,\n         -6.5072e-02, -1.5094e-01,  1.1036e-01,  1.4760e-01, -1.6423e-02,\n          3.4964e-02, -5.9032e-02,  1.0668e-01,  1.6106e-01,  8.5299e-02,\n         -7.4048e-02,  1.5736e-03, -3.7444e-02,  1.4316e-01, -1.6498e-01,\n         -4.2141e-02,  4.7693e-02],\n        [ 1.0324e-01,  5.1189e-02,  1.0799e-01, -1.2045e-01, -9.7438e-02,\n         -2.1219e-02,  1.7225e-01, -6.0477e-02, -5.0180e-02,  1.3704e-01,\n          1.7450e-01, -1.3035e-01,  1.2643e-02,  5.0700e-02, -6.8216e-02,\n          6.1300e-02, -2.4375e-02,  1.5185e-01,  9.2762e-03, -2.3648e-02,\n          9.9124e-03,  1.6991e-01, -1.6993e-01, -2.6340e-02, -1.7655e-01,\n          1.5934e-01,  1.5085e-02, -1.2928e-01,  1.5789e-01, -1.7320e-01,\n          5.7344e-02,  3.5740e-02],\n        [ 3.0209e-02,  1.3592e-01,  5.2482e-02, -1.2748e-01, -4.4095e-02,\n         -1.4240e-01, -1.2931e-01, -1.6955e-02, -2.3849e-02, -4.6008e-02,\n         -2.2948e-02, -1.5313e-01, -1.0163e-02,  4.1831e-02,  1.1764e-01,\n          6.0436e-02, -2.8353e-02, -4.0858e-02,  1.4154e-01,  1.0072e-02,\n          4.6179e-02,  2.0462e-02, -6.2573e-02, -1.7561e-01, -1.1116e-01,\n         -8.1556e-02,  1.0731e-01,  1.2630e-01,  5.9387e-03,  1.2357e-01,\n          1.2760e-01,  4.9892e-02],\n        [-1.1643e-01, -1.5483e-01,  9.3198e-02, -1.6119e-02, -4.4316e-02,\n         -1.7568e-01, -1.5433e-01,  1.5907e-01, -9.5416e-02, -5.8142e-02,\n          1.6746e-01,  1.4236e-02, -3.4802e-03,  7.4517e-03, -1.1156e-01,\n          8.1469e-02, -5.2147e-02,  3.0356e-02, -1.3747e-01,  1.0055e-02,\n          2.2054e-02,  7.8217e-02,  1.6166e-02,  9.3342e-02, -5.2661e-02,\n         -3.4216e-02,  9.8899e-02,  8.9374e-02, -1.4216e-01, -4.9442e-02,\n          1.0213e-01,  4.6187e-02],\n        [-7.7043e-02, -2.1115e-02,  1.0841e-01,  9.2279e-03,  6.6809e-02,\n         -5.3956e-02, -1.8019e-02, -1.3255e-01, -8.0687e-02,  3.2569e-02,\n         -1.6924e-01, -7.2637e-03,  9.6763e-03,  2.0505e-02,  1.4819e-01,\n          7.0613e-02,  3.3021e-02, -1.2516e-01,  6.9592e-02,  3.0014e-03,\n          1.3417e-01,  6.6034e-02,  1.6158e-01, -1.0536e-02,  6.9794e-02,\n         -1.5615e-01,  2.7372e-02,  1.6102e-03,  1.6435e-01, -4.4485e-02,\n          9.8292e-02, -1.6835e-01],\n        [-4.1885e-02, -1.4197e-01,  4.7649e-02, -4.1829e-02,  7.5012e-02,\n          1.8989e-02, -1.3818e-02,  7.8350e-03,  3.8006e-02,  4.2920e-02,\n          1.4989e-01,  1.4764e-01,  9.8519e-02,  4.5083e-03,  7.5327e-02,\n          5.6856e-02, -1.7312e-01, -1.4427e-01,  3.9519e-02, -3.1097e-02,\n         -6.9218e-02, -1.5964e-01,  7.9934e-02,  1.7356e-01,  3.2043e-02,\n          1.4558e-01, -1.3217e-01, -1.6537e-01, -3.7027e-02, -1.6519e-01,\n          1.4538e-01,  3.9140e-02],\n        [ 8.4593e-02, -9.9699e-02, -9.4351e-03, -9.2735e-02, -2.1295e-03,\n         -1.2061e-01, -8.5779e-02, -1.6822e-01, -1.2748e-01,  1.1354e-01,\n         -1.4682e-01, -1.6445e-01,  1.6439e-01,  7.2734e-02, -1.0625e-01,\n         -9.0455e-02,  4.1820e-02,  7.4040e-02,  1.2843e-01, -6.6889e-02,\n         -8.9748e-02, -1.4982e-01,  8.5365e-02,  3.8847e-03,  6.9031e-02,\n         -1.5096e-01, -1.5453e-01, -1.3297e-01, -7.3212e-02,  7.3783e-02,\n          1.5083e-01, -7.5039e-03],\n        [-2.7511e-03,  8.2786e-02, -1.2430e-01, -4.3622e-02, -1.7036e-01,\n          5.1208e-02,  1.2839e-01, -1.1763e-01,  1.6317e-01,  1.4127e-01,\n         -1.6263e-01, -1.3355e-01, -3.3112e-02, -1.6141e-01, -3.7721e-02,\n          1.6866e-01, -4.4685e-02,  1.3036e-01,  1.4312e-01, -1.1191e-01,\n          9.5055e-02, -1.7677e-01,  1.4558e-01,  1.3687e-01,  1.4303e-02,\n         -1.8947e-02, -8.7509e-03, -1.3852e-01,  1.6399e-01,  1.3363e-01,\n         -3.4397e-02,  1.7549e-01],\n        [-9.2699e-02,  6.0914e-03, -1.1510e-01,  5.6753e-02,  2.3974e-02,\n         -1.6277e-01, -1.3527e-02,  5.7772e-02, -1.1952e-01, -1.1551e-01,\n         -9.6869e-03, -7.8096e-04, -1.6581e-02,  6.2632e-02, -1.7186e-01,\n         -4.8576e-02,  3.5102e-03,  1.5367e-01,  1.6227e-01, -7.6368e-02,\n         -1.2961e-01,  1.3144e-01,  1.1819e-01, -5.4768e-02, -9.4620e-02,\n         -1.1917e-01,  5.3195e-02, -1.6505e-01,  4.0109e-02, -1.4097e-01,\n         -3.1890e-02,  1.6157e-01],\n        [ 3.7252e-02, -1.8756e-03,  1.0324e-01,  5.6423e-02, -3.3327e-02,\n         -7.4793e-02, -8.2347e-02, -6.3388e-02,  7.3010e-02,  4.1654e-02,\n         -3.9906e-03,  7.3435e-02,  2.7366e-02,  1.4619e-02,  9.3388e-02,\n          9.8383e-02, -8.8057e-02,  3.2091e-02,  1.5770e-01,  1.5441e-01,\n         -1.5343e-01,  1.2407e-01, -1.5511e-01,  1.0473e-01,  1.4643e-01,\n          1.4280e-01, -1.3590e-02,  1.3145e-01,  1.1361e-01,  2.3141e-02,\n         -1.0230e-01,  1.7597e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0624,  0.0522,  0.0841, -0.0332,  0.1341, -0.0589, -0.0301,  0.1659,\n        -0.0895, -0.1734,  0.1597,  0.0179, -0.0094, -0.0580,  0.1426, -0.0901],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0609, -0.0489,  0.1436, -0.2460, -0.1508, -0.0435, -0.1477, -0.0062,\n          0.0401,  0.2196,  0.0877, -0.1331, -0.0845, -0.1176, -0.1295,  0.0704],\n        [-0.0440,  0.0652,  0.0761,  0.0426,  0.0569, -0.2318,  0.0386, -0.1993,\n         -0.0822, -0.0539, -0.0871,  0.0145, -0.0405, -0.0174, -0.0523,  0.1539],\n        [ 0.0621,  0.1252,  0.1763,  0.1057,  0.0355, -0.0746,  0.1981,  0.0160,\n          0.1010, -0.0042, -0.1444, -0.0390,  0.1070,  0.0502, -0.0685, -0.1490],\n        [ 0.0496,  0.2303,  0.0839,  0.1725,  0.1331, -0.2306,  0.1094, -0.0043,\n          0.1726,  0.2429, -0.0243,  0.1608, -0.1491,  0.1567,  0.1609, -0.2419],\n        [ 0.1896, -0.0824, -0.1941,  0.0926, -0.2431, -0.1025, -0.0059,  0.0571,\n         -0.0134, -0.1403,  0.1385,  0.1978, -0.1539,  0.2169, -0.2154,  0.0111],\n        [ 0.0504, -0.2063,  0.2028, -0.0392, -0.1521, -0.2042,  0.2310,  0.0524,\n          0.0059, -0.0593,  0.1058,  0.1208,  0.1715,  0.0117, -0.1176, -0.0668],\n        [-0.2173, -0.0748,  0.1098,  0.2437,  0.1419, -0.2226,  0.2306,  0.1507,\n          0.1668,  0.1063, -0.0014,  0.0219,  0.0949,  0.1476, -0.1679, -0.1035],\n        [-0.2331, -0.1814, -0.2002,  0.0110,  0.0883,  0.0636, -0.1170,  0.0336,\n          0.1501,  0.2382, -0.0257,  0.1168, -0.0006, -0.0260, -0.0553,  0.1880]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2425, -0.0199,  0.2071, -0.2205,  0.1132,  0.2454,  0.0981, -0.0437],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2327, -0.0991,  0.2370, -0.1790,  0.1677, -0.2989, -0.1231, -0.3325],\n        [-0.1430, -0.2597, -0.2598,  0.1389, -0.1488,  0.0005,  0.3498,  0.2877],\n        [-0.2366, -0.0241,  0.0382, -0.2005,  0.0240, -0.1672, -0.2689, -0.0802],\n        [ 0.2248,  0.1257,  0.2088, -0.2090,  0.0136,  0.0748, -0.2947, -0.0413]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2903, -0.0885,  0.3257, -0.2294], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x70f5bff904d0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	1,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x70f5bf627b90>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1163, -0.1897,  0.3391, -0.0824,  0.0100, -0.2804, -0.3181,  0.2312,\n         0.2908,  0.0010, -0.2238, -0.1223, -0.3343,  0.0566, -0.3231, -0.0472,\n        -0.1415,  0.2322, -0.1642, -0.1065, -0.1487, -0.2135,  0.3177, -0.1602,\n        -0.2804, -0.0371, -0.0555,  0.0882,  0.2827,  0.0368,  0.2363, -0.1940],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3119, -0.3009, -0.3352, -0.0547, -0.3272,  0.3437,  0.1048,  0.0220],\n        [-0.0908, -0.0738, -0.3161, -0.3214,  0.0087, -0.2129, -0.2908,  0.2597],\n        [-0.0417,  0.1636,  0.3348, -0.1159, -0.2003,  0.2764, -0.2179, -0.0824],\n        [-0.2909,  0.1911,  0.2547,  0.1707, -0.3159,  0.0417, -0.0338, -0.1535],\n        [ 0.3227, -0.0627, -0.0487,  0.1875, -0.0264, -0.1323,  0.2462, -0.3349],\n        [ 0.1545,  0.1163,  0.3455,  0.2620, -0.1885, -0.1549, -0.0729, -0.2430],\n        [ 0.2457,  0.1006,  0.0690,  0.3324, -0.3022, -0.2500,  0.2270,  0.1814],\n        [-0.2386, -0.0044,  0.3527, -0.1021,  0.1592,  0.1374,  0.3232, -0.2941],\n        [ 0.0268, -0.0581,  0.1743, -0.2441, -0.1090,  0.2073,  0.1202, -0.2345],\n        [-0.3319,  0.3236, -0.2345,  0.2989, -0.2219, -0.2139, -0.0889, -0.3354],\n        [ 0.1108, -0.1632, -0.1647,  0.0171,  0.2898,  0.1441,  0.1722,  0.1728],\n        [ 0.1103,  0.3060, -0.0456, -0.1649, -0.0578,  0.2224,  0.2959, -0.1549],\n        [-0.2946,  0.2924,  0.3376,  0.1190,  0.3223,  0.2781, -0.2640,  0.3121],\n        [ 0.2393,  0.0194, -0.0531, -0.3002,  0.0351,  0.1047,  0.3533,  0.2845],\n        [ 0.2207,  0.1095, -0.0878,  0.3118,  0.3167, -0.0586, -0.1093,  0.0264],\n        [ 0.1472,  0.0986, -0.1028,  0.2367, -0.0785,  0.0498,  0.3046, -0.0292],\n        [-0.0937,  0.2753,  0.2857,  0.2605, -0.1606, -0.1124,  0.2594,  0.0997],\n        [ 0.0863,  0.3096, -0.2570, -0.1087, -0.0100,  0.0164,  0.1632,  0.1235],\n        [ 0.0837,  0.2731,  0.0930, -0.0540,  0.1305,  0.2536,  0.0574,  0.1232],\n        [ 0.1571, -0.1742, -0.1624,  0.0893,  0.1418,  0.3282, -0.1847,  0.0934],\n        [ 0.3442,  0.1133,  0.2867,  0.2244,  0.0322,  0.1804, -0.2709,  0.0469],\n        [ 0.0641,  0.2400, -0.1040, -0.0482, -0.1700, -0.3215,  0.2751,  0.3062],\n        [-0.2816,  0.1486, -0.3196,  0.2381, -0.1839, -0.2133, -0.3394,  0.3502],\n        [ 0.3489, -0.2321,  0.3291, -0.0092,  0.2831, -0.0669,  0.0305,  0.3364],\n        [ 0.0395,  0.1881, -0.0355,  0.2611, -0.1915, -0.3114,  0.2171,  0.3329],\n        [ 0.1455, -0.2352,  0.1890,  0.2587, -0.1360,  0.3115,  0.2209,  0.0321],\n        [-0.0932,  0.2685, -0.1394,  0.2668,  0.0972,  0.0729,  0.0391,  0.2681],\n        [ 0.2997, -0.3259, -0.3109,  0.3098,  0.2075,  0.1307,  0.1189, -0.2295],\n        [-0.2221, -0.1954,  0.2399,  0.1335,  0.1823,  0.1012, -0.1618, -0.1929],\n        [-0.0645,  0.2883,  0.2614, -0.3524,  0.2555,  0.1158, -0.3284,  0.1694],\n        [ 0.1904, -0.1860,  0.3360, -0.2014, -0.0181, -0.0909, -0.2772, -0.1199],\n        [ 0.0262, -0.2328, -0.1350,  0.3285,  0.2629, -0.2326, -0.2388,  0.0918]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0624,  0.0522,  0.0841, -0.0332,  0.1341, -0.0589, -0.0301,  0.1659,\n        -0.0895, -0.1734,  0.1597,  0.0179, -0.0094, -0.0580,  0.1426, -0.0901],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.4506e-01, -3.3023e-02,  1.5083e-01,  4.2600e-02,  6.9502e-02,\n          7.4130e-02,  1.6896e-01, -7.0079e-02,  1.4326e-01, -1.0406e-01,\n         -7.3032e-02, -1.1064e-01,  1.9508e-02,  1.3496e-01,  1.2230e-01,\n          7.2568e-02,  9.2025e-02, -1.2329e-03, -1.6340e-01,  5.0325e-02,\n         -1.6191e-01,  1.0729e-01, -9.5063e-02, -8.0434e-02,  1.2595e-01,\n          1.5625e-01,  1.2302e-01, -1.4631e-01,  9.5534e-02,  1.4828e-01,\n         -9.9438e-02,  3.2774e-02],\n        [ 1.2540e-01, -7.0139e-02, -1.1220e-01,  1.1426e-01,  1.3979e-01,\n         -6.3179e-02, -4.4513e-02, -1.7426e-01,  1.4194e-01,  7.0977e-02,\n          4.6848e-02, -1.5560e-01, -8.4906e-02, -1.0623e-01, -1.2899e-02,\n          1.0974e-02, -8.3827e-02, -1.4658e-02,  2.4288e-03, -6.8656e-02,\n         -1.3746e-01,  1.2144e-02,  1.3845e-01,  7.6877e-02,  5.1345e-02,\n          3.1676e-02, -1.5576e-01, -5.2973e-02,  4.1011e-02, -4.5240e-02,\n          1.9527e-02,  1.5173e-01],\n        [ 2.9469e-02, -9.1602e-02, -1.2938e-02,  6.1534e-02,  4.3165e-02,\n         -8.3638e-03,  1.6321e-01,  4.2041e-02,  1.4023e-01, -3.2004e-02,\n         -9.1581e-02,  4.1644e-02,  1.8372e-02,  2.5361e-02,  1.7000e-02,\n          9.0723e-02,  4.9873e-02,  1.7494e-01, -1.4283e-01,  1.1242e-01,\n         -1.7286e-02,  1.6219e-01, -3.4011e-02,  1.6962e-01,  1.6262e-01,\n         -3.8879e-02,  6.8057e-02, -1.5705e-01,  1.5758e-01, -4.5007e-02,\n          5.9624e-02,  4.1995e-02],\n        [ 3.1446e-02, -7.8564e-02, -1.2437e-01, -1.1431e-01,  1.0884e-01,\n          1.7659e-01,  1.8734e-02,  9.2661e-02, -3.0919e-02,  5.0567e-02,\n         -6.5514e-02, -7.4076e-02, -2.5050e-02, -1.5132e-01, -1.7357e-01,\n         -1.5699e-01, -4.9016e-02,  8.3777e-02,  6.0797e-04,  1.2676e-01,\n          1.1902e-01, -1.5237e-01, -1.2124e-02,  4.0042e-02, -1.1866e-01,\n          1.2825e-01,  1.4559e-01, -1.3460e-01,  1.2265e-01, -5.0395e-02,\n         -5.0766e-02,  5.7287e-02],\n        [ 7.6983e-02, -1.1261e-01, -7.3071e-02, -8.9636e-02, -6.7674e-02,\n          1.0434e-01, -1.2850e-01, -1.1680e-01,  1.7232e-02, -1.1496e-01,\n          8.2798e-03,  2.9198e-02, -1.3345e-01, -6.5045e-02, -1.3767e-01,\n          1.2100e-01, -1.7136e-01,  7.9999e-02, -4.6822e-02,  7.5201e-02,\n          9.9843e-02,  4.2809e-02,  2.3287e-02,  1.3594e-01,  1.0570e-01,\n         -1.2907e-01,  5.8956e-02, -5.5556e-02, -6.6045e-02,  1.6686e-01,\n         -7.9149e-02,  2.9924e-02],\n        [ 1.3401e-01,  1.5651e-01,  3.3880e-02, -1.3877e-01, -1.1328e-01,\n         -8.2767e-02, -1.6371e-01, -2.4021e-02, -1.3001e-01, -2.2352e-02,\n         -1.4455e-01, -1.5148e-01,  1.6301e-01, -1.4217e-01, -6.1404e-02,\n          5.0677e-02,  9.4647e-02, -1.7143e-01, -1.4299e-01,  5.4222e-05,\n         -5.8787e-03,  1.5294e-01,  7.2290e-02, -1.6049e-01,  3.8849e-04,\n          1.7301e-01,  1.7066e-01,  1.5186e-01, -5.0523e-02, -3.9825e-02,\n          3.1870e-02, -1.1957e-01],\n        [-5.9057e-02,  1.0385e-01,  1.4660e-01, -1.1578e-01,  9.2267e-02,\n         -2.4084e-02,  1.7580e-01,  4.9496e-02,  1.4254e-01, -7.9621e-02,\n         -7.2261e-02, -4.0980e-03, -7.4662e-02,  1.3190e-01,  1.4914e-01,\n         -6.5072e-02, -1.5094e-01,  1.1036e-01,  1.4760e-01, -1.6423e-02,\n          3.4964e-02, -5.9032e-02,  1.0668e-01,  1.6106e-01,  8.5299e-02,\n         -7.4048e-02,  1.5736e-03, -3.7444e-02,  1.4316e-01, -1.6498e-01,\n         -4.2141e-02,  4.7693e-02],\n        [ 1.0324e-01,  5.1189e-02,  1.0799e-01, -1.2045e-01, -9.7438e-02,\n         -2.1219e-02,  1.7225e-01, -6.0477e-02, -5.0180e-02,  1.3704e-01,\n          1.7450e-01, -1.3035e-01,  1.2643e-02,  5.0700e-02, -6.8216e-02,\n          6.1300e-02, -2.4375e-02,  1.5185e-01,  9.2762e-03, -2.3648e-02,\n          9.9124e-03,  1.6991e-01, -1.6993e-01, -2.6340e-02, -1.7655e-01,\n          1.5934e-01,  1.5085e-02, -1.2928e-01,  1.5789e-01, -1.7320e-01,\n          5.7344e-02,  3.5740e-02],\n        [ 3.0209e-02,  1.3592e-01,  5.2482e-02, -1.2748e-01, -4.4095e-02,\n         -1.4240e-01, -1.2931e-01, -1.6955e-02, -2.3849e-02, -4.6008e-02,\n         -2.2948e-02, -1.5313e-01, -1.0163e-02,  4.1831e-02,  1.1764e-01,\n          6.0436e-02, -2.8353e-02, -4.0858e-02,  1.4154e-01,  1.0072e-02,\n          4.6179e-02,  2.0462e-02, -6.2573e-02, -1.7561e-01, -1.1116e-01,\n         -8.1556e-02,  1.0731e-01,  1.2630e-01,  5.9387e-03,  1.2357e-01,\n          1.2760e-01,  4.9892e-02],\n        [-1.1643e-01, -1.5483e-01,  9.3198e-02, -1.6119e-02, -4.4316e-02,\n         -1.7568e-01, -1.5433e-01,  1.5907e-01, -9.5416e-02, -5.8142e-02,\n          1.6746e-01,  1.4236e-02, -3.4802e-03,  7.4517e-03, -1.1156e-01,\n          8.1469e-02, -5.2147e-02,  3.0356e-02, -1.3747e-01,  1.0055e-02,\n          2.2054e-02,  7.8217e-02,  1.6166e-02,  9.3342e-02, -5.2661e-02,\n         -3.4216e-02,  9.8899e-02,  8.9374e-02, -1.4216e-01, -4.9442e-02,\n          1.0213e-01,  4.6187e-02],\n        [-7.7043e-02, -2.1115e-02,  1.0841e-01,  9.2279e-03,  6.6809e-02,\n         -5.3956e-02, -1.8019e-02, -1.3255e-01, -8.0687e-02,  3.2569e-02,\n         -1.6924e-01, -7.2637e-03,  9.6763e-03,  2.0505e-02,  1.4819e-01,\n          7.0613e-02,  3.3021e-02, -1.2516e-01,  6.9592e-02,  3.0014e-03,\n          1.3417e-01,  6.6034e-02,  1.6158e-01, -1.0536e-02,  6.9794e-02,\n         -1.5615e-01,  2.7372e-02,  1.6102e-03,  1.6435e-01, -4.4485e-02,\n          9.8292e-02, -1.6835e-01],\n        [-4.1885e-02, -1.4197e-01,  4.7649e-02, -4.1829e-02,  7.5012e-02,\n          1.8989e-02, -1.3818e-02,  7.8350e-03,  3.8006e-02,  4.2920e-02,\n          1.4989e-01,  1.4764e-01,  9.8519e-02,  4.5083e-03,  7.5327e-02,\n          5.6856e-02, -1.7312e-01, -1.4427e-01,  3.9519e-02, -3.1097e-02,\n         -6.9218e-02, -1.5964e-01,  7.9934e-02,  1.7356e-01,  3.2043e-02,\n          1.4558e-01, -1.3217e-01, -1.6537e-01, -3.7027e-02, -1.6519e-01,\n          1.4538e-01,  3.9140e-02],\n        [ 8.4593e-02, -9.9699e-02, -9.4351e-03, -9.2735e-02, -2.1295e-03,\n         -1.2061e-01, -8.5779e-02, -1.6822e-01, -1.2748e-01,  1.1354e-01,\n         -1.4682e-01, -1.6445e-01,  1.6439e-01,  7.2734e-02, -1.0625e-01,\n         -9.0455e-02,  4.1820e-02,  7.4040e-02,  1.2843e-01, -6.6889e-02,\n         -8.9748e-02, -1.4982e-01,  8.5365e-02,  3.8847e-03,  6.9031e-02,\n         -1.5096e-01, -1.5453e-01, -1.3297e-01, -7.3212e-02,  7.3783e-02,\n          1.5083e-01, -7.5039e-03],\n        [-2.7511e-03,  8.2786e-02, -1.2430e-01, -4.3622e-02, -1.7036e-01,\n          5.1208e-02,  1.2839e-01, -1.1763e-01,  1.6317e-01,  1.4127e-01,\n         -1.6263e-01, -1.3355e-01, -3.3112e-02, -1.6141e-01, -3.7721e-02,\n          1.6866e-01, -4.4685e-02,  1.3036e-01,  1.4312e-01, -1.1191e-01,\n          9.5055e-02, -1.7677e-01,  1.4558e-01,  1.3687e-01,  1.4303e-02,\n         -1.8947e-02, -8.7509e-03, -1.3852e-01,  1.6399e-01,  1.3363e-01,\n         -3.4397e-02,  1.7549e-01],\n        [-9.2699e-02,  6.0914e-03, -1.1510e-01,  5.6753e-02,  2.3974e-02,\n         -1.6277e-01, -1.3527e-02,  5.7772e-02, -1.1952e-01, -1.1551e-01,\n         -9.6869e-03, -7.8096e-04, -1.6581e-02,  6.2632e-02, -1.7186e-01,\n         -4.8576e-02,  3.5102e-03,  1.5367e-01,  1.6227e-01, -7.6368e-02,\n         -1.2961e-01,  1.3144e-01,  1.1819e-01, -5.4768e-02, -9.4620e-02,\n         -1.1917e-01,  5.3195e-02, -1.6505e-01,  4.0109e-02, -1.4097e-01,\n         -3.1890e-02,  1.6157e-01],\n        [ 3.7252e-02, -1.8756e-03,  1.0324e-01,  5.6423e-02, -3.3327e-02,\n         -7.4793e-02, -8.2347e-02, -6.3388e-02,  7.3010e-02,  4.1654e-02,\n         -3.9906e-03,  7.3435e-02,  2.7366e-02,  1.4619e-02,  9.3388e-02,\n          9.8383e-02, -8.8057e-02,  3.2091e-02,  1.5770e-01,  1.5441e-01,\n         -1.5343e-01,  1.2407e-01, -1.5511e-01,  1.0473e-01,  1.4643e-01,\n          1.4280e-01, -1.3590e-02,  1.3145e-01,  1.1361e-01,  2.3141e-02,\n         -1.0230e-01,  1.7597e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2425, -0.0199,  0.2071, -0.2205,  0.1132,  0.2454,  0.0981, -0.0437],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0609, -0.0489,  0.1436, -0.2460, -0.1508, -0.0435, -0.1477, -0.0062,\n          0.0401,  0.2196,  0.0877, -0.1331, -0.0845, -0.1176, -0.1295,  0.0704],\n        [-0.0440,  0.0652,  0.0761,  0.0426,  0.0569, -0.2318,  0.0386, -0.1993,\n         -0.0822, -0.0539, -0.0871,  0.0145, -0.0405, -0.0174, -0.0523,  0.1539],\n        [ 0.0621,  0.1252,  0.1763,  0.1057,  0.0355, -0.0746,  0.1981,  0.0160,\n          0.1010, -0.0042, -0.1444, -0.0390,  0.1070,  0.0502, -0.0685, -0.1490],\n        [ 0.0496,  0.2303,  0.0839,  0.1725,  0.1331, -0.2306,  0.1094, -0.0043,\n          0.1726,  0.2429, -0.0243,  0.1608, -0.1491,  0.1567,  0.1609, -0.2419],\n        [ 0.1896, -0.0824, -0.1941,  0.0926, -0.2431, -0.1025, -0.0059,  0.0571,\n         -0.0134, -0.1403,  0.1385,  0.1978, -0.1539,  0.2169, -0.2154,  0.0111],\n        [ 0.0504, -0.2063,  0.2028, -0.0392, -0.1521, -0.2042,  0.2310,  0.0524,\n          0.0059, -0.0593,  0.1058,  0.1208,  0.1715,  0.0117, -0.1176, -0.0668],\n        [-0.2173, -0.0748,  0.1098,  0.2437,  0.1419, -0.2226,  0.2306,  0.1507,\n          0.1668,  0.1063, -0.0014,  0.0219,  0.0949,  0.1476, -0.1679, -0.1035],\n        [-0.2331, -0.1814, -0.2002,  0.0110,  0.0883,  0.0636, -0.1170,  0.0336,\n          0.1501,  0.2382, -0.0257,  0.1168, -0.0006, -0.0260, -0.0553,  0.1880]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2903, -0.0885,  0.3257, -0.2294], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2327, -0.0991,  0.2370, -0.1790,  0.1677, -0.2989, -0.1231, -0.3325],\n        [-0.1430, -0.2597, -0.2598,  0.1389, -0.1488,  0.0005,  0.3498,  0.2877],\n        [-0.2366, -0.0241,  0.0382, -0.2005,  0.0240, -0.1672, -0.2689, -0.0802],\n        [ 0.2248,  0.1257,  0.2088, -0.2090,  0.0136,  0.0748, -0.2947, -0.0413]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x70f5bc9fe350>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s781480000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s781480000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}