{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.15,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s81070000"
    },
    "q_lr":	0.003,
    "seed":	81070000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x790b9841d4d0>":	{
            "_act_dim":	4,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.15,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 2.9730e-02,  4.2127e-02,  3.2267e-01,  1.4444e-01, -3.0847e-01,\n        -2.6289e-02,  2.0180e-01,  1.4357e-01,  1.7046e-01,  2.8250e-01,\n        -1.2392e-01,  1.5976e-01,  5.5733e-02, -2.8193e-01,  1.0351e-02,\n         2.6751e-01,  1.1450e-01,  1.5973e-01, -2.6285e-03, -2.9749e-01,\n        -3.3068e-04, -7.9242e-02,  1.8652e-01, -2.4974e-01,  5.7774e-02,\n         1.6688e-01,  6.7475e-02,  2.5656e-01, -3.4527e-01,  1.8672e-01,\n         4.9454e-02,  6.5889e-02], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0549,  0.1634, -0.1923,  0.1334,  0.2794,  0.1246, -0.0620, -0.0942],\n        [ 0.1163,  0.1283,  0.0148, -0.1679,  0.3514,  0.3480, -0.1094,  0.2979],\n        [ 0.2658,  0.2385, -0.3065, -0.0172, -0.2697, -0.1992, -0.0526,  0.0734],\n        [ 0.1128, -0.2659,  0.3050,  0.2318, -0.2112,  0.1244, -0.1895,  0.0252],\n        [ 0.2455,  0.2248, -0.3218,  0.1618, -0.3123, -0.1911, -0.2330,  0.1764],\n        [-0.0651,  0.3037,  0.0064,  0.1872,  0.1596,  0.1431, -0.3420, -0.1787],\n        [ 0.1734,  0.2043, -0.0578, -0.3207,  0.3273,  0.1948,  0.2691,  0.2235],\n        [-0.0620, -0.0032, -0.2887,  0.0779,  0.2744,  0.1422,  0.1143, -0.2636],\n        [ 0.2925,  0.0293, -0.2756,  0.1514,  0.0624, -0.2401, -0.1063, -0.0228],\n        [-0.3022, -0.2437,  0.2305, -0.0445, -0.1112, -0.2080,  0.0129, -0.3389],\n        [-0.1856,  0.1858,  0.0786, -0.1707,  0.3074,  0.2527,  0.1255,  0.2986],\n        [-0.3052,  0.0893,  0.1080,  0.0196,  0.2207, -0.3121, -0.2526, -0.2363],\n        [-0.1605,  0.2728, -0.1566,  0.1704, -0.2011, -0.0323,  0.3265, -0.2775],\n        [ 0.1293,  0.1828,  0.0535, -0.0011,  0.3468, -0.3358,  0.3480,  0.1561],\n        [-0.2720, -0.1961,  0.1862,  0.0628, -0.3144, -0.1041, -0.0881, -0.1601],\n        [-0.0313, -0.2631,  0.3412, -0.0961, -0.1060,  0.1010,  0.0931, -0.1664],\n        [-0.2188,  0.1898,  0.3386,  0.0716, -0.1417, -0.1851,  0.1359,  0.2697],\n        [-0.2523, -0.2629,  0.2039, -0.1813,  0.1402,  0.0426,  0.0135,  0.3425],\n        [ 0.0605, -0.3344,  0.1300,  0.0174, -0.1345, -0.0677,  0.3399, -0.1611],\n        [-0.0558,  0.0734, -0.0085,  0.0901, -0.0257, -0.1582, -0.0444,  0.3467],\n        [-0.0996, -0.2971,  0.2307,  0.1079, -0.2488,  0.2107, -0.1355, -0.1599],\n        [-0.1114, -0.0184,  0.0031,  0.1690,  0.3279, -0.2978, -0.3174,  0.2982],\n        [-0.2339, -0.1889, -0.2807, -0.0010,  0.2008, -0.1711,  0.0505, -0.3313],\n        [ 0.0614,  0.1857, -0.0748,  0.0615,  0.2279,  0.1833, -0.1583,  0.3232],\n        [-0.1883, -0.2808,  0.2412, -0.0874, -0.3186, -0.2565,  0.0601,  0.0858],\n        [ 0.2119,  0.3270, -0.0113,  0.3018,  0.1100, -0.0019,  0.3446,  0.2959],\n        [-0.1746,  0.0528, -0.2978,  0.1022, -0.0487,  0.0142,  0.0497, -0.2286],\n        [ 0.3189,  0.1907, -0.3405, -0.2471,  0.0552, -0.0862,  0.0566, -0.1284],\n        [-0.2487, -0.1697, -0.0283, -0.3454, -0.2159,  0.3533, -0.2608,  0.2841],\n        [ 0.1351,  0.2630,  0.2221, -0.0501, -0.0795, -0.2559, -0.0756,  0.1419],\n        [ 0.3440,  0.1565,  0.1383, -0.0847, -0.3282,  0.3025, -0.0837,  0.2252],\n        [-0.0538,  0.1739, -0.2624, -0.3261, -0.2330, -0.3490,  0.1950, -0.1399]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1272, -0.0317,  0.0160, -0.0028, -0.0582,  0.0415, -0.0146,  0.1197,\n        -0.0564,  0.0417,  0.1644,  0.1308,  0.1654,  0.0323, -0.1703,  0.0174],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.2447e-01, -7.4576e-02, -8.8400e-02,  9.4431e-02,  8.6881e-03,\n          1.3870e-01,  4.7848e-02,  1.5873e-01,  1.1732e-01, -1.5776e-02,\n         -8.8438e-02,  4.4496e-02, -9.9716e-03, -1.6394e-01,  1.6554e-01,\n          1.6454e-01,  1.7219e-01, -1.0926e-01,  4.7011e-02, -1.5651e-01,\n          1.7284e-01,  2.9000e-02,  1.0426e-01, -1.2552e-01,  1.6352e-01,\n         -8.2903e-02,  1.1980e-01, -1.6312e-01,  9.6346e-02,  2.1917e-02,\n          2.6337e-03,  1.5202e-01],\n        [ 5.1408e-02,  7.4797e-02, -1.3992e-03, -1.1699e-02,  1.5475e-01,\n          6.3532e-03, -1.1593e-02,  3.5896e-02, -1.7586e-01, -1.6403e-01,\n         -3.8912e-02, -3.4975e-02, -1.3898e-01, -1.1358e-01, -1.7184e-01,\n         -8.5144e-02, -6.6645e-02, -1.5768e-01,  1.4960e-01,  1.6725e-01,\n         -4.5967e-02,  1.0526e-01,  1.2916e-01,  1.6819e-01, -1.1949e-01,\n          4.3585e-02, -9.3524e-05, -3.8999e-02, -1.0871e-01,  1.0980e-01,\n         -1.5650e-01,  5.4078e-03],\n        [-9.5034e-02,  1.7384e-02,  2.4493e-02,  1.3087e-01,  4.7264e-02,\n         -1.0368e-01, -1.5025e-01,  8.8292e-03,  6.5308e-02, -1.5861e-01,\n          3.8867e-03, -2.8170e-02, -8.9895e-04, -1.6052e-01, -1.4358e-01,\n          1.4678e-01,  7.4774e-02, -9.1847e-02,  1.4680e-01, -1.2108e-01,\n         -7.4586e-02, -1.1783e-01,  1.1650e-01, -1.4423e-02,  2.2802e-02,\n         -6.4556e-02, -1.6205e-01, -1.3073e-01,  1.6283e-01,  1.4540e-01,\n         -3.6255e-02,  3.3695e-02],\n        [-6.4803e-04,  4.5253e-02, -1.3943e-01,  3.5549e-02, -1.3231e-01,\n         -3.8650e-02,  1.0789e-01,  2.9881e-02,  1.0510e-01,  2.1597e-02,\n          1.7550e-01,  3.3133e-02,  5.8473e-02,  8.6566e-02, -1.4832e-01,\n          4.3308e-02, -1.5291e-01, -1.3207e-01, -8.0504e-02,  4.1507e-02,\n          8.3282e-02,  1.6853e-01, -1.0749e-02, -1.6620e-01, -1.4650e-01,\n         -9.7045e-02,  6.7119e-02, -3.2068e-02,  9.0703e-02,  1.7118e-01,\n         -1.6996e-01,  8.7710e-02],\n        [-7.7730e-03,  1.6750e-02,  6.0861e-02,  5.1937e-02,  4.4604e-03,\n          1.1128e-01, -1.0976e-01,  7.2164e-03,  6.8002e-02, -9.3131e-02,\n          1.1056e-01,  1.8726e-02, -1.4579e-01, -8.7631e-02, -1.4447e-01,\n         -5.1575e-02,  3.9806e-02, -6.4497e-02, -1.3463e-01, -8.3268e-02,\n         -1.2606e-02, -1.5783e-01,  9.1242e-02,  7.7088e-02,  1.0217e-01,\n          8.3636e-02, -1.0363e-01, -8.9267e-02,  2.9169e-03,  7.1461e-03,\n          1.8634e-02,  2.0929e-03],\n        [-1.3834e-01, -4.6783e-02,  1.7287e-01,  1.1991e-01,  1.5143e-02,\n          7.5094e-02, -8.8069e-02, -5.5677e-02, -1.0078e-01,  1.1955e-01,\n         -1.8243e-02,  1.5361e-01, -1.8684e-02, -1.7630e-01, -9.9688e-02,\n          1.3055e-01, -1.5746e-01, -2.6949e-02, -1.4670e-01, -6.4853e-02,\n          1.3663e-01,  1.3794e-01,  2.0027e-02, -1.4075e-01, -3.7130e-02,\n          2.3257e-02,  1.1745e-01, -1.4108e-01,  1.1837e-01,  1.5377e-02,\n         -5.1942e-02,  2.6874e-02],\n        [ 2.1594e-02,  1.7585e-01, -1.1075e-01,  1.2617e-01,  1.2697e-01,\n         -7.8379e-02, -8.9909e-02, -5.3220e-02, -9.5780e-02, -1.4056e-01,\n         -1.1798e-01,  8.6882e-02,  1.0842e-01,  1.2787e-01,  1.6991e-01,\n          6.4854e-02,  1.0824e-01, -5.5040e-02, -6.5643e-02,  1.0259e-02,\n          6.7944e-02, -7.9653e-03, -1.1772e-01,  1.3725e-01, -8.0131e-02,\n         -5.4366e-02,  4.1638e-03,  4.2045e-02,  3.4818e-02, -7.3858e-02,\n          6.1697e-02, -1.2642e-01],\n        [ 1.5707e-01,  1.5055e-01, -2.9114e-02,  1.5355e-01,  5.6438e-02,\n         -1.7423e-01, -1.1470e-01, -3.8344e-02,  1.6864e-01,  8.4448e-02,\n          1.3674e-01, -6.0554e-03,  2.7800e-02, -2.6287e-02,  1.2923e-01,\n          2.3579e-02, -1.4856e-01, -1.6310e-01,  1.2850e-01, -1.1034e-01,\n         -4.6841e-02, -1.3598e-01,  1.2612e-01, -1.2786e-01, -1.4818e-01,\n         -1.3026e-01,  4.0316e-02, -1.6279e-01, -5.4940e-02, -4.0596e-02,\n          8.4784e-02, -1.5358e-01],\n        [-2.6956e-02, -1.1035e-01,  1.5006e-01,  5.3429e-02, -1.3546e-01,\n          6.4401e-02,  1.6706e-01,  1.3070e-01,  7.3493e-02,  7.4503e-02,\n          9.0125e-02,  9.3463e-02, -1.4396e-02,  3.4870e-02,  9.2174e-02,\n         -1.3658e-01,  1.5390e-01, -6.9858e-02, -1.2674e-01, -1.1029e-01,\n          8.0181e-02,  4.1644e-02, -6.9384e-03,  4.2838e-02, -1.6853e-01,\n          7.0809e-02,  1.6720e-01,  1.6098e-01, -1.4187e-01,  9.2253e-02,\n         -4.6067e-02,  1.5096e-01],\n        [-7.0753e-02, -1.0005e-01,  1.4697e-01,  9.6764e-02,  1.7388e-01,\n          1.0341e-01,  5.3377e-02, -1.5990e-01, -6.6146e-02,  1.4231e-01,\n          1.4658e-02,  5.7542e-02, -5.9400e-02, -1.2481e-01, -5.6511e-02,\n         -6.2389e-02,  1.5305e-01, -1.5775e-02,  4.8688e-02,  1.3346e-01,\n          1.6347e-01, -8.1953e-02,  1.4441e-01, -1.3569e-01, -7.1807e-02,\n          1.0073e-01,  1.6618e-01, -3.4784e-02,  1.5416e-01, -2.1458e-02,\n         -1.5597e-01, -1.0929e-01],\n        [-1.5253e-02, -7.0764e-02,  1.4169e-01, -1.3848e-01,  2.3363e-02,\n          5.4626e-02, -4.6435e-02, -3.9237e-03, -7.8668e-02,  3.0461e-02,\n         -5.9937e-03,  4.0144e-02, -1.7729e-03, -5.8271e-03,  1.0279e-01,\n         -8.8617e-02, -1.4850e-01, -2.7172e-02,  1.5455e-01,  9.6005e-02,\n         -7.1092e-02,  1.7381e-01, -3.2664e-02, -9.8565e-02,  8.9285e-02,\n          1.3869e-01, -3.7166e-02, -1.5360e-02, -1.2492e-01, -9.6126e-02,\n          9.1023e-02, -1.3631e-01],\n        [ 8.7280e-02, -2.1219e-02, -1.2805e-02,  5.5507e-02, -3.2635e-02,\n         -1.1111e-01, -1.6875e-01, -1.5700e-01, -5.4273e-02, -1.3359e-01,\n          5.2856e-02, -4.4300e-02,  1.2382e-02,  6.4579e-02,  7.5156e-02,\n         -1.5655e-01,  1.4960e-01,  1.2900e-01, -1.5215e-01,  3.5688e-02,\n          5.0526e-02,  1.4243e-01, -4.2332e-03, -7.7981e-02,  6.0384e-02,\n         -1.3572e-01, -7.7848e-02, -1.3896e-01,  6.7710e-02,  7.9057e-02,\n         -7.8945e-02,  5.4592e-02],\n        [ 1.5046e-01, -1.5108e-01,  2.2163e-02, -2.6162e-02,  1.5070e-01,\n         -1.2988e-01,  1.5482e-02, -2.6704e-02,  9.1901e-02, -1.1003e-01,\n         -1.7321e-01, -2.9536e-03, -1.1951e-01, -1.0151e-01, -1.9370e-02,\n         -1.7319e-01, -6.6398e-02,  1.4868e-01,  1.2400e-01, -1.1759e-01,\n         -3.3878e-03, -1.7336e-02,  5.2643e-02, -5.4369e-02, -7.3781e-02,\n         -9.0203e-02,  2.2125e-03, -1.0697e-01, -1.4638e-01, -4.3884e-02,\n          1.2102e-01,  8.3271e-03],\n        [-1.3466e-01, -1.4144e-01,  6.3691e-02, -6.8543e-02,  2.5711e-02,\n          8.4089e-02,  1.6569e-01,  2.1562e-02,  8.8232e-02, -5.0726e-02,\n         -1.3178e-01,  1.6580e-01, -1.7165e-01,  4.5947e-02,  1.4830e-01,\n         -1.4450e-01,  4.1336e-02,  9.8756e-02,  1.4083e-01, -1.4044e-01,\n          3.2872e-02, -5.0652e-02, -2.8804e-03,  3.9436e-02, -2.3302e-02,\n         -7.5315e-02,  4.7342e-02, -5.4752e-02, -1.7080e-01,  1.7234e-01,\n          1.7155e-01, -1.1502e-01],\n        [-1.1098e-01,  1.5118e-01,  1.5672e-01,  4.6584e-02,  1.0515e-01,\n         -1.1455e-01,  1.2354e-01, -1.4676e-01,  1.0621e-01, -9.4622e-02,\n         -7.2734e-02, -1.4236e-01,  1.9464e-02,  1.4085e-01, -9.6298e-02,\n         -5.1513e-02,  6.0054e-02,  1.6497e-02, -1.1258e-01,  1.6433e-01,\n         -1.9583e-02,  6.9876e-02,  9.3891e-03, -5.7957e-02,  9.3697e-02,\n         -9.8924e-02, -9.8637e-02,  1.6322e-01, -1.1902e-02,  1.4458e-02,\n          2.2494e-03, -1.2773e-01],\n        [-6.5064e-02, -2.8036e-02, -1.2729e-01,  1.5063e-01,  7.4394e-02,\n         -9.1089e-02, -8.0409e-02,  7.3030e-02, -9.4701e-02, -1.4095e-01,\n         -1.1991e-01, -2.1224e-02,  4.7945e-02, -5.3571e-02,  7.8528e-02,\n         -8.0505e-02, -3.5727e-02,  9.0337e-02,  1.1137e-01, -8.5796e-02,\n          4.2258e-02,  8.4617e-02, -4.3173e-02, -1.3174e-01,  1.5263e-01,\n         -1.2857e-01, -1.1702e-02,  1.2485e-01,  5.8152e-02,  1.6419e-01,\n          1.5897e-01, -1.2658e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0394, -0.1162,  0.0323,  0.0107,  0.0619, -0.0592, -0.1741, -0.0680],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0051, -0.0817,  0.0508,  0.0667, -0.1613,  0.0868, -0.0755, -0.0033,\n          0.2173, -0.0683, -0.2407, -0.0895,  0.2219, -0.1571, -0.1109,  0.0214],\n        [ 0.1861, -0.1359, -0.1299,  0.0969,  0.2046,  0.1461,  0.2027,  0.1836,\n          0.0940,  0.1149, -0.0403,  0.2334, -0.0080,  0.0246,  0.1291, -0.0357],\n        [ 0.1951, -0.0745,  0.1651, -0.0109, -0.1130,  0.0325,  0.1392, -0.1329,\n          0.0047,  0.0004,  0.0900,  0.1270, -0.1952, -0.1412,  0.0319, -0.0199],\n        [ 0.1633,  0.0373, -0.0291,  0.0668,  0.0805,  0.2456,  0.1186,  0.1591,\n          0.0691,  0.1855,  0.1699, -0.0252, -0.2228, -0.1258,  0.0046, -0.0664],\n        [-0.1951,  0.2006, -0.1974, -0.2112, -0.0565,  0.1926,  0.0414, -0.0644,\n          0.1804, -0.1261, -0.1560, -0.0587, -0.0498,  0.2238,  0.2000,  0.2105],\n        [-0.1042, -0.0399,  0.2117, -0.0322, -0.0420,  0.1887, -0.0502, -0.2074,\n         -0.0067, -0.1495,  0.1573,  0.2244,  0.1474,  0.0075,  0.2317, -0.0539],\n        [ 0.2418, -0.1315,  0.0224, -0.0904, -0.2262,  0.1347, -0.0229,  0.2257,\n          0.0205,  0.0816, -0.1483, -0.0408,  0.1997, -0.0843,  0.2097,  0.1441],\n        [-0.0734,  0.0165,  0.2441,  0.2440,  0.0358,  0.2109,  0.2391, -0.1413,\n         -0.1138, -0.1606,  0.1188, -0.2130,  0.0750, -0.1481, -0.0034, -0.0350]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0814, -0.2224,  0.1198,  0.3215], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2280,  0.2170, -0.2657, -0.0462,  0.0863, -0.3198,  0.3411, -0.1481],\n        [-0.0469, -0.2087, -0.1507, -0.0742, -0.2645, -0.1555, -0.0959, -0.2844],\n        [-0.3345, -0.0768,  0.0072, -0.1276, -0.1638, -0.0932,  0.1952, -0.2682],\n        [ 0.0009,  0.1903, -0.3523,  0.3083, -0.1382, -0.2053, -0.2627, -0.1693]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0549,  0.1634, -0.1923,  0.1334,  0.2794,  0.1246, -0.0620, -0.0942],\n        [ 0.1163,  0.1283,  0.0148, -0.1679,  0.3514,  0.3480, -0.1094,  0.2979],\n        [ 0.2658,  0.2385, -0.3065, -0.0172, -0.2697, -0.1992, -0.0526,  0.0734],\n        [ 0.1128, -0.2659,  0.3050,  0.2318, -0.2112,  0.1244, -0.1895,  0.0252],\n        [ 0.2455,  0.2248, -0.3218,  0.1618, -0.3123, -0.1911, -0.2330,  0.1764],\n        [-0.0651,  0.3037,  0.0064,  0.1872,  0.1596,  0.1431, -0.3420, -0.1787],\n        [ 0.1734,  0.2043, -0.0578, -0.3207,  0.3273,  0.1948,  0.2691,  0.2235],\n        [-0.0620, -0.0032, -0.2887,  0.0779,  0.2744,  0.1422,  0.1143, -0.2636],\n        [ 0.2925,  0.0293, -0.2756,  0.1514,  0.0624, -0.2401, -0.1063, -0.0228],\n        [-0.3022, -0.2437,  0.2305, -0.0445, -0.1112, -0.2080,  0.0129, -0.3389],\n        [-0.1856,  0.1858,  0.0786, -0.1707,  0.3074,  0.2527,  0.1255,  0.2986],\n        [-0.3052,  0.0893,  0.1080,  0.0196,  0.2207, -0.3121, -0.2526, -0.2363],\n        [-0.1605,  0.2728, -0.1566,  0.1704, -0.2011, -0.0323,  0.3265, -0.2775],\n        [ 0.1293,  0.1828,  0.0535, -0.0011,  0.3468, -0.3358,  0.3480,  0.1561],\n        [-0.2720, -0.1961,  0.1862,  0.0628, -0.3144, -0.1041, -0.0881, -0.1601],\n        [-0.0313, -0.2631,  0.3412, -0.0961, -0.1060,  0.1010,  0.0931, -0.1664],\n        [-0.2188,  0.1898,  0.3386,  0.0716, -0.1417, -0.1851,  0.1359,  0.2697],\n        [-0.2523, -0.2629,  0.2039, -0.1813,  0.1402,  0.0426,  0.0135,  0.3425],\n        [ 0.0605, -0.3344,  0.1300,  0.0174, -0.1345, -0.0677,  0.3399, -0.1611],\n        [-0.0558,  0.0734, -0.0085,  0.0901, -0.0257, -0.1582, -0.0444,  0.3467],\n        [-0.0996, -0.2971,  0.2307,  0.1079, -0.2488,  0.2107, -0.1355, -0.1599],\n        [-0.1114, -0.0184,  0.0031,  0.1690,  0.3279, -0.2978, -0.3174,  0.2982],\n        [-0.2339, -0.1889, -0.2807, -0.0010,  0.2008, -0.1711,  0.0505, -0.3313],\n        [ 0.0614,  0.1857, -0.0748,  0.0615,  0.2279,  0.1833, -0.1583,  0.3232],\n        [-0.1883, -0.2808,  0.2412, -0.0874, -0.3186, -0.2565,  0.0601,  0.0858],\n        [ 0.2119,  0.3270, -0.0113,  0.3018,  0.1100, -0.0019,  0.3446,  0.2959],\n        [-0.1746,  0.0528, -0.2978,  0.1022, -0.0487,  0.0142,  0.0497, -0.2286],\n        [ 0.3189,  0.1907, -0.3405, -0.2471,  0.0552, -0.0862,  0.0566, -0.1284],\n        [-0.2487, -0.1697, -0.0283, -0.3454, -0.2159,  0.3533, -0.2608,  0.2841],\n        [ 0.1351,  0.2630,  0.2221, -0.0501, -0.0795, -0.2559, -0.0756,  0.1419],\n        [ 0.3440,  0.1565,  0.1383, -0.0847, -0.3282,  0.3025, -0.0837,  0.2252],\n        [-0.0538,  0.1739, -0.2624, -0.3261, -0.2330, -0.3490,  0.1950, -0.1399]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 2.9730e-02,  4.2127e-02,  3.2267e-01,  1.4444e-01, -3.0847e-01,\n        -2.6289e-02,  2.0180e-01,  1.4357e-01,  1.7046e-01,  2.8250e-01,\n        -1.2392e-01,  1.5976e-01,  5.5733e-02, -2.8193e-01,  1.0351e-02,\n         2.6751e-01,  1.1450e-01,  1.5973e-01, -2.6285e-03, -2.9749e-01,\n        -3.3068e-04, -7.9242e-02,  1.8652e-01, -2.4974e-01,  5.7774e-02,\n         1.6688e-01,  6.7475e-02,  2.5656e-01, -3.4527e-01,  1.8672e-01,\n         4.9454e-02,  6.5889e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.2447e-01, -7.4576e-02, -8.8400e-02,  9.4431e-02,  8.6881e-03,\n          1.3870e-01,  4.7848e-02,  1.5873e-01,  1.1732e-01, -1.5776e-02,\n         -8.8438e-02,  4.4496e-02, -9.9716e-03, -1.6394e-01,  1.6554e-01,\n          1.6454e-01,  1.7219e-01, -1.0926e-01,  4.7011e-02, -1.5651e-01,\n          1.7284e-01,  2.9000e-02,  1.0426e-01, -1.2552e-01,  1.6352e-01,\n         -8.2903e-02,  1.1980e-01, -1.6312e-01,  9.6346e-02,  2.1917e-02,\n          2.6337e-03,  1.5202e-01],\n        [ 5.1408e-02,  7.4797e-02, -1.3992e-03, -1.1699e-02,  1.5475e-01,\n          6.3532e-03, -1.1593e-02,  3.5896e-02, -1.7586e-01, -1.6403e-01,\n         -3.8912e-02, -3.4975e-02, -1.3898e-01, -1.1358e-01, -1.7184e-01,\n         -8.5144e-02, -6.6645e-02, -1.5768e-01,  1.4960e-01,  1.6725e-01,\n         -4.5967e-02,  1.0526e-01,  1.2916e-01,  1.6819e-01, -1.1949e-01,\n          4.3585e-02, -9.3524e-05, -3.8999e-02, -1.0871e-01,  1.0980e-01,\n         -1.5650e-01,  5.4078e-03],\n        [-9.5034e-02,  1.7384e-02,  2.4493e-02,  1.3087e-01,  4.7264e-02,\n         -1.0368e-01, -1.5025e-01,  8.8292e-03,  6.5308e-02, -1.5861e-01,\n          3.8867e-03, -2.8170e-02, -8.9895e-04, -1.6052e-01, -1.4358e-01,\n          1.4678e-01,  7.4774e-02, -9.1847e-02,  1.4680e-01, -1.2108e-01,\n         -7.4586e-02, -1.1783e-01,  1.1650e-01, -1.4423e-02,  2.2802e-02,\n         -6.4556e-02, -1.6205e-01, -1.3073e-01,  1.6283e-01,  1.4540e-01,\n         -3.6255e-02,  3.3695e-02],\n        [-6.4803e-04,  4.5253e-02, -1.3943e-01,  3.5549e-02, -1.3231e-01,\n         -3.8650e-02,  1.0789e-01,  2.9881e-02,  1.0510e-01,  2.1597e-02,\n          1.7550e-01,  3.3133e-02,  5.8473e-02,  8.6566e-02, -1.4832e-01,\n          4.3308e-02, -1.5291e-01, -1.3207e-01, -8.0504e-02,  4.1507e-02,\n          8.3282e-02,  1.6853e-01, -1.0749e-02, -1.6620e-01, -1.4650e-01,\n         -9.7045e-02,  6.7119e-02, -3.2068e-02,  9.0703e-02,  1.7118e-01,\n         -1.6996e-01,  8.7710e-02],\n        [-7.7730e-03,  1.6750e-02,  6.0861e-02,  5.1937e-02,  4.4604e-03,\n          1.1128e-01, -1.0976e-01,  7.2164e-03,  6.8002e-02, -9.3131e-02,\n          1.1056e-01,  1.8726e-02, -1.4579e-01, -8.7631e-02, -1.4447e-01,\n         -5.1575e-02,  3.9806e-02, -6.4497e-02, -1.3463e-01, -8.3268e-02,\n         -1.2606e-02, -1.5783e-01,  9.1242e-02,  7.7088e-02,  1.0217e-01,\n          8.3636e-02, -1.0363e-01, -8.9267e-02,  2.9169e-03,  7.1461e-03,\n          1.8634e-02,  2.0929e-03],\n        [-1.3834e-01, -4.6783e-02,  1.7287e-01,  1.1991e-01,  1.5143e-02,\n          7.5094e-02, -8.8069e-02, -5.5677e-02, -1.0078e-01,  1.1955e-01,\n         -1.8243e-02,  1.5361e-01, -1.8684e-02, -1.7630e-01, -9.9688e-02,\n          1.3055e-01, -1.5746e-01, -2.6949e-02, -1.4670e-01, -6.4853e-02,\n          1.3663e-01,  1.3794e-01,  2.0027e-02, -1.4075e-01, -3.7130e-02,\n          2.3257e-02,  1.1745e-01, -1.4108e-01,  1.1837e-01,  1.5377e-02,\n         -5.1942e-02,  2.6874e-02],\n        [ 2.1594e-02,  1.7585e-01, -1.1075e-01,  1.2617e-01,  1.2697e-01,\n         -7.8379e-02, -8.9909e-02, -5.3220e-02, -9.5780e-02, -1.4056e-01,\n         -1.1798e-01,  8.6882e-02,  1.0842e-01,  1.2787e-01,  1.6991e-01,\n          6.4854e-02,  1.0824e-01, -5.5040e-02, -6.5643e-02,  1.0259e-02,\n          6.7944e-02, -7.9653e-03, -1.1772e-01,  1.3725e-01, -8.0131e-02,\n         -5.4366e-02,  4.1638e-03,  4.2045e-02,  3.4818e-02, -7.3858e-02,\n          6.1697e-02, -1.2642e-01],\n        [ 1.5707e-01,  1.5055e-01, -2.9114e-02,  1.5355e-01,  5.6438e-02,\n         -1.7423e-01, -1.1470e-01, -3.8344e-02,  1.6864e-01,  8.4448e-02,\n          1.3674e-01, -6.0554e-03,  2.7800e-02, -2.6287e-02,  1.2923e-01,\n          2.3579e-02, -1.4856e-01, -1.6310e-01,  1.2850e-01, -1.1034e-01,\n         -4.6841e-02, -1.3598e-01,  1.2612e-01, -1.2786e-01, -1.4818e-01,\n         -1.3026e-01,  4.0316e-02, -1.6279e-01, -5.4940e-02, -4.0596e-02,\n          8.4784e-02, -1.5358e-01],\n        [-2.6956e-02, -1.1035e-01,  1.5006e-01,  5.3429e-02, -1.3546e-01,\n          6.4401e-02,  1.6706e-01,  1.3070e-01,  7.3493e-02,  7.4503e-02,\n          9.0125e-02,  9.3463e-02, -1.4396e-02,  3.4870e-02,  9.2174e-02,\n         -1.3658e-01,  1.5390e-01, -6.9858e-02, -1.2674e-01, -1.1029e-01,\n          8.0181e-02,  4.1644e-02, -6.9384e-03,  4.2838e-02, -1.6853e-01,\n          7.0809e-02,  1.6720e-01,  1.6098e-01, -1.4187e-01,  9.2253e-02,\n         -4.6067e-02,  1.5096e-01],\n        [-7.0753e-02, -1.0005e-01,  1.4697e-01,  9.6764e-02,  1.7388e-01,\n          1.0341e-01,  5.3377e-02, -1.5990e-01, -6.6146e-02,  1.4231e-01,\n          1.4658e-02,  5.7542e-02, -5.9400e-02, -1.2481e-01, -5.6511e-02,\n         -6.2389e-02,  1.5305e-01, -1.5775e-02,  4.8688e-02,  1.3346e-01,\n          1.6347e-01, -8.1953e-02,  1.4441e-01, -1.3569e-01, -7.1807e-02,\n          1.0073e-01,  1.6618e-01, -3.4784e-02,  1.5416e-01, -2.1458e-02,\n         -1.5597e-01, -1.0929e-01],\n        [-1.5253e-02, -7.0764e-02,  1.4169e-01, -1.3848e-01,  2.3363e-02,\n          5.4626e-02, -4.6435e-02, -3.9237e-03, -7.8668e-02,  3.0461e-02,\n         -5.9937e-03,  4.0144e-02, -1.7729e-03, -5.8271e-03,  1.0279e-01,\n         -8.8617e-02, -1.4850e-01, -2.7172e-02,  1.5455e-01,  9.6005e-02,\n         -7.1092e-02,  1.7381e-01, -3.2664e-02, -9.8565e-02,  8.9285e-02,\n          1.3869e-01, -3.7166e-02, -1.5360e-02, -1.2492e-01, -9.6126e-02,\n          9.1023e-02, -1.3631e-01],\n        [ 8.7280e-02, -2.1219e-02, -1.2805e-02,  5.5507e-02, -3.2635e-02,\n         -1.1111e-01, -1.6875e-01, -1.5700e-01, -5.4273e-02, -1.3359e-01,\n          5.2856e-02, -4.4300e-02,  1.2382e-02,  6.4579e-02,  7.5156e-02,\n         -1.5655e-01,  1.4960e-01,  1.2900e-01, -1.5215e-01,  3.5688e-02,\n          5.0526e-02,  1.4243e-01, -4.2332e-03, -7.7981e-02,  6.0384e-02,\n         -1.3572e-01, -7.7848e-02, -1.3896e-01,  6.7710e-02,  7.9057e-02,\n         -7.8945e-02,  5.4592e-02],\n        [ 1.5046e-01, -1.5108e-01,  2.2163e-02, -2.6162e-02,  1.5070e-01,\n         -1.2988e-01,  1.5482e-02, -2.6704e-02,  9.1901e-02, -1.1003e-01,\n         -1.7321e-01, -2.9536e-03, -1.1951e-01, -1.0151e-01, -1.9370e-02,\n         -1.7319e-01, -6.6398e-02,  1.4868e-01,  1.2400e-01, -1.1759e-01,\n         -3.3878e-03, -1.7336e-02,  5.2643e-02, -5.4369e-02, -7.3781e-02,\n         -9.0203e-02,  2.2125e-03, -1.0697e-01, -1.4638e-01, -4.3884e-02,\n          1.2102e-01,  8.3271e-03],\n        [-1.3466e-01, -1.4144e-01,  6.3691e-02, -6.8543e-02,  2.5711e-02,\n          8.4089e-02,  1.6569e-01,  2.1562e-02,  8.8232e-02, -5.0726e-02,\n         -1.3178e-01,  1.6580e-01, -1.7165e-01,  4.5947e-02,  1.4830e-01,\n         -1.4450e-01,  4.1336e-02,  9.8756e-02,  1.4083e-01, -1.4044e-01,\n          3.2872e-02, -5.0652e-02, -2.8804e-03,  3.9436e-02, -2.3302e-02,\n         -7.5315e-02,  4.7342e-02, -5.4752e-02, -1.7080e-01,  1.7234e-01,\n          1.7155e-01, -1.1502e-01],\n        [-1.1098e-01,  1.5118e-01,  1.5672e-01,  4.6584e-02,  1.0515e-01,\n         -1.1455e-01,  1.2354e-01, -1.4676e-01,  1.0621e-01, -9.4622e-02,\n         -7.2734e-02, -1.4236e-01,  1.9464e-02,  1.4085e-01, -9.6298e-02,\n         -5.1513e-02,  6.0054e-02,  1.6497e-02, -1.1258e-01,  1.6433e-01,\n         -1.9583e-02,  6.9876e-02,  9.3891e-03, -5.7957e-02,  9.3697e-02,\n         -9.8924e-02, -9.8637e-02,  1.6322e-01, -1.1902e-02,  1.4458e-02,\n          2.2494e-03, -1.2773e-01],\n        [-6.5064e-02, -2.8036e-02, -1.2729e-01,  1.5063e-01,  7.4394e-02,\n         -9.1089e-02, -8.0409e-02,  7.3030e-02, -9.4701e-02, -1.4095e-01,\n         -1.1991e-01, -2.1224e-02,  4.7945e-02, -5.3571e-02,  7.8528e-02,\n         -8.0505e-02, -3.5727e-02,  9.0337e-02,  1.1137e-01, -8.5796e-02,\n          4.2258e-02,  8.4617e-02, -4.3173e-02, -1.3174e-01,  1.5263e-01,\n         -1.2857e-01, -1.1702e-02,  1.2485e-01,  5.8152e-02,  1.6419e-01,\n          1.5897e-01, -1.2658e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1272, -0.0317,  0.0160, -0.0028, -0.0582,  0.0415, -0.0146,  0.1197,\n        -0.0564,  0.0417,  0.1644,  0.1308,  0.1654,  0.0323, -0.1703,  0.0174],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0051, -0.0817,  0.0508,  0.0667, -0.1613,  0.0868, -0.0755, -0.0033,\n          0.2173, -0.0683, -0.2407, -0.0895,  0.2219, -0.1571, -0.1109,  0.0214],\n        [ 0.1861, -0.1359, -0.1299,  0.0969,  0.2046,  0.1461,  0.2027,  0.1836,\n          0.0940,  0.1149, -0.0403,  0.2334, -0.0080,  0.0246,  0.1291, -0.0357],\n        [ 0.1951, -0.0745,  0.1651, -0.0109, -0.1130,  0.0325,  0.1392, -0.1329,\n          0.0047,  0.0004,  0.0900,  0.1270, -0.1952, -0.1412,  0.0319, -0.0199],\n        [ 0.1633,  0.0373, -0.0291,  0.0668,  0.0805,  0.2456,  0.1186,  0.1591,\n          0.0691,  0.1855,  0.1699, -0.0252, -0.2228, -0.1258,  0.0046, -0.0664],\n        [-0.1951,  0.2006, -0.1974, -0.2112, -0.0565,  0.1926,  0.0414, -0.0644,\n          0.1804, -0.1261, -0.1560, -0.0587, -0.0498,  0.2238,  0.2000,  0.2105],\n        [-0.1042, -0.0399,  0.2117, -0.0322, -0.0420,  0.1887, -0.0502, -0.2074,\n         -0.0067, -0.1495,  0.1573,  0.2244,  0.1474,  0.0075,  0.2317, -0.0539],\n        [ 0.2418, -0.1315,  0.0224, -0.0904, -0.2262,  0.1347, -0.0229,  0.2257,\n          0.0205,  0.0816, -0.1483, -0.0408,  0.1997, -0.0843,  0.2097,  0.1441],\n        [-0.0734,  0.0165,  0.2441,  0.2440,  0.0358,  0.2109,  0.2391, -0.1413,\n         -0.1138, -0.1606,  0.1188, -0.2130,  0.0750, -0.1481, -0.0034, -0.0350]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0394, -0.1162,  0.0323,  0.0107,  0.0619, -0.0592, -0.1741, -0.0680],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2280,  0.2170, -0.2657, -0.0462,  0.0863, -0.3198,  0.3411, -0.1481],\n        [-0.0469, -0.2087, -0.1507, -0.0742, -0.2645, -0.1555, -0.0959, -0.2844],\n        [-0.3345, -0.0768,  0.0072, -0.1276, -0.1638, -0.0932,  0.1952, -0.2682],\n        [ 0.0009,  0.1903, -0.3523,  0.3083, -0.1382, -0.2053, -0.2627, -0.1693]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0814, -0.2224,  0.1198,  0.3215], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.stale_replay_buffer.StaleReplayBuffer object at 0x790b97f45ad0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.15,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 2.9730e-02,  4.2127e-02,  3.2267e-01,  1.4444e-01, -3.0847e-01,\n        -2.6289e-02,  2.0180e-01,  1.4357e-01,  1.7046e-01,  2.8250e-01,\n        -1.2392e-01,  1.5976e-01,  5.5733e-02, -2.8193e-01,  1.0351e-02,\n         2.6751e-01,  1.1450e-01,  1.5973e-01, -2.6285e-03, -2.9749e-01,\n        -3.3068e-04, -7.9242e-02,  1.8652e-01, -2.4974e-01,  5.7774e-02,\n         1.6688e-01,  6.7475e-02,  2.5656e-01, -3.4527e-01,  1.8672e-01,\n         4.9454e-02,  6.5889e-02], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0549,  0.1634, -0.1923,  0.1334,  0.2794,  0.1246, -0.0620, -0.0942],\n        [ 0.1163,  0.1283,  0.0148, -0.1679,  0.3514,  0.3480, -0.1094,  0.2979],\n        [ 0.2658,  0.2385, -0.3065, -0.0172, -0.2697, -0.1992, -0.0526,  0.0734],\n        [ 0.1128, -0.2659,  0.3050,  0.2318, -0.2112,  0.1244, -0.1895,  0.0252],\n        [ 0.2455,  0.2248, -0.3218,  0.1618, -0.3123, -0.1911, -0.2330,  0.1764],\n        [-0.0651,  0.3037,  0.0064,  0.1872,  0.1596,  0.1431, -0.3420, -0.1787],\n        [ 0.1734,  0.2043, -0.0578, -0.3207,  0.3273,  0.1948,  0.2691,  0.2235],\n        [-0.0620, -0.0032, -0.2887,  0.0779,  0.2744,  0.1422,  0.1143, -0.2636],\n        [ 0.2925,  0.0293, -0.2756,  0.1514,  0.0624, -0.2401, -0.1063, -0.0228],\n        [-0.3022, -0.2437,  0.2305, -0.0445, -0.1112, -0.2080,  0.0129, -0.3389],\n        [-0.1856,  0.1858,  0.0786, -0.1707,  0.3074,  0.2527,  0.1255,  0.2986],\n        [-0.3052,  0.0893,  0.1080,  0.0196,  0.2207, -0.3121, -0.2526, -0.2363],\n        [-0.1605,  0.2728, -0.1566,  0.1704, -0.2011, -0.0323,  0.3265, -0.2775],\n        [ 0.1293,  0.1828,  0.0535, -0.0011,  0.3468, -0.3358,  0.3480,  0.1561],\n        [-0.2720, -0.1961,  0.1862,  0.0628, -0.3144, -0.1041, -0.0881, -0.1601],\n        [-0.0313, -0.2631,  0.3412, -0.0961, -0.1060,  0.1010,  0.0931, -0.1664],\n        [-0.2188,  0.1898,  0.3386,  0.0716, -0.1417, -0.1851,  0.1359,  0.2697],\n        [-0.2523, -0.2629,  0.2039, -0.1813,  0.1402,  0.0426,  0.0135,  0.3425],\n        [ 0.0605, -0.3344,  0.1300,  0.0174, -0.1345, -0.0677,  0.3399, -0.1611],\n        [-0.0558,  0.0734, -0.0085,  0.0901, -0.0257, -0.1582, -0.0444,  0.3467],\n        [-0.0996, -0.2971,  0.2307,  0.1079, -0.2488,  0.2107, -0.1355, -0.1599],\n        [-0.1114, -0.0184,  0.0031,  0.1690,  0.3279, -0.2978, -0.3174,  0.2982],\n        [-0.2339, -0.1889, -0.2807, -0.0010,  0.2008, -0.1711,  0.0505, -0.3313],\n        [ 0.0614,  0.1857, -0.0748,  0.0615,  0.2279,  0.1833, -0.1583,  0.3232],\n        [-0.1883, -0.2808,  0.2412, -0.0874, -0.3186, -0.2565,  0.0601,  0.0858],\n        [ 0.2119,  0.3270, -0.0113,  0.3018,  0.1100, -0.0019,  0.3446,  0.2959],\n        [-0.1746,  0.0528, -0.2978,  0.1022, -0.0487,  0.0142,  0.0497, -0.2286],\n        [ 0.3189,  0.1907, -0.3405, -0.2471,  0.0552, -0.0862,  0.0566, -0.1284],\n        [-0.2487, -0.1697, -0.0283, -0.3454, -0.2159,  0.3533, -0.2608,  0.2841],\n        [ 0.1351,  0.2630,  0.2221, -0.0501, -0.0795, -0.2559, -0.0756,  0.1419],\n        [ 0.3440,  0.1565,  0.1383, -0.0847, -0.3282,  0.3025, -0.0837,  0.2252],\n        [-0.0538,  0.1739, -0.2624, -0.3261, -0.2330, -0.3490,  0.1950, -0.1399]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1272, -0.0317,  0.0160, -0.0028, -0.0582,  0.0415, -0.0146,  0.1197,\n        -0.0564,  0.0417,  0.1644,  0.1308,  0.1654,  0.0323, -0.1703,  0.0174],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.2447e-01, -7.4576e-02, -8.8400e-02,  9.4431e-02,  8.6881e-03,\n          1.3870e-01,  4.7848e-02,  1.5873e-01,  1.1732e-01, -1.5776e-02,\n         -8.8438e-02,  4.4496e-02, -9.9716e-03, -1.6394e-01,  1.6554e-01,\n          1.6454e-01,  1.7219e-01, -1.0926e-01,  4.7011e-02, -1.5651e-01,\n          1.7284e-01,  2.9000e-02,  1.0426e-01, -1.2552e-01,  1.6352e-01,\n         -8.2903e-02,  1.1980e-01, -1.6312e-01,  9.6346e-02,  2.1917e-02,\n          2.6337e-03,  1.5202e-01],\n        [ 5.1408e-02,  7.4797e-02, -1.3992e-03, -1.1699e-02,  1.5475e-01,\n          6.3532e-03, -1.1593e-02,  3.5896e-02, -1.7586e-01, -1.6403e-01,\n         -3.8912e-02, -3.4975e-02, -1.3898e-01, -1.1358e-01, -1.7184e-01,\n         -8.5144e-02, -6.6645e-02, -1.5768e-01,  1.4960e-01,  1.6725e-01,\n         -4.5967e-02,  1.0526e-01,  1.2916e-01,  1.6819e-01, -1.1949e-01,\n          4.3585e-02, -9.3524e-05, -3.8999e-02, -1.0871e-01,  1.0980e-01,\n         -1.5650e-01,  5.4078e-03],\n        [-9.5034e-02,  1.7384e-02,  2.4493e-02,  1.3087e-01,  4.7264e-02,\n         -1.0368e-01, -1.5025e-01,  8.8292e-03,  6.5308e-02, -1.5861e-01,\n          3.8867e-03, -2.8170e-02, -8.9895e-04, -1.6052e-01, -1.4358e-01,\n          1.4678e-01,  7.4774e-02, -9.1847e-02,  1.4680e-01, -1.2108e-01,\n         -7.4586e-02, -1.1783e-01,  1.1650e-01, -1.4423e-02,  2.2802e-02,\n         -6.4556e-02, -1.6205e-01, -1.3073e-01,  1.6283e-01,  1.4540e-01,\n         -3.6255e-02,  3.3695e-02],\n        [-6.4803e-04,  4.5253e-02, -1.3943e-01,  3.5549e-02, -1.3231e-01,\n         -3.8650e-02,  1.0789e-01,  2.9881e-02,  1.0510e-01,  2.1597e-02,\n          1.7550e-01,  3.3133e-02,  5.8473e-02,  8.6566e-02, -1.4832e-01,\n          4.3308e-02, -1.5291e-01, -1.3207e-01, -8.0504e-02,  4.1507e-02,\n          8.3282e-02,  1.6853e-01, -1.0749e-02, -1.6620e-01, -1.4650e-01,\n         -9.7045e-02,  6.7119e-02, -3.2068e-02,  9.0703e-02,  1.7118e-01,\n         -1.6996e-01,  8.7710e-02],\n        [-7.7730e-03,  1.6750e-02,  6.0861e-02,  5.1937e-02,  4.4604e-03,\n          1.1128e-01, -1.0976e-01,  7.2164e-03,  6.8002e-02, -9.3131e-02,\n          1.1056e-01,  1.8726e-02, -1.4579e-01, -8.7631e-02, -1.4447e-01,\n         -5.1575e-02,  3.9806e-02, -6.4497e-02, -1.3463e-01, -8.3268e-02,\n         -1.2606e-02, -1.5783e-01,  9.1242e-02,  7.7088e-02,  1.0217e-01,\n          8.3636e-02, -1.0363e-01, -8.9267e-02,  2.9169e-03,  7.1461e-03,\n          1.8634e-02,  2.0929e-03],\n        [-1.3834e-01, -4.6783e-02,  1.7287e-01,  1.1991e-01,  1.5143e-02,\n          7.5094e-02, -8.8069e-02, -5.5677e-02, -1.0078e-01,  1.1955e-01,\n         -1.8243e-02,  1.5361e-01, -1.8684e-02, -1.7630e-01, -9.9688e-02,\n          1.3055e-01, -1.5746e-01, -2.6949e-02, -1.4670e-01, -6.4853e-02,\n          1.3663e-01,  1.3794e-01,  2.0027e-02, -1.4075e-01, -3.7130e-02,\n          2.3257e-02,  1.1745e-01, -1.4108e-01,  1.1837e-01,  1.5377e-02,\n         -5.1942e-02,  2.6874e-02],\n        [ 2.1594e-02,  1.7585e-01, -1.1075e-01,  1.2617e-01,  1.2697e-01,\n         -7.8379e-02, -8.9909e-02, -5.3220e-02, -9.5780e-02, -1.4056e-01,\n         -1.1798e-01,  8.6882e-02,  1.0842e-01,  1.2787e-01,  1.6991e-01,\n          6.4854e-02,  1.0824e-01, -5.5040e-02, -6.5643e-02,  1.0259e-02,\n          6.7944e-02, -7.9653e-03, -1.1772e-01,  1.3725e-01, -8.0131e-02,\n         -5.4366e-02,  4.1638e-03,  4.2045e-02,  3.4818e-02, -7.3858e-02,\n          6.1697e-02, -1.2642e-01],\n        [ 1.5707e-01,  1.5055e-01, -2.9114e-02,  1.5355e-01,  5.6438e-02,\n         -1.7423e-01, -1.1470e-01, -3.8344e-02,  1.6864e-01,  8.4448e-02,\n          1.3674e-01, -6.0554e-03,  2.7800e-02, -2.6287e-02,  1.2923e-01,\n          2.3579e-02, -1.4856e-01, -1.6310e-01,  1.2850e-01, -1.1034e-01,\n         -4.6841e-02, -1.3598e-01,  1.2612e-01, -1.2786e-01, -1.4818e-01,\n         -1.3026e-01,  4.0316e-02, -1.6279e-01, -5.4940e-02, -4.0596e-02,\n          8.4784e-02, -1.5358e-01],\n        [-2.6956e-02, -1.1035e-01,  1.5006e-01,  5.3429e-02, -1.3546e-01,\n          6.4401e-02,  1.6706e-01,  1.3070e-01,  7.3493e-02,  7.4503e-02,\n          9.0125e-02,  9.3463e-02, -1.4396e-02,  3.4870e-02,  9.2174e-02,\n         -1.3658e-01,  1.5390e-01, -6.9858e-02, -1.2674e-01, -1.1029e-01,\n          8.0181e-02,  4.1644e-02, -6.9384e-03,  4.2838e-02, -1.6853e-01,\n          7.0809e-02,  1.6720e-01,  1.6098e-01, -1.4187e-01,  9.2253e-02,\n         -4.6067e-02,  1.5096e-01],\n        [-7.0753e-02, -1.0005e-01,  1.4697e-01,  9.6764e-02,  1.7388e-01,\n          1.0341e-01,  5.3377e-02, -1.5990e-01, -6.6146e-02,  1.4231e-01,\n          1.4658e-02,  5.7542e-02, -5.9400e-02, -1.2481e-01, -5.6511e-02,\n         -6.2389e-02,  1.5305e-01, -1.5775e-02,  4.8688e-02,  1.3346e-01,\n          1.6347e-01, -8.1953e-02,  1.4441e-01, -1.3569e-01, -7.1807e-02,\n          1.0073e-01,  1.6618e-01, -3.4784e-02,  1.5416e-01, -2.1458e-02,\n         -1.5597e-01, -1.0929e-01],\n        [-1.5253e-02, -7.0764e-02,  1.4169e-01, -1.3848e-01,  2.3363e-02,\n          5.4626e-02, -4.6435e-02, -3.9237e-03, -7.8668e-02,  3.0461e-02,\n         -5.9937e-03,  4.0144e-02, -1.7729e-03, -5.8271e-03,  1.0279e-01,\n         -8.8617e-02, -1.4850e-01, -2.7172e-02,  1.5455e-01,  9.6005e-02,\n         -7.1092e-02,  1.7381e-01, -3.2664e-02, -9.8565e-02,  8.9285e-02,\n          1.3869e-01, -3.7166e-02, -1.5360e-02, -1.2492e-01, -9.6126e-02,\n          9.1023e-02, -1.3631e-01],\n        [ 8.7280e-02, -2.1219e-02, -1.2805e-02,  5.5507e-02, -3.2635e-02,\n         -1.1111e-01, -1.6875e-01, -1.5700e-01, -5.4273e-02, -1.3359e-01,\n          5.2856e-02, -4.4300e-02,  1.2382e-02,  6.4579e-02,  7.5156e-02,\n         -1.5655e-01,  1.4960e-01,  1.2900e-01, -1.5215e-01,  3.5688e-02,\n          5.0526e-02,  1.4243e-01, -4.2332e-03, -7.7981e-02,  6.0384e-02,\n         -1.3572e-01, -7.7848e-02, -1.3896e-01,  6.7710e-02,  7.9057e-02,\n         -7.8945e-02,  5.4592e-02],\n        [ 1.5046e-01, -1.5108e-01,  2.2163e-02, -2.6162e-02,  1.5070e-01,\n         -1.2988e-01,  1.5482e-02, -2.6704e-02,  9.1901e-02, -1.1003e-01,\n         -1.7321e-01, -2.9536e-03, -1.1951e-01, -1.0151e-01, -1.9370e-02,\n         -1.7319e-01, -6.6398e-02,  1.4868e-01,  1.2400e-01, -1.1759e-01,\n         -3.3878e-03, -1.7336e-02,  5.2643e-02, -5.4369e-02, -7.3781e-02,\n         -9.0203e-02,  2.2125e-03, -1.0697e-01, -1.4638e-01, -4.3884e-02,\n          1.2102e-01,  8.3271e-03],\n        [-1.3466e-01, -1.4144e-01,  6.3691e-02, -6.8543e-02,  2.5711e-02,\n          8.4089e-02,  1.6569e-01,  2.1562e-02,  8.8232e-02, -5.0726e-02,\n         -1.3178e-01,  1.6580e-01, -1.7165e-01,  4.5947e-02,  1.4830e-01,\n         -1.4450e-01,  4.1336e-02,  9.8756e-02,  1.4083e-01, -1.4044e-01,\n          3.2872e-02, -5.0652e-02, -2.8804e-03,  3.9436e-02, -2.3302e-02,\n         -7.5315e-02,  4.7342e-02, -5.4752e-02, -1.7080e-01,  1.7234e-01,\n          1.7155e-01, -1.1502e-01],\n        [-1.1098e-01,  1.5118e-01,  1.5672e-01,  4.6584e-02,  1.0515e-01,\n         -1.1455e-01,  1.2354e-01, -1.4676e-01,  1.0621e-01, -9.4622e-02,\n         -7.2734e-02, -1.4236e-01,  1.9464e-02,  1.4085e-01, -9.6298e-02,\n         -5.1513e-02,  6.0054e-02,  1.6497e-02, -1.1258e-01,  1.6433e-01,\n         -1.9583e-02,  6.9876e-02,  9.3891e-03, -5.7957e-02,  9.3697e-02,\n         -9.8924e-02, -9.8637e-02,  1.6322e-01, -1.1902e-02,  1.4458e-02,\n          2.2494e-03, -1.2773e-01],\n        [-6.5064e-02, -2.8036e-02, -1.2729e-01,  1.5063e-01,  7.4394e-02,\n         -9.1089e-02, -8.0409e-02,  7.3030e-02, -9.4701e-02, -1.4095e-01,\n         -1.1991e-01, -2.1224e-02,  4.7945e-02, -5.3571e-02,  7.8528e-02,\n         -8.0505e-02, -3.5727e-02,  9.0337e-02,  1.1137e-01, -8.5796e-02,\n          4.2258e-02,  8.4617e-02, -4.3173e-02, -1.3174e-01,  1.5263e-01,\n         -1.2857e-01, -1.1702e-02,  1.2485e-01,  5.8152e-02,  1.6419e-01,\n          1.5897e-01, -1.2658e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0394, -0.1162,  0.0323,  0.0107,  0.0619, -0.0592, -0.1741, -0.0680],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0051, -0.0817,  0.0508,  0.0667, -0.1613,  0.0868, -0.0755, -0.0033,\n          0.2173, -0.0683, -0.2407, -0.0895,  0.2219, -0.1571, -0.1109,  0.0214],\n        [ 0.1861, -0.1359, -0.1299,  0.0969,  0.2046,  0.1461,  0.2027,  0.1836,\n          0.0940,  0.1149, -0.0403,  0.2334, -0.0080,  0.0246,  0.1291, -0.0357],\n        [ 0.1951, -0.0745,  0.1651, -0.0109, -0.1130,  0.0325,  0.1392, -0.1329,\n          0.0047,  0.0004,  0.0900,  0.1270, -0.1952, -0.1412,  0.0319, -0.0199],\n        [ 0.1633,  0.0373, -0.0291,  0.0668,  0.0805,  0.2456,  0.1186,  0.1591,\n          0.0691,  0.1855,  0.1699, -0.0252, -0.2228, -0.1258,  0.0046, -0.0664],\n        [-0.1951,  0.2006, -0.1974, -0.2112, -0.0565,  0.1926,  0.0414, -0.0644,\n          0.1804, -0.1261, -0.1560, -0.0587, -0.0498,  0.2238,  0.2000,  0.2105],\n        [-0.1042, -0.0399,  0.2117, -0.0322, -0.0420,  0.1887, -0.0502, -0.2074,\n         -0.0067, -0.1495,  0.1573,  0.2244,  0.1474,  0.0075,  0.2317, -0.0539],\n        [ 0.2418, -0.1315,  0.0224, -0.0904, -0.2262,  0.1347, -0.0229,  0.2257,\n          0.0205,  0.0816, -0.1483, -0.0408,  0.1997, -0.0843,  0.2097,  0.1441],\n        [-0.0734,  0.0165,  0.2441,  0.2440,  0.0358,  0.2109,  0.2391, -0.1413,\n         -0.1138, -0.1606,  0.1188, -0.2130,  0.0750, -0.1481, -0.0034, -0.0350]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0814, -0.2224,  0.1198,  0.3215], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2280,  0.2170, -0.2657, -0.0462,  0.0863, -0.3198,  0.3411, -0.1481],\n        [-0.0469, -0.2087, -0.1507, -0.0742, -0.2645, -0.1555, -0.0959, -0.2844],\n        [-0.3345, -0.0768,  0.0072, -0.1276, -0.1638, -0.0932,  0.1952, -0.2682],\n        [ 0.0009,  0.1903, -0.3523,  0.3083, -0.1382, -0.2053, -0.2627, -0.1693]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x790b96700650>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s81070000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s81070000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}