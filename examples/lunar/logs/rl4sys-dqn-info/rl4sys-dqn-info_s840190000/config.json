{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	4,
    "batch_size":	60,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0007,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s840190000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0005,
    "sample_decay":	0.5,
    "seed":	840190000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x790cb01383d0>":	{
            "_act_dim":	4,
            "_aux_batch_size":	4,
            "_batch_size":	60,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0007,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0626,  0.0195, -0.2009,  0.3503, -0.0013,  0.2020,  0.3098, -0.3394,\n        -0.1280,  0.1192,  0.2400, -0.0507,  0.2941,  0.1111, -0.0566,  0.3105,\n         0.2560,  0.1449,  0.3322,  0.0557, -0.3256, -0.2551, -0.1172, -0.0179,\n        -0.2459,  0.0173,  0.2376, -0.1434, -0.2680,  0.2123,  0.0108, -0.3218],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1102, -0.2187,  0.2526, -0.3519,  0.1611,  0.2519, -0.0166,  0.2837],\n        [-0.2037, -0.2770,  0.3180,  0.2777, -0.2136,  0.1569,  0.0909,  0.2668],\n        [-0.2411, -0.1916,  0.1509, -0.2750, -0.2277, -0.1678, -0.2604, -0.0214],\n        [-0.0893,  0.1746, -0.2599,  0.0094, -0.1600,  0.1175,  0.0625,  0.0707],\n        [ 0.0746, -0.1236,  0.3397,  0.2299,  0.1659, -0.0373, -0.0814,  0.0149],\n        [-0.0572,  0.1862,  0.2466, -0.0735,  0.2773, -0.0594,  0.2841, -0.3192],\n        [ 0.2753,  0.1140,  0.2210, -0.3309,  0.2437,  0.3354,  0.0292, -0.3410],\n        [-0.3359, -0.0942, -0.2946,  0.2509,  0.0330,  0.3316,  0.0819, -0.2225],\n        [-0.1800, -0.1631,  0.0112, -0.1185, -0.0158,  0.2142,  0.1666,  0.0749],\n        [ 0.1933, -0.2848, -0.1968, -0.1194, -0.2663, -0.1669,  0.2571, -0.2282],\n        [-0.3235,  0.0533,  0.0907, -0.0263, -0.2770,  0.3031, -0.1873,  0.0698],\n        [-0.1387,  0.1975,  0.3481, -0.2098,  0.2392, -0.0164, -0.3414, -0.2731],\n        [-0.2166, -0.1949,  0.3157,  0.2872,  0.2659, -0.3476,  0.1687,  0.1451],\n        [ 0.1091,  0.0320, -0.2145, -0.1989,  0.2062,  0.2708,  0.0495, -0.3224],\n        [-0.2954,  0.1078, -0.2482,  0.1326,  0.2964,  0.2654,  0.0315, -0.1657],\n        [-0.2654, -0.3453, -0.2357, -0.1478,  0.0104, -0.1978, -0.2028,  0.3426],\n        [ 0.2984, -0.0521, -0.2737, -0.0268,  0.0330,  0.0688, -0.3479, -0.2156],\n        [ 0.2650,  0.0156, -0.0861, -0.3146,  0.2289, -0.3510,  0.2081,  0.1200],\n        [ 0.3372, -0.0015, -0.2581, -0.0349,  0.1835,  0.0774, -0.0428, -0.2023],\n        [-0.3043,  0.3255,  0.3281,  0.0024,  0.0447, -0.0722, -0.2681,  0.3411],\n        [-0.3114,  0.3469, -0.2390, -0.1174,  0.1015,  0.2330,  0.2648,  0.2753],\n        [-0.2879,  0.1675,  0.3160,  0.0556,  0.2580, -0.0462, -0.1587, -0.1544],\n        [ 0.2989, -0.3334, -0.3143,  0.1974,  0.1647, -0.2970,  0.1113,  0.1899],\n        [-0.0647,  0.1199,  0.1044,  0.0847, -0.1491, -0.3102, -0.3039, -0.0532],\n        [ 0.1724, -0.2494, -0.0881, -0.0701,  0.2225,  0.2156, -0.2047,  0.2796],\n        [-0.2831,  0.1228, -0.1517,  0.3303, -0.0170,  0.2701, -0.2776, -0.2610],\n        [ 0.0494,  0.2692, -0.1487, -0.0578,  0.3222, -0.2819, -0.3253,  0.0882],\n        [-0.2627, -0.0284, -0.0733, -0.2413, -0.0114, -0.0291,  0.2837,  0.2929],\n        [-0.3354,  0.0449,  0.1783, -0.1059,  0.3426,  0.1642, -0.1195, -0.0585],\n        [ 0.1936,  0.2508,  0.0540,  0.0429,  0.1101,  0.3051, -0.0909,  0.2674],\n        [ 0.0184,  0.2678, -0.1607,  0.2629, -0.2242, -0.2367,  0.3200, -0.1944],\n        [ 0.1132,  0.0799, -0.2641,  0.2261, -0.3467, -0.1362,  0.1286, -0.2825]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0829, -0.1146,  0.1663, -0.0267,  0.1429, -0.1049,  0.0824,  0.1471,\n        -0.0156, -0.0447,  0.1650,  0.1084,  0.0656,  0.1729,  0.1420,  0.0201],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0742e-01,  4.8616e-02,  1.1764e-01,  1.3326e-01,  1.4610e-01,\n          8.8086e-02,  1.4830e-01,  1.3878e-02, -7.8523e-02, -8.8853e-02,\n          2.0826e-02,  2.2868e-02, -5.6688e-02,  5.4127e-02, -1.6946e-01,\n         -1.4199e-01, -3.1077e-02,  1.1331e-01,  1.0921e-01, -6.7617e-02,\n         -1.5370e-01,  9.0852e-02,  5.1788e-02, -6.3546e-02, -1.5562e-01,\n         -5.4393e-02, -1.1266e-01,  2.3978e-02, -6.5178e-03, -1.0588e-01,\n          4.6175e-02, -1.4447e-02],\n        [-1.5367e-01,  7.6356e-02, -1.1307e-01, -1.0488e-01, -2.1226e-02,\n         -4.6649e-02, -6.6295e-03,  2.9144e-02, -1.1850e-01,  1.7266e-01,\n          4.1968e-02, -1.6288e-01, -5.1171e-02,  1.4673e-01, -1.0804e-01,\n          1.6381e-01, -1.7165e-01, -7.1547e-02,  8.6112e-02,  1.5774e-02,\n         -4.3331e-02,  4.1093e-02,  1.5738e-01, -9.0633e-02,  6.9631e-02,\n         -8.0522e-02, -2.0706e-02, -1.7373e-02,  1.7071e-02,  1.0935e-01,\n         -1.4440e-01,  1.2713e-01],\n        [-6.2029e-02,  7.9136e-03, -1.7479e-01, -1.2550e-01,  1.6283e-01,\n         -1.0445e-01,  5.7339e-02,  9.1286e-02, -9.6999e-02,  4.3452e-02,\n         -1.2563e-01, -1.1488e-01, -1.1589e-02,  4.8104e-02, -4.9875e-02,\n          9.8006e-02, -2.8010e-02, -9.8871e-02,  1.5908e-02,  1.4862e-01,\n          3.7024e-02,  8.0488e-02,  1.6828e-01,  6.5175e-02, -6.1315e-02,\n          9.1139e-03,  1.1071e-01, -3.4031e-02, -5.8351e-02, -1.6534e-01,\n         -1.2785e-01, -1.0337e-01],\n        [ 5.7374e-02,  1.6552e-01,  1.6536e-02,  1.0960e-01, -1.3434e-01,\n          1.5390e-01,  1.1612e-01, -9.0628e-02, -1.3321e-01, -5.5449e-02,\n         -1.4499e-01, -3.9872e-03, -1.6533e-01, -8.2473e-02, -2.2638e-02,\n         -9.7247e-02,  9.6787e-02,  5.5834e-03,  1.1568e-01,  1.2948e-01,\n          2.3973e-02, -1.0852e-01, -5.6148e-02,  1.4132e-01, -1.3896e-01,\n         -1.1197e-01,  1.0060e-01, -7.5742e-02,  9.4556e-02, -1.4662e-01,\n          8.1606e-02, -1.1367e-03],\n        [-1.0927e-01,  9.4711e-02, -1.4169e-01,  1.0900e-01, -1.5179e-01,\n          1.6791e-01, -1.3671e-02, -3.6066e-02, -1.2197e-01, -1.7454e-01,\n          1.0146e-01, -6.2540e-02, -1.6060e-01, -1.6247e-01,  1.3345e-01,\n         -9.1805e-02,  1.3589e-01, -5.6451e-02,  1.1696e-01, -1.3934e-01,\n          1.3203e-01,  6.6364e-02,  2.6374e-02,  5.1799e-02,  3.1147e-02,\n         -1.1397e-02, -1.7586e-01, -3.1225e-02, -1.4119e-01,  1.3994e-01,\n          1.1868e-02, -1.0581e-01],\n        [-6.6028e-02, -4.4586e-02, -1.3203e-01, -6.6250e-02,  1.1761e-01,\n         -1.1742e-01, -4.4446e-02, -7.3226e-03,  3.0750e-02,  1.1237e-01,\n         -1.3428e-01, -1.1979e-01,  1.2253e-01,  2.7953e-02,  5.9357e-02,\n         -7.9451e-02, -9.2690e-03,  2.5879e-02,  3.9663e-02,  9.6245e-03,\n          6.2664e-04, -5.4934e-02, -1.5126e-01,  8.2111e-02, -1.5599e-01,\n         -9.2297e-03, -7.1418e-02,  1.7422e-01,  1.2145e-01, -2.8169e-03,\n         -4.8614e-02,  1.1824e-01],\n        [-4.2037e-02, -1.0178e-01, -1.4503e-01,  1.7050e-01, -1.1876e-01,\n         -1.0729e-02,  1.3131e-02,  2.3846e-02,  1.6840e-01, -8.8324e-03,\n          8.6637e-02,  7.0579e-02, -8.3544e-02, -1.4110e-01, -9.9760e-02,\n         -1.0962e-02, -8.7991e-02, -2.7047e-02, -1.5565e-01,  1.0162e-01,\n          1.2363e-01, -1.7460e-01, -5.9335e-02, -1.1496e-01, -5.3475e-03,\n          1.6239e-01, -4.8906e-02,  1.4408e-01, -1.0647e-01, -7.4988e-03,\n         -9.3269e-02,  1.3815e-01],\n        [ 1.3002e-02, -1.0453e-02,  1.5402e-01, -1.4811e-01, -3.7583e-02,\n         -1.1748e-01, -2.9033e-02, -2.2191e-02,  1.5149e-01,  4.3807e-02,\n          1.2233e-01, -9.0391e-02, -1.3272e-01, -1.6318e-01,  1.2225e-01,\n         -9.3717e-02,  1.7380e-01,  1.6782e-01,  5.7327e-02,  1.7497e-01,\n         -1.4069e-01,  1.5337e-02,  1.7398e-01, -1.5671e-01,  5.3883e-02,\n         -1.3644e-01,  9.2343e-02,  1.0453e-01,  6.8382e-02,  1.6203e-04,\n          1.3126e-01, -1.1025e-01],\n        [-5.9891e-02, -1.6560e-01,  6.9160e-03, -3.1225e-02, -6.9286e-02,\n         -5.2848e-02,  2.3785e-02, -1.5303e-02,  1.2814e-01, -1.5648e-01,\n         -1.0342e-01, -5.9909e-02, -1.2770e-01, -2.4125e-02, -6.3022e-02,\n          1.2569e-01, -1.1344e-01, -2.9476e-02, -1.2075e-01,  6.8968e-02,\n          7.6552e-02, -1.0809e-01, -2.5723e-02, -4.6705e-02,  1.7435e-03,\n         -1.5898e-01, -1.2896e-01, -1.6611e-01,  7.7058e-02,  6.5376e-02,\n          1.0279e-01, -3.2167e-02],\n        [-2.3100e-02,  1.7494e-01, -1.5574e-01, -1.1391e-01,  8.5795e-02,\n         -1.7037e-01, -7.6580e-02, -1.5751e-01, -1.5866e-01, -1.2470e-01,\n         -7.6006e-02, -5.2697e-02, -5.8984e-02,  1.0609e-01, -1.7203e-01,\n          1.5253e-01, -5.3048e-02,  3.5192e-02,  6.0925e-02, -1.7558e-01,\n          2.0665e-03, -2.1181e-02, -1.3846e-01, -2.0822e-02, -1.7268e-01,\n          9.2148e-03, -1.3697e-01, -2.9976e-02,  3.4613e-02,  2.6676e-02,\n         -1.2866e-01, -1.1962e-01],\n        [-4.8282e-02,  5.1542e-02,  1.5999e-02, -4.7185e-02,  8.3514e-05,\n          2.9420e-02,  3.7320e-02, -4.1562e-02, -1.6040e-01, -2.9032e-02,\n         -1.5285e-01, -8.6766e-02,  1.9196e-02,  1.1462e-01,  9.3654e-02,\n         -2.0777e-02,  7.5983e-02,  1.6068e-01, -1.4131e-01, -1.0989e-01,\n         -1.5183e-01, -1.6324e-01,  3.8706e-02,  6.8750e-02,  1.1045e-01,\n          1.3162e-03,  1.7427e-01,  1.6766e-01,  6.8366e-02,  3.2812e-02,\n          6.1187e-02, -9.4594e-02],\n        [-1.0989e-01, -6.8019e-02, -5.0899e-02, -1.6332e-01, -1.3456e-01,\n         -1.1824e-01, -1.2655e-01, -8.5339e-02, -1.2033e-01, -1.1299e-01,\n          7.7404e-03, -3.2997e-03,  8.3730e-02,  8.2707e-02,  7.6590e-02,\n          2.2331e-02, -1.2694e-01, -6.8128e-02,  4.4261e-02,  8.7712e-02,\n         -1.5781e-01,  7.4417e-02, -1.7003e-01, -1.6370e-02,  3.3868e-02,\n          1.7610e-01,  6.7269e-02, -4.0407e-03, -1.4817e-01,  6.6624e-02,\n          1.8777e-03, -1.4389e-01],\n        [ 1.5648e-01,  2.9956e-02, -1.5018e-01,  2.0153e-02,  1.5016e-01,\n         -1.7499e-01,  1.4430e-01,  2.5893e-03,  1.1923e-01,  1.2076e-01,\n         -4.9776e-02,  9.0364e-02, -3.6460e-02, -8.3931e-02, -6.6453e-02,\n         -1.4004e-01,  1.5904e-01,  2.7122e-02,  1.5755e-01, -4.3732e-02,\n         -2.2365e-02,  1.4236e-01,  1.8887e-02, -6.5289e-02,  1.5768e-01,\n          8.9984e-02, -7.2922e-02, -1.1008e-01,  1.5392e-01,  1.3533e-03,\n          1.1138e-01, -1.0178e-01],\n        [-6.6871e-02, -2.9322e-02,  4.9721e-02,  6.0650e-02, -7.3159e-02,\n         -1.0000e-01, -4.0559e-02, -2.4927e-02,  1.5531e-01, -6.2133e-02,\n         -1.4760e-01, -1.3513e-02, -1.2692e-01, -1.5899e-01, -9.2812e-02,\n          2.0453e-02,  1.5874e-01,  1.3669e-01,  9.3000e-03, -1.1313e-01,\n         -7.5380e-02, -3.0840e-03,  2.5587e-02,  2.0003e-02,  2.6372e-02,\n          1.6635e-01, -7.3014e-03,  1.3852e-01,  1.6964e-02, -4.4283e-03,\n         -5.8380e-02,  1.1409e-01],\n        [ 1.0126e-01,  4.8558e-02, -1.4765e-01, -1.6721e-01,  1.4825e-01,\n          1.7204e-01,  6.1203e-02, -1.7316e-02,  1.2891e-01, -1.4992e-02,\n         -1.2889e-01, -1.4878e-02, -9.1708e-03,  1.1033e-01, -1.4120e-01,\n          1.0290e-01,  1.8681e-02, -1.4052e-01, -2.6409e-02, -8.8216e-03,\n          1.2208e-01, -1.4967e-01,  1.3288e-01,  1.0537e-01, -1.2437e-01,\n          1.3648e-02, -9.3536e-02, -1.6315e-02,  4.8205e-02,  1.7175e-01,\n         -5.9290e-02,  6.9624e-02],\n        [ 2.2721e-02, -1.4563e-01, -1.5585e-01,  1.5893e-01, -1.2227e-01,\n          7.4481e-03,  4.2192e-02,  1.9732e-02, -3.5261e-02, -5.3860e-02,\n          8.2206e-02, -7.9729e-03,  1.1534e-01, -1.1285e-01,  1.4511e-03,\n          4.8290e-03,  6.1617e-03,  2.9589e-02,  1.5276e-01, -1.5286e-01,\n         -1.1911e-01, -1.2078e-01, -1.4769e-01,  6.5401e-02,  9.4569e-02,\n          1.7287e-01, -9.9632e-02, -1.3695e-01, -7.3780e-02, -1.2104e-01,\n         -1.5777e-01,  8.1747e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1468,  0.0512,  0.1413, -0.1160, -0.0636,  0.1374,  0.1969,  0.0386],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2431,  0.2140, -0.0715,  0.1095,  0.1712,  0.0783, -0.2226, -0.2338,\n          0.2497, -0.1700, -0.1096, -0.0722,  0.0564, -0.0111, -0.1809, -0.0933],\n        [-0.2241, -0.0057,  0.0849,  0.2378,  0.2088,  0.0127, -0.1865, -0.2153,\n          0.2065,  0.0144,  0.1659, -0.1937, -0.0288,  0.0354, -0.0445,  0.1677],\n        [ 0.0145,  0.0845,  0.1219, -0.1211,  0.1765,  0.1341, -0.0713, -0.1912,\n          0.0573,  0.0481,  0.1840,  0.0360, -0.1465, -0.1111,  0.2256,  0.0111],\n        [-0.0572, -0.0637,  0.0372, -0.1194,  0.1401, -0.0092, -0.1034,  0.1963,\n         -0.1736, -0.0620,  0.2030,  0.2279,  0.1565, -0.0290, -0.1895, -0.0878],\n        [ 0.0669, -0.2257,  0.1917,  0.1539, -0.1072, -0.0604,  0.1440, -0.0911,\n          0.2220, -0.0064, -0.1761,  0.0903,  0.1112,  0.2005, -0.1292, -0.0656],\n        [ 0.1211, -0.1752, -0.0144, -0.1412, -0.1727,  0.1632, -0.1879, -0.0123,\n         -0.1871, -0.2347,  0.0279,  0.1352,  0.0843, -0.2256,  0.0699,  0.0838],\n        [ 0.1439,  0.1195, -0.0492,  0.2028,  0.1444,  0.0263, -0.1267, -0.0304,\n         -0.2495, -0.1077, -0.0314,  0.2150,  0.1989,  0.1335,  0.1257,  0.1249],\n        [ 0.2205, -0.1683,  0.0295,  0.1384,  0.0556,  0.1183,  0.1667, -0.1712,\n          0.1758,  0.2096,  0.0844, -0.0783,  0.1146,  0.2464,  0.0183, -0.2062]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0082, 0.2932, 0.0159, 0.2783], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1979,  0.1423, -0.1492,  0.0801,  0.0760,  0.3329,  0.2814, -0.3188],\n        [ 0.2773,  0.1921, -0.0575,  0.1064, -0.1303,  0.0396, -0.1144, -0.3472],\n        [-0.1633,  0.3308, -0.0481,  0.2784, -0.0544,  0.2804,  0.0127, -0.2294],\n        [ 0.2761,  0.0643, -0.2524, -0.3458, -0.3151, -0.3024,  0.3094,  0.1220]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1102, -0.2187,  0.2526, -0.3519,  0.1611,  0.2519, -0.0166,  0.2837],\n        [-0.2037, -0.2770,  0.3180,  0.2777, -0.2136,  0.1569,  0.0909,  0.2668],\n        [-0.2411, -0.1916,  0.1509, -0.2750, -0.2277, -0.1678, -0.2604, -0.0214],\n        [-0.0893,  0.1746, -0.2599,  0.0094, -0.1600,  0.1175,  0.0625,  0.0707],\n        [ 0.0746, -0.1236,  0.3397,  0.2299,  0.1659, -0.0373, -0.0814,  0.0149],\n        [-0.0572,  0.1862,  0.2466, -0.0735,  0.2773, -0.0594,  0.2841, -0.3192],\n        [ 0.2753,  0.1140,  0.2210, -0.3309,  0.2437,  0.3354,  0.0292, -0.3410],\n        [-0.3359, -0.0942, -0.2946,  0.2509,  0.0330,  0.3316,  0.0819, -0.2225],\n        [-0.1800, -0.1631,  0.0112, -0.1185, -0.0158,  0.2142,  0.1666,  0.0749],\n        [ 0.1933, -0.2848, -0.1968, -0.1194, -0.2663, -0.1669,  0.2571, -0.2282],\n        [-0.3235,  0.0533,  0.0907, -0.0263, -0.2770,  0.3031, -0.1873,  0.0698],\n        [-0.1387,  0.1975,  0.3481, -0.2098,  0.2392, -0.0164, -0.3414, -0.2731],\n        [-0.2166, -0.1949,  0.3157,  0.2872,  0.2659, -0.3476,  0.1687,  0.1451],\n        [ 0.1091,  0.0320, -0.2145, -0.1989,  0.2062,  0.2708,  0.0495, -0.3224],\n        [-0.2954,  0.1078, -0.2482,  0.1326,  0.2964,  0.2654,  0.0315, -0.1657],\n        [-0.2654, -0.3453, -0.2357, -0.1478,  0.0104, -0.1978, -0.2028,  0.3426],\n        [ 0.2984, -0.0521, -0.2737, -0.0268,  0.0330,  0.0688, -0.3479, -0.2156],\n        [ 0.2650,  0.0156, -0.0861, -0.3146,  0.2289, -0.3510,  0.2081,  0.1200],\n        [ 0.3372, -0.0015, -0.2581, -0.0349,  0.1835,  0.0774, -0.0428, -0.2023],\n        [-0.3043,  0.3255,  0.3281,  0.0024,  0.0447, -0.0722, -0.2681,  0.3411],\n        [-0.3114,  0.3469, -0.2390, -0.1174,  0.1015,  0.2330,  0.2648,  0.2753],\n        [-0.2879,  0.1675,  0.3160,  0.0556,  0.2580, -0.0462, -0.1587, -0.1544],\n        [ 0.2989, -0.3334, -0.3143,  0.1974,  0.1647, -0.2970,  0.1113,  0.1899],\n        [-0.0647,  0.1199,  0.1044,  0.0847, -0.1491, -0.3102, -0.3039, -0.0532],\n        [ 0.1724, -0.2494, -0.0881, -0.0701,  0.2225,  0.2156, -0.2047,  0.2796],\n        [-0.2831,  0.1228, -0.1517,  0.3303, -0.0170,  0.2701, -0.2776, -0.2610],\n        [ 0.0494,  0.2692, -0.1487, -0.0578,  0.3222, -0.2819, -0.3253,  0.0882],\n        [-0.2627, -0.0284, -0.0733, -0.2413, -0.0114, -0.0291,  0.2837,  0.2929],\n        [-0.3354,  0.0449,  0.1783, -0.1059,  0.3426,  0.1642, -0.1195, -0.0585],\n        [ 0.1936,  0.2508,  0.0540,  0.0429,  0.1101,  0.3051, -0.0909,  0.2674],\n        [ 0.0184,  0.2678, -0.1607,  0.2629, -0.2242, -0.2367,  0.3200, -0.1944],\n        [ 0.1132,  0.0799, -0.2641,  0.2261, -0.3467, -0.1362,  0.1286, -0.2825]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0626,  0.0195, -0.2009,  0.3503, -0.0013,  0.2020,  0.3098, -0.3394,\n        -0.1280,  0.1192,  0.2400, -0.0507,  0.2941,  0.1111, -0.0566,  0.3105,\n         0.2560,  0.1449,  0.3322,  0.0557, -0.3256, -0.2551, -0.1172, -0.0179,\n        -0.2459,  0.0173,  0.2376, -0.1434, -0.2680,  0.2123,  0.0108, -0.3218],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.0742e-01,  4.8616e-02,  1.1764e-01,  1.3326e-01,  1.4610e-01,\n          8.8086e-02,  1.4830e-01,  1.3878e-02, -7.8523e-02, -8.8853e-02,\n          2.0826e-02,  2.2868e-02, -5.6688e-02,  5.4127e-02, -1.6946e-01,\n         -1.4199e-01, -3.1077e-02,  1.1331e-01,  1.0921e-01, -6.7617e-02,\n         -1.5370e-01,  9.0852e-02,  5.1788e-02, -6.3546e-02, -1.5562e-01,\n         -5.4393e-02, -1.1266e-01,  2.3978e-02, -6.5178e-03, -1.0588e-01,\n          4.6175e-02, -1.4447e-02],\n        [-1.5367e-01,  7.6356e-02, -1.1307e-01, -1.0488e-01, -2.1226e-02,\n         -4.6649e-02, -6.6295e-03,  2.9144e-02, -1.1850e-01,  1.7266e-01,\n          4.1968e-02, -1.6288e-01, -5.1171e-02,  1.4673e-01, -1.0804e-01,\n          1.6381e-01, -1.7165e-01, -7.1547e-02,  8.6112e-02,  1.5774e-02,\n         -4.3331e-02,  4.1093e-02,  1.5738e-01, -9.0633e-02,  6.9631e-02,\n         -8.0522e-02, -2.0706e-02, -1.7373e-02,  1.7071e-02,  1.0935e-01,\n         -1.4440e-01,  1.2713e-01],\n        [-6.2029e-02,  7.9136e-03, -1.7479e-01, -1.2550e-01,  1.6283e-01,\n         -1.0445e-01,  5.7339e-02,  9.1286e-02, -9.6999e-02,  4.3452e-02,\n         -1.2563e-01, -1.1488e-01, -1.1589e-02,  4.8104e-02, -4.9875e-02,\n          9.8006e-02, -2.8010e-02, -9.8871e-02,  1.5908e-02,  1.4862e-01,\n          3.7024e-02,  8.0488e-02,  1.6828e-01,  6.5175e-02, -6.1315e-02,\n          9.1139e-03,  1.1071e-01, -3.4031e-02, -5.8351e-02, -1.6534e-01,\n         -1.2785e-01, -1.0337e-01],\n        [ 5.7374e-02,  1.6552e-01,  1.6536e-02,  1.0960e-01, -1.3434e-01,\n          1.5390e-01,  1.1612e-01, -9.0628e-02, -1.3321e-01, -5.5449e-02,\n         -1.4499e-01, -3.9872e-03, -1.6533e-01, -8.2473e-02, -2.2638e-02,\n         -9.7247e-02,  9.6787e-02,  5.5834e-03,  1.1568e-01,  1.2948e-01,\n          2.3973e-02, -1.0852e-01, -5.6148e-02,  1.4132e-01, -1.3896e-01,\n         -1.1197e-01,  1.0060e-01, -7.5742e-02,  9.4556e-02, -1.4662e-01,\n          8.1606e-02, -1.1367e-03],\n        [-1.0927e-01,  9.4711e-02, -1.4169e-01,  1.0900e-01, -1.5179e-01,\n          1.6791e-01, -1.3671e-02, -3.6066e-02, -1.2197e-01, -1.7454e-01,\n          1.0146e-01, -6.2540e-02, -1.6060e-01, -1.6247e-01,  1.3345e-01,\n         -9.1805e-02,  1.3589e-01, -5.6451e-02,  1.1696e-01, -1.3934e-01,\n          1.3203e-01,  6.6364e-02,  2.6374e-02,  5.1799e-02,  3.1147e-02,\n         -1.1397e-02, -1.7586e-01, -3.1225e-02, -1.4119e-01,  1.3994e-01,\n          1.1868e-02, -1.0581e-01],\n        [-6.6028e-02, -4.4586e-02, -1.3203e-01, -6.6250e-02,  1.1761e-01,\n         -1.1742e-01, -4.4446e-02, -7.3226e-03,  3.0750e-02,  1.1237e-01,\n         -1.3428e-01, -1.1979e-01,  1.2253e-01,  2.7953e-02,  5.9357e-02,\n         -7.9451e-02, -9.2690e-03,  2.5879e-02,  3.9663e-02,  9.6245e-03,\n          6.2664e-04, -5.4934e-02, -1.5126e-01,  8.2111e-02, -1.5599e-01,\n         -9.2297e-03, -7.1418e-02,  1.7422e-01,  1.2145e-01, -2.8169e-03,\n         -4.8614e-02,  1.1824e-01],\n        [-4.2037e-02, -1.0178e-01, -1.4503e-01,  1.7050e-01, -1.1876e-01,\n         -1.0729e-02,  1.3131e-02,  2.3846e-02,  1.6840e-01, -8.8324e-03,\n          8.6637e-02,  7.0579e-02, -8.3544e-02, -1.4110e-01, -9.9760e-02,\n         -1.0962e-02, -8.7991e-02, -2.7047e-02, -1.5565e-01,  1.0162e-01,\n          1.2363e-01, -1.7460e-01, -5.9335e-02, -1.1496e-01, -5.3475e-03,\n          1.6239e-01, -4.8906e-02,  1.4408e-01, -1.0647e-01, -7.4988e-03,\n         -9.3269e-02,  1.3815e-01],\n        [ 1.3002e-02, -1.0453e-02,  1.5402e-01, -1.4811e-01, -3.7583e-02,\n         -1.1748e-01, -2.9033e-02, -2.2191e-02,  1.5149e-01,  4.3807e-02,\n          1.2233e-01, -9.0391e-02, -1.3272e-01, -1.6318e-01,  1.2225e-01,\n         -9.3717e-02,  1.7380e-01,  1.6782e-01,  5.7327e-02,  1.7497e-01,\n         -1.4069e-01,  1.5337e-02,  1.7398e-01, -1.5671e-01,  5.3883e-02,\n         -1.3644e-01,  9.2343e-02,  1.0453e-01,  6.8382e-02,  1.6203e-04,\n          1.3126e-01, -1.1025e-01],\n        [-5.9891e-02, -1.6560e-01,  6.9160e-03, -3.1225e-02, -6.9286e-02,\n         -5.2848e-02,  2.3785e-02, -1.5303e-02,  1.2814e-01, -1.5648e-01,\n         -1.0342e-01, -5.9909e-02, -1.2770e-01, -2.4125e-02, -6.3022e-02,\n          1.2569e-01, -1.1344e-01, -2.9476e-02, -1.2075e-01,  6.8968e-02,\n          7.6552e-02, -1.0809e-01, -2.5723e-02, -4.6705e-02,  1.7435e-03,\n         -1.5898e-01, -1.2896e-01, -1.6611e-01,  7.7058e-02,  6.5376e-02,\n          1.0279e-01, -3.2167e-02],\n        [-2.3100e-02,  1.7494e-01, -1.5574e-01, -1.1391e-01,  8.5795e-02,\n         -1.7037e-01, -7.6580e-02, -1.5751e-01, -1.5866e-01, -1.2470e-01,\n         -7.6006e-02, -5.2697e-02, -5.8984e-02,  1.0609e-01, -1.7203e-01,\n          1.5253e-01, -5.3048e-02,  3.5192e-02,  6.0925e-02, -1.7558e-01,\n          2.0665e-03, -2.1181e-02, -1.3846e-01, -2.0822e-02, -1.7268e-01,\n          9.2148e-03, -1.3697e-01, -2.9976e-02,  3.4613e-02,  2.6676e-02,\n         -1.2866e-01, -1.1962e-01],\n        [-4.8282e-02,  5.1542e-02,  1.5999e-02, -4.7185e-02,  8.3514e-05,\n          2.9420e-02,  3.7320e-02, -4.1562e-02, -1.6040e-01, -2.9032e-02,\n         -1.5285e-01, -8.6766e-02,  1.9196e-02,  1.1462e-01,  9.3654e-02,\n         -2.0777e-02,  7.5983e-02,  1.6068e-01, -1.4131e-01, -1.0989e-01,\n         -1.5183e-01, -1.6324e-01,  3.8706e-02,  6.8750e-02,  1.1045e-01,\n          1.3162e-03,  1.7427e-01,  1.6766e-01,  6.8366e-02,  3.2812e-02,\n          6.1187e-02, -9.4594e-02],\n        [-1.0989e-01, -6.8019e-02, -5.0899e-02, -1.6332e-01, -1.3456e-01,\n         -1.1824e-01, -1.2655e-01, -8.5339e-02, -1.2033e-01, -1.1299e-01,\n          7.7404e-03, -3.2997e-03,  8.3730e-02,  8.2707e-02,  7.6590e-02,\n          2.2331e-02, -1.2694e-01, -6.8128e-02,  4.4261e-02,  8.7712e-02,\n         -1.5781e-01,  7.4417e-02, -1.7003e-01, -1.6370e-02,  3.3868e-02,\n          1.7610e-01,  6.7269e-02, -4.0407e-03, -1.4817e-01,  6.6624e-02,\n          1.8777e-03, -1.4389e-01],\n        [ 1.5648e-01,  2.9956e-02, -1.5018e-01,  2.0153e-02,  1.5016e-01,\n         -1.7499e-01,  1.4430e-01,  2.5893e-03,  1.1923e-01,  1.2076e-01,\n         -4.9776e-02,  9.0364e-02, -3.6460e-02, -8.3931e-02, -6.6453e-02,\n         -1.4004e-01,  1.5904e-01,  2.7122e-02,  1.5755e-01, -4.3732e-02,\n         -2.2365e-02,  1.4236e-01,  1.8887e-02, -6.5289e-02,  1.5768e-01,\n          8.9984e-02, -7.2922e-02, -1.1008e-01,  1.5392e-01,  1.3533e-03,\n          1.1138e-01, -1.0178e-01],\n        [-6.6871e-02, -2.9322e-02,  4.9721e-02,  6.0650e-02, -7.3159e-02,\n         -1.0000e-01, -4.0559e-02, -2.4927e-02,  1.5531e-01, -6.2133e-02,\n         -1.4760e-01, -1.3513e-02, -1.2692e-01, -1.5899e-01, -9.2812e-02,\n          2.0453e-02,  1.5874e-01,  1.3669e-01,  9.3000e-03, -1.1313e-01,\n         -7.5380e-02, -3.0840e-03,  2.5587e-02,  2.0003e-02,  2.6372e-02,\n          1.6635e-01, -7.3014e-03,  1.3852e-01,  1.6964e-02, -4.4283e-03,\n         -5.8380e-02,  1.1409e-01],\n        [ 1.0126e-01,  4.8558e-02, -1.4765e-01, -1.6721e-01,  1.4825e-01,\n          1.7204e-01,  6.1203e-02, -1.7316e-02,  1.2891e-01, -1.4992e-02,\n         -1.2889e-01, -1.4878e-02, -9.1708e-03,  1.1033e-01, -1.4120e-01,\n          1.0290e-01,  1.8681e-02, -1.4052e-01, -2.6409e-02, -8.8216e-03,\n          1.2208e-01, -1.4967e-01,  1.3288e-01,  1.0537e-01, -1.2437e-01,\n          1.3648e-02, -9.3536e-02, -1.6315e-02,  4.8205e-02,  1.7175e-01,\n         -5.9290e-02,  6.9624e-02],\n        [ 2.2721e-02, -1.4563e-01, -1.5585e-01,  1.5893e-01, -1.2227e-01,\n          7.4481e-03,  4.2192e-02,  1.9732e-02, -3.5261e-02, -5.3860e-02,\n          8.2206e-02, -7.9729e-03,  1.1534e-01, -1.1285e-01,  1.4511e-03,\n          4.8290e-03,  6.1617e-03,  2.9589e-02,  1.5276e-01, -1.5286e-01,\n         -1.1911e-01, -1.2078e-01, -1.4769e-01,  6.5401e-02,  9.4569e-02,\n          1.7287e-01, -9.9632e-02, -1.3695e-01, -7.3780e-02, -1.2104e-01,\n         -1.5777e-01,  8.1747e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0829, -0.1146,  0.1663, -0.0267,  0.1429, -0.1049,  0.0824,  0.1471,\n        -0.0156, -0.0447,  0.1650,  0.1084,  0.0656,  0.1729,  0.1420,  0.0201],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2431,  0.2140, -0.0715,  0.1095,  0.1712,  0.0783, -0.2226, -0.2338,\n          0.2497, -0.1700, -0.1096, -0.0722,  0.0564, -0.0111, -0.1809, -0.0933],\n        [-0.2241, -0.0057,  0.0849,  0.2378,  0.2088,  0.0127, -0.1865, -0.2153,\n          0.2065,  0.0144,  0.1659, -0.1937, -0.0288,  0.0354, -0.0445,  0.1677],\n        [ 0.0145,  0.0845,  0.1219, -0.1211,  0.1765,  0.1341, -0.0713, -0.1912,\n          0.0573,  0.0481,  0.1840,  0.0360, -0.1465, -0.1111,  0.2256,  0.0111],\n        [-0.0572, -0.0637,  0.0372, -0.1194,  0.1401, -0.0092, -0.1034,  0.1963,\n         -0.1736, -0.0620,  0.2030,  0.2279,  0.1565, -0.0290, -0.1895, -0.0878],\n        [ 0.0669, -0.2257,  0.1917,  0.1539, -0.1072, -0.0604,  0.1440, -0.0911,\n          0.2220, -0.0064, -0.1761,  0.0903,  0.1112,  0.2005, -0.1292, -0.0656],\n        [ 0.1211, -0.1752, -0.0144, -0.1412, -0.1727,  0.1632, -0.1879, -0.0123,\n         -0.1871, -0.2347,  0.0279,  0.1352,  0.0843, -0.2256,  0.0699,  0.0838],\n        [ 0.1439,  0.1195, -0.0492,  0.2028,  0.1444,  0.0263, -0.1267, -0.0304,\n         -0.2495, -0.1077, -0.0314,  0.2150,  0.1989,  0.1335,  0.1257,  0.1249],\n        [ 0.2205, -0.1683,  0.0295,  0.1384,  0.0556,  0.1183,  0.1667, -0.1712,\n          0.1758,  0.2096,  0.0844, -0.0783,  0.1146,  0.2464,  0.0183, -0.2062]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1468,  0.0512,  0.1413, -0.1160, -0.0636,  0.1374,  0.1969,  0.0386],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1979,  0.1423, -0.1492,  0.0801,  0.0760,  0.3329,  0.2814, -0.3188],\n        [ 0.2773,  0.1921, -0.0575,  0.1064, -0.1303,  0.0396, -0.1144, -0.3472],\n        [-0.1633,  0.3308, -0.0481,  0.2784, -0.0544,  0.2804,  0.0127, -0.2294],\n        [ 0.2761,  0.0643, -0.2524, -0.3458, -0.3151, -0.3024,  0.3094,  0.1220]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0082, 0.2932, 0.0159, 0.2783], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x790d20fdc0d0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x790cb1aa2d90>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0626,  0.0195, -0.2009,  0.3503, -0.0013,  0.2020,  0.3098, -0.3394,\n        -0.1280,  0.1192,  0.2400, -0.0507,  0.2941,  0.1111, -0.0566,  0.3105,\n         0.2560,  0.1449,  0.3322,  0.0557, -0.3256, -0.2551, -0.1172, -0.0179,\n        -0.2459,  0.0173,  0.2376, -0.1434, -0.2680,  0.2123,  0.0108, -0.3218],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1102, -0.2187,  0.2526, -0.3519,  0.1611,  0.2519, -0.0166,  0.2837],\n        [-0.2037, -0.2770,  0.3180,  0.2777, -0.2136,  0.1569,  0.0909,  0.2668],\n        [-0.2411, -0.1916,  0.1509, -0.2750, -0.2277, -0.1678, -0.2604, -0.0214],\n        [-0.0893,  0.1746, -0.2599,  0.0094, -0.1600,  0.1175,  0.0625,  0.0707],\n        [ 0.0746, -0.1236,  0.3397,  0.2299,  0.1659, -0.0373, -0.0814,  0.0149],\n        [-0.0572,  0.1862,  0.2466, -0.0735,  0.2773, -0.0594,  0.2841, -0.3192],\n        [ 0.2753,  0.1140,  0.2210, -0.3309,  0.2437,  0.3354,  0.0292, -0.3410],\n        [-0.3359, -0.0942, -0.2946,  0.2509,  0.0330,  0.3316,  0.0819, -0.2225],\n        [-0.1800, -0.1631,  0.0112, -0.1185, -0.0158,  0.2142,  0.1666,  0.0749],\n        [ 0.1933, -0.2848, -0.1968, -0.1194, -0.2663, -0.1669,  0.2571, -0.2282],\n        [-0.3235,  0.0533,  0.0907, -0.0263, -0.2770,  0.3031, -0.1873,  0.0698],\n        [-0.1387,  0.1975,  0.3481, -0.2098,  0.2392, -0.0164, -0.3414, -0.2731],\n        [-0.2166, -0.1949,  0.3157,  0.2872,  0.2659, -0.3476,  0.1687,  0.1451],\n        [ 0.1091,  0.0320, -0.2145, -0.1989,  0.2062,  0.2708,  0.0495, -0.3224],\n        [-0.2954,  0.1078, -0.2482,  0.1326,  0.2964,  0.2654,  0.0315, -0.1657],\n        [-0.2654, -0.3453, -0.2357, -0.1478,  0.0104, -0.1978, -0.2028,  0.3426],\n        [ 0.2984, -0.0521, -0.2737, -0.0268,  0.0330,  0.0688, -0.3479, -0.2156],\n        [ 0.2650,  0.0156, -0.0861, -0.3146,  0.2289, -0.3510,  0.2081,  0.1200],\n        [ 0.3372, -0.0015, -0.2581, -0.0349,  0.1835,  0.0774, -0.0428, -0.2023],\n        [-0.3043,  0.3255,  0.3281,  0.0024,  0.0447, -0.0722, -0.2681,  0.3411],\n        [-0.3114,  0.3469, -0.2390, -0.1174,  0.1015,  0.2330,  0.2648,  0.2753],\n        [-0.2879,  0.1675,  0.3160,  0.0556,  0.2580, -0.0462, -0.1587, -0.1544],\n        [ 0.2989, -0.3334, -0.3143,  0.1974,  0.1647, -0.2970,  0.1113,  0.1899],\n        [-0.0647,  0.1199,  0.1044,  0.0847, -0.1491, -0.3102, -0.3039, -0.0532],\n        [ 0.1724, -0.2494, -0.0881, -0.0701,  0.2225,  0.2156, -0.2047,  0.2796],\n        [-0.2831,  0.1228, -0.1517,  0.3303, -0.0170,  0.2701, -0.2776, -0.2610],\n        [ 0.0494,  0.2692, -0.1487, -0.0578,  0.3222, -0.2819, -0.3253,  0.0882],\n        [-0.2627, -0.0284, -0.0733, -0.2413, -0.0114, -0.0291,  0.2837,  0.2929],\n        [-0.3354,  0.0449,  0.1783, -0.1059,  0.3426,  0.1642, -0.1195, -0.0585],\n        [ 0.1936,  0.2508,  0.0540,  0.0429,  0.1101,  0.3051, -0.0909,  0.2674],\n        [ 0.0184,  0.2678, -0.1607,  0.2629, -0.2242, -0.2367,  0.3200, -0.1944],\n        [ 0.1132,  0.0799, -0.2641,  0.2261, -0.3467, -0.1362,  0.1286, -0.2825]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0829, -0.1146,  0.1663, -0.0267,  0.1429, -0.1049,  0.0824,  0.1471,\n        -0.0156, -0.0447,  0.1650,  0.1084,  0.0656,  0.1729,  0.1420,  0.0201],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0742e-01,  4.8616e-02,  1.1764e-01,  1.3326e-01,  1.4610e-01,\n          8.8086e-02,  1.4830e-01,  1.3878e-02, -7.8523e-02, -8.8853e-02,\n          2.0826e-02,  2.2868e-02, -5.6688e-02,  5.4127e-02, -1.6946e-01,\n         -1.4199e-01, -3.1077e-02,  1.1331e-01,  1.0921e-01, -6.7617e-02,\n         -1.5370e-01,  9.0852e-02,  5.1788e-02, -6.3546e-02, -1.5562e-01,\n         -5.4393e-02, -1.1266e-01,  2.3978e-02, -6.5178e-03, -1.0588e-01,\n          4.6175e-02, -1.4447e-02],\n        [-1.5367e-01,  7.6356e-02, -1.1307e-01, -1.0488e-01, -2.1226e-02,\n         -4.6649e-02, -6.6295e-03,  2.9144e-02, -1.1850e-01,  1.7266e-01,\n          4.1968e-02, -1.6288e-01, -5.1171e-02,  1.4673e-01, -1.0804e-01,\n          1.6381e-01, -1.7165e-01, -7.1547e-02,  8.6112e-02,  1.5774e-02,\n         -4.3331e-02,  4.1093e-02,  1.5738e-01, -9.0633e-02,  6.9631e-02,\n         -8.0522e-02, -2.0706e-02, -1.7373e-02,  1.7071e-02,  1.0935e-01,\n         -1.4440e-01,  1.2713e-01],\n        [-6.2029e-02,  7.9136e-03, -1.7479e-01, -1.2550e-01,  1.6283e-01,\n         -1.0445e-01,  5.7339e-02,  9.1286e-02, -9.6999e-02,  4.3452e-02,\n         -1.2563e-01, -1.1488e-01, -1.1589e-02,  4.8104e-02, -4.9875e-02,\n          9.8006e-02, -2.8010e-02, -9.8871e-02,  1.5908e-02,  1.4862e-01,\n          3.7024e-02,  8.0488e-02,  1.6828e-01,  6.5175e-02, -6.1315e-02,\n          9.1139e-03,  1.1071e-01, -3.4031e-02, -5.8351e-02, -1.6534e-01,\n         -1.2785e-01, -1.0337e-01],\n        [ 5.7374e-02,  1.6552e-01,  1.6536e-02,  1.0960e-01, -1.3434e-01,\n          1.5390e-01,  1.1612e-01, -9.0628e-02, -1.3321e-01, -5.5449e-02,\n         -1.4499e-01, -3.9872e-03, -1.6533e-01, -8.2473e-02, -2.2638e-02,\n         -9.7247e-02,  9.6787e-02,  5.5834e-03,  1.1568e-01,  1.2948e-01,\n          2.3973e-02, -1.0852e-01, -5.6148e-02,  1.4132e-01, -1.3896e-01,\n         -1.1197e-01,  1.0060e-01, -7.5742e-02,  9.4556e-02, -1.4662e-01,\n          8.1606e-02, -1.1367e-03],\n        [-1.0927e-01,  9.4711e-02, -1.4169e-01,  1.0900e-01, -1.5179e-01,\n          1.6791e-01, -1.3671e-02, -3.6066e-02, -1.2197e-01, -1.7454e-01,\n          1.0146e-01, -6.2540e-02, -1.6060e-01, -1.6247e-01,  1.3345e-01,\n         -9.1805e-02,  1.3589e-01, -5.6451e-02,  1.1696e-01, -1.3934e-01,\n          1.3203e-01,  6.6364e-02,  2.6374e-02,  5.1799e-02,  3.1147e-02,\n         -1.1397e-02, -1.7586e-01, -3.1225e-02, -1.4119e-01,  1.3994e-01,\n          1.1868e-02, -1.0581e-01],\n        [-6.6028e-02, -4.4586e-02, -1.3203e-01, -6.6250e-02,  1.1761e-01,\n         -1.1742e-01, -4.4446e-02, -7.3226e-03,  3.0750e-02,  1.1237e-01,\n         -1.3428e-01, -1.1979e-01,  1.2253e-01,  2.7953e-02,  5.9357e-02,\n         -7.9451e-02, -9.2690e-03,  2.5879e-02,  3.9663e-02,  9.6245e-03,\n          6.2664e-04, -5.4934e-02, -1.5126e-01,  8.2111e-02, -1.5599e-01,\n         -9.2297e-03, -7.1418e-02,  1.7422e-01,  1.2145e-01, -2.8169e-03,\n         -4.8614e-02,  1.1824e-01],\n        [-4.2037e-02, -1.0178e-01, -1.4503e-01,  1.7050e-01, -1.1876e-01,\n         -1.0729e-02,  1.3131e-02,  2.3846e-02,  1.6840e-01, -8.8324e-03,\n          8.6637e-02,  7.0579e-02, -8.3544e-02, -1.4110e-01, -9.9760e-02,\n         -1.0962e-02, -8.7991e-02, -2.7047e-02, -1.5565e-01,  1.0162e-01,\n          1.2363e-01, -1.7460e-01, -5.9335e-02, -1.1496e-01, -5.3475e-03,\n          1.6239e-01, -4.8906e-02,  1.4408e-01, -1.0647e-01, -7.4988e-03,\n         -9.3269e-02,  1.3815e-01],\n        [ 1.3002e-02, -1.0453e-02,  1.5402e-01, -1.4811e-01, -3.7583e-02,\n         -1.1748e-01, -2.9033e-02, -2.2191e-02,  1.5149e-01,  4.3807e-02,\n          1.2233e-01, -9.0391e-02, -1.3272e-01, -1.6318e-01,  1.2225e-01,\n         -9.3717e-02,  1.7380e-01,  1.6782e-01,  5.7327e-02,  1.7497e-01,\n         -1.4069e-01,  1.5337e-02,  1.7398e-01, -1.5671e-01,  5.3883e-02,\n         -1.3644e-01,  9.2343e-02,  1.0453e-01,  6.8382e-02,  1.6203e-04,\n          1.3126e-01, -1.1025e-01],\n        [-5.9891e-02, -1.6560e-01,  6.9160e-03, -3.1225e-02, -6.9286e-02,\n         -5.2848e-02,  2.3785e-02, -1.5303e-02,  1.2814e-01, -1.5648e-01,\n         -1.0342e-01, -5.9909e-02, -1.2770e-01, -2.4125e-02, -6.3022e-02,\n          1.2569e-01, -1.1344e-01, -2.9476e-02, -1.2075e-01,  6.8968e-02,\n          7.6552e-02, -1.0809e-01, -2.5723e-02, -4.6705e-02,  1.7435e-03,\n         -1.5898e-01, -1.2896e-01, -1.6611e-01,  7.7058e-02,  6.5376e-02,\n          1.0279e-01, -3.2167e-02],\n        [-2.3100e-02,  1.7494e-01, -1.5574e-01, -1.1391e-01,  8.5795e-02,\n         -1.7037e-01, -7.6580e-02, -1.5751e-01, -1.5866e-01, -1.2470e-01,\n         -7.6006e-02, -5.2697e-02, -5.8984e-02,  1.0609e-01, -1.7203e-01,\n          1.5253e-01, -5.3048e-02,  3.5192e-02,  6.0925e-02, -1.7558e-01,\n          2.0665e-03, -2.1181e-02, -1.3846e-01, -2.0822e-02, -1.7268e-01,\n          9.2148e-03, -1.3697e-01, -2.9976e-02,  3.4613e-02,  2.6676e-02,\n         -1.2866e-01, -1.1962e-01],\n        [-4.8282e-02,  5.1542e-02,  1.5999e-02, -4.7185e-02,  8.3514e-05,\n          2.9420e-02,  3.7320e-02, -4.1562e-02, -1.6040e-01, -2.9032e-02,\n         -1.5285e-01, -8.6766e-02,  1.9196e-02,  1.1462e-01,  9.3654e-02,\n         -2.0777e-02,  7.5983e-02,  1.6068e-01, -1.4131e-01, -1.0989e-01,\n         -1.5183e-01, -1.6324e-01,  3.8706e-02,  6.8750e-02,  1.1045e-01,\n          1.3162e-03,  1.7427e-01,  1.6766e-01,  6.8366e-02,  3.2812e-02,\n          6.1187e-02, -9.4594e-02],\n        [-1.0989e-01, -6.8019e-02, -5.0899e-02, -1.6332e-01, -1.3456e-01,\n         -1.1824e-01, -1.2655e-01, -8.5339e-02, -1.2033e-01, -1.1299e-01,\n          7.7404e-03, -3.2997e-03,  8.3730e-02,  8.2707e-02,  7.6590e-02,\n          2.2331e-02, -1.2694e-01, -6.8128e-02,  4.4261e-02,  8.7712e-02,\n         -1.5781e-01,  7.4417e-02, -1.7003e-01, -1.6370e-02,  3.3868e-02,\n          1.7610e-01,  6.7269e-02, -4.0407e-03, -1.4817e-01,  6.6624e-02,\n          1.8777e-03, -1.4389e-01],\n        [ 1.5648e-01,  2.9956e-02, -1.5018e-01,  2.0153e-02,  1.5016e-01,\n         -1.7499e-01,  1.4430e-01,  2.5893e-03,  1.1923e-01,  1.2076e-01,\n         -4.9776e-02,  9.0364e-02, -3.6460e-02, -8.3931e-02, -6.6453e-02,\n         -1.4004e-01,  1.5904e-01,  2.7122e-02,  1.5755e-01, -4.3732e-02,\n         -2.2365e-02,  1.4236e-01,  1.8887e-02, -6.5289e-02,  1.5768e-01,\n          8.9984e-02, -7.2922e-02, -1.1008e-01,  1.5392e-01,  1.3533e-03,\n          1.1138e-01, -1.0178e-01],\n        [-6.6871e-02, -2.9322e-02,  4.9721e-02,  6.0650e-02, -7.3159e-02,\n         -1.0000e-01, -4.0559e-02, -2.4927e-02,  1.5531e-01, -6.2133e-02,\n         -1.4760e-01, -1.3513e-02, -1.2692e-01, -1.5899e-01, -9.2812e-02,\n          2.0453e-02,  1.5874e-01,  1.3669e-01,  9.3000e-03, -1.1313e-01,\n         -7.5380e-02, -3.0840e-03,  2.5587e-02,  2.0003e-02,  2.6372e-02,\n          1.6635e-01, -7.3014e-03,  1.3852e-01,  1.6964e-02, -4.4283e-03,\n         -5.8380e-02,  1.1409e-01],\n        [ 1.0126e-01,  4.8558e-02, -1.4765e-01, -1.6721e-01,  1.4825e-01,\n          1.7204e-01,  6.1203e-02, -1.7316e-02,  1.2891e-01, -1.4992e-02,\n         -1.2889e-01, -1.4878e-02, -9.1708e-03,  1.1033e-01, -1.4120e-01,\n          1.0290e-01,  1.8681e-02, -1.4052e-01, -2.6409e-02, -8.8216e-03,\n          1.2208e-01, -1.4967e-01,  1.3288e-01,  1.0537e-01, -1.2437e-01,\n          1.3648e-02, -9.3536e-02, -1.6315e-02,  4.8205e-02,  1.7175e-01,\n         -5.9290e-02,  6.9624e-02],\n        [ 2.2721e-02, -1.4563e-01, -1.5585e-01,  1.5893e-01, -1.2227e-01,\n          7.4481e-03,  4.2192e-02,  1.9732e-02, -3.5261e-02, -5.3860e-02,\n          8.2206e-02, -7.9729e-03,  1.1534e-01, -1.1285e-01,  1.4511e-03,\n          4.8290e-03,  6.1617e-03,  2.9589e-02,  1.5276e-01, -1.5286e-01,\n         -1.1911e-01, -1.2078e-01, -1.4769e-01,  6.5401e-02,  9.4569e-02,\n          1.7287e-01, -9.9632e-02, -1.3695e-01, -7.3780e-02, -1.2104e-01,\n         -1.5777e-01,  8.1747e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1468,  0.0512,  0.1413, -0.1160, -0.0636,  0.1374,  0.1969,  0.0386],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2431,  0.2140, -0.0715,  0.1095,  0.1712,  0.0783, -0.2226, -0.2338,\n          0.2497, -0.1700, -0.1096, -0.0722,  0.0564, -0.0111, -0.1809, -0.0933],\n        [-0.2241, -0.0057,  0.0849,  0.2378,  0.2088,  0.0127, -0.1865, -0.2153,\n          0.2065,  0.0144,  0.1659, -0.1937, -0.0288,  0.0354, -0.0445,  0.1677],\n        [ 0.0145,  0.0845,  0.1219, -0.1211,  0.1765,  0.1341, -0.0713, -0.1912,\n          0.0573,  0.0481,  0.1840,  0.0360, -0.1465, -0.1111,  0.2256,  0.0111],\n        [-0.0572, -0.0637,  0.0372, -0.1194,  0.1401, -0.0092, -0.1034,  0.1963,\n         -0.1736, -0.0620,  0.2030,  0.2279,  0.1565, -0.0290, -0.1895, -0.0878],\n        [ 0.0669, -0.2257,  0.1917,  0.1539, -0.1072, -0.0604,  0.1440, -0.0911,\n          0.2220, -0.0064, -0.1761,  0.0903,  0.1112,  0.2005, -0.1292, -0.0656],\n        [ 0.1211, -0.1752, -0.0144, -0.1412, -0.1727,  0.1632, -0.1879, -0.0123,\n         -0.1871, -0.2347,  0.0279,  0.1352,  0.0843, -0.2256,  0.0699,  0.0838],\n        [ 0.1439,  0.1195, -0.0492,  0.2028,  0.1444,  0.0263, -0.1267, -0.0304,\n         -0.2495, -0.1077, -0.0314,  0.2150,  0.1989,  0.1335,  0.1257,  0.1249],\n        [ 0.2205, -0.1683,  0.0295,  0.1384,  0.0556,  0.1183,  0.1667, -0.1712,\n          0.1758,  0.2096,  0.0844, -0.0783,  0.1146,  0.2464,  0.0183, -0.2062]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0082, 0.2932, 0.0159, 0.2783], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1979,  0.1423, -0.1492,  0.0801,  0.0760,  0.3329,  0.2814, -0.3188],\n        [ 0.2773,  0.1921, -0.0575,  0.1064, -0.1303,  0.0396, -0.1144, -0.3472],\n        [-0.1633,  0.3308, -0.0481,  0.2784, -0.0544,  0.2804,  0.0127, -0.2294],\n        [ 0.2761,  0.0643, -0.2524, -0.3458, -0.3151, -0.3024,  0.3094,  0.1220]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x790cadef9ed0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s840190000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s840190000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}