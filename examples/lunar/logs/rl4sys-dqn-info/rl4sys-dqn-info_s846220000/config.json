{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s846220000"
    },
    "q_lr":	0.003,
    "seed":	846220000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x78eb22b7a9d0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2427, -0.1223,  0.1613,  0.2882, -0.2955, -0.0452, -0.2174, -0.3221,\n         0.1413, -0.1219,  0.1859, -0.0300,  0.0614, -0.2619,  0.1800,  0.3012,\n         0.1215, -0.0856,  0.0845,  0.0192, -0.0879, -0.2673,  0.0387,  0.1216,\n         0.0528, -0.3471,  0.0302,  0.0745,  0.2372,  0.0772,  0.1277, -0.3099],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3274, -0.0647, -0.0896,  0.1321,  0.3496, -0.3044,  0.2566,  0.0432],\n        [ 0.2585,  0.3047, -0.0571, -0.1915, -0.1771,  0.1680,  0.0789, -0.2159],\n        [-0.0897,  0.1787, -0.1685, -0.1346,  0.2397,  0.1211,  0.2771,  0.0520],\n        [-0.1880,  0.0117, -0.0364, -0.0765, -0.2075,  0.3332,  0.2057,  0.0478],\n        [ 0.0337,  0.1633, -0.0710, -0.1798,  0.3311,  0.1007, -0.2167, -0.2220],\n        [-0.2225,  0.3150,  0.3378, -0.2442,  0.2799,  0.2683,  0.2822,  0.2957],\n        [ 0.1098, -0.2375,  0.2794,  0.0354, -0.1970, -0.0472,  0.0672, -0.1227],\n        [ 0.2604,  0.1016,  0.0168,  0.2106, -0.2437,  0.1009,  0.2159, -0.1744],\n        [ 0.2819,  0.3021, -0.0421,  0.1779, -0.2384, -0.0129, -0.2500,  0.2645],\n        [-0.3523, -0.3308, -0.2599,  0.3427,  0.1604,  0.2458,  0.2980, -0.1695],\n        [-0.0174,  0.2335, -0.1111,  0.0930, -0.0502,  0.0230, -0.1401, -0.2163],\n        [ 0.2224,  0.1608, -0.1411,  0.2413,  0.2166, -0.1135, -0.0203,  0.2576],\n        [-0.2329,  0.1381,  0.0719, -0.1325, -0.1062,  0.0071, -0.3063,  0.0736],\n        [-0.1604, -0.2738,  0.0696,  0.1338,  0.3474,  0.2925, -0.2754,  0.0857],\n        [ 0.2804,  0.2901,  0.2056,  0.1340,  0.2549,  0.3153,  0.2364, -0.2742],\n        [-0.2426,  0.0815,  0.3293, -0.1905,  0.0201, -0.2034,  0.2829, -0.0428],\n        [ 0.1716, -0.0954, -0.3278, -0.2140, -0.0010,  0.2196,  0.0729,  0.0422],\n        [-0.1255,  0.0400,  0.3426,  0.1262, -0.0092,  0.3228, -0.0591, -0.0587],\n        [-0.2247, -0.1606, -0.2923,  0.2471,  0.0421,  0.2095,  0.1180, -0.1903],\n        [ 0.0738,  0.1052,  0.0779, -0.1707,  0.2302, -0.1502, -0.0393,  0.1444],\n        [ 0.3448, -0.2396, -0.1320,  0.1523, -0.2173, -0.0152,  0.0702,  0.0070],\n        [-0.2632,  0.2235, -0.3128,  0.2309,  0.3347, -0.3286,  0.3525, -0.3335],\n        [-0.2507, -0.1857,  0.2445, -0.1288,  0.2393, -0.0849,  0.2342,  0.0166],\n        [-0.3433, -0.0620,  0.3090,  0.0289, -0.2741, -0.0530, -0.1570,  0.1302],\n        [-0.1182, -0.0720,  0.1279,  0.2600, -0.1004, -0.0009, -0.1859, -0.3298],\n        [ 0.1444, -0.0060, -0.0344,  0.2108, -0.1733,  0.1243,  0.0542,  0.0707],\n        [-0.0755, -0.0863,  0.0682,  0.3230, -0.0345, -0.1897,  0.2098, -0.1587],\n        [ 0.2852, -0.2718,  0.1766, -0.2636, -0.3037, -0.2567, -0.1281, -0.0311],\n        [ 0.1934, -0.2437, -0.1463,  0.1929,  0.1042, -0.1748,  0.0985, -0.0860],\n        [-0.2406,  0.0611, -0.2962, -0.0784, -0.3066, -0.1167,  0.0806, -0.1021],\n        [-0.1544, -0.1750, -0.1011,  0.0666,  0.1038,  0.1339, -0.3316, -0.0738],\n        [-0.2608,  0.0839, -0.1700, -0.1223,  0.2282, -0.0033, -0.1530,  0.0635]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1195,  0.1312,  0.1214, -0.0519, -0.1102,  0.0760,  0.1057,  0.1371,\n         0.0436,  0.0956, -0.0381,  0.1003, -0.1486, -0.1332, -0.0881,  0.0991],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.5010e-01,  8.4998e-02, -5.7910e-02,  1.4064e-01, -9.3542e-02,\n         -8.0726e-02,  1.4370e-01, -1.2322e-01, -1.2010e-01,  2.3722e-02,\n          9.1378e-02, -1.3766e-01,  1.3126e-01, -1.7151e-01,  6.4339e-02,\n          1.2478e-01,  1.3739e-01, -9.0928e-02,  4.3361e-02,  9.0184e-02,\n          1.1392e-01, -5.3825e-02, -8.1305e-02,  9.7191e-02,  1.0485e-01,\n          8.3964e-02,  8.5568e-02,  1.7470e-01, -5.3378e-02,  1.0752e-01,\n          1.2539e-01, -5.7982e-02],\n        [ 1.5969e-01, -9.6993e-02, -1.5401e-01,  2.2945e-02, -1.7485e-01,\n         -7.4337e-02, -7.0942e-02, -3.8448e-02,  1.2479e-01,  1.2888e-01,\n          8.2658e-02,  8.0206e-02, -9.2847e-02,  1.0507e-01, -2.6539e-02,\n         -4.3573e-02, -1.2660e-01,  1.6652e-02, -1.1070e-01,  4.7836e-02,\n         -9.2427e-02,  1.3339e-01, -1.4368e-01,  1.3161e-02, -1.9655e-02,\n         -1.0014e-01,  7.2188e-02,  1.5072e-01, -4.5989e-03, -6.9399e-02,\n         -7.9791e-02,  4.9683e-02],\n        [ 1.1175e-01,  6.3458e-02, -6.0109e-02,  1.1138e-01,  1.7339e-01,\n         -7.4360e-03,  1.1723e-01,  1.0166e-01, -9.2496e-02, -1.0972e-01,\n          1.2535e-01, -6.0075e-02, -2.4612e-02, -9.0541e-02, -7.7487e-02,\n          1.6031e-01,  1.6141e-01, -1.3843e-01,  3.3756e-02, -3.2483e-02,\n         -2.2695e-02,  7.4871e-02, -1.3612e-01,  7.8258e-02,  7.4520e-02,\n          1.6888e-01, -1.3298e-03, -1.4945e-01,  5.1209e-02,  1.7274e-02,\n          4.3539e-02,  9.3672e-02],\n        [-3.5837e-02,  1.6287e-01,  6.8397e-02, -3.2395e-02,  4.9555e-02,\n          1.1659e-01,  1.7487e-01, -1.3780e-01, -5.7298e-03, -6.2892e-02,\n         -1.3565e-01,  7.6955e-02, -6.4712e-02,  5.0713e-02, -6.1667e-02,\n         -1.4999e-01,  7.3897e-03,  1.1860e-01, -1.3029e-01, -1.4273e-01,\n         -1.4546e-02, -4.9370e-02, -9.0232e-03,  3.1802e-02,  6.9833e-02,\n         -8.8423e-03,  9.1773e-02,  1.2718e-02, -4.8498e-02,  9.4710e-02,\n         -4.8236e-02, -3.7391e-02],\n        [ 9.2521e-02,  1.0043e-02,  1.1172e-02, -1.0771e-01, -2.8068e-02,\n          3.0948e-02,  8.2277e-02,  5.4257e-02, -4.8510e-02, -3.5977e-03,\n          3.9547e-02, -2.1860e-02, -1.6894e-01,  3.1078e-02, -1.6404e-01,\n          1.2755e-01,  1.6049e-01, -1.4614e-01,  6.0938e-02,  3.6312e-02,\n          1.6493e-01,  9.3164e-02,  5.6232e-03, -2.7718e-02, -1.1528e-01,\n         -7.4547e-03, -4.1419e-02,  1.7407e-01, -4.2398e-02, -3.1229e-02,\n         -1.4215e-01, -1.8963e-02],\n        [ 1.1764e-02, -1.1044e-01, -9.6304e-02,  1.4375e-02,  5.4798e-02,\n         -4.9744e-02,  1.4816e-01, -5.5470e-02,  1.4861e-01, -3.2316e-02,\n          5.9318e-02,  2.7269e-02,  6.9473e-04, -1.0116e-01, -1.3466e-01,\n         -7.1255e-02, -1.0854e-02,  8.0268e-02,  1.6839e-01,  1.6186e-01,\n          8.8575e-02,  5.8111e-02,  1.7563e-01,  7.9400e-02, -1.1153e-01,\n         -2.1140e-02, -1.0717e-01, -7.6016e-02, -1.6259e-01,  5.9520e-02,\n         -5.1766e-02,  7.8962e-02],\n        [ 2.0202e-02, -1.5890e-01, -3.1751e-02, -1.3521e-01, -4.6684e-02,\n          6.7112e-02, -1.3332e-01,  8.1339e-02, -1.3210e-01,  3.6548e-02,\n         -7.6052e-02,  1.2290e-01, -3.3881e-02,  8.3756e-03, -6.1772e-02,\n          1.0536e-01, -1.3720e-01, -4.0001e-02, -6.4616e-02,  1.5594e-01,\n         -3.1548e-03,  3.8754e-02, -1.5922e-01,  1.0546e-01,  1.4258e-01,\n          4.4821e-02, -1.0739e-01, -1.3833e-01,  1.4952e-01, -1.6534e-02,\n         -3.9432e-02, -1.4791e-02],\n        [ 9.2613e-02,  6.7360e-02,  6.4663e-02, -2.9160e-02,  9.2320e-02,\n          8.1219e-02, -3.5836e-02, -1.5717e-01,  1.1573e-01, -1.6359e-01,\n         -1.4163e-01,  1.1339e-01,  1.7449e-01, -1.5854e-01,  1.0326e-01,\n          8.5244e-02,  6.2750e-02, -2.7198e-02,  2.6064e-02, -1.4063e-01,\n         -1.2331e-01, -1.6408e-01,  8.6552e-02,  6.4195e-02,  6.8615e-02,\n          7.3888e-02, -1.0396e-01,  1.0796e-01,  7.7365e-02,  3.9342e-02,\n          9.1284e-02,  1.1817e-01],\n        [ 7.5377e-02,  7.8159e-02, -1.1795e-01, -1.3991e-01, -1.5731e-01,\n         -1.5840e-01,  3.8967e-02,  1.9945e-02,  1.1434e-01, -1.2514e-01,\n         -1.4527e-01, -6.7210e-02,  1.1069e-01,  4.4190e-02, -9.8581e-02,\n          5.7590e-02, -1.0853e-01,  2.5119e-02,  1.2910e-01,  1.7630e-01,\n          6.0483e-02, -7.0442e-02, -1.5552e-01,  7.0179e-02,  4.0846e-02,\n          4.6557e-02, -6.8990e-02,  1.1957e-01,  6.9984e-02, -2.8981e-02,\n         -1.2322e-01, -2.7279e-02],\n        [ 4.7888e-02, -1.3438e-01, -9.0263e-02,  7.0475e-02, -5.2481e-02,\n          1.0119e-01, -1.5909e-01, -4.9793e-03, -5.3413e-03, -6.1033e-02,\n          8.3804e-02,  4.8791e-02,  7.0376e-02, -5.7648e-02,  5.6012e-02,\n          1.0850e-01,  3.3839e-02, -1.2667e-01, -1.7559e-01,  1.5874e-01,\n         -1.2938e-02, -7.7410e-03, -6.6209e-02,  1.2877e-01, -8.7283e-02,\n         -3.7882e-02,  2.9776e-02,  1.5996e-01,  5.9676e-02,  1.2910e-01,\n          3.0351e-03, -1.6391e-01],\n        [-4.1804e-02, -8.9973e-02, -9.3640e-02, -1.0857e-01,  1.2262e-01,\n          1.5861e-02, -6.4606e-02,  1.3170e-01,  1.7341e-02, -1.2684e-01,\n         -1.6994e-01, -3.4509e-03,  1.0700e-01,  6.7113e-02, -7.7652e-02,\n          1.6447e-01, -1.7559e-01, -1.1139e-01, -1.8927e-02,  1.0949e-01,\n         -9.2958e-02,  1.4759e-01,  1.4728e-01, -1.0761e-01, -1.2417e-01,\n         -7.4869e-02,  7.9086e-02, -1.7436e-01, -1.2472e-01, -8.3420e-02,\n         -8.6176e-02, -1.4563e-01],\n        [ 9.2085e-02, -1.3644e-01, -1.5707e-01, -5.3715e-02,  2.4712e-02,\n          1.4888e-02, -1.4776e-02, -5.5143e-02, -1.4930e-01, -5.4352e-02,\n          1.6406e-01, -1.5400e-01, -2.0473e-02, -1.5169e-01,  1.9706e-02,\n          1.3753e-01, -1.1702e-01,  1.2611e-01,  7.4190e-02, -7.5334e-02,\n         -1.1739e-01,  1.7227e-02,  1.7072e-01,  3.8946e-03, -1.5707e-01,\n         -2.3260e-02,  6.1928e-02, -1.3278e-02, -8.3163e-02,  1.7366e-01,\n          8.1926e-03, -1.1140e-01],\n        [-1.2604e-01,  1.1190e-01, -1.6026e-01, -5.7573e-02,  1.4607e-01,\n          3.3733e-02, -7.5841e-03,  1.2709e-01, -1.2898e-01, -1.3731e-01,\n          1.6411e-01, -1.5661e-02,  8.6754e-02,  1.3128e-01, -1.1375e-01,\n         -1.7477e-01,  4.6021e-02, -1.6937e-01,  1.6460e-01,  5.8333e-02,\n          1.0346e-01, -1.4148e-01,  1.0069e-01,  1.5835e-01, -1.1118e-01,\n          1.5004e-01, -1.4493e-01,  1.7405e-01,  1.4925e-01, -2.7355e-02,\n         -1.7408e-02,  1.3963e-01],\n        [ 5.0516e-02,  1.6368e-01,  1.1452e-01,  6.5050e-02, -8.1408e-02,\n         -1.9731e-02, -2.8092e-02,  3.6666e-02, -1.4330e-01, -5.7269e-02,\n          1.2530e-01,  1.4706e-01,  1.3353e-01, -1.0881e-01,  1.0306e-01,\n         -1.0703e-01,  1.6314e-01, -7.1537e-02, -1.2922e-01,  1.0685e-01,\n         -6.9869e-03,  9.5913e-02, -2.5981e-02,  8.8950e-02, -1.6706e-01,\n          1.6661e-01,  1.0884e-01,  4.6238e-02, -8.5868e-03,  1.4864e-01,\n         -8.1640e-02,  5.4799e-02],\n        [-8.9645e-02,  7.9315e-02, -1.6393e-01,  3.1836e-02, -1.1960e-01,\n          2.2196e-02, -8.0669e-02, -5.0233e-02,  1.5296e-01,  5.9784e-02,\n          1.7754e-02,  1.2415e-01, -1.2185e-01, -1.2477e-02,  5.6729e-02,\n         -1.4258e-01, -4.7441e-02, -5.3944e-02,  1.1896e-02, -9.8694e-02,\n         -1.5050e-01,  2.2995e-02,  1.1789e-02, -2.3067e-02,  2.6370e-02,\n          1.4658e-02, -1.3688e-01, -1.5748e-01, -2.1104e-03, -1.0059e-01,\n          1.4201e-01, -1.7424e-01],\n        [-6.0265e-02, -8.9096e-02, -1.5117e-02, -7.6041e-02, -9.2520e-02,\n          1.2135e-01,  6.3280e-02, -9.6531e-03,  7.8570e-02,  5.1514e-02,\n          3.5361e-05, -7.5335e-02,  8.7161e-02, -6.1450e-02,  8.8447e-02,\n          1.0597e-01,  6.4674e-02, -7.5121e-02,  1.4737e-01, -4.5171e-03,\n         -1.2992e-01,  1.7479e-01, -1.7057e-02,  3.0610e-03,  1.2891e-01,\n          6.0282e-02,  7.9001e-02, -1.2830e-01,  1.0481e-01,  6.4951e-02,\n         -1.4619e-01, -4.8441e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0142, -0.2402, -0.0085, -0.2062, -0.0754,  0.2344, -0.2225, -0.1610],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0815, -0.2394, -0.0413, -0.0171,  0.1513,  0.0416, -0.2284,  0.2277,\n          0.0764, -0.2397,  0.1134,  0.1932,  0.0706, -0.2137,  0.0232,  0.1136],\n        [-0.1159, -0.0260,  0.0359, -0.1985, -0.0251,  0.2165,  0.2352, -0.1856,\n          0.0219,  0.1528, -0.1606, -0.2011,  0.0503, -0.0956,  0.1722, -0.0657],\n        [ 0.1052,  0.2005,  0.0211,  0.1948,  0.2198, -0.0321, -0.0827, -0.1283,\n          0.2498, -0.0198, -0.0534, -0.1847, -0.2376,  0.1586,  0.1152,  0.0456],\n        [-0.0428, -0.0749, -0.2377,  0.1174, -0.0581,  0.0999,  0.1477, -0.0042,\n          0.0930,  0.1169, -0.0726,  0.2462, -0.0988, -0.0415, -0.0376,  0.2369],\n        [ 0.1106, -0.1477,  0.1096,  0.1360,  0.1129,  0.1499,  0.1237,  0.0523,\n         -0.2085,  0.2436, -0.1454, -0.0321,  0.0321,  0.0523, -0.1371, -0.0184],\n        [-0.0759, -0.0686,  0.2171, -0.1954,  0.1563, -0.0024,  0.0400, -0.0906,\n         -0.1587,  0.0514, -0.0751, -0.1525,  0.1493, -0.0854,  0.2351, -0.0366],\n        [-0.1305, -0.1459, -0.2136, -0.2158, -0.1427, -0.0736, -0.1071,  0.0162,\n          0.1452, -0.0767,  0.1316,  0.2362,  0.1846, -0.1340, -0.0961, -0.1888],\n        [ 0.1128,  0.0665,  0.1438, -0.1864, -0.1764, -0.2499, -0.2150, -0.1187,\n         -0.2250, -0.0035,  0.1875, -0.1739,  0.2047, -0.0425, -0.1049,  0.2283]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1947,  0.1510,  0.0692, -0.1209], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3418,  0.1733,  0.1330,  0.3447,  0.0251,  0.1285, -0.3109,  0.2322],\n        [-0.3257, -0.2860,  0.0698,  0.2187, -0.2205, -0.2561, -0.2107,  0.2627],\n        [ 0.2308,  0.1987,  0.2391,  0.1831, -0.3396,  0.2284,  0.0131,  0.0338],\n        [-0.3145,  0.1578, -0.2176, -0.2082, -0.0203,  0.0191,  0.2839,  0.0880]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.3274, -0.0647, -0.0896,  0.1321,  0.3496, -0.3044,  0.2566,  0.0432],\n        [ 0.2585,  0.3047, -0.0571, -0.1915, -0.1771,  0.1680,  0.0789, -0.2159],\n        [-0.0897,  0.1787, -0.1685, -0.1346,  0.2397,  0.1211,  0.2771,  0.0520],\n        [-0.1880,  0.0117, -0.0364, -0.0765, -0.2075,  0.3332,  0.2057,  0.0478],\n        [ 0.0337,  0.1633, -0.0710, -0.1798,  0.3311,  0.1007, -0.2167, -0.2220],\n        [-0.2225,  0.3150,  0.3378, -0.2442,  0.2799,  0.2683,  0.2822,  0.2957],\n        [ 0.1098, -0.2375,  0.2794,  0.0354, -0.1970, -0.0472,  0.0672, -0.1227],\n        [ 0.2604,  0.1016,  0.0168,  0.2106, -0.2437,  0.1009,  0.2159, -0.1744],\n        [ 0.2819,  0.3021, -0.0421,  0.1779, -0.2384, -0.0129, -0.2500,  0.2645],\n        [-0.3523, -0.3308, -0.2599,  0.3427,  0.1604,  0.2458,  0.2980, -0.1695],\n        [-0.0174,  0.2335, -0.1111,  0.0930, -0.0502,  0.0230, -0.1401, -0.2163],\n        [ 0.2224,  0.1608, -0.1411,  0.2413,  0.2166, -0.1135, -0.0203,  0.2576],\n        [-0.2329,  0.1381,  0.0719, -0.1325, -0.1062,  0.0071, -0.3063,  0.0736],\n        [-0.1604, -0.2738,  0.0696,  0.1338,  0.3474,  0.2925, -0.2754,  0.0857],\n        [ 0.2804,  0.2901,  0.2056,  0.1340,  0.2549,  0.3153,  0.2364, -0.2742],\n        [-0.2426,  0.0815,  0.3293, -0.1905,  0.0201, -0.2034,  0.2829, -0.0428],\n        [ 0.1716, -0.0954, -0.3278, -0.2140, -0.0010,  0.2196,  0.0729,  0.0422],\n        [-0.1255,  0.0400,  0.3426,  0.1262, -0.0092,  0.3228, -0.0591, -0.0587],\n        [-0.2247, -0.1606, -0.2923,  0.2471,  0.0421,  0.2095,  0.1180, -0.1903],\n        [ 0.0738,  0.1052,  0.0779, -0.1707,  0.2302, -0.1502, -0.0393,  0.1444],\n        [ 0.3448, -0.2396, -0.1320,  0.1523, -0.2173, -0.0152,  0.0702,  0.0070],\n        [-0.2632,  0.2235, -0.3128,  0.2309,  0.3347, -0.3286,  0.3525, -0.3335],\n        [-0.2507, -0.1857,  0.2445, -0.1288,  0.2393, -0.0849,  0.2342,  0.0166],\n        [-0.3433, -0.0620,  0.3090,  0.0289, -0.2741, -0.0530, -0.1570,  0.1302],\n        [-0.1182, -0.0720,  0.1279,  0.2600, -0.1004, -0.0009, -0.1859, -0.3298],\n        [ 0.1444, -0.0060, -0.0344,  0.2108, -0.1733,  0.1243,  0.0542,  0.0707],\n        [-0.0755, -0.0863,  0.0682,  0.3230, -0.0345, -0.1897,  0.2098, -0.1587],\n        [ 0.2852, -0.2718,  0.1766, -0.2636, -0.3037, -0.2567, -0.1281, -0.0311],\n        [ 0.1934, -0.2437, -0.1463,  0.1929,  0.1042, -0.1748,  0.0985, -0.0860],\n        [-0.2406,  0.0611, -0.2962, -0.0784, -0.3066, -0.1167,  0.0806, -0.1021],\n        [-0.1544, -0.1750, -0.1011,  0.0666,  0.1038,  0.1339, -0.3316, -0.0738],\n        [-0.2608,  0.0839, -0.1700, -0.1223,  0.2282, -0.0033, -0.1530,  0.0635]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2427, -0.1223,  0.1613,  0.2882, -0.2955, -0.0452, -0.2174, -0.3221,\n         0.1413, -0.1219,  0.1859, -0.0300,  0.0614, -0.2619,  0.1800,  0.3012,\n         0.1215, -0.0856,  0.0845,  0.0192, -0.0879, -0.2673,  0.0387,  0.1216,\n         0.0528, -0.3471,  0.0302,  0.0745,  0.2372,  0.0772,  0.1277, -0.3099],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.5010e-01,  8.4998e-02, -5.7910e-02,  1.4064e-01, -9.3542e-02,\n         -8.0726e-02,  1.4370e-01, -1.2322e-01, -1.2010e-01,  2.3722e-02,\n          9.1378e-02, -1.3766e-01,  1.3126e-01, -1.7151e-01,  6.4339e-02,\n          1.2478e-01,  1.3739e-01, -9.0928e-02,  4.3361e-02,  9.0184e-02,\n          1.1392e-01, -5.3825e-02, -8.1305e-02,  9.7191e-02,  1.0485e-01,\n          8.3964e-02,  8.5568e-02,  1.7470e-01, -5.3378e-02,  1.0752e-01,\n          1.2539e-01, -5.7982e-02],\n        [ 1.5969e-01, -9.6993e-02, -1.5401e-01,  2.2945e-02, -1.7485e-01,\n         -7.4337e-02, -7.0942e-02, -3.8448e-02,  1.2479e-01,  1.2888e-01,\n          8.2658e-02,  8.0206e-02, -9.2847e-02,  1.0507e-01, -2.6539e-02,\n         -4.3573e-02, -1.2660e-01,  1.6652e-02, -1.1070e-01,  4.7836e-02,\n         -9.2427e-02,  1.3339e-01, -1.4368e-01,  1.3161e-02, -1.9655e-02,\n         -1.0014e-01,  7.2188e-02,  1.5072e-01, -4.5989e-03, -6.9399e-02,\n         -7.9791e-02,  4.9683e-02],\n        [ 1.1175e-01,  6.3458e-02, -6.0109e-02,  1.1138e-01,  1.7339e-01,\n         -7.4360e-03,  1.1723e-01,  1.0166e-01, -9.2496e-02, -1.0972e-01,\n          1.2535e-01, -6.0075e-02, -2.4612e-02, -9.0541e-02, -7.7487e-02,\n          1.6031e-01,  1.6141e-01, -1.3843e-01,  3.3756e-02, -3.2483e-02,\n         -2.2695e-02,  7.4871e-02, -1.3612e-01,  7.8258e-02,  7.4520e-02,\n          1.6888e-01, -1.3298e-03, -1.4945e-01,  5.1209e-02,  1.7274e-02,\n          4.3539e-02,  9.3672e-02],\n        [-3.5837e-02,  1.6287e-01,  6.8397e-02, -3.2395e-02,  4.9555e-02,\n          1.1659e-01,  1.7487e-01, -1.3780e-01, -5.7298e-03, -6.2892e-02,\n         -1.3565e-01,  7.6955e-02, -6.4712e-02,  5.0713e-02, -6.1667e-02,\n         -1.4999e-01,  7.3897e-03,  1.1860e-01, -1.3029e-01, -1.4273e-01,\n         -1.4546e-02, -4.9370e-02, -9.0232e-03,  3.1802e-02,  6.9833e-02,\n         -8.8423e-03,  9.1773e-02,  1.2718e-02, -4.8498e-02,  9.4710e-02,\n         -4.8236e-02, -3.7391e-02],\n        [ 9.2521e-02,  1.0043e-02,  1.1172e-02, -1.0771e-01, -2.8068e-02,\n          3.0948e-02,  8.2277e-02,  5.4257e-02, -4.8510e-02, -3.5977e-03,\n          3.9547e-02, -2.1860e-02, -1.6894e-01,  3.1078e-02, -1.6404e-01,\n          1.2755e-01,  1.6049e-01, -1.4614e-01,  6.0938e-02,  3.6312e-02,\n          1.6493e-01,  9.3164e-02,  5.6232e-03, -2.7718e-02, -1.1528e-01,\n         -7.4547e-03, -4.1419e-02,  1.7407e-01, -4.2398e-02, -3.1229e-02,\n         -1.4215e-01, -1.8963e-02],\n        [ 1.1764e-02, -1.1044e-01, -9.6304e-02,  1.4375e-02,  5.4798e-02,\n         -4.9744e-02,  1.4816e-01, -5.5470e-02,  1.4861e-01, -3.2316e-02,\n          5.9318e-02,  2.7269e-02,  6.9473e-04, -1.0116e-01, -1.3466e-01,\n         -7.1255e-02, -1.0854e-02,  8.0268e-02,  1.6839e-01,  1.6186e-01,\n          8.8575e-02,  5.8111e-02,  1.7563e-01,  7.9400e-02, -1.1153e-01,\n         -2.1140e-02, -1.0717e-01, -7.6016e-02, -1.6259e-01,  5.9520e-02,\n         -5.1766e-02,  7.8962e-02],\n        [ 2.0202e-02, -1.5890e-01, -3.1751e-02, -1.3521e-01, -4.6684e-02,\n          6.7112e-02, -1.3332e-01,  8.1339e-02, -1.3210e-01,  3.6548e-02,\n         -7.6052e-02,  1.2290e-01, -3.3881e-02,  8.3756e-03, -6.1772e-02,\n          1.0536e-01, -1.3720e-01, -4.0001e-02, -6.4616e-02,  1.5594e-01,\n         -3.1548e-03,  3.8754e-02, -1.5922e-01,  1.0546e-01,  1.4258e-01,\n          4.4821e-02, -1.0739e-01, -1.3833e-01,  1.4952e-01, -1.6534e-02,\n         -3.9432e-02, -1.4791e-02],\n        [ 9.2613e-02,  6.7360e-02,  6.4663e-02, -2.9160e-02,  9.2320e-02,\n          8.1219e-02, -3.5836e-02, -1.5717e-01,  1.1573e-01, -1.6359e-01,\n         -1.4163e-01,  1.1339e-01,  1.7449e-01, -1.5854e-01,  1.0326e-01,\n          8.5244e-02,  6.2750e-02, -2.7198e-02,  2.6064e-02, -1.4063e-01,\n         -1.2331e-01, -1.6408e-01,  8.6552e-02,  6.4195e-02,  6.8615e-02,\n          7.3888e-02, -1.0396e-01,  1.0796e-01,  7.7365e-02,  3.9342e-02,\n          9.1284e-02,  1.1817e-01],\n        [ 7.5377e-02,  7.8159e-02, -1.1795e-01, -1.3991e-01, -1.5731e-01,\n         -1.5840e-01,  3.8967e-02,  1.9945e-02,  1.1434e-01, -1.2514e-01,\n         -1.4527e-01, -6.7210e-02,  1.1069e-01,  4.4190e-02, -9.8581e-02,\n          5.7590e-02, -1.0853e-01,  2.5119e-02,  1.2910e-01,  1.7630e-01,\n          6.0483e-02, -7.0442e-02, -1.5552e-01,  7.0179e-02,  4.0846e-02,\n          4.6557e-02, -6.8990e-02,  1.1957e-01,  6.9984e-02, -2.8981e-02,\n         -1.2322e-01, -2.7279e-02],\n        [ 4.7888e-02, -1.3438e-01, -9.0263e-02,  7.0475e-02, -5.2481e-02,\n          1.0119e-01, -1.5909e-01, -4.9793e-03, -5.3413e-03, -6.1033e-02,\n          8.3804e-02,  4.8791e-02,  7.0376e-02, -5.7648e-02,  5.6012e-02,\n          1.0850e-01,  3.3839e-02, -1.2667e-01, -1.7559e-01,  1.5874e-01,\n         -1.2938e-02, -7.7410e-03, -6.6209e-02,  1.2877e-01, -8.7283e-02,\n         -3.7882e-02,  2.9776e-02,  1.5996e-01,  5.9676e-02,  1.2910e-01,\n          3.0351e-03, -1.6391e-01],\n        [-4.1804e-02, -8.9973e-02, -9.3640e-02, -1.0857e-01,  1.2262e-01,\n          1.5861e-02, -6.4606e-02,  1.3170e-01,  1.7341e-02, -1.2684e-01,\n         -1.6994e-01, -3.4509e-03,  1.0700e-01,  6.7113e-02, -7.7652e-02,\n          1.6447e-01, -1.7559e-01, -1.1139e-01, -1.8927e-02,  1.0949e-01,\n         -9.2958e-02,  1.4759e-01,  1.4728e-01, -1.0761e-01, -1.2417e-01,\n         -7.4869e-02,  7.9086e-02, -1.7436e-01, -1.2472e-01, -8.3420e-02,\n         -8.6176e-02, -1.4563e-01],\n        [ 9.2085e-02, -1.3644e-01, -1.5707e-01, -5.3715e-02,  2.4712e-02,\n          1.4888e-02, -1.4776e-02, -5.5143e-02, -1.4930e-01, -5.4352e-02,\n          1.6406e-01, -1.5400e-01, -2.0473e-02, -1.5169e-01,  1.9706e-02,\n          1.3753e-01, -1.1702e-01,  1.2611e-01,  7.4190e-02, -7.5334e-02,\n         -1.1739e-01,  1.7227e-02,  1.7072e-01,  3.8946e-03, -1.5707e-01,\n         -2.3260e-02,  6.1928e-02, -1.3278e-02, -8.3163e-02,  1.7366e-01,\n          8.1926e-03, -1.1140e-01],\n        [-1.2604e-01,  1.1190e-01, -1.6026e-01, -5.7573e-02,  1.4607e-01,\n          3.3733e-02, -7.5841e-03,  1.2709e-01, -1.2898e-01, -1.3731e-01,\n          1.6411e-01, -1.5661e-02,  8.6754e-02,  1.3128e-01, -1.1375e-01,\n         -1.7477e-01,  4.6021e-02, -1.6937e-01,  1.6460e-01,  5.8333e-02,\n          1.0346e-01, -1.4148e-01,  1.0069e-01,  1.5835e-01, -1.1118e-01,\n          1.5004e-01, -1.4493e-01,  1.7405e-01,  1.4925e-01, -2.7355e-02,\n         -1.7408e-02,  1.3963e-01],\n        [ 5.0516e-02,  1.6368e-01,  1.1452e-01,  6.5050e-02, -8.1408e-02,\n         -1.9731e-02, -2.8092e-02,  3.6666e-02, -1.4330e-01, -5.7269e-02,\n          1.2530e-01,  1.4706e-01,  1.3353e-01, -1.0881e-01,  1.0306e-01,\n         -1.0703e-01,  1.6314e-01, -7.1537e-02, -1.2922e-01,  1.0685e-01,\n         -6.9869e-03,  9.5913e-02, -2.5981e-02,  8.8950e-02, -1.6706e-01,\n          1.6661e-01,  1.0884e-01,  4.6238e-02, -8.5868e-03,  1.4864e-01,\n         -8.1640e-02,  5.4799e-02],\n        [-8.9645e-02,  7.9315e-02, -1.6393e-01,  3.1836e-02, -1.1960e-01,\n          2.2196e-02, -8.0669e-02, -5.0233e-02,  1.5296e-01,  5.9784e-02,\n          1.7754e-02,  1.2415e-01, -1.2185e-01, -1.2477e-02,  5.6729e-02,\n         -1.4258e-01, -4.7441e-02, -5.3944e-02,  1.1896e-02, -9.8694e-02,\n         -1.5050e-01,  2.2995e-02,  1.1789e-02, -2.3067e-02,  2.6370e-02,\n          1.4658e-02, -1.3688e-01, -1.5748e-01, -2.1104e-03, -1.0059e-01,\n          1.4201e-01, -1.7424e-01],\n        [-6.0265e-02, -8.9096e-02, -1.5117e-02, -7.6041e-02, -9.2520e-02,\n          1.2135e-01,  6.3280e-02, -9.6531e-03,  7.8570e-02,  5.1514e-02,\n          3.5361e-05, -7.5335e-02,  8.7161e-02, -6.1450e-02,  8.8447e-02,\n          1.0597e-01,  6.4674e-02, -7.5121e-02,  1.4737e-01, -4.5171e-03,\n         -1.2992e-01,  1.7479e-01, -1.7057e-02,  3.0610e-03,  1.2891e-01,\n          6.0282e-02,  7.9001e-02, -1.2830e-01,  1.0481e-01,  6.4951e-02,\n         -1.4619e-01, -4.8441e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1195,  0.1312,  0.1214, -0.0519, -0.1102,  0.0760,  0.1057,  0.1371,\n         0.0436,  0.0956, -0.0381,  0.1003, -0.1486, -0.1332, -0.0881,  0.0991],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0815, -0.2394, -0.0413, -0.0171,  0.1513,  0.0416, -0.2284,  0.2277,\n          0.0764, -0.2397,  0.1134,  0.1932,  0.0706, -0.2137,  0.0232,  0.1136],\n        [-0.1159, -0.0260,  0.0359, -0.1985, -0.0251,  0.2165,  0.2352, -0.1856,\n          0.0219,  0.1528, -0.1606, -0.2011,  0.0503, -0.0956,  0.1722, -0.0657],\n        [ 0.1052,  0.2005,  0.0211,  0.1948,  0.2198, -0.0321, -0.0827, -0.1283,\n          0.2498, -0.0198, -0.0534, -0.1847, -0.2376,  0.1586,  0.1152,  0.0456],\n        [-0.0428, -0.0749, -0.2377,  0.1174, -0.0581,  0.0999,  0.1477, -0.0042,\n          0.0930,  0.1169, -0.0726,  0.2462, -0.0988, -0.0415, -0.0376,  0.2369],\n        [ 0.1106, -0.1477,  0.1096,  0.1360,  0.1129,  0.1499,  0.1237,  0.0523,\n         -0.2085,  0.2436, -0.1454, -0.0321,  0.0321,  0.0523, -0.1371, -0.0184],\n        [-0.0759, -0.0686,  0.2171, -0.1954,  0.1563, -0.0024,  0.0400, -0.0906,\n         -0.1587,  0.0514, -0.0751, -0.1525,  0.1493, -0.0854,  0.2351, -0.0366],\n        [-0.1305, -0.1459, -0.2136, -0.2158, -0.1427, -0.0736, -0.1071,  0.0162,\n          0.1452, -0.0767,  0.1316,  0.2362,  0.1846, -0.1340, -0.0961, -0.1888],\n        [ 0.1128,  0.0665,  0.1438, -0.1864, -0.1764, -0.2499, -0.2150, -0.1187,\n         -0.2250, -0.0035,  0.1875, -0.1739,  0.2047, -0.0425, -0.1049,  0.2283]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0142, -0.2402, -0.0085, -0.2062, -0.0754,  0.2344, -0.2225, -0.1610],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3418,  0.1733,  0.1330,  0.3447,  0.0251,  0.1285, -0.3109,  0.2322],\n        [-0.3257, -0.2860,  0.0698,  0.2187, -0.2205, -0.2561, -0.2107,  0.2627],\n        [ 0.2308,  0.1987,  0.2391,  0.1831, -0.3396,  0.2284,  0.0131,  0.0338],\n        [-0.3145,  0.1578, -0.2176, -0.2082, -0.0203,  0.0191,  0.2839,  0.0880]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1947,  0.1510,  0.0692, -0.1209], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x78eba1beac50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2427, -0.1223,  0.1613,  0.2882, -0.2955, -0.0452, -0.2174, -0.3221,\n         0.1413, -0.1219,  0.1859, -0.0300,  0.0614, -0.2619,  0.1800,  0.3012,\n         0.1215, -0.0856,  0.0845,  0.0192, -0.0879, -0.2673,  0.0387,  0.1216,\n         0.0528, -0.3471,  0.0302,  0.0745,  0.2372,  0.0772,  0.1277, -0.3099],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3274, -0.0647, -0.0896,  0.1321,  0.3496, -0.3044,  0.2566,  0.0432],\n        [ 0.2585,  0.3047, -0.0571, -0.1915, -0.1771,  0.1680,  0.0789, -0.2159],\n        [-0.0897,  0.1787, -0.1685, -0.1346,  0.2397,  0.1211,  0.2771,  0.0520],\n        [-0.1880,  0.0117, -0.0364, -0.0765, -0.2075,  0.3332,  0.2057,  0.0478],\n        [ 0.0337,  0.1633, -0.0710, -0.1798,  0.3311,  0.1007, -0.2167, -0.2220],\n        [-0.2225,  0.3150,  0.3378, -0.2442,  0.2799,  0.2683,  0.2822,  0.2957],\n        [ 0.1098, -0.2375,  0.2794,  0.0354, -0.1970, -0.0472,  0.0672, -0.1227],\n        [ 0.2604,  0.1016,  0.0168,  0.2106, -0.2437,  0.1009,  0.2159, -0.1744],\n        [ 0.2819,  0.3021, -0.0421,  0.1779, -0.2384, -0.0129, -0.2500,  0.2645],\n        [-0.3523, -0.3308, -0.2599,  0.3427,  0.1604,  0.2458,  0.2980, -0.1695],\n        [-0.0174,  0.2335, -0.1111,  0.0930, -0.0502,  0.0230, -0.1401, -0.2163],\n        [ 0.2224,  0.1608, -0.1411,  0.2413,  0.2166, -0.1135, -0.0203,  0.2576],\n        [-0.2329,  0.1381,  0.0719, -0.1325, -0.1062,  0.0071, -0.3063,  0.0736],\n        [-0.1604, -0.2738,  0.0696,  0.1338,  0.3474,  0.2925, -0.2754,  0.0857],\n        [ 0.2804,  0.2901,  0.2056,  0.1340,  0.2549,  0.3153,  0.2364, -0.2742],\n        [-0.2426,  0.0815,  0.3293, -0.1905,  0.0201, -0.2034,  0.2829, -0.0428],\n        [ 0.1716, -0.0954, -0.3278, -0.2140, -0.0010,  0.2196,  0.0729,  0.0422],\n        [-0.1255,  0.0400,  0.3426,  0.1262, -0.0092,  0.3228, -0.0591, -0.0587],\n        [-0.2247, -0.1606, -0.2923,  0.2471,  0.0421,  0.2095,  0.1180, -0.1903],\n        [ 0.0738,  0.1052,  0.0779, -0.1707,  0.2302, -0.1502, -0.0393,  0.1444],\n        [ 0.3448, -0.2396, -0.1320,  0.1523, -0.2173, -0.0152,  0.0702,  0.0070],\n        [-0.2632,  0.2235, -0.3128,  0.2309,  0.3347, -0.3286,  0.3525, -0.3335],\n        [-0.2507, -0.1857,  0.2445, -0.1288,  0.2393, -0.0849,  0.2342,  0.0166],\n        [-0.3433, -0.0620,  0.3090,  0.0289, -0.2741, -0.0530, -0.1570,  0.1302],\n        [-0.1182, -0.0720,  0.1279,  0.2600, -0.1004, -0.0009, -0.1859, -0.3298],\n        [ 0.1444, -0.0060, -0.0344,  0.2108, -0.1733,  0.1243,  0.0542,  0.0707],\n        [-0.0755, -0.0863,  0.0682,  0.3230, -0.0345, -0.1897,  0.2098, -0.1587],\n        [ 0.2852, -0.2718,  0.1766, -0.2636, -0.3037, -0.2567, -0.1281, -0.0311],\n        [ 0.1934, -0.2437, -0.1463,  0.1929,  0.1042, -0.1748,  0.0985, -0.0860],\n        [-0.2406,  0.0611, -0.2962, -0.0784, -0.3066, -0.1167,  0.0806, -0.1021],\n        [-0.1544, -0.1750, -0.1011,  0.0666,  0.1038,  0.1339, -0.3316, -0.0738],\n        [-0.2608,  0.0839, -0.1700, -0.1223,  0.2282, -0.0033, -0.1530,  0.0635]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1195,  0.1312,  0.1214, -0.0519, -0.1102,  0.0760,  0.1057,  0.1371,\n         0.0436,  0.0956, -0.0381,  0.1003, -0.1486, -0.1332, -0.0881,  0.0991],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.5010e-01,  8.4998e-02, -5.7910e-02,  1.4064e-01, -9.3542e-02,\n         -8.0726e-02,  1.4370e-01, -1.2322e-01, -1.2010e-01,  2.3722e-02,\n          9.1378e-02, -1.3766e-01,  1.3126e-01, -1.7151e-01,  6.4339e-02,\n          1.2478e-01,  1.3739e-01, -9.0928e-02,  4.3361e-02,  9.0184e-02,\n          1.1392e-01, -5.3825e-02, -8.1305e-02,  9.7191e-02,  1.0485e-01,\n          8.3964e-02,  8.5568e-02,  1.7470e-01, -5.3378e-02,  1.0752e-01,\n          1.2539e-01, -5.7982e-02],\n        [ 1.5969e-01, -9.6993e-02, -1.5401e-01,  2.2945e-02, -1.7485e-01,\n         -7.4337e-02, -7.0942e-02, -3.8448e-02,  1.2479e-01,  1.2888e-01,\n          8.2658e-02,  8.0206e-02, -9.2847e-02,  1.0507e-01, -2.6539e-02,\n         -4.3573e-02, -1.2660e-01,  1.6652e-02, -1.1070e-01,  4.7836e-02,\n         -9.2427e-02,  1.3339e-01, -1.4368e-01,  1.3161e-02, -1.9655e-02,\n         -1.0014e-01,  7.2188e-02,  1.5072e-01, -4.5989e-03, -6.9399e-02,\n         -7.9791e-02,  4.9683e-02],\n        [ 1.1175e-01,  6.3458e-02, -6.0109e-02,  1.1138e-01,  1.7339e-01,\n         -7.4360e-03,  1.1723e-01,  1.0166e-01, -9.2496e-02, -1.0972e-01,\n          1.2535e-01, -6.0075e-02, -2.4612e-02, -9.0541e-02, -7.7487e-02,\n          1.6031e-01,  1.6141e-01, -1.3843e-01,  3.3756e-02, -3.2483e-02,\n         -2.2695e-02,  7.4871e-02, -1.3612e-01,  7.8258e-02,  7.4520e-02,\n          1.6888e-01, -1.3298e-03, -1.4945e-01,  5.1209e-02,  1.7274e-02,\n          4.3539e-02,  9.3672e-02],\n        [-3.5837e-02,  1.6287e-01,  6.8397e-02, -3.2395e-02,  4.9555e-02,\n          1.1659e-01,  1.7487e-01, -1.3780e-01, -5.7298e-03, -6.2892e-02,\n         -1.3565e-01,  7.6955e-02, -6.4712e-02,  5.0713e-02, -6.1667e-02,\n         -1.4999e-01,  7.3897e-03,  1.1860e-01, -1.3029e-01, -1.4273e-01,\n         -1.4546e-02, -4.9370e-02, -9.0232e-03,  3.1802e-02,  6.9833e-02,\n         -8.8423e-03,  9.1773e-02,  1.2718e-02, -4.8498e-02,  9.4710e-02,\n         -4.8236e-02, -3.7391e-02],\n        [ 9.2521e-02,  1.0043e-02,  1.1172e-02, -1.0771e-01, -2.8068e-02,\n          3.0948e-02,  8.2277e-02,  5.4257e-02, -4.8510e-02, -3.5977e-03,\n          3.9547e-02, -2.1860e-02, -1.6894e-01,  3.1078e-02, -1.6404e-01,\n          1.2755e-01,  1.6049e-01, -1.4614e-01,  6.0938e-02,  3.6312e-02,\n          1.6493e-01,  9.3164e-02,  5.6232e-03, -2.7718e-02, -1.1528e-01,\n         -7.4547e-03, -4.1419e-02,  1.7407e-01, -4.2398e-02, -3.1229e-02,\n         -1.4215e-01, -1.8963e-02],\n        [ 1.1764e-02, -1.1044e-01, -9.6304e-02,  1.4375e-02,  5.4798e-02,\n         -4.9744e-02,  1.4816e-01, -5.5470e-02,  1.4861e-01, -3.2316e-02,\n          5.9318e-02,  2.7269e-02,  6.9473e-04, -1.0116e-01, -1.3466e-01,\n         -7.1255e-02, -1.0854e-02,  8.0268e-02,  1.6839e-01,  1.6186e-01,\n          8.8575e-02,  5.8111e-02,  1.7563e-01,  7.9400e-02, -1.1153e-01,\n         -2.1140e-02, -1.0717e-01, -7.6016e-02, -1.6259e-01,  5.9520e-02,\n         -5.1766e-02,  7.8962e-02],\n        [ 2.0202e-02, -1.5890e-01, -3.1751e-02, -1.3521e-01, -4.6684e-02,\n          6.7112e-02, -1.3332e-01,  8.1339e-02, -1.3210e-01,  3.6548e-02,\n         -7.6052e-02,  1.2290e-01, -3.3881e-02,  8.3756e-03, -6.1772e-02,\n          1.0536e-01, -1.3720e-01, -4.0001e-02, -6.4616e-02,  1.5594e-01,\n         -3.1548e-03,  3.8754e-02, -1.5922e-01,  1.0546e-01,  1.4258e-01,\n          4.4821e-02, -1.0739e-01, -1.3833e-01,  1.4952e-01, -1.6534e-02,\n         -3.9432e-02, -1.4791e-02],\n        [ 9.2613e-02,  6.7360e-02,  6.4663e-02, -2.9160e-02,  9.2320e-02,\n          8.1219e-02, -3.5836e-02, -1.5717e-01,  1.1573e-01, -1.6359e-01,\n         -1.4163e-01,  1.1339e-01,  1.7449e-01, -1.5854e-01,  1.0326e-01,\n          8.5244e-02,  6.2750e-02, -2.7198e-02,  2.6064e-02, -1.4063e-01,\n         -1.2331e-01, -1.6408e-01,  8.6552e-02,  6.4195e-02,  6.8615e-02,\n          7.3888e-02, -1.0396e-01,  1.0796e-01,  7.7365e-02,  3.9342e-02,\n          9.1284e-02,  1.1817e-01],\n        [ 7.5377e-02,  7.8159e-02, -1.1795e-01, -1.3991e-01, -1.5731e-01,\n         -1.5840e-01,  3.8967e-02,  1.9945e-02,  1.1434e-01, -1.2514e-01,\n         -1.4527e-01, -6.7210e-02,  1.1069e-01,  4.4190e-02, -9.8581e-02,\n          5.7590e-02, -1.0853e-01,  2.5119e-02,  1.2910e-01,  1.7630e-01,\n          6.0483e-02, -7.0442e-02, -1.5552e-01,  7.0179e-02,  4.0846e-02,\n          4.6557e-02, -6.8990e-02,  1.1957e-01,  6.9984e-02, -2.8981e-02,\n         -1.2322e-01, -2.7279e-02],\n        [ 4.7888e-02, -1.3438e-01, -9.0263e-02,  7.0475e-02, -5.2481e-02,\n          1.0119e-01, -1.5909e-01, -4.9793e-03, -5.3413e-03, -6.1033e-02,\n          8.3804e-02,  4.8791e-02,  7.0376e-02, -5.7648e-02,  5.6012e-02,\n          1.0850e-01,  3.3839e-02, -1.2667e-01, -1.7559e-01,  1.5874e-01,\n         -1.2938e-02, -7.7410e-03, -6.6209e-02,  1.2877e-01, -8.7283e-02,\n         -3.7882e-02,  2.9776e-02,  1.5996e-01,  5.9676e-02,  1.2910e-01,\n          3.0351e-03, -1.6391e-01],\n        [-4.1804e-02, -8.9973e-02, -9.3640e-02, -1.0857e-01,  1.2262e-01,\n          1.5861e-02, -6.4606e-02,  1.3170e-01,  1.7341e-02, -1.2684e-01,\n         -1.6994e-01, -3.4509e-03,  1.0700e-01,  6.7113e-02, -7.7652e-02,\n          1.6447e-01, -1.7559e-01, -1.1139e-01, -1.8927e-02,  1.0949e-01,\n         -9.2958e-02,  1.4759e-01,  1.4728e-01, -1.0761e-01, -1.2417e-01,\n         -7.4869e-02,  7.9086e-02, -1.7436e-01, -1.2472e-01, -8.3420e-02,\n         -8.6176e-02, -1.4563e-01],\n        [ 9.2085e-02, -1.3644e-01, -1.5707e-01, -5.3715e-02,  2.4712e-02,\n          1.4888e-02, -1.4776e-02, -5.5143e-02, -1.4930e-01, -5.4352e-02,\n          1.6406e-01, -1.5400e-01, -2.0473e-02, -1.5169e-01,  1.9706e-02,\n          1.3753e-01, -1.1702e-01,  1.2611e-01,  7.4190e-02, -7.5334e-02,\n         -1.1739e-01,  1.7227e-02,  1.7072e-01,  3.8946e-03, -1.5707e-01,\n         -2.3260e-02,  6.1928e-02, -1.3278e-02, -8.3163e-02,  1.7366e-01,\n          8.1926e-03, -1.1140e-01],\n        [-1.2604e-01,  1.1190e-01, -1.6026e-01, -5.7573e-02,  1.4607e-01,\n          3.3733e-02, -7.5841e-03,  1.2709e-01, -1.2898e-01, -1.3731e-01,\n          1.6411e-01, -1.5661e-02,  8.6754e-02,  1.3128e-01, -1.1375e-01,\n         -1.7477e-01,  4.6021e-02, -1.6937e-01,  1.6460e-01,  5.8333e-02,\n          1.0346e-01, -1.4148e-01,  1.0069e-01,  1.5835e-01, -1.1118e-01,\n          1.5004e-01, -1.4493e-01,  1.7405e-01,  1.4925e-01, -2.7355e-02,\n         -1.7408e-02,  1.3963e-01],\n        [ 5.0516e-02,  1.6368e-01,  1.1452e-01,  6.5050e-02, -8.1408e-02,\n         -1.9731e-02, -2.8092e-02,  3.6666e-02, -1.4330e-01, -5.7269e-02,\n          1.2530e-01,  1.4706e-01,  1.3353e-01, -1.0881e-01,  1.0306e-01,\n         -1.0703e-01,  1.6314e-01, -7.1537e-02, -1.2922e-01,  1.0685e-01,\n         -6.9869e-03,  9.5913e-02, -2.5981e-02,  8.8950e-02, -1.6706e-01,\n          1.6661e-01,  1.0884e-01,  4.6238e-02, -8.5868e-03,  1.4864e-01,\n         -8.1640e-02,  5.4799e-02],\n        [-8.9645e-02,  7.9315e-02, -1.6393e-01,  3.1836e-02, -1.1960e-01,\n          2.2196e-02, -8.0669e-02, -5.0233e-02,  1.5296e-01,  5.9784e-02,\n          1.7754e-02,  1.2415e-01, -1.2185e-01, -1.2477e-02,  5.6729e-02,\n         -1.4258e-01, -4.7441e-02, -5.3944e-02,  1.1896e-02, -9.8694e-02,\n         -1.5050e-01,  2.2995e-02,  1.1789e-02, -2.3067e-02,  2.6370e-02,\n          1.4658e-02, -1.3688e-01, -1.5748e-01, -2.1104e-03, -1.0059e-01,\n          1.4201e-01, -1.7424e-01],\n        [-6.0265e-02, -8.9096e-02, -1.5117e-02, -7.6041e-02, -9.2520e-02,\n          1.2135e-01,  6.3280e-02, -9.6531e-03,  7.8570e-02,  5.1514e-02,\n          3.5361e-05, -7.5335e-02,  8.7161e-02, -6.1450e-02,  8.8447e-02,\n          1.0597e-01,  6.4674e-02, -7.5121e-02,  1.4737e-01, -4.5171e-03,\n         -1.2992e-01,  1.7479e-01, -1.7057e-02,  3.0610e-03,  1.2891e-01,\n          6.0282e-02,  7.9001e-02, -1.2830e-01,  1.0481e-01,  6.4951e-02,\n         -1.4619e-01, -4.8441e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0142, -0.2402, -0.0085, -0.2062, -0.0754,  0.2344, -0.2225, -0.1610],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0815, -0.2394, -0.0413, -0.0171,  0.1513,  0.0416, -0.2284,  0.2277,\n          0.0764, -0.2397,  0.1134,  0.1932,  0.0706, -0.2137,  0.0232,  0.1136],\n        [-0.1159, -0.0260,  0.0359, -0.1985, -0.0251,  0.2165,  0.2352, -0.1856,\n          0.0219,  0.1528, -0.1606, -0.2011,  0.0503, -0.0956,  0.1722, -0.0657],\n        [ 0.1052,  0.2005,  0.0211,  0.1948,  0.2198, -0.0321, -0.0827, -0.1283,\n          0.2498, -0.0198, -0.0534, -0.1847, -0.2376,  0.1586,  0.1152,  0.0456],\n        [-0.0428, -0.0749, -0.2377,  0.1174, -0.0581,  0.0999,  0.1477, -0.0042,\n          0.0930,  0.1169, -0.0726,  0.2462, -0.0988, -0.0415, -0.0376,  0.2369],\n        [ 0.1106, -0.1477,  0.1096,  0.1360,  0.1129,  0.1499,  0.1237,  0.0523,\n         -0.2085,  0.2436, -0.1454, -0.0321,  0.0321,  0.0523, -0.1371, -0.0184],\n        [-0.0759, -0.0686,  0.2171, -0.1954,  0.1563, -0.0024,  0.0400, -0.0906,\n         -0.1587,  0.0514, -0.0751, -0.1525,  0.1493, -0.0854,  0.2351, -0.0366],\n        [-0.1305, -0.1459, -0.2136, -0.2158, -0.1427, -0.0736, -0.1071,  0.0162,\n          0.1452, -0.0767,  0.1316,  0.2362,  0.1846, -0.1340, -0.0961, -0.1888],\n        [ 0.1128,  0.0665,  0.1438, -0.1864, -0.1764, -0.2499, -0.2150, -0.1187,\n         -0.2250, -0.0035,  0.1875, -0.1739,  0.2047, -0.0425, -0.1049,  0.2283]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1947,  0.1510,  0.0692, -0.1209], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3418,  0.1733,  0.1330,  0.3447,  0.0251,  0.1285, -0.3109,  0.2322],\n        [-0.3257, -0.2860,  0.0698,  0.2187, -0.2205, -0.2561, -0.2107,  0.2627],\n        [ 0.2308,  0.1987,  0.2391,  0.1831, -0.3396,  0.2284,  0.0131,  0.0338],\n        [-0.3145,  0.1578, -0.2176, -0.2082, -0.0203,  0.0191,  0.2839,  0.0880]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x78eb1eae9390>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s846220000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s846220000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}