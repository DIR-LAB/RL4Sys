{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	0,
    "batch_size":	128,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.0007,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s846290000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0003,
    "sample_decay":	0.5,
    "seed":	846290000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x78d5bda6c050>":	{
            "_act_dim":	4,
            "_aux_batch_size":	0,
            "_batch_size":	128,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.0007,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0485,  0.2030,  0.3408,  0.1712, -0.1142, -0.0708, -0.2274,  0.2129,\n        -0.0674, -0.3384,  0.1625,  0.0903,  0.1373,  0.0500,  0.2015, -0.1069,\n         0.2529,  0.1900,  0.0498, -0.1651, -0.0317,  0.3046, -0.2516, -0.2155,\n        -0.0251, -0.0758,  0.2649,  0.1089, -0.1718, -0.1409, -0.0442,  0.0550],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.3493e-01,  3.2802e-01, -2.0559e-02, -3.3843e-01,  2.1477e-01,\n          2.6533e-01,  1.5785e-02,  3.1021e-02],\n        [-1.0264e-01,  1.2191e-01, -3.1804e-01, -1.6217e-01, -5.0826e-02,\n          2.8706e-01, -3.4259e-01, -3.3625e-01],\n        [-2.7570e-01, -2.6660e-01, -2.3166e-01,  2.0400e-01, -1.2741e-01,\n          5.1278e-02, -2.2740e-01,  2.5822e-01],\n        [-3.2182e-01,  1.8786e-01, -2.4268e-01, -2.6643e-01, -1.1329e-01,\n          1.7511e-02,  4.2981e-02, -4.9539e-03],\n        [ 1.9617e-01,  1.4182e-01, -2.3032e-01, -3.0069e-01,  2.4118e-01,\n          6.1948e-02, -2.9794e-01,  1.8502e-01],\n        [-2.3560e-01,  1.1249e-01, -1.2615e-01, -1.2187e-01,  1.8981e-01,\n          2.8626e-01,  1.0242e-01, -1.5353e-01],\n        [ 3.4959e-01, -1.3524e-02,  1.9612e-01,  2.4872e-01, -8.6076e-02,\n          3.0855e-01,  6.8657e-03, -1.3934e-01],\n        [-2.9343e-01, -2.7964e-01, -1.2612e-02, -1.7712e-01,  3.1699e-01,\n         -8.5572e-02, -2.6071e-01, -9.6783e-02],\n        [-4.1621e-02, -2.1444e-03,  2.1137e-01,  2.3872e-02, -2.4904e-01,\n         -2.5712e-01,  9.5227e-02,  7.7434e-02],\n        [ 2.4482e-02,  1.0941e-02, -1.0775e-01,  2.6120e-02,  3.1278e-01,\n         -2.8721e-01,  3.4631e-01, -3.0748e-01],\n        [-1.4298e-01, -2.1385e-01, -7.9419e-02, -1.4409e-01, -2.1353e-01,\n          2.1107e-01,  1.7722e-01, -2.8535e-01],\n        [-3.0136e-01, -1.2597e-01,  5.9571e-02, -1.6800e-01, -1.6894e-02,\n         -2.7876e-01, -3.4280e-01,  3.2389e-01],\n        [-3.4513e-01,  4.0625e-04,  4.0428e-02, -3.2283e-01,  2.9377e-01,\n          1.1328e-01,  1.7042e-01, -2.2777e-01],\n        [ 1.2486e-01,  2.1517e-01,  1.0285e-01, -1.6236e-02, -2.6142e-01,\n          2.0958e-01,  2.8668e-01, -1.7590e-01],\n        [-9.6951e-02, -4.5841e-02, -3.0465e-01,  2.6064e-01, -3.0282e-01,\n          2.6526e-01, -2.2828e-01,  2.8520e-01],\n        [ 2.0941e-01,  2.9315e-01,  1.1836e-01, -6.4066e-02,  2.2269e-01,\n          4.5137e-02,  2.9528e-01,  2.4847e-01],\n        [ 1.2138e-01,  2.3101e-01,  9.3691e-02, -5.8842e-02, -1.0666e-01,\n          2.9714e-01, -2.3420e-02,  7.7742e-02],\n        [-1.9911e-01,  1.0350e-01,  9.0930e-02,  1.2738e-02, -2.6309e-01,\n          9.5863e-02, -3.1363e-01,  5.2120e-02],\n        [ 1.4069e-01, -3.0121e-01,  3.8848e-02, -8.3717e-02, -2.0395e-01,\n          2.7837e-01, -2.2854e-01, -1.8971e-01],\n        [-2.6739e-01,  2.2570e-01, -1.2171e-01,  2.6694e-01, -9.1033e-04,\n          2.6836e-01, -2.9571e-01, -9.9847e-02],\n        [ 2.4644e-01, -6.3207e-02,  3.4621e-02,  5.7097e-02, -9.1706e-02,\n         -1.3911e-01,  1.0197e-01, -3.3757e-01],\n        [-1.7091e-01, -4.2177e-02,  2.8543e-02, -3.0201e-01,  3.7016e-02,\n         -3.4117e-01,  2.9444e-01, -3.6977e-02],\n        [-2.5421e-01,  3.0789e-01,  1.3999e-01, -1.4792e-01, -3.1432e-01,\n         -4.7465e-02,  5.1398e-02,  6.3865e-02],\n        [ 2.6995e-02,  8.8155e-02, -2.4829e-04,  1.1161e-01, -2.3248e-01,\n         -1.1553e-01,  1.8823e-01,  1.2966e-01],\n        [ 1.7988e-01, -7.2963e-02,  2.7048e-01, -1.2755e-01, -3.1476e-01,\n         -1.3058e-01,  1.5149e-01, -4.8328e-02],\n        [ 3.1427e-01, -1.9782e-01,  3.2689e-01, -4.7879e-02, -3.4718e-01,\n          1.6541e-01, -6.8287e-02,  2.1375e-01],\n        [-2.4375e-01, -1.8613e-01,  1.3747e-01,  1.8854e-01,  2.5673e-01,\n          4.3313e-02,  1.9850e-01, -1.5298e-01],\n        [ 1.0372e-01, -1.7631e-01, -5.6638e-02, -2.9548e-01, -9.1000e-02,\n          2.7682e-02,  6.2897e-02,  3.0454e-01],\n        [-9.8701e-02, -3.5201e-01, -3.8171e-02,  2.8388e-01, -1.6773e-01,\n          2.2923e-01, -7.7163e-02,  1.7808e-01],\n        [-1.6036e-01,  1.6378e-01, -1.2630e-01, -1.9148e-01, -2.9390e-01,\n          8.4315e-02,  3.2741e-01, -1.1345e-01],\n        [-1.0995e-01, -2.2244e-01,  2.6986e-01,  5.0996e-03,  1.5868e-01,\n         -3.0379e-01, -2.0101e-01,  1.4308e-01],\n        [-2.4627e-01,  3.4392e-01,  3.4454e-01, -1.6722e-01, -1.9609e-01,\n         -3.4105e-02, -1.0993e-01, -2.6064e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1585, -0.0805, -0.1724,  0.1572,  0.0830,  0.1696, -0.1559, -0.1400,\n         0.0889,  0.0181, -0.1586,  0.0384, -0.0293, -0.0260,  0.1530, -0.1431],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.5440e-02, -7.2484e-02, -2.7200e-03,  1.0374e-02, -1.4785e-01,\n         -1.3226e-01, -4.9929e-02, -5.3796e-02,  1.5595e-01,  1.0597e-01,\n         -2.8745e-02,  1.7219e-01,  9.8140e-02, -1.3130e-01, -4.5824e-02,\n          2.5184e-03, -1.3752e-01, -3.1228e-02,  1.2423e-01,  1.0887e-01,\n         -1.5057e-01, -1.6446e-01,  4.3083e-02, -4.0209e-02, -1.3341e-01,\n          1.4837e-01, -7.6709e-02, -8.5881e-02, -3.6037e-02,  6.7376e-04,\n          7.5976e-02, -1.1362e-01],\n        [ 1.3284e-01, -1.6360e-01,  6.6205e-03, -2.9552e-02,  6.4616e-02,\n         -5.2206e-02,  8.0301e-02,  1.2422e-01,  2.3635e-02,  2.9912e-02,\n          1.0344e-01,  1.0584e-01, -3.5905e-02, -6.6372e-02, -5.2942e-02,\n         -1.7288e-01, -1.3341e-01, -2.0870e-02,  1.3892e-01, -1.0122e-01,\n          6.1132e-02, -1.2010e-01, -1.4334e-01, -1.6864e-01,  1.5523e-01,\n         -7.1098e-02,  1.3783e-01, -1.3306e-01, -1.0908e-01, -4.1493e-02,\n          1.7368e-02, -6.8669e-02],\n        [-1.9019e-02, -4.2749e-02,  8.8384e-02,  3.4167e-02,  9.7131e-02,\n         -8.5800e-02,  1.1554e-01, -1.6973e-01, -1.3984e-01, -8.0537e-02,\n          1.2758e-01,  1.4926e-01,  5.3905e-02, -1.0456e-01,  1.2793e-01,\n          1.7237e-01, -1.7243e-01,  7.3854e-02, -1.5596e-01,  6.4214e-02,\n         -1.6105e-01, -1.4726e-01, -8.7780e-02, -3.9616e-02, -2.8038e-02,\n         -1.0534e-01, -1.2451e-01, -1.0043e-01, -3.1631e-02, -1.4709e-01,\n          5.7059e-02,  1.4963e-01],\n        [ 1.5689e-01, -9.7794e-02, -6.2543e-02,  7.2685e-02,  2.9857e-02,\n         -2.7943e-02, -1.1272e-01, -8.7344e-02,  3.7176e-02,  1.7032e-01,\n          1.3209e-01, -1.0715e-01, -7.5940e-02, -2.1538e-02,  1.3272e-01,\n         -1.3803e-01,  1.5709e-01, -1.7072e-01,  3.3646e-02, -7.9473e-02,\n          1.6818e-01, -1.4626e-01,  9.2875e-02, -9.8897e-02,  6.5492e-02,\n          1.1334e-01,  1.4128e-01,  1.1913e-01, -1.0120e-01,  2.6941e-02,\n         -1.7733e-02,  1.6920e-01],\n        [-7.5610e-02,  1.1014e-01,  1.6422e-01,  1.5519e-01, -1.8984e-02,\n          1.5244e-01,  1.1899e-01, -1.4396e-01,  1.3794e-01, -1.6610e-01,\n          1.1122e-01,  4.9686e-02,  1.3472e-01, -1.6423e-04,  3.4441e-02,\n         -1.0749e-02,  3.8562e-02,  1.5256e-01, -1.5990e-01, -6.0810e-02,\n          1.7467e-03, -1.7114e-01,  5.7627e-02, -1.6100e-01, -3.2099e-02,\n         -2.2907e-02,  6.6358e-02, -1.5378e-01,  1.3464e-01,  1.5454e-02,\n          1.4004e-01,  1.4519e-01],\n        [ 1.1807e-01,  3.5622e-02, -1.6390e-01,  8.8443e-02, -1.3089e-01,\n         -1.7004e-01,  3.2855e-02,  5.9682e-02, -1.5281e-01, -6.5887e-02,\n          1.3927e-02, -4.5995e-02, -1.0860e-01,  1.7125e-02,  7.2542e-02,\n          8.1775e-03, -8.4339e-02,  8.0001e-03, -5.2979e-02,  3.7735e-02,\n         -6.9884e-02, -6.8766e-03,  1.4053e-01,  1.6236e-01,  8.8951e-02,\n          1.3567e-01, -5.0025e-02, -1.6907e-01,  7.7126e-02,  9.7058e-02,\n          6.1914e-02, -1.1642e-01],\n        [-3.6100e-02,  5.3417e-02, -1.5561e-01, -9.4601e-03,  1.5580e-01,\n         -3.1125e-02, -1.7581e-01, -5.1476e-02, -2.4438e-02,  1.1131e-01,\n          4.7294e-02,  4.2242e-02,  7.6689e-02, -5.7903e-02, -1.0784e-01,\n         -1.6320e-01,  1.5827e-01,  6.4489e-02,  3.8409e-02, -3.8158e-03,\n          1.1886e-01, -2.0337e-02, -4.9368e-02,  1.2470e-02, -2.6655e-02,\n          4.2971e-03, -6.7288e-02,  1.1565e-01, -1.0526e-01,  1.5418e-01,\n          7.4588e-02,  1.1736e-01],\n        [-1.6063e-01,  7.1328e-02, -1.6333e-01, -7.2586e-03,  1.3473e-02,\n          1.3883e-01,  7.0603e-02, -1.1747e-01, -5.3855e-02, -2.7124e-02,\n          1.0973e-01, -2.0026e-02,  9.6773e-02, -1.0654e-02,  1.3002e-01,\n          1.2533e-01,  9.9774e-02,  1.1363e-01, -8.2434e-02, -8.4696e-02,\n          5.9523e-02,  1.6307e-01,  3.8523e-02, -1.1448e-01,  1.0308e-01,\n         -1.0761e-01,  3.8470e-02, -1.2538e-02,  3.1591e-02, -1.1972e-01,\n         -1.5979e-01,  2.9303e-03],\n        [-3.8824e-02,  8.3319e-02, -1.6979e-01, -7.1218e-02,  1.6689e-01,\n          4.2378e-02, -1.5338e-01, -1.2863e-02, -7.4541e-02, -6.8707e-02,\n          1.2028e-01,  1.7424e-01, -1.9397e-02,  1.3455e-01, -6.7520e-02,\n          6.8566e-02,  1.6150e-01,  4.9588e-02,  1.7037e-02, -1.4367e-02,\n         -1.2432e-01, -1.3508e-01, -1.7023e-01, -7.9071e-02, -5.5427e-02,\n          8.6740e-02,  3.2669e-02, -6.2390e-02, -1.1160e-01,  1.6714e-01,\n          1.3148e-01,  1.4799e-01],\n        [-1.6304e-01, -9.8910e-02, -6.2274e-02, -1.0092e-01,  5.9529e-02,\n         -8.0258e-02,  1.5849e-01, -1.5228e-01,  1.5809e-01, -1.7087e-01,\n         -1.6177e-01, -1.0313e-01,  1.4798e-01,  1.0701e-01, -7.0244e-02,\n         -1.0262e-01, -3.6627e-02,  4.3983e-02,  4.8524e-02, -8.4422e-02,\n         -1.3397e-01,  1.0896e-01, -5.6087e-02, -1.2061e-01, -7.4419e-02,\n          1.4364e-01, -1.7305e-01,  1.2931e-01,  7.6992e-02, -1.1133e-01,\n          3.5483e-02,  8.9848e-02],\n        [-3.1601e-02, -1.1903e-02, -9.3290e-02,  1.6139e-01,  6.0869e-02,\n          8.4475e-02, -1.7107e-01, -7.9430e-02, -1.3523e-02, -7.1642e-02,\n         -1.1317e-01, -3.8422e-02, -1.4131e-01, -3.1238e-02,  9.7280e-02,\n          2.2758e-02, -1.5554e-01,  1.4353e-01, -9.8977e-03,  7.0956e-02,\n         -7.1951e-02, -2.5155e-02,  1.2468e-01, -1.6399e-01,  4.2886e-02,\n         -1.2387e-01, -2.5493e-02, -1.2842e-01,  6.1752e-02,  1.3466e-01,\n         -9.8484e-02,  1.6854e-01],\n        [-1.9993e-02, -4.8836e-02, -4.8439e-02, -8.9954e-02,  1.6484e-01,\n          6.0568e-02, -1.3807e-01,  4.4215e-02,  9.5211e-02,  6.5440e-03,\n          9.8178e-02, -1.3444e-01, -5.3073e-02,  3.9761e-02, -3.7745e-02,\n         -6.6312e-02, -7.1645e-02, -6.6420e-02,  1.7460e-01,  8.4450e-02,\n         -1.0115e-01, -2.6593e-02, -2.0200e-02,  5.9627e-02,  7.9374e-02,\n         -1.0449e-01,  6.4544e-02, -6.4354e-02,  4.0248e-02, -4.1830e-03,\n         -1.1229e-01, -7.8162e-02],\n        [-1.1970e-01, -2.5342e-02, -1.5758e-01, -1.1445e-01,  1.0343e-01,\n          1.0029e-01, -6.2679e-02,  3.1297e-02,  1.1694e-02,  1.0201e-01,\n         -1.7215e-01,  9.9843e-02, -1.6720e-01, -3.9397e-04, -8.3000e-04,\n          5.6644e-02,  1.0133e-01,  1.3812e-01, -1.2381e-01,  7.6299e-02,\n          3.8288e-02, -8.3457e-02, -6.9135e-02, -2.1587e-02, -5.3124e-02,\n         -3.7577e-02,  4.1564e-02,  1.6051e-01, -1.2378e-01,  1.0298e-01,\n          1.6018e-01, -2.6326e-02],\n        [ 1.7211e-03, -1.1935e-03, -9.7849e-02,  1.3151e-01, -9.9820e-02,\n          2.5047e-02,  3.3280e-02,  5.8661e-02, -9.6950e-02,  9.0985e-02,\n         -1.6988e-01,  6.1901e-02,  9.8058e-02,  1.7501e-01,  1.1393e-02,\n          8.5130e-02,  1.6437e-01,  1.1218e-01,  1.0909e-01, -2.0779e-02,\n          1.0648e-01,  8.7649e-02, -4.5130e-02,  6.3363e-02,  1.4603e-01,\n          4.4761e-02,  2.3356e-02, -5.3965e-02, -9.2599e-02,  1.7605e-01,\n         -1.3000e-01,  7.6455e-02],\n        [ 1.1665e-01, -1.2581e-01, -1.2375e-01,  9.2656e-02,  1.7660e-01,\n         -8.5118e-02,  8.3654e-02,  1.1872e-01,  1.5672e-01,  8.5404e-02,\n          1.2036e-02, -5.2177e-02,  1.4698e-01, -3.8140e-02,  1.4860e-01,\n          6.8817e-02,  9.3135e-02, -1.5041e-02, -8.3813e-02, -8.8493e-02,\n          1.2111e-02,  1.3643e-01,  4.7149e-02, -9.7445e-02, -1.4813e-01,\n          1.5512e-01,  9.2813e-02, -1.5127e-01, -1.2582e-02, -1.2613e-01,\n         -6.6748e-02, -1.0455e-01],\n        [-4.8161e-02, -1.5288e-01,  4.9622e-02, -8.2255e-02, -1.5094e-01,\n          6.0499e-02,  1.6517e-01, -1.5019e-01,  1.7275e-01, -8.8851e-02,\n          1.3257e-01,  8.4750e-02, -8.4744e-02,  1.5097e-01,  3.3221e-02,\n         -8.6348e-02, -1.1830e-01,  8.6054e-02, -1.6109e-01, -5.2584e-03,\n         -4.8228e-02,  1.6570e-01, -1.6710e-01,  3.7666e-02, -6.6822e-03,\n          1.2779e-01, -2.9407e-02, -1.2855e-01,  6.5137e-02, -1.1155e-01,\n         -9.5781e-02, -2.3853e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0966,  0.0967, -0.0636, -0.1542,  0.0729, -0.1601, -0.1845,  0.2478],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2419, -0.2046, -0.0342,  0.1941, -0.1772,  0.2136,  0.1943,  0.1089,\n          0.1845, -0.1113,  0.0342,  0.0410,  0.0894,  0.2244,  0.2462, -0.0480],\n        [-0.0255,  0.1338, -0.0955, -0.1670, -0.0335,  0.0827, -0.0584,  0.1517,\n         -0.1143, -0.0124, -0.1076,  0.0036,  0.1621,  0.2061, -0.0490,  0.0320],\n        [ 0.0589, -0.0937,  0.2397, -0.0411, -0.1521,  0.0060, -0.1711,  0.2107,\n          0.1161,  0.2181, -0.0346, -0.0928, -0.2021,  0.2007,  0.2116,  0.2377],\n        [-0.0347, -0.1755,  0.0592,  0.1718, -0.1790, -0.1685, -0.0923,  0.1942,\n          0.0321, -0.1375,  0.0191, -0.0311, -0.1912,  0.2462,  0.0460, -0.1926],\n        [-0.1062, -0.0886, -0.1472, -0.2499,  0.1107, -0.2203, -0.2041,  0.0811,\n         -0.1441,  0.0813, -0.0038,  0.1795, -0.2032, -0.1454, -0.1388, -0.0884],\n        [ 0.1199,  0.2024, -0.1749, -0.0020, -0.1605, -0.1087,  0.2368, -0.1994,\n          0.2137,  0.1443, -0.0534,  0.0927, -0.2171,  0.0893,  0.0244,  0.2338],\n        [-0.0674, -0.1809,  0.0976, -0.1965,  0.0942, -0.1991, -0.2217, -0.0386,\n         -0.1392,  0.1124, -0.2451,  0.0991, -0.0850, -0.0952, -0.1352,  0.0363],\n        [ 0.1670,  0.1238, -0.0267, -0.2227,  0.0824,  0.1395,  0.2242,  0.0981,\n          0.1538,  0.0097, -0.1367,  0.1887, -0.2012, -0.1793, -0.1115,  0.2142]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1607,  0.1999, -0.1698,  0.0085], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1462,  0.1983, -0.2522,  0.0965,  0.3152, -0.0483, -0.0186,  0.2704],\n        [ 0.2142,  0.1984, -0.0764, -0.1670,  0.0280, -0.3256, -0.3026,  0.3120],\n        [-0.0682, -0.0904, -0.0899, -0.1143,  0.1383, -0.0168, -0.3022,  0.2510],\n        [ 0.2214, -0.0270,  0.1453, -0.0087, -0.3455, -0.1590,  0.0374, -0.0724]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-1.3493e-01,  3.2802e-01, -2.0559e-02, -3.3843e-01,  2.1477e-01,\n          2.6533e-01,  1.5785e-02,  3.1021e-02],\n        [-1.0264e-01,  1.2191e-01, -3.1804e-01, -1.6217e-01, -5.0826e-02,\n          2.8706e-01, -3.4259e-01, -3.3625e-01],\n        [-2.7570e-01, -2.6660e-01, -2.3166e-01,  2.0400e-01, -1.2741e-01,\n          5.1278e-02, -2.2740e-01,  2.5822e-01],\n        [-3.2182e-01,  1.8786e-01, -2.4268e-01, -2.6643e-01, -1.1329e-01,\n          1.7511e-02,  4.2981e-02, -4.9539e-03],\n        [ 1.9617e-01,  1.4182e-01, -2.3032e-01, -3.0069e-01,  2.4118e-01,\n          6.1948e-02, -2.9794e-01,  1.8502e-01],\n        [-2.3560e-01,  1.1249e-01, -1.2615e-01, -1.2187e-01,  1.8981e-01,\n          2.8626e-01,  1.0242e-01, -1.5353e-01],\n        [ 3.4959e-01, -1.3524e-02,  1.9612e-01,  2.4872e-01, -8.6076e-02,\n          3.0855e-01,  6.8657e-03, -1.3934e-01],\n        [-2.9343e-01, -2.7964e-01, -1.2612e-02, -1.7712e-01,  3.1699e-01,\n         -8.5572e-02, -2.6071e-01, -9.6783e-02],\n        [-4.1621e-02, -2.1444e-03,  2.1137e-01,  2.3872e-02, -2.4904e-01,\n         -2.5712e-01,  9.5227e-02,  7.7434e-02],\n        [ 2.4482e-02,  1.0941e-02, -1.0775e-01,  2.6120e-02,  3.1278e-01,\n         -2.8721e-01,  3.4631e-01, -3.0748e-01],\n        [-1.4298e-01, -2.1385e-01, -7.9419e-02, -1.4409e-01, -2.1353e-01,\n          2.1107e-01,  1.7722e-01, -2.8535e-01],\n        [-3.0136e-01, -1.2597e-01,  5.9571e-02, -1.6800e-01, -1.6894e-02,\n         -2.7876e-01, -3.4280e-01,  3.2389e-01],\n        [-3.4513e-01,  4.0625e-04,  4.0428e-02, -3.2283e-01,  2.9377e-01,\n          1.1328e-01,  1.7042e-01, -2.2777e-01],\n        [ 1.2486e-01,  2.1517e-01,  1.0285e-01, -1.6236e-02, -2.6142e-01,\n          2.0958e-01,  2.8668e-01, -1.7590e-01],\n        [-9.6951e-02, -4.5841e-02, -3.0465e-01,  2.6064e-01, -3.0282e-01,\n          2.6526e-01, -2.2828e-01,  2.8520e-01],\n        [ 2.0941e-01,  2.9315e-01,  1.1836e-01, -6.4066e-02,  2.2269e-01,\n          4.5137e-02,  2.9528e-01,  2.4847e-01],\n        [ 1.2138e-01,  2.3101e-01,  9.3691e-02, -5.8842e-02, -1.0666e-01,\n          2.9714e-01, -2.3420e-02,  7.7742e-02],\n        [-1.9911e-01,  1.0350e-01,  9.0930e-02,  1.2738e-02, -2.6309e-01,\n          9.5863e-02, -3.1363e-01,  5.2120e-02],\n        [ 1.4069e-01, -3.0121e-01,  3.8848e-02, -8.3717e-02, -2.0395e-01,\n          2.7837e-01, -2.2854e-01, -1.8971e-01],\n        [-2.6739e-01,  2.2570e-01, -1.2171e-01,  2.6694e-01, -9.1033e-04,\n          2.6836e-01, -2.9571e-01, -9.9847e-02],\n        [ 2.4644e-01, -6.3207e-02,  3.4621e-02,  5.7097e-02, -9.1706e-02,\n         -1.3911e-01,  1.0197e-01, -3.3757e-01],\n        [-1.7091e-01, -4.2177e-02,  2.8543e-02, -3.0201e-01,  3.7016e-02,\n         -3.4117e-01,  2.9444e-01, -3.6977e-02],\n        [-2.5421e-01,  3.0789e-01,  1.3999e-01, -1.4792e-01, -3.1432e-01,\n         -4.7465e-02,  5.1398e-02,  6.3865e-02],\n        [ 2.6995e-02,  8.8155e-02, -2.4829e-04,  1.1161e-01, -2.3248e-01,\n         -1.1553e-01,  1.8823e-01,  1.2966e-01],\n        [ 1.7988e-01, -7.2963e-02,  2.7048e-01, -1.2755e-01, -3.1476e-01,\n         -1.3058e-01,  1.5149e-01, -4.8328e-02],\n        [ 3.1427e-01, -1.9782e-01,  3.2689e-01, -4.7879e-02, -3.4718e-01,\n          1.6541e-01, -6.8287e-02,  2.1375e-01],\n        [-2.4375e-01, -1.8613e-01,  1.3747e-01,  1.8854e-01,  2.5673e-01,\n          4.3313e-02,  1.9850e-01, -1.5298e-01],\n        [ 1.0372e-01, -1.7631e-01, -5.6638e-02, -2.9548e-01, -9.1000e-02,\n          2.7682e-02,  6.2897e-02,  3.0454e-01],\n        [-9.8701e-02, -3.5201e-01, -3.8171e-02,  2.8388e-01, -1.6773e-01,\n          2.2923e-01, -7.7163e-02,  1.7808e-01],\n        [-1.6036e-01,  1.6378e-01, -1.2630e-01, -1.9148e-01, -2.9390e-01,\n          8.4315e-02,  3.2741e-01, -1.1345e-01],\n        [-1.0995e-01, -2.2244e-01,  2.6986e-01,  5.0996e-03,  1.5868e-01,\n         -3.0379e-01, -2.0101e-01,  1.4308e-01],\n        [-2.4627e-01,  3.4392e-01,  3.4454e-01, -1.6722e-01, -1.9609e-01,\n         -3.4105e-02, -1.0993e-01, -2.6064e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0485,  0.2030,  0.3408,  0.1712, -0.1142, -0.0708, -0.2274,  0.2129,\n        -0.0674, -0.3384,  0.1625,  0.0903,  0.1373,  0.0500,  0.2015, -0.1069,\n         0.2529,  0.1900,  0.0498, -0.1651, -0.0317,  0.3046, -0.2516, -0.2155,\n        -0.0251, -0.0758,  0.2649,  0.1089, -0.1718, -0.1409, -0.0442,  0.0550],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-8.5440e-02, -7.2484e-02, -2.7200e-03,  1.0374e-02, -1.4785e-01,\n         -1.3226e-01, -4.9929e-02, -5.3796e-02,  1.5595e-01,  1.0597e-01,\n         -2.8745e-02,  1.7219e-01,  9.8140e-02, -1.3130e-01, -4.5824e-02,\n          2.5184e-03, -1.3752e-01, -3.1228e-02,  1.2423e-01,  1.0887e-01,\n         -1.5057e-01, -1.6446e-01,  4.3083e-02, -4.0209e-02, -1.3341e-01,\n          1.4837e-01, -7.6709e-02, -8.5881e-02, -3.6037e-02,  6.7376e-04,\n          7.5976e-02, -1.1362e-01],\n        [ 1.3284e-01, -1.6360e-01,  6.6205e-03, -2.9552e-02,  6.4616e-02,\n         -5.2206e-02,  8.0301e-02,  1.2422e-01,  2.3635e-02,  2.9912e-02,\n          1.0344e-01,  1.0584e-01, -3.5905e-02, -6.6372e-02, -5.2942e-02,\n         -1.7288e-01, -1.3341e-01, -2.0870e-02,  1.3892e-01, -1.0122e-01,\n          6.1132e-02, -1.2010e-01, -1.4334e-01, -1.6864e-01,  1.5523e-01,\n         -7.1098e-02,  1.3783e-01, -1.3306e-01, -1.0908e-01, -4.1493e-02,\n          1.7368e-02, -6.8669e-02],\n        [-1.9019e-02, -4.2749e-02,  8.8384e-02,  3.4167e-02,  9.7131e-02,\n         -8.5800e-02,  1.1554e-01, -1.6973e-01, -1.3984e-01, -8.0537e-02,\n          1.2758e-01,  1.4926e-01,  5.3905e-02, -1.0456e-01,  1.2793e-01,\n          1.7237e-01, -1.7243e-01,  7.3854e-02, -1.5596e-01,  6.4214e-02,\n         -1.6105e-01, -1.4726e-01, -8.7780e-02, -3.9616e-02, -2.8038e-02,\n         -1.0534e-01, -1.2451e-01, -1.0043e-01, -3.1631e-02, -1.4709e-01,\n          5.7059e-02,  1.4963e-01],\n        [ 1.5689e-01, -9.7794e-02, -6.2543e-02,  7.2685e-02,  2.9857e-02,\n         -2.7943e-02, -1.1272e-01, -8.7344e-02,  3.7176e-02,  1.7032e-01,\n          1.3209e-01, -1.0715e-01, -7.5940e-02, -2.1538e-02,  1.3272e-01,\n         -1.3803e-01,  1.5709e-01, -1.7072e-01,  3.3646e-02, -7.9473e-02,\n          1.6818e-01, -1.4626e-01,  9.2875e-02, -9.8897e-02,  6.5492e-02,\n          1.1334e-01,  1.4128e-01,  1.1913e-01, -1.0120e-01,  2.6941e-02,\n         -1.7733e-02,  1.6920e-01],\n        [-7.5610e-02,  1.1014e-01,  1.6422e-01,  1.5519e-01, -1.8984e-02,\n          1.5244e-01,  1.1899e-01, -1.4396e-01,  1.3794e-01, -1.6610e-01,\n          1.1122e-01,  4.9686e-02,  1.3472e-01, -1.6423e-04,  3.4441e-02,\n         -1.0749e-02,  3.8562e-02,  1.5256e-01, -1.5990e-01, -6.0810e-02,\n          1.7467e-03, -1.7114e-01,  5.7627e-02, -1.6100e-01, -3.2099e-02,\n         -2.2907e-02,  6.6358e-02, -1.5378e-01,  1.3464e-01,  1.5454e-02,\n          1.4004e-01,  1.4519e-01],\n        [ 1.1807e-01,  3.5622e-02, -1.6390e-01,  8.8443e-02, -1.3089e-01,\n         -1.7004e-01,  3.2855e-02,  5.9682e-02, -1.5281e-01, -6.5887e-02,\n          1.3927e-02, -4.5995e-02, -1.0860e-01,  1.7125e-02,  7.2542e-02,\n          8.1775e-03, -8.4339e-02,  8.0001e-03, -5.2979e-02,  3.7735e-02,\n         -6.9884e-02, -6.8766e-03,  1.4053e-01,  1.6236e-01,  8.8951e-02,\n          1.3567e-01, -5.0025e-02, -1.6907e-01,  7.7126e-02,  9.7058e-02,\n          6.1914e-02, -1.1642e-01],\n        [-3.6100e-02,  5.3417e-02, -1.5561e-01, -9.4601e-03,  1.5580e-01,\n         -3.1125e-02, -1.7581e-01, -5.1476e-02, -2.4438e-02,  1.1131e-01,\n          4.7294e-02,  4.2242e-02,  7.6689e-02, -5.7903e-02, -1.0784e-01,\n         -1.6320e-01,  1.5827e-01,  6.4489e-02,  3.8409e-02, -3.8158e-03,\n          1.1886e-01, -2.0337e-02, -4.9368e-02,  1.2470e-02, -2.6655e-02,\n          4.2971e-03, -6.7288e-02,  1.1565e-01, -1.0526e-01,  1.5418e-01,\n          7.4588e-02,  1.1736e-01],\n        [-1.6063e-01,  7.1328e-02, -1.6333e-01, -7.2586e-03,  1.3473e-02,\n          1.3883e-01,  7.0603e-02, -1.1747e-01, -5.3855e-02, -2.7124e-02,\n          1.0973e-01, -2.0026e-02,  9.6773e-02, -1.0654e-02,  1.3002e-01,\n          1.2533e-01,  9.9774e-02,  1.1363e-01, -8.2434e-02, -8.4696e-02,\n          5.9523e-02,  1.6307e-01,  3.8523e-02, -1.1448e-01,  1.0308e-01,\n         -1.0761e-01,  3.8470e-02, -1.2538e-02,  3.1591e-02, -1.1972e-01,\n         -1.5979e-01,  2.9303e-03],\n        [-3.8824e-02,  8.3319e-02, -1.6979e-01, -7.1218e-02,  1.6689e-01,\n          4.2378e-02, -1.5338e-01, -1.2863e-02, -7.4541e-02, -6.8707e-02,\n          1.2028e-01,  1.7424e-01, -1.9397e-02,  1.3455e-01, -6.7520e-02,\n          6.8566e-02,  1.6150e-01,  4.9588e-02,  1.7037e-02, -1.4367e-02,\n         -1.2432e-01, -1.3508e-01, -1.7023e-01, -7.9071e-02, -5.5427e-02,\n          8.6740e-02,  3.2669e-02, -6.2390e-02, -1.1160e-01,  1.6714e-01,\n          1.3148e-01,  1.4799e-01],\n        [-1.6304e-01, -9.8910e-02, -6.2274e-02, -1.0092e-01,  5.9529e-02,\n         -8.0258e-02,  1.5849e-01, -1.5228e-01,  1.5809e-01, -1.7087e-01,\n         -1.6177e-01, -1.0313e-01,  1.4798e-01,  1.0701e-01, -7.0244e-02,\n         -1.0262e-01, -3.6627e-02,  4.3983e-02,  4.8524e-02, -8.4422e-02,\n         -1.3397e-01,  1.0896e-01, -5.6087e-02, -1.2061e-01, -7.4419e-02,\n          1.4364e-01, -1.7305e-01,  1.2931e-01,  7.6992e-02, -1.1133e-01,\n          3.5483e-02,  8.9848e-02],\n        [-3.1601e-02, -1.1903e-02, -9.3290e-02,  1.6139e-01,  6.0869e-02,\n          8.4475e-02, -1.7107e-01, -7.9430e-02, -1.3523e-02, -7.1642e-02,\n         -1.1317e-01, -3.8422e-02, -1.4131e-01, -3.1238e-02,  9.7280e-02,\n          2.2758e-02, -1.5554e-01,  1.4353e-01, -9.8977e-03,  7.0956e-02,\n         -7.1951e-02, -2.5155e-02,  1.2468e-01, -1.6399e-01,  4.2886e-02,\n         -1.2387e-01, -2.5493e-02, -1.2842e-01,  6.1752e-02,  1.3466e-01,\n         -9.8484e-02,  1.6854e-01],\n        [-1.9993e-02, -4.8836e-02, -4.8439e-02, -8.9954e-02,  1.6484e-01,\n          6.0568e-02, -1.3807e-01,  4.4215e-02,  9.5211e-02,  6.5440e-03,\n          9.8178e-02, -1.3444e-01, -5.3073e-02,  3.9761e-02, -3.7745e-02,\n         -6.6312e-02, -7.1645e-02, -6.6420e-02,  1.7460e-01,  8.4450e-02,\n         -1.0115e-01, -2.6593e-02, -2.0200e-02,  5.9627e-02,  7.9374e-02,\n         -1.0449e-01,  6.4544e-02, -6.4354e-02,  4.0248e-02, -4.1830e-03,\n         -1.1229e-01, -7.8162e-02],\n        [-1.1970e-01, -2.5342e-02, -1.5758e-01, -1.1445e-01,  1.0343e-01,\n          1.0029e-01, -6.2679e-02,  3.1297e-02,  1.1694e-02,  1.0201e-01,\n         -1.7215e-01,  9.9843e-02, -1.6720e-01, -3.9397e-04, -8.3000e-04,\n          5.6644e-02,  1.0133e-01,  1.3812e-01, -1.2381e-01,  7.6299e-02,\n          3.8288e-02, -8.3457e-02, -6.9135e-02, -2.1587e-02, -5.3124e-02,\n         -3.7577e-02,  4.1564e-02,  1.6051e-01, -1.2378e-01,  1.0298e-01,\n          1.6018e-01, -2.6326e-02],\n        [ 1.7211e-03, -1.1935e-03, -9.7849e-02,  1.3151e-01, -9.9820e-02,\n          2.5047e-02,  3.3280e-02,  5.8661e-02, -9.6950e-02,  9.0985e-02,\n         -1.6988e-01,  6.1901e-02,  9.8058e-02,  1.7501e-01,  1.1393e-02,\n          8.5130e-02,  1.6437e-01,  1.1218e-01,  1.0909e-01, -2.0779e-02,\n          1.0648e-01,  8.7649e-02, -4.5130e-02,  6.3363e-02,  1.4603e-01,\n          4.4761e-02,  2.3356e-02, -5.3965e-02, -9.2599e-02,  1.7605e-01,\n         -1.3000e-01,  7.6455e-02],\n        [ 1.1665e-01, -1.2581e-01, -1.2375e-01,  9.2656e-02,  1.7660e-01,\n         -8.5118e-02,  8.3654e-02,  1.1872e-01,  1.5672e-01,  8.5404e-02,\n          1.2036e-02, -5.2177e-02,  1.4698e-01, -3.8140e-02,  1.4860e-01,\n          6.8817e-02,  9.3135e-02, -1.5041e-02, -8.3813e-02, -8.8493e-02,\n          1.2111e-02,  1.3643e-01,  4.7149e-02, -9.7445e-02, -1.4813e-01,\n          1.5512e-01,  9.2813e-02, -1.5127e-01, -1.2582e-02, -1.2613e-01,\n         -6.6748e-02, -1.0455e-01],\n        [-4.8161e-02, -1.5288e-01,  4.9622e-02, -8.2255e-02, -1.5094e-01,\n          6.0499e-02,  1.6517e-01, -1.5019e-01,  1.7275e-01, -8.8851e-02,\n          1.3257e-01,  8.4750e-02, -8.4744e-02,  1.5097e-01,  3.3221e-02,\n         -8.6348e-02, -1.1830e-01,  8.6054e-02, -1.6109e-01, -5.2584e-03,\n         -4.8228e-02,  1.6570e-01, -1.6710e-01,  3.7666e-02, -6.6822e-03,\n          1.2779e-01, -2.9407e-02, -1.2855e-01,  6.5137e-02, -1.1155e-01,\n         -9.5781e-02, -2.3853e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1585, -0.0805, -0.1724,  0.1572,  0.0830,  0.1696, -0.1559, -0.1400,\n         0.0889,  0.0181, -0.1586,  0.0384, -0.0293, -0.0260,  0.1530, -0.1431],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2419, -0.2046, -0.0342,  0.1941, -0.1772,  0.2136,  0.1943,  0.1089,\n          0.1845, -0.1113,  0.0342,  0.0410,  0.0894,  0.2244,  0.2462, -0.0480],\n        [-0.0255,  0.1338, -0.0955, -0.1670, -0.0335,  0.0827, -0.0584,  0.1517,\n         -0.1143, -0.0124, -0.1076,  0.0036,  0.1621,  0.2061, -0.0490,  0.0320],\n        [ 0.0589, -0.0937,  0.2397, -0.0411, -0.1521,  0.0060, -0.1711,  0.2107,\n          0.1161,  0.2181, -0.0346, -0.0928, -0.2021,  0.2007,  0.2116,  0.2377],\n        [-0.0347, -0.1755,  0.0592,  0.1718, -0.1790, -0.1685, -0.0923,  0.1942,\n          0.0321, -0.1375,  0.0191, -0.0311, -0.1912,  0.2462,  0.0460, -0.1926],\n        [-0.1062, -0.0886, -0.1472, -0.2499,  0.1107, -0.2203, -0.2041,  0.0811,\n         -0.1441,  0.0813, -0.0038,  0.1795, -0.2032, -0.1454, -0.1388, -0.0884],\n        [ 0.1199,  0.2024, -0.1749, -0.0020, -0.1605, -0.1087,  0.2368, -0.1994,\n          0.2137,  0.1443, -0.0534,  0.0927, -0.2171,  0.0893,  0.0244,  0.2338],\n        [-0.0674, -0.1809,  0.0976, -0.1965,  0.0942, -0.1991, -0.2217, -0.0386,\n         -0.1392,  0.1124, -0.2451,  0.0991, -0.0850, -0.0952, -0.1352,  0.0363],\n        [ 0.1670,  0.1238, -0.0267, -0.2227,  0.0824,  0.1395,  0.2242,  0.0981,\n          0.1538,  0.0097, -0.1367,  0.1887, -0.2012, -0.1793, -0.1115,  0.2142]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0966,  0.0967, -0.0636, -0.1542,  0.0729, -0.1601, -0.1845,  0.2478],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1462,  0.1983, -0.2522,  0.0965,  0.3152, -0.0483, -0.0186,  0.2704],\n        [ 0.2142,  0.1984, -0.0764, -0.1670,  0.0280, -0.3256, -0.3026,  0.3120],\n        [-0.0682, -0.0904, -0.0899, -0.1143,  0.1383, -0.0168, -0.3022,  0.2510],\n        [ 0.2214, -0.0270,  0.1453, -0.0087, -0.3455, -0.1590,  0.0374, -0.0724]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1607,  0.1999, -0.1698,  0.0085], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x78d63d9bde50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x78d5bc062e10>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.0007,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0485,  0.2030,  0.3408,  0.1712, -0.1142, -0.0708, -0.2274,  0.2129,\n        -0.0674, -0.3384,  0.1625,  0.0903,  0.1373,  0.0500,  0.2015, -0.1069,\n         0.2529,  0.1900,  0.0498, -0.1651, -0.0317,  0.3046, -0.2516, -0.2155,\n        -0.0251, -0.0758,  0.2649,  0.1089, -0.1718, -0.1409, -0.0442,  0.0550],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.3493e-01,  3.2802e-01, -2.0559e-02, -3.3843e-01,  2.1477e-01,\n          2.6533e-01,  1.5785e-02,  3.1021e-02],\n        [-1.0264e-01,  1.2191e-01, -3.1804e-01, -1.6217e-01, -5.0826e-02,\n          2.8706e-01, -3.4259e-01, -3.3625e-01],\n        [-2.7570e-01, -2.6660e-01, -2.3166e-01,  2.0400e-01, -1.2741e-01,\n          5.1278e-02, -2.2740e-01,  2.5822e-01],\n        [-3.2182e-01,  1.8786e-01, -2.4268e-01, -2.6643e-01, -1.1329e-01,\n          1.7511e-02,  4.2981e-02, -4.9539e-03],\n        [ 1.9617e-01,  1.4182e-01, -2.3032e-01, -3.0069e-01,  2.4118e-01,\n          6.1948e-02, -2.9794e-01,  1.8502e-01],\n        [-2.3560e-01,  1.1249e-01, -1.2615e-01, -1.2187e-01,  1.8981e-01,\n          2.8626e-01,  1.0242e-01, -1.5353e-01],\n        [ 3.4959e-01, -1.3524e-02,  1.9612e-01,  2.4872e-01, -8.6076e-02,\n          3.0855e-01,  6.8657e-03, -1.3934e-01],\n        [-2.9343e-01, -2.7964e-01, -1.2612e-02, -1.7712e-01,  3.1699e-01,\n         -8.5572e-02, -2.6071e-01, -9.6783e-02],\n        [-4.1621e-02, -2.1444e-03,  2.1137e-01,  2.3872e-02, -2.4904e-01,\n         -2.5712e-01,  9.5227e-02,  7.7434e-02],\n        [ 2.4482e-02,  1.0941e-02, -1.0775e-01,  2.6120e-02,  3.1278e-01,\n         -2.8721e-01,  3.4631e-01, -3.0748e-01],\n        [-1.4298e-01, -2.1385e-01, -7.9419e-02, -1.4409e-01, -2.1353e-01,\n          2.1107e-01,  1.7722e-01, -2.8535e-01],\n        [-3.0136e-01, -1.2597e-01,  5.9571e-02, -1.6800e-01, -1.6894e-02,\n         -2.7876e-01, -3.4280e-01,  3.2389e-01],\n        [-3.4513e-01,  4.0625e-04,  4.0428e-02, -3.2283e-01,  2.9377e-01,\n          1.1328e-01,  1.7042e-01, -2.2777e-01],\n        [ 1.2486e-01,  2.1517e-01,  1.0285e-01, -1.6236e-02, -2.6142e-01,\n          2.0958e-01,  2.8668e-01, -1.7590e-01],\n        [-9.6951e-02, -4.5841e-02, -3.0465e-01,  2.6064e-01, -3.0282e-01,\n          2.6526e-01, -2.2828e-01,  2.8520e-01],\n        [ 2.0941e-01,  2.9315e-01,  1.1836e-01, -6.4066e-02,  2.2269e-01,\n          4.5137e-02,  2.9528e-01,  2.4847e-01],\n        [ 1.2138e-01,  2.3101e-01,  9.3691e-02, -5.8842e-02, -1.0666e-01,\n          2.9714e-01, -2.3420e-02,  7.7742e-02],\n        [-1.9911e-01,  1.0350e-01,  9.0930e-02,  1.2738e-02, -2.6309e-01,\n          9.5863e-02, -3.1363e-01,  5.2120e-02],\n        [ 1.4069e-01, -3.0121e-01,  3.8848e-02, -8.3717e-02, -2.0395e-01,\n          2.7837e-01, -2.2854e-01, -1.8971e-01],\n        [-2.6739e-01,  2.2570e-01, -1.2171e-01,  2.6694e-01, -9.1033e-04,\n          2.6836e-01, -2.9571e-01, -9.9847e-02],\n        [ 2.4644e-01, -6.3207e-02,  3.4621e-02,  5.7097e-02, -9.1706e-02,\n         -1.3911e-01,  1.0197e-01, -3.3757e-01],\n        [-1.7091e-01, -4.2177e-02,  2.8543e-02, -3.0201e-01,  3.7016e-02,\n         -3.4117e-01,  2.9444e-01, -3.6977e-02],\n        [-2.5421e-01,  3.0789e-01,  1.3999e-01, -1.4792e-01, -3.1432e-01,\n         -4.7465e-02,  5.1398e-02,  6.3865e-02],\n        [ 2.6995e-02,  8.8155e-02, -2.4829e-04,  1.1161e-01, -2.3248e-01,\n         -1.1553e-01,  1.8823e-01,  1.2966e-01],\n        [ 1.7988e-01, -7.2963e-02,  2.7048e-01, -1.2755e-01, -3.1476e-01,\n         -1.3058e-01,  1.5149e-01, -4.8328e-02],\n        [ 3.1427e-01, -1.9782e-01,  3.2689e-01, -4.7879e-02, -3.4718e-01,\n          1.6541e-01, -6.8287e-02,  2.1375e-01],\n        [-2.4375e-01, -1.8613e-01,  1.3747e-01,  1.8854e-01,  2.5673e-01,\n          4.3313e-02,  1.9850e-01, -1.5298e-01],\n        [ 1.0372e-01, -1.7631e-01, -5.6638e-02, -2.9548e-01, -9.1000e-02,\n          2.7682e-02,  6.2897e-02,  3.0454e-01],\n        [-9.8701e-02, -3.5201e-01, -3.8171e-02,  2.8388e-01, -1.6773e-01,\n          2.2923e-01, -7.7163e-02,  1.7808e-01],\n        [-1.6036e-01,  1.6378e-01, -1.2630e-01, -1.9148e-01, -2.9390e-01,\n          8.4315e-02,  3.2741e-01, -1.1345e-01],\n        [-1.0995e-01, -2.2244e-01,  2.6986e-01,  5.0996e-03,  1.5868e-01,\n         -3.0379e-01, -2.0101e-01,  1.4308e-01],\n        [-2.4627e-01,  3.4392e-01,  3.4454e-01, -1.6722e-01, -1.9609e-01,\n         -3.4105e-02, -1.0993e-01, -2.6064e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1585, -0.0805, -0.1724,  0.1572,  0.0830,  0.1696, -0.1559, -0.1400,\n         0.0889,  0.0181, -0.1586,  0.0384, -0.0293, -0.0260,  0.1530, -0.1431],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.5440e-02, -7.2484e-02, -2.7200e-03,  1.0374e-02, -1.4785e-01,\n         -1.3226e-01, -4.9929e-02, -5.3796e-02,  1.5595e-01,  1.0597e-01,\n         -2.8745e-02,  1.7219e-01,  9.8140e-02, -1.3130e-01, -4.5824e-02,\n          2.5184e-03, -1.3752e-01, -3.1228e-02,  1.2423e-01,  1.0887e-01,\n         -1.5057e-01, -1.6446e-01,  4.3083e-02, -4.0209e-02, -1.3341e-01,\n          1.4837e-01, -7.6709e-02, -8.5881e-02, -3.6037e-02,  6.7376e-04,\n          7.5976e-02, -1.1362e-01],\n        [ 1.3284e-01, -1.6360e-01,  6.6205e-03, -2.9552e-02,  6.4616e-02,\n         -5.2206e-02,  8.0301e-02,  1.2422e-01,  2.3635e-02,  2.9912e-02,\n          1.0344e-01,  1.0584e-01, -3.5905e-02, -6.6372e-02, -5.2942e-02,\n         -1.7288e-01, -1.3341e-01, -2.0870e-02,  1.3892e-01, -1.0122e-01,\n          6.1132e-02, -1.2010e-01, -1.4334e-01, -1.6864e-01,  1.5523e-01,\n         -7.1098e-02,  1.3783e-01, -1.3306e-01, -1.0908e-01, -4.1493e-02,\n          1.7368e-02, -6.8669e-02],\n        [-1.9019e-02, -4.2749e-02,  8.8384e-02,  3.4167e-02,  9.7131e-02,\n         -8.5800e-02,  1.1554e-01, -1.6973e-01, -1.3984e-01, -8.0537e-02,\n          1.2758e-01,  1.4926e-01,  5.3905e-02, -1.0456e-01,  1.2793e-01,\n          1.7237e-01, -1.7243e-01,  7.3854e-02, -1.5596e-01,  6.4214e-02,\n         -1.6105e-01, -1.4726e-01, -8.7780e-02, -3.9616e-02, -2.8038e-02,\n         -1.0534e-01, -1.2451e-01, -1.0043e-01, -3.1631e-02, -1.4709e-01,\n          5.7059e-02,  1.4963e-01],\n        [ 1.5689e-01, -9.7794e-02, -6.2543e-02,  7.2685e-02,  2.9857e-02,\n         -2.7943e-02, -1.1272e-01, -8.7344e-02,  3.7176e-02,  1.7032e-01,\n          1.3209e-01, -1.0715e-01, -7.5940e-02, -2.1538e-02,  1.3272e-01,\n         -1.3803e-01,  1.5709e-01, -1.7072e-01,  3.3646e-02, -7.9473e-02,\n          1.6818e-01, -1.4626e-01,  9.2875e-02, -9.8897e-02,  6.5492e-02,\n          1.1334e-01,  1.4128e-01,  1.1913e-01, -1.0120e-01,  2.6941e-02,\n         -1.7733e-02,  1.6920e-01],\n        [-7.5610e-02,  1.1014e-01,  1.6422e-01,  1.5519e-01, -1.8984e-02,\n          1.5244e-01,  1.1899e-01, -1.4396e-01,  1.3794e-01, -1.6610e-01,\n          1.1122e-01,  4.9686e-02,  1.3472e-01, -1.6423e-04,  3.4441e-02,\n         -1.0749e-02,  3.8562e-02,  1.5256e-01, -1.5990e-01, -6.0810e-02,\n          1.7467e-03, -1.7114e-01,  5.7627e-02, -1.6100e-01, -3.2099e-02,\n         -2.2907e-02,  6.6358e-02, -1.5378e-01,  1.3464e-01,  1.5454e-02,\n          1.4004e-01,  1.4519e-01],\n        [ 1.1807e-01,  3.5622e-02, -1.6390e-01,  8.8443e-02, -1.3089e-01,\n         -1.7004e-01,  3.2855e-02,  5.9682e-02, -1.5281e-01, -6.5887e-02,\n          1.3927e-02, -4.5995e-02, -1.0860e-01,  1.7125e-02,  7.2542e-02,\n          8.1775e-03, -8.4339e-02,  8.0001e-03, -5.2979e-02,  3.7735e-02,\n         -6.9884e-02, -6.8766e-03,  1.4053e-01,  1.6236e-01,  8.8951e-02,\n          1.3567e-01, -5.0025e-02, -1.6907e-01,  7.7126e-02,  9.7058e-02,\n          6.1914e-02, -1.1642e-01],\n        [-3.6100e-02,  5.3417e-02, -1.5561e-01, -9.4601e-03,  1.5580e-01,\n         -3.1125e-02, -1.7581e-01, -5.1476e-02, -2.4438e-02,  1.1131e-01,\n          4.7294e-02,  4.2242e-02,  7.6689e-02, -5.7903e-02, -1.0784e-01,\n         -1.6320e-01,  1.5827e-01,  6.4489e-02,  3.8409e-02, -3.8158e-03,\n          1.1886e-01, -2.0337e-02, -4.9368e-02,  1.2470e-02, -2.6655e-02,\n          4.2971e-03, -6.7288e-02,  1.1565e-01, -1.0526e-01,  1.5418e-01,\n          7.4588e-02,  1.1736e-01],\n        [-1.6063e-01,  7.1328e-02, -1.6333e-01, -7.2586e-03,  1.3473e-02,\n          1.3883e-01,  7.0603e-02, -1.1747e-01, -5.3855e-02, -2.7124e-02,\n          1.0973e-01, -2.0026e-02,  9.6773e-02, -1.0654e-02,  1.3002e-01,\n          1.2533e-01,  9.9774e-02,  1.1363e-01, -8.2434e-02, -8.4696e-02,\n          5.9523e-02,  1.6307e-01,  3.8523e-02, -1.1448e-01,  1.0308e-01,\n         -1.0761e-01,  3.8470e-02, -1.2538e-02,  3.1591e-02, -1.1972e-01,\n         -1.5979e-01,  2.9303e-03],\n        [-3.8824e-02,  8.3319e-02, -1.6979e-01, -7.1218e-02,  1.6689e-01,\n          4.2378e-02, -1.5338e-01, -1.2863e-02, -7.4541e-02, -6.8707e-02,\n          1.2028e-01,  1.7424e-01, -1.9397e-02,  1.3455e-01, -6.7520e-02,\n          6.8566e-02,  1.6150e-01,  4.9588e-02,  1.7037e-02, -1.4367e-02,\n         -1.2432e-01, -1.3508e-01, -1.7023e-01, -7.9071e-02, -5.5427e-02,\n          8.6740e-02,  3.2669e-02, -6.2390e-02, -1.1160e-01,  1.6714e-01,\n          1.3148e-01,  1.4799e-01],\n        [-1.6304e-01, -9.8910e-02, -6.2274e-02, -1.0092e-01,  5.9529e-02,\n         -8.0258e-02,  1.5849e-01, -1.5228e-01,  1.5809e-01, -1.7087e-01,\n         -1.6177e-01, -1.0313e-01,  1.4798e-01,  1.0701e-01, -7.0244e-02,\n         -1.0262e-01, -3.6627e-02,  4.3983e-02,  4.8524e-02, -8.4422e-02,\n         -1.3397e-01,  1.0896e-01, -5.6087e-02, -1.2061e-01, -7.4419e-02,\n          1.4364e-01, -1.7305e-01,  1.2931e-01,  7.6992e-02, -1.1133e-01,\n          3.5483e-02,  8.9848e-02],\n        [-3.1601e-02, -1.1903e-02, -9.3290e-02,  1.6139e-01,  6.0869e-02,\n          8.4475e-02, -1.7107e-01, -7.9430e-02, -1.3523e-02, -7.1642e-02,\n         -1.1317e-01, -3.8422e-02, -1.4131e-01, -3.1238e-02,  9.7280e-02,\n          2.2758e-02, -1.5554e-01,  1.4353e-01, -9.8977e-03,  7.0956e-02,\n         -7.1951e-02, -2.5155e-02,  1.2468e-01, -1.6399e-01,  4.2886e-02,\n         -1.2387e-01, -2.5493e-02, -1.2842e-01,  6.1752e-02,  1.3466e-01,\n         -9.8484e-02,  1.6854e-01],\n        [-1.9993e-02, -4.8836e-02, -4.8439e-02, -8.9954e-02,  1.6484e-01,\n          6.0568e-02, -1.3807e-01,  4.4215e-02,  9.5211e-02,  6.5440e-03,\n          9.8178e-02, -1.3444e-01, -5.3073e-02,  3.9761e-02, -3.7745e-02,\n         -6.6312e-02, -7.1645e-02, -6.6420e-02,  1.7460e-01,  8.4450e-02,\n         -1.0115e-01, -2.6593e-02, -2.0200e-02,  5.9627e-02,  7.9374e-02,\n         -1.0449e-01,  6.4544e-02, -6.4354e-02,  4.0248e-02, -4.1830e-03,\n         -1.1229e-01, -7.8162e-02],\n        [-1.1970e-01, -2.5342e-02, -1.5758e-01, -1.1445e-01,  1.0343e-01,\n          1.0029e-01, -6.2679e-02,  3.1297e-02,  1.1694e-02,  1.0201e-01,\n         -1.7215e-01,  9.9843e-02, -1.6720e-01, -3.9397e-04, -8.3000e-04,\n          5.6644e-02,  1.0133e-01,  1.3812e-01, -1.2381e-01,  7.6299e-02,\n          3.8288e-02, -8.3457e-02, -6.9135e-02, -2.1587e-02, -5.3124e-02,\n         -3.7577e-02,  4.1564e-02,  1.6051e-01, -1.2378e-01,  1.0298e-01,\n          1.6018e-01, -2.6326e-02],\n        [ 1.7211e-03, -1.1935e-03, -9.7849e-02,  1.3151e-01, -9.9820e-02,\n          2.5047e-02,  3.3280e-02,  5.8661e-02, -9.6950e-02,  9.0985e-02,\n         -1.6988e-01,  6.1901e-02,  9.8058e-02,  1.7501e-01,  1.1393e-02,\n          8.5130e-02,  1.6437e-01,  1.1218e-01,  1.0909e-01, -2.0779e-02,\n          1.0648e-01,  8.7649e-02, -4.5130e-02,  6.3363e-02,  1.4603e-01,\n          4.4761e-02,  2.3356e-02, -5.3965e-02, -9.2599e-02,  1.7605e-01,\n         -1.3000e-01,  7.6455e-02],\n        [ 1.1665e-01, -1.2581e-01, -1.2375e-01,  9.2656e-02,  1.7660e-01,\n         -8.5118e-02,  8.3654e-02,  1.1872e-01,  1.5672e-01,  8.5404e-02,\n          1.2036e-02, -5.2177e-02,  1.4698e-01, -3.8140e-02,  1.4860e-01,\n          6.8817e-02,  9.3135e-02, -1.5041e-02, -8.3813e-02, -8.8493e-02,\n          1.2111e-02,  1.3643e-01,  4.7149e-02, -9.7445e-02, -1.4813e-01,\n          1.5512e-01,  9.2813e-02, -1.5127e-01, -1.2582e-02, -1.2613e-01,\n         -6.6748e-02, -1.0455e-01],\n        [-4.8161e-02, -1.5288e-01,  4.9622e-02, -8.2255e-02, -1.5094e-01,\n          6.0499e-02,  1.6517e-01, -1.5019e-01,  1.7275e-01, -8.8851e-02,\n          1.3257e-01,  8.4750e-02, -8.4744e-02,  1.5097e-01,  3.3221e-02,\n         -8.6348e-02, -1.1830e-01,  8.6054e-02, -1.6109e-01, -5.2584e-03,\n         -4.8228e-02,  1.6570e-01, -1.6710e-01,  3.7666e-02, -6.6822e-03,\n          1.2779e-01, -2.9407e-02, -1.2855e-01,  6.5137e-02, -1.1155e-01,\n         -9.5781e-02, -2.3853e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0966,  0.0967, -0.0636, -0.1542,  0.0729, -0.1601, -0.1845,  0.2478],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2419, -0.2046, -0.0342,  0.1941, -0.1772,  0.2136,  0.1943,  0.1089,\n          0.1845, -0.1113,  0.0342,  0.0410,  0.0894,  0.2244,  0.2462, -0.0480],\n        [-0.0255,  0.1338, -0.0955, -0.1670, -0.0335,  0.0827, -0.0584,  0.1517,\n         -0.1143, -0.0124, -0.1076,  0.0036,  0.1621,  0.2061, -0.0490,  0.0320],\n        [ 0.0589, -0.0937,  0.2397, -0.0411, -0.1521,  0.0060, -0.1711,  0.2107,\n          0.1161,  0.2181, -0.0346, -0.0928, -0.2021,  0.2007,  0.2116,  0.2377],\n        [-0.0347, -0.1755,  0.0592,  0.1718, -0.1790, -0.1685, -0.0923,  0.1942,\n          0.0321, -0.1375,  0.0191, -0.0311, -0.1912,  0.2462,  0.0460, -0.1926],\n        [-0.1062, -0.0886, -0.1472, -0.2499,  0.1107, -0.2203, -0.2041,  0.0811,\n         -0.1441,  0.0813, -0.0038,  0.1795, -0.2032, -0.1454, -0.1388, -0.0884],\n        [ 0.1199,  0.2024, -0.1749, -0.0020, -0.1605, -0.1087,  0.2368, -0.1994,\n          0.2137,  0.1443, -0.0534,  0.0927, -0.2171,  0.0893,  0.0244,  0.2338],\n        [-0.0674, -0.1809,  0.0976, -0.1965,  0.0942, -0.1991, -0.2217, -0.0386,\n         -0.1392,  0.1124, -0.2451,  0.0991, -0.0850, -0.0952, -0.1352,  0.0363],\n        [ 0.1670,  0.1238, -0.0267, -0.2227,  0.0824,  0.1395,  0.2242,  0.0981,\n          0.1538,  0.0097, -0.1367,  0.1887, -0.2012, -0.1793, -0.1115,  0.2142]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1607,  0.1999, -0.1698,  0.0085], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1462,  0.1983, -0.2522,  0.0965,  0.3152, -0.0483, -0.0186,  0.2704],\n        [ 0.2142,  0.1984, -0.0764, -0.1670,  0.0280, -0.3256, -0.3026,  0.3120],\n        [-0.0682, -0.0904, -0.0899, -0.1143,  0.1383, -0.0168, -0.3022,  0.2510],\n        [ 0.2214, -0.0270,  0.1453, -0.0087, -0.3455, -0.1590,  0.0374, -0.0724]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x78d5b9ef9d50>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s846290000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s846290000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}