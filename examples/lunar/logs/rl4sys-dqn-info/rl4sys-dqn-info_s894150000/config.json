{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	0,
    "batch_size":	256,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s894150000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0003,
    "sample_decay":	0.5,
    "seed":	894150000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7f5b4d3b4450>":	{
            "_act_dim":	4,
            "_aux_batch_size":	0,
            "_batch_size":	256,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0350,  0.0894, -0.2452,  0.1838, -0.2711, -0.1591,  0.0893,  0.2074,\n        -0.1108, -0.1333,  0.1304, -0.1764, -0.1612, -0.2537, -0.0467, -0.1845,\n        -0.1298, -0.2096,  0.3003, -0.3094, -0.3289,  0.0767, -0.0550,  0.2138,\n         0.1100, -0.3096,  0.2237,  0.1070,  0.0177,  0.2794,  0.0047,  0.3266],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2163, -0.0081, -0.2871, -0.0155, -0.1176,  0.0964, -0.0135, -0.1050],\n        [ 0.2525, -0.0564, -0.2306, -0.2807,  0.0794, -0.0527, -0.0480, -0.1016],\n        [-0.0753, -0.1008, -0.3042,  0.1648,  0.0041, -0.0464,  0.1864,  0.0476],\n        [ 0.0906,  0.2277,  0.0873, -0.1555,  0.2686,  0.3294,  0.2663,  0.1176],\n        [-0.3376,  0.0290,  0.0047, -0.2755,  0.0601, -0.3498,  0.3308, -0.0159],\n        [-0.1986, -0.0826, -0.2304, -0.3256, -0.2240, -0.2904, -0.0504, -0.0172],\n        [-0.0922, -0.0586, -0.2498, -0.1573, -0.1550, -0.1727,  0.0593, -0.3324],\n        [ 0.0654, -0.3057, -0.0684, -0.1473,  0.1303, -0.0572,  0.2104,  0.3123],\n        [ 0.0492,  0.2743, -0.3280,  0.0417,  0.0938,  0.3285,  0.1416,  0.3128],\n        [ 0.2804,  0.3454, -0.1197, -0.0631,  0.0161,  0.1485,  0.1016, -0.3093],\n        [-0.1704, -0.0274,  0.0917,  0.2925,  0.2243, -0.2026, -0.0943, -0.1805],\n        [-0.3497,  0.2718,  0.2482, -0.2385, -0.0951, -0.3160, -0.0108,  0.1495],\n        [ 0.3486,  0.2727,  0.3334,  0.3105,  0.1983, -0.2766,  0.1314, -0.3104],\n        [-0.1082,  0.1359, -0.2708, -0.3126, -0.1651, -0.2567, -0.2677,  0.1559],\n        [-0.1955, -0.2222,  0.2206,  0.3339, -0.1459,  0.2850, -0.1949, -0.2200],\n        [ 0.3316,  0.0733, -0.1845, -0.2794,  0.0071,  0.1587,  0.0856,  0.2767],\n        [-0.1616,  0.3294, -0.2657,  0.3483, -0.1826,  0.2541, -0.3172, -0.2043],\n        [-0.3344,  0.1468,  0.0760, -0.0700,  0.3064,  0.2680, -0.0115,  0.0093],\n        [ 0.3211,  0.2044, -0.0322,  0.2151,  0.2086, -0.3451,  0.1114,  0.1385],\n        [ 0.1107,  0.2119,  0.2858,  0.1215, -0.1912, -0.2048,  0.0386, -0.0886],\n        [-0.2059,  0.3343,  0.0011, -0.1294,  0.1732,  0.0228, -0.2077, -0.1812],\n        [ 0.1190, -0.2935,  0.1505, -0.0739, -0.2975,  0.0408, -0.2733,  0.2718],\n        [ 0.0832,  0.3137,  0.3501,  0.3099, -0.0872,  0.1633, -0.1361, -0.0934],\n        [ 0.1028, -0.1463,  0.0358,  0.2420, -0.3453, -0.2626,  0.1578, -0.0758],\n        [-0.1260, -0.1007, -0.0457, -0.0307, -0.3350,  0.0760,  0.0800, -0.2929],\n        [-0.1315,  0.2683, -0.1000, -0.2574,  0.1371, -0.2187,  0.2337,  0.1102],\n        [ 0.1081, -0.2574, -0.2490,  0.1793, -0.1967,  0.2100,  0.1640,  0.3336],\n        [-0.0375,  0.1188, -0.2870,  0.3399,  0.1361,  0.3448, -0.1938, -0.3420],\n        [ 0.1305,  0.1273, -0.0434,  0.1037,  0.2382,  0.1577, -0.2556,  0.1397],\n        [-0.3159,  0.0515,  0.1941, -0.2907, -0.2105,  0.2185,  0.0336, -0.2652],\n        [ 0.0865,  0.0741,  0.1631,  0.3132,  0.2634, -0.0861,  0.1805, -0.1944],\n        [ 0.0376,  0.1039,  0.2622, -0.1737, -0.0902, -0.0605, -0.3288,  0.3268]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0183, -0.0054,  0.0674, -0.1759,  0.0941, -0.0634,  0.0633, -0.1654,\n         0.0505,  0.1634, -0.0444,  0.0031, -0.0147,  0.0601, -0.0343, -0.0262],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.3018e-02, -1.2913e-01, -1.2923e-01, -1.2456e-01, -6.6904e-02,\n          1.9422e-02,  1.3550e-01,  1.1866e-01,  1.7755e-02,  1.0018e-01,\n          1.2328e-01,  2.7938e-03, -1.6278e-01,  7.1730e-03, -6.9012e-02,\n         -2.6778e-02,  6.3212e-02,  9.9017e-02,  1.2303e-01,  9.0170e-02,\n         -1.5477e-01, -4.2195e-02,  1.1289e-01,  7.0081e-02, -8.3295e-03,\n          4.1849e-02, -5.9269e-02, -1.5023e-01,  6.7262e-02,  1.6417e-01,\n         -1.4455e-01, -7.7363e-02],\n        [-9.3648e-02,  1.2951e-01, -8.0622e-02,  1.7118e-01, -2.9202e-02,\n         -1.2437e-01, -1.1208e-01,  1.2374e-01,  2.6372e-02, -1.1376e-01,\n         -1.4767e-01, -1.3788e-01, -1.3355e-01, -2.2495e-02,  8.7679e-02,\n         -1.6875e-01,  2.4631e-02, -8.9750e-02, -1.0731e-01,  1.7194e-01,\n         -6.2351e-02,  1.1370e-01, -6.4507e-02, -9.6783e-03, -7.9711e-02,\n         -1.2774e-01,  1.3648e-01,  7.6118e-02,  2.2173e-02, -1.3713e-01,\n         -9.1072e-02,  1.2770e-01],\n        [-6.8973e-02, -7.7804e-02,  1.7361e-01, -2.0124e-02, -1.3873e-01,\n         -1.8502e-02, -6.9446e-02, -5.9900e-02, -1.3536e-01, -2.0101e-02,\n         -7.2745e-02,  9.1664e-02, -9.8929e-02, -5.6881e-02, -5.6640e-02,\n          9.3486e-02, -5.6360e-02,  1.2074e-01,  1.0402e-01, -1.5020e-01,\n         -1.1530e-01,  2.0394e-02,  8.1591e-02,  8.1191e-03,  8.5702e-02,\n          7.2628e-02, -1.4025e-01,  3.3143e-02,  1.5769e-01, -1.1328e-01,\n         -1.3790e-01, -8.2521e-02],\n        [ 1.7378e-01,  6.5122e-02, -6.7701e-02,  2.5330e-02, -2.3351e-02,\n         -1.0483e-01,  1.3346e-01,  1.7482e-01,  9.0775e-02,  4.6648e-02,\n         -7.7034e-02,  7.7998e-02,  8.7989e-02,  1.7426e-01,  2.5604e-02,\n          1.2428e-01, -1.3821e-01,  4.6064e-02,  5.8075e-02,  7.1465e-02,\n         -1.7491e-01,  1.5017e-04,  1.4734e-01,  1.5360e-01,  2.8832e-02,\n         -7.3653e-02,  1.2063e-01, -1.0516e-01, -7.5384e-02, -4.1521e-02,\n          1.5318e-02,  1.2942e-01],\n        [ 6.8500e-02, -1.6920e-01,  1.6076e-01, -1.2665e-01,  1.2920e-02,\n         -1.5529e-01,  1.0812e-02,  6.9105e-02,  8.3093e-02,  7.6631e-02,\n          1.4025e-01,  1.1867e-01, -2.7947e-02,  6.6260e-02,  9.8175e-02,\n         -6.7985e-02, -1.3631e-01,  1.5899e-01,  1.1884e-01,  1.2949e-01,\n         -7.0650e-02, -1.7773e-02, -1.6800e-01,  1.1932e-01, -1.3889e-01,\n          3.3750e-02, -6.1702e-02,  4.7452e-02, -3.6930e-02, -9.7420e-02,\n         -1.1635e-01, -1.5469e-02],\n        [ 1.2733e-01, -2.4736e-02,  8.0263e-02, -4.0487e-02, -2.8881e-02,\n         -1.6776e-02,  1.5451e-01,  1.6823e-01, -1.6196e-01,  1.3484e-01,\n          1.0284e-01, -3.2477e-02, -1.3180e-01, -7.6037e-02,  1.3952e-01,\n         -3.8053e-02, -1.6476e-01, -3.8691e-03, -2.0871e-03, -1.0562e-01,\n         -4.2293e-02, -1.2444e-01, -8.3126e-02,  8.7560e-02,  6.5369e-02,\n          1.4310e-01, -8.2994e-02,  6.5636e-02, -3.7321e-02, -4.8343e-02,\n         -7.7507e-02, -4.7443e-04],\n        [-1.6582e-01,  1.4365e-01,  4.0970e-02,  1.6887e-01, -1.3876e-01,\n         -1.6318e-01,  2.3687e-02, -9.6147e-02,  1.7356e-01, -8.6659e-02,\n          1.1271e-01,  1.3485e-01,  1.2841e-01,  8.5754e-02, -3.6633e-02,\n          1.5994e-02,  5.7830e-02, -2.2450e-02, -1.9397e-02, -1.6898e-02,\n          4.8979e-02,  5.5678e-02, -3.2330e-03,  6.3444e-02,  1.3604e-01,\n          1.6411e-01, -1.1293e-01, -1.7184e-01,  9.2490e-02,  3.9939e-02,\n          1.7657e-01,  1.0387e-02],\n        [-1.0651e-01,  7.6598e-03,  4.2096e-03, -7.8798e-02, -1.5704e-01,\n          1.0846e-01, -1.3840e-01, -1.6247e-01,  2.0372e-02, -2.9015e-02,\n          1.0334e-01, -7.6829e-02, -7.9459e-02, -6.4145e-02,  8.6535e-02,\n          1.2952e-01, -1.6041e-01, -1.2893e-01,  1.6823e-01, -1.7158e-02,\n          1.1847e-02,  2.4648e-02,  1.2359e-01, -4.6620e-02, -9.5477e-02,\n          1.4727e-01, -1.3007e-01, -1.5811e-01,  6.6568e-02, -7.0100e-02,\n         -3.9803e-02,  2.1356e-02],\n        [ 2.4144e-02, -1.4519e-01, -1.7324e-01,  2.8763e-02,  8.7585e-02,\n         -5.2126e-02, -7.2006e-02,  1.7017e-01,  2.0722e-02,  1.0718e-01,\n          1.0142e-01, -1.3445e-01,  2.5906e-03,  1.8564e-02, -9.0046e-03,\n         -4.5182e-02,  6.6352e-02,  1.6581e-01, -3.7988e-02,  1.6065e-01,\n         -1.5130e-01,  7.0918e-02, -1.3552e-01,  9.3130e-02, -4.0126e-02,\n          1.1094e-01,  3.0476e-02, -3.6411e-02, -8.3003e-02, -9.7103e-02,\n         -8.3051e-02, -8.6854e-02],\n        [-9.6216e-02,  1.0442e-02, -2.0760e-02, -1.8152e-02,  1.0735e-01,\n         -1.0934e-02,  1.2386e-01,  1.0389e-02, -2.6165e-02, -7.6441e-02,\n          6.1258e-02,  7.3151e-02,  6.0346e-02, -1.1651e-01, -1.1015e-01,\n          1.6871e-01, -8.3234e-02,  2.3926e-02,  6.9890e-02, -3.5540e-02,\n         -1.6888e-01,  1.2352e-01,  9.6114e-02, -1.3536e-01, -2.5953e-02,\n          1.4008e-01,  1.4299e-01,  9.7187e-02,  4.9541e-02, -2.7436e-02,\n          2.9718e-02, -9.6678e-02],\n        [-5.1554e-02,  8.2307e-02, -7.4595e-02,  1.1591e-01, -2.3270e-03,\n         -1.0140e-01, -1.1911e-01, -3.2423e-02, -1.0643e-01,  9.9464e-02,\n          5.5321e-02, -1.4227e-01, -2.8404e-03,  6.8881e-03,  9.3944e-03,\n         -8.6352e-03, -4.4943e-02, -1.7411e-01, -8.9991e-02, -6.0319e-02,\n          9.3226e-02,  5.1379e-04, -1.1982e-01, -8.8923e-02,  1.1779e-01,\n         -7.8774e-02,  1.5786e-01,  3.3351e-02, -6.2373e-03,  1.2562e-01,\n         -2.8634e-02,  2.8075e-02],\n        [ 8.4461e-03,  1.5349e-02, -7.0027e-02,  5.2252e-03,  6.2523e-02,\n         -4.2305e-02,  2.7610e-02, -1.0027e-01, -1.6535e-01, -3.3015e-02,\n          1.5222e-01, -1.6875e-01,  1.2508e-01, -9.3096e-02,  1.3222e-01,\n          7.0069e-02,  1.4695e-01, -1.3521e-01,  1.4394e-01,  7.3748e-02,\n          1.4786e-02,  8.4052e-03, -7.8596e-02,  1.1024e-01, -1.5173e-01,\n         -1.1034e-01,  9.7767e-02,  1.3206e-01, -8.5590e-02, -1.2041e-01,\n         -1.4192e-01, -4.6455e-02],\n        [-7.2448e-02, -3.9742e-02, -1.5288e-03, -1.6146e-01, -1.1763e-01,\n         -7.6051e-02,  4.4391e-02,  4.7611e-02, -1.7258e-01,  6.0453e-03,\n          1.4708e-01,  1.0154e-01,  4.2597e-02, -7.2812e-02,  6.5045e-02,\n          6.7957e-02, -1.4008e-01,  6.7872e-02,  4.4275e-02, -2.1332e-03,\n         -7.6495e-02, -1.6868e-01,  2.3321e-02, -3.0987e-02, -9.5444e-02,\n         -8.7979e-02,  1.0763e-01,  1.3166e-01,  1.6776e-01,  1.5868e-01,\n         -8.2703e-02, -1.2029e-01],\n        [ 4.8739e-02,  4.9370e-02,  6.5531e-02,  1.0697e-01,  3.0990e-02,\n         -7.3886e-02,  5.5863e-02,  9.0530e-02, -1.3896e-01, -1.4024e-01,\n         -1.2560e-01, -7.6242e-02,  3.7804e-02,  1.3727e-01, -9.0431e-02,\n         -1.2472e-01, -1.1555e-01, -1.3718e-01, -1.3990e-01, -9.2370e-02,\n         -1.6366e-01, -2.9826e-02,  7.9261e-02, -8.5417e-02, -9.2797e-02,\n         -1.6342e-01, -6.9078e-02, -1.4404e-02, -8.0259e-02, -1.5794e-01,\n          4.1606e-02,  3.0109e-02],\n        [ 3.8007e-02, -1.1297e-01,  1.1396e-01,  1.5963e-01,  1.2420e-02,\n          6.7518e-02,  1.6474e-01,  1.3530e-01, -4.1975e-03,  9.7888e-02,\n         -5.2696e-02,  2.5203e-02,  1.4235e-01, -5.2958e-02, -1.5703e-01,\n          1.2242e-01,  1.7672e-01,  1.4220e-01,  1.0571e-01, -4.5394e-02,\n         -1.0743e-01, -7.8995e-02, -3.9378e-02,  1.5953e-01, -1.6345e-02,\n         -8.7727e-02, -1.6867e-01,  1.7156e-01,  4.4933e-02,  1.3480e-01,\n         -1.2250e-01,  1.2856e-01],\n        [ 6.2887e-03,  7.3878e-02,  2.1047e-02,  1.0977e-01,  5.0078e-02,\n          1.5748e-01,  7.2298e-02, -1.2432e-01, -1.6176e-01, -1.6344e-01,\n         -9.4004e-02,  1.6967e-01, -7.8052e-02,  6.1783e-02, -4.2118e-02,\n         -4.3257e-02,  6.5020e-02,  2.0336e-02, -1.3198e-01, -1.2391e-01,\n         -1.1190e-02, -5.6529e-03, -2.6189e-02, -3.2725e-02, -1.2662e-01,\n         -1.7333e-01, -1.5863e-02,  1.6445e-01, -4.4276e-02,  8.7497e-02,\n          1.1280e-01, -1.1175e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2279,  0.2030, -0.0777, -0.0970, -0.0275,  0.0840, -0.1323,  0.0947],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1183,  0.0725, -0.1246,  0.1391,  0.2007, -0.2027,  0.0150,  0.1894,\n          0.0504,  0.0130, -0.0094,  0.1141, -0.1143,  0.1355, -0.2030,  0.1916],\n        [-0.0684, -0.0253, -0.0745, -0.0565, -0.1675, -0.0965, -0.0114, -0.2354,\n         -0.0789, -0.2005,  0.1257, -0.0567,  0.2301, -0.1764, -0.0957,  0.1185],\n        [-0.1053,  0.0368, -0.1782,  0.2105, -0.1108,  0.2107,  0.0181, -0.1102,\n         -0.0447,  0.2001, -0.1757,  0.0712, -0.0683, -0.1397, -0.0542, -0.0426],\n        [-0.1646,  0.1361,  0.0064, -0.2088, -0.1914, -0.2035,  0.2332,  0.1628,\n          0.0011, -0.2367,  0.2007, -0.2319, -0.1805,  0.0589,  0.1396, -0.0185],\n        [-0.1443,  0.1221,  0.0207, -0.0444, -0.2205, -0.1987, -0.1216,  0.0837,\n         -0.0665, -0.0770, -0.1835, -0.0185, -0.0879,  0.0184,  0.0970, -0.1703],\n        [ 0.1283, -0.1998, -0.1762, -0.2377, -0.1678, -0.1341,  0.2001, -0.1773,\n         -0.0302, -0.1787, -0.0284,  0.1198, -0.1805, -0.2289, -0.0874, -0.1506],\n        [-0.0292, -0.2375, -0.2408, -0.1564, -0.0828, -0.0091,  0.1235, -0.0757,\n         -0.2344, -0.0372,  0.0318,  0.1396, -0.1990, -0.1385, -0.1927, -0.2133],\n        [ 0.0852, -0.2077,  0.0455, -0.2477, -0.0543,  0.0018,  0.1871,  0.0774,\n         -0.0338, -0.0207, -0.1438,  0.2121, -0.0125,  0.0537, -0.0501, -0.0397]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0484, -0.1190, -0.3329, -0.2363], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0144,  0.2927, -0.3349, -0.1529,  0.0265, -0.2480, -0.0730, -0.3270],\n        [-0.1537,  0.3374, -0.2392,  0.2533,  0.3273, -0.2779,  0.1244, -0.0310],\n        [-0.3049,  0.2698,  0.2863, -0.0881, -0.0840,  0.0965, -0.1350,  0.1123],\n        [-0.3369,  0.0948, -0.1156, -0.2575, -0.1858,  0.2878, -0.3499,  0.0947]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2163, -0.0081, -0.2871, -0.0155, -0.1176,  0.0964, -0.0135, -0.1050],\n        [ 0.2525, -0.0564, -0.2306, -0.2807,  0.0794, -0.0527, -0.0480, -0.1016],\n        [-0.0753, -0.1008, -0.3042,  0.1648,  0.0041, -0.0464,  0.1864,  0.0476],\n        [ 0.0906,  0.2277,  0.0873, -0.1555,  0.2686,  0.3294,  0.2663,  0.1176],\n        [-0.3376,  0.0290,  0.0047, -0.2755,  0.0601, -0.3498,  0.3308, -0.0159],\n        [-0.1986, -0.0826, -0.2304, -0.3256, -0.2240, -0.2904, -0.0504, -0.0172],\n        [-0.0922, -0.0586, -0.2498, -0.1573, -0.1550, -0.1727,  0.0593, -0.3324],\n        [ 0.0654, -0.3057, -0.0684, -0.1473,  0.1303, -0.0572,  0.2104,  0.3123],\n        [ 0.0492,  0.2743, -0.3280,  0.0417,  0.0938,  0.3285,  0.1416,  0.3128],\n        [ 0.2804,  0.3454, -0.1197, -0.0631,  0.0161,  0.1485,  0.1016, -0.3093],\n        [-0.1704, -0.0274,  0.0917,  0.2925,  0.2243, -0.2026, -0.0943, -0.1805],\n        [-0.3497,  0.2718,  0.2482, -0.2385, -0.0951, -0.3160, -0.0108,  0.1495],\n        [ 0.3486,  0.2727,  0.3334,  0.3105,  0.1983, -0.2766,  0.1314, -0.3104],\n        [-0.1082,  0.1359, -0.2708, -0.3126, -0.1651, -0.2567, -0.2677,  0.1559],\n        [-0.1955, -0.2222,  0.2206,  0.3339, -0.1459,  0.2850, -0.1949, -0.2200],\n        [ 0.3316,  0.0733, -0.1845, -0.2794,  0.0071,  0.1587,  0.0856,  0.2767],\n        [-0.1616,  0.3294, -0.2657,  0.3483, -0.1826,  0.2541, -0.3172, -0.2043],\n        [-0.3344,  0.1468,  0.0760, -0.0700,  0.3064,  0.2680, -0.0115,  0.0093],\n        [ 0.3211,  0.2044, -0.0322,  0.2151,  0.2086, -0.3451,  0.1114,  0.1385],\n        [ 0.1107,  0.2119,  0.2858,  0.1215, -0.1912, -0.2048,  0.0386, -0.0886],\n        [-0.2059,  0.3343,  0.0011, -0.1294,  0.1732,  0.0228, -0.2077, -0.1812],\n        [ 0.1190, -0.2935,  0.1505, -0.0739, -0.2975,  0.0408, -0.2733,  0.2718],\n        [ 0.0832,  0.3137,  0.3501,  0.3099, -0.0872,  0.1633, -0.1361, -0.0934],\n        [ 0.1028, -0.1463,  0.0358,  0.2420, -0.3453, -0.2626,  0.1578, -0.0758],\n        [-0.1260, -0.1007, -0.0457, -0.0307, -0.3350,  0.0760,  0.0800, -0.2929],\n        [-0.1315,  0.2683, -0.1000, -0.2574,  0.1371, -0.2187,  0.2337,  0.1102],\n        [ 0.1081, -0.2574, -0.2490,  0.1793, -0.1967,  0.2100,  0.1640,  0.3336],\n        [-0.0375,  0.1188, -0.2870,  0.3399,  0.1361,  0.3448, -0.1938, -0.3420],\n        [ 0.1305,  0.1273, -0.0434,  0.1037,  0.2382,  0.1577, -0.2556,  0.1397],\n        [-0.3159,  0.0515,  0.1941, -0.2907, -0.2105,  0.2185,  0.0336, -0.2652],\n        [ 0.0865,  0.0741,  0.1631,  0.3132,  0.2634, -0.0861,  0.1805, -0.1944],\n        [ 0.0376,  0.1039,  0.2622, -0.1737, -0.0902, -0.0605, -0.3288,  0.3268]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0350,  0.0894, -0.2452,  0.1838, -0.2711, -0.1591,  0.0893,  0.2074,\n        -0.1108, -0.1333,  0.1304, -0.1764, -0.1612, -0.2537, -0.0467, -0.1845,\n        -0.1298, -0.2096,  0.3003, -0.3094, -0.3289,  0.0767, -0.0550,  0.2138,\n         0.1100, -0.3096,  0.2237,  0.1070,  0.0177,  0.2794,  0.0047,  0.3266],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-3.3018e-02, -1.2913e-01, -1.2923e-01, -1.2456e-01, -6.6904e-02,\n          1.9422e-02,  1.3550e-01,  1.1866e-01,  1.7755e-02,  1.0018e-01,\n          1.2328e-01,  2.7938e-03, -1.6278e-01,  7.1730e-03, -6.9012e-02,\n         -2.6778e-02,  6.3212e-02,  9.9017e-02,  1.2303e-01,  9.0170e-02,\n         -1.5477e-01, -4.2195e-02,  1.1289e-01,  7.0081e-02, -8.3295e-03,\n          4.1849e-02, -5.9269e-02, -1.5023e-01,  6.7262e-02,  1.6417e-01,\n         -1.4455e-01, -7.7363e-02],\n        [-9.3648e-02,  1.2951e-01, -8.0622e-02,  1.7118e-01, -2.9202e-02,\n         -1.2437e-01, -1.1208e-01,  1.2374e-01,  2.6372e-02, -1.1376e-01,\n         -1.4767e-01, -1.3788e-01, -1.3355e-01, -2.2495e-02,  8.7679e-02,\n         -1.6875e-01,  2.4631e-02, -8.9750e-02, -1.0731e-01,  1.7194e-01,\n         -6.2351e-02,  1.1370e-01, -6.4507e-02, -9.6783e-03, -7.9711e-02,\n         -1.2774e-01,  1.3648e-01,  7.6118e-02,  2.2173e-02, -1.3713e-01,\n         -9.1072e-02,  1.2770e-01],\n        [-6.8973e-02, -7.7804e-02,  1.7361e-01, -2.0124e-02, -1.3873e-01,\n         -1.8502e-02, -6.9446e-02, -5.9900e-02, -1.3536e-01, -2.0101e-02,\n         -7.2745e-02,  9.1664e-02, -9.8929e-02, -5.6881e-02, -5.6640e-02,\n          9.3486e-02, -5.6360e-02,  1.2074e-01,  1.0402e-01, -1.5020e-01,\n         -1.1530e-01,  2.0394e-02,  8.1591e-02,  8.1191e-03,  8.5702e-02,\n          7.2628e-02, -1.4025e-01,  3.3143e-02,  1.5769e-01, -1.1328e-01,\n         -1.3790e-01, -8.2521e-02],\n        [ 1.7378e-01,  6.5122e-02, -6.7701e-02,  2.5330e-02, -2.3351e-02,\n         -1.0483e-01,  1.3346e-01,  1.7482e-01,  9.0775e-02,  4.6648e-02,\n         -7.7034e-02,  7.7998e-02,  8.7989e-02,  1.7426e-01,  2.5604e-02,\n          1.2428e-01, -1.3821e-01,  4.6064e-02,  5.8075e-02,  7.1465e-02,\n         -1.7491e-01,  1.5017e-04,  1.4734e-01,  1.5360e-01,  2.8832e-02,\n         -7.3653e-02,  1.2063e-01, -1.0516e-01, -7.5384e-02, -4.1521e-02,\n          1.5318e-02,  1.2942e-01],\n        [ 6.8500e-02, -1.6920e-01,  1.6076e-01, -1.2665e-01,  1.2920e-02,\n         -1.5529e-01,  1.0812e-02,  6.9105e-02,  8.3093e-02,  7.6631e-02,\n          1.4025e-01,  1.1867e-01, -2.7947e-02,  6.6260e-02,  9.8175e-02,\n         -6.7985e-02, -1.3631e-01,  1.5899e-01,  1.1884e-01,  1.2949e-01,\n         -7.0650e-02, -1.7773e-02, -1.6800e-01,  1.1932e-01, -1.3889e-01,\n          3.3750e-02, -6.1702e-02,  4.7452e-02, -3.6930e-02, -9.7420e-02,\n         -1.1635e-01, -1.5469e-02],\n        [ 1.2733e-01, -2.4736e-02,  8.0263e-02, -4.0487e-02, -2.8881e-02,\n         -1.6776e-02,  1.5451e-01,  1.6823e-01, -1.6196e-01,  1.3484e-01,\n          1.0284e-01, -3.2477e-02, -1.3180e-01, -7.6037e-02,  1.3952e-01,\n         -3.8053e-02, -1.6476e-01, -3.8691e-03, -2.0871e-03, -1.0562e-01,\n         -4.2293e-02, -1.2444e-01, -8.3126e-02,  8.7560e-02,  6.5369e-02,\n          1.4310e-01, -8.2994e-02,  6.5636e-02, -3.7321e-02, -4.8343e-02,\n         -7.7507e-02, -4.7443e-04],\n        [-1.6582e-01,  1.4365e-01,  4.0970e-02,  1.6887e-01, -1.3876e-01,\n         -1.6318e-01,  2.3687e-02, -9.6147e-02,  1.7356e-01, -8.6659e-02,\n          1.1271e-01,  1.3485e-01,  1.2841e-01,  8.5754e-02, -3.6633e-02,\n          1.5994e-02,  5.7830e-02, -2.2450e-02, -1.9397e-02, -1.6898e-02,\n          4.8979e-02,  5.5678e-02, -3.2330e-03,  6.3444e-02,  1.3604e-01,\n          1.6411e-01, -1.1293e-01, -1.7184e-01,  9.2490e-02,  3.9939e-02,\n          1.7657e-01,  1.0387e-02],\n        [-1.0651e-01,  7.6598e-03,  4.2096e-03, -7.8798e-02, -1.5704e-01,\n          1.0846e-01, -1.3840e-01, -1.6247e-01,  2.0372e-02, -2.9015e-02,\n          1.0334e-01, -7.6829e-02, -7.9459e-02, -6.4145e-02,  8.6535e-02,\n          1.2952e-01, -1.6041e-01, -1.2893e-01,  1.6823e-01, -1.7158e-02,\n          1.1847e-02,  2.4648e-02,  1.2359e-01, -4.6620e-02, -9.5477e-02,\n          1.4727e-01, -1.3007e-01, -1.5811e-01,  6.6568e-02, -7.0100e-02,\n         -3.9803e-02,  2.1356e-02],\n        [ 2.4144e-02, -1.4519e-01, -1.7324e-01,  2.8763e-02,  8.7585e-02,\n         -5.2126e-02, -7.2006e-02,  1.7017e-01,  2.0722e-02,  1.0718e-01,\n          1.0142e-01, -1.3445e-01,  2.5906e-03,  1.8564e-02, -9.0046e-03,\n         -4.5182e-02,  6.6352e-02,  1.6581e-01, -3.7988e-02,  1.6065e-01,\n         -1.5130e-01,  7.0918e-02, -1.3552e-01,  9.3130e-02, -4.0126e-02,\n          1.1094e-01,  3.0476e-02, -3.6411e-02, -8.3003e-02, -9.7103e-02,\n         -8.3051e-02, -8.6854e-02],\n        [-9.6216e-02,  1.0442e-02, -2.0760e-02, -1.8152e-02,  1.0735e-01,\n         -1.0934e-02,  1.2386e-01,  1.0389e-02, -2.6165e-02, -7.6441e-02,\n          6.1258e-02,  7.3151e-02,  6.0346e-02, -1.1651e-01, -1.1015e-01,\n          1.6871e-01, -8.3234e-02,  2.3926e-02,  6.9890e-02, -3.5540e-02,\n         -1.6888e-01,  1.2352e-01,  9.6114e-02, -1.3536e-01, -2.5953e-02,\n          1.4008e-01,  1.4299e-01,  9.7187e-02,  4.9541e-02, -2.7436e-02,\n          2.9718e-02, -9.6678e-02],\n        [-5.1554e-02,  8.2307e-02, -7.4595e-02,  1.1591e-01, -2.3270e-03,\n         -1.0140e-01, -1.1911e-01, -3.2423e-02, -1.0643e-01,  9.9464e-02,\n          5.5321e-02, -1.4227e-01, -2.8404e-03,  6.8881e-03,  9.3944e-03,\n         -8.6352e-03, -4.4943e-02, -1.7411e-01, -8.9991e-02, -6.0319e-02,\n          9.3226e-02,  5.1379e-04, -1.1982e-01, -8.8923e-02,  1.1779e-01,\n         -7.8774e-02,  1.5786e-01,  3.3351e-02, -6.2373e-03,  1.2562e-01,\n         -2.8634e-02,  2.8075e-02],\n        [ 8.4461e-03,  1.5349e-02, -7.0027e-02,  5.2252e-03,  6.2523e-02,\n         -4.2305e-02,  2.7610e-02, -1.0027e-01, -1.6535e-01, -3.3015e-02,\n          1.5222e-01, -1.6875e-01,  1.2508e-01, -9.3096e-02,  1.3222e-01,\n          7.0069e-02,  1.4695e-01, -1.3521e-01,  1.4394e-01,  7.3748e-02,\n          1.4786e-02,  8.4052e-03, -7.8596e-02,  1.1024e-01, -1.5173e-01,\n         -1.1034e-01,  9.7767e-02,  1.3206e-01, -8.5590e-02, -1.2041e-01,\n         -1.4192e-01, -4.6455e-02],\n        [-7.2448e-02, -3.9742e-02, -1.5288e-03, -1.6146e-01, -1.1763e-01,\n         -7.6051e-02,  4.4391e-02,  4.7611e-02, -1.7258e-01,  6.0453e-03,\n          1.4708e-01,  1.0154e-01,  4.2597e-02, -7.2812e-02,  6.5045e-02,\n          6.7957e-02, -1.4008e-01,  6.7872e-02,  4.4275e-02, -2.1332e-03,\n         -7.6495e-02, -1.6868e-01,  2.3321e-02, -3.0987e-02, -9.5444e-02,\n         -8.7979e-02,  1.0763e-01,  1.3166e-01,  1.6776e-01,  1.5868e-01,\n         -8.2703e-02, -1.2029e-01],\n        [ 4.8739e-02,  4.9370e-02,  6.5531e-02,  1.0697e-01,  3.0990e-02,\n         -7.3886e-02,  5.5863e-02,  9.0530e-02, -1.3896e-01, -1.4024e-01,\n         -1.2560e-01, -7.6242e-02,  3.7804e-02,  1.3727e-01, -9.0431e-02,\n         -1.2472e-01, -1.1555e-01, -1.3718e-01, -1.3990e-01, -9.2370e-02,\n         -1.6366e-01, -2.9826e-02,  7.9261e-02, -8.5417e-02, -9.2797e-02,\n         -1.6342e-01, -6.9078e-02, -1.4404e-02, -8.0259e-02, -1.5794e-01,\n          4.1606e-02,  3.0109e-02],\n        [ 3.8007e-02, -1.1297e-01,  1.1396e-01,  1.5963e-01,  1.2420e-02,\n          6.7518e-02,  1.6474e-01,  1.3530e-01, -4.1975e-03,  9.7888e-02,\n         -5.2696e-02,  2.5203e-02,  1.4235e-01, -5.2958e-02, -1.5703e-01,\n          1.2242e-01,  1.7672e-01,  1.4220e-01,  1.0571e-01, -4.5394e-02,\n         -1.0743e-01, -7.8995e-02, -3.9378e-02,  1.5953e-01, -1.6345e-02,\n         -8.7727e-02, -1.6867e-01,  1.7156e-01,  4.4933e-02,  1.3480e-01,\n         -1.2250e-01,  1.2856e-01],\n        [ 6.2887e-03,  7.3878e-02,  2.1047e-02,  1.0977e-01,  5.0078e-02,\n          1.5748e-01,  7.2298e-02, -1.2432e-01, -1.6176e-01, -1.6344e-01,\n         -9.4004e-02,  1.6967e-01, -7.8052e-02,  6.1783e-02, -4.2118e-02,\n         -4.3257e-02,  6.5020e-02,  2.0336e-02, -1.3198e-01, -1.2391e-01,\n         -1.1190e-02, -5.6529e-03, -2.6189e-02, -3.2725e-02, -1.2662e-01,\n         -1.7333e-01, -1.5863e-02,  1.6445e-01, -4.4276e-02,  8.7497e-02,\n          1.1280e-01, -1.1175e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0183, -0.0054,  0.0674, -0.1759,  0.0941, -0.0634,  0.0633, -0.1654,\n         0.0505,  0.1634, -0.0444,  0.0031, -0.0147,  0.0601, -0.0343, -0.0262],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1183,  0.0725, -0.1246,  0.1391,  0.2007, -0.2027,  0.0150,  0.1894,\n          0.0504,  0.0130, -0.0094,  0.1141, -0.1143,  0.1355, -0.2030,  0.1916],\n        [-0.0684, -0.0253, -0.0745, -0.0565, -0.1675, -0.0965, -0.0114, -0.2354,\n         -0.0789, -0.2005,  0.1257, -0.0567,  0.2301, -0.1764, -0.0957,  0.1185],\n        [-0.1053,  0.0368, -0.1782,  0.2105, -0.1108,  0.2107,  0.0181, -0.1102,\n         -0.0447,  0.2001, -0.1757,  0.0712, -0.0683, -0.1397, -0.0542, -0.0426],\n        [-0.1646,  0.1361,  0.0064, -0.2088, -0.1914, -0.2035,  0.2332,  0.1628,\n          0.0011, -0.2367,  0.2007, -0.2319, -0.1805,  0.0589,  0.1396, -0.0185],\n        [-0.1443,  0.1221,  0.0207, -0.0444, -0.2205, -0.1987, -0.1216,  0.0837,\n         -0.0665, -0.0770, -0.1835, -0.0185, -0.0879,  0.0184,  0.0970, -0.1703],\n        [ 0.1283, -0.1998, -0.1762, -0.2377, -0.1678, -0.1341,  0.2001, -0.1773,\n         -0.0302, -0.1787, -0.0284,  0.1198, -0.1805, -0.2289, -0.0874, -0.1506],\n        [-0.0292, -0.2375, -0.2408, -0.1564, -0.0828, -0.0091,  0.1235, -0.0757,\n         -0.2344, -0.0372,  0.0318,  0.1396, -0.1990, -0.1385, -0.1927, -0.2133],\n        [ 0.0852, -0.2077,  0.0455, -0.2477, -0.0543,  0.0018,  0.1871,  0.0774,\n         -0.0338, -0.0207, -0.1438,  0.2121, -0.0125,  0.0537, -0.0501, -0.0397]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2279,  0.2030, -0.0777, -0.0970, -0.0275,  0.0840, -0.1323,  0.0947],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0144,  0.2927, -0.3349, -0.1529,  0.0265, -0.2480, -0.0730, -0.3270],\n        [-0.1537,  0.3374, -0.2392,  0.2533,  0.3273, -0.2779,  0.1244, -0.0310],\n        [-0.3049,  0.2698,  0.2863, -0.0881, -0.0840,  0.0965, -0.1350,  0.1123],\n        [-0.3369,  0.0948, -0.1156, -0.2575, -0.1858,  0.2878, -0.3499,  0.0947]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0484, -0.1190, -0.3329, -0.2363], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7f5bcf179e50>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x7f5b4ecc5650>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0350,  0.0894, -0.2452,  0.1838, -0.2711, -0.1591,  0.0893,  0.2074,\n        -0.1108, -0.1333,  0.1304, -0.1764, -0.1612, -0.2537, -0.0467, -0.1845,\n        -0.1298, -0.2096,  0.3003, -0.3094, -0.3289,  0.0767, -0.0550,  0.2138,\n         0.1100, -0.3096,  0.2237,  0.1070,  0.0177,  0.2794,  0.0047,  0.3266],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2163, -0.0081, -0.2871, -0.0155, -0.1176,  0.0964, -0.0135, -0.1050],\n        [ 0.2525, -0.0564, -0.2306, -0.2807,  0.0794, -0.0527, -0.0480, -0.1016],\n        [-0.0753, -0.1008, -0.3042,  0.1648,  0.0041, -0.0464,  0.1864,  0.0476],\n        [ 0.0906,  0.2277,  0.0873, -0.1555,  0.2686,  0.3294,  0.2663,  0.1176],\n        [-0.3376,  0.0290,  0.0047, -0.2755,  0.0601, -0.3498,  0.3308, -0.0159],\n        [-0.1986, -0.0826, -0.2304, -0.3256, -0.2240, -0.2904, -0.0504, -0.0172],\n        [-0.0922, -0.0586, -0.2498, -0.1573, -0.1550, -0.1727,  0.0593, -0.3324],\n        [ 0.0654, -0.3057, -0.0684, -0.1473,  0.1303, -0.0572,  0.2104,  0.3123],\n        [ 0.0492,  0.2743, -0.3280,  0.0417,  0.0938,  0.3285,  0.1416,  0.3128],\n        [ 0.2804,  0.3454, -0.1197, -0.0631,  0.0161,  0.1485,  0.1016, -0.3093],\n        [-0.1704, -0.0274,  0.0917,  0.2925,  0.2243, -0.2026, -0.0943, -0.1805],\n        [-0.3497,  0.2718,  0.2482, -0.2385, -0.0951, -0.3160, -0.0108,  0.1495],\n        [ 0.3486,  0.2727,  0.3334,  0.3105,  0.1983, -0.2766,  0.1314, -0.3104],\n        [-0.1082,  0.1359, -0.2708, -0.3126, -0.1651, -0.2567, -0.2677,  0.1559],\n        [-0.1955, -0.2222,  0.2206,  0.3339, -0.1459,  0.2850, -0.1949, -0.2200],\n        [ 0.3316,  0.0733, -0.1845, -0.2794,  0.0071,  0.1587,  0.0856,  0.2767],\n        [-0.1616,  0.3294, -0.2657,  0.3483, -0.1826,  0.2541, -0.3172, -0.2043],\n        [-0.3344,  0.1468,  0.0760, -0.0700,  0.3064,  0.2680, -0.0115,  0.0093],\n        [ 0.3211,  0.2044, -0.0322,  0.2151,  0.2086, -0.3451,  0.1114,  0.1385],\n        [ 0.1107,  0.2119,  0.2858,  0.1215, -0.1912, -0.2048,  0.0386, -0.0886],\n        [-0.2059,  0.3343,  0.0011, -0.1294,  0.1732,  0.0228, -0.2077, -0.1812],\n        [ 0.1190, -0.2935,  0.1505, -0.0739, -0.2975,  0.0408, -0.2733,  0.2718],\n        [ 0.0832,  0.3137,  0.3501,  0.3099, -0.0872,  0.1633, -0.1361, -0.0934],\n        [ 0.1028, -0.1463,  0.0358,  0.2420, -0.3453, -0.2626,  0.1578, -0.0758],\n        [-0.1260, -0.1007, -0.0457, -0.0307, -0.3350,  0.0760,  0.0800, -0.2929],\n        [-0.1315,  0.2683, -0.1000, -0.2574,  0.1371, -0.2187,  0.2337,  0.1102],\n        [ 0.1081, -0.2574, -0.2490,  0.1793, -0.1967,  0.2100,  0.1640,  0.3336],\n        [-0.0375,  0.1188, -0.2870,  0.3399,  0.1361,  0.3448, -0.1938, -0.3420],\n        [ 0.1305,  0.1273, -0.0434,  0.1037,  0.2382,  0.1577, -0.2556,  0.1397],\n        [-0.3159,  0.0515,  0.1941, -0.2907, -0.2105,  0.2185,  0.0336, -0.2652],\n        [ 0.0865,  0.0741,  0.1631,  0.3132,  0.2634, -0.0861,  0.1805, -0.1944],\n        [ 0.0376,  0.1039,  0.2622, -0.1737, -0.0902, -0.0605, -0.3288,  0.3268]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0183, -0.0054,  0.0674, -0.1759,  0.0941, -0.0634,  0.0633, -0.1654,\n         0.0505,  0.1634, -0.0444,  0.0031, -0.0147,  0.0601, -0.0343, -0.0262],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.3018e-02, -1.2913e-01, -1.2923e-01, -1.2456e-01, -6.6904e-02,\n          1.9422e-02,  1.3550e-01,  1.1866e-01,  1.7755e-02,  1.0018e-01,\n          1.2328e-01,  2.7938e-03, -1.6278e-01,  7.1730e-03, -6.9012e-02,\n         -2.6778e-02,  6.3212e-02,  9.9017e-02,  1.2303e-01,  9.0170e-02,\n         -1.5477e-01, -4.2195e-02,  1.1289e-01,  7.0081e-02, -8.3295e-03,\n          4.1849e-02, -5.9269e-02, -1.5023e-01,  6.7262e-02,  1.6417e-01,\n         -1.4455e-01, -7.7363e-02],\n        [-9.3648e-02,  1.2951e-01, -8.0622e-02,  1.7118e-01, -2.9202e-02,\n         -1.2437e-01, -1.1208e-01,  1.2374e-01,  2.6372e-02, -1.1376e-01,\n         -1.4767e-01, -1.3788e-01, -1.3355e-01, -2.2495e-02,  8.7679e-02,\n         -1.6875e-01,  2.4631e-02, -8.9750e-02, -1.0731e-01,  1.7194e-01,\n         -6.2351e-02,  1.1370e-01, -6.4507e-02, -9.6783e-03, -7.9711e-02,\n         -1.2774e-01,  1.3648e-01,  7.6118e-02,  2.2173e-02, -1.3713e-01,\n         -9.1072e-02,  1.2770e-01],\n        [-6.8973e-02, -7.7804e-02,  1.7361e-01, -2.0124e-02, -1.3873e-01,\n         -1.8502e-02, -6.9446e-02, -5.9900e-02, -1.3536e-01, -2.0101e-02,\n         -7.2745e-02,  9.1664e-02, -9.8929e-02, -5.6881e-02, -5.6640e-02,\n          9.3486e-02, -5.6360e-02,  1.2074e-01,  1.0402e-01, -1.5020e-01,\n         -1.1530e-01,  2.0394e-02,  8.1591e-02,  8.1191e-03,  8.5702e-02,\n          7.2628e-02, -1.4025e-01,  3.3143e-02,  1.5769e-01, -1.1328e-01,\n         -1.3790e-01, -8.2521e-02],\n        [ 1.7378e-01,  6.5122e-02, -6.7701e-02,  2.5330e-02, -2.3351e-02,\n         -1.0483e-01,  1.3346e-01,  1.7482e-01,  9.0775e-02,  4.6648e-02,\n         -7.7034e-02,  7.7998e-02,  8.7989e-02,  1.7426e-01,  2.5604e-02,\n          1.2428e-01, -1.3821e-01,  4.6064e-02,  5.8075e-02,  7.1465e-02,\n         -1.7491e-01,  1.5017e-04,  1.4734e-01,  1.5360e-01,  2.8832e-02,\n         -7.3653e-02,  1.2063e-01, -1.0516e-01, -7.5384e-02, -4.1521e-02,\n          1.5318e-02,  1.2942e-01],\n        [ 6.8500e-02, -1.6920e-01,  1.6076e-01, -1.2665e-01,  1.2920e-02,\n         -1.5529e-01,  1.0812e-02,  6.9105e-02,  8.3093e-02,  7.6631e-02,\n          1.4025e-01,  1.1867e-01, -2.7947e-02,  6.6260e-02,  9.8175e-02,\n         -6.7985e-02, -1.3631e-01,  1.5899e-01,  1.1884e-01,  1.2949e-01,\n         -7.0650e-02, -1.7773e-02, -1.6800e-01,  1.1932e-01, -1.3889e-01,\n          3.3750e-02, -6.1702e-02,  4.7452e-02, -3.6930e-02, -9.7420e-02,\n         -1.1635e-01, -1.5469e-02],\n        [ 1.2733e-01, -2.4736e-02,  8.0263e-02, -4.0487e-02, -2.8881e-02,\n         -1.6776e-02,  1.5451e-01,  1.6823e-01, -1.6196e-01,  1.3484e-01,\n          1.0284e-01, -3.2477e-02, -1.3180e-01, -7.6037e-02,  1.3952e-01,\n         -3.8053e-02, -1.6476e-01, -3.8691e-03, -2.0871e-03, -1.0562e-01,\n         -4.2293e-02, -1.2444e-01, -8.3126e-02,  8.7560e-02,  6.5369e-02,\n          1.4310e-01, -8.2994e-02,  6.5636e-02, -3.7321e-02, -4.8343e-02,\n         -7.7507e-02, -4.7443e-04],\n        [-1.6582e-01,  1.4365e-01,  4.0970e-02,  1.6887e-01, -1.3876e-01,\n         -1.6318e-01,  2.3687e-02, -9.6147e-02,  1.7356e-01, -8.6659e-02,\n          1.1271e-01,  1.3485e-01,  1.2841e-01,  8.5754e-02, -3.6633e-02,\n          1.5994e-02,  5.7830e-02, -2.2450e-02, -1.9397e-02, -1.6898e-02,\n          4.8979e-02,  5.5678e-02, -3.2330e-03,  6.3444e-02,  1.3604e-01,\n          1.6411e-01, -1.1293e-01, -1.7184e-01,  9.2490e-02,  3.9939e-02,\n          1.7657e-01,  1.0387e-02],\n        [-1.0651e-01,  7.6598e-03,  4.2096e-03, -7.8798e-02, -1.5704e-01,\n          1.0846e-01, -1.3840e-01, -1.6247e-01,  2.0372e-02, -2.9015e-02,\n          1.0334e-01, -7.6829e-02, -7.9459e-02, -6.4145e-02,  8.6535e-02,\n          1.2952e-01, -1.6041e-01, -1.2893e-01,  1.6823e-01, -1.7158e-02,\n          1.1847e-02,  2.4648e-02,  1.2359e-01, -4.6620e-02, -9.5477e-02,\n          1.4727e-01, -1.3007e-01, -1.5811e-01,  6.6568e-02, -7.0100e-02,\n         -3.9803e-02,  2.1356e-02],\n        [ 2.4144e-02, -1.4519e-01, -1.7324e-01,  2.8763e-02,  8.7585e-02,\n         -5.2126e-02, -7.2006e-02,  1.7017e-01,  2.0722e-02,  1.0718e-01,\n          1.0142e-01, -1.3445e-01,  2.5906e-03,  1.8564e-02, -9.0046e-03,\n         -4.5182e-02,  6.6352e-02,  1.6581e-01, -3.7988e-02,  1.6065e-01,\n         -1.5130e-01,  7.0918e-02, -1.3552e-01,  9.3130e-02, -4.0126e-02,\n          1.1094e-01,  3.0476e-02, -3.6411e-02, -8.3003e-02, -9.7103e-02,\n         -8.3051e-02, -8.6854e-02],\n        [-9.6216e-02,  1.0442e-02, -2.0760e-02, -1.8152e-02,  1.0735e-01,\n         -1.0934e-02,  1.2386e-01,  1.0389e-02, -2.6165e-02, -7.6441e-02,\n          6.1258e-02,  7.3151e-02,  6.0346e-02, -1.1651e-01, -1.1015e-01,\n          1.6871e-01, -8.3234e-02,  2.3926e-02,  6.9890e-02, -3.5540e-02,\n         -1.6888e-01,  1.2352e-01,  9.6114e-02, -1.3536e-01, -2.5953e-02,\n          1.4008e-01,  1.4299e-01,  9.7187e-02,  4.9541e-02, -2.7436e-02,\n          2.9718e-02, -9.6678e-02],\n        [-5.1554e-02,  8.2307e-02, -7.4595e-02,  1.1591e-01, -2.3270e-03,\n         -1.0140e-01, -1.1911e-01, -3.2423e-02, -1.0643e-01,  9.9464e-02,\n          5.5321e-02, -1.4227e-01, -2.8404e-03,  6.8881e-03,  9.3944e-03,\n         -8.6352e-03, -4.4943e-02, -1.7411e-01, -8.9991e-02, -6.0319e-02,\n          9.3226e-02,  5.1379e-04, -1.1982e-01, -8.8923e-02,  1.1779e-01,\n         -7.8774e-02,  1.5786e-01,  3.3351e-02, -6.2373e-03,  1.2562e-01,\n         -2.8634e-02,  2.8075e-02],\n        [ 8.4461e-03,  1.5349e-02, -7.0027e-02,  5.2252e-03,  6.2523e-02,\n         -4.2305e-02,  2.7610e-02, -1.0027e-01, -1.6535e-01, -3.3015e-02,\n          1.5222e-01, -1.6875e-01,  1.2508e-01, -9.3096e-02,  1.3222e-01,\n          7.0069e-02,  1.4695e-01, -1.3521e-01,  1.4394e-01,  7.3748e-02,\n          1.4786e-02,  8.4052e-03, -7.8596e-02,  1.1024e-01, -1.5173e-01,\n         -1.1034e-01,  9.7767e-02,  1.3206e-01, -8.5590e-02, -1.2041e-01,\n         -1.4192e-01, -4.6455e-02],\n        [-7.2448e-02, -3.9742e-02, -1.5288e-03, -1.6146e-01, -1.1763e-01,\n         -7.6051e-02,  4.4391e-02,  4.7611e-02, -1.7258e-01,  6.0453e-03,\n          1.4708e-01,  1.0154e-01,  4.2597e-02, -7.2812e-02,  6.5045e-02,\n          6.7957e-02, -1.4008e-01,  6.7872e-02,  4.4275e-02, -2.1332e-03,\n         -7.6495e-02, -1.6868e-01,  2.3321e-02, -3.0987e-02, -9.5444e-02,\n         -8.7979e-02,  1.0763e-01,  1.3166e-01,  1.6776e-01,  1.5868e-01,\n         -8.2703e-02, -1.2029e-01],\n        [ 4.8739e-02,  4.9370e-02,  6.5531e-02,  1.0697e-01,  3.0990e-02,\n         -7.3886e-02,  5.5863e-02,  9.0530e-02, -1.3896e-01, -1.4024e-01,\n         -1.2560e-01, -7.6242e-02,  3.7804e-02,  1.3727e-01, -9.0431e-02,\n         -1.2472e-01, -1.1555e-01, -1.3718e-01, -1.3990e-01, -9.2370e-02,\n         -1.6366e-01, -2.9826e-02,  7.9261e-02, -8.5417e-02, -9.2797e-02,\n         -1.6342e-01, -6.9078e-02, -1.4404e-02, -8.0259e-02, -1.5794e-01,\n          4.1606e-02,  3.0109e-02],\n        [ 3.8007e-02, -1.1297e-01,  1.1396e-01,  1.5963e-01,  1.2420e-02,\n          6.7518e-02,  1.6474e-01,  1.3530e-01, -4.1975e-03,  9.7888e-02,\n         -5.2696e-02,  2.5203e-02,  1.4235e-01, -5.2958e-02, -1.5703e-01,\n          1.2242e-01,  1.7672e-01,  1.4220e-01,  1.0571e-01, -4.5394e-02,\n         -1.0743e-01, -7.8995e-02, -3.9378e-02,  1.5953e-01, -1.6345e-02,\n         -8.7727e-02, -1.6867e-01,  1.7156e-01,  4.4933e-02,  1.3480e-01,\n         -1.2250e-01,  1.2856e-01],\n        [ 6.2887e-03,  7.3878e-02,  2.1047e-02,  1.0977e-01,  5.0078e-02,\n          1.5748e-01,  7.2298e-02, -1.2432e-01, -1.6176e-01, -1.6344e-01,\n         -9.4004e-02,  1.6967e-01, -7.8052e-02,  6.1783e-02, -4.2118e-02,\n         -4.3257e-02,  6.5020e-02,  2.0336e-02, -1.3198e-01, -1.2391e-01,\n         -1.1190e-02, -5.6529e-03, -2.6189e-02, -3.2725e-02, -1.2662e-01,\n         -1.7333e-01, -1.5863e-02,  1.6445e-01, -4.4276e-02,  8.7497e-02,\n          1.1280e-01, -1.1175e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2279,  0.2030, -0.0777, -0.0970, -0.0275,  0.0840, -0.1323,  0.0947],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1183,  0.0725, -0.1246,  0.1391,  0.2007, -0.2027,  0.0150,  0.1894,\n          0.0504,  0.0130, -0.0094,  0.1141, -0.1143,  0.1355, -0.2030,  0.1916],\n        [-0.0684, -0.0253, -0.0745, -0.0565, -0.1675, -0.0965, -0.0114, -0.2354,\n         -0.0789, -0.2005,  0.1257, -0.0567,  0.2301, -0.1764, -0.0957,  0.1185],\n        [-0.1053,  0.0368, -0.1782,  0.2105, -0.1108,  0.2107,  0.0181, -0.1102,\n         -0.0447,  0.2001, -0.1757,  0.0712, -0.0683, -0.1397, -0.0542, -0.0426],\n        [-0.1646,  0.1361,  0.0064, -0.2088, -0.1914, -0.2035,  0.2332,  0.1628,\n          0.0011, -0.2367,  0.2007, -0.2319, -0.1805,  0.0589,  0.1396, -0.0185],\n        [-0.1443,  0.1221,  0.0207, -0.0444, -0.2205, -0.1987, -0.1216,  0.0837,\n         -0.0665, -0.0770, -0.1835, -0.0185, -0.0879,  0.0184,  0.0970, -0.1703],\n        [ 0.1283, -0.1998, -0.1762, -0.2377, -0.1678, -0.1341,  0.2001, -0.1773,\n         -0.0302, -0.1787, -0.0284,  0.1198, -0.1805, -0.2289, -0.0874, -0.1506],\n        [-0.0292, -0.2375, -0.2408, -0.1564, -0.0828, -0.0091,  0.1235, -0.0757,\n         -0.2344, -0.0372,  0.0318,  0.1396, -0.1990, -0.1385, -0.1927, -0.2133],\n        [ 0.0852, -0.2077,  0.0455, -0.2477, -0.0543,  0.0018,  0.1871,  0.0774,\n         -0.0338, -0.0207, -0.1438,  0.2121, -0.0125,  0.0537, -0.0501, -0.0397]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0484, -0.1190, -0.3329, -0.2363], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0144,  0.2927, -0.3349, -0.1529,  0.0265, -0.2480, -0.0730, -0.3270],\n        [-0.1537,  0.3374, -0.2392,  0.2533,  0.3273, -0.2779,  0.1244, -0.0310],\n        [-0.3049,  0.2698,  0.2863, -0.0881, -0.0840,  0.0965, -0.1350,  0.1123],\n        [-0.3369,  0.0948, -0.1156, -0.2575, -0.1858,  0.2878, -0.3499,  0.0947]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7f5b4b7a4950>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s894150000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s894150000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}