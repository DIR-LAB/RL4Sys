{
    "__class__":	"DQN",
    "act_dim":	4,
    "aux_batch_size":	0,
    "batch_size":	256,
    "buf_size":	50000,
    "buffer_segments":	5,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s914540000"
    },
    "max_sample_age":	200,
    "q_lr":	0.0003,
    "sample_decay":	0.5,
    "seed":	914540000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x761d2b1f3fd0>":	{
            "_act_dim":	4,
            "_aux_batch_size":	0,
            "_batch_size":	256,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2604,  0.1088,  0.3161, -0.2476, -0.3350,  0.2936,  0.0219, -0.2146,\n         0.3474, -0.2312, -0.2746,  0.3269, -0.2891,  0.0228, -0.0591,  0.1750,\n         0.0143, -0.3436,  0.2916, -0.0900, -0.1273,  0.0201,  0.3197, -0.1072,\n         0.2040, -0.2282, -0.0594,  0.2428,  0.1399,  0.1278,  0.0418, -0.1295],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3496, -0.1412, -0.3043,  0.1683, -0.0740,  0.1847,  0.0131,  0.2862],\n        [-0.1122,  0.0081, -0.3376,  0.1615, -0.1204, -0.0887, -0.2748,  0.3254],\n        [-0.2363, -0.3413,  0.0816,  0.3161, -0.1369, -0.0432,  0.1099, -0.1447],\n        [ 0.1385,  0.0463,  0.1482, -0.2285,  0.3474, -0.0492,  0.1898, -0.1695],\n        [ 0.2665, -0.0951, -0.1911, -0.2118, -0.2336,  0.1371,  0.1193, -0.2133],\n        [ 0.0795,  0.1590, -0.2755, -0.2776, -0.3216, -0.2286, -0.2031,  0.1840],\n        [-0.1944, -0.3493,  0.0242,  0.0060,  0.0944,  0.0119,  0.1413,  0.2240],\n        [-0.1975, -0.3042, -0.1749, -0.2582,  0.0294,  0.1348,  0.1876, -0.3329],\n        [ 0.0149, -0.1483,  0.0813,  0.3457, -0.3267, -0.2596, -0.0746, -0.0213],\n        [ 0.3439, -0.0614, -0.3214,  0.2158,  0.0524,  0.1659, -0.3510, -0.1947],\n        [-0.2046,  0.2451, -0.3128, -0.0133,  0.1862,  0.3527,  0.1449,  0.2528],\n        [-0.2526,  0.3126,  0.1441, -0.0684,  0.0484,  0.3343,  0.1292,  0.1774],\n        [ 0.2728,  0.3512, -0.1306,  0.0194, -0.1250, -0.0588,  0.1346, -0.0825],\n        [ 0.2126, -0.2481, -0.1367, -0.2988, -0.3326, -0.0804,  0.2229,  0.2332],\n        [ 0.2133,  0.1074,  0.0101, -0.0198, -0.0208,  0.1584,  0.0896,  0.3318],\n        [ 0.1403, -0.3063, -0.1403,  0.0186, -0.3355,  0.0184,  0.2953,  0.2397],\n        [-0.1720, -0.2771, -0.0028, -0.0600,  0.0911,  0.0217,  0.2099, -0.1480],\n        [ 0.1324,  0.1058, -0.1501,  0.3453, -0.0343, -0.2807,  0.2459, -0.0455],\n        [-0.2123, -0.2124, -0.3206,  0.3244,  0.3521,  0.2500,  0.0530,  0.0893],\n        [ 0.1043,  0.3058, -0.1635,  0.1696, -0.3405, -0.1660,  0.1245, -0.1320],\n        [-0.2438, -0.2078, -0.3484,  0.1686,  0.2323,  0.1126, -0.2417,  0.2918],\n        [-0.0805,  0.0499,  0.0598, -0.0740, -0.2198,  0.3108,  0.1245, -0.3161],\n        [ 0.1900,  0.3395,  0.0836,  0.0551,  0.0643,  0.2632,  0.1375,  0.0620],\n        [-0.2086, -0.0254,  0.2862, -0.2827,  0.0401,  0.2818,  0.0589, -0.1179],\n        [ 0.1692, -0.2501,  0.0242,  0.1738, -0.0399, -0.2833,  0.1434, -0.2652],\n        [-0.2147,  0.2662, -0.1914,  0.1654, -0.0377, -0.0791, -0.2515,  0.1475],\n        [ 0.2642,  0.1198,  0.1578, -0.2431,  0.1372, -0.0519, -0.2576, -0.1504],\n        [-0.1204,  0.2754, -0.2421, -0.0705, -0.1639, -0.2410, -0.0519,  0.1408],\n        [-0.2144,  0.3418, -0.1213, -0.1310, -0.1540,  0.0715, -0.2306,  0.1786],\n        [-0.0055, -0.1686,  0.2649,  0.1402,  0.1079,  0.2135,  0.0450,  0.2947],\n        [ 0.2178, -0.2236, -0.0380,  0.2979,  0.2756, -0.1833, -0.2723,  0.2818],\n        [ 0.2135, -0.1123,  0.1434, -0.3426,  0.0789,  0.1835, -0.3399, -0.2837]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1232,  0.0404, -0.0347, -0.0608, -0.0020,  0.1529,  0.0394,  0.0553,\n         0.0645,  0.1441, -0.0157,  0.0706,  0.0944,  0.1685,  0.1417,  0.0432],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.0810e-02, -1.3017e-01, -1.5216e-01,  1.4692e-01, -1.4637e-01,\n          1.7204e-01,  9.8948e-02, -4.7747e-02, -1.1353e-01, -4.3207e-02,\n         -1.6328e-01, -7.2023e-02,  8.9747e-02,  8.5506e-02,  7.6153e-02,\n         -1.3825e-01, -1.0962e-02, -1.6311e-01, -1.3365e-01, -7.8665e-02,\n         -1.6972e-01,  1.7033e-02,  1.3186e-01, -2.2635e-03,  8.6985e-02,\n          1.2529e-01, -9.4042e-02,  1.0032e-01, -2.9910e-02,  2.2365e-02,\n          9.8412e-02,  7.6138e-02],\n        [-2.9500e-02,  3.8725e-02, -5.4754e-02,  4.1671e-02, -3.9158e-03,\n          1.1748e-01, -1.6459e-01,  1.3929e-01,  1.7313e-01,  3.5716e-02,\n         -6.0376e-02, -6.6486e-02,  1.5402e-01, -1.2273e-01,  8.7424e-02,\n         -5.4687e-02, -9.5658e-02, -1.4010e-01, -3.8866e-02, -1.5217e-01,\n         -1.4532e-01, -5.4685e-02, -1.0303e-02, -1.6371e-01, -1.3773e-01,\n          7.3369e-02, -7.9025e-02,  2.3082e-03, -1.4008e-02, -8.0162e-02,\n          5.2363e-02,  6.2426e-02],\n        [-9.4385e-02,  6.6500e-02,  1.4409e-01, -7.2178e-02,  7.7567e-02,\n          8.7868e-02,  7.5608e-02,  1.3927e-01, -3.4187e-02,  3.6131e-02,\n         -1.8509e-02, -1.4640e-01, -1.4776e-01, -1.6525e-01,  1.3330e-02,\n         -4.3934e-02, -3.2688e-02,  7.8069e-02,  2.6348e-02, -2.2511e-02,\n         -1.3386e-01, -1.4130e-01,  6.0832e-02,  1.2038e-01, -1.0234e-01,\n          4.7327e-02,  7.0755e-02,  9.6209e-02, -5.6684e-02, -1.0100e-01,\n          1.4703e-01,  1.1427e-01],\n        [ 1.0638e-01,  7.6847e-02, -8.4577e-02, -1.7089e-01, -1.5190e-01,\n          1.6519e-01, -1.0664e-01,  7.1311e-02,  5.7141e-02, -7.8404e-02,\n          6.2280e-02,  7.3170e-02, -1.3698e-01, -1.6137e-01,  1.3932e-01,\n          1.0393e-01, -1.4060e-01, -1.5296e-01,  1.5210e-01, -1.2120e-01,\n         -1.0038e-01,  4.2650e-02,  4.7369e-02, -1.3904e-01,  1.7374e-02,\n          2.1899e-02,  9.1818e-02, -2.5611e-02,  2.4913e-02,  1.5328e-02,\n          2.5350e-02,  1.6237e-01],\n        [-5.6047e-02,  4.3228e-02,  1.3273e-01,  9.7388e-02,  7.3244e-02,\n         -1.2308e-01,  1.4534e-01, -1.2877e-01, -1.5958e-02, -1.1555e-01,\n         -2.0178e-02,  6.9005e-02, -1.4644e-01,  1.5323e-01, -2.4681e-02,\n          1.3170e-01, -1.6849e-01, -2.0120e-02, -1.7032e-02, -6.4580e-02,\n          1.0123e-01,  1.1087e-01, -1.0561e-01, -8.7313e-02,  3.8383e-02,\n         -1.1421e-01,  1.7486e-01,  1.1604e-01,  1.5365e-01, -6.0519e-02,\n         -1.3072e-01,  5.2379e-02],\n        [-1.5478e-01,  1.8980e-02, -8.5749e-02, -9.7231e-02, -1.2796e-01,\n          6.3271e-02,  1.3336e-01, -8.9667e-05,  1.0514e-02,  1.6861e-01,\n         -6.0826e-03, -1.1405e-01, -1.8366e-02, -1.2654e-01,  1.6432e-01,\n         -9.0601e-02, -9.7614e-02, -1.7250e-01,  6.6950e-02, -1.4882e-01,\n          1.6805e-02,  6.8642e-03, -1.1273e-01, -5.2750e-02,  3.2839e-02,\n         -6.2587e-03, -1.5106e-01, -6.1447e-02,  4.7167e-02, -1.7528e-01,\n         -5.1642e-03, -9.0123e-02],\n        [ 9.3947e-02, -1.4901e-01, -6.2890e-03,  1.3071e-01,  2.6208e-02,\n          1.0060e-01, -8.4334e-02,  1.6000e-01,  1.2651e-01, -6.8938e-03,\n         -1.1119e-01, -2.3794e-04, -1.5466e-01,  1.3138e-01,  1.1775e-01,\n         -1.5594e-01, -3.0391e-02, -1.7431e-01,  9.3385e-02, -1.2036e-02,\n         -1.1868e-01,  1.4364e-01,  9.3211e-02, -8.3724e-02,  1.6336e-01,\n          1.9541e-04,  1.7664e-01, -1.2337e-02,  1.5814e-01,  9.0802e-02,\n         -6.3716e-02,  1.2801e-01],\n        [-8.2167e-02, -1.5118e-01, -1.4100e-01, -1.6018e-01, -8.8428e-02,\n         -1.7134e-02, -2.3093e-02,  1.5119e-01,  1.4917e-01, -1.4599e-01,\n          1.1388e-01, -4.1831e-02, -3.9836e-02,  1.6732e-01,  1.3698e-01,\n          6.7320e-02, -1.0482e-01,  1.5898e-01,  6.3326e-02,  1.2388e-02,\n          1.1611e-01,  3.8520e-02,  1.6975e-01, -8.2995e-02, -3.1650e-02,\n         -1.1045e-01, -3.8199e-02, -1.0728e-04, -3.4268e-02, -3.3134e-02,\n          3.3708e-02,  4.4274e-02],\n        [ 1.6511e-02,  3.1588e-02,  6.4728e-02, -1.6023e-01,  1.2101e-01,\n          9.0821e-02, -6.7913e-02,  1.0428e-02, -1.4591e-02, -1.3290e-01,\n          3.1210e-02, -8.1209e-02,  1.0449e-01, -1.2719e-01, -5.3699e-02,\n          4.7515e-03,  5.0314e-02,  1.7491e-01, -6.4015e-03,  3.0559e-03,\n          7.8318e-02, -5.5155e-02, -1.0952e-02,  1.5396e-01, -2.9027e-02,\n         -8.4025e-02, -6.3634e-02, -1.6356e-01, -2.0116e-02,  1.6573e-01,\n         -8.5072e-02,  7.4105e-02],\n        [-1.2737e-01,  1.6760e-01, -3.9503e-02,  8.6097e-02,  2.8758e-03,\n         -3.1082e-02, -1.7778e-02,  1.2720e-01,  7.5380e-02,  1.6391e-01,\n          1.2352e-01, -4.2337e-02,  1.0179e-01,  3.8919e-02,  1.7293e-01,\n         -7.0212e-02, -1.5767e-01,  1.5442e-01,  7.2708e-02, -9.7612e-04,\n         -9.8181e-02,  1.6565e-01,  1.4722e-01,  1.6271e-01, -5.9819e-02,\n         -1.7536e-01,  1.6597e-01, -4.8438e-02,  1.6044e-01,  1.5381e-01,\n         -3.3460e-02,  1.7739e-02],\n        [ 1.7443e-01, -4.6273e-02,  5.6060e-02, -1.4066e-01,  1.1682e-01,\n         -1.7199e-01,  4.5967e-02, -9.0725e-02, -1.2599e-01,  8.9419e-03,\n          9.3607e-02, -1.0126e-01, -3.5075e-02, -1.3950e-01, -1.5262e-01,\n         -8.8179e-02, -1.5882e-01, -1.6910e-02,  8.5911e-02, -8.4526e-03,\n          1.0191e-01,  1.1718e-01, -1.4613e-01, -8.8373e-02,  6.2468e-02,\n          1.3281e-01, -1.0763e-01,  4.9510e-02,  5.9186e-02, -1.6408e-01,\n         -1.7045e-01,  7.3083e-02],\n        [-2.1753e-02, -6.3263e-02, -3.5803e-02, -9.0434e-02, -1.6998e-01,\n         -1.5219e-01, -9.0709e-02, -3.4662e-02,  1.0109e-02, -1.6489e-01,\n          6.0590e-02,  9.1922e-02, -9.8897e-02, -6.9512e-02, -1.2461e-01,\n          1.4638e-01,  7.2102e-02, -5.8868e-02, -5.5711e-02, -1.3090e-01,\n         -6.5996e-02, -8.0332e-02,  1.0721e-01,  4.9547e-02, -8.8862e-02,\n         -1.6237e-01,  8.3822e-02,  8.9783e-02, -3.4291e-02, -2.3599e-02,\n         -1.2184e-01,  1.0370e-01],\n        [-8.9300e-02, -2.8874e-02,  1.4258e-01,  1.1540e-01,  1.2209e-01,\n          1.1609e-01, -6.3560e-02, -1.3795e-01, -1.2029e-01,  8.0569e-02,\n          1.6352e-01, -2.7418e-02, -1.7533e-01, -8.3575e-03,  8.1207e-02,\n         -5.2423e-02,  1.6274e-01,  1.4166e-01,  1.2283e-01, -8.4633e-02,\n          7.0779e-02,  1.0270e-02,  1.1278e-01,  1.6372e-01,  1.5649e-01,\n         -1.3772e-03,  1.0003e-01, -1.3856e-02, -4.7110e-02,  7.4241e-02,\n         -1.3038e-01, -5.1291e-02],\n        [ 1.5679e-02,  5.9200e-02, -8.1016e-02, -3.9904e-02,  1.3529e-01,\n         -8.2168e-02, -1.0117e-01, -1.6801e-02, -1.7074e-01,  1.4755e-01,\n         -6.4766e-02,  1.2597e-01, -1.4954e-02,  1.4565e-01,  5.7075e-02,\n         -3.3373e-02, -1.0292e-02,  1.3791e-01,  1.4272e-01, -3.2126e-02,\n         -1.6484e-01, -7.4911e-02,  1.2833e-02,  1.0893e-01,  6.4730e-02,\n          2.7974e-02, -1.2539e-02, -1.0158e-01, -1.6838e-01, -4.7145e-02,\n         -1.1713e-01,  8.2016e-02],\n        [-1.2868e-01, -1.3661e-01, -3.4269e-02, -1.1952e-01, -2.9378e-02,\n          1.5414e-03,  1.3151e-01,  1.4695e-01,  2.4913e-02,  9.3570e-02,\n         -1.1717e-02,  5.3881e-02, -6.4228e-02,  9.0769e-02,  1.6702e-01,\n         -9.3792e-02,  1.6184e-02, -4.2965e-02,  4.2513e-02,  1.5222e-01,\n         -1.4980e-01, -2.2572e-02,  1.5475e-01,  1.7667e-01, -7.0245e-02,\n          1.3209e-01, -5.8459e-02,  7.0100e-02,  1.5786e-01, -6.3951e-02,\n         -1.5686e-01, -5.4901e-02],\n        [ 7.8075e-02,  9.0983e-02, -9.1872e-02, -1.3860e-01,  1.1282e-01,\n          1.5193e-01, -1.7581e-02, -1.0694e-01, -1.4103e-01,  1.4062e-01,\n         -9.0694e-02, -1.3733e-01, -6.5489e-02,  4.9840e-02, -7.3899e-02,\n          6.7461e-03,  1.3469e-01, -1.3818e-01,  1.3618e-01, -1.0941e-01,\n          6.2751e-02,  9.5302e-02, -1.2113e-01,  1.0926e-01,  1.1635e-01,\n          1.3687e-01,  7.3876e-02,  1.3127e-01, -1.6897e-01, -1.4305e-01,\n         -8.5795e-02,  5.9319e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1025,  0.0401, -0.1752, -0.1318, -0.1863,  0.0615,  0.1265, -0.0220],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2016,  0.0986, -0.1407, -0.1797, -0.2156,  0.0192,  0.1096,  0.2113,\n          0.0372,  0.0031,  0.1716, -0.2026,  0.0707, -0.1297,  0.0864,  0.1049],\n        [-0.2267, -0.1964,  0.1345,  0.1053, -0.1073,  0.0732,  0.2438,  0.1020,\n          0.0614,  0.1704,  0.0867, -0.0226,  0.1879, -0.0297, -0.2304, -0.1146],\n        [ 0.1463,  0.0449,  0.0034, -0.0907, -0.0653, -0.1911,  0.1024,  0.1702,\n         -0.0245,  0.2332, -0.2127, -0.0241, -0.1694,  0.1644, -0.1908, -0.2104],\n        [-0.1138, -0.1649,  0.1926, -0.0239, -0.2031, -0.1361,  0.1504,  0.2349,\n         -0.0623,  0.1530, -0.1790, -0.0904,  0.2188, -0.2367, -0.1777,  0.1321],\n        [ 0.1888, -0.2370,  0.0957, -0.0800,  0.1856, -0.1583,  0.1492, -0.0221,\n         -0.1794, -0.1647, -0.1363,  0.0430,  0.0457,  0.2082, -0.1968,  0.1288],\n        [ 0.1262,  0.2432,  0.1037, -0.0260,  0.0868, -0.1010, -0.1131, -0.2080,\n          0.1647,  0.0146,  0.0546, -0.0471,  0.0641, -0.1421, -0.0294,  0.0572],\n        [ 0.2084,  0.1495,  0.1502,  0.1720,  0.1017,  0.0827, -0.0280,  0.0727,\n          0.1616,  0.1700,  0.0408, -0.0678, -0.1266,  0.0365, -0.1571,  0.0485],\n        [ 0.2355,  0.0315, -0.1865,  0.2208,  0.0608, -0.0961,  0.1873,  0.2183,\n         -0.0733, -0.0921,  0.0501, -0.1860, -0.0398,  0.2323, -0.0213,  0.2246]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3370, -0.1561, -0.2709,  0.0857], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2907, -0.1500, -0.0945,  0.0209, -0.1200,  0.0627, -0.0069, -0.0048],\n        [ 0.3492, -0.2518,  0.2030,  0.1840, -0.0218,  0.1051, -0.2804, -0.3132],\n        [ 0.1442, -0.1388,  0.2179, -0.1368,  0.0509,  0.1298, -0.1829,  0.0519],\n        [ 0.0431,  0.2615, -0.2598,  0.3098, -0.2057,  0.0672,  0.1337,  0.3394]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.3496, -0.1412, -0.3043,  0.1683, -0.0740,  0.1847,  0.0131,  0.2862],\n        [-0.1122,  0.0081, -0.3376,  0.1615, -0.1204, -0.0887, -0.2748,  0.3254],\n        [-0.2363, -0.3413,  0.0816,  0.3161, -0.1369, -0.0432,  0.1099, -0.1447],\n        [ 0.1385,  0.0463,  0.1482, -0.2285,  0.3474, -0.0492,  0.1898, -0.1695],\n        [ 0.2665, -0.0951, -0.1911, -0.2118, -0.2336,  0.1371,  0.1193, -0.2133],\n        [ 0.0795,  0.1590, -0.2755, -0.2776, -0.3216, -0.2286, -0.2031,  0.1840],\n        [-0.1944, -0.3493,  0.0242,  0.0060,  0.0944,  0.0119,  0.1413,  0.2240],\n        [-0.1975, -0.3042, -0.1749, -0.2582,  0.0294,  0.1348,  0.1876, -0.3329],\n        [ 0.0149, -0.1483,  0.0813,  0.3457, -0.3267, -0.2596, -0.0746, -0.0213],\n        [ 0.3439, -0.0614, -0.3214,  0.2158,  0.0524,  0.1659, -0.3510, -0.1947],\n        [-0.2046,  0.2451, -0.3128, -0.0133,  0.1862,  0.3527,  0.1449,  0.2528],\n        [-0.2526,  0.3126,  0.1441, -0.0684,  0.0484,  0.3343,  0.1292,  0.1774],\n        [ 0.2728,  0.3512, -0.1306,  0.0194, -0.1250, -0.0588,  0.1346, -0.0825],\n        [ 0.2126, -0.2481, -0.1367, -0.2988, -0.3326, -0.0804,  0.2229,  0.2332],\n        [ 0.2133,  0.1074,  0.0101, -0.0198, -0.0208,  0.1584,  0.0896,  0.3318],\n        [ 0.1403, -0.3063, -0.1403,  0.0186, -0.3355,  0.0184,  0.2953,  0.2397],\n        [-0.1720, -0.2771, -0.0028, -0.0600,  0.0911,  0.0217,  0.2099, -0.1480],\n        [ 0.1324,  0.1058, -0.1501,  0.3453, -0.0343, -0.2807,  0.2459, -0.0455],\n        [-0.2123, -0.2124, -0.3206,  0.3244,  0.3521,  0.2500,  0.0530,  0.0893],\n        [ 0.1043,  0.3058, -0.1635,  0.1696, -0.3405, -0.1660,  0.1245, -0.1320],\n        [-0.2438, -0.2078, -0.3484,  0.1686,  0.2323,  0.1126, -0.2417,  0.2918],\n        [-0.0805,  0.0499,  0.0598, -0.0740, -0.2198,  0.3108,  0.1245, -0.3161],\n        [ 0.1900,  0.3395,  0.0836,  0.0551,  0.0643,  0.2632,  0.1375,  0.0620],\n        [-0.2086, -0.0254,  0.2862, -0.2827,  0.0401,  0.2818,  0.0589, -0.1179],\n        [ 0.1692, -0.2501,  0.0242,  0.1738, -0.0399, -0.2833,  0.1434, -0.2652],\n        [-0.2147,  0.2662, -0.1914,  0.1654, -0.0377, -0.0791, -0.2515,  0.1475],\n        [ 0.2642,  0.1198,  0.1578, -0.2431,  0.1372, -0.0519, -0.2576, -0.1504],\n        [-0.1204,  0.2754, -0.2421, -0.0705, -0.1639, -0.2410, -0.0519,  0.1408],\n        [-0.2144,  0.3418, -0.1213, -0.1310, -0.1540,  0.0715, -0.2306,  0.1786],\n        [-0.0055, -0.1686,  0.2649,  0.1402,  0.1079,  0.2135,  0.0450,  0.2947],\n        [ 0.2178, -0.2236, -0.0380,  0.2979,  0.2756, -0.1833, -0.2723,  0.2818],\n        [ 0.2135, -0.1123,  0.1434, -0.3426,  0.0789,  0.1835, -0.3399, -0.2837]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2604,  0.1088,  0.3161, -0.2476, -0.3350,  0.2936,  0.0219, -0.2146,\n         0.3474, -0.2312, -0.2746,  0.3269, -0.2891,  0.0228, -0.0591,  0.1750,\n         0.0143, -0.3436,  0.2916, -0.0900, -0.1273,  0.0201,  0.3197, -0.1072,\n         0.2040, -0.2282, -0.0594,  0.2428,  0.1399,  0.1278,  0.0418, -0.1295],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-2.0810e-02, -1.3017e-01, -1.5216e-01,  1.4692e-01, -1.4637e-01,\n          1.7204e-01,  9.8948e-02, -4.7747e-02, -1.1353e-01, -4.3207e-02,\n         -1.6328e-01, -7.2023e-02,  8.9747e-02,  8.5506e-02,  7.6153e-02,\n         -1.3825e-01, -1.0962e-02, -1.6311e-01, -1.3365e-01, -7.8665e-02,\n         -1.6972e-01,  1.7033e-02,  1.3186e-01, -2.2635e-03,  8.6985e-02,\n          1.2529e-01, -9.4042e-02,  1.0032e-01, -2.9910e-02,  2.2365e-02,\n          9.8412e-02,  7.6138e-02],\n        [-2.9500e-02,  3.8725e-02, -5.4754e-02,  4.1671e-02, -3.9158e-03,\n          1.1748e-01, -1.6459e-01,  1.3929e-01,  1.7313e-01,  3.5716e-02,\n         -6.0376e-02, -6.6486e-02,  1.5402e-01, -1.2273e-01,  8.7424e-02,\n         -5.4687e-02, -9.5658e-02, -1.4010e-01, -3.8866e-02, -1.5217e-01,\n         -1.4532e-01, -5.4685e-02, -1.0303e-02, -1.6371e-01, -1.3773e-01,\n          7.3369e-02, -7.9025e-02,  2.3082e-03, -1.4008e-02, -8.0162e-02,\n          5.2363e-02,  6.2426e-02],\n        [-9.4385e-02,  6.6500e-02,  1.4409e-01, -7.2178e-02,  7.7567e-02,\n          8.7868e-02,  7.5608e-02,  1.3927e-01, -3.4187e-02,  3.6131e-02,\n         -1.8509e-02, -1.4640e-01, -1.4776e-01, -1.6525e-01,  1.3330e-02,\n         -4.3934e-02, -3.2688e-02,  7.8069e-02,  2.6348e-02, -2.2511e-02,\n         -1.3386e-01, -1.4130e-01,  6.0832e-02,  1.2038e-01, -1.0234e-01,\n          4.7327e-02,  7.0755e-02,  9.6209e-02, -5.6684e-02, -1.0100e-01,\n          1.4703e-01,  1.1427e-01],\n        [ 1.0638e-01,  7.6847e-02, -8.4577e-02, -1.7089e-01, -1.5190e-01,\n          1.6519e-01, -1.0664e-01,  7.1311e-02,  5.7141e-02, -7.8404e-02,\n          6.2280e-02,  7.3170e-02, -1.3698e-01, -1.6137e-01,  1.3932e-01,\n          1.0393e-01, -1.4060e-01, -1.5296e-01,  1.5210e-01, -1.2120e-01,\n         -1.0038e-01,  4.2650e-02,  4.7369e-02, -1.3904e-01,  1.7374e-02,\n          2.1899e-02,  9.1818e-02, -2.5611e-02,  2.4913e-02,  1.5328e-02,\n          2.5350e-02,  1.6237e-01],\n        [-5.6047e-02,  4.3228e-02,  1.3273e-01,  9.7388e-02,  7.3244e-02,\n         -1.2308e-01,  1.4534e-01, -1.2877e-01, -1.5958e-02, -1.1555e-01,\n         -2.0178e-02,  6.9005e-02, -1.4644e-01,  1.5323e-01, -2.4681e-02,\n          1.3170e-01, -1.6849e-01, -2.0120e-02, -1.7032e-02, -6.4580e-02,\n          1.0123e-01,  1.1087e-01, -1.0561e-01, -8.7313e-02,  3.8383e-02,\n         -1.1421e-01,  1.7486e-01,  1.1604e-01,  1.5365e-01, -6.0519e-02,\n         -1.3072e-01,  5.2379e-02],\n        [-1.5478e-01,  1.8980e-02, -8.5749e-02, -9.7231e-02, -1.2796e-01,\n          6.3271e-02,  1.3336e-01, -8.9667e-05,  1.0514e-02,  1.6861e-01,\n         -6.0826e-03, -1.1405e-01, -1.8366e-02, -1.2654e-01,  1.6432e-01,\n         -9.0601e-02, -9.7614e-02, -1.7250e-01,  6.6950e-02, -1.4882e-01,\n          1.6805e-02,  6.8642e-03, -1.1273e-01, -5.2750e-02,  3.2839e-02,\n         -6.2587e-03, -1.5106e-01, -6.1447e-02,  4.7167e-02, -1.7528e-01,\n         -5.1642e-03, -9.0123e-02],\n        [ 9.3947e-02, -1.4901e-01, -6.2890e-03,  1.3071e-01,  2.6208e-02,\n          1.0060e-01, -8.4334e-02,  1.6000e-01,  1.2651e-01, -6.8938e-03,\n         -1.1119e-01, -2.3794e-04, -1.5466e-01,  1.3138e-01,  1.1775e-01,\n         -1.5594e-01, -3.0391e-02, -1.7431e-01,  9.3385e-02, -1.2036e-02,\n         -1.1868e-01,  1.4364e-01,  9.3211e-02, -8.3724e-02,  1.6336e-01,\n          1.9541e-04,  1.7664e-01, -1.2337e-02,  1.5814e-01,  9.0802e-02,\n         -6.3716e-02,  1.2801e-01],\n        [-8.2167e-02, -1.5118e-01, -1.4100e-01, -1.6018e-01, -8.8428e-02,\n         -1.7134e-02, -2.3093e-02,  1.5119e-01,  1.4917e-01, -1.4599e-01,\n          1.1388e-01, -4.1831e-02, -3.9836e-02,  1.6732e-01,  1.3698e-01,\n          6.7320e-02, -1.0482e-01,  1.5898e-01,  6.3326e-02,  1.2388e-02,\n          1.1611e-01,  3.8520e-02,  1.6975e-01, -8.2995e-02, -3.1650e-02,\n         -1.1045e-01, -3.8199e-02, -1.0728e-04, -3.4268e-02, -3.3134e-02,\n          3.3708e-02,  4.4274e-02],\n        [ 1.6511e-02,  3.1588e-02,  6.4728e-02, -1.6023e-01,  1.2101e-01,\n          9.0821e-02, -6.7913e-02,  1.0428e-02, -1.4591e-02, -1.3290e-01,\n          3.1210e-02, -8.1209e-02,  1.0449e-01, -1.2719e-01, -5.3699e-02,\n          4.7515e-03,  5.0314e-02,  1.7491e-01, -6.4015e-03,  3.0559e-03,\n          7.8318e-02, -5.5155e-02, -1.0952e-02,  1.5396e-01, -2.9027e-02,\n         -8.4025e-02, -6.3634e-02, -1.6356e-01, -2.0116e-02,  1.6573e-01,\n         -8.5072e-02,  7.4105e-02],\n        [-1.2737e-01,  1.6760e-01, -3.9503e-02,  8.6097e-02,  2.8758e-03,\n         -3.1082e-02, -1.7778e-02,  1.2720e-01,  7.5380e-02,  1.6391e-01,\n          1.2352e-01, -4.2337e-02,  1.0179e-01,  3.8919e-02,  1.7293e-01,\n         -7.0212e-02, -1.5767e-01,  1.5442e-01,  7.2708e-02, -9.7612e-04,\n         -9.8181e-02,  1.6565e-01,  1.4722e-01,  1.6271e-01, -5.9819e-02,\n         -1.7536e-01,  1.6597e-01, -4.8438e-02,  1.6044e-01,  1.5381e-01,\n         -3.3460e-02,  1.7739e-02],\n        [ 1.7443e-01, -4.6273e-02,  5.6060e-02, -1.4066e-01,  1.1682e-01,\n         -1.7199e-01,  4.5967e-02, -9.0725e-02, -1.2599e-01,  8.9419e-03,\n          9.3607e-02, -1.0126e-01, -3.5075e-02, -1.3950e-01, -1.5262e-01,\n         -8.8179e-02, -1.5882e-01, -1.6910e-02,  8.5911e-02, -8.4526e-03,\n          1.0191e-01,  1.1718e-01, -1.4613e-01, -8.8373e-02,  6.2468e-02,\n          1.3281e-01, -1.0763e-01,  4.9510e-02,  5.9186e-02, -1.6408e-01,\n         -1.7045e-01,  7.3083e-02],\n        [-2.1753e-02, -6.3263e-02, -3.5803e-02, -9.0434e-02, -1.6998e-01,\n         -1.5219e-01, -9.0709e-02, -3.4662e-02,  1.0109e-02, -1.6489e-01,\n          6.0590e-02,  9.1922e-02, -9.8897e-02, -6.9512e-02, -1.2461e-01,\n          1.4638e-01,  7.2102e-02, -5.8868e-02, -5.5711e-02, -1.3090e-01,\n         -6.5996e-02, -8.0332e-02,  1.0721e-01,  4.9547e-02, -8.8862e-02,\n         -1.6237e-01,  8.3822e-02,  8.9783e-02, -3.4291e-02, -2.3599e-02,\n         -1.2184e-01,  1.0370e-01],\n        [-8.9300e-02, -2.8874e-02,  1.4258e-01,  1.1540e-01,  1.2209e-01,\n          1.1609e-01, -6.3560e-02, -1.3795e-01, -1.2029e-01,  8.0569e-02,\n          1.6352e-01, -2.7418e-02, -1.7533e-01, -8.3575e-03,  8.1207e-02,\n         -5.2423e-02,  1.6274e-01,  1.4166e-01,  1.2283e-01, -8.4633e-02,\n          7.0779e-02,  1.0270e-02,  1.1278e-01,  1.6372e-01,  1.5649e-01,\n         -1.3772e-03,  1.0003e-01, -1.3856e-02, -4.7110e-02,  7.4241e-02,\n         -1.3038e-01, -5.1291e-02],\n        [ 1.5679e-02,  5.9200e-02, -8.1016e-02, -3.9904e-02,  1.3529e-01,\n         -8.2168e-02, -1.0117e-01, -1.6801e-02, -1.7074e-01,  1.4755e-01,\n         -6.4766e-02,  1.2597e-01, -1.4954e-02,  1.4565e-01,  5.7075e-02,\n         -3.3373e-02, -1.0292e-02,  1.3791e-01,  1.4272e-01, -3.2126e-02,\n         -1.6484e-01, -7.4911e-02,  1.2833e-02,  1.0893e-01,  6.4730e-02,\n          2.7974e-02, -1.2539e-02, -1.0158e-01, -1.6838e-01, -4.7145e-02,\n         -1.1713e-01,  8.2016e-02],\n        [-1.2868e-01, -1.3661e-01, -3.4269e-02, -1.1952e-01, -2.9378e-02,\n          1.5414e-03,  1.3151e-01,  1.4695e-01,  2.4913e-02,  9.3570e-02,\n         -1.1717e-02,  5.3881e-02, -6.4228e-02,  9.0769e-02,  1.6702e-01,\n         -9.3792e-02,  1.6184e-02, -4.2965e-02,  4.2513e-02,  1.5222e-01,\n         -1.4980e-01, -2.2572e-02,  1.5475e-01,  1.7667e-01, -7.0245e-02,\n          1.3209e-01, -5.8459e-02,  7.0100e-02,  1.5786e-01, -6.3951e-02,\n         -1.5686e-01, -5.4901e-02],\n        [ 7.8075e-02,  9.0983e-02, -9.1872e-02, -1.3860e-01,  1.1282e-01,\n          1.5193e-01, -1.7581e-02, -1.0694e-01, -1.4103e-01,  1.4062e-01,\n         -9.0694e-02, -1.3733e-01, -6.5489e-02,  4.9840e-02, -7.3899e-02,\n          6.7461e-03,  1.3469e-01, -1.3818e-01,  1.3618e-01, -1.0941e-01,\n          6.2751e-02,  9.5302e-02, -1.2113e-01,  1.0926e-01,  1.1635e-01,\n          1.3687e-01,  7.3876e-02,  1.3127e-01, -1.6897e-01, -1.4305e-01,\n         -8.5795e-02,  5.9319e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1232,  0.0404, -0.0347, -0.0608, -0.0020,  0.1529,  0.0394,  0.0553,\n         0.0645,  0.1441, -0.0157,  0.0706,  0.0944,  0.1685,  0.1417,  0.0432],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2016,  0.0986, -0.1407, -0.1797, -0.2156,  0.0192,  0.1096,  0.2113,\n          0.0372,  0.0031,  0.1716, -0.2026,  0.0707, -0.1297,  0.0864,  0.1049],\n        [-0.2267, -0.1964,  0.1345,  0.1053, -0.1073,  0.0732,  0.2438,  0.1020,\n          0.0614,  0.1704,  0.0867, -0.0226,  0.1879, -0.0297, -0.2304, -0.1146],\n        [ 0.1463,  0.0449,  0.0034, -0.0907, -0.0653, -0.1911,  0.1024,  0.1702,\n         -0.0245,  0.2332, -0.2127, -0.0241, -0.1694,  0.1644, -0.1908, -0.2104],\n        [-0.1138, -0.1649,  0.1926, -0.0239, -0.2031, -0.1361,  0.1504,  0.2349,\n         -0.0623,  0.1530, -0.1790, -0.0904,  0.2188, -0.2367, -0.1777,  0.1321],\n        [ 0.1888, -0.2370,  0.0957, -0.0800,  0.1856, -0.1583,  0.1492, -0.0221,\n         -0.1794, -0.1647, -0.1363,  0.0430,  0.0457,  0.2082, -0.1968,  0.1288],\n        [ 0.1262,  0.2432,  0.1037, -0.0260,  0.0868, -0.1010, -0.1131, -0.2080,\n          0.1647,  0.0146,  0.0546, -0.0471,  0.0641, -0.1421, -0.0294,  0.0572],\n        [ 0.2084,  0.1495,  0.1502,  0.1720,  0.1017,  0.0827, -0.0280,  0.0727,\n          0.1616,  0.1700,  0.0408, -0.0678, -0.1266,  0.0365, -0.1571,  0.0485],\n        [ 0.2355,  0.0315, -0.1865,  0.2208,  0.0608, -0.0961,  0.1873,  0.2183,\n         -0.0733, -0.0921,  0.0501, -0.1860, -0.0398,  0.2323, -0.0213,  0.2246]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1025,  0.0401, -0.1752, -0.1318, -0.1863,  0.0615,  0.1265, -0.0220],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2907, -0.1500, -0.0945,  0.0209, -0.1200,  0.0627, -0.0069, -0.0048],\n        [ 0.3492, -0.2518,  0.2030,  0.1840, -0.0218,  0.1051, -0.2804, -0.3132],\n        [ 0.1442, -0.1388,  0.2179, -0.1368,  0.0509,  0.1298, -0.1829,  0.0519],\n        [ 0.0431,  0.2615, -0.2598,  0.3098, -0.2057,  0.0672,  0.1337,  0.3394]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.3370, -0.1561, -0.2709,  0.0857], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x761d2ab9ba10>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "alpha":	0.6,
                    "beta":	0.4,
                    "beta_increment_per_sampling":	0.0001,
                    "buf_size":	50000,
                    "done_buf":	"[False False False ... False False False]",
                    "epsilon_per_priority":	1e-06,
                    "markers":	"[False False False ... False False False]",
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "mask_dim":	2,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_dim":	8,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "step":	0,
                    "sum_tree":	{
                        "<algorithms.DQN.replay_buffer.SumTree object at 0x761d2aa6fc90>":	{
                            "capacity":	50000,
                            "data":	"[0 0 0 ... 0 0 0]",
                            "n_entries":	0,
                            "tree":	"[0. 0. 0. ... 0. 0. 0.]",
                            "write":	0
                        }
                    },
                    "timestamps":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2604,  0.1088,  0.3161, -0.2476, -0.3350,  0.2936,  0.0219, -0.2146,\n         0.3474, -0.2312, -0.2746,  0.3269, -0.2891,  0.0228, -0.0591,  0.1750,\n         0.0143, -0.3436,  0.2916, -0.0900, -0.1273,  0.0201,  0.3197, -0.1072,\n         0.2040, -0.2282, -0.0594,  0.2428,  0.1399,  0.1278,  0.0418, -0.1295],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3496, -0.1412, -0.3043,  0.1683, -0.0740,  0.1847,  0.0131,  0.2862],\n        [-0.1122,  0.0081, -0.3376,  0.1615, -0.1204, -0.0887, -0.2748,  0.3254],\n        [-0.2363, -0.3413,  0.0816,  0.3161, -0.1369, -0.0432,  0.1099, -0.1447],\n        [ 0.1385,  0.0463,  0.1482, -0.2285,  0.3474, -0.0492,  0.1898, -0.1695],\n        [ 0.2665, -0.0951, -0.1911, -0.2118, -0.2336,  0.1371,  0.1193, -0.2133],\n        [ 0.0795,  0.1590, -0.2755, -0.2776, -0.3216, -0.2286, -0.2031,  0.1840],\n        [-0.1944, -0.3493,  0.0242,  0.0060,  0.0944,  0.0119,  0.1413,  0.2240],\n        [-0.1975, -0.3042, -0.1749, -0.2582,  0.0294,  0.1348,  0.1876, -0.3329],\n        [ 0.0149, -0.1483,  0.0813,  0.3457, -0.3267, -0.2596, -0.0746, -0.0213],\n        [ 0.3439, -0.0614, -0.3214,  0.2158,  0.0524,  0.1659, -0.3510, -0.1947],\n        [-0.2046,  0.2451, -0.3128, -0.0133,  0.1862,  0.3527,  0.1449,  0.2528],\n        [-0.2526,  0.3126,  0.1441, -0.0684,  0.0484,  0.3343,  0.1292,  0.1774],\n        [ 0.2728,  0.3512, -0.1306,  0.0194, -0.1250, -0.0588,  0.1346, -0.0825],\n        [ 0.2126, -0.2481, -0.1367, -0.2988, -0.3326, -0.0804,  0.2229,  0.2332],\n        [ 0.2133,  0.1074,  0.0101, -0.0198, -0.0208,  0.1584,  0.0896,  0.3318],\n        [ 0.1403, -0.3063, -0.1403,  0.0186, -0.3355,  0.0184,  0.2953,  0.2397],\n        [-0.1720, -0.2771, -0.0028, -0.0600,  0.0911,  0.0217,  0.2099, -0.1480],\n        [ 0.1324,  0.1058, -0.1501,  0.3453, -0.0343, -0.2807,  0.2459, -0.0455],\n        [-0.2123, -0.2124, -0.3206,  0.3244,  0.3521,  0.2500,  0.0530,  0.0893],\n        [ 0.1043,  0.3058, -0.1635,  0.1696, -0.3405, -0.1660,  0.1245, -0.1320],\n        [-0.2438, -0.2078, -0.3484,  0.1686,  0.2323,  0.1126, -0.2417,  0.2918],\n        [-0.0805,  0.0499,  0.0598, -0.0740, -0.2198,  0.3108,  0.1245, -0.3161],\n        [ 0.1900,  0.3395,  0.0836,  0.0551,  0.0643,  0.2632,  0.1375,  0.0620],\n        [-0.2086, -0.0254,  0.2862, -0.2827,  0.0401,  0.2818,  0.0589, -0.1179],\n        [ 0.1692, -0.2501,  0.0242,  0.1738, -0.0399, -0.2833,  0.1434, -0.2652],\n        [-0.2147,  0.2662, -0.1914,  0.1654, -0.0377, -0.0791, -0.2515,  0.1475],\n        [ 0.2642,  0.1198,  0.1578, -0.2431,  0.1372, -0.0519, -0.2576, -0.1504],\n        [-0.1204,  0.2754, -0.2421, -0.0705, -0.1639, -0.2410, -0.0519,  0.1408],\n        [-0.2144,  0.3418, -0.1213, -0.1310, -0.1540,  0.0715, -0.2306,  0.1786],\n        [-0.0055, -0.1686,  0.2649,  0.1402,  0.1079,  0.2135,  0.0450,  0.2947],\n        [ 0.2178, -0.2236, -0.0380,  0.2979,  0.2756, -0.1833, -0.2723,  0.2818],\n        [ 0.2135, -0.1123,  0.1434, -0.3426,  0.0789,  0.1835, -0.3399, -0.2837]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1232,  0.0404, -0.0347, -0.0608, -0.0020,  0.1529,  0.0394,  0.0553,\n         0.0645,  0.1441, -0.0157,  0.0706,  0.0944,  0.1685,  0.1417,  0.0432],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.0810e-02, -1.3017e-01, -1.5216e-01,  1.4692e-01, -1.4637e-01,\n          1.7204e-01,  9.8948e-02, -4.7747e-02, -1.1353e-01, -4.3207e-02,\n         -1.6328e-01, -7.2023e-02,  8.9747e-02,  8.5506e-02,  7.6153e-02,\n         -1.3825e-01, -1.0962e-02, -1.6311e-01, -1.3365e-01, -7.8665e-02,\n         -1.6972e-01,  1.7033e-02,  1.3186e-01, -2.2635e-03,  8.6985e-02,\n          1.2529e-01, -9.4042e-02,  1.0032e-01, -2.9910e-02,  2.2365e-02,\n          9.8412e-02,  7.6138e-02],\n        [-2.9500e-02,  3.8725e-02, -5.4754e-02,  4.1671e-02, -3.9158e-03,\n          1.1748e-01, -1.6459e-01,  1.3929e-01,  1.7313e-01,  3.5716e-02,\n         -6.0376e-02, -6.6486e-02,  1.5402e-01, -1.2273e-01,  8.7424e-02,\n         -5.4687e-02, -9.5658e-02, -1.4010e-01, -3.8866e-02, -1.5217e-01,\n         -1.4532e-01, -5.4685e-02, -1.0303e-02, -1.6371e-01, -1.3773e-01,\n          7.3369e-02, -7.9025e-02,  2.3082e-03, -1.4008e-02, -8.0162e-02,\n          5.2363e-02,  6.2426e-02],\n        [-9.4385e-02,  6.6500e-02,  1.4409e-01, -7.2178e-02,  7.7567e-02,\n          8.7868e-02,  7.5608e-02,  1.3927e-01, -3.4187e-02,  3.6131e-02,\n         -1.8509e-02, -1.4640e-01, -1.4776e-01, -1.6525e-01,  1.3330e-02,\n         -4.3934e-02, -3.2688e-02,  7.8069e-02,  2.6348e-02, -2.2511e-02,\n         -1.3386e-01, -1.4130e-01,  6.0832e-02,  1.2038e-01, -1.0234e-01,\n          4.7327e-02,  7.0755e-02,  9.6209e-02, -5.6684e-02, -1.0100e-01,\n          1.4703e-01,  1.1427e-01],\n        [ 1.0638e-01,  7.6847e-02, -8.4577e-02, -1.7089e-01, -1.5190e-01,\n          1.6519e-01, -1.0664e-01,  7.1311e-02,  5.7141e-02, -7.8404e-02,\n          6.2280e-02,  7.3170e-02, -1.3698e-01, -1.6137e-01,  1.3932e-01,\n          1.0393e-01, -1.4060e-01, -1.5296e-01,  1.5210e-01, -1.2120e-01,\n         -1.0038e-01,  4.2650e-02,  4.7369e-02, -1.3904e-01,  1.7374e-02,\n          2.1899e-02,  9.1818e-02, -2.5611e-02,  2.4913e-02,  1.5328e-02,\n          2.5350e-02,  1.6237e-01],\n        [-5.6047e-02,  4.3228e-02,  1.3273e-01,  9.7388e-02,  7.3244e-02,\n         -1.2308e-01,  1.4534e-01, -1.2877e-01, -1.5958e-02, -1.1555e-01,\n         -2.0178e-02,  6.9005e-02, -1.4644e-01,  1.5323e-01, -2.4681e-02,\n          1.3170e-01, -1.6849e-01, -2.0120e-02, -1.7032e-02, -6.4580e-02,\n          1.0123e-01,  1.1087e-01, -1.0561e-01, -8.7313e-02,  3.8383e-02,\n         -1.1421e-01,  1.7486e-01,  1.1604e-01,  1.5365e-01, -6.0519e-02,\n         -1.3072e-01,  5.2379e-02],\n        [-1.5478e-01,  1.8980e-02, -8.5749e-02, -9.7231e-02, -1.2796e-01,\n          6.3271e-02,  1.3336e-01, -8.9667e-05,  1.0514e-02,  1.6861e-01,\n         -6.0826e-03, -1.1405e-01, -1.8366e-02, -1.2654e-01,  1.6432e-01,\n         -9.0601e-02, -9.7614e-02, -1.7250e-01,  6.6950e-02, -1.4882e-01,\n          1.6805e-02,  6.8642e-03, -1.1273e-01, -5.2750e-02,  3.2839e-02,\n         -6.2587e-03, -1.5106e-01, -6.1447e-02,  4.7167e-02, -1.7528e-01,\n         -5.1642e-03, -9.0123e-02],\n        [ 9.3947e-02, -1.4901e-01, -6.2890e-03,  1.3071e-01,  2.6208e-02,\n          1.0060e-01, -8.4334e-02,  1.6000e-01,  1.2651e-01, -6.8938e-03,\n         -1.1119e-01, -2.3794e-04, -1.5466e-01,  1.3138e-01,  1.1775e-01,\n         -1.5594e-01, -3.0391e-02, -1.7431e-01,  9.3385e-02, -1.2036e-02,\n         -1.1868e-01,  1.4364e-01,  9.3211e-02, -8.3724e-02,  1.6336e-01,\n          1.9541e-04,  1.7664e-01, -1.2337e-02,  1.5814e-01,  9.0802e-02,\n         -6.3716e-02,  1.2801e-01],\n        [-8.2167e-02, -1.5118e-01, -1.4100e-01, -1.6018e-01, -8.8428e-02,\n         -1.7134e-02, -2.3093e-02,  1.5119e-01,  1.4917e-01, -1.4599e-01,\n          1.1388e-01, -4.1831e-02, -3.9836e-02,  1.6732e-01,  1.3698e-01,\n          6.7320e-02, -1.0482e-01,  1.5898e-01,  6.3326e-02,  1.2388e-02,\n          1.1611e-01,  3.8520e-02,  1.6975e-01, -8.2995e-02, -3.1650e-02,\n         -1.1045e-01, -3.8199e-02, -1.0728e-04, -3.4268e-02, -3.3134e-02,\n          3.3708e-02,  4.4274e-02],\n        [ 1.6511e-02,  3.1588e-02,  6.4728e-02, -1.6023e-01,  1.2101e-01,\n          9.0821e-02, -6.7913e-02,  1.0428e-02, -1.4591e-02, -1.3290e-01,\n          3.1210e-02, -8.1209e-02,  1.0449e-01, -1.2719e-01, -5.3699e-02,\n          4.7515e-03,  5.0314e-02,  1.7491e-01, -6.4015e-03,  3.0559e-03,\n          7.8318e-02, -5.5155e-02, -1.0952e-02,  1.5396e-01, -2.9027e-02,\n         -8.4025e-02, -6.3634e-02, -1.6356e-01, -2.0116e-02,  1.6573e-01,\n         -8.5072e-02,  7.4105e-02],\n        [-1.2737e-01,  1.6760e-01, -3.9503e-02,  8.6097e-02,  2.8758e-03,\n         -3.1082e-02, -1.7778e-02,  1.2720e-01,  7.5380e-02,  1.6391e-01,\n          1.2352e-01, -4.2337e-02,  1.0179e-01,  3.8919e-02,  1.7293e-01,\n         -7.0212e-02, -1.5767e-01,  1.5442e-01,  7.2708e-02, -9.7612e-04,\n         -9.8181e-02,  1.6565e-01,  1.4722e-01,  1.6271e-01, -5.9819e-02,\n         -1.7536e-01,  1.6597e-01, -4.8438e-02,  1.6044e-01,  1.5381e-01,\n         -3.3460e-02,  1.7739e-02],\n        [ 1.7443e-01, -4.6273e-02,  5.6060e-02, -1.4066e-01,  1.1682e-01,\n         -1.7199e-01,  4.5967e-02, -9.0725e-02, -1.2599e-01,  8.9419e-03,\n          9.3607e-02, -1.0126e-01, -3.5075e-02, -1.3950e-01, -1.5262e-01,\n         -8.8179e-02, -1.5882e-01, -1.6910e-02,  8.5911e-02, -8.4526e-03,\n          1.0191e-01,  1.1718e-01, -1.4613e-01, -8.8373e-02,  6.2468e-02,\n          1.3281e-01, -1.0763e-01,  4.9510e-02,  5.9186e-02, -1.6408e-01,\n         -1.7045e-01,  7.3083e-02],\n        [-2.1753e-02, -6.3263e-02, -3.5803e-02, -9.0434e-02, -1.6998e-01,\n         -1.5219e-01, -9.0709e-02, -3.4662e-02,  1.0109e-02, -1.6489e-01,\n          6.0590e-02,  9.1922e-02, -9.8897e-02, -6.9512e-02, -1.2461e-01,\n          1.4638e-01,  7.2102e-02, -5.8868e-02, -5.5711e-02, -1.3090e-01,\n         -6.5996e-02, -8.0332e-02,  1.0721e-01,  4.9547e-02, -8.8862e-02,\n         -1.6237e-01,  8.3822e-02,  8.9783e-02, -3.4291e-02, -2.3599e-02,\n         -1.2184e-01,  1.0370e-01],\n        [-8.9300e-02, -2.8874e-02,  1.4258e-01,  1.1540e-01,  1.2209e-01,\n          1.1609e-01, -6.3560e-02, -1.3795e-01, -1.2029e-01,  8.0569e-02,\n          1.6352e-01, -2.7418e-02, -1.7533e-01, -8.3575e-03,  8.1207e-02,\n         -5.2423e-02,  1.6274e-01,  1.4166e-01,  1.2283e-01, -8.4633e-02,\n          7.0779e-02,  1.0270e-02,  1.1278e-01,  1.6372e-01,  1.5649e-01,\n         -1.3772e-03,  1.0003e-01, -1.3856e-02, -4.7110e-02,  7.4241e-02,\n         -1.3038e-01, -5.1291e-02],\n        [ 1.5679e-02,  5.9200e-02, -8.1016e-02, -3.9904e-02,  1.3529e-01,\n         -8.2168e-02, -1.0117e-01, -1.6801e-02, -1.7074e-01,  1.4755e-01,\n         -6.4766e-02,  1.2597e-01, -1.4954e-02,  1.4565e-01,  5.7075e-02,\n         -3.3373e-02, -1.0292e-02,  1.3791e-01,  1.4272e-01, -3.2126e-02,\n         -1.6484e-01, -7.4911e-02,  1.2833e-02,  1.0893e-01,  6.4730e-02,\n          2.7974e-02, -1.2539e-02, -1.0158e-01, -1.6838e-01, -4.7145e-02,\n         -1.1713e-01,  8.2016e-02],\n        [-1.2868e-01, -1.3661e-01, -3.4269e-02, -1.1952e-01, -2.9378e-02,\n          1.5414e-03,  1.3151e-01,  1.4695e-01,  2.4913e-02,  9.3570e-02,\n         -1.1717e-02,  5.3881e-02, -6.4228e-02,  9.0769e-02,  1.6702e-01,\n         -9.3792e-02,  1.6184e-02, -4.2965e-02,  4.2513e-02,  1.5222e-01,\n         -1.4980e-01, -2.2572e-02,  1.5475e-01,  1.7667e-01, -7.0245e-02,\n          1.3209e-01, -5.8459e-02,  7.0100e-02,  1.5786e-01, -6.3951e-02,\n         -1.5686e-01, -5.4901e-02],\n        [ 7.8075e-02,  9.0983e-02, -9.1872e-02, -1.3860e-01,  1.1282e-01,\n          1.5193e-01, -1.7581e-02, -1.0694e-01, -1.4103e-01,  1.4062e-01,\n         -9.0694e-02, -1.3733e-01, -6.5489e-02,  4.9840e-02, -7.3899e-02,\n          6.7461e-03,  1.3469e-01, -1.3818e-01,  1.3618e-01, -1.0941e-01,\n          6.2751e-02,  9.5302e-02, -1.2113e-01,  1.0926e-01,  1.1635e-01,\n          1.3687e-01,  7.3876e-02,  1.3127e-01, -1.6897e-01, -1.4305e-01,\n         -8.5795e-02,  5.9319e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1025,  0.0401, -0.1752, -0.1318, -0.1863,  0.0615,  0.1265, -0.0220],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2016,  0.0986, -0.1407, -0.1797, -0.2156,  0.0192,  0.1096,  0.2113,\n          0.0372,  0.0031,  0.1716, -0.2026,  0.0707, -0.1297,  0.0864,  0.1049],\n        [-0.2267, -0.1964,  0.1345,  0.1053, -0.1073,  0.0732,  0.2438,  0.1020,\n          0.0614,  0.1704,  0.0867, -0.0226,  0.1879, -0.0297, -0.2304, -0.1146],\n        [ 0.1463,  0.0449,  0.0034, -0.0907, -0.0653, -0.1911,  0.1024,  0.1702,\n         -0.0245,  0.2332, -0.2127, -0.0241, -0.1694,  0.1644, -0.1908, -0.2104],\n        [-0.1138, -0.1649,  0.1926, -0.0239, -0.2031, -0.1361,  0.1504,  0.2349,\n         -0.0623,  0.1530, -0.1790, -0.0904,  0.2188, -0.2367, -0.1777,  0.1321],\n        [ 0.1888, -0.2370,  0.0957, -0.0800,  0.1856, -0.1583,  0.1492, -0.0221,\n         -0.1794, -0.1647, -0.1363,  0.0430,  0.0457,  0.2082, -0.1968,  0.1288],\n        [ 0.1262,  0.2432,  0.1037, -0.0260,  0.0868, -0.1010, -0.1131, -0.2080,\n          0.1647,  0.0146,  0.0546, -0.0471,  0.0641, -0.1421, -0.0294,  0.0572],\n        [ 0.2084,  0.1495,  0.1502,  0.1720,  0.1017,  0.0827, -0.0280,  0.0727,\n          0.1616,  0.1700,  0.0408, -0.0678, -0.1266,  0.0365, -0.1571,  0.0485],\n        [ 0.2355,  0.0315, -0.1865,  0.2208,  0.0608, -0.0961,  0.1873,  0.2183,\n         -0.0733, -0.0921,  0.0501, -0.1860, -0.0398,  0.2323, -0.0213,  0.2246]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3370, -0.1561, -0.2709,  0.0857], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2907, -0.1500, -0.0945,  0.0209, -0.1200,  0.0627, -0.0069, -0.0048],\n        [ 0.3492, -0.2518,  0.2030,  0.1840, -0.0218,  0.1051, -0.2804, -0.3132],\n        [ 0.1442, -0.1388,  0.2179, -0.1368,  0.0509,  0.1298, -0.1829,  0.0519],\n        [ 0.0431,  0.2615, -0.2598,  0.3098, -0.2057,  0.0672,  0.1337,  0.3394]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_freq":	100,
            "_train_q_iters":	80,
            "_train_update_freq":	3,
            "_traj_per_epoch":	6,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x761d26efd110>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s914540000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s914540000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	100,
    "train_q_iters":	80,
    "train_update_freq":	3,
    "traj_per_epoch":	6
}