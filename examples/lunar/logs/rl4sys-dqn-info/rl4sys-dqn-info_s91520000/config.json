{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	12,
    "buf_size":	5000,
    "env_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s91520000"
    },
    "q_lr":	0.0005,
    "seed":	91520000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000001EC61E4D120>":	{
            "_act_dim":	1,
            "_batch_size":	12,
            "_buf_size":	5000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3322, -0.1170, -0.2408, -0.2633,  0.3067, -0.1566,  0.2017, -0.1253,\n         0.0295,  0.1696,  0.3064, -0.2109, -0.1021,  0.0355,  0.2922,  0.0654,\n         0.0901, -0.3421, -0.3486, -0.1867, -0.2983,  0.0319,  0.0085, -0.1471,\n        -0.0525,  0.3178, -0.1214, -0.0142, -0.0553,  0.2122, -0.0592,  0.0260],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0896, -0.1908, -0.1031,  0.0838, -0.0867,  0.3038,  0.0903, -0.3088],\n        [-0.0672,  0.1296, -0.0065,  0.0886, -0.0730, -0.0095,  0.0472, -0.3519],\n        [-0.0533, -0.1354, -0.3116, -0.0803,  0.3403,  0.2347, -0.1786,  0.1728],\n        [-0.1348, -0.0452,  0.1080, -0.2290, -0.3352,  0.3149,  0.1114,  0.1468],\n        [-0.0859,  0.2855,  0.0665,  0.1880,  0.2643,  0.0741, -0.2088,  0.3431],\n        [ 0.3517,  0.0682,  0.1317, -0.1882,  0.2028, -0.0171, -0.0766, -0.0861],\n        [-0.2017, -0.3478,  0.2864,  0.1810,  0.2731, -0.1784,  0.0563,  0.2753],\n        [ 0.1857, -0.0292,  0.1585, -0.2637, -0.2923, -0.2262,  0.1823,  0.2153],\n        [ 0.0607,  0.0805, -0.1112, -0.3222,  0.1100, -0.3362,  0.2124,  0.1052],\n        [ 0.1425,  0.1267,  0.2140,  0.2410,  0.1099, -0.0222,  0.2446, -0.0464],\n        [-0.1580, -0.1133, -0.1547, -0.0170,  0.2680, -0.1590, -0.2953, -0.0292],\n        [ 0.0528,  0.1988,  0.0243,  0.0607,  0.3234,  0.2002, -0.0965,  0.2311],\n        [ 0.1630, -0.3343, -0.1460, -0.2764,  0.2043, -0.1066,  0.1741, -0.1706],\n        [ 0.1067,  0.0601,  0.2859, -0.2279,  0.2331,  0.2561,  0.2836, -0.1779],\n        [ 0.1993,  0.0827, -0.0700,  0.3463,  0.1735, -0.1412, -0.2484,  0.0623],\n        [-0.0646, -0.0740,  0.1599, -0.1607, -0.0908,  0.1798, -0.1433, -0.0769],\n        [-0.3066, -0.1419,  0.2189,  0.2283,  0.0901,  0.1480,  0.1937, -0.2376],\n        [ 0.0791,  0.1601, -0.1756, -0.2883,  0.1790, -0.3085, -0.0234,  0.2035],\n        [ 0.3295, -0.1010, -0.3086,  0.3229, -0.2857, -0.1459, -0.3329, -0.3326],\n        [-0.2500, -0.1614, -0.1352, -0.0598, -0.0529, -0.2965, -0.1766,  0.0468],\n        [ 0.3173, -0.2672,  0.3370, -0.0188, -0.1261, -0.1682, -0.0819,  0.0638],\n        [ 0.2491,  0.3177,  0.2396,  0.2708,  0.0086,  0.1131,  0.3323, -0.1080],\n        [ 0.1065, -0.2893, -0.1358,  0.2847,  0.1660, -0.3526,  0.0326,  0.3117],\n        [ 0.0677, -0.2638, -0.1573, -0.0894,  0.0927,  0.1727,  0.0557, -0.2137],\n        [ 0.2639,  0.1261,  0.1437,  0.2050,  0.0837, -0.2175,  0.1315,  0.1914],\n        [ 0.2370, -0.0148, -0.3359,  0.2961, -0.2534, -0.1631, -0.3498, -0.1344],\n        [ 0.2356,  0.1280, -0.2214,  0.2127,  0.0881, -0.0357,  0.2633, -0.2118],\n        [ 0.0645, -0.0771,  0.2937,  0.3283,  0.2297, -0.2075, -0.1649,  0.0133],\n        [-0.0471,  0.2721,  0.2307,  0.2739,  0.0123, -0.1216,  0.2845, -0.1920],\n        [ 0.1016, -0.2861,  0.3048, -0.2686, -0.2991,  0.0146,  0.0663, -0.2343],\n        [-0.1235,  0.1695,  0.0239,  0.0566,  0.3295,  0.0510,  0.0355,  0.3161],\n        [-0.0329, -0.2272,  0.2562, -0.2416, -0.0404, -0.0315, -0.0745,  0.1900]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1233, -0.1142,  0.0093, -0.1716, -0.1328,  0.0119,  0.0848, -0.1384,\n        -0.1730,  0.1601, -0.0067, -0.1163, -0.0594,  0.1466, -0.1718,  0.1764],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.2150e-01,  3.5599e-02,  3.7226e-02, -9.7311e-02,  1.0964e-01,\n          9.3202e-02,  1.2970e-01,  1.2341e-01,  4.4828e-02, -2.1098e-02,\n         -5.7993e-03, -7.9132e-02,  1.6795e-01, -3.2354e-03, -1.0158e-01,\n          1.1192e-01, -1.0533e-01, -1.6534e-01,  9.7660e-02, -1.4301e-01,\n         -6.2253e-02,  3.0232e-02, -2.4355e-02, -9.0525e-05, -7.9363e-02,\n         -1.0248e-01,  1.5610e-02, -1.2952e-01,  4.1551e-02,  1.5634e-01,\n          1.5777e-01,  1.5189e-01],\n        [-4.4209e-02, -7.6435e-02, -3.2345e-02, -1.2261e-01,  1.1996e-01,\n         -1.2322e-01,  1.2136e-01, -1.1791e-01,  4.5710e-02,  1.4154e-01,\n         -1.2912e-01,  1.4206e-01,  1.5371e-02,  8.0601e-02, -1.4171e-01,\n         -1.4801e-01, -1.4033e-01, -8.8635e-03, -1.2189e-01,  1.0253e-01,\n         -1.1573e-01,  1.2047e-01,  8.2260e-02,  6.0407e-02, -1.1687e-01,\n         -5.6881e-02,  1.7088e-02,  4.3182e-02,  4.8578e-02,  2.3570e-03,\n         -2.4394e-02,  1.3293e-01],\n        [ 3.3651e-02,  7.7614e-03, -2.5270e-02,  4.6678e-02, -2.8384e-02,\n         -2.9194e-02,  7.8068e-02,  1.0596e-01,  1.2896e-01,  1.0236e-01,\n          1.1609e-01,  1.4856e-01,  9.1269e-02,  1.6375e-01,  6.1241e-02,\n         -1.0061e-03,  1.0900e-01,  8.0096e-02,  4.5294e-02,  4.6618e-02,\n         -1.6739e-01, -2.9689e-02,  1.4430e-01,  8.0721e-02,  1.0319e-01,\n         -1.7107e-01,  6.6851e-02,  4.0418e-02, -3.2565e-02, -8.8568e-02,\n          1.2262e-01, -8.3454e-02],\n        [ 1.6997e-01, -3.8566e-03, -4.5336e-02, -1.3333e-02, -1.0370e-01,\n         -6.4978e-02,  1.4742e-01,  2.6068e-02,  2.6646e-03,  7.5899e-02,\n          6.9182e-02, -1.2280e-01, -7.4479e-02,  3.1390e-02, -6.9306e-02,\n          1.0483e-01,  9.2416e-02,  6.6375e-02,  1.2709e-01,  7.8088e-02,\n         -3.7560e-04, -1.0944e-02, -1.5301e-03,  1.5064e-01,  9.6920e-02,\n         -2.1939e-04, -1.0996e-01,  1.2922e-01,  1.4454e-01, -1.7620e-01,\n          4.2771e-02, -8.4708e-02],\n        [-5.3119e-02, -1.5070e-01,  7.7316e-02, -1.0092e-01, -1.5946e-01,\n          1.3094e-02,  9.5148e-02,  1.5678e-01,  3.9129e-02,  6.6995e-03,\n          1.0959e-01,  1.4801e-01, -7.0643e-02,  1.4855e-01, -8.0245e-02,\n          1.0576e-01, -1.3286e-01,  9.2778e-02,  5.2597e-03,  8.2780e-02,\n         -1.5170e-01,  1.7445e-01,  1.0233e-01, -6.3487e-02,  1.3876e-01,\n          1.7425e-01,  1.5616e-01,  6.0162e-02,  1.3323e-02,  1.6506e-01,\n         -5.3326e-02, -1.4819e-01],\n        [ 1.0581e-01, -1.4679e-01,  1.4841e-01,  7.9771e-02, -1.7069e-01,\n         -1.7345e-01, -1.4791e-01,  6.2253e-02, -2.8043e-02, -7.2243e-02,\n          3.5697e-02, -5.8799e-02,  1.1747e-01, -1.2193e-02,  5.7968e-02,\n          1.9756e-02,  5.1103e-02,  1.6189e-02,  1.1292e-01,  1.4584e-02,\n         -1.9235e-02,  1.0126e-01, -1.6853e-01, -6.7711e-02, -1.4309e-01,\n         -4.8827e-02,  5.0679e-02,  1.4950e-01, -4.5841e-02,  7.1925e-02,\n          1.6685e-02, -1.4706e-01],\n        [-6.4533e-02,  5.2542e-02, -7.8184e-02, -4.7640e-02,  1.5894e-01,\n         -1.0109e-01,  1.7239e-01, -6.7398e-02,  1.6485e-01, -6.0271e-02,\n         -1.7110e-01, -9.3930e-02,  3.0166e-02,  1.7184e-01, -5.1176e-02,\n          1.7041e-01,  1.4891e-01, -1.1256e-01, -6.3440e-02,  4.8429e-02,\n         -8.8441e-03, -1.2940e-01,  1.1778e-01,  1.2987e-02,  3.8383e-02,\n         -1.1276e-01,  1.5532e-01,  5.1430e-02,  1.6598e-02,  6.7562e-02,\n          1.4657e-01,  1.6562e-01],\n        [ 1.5304e-01, -8.2001e-02, -1.6990e-01,  1.6249e-01, -1.1237e-01,\n          1.7029e-01, -9.5613e-03,  1.6337e-01, -6.6967e-02,  9.5349e-03,\n          1.4380e-01,  5.7518e-02,  8.9650e-02,  4.2126e-02, -6.6369e-02,\n          4.7957e-02,  9.9819e-02,  5.2833e-02,  8.4117e-02, -3.9691e-02,\n          1.1289e-01, -1.4642e-01,  5.2595e-02,  1.0851e-01,  1.5627e-01,\n          1.3544e-01, -5.2053e-02, -8.8476e-02, -2.3387e-02, -1.2212e-01,\n         -9.3118e-02,  1.5894e-01],\n        [-9.8514e-02, -3.2823e-03, -1.5247e-01,  3.5576e-02, -1.1229e-01,\n         -5.3940e-02,  7.2796e-02, -1.4213e-01,  5.3081e-02, -1.5133e-01,\n         -1.1990e-01, -8.6346e-02, -3.0745e-02,  1.5881e-01, -7.3349e-02,\n          2.1707e-02, -1.9109e-02,  1.4098e-01,  9.4545e-03, -1.7297e-01,\n          1.2035e-01,  5.6944e-02, -3.7590e-02,  1.4409e-01,  6.8737e-02,\n          1.6841e-01, -1.4896e-01, -1.6593e-01, -4.7493e-02,  1.6964e-01,\n         -1.6694e-01,  1.7585e-01],\n        [-1.6388e-01,  7.6391e-02, -9.8967e-02,  4.4664e-02, -1.2693e-01,\n          1.3454e-01,  1.6859e-01, -1.5417e-01,  3.4223e-02,  5.7522e-03,\n          1.4888e-01, -1.0498e-01,  1.7388e-01,  1.3360e-01,  4.5996e-02,\n          1.6034e-01, -1.7361e-01,  1.0573e-01,  1.2358e-01, -2.4935e-02,\n          1.2115e-01,  1.5886e-01,  1.3288e-01, -6.8780e-02, -1.4538e-01,\n         -1.3171e-01, -1.2303e-01, -1.5719e-01, -1.3300e-02, -1.5720e-01,\n         -2.5661e-02,  8.3815e-02],\n        [-1.0405e-01,  1.0720e-01, -2.8865e-02, -4.3979e-02, -1.0939e-01,\n         -4.2002e-02, -4.3917e-02,  9.2645e-02, -3.1672e-02,  1.0894e-01,\n         -5.4723e-02, -3.5056e-02,  9.4809e-02,  3.8015e-02,  7.4900e-02,\n         -6.3481e-02,  1.3685e-01, -1.1216e-01,  1.4883e-01,  1.5943e-01,\n          1.2227e-01, -1.2656e-01,  1.5287e-01, -1.4534e-01, -1.4458e-01,\n          1.4649e-01, -1.0490e-01,  7.5467e-02, -1.5476e-01,  5.4584e-02,\n          1.3323e-01, -9.5037e-02],\n        [-1.6661e-01,  1.0837e-01,  1.3924e-01, -1.4967e-01,  1.3045e-01,\n         -1.2610e-02, -9.0452e-02, -1.2854e-01,  1.4627e-03, -7.1969e-02,\n          8.0933e-02,  3.7838e-02,  7.8024e-02,  1.6079e-01, -1.7517e-01,\n         -5.1047e-02, -1.1858e-01,  6.9754e-02, -1.0655e-01,  4.1995e-02,\n          1.1893e-01,  4.7269e-03,  1.1895e-01, -1.1911e-01,  4.4581e-02,\n          9.5502e-02, -9.0451e-03,  1.7061e-01, -1.2648e-01,  1.6891e-01,\n          1.0370e-01, -3.3170e-02],\n        [-1.7237e-01,  3.1430e-02, -1.3749e-02,  1.4905e-01,  4.3216e-02,\n         -1.0546e-01, -6.0496e-02, -4.6466e-02, -6.3188e-02,  7.2301e-02,\n         -3.7964e-02,  1.0629e-01,  7.3067e-02,  1.6639e-01,  5.2004e-02,\n          2.4420e-02,  3.0424e-02,  1.0912e-01,  5.0474e-02, -6.1551e-02,\n         -9.1411e-02, -1.7249e-01, -3.3541e-02, -1.2313e-01,  1.2259e-01,\n          6.5348e-02, -1.3812e-01,  1.3161e-03,  1.0261e-01, -1.0778e-01,\n          1.6667e-01,  1.5915e-01],\n        [ 5.3585e-02,  9.9932e-02, -9.5162e-02, -8.8575e-04,  3.9714e-02,\n          5.0982e-02,  4.0235e-02,  7.7957e-02,  2.7892e-02, -1.0128e-01,\n         -4.6433e-02,  6.4765e-02,  8.6350e-02,  2.3537e-03,  8.3486e-02,\n          1.1935e-01, -8.0504e-02, -8.7036e-02, -1.6565e-01, -5.8532e-03,\n          1.1381e-01, -1.0464e-01, -1.0610e-01, -1.0188e-01, -4.7761e-02,\n          5.3480e-03,  1.8141e-02,  4.1989e-02, -8.2098e-02,  1.3020e-01,\n         -1.1940e-01, -2.9938e-02],\n        [-1.4517e-01,  8.0546e-02,  8.5131e-02,  5.7625e-02,  5.8309e-03,\n         -6.9512e-02, -1.3183e-01,  1.5543e-01,  1.5061e-01,  3.9661e-02,\n          2.0657e-02,  3.1386e-02,  7.5010e-02, -1.4252e-01, -1.5520e-01,\n          1.5577e-01, -1.1160e-01,  3.0147e-02, -1.1869e-01, -4.9377e-02,\n          1.6092e-02, -1.0287e-01,  1.2492e-01, -9.5318e-02,  3.3699e-02,\n          1.5855e-01,  1.3661e-01,  1.2212e-03, -2.3767e-02,  1.4403e-01,\n          9.6165e-02, -1.3237e-01],\n        [-1.2400e-01, -5.3179e-02,  1.6663e-01, -2.0895e-03,  7.4334e-02,\n          6.1825e-02, -1.5864e-01,  5.6736e-02,  1.3522e-01, -4.4474e-02,\n          5.3303e-02, -9.3253e-03, -1.5940e-01, -1.0298e-01,  1.3216e-01,\n         -9.8407e-02,  4.7653e-02, -1.3203e-01,  1.2680e-01, -4.2679e-03,\n         -1.0477e-01,  1.0419e-01, -3.6799e-02, -1.3805e-01,  9.6787e-02,\n          1.0625e-01, -1.7631e-01,  1.3206e-01,  5.7514e-03, -6.2304e-03,\n          5.1391e-03,  9.9777e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2133, -0.2222,  0.2445,  0.0130, -0.1643,  0.0258, -0.0394, -0.2320],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2460, -0.1447, -0.0121,  0.0919, -0.0764,  0.1332, -0.1780, -0.0788,\n         -0.1664, -0.1663, -0.0525,  0.2110, -0.1359,  0.2309,  0.1073, -0.2192],\n        [ 0.2303, -0.2496,  0.1666, -0.2313,  0.1064, -0.2405,  0.1288,  0.2078,\n          0.2028, -0.0697, -0.1304,  0.1033,  0.1906, -0.0400,  0.0839, -0.1400],\n        [ 0.0419, -0.1918, -0.0155, -0.0607, -0.2182, -0.1638, -0.0343,  0.0278,\n          0.0544,  0.1702,  0.0053,  0.2413, -0.0966,  0.0397,  0.0798,  0.0939],\n        [ 0.2386,  0.0998, -0.1522,  0.2488, -0.2498,  0.0111, -0.1361,  0.1820,\n         -0.2356, -0.1918, -0.2187, -0.1226, -0.1955, -0.0100,  0.0668,  0.2432],\n        [ 0.0213, -0.1390, -0.1386, -0.0208,  0.1943, -0.0651,  0.1116,  0.0586,\n         -0.0182,  0.2027, -0.0697,  0.1106,  0.1077,  0.0389,  0.0112, -0.0530],\n        [-0.1826,  0.1803, -0.1353, -0.0173,  0.0102, -0.1110, -0.1484, -0.0540,\n          0.0242,  0.1244,  0.2324,  0.1841,  0.0258, -0.2032, -0.1415,  0.0135],\n        [-0.1401, -0.2426, -0.1649,  0.1756, -0.0032, -0.0613,  0.1338, -0.0198,\n         -0.0678,  0.2109, -0.1992,  0.2189,  0.1094, -0.1360,  0.1564, -0.1561],\n        [-0.0888,  0.0076, -0.1270,  0.2440, -0.2036,  0.0229, -0.1843, -0.0644,\n         -0.2303, -0.0978,  0.2111, -0.2150,  0.0773,  0.1106, -0.1330,  0.2318]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2270], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1670,  0.1533,  0.2877, -0.2537,  0.2569,  0.0567, -0.3129, -0.1968]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0896, -0.1908, -0.1031,  0.0838, -0.0867,  0.3038,  0.0903, -0.3088],\n        [-0.0672,  0.1296, -0.0065,  0.0886, -0.0730, -0.0095,  0.0472, -0.3519],\n        [-0.0533, -0.1354, -0.3116, -0.0803,  0.3403,  0.2347, -0.1786,  0.1728],\n        [-0.1348, -0.0452,  0.1080, -0.2290, -0.3352,  0.3149,  0.1114,  0.1468],\n        [-0.0859,  0.2855,  0.0665,  0.1880,  0.2643,  0.0741, -0.2088,  0.3431],\n        [ 0.3517,  0.0682,  0.1317, -0.1882,  0.2028, -0.0171, -0.0766, -0.0861],\n        [-0.2017, -0.3478,  0.2864,  0.1810,  0.2731, -0.1784,  0.0563,  0.2753],\n        [ 0.1857, -0.0292,  0.1585, -0.2637, -0.2923, -0.2262,  0.1823,  0.2153],\n        [ 0.0607,  0.0805, -0.1112, -0.3222,  0.1100, -0.3362,  0.2124,  0.1052],\n        [ 0.1425,  0.1267,  0.2140,  0.2410,  0.1099, -0.0222,  0.2446, -0.0464],\n        [-0.1580, -0.1133, -0.1547, -0.0170,  0.2680, -0.1590, -0.2953, -0.0292],\n        [ 0.0528,  0.1988,  0.0243,  0.0607,  0.3234,  0.2002, -0.0965,  0.2311],\n        [ 0.1630, -0.3343, -0.1460, -0.2764,  0.2043, -0.1066,  0.1741, -0.1706],\n        [ 0.1067,  0.0601,  0.2859, -0.2279,  0.2331,  0.2561,  0.2836, -0.1779],\n        [ 0.1993,  0.0827, -0.0700,  0.3463,  0.1735, -0.1412, -0.2484,  0.0623],\n        [-0.0646, -0.0740,  0.1599, -0.1607, -0.0908,  0.1798, -0.1433, -0.0769],\n        [-0.3066, -0.1419,  0.2189,  0.2283,  0.0901,  0.1480,  0.1937, -0.2376],\n        [ 0.0791,  0.1601, -0.1756, -0.2883,  0.1790, -0.3085, -0.0234,  0.2035],\n        [ 0.3295, -0.1010, -0.3086,  0.3229, -0.2857, -0.1459, -0.3329, -0.3326],\n        [-0.2500, -0.1614, -0.1352, -0.0598, -0.0529, -0.2965, -0.1766,  0.0468],\n        [ 0.3173, -0.2672,  0.3370, -0.0188, -0.1261, -0.1682, -0.0819,  0.0638],\n        [ 0.2491,  0.3177,  0.2396,  0.2708,  0.0086,  0.1131,  0.3323, -0.1080],\n        [ 0.1065, -0.2893, -0.1358,  0.2847,  0.1660, -0.3526,  0.0326,  0.3117],\n        [ 0.0677, -0.2638, -0.1573, -0.0894,  0.0927,  0.1727,  0.0557, -0.2137],\n        [ 0.2639,  0.1261,  0.1437,  0.2050,  0.0837, -0.2175,  0.1315,  0.1914],\n        [ 0.2370, -0.0148, -0.3359,  0.2961, -0.2534, -0.1631, -0.3498, -0.1344],\n        [ 0.2356,  0.1280, -0.2214,  0.2127,  0.0881, -0.0357,  0.2633, -0.2118],\n        [ 0.0645, -0.0771,  0.2937,  0.3283,  0.2297, -0.2075, -0.1649,  0.0133],\n        [-0.0471,  0.2721,  0.2307,  0.2739,  0.0123, -0.1216,  0.2845, -0.1920],\n        [ 0.1016, -0.2861,  0.3048, -0.2686, -0.2991,  0.0146,  0.0663, -0.2343],\n        [-0.1235,  0.1695,  0.0239,  0.0566,  0.3295,  0.0510,  0.0355,  0.3161],\n        [-0.0329, -0.2272,  0.2562, -0.2416, -0.0404, -0.0315, -0.0745,  0.1900]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.3322, -0.1170, -0.2408, -0.2633,  0.3067, -0.1566,  0.2017, -0.1253,\n         0.0295,  0.1696,  0.3064, -0.2109, -0.1021,  0.0355,  0.2922,  0.0654,\n         0.0901, -0.3421, -0.3486, -0.1867, -0.2983,  0.0319,  0.0085, -0.1471,\n        -0.0525,  0.3178, -0.1214, -0.0142, -0.0553,  0.2122, -0.0592,  0.0260],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.2150e-01,  3.5599e-02,  3.7226e-02, -9.7311e-02,  1.0964e-01,\n          9.3202e-02,  1.2970e-01,  1.2341e-01,  4.4828e-02, -2.1098e-02,\n         -5.7993e-03, -7.9132e-02,  1.6795e-01, -3.2354e-03, -1.0158e-01,\n          1.1192e-01, -1.0533e-01, -1.6534e-01,  9.7660e-02, -1.4301e-01,\n         -6.2253e-02,  3.0232e-02, -2.4355e-02, -9.0525e-05, -7.9363e-02,\n         -1.0248e-01,  1.5610e-02, -1.2952e-01,  4.1551e-02,  1.5634e-01,\n          1.5777e-01,  1.5189e-01],\n        [-4.4209e-02, -7.6435e-02, -3.2345e-02, -1.2261e-01,  1.1996e-01,\n         -1.2322e-01,  1.2136e-01, -1.1791e-01,  4.5710e-02,  1.4154e-01,\n         -1.2912e-01,  1.4206e-01,  1.5371e-02,  8.0601e-02, -1.4171e-01,\n         -1.4801e-01, -1.4033e-01, -8.8635e-03, -1.2189e-01,  1.0253e-01,\n         -1.1573e-01,  1.2047e-01,  8.2260e-02,  6.0407e-02, -1.1687e-01,\n         -5.6881e-02,  1.7088e-02,  4.3182e-02,  4.8578e-02,  2.3570e-03,\n         -2.4394e-02,  1.3293e-01],\n        [ 3.3651e-02,  7.7614e-03, -2.5270e-02,  4.6678e-02, -2.8384e-02,\n         -2.9194e-02,  7.8068e-02,  1.0596e-01,  1.2896e-01,  1.0236e-01,\n          1.1609e-01,  1.4856e-01,  9.1269e-02,  1.6375e-01,  6.1241e-02,\n         -1.0061e-03,  1.0900e-01,  8.0096e-02,  4.5294e-02,  4.6618e-02,\n         -1.6739e-01, -2.9689e-02,  1.4430e-01,  8.0721e-02,  1.0319e-01,\n         -1.7107e-01,  6.6851e-02,  4.0418e-02, -3.2565e-02, -8.8568e-02,\n          1.2262e-01, -8.3454e-02],\n        [ 1.6997e-01, -3.8566e-03, -4.5336e-02, -1.3333e-02, -1.0370e-01,\n         -6.4978e-02,  1.4742e-01,  2.6068e-02,  2.6646e-03,  7.5899e-02,\n          6.9182e-02, -1.2280e-01, -7.4479e-02,  3.1390e-02, -6.9306e-02,\n          1.0483e-01,  9.2416e-02,  6.6375e-02,  1.2709e-01,  7.8088e-02,\n         -3.7560e-04, -1.0944e-02, -1.5301e-03,  1.5064e-01,  9.6920e-02,\n         -2.1939e-04, -1.0996e-01,  1.2922e-01,  1.4454e-01, -1.7620e-01,\n          4.2771e-02, -8.4708e-02],\n        [-5.3119e-02, -1.5070e-01,  7.7316e-02, -1.0092e-01, -1.5946e-01,\n          1.3094e-02,  9.5148e-02,  1.5678e-01,  3.9129e-02,  6.6995e-03,\n          1.0959e-01,  1.4801e-01, -7.0643e-02,  1.4855e-01, -8.0245e-02,\n          1.0576e-01, -1.3286e-01,  9.2778e-02,  5.2597e-03,  8.2780e-02,\n         -1.5170e-01,  1.7445e-01,  1.0233e-01, -6.3487e-02,  1.3876e-01,\n          1.7425e-01,  1.5616e-01,  6.0162e-02,  1.3323e-02,  1.6506e-01,\n         -5.3326e-02, -1.4819e-01],\n        [ 1.0581e-01, -1.4679e-01,  1.4841e-01,  7.9771e-02, -1.7069e-01,\n         -1.7345e-01, -1.4791e-01,  6.2253e-02, -2.8043e-02, -7.2243e-02,\n          3.5697e-02, -5.8799e-02,  1.1747e-01, -1.2193e-02,  5.7968e-02,\n          1.9756e-02,  5.1103e-02,  1.6189e-02,  1.1292e-01,  1.4584e-02,\n         -1.9235e-02,  1.0126e-01, -1.6853e-01, -6.7711e-02, -1.4309e-01,\n         -4.8827e-02,  5.0679e-02,  1.4950e-01, -4.5841e-02,  7.1925e-02,\n          1.6685e-02, -1.4706e-01],\n        [-6.4533e-02,  5.2542e-02, -7.8184e-02, -4.7640e-02,  1.5894e-01,\n         -1.0109e-01,  1.7239e-01, -6.7398e-02,  1.6485e-01, -6.0271e-02,\n         -1.7110e-01, -9.3930e-02,  3.0166e-02,  1.7184e-01, -5.1176e-02,\n          1.7041e-01,  1.4891e-01, -1.1256e-01, -6.3440e-02,  4.8429e-02,\n         -8.8441e-03, -1.2940e-01,  1.1778e-01,  1.2987e-02,  3.8383e-02,\n         -1.1276e-01,  1.5532e-01,  5.1430e-02,  1.6598e-02,  6.7562e-02,\n          1.4657e-01,  1.6562e-01],\n        [ 1.5304e-01, -8.2001e-02, -1.6990e-01,  1.6249e-01, -1.1237e-01,\n          1.7029e-01, -9.5613e-03,  1.6337e-01, -6.6967e-02,  9.5349e-03,\n          1.4380e-01,  5.7518e-02,  8.9650e-02,  4.2126e-02, -6.6369e-02,\n          4.7957e-02,  9.9819e-02,  5.2833e-02,  8.4117e-02, -3.9691e-02,\n          1.1289e-01, -1.4642e-01,  5.2595e-02,  1.0851e-01,  1.5627e-01,\n          1.3544e-01, -5.2053e-02, -8.8476e-02, -2.3387e-02, -1.2212e-01,\n         -9.3118e-02,  1.5894e-01],\n        [-9.8514e-02, -3.2823e-03, -1.5247e-01,  3.5576e-02, -1.1229e-01,\n         -5.3940e-02,  7.2796e-02, -1.4213e-01,  5.3081e-02, -1.5133e-01,\n         -1.1990e-01, -8.6346e-02, -3.0745e-02,  1.5881e-01, -7.3349e-02,\n          2.1707e-02, -1.9109e-02,  1.4098e-01,  9.4545e-03, -1.7297e-01,\n          1.2035e-01,  5.6944e-02, -3.7590e-02,  1.4409e-01,  6.8737e-02,\n          1.6841e-01, -1.4896e-01, -1.6593e-01, -4.7493e-02,  1.6964e-01,\n         -1.6694e-01,  1.7585e-01],\n        [-1.6388e-01,  7.6391e-02, -9.8967e-02,  4.4664e-02, -1.2693e-01,\n          1.3454e-01,  1.6859e-01, -1.5417e-01,  3.4223e-02,  5.7522e-03,\n          1.4888e-01, -1.0498e-01,  1.7388e-01,  1.3360e-01,  4.5996e-02,\n          1.6034e-01, -1.7361e-01,  1.0573e-01,  1.2358e-01, -2.4935e-02,\n          1.2115e-01,  1.5886e-01,  1.3288e-01, -6.8780e-02, -1.4538e-01,\n         -1.3171e-01, -1.2303e-01, -1.5719e-01, -1.3300e-02, -1.5720e-01,\n         -2.5661e-02,  8.3815e-02],\n        [-1.0405e-01,  1.0720e-01, -2.8865e-02, -4.3979e-02, -1.0939e-01,\n         -4.2002e-02, -4.3917e-02,  9.2645e-02, -3.1672e-02,  1.0894e-01,\n         -5.4723e-02, -3.5056e-02,  9.4809e-02,  3.8015e-02,  7.4900e-02,\n         -6.3481e-02,  1.3685e-01, -1.1216e-01,  1.4883e-01,  1.5943e-01,\n          1.2227e-01, -1.2656e-01,  1.5287e-01, -1.4534e-01, -1.4458e-01,\n          1.4649e-01, -1.0490e-01,  7.5467e-02, -1.5476e-01,  5.4584e-02,\n          1.3323e-01, -9.5037e-02],\n        [-1.6661e-01,  1.0837e-01,  1.3924e-01, -1.4967e-01,  1.3045e-01,\n         -1.2610e-02, -9.0452e-02, -1.2854e-01,  1.4627e-03, -7.1969e-02,\n          8.0933e-02,  3.7838e-02,  7.8024e-02,  1.6079e-01, -1.7517e-01,\n         -5.1047e-02, -1.1858e-01,  6.9754e-02, -1.0655e-01,  4.1995e-02,\n          1.1893e-01,  4.7269e-03,  1.1895e-01, -1.1911e-01,  4.4581e-02,\n          9.5502e-02, -9.0451e-03,  1.7061e-01, -1.2648e-01,  1.6891e-01,\n          1.0370e-01, -3.3170e-02],\n        [-1.7237e-01,  3.1430e-02, -1.3749e-02,  1.4905e-01,  4.3216e-02,\n         -1.0546e-01, -6.0496e-02, -4.6466e-02, -6.3188e-02,  7.2301e-02,\n         -3.7964e-02,  1.0629e-01,  7.3067e-02,  1.6639e-01,  5.2004e-02,\n          2.4420e-02,  3.0424e-02,  1.0912e-01,  5.0474e-02, -6.1551e-02,\n         -9.1411e-02, -1.7249e-01, -3.3541e-02, -1.2313e-01,  1.2259e-01,\n          6.5348e-02, -1.3812e-01,  1.3161e-03,  1.0261e-01, -1.0778e-01,\n          1.6667e-01,  1.5915e-01],\n        [ 5.3585e-02,  9.9932e-02, -9.5162e-02, -8.8575e-04,  3.9714e-02,\n          5.0982e-02,  4.0235e-02,  7.7957e-02,  2.7892e-02, -1.0128e-01,\n         -4.6433e-02,  6.4765e-02,  8.6350e-02,  2.3537e-03,  8.3486e-02,\n          1.1935e-01, -8.0504e-02, -8.7036e-02, -1.6565e-01, -5.8532e-03,\n          1.1381e-01, -1.0464e-01, -1.0610e-01, -1.0188e-01, -4.7761e-02,\n          5.3480e-03,  1.8141e-02,  4.1989e-02, -8.2098e-02,  1.3020e-01,\n         -1.1940e-01, -2.9938e-02],\n        [-1.4517e-01,  8.0546e-02,  8.5131e-02,  5.7625e-02,  5.8309e-03,\n         -6.9512e-02, -1.3183e-01,  1.5543e-01,  1.5061e-01,  3.9661e-02,\n          2.0657e-02,  3.1386e-02,  7.5010e-02, -1.4252e-01, -1.5520e-01,\n          1.5577e-01, -1.1160e-01,  3.0147e-02, -1.1869e-01, -4.9377e-02,\n          1.6092e-02, -1.0287e-01,  1.2492e-01, -9.5318e-02,  3.3699e-02,\n          1.5855e-01,  1.3661e-01,  1.2212e-03, -2.3767e-02,  1.4403e-01,\n          9.6165e-02, -1.3237e-01],\n        [-1.2400e-01, -5.3179e-02,  1.6663e-01, -2.0895e-03,  7.4334e-02,\n          6.1825e-02, -1.5864e-01,  5.6736e-02,  1.3522e-01, -4.4474e-02,\n          5.3303e-02, -9.3253e-03, -1.5940e-01, -1.0298e-01,  1.3216e-01,\n         -9.8407e-02,  4.7653e-02, -1.3203e-01,  1.2680e-01, -4.2679e-03,\n         -1.0477e-01,  1.0419e-01, -3.6799e-02, -1.3805e-01,  9.6787e-02,\n          1.0625e-01, -1.7631e-01,  1.3206e-01,  5.7514e-03, -6.2304e-03,\n          5.1391e-03,  9.9777e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1233, -0.1142,  0.0093, -0.1716, -0.1328,  0.0119,  0.0848, -0.1384,\n        -0.1730,  0.1601, -0.0067, -0.1163, -0.0594,  0.1466, -0.1718,  0.1764],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2460, -0.1447, -0.0121,  0.0919, -0.0764,  0.1332, -0.1780, -0.0788,\n         -0.1664, -0.1663, -0.0525,  0.2110, -0.1359,  0.2309,  0.1073, -0.2192],\n        [ 0.2303, -0.2496,  0.1666, -0.2313,  0.1064, -0.2405,  0.1288,  0.2078,\n          0.2028, -0.0697, -0.1304,  0.1033,  0.1906, -0.0400,  0.0839, -0.1400],\n        [ 0.0419, -0.1918, -0.0155, -0.0607, -0.2182, -0.1638, -0.0343,  0.0278,\n          0.0544,  0.1702,  0.0053,  0.2413, -0.0966,  0.0397,  0.0798,  0.0939],\n        [ 0.2386,  0.0998, -0.1522,  0.2488, -0.2498,  0.0111, -0.1361,  0.1820,\n         -0.2356, -0.1918, -0.2187, -0.1226, -0.1955, -0.0100,  0.0668,  0.2432],\n        [ 0.0213, -0.1390, -0.1386, -0.0208,  0.1943, -0.0651,  0.1116,  0.0586,\n         -0.0182,  0.2027, -0.0697,  0.1106,  0.1077,  0.0389,  0.0112, -0.0530],\n        [-0.1826,  0.1803, -0.1353, -0.0173,  0.0102, -0.1110, -0.1484, -0.0540,\n          0.0242,  0.1244,  0.2324,  0.1841,  0.0258, -0.2032, -0.1415,  0.0135],\n        [-0.1401, -0.2426, -0.1649,  0.1756, -0.0032, -0.0613,  0.1338, -0.0198,\n         -0.0678,  0.2109, -0.1992,  0.2189,  0.1094, -0.1360,  0.1564, -0.1561],\n        [-0.0888,  0.0076, -0.1270,  0.2440, -0.2036,  0.0229, -0.1843, -0.0644,\n         -0.2303, -0.0978,  0.2111, -0.2150,  0.0773,  0.1106, -0.1330,  0.2318]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2133, -0.2222,  0.2445,  0.0130, -0.1643,  0.0258, -0.0394, -0.2320],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1670,  0.1533,  0.2877, -0.2537,  0.2569,  0.0567, -0.3129, -0.1968]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2270], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000001EC19A162F0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	5000,
                    "epsilon":	1.0,
                    "gamma":	0.99,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	5000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001EC61E4CC70>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"d:\\Projects\\0_Udel\\RL4Sys\\examples\\lunar\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s91520000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='d:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\lunar\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s91520000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            },
            "q_target":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3322, -0.1170, -0.2408, -0.2633,  0.3067, -0.1566,  0.2017, -0.1253,\n         0.0295,  0.1696,  0.3064, -0.2109, -0.1021,  0.0355,  0.2922,  0.0654,\n         0.0901, -0.3421, -0.3486, -0.1867, -0.2983,  0.0319,  0.0085, -0.1471,\n        -0.0525,  0.3178, -0.1214, -0.0142, -0.0553,  0.2122, -0.0592,  0.0260],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0896, -0.1908, -0.1031,  0.0838, -0.0867,  0.3038,  0.0903, -0.3088],\n        [-0.0672,  0.1296, -0.0065,  0.0886, -0.0730, -0.0095,  0.0472, -0.3519],\n        [-0.0533, -0.1354, -0.3116, -0.0803,  0.3403,  0.2347, -0.1786,  0.1728],\n        [-0.1348, -0.0452,  0.1080, -0.2290, -0.3352,  0.3149,  0.1114,  0.1468],\n        [-0.0859,  0.2855,  0.0665,  0.1880,  0.2643,  0.0741, -0.2088,  0.3431],\n        [ 0.3517,  0.0682,  0.1317, -0.1882,  0.2028, -0.0171, -0.0766, -0.0861],\n        [-0.2017, -0.3478,  0.2864,  0.1810,  0.2731, -0.1784,  0.0563,  0.2753],\n        [ 0.1857, -0.0292,  0.1585, -0.2637, -0.2923, -0.2262,  0.1823,  0.2153],\n        [ 0.0607,  0.0805, -0.1112, -0.3222,  0.1100, -0.3362,  0.2124,  0.1052],\n        [ 0.1425,  0.1267,  0.2140,  0.2410,  0.1099, -0.0222,  0.2446, -0.0464],\n        [-0.1580, -0.1133, -0.1547, -0.0170,  0.2680, -0.1590, -0.2953, -0.0292],\n        [ 0.0528,  0.1988,  0.0243,  0.0607,  0.3234,  0.2002, -0.0965,  0.2311],\n        [ 0.1630, -0.3343, -0.1460, -0.2764,  0.2043, -0.1066,  0.1741, -0.1706],\n        [ 0.1067,  0.0601,  0.2859, -0.2279,  0.2331,  0.2561,  0.2836, -0.1779],\n        [ 0.1993,  0.0827, -0.0700,  0.3463,  0.1735, -0.1412, -0.2484,  0.0623],\n        [-0.0646, -0.0740,  0.1599, -0.1607, -0.0908,  0.1798, -0.1433, -0.0769],\n        [-0.3066, -0.1419,  0.2189,  0.2283,  0.0901,  0.1480,  0.1937, -0.2376],\n        [ 0.0791,  0.1601, -0.1756, -0.2883,  0.1790, -0.3085, -0.0234,  0.2035],\n        [ 0.3295, -0.1010, -0.3086,  0.3229, -0.2857, -0.1459, -0.3329, -0.3326],\n        [-0.2500, -0.1614, -0.1352, -0.0598, -0.0529, -0.2965, -0.1766,  0.0468],\n        [ 0.3173, -0.2672,  0.3370, -0.0188, -0.1261, -0.1682, -0.0819,  0.0638],\n        [ 0.2491,  0.3177,  0.2396,  0.2708,  0.0086,  0.1131,  0.3323, -0.1080],\n        [ 0.1065, -0.2893, -0.1358,  0.2847,  0.1660, -0.3526,  0.0326,  0.3117],\n        [ 0.0677, -0.2638, -0.1573, -0.0894,  0.0927,  0.1727,  0.0557, -0.2137],\n        [ 0.2639,  0.1261,  0.1437,  0.2050,  0.0837, -0.2175,  0.1315,  0.1914],\n        [ 0.2370, -0.0148, -0.3359,  0.2961, -0.2534, -0.1631, -0.3498, -0.1344],\n        [ 0.2356,  0.1280, -0.2214,  0.2127,  0.0881, -0.0357,  0.2633, -0.2118],\n        [ 0.0645, -0.0771,  0.2937,  0.3283,  0.2297, -0.2075, -0.1649,  0.0133],\n        [-0.0471,  0.2721,  0.2307,  0.2739,  0.0123, -0.1216,  0.2845, -0.1920],\n        [ 0.1016, -0.2861,  0.3048, -0.2686, -0.2991,  0.0146,  0.0663, -0.2343],\n        [-0.1235,  0.1695,  0.0239,  0.0566,  0.3295,  0.0510,  0.0355,  0.3161],\n        [-0.0329, -0.2272,  0.2562, -0.2416, -0.0404, -0.0315, -0.0745,  0.1900]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1233, -0.1142,  0.0093, -0.1716, -0.1328,  0.0119,  0.0848, -0.1384,\n        -0.1730,  0.1601, -0.0067, -0.1163, -0.0594,  0.1466, -0.1718,  0.1764],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.2150e-01,  3.5599e-02,  3.7226e-02, -9.7311e-02,  1.0964e-01,\n          9.3202e-02,  1.2970e-01,  1.2341e-01,  4.4828e-02, -2.1098e-02,\n         -5.7993e-03, -7.9132e-02,  1.6795e-01, -3.2354e-03, -1.0158e-01,\n          1.1192e-01, -1.0533e-01, -1.6534e-01,  9.7660e-02, -1.4301e-01,\n         -6.2253e-02,  3.0232e-02, -2.4355e-02, -9.0525e-05, -7.9363e-02,\n         -1.0248e-01,  1.5610e-02, -1.2952e-01,  4.1551e-02,  1.5634e-01,\n          1.5777e-01,  1.5189e-01],\n        [-4.4209e-02, -7.6435e-02, -3.2345e-02, -1.2261e-01,  1.1996e-01,\n         -1.2322e-01,  1.2136e-01, -1.1791e-01,  4.5710e-02,  1.4154e-01,\n         -1.2912e-01,  1.4206e-01,  1.5371e-02,  8.0601e-02, -1.4171e-01,\n         -1.4801e-01, -1.4033e-01, -8.8635e-03, -1.2189e-01,  1.0253e-01,\n         -1.1573e-01,  1.2047e-01,  8.2260e-02,  6.0407e-02, -1.1687e-01,\n         -5.6881e-02,  1.7088e-02,  4.3182e-02,  4.8578e-02,  2.3570e-03,\n         -2.4394e-02,  1.3293e-01],\n        [ 3.3651e-02,  7.7614e-03, -2.5270e-02,  4.6678e-02, -2.8384e-02,\n         -2.9194e-02,  7.8068e-02,  1.0596e-01,  1.2896e-01,  1.0236e-01,\n          1.1609e-01,  1.4856e-01,  9.1269e-02,  1.6375e-01,  6.1241e-02,\n         -1.0061e-03,  1.0900e-01,  8.0096e-02,  4.5294e-02,  4.6618e-02,\n         -1.6739e-01, -2.9689e-02,  1.4430e-01,  8.0721e-02,  1.0319e-01,\n         -1.7107e-01,  6.6851e-02,  4.0418e-02, -3.2565e-02, -8.8568e-02,\n          1.2262e-01, -8.3454e-02],\n        [ 1.6997e-01, -3.8566e-03, -4.5336e-02, -1.3333e-02, -1.0370e-01,\n         -6.4978e-02,  1.4742e-01,  2.6068e-02,  2.6646e-03,  7.5899e-02,\n          6.9182e-02, -1.2280e-01, -7.4479e-02,  3.1390e-02, -6.9306e-02,\n          1.0483e-01,  9.2416e-02,  6.6375e-02,  1.2709e-01,  7.8088e-02,\n         -3.7560e-04, -1.0944e-02, -1.5301e-03,  1.5064e-01,  9.6920e-02,\n         -2.1939e-04, -1.0996e-01,  1.2922e-01,  1.4454e-01, -1.7620e-01,\n          4.2771e-02, -8.4708e-02],\n        [-5.3119e-02, -1.5070e-01,  7.7316e-02, -1.0092e-01, -1.5946e-01,\n          1.3094e-02,  9.5148e-02,  1.5678e-01,  3.9129e-02,  6.6995e-03,\n          1.0959e-01,  1.4801e-01, -7.0643e-02,  1.4855e-01, -8.0245e-02,\n          1.0576e-01, -1.3286e-01,  9.2778e-02,  5.2597e-03,  8.2780e-02,\n         -1.5170e-01,  1.7445e-01,  1.0233e-01, -6.3487e-02,  1.3876e-01,\n          1.7425e-01,  1.5616e-01,  6.0162e-02,  1.3323e-02,  1.6506e-01,\n         -5.3326e-02, -1.4819e-01],\n        [ 1.0581e-01, -1.4679e-01,  1.4841e-01,  7.9771e-02, -1.7069e-01,\n         -1.7345e-01, -1.4791e-01,  6.2253e-02, -2.8043e-02, -7.2243e-02,\n          3.5697e-02, -5.8799e-02,  1.1747e-01, -1.2193e-02,  5.7968e-02,\n          1.9756e-02,  5.1103e-02,  1.6189e-02,  1.1292e-01,  1.4584e-02,\n         -1.9235e-02,  1.0126e-01, -1.6853e-01, -6.7711e-02, -1.4309e-01,\n         -4.8827e-02,  5.0679e-02,  1.4950e-01, -4.5841e-02,  7.1925e-02,\n          1.6685e-02, -1.4706e-01],\n        [-6.4533e-02,  5.2542e-02, -7.8184e-02, -4.7640e-02,  1.5894e-01,\n         -1.0109e-01,  1.7239e-01, -6.7398e-02,  1.6485e-01, -6.0271e-02,\n         -1.7110e-01, -9.3930e-02,  3.0166e-02,  1.7184e-01, -5.1176e-02,\n          1.7041e-01,  1.4891e-01, -1.1256e-01, -6.3440e-02,  4.8429e-02,\n         -8.8441e-03, -1.2940e-01,  1.1778e-01,  1.2987e-02,  3.8383e-02,\n         -1.1276e-01,  1.5532e-01,  5.1430e-02,  1.6598e-02,  6.7562e-02,\n          1.4657e-01,  1.6562e-01],\n        [ 1.5304e-01, -8.2001e-02, -1.6990e-01,  1.6249e-01, -1.1237e-01,\n          1.7029e-01, -9.5613e-03,  1.6337e-01, -6.6967e-02,  9.5349e-03,\n          1.4380e-01,  5.7518e-02,  8.9650e-02,  4.2126e-02, -6.6369e-02,\n          4.7957e-02,  9.9819e-02,  5.2833e-02,  8.4117e-02, -3.9691e-02,\n          1.1289e-01, -1.4642e-01,  5.2595e-02,  1.0851e-01,  1.5627e-01,\n          1.3544e-01, -5.2053e-02, -8.8476e-02, -2.3387e-02, -1.2212e-01,\n         -9.3118e-02,  1.5894e-01],\n        [-9.8514e-02, -3.2823e-03, -1.5247e-01,  3.5576e-02, -1.1229e-01,\n         -5.3940e-02,  7.2796e-02, -1.4213e-01,  5.3081e-02, -1.5133e-01,\n         -1.1990e-01, -8.6346e-02, -3.0745e-02,  1.5881e-01, -7.3349e-02,\n          2.1707e-02, -1.9109e-02,  1.4098e-01,  9.4545e-03, -1.7297e-01,\n          1.2035e-01,  5.6944e-02, -3.7590e-02,  1.4409e-01,  6.8737e-02,\n          1.6841e-01, -1.4896e-01, -1.6593e-01, -4.7493e-02,  1.6964e-01,\n         -1.6694e-01,  1.7585e-01],\n        [-1.6388e-01,  7.6391e-02, -9.8967e-02,  4.4664e-02, -1.2693e-01,\n          1.3454e-01,  1.6859e-01, -1.5417e-01,  3.4223e-02,  5.7522e-03,\n          1.4888e-01, -1.0498e-01,  1.7388e-01,  1.3360e-01,  4.5996e-02,\n          1.6034e-01, -1.7361e-01,  1.0573e-01,  1.2358e-01, -2.4935e-02,\n          1.2115e-01,  1.5886e-01,  1.3288e-01, -6.8780e-02, -1.4538e-01,\n         -1.3171e-01, -1.2303e-01, -1.5719e-01, -1.3300e-02, -1.5720e-01,\n         -2.5661e-02,  8.3815e-02],\n        [-1.0405e-01,  1.0720e-01, -2.8865e-02, -4.3979e-02, -1.0939e-01,\n         -4.2002e-02, -4.3917e-02,  9.2645e-02, -3.1672e-02,  1.0894e-01,\n         -5.4723e-02, -3.5056e-02,  9.4809e-02,  3.8015e-02,  7.4900e-02,\n         -6.3481e-02,  1.3685e-01, -1.1216e-01,  1.4883e-01,  1.5943e-01,\n          1.2227e-01, -1.2656e-01,  1.5287e-01, -1.4534e-01, -1.4458e-01,\n          1.4649e-01, -1.0490e-01,  7.5467e-02, -1.5476e-01,  5.4584e-02,\n          1.3323e-01, -9.5037e-02],\n        [-1.6661e-01,  1.0837e-01,  1.3924e-01, -1.4967e-01,  1.3045e-01,\n         -1.2610e-02, -9.0452e-02, -1.2854e-01,  1.4627e-03, -7.1969e-02,\n          8.0933e-02,  3.7838e-02,  7.8024e-02,  1.6079e-01, -1.7517e-01,\n         -5.1047e-02, -1.1858e-01,  6.9754e-02, -1.0655e-01,  4.1995e-02,\n          1.1893e-01,  4.7269e-03,  1.1895e-01, -1.1911e-01,  4.4581e-02,\n          9.5502e-02, -9.0451e-03,  1.7061e-01, -1.2648e-01,  1.6891e-01,\n          1.0370e-01, -3.3170e-02],\n        [-1.7237e-01,  3.1430e-02, -1.3749e-02,  1.4905e-01,  4.3216e-02,\n         -1.0546e-01, -6.0496e-02, -4.6466e-02, -6.3188e-02,  7.2301e-02,\n         -3.7964e-02,  1.0629e-01,  7.3067e-02,  1.6639e-01,  5.2004e-02,\n          2.4420e-02,  3.0424e-02,  1.0912e-01,  5.0474e-02, -6.1551e-02,\n         -9.1411e-02, -1.7249e-01, -3.3541e-02, -1.2313e-01,  1.2259e-01,\n          6.5348e-02, -1.3812e-01,  1.3161e-03,  1.0261e-01, -1.0778e-01,\n          1.6667e-01,  1.5915e-01],\n        [ 5.3585e-02,  9.9932e-02, -9.5162e-02, -8.8575e-04,  3.9714e-02,\n          5.0982e-02,  4.0235e-02,  7.7957e-02,  2.7892e-02, -1.0128e-01,\n         -4.6433e-02,  6.4765e-02,  8.6350e-02,  2.3537e-03,  8.3486e-02,\n          1.1935e-01, -8.0504e-02, -8.7036e-02, -1.6565e-01, -5.8532e-03,\n          1.1381e-01, -1.0464e-01, -1.0610e-01, -1.0188e-01, -4.7761e-02,\n          5.3480e-03,  1.8141e-02,  4.1989e-02, -8.2098e-02,  1.3020e-01,\n         -1.1940e-01, -2.9938e-02],\n        [-1.4517e-01,  8.0546e-02,  8.5131e-02,  5.7625e-02,  5.8309e-03,\n         -6.9512e-02, -1.3183e-01,  1.5543e-01,  1.5061e-01,  3.9661e-02,\n          2.0657e-02,  3.1386e-02,  7.5010e-02, -1.4252e-01, -1.5520e-01,\n          1.5577e-01, -1.1160e-01,  3.0147e-02, -1.1869e-01, -4.9377e-02,\n          1.6092e-02, -1.0287e-01,  1.2492e-01, -9.5318e-02,  3.3699e-02,\n          1.5855e-01,  1.3661e-01,  1.2212e-03, -2.3767e-02,  1.4403e-01,\n          9.6165e-02, -1.3237e-01],\n        [-1.2400e-01, -5.3179e-02,  1.6663e-01, -2.0895e-03,  7.4334e-02,\n          6.1825e-02, -1.5864e-01,  5.6736e-02,  1.3522e-01, -4.4474e-02,\n          5.3303e-02, -9.3253e-03, -1.5940e-01, -1.0298e-01,  1.3216e-01,\n         -9.8407e-02,  4.7653e-02, -1.3203e-01,  1.2680e-01, -4.2679e-03,\n         -1.0477e-01,  1.0419e-01, -3.6799e-02, -1.3805e-01,  9.6787e-02,\n          1.0625e-01, -1.7631e-01,  1.3206e-01,  5.7514e-03, -6.2304e-03,\n          5.1391e-03,  9.9777e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2133, -0.2222,  0.2445,  0.0130, -0.1643,  0.0258, -0.0394, -0.2320],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2460, -0.1447, -0.0121,  0.0919, -0.0764,  0.1332, -0.1780, -0.0788,\n         -0.1664, -0.1663, -0.0525,  0.2110, -0.1359,  0.2309,  0.1073, -0.2192],\n        [ 0.2303, -0.2496,  0.1666, -0.2313,  0.1064, -0.2405,  0.1288,  0.2078,\n          0.2028, -0.0697, -0.1304,  0.1033,  0.1906, -0.0400,  0.0839, -0.1400],\n        [ 0.0419, -0.1918, -0.0155, -0.0607, -0.2182, -0.1638, -0.0343,  0.0278,\n          0.0544,  0.1702,  0.0053,  0.2413, -0.0966,  0.0397,  0.0798,  0.0939],\n        [ 0.2386,  0.0998, -0.1522,  0.2488, -0.2498,  0.0111, -0.1361,  0.1820,\n         -0.2356, -0.1918, -0.2187, -0.1226, -0.1955, -0.0100,  0.0668,  0.2432],\n        [ 0.0213, -0.1390, -0.1386, -0.0208,  0.1943, -0.0651,  0.1116,  0.0586,\n         -0.0182,  0.2027, -0.0697,  0.1106,  0.1077,  0.0389,  0.0112, -0.0530],\n        [-0.1826,  0.1803, -0.1353, -0.0173,  0.0102, -0.1110, -0.1484, -0.0540,\n          0.0242,  0.1244,  0.2324,  0.1841,  0.0258, -0.2032, -0.1415,  0.0135],\n        [-0.1401, -0.2426, -0.1649,  0.1756, -0.0032, -0.0613,  0.1338, -0.0198,\n         -0.0678,  0.2109, -0.1992,  0.2189,  0.1094, -0.1360,  0.1564, -0.1561],\n        [-0.0888,  0.0076, -0.1270,  0.2440, -0.2036,  0.0229, -0.1843, -0.0644,\n         -0.2303, -0.0978,  0.2111, -0.2150,  0.0773,  0.1106, -0.1330,  0.2318]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2270], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1670,  0.1533,  0.2877, -0.2537,  0.2569,  0.0567, -0.3129, -0.1968]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	2,
                    "kernel_size":	4,
                    "training":	true
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}