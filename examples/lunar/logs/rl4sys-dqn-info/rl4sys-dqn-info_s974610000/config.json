{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	2,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s974610000"
    },
    "q_lr":	0.003,
    "seed":	974610000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x775b3f054d90>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.99,
            "_kernel_dim":	4,
            "_kernel_size":	2,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1996, -0.2808, -0.3117,  0.1286,  0.1159, -0.1301, -0.3492, -0.2412,\n        -0.1380, -0.0837,  0.3376, -0.3108, -0.0433,  0.2211, -0.1745,  0.2040,\n        -0.1861,  0.0663, -0.1077, -0.0176, -0.2223,  0.0894, -0.3200, -0.0908,\n         0.0978,  0.1217,  0.0938, -0.2993, -0.0228,  0.2270, -0.2165,  0.1659],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1603,  0.3065, -0.1446, -0.2896, -0.2029, -0.2914, -0.0824,  0.2119],\n        [ 0.2432, -0.1741, -0.1915,  0.1778, -0.0412,  0.0110, -0.1811,  0.3405],\n        [-0.1660,  0.0168,  0.2092, -0.1217, -0.0574,  0.2740, -0.0240, -0.0894],\n        [-0.2796, -0.2094,  0.2150,  0.2221, -0.3296, -0.3078,  0.1098,  0.0709],\n        [ 0.0964,  0.3035, -0.0364,  0.3479, -0.0917,  0.2906,  0.0286,  0.0920],\n        [-0.1023, -0.2391,  0.2015,  0.3015,  0.0474, -0.2291, -0.1033, -0.1870],\n        [-0.1761,  0.3124, -0.3308,  0.2759,  0.1311, -0.2924,  0.1778,  0.1492],\n        [ 0.0258, -0.0384,  0.1299,  0.2656, -0.0780, -0.3250, -0.0572, -0.0640],\n        [-0.2268, -0.2566, -0.1579,  0.3330,  0.2949,  0.2412, -0.3110, -0.1825],\n        [-0.3013,  0.3307, -0.3111,  0.2880,  0.1851,  0.1431, -0.3357, -0.0607],\n        [-0.2652, -0.0543,  0.3410, -0.0592,  0.2612,  0.0597, -0.0057,  0.1337],\n        [ 0.2603,  0.3349,  0.0972,  0.0300, -0.0235, -0.2036, -0.0856,  0.3505],\n        [-0.0553, -0.3018, -0.2622, -0.0180, -0.3328, -0.3135,  0.3525,  0.0805],\n        [-0.0845,  0.0158,  0.2577,  0.2326,  0.1932, -0.1935,  0.0185,  0.2900],\n        [ 0.0165,  0.1347,  0.0806,  0.3082, -0.1464,  0.0376, -0.1963, -0.1297],\n        [ 0.3003,  0.3332,  0.0144, -0.2390,  0.1796, -0.0373,  0.1098, -0.0211],\n        [ 0.1330, -0.2377,  0.1559,  0.3096, -0.2868, -0.3494, -0.0807,  0.2562],\n        [-0.2461, -0.2060,  0.2364, -0.0159, -0.1383,  0.1940, -0.0135,  0.2072],\n        [ 0.3039,  0.0741, -0.1090,  0.0944,  0.0449, -0.0987, -0.2558, -0.0646],\n        [ 0.2137, -0.2894, -0.0497, -0.2043, -0.2009,  0.1016, -0.1829,  0.2820],\n        [ 0.1058,  0.0515, -0.0337,  0.0561, -0.3222, -0.1584, -0.0609,  0.2136],\n        [-0.3400,  0.0685,  0.2370, -0.1669,  0.2526, -0.2730,  0.2108, -0.1964],\n        [-0.0043, -0.1448, -0.0531, -0.3479,  0.0292,  0.2338,  0.2243, -0.2313],\n        [ 0.1108,  0.2501,  0.1400,  0.1377, -0.2028,  0.2003, -0.3378, -0.2362],\n        [ 0.3136,  0.0193, -0.3093,  0.0241,  0.0006, -0.3233,  0.3393,  0.1339],\n        [ 0.2770, -0.0523, -0.0862, -0.2319,  0.1166,  0.2775,  0.1856,  0.0642],\n        [-0.0325, -0.2548,  0.1983,  0.0614, -0.1793,  0.1906,  0.1056, -0.1458],\n        [-0.1749,  0.3089,  0.3261, -0.2720,  0.2477, -0.1998, -0.0234,  0.3142],\n        [-0.2227,  0.3391, -0.1085, -0.2326,  0.1800, -0.1488,  0.0460,  0.0459],\n        [-0.0783,  0.1577, -0.1326,  0.3410, -0.3134,  0.0191, -0.0652,  0.1029],\n        [-0.1245,  0.3281, -0.2005,  0.1837,  0.0398, -0.1793,  0.3094,  0.1634],\n        [-0.2942, -0.3147,  0.0697, -0.2547,  0.2403, -0.1682,  0.0789,  0.0339]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1538,  0.0722, -0.0658,  0.0685,  0.0631,  0.1258,  0.0039, -0.0248,\n        -0.1524,  0.0346,  0.0631, -0.0185,  0.0995, -0.1350,  0.0205, -0.1239],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 6.3536e-02,  1.6405e-01, -2.0374e-02,  1.4157e-01, -7.3672e-02,\n         -1.7598e-01,  3.5715e-02,  3.4496e-02,  5.9573e-02,  1.4022e-01,\n         -1.1252e-02,  1.5428e-01,  5.9549e-02,  1.5096e-01,  1.3862e-01,\n          1.7649e-02, -6.0254e-02,  1.4336e-01, -1.2966e-01, -1.5878e-01,\n          1.7225e-01,  7.3468e-02,  1.7364e-01, -1.6835e-02,  6.6366e-02,\n         -8.3043e-02,  1.3515e-01, -6.6275e-02, -1.0246e-02, -6.1329e-03,\n         -9.9649e-03, -5.2195e-02],\n        [-9.2684e-02,  1.5651e-01, -1.7417e-02,  8.0534e-02, -7.9853e-02,\n          8.4436e-02,  4.2343e-02,  1.0126e-01, -7.9562e-02, -9.2977e-02,\n         -5.8987e-02, -2.0300e-02,  1.3456e-01, -1.4298e-01, -7.3391e-02,\n         -9.2621e-02,  1.3966e-01, -1.3127e-01, -1.2983e-01,  5.5693e-02,\n          5.2325e-05,  3.5829e-02, -5.5800e-02, -8.4711e-02,  1.6090e-01,\n         -1.4061e-01, -1.2135e-01, -8.9746e-02, -1.6793e-01, -1.7483e-01,\n          3.3592e-02,  1.5699e-01],\n        [ 4.1692e-02, -1.7148e-02, -3.5472e-02, -4.2522e-02, -1.4314e-01,\n         -1.7499e-01, -5.9296e-02,  1.4634e-01, -7.5838e-02,  7.9269e-02,\n          1.4598e-01,  3.2372e-02,  4.4122e-02,  1.0277e-01,  1.3078e-01,\n         -1.6877e-02, -4.5638e-02,  2.5507e-04, -1.4500e-01, -2.0391e-03,\n         -4.7772e-02, -1.0294e-01, -1.0121e-01,  1.4523e-01, -5.1653e-02,\n         -9.0750e-02,  7.4714e-02, -4.4669e-03,  3.3331e-02, -1.6809e-01,\n         -7.3207e-02,  1.5612e-01],\n        [ 8.9164e-02,  2.7218e-02,  1.0396e-01, -1.1219e-02,  1.5242e-01,\n         -1.3233e-01,  7.6640e-02,  9.4974e-02,  8.9066e-02, -1.6135e-01,\n          6.8296e-02, -4.0813e-02,  6.3151e-03,  1.3082e-01, -4.0811e-02,\n          4.3540e-02, -1.5098e-01, -7.6416e-02,  1.6611e-01,  2.9126e-02,\n         -1.1356e-02,  6.6271e-02, -1.4640e-01,  6.2437e-02,  1.3600e-01,\n         -1.5711e-01, -1.2128e-01, -4.9987e-02, -6.1817e-02,  1.6164e-01,\n         -1.0560e-01,  1.3581e-01],\n        [ 9.8184e-02,  4.3025e-02, -7.0889e-02,  1.3661e-01,  1.3297e-01,\n          5.1686e-03, -1.0941e-01,  1.6191e-01,  1.1504e-01,  1.4406e-01,\n          1.6184e-01,  1.3663e-01, -1.0923e-01, -1.2208e-02,  1.3346e-01,\n          1.1753e-01,  5.8550e-02, -9.9499e-02,  1.4105e-02,  1.4555e-01,\n         -1.4559e-01,  1.6970e-01,  1.4917e-01,  1.6429e-01, -1.6228e-01,\n          1.4206e-01,  6.6631e-02, -2.9291e-02, -2.3915e-02, -5.1053e-02,\n         -1.4731e-01,  6.9775e-02],\n        [-2.0237e-02, -7.4315e-02, -7.6846e-03, -1.6984e-01,  4.9428e-03,\n         -1.1008e-01, -2.9851e-02, -1.4797e-01,  3.5122e-02,  1.3869e-01,\n          1.0860e-01, -1.0186e-01, -1.1905e-01, -1.7440e-01, -1.0288e-01,\n          1.5139e-01,  1.2899e-01, -1.7563e-01,  3.4468e-03, -1.5033e-01,\n         -7.0140e-02,  3.3602e-03, -3.2471e-02,  1.7258e-01,  7.2494e-03,\n          1.4676e-01, -2.3609e-02, -9.7964e-02,  1.7032e-02,  4.7275e-02,\n          1.3286e-01,  1.3492e-01],\n        [-2.9305e-02, -1.5433e-01,  1.4351e-01, -4.0492e-02, -1.1093e-01,\n          1.2535e-01, -7.5446e-02, -1.4161e-01,  1.3262e-02, -1.0664e-01,\n         -1.4504e-01, -8.4792e-02, -1.0160e-01,  7.6955e-02,  1.5939e-01,\n         -1.0451e-01, -8.2095e-02,  1.3037e-01,  1.0826e-01,  1.2116e-01,\n         -1.6500e-03,  1.1793e-01,  4.8082e-02, -1.6745e-01,  9.5486e-02,\n         -9.0838e-02,  1.7499e-01, -2.5281e-02, -7.0626e-02, -9.3245e-02,\n         -3.6885e-04, -9.6004e-02],\n        [ 9.4410e-02, -1.3368e-03,  8.7165e-02,  5.4844e-02,  1.5910e-01,\n          1.5213e-01,  9.6546e-02,  7.1310e-02,  1.1475e-01, -1.0153e-01,\n          9.0795e-02,  1.1026e-01, -6.6480e-02,  2.2866e-02,  5.6883e-02,\n          6.4905e-02,  1.2258e-01, -7.3967e-02, -1.2669e-01, -3.9945e-02,\n          3.5112e-02, -1.3409e-01,  2.2630e-02,  4.3219e-02, -1.4878e-01,\n          5.2999e-02,  1.9416e-02, -1.1785e-01,  1.5335e-01, -4.3565e-02,\n          5.1248e-02, -5.8222e-02],\n        [ 1.7313e-01, -2.8678e-02,  1.9973e-02, -3.6777e-02, -1.1130e-01,\n         -1.7654e-01, -1.4832e-01,  1.5990e-01, -1.7077e-01, -8.8462e-02,\n          2.7264e-02, -1.3992e-01, -1.7191e-01, -7.6388e-02, -1.4444e-01,\n         -6.4857e-02,  1.0457e-01, -5.0287e-02,  1.5282e-01,  3.6143e-02,\n          1.5354e-03,  1.6947e-01,  8.6163e-02,  1.2562e-01, -1.6718e-01,\n          4.3430e-02, -6.8529e-02,  4.7115e-02,  1.3588e-01, -8.8561e-02,\n          1.3940e-01, -3.6218e-02],\n        [-2.7739e-02, -9.9880e-02,  1.5585e-01, -1.4967e-01,  1.1850e-01,\n         -8.8812e-02, -1.4070e-01, -2.8252e-02,  1.6979e-01,  7.8130e-02,\n         -4.8597e-02,  1.6669e-01,  1.1861e-01,  9.9142e-02, -3.2422e-02,\n         -3.4922e-02, -1.9994e-03,  1.0466e-01,  1.4757e-01,  7.0918e-02,\n          5.4083e-03,  1.1188e-01,  1.2752e-01,  2.1406e-02, -2.2045e-02,\n         -5.5458e-02, -6.9873e-02, -7.5325e-02,  1.2147e-01,  1.5911e-01,\n         -5.5968e-02,  2.6349e-02],\n        [-1.6174e-01,  7.4182e-02, -9.1686e-02, -9.7640e-02,  1.2560e-01,\n          1.4182e-01, -8.8949e-02, -8.6414e-02,  1.8884e-02,  1.5307e-01,\n         -1.6634e-01,  4.4532e-02,  1.3532e-01, -8.1203e-02,  7.4115e-02,\n          1.5580e-01,  1.5167e-01, -5.9229e-02, -1.8278e-02, -1.5915e-01,\n         -5.3101e-02, -6.2734e-02, -1.4165e-01, -6.6441e-02,  1.2457e-01,\n         -2.3127e-02, -4.5175e-02, -2.9301e-02, -1.2443e-01,  1.3353e-01,\n          1.6517e-01,  1.5532e-01],\n        [-6.7886e-02, -8.3627e-02, -7.6831e-02, -1.3055e-01,  3.1239e-02,\n         -3.3502e-02,  5.8458e-02, -1.3439e-01,  3.3995e-02,  4.3422e-02,\n          8.6719e-02, -1.3332e-01,  7.8400e-02,  1.6864e-01,  8.2263e-02,\n         -3.4976e-02,  1.3937e-01,  2.9696e-02, -1.0608e-01, -2.0719e-02,\n          6.2541e-02, -3.2993e-02, -6.2622e-02, -1.0647e-01,  1.2966e-01,\n          5.4648e-02, -9.7884e-02,  1.4303e-01, -9.3840e-02,  1.0109e-01,\n         -5.3222e-02,  1.1514e-01],\n        [-1.2363e-01, -4.2064e-02, -1.2012e-06,  1.5345e-01,  1.2080e-01,\n         -2.3536e-02,  1.3985e-01,  1.6277e-01, -1.4176e-01,  1.2604e-01,\n          9.5886e-03,  2.9211e-02,  4.5352e-02,  1.5463e-01,  2.3672e-02,\n         -4.8132e-02,  1.1997e-01,  2.8029e-02, -7.9551e-02, -1.2852e-02,\n         -9.9671e-02, -1.7645e-02,  1.6867e-01, -8.3747e-02,  1.0022e-02,\n          3.3711e-02, -2.8708e-02, -5.3161e-02,  8.6182e-02,  1.6332e-01,\n          1.1616e-01, -4.6526e-04],\n        [-4.2971e-02, -1.4617e-01,  3.5072e-02,  1.2482e-01, -5.0075e-02,\n         -1.5434e-01,  9.2417e-02,  2.7780e-02,  9.2122e-02,  7.4558e-02,\n          1.3431e-01,  5.8668e-02, -8.6301e-03, -1.4448e-02,  1.1515e-01,\n         -1.3116e-01, -4.9267e-03,  5.0379e-02, -9.8907e-02, -5.9368e-02,\n         -8.5519e-03, -9.4354e-02,  1.6078e-01, -1.2041e-01,  1.0053e-01,\n         -1.4050e-01, -1.6638e-01, -2.2781e-02, -1.7245e-01, -8.7775e-02,\n         -1.4058e-01, -1.7813e-02],\n        [ 1.0747e-01, -1.3031e-01, -1.0377e-01,  1.1383e-01,  2.8890e-02,\n          6.2618e-02, -1.0159e-01,  1.2010e-01,  6.1479e-02, -7.3737e-03,\n         -1.1623e-01, -1.7178e-01,  8.2951e-02,  1.1257e-01, -4.4871e-02,\n          4.6377e-02, -1.4311e-01, -9.3041e-02,  9.2142e-02, -1.4696e-01,\n         -9.6957e-02, -7.6525e-02,  3.5845e-02, -6.3909e-02, -2.6358e-02,\n         -3.2745e-02, -1.3682e-01, -3.2214e-02,  1.2518e-01,  1.1183e-01,\n          1.5740e-01, -6.3368e-02],\n        [ 4.0095e-02,  1.3679e-01,  1.0593e-01,  1.2448e-01,  3.0267e-02,\n         -1.1426e-01,  1.6296e-01, -4.6080e-02, -8.8080e-03, -2.8699e-02,\n          1.6161e-01, -1.3901e-01, -1.4082e-01, -1.2065e-01, -7.8908e-03,\n          8.2460e-02,  1.1747e-01,  1.4999e-02, -1.2974e-01, -1.1419e-01,\n          4.3814e-02,  4.9336e-02, -6.1501e-02,  7.1674e-03, -5.8658e-02,\n          5.4700e-02, -1.3994e-01, -1.4717e-01, -1.2767e-01,  1.6503e-01,\n          8.0996e-03, -1.4548e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1278,  0.1301,  0.0257, -0.1413, -0.0374, -0.0890, -0.1366, -0.1654],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0047,  0.0527,  0.0263, -0.0488, -0.1057, -0.1536,  0.0651, -0.0493,\n          0.1906, -0.2153,  0.0872, -0.1922, -0.0532, -0.0871, -0.1855,  0.1539],\n        [ 0.1936, -0.2493, -0.1838,  0.0034,  0.1388, -0.0223,  0.0123,  0.0832,\n          0.1983, -0.1342, -0.1291, -0.0087,  0.1889,  0.1432, -0.2140, -0.0238],\n        [ 0.1774, -0.1554,  0.2192,  0.0462,  0.1333, -0.1840,  0.1449,  0.0108,\n          0.0691,  0.0140, -0.1644,  0.1616, -0.0289, -0.2438,  0.0045, -0.1543],\n        [-0.2231,  0.0892, -0.1508,  0.0589, -0.1635,  0.1701, -0.1010, -0.1749,\n          0.0526,  0.1623, -0.0944,  0.2366,  0.0307,  0.0516,  0.1384,  0.1516],\n        [ 0.2197,  0.0900, -0.0040,  0.1782,  0.1575,  0.2014,  0.2076, -0.1963,\n          0.2393,  0.2208, -0.1038,  0.0396, -0.2028,  0.0030,  0.1474, -0.0347],\n        [-0.0664,  0.2267, -0.0343, -0.0397,  0.2013,  0.1161, -0.1795, -0.0482,\n         -0.2321, -0.1239,  0.0248, -0.2446,  0.1358, -0.0246, -0.0861, -0.2224],\n        [ 0.1688,  0.0507,  0.0256,  0.0207,  0.1377,  0.0524, -0.1315,  0.1151,\n         -0.1983, -0.2130, -0.0511,  0.1285, -0.0145,  0.1174, -0.1359,  0.0142],\n        [ 0.2261, -0.2099, -0.0381,  0.2355,  0.0902,  0.0010,  0.0020,  0.0781,\n          0.1929, -0.2048, -0.0174,  0.1865, -0.0290, -0.0833, -0.0313, -0.0179]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2903, -0.0921, -0.1146, -0.1766], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0985, -0.1413,  0.3425, -0.1075, -0.0708, -0.0043,  0.1083, -0.1838],\n        [ 0.1843, -0.1983, -0.1018,  0.2923,  0.1630,  0.1231,  0.0287,  0.3436],\n        [ 0.1803, -0.3452,  0.2258, -0.1208,  0.0267,  0.1767,  0.0541, -0.1824],\n        [-0.1226, -0.3480,  0.1920, -0.2046, -0.1089,  0.2213,  0.1708,  0.1489]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1603,  0.3065, -0.1446, -0.2896, -0.2029, -0.2914, -0.0824,  0.2119],\n        [ 0.2432, -0.1741, -0.1915,  0.1778, -0.0412,  0.0110, -0.1811,  0.3405],\n        [-0.1660,  0.0168,  0.2092, -0.1217, -0.0574,  0.2740, -0.0240, -0.0894],\n        [-0.2796, -0.2094,  0.2150,  0.2221, -0.3296, -0.3078,  0.1098,  0.0709],\n        [ 0.0964,  0.3035, -0.0364,  0.3479, -0.0917,  0.2906,  0.0286,  0.0920],\n        [-0.1023, -0.2391,  0.2015,  0.3015,  0.0474, -0.2291, -0.1033, -0.1870],\n        [-0.1761,  0.3124, -0.3308,  0.2759,  0.1311, -0.2924,  0.1778,  0.1492],\n        [ 0.0258, -0.0384,  0.1299,  0.2656, -0.0780, -0.3250, -0.0572, -0.0640],\n        [-0.2268, -0.2566, -0.1579,  0.3330,  0.2949,  0.2412, -0.3110, -0.1825],\n        [-0.3013,  0.3307, -0.3111,  0.2880,  0.1851,  0.1431, -0.3357, -0.0607],\n        [-0.2652, -0.0543,  0.3410, -0.0592,  0.2612,  0.0597, -0.0057,  0.1337],\n        [ 0.2603,  0.3349,  0.0972,  0.0300, -0.0235, -0.2036, -0.0856,  0.3505],\n        [-0.0553, -0.3018, -0.2622, -0.0180, -0.3328, -0.3135,  0.3525,  0.0805],\n        [-0.0845,  0.0158,  0.2577,  0.2326,  0.1932, -0.1935,  0.0185,  0.2900],\n        [ 0.0165,  0.1347,  0.0806,  0.3082, -0.1464,  0.0376, -0.1963, -0.1297],\n        [ 0.3003,  0.3332,  0.0144, -0.2390,  0.1796, -0.0373,  0.1098, -0.0211],\n        [ 0.1330, -0.2377,  0.1559,  0.3096, -0.2868, -0.3494, -0.0807,  0.2562],\n        [-0.2461, -0.2060,  0.2364, -0.0159, -0.1383,  0.1940, -0.0135,  0.2072],\n        [ 0.3039,  0.0741, -0.1090,  0.0944,  0.0449, -0.0987, -0.2558, -0.0646],\n        [ 0.2137, -0.2894, -0.0497, -0.2043, -0.2009,  0.1016, -0.1829,  0.2820],\n        [ 0.1058,  0.0515, -0.0337,  0.0561, -0.3222, -0.1584, -0.0609,  0.2136],\n        [-0.3400,  0.0685,  0.2370, -0.1669,  0.2526, -0.2730,  0.2108, -0.1964],\n        [-0.0043, -0.1448, -0.0531, -0.3479,  0.0292,  0.2338,  0.2243, -0.2313],\n        [ 0.1108,  0.2501,  0.1400,  0.1377, -0.2028,  0.2003, -0.3378, -0.2362],\n        [ 0.3136,  0.0193, -0.3093,  0.0241,  0.0006, -0.3233,  0.3393,  0.1339],\n        [ 0.2770, -0.0523, -0.0862, -0.2319,  0.1166,  0.2775,  0.1856,  0.0642],\n        [-0.0325, -0.2548,  0.1983,  0.0614, -0.1793,  0.1906,  0.1056, -0.1458],\n        [-0.1749,  0.3089,  0.3261, -0.2720,  0.2477, -0.1998, -0.0234,  0.3142],\n        [-0.2227,  0.3391, -0.1085, -0.2326,  0.1800, -0.1488,  0.0460,  0.0459],\n        [-0.0783,  0.1577, -0.1326,  0.3410, -0.3134,  0.0191, -0.0652,  0.1029],\n        [-0.1245,  0.3281, -0.2005,  0.1837,  0.0398, -0.1793,  0.3094,  0.1634],\n        [-0.2942, -0.3147,  0.0697, -0.2547,  0.2403, -0.1682,  0.0789,  0.0339]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1996, -0.2808, -0.3117,  0.1286,  0.1159, -0.1301, -0.3492, -0.2412,\n        -0.1380, -0.0837,  0.3376, -0.3108, -0.0433,  0.2211, -0.1745,  0.2040,\n        -0.1861,  0.0663, -0.1077, -0.0176, -0.2223,  0.0894, -0.3200, -0.0908,\n         0.0978,  0.1217,  0.0938, -0.2993, -0.0228,  0.2270, -0.2165,  0.1659],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 6.3536e-02,  1.6405e-01, -2.0374e-02,  1.4157e-01, -7.3672e-02,\n         -1.7598e-01,  3.5715e-02,  3.4496e-02,  5.9573e-02,  1.4022e-01,\n         -1.1252e-02,  1.5428e-01,  5.9549e-02,  1.5096e-01,  1.3862e-01,\n          1.7649e-02, -6.0254e-02,  1.4336e-01, -1.2966e-01, -1.5878e-01,\n          1.7225e-01,  7.3468e-02,  1.7364e-01, -1.6835e-02,  6.6366e-02,\n         -8.3043e-02,  1.3515e-01, -6.6275e-02, -1.0246e-02, -6.1329e-03,\n         -9.9649e-03, -5.2195e-02],\n        [-9.2684e-02,  1.5651e-01, -1.7417e-02,  8.0534e-02, -7.9853e-02,\n          8.4436e-02,  4.2343e-02,  1.0126e-01, -7.9562e-02, -9.2977e-02,\n         -5.8987e-02, -2.0300e-02,  1.3456e-01, -1.4298e-01, -7.3391e-02,\n         -9.2621e-02,  1.3966e-01, -1.3127e-01, -1.2983e-01,  5.5693e-02,\n          5.2325e-05,  3.5829e-02, -5.5800e-02, -8.4711e-02,  1.6090e-01,\n         -1.4061e-01, -1.2135e-01, -8.9746e-02, -1.6793e-01, -1.7483e-01,\n          3.3592e-02,  1.5699e-01],\n        [ 4.1692e-02, -1.7148e-02, -3.5472e-02, -4.2522e-02, -1.4314e-01,\n         -1.7499e-01, -5.9296e-02,  1.4634e-01, -7.5838e-02,  7.9269e-02,\n          1.4598e-01,  3.2372e-02,  4.4122e-02,  1.0277e-01,  1.3078e-01,\n         -1.6877e-02, -4.5638e-02,  2.5507e-04, -1.4500e-01, -2.0391e-03,\n         -4.7772e-02, -1.0294e-01, -1.0121e-01,  1.4523e-01, -5.1653e-02,\n         -9.0750e-02,  7.4714e-02, -4.4669e-03,  3.3331e-02, -1.6809e-01,\n         -7.3207e-02,  1.5612e-01],\n        [ 8.9164e-02,  2.7218e-02,  1.0396e-01, -1.1219e-02,  1.5242e-01,\n         -1.3233e-01,  7.6640e-02,  9.4974e-02,  8.9066e-02, -1.6135e-01,\n          6.8296e-02, -4.0813e-02,  6.3151e-03,  1.3082e-01, -4.0811e-02,\n          4.3540e-02, -1.5098e-01, -7.6416e-02,  1.6611e-01,  2.9126e-02,\n         -1.1356e-02,  6.6271e-02, -1.4640e-01,  6.2437e-02,  1.3600e-01,\n         -1.5711e-01, -1.2128e-01, -4.9987e-02, -6.1817e-02,  1.6164e-01,\n         -1.0560e-01,  1.3581e-01],\n        [ 9.8184e-02,  4.3025e-02, -7.0889e-02,  1.3661e-01,  1.3297e-01,\n          5.1686e-03, -1.0941e-01,  1.6191e-01,  1.1504e-01,  1.4406e-01,\n          1.6184e-01,  1.3663e-01, -1.0923e-01, -1.2208e-02,  1.3346e-01,\n          1.1753e-01,  5.8550e-02, -9.9499e-02,  1.4105e-02,  1.4555e-01,\n         -1.4559e-01,  1.6970e-01,  1.4917e-01,  1.6429e-01, -1.6228e-01,\n          1.4206e-01,  6.6631e-02, -2.9291e-02, -2.3915e-02, -5.1053e-02,\n         -1.4731e-01,  6.9775e-02],\n        [-2.0237e-02, -7.4315e-02, -7.6846e-03, -1.6984e-01,  4.9428e-03,\n         -1.1008e-01, -2.9851e-02, -1.4797e-01,  3.5122e-02,  1.3869e-01,\n          1.0860e-01, -1.0186e-01, -1.1905e-01, -1.7440e-01, -1.0288e-01,\n          1.5139e-01,  1.2899e-01, -1.7563e-01,  3.4468e-03, -1.5033e-01,\n         -7.0140e-02,  3.3602e-03, -3.2471e-02,  1.7258e-01,  7.2494e-03,\n          1.4676e-01, -2.3609e-02, -9.7964e-02,  1.7032e-02,  4.7275e-02,\n          1.3286e-01,  1.3492e-01],\n        [-2.9305e-02, -1.5433e-01,  1.4351e-01, -4.0492e-02, -1.1093e-01,\n          1.2535e-01, -7.5446e-02, -1.4161e-01,  1.3262e-02, -1.0664e-01,\n         -1.4504e-01, -8.4792e-02, -1.0160e-01,  7.6955e-02,  1.5939e-01,\n         -1.0451e-01, -8.2095e-02,  1.3037e-01,  1.0826e-01,  1.2116e-01,\n         -1.6500e-03,  1.1793e-01,  4.8082e-02, -1.6745e-01,  9.5486e-02,\n         -9.0838e-02,  1.7499e-01, -2.5281e-02, -7.0626e-02, -9.3245e-02,\n         -3.6885e-04, -9.6004e-02],\n        [ 9.4410e-02, -1.3368e-03,  8.7165e-02,  5.4844e-02,  1.5910e-01,\n          1.5213e-01,  9.6546e-02,  7.1310e-02,  1.1475e-01, -1.0153e-01,\n          9.0795e-02,  1.1026e-01, -6.6480e-02,  2.2866e-02,  5.6883e-02,\n          6.4905e-02,  1.2258e-01, -7.3967e-02, -1.2669e-01, -3.9945e-02,\n          3.5112e-02, -1.3409e-01,  2.2630e-02,  4.3219e-02, -1.4878e-01,\n          5.2999e-02,  1.9416e-02, -1.1785e-01,  1.5335e-01, -4.3565e-02,\n          5.1248e-02, -5.8222e-02],\n        [ 1.7313e-01, -2.8678e-02,  1.9973e-02, -3.6777e-02, -1.1130e-01,\n         -1.7654e-01, -1.4832e-01,  1.5990e-01, -1.7077e-01, -8.8462e-02,\n          2.7264e-02, -1.3992e-01, -1.7191e-01, -7.6388e-02, -1.4444e-01,\n         -6.4857e-02,  1.0457e-01, -5.0287e-02,  1.5282e-01,  3.6143e-02,\n          1.5354e-03,  1.6947e-01,  8.6163e-02,  1.2562e-01, -1.6718e-01,\n          4.3430e-02, -6.8529e-02,  4.7115e-02,  1.3588e-01, -8.8561e-02,\n          1.3940e-01, -3.6218e-02],\n        [-2.7739e-02, -9.9880e-02,  1.5585e-01, -1.4967e-01,  1.1850e-01,\n         -8.8812e-02, -1.4070e-01, -2.8252e-02,  1.6979e-01,  7.8130e-02,\n         -4.8597e-02,  1.6669e-01,  1.1861e-01,  9.9142e-02, -3.2422e-02,\n         -3.4922e-02, -1.9994e-03,  1.0466e-01,  1.4757e-01,  7.0918e-02,\n          5.4083e-03,  1.1188e-01,  1.2752e-01,  2.1406e-02, -2.2045e-02,\n         -5.5458e-02, -6.9873e-02, -7.5325e-02,  1.2147e-01,  1.5911e-01,\n         -5.5968e-02,  2.6349e-02],\n        [-1.6174e-01,  7.4182e-02, -9.1686e-02, -9.7640e-02,  1.2560e-01,\n          1.4182e-01, -8.8949e-02, -8.6414e-02,  1.8884e-02,  1.5307e-01,\n         -1.6634e-01,  4.4532e-02,  1.3532e-01, -8.1203e-02,  7.4115e-02,\n          1.5580e-01,  1.5167e-01, -5.9229e-02, -1.8278e-02, -1.5915e-01,\n         -5.3101e-02, -6.2734e-02, -1.4165e-01, -6.6441e-02,  1.2457e-01,\n         -2.3127e-02, -4.5175e-02, -2.9301e-02, -1.2443e-01,  1.3353e-01,\n          1.6517e-01,  1.5532e-01],\n        [-6.7886e-02, -8.3627e-02, -7.6831e-02, -1.3055e-01,  3.1239e-02,\n         -3.3502e-02,  5.8458e-02, -1.3439e-01,  3.3995e-02,  4.3422e-02,\n          8.6719e-02, -1.3332e-01,  7.8400e-02,  1.6864e-01,  8.2263e-02,\n         -3.4976e-02,  1.3937e-01,  2.9696e-02, -1.0608e-01, -2.0719e-02,\n          6.2541e-02, -3.2993e-02, -6.2622e-02, -1.0647e-01,  1.2966e-01,\n          5.4648e-02, -9.7884e-02,  1.4303e-01, -9.3840e-02,  1.0109e-01,\n         -5.3222e-02,  1.1514e-01],\n        [-1.2363e-01, -4.2064e-02, -1.2012e-06,  1.5345e-01,  1.2080e-01,\n         -2.3536e-02,  1.3985e-01,  1.6277e-01, -1.4176e-01,  1.2604e-01,\n          9.5886e-03,  2.9211e-02,  4.5352e-02,  1.5463e-01,  2.3672e-02,\n         -4.8132e-02,  1.1997e-01,  2.8029e-02, -7.9551e-02, -1.2852e-02,\n         -9.9671e-02, -1.7645e-02,  1.6867e-01, -8.3747e-02,  1.0022e-02,\n          3.3711e-02, -2.8708e-02, -5.3161e-02,  8.6182e-02,  1.6332e-01,\n          1.1616e-01, -4.6526e-04],\n        [-4.2971e-02, -1.4617e-01,  3.5072e-02,  1.2482e-01, -5.0075e-02,\n         -1.5434e-01,  9.2417e-02,  2.7780e-02,  9.2122e-02,  7.4558e-02,\n          1.3431e-01,  5.8668e-02, -8.6301e-03, -1.4448e-02,  1.1515e-01,\n         -1.3116e-01, -4.9267e-03,  5.0379e-02, -9.8907e-02, -5.9368e-02,\n         -8.5519e-03, -9.4354e-02,  1.6078e-01, -1.2041e-01,  1.0053e-01,\n         -1.4050e-01, -1.6638e-01, -2.2781e-02, -1.7245e-01, -8.7775e-02,\n         -1.4058e-01, -1.7813e-02],\n        [ 1.0747e-01, -1.3031e-01, -1.0377e-01,  1.1383e-01,  2.8890e-02,\n          6.2618e-02, -1.0159e-01,  1.2010e-01,  6.1479e-02, -7.3737e-03,\n         -1.1623e-01, -1.7178e-01,  8.2951e-02,  1.1257e-01, -4.4871e-02,\n          4.6377e-02, -1.4311e-01, -9.3041e-02,  9.2142e-02, -1.4696e-01,\n         -9.6957e-02, -7.6525e-02,  3.5845e-02, -6.3909e-02, -2.6358e-02,\n         -3.2745e-02, -1.3682e-01, -3.2214e-02,  1.2518e-01,  1.1183e-01,\n          1.5740e-01, -6.3368e-02],\n        [ 4.0095e-02,  1.3679e-01,  1.0593e-01,  1.2448e-01,  3.0267e-02,\n         -1.1426e-01,  1.6296e-01, -4.6080e-02, -8.8080e-03, -2.8699e-02,\n          1.6161e-01, -1.3901e-01, -1.4082e-01, -1.2065e-01, -7.8908e-03,\n          8.2460e-02,  1.1747e-01,  1.4999e-02, -1.2974e-01, -1.1419e-01,\n          4.3814e-02,  4.9336e-02, -6.1501e-02,  7.1674e-03, -5.8658e-02,\n          5.4700e-02, -1.3994e-01, -1.4717e-01, -1.2767e-01,  1.6503e-01,\n          8.0996e-03, -1.4548e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1538,  0.0722, -0.0658,  0.0685,  0.0631,  0.1258,  0.0039, -0.0248,\n        -0.1524,  0.0346,  0.0631, -0.0185,  0.0995, -0.1350,  0.0205, -0.1239],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0047,  0.0527,  0.0263, -0.0488, -0.1057, -0.1536,  0.0651, -0.0493,\n          0.1906, -0.2153,  0.0872, -0.1922, -0.0532, -0.0871, -0.1855,  0.1539],\n        [ 0.1936, -0.2493, -0.1838,  0.0034,  0.1388, -0.0223,  0.0123,  0.0832,\n          0.1983, -0.1342, -0.1291, -0.0087,  0.1889,  0.1432, -0.2140, -0.0238],\n        [ 0.1774, -0.1554,  0.2192,  0.0462,  0.1333, -0.1840,  0.1449,  0.0108,\n          0.0691,  0.0140, -0.1644,  0.1616, -0.0289, -0.2438,  0.0045, -0.1543],\n        [-0.2231,  0.0892, -0.1508,  0.0589, -0.1635,  0.1701, -0.1010, -0.1749,\n          0.0526,  0.1623, -0.0944,  0.2366,  0.0307,  0.0516,  0.1384,  0.1516],\n        [ 0.2197,  0.0900, -0.0040,  0.1782,  0.1575,  0.2014,  0.2076, -0.1963,\n          0.2393,  0.2208, -0.1038,  0.0396, -0.2028,  0.0030,  0.1474, -0.0347],\n        [-0.0664,  0.2267, -0.0343, -0.0397,  0.2013,  0.1161, -0.1795, -0.0482,\n         -0.2321, -0.1239,  0.0248, -0.2446,  0.1358, -0.0246, -0.0861, -0.2224],\n        [ 0.1688,  0.0507,  0.0256,  0.0207,  0.1377,  0.0524, -0.1315,  0.1151,\n         -0.1983, -0.2130, -0.0511,  0.1285, -0.0145,  0.1174, -0.1359,  0.0142],\n        [ 0.2261, -0.2099, -0.0381,  0.2355,  0.0902,  0.0010,  0.0020,  0.0781,\n          0.1929, -0.2048, -0.0174,  0.1865, -0.0290, -0.0833, -0.0313, -0.0179]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1278,  0.1301,  0.0257, -0.1413, -0.0374, -0.0890, -0.1366, -0.1654],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0985, -0.1413,  0.3425, -0.1075, -0.0708, -0.0043,  0.1083, -0.1838],\n        [ 0.1843, -0.1983, -0.1018,  0.2923,  0.1630,  0.1231,  0.0287,  0.3436],\n        [ 0.1803, -0.3452,  0.2258, -0.1208,  0.0267,  0.1767,  0.0541, -0.1824],\n        [-0.1226, -0.3480,  0.1920, -0.2046, -0.1089,  0.2213,  0.1708,  0.1489]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2903, -0.0921, -0.1146, -0.1766], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x775baefdd150>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "full":	false,
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0.]\n [0. 0.]\n [0. 0.]\n ...\n [0. 0.]\n [0. 0.]\n [0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=8, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=8, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=8, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1996, -0.2808, -0.3117,  0.1286,  0.1159, -0.1301, -0.3492, -0.2412,\n        -0.1380, -0.0837,  0.3376, -0.3108, -0.0433,  0.2211, -0.1745,  0.2040,\n        -0.1861,  0.0663, -0.1077, -0.0176, -0.2223,  0.0894, -0.3200, -0.0908,\n         0.0978,  0.1217,  0.0938, -0.2993, -0.0228,  0.2270, -0.2165,  0.1659],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1603,  0.3065, -0.1446, -0.2896, -0.2029, -0.2914, -0.0824,  0.2119],\n        [ 0.2432, -0.1741, -0.1915,  0.1778, -0.0412,  0.0110, -0.1811,  0.3405],\n        [-0.1660,  0.0168,  0.2092, -0.1217, -0.0574,  0.2740, -0.0240, -0.0894],\n        [-0.2796, -0.2094,  0.2150,  0.2221, -0.3296, -0.3078,  0.1098,  0.0709],\n        [ 0.0964,  0.3035, -0.0364,  0.3479, -0.0917,  0.2906,  0.0286,  0.0920],\n        [-0.1023, -0.2391,  0.2015,  0.3015,  0.0474, -0.2291, -0.1033, -0.1870],\n        [-0.1761,  0.3124, -0.3308,  0.2759,  0.1311, -0.2924,  0.1778,  0.1492],\n        [ 0.0258, -0.0384,  0.1299,  0.2656, -0.0780, -0.3250, -0.0572, -0.0640],\n        [-0.2268, -0.2566, -0.1579,  0.3330,  0.2949,  0.2412, -0.3110, -0.1825],\n        [-0.3013,  0.3307, -0.3111,  0.2880,  0.1851,  0.1431, -0.3357, -0.0607],\n        [-0.2652, -0.0543,  0.3410, -0.0592,  0.2612,  0.0597, -0.0057,  0.1337],\n        [ 0.2603,  0.3349,  0.0972,  0.0300, -0.0235, -0.2036, -0.0856,  0.3505],\n        [-0.0553, -0.3018, -0.2622, -0.0180, -0.3328, -0.3135,  0.3525,  0.0805],\n        [-0.0845,  0.0158,  0.2577,  0.2326,  0.1932, -0.1935,  0.0185,  0.2900],\n        [ 0.0165,  0.1347,  0.0806,  0.3082, -0.1464,  0.0376, -0.1963, -0.1297],\n        [ 0.3003,  0.3332,  0.0144, -0.2390,  0.1796, -0.0373,  0.1098, -0.0211],\n        [ 0.1330, -0.2377,  0.1559,  0.3096, -0.2868, -0.3494, -0.0807,  0.2562],\n        [-0.2461, -0.2060,  0.2364, -0.0159, -0.1383,  0.1940, -0.0135,  0.2072],\n        [ 0.3039,  0.0741, -0.1090,  0.0944,  0.0449, -0.0987, -0.2558, -0.0646],\n        [ 0.2137, -0.2894, -0.0497, -0.2043, -0.2009,  0.1016, -0.1829,  0.2820],\n        [ 0.1058,  0.0515, -0.0337,  0.0561, -0.3222, -0.1584, -0.0609,  0.2136],\n        [-0.3400,  0.0685,  0.2370, -0.1669,  0.2526, -0.2730,  0.2108, -0.1964],\n        [-0.0043, -0.1448, -0.0531, -0.3479,  0.0292,  0.2338,  0.2243, -0.2313],\n        [ 0.1108,  0.2501,  0.1400,  0.1377, -0.2028,  0.2003, -0.3378, -0.2362],\n        [ 0.3136,  0.0193, -0.3093,  0.0241,  0.0006, -0.3233,  0.3393,  0.1339],\n        [ 0.2770, -0.0523, -0.0862, -0.2319,  0.1166,  0.2775,  0.1856,  0.0642],\n        [-0.0325, -0.2548,  0.1983,  0.0614, -0.1793,  0.1906,  0.1056, -0.1458],\n        [-0.1749,  0.3089,  0.3261, -0.2720,  0.2477, -0.1998, -0.0234,  0.3142],\n        [-0.2227,  0.3391, -0.1085, -0.2326,  0.1800, -0.1488,  0.0460,  0.0459],\n        [-0.0783,  0.1577, -0.1326,  0.3410, -0.3134,  0.0191, -0.0652,  0.1029],\n        [-0.1245,  0.3281, -0.2005,  0.1837,  0.0398, -0.1793,  0.3094,  0.1634],\n        [-0.2942, -0.3147,  0.0697, -0.2547,  0.2403, -0.1682,  0.0789,  0.0339]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1538,  0.0722, -0.0658,  0.0685,  0.0631,  0.1258,  0.0039, -0.0248,\n        -0.1524,  0.0346,  0.0631, -0.0185,  0.0995, -0.1350,  0.0205, -0.1239],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 6.3536e-02,  1.6405e-01, -2.0374e-02,  1.4157e-01, -7.3672e-02,\n         -1.7598e-01,  3.5715e-02,  3.4496e-02,  5.9573e-02,  1.4022e-01,\n         -1.1252e-02,  1.5428e-01,  5.9549e-02,  1.5096e-01,  1.3862e-01,\n          1.7649e-02, -6.0254e-02,  1.4336e-01, -1.2966e-01, -1.5878e-01,\n          1.7225e-01,  7.3468e-02,  1.7364e-01, -1.6835e-02,  6.6366e-02,\n         -8.3043e-02,  1.3515e-01, -6.6275e-02, -1.0246e-02, -6.1329e-03,\n         -9.9649e-03, -5.2195e-02],\n        [-9.2684e-02,  1.5651e-01, -1.7417e-02,  8.0534e-02, -7.9853e-02,\n          8.4436e-02,  4.2343e-02,  1.0126e-01, -7.9562e-02, -9.2977e-02,\n         -5.8987e-02, -2.0300e-02,  1.3456e-01, -1.4298e-01, -7.3391e-02,\n         -9.2621e-02,  1.3966e-01, -1.3127e-01, -1.2983e-01,  5.5693e-02,\n          5.2325e-05,  3.5829e-02, -5.5800e-02, -8.4711e-02,  1.6090e-01,\n         -1.4061e-01, -1.2135e-01, -8.9746e-02, -1.6793e-01, -1.7483e-01,\n          3.3592e-02,  1.5699e-01],\n        [ 4.1692e-02, -1.7148e-02, -3.5472e-02, -4.2522e-02, -1.4314e-01,\n         -1.7499e-01, -5.9296e-02,  1.4634e-01, -7.5838e-02,  7.9269e-02,\n          1.4598e-01,  3.2372e-02,  4.4122e-02,  1.0277e-01,  1.3078e-01,\n         -1.6877e-02, -4.5638e-02,  2.5507e-04, -1.4500e-01, -2.0391e-03,\n         -4.7772e-02, -1.0294e-01, -1.0121e-01,  1.4523e-01, -5.1653e-02,\n         -9.0750e-02,  7.4714e-02, -4.4669e-03,  3.3331e-02, -1.6809e-01,\n         -7.3207e-02,  1.5612e-01],\n        [ 8.9164e-02,  2.7218e-02,  1.0396e-01, -1.1219e-02,  1.5242e-01,\n         -1.3233e-01,  7.6640e-02,  9.4974e-02,  8.9066e-02, -1.6135e-01,\n          6.8296e-02, -4.0813e-02,  6.3151e-03,  1.3082e-01, -4.0811e-02,\n          4.3540e-02, -1.5098e-01, -7.6416e-02,  1.6611e-01,  2.9126e-02,\n         -1.1356e-02,  6.6271e-02, -1.4640e-01,  6.2437e-02,  1.3600e-01,\n         -1.5711e-01, -1.2128e-01, -4.9987e-02, -6.1817e-02,  1.6164e-01,\n         -1.0560e-01,  1.3581e-01],\n        [ 9.8184e-02,  4.3025e-02, -7.0889e-02,  1.3661e-01,  1.3297e-01,\n          5.1686e-03, -1.0941e-01,  1.6191e-01,  1.1504e-01,  1.4406e-01,\n          1.6184e-01,  1.3663e-01, -1.0923e-01, -1.2208e-02,  1.3346e-01,\n          1.1753e-01,  5.8550e-02, -9.9499e-02,  1.4105e-02,  1.4555e-01,\n         -1.4559e-01,  1.6970e-01,  1.4917e-01,  1.6429e-01, -1.6228e-01,\n          1.4206e-01,  6.6631e-02, -2.9291e-02, -2.3915e-02, -5.1053e-02,\n         -1.4731e-01,  6.9775e-02],\n        [-2.0237e-02, -7.4315e-02, -7.6846e-03, -1.6984e-01,  4.9428e-03,\n         -1.1008e-01, -2.9851e-02, -1.4797e-01,  3.5122e-02,  1.3869e-01,\n          1.0860e-01, -1.0186e-01, -1.1905e-01, -1.7440e-01, -1.0288e-01,\n          1.5139e-01,  1.2899e-01, -1.7563e-01,  3.4468e-03, -1.5033e-01,\n         -7.0140e-02,  3.3602e-03, -3.2471e-02,  1.7258e-01,  7.2494e-03,\n          1.4676e-01, -2.3609e-02, -9.7964e-02,  1.7032e-02,  4.7275e-02,\n          1.3286e-01,  1.3492e-01],\n        [-2.9305e-02, -1.5433e-01,  1.4351e-01, -4.0492e-02, -1.1093e-01,\n          1.2535e-01, -7.5446e-02, -1.4161e-01,  1.3262e-02, -1.0664e-01,\n         -1.4504e-01, -8.4792e-02, -1.0160e-01,  7.6955e-02,  1.5939e-01,\n         -1.0451e-01, -8.2095e-02,  1.3037e-01,  1.0826e-01,  1.2116e-01,\n         -1.6500e-03,  1.1793e-01,  4.8082e-02, -1.6745e-01,  9.5486e-02,\n         -9.0838e-02,  1.7499e-01, -2.5281e-02, -7.0626e-02, -9.3245e-02,\n         -3.6885e-04, -9.6004e-02],\n        [ 9.4410e-02, -1.3368e-03,  8.7165e-02,  5.4844e-02,  1.5910e-01,\n          1.5213e-01,  9.6546e-02,  7.1310e-02,  1.1475e-01, -1.0153e-01,\n          9.0795e-02,  1.1026e-01, -6.6480e-02,  2.2866e-02,  5.6883e-02,\n          6.4905e-02,  1.2258e-01, -7.3967e-02, -1.2669e-01, -3.9945e-02,\n          3.5112e-02, -1.3409e-01,  2.2630e-02,  4.3219e-02, -1.4878e-01,\n          5.2999e-02,  1.9416e-02, -1.1785e-01,  1.5335e-01, -4.3565e-02,\n          5.1248e-02, -5.8222e-02],\n        [ 1.7313e-01, -2.8678e-02,  1.9973e-02, -3.6777e-02, -1.1130e-01,\n         -1.7654e-01, -1.4832e-01,  1.5990e-01, -1.7077e-01, -8.8462e-02,\n          2.7264e-02, -1.3992e-01, -1.7191e-01, -7.6388e-02, -1.4444e-01,\n         -6.4857e-02,  1.0457e-01, -5.0287e-02,  1.5282e-01,  3.6143e-02,\n          1.5354e-03,  1.6947e-01,  8.6163e-02,  1.2562e-01, -1.6718e-01,\n          4.3430e-02, -6.8529e-02,  4.7115e-02,  1.3588e-01, -8.8561e-02,\n          1.3940e-01, -3.6218e-02],\n        [-2.7739e-02, -9.9880e-02,  1.5585e-01, -1.4967e-01,  1.1850e-01,\n         -8.8812e-02, -1.4070e-01, -2.8252e-02,  1.6979e-01,  7.8130e-02,\n         -4.8597e-02,  1.6669e-01,  1.1861e-01,  9.9142e-02, -3.2422e-02,\n         -3.4922e-02, -1.9994e-03,  1.0466e-01,  1.4757e-01,  7.0918e-02,\n          5.4083e-03,  1.1188e-01,  1.2752e-01,  2.1406e-02, -2.2045e-02,\n         -5.5458e-02, -6.9873e-02, -7.5325e-02,  1.2147e-01,  1.5911e-01,\n         -5.5968e-02,  2.6349e-02],\n        [-1.6174e-01,  7.4182e-02, -9.1686e-02, -9.7640e-02,  1.2560e-01,\n          1.4182e-01, -8.8949e-02, -8.6414e-02,  1.8884e-02,  1.5307e-01,\n         -1.6634e-01,  4.4532e-02,  1.3532e-01, -8.1203e-02,  7.4115e-02,\n          1.5580e-01,  1.5167e-01, -5.9229e-02, -1.8278e-02, -1.5915e-01,\n         -5.3101e-02, -6.2734e-02, -1.4165e-01, -6.6441e-02,  1.2457e-01,\n         -2.3127e-02, -4.5175e-02, -2.9301e-02, -1.2443e-01,  1.3353e-01,\n          1.6517e-01,  1.5532e-01],\n        [-6.7886e-02, -8.3627e-02, -7.6831e-02, -1.3055e-01,  3.1239e-02,\n         -3.3502e-02,  5.8458e-02, -1.3439e-01,  3.3995e-02,  4.3422e-02,\n          8.6719e-02, -1.3332e-01,  7.8400e-02,  1.6864e-01,  8.2263e-02,\n         -3.4976e-02,  1.3937e-01,  2.9696e-02, -1.0608e-01, -2.0719e-02,\n          6.2541e-02, -3.2993e-02, -6.2622e-02, -1.0647e-01,  1.2966e-01,\n          5.4648e-02, -9.7884e-02,  1.4303e-01, -9.3840e-02,  1.0109e-01,\n         -5.3222e-02,  1.1514e-01],\n        [-1.2363e-01, -4.2064e-02, -1.2012e-06,  1.5345e-01,  1.2080e-01,\n         -2.3536e-02,  1.3985e-01,  1.6277e-01, -1.4176e-01,  1.2604e-01,\n          9.5886e-03,  2.9211e-02,  4.5352e-02,  1.5463e-01,  2.3672e-02,\n         -4.8132e-02,  1.1997e-01,  2.8029e-02, -7.9551e-02, -1.2852e-02,\n         -9.9671e-02, -1.7645e-02,  1.6867e-01, -8.3747e-02,  1.0022e-02,\n          3.3711e-02, -2.8708e-02, -5.3161e-02,  8.6182e-02,  1.6332e-01,\n          1.1616e-01, -4.6526e-04],\n        [-4.2971e-02, -1.4617e-01,  3.5072e-02,  1.2482e-01, -5.0075e-02,\n         -1.5434e-01,  9.2417e-02,  2.7780e-02,  9.2122e-02,  7.4558e-02,\n          1.3431e-01,  5.8668e-02, -8.6301e-03, -1.4448e-02,  1.1515e-01,\n         -1.3116e-01, -4.9267e-03,  5.0379e-02, -9.8907e-02, -5.9368e-02,\n         -8.5519e-03, -9.4354e-02,  1.6078e-01, -1.2041e-01,  1.0053e-01,\n         -1.4050e-01, -1.6638e-01, -2.2781e-02, -1.7245e-01, -8.7775e-02,\n         -1.4058e-01, -1.7813e-02],\n        [ 1.0747e-01, -1.3031e-01, -1.0377e-01,  1.1383e-01,  2.8890e-02,\n          6.2618e-02, -1.0159e-01,  1.2010e-01,  6.1479e-02, -7.3737e-03,\n         -1.1623e-01, -1.7178e-01,  8.2951e-02,  1.1257e-01, -4.4871e-02,\n          4.6377e-02, -1.4311e-01, -9.3041e-02,  9.2142e-02, -1.4696e-01,\n         -9.6957e-02, -7.6525e-02,  3.5845e-02, -6.3909e-02, -2.6358e-02,\n         -3.2745e-02, -1.3682e-01, -3.2214e-02,  1.2518e-01,  1.1183e-01,\n          1.5740e-01, -6.3368e-02],\n        [ 4.0095e-02,  1.3679e-01,  1.0593e-01,  1.2448e-01,  3.0267e-02,\n         -1.1426e-01,  1.6296e-01, -4.6080e-02, -8.8080e-03, -2.8699e-02,\n          1.6161e-01, -1.3901e-01, -1.4082e-01, -1.2065e-01, -7.8908e-03,\n          8.2460e-02,  1.1747e-01,  1.4999e-02, -1.2974e-01, -1.1419e-01,\n          4.3814e-02,  4.9336e-02, -6.1501e-02,  7.1674e-03, -5.8658e-02,\n          5.4700e-02, -1.3994e-01, -1.4717e-01, -1.2767e-01,  1.6503e-01,\n          8.0996e-03, -1.4548e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1278,  0.1301,  0.0257, -0.1413, -0.0374, -0.0890, -0.1366, -0.1654],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0047,  0.0527,  0.0263, -0.0488, -0.1057, -0.1536,  0.0651, -0.0493,\n          0.1906, -0.2153,  0.0872, -0.1922, -0.0532, -0.0871, -0.1855,  0.1539],\n        [ 0.1936, -0.2493, -0.1838,  0.0034,  0.1388, -0.0223,  0.0123,  0.0832,\n          0.1983, -0.1342, -0.1291, -0.0087,  0.1889,  0.1432, -0.2140, -0.0238],\n        [ 0.1774, -0.1554,  0.2192,  0.0462,  0.1333, -0.1840,  0.1449,  0.0108,\n          0.0691,  0.0140, -0.1644,  0.1616, -0.0289, -0.2438,  0.0045, -0.1543],\n        [-0.2231,  0.0892, -0.1508,  0.0589, -0.1635,  0.1701, -0.1010, -0.1749,\n          0.0526,  0.1623, -0.0944,  0.2366,  0.0307,  0.0516,  0.1384,  0.1516],\n        [ 0.2197,  0.0900, -0.0040,  0.1782,  0.1575,  0.2014,  0.2076, -0.1963,\n          0.2393,  0.2208, -0.1038,  0.0396, -0.2028,  0.0030,  0.1474, -0.0347],\n        [-0.0664,  0.2267, -0.0343, -0.0397,  0.2013,  0.1161, -0.1795, -0.0482,\n         -0.2321, -0.1239,  0.0248, -0.2446,  0.1358, -0.0246, -0.0861, -0.2224],\n        [ 0.1688,  0.0507,  0.0256,  0.0207,  0.1377,  0.0524, -0.1315,  0.1151,\n         -0.1983, -0.2130, -0.0511,  0.1285, -0.0145,  0.1174, -0.1359,  0.0142],\n        [ 0.2261, -0.2099, -0.0381,  0.2355,  0.0902,  0.0010,  0.0020,  0.0781,\n          0.1929, -0.2048, -0.0174,  0.1865, -0.0290, -0.0833, -0.0313, -0.0179]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2903, -0.0921, -0.1146, -0.1766], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0985, -0.1413,  0.3425, -0.1075, -0.0708, -0.0043,  0.1083, -0.1838],\n        [ 0.1843, -0.1983, -0.1018,  0.2923,  0.1630,  0.1231,  0.0287,  0.3436],\n        [ 0.1803, -0.3452,  0.2258, -0.1208,  0.0267,  0.1767,  0.0541, -0.1824],\n        [-0.1226, -0.3480,  0.1920, -0.2046, -0.1089,  0.2213,  0.1708,  0.1489]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	2,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x775b3db11ad0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s974610000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/lunar/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s974610000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}