{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s109630000"
    },
    "q_lr":	0.0005,
    "seed":	109630000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x124bd4c10>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 2.1455e-01, -2.2233e-01, -1.8258e-01, -3.2295e-02,  6.6067e-02,\n        -1.4629e-01, -3.9474e-02, -6.4134e-02,  1.4777e-01, -1.7388e-01,\n        -8.3250e-02, -1.6271e-01,  7.5288e-02,  2.6880e-02, -2.2107e-01,\n        -9.4357e-03, -4.4556e-02,  4.1903e-05,  8.0736e-02, -7.1275e-02,\n         1.6156e-01, -4.1075e-02, -2.6347e-02,  1.6092e-01, -2.1712e-01,\n         4.1662e-02,  1.9554e-01, -3.9559e-03,  1.1595e-01,  1.0092e-01,\n        -1.0995e-01, -1.5464e-01], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.4539e-01, -2.1605e-01,  1.7616e-01,  2.0662e-01,  1.2073e-01,\n         -5.5442e-02,  2.1750e-01,  5.8450e-02,  7.6680e-02,  1.2901e-01,\n          6.5793e-02,  2.0413e-01, -2.0021e-01, -1.8660e-02, -1.7179e-01,\n         -1.8034e-01, -4.0988e-03, -3.6654e-02, -6.8532e-02, -6.7005e-02],\n        [ 7.6497e-04,  6.3998e-02,  1.6821e-01, -1.2151e-01, -1.2306e-01,\n          1.1412e-01, -1.3276e-02, -1.8792e-01, -1.6429e-01,  1.9266e-01,\n         -2.1103e-01, -9.2789e-03, -1.6186e-01, -3.7130e-02, -1.9884e-01,\n          1.3393e-01, -5.0206e-02,  1.1296e-02,  1.6002e-01, -3.8762e-03],\n        [ 2.0184e-01,  2.2276e-01,  2.1409e-01,  1.9893e-01, -7.1970e-02,\n          9.7711e-02, -1.8009e-01, -9.6402e-02,  1.0099e-01, -6.0720e-02,\n         -7.2393e-02, -1.0101e-01,  1.6021e-01,  1.8900e-01, -1.3638e-02,\n         -3.5810e-02, -1.8790e-01,  1.2121e-01,  5.4000e-02,  4.7395e-02],\n        [-8.3144e-02, -2.1878e-01,  1.8114e-01, -2.3377e-02,  1.2612e-01,\n         -6.8912e-02, -6.5779e-02, -2.2125e-01,  1.5518e-01, -1.5730e-01,\n          7.4000e-02, -4.6061e-02, -1.9317e-01,  1.1501e-01,  1.9359e-01,\n          2.1039e-01, -1.0902e-01,  1.8215e-01,  9.9462e-03, -1.2161e-01],\n        [-1.6890e-01, -2.2249e-01, -1.6359e-01,  1.4387e-01,  1.5971e-01,\n          1.9862e-01, -1.2590e-01, -6.6459e-02,  4.3956e-02,  2.0154e-01,\n          2.0752e-01, -1.0278e-01,  1.7499e-01, -2.0990e-01, -1.4318e-01,\n          1.6438e-01,  1.8492e-01, -2.1780e-01,  8.8155e-02,  3.0546e-02],\n        [ 1.6275e-01,  1.9645e-01, -5.5402e-02,  1.7667e-01, -7.3365e-02,\n          1.5674e-01,  2.1140e-01, -8.2169e-02,  1.9610e-01,  1.0279e-01,\n          3.5983e-02, -2.0897e-01, -1.0619e-01, -6.6444e-02, -6.1091e-02,\n          1.1168e-01, -2.0605e-01, -7.5809e-02,  2.1301e-01,  1.2133e-01],\n        [ 8.8632e-03,  9.3092e-02,  1.4923e-01,  9.8794e-02, -1.3555e-02,\n         -6.0075e-03, -1.0803e-01,  1.5445e-02,  9.9214e-02, -6.0844e-02,\n          2.0902e-01,  1.8390e-01,  1.1996e-01, -1.4208e-02, -1.1261e-02,\n         -1.2324e-01,  1.7663e-01, -1.6573e-01, -1.4913e-01,  2.0661e-01],\n        [ 2.1008e-01, -2.1742e-01,  2.1943e-01, -8.7402e-03, -1.8935e-01,\n         -2.0752e-01, -1.8343e-01,  1.6132e-01,  9.9905e-02, -1.4696e-01,\n         -1.4303e-01,  1.2379e-01, -1.8434e-02, -1.4624e-01,  5.6464e-02,\n          6.0237e-02, -5.4360e-02,  1.1498e-01,  1.8013e-01, -2.0818e-01],\n        [ 5.1352e-02,  1.8254e-01,  1.0024e-02,  7.7761e-02, -1.5464e-02,\n         -1.2864e-01,  7.2675e-02, -1.8360e-02, -1.4144e-01, -1.1067e-01,\n         -4.7426e-02,  7.7766e-02, -1.6274e-01,  8.2860e-02, -9.6269e-02,\n          4.0532e-02,  4.3134e-02,  6.7562e-02, -7.2888e-02, -2.0308e-01],\n        [-2.2065e-01,  1.0185e-01, -1.8324e-01,  5.3244e-02, -5.2684e-02,\n         -1.0875e-01,  2.6583e-02, -2.1378e-01, -1.9793e-01, -1.6474e-01,\n         -1.5287e-01, -9.8037e-02,  1.8486e-02, -5.7566e-02,  1.2080e-01,\n         -1.3974e-01, -2.1731e-01, -1.1300e-01, -1.1133e-01,  3.1050e-02],\n        [ 2.4738e-02, -1.7604e-01,  9.9650e-02, -1.2752e-01, -2.1929e-02,\n          1.9456e-01,  1.7769e-01, -1.7199e-01,  1.8428e-01,  2.9712e-02,\n          1.2782e-01, -1.6882e-01,  1.7489e-01,  2.0665e-01, -1.4702e-01,\n          1.0950e-01,  2.7849e-02, -8.6951e-02, -1.0166e-01,  8.1230e-03],\n        [-1.9319e-01, -4.4838e-03,  4.0362e-02, -2.1964e-02, -9.7990e-02,\n         -3.2040e-02, -1.3314e-01, -1.2957e-02,  2.1274e-01,  8.0507e-02,\n         -9.2575e-02,  1.1426e-01,  7.9559e-02,  2.9703e-03, -2.0528e-01,\n         -1.1164e-01, -1.2359e-01, -1.4427e-01, -1.3535e-01, -7.5434e-02],\n        [ 1.3775e-01, -1.0471e-01,  1.1518e-03, -1.5108e-01,  2.1386e-01,\n          2.2229e-01,  1.6170e-01,  7.8395e-02, -2.1988e-01, -6.0627e-02,\n          4.0790e-02, -1.5570e-01,  4.5656e-02,  5.0955e-02, -8.3563e-03,\n          6.7382e-02, -6.0257e-02,  7.7342e-02,  9.8964e-02, -1.8450e-01],\n        [-1.1392e-02,  5.5454e-02,  9.0505e-04, -1.0976e-01, -1.8207e-01,\n          1.1445e-01,  1.0372e-02,  1.5288e-01, -1.8770e-01, -2.2848e-02,\n         -1.2089e-01,  2.1994e-01,  6.7795e-02,  3.5533e-02,  1.8278e-02,\n          2.6854e-02,  5.4043e-02, -1.0870e-01,  3.2555e-02,  1.9884e-01],\n        [ 1.8896e-01,  1.7582e-01,  1.6642e-01,  1.3532e-01,  5.2233e-02,\n          1.7969e-01, -1.7735e-01, -1.9858e-01,  1.1266e-02,  6.8683e-02,\n         -1.5785e-01,  1.4469e-01, -6.6530e-02, -2.1521e-01, -1.9041e-01,\n          8.4569e-02,  3.5544e-02, -1.4700e-01,  1.7509e-01, -1.8363e-01],\n        [ 2.7618e-02, -1.3438e-01,  4.6565e-02,  3.1791e-02, -7.0237e-02,\n          2.0025e-01, -6.4582e-02, -2.1351e-01, -1.6322e-01,  1.3731e-02,\n          4.1759e-02, -1.6242e-01, -2.2219e-01,  4.5381e-02,  1.6435e-01,\n         -2.1187e-01, -1.3807e-01,  1.2102e-02,  1.0704e-01,  2.1642e-01],\n        [-1.0756e-01,  1.8429e-01, -4.9638e-02,  1.2501e-01, -9.7447e-02,\n          2.9385e-02,  1.2690e-01,  2.0313e-02,  1.3804e-01,  9.7843e-03,\n          1.3753e-01,  1.7216e-01,  4.4356e-02,  1.7120e-01,  1.3301e-01,\n          1.7971e-01, -1.5868e-01, -2.1441e-01,  1.9806e-01, -7.1595e-02],\n        [-1.7865e-01, -1.1593e-02, -1.6870e-01, -8.8766e-03, -6.5377e-02,\n         -1.6227e-01,  2.0335e-01,  1.4390e-01,  1.8998e-01, -1.3886e-01,\n          2.6354e-02, -4.6876e-02,  1.7104e-01,  1.9703e-01, -1.4014e-02,\n          1.8599e-01, -2.1810e-01, -1.2330e-01,  1.6238e-01,  6.0625e-02],\n        [-7.6744e-02,  4.5472e-02,  2.1302e-02, -1.4794e-01,  3.3522e-02,\n         -1.4158e-01,  1.2903e-02,  9.1047e-02,  1.3661e-01,  1.3351e-01,\n         -1.9667e-01, -2.0927e-02, -1.1074e-01,  1.8766e-01, -6.9201e-02,\n         -1.0370e-02,  7.6992e-02, -5.1101e-02,  1.6167e-02,  1.1751e-01],\n        [ 8.9909e-02, -2.3252e-02,  2.5536e-02, -7.1117e-02, -1.2721e-01,\n         -1.8783e-01, -1.9608e-01,  1.0647e-01, -2.1306e-01,  1.4208e-01,\n          1.6912e-01, -5.1190e-04, -6.6156e-02, -5.1376e-02, -2.5752e-02,\n         -2.0856e-01, -1.0377e-01,  2.2276e-01, -9.3052e-02,  2.0410e-01],\n        [ 1.3809e-01,  1.3570e-01, -1.5664e-01,  8.0695e-02, -1.6308e-01,\n          1.5393e-01, -9.0193e-02, -1.1987e-01, -3.6609e-02, -6.8436e-02,\n         -1.4164e-01, -6.5596e-02, -2.6618e-02, -5.3337e-02,  1.1788e-01,\n          8.4903e-02, -3.4320e-02, -4.5662e-02,  4.2037e-02,  2.1386e-01],\n        [ 1.8624e-01,  9.1646e-02,  1.8231e-01, -9.6146e-02, -4.0659e-02,\n          1.2050e-01,  1.8762e-01,  2.2084e-01, -1.9159e-01, -1.3064e-01,\n          5.1449e-02, -8.5394e-02, -2.1706e-01, -1.7208e-01, -2.0332e-01,\n         -4.3670e-02,  1.2379e-01,  5.6135e-02, -2.1120e-01,  1.3082e-01],\n        [-2.1104e-01, -1.1078e-01,  1.9004e-01,  1.0623e-01, -3.2483e-02,\n         -1.0141e-01,  5.9721e-02, -1.6020e-01,  4.3407e-02, -9.3170e-02,\n         -2.0291e-01,  1.3396e-01,  1.7390e-01,  1.6877e-01, -1.4684e-01,\n         -1.6387e-02,  9.2890e-02,  1.1876e-01, -1.0273e-01, -1.0337e-01],\n        [-6.4113e-02,  1.0767e-01,  1.7226e-01,  1.8816e-01, -2.2048e-02,\n         -8.5757e-02,  1.5708e-01,  6.7629e-02,  1.7498e-01,  5.9103e-02,\n         -1.7964e-01,  4.6180e-02,  7.8910e-02, -2.1486e-01,  1.7614e-01,\n         -2.0374e-01,  8.7663e-02,  2.1092e-02, -1.8481e-01,  1.9116e-01],\n        [ 1.5539e-01,  1.3714e-01,  1.2812e-01,  1.6121e-01, -5.1214e-02,\n          1.3688e-01,  1.5487e-01,  2.5358e-02,  1.2489e-01, -1.0405e-01,\n         -2.0386e-01, -1.0021e-01, -6.4508e-02,  1.4722e-01,  8.3935e-03,\n         -2.5190e-02, -7.0804e-03,  8.9288e-02,  1.5792e-01, -1.9500e-01],\n        [ 9.0254e-02,  1.6928e-01, -1.1332e-01,  7.7508e-04,  2.1658e-01,\n          1.1969e-01,  1.8651e-01,  5.1707e-02,  8.6665e-02,  1.4970e-01,\n          1.9031e-01,  1.3379e-01, -7.5915e-02, -3.3205e-02, -1.8451e-01,\n          1.7311e-01, -7.3765e-02, -2.0441e-01, -1.5076e-01, -1.4362e-01],\n        [ 2.0142e-01,  5.9762e-02,  1.4969e-01, -1.5826e-01, -1.7725e-01,\n         -1.8305e-01,  1.9883e-01,  2.2117e-01,  8.5524e-02, -3.0039e-02,\n         -9.9895e-03, -1.6708e-01, -7.7178e-02, -1.8599e-01, -3.8541e-02,\n         -1.3615e-01, -1.7710e-03,  1.7913e-01, -1.7010e-01,  1.3029e-01],\n        [ 3.5055e-02,  1.1329e-01,  4.1070e-02, -2.0315e-01,  7.2385e-02,\n          8.7472e-03,  4.2647e-02,  1.6835e-01,  4.7756e-02,  1.5114e-02,\n         -1.6809e-01,  1.9683e-01, -1.5421e-01, -3.4954e-03, -4.4982e-02,\n          1.3236e-01, -2.1161e-01,  9.1501e-02, -8.9484e-02, -9.5877e-02],\n        [ 7.0728e-02,  1.5066e-01, -1.3853e-01, -1.6386e-01,  1.9754e-01,\n          1.6707e-01,  1.4857e-01,  1.0376e-01, -1.3301e-01, -1.2811e-01,\n         -1.5333e-01, -9.6584e-02, -7.4474e-02,  2.1385e-01, -7.1343e-02,\n         -1.5860e-01,  1.8500e-01, -1.9366e-02, -1.4941e-01,  8.2395e-02],\n        [-8.3736e-02, -5.5533e-02, -2.0344e-01, -1.3700e-01,  5.6591e-02,\n         -1.0521e-01,  1.0606e-01, -1.2498e-01, -1.6357e-01, -1.8681e-01,\n         -1.3822e-01,  1.5867e-01,  1.4620e-01, -1.8003e-01,  7.7791e-02,\n         -7.4901e-02, -1.7808e-01,  1.6704e-01,  1.8639e-01, -1.5211e-01],\n        [-1.3571e-01, -2.1844e-01, -7.0068e-02, -1.5394e-01,  2.1255e-01,\n         -1.8672e-01, -9.4328e-02, -1.1742e-01,  2.1477e-01,  1.6197e-01,\n          1.8885e-01,  9.7209e-02,  1.2870e-01,  7.4625e-02,  2.9716e-02,\n          7.2746e-02, -1.6596e-01, -1.4250e-02,  1.0928e-01,  2.2886e-02],\n        [-5.8974e-02, -8.2588e-02,  4.7049e-02, -4.3319e-02, -1.9693e-04,\n         -5.3691e-02,  5.0260e-02,  1.0180e-01, -3.9489e-02,  1.3321e-01,\n         -1.8001e-01,  1.2625e-02,  1.5711e-01, -2.1258e-02, -6.2015e-02,\n         -6.5773e-02,  1.1561e-01, -2.0297e-01, -2.1990e-01,  1.6668e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0915, -0.0125, -0.0444,  0.1466,  0.0501, -0.1712,  0.1040,  0.0043,\n         0.0622,  0.1540,  0.1651,  0.1344,  0.0806, -0.1225,  0.0591, -0.0450],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0985,  0.0195, -0.1277,  0.1747, -0.1472, -0.0656, -0.1360,  0.0693,\n         -0.1387, -0.1040, -0.1706, -0.1226, -0.0852, -0.0314, -0.0571, -0.0004,\n          0.1754, -0.0897, -0.0584, -0.0775,  0.0268,  0.0799,  0.1340, -0.0013,\n         -0.1120, -0.0036,  0.1197, -0.0789,  0.1371, -0.0863,  0.0831, -0.1680],\n        [ 0.0458,  0.0511,  0.0622, -0.0253,  0.0282, -0.1603,  0.0340, -0.0921,\n         -0.0186, -0.1449, -0.1666, -0.0174,  0.0775, -0.0396,  0.0662,  0.0993,\n         -0.0204,  0.0142,  0.1623,  0.0514,  0.0539,  0.0021,  0.1550, -0.1245,\n          0.1176, -0.0311, -0.0630, -0.0389, -0.1054, -0.0234,  0.0474, -0.0926],\n        [ 0.1326, -0.0848,  0.0291,  0.1633, -0.1070,  0.0016, -0.0503, -0.1480,\n         -0.0350,  0.1214, -0.1161, -0.1767,  0.1627,  0.1653, -0.1115,  0.0908,\n         -0.1739,  0.0054,  0.0475, -0.0771, -0.1284, -0.1190, -0.1721,  0.0642,\n         -0.0063, -0.1358, -0.0639,  0.0859,  0.0564, -0.1282,  0.1521, -0.1076],\n        [ 0.1381, -0.0795,  0.1254,  0.0166, -0.0889,  0.0153,  0.0733,  0.0158,\n         -0.1696,  0.1600,  0.0231,  0.0598,  0.0223,  0.0008, -0.1691,  0.0542,\n          0.1362,  0.0814,  0.0150,  0.0885, -0.1052,  0.0419,  0.1345,  0.1667,\n          0.0517, -0.1626,  0.0309, -0.1703, -0.1487,  0.0535, -0.0497,  0.1584],\n        [ 0.0255,  0.1230, -0.0496,  0.1576, -0.1323, -0.1299,  0.1111, -0.1747,\n          0.0280, -0.1218, -0.1267, -0.1668,  0.0131, -0.0721, -0.0483, -0.0433,\n         -0.1339,  0.0066, -0.1083,  0.0850,  0.1741, -0.1498, -0.0268,  0.1726,\n          0.0614,  0.1227, -0.1235, -0.1216,  0.0283, -0.0730, -0.0136,  0.1494],\n        [-0.0906,  0.0082,  0.1459, -0.1360, -0.0030, -0.1740, -0.1650, -0.0136,\n          0.0431,  0.1007,  0.1056,  0.0487,  0.0923, -0.1294,  0.1048,  0.1010,\n          0.0104, -0.0329,  0.0013, -0.0554,  0.0760,  0.0111, -0.0821,  0.1220,\n          0.0584,  0.0543, -0.1539, -0.0356,  0.1311,  0.1222, -0.0589,  0.0058],\n        [-0.1275, -0.1736,  0.0341,  0.0887, -0.0858,  0.1574, -0.0390, -0.0747,\n          0.0059, -0.0903, -0.0254,  0.1554, -0.0610, -0.0317,  0.1224, -0.1158,\n         -0.0655,  0.1351, -0.0672, -0.0206,  0.0039,  0.1414, -0.0518,  0.1262,\n         -0.0424,  0.1767,  0.1342,  0.1339,  0.0728, -0.1404, -0.0594,  0.0748],\n        [-0.0271, -0.0409,  0.0550,  0.0625,  0.0955, -0.1460, -0.0929, -0.1181,\n         -0.1067, -0.1547, -0.0401, -0.1212, -0.0892, -0.0589, -0.0553,  0.1073,\n          0.0692, -0.0316,  0.0135,  0.0344,  0.0418,  0.1221, -0.0963, -0.0652,\n         -0.1134,  0.0670, -0.1178, -0.0863,  0.1727,  0.0963,  0.0182, -0.1577],\n        [-0.1305, -0.0694, -0.0007, -0.0233, -0.0376, -0.1383, -0.1434, -0.0652,\n          0.1293,  0.1726,  0.0940,  0.0388, -0.0915, -0.1149, -0.1306, -0.0514,\n         -0.0400,  0.0947,  0.0068,  0.1721, -0.1446,  0.0192,  0.0213, -0.0578,\n          0.0009, -0.1686, -0.0203,  0.1073,  0.1024,  0.0220, -0.1426, -0.0738],\n        [-0.1656,  0.1539, -0.0421,  0.0051,  0.0458, -0.0986, -0.1185, -0.0256,\n         -0.0428,  0.1459,  0.0357,  0.0224, -0.0370,  0.0751,  0.0180,  0.1116,\n          0.0344, -0.0830, -0.1750, -0.0405,  0.0187, -0.1370, -0.1439, -0.1624,\n         -0.0558, -0.0076, -0.1640,  0.1638,  0.1110,  0.1587,  0.0787, -0.0146],\n        [-0.1426,  0.0413,  0.0633,  0.0908, -0.0302,  0.1334, -0.1562, -0.0057,\n         -0.1362, -0.0672,  0.1670,  0.0913,  0.1160,  0.0257, -0.1703, -0.0682,\n          0.0371,  0.0320, -0.1145,  0.0523,  0.0297,  0.1767,  0.0739, -0.0621,\n         -0.1176,  0.1528, -0.0465, -0.0583, -0.1747,  0.0718, -0.0673,  0.1302],\n        [ 0.1321,  0.0059,  0.1162, -0.1011,  0.1126,  0.0230, -0.0229, -0.0498,\n         -0.1476,  0.1705,  0.0089, -0.0291,  0.0726, -0.0989,  0.0684, -0.1524,\n          0.1285,  0.0985,  0.0801, -0.1220,  0.0535,  0.1119, -0.0755,  0.1759,\n          0.1170, -0.1666,  0.0847,  0.0738, -0.0459,  0.1268, -0.0955,  0.1320],\n        [-0.0087, -0.0688, -0.0987, -0.1258,  0.0204,  0.1360,  0.0999,  0.0659,\n          0.0693,  0.1214,  0.1655,  0.0195, -0.0094,  0.0845, -0.0909,  0.1484,\n          0.0685,  0.1724, -0.1623,  0.1415, -0.0488, -0.1712,  0.0628,  0.1041,\n          0.1674, -0.0237, -0.1155,  0.1494,  0.0925,  0.0902,  0.0019,  0.0929],\n        [-0.1082,  0.0129, -0.1748, -0.0146,  0.0796,  0.1255, -0.1650,  0.0513,\n         -0.1661, -0.0208, -0.1149,  0.1582,  0.0492, -0.1093,  0.1402,  0.0225,\n         -0.0085, -0.0589, -0.1477, -0.1023, -0.1276,  0.1417, -0.1662,  0.0018,\n          0.1066, -0.1520, -0.1367,  0.0925,  0.0216,  0.0837,  0.0783,  0.1492],\n        [-0.1465,  0.1060, -0.0395, -0.0565, -0.0141, -0.0055, -0.0546, -0.0668,\n         -0.1747,  0.1072, -0.0367,  0.0543, -0.1385, -0.1027, -0.1004, -0.0078,\n          0.0947, -0.1227, -0.0077,  0.1119, -0.0995,  0.1415,  0.0341, -0.0929,\n         -0.0827,  0.1707, -0.0210, -0.1113, -0.1032,  0.0514,  0.0659,  0.1209],\n        [-0.1245, -0.0255, -0.0818, -0.1663,  0.0118, -0.0564,  0.1475,  0.1425,\n          0.0696, -0.0467, -0.0751,  0.0270, -0.0909,  0.0854, -0.1372, -0.0340,\n         -0.0117, -0.1395, -0.0828, -0.0623, -0.1069,  0.0091,  0.0740,  0.1717,\n          0.0762,  0.1180, -0.1704,  0.1094,  0.1451,  0.1705, -0.0978, -0.1512]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1559, -0.1472,  0.2318,  0.2464,  0.1365, -0.2313,  0.0682, -0.1093],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1635,  0.2255,  0.1648, -0.0205,  0.1252,  0.1498, -0.1908,  0.1908,\n         -0.1924,  0.2177,  0.0844, -0.1603, -0.1365,  0.0453,  0.0122,  0.1726],\n        [ 0.1035,  0.0511, -0.2424, -0.0143, -0.2232,  0.2243,  0.1662, -0.0103,\n          0.2200,  0.1657,  0.1169, -0.0620,  0.2496, -0.0950,  0.0679,  0.0708],\n        [-0.2114, -0.1368, -0.0839,  0.0525,  0.0174, -0.0861, -0.1627, -0.1712,\n          0.0257,  0.2437, -0.1988, -0.2268, -0.1958,  0.1988,  0.1053, -0.0040],\n        [ 0.0904, -0.0483,  0.0679,  0.0461, -0.1929,  0.0209, -0.0347, -0.2030,\n          0.0948, -0.1055,  0.0845, -0.0556,  0.1574,  0.0524,  0.0236,  0.1873],\n        [-0.0182,  0.1122, -0.1973,  0.0545, -0.2494,  0.1190,  0.0689, -0.1450,\n         -0.0355, -0.0446,  0.0484, -0.0820,  0.1335,  0.0218, -0.0595,  0.1619],\n        [-0.2360, -0.1513, -0.0720,  0.0878, -0.0521, -0.2115, -0.0566,  0.2492,\n          0.0347,  0.0794,  0.1596,  0.0348,  0.2403, -0.1412, -0.0422,  0.1611],\n        [-0.1471, -0.0897, -0.1321,  0.0799,  0.0848,  0.1334, -0.2265,  0.0687,\n         -0.1339, -0.1804,  0.2313, -0.1334,  0.1611,  0.0257,  0.2490,  0.2360],\n        [-0.2082, -0.1084, -0.2051, -0.0939,  0.0923, -0.0646, -0.0885,  0.2493,\n         -0.0386,  0.0280, -0.0328, -0.1268,  0.0708,  0.0798, -0.1215,  0.1624]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1834], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2347,  0.3504, -0.0522, -0.3469,  0.0716,  0.0758, -0.1920, -0.0114]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 1.4539e-01, -2.1605e-01,  1.7616e-01,  2.0662e-01,  1.2073e-01,\n         -5.5442e-02,  2.1750e-01,  5.8450e-02,  7.6680e-02,  1.2901e-01,\n          6.5793e-02,  2.0413e-01, -2.0021e-01, -1.8660e-02, -1.7179e-01,\n         -1.8034e-01, -4.0988e-03, -3.6654e-02, -6.8532e-02, -6.7005e-02],\n        [ 7.6497e-04,  6.3998e-02,  1.6821e-01, -1.2151e-01, -1.2306e-01,\n          1.1412e-01, -1.3276e-02, -1.8792e-01, -1.6429e-01,  1.9266e-01,\n         -2.1103e-01, -9.2789e-03, -1.6186e-01, -3.7130e-02, -1.9884e-01,\n          1.3393e-01, -5.0206e-02,  1.1296e-02,  1.6002e-01, -3.8762e-03],\n        [ 2.0184e-01,  2.2276e-01,  2.1409e-01,  1.9893e-01, -7.1970e-02,\n          9.7711e-02, -1.8009e-01, -9.6402e-02,  1.0099e-01, -6.0720e-02,\n         -7.2393e-02, -1.0101e-01,  1.6021e-01,  1.8900e-01, -1.3638e-02,\n         -3.5810e-02, -1.8790e-01,  1.2121e-01,  5.4000e-02,  4.7395e-02],\n        [-8.3144e-02, -2.1878e-01,  1.8114e-01, -2.3377e-02,  1.2612e-01,\n         -6.8912e-02, -6.5779e-02, -2.2125e-01,  1.5518e-01, -1.5730e-01,\n          7.4000e-02, -4.6061e-02, -1.9317e-01,  1.1501e-01,  1.9359e-01,\n          2.1039e-01, -1.0902e-01,  1.8215e-01,  9.9462e-03, -1.2161e-01],\n        [-1.6890e-01, -2.2249e-01, -1.6359e-01,  1.4387e-01,  1.5971e-01,\n          1.9862e-01, -1.2590e-01, -6.6459e-02,  4.3956e-02,  2.0154e-01,\n          2.0752e-01, -1.0278e-01,  1.7499e-01, -2.0990e-01, -1.4318e-01,\n          1.6438e-01,  1.8492e-01, -2.1780e-01,  8.8155e-02,  3.0546e-02],\n        [ 1.6275e-01,  1.9645e-01, -5.5402e-02,  1.7667e-01, -7.3365e-02,\n          1.5674e-01,  2.1140e-01, -8.2169e-02,  1.9610e-01,  1.0279e-01,\n          3.5983e-02, -2.0897e-01, -1.0619e-01, -6.6444e-02, -6.1091e-02,\n          1.1168e-01, -2.0605e-01, -7.5809e-02,  2.1301e-01,  1.2133e-01],\n        [ 8.8632e-03,  9.3092e-02,  1.4923e-01,  9.8794e-02, -1.3555e-02,\n         -6.0075e-03, -1.0803e-01,  1.5445e-02,  9.9214e-02, -6.0844e-02,\n          2.0902e-01,  1.8390e-01,  1.1996e-01, -1.4208e-02, -1.1261e-02,\n         -1.2324e-01,  1.7663e-01, -1.6573e-01, -1.4913e-01,  2.0661e-01],\n        [ 2.1008e-01, -2.1742e-01,  2.1943e-01, -8.7402e-03, -1.8935e-01,\n         -2.0752e-01, -1.8343e-01,  1.6132e-01,  9.9905e-02, -1.4696e-01,\n         -1.4303e-01,  1.2379e-01, -1.8434e-02, -1.4624e-01,  5.6464e-02,\n          6.0237e-02, -5.4360e-02,  1.1498e-01,  1.8013e-01, -2.0818e-01],\n        [ 5.1352e-02,  1.8254e-01,  1.0024e-02,  7.7761e-02, -1.5464e-02,\n         -1.2864e-01,  7.2675e-02, -1.8360e-02, -1.4144e-01, -1.1067e-01,\n         -4.7426e-02,  7.7766e-02, -1.6274e-01,  8.2860e-02, -9.6269e-02,\n          4.0532e-02,  4.3134e-02,  6.7562e-02, -7.2888e-02, -2.0308e-01],\n        [-2.2065e-01,  1.0185e-01, -1.8324e-01,  5.3244e-02, -5.2684e-02,\n         -1.0875e-01,  2.6583e-02, -2.1378e-01, -1.9793e-01, -1.6474e-01,\n         -1.5287e-01, -9.8037e-02,  1.8486e-02, -5.7566e-02,  1.2080e-01,\n         -1.3974e-01, -2.1731e-01, -1.1300e-01, -1.1133e-01,  3.1050e-02],\n        [ 2.4738e-02, -1.7604e-01,  9.9650e-02, -1.2752e-01, -2.1929e-02,\n          1.9456e-01,  1.7769e-01, -1.7199e-01,  1.8428e-01,  2.9712e-02,\n          1.2782e-01, -1.6882e-01,  1.7489e-01,  2.0665e-01, -1.4702e-01,\n          1.0950e-01,  2.7849e-02, -8.6951e-02, -1.0166e-01,  8.1230e-03],\n        [-1.9319e-01, -4.4838e-03,  4.0362e-02, -2.1964e-02, -9.7990e-02,\n         -3.2040e-02, -1.3314e-01, -1.2957e-02,  2.1274e-01,  8.0507e-02,\n         -9.2575e-02,  1.1426e-01,  7.9559e-02,  2.9703e-03, -2.0528e-01,\n         -1.1164e-01, -1.2359e-01, -1.4427e-01, -1.3535e-01, -7.5434e-02],\n        [ 1.3775e-01, -1.0471e-01,  1.1518e-03, -1.5108e-01,  2.1386e-01,\n          2.2229e-01,  1.6170e-01,  7.8395e-02, -2.1988e-01, -6.0627e-02,\n          4.0790e-02, -1.5570e-01,  4.5656e-02,  5.0955e-02, -8.3563e-03,\n          6.7382e-02, -6.0257e-02,  7.7342e-02,  9.8964e-02, -1.8450e-01],\n        [-1.1392e-02,  5.5454e-02,  9.0505e-04, -1.0976e-01, -1.8207e-01,\n          1.1445e-01,  1.0372e-02,  1.5288e-01, -1.8770e-01, -2.2848e-02,\n         -1.2089e-01,  2.1994e-01,  6.7795e-02,  3.5533e-02,  1.8278e-02,\n          2.6854e-02,  5.4043e-02, -1.0870e-01,  3.2555e-02,  1.9884e-01],\n        [ 1.8896e-01,  1.7582e-01,  1.6642e-01,  1.3532e-01,  5.2233e-02,\n          1.7969e-01, -1.7735e-01, -1.9858e-01,  1.1266e-02,  6.8683e-02,\n         -1.5785e-01,  1.4469e-01, -6.6530e-02, -2.1521e-01, -1.9041e-01,\n          8.4569e-02,  3.5544e-02, -1.4700e-01,  1.7509e-01, -1.8363e-01],\n        [ 2.7618e-02, -1.3438e-01,  4.6565e-02,  3.1791e-02, -7.0237e-02,\n          2.0025e-01, -6.4582e-02, -2.1351e-01, -1.6322e-01,  1.3731e-02,\n          4.1759e-02, -1.6242e-01, -2.2219e-01,  4.5381e-02,  1.6435e-01,\n         -2.1187e-01, -1.3807e-01,  1.2102e-02,  1.0704e-01,  2.1642e-01],\n        [-1.0756e-01,  1.8429e-01, -4.9638e-02,  1.2501e-01, -9.7447e-02,\n          2.9385e-02,  1.2690e-01,  2.0313e-02,  1.3804e-01,  9.7843e-03,\n          1.3753e-01,  1.7216e-01,  4.4356e-02,  1.7120e-01,  1.3301e-01,\n          1.7971e-01, -1.5868e-01, -2.1441e-01,  1.9806e-01, -7.1595e-02],\n        [-1.7865e-01, -1.1593e-02, -1.6870e-01, -8.8766e-03, -6.5377e-02,\n         -1.6227e-01,  2.0335e-01,  1.4390e-01,  1.8998e-01, -1.3886e-01,\n          2.6354e-02, -4.6876e-02,  1.7104e-01,  1.9703e-01, -1.4014e-02,\n          1.8599e-01, -2.1810e-01, -1.2330e-01,  1.6238e-01,  6.0625e-02],\n        [-7.6744e-02,  4.5472e-02,  2.1302e-02, -1.4794e-01,  3.3522e-02,\n         -1.4158e-01,  1.2903e-02,  9.1047e-02,  1.3661e-01,  1.3351e-01,\n         -1.9667e-01, -2.0927e-02, -1.1074e-01,  1.8766e-01, -6.9201e-02,\n         -1.0370e-02,  7.6992e-02, -5.1101e-02,  1.6167e-02,  1.1751e-01],\n        [ 8.9909e-02, -2.3252e-02,  2.5536e-02, -7.1117e-02, -1.2721e-01,\n         -1.8783e-01, -1.9608e-01,  1.0647e-01, -2.1306e-01,  1.4208e-01,\n          1.6912e-01, -5.1190e-04, -6.6156e-02, -5.1376e-02, -2.5752e-02,\n         -2.0856e-01, -1.0377e-01,  2.2276e-01, -9.3052e-02,  2.0410e-01],\n        [ 1.3809e-01,  1.3570e-01, -1.5664e-01,  8.0695e-02, -1.6308e-01,\n          1.5393e-01, -9.0193e-02, -1.1987e-01, -3.6609e-02, -6.8436e-02,\n         -1.4164e-01, -6.5596e-02, -2.6618e-02, -5.3337e-02,  1.1788e-01,\n          8.4903e-02, -3.4320e-02, -4.5662e-02,  4.2037e-02,  2.1386e-01],\n        [ 1.8624e-01,  9.1646e-02,  1.8231e-01, -9.6146e-02, -4.0659e-02,\n          1.2050e-01,  1.8762e-01,  2.2084e-01, -1.9159e-01, -1.3064e-01,\n          5.1449e-02, -8.5394e-02, -2.1706e-01, -1.7208e-01, -2.0332e-01,\n         -4.3670e-02,  1.2379e-01,  5.6135e-02, -2.1120e-01,  1.3082e-01],\n        [-2.1104e-01, -1.1078e-01,  1.9004e-01,  1.0623e-01, -3.2483e-02,\n         -1.0141e-01,  5.9721e-02, -1.6020e-01,  4.3407e-02, -9.3170e-02,\n         -2.0291e-01,  1.3396e-01,  1.7390e-01,  1.6877e-01, -1.4684e-01,\n         -1.6387e-02,  9.2890e-02,  1.1876e-01, -1.0273e-01, -1.0337e-01],\n        [-6.4113e-02,  1.0767e-01,  1.7226e-01,  1.8816e-01, -2.2048e-02,\n         -8.5757e-02,  1.5708e-01,  6.7629e-02,  1.7498e-01,  5.9103e-02,\n         -1.7964e-01,  4.6180e-02,  7.8910e-02, -2.1486e-01,  1.7614e-01,\n         -2.0374e-01,  8.7663e-02,  2.1092e-02, -1.8481e-01,  1.9116e-01],\n        [ 1.5539e-01,  1.3714e-01,  1.2812e-01,  1.6121e-01, -5.1214e-02,\n          1.3688e-01,  1.5487e-01,  2.5358e-02,  1.2489e-01, -1.0405e-01,\n         -2.0386e-01, -1.0021e-01, -6.4508e-02,  1.4722e-01,  8.3935e-03,\n         -2.5190e-02, -7.0804e-03,  8.9288e-02,  1.5792e-01, -1.9500e-01],\n        [ 9.0254e-02,  1.6928e-01, -1.1332e-01,  7.7508e-04,  2.1658e-01,\n          1.1969e-01,  1.8651e-01,  5.1707e-02,  8.6665e-02,  1.4970e-01,\n          1.9031e-01,  1.3379e-01, -7.5915e-02, -3.3205e-02, -1.8451e-01,\n          1.7311e-01, -7.3765e-02, -2.0441e-01, -1.5076e-01, -1.4362e-01],\n        [ 2.0142e-01,  5.9762e-02,  1.4969e-01, -1.5826e-01, -1.7725e-01,\n         -1.8305e-01,  1.9883e-01,  2.2117e-01,  8.5524e-02, -3.0039e-02,\n         -9.9895e-03, -1.6708e-01, -7.7178e-02, -1.8599e-01, -3.8541e-02,\n         -1.3615e-01, -1.7710e-03,  1.7913e-01, -1.7010e-01,  1.3029e-01],\n        [ 3.5055e-02,  1.1329e-01,  4.1070e-02, -2.0315e-01,  7.2385e-02,\n          8.7472e-03,  4.2647e-02,  1.6835e-01,  4.7756e-02,  1.5114e-02,\n         -1.6809e-01,  1.9683e-01, -1.5421e-01, -3.4954e-03, -4.4982e-02,\n          1.3236e-01, -2.1161e-01,  9.1501e-02, -8.9484e-02, -9.5877e-02],\n        [ 7.0728e-02,  1.5066e-01, -1.3853e-01, -1.6386e-01,  1.9754e-01,\n          1.6707e-01,  1.4857e-01,  1.0376e-01, -1.3301e-01, -1.2811e-01,\n         -1.5333e-01, -9.6584e-02, -7.4474e-02,  2.1385e-01, -7.1343e-02,\n         -1.5860e-01,  1.8500e-01, -1.9366e-02, -1.4941e-01,  8.2395e-02],\n        [-8.3736e-02, -5.5533e-02, -2.0344e-01, -1.3700e-01,  5.6591e-02,\n         -1.0521e-01,  1.0606e-01, -1.2498e-01, -1.6357e-01, -1.8681e-01,\n         -1.3822e-01,  1.5867e-01,  1.4620e-01, -1.8003e-01,  7.7791e-02,\n         -7.4901e-02, -1.7808e-01,  1.6704e-01,  1.8639e-01, -1.5211e-01],\n        [-1.3571e-01, -2.1844e-01, -7.0068e-02, -1.5394e-01,  2.1255e-01,\n         -1.8672e-01, -9.4328e-02, -1.1742e-01,  2.1477e-01,  1.6197e-01,\n          1.8885e-01,  9.7209e-02,  1.2870e-01,  7.4625e-02,  2.9716e-02,\n          7.2746e-02, -1.6596e-01, -1.4250e-02,  1.0928e-01,  2.2886e-02],\n        [-5.8974e-02, -8.2588e-02,  4.7049e-02, -4.3319e-02, -1.9693e-04,\n         -5.3691e-02,  5.0260e-02,  1.0180e-01, -3.9489e-02,  1.3321e-01,\n         -1.8001e-01,  1.2625e-02,  1.5711e-01, -2.1258e-02, -6.2015e-02,\n         -6.5773e-02,  1.1561e-01, -2.0297e-01, -2.1990e-01,  1.6668e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 2.1455e-01, -2.2233e-01, -1.8258e-01, -3.2295e-02,  6.6067e-02,\n        -1.4629e-01, -3.9474e-02, -6.4134e-02,  1.4777e-01, -1.7388e-01,\n        -8.3250e-02, -1.6271e-01,  7.5288e-02,  2.6880e-02, -2.2107e-01,\n        -9.4357e-03, -4.4556e-02,  4.1903e-05,  8.0736e-02, -7.1275e-02,\n         1.6156e-01, -4.1075e-02, -2.6347e-02,  1.6092e-01, -2.1712e-01,\n         4.1662e-02,  1.9554e-01, -3.9559e-03,  1.1595e-01,  1.0092e-01,\n        -1.0995e-01, -1.5464e-01], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0985,  0.0195, -0.1277,  0.1747, -0.1472, -0.0656, -0.1360,  0.0693,\n         -0.1387, -0.1040, -0.1706, -0.1226, -0.0852, -0.0314, -0.0571, -0.0004,\n          0.1754, -0.0897, -0.0584, -0.0775,  0.0268,  0.0799,  0.1340, -0.0013,\n         -0.1120, -0.0036,  0.1197, -0.0789,  0.1371, -0.0863,  0.0831, -0.1680],\n        [ 0.0458,  0.0511,  0.0622, -0.0253,  0.0282, -0.1603,  0.0340, -0.0921,\n         -0.0186, -0.1449, -0.1666, -0.0174,  0.0775, -0.0396,  0.0662,  0.0993,\n         -0.0204,  0.0142,  0.1623,  0.0514,  0.0539,  0.0021,  0.1550, -0.1245,\n          0.1176, -0.0311, -0.0630, -0.0389, -0.1054, -0.0234,  0.0474, -0.0926],\n        [ 0.1326, -0.0848,  0.0291,  0.1633, -0.1070,  0.0016, -0.0503, -0.1480,\n         -0.0350,  0.1214, -0.1161, -0.1767,  0.1627,  0.1653, -0.1115,  0.0908,\n         -0.1739,  0.0054,  0.0475, -0.0771, -0.1284, -0.1190, -0.1721,  0.0642,\n         -0.0063, -0.1358, -0.0639,  0.0859,  0.0564, -0.1282,  0.1521, -0.1076],\n        [ 0.1381, -0.0795,  0.1254,  0.0166, -0.0889,  0.0153,  0.0733,  0.0158,\n         -0.1696,  0.1600,  0.0231,  0.0598,  0.0223,  0.0008, -0.1691,  0.0542,\n          0.1362,  0.0814,  0.0150,  0.0885, -0.1052,  0.0419,  0.1345,  0.1667,\n          0.0517, -0.1626,  0.0309, -0.1703, -0.1487,  0.0535, -0.0497,  0.1584],\n        [ 0.0255,  0.1230, -0.0496,  0.1576, -0.1323, -0.1299,  0.1111, -0.1747,\n          0.0280, -0.1218, -0.1267, -0.1668,  0.0131, -0.0721, -0.0483, -0.0433,\n         -0.1339,  0.0066, -0.1083,  0.0850,  0.1741, -0.1498, -0.0268,  0.1726,\n          0.0614,  0.1227, -0.1235, -0.1216,  0.0283, -0.0730, -0.0136,  0.1494],\n        [-0.0906,  0.0082,  0.1459, -0.1360, -0.0030, -0.1740, -0.1650, -0.0136,\n          0.0431,  0.1007,  0.1056,  0.0487,  0.0923, -0.1294,  0.1048,  0.1010,\n          0.0104, -0.0329,  0.0013, -0.0554,  0.0760,  0.0111, -0.0821,  0.1220,\n          0.0584,  0.0543, -0.1539, -0.0356,  0.1311,  0.1222, -0.0589,  0.0058],\n        [-0.1275, -0.1736,  0.0341,  0.0887, -0.0858,  0.1574, -0.0390, -0.0747,\n          0.0059, -0.0903, -0.0254,  0.1554, -0.0610, -0.0317,  0.1224, -0.1158,\n         -0.0655,  0.1351, -0.0672, -0.0206,  0.0039,  0.1414, -0.0518,  0.1262,\n         -0.0424,  0.1767,  0.1342,  0.1339,  0.0728, -0.1404, -0.0594,  0.0748],\n        [-0.0271, -0.0409,  0.0550,  0.0625,  0.0955, -0.1460, -0.0929, -0.1181,\n         -0.1067, -0.1547, -0.0401, -0.1212, -0.0892, -0.0589, -0.0553,  0.1073,\n          0.0692, -0.0316,  0.0135,  0.0344,  0.0418,  0.1221, -0.0963, -0.0652,\n         -0.1134,  0.0670, -0.1178, -0.0863,  0.1727,  0.0963,  0.0182, -0.1577],\n        [-0.1305, -0.0694, -0.0007, -0.0233, -0.0376, -0.1383, -0.1434, -0.0652,\n          0.1293,  0.1726,  0.0940,  0.0388, -0.0915, -0.1149, -0.1306, -0.0514,\n         -0.0400,  0.0947,  0.0068,  0.1721, -0.1446,  0.0192,  0.0213, -0.0578,\n          0.0009, -0.1686, -0.0203,  0.1073,  0.1024,  0.0220, -0.1426, -0.0738],\n        [-0.1656,  0.1539, -0.0421,  0.0051,  0.0458, -0.0986, -0.1185, -0.0256,\n         -0.0428,  0.1459,  0.0357,  0.0224, -0.0370,  0.0751,  0.0180,  0.1116,\n          0.0344, -0.0830, -0.1750, -0.0405,  0.0187, -0.1370, -0.1439, -0.1624,\n         -0.0558, -0.0076, -0.1640,  0.1638,  0.1110,  0.1587,  0.0787, -0.0146],\n        [-0.1426,  0.0413,  0.0633,  0.0908, -0.0302,  0.1334, -0.1562, -0.0057,\n         -0.1362, -0.0672,  0.1670,  0.0913,  0.1160,  0.0257, -0.1703, -0.0682,\n          0.0371,  0.0320, -0.1145,  0.0523,  0.0297,  0.1767,  0.0739, -0.0621,\n         -0.1176,  0.1528, -0.0465, -0.0583, -0.1747,  0.0718, -0.0673,  0.1302],\n        [ 0.1321,  0.0059,  0.1162, -0.1011,  0.1126,  0.0230, -0.0229, -0.0498,\n         -0.1476,  0.1705,  0.0089, -0.0291,  0.0726, -0.0989,  0.0684, -0.1524,\n          0.1285,  0.0985,  0.0801, -0.1220,  0.0535,  0.1119, -0.0755,  0.1759,\n          0.1170, -0.1666,  0.0847,  0.0738, -0.0459,  0.1268, -0.0955,  0.1320],\n        [-0.0087, -0.0688, -0.0987, -0.1258,  0.0204,  0.1360,  0.0999,  0.0659,\n          0.0693,  0.1214,  0.1655,  0.0195, -0.0094,  0.0845, -0.0909,  0.1484,\n          0.0685,  0.1724, -0.1623,  0.1415, -0.0488, -0.1712,  0.0628,  0.1041,\n          0.1674, -0.0237, -0.1155,  0.1494,  0.0925,  0.0902,  0.0019,  0.0929],\n        [-0.1082,  0.0129, -0.1748, -0.0146,  0.0796,  0.1255, -0.1650,  0.0513,\n         -0.1661, -0.0208, -0.1149,  0.1582,  0.0492, -0.1093,  0.1402,  0.0225,\n         -0.0085, -0.0589, -0.1477, -0.1023, -0.1276,  0.1417, -0.1662,  0.0018,\n          0.1066, -0.1520, -0.1367,  0.0925,  0.0216,  0.0837,  0.0783,  0.1492],\n        [-0.1465,  0.1060, -0.0395, -0.0565, -0.0141, -0.0055, -0.0546, -0.0668,\n         -0.1747,  0.1072, -0.0367,  0.0543, -0.1385, -0.1027, -0.1004, -0.0078,\n          0.0947, -0.1227, -0.0077,  0.1119, -0.0995,  0.1415,  0.0341, -0.0929,\n         -0.0827,  0.1707, -0.0210, -0.1113, -0.1032,  0.0514,  0.0659,  0.1209],\n        [-0.1245, -0.0255, -0.0818, -0.1663,  0.0118, -0.0564,  0.1475,  0.1425,\n          0.0696, -0.0467, -0.0751,  0.0270, -0.0909,  0.0854, -0.1372, -0.0340,\n         -0.0117, -0.1395, -0.0828, -0.0623, -0.1069,  0.0091,  0.0740,  0.1717,\n          0.0762,  0.1180, -0.1704,  0.1094,  0.1451,  0.1705, -0.0978, -0.1512]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0915, -0.0125, -0.0444,  0.1466,  0.0501, -0.1712,  0.1040,  0.0043,\n         0.0622,  0.1540,  0.1651,  0.1344,  0.0806, -0.1225,  0.0591, -0.0450],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1635,  0.2255,  0.1648, -0.0205,  0.1252,  0.1498, -0.1908,  0.1908,\n         -0.1924,  0.2177,  0.0844, -0.1603, -0.1365,  0.0453,  0.0122,  0.1726],\n        [ 0.1035,  0.0511, -0.2424, -0.0143, -0.2232,  0.2243,  0.1662, -0.0103,\n          0.2200,  0.1657,  0.1169, -0.0620,  0.2496, -0.0950,  0.0679,  0.0708],\n        [-0.2114, -0.1368, -0.0839,  0.0525,  0.0174, -0.0861, -0.1627, -0.1712,\n          0.0257,  0.2437, -0.1988, -0.2268, -0.1958,  0.1988,  0.1053, -0.0040],\n        [ 0.0904, -0.0483,  0.0679,  0.0461, -0.1929,  0.0209, -0.0347, -0.2030,\n          0.0948, -0.1055,  0.0845, -0.0556,  0.1574,  0.0524,  0.0236,  0.1873],\n        [-0.0182,  0.1122, -0.1973,  0.0545, -0.2494,  0.1190,  0.0689, -0.1450,\n         -0.0355, -0.0446,  0.0484, -0.0820,  0.1335,  0.0218, -0.0595,  0.1619],\n        [-0.2360, -0.1513, -0.0720,  0.0878, -0.0521, -0.2115, -0.0566,  0.2492,\n          0.0347,  0.0794,  0.1596,  0.0348,  0.2403, -0.1412, -0.0422,  0.1611],\n        [-0.1471, -0.0897, -0.1321,  0.0799,  0.0848,  0.1334, -0.2265,  0.0687,\n         -0.1339, -0.1804,  0.2313, -0.1334,  0.1611,  0.0257,  0.2490,  0.2360],\n        [-0.2082, -0.1084, -0.2051, -0.0939,  0.0923, -0.0646, -0.0885,  0.2493,\n         -0.0386,  0.0280, -0.0328, -0.1268,  0.0708,  0.0798, -0.1215,  0.1624]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1559, -0.1472,  0.2318,  0.2464,  0.1365, -0.2313,  0.0682, -0.1093],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2347,  0.3504, -0.0522, -0.3469,  0.0716,  0.0758, -0.1920, -0.0114]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1834], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x114592260>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 2.1455e-01, -2.2233e-01, -1.8258e-01, -3.2295e-02,  6.6067e-02,\n        -1.4629e-01, -3.9474e-02, -6.4134e-02,  1.4777e-01, -1.7388e-01,\n        -8.3250e-02, -1.6271e-01,  7.5288e-02,  2.6880e-02, -2.2107e-01,\n        -9.4357e-03, -4.4556e-02,  4.1903e-05,  8.0736e-02, -7.1275e-02,\n         1.6156e-01, -4.1075e-02, -2.6347e-02,  1.6092e-01, -2.1712e-01,\n         4.1662e-02,  1.9554e-01, -3.9559e-03,  1.1595e-01,  1.0092e-01,\n        -1.0995e-01, -1.5464e-01], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.4539e-01, -2.1605e-01,  1.7616e-01,  2.0662e-01,  1.2073e-01,\n         -5.5442e-02,  2.1750e-01,  5.8450e-02,  7.6680e-02,  1.2901e-01,\n          6.5793e-02,  2.0413e-01, -2.0021e-01, -1.8660e-02, -1.7179e-01,\n         -1.8034e-01, -4.0988e-03, -3.6654e-02, -6.8532e-02, -6.7005e-02],\n        [ 7.6497e-04,  6.3998e-02,  1.6821e-01, -1.2151e-01, -1.2306e-01,\n          1.1412e-01, -1.3276e-02, -1.8792e-01, -1.6429e-01,  1.9266e-01,\n         -2.1103e-01, -9.2789e-03, -1.6186e-01, -3.7130e-02, -1.9884e-01,\n          1.3393e-01, -5.0206e-02,  1.1296e-02,  1.6002e-01, -3.8762e-03],\n        [ 2.0184e-01,  2.2276e-01,  2.1409e-01,  1.9893e-01, -7.1970e-02,\n          9.7711e-02, -1.8009e-01, -9.6402e-02,  1.0099e-01, -6.0720e-02,\n         -7.2393e-02, -1.0101e-01,  1.6021e-01,  1.8900e-01, -1.3638e-02,\n         -3.5810e-02, -1.8790e-01,  1.2121e-01,  5.4000e-02,  4.7395e-02],\n        [-8.3144e-02, -2.1878e-01,  1.8114e-01, -2.3377e-02,  1.2612e-01,\n         -6.8912e-02, -6.5779e-02, -2.2125e-01,  1.5518e-01, -1.5730e-01,\n          7.4000e-02, -4.6061e-02, -1.9317e-01,  1.1501e-01,  1.9359e-01,\n          2.1039e-01, -1.0902e-01,  1.8215e-01,  9.9462e-03, -1.2161e-01],\n        [-1.6890e-01, -2.2249e-01, -1.6359e-01,  1.4387e-01,  1.5971e-01,\n          1.9862e-01, -1.2590e-01, -6.6459e-02,  4.3956e-02,  2.0154e-01,\n          2.0752e-01, -1.0278e-01,  1.7499e-01, -2.0990e-01, -1.4318e-01,\n          1.6438e-01,  1.8492e-01, -2.1780e-01,  8.8155e-02,  3.0546e-02],\n        [ 1.6275e-01,  1.9645e-01, -5.5402e-02,  1.7667e-01, -7.3365e-02,\n          1.5674e-01,  2.1140e-01, -8.2169e-02,  1.9610e-01,  1.0279e-01,\n          3.5983e-02, -2.0897e-01, -1.0619e-01, -6.6444e-02, -6.1091e-02,\n          1.1168e-01, -2.0605e-01, -7.5809e-02,  2.1301e-01,  1.2133e-01],\n        [ 8.8632e-03,  9.3092e-02,  1.4923e-01,  9.8794e-02, -1.3555e-02,\n         -6.0075e-03, -1.0803e-01,  1.5445e-02,  9.9214e-02, -6.0844e-02,\n          2.0902e-01,  1.8390e-01,  1.1996e-01, -1.4208e-02, -1.1261e-02,\n         -1.2324e-01,  1.7663e-01, -1.6573e-01, -1.4913e-01,  2.0661e-01],\n        [ 2.1008e-01, -2.1742e-01,  2.1943e-01, -8.7402e-03, -1.8935e-01,\n         -2.0752e-01, -1.8343e-01,  1.6132e-01,  9.9905e-02, -1.4696e-01,\n         -1.4303e-01,  1.2379e-01, -1.8434e-02, -1.4624e-01,  5.6464e-02,\n          6.0237e-02, -5.4360e-02,  1.1498e-01,  1.8013e-01, -2.0818e-01],\n        [ 5.1352e-02,  1.8254e-01,  1.0024e-02,  7.7761e-02, -1.5464e-02,\n         -1.2864e-01,  7.2675e-02, -1.8360e-02, -1.4144e-01, -1.1067e-01,\n         -4.7426e-02,  7.7766e-02, -1.6274e-01,  8.2860e-02, -9.6269e-02,\n          4.0532e-02,  4.3134e-02,  6.7562e-02, -7.2888e-02, -2.0308e-01],\n        [-2.2065e-01,  1.0185e-01, -1.8324e-01,  5.3244e-02, -5.2684e-02,\n         -1.0875e-01,  2.6583e-02, -2.1378e-01, -1.9793e-01, -1.6474e-01,\n         -1.5287e-01, -9.8037e-02,  1.8486e-02, -5.7566e-02,  1.2080e-01,\n         -1.3974e-01, -2.1731e-01, -1.1300e-01, -1.1133e-01,  3.1050e-02],\n        [ 2.4738e-02, -1.7604e-01,  9.9650e-02, -1.2752e-01, -2.1929e-02,\n          1.9456e-01,  1.7769e-01, -1.7199e-01,  1.8428e-01,  2.9712e-02,\n          1.2782e-01, -1.6882e-01,  1.7489e-01,  2.0665e-01, -1.4702e-01,\n          1.0950e-01,  2.7849e-02, -8.6951e-02, -1.0166e-01,  8.1230e-03],\n        [-1.9319e-01, -4.4838e-03,  4.0362e-02, -2.1964e-02, -9.7990e-02,\n         -3.2040e-02, -1.3314e-01, -1.2957e-02,  2.1274e-01,  8.0507e-02,\n         -9.2575e-02,  1.1426e-01,  7.9559e-02,  2.9703e-03, -2.0528e-01,\n         -1.1164e-01, -1.2359e-01, -1.4427e-01, -1.3535e-01, -7.5434e-02],\n        [ 1.3775e-01, -1.0471e-01,  1.1518e-03, -1.5108e-01,  2.1386e-01,\n          2.2229e-01,  1.6170e-01,  7.8395e-02, -2.1988e-01, -6.0627e-02,\n          4.0790e-02, -1.5570e-01,  4.5656e-02,  5.0955e-02, -8.3563e-03,\n          6.7382e-02, -6.0257e-02,  7.7342e-02,  9.8964e-02, -1.8450e-01],\n        [-1.1392e-02,  5.5454e-02,  9.0505e-04, -1.0976e-01, -1.8207e-01,\n          1.1445e-01,  1.0372e-02,  1.5288e-01, -1.8770e-01, -2.2848e-02,\n         -1.2089e-01,  2.1994e-01,  6.7795e-02,  3.5533e-02,  1.8278e-02,\n          2.6854e-02,  5.4043e-02, -1.0870e-01,  3.2555e-02,  1.9884e-01],\n        [ 1.8896e-01,  1.7582e-01,  1.6642e-01,  1.3532e-01,  5.2233e-02,\n          1.7969e-01, -1.7735e-01, -1.9858e-01,  1.1266e-02,  6.8683e-02,\n         -1.5785e-01,  1.4469e-01, -6.6530e-02, -2.1521e-01, -1.9041e-01,\n          8.4569e-02,  3.5544e-02, -1.4700e-01,  1.7509e-01, -1.8363e-01],\n        [ 2.7618e-02, -1.3438e-01,  4.6565e-02,  3.1791e-02, -7.0237e-02,\n          2.0025e-01, -6.4582e-02, -2.1351e-01, -1.6322e-01,  1.3731e-02,\n          4.1759e-02, -1.6242e-01, -2.2219e-01,  4.5381e-02,  1.6435e-01,\n         -2.1187e-01, -1.3807e-01,  1.2102e-02,  1.0704e-01,  2.1642e-01],\n        [-1.0756e-01,  1.8429e-01, -4.9638e-02,  1.2501e-01, -9.7447e-02,\n          2.9385e-02,  1.2690e-01,  2.0313e-02,  1.3804e-01,  9.7843e-03,\n          1.3753e-01,  1.7216e-01,  4.4356e-02,  1.7120e-01,  1.3301e-01,\n          1.7971e-01, -1.5868e-01, -2.1441e-01,  1.9806e-01, -7.1595e-02],\n        [-1.7865e-01, -1.1593e-02, -1.6870e-01, -8.8766e-03, -6.5377e-02,\n         -1.6227e-01,  2.0335e-01,  1.4390e-01,  1.8998e-01, -1.3886e-01,\n          2.6354e-02, -4.6876e-02,  1.7104e-01,  1.9703e-01, -1.4014e-02,\n          1.8599e-01, -2.1810e-01, -1.2330e-01,  1.6238e-01,  6.0625e-02],\n        [-7.6744e-02,  4.5472e-02,  2.1302e-02, -1.4794e-01,  3.3522e-02,\n         -1.4158e-01,  1.2903e-02,  9.1047e-02,  1.3661e-01,  1.3351e-01,\n         -1.9667e-01, -2.0927e-02, -1.1074e-01,  1.8766e-01, -6.9201e-02,\n         -1.0370e-02,  7.6992e-02, -5.1101e-02,  1.6167e-02,  1.1751e-01],\n        [ 8.9909e-02, -2.3252e-02,  2.5536e-02, -7.1117e-02, -1.2721e-01,\n         -1.8783e-01, -1.9608e-01,  1.0647e-01, -2.1306e-01,  1.4208e-01,\n          1.6912e-01, -5.1190e-04, -6.6156e-02, -5.1376e-02, -2.5752e-02,\n         -2.0856e-01, -1.0377e-01,  2.2276e-01, -9.3052e-02,  2.0410e-01],\n        [ 1.3809e-01,  1.3570e-01, -1.5664e-01,  8.0695e-02, -1.6308e-01,\n          1.5393e-01, -9.0193e-02, -1.1987e-01, -3.6609e-02, -6.8436e-02,\n         -1.4164e-01, -6.5596e-02, -2.6618e-02, -5.3337e-02,  1.1788e-01,\n          8.4903e-02, -3.4320e-02, -4.5662e-02,  4.2037e-02,  2.1386e-01],\n        [ 1.8624e-01,  9.1646e-02,  1.8231e-01, -9.6146e-02, -4.0659e-02,\n          1.2050e-01,  1.8762e-01,  2.2084e-01, -1.9159e-01, -1.3064e-01,\n          5.1449e-02, -8.5394e-02, -2.1706e-01, -1.7208e-01, -2.0332e-01,\n         -4.3670e-02,  1.2379e-01,  5.6135e-02, -2.1120e-01,  1.3082e-01],\n        [-2.1104e-01, -1.1078e-01,  1.9004e-01,  1.0623e-01, -3.2483e-02,\n         -1.0141e-01,  5.9721e-02, -1.6020e-01,  4.3407e-02, -9.3170e-02,\n         -2.0291e-01,  1.3396e-01,  1.7390e-01,  1.6877e-01, -1.4684e-01,\n         -1.6387e-02,  9.2890e-02,  1.1876e-01, -1.0273e-01, -1.0337e-01],\n        [-6.4113e-02,  1.0767e-01,  1.7226e-01,  1.8816e-01, -2.2048e-02,\n         -8.5757e-02,  1.5708e-01,  6.7629e-02,  1.7498e-01,  5.9103e-02,\n         -1.7964e-01,  4.6180e-02,  7.8910e-02, -2.1486e-01,  1.7614e-01,\n         -2.0374e-01,  8.7663e-02,  2.1092e-02, -1.8481e-01,  1.9116e-01],\n        [ 1.5539e-01,  1.3714e-01,  1.2812e-01,  1.6121e-01, -5.1214e-02,\n          1.3688e-01,  1.5487e-01,  2.5358e-02,  1.2489e-01, -1.0405e-01,\n         -2.0386e-01, -1.0021e-01, -6.4508e-02,  1.4722e-01,  8.3935e-03,\n         -2.5190e-02, -7.0804e-03,  8.9288e-02,  1.5792e-01, -1.9500e-01],\n        [ 9.0254e-02,  1.6928e-01, -1.1332e-01,  7.7508e-04,  2.1658e-01,\n          1.1969e-01,  1.8651e-01,  5.1707e-02,  8.6665e-02,  1.4970e-01,\n          1.9031e-01,  1.3379e-01, -7.5915e-02, -3.3205e-02, -1.8451e-01,\n          1.7311e-01, -7.3765e-02, -2.0441e-01, -1.5076e-01, -1.4362e-01],\n        [ 2.0142e-01,  5.9762e-02,  1.4969e-01, -1.5826e-01, -1.7725e-01,\n         -1.8305e-01,  1.9883e-01,  2.2117e-01,  8.5524e-02, -3.0039e-02,\n         -9.9895e-03, -1.6708e-01, -7.7178e-02, -1.8599e-01, -3.8541e-02,\n         -1.3615e-01, -1.7710e-03,  1.7913e-01, -1.7010e-01,  1.3029e-01],\n        [ 3.5055e-02,  1.1329e-01,  4.1070e-02, -2.0315e-01,  7.2385e-02,\n          8.7472e-03,  4.2647e-02,  1.6835e-01,  4.7756e-02,  1.5114e-02,\n         -1.6809e-01,  1.9683e-01, -1.5421e-01, -3.4954e-03, -4.4982e-02,\n          1.3236e-01, -2.1161e-01,  9.1501e-02, -8.9484e-02, -9.5877e-02],\n        [ 7.0728e-02,  1.5066e-01, -1.3853e-01, -1.6386e-01,  1.9754e-01,\n          1.6707e-01,  1.4857e-01,  1.0376e-01, -1.3301e-01, -1.2811e-01,\n         -1.5333e-01, -9.6584e-02, -7.4474e-02,  2.1385e-01, -7.1343e-02,\n         -1.5860e-01,  1.8500e-01, -1.9366e-02, -1.4941e-01,  8.2395e-02],\n        [-8.3736e-02, -5.5533e-02, -2.0344e-01, -1.3700e-01,  5.6591e-02,\n         -1.0521e-01,  1.0606e-01, -1.2498e-01, -1.6357e-01, -1.8681e-01,\n         -1.3822e-01,  1.5867e-01,  1.4620e-01, -1.8003e-01,  7.7791e-02,\n         -7.4901e-02, -1.7808e-01,  1.6704e-01,  1.8639e-01, -1.5211e-01],\n        [-1.3571e-01, -2.1844e-01, -7.0068e-02, -1.5394e-01,  2.1255e-01,\n         -1.8672e-01, -9.4328e-02, -1.1742e-01,  2.1477e-01,  1.6197e-01,\n          1.8885e-01,  9.7209e-02,  1.2870e-01,  7.4625e-02,  2.9716e-02,\n          7.2746e-02, -1.6596e-01, -1.4250e-02,  1.0928e-01,  2.2886e-02],\n        [-5.8974e-02, -8.2588e-02,  4.7049e-02, -4.3319e-02, -1.9693e-04,\n         -5.3691e-02,  5.0260e-02,  1.0180e-01, -3.9489e-02,  1.3321e-01,\n         -1.8001e-01,  1.2625e-02,  1.5711e-01, -2.1258e-02, -6.2015e-02,\n         -6.5773e-02,  1.1561e-01, -2.0297e-01, -2.1990e-01,  1.6668e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0915, -0.0125, -0.0444,  0.1466,  0.0501, -0.1712,  0.1040,  0.0043,\n         0.0622,  0.1540,  0.1651,  0.1344,  0.0806, -0.1225,  0.0591, -0.0450],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0985,  0.0195, -0.1277,  0.1747, -0.1472, -0.0656, -0.1360,  0.0693,\n         -0.1387, -0.1040, -0.1706, -0.1226, -0.0852, -0.0314, -0.0571, -0.0004,\n          0.1754, -0.0897, -0.0584, -0.0775,  0.0268,  0.0799,  0.1340, -0.0013,\n         -0.1120, -0.0036,  0.1197, -0.0789,  0.1371, -0.0863,  0.0831, -0.1680],\n        [ 0.0458,  0.0511,  0.0622, -0.0253,  0.0282, -0.1603,  0.0340, -0.0921,\n         -0.0186, -0.1449, -0.1666, -0.0174,  0.0775, -0.0396,  0.0662,  0.0993,\n         -0.0204,  0.0142,  0.1623,  0.0514,  0.0539,  0.0021,  0.1550, -0.1245,\n          0.1176, -0.0311, -0.0630, -0.0389, -0.1054, -0.0234,  0.0474, -0.0926],\n        [ 0.1326, -0.0848,  0.0291,  0.1633, -0.1070,  0.0016, -0.0503, -0.1480,\n         -0.0350,  0.1214, -0.1161, -0.1767,  0.1627,  0.1653, -0.1115,  0.0908,\n         -0.1739,  0.0054,  0.0475, -0.0771, -0.1284, -0.1190, -0.1721,  0.0642,\n         -0.0063, -0.1358, -0.0639,  0.0859,  0.0564, -0.1282,  0.1521, -0.1076],\n        [ 0.1381, -0.0795,  0.1254,  0.0166, -0.0889,  0.0153,  0.0733,  0.0158,\n         -0.1696,  0.1600,  0.0231,  0.0598,  0.0223,  0.0008, -0.1691,  0.0542,\n          0.1362,  0.0814,  0.0150,  0.0885, -0.1052,  0.0419,  0.1345,  0.1667,\n          0.0517, -0.1626,  0.0309, -0.1703, -0.1487,  0.0535, -0.0497,  0.1584],\n        [ 0.0255,  0.1230, -0.0496,  0.1576, -0.1323, -0.1299,  0.1111, -0.1747,\n          0.0280, -0.1218, -0.1267, -0.1668,  0.0131, -0.0721, -0.0483, -0.0433,\n         -0.1339,  0.0066, -0.1083,  0.0850,  0.1741, -0.1498, -0.0268,  0.1726,\n          0.0614,  0.1227, -0.1235, -0.1216,  0.0283, -0.0730, -0.0136,  0.1494],\n        [-0.0906,  0.0082,  0.1459, -0.1360, -0.0030, -0.1740, -0.1650, -0.0136,\n          0.0431,  0.1007,  0.1056,  0.0487,  0.0923, -0.1294,  0.1048,  0.1010,\n          0.0104, -0.0329,  0.0013, -0.0554,  0.0760,  0.0111, -0.0821,  0.1220,\n          0.0584,  0.0543, -0.1539, -0.0356,  0.1311,  0.1222, -0.0589,  0.0058],\n        [-0.1275, -0.1736,  0.0341,  0.0887, -0.0858,  0.1574, -0.0390, -0.0747,\n          0.0059, -0.0903, -0.0254,  0.1554, -0.0610, -0.0317,  0.1224, -0.1158,\n         -0.0655,  0.1351, -0.0672, -0.0206,  0.0039,  0.1414, -0.0518,  0.1262,\n         -0.0424,  0.1767,  0.1342,  0.1339,  0.0728, -0.1404, -0.0594,  0.0748],\n        [-0.0271, -0.0409,  0.0550,  0.0625,  0.0955, -0.1460, -0.0929, -0.1181,\n         -0.1067, -0.1547, -0.0401, -0.1212, -0.0892, -0.0589, -0.0553,  0.1073,\n          0.0692, -0.0316,  0.0135,  0.0344,  0.0418,  0.1221, -0.0963, -0.0652,\n         -0.1134,  0.0670, -0.1178, -0.0863,  0.1727,  0.0963,  0.0182, -0.1577],\n        [-0.1305, -0.0694, -0.0007, -0.0233, -0.0376, -0.1383, -0.1434, -0.0652,\n          0.1293,  0.1726,  0.0940,  0.0388, -0.0915, -0.1149, -0.1306, -0.0514,\n         -0.0400,  0.0947,  0.0068,  0.1721, -0.1446,  0.0192,  0.0213, -0.0578,\n          0.0009, -0.1686, -0.0203,  0.1073,  0.1024,  0.0220, -0.1426, -0.0738],\n        [-0.1656,  0.1539, -0.0421,  0.0051,  0.0458, -0.0986, -0.1185, -0.0256,\n         -0.0428,  0.1459,  0.0357,  0.0224, -0.0370,  0.0751,  0.0180,  0.1116,\n          0.0344, -0.0830, -0.1750, -0.0405,  0.0187, -0.1370, -0.1439, -0.1624,\n         -0.0558, -0.0076, -0.1640,  0.1638,  0.1110,  0.1587,  0.0787, -0.0146],\n        [-0.1426,  0.0413,  0.0633,  0.0908, -0.0302,  0.1334, -0.1562, -0.0057,\n         -0.1362, -0.0672,  0.1670,  0.0913,  0.1160,  0.0257, -0.1703, -0.0682,\n          0.0371,  0.0320, -0.1145,  0.0523,  0.0297,  0.1767,  0.0739, -0.0621,\n         -0.1176,  0.1528, -0.0465, -0.0583, -0.1747,  0.0718, -0.0673,  0.1302],\n        [ 0.1321,  0.0059,  0.1162, -0.1011,  0.1126,  0.0230, -0.0229, -0.0498,\n         -0.1476,  0.1705,  0.0089, -0.0291,  0.0726, -0.0989,  0.0684, -0.1524,\n          0.1285,  0.0985,  0.0801, -0.1220,  0.0535,  0.1119, -0.0755,  0.1759,\n          0.1170, -0.1666,  0.0847,  0.0738, -0.0459,  0.1268, -0.0955,  0.1320],\n        [-0.0087, -0.0688, -0.0987, -0.1258,  0.0204,  0.1360,  0.0999,  0.0659,\n          0.0693,  0.1214,  0.1655,  0.0195, -0.0094,  0.0845, -0.0909,  0.1484,\n          0.0685,  0.1724, -0.1623,  0.1415, -0.0488, -0.1712,  0.0628,  0.1041,\n          0.1674, -0.0237, -0.1155,  0.1494,  0.0925,  0.0902,  0.0019,  0.0929],\n        [-0.1082,  0.0129, -0.1748, -0.0146,  0.0796,  0.1255, -0.1650,  0.0513,\n         -0.1661, -0.0208, -0.1149,  0.1582,  0.0492, -0.1093,  0.1402,  0.0225,\n         -0.0085, -0.0589, -0.1477, -0.1023, -0.1276,  0.1417, -0.1662,  0.0018,\n          0.1066, -0.1520, -0.1367,  0.0925,  0.0216,  0.0837,  0.0783,  0.1492],\n        [-0.1465,  0.1060, -0.0395, -0.0565, -0.0141, -0.0055, -0.0546, -0.0668,\n         -0.1747,  0.1072, -0.0367,  0.0543, -0.1385, -0.1027, -0.1004, -0.0078,\n          0.0947, -0.1227, -0.0077,  0.1119, -0.0995,  0.1415,  0.0341, -0.0929,\n         -0.0827,  0.1707, -0.0210, -0.1113, -0.1032,  0.0514,  0.0659,  0.1209],\n        [-0.1245, -0.0255, -0.0818, -0.1663,  0.0118, -0.0564,  0.1475,  0.1425,\n          0.0696, -0.0467, -0.0751,  0.0270, -0.0909,  0.0854, -0.1372, -0.0340,\n         -0.0117, -0.1395, -0.0828, -0.0623, -0.1069,  0.0091,  0.0740,  0.1717,\n          0.0762,  0.1180, -0.1704,  0.1094,  0.1451,  0.1705, -0.0978, -0.1512]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1559, -0.1472,  0.2318,  0.2464,  0.1365, -0.2313,  0.0682, -0.1093],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1635,  0.2255,  0.1648, -0.0205,  0.1252,  0.1498, -0.1908,  0.1908,\n         -0.1924,  0.2177,  0.0844, -0.1603, -0.1365,  0.0453,  0.0122,  0.1726],\n        [ 0.1035,  0.0511, -0.2424, -0.0143, -0.2232,  0.2243,  0.1662, -0.0103,\n          0.2200,  0.1657,  0.1169, -0.0620,  0.2496, -0.0950,  0.0679,  0.0708],\n        [-0.2114, -0.1368, -0.0839,  0.0525,  0.0174, -0.0861, -0.1627, -0.1712,\n          0.0257,  0.2437, -0.1988, -0.2268, -0.1958,  0.1988,  0.1053, -0.0040],\n        [ 0.0904, -0.0483,  0.0679,  0.0461, -0.1929,  0.0209, -0.0347, -0.2030,\n          0.0948, -0.1055,  0.0845, -0.0556,  0.1574,  0.0524,  0.0236,  0.1873],\n        [-0.0182,  0.1122, -0.1973,  0.0545, -0.2494,  0.1190,  0.0689, -0.1450,\n         -0.0355, -0.0446,  0.0484, -0.0820,  0.1335,  0.0218, -0.0595,  0.1619],\n        [-0.2360, -0.1513, -0.0720,  0.0878, -0.0521, -0.2115, -0.0566,  0.2492,\n          0.0347,  0.0794,  0.1596,  0.0348,  0.2403, -0.1412, -0.0422,  0.1611],\n        [-0.1471, -0.0897, -0.1321,  0.0799,  0.0848,  0.1334, -0.2265,  0.0687,\n         -0.1339, -0.1804,  0.2313, -0.1334,  0.1611,  0.0257,  0.2490,  0.2360],\n        [-0.2082, -0.1084, -0.2051, -0.0939,  0.0923, -0.0646, -0.0885,  0.2493,\n         -0.0386,  0.0280, -0.0328, -0.1268,  0.0708,  0.0798, -0.1215,  0.1624]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1834], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2347,  0.3504, -0.0522, -0.3469,  0.0716,  0.0758, -0.1920, -0.0114]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_frequency":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x124bd4580>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s109630000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s109630000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_frequency":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}