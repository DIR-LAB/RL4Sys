{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s16800000"
    },
    "q_lr":	0.0005,
    "seed":	16800000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000001D008ADE680>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0600, -0.2016, -0.0226, -0.0695, -0.0671, -0.1522, -0.0181,  0.2150,\n        -0.2007, -0.0822,  0.2128, -0.2032, -0.1759,  0.2145, -0.1482, -0.1417,\n         0.2183, -0.0090,  0.1738,  0.1533,  0.1841, -0.0543, -0.0006, -0.2150,\n        -0.0665, -0.1308, -0.0494, -0.0768,  0.1242,  0.1671,  0.1142, -0.1142],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2178, -0.1092, -0.0764, -0.1144,  0.0541,  0.0433, -0.2218,  0.0676,\n         -0.2154,  0.0427,  0.1721,  0.0530,  0.2076,  0.0296,  0.1279,  0.1180,\n          0.1916, -0.0363,  0.0024, -0.2126],\n        [-0.1106,  0.1124,  0.1629, -0.0656,  0.1262,  0.2127,  0.1629, -0.1783,\n          0.1195,  0.1957, -0.1976,  0.0432, -0.1107,  0.0134, -0.2059,  0.1366,\n         -0.2037,  0.0098, -0.1000,  0.1377],\n        [ 0.2197, -0.1367, -0.1407,  0.0021, -0.1824, -0.0667,  0.0272, -0.0320,\n          0.0648,  0.0085,  0.0316,  0.1021,  0.1862, -0.0309,  0.1038, -0.0698,\n          0.0244, -0.1803, -0.1892,  0.1526],\n        [-0.0528, -0.1468,  0.1261,  0.0797, -0.0881,  0.0009, -0.1185, -0.2017,\n          0.0797, -0.1343,  0.0548,  0.0810,  0.1068, -0.0775, -0.1548, -0.1823,\n          0.0013, -0.0453,  0.0186, -0.1932],\n        [ 0.1334,  0.0646,  0.2129, -0.1230,  0.0873,  0.1359,  0.0756,  0.0701,\n          0.0349, -0.1262,  0.1055,  0.0216, -0.1786, -0.1124, -0.1385,  0.0496,\n          0.1431, -0.1645,  0.2190, -0.0203],\n        [ 0.1781,  0.1135,  0.1149,  0.1572,  0.0626,  0.1492, -0.0257,  0.0588,\n          0.0721,  0.1759, -0.0421, -0.1805,  0.1630,  0.0673,  0.1082,  0.1155,\n         -0.1678,  0.1003,  0.1226, -0.2177],\n        [-0.1132,  0.0960,  0.1438,  0.1104, -0.2146, -0.0278,  0.1949, -0.1400,\n          0.1996,  0.0135,  0.0073, -0.0691,  0.1043,  0.1189, -0.0323,  0.0908,\n          0.0890, -0.0657, -0.1937,  0.1638],\n        [ 0.1800,  0.0648, -0.0680,  0.0252,  0.1962,  0.0967, -0.1100,  0.0594,\n         -0.2146,  0.0085,  0.1449,  0.0830, -0.1126, -0.0238, -0.1802, -0.1415,\n         -0.1550, -0.1402, -0.0446, -0.0153],\n        [-0.2186,  0.1100,  0.1242, -0.0358,  0.0697, -0.1568,  0.0752,  0.0412,\n          0.1415,  0.1979, -0.0788,  0.1040,  0.1525,  0.1505, -0.1087,  0.1896,\n          0.0746,  0.0115, -0.0486, -0.1156],\n        [ 0.0957,  0.1991, -0.2099, -0.1675,  0.1143,  0.1683, -0.1872, -0.2149,\n          0.1940, -0.1688, -0.1259,  0.1421,  0.0621,  0.1612,  0.1661, -0.0997,\n          0.1814, -0.1739,  0.1601, -0.2164],\n        [-0.0089, -0.1692,  0.1734,  0.1179, -0.1774, -0.1245, -0.0414,  0.1223,\n          0.0729, -0.0890, -0.1507, -0.0671, -0.0749, -0.0385, -0.1928,  0.1262,\n          0.0817, -0.1818,  0.0837, -0.0253],\n        [-0.0773,  0.2078,  0.1026,  0.0297,  0.1056, -0.1845, -0.1406,  0.0958,\n          0.0465, -0.0696,  0.1835, -0.2170,  0.1538,  0.0541, -0.1429,  0.2120,\n         -0.1030,  0.0761,  0.0400, -0.1677],\n        [ 0.0011, -0.1509,  0.1616,  0.1149, -0.1553, -0.1398,  0.1683, -0.1685,\n         -0.1946, -0.1433,  0.1417, -0.0740,  0.0329, -0.0995,  0.0466, -0.0115,\n          0.1933,  0.0709, -0.0074, -0.0765],\n        [-0.1831, -0.1793, -0.0931, -0.1729, -0.0263,  0.0298,  0.1214,  0.2166,\n         -0.0776,  0.0561, -0.1917,  0.0575, -0.0454, -0.0872, -0.0155,  0.1693,\n         -0.1677,  0.1757,  0.0842, -0.0649],\n        [ 0.0228,  0.0011, -0.1955,  0.0196,  0.0462,  0.2224,  0.0639, -0.0851,\n          0.0635,  0.1033, -0.1722,  0.0401, -0.0174, -0.0751,  0.0512,  0.2227,\n          0.0851, -0.0468,  0.0151, -0.0688],\n        [-0.2136,  0.1984, -0.1130, -0.0085, -0.0622, -0.1023, -0.1729, -0.0820,\n          0.0704, -0.0872,  0.1663, -0.1543,  0.1886,  0.0531, -0.1461, -0.0294,\n         -0.0591, -0.0396, -0.0162,  0.2162],\n        [ 0.1175,  0.0920, -0.1497,  0.0004, -0.2042, -0.0110, -0.1500,  0.1920,\n          0.0270, -0.0434,  0.0731, -0.1976,  0.1749, -0.0483, -0.1234,  0.2038,\n         -0.2186, -0.1878, -0.2153, -0.0303],\n        [ 0.2045, -0.0043,  0.1910,  0.1516,  0.0500,  0.2171,  0.0085,  0.1552,\n          0.0458, -0.0810, -0.1416,  0.1928,  0.0347,  0.2129,  0.1746,  0.0764,\n         -0.0198,  0.0606,  0.2187, -0.0803],\n        [ 0.0901,  0.1789,  0.1265,  0.1381, -0.0867, -0.1907, -0.0845,  0.0719,\n         -0.0572,  0.0333, -0.0320, -0.1353, -0.1311,  0.1383,  0.2044,  0.1319,\n         -0.1924, -0.1578,  0.1743,  0.0767],\n        [-0.1555, -0.1465,  0.1101, -0.0926,  0.1823, -0.0773, -0.1158, -0.1469,\n          0.1201,  0.0412, -0.1686, -0.1333, -0.0644, -0.1139,  0.1396, -0.0249,\n         -0.0963, -0.0889,  0.1416, -0.0887],\n        [-0.1113, -0.1065, -0.1096,  0.0591, -0.0325,  0.0464, -0.1257,  0.1767,\n         -0.0506,  0.2233, -0.0608, -0.1556,  0.1273, -0.0215, -0.2193, -0.1270,\n         -0.0540, -0.0908,  0.1109,  0.0654],\n        [ 0.0538,  0.1105,  0.1064, -0.2191,  0.0396, -0.0224,  0.0443,  0.0187,\n          0.0287, -0.0979, -0.1089,  0.1137, -0.1306, -0.2089, -0.1724,  0.1812,\n         -0.1706, -0.0148,  0.0682, -0.0761],\n        [-0.1085,  0.0719,  0.1114, -0.0974, -0.1421, -0.1252, -0.1943,  0.0508,\n         -0.1520,  0.1858,  0.0313, -0.1163,  0.0142,  0.0666, -0.1910, -0.1543,\n          0.0459, -0.2120,  0.0372, -0.1647],\n        [ 0.1035, -0.0955,  0.1262,  0.0631,  0.1604,  0.1504,  0.1659,  0.2085,\n          0.0110,  0.1548,  0.2026, -0.1094, -0.0321,  0.1581,  0.0569, -0.0331,\n         -0.0586, -0.0542, -0.1776,  0.0240],\n        [ 0.0952, -0.1320, -0.1589, -0.0544,  0.0245,  0.0259,  0.1595,  0.0365,\n          0.2120,  0.1381, -0.1172, -0.0096,  0.1235, -0.1997, -0.0098,  0.0411,\n          0.1590, -0.0719, -0.1113, -0.0924],\n        [ 0.0157,  0.1091, -0.0118, -0.1605, -0.1581, -0.0832,  0.2055, -0.0095,\n         -0.1161, -0.0857, -0.1763,  0.0536,  0.1446,  0.0948,  0.1781, -0.1913,\n         -0.1777, -0.0616, -0.1637, -0.2192],\n        [-0.1417, -0.0563, -0.0628,  0.1072,  0.1917,  0.0520, -0.2123,  0.0624,\n          0.2015,  0.1960,  0.0384, -0.0055,  0.1689,  0.0462, -0.1851, -0.1200,\n         -0.0460, -0.1277, -0.0566,  0.1881],\n        [ 0.1539, -0.1635, -0.1031, -0.1929,  0.1602, -0.1754,  0.1962, -0.0314,\n         -0.0380, -0.1446,  0.1695, -0.0706, -0.1102, -0.1958, -0.0141,  0.0332,\n          0.1370, -0.1624,  0.0453, -0.0079],\n        [ 0.1474,  0.2104, -0.0532, -0.2159,  0.0549, -0.1143, -0.1061, -0.1546,\n         -0.1728, -0.0038,  0.0437,  0.1854, -0.2155,  0.0268, -0.2196, -0.1875,\n          0.2126,  0.0174,  0.1977,  0.0402],\n        [ 0.0231, -0.0273, -0.2046,  0.1495, -0.1835, -0.1659,  0.2145,  0.0905,\n          0.0681,  0.0323, -0.1791,  0.2234,  0.1955,  0.0344,  0.1913, -0.2220,\n         -0.1730, -0.0609, -0.1928,  0.1508],\n        [-0.0541, -0.1376,  0.0331, -0.1337, -0.1398, -0.0039,  0.0560, -0.1074,\n          0.1110, -0.0319, -0.1878,  0.2213,  0.1618, -0.0599,  0.2223, -0.0877,\n         -0.2193, -0.0700, -0.0212, -0.0708],\n        [-0.1573,  0.0546, -0.1075,  0.1960,  0.1761, -0.0413, -0.1621,  0.0049,\n          0.0366,  0.1001, -0.1480,  0.1600,  0.1308, -0.1357,  0.0606, -0.0045,\n         -0.1538,  0.2142, -0.1674, -0.0142]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0474, -0.1490,  0.1339, -0.1648, -0.0398,  0.1238, -0.0915,  0.0162,\n         0.1053, -0.1233,  0.0934,  0.1114, -0.1526, -0.1160,  0.1346, -0.0849],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0172, -0.0828, -0.0934,  0.0135, -0.0416, -0.0058,  0.0922,  0.1460,\n         -0.1219, -0.0120,  0.1738, -0.0437, -0.0975, -0.0651, -0.1266, -0.1667,\n         -0.1014, -0.1754, -0.1030, -0.1156, -0.0466, -0.0222, -0.0201, -0.1231,\n         -0.1469,  0.0594, -0.0925, -0.0051,  0.1485,  0.0436, -0.1538, -0.1400],\n        [ 0.0088,  0.0229, -0.0005, -0.0019,  0.0845,  0.1092, -0.0028, -0.1438,\n         -0.0090,  0.0566,  0.1048, -0.1735,  0.0623, -0.1030, -0.0419, -0.1733,\n         -0.0276, -0.1417,  0.0290,  0.1183, -0.1431, -0.1064,  0.1137,  0.1044,\n         -0.0893,  0.1310, -0.0327, -0.0049,  0.1650,  0.0636, -0.0448, -0.0758],\n        [-0.0291, -0.0773,  0.1530,  0.1742, -0.1365,  0.0173, -0.1368,  0.0044,\n          0.0423, -0.0605, -0.0919, -0.0366, -0.1384,  0.1125, -0.1456, -0.1685,\n         -0.0010,  0.1000,  0.0625, -0.1357, -0.0429, -0.1276, -0.1238, -0.1471,\n          0.0161,  0.1312, -0.0159, -0.1611, -0.0678,  0.0139,  0.0319, -0.0337],\n        [-0.0131, -0.1434, -0.0672,  0.0828, -0.0806,  0.1234,  0.1118, -0.0455,\n         -0.0876,  0.0965,  0.0266,  0.0964, -0.0826,  0.1305,  0.0557, -0.0961,\n          0.1578, -0.0898, -0.1320,  0.0280, -0.0230, -0.0092, -0.1235, -0.0770,\n          0.0023, -0.1625,  0.1410, -0.0203,  0.0979,  0.0607, -0.0882,  0.0656],\n        [ 0.1379,  0.0648,  0.1189,  0.0965,  0.1323, -0.1564, -0.1253, -0.0937,\n         -0.0466, -0.0427,  0.0992,  0.0241,  0.1140,  0.0683, -0.0022,  0.1119,\n         -0.0954,  0.0569,  0.1387, -0.0821, -0.0684,  0.1231,  0.0445, -0.1454,\n         -0.0414, -0.1470, -0.0079,  0.0586, -0.0880,  0.1453, -0.1553, -0.0722],\n        [-0.1226, -0.0523,  0.1013, -0.1322,  0.0118,  0.0599, -0.0299, -0.0731,\n         -0.0886, -0.1468,  0.0265,  0.1215,  0.1751,  0.1318, -0.0730, -0.0337,\n          0.1069,  0.0134,  0.0571, -0.0321, -0.1010,  0.0890, -0.1119,  0.0771,\n          0.0312, -0.1439, -0.1691, -0.1380, -0.0753, -0.0158, -0.0877,  0.1664],\n        [-0.0502, -0.0573, -0.0664, -0.0233,  0.0103, -0.0161, -0.0573,  0.0018,\n         -0.0072, -0.1657,  0.0118,  0.0580,  0.0927, -0.1523, -0.1392, -0.0229,\n          0.0558, -0.1096,  0.0233,  0.0537,  0.0024,  0.0527,  0.0153,  0.0293,\n          0.0783, -0.0760, -0.1451, -0.0238, -0.0863,  0.0557, -0.1136, -0.1403],\n        [-0.1689,  0.0727, -0.1037,  0.1740, -0.1044,  0.1684, -0.1029,  0.0636,\n         -0.0741,  0.1174,  0.0796, -0.1331, -0.0555,  0.1167, -0.0179,  0.0421,\n         -0.1694,  0.1097, -0.1476,  0.1101,  0.1082, -0.0522,  0.0886, -0.1227,\n         -0.0437, -0.0264,  0.0256, -0.1008, -0.0883,  0.1313,  0.0535,  0.0822],\n        [ 0.1036,  0.1527, -0.0939,  0.1730, -0.0239,  0.0764, -0.0599, -0.0570,\n         -0.0228, -0.0357,  0.0580, -0.1466,  0.0403, -0.1666, -0.1295,  0.0526,\n         -0.1362,  0.0486,  0.0193, -0.0568,  0.0860,  0.0591,  0.1549, -0.0066,\n          0.0467, -0.0340, -0.0134, -0.0168,  0.1638,  0.1763,  0.0804,  0.0401],\n        [ 0.0479,  0.0235,  0.1039, -0.1199,  0.1099,  0.0314,  0.0382, -0.1604,\n         -0.0115,  0.1680,  0.1079, -0.0494,  0.0789,  0.1439,  0.1610,  0.1697,\n         -0.0805, -0.0203,  0.1369, -0.0206,  0.0717, -0.1598, -0.0688, -0.1632,\n          0.0937,  0.1640,  0.0232, -0.1117,  0.1664, -0.0387,  0.1324,  0.1382],\n        [-0.0349, -0.1395, -0.0145, -0.1350,  0.0994,  0.0349, -0.0552, -0.0049,\n          0.0059,  0.0752, -0.0017, -0.0880, -0.1188, -0.1168,  0.0312,  0.0372,\n          0.0792, -0.0512, -0.1191, -0.0808, -0.0801,  0.1291,  0.0236, -0.0877,\n          0.1046, -0.0292, -0.0046, -0.1578,  0.1139,  0.1639, -0.0865, -0.0931],\n        [-0.1201, -0.1694, -0.1420,  0.0831, -0.0132, -0.0183, -0.1609,  0.0170,\n         -0.1301, -0.0457, -0.1158,  0.0978, -0.0344, -0.0108,  0.1619,  0.0988,\n          0.0198, -0.1234, -0.0229,  0.0575,  0.0072,  0.0576, -0.0456, -0.0895,\n         -0.0081, -0.1517, -0.1223,  0.1471,  0.1206, -0.1514, -0.0852, -0.0163],\n        [ 0.1732, -0.0167, -0.0260, -0.0500,  0.1511,  0.0713, -0.1740, -0.1333,\n         -0.0546,  0.1369,  0.1492, -0.0463,  0.0397,  0.1664, -0.0460,  0.1564,\n         -0.1299, -0.1089,  0.0851, -0.0007,  0.0723, -0.0045,  0.0954,  0.1398,\n         -0.1493,  0.0585,  0.1254,  0.0550, -0.0756, -0.0083, -0.1030,  0.0545],\n        [-0.1057,  0.0193,  0.0025, -0.0891,  0.1222, -0.1266, -0.1097, -0.0727,\n          0.1575,  0.0842, -0.0291,  0.1739,  0.1216, -0.0488, -0.1506,  0.1239,\n          0.1158, -0.1388, -0.0541,  0.0527,  0.0377, -0.0611,  0.1296, -0.0944,\n          0.1258, -0.1166, -0.0999,  0.1485, -0.1131,  0.0796, -0.0483,  0.1688],\n        [-0.1189, -0.0217,  0.1010,  0.0763, -0.0491,  0.1033,  0.0074, -0.0041,\n         -0.1019,  0.0316,  0.1402,  0.0711,  0.0330,  0.1564,  0.0871, -0.1127,\n         -0.0563,  0.0983,  0.0981, -0.1246,  0.0843, -0.0657,  0.1206, -0.0824,\n         -0.0533,  0.1760,  0.0972,  0.1006, -0.1459,  0.0596, -0.0741, -0.0880],\n        [ 0.1146,  0.0393,  0.0143,  0.0333,  0.1059, -0.1429, -0.0642, -0.1023,\n         -0.0409, -0.1668, -0.0347,  0.0339, -0.1544, -0.1002, -0.1104, -0.1669,\n          0.0954,  0.1133, -0.0275, -0.1351, -0.0478, -0.1323,  0.1623, -0.0597,\n         -0.1740, -0.1027, -0.1135,  0.0148,  0.0372, -0.0325, -0.1178, -0.1587]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0988, -0.1756, -0.2388,  0.1270, -0.1071, -0.2007,  0.2056, -0.2227],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1577,  0.2139, -0.0558,  0.0824,  0.2218,  0.1352,  0.1378, -0.1945,\n          0.0615, -0.1176,  0.1839, -0.1512,  0.0862, -0.2349,  0.0561, -0.1304],\n        [ 0.1802, -0.0130, -0.2185, -0.2347, -0.1399, -0.2196, -0.0054, -0.1240,\n         -0.2253,  0.1950,  0.0232,  0.0306, -0.1439,  0.1750,  0.1888,  0.2031],\n        [-0.2187, -0.0046, -0.0769,  0.0673,  0.1492,  0.1409,  0.1828, -0.1388,\n         -0.2035, -0.0772,  0.1037, -0.0247,  0.2208,  0.1219, -0.2284, -0.2342],\n        [-0.0828,  0.1189,  0.0387, -0.1101, -0.0758,  0.2032,  0.2050, -0.1821,\n          0.0472, -0.1769,  0.1173, -0.0954, -0.1814,  0.2176, -0.1829, -0.1197],\n        [-0.0035,  0.1949, -0.1479, -0.2131, -0.0542, -0.1843,  0.1050,  0.0884,\n          0.2428, -0.1257, -0.0595,  0.1592, -0.0914,  0.1820,  0.1468,  0.1218],\n        [ 0.1339,  0.0535,  0.1722, -0.2332, -0.0623,  0.1260, -0.2005, -0.1477,\n         -0.1640, -0.1016,  0.0932, -0.0460, -0.0525, -0.1657, -0.0424, -0.1597],\n        [-0.1930, -0.2099, -0.1556,  0.1717, -0.2009,  0.0547,  0.0959,  0.2486,\n         -0.2181, -0.2031, -0.1435,  0.2314,  0.1452, -0.0277,  0.0447, -0.1994],\n        [ 0.0464, -0.2248,  0.2005,  0.0183,  0.1753, -0.0634, -0.2065, -0.0931,\n         -0.1895, -0.0374, -0.1409, -0.0533, -0.1121,  0.1903,  0.1104, -0.0342]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0223], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1426, -0.1371, -0.1311, -0.2128,  0.1226,  0.2881, -0.0100, -0.3415]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.2178, -0.1092, -0.0764, -0.1144,  0.0541,  0.0433, -0.2218,  0.0676,\n         -0.2154,  0.0427,  0.1721,  0.0530,  0.2076,  0.0296,  0.1279,  0.1180,\n          0.1916, -0.0363,  0.0024, -0.2126],\n        [-0.1106,  0.1124,  0.1629, -0.0656,  0.1262,  0.2127,  0.1629, -0.1783,\n          0.1195,  0.1957, -0.1976,  0.0432, -0.1107,  0.0134, -0.2059,  0.1366,\n         -0.2037,  0.0098, -0.1000,  0.1377],\n        [ 0.2197, -0.1367, -0.1407,  0.0021, -0.1824, -0.0667,  0.0272, -0.0320,\n          0.0648,  0.0085,  0.0316,  0.1021,  0.1862, -0.0309,  0.1038, -0.0698,\n          0.0244, -0.1803, -0.1892,  0.1526],\n        [-0.0528, -0.1468,  0.1261,  0.0797, -0.0881,  0.0009, -0.1185, -0.2017,\n          0.0797, -0.1343,  0.0548,  0.0810,  0.1068, -0.0775, -0.1548, -0.1823,\n          0.0013, -0.0453,  0.0186, -0.1932],\n        [ 0.1334,  0.0646,  0.2129, -0.1230,  0.0873,  0.1359,  0.0756,  0.0701,\n          0.0349, -0.1262,  0.1055,  0.0216, -0.1786, -0.1124, -0.1385,  0.0496,\n          0.1431, -0.1645,  0.2190, -0.0203],\n        [ 0.1781,  0.1135,  0.1149,  0.1572,  0.0626,  0.1492, -0.0257,  0.0588,\n          0.0721,  0.1759, -0.0421, -0.1805,  0.1630,  0.0673,  0.1082,  0.1155,\n         -0.1678,  0.1003,  0.1226, -0.2177],\n        [-0.1132,  0.0960,  0.1438,  0.1104, -0.2146, -0.0278,  0.1949, -0.1400,\n          0.1996,  0.0135,  0.0073, -0.0691,  0.1043,  0.1189, -0.0323,  0.0908,\n          0.0890, -0.0657, -0.1937,  0.1638],\n        [ 0.1800,  0.0648, -0.0680,  0.0252,  0.1962,  0.0967, -0.1100,  0.0594,\n         -0.2146,  0.0085,  0.1449,  0.0830, -0.1126, -0.0238, -0.1802, -0.1415,\n         -0.1550, -0.1402, -0.0446, -0.0153],\n        [-0.2186,  0.1100,  0.1242, -0.0358,  0.0697, -0.1568,  0.0752,  0.0412,\n          0.1415,  0.1979, -0.0788,  0.1040,  0.1525,  0.1505, -0.1087,  0.1896,\n          0.0746,  0.0115, -0.0486, -0.1156],\n        [ 0.0957,  0.1991, -0.2099, -0.1675,  0.1143,  0.1683, -0.1872, -0.2149,\n          0.1940, -0.1688, -0.1259,  0.1421,  0.0621,  0.1612,  0.1661, -0.0997,\n          0.1814, -0.1739,  0.1601, -0.2164],\n        [-0.0089, -0.1692,  0.1734,  0.1179, -0.1774, -0.1245, -0.0414,  0.1223,\n          0.0729, -0.0890, -0.1507, -0.0671, -0.0749, -0.0385, -0.1928,  0.1262,\n          0.0817, -0.1818,  0.0837, -0.0253],\n        [-0.0773,  0.2078,  0.1026,  0.0297,  0.1056, -0.1845, -0.1406,  0.0958,\n          0.0465, -0.0696,  0.1835, -0.2170,  0.1538,  0.0541, -0.1429,  0.2120,\n         -0.1030,  0.0761,  0.0400, -0.1677],\n        [ 0.0011, -0.1509,  0.1616,  0.1149, -0.1553, -0.1398,  0.1683, -0.1685,\n         -0.1946, -0.1433,  0.1417, -0.0740,  0.0329, -0.0995,  0.0466, -0.0115,\n          0.1933,  0.0709, -0.0074, -0.0765],\n        [-0.1831, -0.1793, -0.0931, -0.1729, -0.0263,  0.0298,  0.1214,  0.2166,\n         -0.0776,  0.0561, -0.1917,  0.0575, -0.0454, -0.0872, -0.0155,  0.1693,\n         -0.1677,  0.1757,  0.0842, -0.0649],\n        [ 0.0228,  0.0011, -0.1955,  0.0196,  0.0462,  0.2224,  0.0639, -0.0851,\n          0.0635,  0.1033, -0.1722,  0.0401, -0.0174, -0.0751,  0.0512,  0.2227,\n          0.0851, -0.0468,  0.0151, -0.0688],\n        [-0.2136,  0.1984, -0.1130, -0.0085, -0.0622, -0.1023, -0.1729, -0.0820,\n          0.0704, -0.0872,  0.1663, -0.1543,  0.1886,  0.0531, -0.1461, -0.0294,\n         -0.0591, -0.0396, -0.0162,  0.2162],\n        [ 0.1175,  0.0920, -0.1497,  0.0004, -0.2042, -0.0110, -0.1500,  0.1920,\n          0.0270, -0.0434,  0.0731, -0.1976,  0.1749, -0.0483, -0.1234,  0.2038,\n         -0.2186, -0.1878, -0.2153, -0.0303],\n        [ 0.2045, -0.0043,  0.1910,  0.1516,  0.0500,  0.2171,  0.0085,  0.1552,\n          0.0458, -0.0810, -0.1416,  0.1928,  0.0347,  0.2129,  0.1746,  0.0764,\n         -0.0198,  0.0606,  0.2187, -0.0803],\n        [ 0.0901,  0.1789,  0.1265,  0.1381, -0.0867, -0.1907, -0.0845,  0.0719,\n         -0.0572,  0.0333, -0.0320, -0.1353, -0.1311,  0.1383,  0.2044,  0.1319,\n         -0.1924, -0.1578,  0.1743,  0.0767],\n        [-0.1555, -0.1465,  0.1101, -0.0926,  0.1823, -0.0773, -0.1158, -0.1469,\n          0.1201,  0.0412, -0.1686, -0.1333, -0.0644, -0.1139,  0.1396, -0.0249,\n         -0.0963, -0.0889,  0.1416, -0.0887],\n        [-0.1113, -0.1065, -0.1096,  0.0591, -0.0325,  0.0464, -0.1257,  0.1767,\n         -0.0506,  0.2233, -0.0608, -0.1556,  0.1273, -0.0215, -0.2193, -0.1270,\n         -0.0540, -0.0908,  0.1109,  0.0654],\n        [ 0.0538,  0.1105,  0.1064, -0.2191,  0.0396, -0.0224,  0.0443,  0.0187,\n          0.0287, -0.0979, -0.1089,  0.1137, -0.1306, -0.2089, -0.1724,  0.1812,\n         -0.1706, -0.0148,  0.0682, -0.0761],\n        [-0.1085,  0.0719,  0.1114, -0.0974, -0.1421, -0.1252, -0.1943,  0.0508,\n         -0.1520,  0.1858,  0.0313, -0.1163,  0.0142,  0.0666, -0.1910, -0.1543,\n          0.0459, -0.2120,  0.0372, -0.1647],\n        [ 0.1035, -0.0955,  0.1262,  0.0631,  0.1604,  0.1504,  0.1659,  0.2085,\n          0.0110,  0.1548,  0.2026, -0.1094, -0.0321,  0.1581,  0.0569, -0.0331,\n         -0.0586, -0.0542, -0.1776,  0.0240],\n        [ 0.0952, -0.1320, -0.1589, -0.0544,  0.0245,  0.0259,  0.1595,  0.0365,\n          0.2120,  0.1381, -0.1172, -0.0096,  0.1235, -0.1997, -0.0098,  0.0411,\n          0.1590, -0.0719, -0.1113, -0.0924],\n        [ 0.0157,  0.1091, -0.0118, -0.1605, -0.1581, -0.0832,  0.2055, -0.0095,\n         -0.1161, -0.0857, -0.1763,  0.0536,  0.1446,  0.0948,  0.1781, -0.1913,\n         -0.1777, -0.0616, -0.1637, -0.2192],\n        [-0.1417, -0.0563, -0.0628,  0.1072,  0.1917,  0.0520, -0.2123,  0.0624,\n          0.2015,  0.1960,  0.0384, -0.0055,  0.1689,  0.0462, -0.1851, -0.1200,\n         -0.0460, -0.1277, -0.0566,  0.1881],\n        [ 0.1539, -0.1635, -0.1031, -0.1929,  0.1602, -0.1754,  0.1962, -0.0314,\n         -0.0380, -0.1446,  0.1695, -0.0706, -0.1102, -0.1958, -0.0141,  0.0332,\n          0.1370, -0.1624,  0.0453, -0.0079],\n        [ 0.1474,  0.2104, -0.0532, -0.2159,  0.0549, -0.1143, -0.1061, -0.1546,\n         -0.1728, -0.0038,  0.0437,  0.1854, -0.2155,  0.0268, -0.2196, -0.1875,\n          0.2126,  0.0174,  0.1977,  0.0402],\n        [ 0.0231, -0.0273, -0.2046,  0.1495, -0.1835, -0.1659,  0.2145,  0.0905,\n          0.0681,  0.0323, -0.1791,  0.2234,  0.1955,  0.0344,  0.1913, -0.2220,\n         -0.1730, -0.0609, -0.1928,  0.1508],\n        [-0.0541, -0.1376,  0.0331, -0.1337, -0.1398, -0.0039,  0.0560, -0.1074,\n          0.1110, -0.0319, -0.1878,  0.2213,  0.1618, -0.0599,  0.2223, -0.0877,\n         -0.2193, -0.0700, -0.0212, -0.0708],\n        [-0.1573,  0.0546, -0.1075,  0.1960,  0.1761, -0.0413, -0.1621,  0.0049,\n          0.0366,  0.1001, -0.1480,  0.1600,  0.1308, -0.1357,  0.0606, -0.0045,\n         -0.1538,  0.2142, -0.1674, -0.0142]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0600, -0.2016, -0.0226, -0.0695, -0.0671, -0.1522, -0.0181,  0.2150,\n        -0.2007, -0.0822,  0.2128, -0.2032, -0.1759,  0.2145, -0.1482, -0.1417,\n         0.2183, -0.0090,  0.1738,  0.1533,  0.1841, -0.0543, -0.0006, -0.2150,\n        -0.0665, -0.1308, -0.0494, -0.0768,  0.1242,  0.1671,  0.1142, -0.1142],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0172, -0.0828, -0.0934,  0.0135, -0.0416, -0.0058,  0.0922,  0.1460,\n         -0.1219, -0.0120,  0.1738, -0.0437, -0.0975, -0.0651, -0.1266, -0.1667,\n         -0.1014, -0.1754, -0.1030, -0.1156, -0.0466, -0.0222, -0.0201, -0.1231,\n         -0.1469,  0.0594, -0.0925, -0.0051,  0.1485,  0.0436, -0.1538, -0.1400],\n        [ 0.0088,  0.0229, -0.0005, -0.0019,  0.0845,  0.1092, -0.0028, -0.1438,\n         -0.0090,  0.0566,  0.1048, -0.1735,  0.0623, -0.1030, -0.0419, -0.1733,\n         -0.0276, -0.1417,  0.0290,  0.1183, -0.1431, -0.1064,  0.1137,  0.1044,\n         -0.0893,  0.1310, -0.0327, -0.0049,  0.1650,  0.0636, -0.0448, -0.0758],\n        [-0.0291, -0.0773,  0.1530,  0.1742, -0.1365,  0.0173, -0.1368,  0.0044,\n          0.0423, -0.0605, -0.0919, -0.0366, -0.1384,  0.1125, -0.1456, -0.1685,\n         -0.0010,  0.1000,  0.0625, -0.1357, -0.0429, -0.1276, -0.1238, -0.1471,\n          0.0161,  0.1312, -0.0159, -0.1611, -0.0678,  0.0139,  0.0319, -0.0337],\n        [-0.0131, -0.1434, -0.0672,  0.0828, -0.0806,  0.1234,  0.1118, -0.0455,\n         -0.0876,  0.0965,  0.0266,  0.0964, -0.0826,  0.1305,  0.0557, -0.0961,\n          0.1578, -0.0898, -0.1320,  0.0280, -0.0230, -0.0092, -0.1235, -0.0770,\n          0.0023, -0.1625,  0.1410, -0.0203,  0.0979,  0.0607, -0.0882,  0.0656],\n        [ 0.1379,  0.0648,  0.1189,  0.0965,  0.1323, -0.1564, -0.1253, -0.0937,\n         -0.0466, -0.0427,  0.0992,  0.0241,  0.1140,  0.0683, -0.0022,  0.1119,\n         -0.0954,  0.0569,  0.1387, -0.0821, -0.0684,  0.1231,  0.0445, -0.1454,\n         -0.0414, -0.1470, -0.0079,  0.0586, -0.0880,  0.1453, -0.1553, -0.0722],\n        [-0.1226, -0.0523,  0.1013, -0.1322,  0.0118,  0.0599, -0.0299, -0.0731,\n         -0.0886, -0.1468,  0.0265,  0.1215,  0.1751,  0.1318, -0.0730, -0.0337,\n          0.1069,  0.0134,  0.0571, -0.0321, -0.1010,  0.0890, -0.1119,  0.0771,\n          0.0312, -0.1439, -0.1691, -0.1380, -0.0753, -0.0158, -0.0877,  0.1664],\n        [-0.0502, -0.0573, -0.0664, -0.0233,  0.0103, -0.0161, -0.0573,  0.0018,\n         -0.0072, -0.1657,  0.0118,  0.0580,  0.0927, -0.1523, -0.1392, -0.0229,\n          0.0558, -0.1096,  0.0233,  0.0537,  0.0024,  0.0527,  0.0153,  0.0293,\n          0.0783, -0.0760, -0.1451, -0.0238, -0.0863,  0.0557, -0.1136, -0.1403],\n        [-0.1689,  0.0727, -0.1037,  0.1740, -0.1044,  0.1684, -0.1029,  0.0636,\n         -0.0741,  0.1174,  0.0796, -0.1331, -0.0555,  0.1167, -0.0179,  0.0421,\n         -0.1694,  0.1097, -0.1476,  0.1101,  0.1082, -0.0522,  0.0886, -0.1227,\n         -0.0437, -0.0264,  0.0256, -0.1008, -0.0883,  0.1313,  0.0535,  0.0822],\n        [ 0.1036,  0.1527, -0.0939,  0.1730, -0.0239,  0.0764, -0.0599, -0.0570,\n         -0.0228, -0.0357,  0.0580, -0.1466,  0.0403, -0.1666, -0.1295,  0.0526,\n         -0.1362,  0.0486,  0.0193, -0.0568,  0.0860,  0.0591,  0.1549, -0.0066,\n          0.0467, -0.0340, -0.0134, -0.0168,  0.1638,  0.1763,  0.0804,  0.0401],\n        [ 0.0479,  0.0235,  0.1039, -0.1199,  0.1099,  0.0314,  0.0382, -0.1604,\n         -0.0115,  0.1680,  0.1079, -0.0494,  0.0789,  0.1439,  0.1610,  0.1697,\n         -0.0805, -0.0203,  0.1369, -0.0206,  0.0717, -0.1598, -0.0688, -0.1632,\n          0.0937,  0.1640,  0.0232, -0.1117,  0.1664, -0.0387,  0.1324,  0.1382],\n        [-0.0349, -0.1395, -0.0145, -0.1350,  0.0994,  0.0349, -0.0552, -0.0049,\n          0.0059,  0.0752, -0.0017, -0.0880, -0.1188, -0.1168,  0.0312,  0.0372,\n          0.0792, -0.0512, -0.1191, -0.0808, -0.0801,  0.1291,  0.0236, -0.0877,\n          0.1046, -0.0292, -0.0046, -0.1578,  0.1139,  0.1639, -0.0865, -0.0931],\n        [-0.1201, -0.1694, -0.1420,  0.0831, -0.0132, -0.0183, -0.1609,  0.0170,\n         -0.1301, -0.0457, -0.1158,  0.0978, -0.0344, -0.0108,  0.1619,  0.0988,\n          0.0198, -0.1234, -0.0229,  0.0575,  0.0072,  0.0576, -0.0456, -0.0895,\n         -0.0081, -0.1517, -0.1223,  0.1471,  0.1206, -0.1514, -0.0852, -0.0163],\n        [ 0.1732, -0.0167, -0.0260, -0.0500,  0.1511,  0.0713, -0.1740, -0.1333,\n         -0.0546,  0.1369,  0.1492, -0.0463,  0.0397,  0.1664, -0.0460,  0.1564,\n         -0.1299, -0.1089,  0.0851, -0.0007,  0.0723, -0.0045,  0.0954,  0.1398,\n         -0.1493,  0.0585,  0.1254,  0.0550, -0.0756, -0.0083, -0.1030,  0.0545],\n        [-0.1057,  0.0193,  0.0025, -0.0891,  0.1222, -0.1266, -0.1097, -0.0727,\n          0.1575,  0.0842, -0.0291,  0.1739,  0.1216, -0.0488, -0.1506,  0.1239,\n          0.1158, -0.1388, -0.0541,  0.0527,  0.0377, -0.0611,  0.1296, -0.0944,\n          0.1258, -0.1166, -0.0999,  0.1485, -0.1131,  0.0796, -0.0483,  0.1688],\n        [-0.1189, -0.0217,  0.1010,  0.0763, -0.0491,  0.1033,  0.0074, -0.0041,\n         -0.1019,  0.0316,  0.1402,  0.0711,  0.0330,  0.1564,  0.0871, -0.1127,\n         -0.0563,  0.0983,  0.0981, -0.1246,  0.0843, -0.0657,  0.1206, -0.0824,\n         -0.0533,  0.1760,  0.0972,  0.1006, -0.1459,  0.0596, -0.0741, -0.0880],\n        [ 0.1146,  0.0393,  0.0143,  0.0333,  0.1059, -0.1429, -0.0642, -0.1023,\n         -0.0409, -0.1668, -0.0347,  0.0339, -0.1544, -0.1002, -0.1104, -0.1669,\n          0.0954,  0.1133, -0.0275, -0.1351, -0.0478, -0.1323,  0.1623, -0.0597,\n         -0.1740, -0.1027, -0.1135,  0.0148,  0.0372, -0.0325, -0.1178, -0.1587]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0474, -0.1490,  0.1339, -0.1648, -0.0398,  0.1238, -0.0915,  0.0162,\n         0.1053, -0.1233,  0.0934,  0.1114, -0.1526, -0.1160,  0.1346, -0.0849],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1577,  0.2139, -0.0558,  0.0824,  0.2218,  0.1352,  0.1378, -0.1945,\n          0.0615, -0.1176,  0.1839, -0.1512,  0.0862, -0.2349,  0.0561, -0.1304],\n        [ 0.1802, -0.0130, -0.2185, -0.2347, -0.1399, -0.2196, -0.0054, -0.1240,\n         -0.2253,  0.1950,  0.0232,  0.0306, -0.1439,  0.1750,  0.1888,  0.2031],\n        [-0.2187, -0.0046, -0.0769,  0.0673,  0.1492,  0.1409,  0.1828, -0.1388,\n         -0.2035, -0.0772,  0.1037, -0.0247,  0.2208,  0.1219, -0.2284, -0.2342],\n        [-0.0828,  0.1189,  0.0387, -0.1101, -0.0758,  0.2032,  0.2050, -0.1821,\n          0.0472, -0.1769,  0.1173, -0.0954, -0.1814,  0.2176, -0.1829, -0.1197],\n        [-0.0035,  0.1949, -0.1479, -0.2131, -0.0542, -0.1843,  0.1050,  0.0884,\n          0.2428, -0.1257, -0.0595,  0.1592, -0.0914,  0.1820,  0.1468,  0.1218],\n        [ 0.1339,  0.0535,  0.1722, -0.2332, -0.0623,  0.1260, -0.2005, -0.1477,\n         -0.1640, -0.1016,  0.0932, -0.0460, -0.0525, -0.1657, -0.0424, -0.1597],\n        [-0.1930, -0.2099, -0.1556,  0.1717, -0.2009,  0.0547,  0.0959,  0.2486,\n         -0.2181, -0.2031, -0.1435,  0.2314,  0.1452, -0.0277,  0.0447, -0.1994],\n        [ 0.0464, -0.2248,  0.2005,  0.0183,  0.1753, -0.0634, -0.2065, -0.0931,\n         -0.1895, -0.0374, -0.1409, -0.0533, -0.1121,  0.1903,  0.1104, -0.0342]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0988, -0.1756, -0.2388,  0.1270, -0.1071, -0.2007,  0.2056, -0.2227],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1426, -0.1371, -0.1311, -0.2128,  0.1226,  0.2881, -0.0100, -0.3415]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0223], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000001D05443B820>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001D008ADE860>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s16800000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='D:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\maze-game\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s16800000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}