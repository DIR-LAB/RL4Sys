{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s168960000"
    },
    "q_lr":	0.0005,
    "seed":	168960000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x0000021B40F9E680>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0015,  0.1187,  0.2024, -0.0215,  0.0324,  0.0806,  0.0678, -0.0089,\n        -0.1559, -0.1554, -0.1658,  0.0779,  0.0261, -0.1326,  0.0567,  0.1107,\n        -0.0336,  0.2041,  0.0553,  0.1352,  0.1101,  0.1372,  0.0551, -0.0397,\n         0.0173, -0.2072, -0.1800, -0.1802, -0.0230,  0.2133,  0.1212,  0.2152],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 2.0039e-01,  7.0011e-03,  1.9300e-02, -9.3747e-02,  3.3365e-02,\n         -2.1771e-01, -2.0190e-01,  1.9696e-01,  8.3769e-02,  6.1687e-02,\n          1.0228e-02,  2.0366e-01,  1.0447e-01, -6.9869e-02,  1.0800e-01,\n          2.0691e-01,  1.8708e-01, -1.0263e-01,  1.8531e-01, -1.8120e-01],\n        [ 1.4331e-01,  1.9623e-01, -1.0647e-01,  1.8086e-01,  2.2105e-01,\n         -2.4427e-02, -2.3745e-02, -2.0657e-02, -3.6507e-02,  1.1373e-01,\n          1.7047e-01,  3.8232e-02, -1.5445e-01, -1.7408e-01, -6.5124e-03,\n          1.3000e-01,  7.1661e-03,  1.2399e-01, -2.6053e-02, -2.5546e-02],\n        [ 8.1171e-02,  1.2132e-01, -9.5410e-02,  2.1557e-01,  1.2153e-01,\n          1.2694e-01, -5.6512e-02,  1.0414e-01, -1.2958e-01, -1.5909e-02,\n          1.0454e-02,  1.0428e-01,  1.4059e-01, -8.4397e-03, -2.1685e-01,\n         -1.4820e-02, -7.2183e-02,  1.4575e-01,  1.1864e-01,  1.0313e-01],\n        [ 5.4898e-02,  5.2659e-03, -6.9769e-02,  2.1658e-01, -1.4776e-01,\n         -2.1773e-01, -7.0326e-02,  3.0839e-02, -2.1900e-02,  2.4157e-02,\n          2.1780e-02, -1.9310e-01,  2.1133e-01, -2.0120e-01,  2.4673e-02,\n          2.6513e-02, -2.0749e-02, -1.7770e-01, -2.3066e-02,  1.7577e-01],\n        [-8.4081e-02, -1.9732e-01, -1.4446e-01, -5.8556e-02, -9.5660e-02,\n         -2.1116e-02, -2.0853e-02, -1.3388e-01, -1.4162e-01, -1.1074e-01,\n         -5.8246e-02,  2.1673e-01,  1.9985e-01,  1.5667e-01, -1.9664e-01,\n          1.3460e-01, -4.3028e-02, -1.3655e-01,  2.9841e-02,  8.6013e-02],\n        [ 2.1983e-01,  2.5252e-02, -1.3188e-01,  9.7791e-02,  1.9583e-01,\n          2.0077e-01,  1.3472e-01, -9.9390e-02, -1.6273e-01, -1.7447e-02,\n         -1.2927e-02, -9.8562e-02, -1.7456e-02, -8.1263e-02,  1.4646e-01,\n          1.0897e-01,  9.2460e-02, -1.8887e-01, -5.6904e-03, -5.9038e-02],\n        [-7.4698e-02, -1.4543e-02,  2.3332e-02,  2.0765e-01, -2.1348e-02,\n          1.0598e-01, -5.7673e-02, -1.4846e-01,  1.5150e-01, -1.3807e-01,\n          2.1246e-01, -2.1703e-01,  8.4475e-02, -3.5392e-02,  1.5364e-01,\n         -2.0937e-01, -9.8164e-02,  5.5600e-02,  3.7124e-02,  5.8565e-02],\n        [ 1.0853e-01,  6.1434e-02, -9.1739e-02,  1.2143e-01, -2.8992e-03,\n         -1.2210e-01,  2.1004e-01, -9.1226e-02,  2.4431e-02,  2.8206e-02,\n          7.8968e-02,  2.1000e-01, -5.8899e-02,  1.5260e-01,  6.5362e-02,\n          2.8990e-02, -1.2473e-01,  2.1574e-01,  1.6136e-01,  4.1476e-02],\n        [ 1.2380e-01, -7.6063e-04,  2.1675e-01,  1.9093e-01,  1.0719e-01,\n          7.6954e-02,  2.1532e-01, -7.1350e-02, -3.2382e-03, -2.6104e-02,\n          1.1443e-01,  9.0740e-02,  1.7194e-01,  1.8871e-01,  1.6608e-01,\n         -1.2459e-01,  1.0453e-01, -9.3951e-02, -1.0991e-01,  9.2252e-02],\n        [ 4.8378e-04, -1.7856e-01,  3.8325e-03,  4.5772e-02,  6.8296e-02,\n          5.6165e-03, -1.1424e-01,  4.5984e-02,  2.1688e-01, -1.3625e-01,\n         -1.5094e-01,  1.4444e-02,  1.4795e-01,  1.5830e-01, -1.8345e-01,\n          5.6198e-02,  6.1679e-02, -1.1649e-01,  1.3956e-04,  6.2496e-02],\n        [-1.9533e-01, -8.9796e-02,  1.8163e-01, -4.7255e-02,  4.3273e-02,\n         -5.3793e-02, -1.3704e-01, -2.9679e-02, -3.1147e-03,  1.1885e-01,\n          1.9911e-01, -1.7467e-01,  8.8632e-02,  1.9462e-01, -4.1087e-02,\n          1.4941e-01, -1.7968e-01,  6.8958e-02, -2.1356e-01,  1.4821e-01],\n        [ 9.2900e-02,  6.0723e-02, -7.2187e-02, -2.2071e-01,  1.7639e-01,\n          1.9878e-01, -1.2664e-01, -8.6750e-02,  2.2177e-01, -1.9320e-01,\n          8.0675e-03, -1.5163e-01, -5.4119e-02,  1.8659e-01, -1.4085e-01,\n          1.2030e-01, -8.1649e-02,  1.4113e-01,  1.2108e-01,  2.7049e-02],\n        [-1.5676e-01,  1.7173e-01,  1.0139e-01, -2.1999e-01, -1.8910e-01,\n          5.8530e-02, -1.7793e-01, -2.1079e-01, -8.5822e-02,  2.5862e-02,\n          1.0024e-01,  4.8015e-02,  9.1640e-02, -1.4697e-01, -6.5228e-02,\n         -1.7824e-01,  7.0416e-03,  2.0062e-01, -1.9583e-01, -1.0275e-02],\n        [ 5.0626e-02, -1.1056e-01, -9.0225e-02, -2.2879e-02, -1.7998e-01,\n         -1.5565e-01,  1.5079e-01, -1.1477e-01, -1.8688e-01, -2.1438e-01,\n          4.9332e-02,  7.6841e-02,  1.0404e-01,  1.9435e-01, -1.7348e-01,\n         -1.8590e-01,  4.5929e-03, -4.2599e-02, -1.0064e-01, -1.2644e-02],\n        [-1.3980e-01,  1.6207e-02, -6.2879e-02, -5.8046e-02, -1.3742e-01,\n         -8.0713e-02,  2.7729e-02, -1.3450e-01,  3.9589e-02,  3.9222e-02,\n         -4.2151e-03, -8.1900e-02,  1.7584e-01, -9.1416e-02, -1.1426e-01,\n          1.5343e-01,  5.2082e-02, -1.6192e-01,  2.2955e-02, -1.4979e-01],\n        [-1.5206e-01,  1.0131e-01, -1.2602e-01,  2.1473e-01,  1.5446e-01,\n         -1.1733e-01,  6.2225e-02,  1.7801e-01, -1.5412e-01,  1.9471e-03,\n         -1.2063e-01, -1.5418e-01,  1.9694e-03,  4.8007e-02,  3.8727e-02,\n         -1.3997e-01,  7.4577e-02, -1.0703e-01, -1.8016e-01, -9.5490e-02],\n        [ 5.6983e-02, -1.8019e-01, -1.2044e-01, -1.9041e-01,  2.1287e-01,\n         -1.9850e-01, -7.6481e-02,  2.2299e-01, -1.3550e-01, -1.8496e-01,\n          7.0338e-02, -2.0906e-01,  9.9132e-02, -2.1394e-01, -5.0985e-02,\n         -2.1387e-01, -2.0677e-01, -7.0806e-02, -2.0675e-01,  1.8921e-01],\n        [-1.5481e-01,  1.2122e-02, -4.6677e-02, -2.0277e-01, -2.0081e-01,\n          1.3126e-01,  9.2759e-02,  1.6069e-01, -1.7206e-01, -1.8474e-01,\n         -2.1937e-02,  1.1855e-01,  1.0156e-01, -1.1863e-01,  8.6785e-02,\n         -2.0062e-01, -1.2512e-01, -3.6197e-02, -1.1459e-01, -1.8251e-02],\n        [ 1.7657e-01,  1.3804e-01, -2.0106e-01, -3.1813e-02, -4.2928e-02,\n          1.7389e-01,  2.1920e-02, -1.3115e-01, -9.0237e-03,  1.2207e-01,\n          9.2979e-02,  1.5233e-01,  2.1102e-01,  4.9272e-02,  1.4788e-01,\n          1.7264e-01,  2.1337e-01, -1.3326e-01,  1.5670e-01, -3.3149e-02],\n        [-1.5337e-01, -3.9238e-02,  1.8485e-01,  1.1526e-01,  1.2166e-01,\n          5.5368e-02,  1.9305e-01,  7.4129e-02, -2.0009e-02, -2.2294e-01,\n          5.2592e-02,  1.9565e-01,  3.7893e-02,  1.0544e-01, -5.5553e-02,\n          2.4380e-02,  5.3951e-02,  4.4190e-02,  1.0295e-01, -2.1846e-02],\n        [-4.6164e-05,  1.7216e-01,  1.3743e-01, -8.4817e-02,  6.6153e-02,\n         -1.8552e-01, -3.6551e-02,  2.2181e-01, -1.3456e-01, -2.1800e-01,\n          1.6408e-01,  2.1102e-01,  1.0377e-01,  2.1052e-01,  1.3970e-01,\n          7.2390e-02,  3.7725e-02, -8.5752e-02, -1.3505e-01, -1.0398e-01],\n        [ 2.0668e-01,  1.8949e-02,  1.0875e-01, -1.5999e-02, -1.4933e-01,\n          1.0319e-01, -9.6035e-02,  1.2534e-02, -6.2474e-02,  6.1931e-02,\n         -2.0979e-01,  1.7362e-01, -1.1910e-01, -1.4284e-02, -9.4414e-02,\n         -7.0039e-02, -2.7689e-02, -7.0711e-03, -3.6612e-02, -2.0736e-01],\n        [ 1.6697e-01, -1.9794e-01, -1.8113e-01, -1.9030e-01, -1.1980e-01,\n          7.6542e-02, -5.5349e-02, -9.8749e-02,  2.0724e-01, -9.3983e-02,\n         -1.4162e-01,  1.2599e-01, -1.0785e-01,  4.1968e-02,  1.1923e-01,\n         -4.1987e-02,  1.0824e-01,  3.6334e-03, -5.8381e-02, -9.1539e-02],\n        [ 1.9891e-01, -2.3000e-02,  1.7072e-01, -9.1140e-02, -6.1683e-02,\n          7.7466e-02,  1.7438e-01, -1.2265e-01,  6.9400e-02,  2.7401e-02,\n         -6.1930e-02,  1.3394e-01,  1.4188e-01,  1.8195e-01,  9.7313e-02,\n          3.8231e-02,  1.7642e-01,  2.0107e-01, -2.5795e-03, -6.2358e-02],\n        [-9.9091e-02,  1.1348e-01,  2.1877e-01, -1.5644e-01, -1.2273e-01,\n         -9.4444e-02, -1.6535e-01,  6.5076e-02, -2.1054e-01,  1.6845e-01,\n         -5.7249e-02, -1.1493e-01,  2.0400e-01,  2.2045e-01,  1.9089e-01,\n          1.0321e-01,  1.0960e-01,  1.9453e-01, -1.0455e-01,  1.0311e-01],\n        [-1.8360e-01,  1.2542e-02,  2.1201e-01, -3.8559e-02,  1.9301e-01,\n          4.8914e-02, -1.7919e-01,  1.3696e-01, -1.6641e-01, -1.1213e-01,\n          5.9204e-02,  1.4665e-01, -1.5128e-01, -1.0794e-01,  1.3826e-01,\n         -1.5326e-01,  8.4192e-02,  6.0449e-02, -1.9284e-01, -5.3542e-02],\n        [-1.4098e-01, -1.3218e-01, -1.7258e-01,  1.7773e-01, -7.0255e-02,\n         -5.8791e-02,  5.6638e-02, -1.1863e-01, -2.4868e-03,  1.9496e-01,\n         -6.0664e-03,  9.7667e-02, -5.2522e-02,  1.6080e-01,  4.9377e-02,\n         -1.6943e-01, -1.0212e-01,  1.1027e-01,  2.1218e-01, -1.3736e-01],\n        [-1.8063e-01, -9.5274e-02,  6.1455e-02,  8.8203e-02,  8.7634e-02,\n          1.8472e-01,  1.0818e-02, -4.7130e-02,  1.0412e-01,  8.1824e-02,\n          9.1556e-02, -5.8604e-02, -1.0685e-01, -9.5573e-03,  2.0745e-02,\n          4.2613e-02,  7.0001e-03, -7.6141e-02,  2.0115e-01,  1.9919e-01],\n        [-1.0567e-01, -1.3527e-01,  3.1104e-02,  6.3106e-03,  1.0856e-01,\n          4.7059e-02, -1.6990e-01,  1.6920e-02, -1.0779e-01,  2.0034e-01,\n          1.5955e-01,  1.5400e-01, -9.3397e-02, -1.0171e-01, -9.6585e-02,\n         -1.2923e-02,  2.0120e-01, -8.1667e-02, -2.1151e-01, -1.4656e-01],\n        [-3.6108e-02,  2.1223e-01, -3.9540e-02, -1.0272e-01, -9.5407e-02,\n         -1.8662e-01,  4.0347e-02,  2.6142e-02,  1.4666e-01,  2.0014e-01,\n         -2.2027e-01, -1.3389e-01,  1.6732e-01, -5.2711e-02, -3.1334e-02,\n         -8.6971e-02,  3.8172e-02, -2.1794e-01,  1.2569e-01,  1.4027e-01],\n        [-1.5107e-01, -1.4883e-01,  2.0979e-01, -1.1387e-01,  1.9825e-01,\n          2.0607e-01,  1.3922e-01, -1.0679e-01, -6.4653e-03, -9.1551e-02,\n         -1.6973e-01,  1.5536e-01,  7.0354e-02,  3.1978e-02, -1.6581e-02,\n          2.0488e-01,  3.4267e-02,  1.8197e-01,  1.2078e-02, -1.1010e-01],\n        [ 1.3179e-02, -2.0924e-01, -1.4478e-01, -2.3477e-02,  2.0871e-01,\n         -2.4373e-02, -8.2881e-02,  1.6642e-01, -1.9608e-01,  7.2073e-02,\n         -5.0152e-02, -1.6622e-01,  1.3882e-01, -8.6785e-03, -4.8397e-02,\n         -1.1286e-01, -2.0445e-01,  2.0560e-03,  1.1398e-01,  2.0293e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1366,  0.0640, -0.0426, -0.1609,  0.1282,  0.0082,  0.0159, -0.0327,\n        -0.0253,  0.1135,  0.1508, -0.1487,  0.1020, -0.0912, -0.0777, -0.0662],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1363,  0.0386,  0.0329,  0.1582, -0.1564,  0.0998,  0.1225,  0.0294,\n          0.0761, -0.0976,  0.1454, -0.0116,  0.0676,  0.0887, -0.1121, -0.1381,\n         -0.1574,  0.0321, -0.0093, -0.0719,  0.0825, -0.0881,  0.1456,  0.0681,\n          0.0115,  0.1515,  0.0654,  0.0875,  0.0237, -0.0910,  0.1372, -0.1332],\n        [-0.1125, -0.0411,  0.0232,  0.0896, -0.0308, -0.1408,  0.0874,  0.0811,\n         -0.0598, -0.0453,  0.1265, -0.0333,  0.1297, -0.0709,  0.1120,  0.0279,\n         -0.0060, -0.1346,  0.1528,  0.0130,  0.0273, -0.1083,  0.0899,  0.0328,\n         -0.1411, -0.1461, -0.1325,  0.0210, -0.0401,  0.1023, -0.0833,  0.0857],\n        [ 0.0460, -0.0983,  0.1225,  0.0454, -0.1568, -0.0950, -0.1468,  0.1632,\n         -0.1351, -0.0289,  0.0054,  0.1601,  0.1339, -0.0381,  0.0260, -0.0697,\n         -0.1503, -0.0202, -0.1541, -0.1399,  0.0042, -0.1079,  0.1672,  0.1196,\n         -0.1165,  0.0269, -0.1463, -0.1098, -0.1018,  0.1738,  0.0953, -0.0721],\n        [ 0.0882,  0.0577, -0.1703,  0.1108,  0.1732,  0.1300,  0.0976, -0.1347,\n          0.0870, -0.0516, -0.1358, -0.0162, -0.1064,  0.1306,  0.0757,  0.1549,\n          0.0067,  0.0757,  0.0222, -0.0143,  0.1715,  0.1577,  0.1389, -0.1171,\n         -0.1370, -0.0341,  0.0378, -0.1535,  0.1045, -0.1385, -0.0469,  0.0486],\n        [-0.0655, -0.0016,  0.0338, -0.1438,  0.0913,  0.1249,  0.0697, -0.1481,\n          0.1380,  0.0559, -0.0549, -0.1491,  0.1487, -0.1513,  0.0619, -0.1592,\n         -0.0884, -0.0887,  0.0452,  0.0052,  0.0560, -0.1013, -0.0026, -0.0024,\n          0.0968,  0.0667,  0.1540,  0.0796,  0.1467, -0.0954,  0.1586, -0.0584],\n        [-0.1027,  0.1679,  0.0951,  0.0378,  0.0077, -0.0563, -0.0400, -0.1278,\n          0.0246, -0.1471, -0.1458,  0.1635,  0.0074, -0.0892, -0.0833,  0.0874,\n          0.0870, -0.0537,  0.1304,  0.1736,  0.0694, -0.0363,  0.0741, -0.0127,\n         -0.0764,  0.1213, -0.0025, -0.0316, -0.1021,  0.0366,  0.1428, -0.0695],\n        [-0.1204,  0.0373,  0.0542, -0.1006,  0.0477, -0.0398,  0.0051,  0.1043,\n         -0.1296,  0.0209, -0.0979, -0.0073, -0.0679, -0.0247, -0.0184,  0.0963,\n         -0.0812,  0.1265, -0.0295, -0.1299, -0.1472, -0.1766, -0.1488,  0.0389,\n         -0.1625, -0.0191, -0.0898, -0.0462, -0.0995,  0.0137,  0.0156, -0.0410],\n        [-0.0285,  0.0738,  0.0160, -0.1423, -0.0611, -0.0009,  0.0477,  0.0418,\n         -0.0177, -0.0046, -0.0717, -0.0856, -0.0334,  0.1121,  0.1265,  0.1079,\n          0.1047,  0.0497, -0.0343,  0.1153,  0.0958,  0.1450, -0.0835,  0.1346,\n          0.1156, -0.1619,  0.0350,  0.1570,  0.0015, -0.0645, -0.1281,  0.1408],\n        [ 0.1595, -0.0171,  0.1398, -0.0913, -0.0032,  0.0978,  0.0746, -0.1096,\n          0.0378, -0.0263,  0.0047,  0.0598,  0.1467,  0.0706, -0.1576, -0.0354,\n          0.0419,  0.0718, -0.0273,  0.1641,  0.0441,  0.0695,  0.0554, -0.0725,\n          0.1080,  0.0363, -0.1374, -0.1170,  0.0394, -0.1576,  0.0585,  0.1018],\n        [ 0.0906, -0.0109, -0.1404, -0.1272, -0.0407, -0.0308, -0.0361, -0.0820,\n         -0.0665, -0.0358,  0.0880, -0.0586, -0.0757,  0.0230, -0.0223,  0.0924,\n          0.0309, -0.0958,  0.0950, -0.1404, -0.0760,  0.1510,  0.0912,  0.0224,\n         -0.0228, -0.0799,  0.0710,  0.0927,  0.0275, -0.0242,  0.1193,  0.0897],\n        [ 0.1116, -0.0923,  0.1166,  0.0306, -0.0721, -0.1530,  0.1294, -0.1443,\n         -0.0713, -0.1425, -0.1159, -0.0956,  0.0377,  0.1629, -0.1349,  0.1048,\n         -0.0443, -0.0678, -0.0364, -0.0777,  0.0622, -0.0258, -0.0502, -0.1581,\n         -0.0417,  0.0930, -0.1271, -0.1671,  0.0489,  0.0185, -0.1656,  0.0283],\n        [ 0.0381, -0.0190,  0.0918, -0.0907, -0.0386,  0.1498,  0.0566, -0.1635,\n          0.0563, -0.0009, -0.1475,  0.0663, -0.1618,  0.0913, -0.1094, -0.0734,\n          0.0863,  0.0624, -0.0283,  0.1050,  0.0148, -0.1234, -0.1359, -0.0508,\n         -0.1741, -0.1598, -0.1392,  0.0393,  0.1047,  0.1636,  0.0851, -0.0635],\n        [-0.1156,  0.0246,  0.0286,  0.0794, -0.1062, -0.0064, -0.1469,  0.1151,\n         -0.0782,  0.1511, -0.1583,  0.0774,  0.0125,  0.1764,  0.0705, -0.0398,\n          0.1585,  0.1178,  0.1080, -0.1449, -0.0319, -0.0125, -0.0161, -0.1411,\n          0.0293,  0.0206, -0.1293,  0.0810, -0.0048,  0.0651, -0.1568,  0.1326],\n        [-0.0601, -0.0005, -0.1481, -0.0028, -0.0602,  0.0260,  0.0711, -0.0967,\n          0.0541,  0.0469, -0.0359, -0.0924, -0.1709, -0.1709, -0.1082,  0.1559,\n         -0.0740,  0.0133, -0.1060, -0.0066,  0.1685, -0.1103,  0.0777,  0.0283,\n          0.1349, -0.0756,  0.1429, -0.0888, -0.0147,  0.1284, -0.0049, -0.1439],\n        [ 0.1735, -0.0785, -0.0204,  0.1359,  0.0618, -0.1748, -0.0475,  0.1158,\n         -0.0459,  0.1330, -0.1069,  0.1733, -0.0027, -0.1744, -0.1021,  0.1143,\n          0.0462,  0.1739,  0.0101,  0.1562, -0.0343,  0.1229,  0.0939,  0.1292,\n         -0.1092, -0.0718,  0.0939,  0.0198,  0.1706, -0.1343,  0.1758, -0.0690],\n        [ 0.1082, -0.1026,  0.0953, -0.1367,  0.1468,  0.0320, -0.0226,  0.1599,\n         -0.1531,  0.0729,  0.0197,  0.1736,  0.1382,  0.1333,  0.0086, -0.1356,\n          0.1097, -0.0790, -0.0872, -0.1749,  0.0820, -0.0684,  0.0244, -0.1680,\n         -0.0527, -0.1372,  0.0429,  0.0251,  0.0485, -0.0603,  0.0486,  0.0172]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0437,  0.0848,  0.1883,  0.1386,  0.1998,  0.2059, -0.1808, -0.2261],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1690,  0.1350,  0.1976, -0.2451,  0.1019, -0.0883,  0.0739,  0.0880,\n          0.0777,  0.1995,  0.1587,  0.2160, -0.1400, -0.0495,  0.0725, -0.0557],\n        [-0.1951, -0.0233,  0.0461,  0.0550, -0.0616, -0.0647, -0.2476,  0.0947,\n         -0.1492,  0.1140, -0.2315, -0.1391, -0.2438, -0.0183,  0.1148,  0.1815],\n        [ 0.0291,  0.2307,  0.2285, -0.0292, -0.2307,  0.1844, -0.1105,  0.1633,\n          0.1560,  0.1854,  0.1247,  0.1163,  0.1823,  0.2273, -0.1614, -0.1117],\n        [-0.1584,  0.1941, -0.0862,  0.0184, -0.0531,  0.1087, -0.0441,  0.2458,\n         -0.0101, -0.2463,  0.1917,  0.2363,  0.0688,  0.1869,  0.0422, -0.2070],\n        [-0.1495, -0.1095,  0.1635,  0.1801, -0.2208, -0.1478,  0.0249,  0.1101,\n         -0.0972,  0.1202, -0.0961, -0.0948,  0.1252, -0.0200, -0.0515, -0.0712],\n        [-0.0144,  0.1158, -0.1119, -0.1138,  0.0996,  0.1257, -0.2406,  0.2464,\n         -0.1923,  0.0223, -0.0833,  0.2085, -0.2073, -0.0167, -0.1502,  0.0374],\n        [-0.1416, -0.0649,  0.0765,  0.1626,  0.2235, -0.0219, -0.0752, -0.1912,\n         -0.0222,  0.2420,  0.1706, -0.2302, -0.1427,  0.0676, -0.2215, -0.2387],\n        [-0.1911,  0.1548, -0.0100, -0.1142, -0.1870,  0.0778, -0.1203, -0.2149,\n          0.1867, -0.2351,  0.0503, -0.0277, -0.1627, -0.2031, -0.2311, -0.0176]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2681], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1749, -0.0600,  0.1086, -0.0646, -0.2196,  0.2542,  0.2494, -0.0164]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 2.0039e-01,  7.0011e-03,  1.9300e-02, -9.3747e-02,  3.3365e-02,\n         -2.1771e-01, -2.0190e-01,  1.9696e-01,  8.3769e-02,  6.1687e-02,\n          1.0228e-02,  2.0366e-01,  1.0447e-01, -6.9869e-02,  1.0800e-01,\n          2.0691e-01,  1.8708e-01, -1.0263e-01,  1.8531e-01, -1.8120e-01],\n        [ 1.4331e-01,  1.9623e-01, -1.0647e-01,  1.8086e-01,  2.2105e-01,\n         -2.4427e-02, -2.3745e-02, -2.0657e-02, -3.6507e-02,  1.1373e-01,\n          1.7047e-01,  3.8232e-02, -1.5445e-01, -1.7408e-01, -6.5124e-03,\n          1.3000e-01,  7.1661e-03,  1.2399e-01, -2.6053e-02, -2.5546e-02],\n        [ 8.1171e-02,  1.2132e-01, -9.5410e-02,  2.1557e-01,  1.2153e-01,\n          1.2694e-01, -5.6512e-02,  1.0414e-01, -1.2958e-01, -1.5909e-02,\n          1.0454e-02,  1.0428e-01,  1.4059e-01, -8.4397e-03, -2.1685e-01,\n         -1.4820e-02, -7.2183e-02,  1.4575e-01,  1.1864e-01,  1.0313e-01],\n        [ 5.4898e-02,  5.2659e-03, -6.9769e-02,  2.1658e-01, -1.4776e-01,\n         -2.1773e-01, -7.0326e-02,  3.0839e-02, -2.1900e-02,  2.4157e-02,\n          2.1780e-02, -1.9310e-01,  2.1133e-01, -2.0120e-01,  2.4673e-02,\n          2.6513e-02, -2.0749e-02, -1.7770e-01, -2.3066e-02,  1.7577e-01],\n        [-8.4081e-02, -1.9732e-01, -1.4446e-01, -5.8556e-02, -9.5660e-02,\n         -2.1116e-02, -2.0853e-02, -1.3388e-01, -1.4162e-01, -1.1074e-01,\n         -5.8246e-02,  2.1673e-01,  1.9985e-01,  1.5667e-01, -1.9664e-01,\n          1.3460e-01, -4.3028e-02, -1.3655e-01,  2.9841e-02,  8.6013e-02],\n        [ 2.1983e-01,  2.5252e-02, -1.3188e-01,  9.7791e-02,  1.9583e-01,\n          2.0077e-01,  1.3472e-01, -9.9390e-02, -1.6273e-01, -1.7447e-02,\n         -1.2927e-02, -9.8562e-02, -1.7456e-02, -8.1263e-02,  1.4646e-01,\n          1.0897e-01,  9.2460e-02, -1.8887e-01, -5.6904e-03, -5.9038e-02],\n        [-7.4698e-02, -1.4543e-02,  2.3332e-02,  2.0765e-01, -2.1348e-02,\n          1.0598e-01, -5.7673e-02, -1.4846e-01,  1.5150e-01, -1.3807e-01,\n          2.1246e-01, -2.1703e-01,  8.4475e-02, -3.5392e-02,  1.5364e-01,\n         -2.0937e-01, -9.8164e-02,  5.5600e-02,  3.7124e-02,  5.8565e-02],\n        [ 1.0853e-01,  6.1434e-02, -9.1739e-02,  1.2143e-01, -2.8992e-03,\n         -1.2210e-01,  2.1004e-01, -9.1226e-02,  2.4431e-02,  2.8206e-02,\n          7.8968e-02,  2.1000e-01, -5.8899e-02,  1.5260e-01,  6.5362e-02,\n          2.8990e-02, -1.2473e-01,  2.1574e-01,  1.6136e-01,  4.1476e-02],\n        [ 1.2380e-01, -7.6063e-04,  2.1675e-01,  1.9093e-01,  1.0719e-01,\n          7.6954e-02,  2.1532e-01, -7.1350e-02, -3.2382e-03, -2.6104e-02,\n          1.1443e-01,  9.0740e-02,  1.7194e-01,  1.8871e-01,  1.6608e-01,\n         -1.2459e-01,  1.0453e-01, -9.3951e-02, -1.0991e-01,  9.2252e-02],\n        [ 4.8378e-04, -1.7856e-01,  3.8325e-03,  4.5772e-02,  6.8296e-02,\n          5.6165e-03, -1.1424e-01,  4.5984e-02,  2.1688e-01, -1.3625e-01,\n         -1.5094e-01,  1.4444e-02,  1.4795e-01,  1.5830e-01, -1.8345e-01,\n          5.6198e-02,  6.1679e-02, -1.1649e-01,  1.3956e-04,  6.2496e-02],\n        [-1.9533e-01, -8.9796e-02,  1.8163e-01, -4.7255e-02,  4.3273e-02,\n         -5.3793e-02, -1.3704e-01, -2.9679e-02, -3.1147e-03,  1.1885e-01,\n          1.9911e-01, -1.7467e-01,  8.8632e-02,  1.9462e-01, -4.1087e-02,\n          1.4941e-01, -1.7968e-01,  6.8958e-02, -2.1356e-01,  1.4821e-01],\n        [ 9.2900e-02,  6.0723e-02, -7.2187e-02, -2.2071e-01,  1.7639e-01,\n          1.9878e-01, -1.2664e-01, -8.6750e-02,  2.2177e-01, -1.9320e-01,\n          8.0675e-03, -1.5163e-01, -5.4119e-02,  1.8659e-01, -1.4085e-01,\n          1.2030e-01, -8.1649e-02,  1.4113e-01,  1.2108e-01,  2.7049e-02],\n        [-1.5676e-01,  1.7173e-01,  1.0139e-01, -2.1999e-01, -1.8910e-01,\n          5.8530e-02, -1.7793e-01, -2.1079e-01, -8.5822e-02,  2.5862e-02,\n          1.0024e-01,  4.8015e-02,  9.1640e-02, -1.4697e-01, -6.5228e-02,\n         -1.7824e-01,  7.0416e-03,  2.0062e-01, -1.9583e-01, -1.0275e-02],\n        [ 5.0626e-02, -1.1056e-01, -9.0225e-02, -2.2879e-02, -1.7998e-01,\n         -1.5565e-01,  1.5079e-01, -1.1477e-01, -1.8688e-01, -2.1438e-01,\n          4.9332e-02,  7.6841e-02,  1.0404e-01,  1.9435e-01, -1.7348e-01,\n         -1.8590e-01,  4.5929e-03, -4.2599e-02, -1.0064e-01, -1.2644e-02],\n        [-1.3980e-01,  1.6207e-02, -6.2879e-02, -5.8046e-02, -1.3742e-01,\n         -8.0713e-02,  2.7729e-02, -1.3450e-01,  3.9589e-02,  3.9222e-02,\n         -4.2151e-03, -8.1900e-02,  1.7584e-01, -9.1416e-02, -1.1426e-01,\n          1.5343e-01,  5.2082e-02, -1.6192e-01,  2.2955e-02, -1.4979e-01],\n        [-1.5206e-01,  1.0131e-01, -1.2602e-01,  2.1473e-01,  1.5446e-01,\n         -1.1733e-01,  6.2225e-02,  1.7801e-01, -1.5412e-01,  1.9471e-03,\n         -1.2063e-01, -1.5418e-01,  1.9694e-03,  4.8007e-02,  3.8727e-02,\n         -1.3997e-01,  7.4577e-02, -1.0703e-01, -1.8016e-01, -9.5490e-02],\n        [ 5.6983e-02, -1.8019e-01, -1.2044e-01, -1.9041e-01,  2.1287e-01,\n         -1.9850e-01, -7.6481e-02,  2.2299e-01, -1.3550e-01, -1.8496e-01,\n          7.0338e-02, -2.0906e-01,  9.9132e-02, -2.1394e-01, -5.0985e-02,\n         -2.1387e-01, -2.0677e-01, -7.0806e-02, -2.0675e-01,  1.8921e-01],\n        [-1.5481e-01,  1.2122e-02, -4.6677e-02, -2.0277e-01, -2.0081e-01,\n          1.3126e-01,  9.2759e-02,  1.6069e-01, -1.7206e-01, -1.8474e-01,\n         -2.1937e-02,  1.1855e-01,  1.0156e-01, -1.1863e-01,  8.6785e-02,\n         -2.0062e-01, -1.2512e-01, -3.6197e-02, -1.1459e-01, -1.8251e-02],\n        [ 1.7657e-01,  1.3804e-01, -2.0106e-01, -3.1813e-02, -4.2928e-02,\n          1.7389e-01,  2.1920e-02, -1.3115e-01, -9.0237e-03,  1.2207e-01,\n          9.2979e-02,  1.5233e-01,  2.1102e-01,  4.9272e-02,  1.4788e-01,\n          1.7264e-01,  2.1337e-01, -1.3326e-01,  1.5670e-01, -3.3149e-02],\n        [-1.5337e-01, -3.9238e-02,  1.8485e-01,  1.1526e-01,  1.2166e-01,\n          5.5368e-02,  1.9305e-01,  7.4129e-02, -2.0009e-02, -2.2294e-01,\n          5.2592e-02,  1.9565e-01,  3.7893e-02,  1.0544e-01, -5.5553e-02,\n          2.4380e-02,  5.3951e-02,  4.4190e-02,  1.0295e-01, -2.1846e-02],\n        [-4.6164e-05,  1.7216e-01,  1.3743e-01, -8.4817e-02,  6.6153e-02,\n         -1.8552e-01, -3.6551e-02,  2.2181e-01, -1.3456e-01, -2.1800e-01,\n          1.6408e-01,  2.1102e-01,  1.0377e-01,  2.1052e-01,  1.3970e-01,\n          7.2390e-02,  3.7725e-02, -8.5752e-02, -1.3505e-01, -1.0398e-01],\n        [ 2.0668e-01,  1.8949e-02,  1.0875e-01, -1.5999e-02, -1.4933e-01,\n          1.0319e-01, -9.6035e-02,  1.2534e-02, -6.2474e-02,  6.1931e-02,\n         -2.0979e-01,  1.7362e-01, -1.1910e-01, -1.4284e-02, -9.4414e-02,\n         -7.0039e-02, -2.7689e-02, -7.0711e-03, -3.6612e-02, -2.0736e-01],\n        [ 1.6697e-01, -1.9794e-01, -1.8113e-01, -1.9030e-01, -1.1980e-01,\n          7.6542e-02, -5.5349e-02, -9.8749e-02,  2.0724e-01, -9.3983e-02,\n         -1.4162e-01,  1.2599e-01, -1.0785e-01,  4.1968e-02,  1.1923e-01,\n         -4.1987e-02,  1.0824e-01,  3.6334e-03, -5.8381e-02, -9.1539e-02],\n        [ 1.9891e-01, -2.3000e-02,  1.7072e-01, -9.1140e-02, -6.1683e-02,\n          7.7466e-02,  1.7438e-01, -1.2265e-01,  6.9400e-02,  2.7401e-02,\n         -6.1930e-02,  1.3394e-01,  1.4188e-01,  1.8195e-01,  9.7313e-02,\n          3.8231e-02,  1.7642e-01,  2.0107e-01, -2.5795e-03, -6.2358e-02],\n        [-9.9091e-02,  1.1348e-01,  2.1877e-01, -1.5644e-01, -1.2273e-01,\n         -9.4444e-02, -1.6535e-01,  6.5076e-02, -2.1054e-01,  1.6845e-01,\n         -5.7249e-02, -1.1493e-01,  2.0400e-01,  2.2045e-01,  1.9089e-01,\n          1.0321e-01,  1.0960e-01,  1.9453e-01, -1.0455e-01,  1.0311e-01],\n        [-1.8360e-01,  1.2542e-02,  2.1201e-01, -3.8559e-02,  1.9301e-01,\n          4.8914e-02, -1.7919e-01,  1.3696e-01, -1.6641e-01, -1.1213e-01,\n          5.9204e-02,  1.4665e-01, -1.5128e-01, -1.0794e-01,  1.3826e-01,\n         -1.5326e-01,  8.4192e-02,  6.0449e-02, -1.9284e-01, -5.3542e-02],\n        [-1.4098e-01, -1.3218e-01, -1.7258e-01,  1.7773e-01, -7.0255e-02,\n         -5.8791e-02,  5.6638e-02, -1.1863e-01, -2.4868e-03,  1.9496e-01,\n         -6.0664e-03,  9.7667e-02, -5.2522e-02,  1.6080e-01,  4.9377e-02,\n         -1.6943e-01, -1.0212e-01,  1.1027e-01,  2.1218e-01, -1.3736e-01],\n        [-1.8063e-01, -9.5274e-02,  6.1455e-02,  8.8203e-02,  8.7634e-02,\n          1.8472e-01,  1.0818e-02, -4.7130e-02,  1.0412e-01,  8.1824e-02,\n          9.1556e-02, -5.8604e-02, -1.0685e-01, -9.5573e-03,  2.0745e-02,\n          4.2613e-02,  7.0001e-03, -7.6141e-02,  2.0115e-01,  1.9919e-01],\n        [-1.0567e-01, -1.3527e-01,  3.1104e-02,  6.3106e-03,  1.0856e-01,\n          4.7059e-02, -1.6990e-01,  1.6920e-02, -1.0779e-01,  2.0034e-01,\n          1.5955e-01,  1.5400e-01, -9.3397e-02, -1.0171e-01, -9.6585e-02,\n         -1.2923e-02,  2.0120e-01, -8.1667e-02, -2.1151e-01, -1.4656e-01],\n        [-3.6108e-02,  2.1223e-01, -3.9540e-02, -1.0272e-01, -9.5407e-02,\n         -1.8662e-01,  4.0347e-02,  2.6142e-02,  1.4666e-01,  2.0014e-01,\n         -2.2027e-01, -1.3389e-01,  1.6732e-01, -5.2711e-02, -3.1334e-02,\n         -8.6971e-02,  3.8172e-02, -2.1794e-01,  1.2569e-01,  1.4027e-01],\n        [-1.5107e-01, -1.4883e-01,  2.0979e-01, -1.1387e-01,  1.9825e-01,\n          2.0607e-01,  1.3922e-01, -1.0679e-01, -6.4653e-03, -9.1551e-02,\n         -1.6973e-01,  1.5536e-01,  7.0354e-02,  3.1978e-02, -1.6581e-02,\n          2.0488e-01,  3.4267e-02,  1.8197e-01,  1.2078e-02, -1.1010e-01],\n        [ 1.3179e-02, -2.0924e-01, -1.4478e-01, -2.3477e-02,  2.0871e-01,\n         -2.4373e-02, -8.2881e-02,  1.6642e-01, -1.9608e-01,  7.2073e-02,\n         -5.0152e-02, -1.6622e-01,  1.3882e-01, -8.6785e-03, -4.8397e-02,\n         -1.1286e-01, -2.0445e-01,  2.0560e-03,  1.1398e-01,  2.0293e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0015,  0.1187,  0.2024, -0.0215,  0.0324,  0.0806,  0.0678, -0.0089,\n        -0.1559, -0.1554, -0.1658,  0.0779,  0.0261, -0.1326,  0.0567,  0.1107,\n        -0.0336,  0.2041,  0.0553,  0.1352,  0.1101,  0.1372,  0.0551, -0.0397,\n         0.0173, -0.2072, -0.1800, -0.1802, -0.0230,  0.2133,  0.1212,  0.2152],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1363,  0.0386,  0.0329,  0.1582, -0.1564,  0.0998,  0.1225,  0.0294,\n          0.0761, -0.0976,  0.1454, -0.0116,  0.0676,  0.0887, -0.1121, -0.1381,\n         -0.1574,  0.0321, -0.0093, -0.0719,  0.0825, -0.0881,  0.1456,  0.0681,\n          0.0115,  0.1515,  0.0654,  0.0875,  0.0237, -0.0910,  0.1372, -0.1332],\n        [-0.1125, -0.0411,  0.0232,  0.0896, -0.0308, -0.1408,  0.0874,  0.0811,\n         -0.0598, -0.0453,  0.1265, -0.0333,  0.1297, -0.0709,  0.1120,  0.0279,\n         -0.0060, -0.1346,  0.1528,  0.0130,  0.0273, -0.1083,  0.0899,  0.0328,\n         -0.1411, -0.1461, -0.1325,  0.0210, -0.0401,  0.1023, -0.0833,  0.0857],\n        [ 0.0460, -0.0983,  0.1225,  0.0454, -0.1568, -0.0950, -0.1468,  0.1632,\n         -0.1351, -0.0289,  0.0054,  0.1601,  0.1339, -0.0381,  0.0260, -0.0697,\n         -0.1503, -0.0202, -0.1541, -0.1399,  0.0042, -0.1079,  0.1672,  0.1196,\n         -0.1165,  0.0269, -0.1463, -0.1098, -0.1018,  0.1738,  0.0953, -0.0721],\n        [ 0.0882,  0.0577, -0.1703,  0.1108,  0.1732,  0.1300,  0.0976, -0.1347,\n          0.0870, -0.0516, -0.1358, -0.0162, -0.1064,  0.1306,  0.0757,  0.1549,\n          0.0067,  0.0757,  0.0222, -0.0143,  0.1715,  0.1577,  0.1389, -0.1171,\n         -0.1370, -0.0341,  0.0378, -0.1535,  0.1045, -0.1385, -0.0469,  0.0486],\n        [-0.0655, -0.0016,  0.0338, -0.1438,  0.0913,  0.1249,  0.0697, -0.1481,\n          0.1380,  0.0559, -0.0549, -0.1491,  0.1487, -0.1513,  0.0619, -0.1592,\n         -0.0884, -0.0887,  0.0452,  0.0052,  0.0560, -0.1013, -0.0026, -0.0024,\n          0.0968,  0.0667,  0.1540,  0.0796,  0.1467, -0.0954,  0.1586, -0.0584],\n        [-0.1027,  0.1679,  0.0951,  0.0378,  0.0077, -0.0563, -0.0400, -0.1278,\n          0.0246, -0.1471, -0.1458,  0.1635,  0.0074, -0.0892, -0.0833,  0.0874,\n          0.0870, -0.0537,  0.1304,  0.1736,  0.0694, -0.0363,  0.0741, -0.0127,\n         -0.0764,  0.1213, -0.0025, -0.0316, -0.1021,  0.0366,  0.1428, -0.0695],\n        [-0.1204,  0.0373,  0.0542, -0.1006,  0.0477, -0.0398,  0.0051,  0.1043,\n         -0.1296,  0.0209, -0.0979, -0.0073, -0.0679, -0.0247, -0.0184,  0.0963,\n         -0.0812,  0.1265, -0.0295, -0.1299, -0.1472, -0.1766, -0.1488,  0.0389,\n         -0.1625, -0.0191, -0.0898, -0.0462, -0.0995,  0.0137,  0.0156, -0.0410],\n        [-0.0285,  0.0738,  0.0160, -0.1423, -0.0611, -0.0009,  0.0477,  0.0418,\n         -0.0177, -0.0046, -0.0717, -0.0856, -0.0334,  0.1121,  0.1265,  0.1079,\n          0.1047,  0.0497, -0.0343,  0.1153,  0.0958,  0.1450, -0.0835,  0.1346,\n          0.1156, -0.1619,  0.0350,  0.1570,  0.0015, -0.0645, -0.1281,  0.1408],\n        [ 0.1595, -0.0171,  0.1398, -0.0913, -0.0032,  0.0978,  0.0746, -0.1096,\n          0.0378, -0.0263,  0.0047,  0.0598,  0.1467,  0.0706, -0.1576, -0.0354,\n          0.0419,  0.0718, -0.0273,  0.1641,  0.0441,  0.0695,  0.0554, -0.0725,\n          0.1080,  0.0363, -0.1374, -0.1170,  0.0394, -0.1576,  0.0585,  0.1018],\n        [ 0.0906, -0.0109, -0.1404, -0.1272, -0.0407, -0.0308, -0.0361, -0.0820,\n         -0.0665, -0.0358,  0.0880, -0.0586, -0.0757,  0.0230, -0.0223,  0.0924,\n          0.0309, -0.0958,  0.0950, -0.1404, -0.0760,  0.1510,  0.0912,  0.0224,\n         -0.0228, -0.0799,  0.0710,  0.0927,  0.0275, -0.0242,  0.1193,  0.0897],\n        [ 0.1116, -0.0923,  0.1166,  0.0306, -0.0721, -0.1530,  0.1294, -0.1443,\n         -0.0713, -0.1425, -0.1159, -0.0956,  0.0377,  0.1629, -0.1349,  0.1048,\n         -0.0443, -0.0678, -0.0364, -0.0777,  0.0622, -0.0258, -0.0502, -0.1581,\n         -0.0417,  0.0930, -0.1271, -0.1671,  0.0489,  0.0185, -0.1656,  0.0283],\n        [ 0.0381, -0.0190,  0.0918, -0.0907, -0.0386,  0.1498,  0.0566, -0.1635,\n          0.0563, -0.0009, -0.1475,  0.0663, -0.1618,  0.0913, -0.1094, -0.0734,\n          0.0863,  0.0624, -0.0283,  0.1050,  0.0148, -0.1234, -0.1359, -0.0508,\n         -0.1741, -0.1598, -0.1392,  0.0393,  0.1047,  0.1636,  0.0851, -0.0635],\n        [-0.1156,  0.0246,  0.0286,  0.0794, -0.1062, -0.0064, -0.1469,  0.1151,\n         -0.0782,  0.1511, -0.1583,  0.0774,  0.0125,  0.1764,  0.0705, -0.0398,\n          0.1585,  0.1178,  0.1080, -0.1449, -0.0319, -0.0125, -0.0161, -0.1411,\n          0.0293,  0.0206, -0.1293,  0.0810, -0.0048,  0.0651, -0.1568,  0.1326],\n        [-0.0601, -0.0005, -0.1481, -0.0028, -0.0602,  0.0260,  0.0711, -0.0967,\n          0.0541,  0.0469, -0.0359, -0.0924, -0.1709, -0.1709, -0.1082,  0.1559,\n         -0.0740,  0.0133, -0.1060, -0.0066,  0.1685, -0.1103,  0.0777,  0.0283,\n          0.1349, -0.0756,  0.1429, -0.0888, -0.0147,  0.1284, -0.0049, -0.1439],\n        [ 0.1735, -0.0785, -0.0204,  0.1359,  0.0618, -0.1748, -0.0475,  0.1158,\n         -0.0459,  0.1330, -0.1069,  0.1733, -0.0027, -0.1744, -0.1021,  0.1143,\n          0.0462,  0.1739,  0.0101,  0.1562, -0.0343,  0.1229,  0.0939,  0.1292,\n         -0.1092, -0.0718,  0.0939,  0.0198,  0.1706, -0.1343,  0.1758, -0.0690],\n        [ 0.1082, -0.1026,  0.0953, -0.1367,  0.1468,  0.0320, -0.0226,  0.1599,\n         -0.1531,  0.0729,  0.0197,  0.1736,  0.1382,  0.1333,  0.0086, -0.1356,\n          0.1097, -0.0790, -0.0872, -0.1749,  0.0820, -0.0684,  0.0244, -0.1680,\n         -0.0527, -0.1372,  0.0429,  0.0251,  0.0485, -0.0603,  0.0486,  0.0172]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1366,  0.0640, -0.0426, -0.1609,  0.1282,  0.0082,  0.0159, -0.0327,\n        -0.0253,  0.1135,  0.1508, -0.1487,  0.1020, -0.0912, -0.0777, -0.0662],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1690,  0.1350,  0.1976, -0.2451,  0.1019, -0.0883,  0.0739,  0.0880,\n          0.0777,  0.1995,  0.1587,  0.2160, -0.1400, -0.0495,  0.0725, -0.0557],\n        [-0.1951, -0.0233,  0.0461,  0.0550, -0.0616, -0.0647, -0.2476,  0.0947,\n         -0.1492,  0.1140, -0.2315, -0.1391, -0.2438, -0.0183,  0.1148,  0.1815],\n        [ 0.0291,  0.2307,  0.2285, -0.0292, -0.2307,  0.1844, -0.1105,  0.1633,\n          0.1560,  0.1854,  0.1247,  0.1163,  0.1823,  0.2273, -0.1614, -0.1117],\n        [-0.1584,  0.1941, -0.0862,  0.0184, -0.0531,  0.1087, -0.0441,  0.2458,\n         -0.0101, -0.2463,  0.1917,  0.2363,  0.0688,  0.1869,  0.0422, -0.2070],\n        [-0.1495, -0.1095,  0.1635,  0.1801, -0.2208, -0.1478,  0.0249,  0.1101,\n         -0.0972,  0.1202, -0.0961, -0.0948,  0.1252, -0.0200, -0.0515, -0.0712],\n        [-0.0144,  0.1158, -0.1119, -0.1138,  0.0996,  0.1257, -0.2406,  0.2464,\n         -0.1923,  0.0223, -0.0833,  0.2085, -0.2073, -0.0167, -0.1502,  0.0374],\n        [-0.1416, -0.0649,  0.0765,  0.1626,  0.2235, -0.0219, -0.0752, -0.1912,\n         -0.0222,  0.2420,  0.1706, -0.2302, -0.1427,  0.0676, -0.2215, -0.2387],\n        [-0.1911,  0.1548, -0.0100, -0.1142, -0.1870,  0.0778, -0.1203, -0.2149,\n          0.1867, -0.2351,  0.0503, -0.0277, -0.1627, -0.2031, -0.2311, -0.0176]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0437,  0.0848,  0.1883,  0.1386,  0.1998,  0.2059, -0.1808, -0.2261],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1749, -0.0600,  0.1086, -0.0646, -0.2196,  0.2542,  0.2494, -0.0164]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2681], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x0000021B41BEB820>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x0000021B40F9E860>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s168960000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='D:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\maze-game\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s168960000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}