{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s211750000"
    },
    "q_lr":	0.0005,
    "seed":	211750000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7ab079a135d0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1221, -0.0942, -0.0837, -0.1439, -0.1773, -0.1226,  0.1412,  0.1942,\n        -0.0379, -0.0056, -0.0806, -0.1258, -0.0883, -0.0641,  0.1203,  0.1389,\n        -0.0222, -0.1575, -0.2070,  0.1630, -0.1863,  0.1179,  0.1144, -0.1852,\n         0.0359, -0.1061, -0.1077,  0.0659,  0.1135,  0.1084, -0.1139, -0.0150],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0290,  0.0565,  0.1741,  0.2156, -0.1304, -0.1236, -0.2041, -0.0439,\n         -0.1023, -0.1280, -0.1282,  0.1833, -0.0441,  0.1262,  0.0779,  0.1742,\n         -0.0038,  0.2205, -0.1584,  0.1809],\n        [ 0.1527,  0.0869,  0.1706, -0.1017, -0.0879, -0.1361,  0.0454,  0.1970,\n          0.1897,  0.1597, -0.1541,  0.0779,  0.2186,  0.0110, -0.1346, -0.0728,\n          0.1780, -0.0734, -0.1585, -0.0172],\n        [-0.1034, -0.0007,  0.0789, -0.1361, -0.0580, -0.0455,  0.0753, -0.1822,\n          0.0478,  0.1647, -0.0364, -0.1255, -0.2028,  0.1770, -0.1869, -0.0559,\n         -0.0300,  0.0949,  0.2083, -0.0094],\n        [ 0.0335,  0.0654, -0.1851, -0.1624, -0.1258,  0.0407, -0.1825,  0.1817,\n          0.1608, -0.1971, -0.1705,  0.2063,  0.1976, -0.0007,  0.2136, -0.1674,\n         -0.0204, -0.0226,  0.0596,  0.0621],\n        [ 0.2219, -0.0457,  0.0348, -0.0475, -0.0130,  0.0831,  0.2158, -0.0046,\n         -0.0902,  0.0666,  0.2063, -0.0903,  0.1860,  0.1234, -0.1144,  0.0127,\n          0.0871,  0.0755, -0.0694,  0.0256],\n        [ 0.0639,  0.2161, -0.0297,  0.1305, -0.1226, -0.1070,  0.1799,  0.0890,\n         -0.0992,  0.1911,  0.1372, -0.1385, -0.1754,  0.1951, -0.2200,  0.2107,\n         -0.0809,  0.0722,  0.1365,  0.0153],\n        [-0.1556, -0.0302,  0.0076, -0.0790,  0.0349,  0.1006, -0.0901,  0.1190,\n         -0.0018, -0.0285, -0.1374, -0.0375, -0.0137,  0.1157, -0.1340, -0.0722,\n          0.0663, -0.2037,  0.2006, -0.1275],\n        [-0.1303,  0.2092, -0.0512, -0.0548,  0.1670,  0.1095, -0.1029,  0.1969,\n          0.2159,  0.1815, -0.2010, -0.1310,  0.0638,  0.0928,  0.0920, -0.0447,\n         -0.0051, -0.1856, -0.0950,  0.0600],\n        [-0.1875, -0.1867, -0.0340,  0.1643,  0.0161,  0.0041,  0.1926,  0.0333,\n         -0.1598, -0.1457, -0.1289, -0.2038, -0.2010,  0.0958,  0.1300, -0.1702,\n         -0.2062, -0.1849, -0.1410, -0.0631],\n        [-0.2209, -0.1104,  0.1394, -0.0956, -0.0293, -0.1892,  0.1332,  0.1205,\n         -0.1034,  0.2016, -0.1055,  0.0558,  0.0216, -0.1830,  0.0173, -0.0515,\n          0.0411, -0.1795,  0.0399,  0.1247],\n        [-0.0548, -0.1303, -0.1718,  0.0618,  0.1093, -0.1822, -0.0424,  0.1775,\n          0.1272, -0.0710,  0.1662, -0.0826, -0.1143,  0.1456, -0.0056, -0.2006,\n          0.1558, -0.0929,  0.0009, -0.1867],\n        [-0.1560,  0.1702, -0.0319, -0.0119,  0.0226, -0.1818, -0.0745,  0.0218,\n         -0.1638, -0.0848,  0.1553,  0.1610, -0.1574,  0.1135,  0.0194, -0.2030,\n         -0.1104, -0.0444,  0.0540,  0.1141],\n        [-0.1164,  0.1392,  0.1104, -0.1284, -0.2071,  0.1040,  0.1941, -0.0006,\n          0.0487, -0.0082, -0.0053,  0.2148,  0.1044, -0.1313,  0.1233, -0.0271,\n          0.0046, -0.1727,  0.1824, -0.0645],\n        [ 0.1197,  0.1838, -0.0413, -0.1915,  0.1492, -0.0549,  0.1993,  0.1167,\n          0.1367, -0.0901, -0.1434,  0.1515, -0.1385, -0.1893, -0.2162,  0.1582,\n         -0.0973, -0.1894, -0.0712,  0.1869],\n        [-0.1891, -0.0766,  0.1700,  0.1493,  0.1125,  0.1723, -0.2021, -0.1467,\n          0.1225,  0.0313, -0.0423,  0.0387, -0.1091, -0.0736, -0.1122,  0.1009,\n         -0.1616, -0.0451,  0.2227, -0.1148],\n        [-0.0764,  0.1135,  0.0434, -0.1528, -0.0727,  0.0454,  0.0638,  0.1387,\n          0.0192,  0.0168, -0.0590, -0.1037,  0.0286, -0.1646, -0.1159, -0.2062,\n          0.2049, -0.1903, -0.1543,  0.1453],\n        [ 0.0052,  0.0697,  0.0351, -0.1023,  0.1817,  0.0959,  0.0876, -0.1899,\n         -0.1249, -0.1651, -0.1280, -0.1583, -0.1421,  0.1566, -0.0457, -0.1440,\n         -0.0210,  0.0536, -0.1579, -0.1194],\n        [ 0.2099,  0.2188, -0.0452,  0.0165, -0.0926,  0.0497, -0.2117, -0.1394,\n         -0.1060, -0.1150, -0.1206,  0.0406, -0.2018,  0.0928,  0.0193, -0.0664,\n         -0.0889,  0.0376, -0.0749, -0.1048],\n        [-0.0354,  0.2168,  0.1830, -0.0777, -0.1898, -0.2218,  0.0706,  0.0354,\n          0.0952, -0.1037, -0.1473,  0.1898,  0.0758,  0.0462, -0.2079,  0.0518,\n          0.0521,  0.0372, -0.0206,  0.0688],\n        [ 0.0312, -0.1220, -0.1505,  0.1815,  0.0975, -0.1758, -0.2036, -0.0684,\n         -0.0701, -0.0123, -0.2112, -0.2134,  0.0474,  0.0071,  0.1265,  0.0206,\n         -0.0510,  0.1019,  0.2027,  0.1901],\n        [-0.1170,  0.0493,  0.0289,  0.1725, -0.1476, -0.1223,  0.0166, -0.1186,\n          0.1879, -0.2114,  0.1664,  0.1601, -0.1075,  0.1844,  0.1220,  0.1846,\n         -0.2224, -0.0003, -0.1122, -0.1153],\n        [ 0.1522,  0.1020, -0.1487, -0.1890,  0.0382,  0.1609,  0.0525,  0.0734,\n          0.1910,  0.0720, -0.1207, -0.0470, -0.0732,  0.0588,  0.0280,  0.1345,\n          0.0099,  0.0122, -0.0659,  0.0636],\n        [-0.0012, -0.1531,  0.0313, -0.0003,  0.0378, -0.1088,  0.1006,  0.1538,\n         -0.0397, -0.0409,  0.2082,  0.2205,  0.0836, -0.1630, -0.1582,  0.0010,\n         -0.0930,  0.0792, -0.0843,  0.0512],\n        [ 0.1347,  0.0596, -0.1095,  0.1099,  0.0028, -0.1625,  0.1633, -0.1098,\n         -0.1537,  0.2146,  0.1604,  0.2132, -0.0809,  0.0311,  0.0148, -0.1676,\n          0.2011, -0.1547,  0.1314, -0.0084],\n        [ 0.1651, -0.1571, -0.1037, -0.1625, -0.1279, -0.0829, -0.0489, -0.2051,\n         -0.1473,  0.0511,  0.1903,  0.0738,  0.1348,  0.2030, -0.0703,  0.1480,\n          0.1726, -0.0412,  0.1691,  0.1839],\n        [ 0.1636, -0.1944,  0.1411,  0.0035, -0.1733,  0.1232,  0.1805,  0.1088,\n          0.1783,  0.1289, -0.0834, -0.1501, -0.1255, -0.1695, -0.0625,  0.1034,\n         -0.1826,  0.1363,  0.2115, -0.1970],\n        [-0.0702, -0.0598, -0.1956, -0.2234, -0.1612, -0.0787, -0.1024,  0.1652,\n          0.0592,  0.1639,  0.1891, -0.1084, -0.1723,  0.1120,  0.0056, -0.0855,\n          0.1870,  0.1821,  0.2218,  0.0017],\n        [-0.1086,  0.2082,  0.1084, -0.0791, -0.1503,  0.1143,  0.1400, -0.1267,\n         -0.1509, -0.2093,  0.1207, -0.0658,  0.2153,  0.1705, -0.0086, -0.1291,\n          0.0891, -0.0405,  0.0639, -0.0401],\n        [ 0.0461,  0.0635,  0.0062,  0.0705,  0.0377,  0.0770,  0.1167, -0.0124,\n         -0.1904,  0.2140,  0.2168,  0.0318, -0.0569, -0.0976,  0.0055, -0.1942,\n         -0.1376,  0.0390, -0.0939, -0.2070],\n        [-0.1100, -0.1850, -0.1360,  0.1095, -0.1711, -0.0643,  0.2093,  0.0270,\n          0.0201, -0.1795,  0.0969, -0.2206,  0.1777,  0.0032, -0.0829, -0.1072,\n         -0.0820,  0.0682, -0.0744, -0.2160],\n        [ 0.0108,  0.2125,  0.0958, -0.1316, -0.0314,  0.0256, -0.0290, -0.1477,\n          0.0241,  0.0688, -0.0303,  0.0185, -0.1786, -0.1726, -0.1434,  0.1232,\n          0.1667, -0.1143,  0.0313,  0.1575],\n        [-0.0513, -0.2038, -0.0631, -0.0976,  0.1019, -0.0839, -0.1680, -0.0075,\n         -0.0648,  0.0915,  0.1371, -0.1844, -0.1875, -0.1859, -0.2035,  0.0881,\n         -0.1884,  0.1752, -0.0915, -0.0539]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1034,  0.0506, -0.0563,  0.1244,  0.0876,  0.0552,  0.1569, -0.0220,\n         0.0548, -0.0258,  0.1555, -0.0818,  0.0865, -0.1171,  0.1594,  0.0884],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0022e-01, -8.9776e-02,  3.9883e-02, -1.5371e-01,  1.3141e-01,\n          1.2691e-02, -1.1653e-01,  7.6506e-02, -1.6903e-01,  5.7165e-02,\n         -1.3315e-01,  9.8475e-02, -2.2188e-02, -1.1739e-01, -7.8354e-02,\n         -1.1696e-01, -7.9379e-02,  2.0049e-02, -1.5287e-01,  1.0419e-01,\n          1.0075e-01, -1.0531e-01, -1.2070e-01,  3.8492e-02, -5.3738e-02,\n          8.9927e-02,  1.0790e-01,  2.0207e-02,  1.5857e-01, -1.7052e-01,\n         -1.3534e-01, -6.7967e-02],\n        [ 5.3794e-02, -1.5418e-01,  7.6243e-02,  7.7802e-03,  2.1563e-02,\n         -1.1583e-01,  1.4906e-01, -7.0255e-02, -8.7957e-02, -9.2516e-02,\n         -4.4279e-02, -4.9584e-02, -5.3818e-03, -7.1583e-02,  3.4696e-02,\n          1.1216e-01, -4.1458e-02,  3.3474e-02,  3.3311e-02,  9.3157e-03,\n          8.2979e-02,  6.3194e-02,  7.9388e-02,  9.5271e-02,  1.0189e-01,\n         -3.2556e-02, -4.1983e-02,  3.2888e-02,  7.1484e-02, -1.3751e-01,\n         -1.6318e-01,  1.5266e-01],\n        [ 1.3379e-02,  1.0755e-01, -4.9843e-02,  1.3385e-02, -8.6897e-02,\n         -1.6853e-01,  4.3012e-02,  5.0699e-02, -2.3541e-02, -1.1891e-01,\n         -7.1028e-02,  1.3110e-01,  4.6099e-02, -1.3714e-01, -1.2312e-02,\n          4.5692e-02,  1.3687e-01, -1.6870e-01, -1.5285e-01,  1.4648e-01,\n         -1.5899e-01,  1.1641e-01,  1.3229e-01, -7.4882e-02,  1.4167e-01,\n         -7.3400e-02, -3.2980e-02, -8.5098e-02,  3.2280e-02,  1.6047e-01,\n          1.5392e-01, -1.0738e-01],\n        [ 5.5391e-02, -1.5963e-02, -3.7638e-02,  9.0069e-02,  1.4442e-01,\n         -1.2489e-01, -1.7016e-01,  1.2970e-01, -1.1872e-01,  1.7411e-01,\n         -8.9305e-02,  1.3647e-01,  1.6976e-01, -1.4026e-01,  3.0125e-02,\n          3.8211e-03,  1.5874e-01, -5.9442e-02,  1.3796e-01,  5.4064e-02,\n         -6.7172e-02,  1.3907e-01,  1.0385e-01, -1.6559e-01, -9.3015e-02,\n          1.2245e-01, -1.6536e-01,  1.0633e-01, -1.2299e-01, -3.7431e-02,\n         -8.5442e-02,  9.7598e-02],\n        [ 4.5469e-03, -3.5707e-02,  9.4891e-02,  1.3139e-01,  3.7965e-02,\n         -7.0530e-02, -4.7107e-02, -3.8089e-02, -5.4999e-02, -3.2333e-02,\n          6.0216e-02,  1.1664e-01,  1.4209e-01,  5.1992e-02,  1.5464e-01,\n          1.5146e-01, -4.0780e-02, -1.2524e-01, -9.3280e-02, -1.4561e-01,\n          8.1264e-02,  1.1497e-01,  1.3758e-01, -1.1170e-01,  1.1981e-02,\n          9.6624e-02, -3.3924e-02, -7.6213e-02,  5.5779e-02, -3.0516e-02,\n          1.3847e-01, -6.1048e-02],\n        [-6.3140e-02,  1.0880e-01,  1.2997e-01, -4.4416e-02, -5.0529e-02,\n          6.2785e-02, -8.2859e-02,  9.8807e-02, -7.6243e-02, -1.0440e-01,\n         -9.0612e-02, -3.3605e-02, -2.0041e-02,  2.1134e-02,  5.9653e-02,\n         -1.3695e-01,  1.0885e-01, -9.3909e-02, -1.1433e-01,  1.2652e-01,\n          9.9004e-02,  6.3158e-02, -1.6508e-02, -4.9263e-02, -5.1668e-02,\n          1.7178e-01,  5.0204e-02, -6.6519e-02,  1.4785e-01, -5.4126e-02,\n         -1.3023e-01, -2.6704e-02],\n        [-5.5096e-02,  1.5386e-01, -1.0992e-01,  1.0389e-02,  3.5115e-02,\n          1.6927e-01,  2.5576e-02,  3.3153e-02, -1.2501e-01,  3.0095e-02,\n         -1.0753e-01, -9.7943e-02,  7.5417e-02,  1.2473e-01, -1.4681e-01,\n          1.1503e-01,  9.5743e-02, -8.4165e-03, -8.6468e-02, -7.7657e-02,\n         -1.7126e-01, -1.6778e-01, -2.3783e-02,  9.6809e-03,  3.8113e-02,\n          1.6973e-01,  6.4901e-02, -9.7169e-02, -1.5630e-01,  8.2746e-02,\n          1.1964e-01,  3.2351e-02],\n        [-1.1873e-01,  7.6070e-02, -6.2159e-02,  1.4841e-02, -3.1261e-02,\n         -5.5258e-02, -2.3289e-02,  1.0671e-01,  6.1311e-02,  1.6261e-01,\n          9.5685e-02, -1.3410e-01,  7.2614e-02, -7.1012e-02,  4.2203e-02,\n          1.0409e-02,  5.7422e-02, -1.4610e-01, -7.3246e-02, -1.0971e-01,\n         -1.7267e-01, -2.6794e-02,  8.0849e-02,  4.9164e-02, -1.3526e-01,\n         -3.7182e-02,  1.1716e-01, -1.5379e-01, -5.6189e-02,  1.1729e-01,\n          1.2664e-01,  2.6440e-02],\n        [-9.2250e-02, -3.2114e-03,  3.9460e-04, -1.2232e-01,  1.6308e-01,\n          3.0456e-02,  8.5654e-03,  1.6014e-01, -4.8866e-03, -7.4416e-02,\n          9.5551e-02,  4.3678e-02, -1.2892e-01,  1.7198e-01,  6.7769e-02,\n         -8.2905e-02,  5.1582e-02,  1.3969e-01, -8.7498e-02, -5.5720e-02,\n         -1.1584e-01, -1.7060e-01, -1.5615e-01, -4.5051e-02, -8.8633e-02,\n         -1.4405e-01, -1.6342e-01,  1.6015e-01,  7.1273e-03,  6.8635e-02,\n          9.3942e-02, -1.4993e-01],\n        [ 4.2256e-04,  1.0443e-01,  6.2242e-02, -1.3787e-01,  2.8406e-02,\n         -7.8801e-02,  3.8572e-02,  1.7027e-01,  1.6389e-01,  2.0541e-02,\n          1.3156e-01, -1.2413e-01,  1.4046e-01, -7.5193e-02, -1.1878e-01,\n          6.4385e-02,  3.6787e-02, -1.7198e-01, -9.0058e-02,  6.7300e-02,\n         -5.8832e-02, -1.1218e-01,  7.6739e-03,  9.9331e-02,  1.1697e-02,\n          6.4981e-02, -1.6488e-01,  2.8446e-02,  1.3222e-01,  3.5595e-02,\n          1.1983e-01,  8.1019e-02],\n        [ 5.2372e-02,  8.6845e-02,  2.0013e-02, -1.2833e-01, -1.5826e-01,\n         -8.9240e-02, -4.6678e-02,  1.2585e-01,  1.5742e-01, -3.5005e-02,\n         -1.2511e-01, -1.6439e-01,  1.3226e-01, -1.4766e-01,  1.0190e-03,\n          1.1196e-01,  5.3766e-02, -3.8394e-02,  1.4933e-01, -3.6250e-02,\n          2.3916e-02, -1.4229e-01,  1.6214e-02,  1.1854e-01, -1.4479e-01,\n          1.0838e-01, -3.8005e-02,  2.9810e-03,  8.0736e-02,  4.2175e-02,\n         -7.0890e-02, -1.5780e-01],\n        [-2.4165e-02,  1.8858e-02, -3.0177e-02,  2.4718e-03,  1.4002e-01,\n         -6.2535e-02, -6.8579e-03, -1.6104e-03,  2.2624e-02, -2.8211e-02,\n          1.0879e-01,  1.5139e-01,  1.1890e-01,  2.0468e-02, -1.4122e-01,\n         -1.0016e-01, -5.6284e-02, -3.8592e-02, -1.2617e-01, -1.4700e-01,\n         -1.6071e-01,  5.8256e-02, -1.7463e-01,  5.9053e-02, -3.1166e-03,\n         -2.4459e-02,  1.0125e-01, -9.9324e-03, -1.7598e-01, -5.5863e-02,\n          1.0362e-01,  1.1326e-01],\n        [ 5.0441e-02, -3.8858e-02, -9.8103e-02, -1.2661e-01, -1.6165e-01,\n          1.3767e-01, -2.6961e-02,  7.9155e-02,  1.2397e-01,  3.2043e-02,\n          1.0023e-01, -9.4581e-02, -1.0086e-01, -5.4303e-02, -9.7957e-02,\n          1.0132e-02, -1.3021e-02, -9.9809e-02, -5.6943e-02, -1.9882e-02,\n          1.7420e-01, -1.6634e-01, -9.2108e-02, -1.7286e-01,  3.3512e-02,\n          3.5846e-02,  5.9268e-02, -5.7766e-02, -1.1437e-01, -1.1514e-01,\n         -1.4356e-01, -1.1081e-01],\n        [-1.3115e-01, -2.6359e-02, -1.3619e-01,  1.2518e-01,  1.5408e-01,\n          5.0231e-02,  1.0086e-01, -1.6656e-01,  9.6707e-02, -1.7517e-01,\n          8.7269e-02,  7.3642e-02, -1.3570e-01, -1.2520e-01,  9.8961e-02,\n          4.6981e-02,  7.9455e-02,  5.9112e-02,  1.0858e-01, -1.3420e-01,\n         -1.0768e-02, -1.3194e-01,  9.7963e-02, -2.7816e-02,  6.2851e-02,\n         -8.2640e-02,  1.2767e-01,  3.6426e-02,  2.8656e-02,  3.4503e-02,\n         -1.4643e-01, -2.4456e-02],\n        [ 1.2826e-02, -1.3391e-01,  5.3600e-02,  3.1792e-02, -9.1091e-02,\n         -1.1258e-01, -1.1244e-01,  7.9504e-02, -1.2390e-01,  1.3750e-01,\n          7.5579e-02,  6.3293e-02, -1.4626e-02, -2.8207e-02,  1.2415e-01,\n          1.1189e-01,  1.1602e-01, -1.3808e-01, -1.4105e-01,  6.9227e-02,\n          4.8168e-02, -7.4571e-02,  2.3457e-02,  1.0444e-01, -6.8875e-02,\n         -3.5199e-03, -7.8750e-02,  2.5279e-02,  1.4902e-01,  1.0122e-01,\n         -6.6458e-02,  3.4953e-02],\n        [-1.6003e-01, -1.2173e-01, -2.5266e-02, -7.3611e-02, -3.5270e-02,\n         -1.6920e-02, -1.1762e-01,  1.5477e-01, -9.9108e-05, -1.0638e-01,\n          1.1007e-01,  2.3434e-02, -7.3039e-02,  8.8520e-02,  6.1135e-02,\n          1.2741e-01,  2.7308e-02, -2.2513e-02,  1.4223e-01, -8.4373e-02,\n         -2.7923e-02, -1.3246e-02,  2.6834e-03,  3.5940e-02,  1.3376e-03,\n         -6.1082e-03,  3.7504e-02,  6.3136e-02,  7.5125e-02, -1.1722e-01,\n         -8.1380e-02,  1.1408e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1760,  0.1772, -0.0969, -0.1525, -0.0045,  0.0529,  0.2220,  0.2420],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1808, -0.2440,  0.0387, -0.0853, -0.0571,  0.0256,  0.1895,  0.2201,\n          0.1659,  0.2057, -0.1301, -0.1698,  0.1163,  0.0684, -0.2219, -0.0021],\n        [ 0.0862, -0.1469, -0.0907,  0.0476, -0.1739, -0.0105, -0.0810,  0.2475,\n          0.2347,  0.2177, -0.0901, -0.0054,  0.1192,  0.2141,  0.0830, -0.1226],\n        [-0.1574, -0.1499, -0.0380,  0.2220,  0.0237, -0.1618, -0.2281,  0.1179,\n         -0.0599,  0.2086, -0.0308, -0.1149, -0.2060,  0.0994, -0.0665,  0.2117],\n        [-0.1216,  0.1404, -0.2049, -0.1650,  0.0436, -0.2330, -0.0880,  0.2065,\n          0.0541,  0.1551, -0.0699, -0.2043,  0.0291, -0.2212,  0.2036, -0.0977],\n        [ 0.0899,  0.1145, -0.1534,  0.0971, -0.1956, -0.1488, -0.1712,  0.0670,\n          0.1528,  0.0137, -0.1138,  0.2111,  0.1611, -0.1031,  0.0925,  0.1566],\n        [ 0.1544,  0.1435, -0.0063,  0.0069,  0.2423, -0.1249, -0.1896, -0.0159,\n         -0.0724, -0.0656,  0.0498,  0.2377,  0.2053,  0.0357, -0.0539,  0.0751],\n        [ 0.1144,  0.0333,  0.1446,  0.0008,  0.1778,  0.1316, -0.0298,  0.0607,\n         -0.0578, -0.1671,  0.0082, -0.0573, -0.0601,  0.0834, -0.1703, -0.0042],\n        [ 0.1253, -0.1455,  0.0764, -0.2095,  0.1371,  0.0588, -0.1029, -0.2272,\n         -0.1642, -0.2076, -0.2155,  0.0105, -0.1132, -0.1625, -0.1224,  0.0604]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1848,  0.2135,  0.1263, -0.2696], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1118,  0.1704,  0.2950, -0.0093, -0.3044, -0.0547, -0.0016,  0.0840],\n        [-0.1517,  0.1385,  0.1181,  0.3182,  0.1494,  0.2541, -0.2985,  0.3352],\n        [ 0.0828, -0.2265,  0.2126,  0.3227, -0.2439,  0.1330,  0.3183, -0.0478],\n        [-0.0937, -0.1865,  0.1608, -0.2563,  0.2086, -0.2778,  0.0923,  0.2415]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0290,  0.0565,  0.1741,  0.2156, -0.1304, -0.1236, -0.2041, -0.0439,\n         -0.1023, -0.1280, -0.1282,  0.1833, -0.0441,  0.1262,  0.0779,  0.1742,\n         -0.0038,  0.2205, -0.1584,  0.1809],\n        [ 0.1527,  0.0869,  0.1706, -0.1017, -0.0879, -0.1361,  0.0454,  0.1970,\n          0.1897,  0.1597, -0.1541,  0.0779,  0.2186,  0.0110, -0.1346, -0.0728,\n          0.1780, -0.0734, -0.1585, -0.0172],\n        [-0.1034, -0.0007,  0.0789, -0.1361, -0.0580, -0.0455,  0.0753, -0.1822,\n          0.0478,  0.1647, -0.0364, -0.1255, -0.2028,  0.1770, -0.1869, -0.0559,\n         -0.0300,  0.0949,  0.2083, -0.0094],\n        [ 0.0335,  0.0654, -0.1851, -0.1624, -0.1258,  0.0407, -0.1825,  0.1817,\n          0.1608, -0.1971, -0.1705,  0.2063,  0.1976, -0.0007,  0.2136, -0.1674,\n         -0.0204, -0.0226,  0.0596,  0.0621],\n        [ 0.2219, -0.0457,  0.0348, -0.0475, -0.0130,  0.0831,  0.2158, -0.0046,\n         -0.0902,  0.0666,  0.2063, -0.0903,  0.1860,  0.1234, -0.1144,  0.0127,\n          0.0871,  0.0755, -0.0694,  0.0256],\n        [ 0.0639,  0.2161, -0.0297,  0.1305, -0.1226, -0.1070,  0.1799,  0.0890,\n         -0.0992,  0.1911,  0.1372, -0.1385, -0.1754,  0.1951, -0.2200,  0.2107,\n         -0.0809,  0.0722,  0.1365,  0.0153],\n        [-0.1556, -0.0302,  0.0076, -0.0790,  0.0349,  0.1006, -0.0901,  0.1190,\n         -0.0018, -0.0285, -0.1374, -0.0375, -0.0137,  0.1157, -0.1340, -0.0722,\n          0.0663, -0.2037,  0.2006, -0.1275],\n        [-0.1303,  0.2092, -0.0512, -0.0548,  0.1670,  0.1095, -0.1029,  0.1969,\n          0.2159,  0.1815, -0.2010, -0.1310,  0.0638,  0.0928,  0.0920, -0.0447,\n         -0.0051, -0.1856, -0.0950,  0.0600],\n        [-0.1875, -0.1867, -0.0340,  0.1643,  0.0161,  0.0041,  0.1926,  0.0333,\n         -0.1598, -0.1457, -0.1289, -0.2038, -0.2010,  0.0958,  0.1300, -0.1702,\n         -0.2062, -0.1849, -0.1410, -0.0631],\n        [-0.2209, -0.1104,  0.1394, -0.0956, -0.0293, -0.1892,  0.1332,  0.1205,\n         -0.1034,  0.2016, -0.1055,  0.0558,  0.0216, -0.1830,  0.0173, -0.0515,\n          0.0411, -0.1795,  0.0399,  0.1247],\n        [-0.0548, -0.1303, -0.1718,  0.0618,  0.1093, -0.1822, -0.0424,  0.1775,\n          0.1272, -0.0710,  0.1662, -0.0826, -0.1143,  0.1456, -0.0056, -0.2006,\n          0.1558, -0.0929,  0.0009, -0.1867],\n        [-0.1560,  0.1702, -0.0319, -0.0119,  0.0226, -0.1818, -0.0745,  0.0218,\n         -0.1638, -0.0848,  0.1553,  0.1610, -0.1574,  0.1135,  0.0194, -0.2030,\n         -0.1104, -0.0444,  0.0540,  0.1141],\n        [-0.1164,  0.1392,  0.1104, -0.1284, -0.2071,  0.1040,  0.1941, -0.0006,\n          0.0487, -0.0082, -0.0053,  0.2148,  0.1044, -0.1313,  0.1233, -0.0271,\n          0.0046, -0.1727,  0.1824, -0.0645],\n        [ 0.1197,  0.1838, -0.0413, -0.1915,  0.1492, -0.0549,  0.1993,  0.1167,\n          0.1367, -0.0901, -0.1434,  0.1515, -0.1385, -0.1893, -0.2162,  0.1582,\n         -0.0973, -0.1894, -0.0712,  0.1869],\n        [-0.1891, -0.0766,  0.1700,  0.1493,  0.1125,  0.1723, -0.2021, -0.1467,\n          0.1225,  0.0313, -0.0423,  0.0387, -0.1091, -0.0736, -0.1122,  0.1009,\n         -0.1616, -0.0451,  0.2227, -0.1148],\n        [-0.0764,  0.1135,  0.0434, -0.1528, -0.0727,  0.0454,  0.0638,  0.1387,\n          0.0192,  0.0168, -0.0590, -0.1037,  0.0286, -0.1646, -0.1159, -0.2062,\n          0.2049, -0.1903, -0.1543,  0.1453],\n        [ 0.0052,  0.0697,  0.0351, -0.1023,  0.1817,  0.0959,  0.0876, -0.1899,\n         -0.1249, -0.1651, -0.1280, -0.1583, -0.1421,  0.1566, -0.0457, -0.1440,\n         -0.0210,  0.0536, -0.1579, -0.1194],\n        [ 0.2099,  0.2188, -0.0452,  0.0165, -0.0926,  0.0497, -0.2117, -0.1394,\n         -0.1060, -0.1150, -0.1206,  0.0406, -0.2018,  0.0928,  0.0193, -0.0664,\n         -0.0889,  0.0376, -0.0749, -0.1048],\n        [-0.0354,  0.2168,  0.1830, -0.0777, -0.1898, -0.2218,  0.0706,  0.0354,\n          0.0952, -0.1037, -0.1473,  0.1898,  0.0758,  0.0462, -0.2079,  0.0518,\n          0.0521,  0.0372, -0.0206,  0.0688],\n        [ 0.0312, -0.1220, -0.1505,  0.1815,  0.0975, -0.1758, -0.2036, -0.0684,\n         -0.0701, -0.0123, -0.2112, -0.2134,  0.0474,  0.0071,  0.1265,  0.0206,\n         -0.0510,  0.1019,  0.2027,  0.1901],\n        [-0.1170,  0.0493,  0.0289,  0.1725, -0.1476, -0.1223,  0.0166, -0.1186,\n          0.1879, -0.2114,  0.1664,  0.1601, -0.1075,  0.1844,  0.1220,  0.1846,\n         -0.2224, -0.0003, -0.1122, -0.1153],\n        [ 0.1522,  0.1020, -0.1487, -0.1890,  0.0382,  0.1609,  0.0525,  0.0734,\n          0.1910,  0.0720, -0.1207, -0.0470, -0.0732,  0.0588,  0.0280,  0.1345,\n          0.0099,  0.0122, -0.0659,  0.0636],\n        [-0.0012, -0.1531,  0.0313, -0.0003,  0.0378, -0.1088,  0.1006,  0.1538,\n         -0.0397, -0.0409,  0.2082,  0.2205,  0.0836, -0.1630, -0.1582,  0.0010,\n         -0.0930,  0.0792, -0.0843,  0.0512],\n        [ 0.1347,  0.0596, -0.1095,  0.1099,  0.0028, -0.1625,  0.1633, -0.1098,\n         -0.1537,  0.2146,  0.1604,  0.2132, -0.0809,  0.0311,  0.0148, -0.1676,\n          0.2011, -0.1547,  0.1314, -0.0084],\n        [ 0.1651, -0.1571, -0.1037, -0.1625, -0.1279, -0.0829, -0.0489, -0.2051,\n         -0.1473,  0.0511,  0.1903,  0.0738,  0.1348,  0.2030, -0.0703,  0.1480,\n          0.1726, -0.0412,  0.1691,  0.1839],\n        [ 0.1636, -0.1944,  0.1411,  0.0035, -0.1733,  0.1232,  0.1805,  0.1088,\n          0.1783,  0.1289, -0.0834, -0.1501, -0.1255, -0.1695, -0.0625,  0.1034,\n         -0.1826,  0.1363,  0.2115, -0.1970],\n        [-0.0702, -0.0598, -0.1956, -0.2234, -0.1612, -0.0787, -0.1024,  0.1652,\n          0.0592,  0.1639,  0.1891, -0.1084, -0.1723,  0.1120,  0.0056, -0.0855,\n          0.1870,  0.1821,  0.2218,  0.0017],\n        [-0.1086,  0.2082,  0.1084, -0.0791, -0.1503,  0.1143,  0.1400, -0.1267,\n         -0.1509, -0.2093,  0.1207, -0.0658,  0.2153,  0.1705, -0.0086, -0.1291,\n          0.0891, -0.0405,  0.0639, -0.0401],\n        [ 0.0461,  0.0635,  0.0062,  0.0705,  0.0377,  0.0770,  0.1167, -0.0124,\n         -0.1904,  0.2140,  0.2168,  0.0318, -0.0569, -0.0976,  0.0055, -0.1942,\n         -0.1376,  0.0390, -0.0939, -0.2070],\n        [-0.1100, -0.1850, -0.1360,  0.1095, -0.1711, -0.0643,  0.2093,  0.0270,\n          0.0201, -0.1795,  0.0969, -0.2206,  0.1777,  0.0032, -0.0829, -0.1072,\n         -0.0820,  0.0682, -0.0744, -0.2160],\n        [ 0.0108,  0.2125,  0.0958, -0.1316, -0.0314,  0.0256, -0.0290, -0.1477,\n          0.0241,  0.0688, -0.0303,  0.0185, -0.1786, -0.1726, -0.1434,  0.1232,\n          0.1667, -0.1143,  0.0313,  0.1575],\n        [-0.0513, -0.2038, -0.0631, -0.0976,  0.1019, -0.0839, -0.1680, -0.0075,\n         -0.0648,  0.0915,  0.1371, -0.1844, -0.1875, -0.1859, -0.2035,  0.0881,\n         -0.1884,  0.1752, -0.0915, -0.0539]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1221, -0.0942, -0.0837, -0.1439, -0.1773, -0.1226,  0.1412,  0.1942,\n        -0.0379, -0.0056, -0.0806, -0.1258, -0.0883, -0.0641,  0.1203,  0.1389,\n        -0.0222, -0.1575, -0.2070,  0.1630, -0.1863,  0.1179,  0.1144, -0.1852,\n         0.0359, -0.1061, -0.1077,  0.0659,  0.1135,  0.1084, -0.1139, -0.0150],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.0022e-01, -8.9776e-02,  3.9883e-02, -1.5371e-01,  1.3141e-01,\n          1.2691e-02, -1.1653e-01,  7.6506e-02, -1.6903e-01,  5.7165e-02,\n         -1.3315e-01,  9.8475e-02, -2.2188e-02, -1.1739e-01, -7.8354e-02,\n         -1.1696e-01, -7.9379e-02,  2.0049e-02, -1.5287e-01,  1.0419e-01,\n          1.0075e-01, -1.0531e-01, -1.2070e-01,  3.8492e-02, -5.3738e-02,\n          8.9927e-02,  1.0790e-01,  2.0207e-02,  1.5857e-01, -1.7052e-01,\n         -1.3534e-01, -6.7967e-02],\n        [ 5.3794e-02, -1.5418e-01,  7.6243e-02,  7.7802e-03,  2.1563e-02,\n         -1.1583e-01,  1.4906e-01, -7.0255e-02, -8.7957e-02, -9.2516e-02,\n         -4.4279e-02, -4.9584e-02, -5.3818e-03, -7.1583e-02,  3.4696e-02,\n          1.1216e-01, -4.1458e-02,  3.3474e-02,  3.3311e-02,  9.3157e-03,\n          8.2979e-02,  6.3194e-02,  7.9388e-02,  9.5271e-02,  1.0189e-01,\n         -3.2556e-02, -4.1983e-02,  3.2888e-02,  7.1484e-02, -1.3751e-01,\n         -1.6318e-01,  1.5266e-01],\n        [ 1.3379e-02,  1.0755e-01, -4.9843e-02,  1.3385e-02, -8.6897e-02,\n         -1.6853e-01,  4.3012e-02,  5.0699e-02, -2.3541e-02, -1.1891e-01,\n         -7.1028e-02,  1.3110e-01,  4.6099e-02, -1.3714e-01, -1.2312e-02,\n          4.5692e-02,  1.3687e-01, -1.6870e-01, -1.5285e-01,  1.4648e-01,\n         -1.5899e-01,  1.1641e-01,  1.3229e-01, -7.4882e-02,  1.4167e-01,\n         -7.3400e-02, -3.2980e-02, -8.5098e-02,  3.2280e-02,  1.6047e-01,\n          1.5392e-01, -1.0738e-01],\n        [ 5.5391e-02, -1.5963e-02, -3.7638e-02,  9.0069e-02,  1.4442e-01,\n         -1.2489e-01, -1.7016e-01,  1.2970e-01, -1.1872e-01,  1.7411e-01,\n         -8.9305e-02,  1.3647e-01,  1.6976e-01, -1.4026e-01,  3.0125e-02,\n          3.8211e-03,  1.5874e-01, -5.9442e-02,  1.3796e-01,  5.4064e-02,\n         -6.7172e-02,  1.3907e-01,  1.0385e-01, -1.6559e-01, -9.3015e-02,\n          1.2245e-01, -1.6536e-01,  1.0633e-01, -1.2299e-01, -3.7431e-02,\n         -8.5442e-02,  9.7598e-02],\n        [ 4.5469e-03, -3.5707e-02,  9.4891e-02,  1.3139e-01,  3.7965e-02,\n         -7.0530e-02, -4.7107e-02, -3.8089e-02, -5.4999e-02, -3.2333e-02,\n          6.0216e-02,  1.1664e-01,  1.4209e-01,  5.1992e-02,  1.5464e-01,\n          1.5146e-01, -4.0780e-02, -1.2524e-01, -9.3280e-02, -1.4561e-01,\n          8.1264e-02,  1.1497e-01,  1.3758e-01, -1.1170e-01,  1.1981e-02,\n          9.6624e-02, -3.3924e-02, -7.6213e-02,  5.5779e-02, -3.0516e-02,\n          1.3847e-01, -6.1048e-02],\n        [-6.3140e-02,  1.0880e-01,  1.2997e-01, -4.4416e-02, -5.0529e-02,\n          6.2785e-02, -8.2859e-02,  9.8807e-02, -7.6243e-02, -1.0440e-01,\n         -9.0612e-02, -3.3605e-02, -2.0041e-02,  2.1134e-02,  5.9653e-02,\n         -1.3695e-01,  1.0885e-01, -9.3909e-02, -1.1433e-01,  1.2652e-01,\n          9.9004e-02,  6.3158e-02, -1.6508e-02, -4.9263e-02, -5.1668e-02,\n          1.7178e-01,  5.0204e-02, -6.6519e-02,  1.4785e-01, -5.4126e-02,\n         -1.3023e-01, -2.6704e-02],\n        [-5.5096e-02,  1.5386e-01, -1.0992e-01,  1.0389e-02,  3.5115e-02,\n          1.6927e-01,  2.5576e-02,  3.3153e-02, -1.2501e-01,  3.0095e-02,\n         -1.0753e-01, -9.7943e-02,  7.5417e-02,  1.2473e-01, -1.4681e-01,\n          1.1503e-01,  9.5743e-02, -8.4165e-03, -8.6468e-02, -7.7657e-02,\n         -1.7126e-01, -1.6778e-01, -2.3783e-02,  9.6809e-03,  3.8113e-02,\n          1.6973e-01,  6.4901e-02, -9.7169e-02, -1.5630e-01,  8.2746e-02,\n          1.1964e-01,  3.2351e-02],\n        [-1.1873e-01,  7.6070e-02, -6.2159e-02,  1.4841e-02, -3.1261e-02,\n         -5.5258e-02, -2.3289e-02,  1.0671e-01,  6.1311e-02,  1.6261e-01,\n          9.5685e-02, -1.3410e-01,  7.2614e-02, -7.1012e-02,  4.2203e-02,\n          1.0409e-02,  5.7422e-02, -1.4610e-01, -7.3246e-02, -1.0971e-01,\n         -1.7267e-01, -2.6794e-02,  8.0849e-02,  4.9164e-02, -1.3526e-01,\n         -3.7182e-02,  1.1716e-01, -1.5379e-01, -5.6189e-02,  1.1729e-01,\n          1.2664e-01,  2.6440e-02],\n        [-9.2250e-02, -3.2114e-03,  3.9460e-04, -1.2232e-01,  1.6308e-01,\n          3.0456e-02,  8.5654e-03,  1.6014e-01, -4.8866e-03, -7.4416e-02,\n          9.5551e-02,  4.3678e-02, -1.2892e-01,  1.7198e-01,  6.7769e-02,\n         -8.2905e-02,  5.1582e-02,  1.3969e-01, -8.7498e-02, -5.5720e-02,\n         -1.1584e-01, -1.7060e-01, -1.5615e-01, -4.5051e-02, -8.8633e-02,\n         -1.4405e-01, -1.6342e-01,  1.6015e-01,  7.1273e-03,  6.8635e-02,\n          9.3942e-02, -1.4993e-01],\n        [ 4.2256e-04,  1.0443e-01,  6.2242e-02, -1.3787e-01,  2.8406e-02,\n         -7.8801e-02,  3.8572e-02,  1.7027e-01,  1.6389e-01,  2.0541e-02,\n          1.3156e-01, -1.2413e-01,  1.4046e-01, -7.5193e-02, -1.1878e-01,\n          6.4385e-02,  3.6787e-02, -1.7198e-01, -9.0058e-02,  6.7300e-02,\n         -5.8832e-02, -1.1218e-01,  7.6739e-03,  9.9331e-02,  1.1697e-02,\n          6.4981e-02, -1.6488e-01,  2.8446e-02,  1.3222e-01,  3.5595e-02,\n          1.1983e-01,  8.1019e-02],\n        [ 5.2372e-02,  8.6845e-02,  2.0013e-02, -1.2833e-01, -1.5826e-01,\n         -8.9240e-02, -4.6678e-02,  1.2585e-01,  1.5742e-01, -3.5005e-02,\n         -1.2511e-01, -1.6439e-01,  1.3226e-01, -1.4766e-01,  1.0190e-03,\n          1.1196e-01,  5.3766e-02, -3.8394e-02,  1.4933e-01, -3.6250e-02,\n          2.3916e-02, -1.4229e-01,  1.6214e-02,  1.1854e-01, -1.4479e-01,\n          1.0838e-01, -3.8005e-02,  2.9810e-03,  8.0736e-02,  4.2175e-02,\n         -7.0890e-02, -1.5780e-01],\n        [-2.4165e-02,  1.8858e-02, -3.0177e-02,  2.4718e-03,  1.4002e-01,\n         -6.2535e-02, -6.8579e-03, -1.6104e-03,  2.2624e-02, -2.8211e-02,\n          1.0879e-01,  1.5139e-01,  1.1890e-01,  2.0468e-02, -1.4122e-01,\n         -1.0016e-01, -5.6284e-02, -3.8592e-02, -1.2617e-01, -1.4700e-01,\n         -1.6071e-01,  5.8256e-02, -1.7463e-01,  5.9053e-02, -3.1166e-03,\n         -2.4459e-02,  1.0125e-01, -9.9324e-03, -1.7598e-01, -5.5863e-02,\n          1.0362e-01,  1.1326e-01],\n        [ 5.0441e-02, -3.8858e-02, -9.8103e-02, -1.2661e-01, -1.6165e-01,\n          1.3767e-01, -2.6961e-02,  7.9155e-02,  1.2397e-01,  3.2043e-02,\n          1.0023e-01, -9.4581e-02, -1.0086e-01, -5.4303e-02, -9.7957e-02,\n          1.0132e-02, -1.3021e-02, -9.9809e-02, -5.6943e-02, -1.9882e-02,\n          1.7420e-01, -1.6634e-01, -9.2108e-02, -1.7286e-01,  3.3512e-02,\n          3.5846e-02,  5.9268e-02, -5.7766e-02, -1.1437e-01, -1.1514e-01,\n         -1.4356e-01, -1.1081e-01],\n        [-1.3115e-01, -2.6359e-02, -1.3619e-01,  1.2518e-01,  1.5408e-01,\n          5.0231e-02,  1.0086e-01, -1.6656e-01,  9.6707e-02, -1.7517e-01,\n          8.7269e-02,  7.3642e-02, -1.3570e-01, -1.2520e-01,  9.8961e-02,\n          4.6981e-02,  7.9455e-02,  5.9112e-02,  1.0858e-01, -1.3420e-01,\n         -1.0768e-02, -1.3194e-01,  9.7963e-02, -2.7816e-02,  6.2851e-02,\n         -8.2640e-02,  1.2767e-01,  3.6426e-02,  2.8656e-02,  3.4503e-02,\n         -1.4643e-01, -2.4456e-02],\n        [ 1.2826e-02, -1.3391e-01,  5.3600e-02,  3.1792e-02, -9.1091e-02,\n         -1.1258e-01, -1.1244e-01,  7.9504e-02, -1.2390e-01,  1.3750e-01,\n          7.5579e-02,  6.3293e-02, -1.4626e-02, -2.8207e-02,  1.2415e-01,\n          1.1189e-01,  1.1602e-01, -1.3808e-01, -1.4105e-01,  6.9227e-02,\n          4.8168e-02, -7.4571e-02,  2.3457e-02,  1.0444e-01, -6.8875e-02,\n         -3.5199e-03, -7.8750e-02,  2.5279e-02,  1.4902e-01,  1.0122e-01,\n         -6.6458e-02,  3.4953e-02],\n        [-1.6003e-01, -1.2173e-01, -2.5266e-02, -7.3611e-02, -3.5270e-02,\n         -1.6920e-02, -1.1762e-01,  1.5477e-01, -9.9108e-05, -1.0638e-01,\n          1.1007e-01,  2.3434e-02, -7.3039e-02,  8.8520e-02,  6.1135e-02,\n          1.2741e-01,  2.7308e-02, -2.2513e-02,  1.4223e-01, -8.4373e-02,\n         -2.7923e-02, -1.3246e-02,  2.6834e-03,  3.5940e-02,  1.3376e-03,\n         -6.1082e-03,  3.7504e-02,  6.3136e-02,  7.5125e-02, -1.1722e-01,\n         -8.1380e-02,  1.1408e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1034,  0.0506, -0.0563,  0.1244,  0.0876,  0.0552,  0.1569, -0.0220,\n         0.0548, -0.0258,  0.1555, -0.0818,  0.0865, -0.1171,  0.1594,  0.0884],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1808, -0.2440,  0.0387, -0.0853, -0.0571,  0.0256,  0.1895,  0.2201,\n          0.1659,  0.2057, -0.1301, -0.1698,  0.1163,  0.0684, -0.2219, -0.0021],\n        [ 0.0862, -0.1469, -0.0907,  0.0476, -0.1739, -0.0105, -0.0810,  0.2475,\n          0.2347,  0.2177, -0.0901, -0.0054,  0.1192,  0.2141,  0.0830, -0.1226],\n        [-0.1574, -0.1499, -0.0380,  0.2220,  0.0237, -0.1618, -0.2281,  0.1179,\n         -0.0599,  0.2086, -0.0308, -0.1149, -0.2060,  0.0994, -0.0665,  0.2117],\n        [-0.1216,  0.1404, -0.2049, -0.1650,  0.0436, -0.2330, -0.0880,  0.2065,\n          0.0541,  0.1551, -0.0699, -0.2043,  0.0291, -0.2212,  0.2036, -0.0977],\n        [ 0.0899,  0.1145, -0.1534,  0.0971, -0.1956, -0.1488, -0.1712,  0.0670,\n          0.1528,  0.0137, -0.1138,  0.2111,  0.1611, -0.1031,  0.0925,  0.1566],\n        [ 0.1544,  0.1435, -0.0063,  0.0069,  0.2423, -0.1249, -0.1896, -0.0159,\n         -0.0724, -0.0656,  0.0498,  0.2377,  0.2053,  0.0357, -0.0539,  0.0751],\n        [ 0.1144,  0.0333,  0.1446,  0.0008,  0.1778,  0.1316, -0.0298,  0.0607,\n         -0.0578, -0.1671,  0.0082, -0.0573, -0.0601,  0.0834, -0.1703, -0.0042],\n        [ 0.1253, -0.1455,  0.0764, -0.2095,  0.1371,  0.0588, -0.1029, -0.2272,\n         -0.1642, -0.2076, -0.2155,  0.0105, -0.1132, -0.1625, -0.1224,  0.0604]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1760,  0.1772, -0.0969, -0.1525, -0.0045,  0.0529,  0.2220,  0.2420],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1118,  0.1704,  0.2950, -0.0093, -0.3044, -0.0547, -0.0016,  0.0840],\n        [-0.1517,  0.1385,  0.1181,  0.3182,  0.1494,  0.2541, -0.2985,  0.3352],\n        [ 0.0828, -0.2265,  0.2126,  0.3227, -0.2439,  0.1330,  0.3183, -0.0478],\n        [-0.0937, -0.1865,  0.1608, -0.2563,  0.2086, -0.2778,  0.0923,  0.2415]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1848,  0.2135,  0.1263, -0.2696], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7ab0779e7710>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "time":	0,
                    "timestamp_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1221, -0.0942, -0.0837, -0.1439, -0.1773, -0.1226,  0.1412,  0.1942,\n        -0.0379, -0.0056, -0.0806, -0.1258, -0.0883, -0.0641,  0.1203,  0.1389,\n        -0.0222, -0.1575, -0.2070,  0.1630, -0.1863,  0.1179,  0.1144, -0.1852,\n         0.0359, -0.1061, -0.1077,  0.0659,  0.1135,  0.1084, -0.1139, -0.0150],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0290,  0.0565,  0.1741,  0.2156, -0.1304, -0.1236, -0.2041, -0.0439,\n         -0.1023, -0.1280, -0.1282,  0.1833, -0.0441,  0.1262,  0.0779,  0.1742,\n         -0.0038,  0.2205, -0.1584,  0.1809],\n        [ 0.1527,  0.0869,  0.1706, -0.1017, -0.0879, -0.1361,  0.0454,  0.1970,\n          0.1897,  0.1597, -0.1541,  0.0779,  0.2186,  0.0110, -0.1346, -0.0728,\n          0.1780, -0.0734, -0.1585, -0.0172],\n        [-0.1034, -0.0007,  0.0789, -0.1361, -0.0580, -0.0455,  0.0753, -0.1822,\n          0.0478,  0.1647, -0.0364, -0.1255, -0.2028,  0.1770, -0.1869, -0.0559,\n         -0.0300,  0.0949,  0.2083, -0.0094],\n        [ 0.0335,  0.0654, -0.1851, -0.1624, -0.1258,  0.0407, -0.1825,  0.1817,\n          0.1608, -0.1971, -0.1705,  0.2063,  0.1976, -0.0007,  0.2136, -0.1674,\n         -0.0204, -0.0226,  0.0596,  0.0621],\n        [ 0.2219, -0.0457,  0.0348, -0.0475, -0.0130,  0.0831,  0.2158, -0.0046,\n         -0.0902,  0.0666,  0.2063, -0.0903,  0.1860,  0.1234, -0.1144,  0.0127,\n          0.0871,  0.0755, -0.0694,  0.0256],\n        [ 0.0639,  0.2161, -0.0297,  0.1305, -0.1226, -0.1070,  0.1799,  0.0890,\n         -0.0992,  0.1911,  0.1372, -0.1385, -0.1754,  0.1951, -0.2200,  0.2107,\n         -0.0809,  0.0722,  0.1365,  0.0153],\n        [-0.1556, -0.0302,  0.0076, -0.0790,  0.0349,  0.1006, -0.0901,  0.1190,\n         -0.0018, -0.0285, -0.1374, -0.0375, -0.0137,  0.1157, -0.1340, -0.0722,\n          0.0663, -0.2037,  0.2006, -0.1275],\n        [-0.1303,  0.2092, -0.0512, -0.0548,  0.1670,  0.1095, -0.1029,  0.1969,\n          0.2159,  0.1815, -0.2010, -0.1310,  0.0638,  0.0928,  0.0920, -0.0447,\n         -0.0051, -0.1856, -0.0950,  0.0600],\n        [-0.1875, -0.1867, -0.0340,  0.1643,  0.0161,  0.0041,  0.1926,  0.0333,\n         -0.1598, -0.1457, -0.1289, -0.2038, -0.2010,  0.0958,  0.1300, -0.1702,\n         -0.2062, -0.1849, -0.1410, -0.0631],\n        [-0.2209, -0.1104,  0.1394, -0.0956, -0.0293, -0.1892,  0.1332,  0.1205,\n         -0.1034,  0.2016, -0.1055,  0.0558,  0.0216, -0.1830,  0.0173, -0.0515,\n          0.0411, -0.1795,  0.0399,  0.1247],\n        [-0.0548, -0.1303, -0.1718,  0.0618,  0.1093, -0.1822, -0.0424,  0.1775,\n          0.1272, -0.0710,  0.1662, -0.0826, -0.1143,  0.1456, -0.0056, -0.2006,\n          0.1558, -0.0929,  0.0009, -0.1867],\n        [-0.1560,  0.1702, -0.0319, -0.0119,  0.0226, -0.1818, -0.0745,  0.0218,\n         -0.1638, -0.0848,  0.1553,  0.1610, -0.1574,  0.1135,  0.0194, -0.2030,\n         -0.1104, -0.0444,  0.0540,  0.1141],\n        [-0.1164,  0.1392,  0.1104, -0.1284, -0.2071,  0.1040,  0.1941, -0.0006,\n          0.0487, -0.0082, -0.0053,  0.2148,  0.1044, -0.1313,  0.1233, -0.0271,\n          0.0046, -0.1727,  0.1824, -0.0645],\n        [ 0.1197,  0.1838, -0.0413, -0.1915,  0.1492, -0.0549,  0.1993,  0.1167,\n          0.1367, -0.0901, -0.1434,  0.1515, -0.1385, -0.1893, -0.2162,  0.1582,\n         -0.0973, -0.1894, -0.0712,  0.1869],\n        [-0.1891, -0.0766,  0.1700,  0.1493,  0.1125,  0.1723, -0.2021, -0.1467,\n          0.1225,  0.0313, -0.0423,  0.0387, -0.1091, -0.0736, -0.1122,  0.1009,\n         -0.1616, -0.0451,  0.2227, -0.1148],\n        [-0.0764,  0.1135,  0.0434, -0.1528, -0.0727,  0.0454,  0.0638,  0.1387,\n          0.0192,  0.0168, -0.0590, -0.1037,  0.0286, -0.1646, -0.1159, -0.2062,\n          0.2049, -0.1903, -0.1543,  0.1453],\n        [ 0.0052,  0.0697,  0.0351, -0.1023,  0.1817,  0.0959,  0.0876, -0.1899,\n         -0.1249, -0.1651, -0.1280, -0.1583, -0.1421,  0.1566, -0.0457, -0.1440,\n         -0.0210,  0.0536, -0.1579, -0.1194],\n        [ 0.2099,  0.2188, -0.0452,  0.0165, -0.0926,  0.0497, -0.2117, -0.1394,\n         -0.1060, -0.1150, -0.1206,  0.0406, -0.2018,  0.0928,  0.0193, -0.0664,\n         -0.0889,  0.0376, -0.0749, -0.1048],\n        [-0.0354,  0.2168,  0.1830, -0.0777, -0.1898, -0.2218,  0.0706,  0.0354,\n          0.0952, -0.1037, -0.1473,  0.1898,  0.0758,  0.0462, -0.2079,  0.0518,\n          0.0521,  0.0372, -0.0206,  0.0688],\n        [ 0.0312, -0.1220, -0.1505,  0.1815,  0.0975, -0.1758, -0.2036, -0.0684,\n         -0.0701, -0.0123, -0.2112, -0.2134,  0.0474,  0.0071,  0.1265,  0.0206,\n         -0.0510,  0.1019,  0.2027,  0.1901],\n        [-0.1170,  0.0493,  0.0289,  0.1725, -0.1476, -0.1223,  0.0166, -0.1186,\n          0.1879, -0.2114,  0.1664,  0.1601, -0.1075,  0.1844,  0.1220,  0.1846,\n         -0.2224, -0.0003, -0.1122, -0.1153],\n        [ 0.1522,  0.1020, -0.1487, -0.1890,  0.0382,  0.1609,  0.0525,  0.0734,\n          0.1910,  0.0720, -0.1207, -0.0470, -0.0732,  0.0588,  0.0280,  0.1345,\n          0.0099,  0.0122, -0.0659,  0.0636],\n        [-0.0012, -0.1531,  0.0313, -0.0003,  0.0378, -0.1088,  0.1006,  0.1538,\n         -0.0397, -0.0409,  0.2082,  0.2205,  0.0836, -0.1630, -0.1582,  0.0010,\n         -0.0930,  0.0792, -0.0843,  0.0512],\n        [ 0.1347,  0.0596, -0.1095,  0.1099,  0.0028, -0.1625,  0.1633, -0.1098,\n         -0.1537,  0.2146,  0.1604,  0.2132, -0.0809,  0.0311,  0.0148, -0.1676,\n          0.2011, -0.1547,  0.1314, -0.0084],\n        [ 0.1651, -0.1571, -0.1037, -0.1625, -0.1279, -0.0829, -0.0489, -0.2051,\n         -0.1473,  0.0511,  0.1903,  0.0738,  0.1348,  0.2030, -0.0703,  0.1480,\n          0.1726, -0.0412,  0.1691,  0.1839],\n        [ 0.1636, -0.1944,  0.1411,  0.0035, -0.1733,  0.1232,  0.1805,  0.1088,\n          0.1783,  0.1289, -0.0834, -0.1501, -0.1255, -0.1695, -0.0625,  0.1034,\n         -0.1826,  0.1363,  0.2115, -0.1970],\n        [-0.0702, -0.0598, -0.1956, -0.2234, -0.1612, -0.0787, -0.1024,  0.1652,\n          0.0592,  0.1639,  0.1891, -0.1084, -0.1723,  0.1120,  0.0056, -0.0855,\n          0.1870,  0.1821,  0.2218,  0.0017],\n        [-0.1086,  0.2082,  0.1084, -0.0791, -0.1503,  0.1143,  0.1400, -0.1267,\n         -0.1509, -0.2093,  0.1207, -0.0658,  0.2153,  0.1705, -0.0086, -0.1291,\n          0.0891, -0.0405,  0.0639, -0.0401],\n        [ 0.0461,  0.0635,  0.0062,  0.0705,  0.0377,  0.0770,  0.1167, -0.0124,\n         -0.1904,  0.2140,  0.2168,  0.0318, -0.0569, -0.0976,  0.0055, -0.1942,\n         -0.1376,  0.0390, -0.0939, -0.2070],\n        [-0.1100, -0.1850, -0.1360,  0.1095, -0.1711, -0.0643,  0.2093,  0.0270,\n          0.0201, -0.1795,  0.0969, -0.2206,  0.1777,  0.0032, -0.0829, -0.1072,\n         -0.0820,  0.0682, -0.0744, -0.2160],\n        [ 0.0108,  0.2125,  0.0958, -0.1316, -0.0314,  0.0256, -0.0290, -0.1477,\n          0.0241,  0.0688, -0.0303,  0.0185, -0.1786, -0.1726, -0.1434,  0.1232,\n          0.1667, -0.1143,  0.0313,  0.1575],\n        [-0.0513, -0.2038, -0.0631, -0.0976,  0.1019, -0.0839, -0.1680, -0.0075,\n         -0.0648,  0.0915,  0.1371, -0.1844, -0.1875, -0.1859, -0.2035,  0.0881,\n         -0.1884,  0.1752, -0.0915, -0.0539]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1034,  0.0506, -0.0563,  0.1244,  0.0876,  0.0552,  0.1569, -0.0220,\n         0.0548, -0.0258,  0.1555, -0.0818,  0.0865, -0.1171,  0.1594,  0.0884],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0022e-01, -8.9776e-02,  3.9883e-02, -1.5371e-01,  1.3141e-01,\n          1.2691e-02, -1.1653e-01,  7.6506e-02, -1.6903e-01,  5.7165e-02,\n         -1.3315e-01,  9.8475e-02, -2.2188e-02, -1.1739e-01, -7.8354e-02,\n         -1.1696e-01, -7.9379e-02,  2.0049e-02, -1.5287e-01,  1.0419e-01,\n          1.0075e-01, -1.0531e-01, -1.2070e-01,  3.8492e-02, -5.3738e-02,\n          8.9927e-02,  1.0790e-01,  2.0207e-02,  1.5857e-01, -1.7052e-01,\n         -1.3534e-01, -6.7967e-02],\n        [ 5.3794e-02, -1.5418e-01,  7.6243e-02,  7.7802e-03,  2.1563e-02,\n         -1.1583e-01,  1.4906e-01, -7.0255e-02, -8.7957e-02, -9.2516e-02,\n         -4.4279e-02, -4.9584e-02, -5.3818e-03, -7.1583e-02,  3.4696e-02,\n          1.1216e-01, -4.1458e-02,  3.3474e-02,  3.3311e-02,  9.3157e-03,\n          8.2979e-02,  6.3194e-02,  7.9388e-02,  9.5271e-02,  1.0189e-01,\n         -3.2556e-02, -4.1983e-02,  3.2888e-02,  7.1484e-02, -1.3751e-01,\n         -1.6318e-01,  1.5266e-01],\n        [ 1.3379e-02,  1.0755e-01, -4.9843e-02,  1.3385e-02, -8.6897e-02,\n         -1.6853e-01,  4.3012e-02,  5.0699e-02, -2.3541e-02, -1.1891e-01,\n         -7.1028e-02,  1.3110e-01,  4.6099e-02, -1.3714e-01, -1.2312e-02,\n          4.5692e-02,  1.3687e-01, -1.6870e-01, -1.5285e-01,  1.4648e-01,\n         -1.5899e-01,  1.1641e-01,  1.3229e-01, -7.4882e-02,  1.4167e-01,\n         -7.3400e-02, -3.2980e-02, -8.5098e-02,  3.2280e-02,  1.6047e-01,\n          1.5392e-01, -1.0738e-01],\n        [ 5.5391e-02, -1.5963e-02, -3.7638e-02,  9.0069e-02,  1.4442e-01,\n         -1.2489e-01, -1.7016e-01,  1.2970e-01, -1.1872e-01,  1.7411e-01,\n         -8.9305e-02,  1.3647e-01,  1.6976e-01, -1.4026e-01,  3.0125e-02,\n          3.8211e-03,  1.5874e-01, -5.9442e-02,  1.3796e-01,  5.4064e-02,\n         -6.7172e-02,  1.3907e-01,  1.0385e-01, -1.6559e-01, -9.3015e-02,\n          1.2245e-01, -1.6536e-01,  1.0633e-01, -1.2299e-01, -3.7431e-02,\n         -8.5442e-02,  9.7598e-02],\n        [ 4.5469e-03, -3.5707e-02,  9.4891e-02,  1.3139e-01,  3.7965e-02,\n         -7.0530e-02, -4.7107e-02, -3.8089e-02, -5.4999e-02, -3.2333e-02,\n          6.0216e-02,  1.1664e-01,  1.4209e-01,  5.1992e-02,  1.5464e-01,\n          1.5146e-01, -4.0780e-02, -1.2524e-01, -9.3280e-02, -1.4561e-01,\n          8.1264e-02,  1.1497e-01,  1.3758e-01, -1.1170e-01,  1.1981e-02,\n          9.6624e-02, -3.3924e-02, -7.6213e-02,  5.5779e-02, -3.0516e-02,\n          1.3847e-01, -6.1048e-02],\n        [-6.3140e-02,  1.0880e-01,  1.2997e-01, -4.4416e-02, -5.0529e-02,\n          6.2785e-02, -8.2859e-02,  9.8807e-02, -7.6243e-02, -1.0440e-01,\n         -9.0612e-02, -3.3605e-02, -2.0041e-02,  2.1134e-02,  5.9653e-02,\n         -1.3695e-01,  1.0885e-01, -9.3909e-02, -1.1433e-01,  1.2652e-01,\n          9.9004e-02,  6.3158e-02, -1.6508e-02, -4.9263e-02, -5.1668e-02,\n          1.7178e-01,  5.0204e-02, -6.6519e-02,  1.4785e-01, -5.4126e-02,\n         -1.3023e-01, -2.6704e-02],\n        [-5.5096e-02,  1.5386e-01, -1.0992e-01,  1.0389e-02,  3.5115e-02,\n          1.6927e-01,  2.5576e-02,  3.3153e-02, -1.2501e-01,  3.0095e-02,\n         -1.0753e-01, -9.7943e-02,  7.5417e-02,  1.2473e-01, -1.4681e-01,\n          1.1503e-01,  9.5743e-02, -8.4165e-03, -8.6468e-02, -7.7657e-02,\n         -1.7126e-01, -1.6778e-01, -2.3783e-02,  9.6809e-03,  3.8113e-02,\n          1.6973e-01,  6.4901e-02, -9.7169e-02, -1.5630e-01,  8.2746e-02,\n          1.1964e-01,  3.2351e-02],\n        [-1.1873e-01,  7.6070e-02, -6.2159e-02,  1.4841e-02, -3.1261e-02,\n         -5.5258e-02, -2.3289e-02,  1.0671e-01,  6.1311e-02,  1.6261e-01,\n          9.5685e-02, -1.3410e-01,  7.2614e-02, -7.1012e-02,  4.2203e-02,\n          1.0409e-02,  5.7422e-02, -1.4610e-01, -7.3246e-02, -1.0971e-01,\n         -1.7267e-01, -2.6794e-02,  8.0849e-02,  4.9164e-02, -1.3526e-01,\n         -3.7182e-02,  1.1716e-01, -1.5379e-01, -5.6189e-02,  1.1729e-01,\n          1.2664e-01,  2.6440e-02],\n        [-9.2250e-02, -3.2114e-03,  3.9460e-04, -1.2232e-01,  1.6308e-01,\n          3.0456e-02,  8.5654e-03,  1.6014e-01, -4.8866e-03, -7.4416e-02,\n          9.5551e-02,  4.3678e-02, -1.2892e-01,  1.7198e-01,  6.7769e-02,\n         -8.2905e-02,  5.1582e-02,  1.3969e-01, -8.7498e-02, -5.5720e-02,\n         -1.1584e-01, -1.7060e-01, -1.5615e-01, -4.5051e-02, -8.8633e-02,\n         -1.4405e-01, -1.6342e-01,  1.6015e-01,  7.1273e-03,  6.8635e-02,\n          9.3942e-02, -1.4993e-01],\n        [ 4.2256e-04,  1.0443e-01,  6.2242e-02, -1.3787e-01,  2.8406e-02,\n         -7.8801e-02,  3.8572e-02,  1.7027e-01,  1.6389e-01,  2.0541e-02,\n          1.3156e-01, -1.2413e-01,  1.4046e-01, -7.5193e-02, -1.1878e-01,\n          6.4385e-02,  3.6787e-02, -1.7198e-01, -9.0058e-02,  6.7300e-02,\n         -5.8832e-02, -1.1218e-01,  7.6739e-03,  9.9331e-02,  1.1697e-02,\n          6.4981e-02, -1.6488e-01,  2.8446e-02,  1.3222e-01,  3.5595e-02,\n          1.1983e-01,  8.1019e-02],\n        [ 5.2372e-02,  8.6845e-02,  2.0013e-02, -1.2833e-01, -1.5826e-01,\n         -8.9240e-02, -4.6678e-02,  1.2585e-01,  1.5742e-01, -3.5005e-02,\n         -1.2511e-01, -1.6439e-01,  1.3226e-01, -1.4766e-01,  1.0190e-03,\n          1.1196e-01,  5.3766e-02, -3.8394e-02,  1.4933e-01, -3.6250e-02,\n          2.3916e-02, -1.4229e-01,  1.6214e-02,  1.1854e-01, -1.4479e-01,\n          1.0838e-01, -3.8005e-02,  2.9810e-03,  8.0736e-02,  4.2175e-02,\n         -7.0890e-02, -1.5780e-01],\n        [-2.4165e-02,  1.8858e-02, -3.0177e-02,  2.4718e-03,  1.4002e-01,\n         -6.2535e-02, -6.8579e-03, -1.6104e-03,  2.2624e-02, -2.8211e-02,\n          1.0879e-01,  1.5139e-01,  1.1890e-01,  2.0468e-02, -1.4122e-01,\n         -1.0016e-01, -5.6284e-02, -3.8592e-02, -1.2617e-01, -1.4700e-01,\n         -1.6071e-01,  5.8256e-02, -1.7463e-01,  5.9053e-02, -3.1166e-03,\n         -2.4459e-02,  1.0125e-01, -9.9324e-03, -1.7598e-01, -5.5863e-02,\n          1.0362e-01,  1.1326e-01],\n        [ 5.0441e-02, -3.8858e-02, -9.8103e-02, -1.2661e-01, -1.6165e-01,\n          1.3767e-01, -2.6961e-02,  7.9155e-02,  1.2397e-01,  3.2043e-02,\n          1.0023e-01, -9.4581e-02, -1.0086e-01, -5.4303e-02, -9.7957e-02,\n          1.0132e-02, -1.3021e-02, -9.9809e-02, -5.6943e-02, -1.9882e-02,\n          1.7420e-01, -1.6634e-01, -9.2108e-02, -1.7286e-01,  3.3512e-02,\n          3.5846e-02,  5.9268e-02, -5.7766e-02, -1.1437e-01, -1.1514e-01,\n         -1.4356e-01, -1.1081e-01],\n        [-1.3115e-01, -2.6359e-02, -1.3619e-01,  1.2518e-01,  1.5408e-01,\n          5.0231e-02,  1.0086e-01, -1.6656e-01,  9.6707e-02, -1.7517e-01,\n          8.7269e-02,  7.3642e-02, -1.3570e-01, -1.2520e-01,  9.8961e-02,\n          4.6981e-02,  7.9455e-02,  5.9112e-02,  1.0858e-01, -1.3420e-01,\n         -1.0768e-02, -1.3194e-01,  9.7963e-02, -2.7816e-02,  6.2851e-02,\n         -8.2640e-02,  1.2767e-01,  3.6426e-02,  2.8656e-02,  3.4503e-02,\n         -1.4643e-01, -2.4456e-02],\n        [ 1.2826e-02, -1.3391e-01,  5.3600e-02,  3.1792e-02, -9.1091e-02,\n         -1.1258e-01, -1.1244e-01,  7.9504e-02, -1.2390e-01,  1.3750e-01,\n          7.5579e-02,  6.3293e-02, -1.4626e-02, -2.8207e-02,  1.2415e-01,\n          1.1189e-01,  1.1602e-01, -1.3808e-01, -1.4105e-01,  6.9227e-02,\n          4.8168e-02, -7.4571e-02,  2.3457e-02,  1.0444e-01, -6.8875e-02,\n         -3.5199e-03, -7.8750e-02,  2.5279e-02,  1.4902e-01,  1.0122e-01,\n         -6.6458e-02,  3.4953e-02],\n        [-1.6003e-01, -1.2173e-01, -2.5266e-02, -7.3611e-02, -3.5270e-02,\n         -1.6920e-02, -1.1762e-01,  1.5477e-01, -9.9108e-05, -1.0638e-01,\n          1.1007e-01,  2.3434e-02, -7.3039e-02,  8.8520e-02,  6.1135e-02,\n          1.2741e-01,  2.7308e-02, -2.2513e-02,  1.4223e-01, -8.4373e-02,\n         -2.7923e-02, -1.3246e-02,  2.6834e-03,  3.5940e-02,  1.3376e-03,\n         -6.1082e-03,  3.7504e-02,  6.3136e-02,  7.5125e-02, -1.1722e-01,\n         -8.1380e-02,  1.1408e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1760,  0.1772, -0.0969, -0.1525, -0.0045,  0.0529,  0.2220,  0.2420],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1808, -0.2440,  0.0387, -0.0853, -0.0571,  0.0256,  0.1895,  0.2201,\n          0.1659,  0.2057, -0.1301, -0.1698,  0.1163,  0.0684, -0.2219, -0.0021],\n        [ 0.0862, -0.1469, -0.0907,  0.0476, -0.1739, -0.0105, -0.0810,  0.2475,\n          0.2347,  0.2177, -0.0901, -0.0054,  0.1192,  0.2141,  0.0830, -0.1226],\n        [-0.1574, -0.1499, -0.0380,  0.2220,  0.0237, -0.1618, -0.2281,  0.1179,\n         -0.0599,  0.2086, -0.0308, -0.1149, -0.2060,  0.0994, -0.0665,  0.2117],\n        [-0.1216,  0.1404, -0.2049, -0.1650,  0.0436, -0.2330, -0.0880,  0.2065,\n          0.0541,  0.1551, -0.0699, -0.2043,  0.0291, -0.2212,  0.2036, -0.0977],\n        [ 0.0899,  0.1145, -0.1534,  0.0971, -0.1956, -0.1488, -0.1712,  0.0670,\n          0.1528,  0.0137, -0.1138,  0.2111,  0.1611, -0.1031,  0.0925,  0.1566],\n        [ 0.1544,  0.1435, -0.0063,  0.0069,  0.2423, -0.1249, -0.1896, -0.0159,\n         -0.0724, -0.0656,  0.0498,  0.2377,  0.2053,  0.0357, -0.0539,  0.0751],\n        [ 0.1144,  0.0333,  0.1446,  0.0008,  0.1778,  0.1316, -0.0298,  0.0607,\n         -0.0578, -0.1671,  0.0082, -0.0573, -0.0601,  0.0834, -0.1703, -0.0042],\n        [ 0.1253, -0.1455,  0.0764, -0.2095,  0.1371,  0.0588, -0.1029, -0.2272,\n         -0.1642, -0.2076, -0.2155,  0.0105, -0.1132, -0.1625, -0.1224,  0.0604]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1848,  0.2135,  0.1263, -0.2696], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1118,  0.1704,  0.2950, -0.0093, -0.3044, -0.0547, -0.0016,  0.0840],\n        [-0.1517,  0.1385,  0.1181,  0.3182,  0.1494,  0.2541, -0.2985,  0.3352],\n        [ 0.0828, -0.2265,  0.2126,  0.3227, -0.2439,  0.1330,  0.3183, -0.0478],\n        [-0.0937, -0.1865,  0.1608, -0.2563,  0.2086, -0.2778,  0.0923,  0.2415]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7ab075d677d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s211750000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s211750000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}