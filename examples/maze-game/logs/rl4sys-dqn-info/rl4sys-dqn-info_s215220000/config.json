{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s215220000"
    },
    "q_lr":	0.0005,
    "seed":	215220000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x7867e3429a10>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1138,  0.0294, -0.0301, -0.2084,  0.0594, -0.1082,  0.2223,  0.0423,\n        -0.1273, -0.0091, -0.1629, -0.2075, -0.0686,  0.2063, -0.2043, -0.1349,\n        -0.1342,  0.0094,  0.1711, -0.2077, -0.0285,  0.0807,  0.1483,  0.2082,\n        -0.0296, -0.0900, -0.0852,  0.0753, -0.0375, -0.0933, -0.0748, -0.1830],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0569, -0.0352,  0.1709, -0.0086,  0.0114,  0.0218,  0.0069,  0.0581,\n          0.0554,  0.1564,  0.0261,  0.0367,  0.0549,  0.1859, -0.0254, -0.0261,\n          0.1730, -0.1603, -0.0340,  0.1548],\n        [-0.0450,  0.1357,  0.0247, -0.0199, -0.1201,  0.0316,  0.1278, -0.0348,\n         -0.1116, -0.1540, -0.2220,  0.0399,  0.2212,  0.1801, -0.1659,  0.0229,\n         -0.1521, -0.1573, -0.1617, -0.0250],\n        [-0.0288,  0.2133,  0.1953,  0.1269, -0.1860,  0.0462,  0.1961, -0.0660,\n          0.0513,  0.1475,  0.1768,  0.1051, -0.0309, -0.0798, -0.1147, -0.0442,\n         -0.0465,  0.1486, -0.1286,  0.0142],\n        [ 0.1201, -0.0030,  0.0892,  0.0525, -0.0492, -0.1886, -0.1351, -0.1490,\n          0.1888, -0.1964, -0.1594, -0.1194,  0.2005, -0.1306,  0.1530, -0.1185,\n          0.2128, -0.0441,  0.1029, -0.0023],\n        [ 0.1755,  0.1342,  0.0471,  0.1377, -0.1777,  0.2164,  0.1053,  0.1475,\n         -0.0941, -0.1859, -0.0169, -0.1348, -0.1037, -0.1213,  0.1657,  0.0921,\n          0.1020,  0.0630, -0.1079, -0.0997],\n        [ 0.2134,  0.0826,  0.0484, -0.0962,  0.1991,  0.1489,  0.0254,  0.1310,\n          0.0052, -0.0295,  0.0424, -0.2111, -0.1960,  0.1962,  0.0247, -0.1867,\n          0.0747,  0.1384, -0.1169,  0.1127],\n        [ 0.1893,  0.0716, -0.0358,  0.0540, -0.0396, -0.1020,  0.0500, -0.0971,\n          0.0321,  0.0715, -0.0860,  0.0775, -0.1873, -0.0586, -0.0455, -0.0588,\n         -0.1170, -0.1832, -0.1437, -0.0112],\n        [ 0.0999,  0.2215, -0.2006,  0.1984, -0.0790, -0.1501, -0.1283, -0.1348,\n          0.1406,  0.0406,  0.1039,  0.0308, -0.0728, -0.1577,  0.2169,  0.0418,\n          0.2197, -0.1778, -0.1534, -0.1095],\n        [ 0.0909,  0.1813,  0.1232,  0.1620,  0.0387,  0.0666, -0.1405,  0.1779,\n         -0.1683, -0.1578, -0.1006, -0.0021, -0.1568, -0.1119,  0.1075, -0.1573,\n         -0.1007,  0.1662,  0.0561, -0.0027],\n        [ 0.1041,  0.1772,  0.0997,  0.1420, -0.0079,  0.1744,  0.0128, -0.1580,\n          0.1865, -0.1988, -0.1730,  0.0103, -0.0064,  0.0827, -0.1478,  0.0077,\n          0.0196,  0.1502,  0.1050,  0.1121],\n        [ 0.0321,  0.1179,  0.1856, -0.0836, -0.0296, -0.0091,  0.0302, -0.0503,\n         -0.0619,  0.2022,  0.0739,  0.1310, -0.0542, -0.1624, -0.0704, -0.0310,\n         -0.1064,  0.0227,  0.0340,  0.1100],\n        [-0.1459,  0.0756,  0.0485,  0.0836, -0.1281,  0.1926,  0.1410, -0.0765,\n          0.1589, -0.1235, -0.1969, -0.0570, -0.1642,  0.0887,  0.1618,  0.1387,\n         -0.0799,  0.1972, -0.1697, -0.0063],\n        [-0.0143, -0.0853,  0.0786, -0.0935, -0.0502,  0.0715, -0.0004, -0.1022,\n         -0.0957, -0.0846, -0.0135,  0.2178, -0.1950,  0.1326,  0.0590, -0.0532,\n         -0.2078, -0.0982, -0.0657,  0.0501],\n        [ 0.1886,  0.1358,  0.1752, -0.0197, -0.0511, -0.0238,  0.1033, -0.1690,\n          0.0306,  0.1896, -0.1013,  0.1537, -0.0404,  0.0851, -0.1905,  0.1490,\n          0.0127, -0.0785,  0.1339,  0.1723],\n        [-0.1820,  0.1193,  0.0165, -0.0325, -0.0828,  0.0256,  0.2150, -0.2217,\n          0.1266,  0.2074,  0.1753,  0.1033, -0.0719, -0.0570, -0.0935,  0.1900,\n         -0.0955, -0.0556, -0.0917,  0.0625],\n        [ 0.2032, -0.0141, -0.0490,  0.0346, -0.1584, -0.0118,  0.1326,  0.0612,\n         -0.1890,  0.1078, -0.1737,  0.1801,  0.1142,  0.0856,  0.0515, -0.1514,\n          0.0835,  0.0254,  0.0854, -0.1395],\n        [-0.0290, -0.1689, -0.1208, -0.1215,  0.1633, -0.0089,  0.0530,  0.1502,\n         -0.1788, -0.2097,  0.0318, -0.1125, -0.0078, -0.0254,  0.2207, -0.0758,\n          0.1139,  0.1071, -0.1417, -0.1106],\n        [ 0.0395,  0.1465,  0.1622, -0.0467,  0.1249,  0.0840,  0.0044, -0.1481,\n          0.1429, -0.0511,  0.0573,  0.0646,  0.0064,  0.0193, -0.0401, -0.1677,\n          0.1743, -0.0169, -0.0417,  0.0814],\n        [ 0.0486,  0.1170, -0.0451, -0.2174, -0.0816, -0.0474, -0.1614, -0.2174,\n          0.1824,  0.0134,  0.0127, -0.0067, -0.2125, -0.1663,  0.2163, -0.2002,\n         -0.0432, -0.1737, -0.0651, -0.1258],\n        [ 0.0699,  0.0961,  0.1212, -0.1069,  0.1806, -0.1310,  0.0746,  0.1942,\n         -0.0023, -0.1857, -0.2171, -0.0285,  0.1962,  0.1957, -0.1686, -0.1130,\n         -0.1990,  0.0672,  0.1515,  0.1085],\n        [ 0.1414,  0.1107,  0.0682, -0.2196, -0.1823,  0.1076, -0.1792,  0.1739,\n         -0.0335,  0.2074, -0.1088,  0.0954, -0.1547, -0.1311,  0.0642,  0.0154,\n          0.0334, -0.0198, -0.2217, -0.1501],\n        [-0.0250, -0.0422, -0.0478,  0.1004, -0.0652, -0.0592, -0.0871,  0.2141,\n         -0.1297, -0.1670, -0.1777, -0.0919,  0.1619, -0.0779,  0.1139, -0.0088,\n         -0.0610, -0.1011,  0.0890, -0.0126],\n        [ 0.1141,  0.0826,  0.1827, -0.2003,  0.0909, -0.1180,  0.0336, -0.0884,\n         -0.0291,  0.1520, -0.2074,  0.0164, -0.1647, -0.1009,  0.0448, -0.0729,\n         -0.0533,  0.1825,  0.1163, -0.1576],\n        [-0.0128,  0.1920,  0.1259, -0.0190,  0.0328, -0.0180, -0.2104,  0.1185,\n         -0.1496, -0.0856,  0.0150,  0.1472, -0.0857,  0.0678,  0.1374,  0.1329,\n         -0.0010, -0.0364, -0.0533, -0.0426],\n        [-0.1225,  0.0029,  0.0875, -0.1122, -0.0211, -0.1821, -0.0023,  0.0890,\n         -0.0210, -0.0210,  0.0917, -0.1505,  0.0446,  0.1616, -0.1481, -0.1663,\n          0.2186, -0.0442,  0.0759,  0.1887],\n        [-0.1395,  0.1529,  0.0788,  0.0073, -0.0267,  0.1349,  0.1543,  0.1259,\n          0.0063,  0.0265, -0.0850, -0.1017, -0.0042,  0.1972, -0.1502, -0.1931,\n          0.1695,  0.0441, -0.0423, -0.0601],\n        [ 0.2096, -0.0976, -0.0877,  0.0415,  0.0186,  0.1431,  0.1687,  0.0362,\n         -0.0085, -0.2035, -0.0130, -0.2159,  0.1117,  0.0300, -0.1525, -0.0911,\n          0.0509,  0.1488,  0.0164,  0.1551],\n        [-0.0892,  0.2079,  0.0468,  0.0344, -0.1164,  0.0160, -0.0519, -0.1756,\n          0.1264, -0.0517,  0.0195,  0.1746, -0.2204, -0.1847,  0.2031,  0.0851,\n          0.1026,  0.2081,  0.1263,  0.1789],\n        [ 0.1537,  0.0252,  0.1704,  0.0075,  0.1065, -0.0904, -0.1948, -0.0562,\n          0.0112,  0.1617,  0.0919, -0.1186,  0.0576,  0.1282, -0.0620, -0.1256,\n         -0.0437,  0.0122,  0.0528,  0.1435],\n        [ 0.1914, -0.0287, -0.1675,  0.0782,  0.1915,  0.0366, -0.0107,  0.0113,\n          0.1130, -0.1714, -0.0070,  0.1550, -0.2027,  0.0032,  0.0117,  0.1857,\n          0.0766,  0.0028,  0.1337,  0.0495],\n        [-0.1331,  0.1922, -0.1167,  0.0200, -0.1885,  0.1529, -0.0993, -0.1942,\n         -0.0164,  0.1521, -0.0109, -0.2187,  0.1974,  0.0705,  0.1772,  0.0178,\n         -0.0792,  0.2200, -0.1656,  0.1870],\n        [ 0.0082,  0.0548, -0.0918,  0.1653, -0.0567,  0.1877,  0.1040,  0.0264,\n          0.1894,  0.1160,  0.0999,  0.0736, -0.0533,  0.1705,  0.0992, -0.1611,\n         -0.1853, -0.0293, -0.1177,  0.1839]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0851, -0.0755,  0.1138,  0.0581,  0.0731, -0.1680,  0.0315,  0.0329,\n        -0.0484,  0.0298, -0.0317, -0.0497,  0.0810, -0.0237,  0.1502, -0.1492],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.2859e-02,  1.1921e-01,  3.8572e-03,  6.4153e-02,  5.4751e-02,\n          9.6097e-04,  8.0978e-02,  5.7086e-02,  1.1081e-02,  1.7660e-02,\n         -1.1400e-01, -4.2915e-02,  1.0533e-01, -1.7606e-02,  8.1835e-02,\n          8.4020e-02, -8.3239e-02, -1.1256e-01, -1.5361e-01, -8.6556e-02,\n         -1.7676e-01, -2.5423e-03, -3.7191e-02, -9.1493e-02, -9.8335e-02,\n         -8.3382e-02,  7.3858e-02,  4.6041e-02, -1.9117e-02, -1.3895e-01,\n         -8.0491e-02,  7.4818e-02],\n        [-7.7643e-02, -3.1321e-03, -5.7108e-02,  1.5393e-01, -4.8180e-02,\n          1.0087e-01, -8.4701e-02, -1.1988e-01, -1.4855e-01, -9.9589e-02,\n         -6.8804e-02,  1.2234e-02, -1.5850e-01, -5.3130e-02,  4.3792e-02,\n          6.7469e-02, -1.0596e-01,  7.4191e-02, -1.5350e-01,  1.0038e-01,\n         -1.3232e-01, -2.9365e-02,  9.5308e-02,  9.2827e-02, -1.0279e-01,\n         -6.6130e-02,  1.1277e-01,  1.2769e-01,  8.5930e-02,  8.5114e-02,\n          1.0455e-01,  1.2744e-01],\n        [-7.7084e-02,  1.3758e-01, -2.8349e-02, -8.6276e-02, -1.7240e-01,\n         -1.2896e-01, -1.3105e-01,  1.4513e-01,  7.1519e-02,  1.1685e-01,\n         -6.0011e-02,  7.0192e-02, -7.8323e-02, -1.5648e-02, -7.8204e-02,\n         -3.9489e-02, -5.5950e-02,  1.6700e-01, -4.6076e-02, -8.8140e-03,\n          7.1110e-02,  8.2898e-02,  8.4618e-03,  1.1373e-01, -1.4879e-01,\n         -5.1112e-02, -1.1180e-01, -4.5998e-02,  1.3732e-01,  1.1925e-01,\n          8.2666e-02,  5.3069e-02],\n        [ 6.7007e-02, -9.4158e-02,  3.3549e-02, -1.7376e-01, -1.3488e-01,\n          9.9702e-02,  6.4775e-02, -6.2758e-02, -5.1950e-02, -6.7405e-03,\n         -1.4409e-01,  7.6368e-02, -1.2315e-01, -1.5002e-01, -1.5280e-01,\n         -2.0062e-02,  8.0926e-02, -1.7662e-01,  4.7677e-02,  1.3803e-01,\n          1.4594e-01, -9.0678e-02,  1.1419e-01,  2.1535e-02, -1.1735e-01,\n         -1.0064e-01,  1.1745e-01, -7.0958e-02, -1.6087e-01, -5.7044e-02,\n         -7.8312e-02,  2.5214e-02],\n        [-1.8569e-02, -1.1151e-01,  3.8240e-02, -1.4078e-02,  4.4998e-02,\n          2.6435e-02, -4.8221e-02, -1.1843e-01, -1.6193e-01,  1.7704e-02,\n         -1.7550e-02,  5.0032e-02,  1.7149e-01,  5.8879e-02,  8.9796e-02,\n          1.5958e-01,  1.2443e-01,  1.6488e-01, -7.3287e-02,  1.9841e-02,\n          1.4097e-01,  1.6268e-01, -9.1275e-02,  1.2541e-01, -8.0278e-02,\n          4.3583e-02, -7.7334e-02,  1.1823e-03, -1.0837e-01, -5.8710e-02,\n         -1.2305e-01, -8.0071e-02],\n        [-9.4483e-02, -1.0087e-01,  1.1387e-02,  1.3820e-01, -1.2158e-01,\n          1.2672e-01,  9.4493e-02,  1.4915e-01,  6.9001e-02,  1.5306e-01,\n          8.9978e-02, -1.0244e-01, -1.6436e-01, -7.3642e-02, -7.4760e-02,\n         -4.1421e-03,  1.5334e-01,  9.7715e-02,  4.8489e-02,  1.2563e-01,\n          3.6225e-02,  3.7822e-03,  5.3996e-02, -1.2231e-01,  1.5269e-02,\n          9.6182e-02,  3.2940e-02, -1.2650e-01,  8.8629e-02, -1.3658e-02,\n          5.4749e-02, -6.4516e-02],\n        [-3.3758e-02, -6.7180e-02, -2.1314e-02,  1.3147e-01, -8.8537e-03,\n          1.7577e-01,  7.7026e-02,  1.7529e-01,  1.3751e-01,  1.2513e-01,\n          1.6347e-01,  5.6189e-02,  1.7607e-01, -8.2146e-02, -7.4141e-02,\n         -1.3991e-01,  1.4753e-01, -8.6284e-02,  1.1934e-01,  2.9778e-02,\n         -1.3051e-01,  9.7343e-02,  1.4789e-01, -1.5073e-01,  7.6575e-02,\n          4.9668e-02,  1.3845e-01,  1.5583e-01, -8.5254e-02, -2.5292e-02,\n          3.1707e-02, -4.0046e-02],\n        [ 1.1549e-01, -7.9369e-02,  1.0649e-01, -8.2113e-02,  5.5177e-02,\n         -1.4101e-02,  1.3527e-01,  7.6740e-02,  1.1855e-01, -8.0440e-02,\n          2.3849e-02, -4.9724e-02, -1.9682e-02,  1.6398e-01, -1.9721e-02,\n         -4.3547e-02,  1.7611e-01,  3.7803e-02,  1.3651e-01, -9.5693e-02,\n          1.3724e-01,  3.6176e-02, -5.9927e-02, -1.1040e-01,  1.6095e-02,\n         -9.3676e-02, -9.7637e-02,  6.5609e-02, -1.5444e-01, -1.1464e-01,\n          1.6995e-01, -1.6196e-01],\n        [-4.3503e-02,  1.4559e-01, -8.3278e-02, -1.2140e-01,  1.0712e-01,\n          1.1338e-01,  1.1984e-01,  2.1783e-02, -1.0573e-01,  6.7313e-03,\n          1.4803e-01,  2.2633e-03,  6.7545e-02,  9.1501e-02,  1.3987e-01,\n         -1.6467e-01,  5.2761e-02,  9.5119e-02, -3.8409e-02, -4.2598e-02,\n         -3.3481e-04, -1.9220e-02, -1.7249e-01, -2.6369e-02,  1.1568e-01,\n         -2.6051e-02, -8.2491e-02, -6.4370e-02, -1.3778e-01, -9.7047e-02,\n          6.8109e-02, -2.7193e-03],\n        [ 3.8175e-03, -9.4209e-02, -9.8212e-02,  8.7983e-02,  1.5371e-01,\n          8.8452e-02, -5.7600e-02, -7.1318e-02,  1.0173e-02,  1.2583e-01,\n          9.4381e-02,  2.9796e-02,  1.0597e-01,  9.8893e-02,  8.1822e-02,\n         -9.4992e-02, -1.2951e-01,  6.4387e-02,  4.9440e-02, -7.0131e-02,\n         -4.7382e-02, -1.2923e-01,  5.5325e-02,  1.0118e-01,  5.7358e-02,\n         -1.2159e-01,  8.3495e-02, -1.2550e-01, -1.5565e-01, -5.3382e-02,\n         -1.2860e-01,  6.1441e-02],\n        [ 7.6576e-02, -7.5552e-02, -9.6878e-02,  3.7807e-02, -8.1728e-02,\n          8.6466e-02, -1.1777e-02, -5.5456e-02,  8.7915e-02, -2.8338e-02,\n         -1.6414e-01, -8.4893e-02,  5.1933e-02,  2.4141e-02, -1.3894e-01,\n         -7.0814e-02, -3.7619e-02, -8.1392e-02, -7.6035e-02, -1.6523e-01,\n          1.6458e-01, -1.1134e-02, -5.2497e-02, -1.4079e-01, -1.5306e-02,\n         -4.0508e-02,  1.1286e-01,  1.1889e-01, -7.2959e-02,  7.0282e-02,\n         -7.2763e-02, -1.3066e-01],\n        [-1.1886e-01, -1.6163e-01,  1.7899e-02,  3.1227e-03,  5.1545e-02,\n          1.4797e-01, -1.5937e-01, -1.6118e-01,  8.2355e-02,  1.1408e-01,\n          1.7099e-01, -1.6430e-01,  3.6435e-02, -1.7427e-01,  1.2857e-01,\n          1.1040e-01, -7.4028e-02,  6.6530e-02,  1.5758e-01,  1.6973e-01,\n         -1.0463e-01,  7.5718e-02,  1.1831e-01,  1.7594e-01,  9.2086e-02,\n         -1.4602e-01, -1.1736e-01, -3.5259e-02, -1.6436e-01,  3.4527e-02,\n         -4.7474e-02,  1.5561e-01],\n        [-1.0244e-01,  2.5071e-02,  3.0895e-02, -7.1731e-02,  1.2314e-01,\n         -2.3964e-02, -1.6479e-01,  1.7155e-01, -2.5403e-02,  1.1698e-01,\n          6.3256e-02, -1.6514e-01,  3.1281e-02, -1.3283e-01, -7.2257e-02,\n          1.2816e-01,  1.0751e-01,  6.9783e-02, -1.3308e-01,  5.2577e-02,\n          7.8576e-02,  3.5578e-02,  1.3042e-01, -1.1663e-01,  1.5207e-01,\n         -3.1542e-02,  5.0660e-02, -5.4789e-03,  1.2376e-01,  5.6704e-02,\n         -7.2378e-02, -1.4420e-01],\n        [ 1.2952e-01,  1.5883e-01, -1.7612e-01, -9.1358e-02, -6.3334e-02,\n         -7.0004e-02, -4.0973e-02, -1.7424e-01, -1.6795e-03,  1.3601e-01,\n          5.6114e-02,  1.5468e-01, -1.7113e-01,  4.2665e-03, -1.0546e-02,\n         -1.3671e-01, -5.2714e-02, -1.6731e-01,  8.8532e-03,  1.7405e-01,\n         -5.5554e-02,  5.9727e-02,  2.4320e-02,  2.5757e-02,  9.1804e-04,\n         -1.5852e-01,  9.5928e-02,  1.6751e-01, -6.4088e-02, -8.7883e-02,\n          1.1030e-01, -3.9972e-03],\n        [ 1.6456e-01,  1.2983e-01, -6.6895e-02,  6.8754e-02,  1.3341e-02,\n         -7.9812e-02, -2.7101e-02, -7.8932e-02,  3.7150e-02,  8.0816e-02,\n         -6.5545e-02,  9.2533e-02,  1.6625e-01, -1.6673e-01, -4.0514e-03,\n          1.6819e-01,  9.5779e-02, -9.2910e-03, -5.9982e-02, -5.0426e-02,\n          6.5944e-02,  6.8858e-03,  1.6970e-02, -1.6018e-01, -6.5717e-02,\n          1.2968e-01, -4.1499e-02,  5.5040e-02, -3.7243e-02,  5.2267e-02,\n          1.4432e-01,  1.1483e-01],\n        [ 1.7656e-01, -1.3234e-01,  8.1834e-02, -8.4223e-02,  1.5014e-01,\n         -2.6680e-02, -6.7179e-02,  1.5881e-01, -3.6292e-02,  1.2307e-02,\n         -1.0815e-01,  1.6180e-01, -1.3773e-01, -7.5385e-02, -1.0385e-01,\n          9.0261e-02,  9.4438e-02,  3.6630e-02,  1.2990e-01, -6.4420e-02,\n         -3.1282e-02, -9.2851e-03,  3.7953e-05,  9.5238e-02,  1.1187e-01,\n          5.4129e-02,  3.2236e-02,  4.9357e-02,  4.2094e-02, -6.3207e-02,\n         -1.4933e-01,  5.2072e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1580, -0.1593,  0.0832, -0.0256,  0.1033,  0.1413,  0.1778,  0.0794],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0016, -0.0612, -0.1863, -0.1320,  0.2469, -0.0403, -0.2040, -0.2424,\n          0.2319, -0.2344, -0.2398,  0.1856, -0.1609,  0.2126, -0.2103,  0.2364],\n        [-0.2298, -0.0482,  0.0171,  0.1905, -0.2333,  0.2275, -0.2212, -0.2424,\n         -0.0460,  0.1008, -0.0785, -0.0187,  0.1103, -0.1611,  0.2260,  0.1219],\n        [ 0.1154,  0.1401,  0.1653, -0.0279,  0.2038, -0.1719, -0.2267,  0.0114,\n         -0.2419,  0.1732,  0.0715,  0.1533,  0.0749,  0.1042,  0.0487, -0.1067],\n        [-0.1896,  0.2315, -0.0017, -0.1709, -0.2124, -0.0233,  0.0303,  0.2161,\n         -0.0047,  0.1425, -0.0142, -0.0811, -0.1171,  0.0145, -0.1019,  0.2086],\n        [ 0.1400, -0.0484, -0.0276, -0.0245, -0.0018, -0.0400, -0.1460,  0.2313,\n         -0.1438,  0.1839,  0.2125, -0.2045, -0.0970,  0.1537,  0.1286,  0.1893],\n        [-0.1568, -0.1069, -0.0728, -0.0553, -0.0717,  0.1317, -0.0663, -0.2381,\n         -0.1510, -0.1094, -0.0007, -0.0915,  0.0641, -0.2210,  0.1956, -0.1237],\n        [ 0.2108,  0.1571, -0.1035,  0.1731, -0.0331,  0.0784,  0.0880, -0.1097,\n          0.0372, -0.1389, -0.2233,  0.1354,  0.1755,  0.1333,  0.2463, -0.1314],\n        [-0.1898,  0.2066,  0.1082,  0.2038,  0.0215, -0.0550, -0.1279, -0.2001,\n          0.1257, -0.2313,  0.1706, -0.1813, -0.2458, -0.0991, -0.0481, -0.1294]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3100,  0.1486,  0.2498, -0.2198], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.2393e-04,  2.5861e-01,  1.7013e-01, -1.6823e-01, -1.5857e-01,\n         -2.8300e-02,  1.1526e-01,  3.3199e-01],\n        [-1.8060e-01, -3.1386e-01, -1.9641e-01, -2.3061e-01,  2.3386e-01,\n          2.1732e-03, -2.2225e-01,  2.4447e-01],\n        [-3.3215e-01, -1.6435e-01, -1.6371e-01,  6.1348e-03,  3.0580e-01,\n          4.1365e-02, -7.4291e-02, -5.2089e-02],\n        [ 2.2564e-01, -7.2344e-02,  1.6733e-01,  5.4999e-02,  2.4824e-01,\n         -1.1927e-01,  1.8644e-01,  2.2471e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0569, -0.0352,  0.1709, -0.0086,  0.0114,  0.0218,  0.0069,  0.0581,\n          0.0554,  0.1564,  0.0261,  0.0367,  0.0549,  0.1859, -0.0254, -0.0261,\n          0.1730, -0.1603, -0.0340,  0.1548],\n        [-0.0450,  0.1357,  0.0247, -0.0199, -0.1201,  0.0316,  0.1278, -0.0348,\n         -0.1116, -0.1540, -0.2220,  0.0399,  0.2212,  0.1801, -0.1659,  0.0229,\n         -0.1521, -0.1573, -0.1617, -0.0250],\n        [-0.0288,  0.2133,  0.1953,  0.1269, -0.1860,  0.0462,  0.1961, -0.0660,\n          0.0513,  0.1475,  0.1768,  0.1051, -0.0309, -0.0798, -0.1147, -0.0442,\n         -0.0465,  0.1486, -0.1286,  0.0142],\n        [ 0.1201, -0.0030,  0.0892,  0.0525, -0.0492, -0.1886, -0.1351, -0.1490,\n          0.1888, -0.1964, -0.1594, -0.1194,  0.2005, -0.1306,  0.1530, -0.1185,\n          0.2128, -0.0441,  0.1029, -0.0023],\n        [ 0.1755,  0.1342,  0.0471,  0.1377, -0.1777,  0.2164,  0.1053,  0.1475,\n         -0.0941, -0.1859, -0.0169, -0.1348, -0.1037, -0.1213,  0.1657,  0.0921,\n          0.1020,  0.0630, -0.1079, -0.0997],\n        [ 0.2134,  0.0826,  0.0484, -0.0962,  0.1991,  0.1489,  0.0254,  0.1310,\n          0.0052, -0.0295,  0.0424, -0.2111, -0.1960,  0.1962,  0.0247, -0.1867,\n          0.0747,  0.1384, -0.1169,  0.1127],\n        [ 0.1893,  0.0716, -0.0358,  0.0540, -0.0396, -0.1020,  0.0500, -0.0971,\n          0.0321,  0.0715, -0.0860,  0.0775, -0.1873, -0.0586, -0.0455, -0.0588,\n         -0.1170, -0.1832, -0.1437, -0.0112],\n        [ 0.0999,  0.2215, -0.2006,  0.1984, -0.0790, -0.1501, -0.1283, -0.1348,\n          0.1406,  0.0406,  0.1039,  0.0308, -0.0728, -0.1577,  0.2169,  0.0418,\n          0.2197, -0.1778, -0.1534, -0.1095],\n        [ 0.0909,  0.1813,  0.1232,  0.1620,  0.0387,  0.0666, -0.1405,  0.1779,\n         -0.1683, -0.1578, -0.1006, -0.0021, -0.1568, -0.1119,  0.1075, -0.1573,\n         -0.1007,  0.1662,  0.0561, -0.0027],\n        [ 0.1041,  0.1772,  0.0997,  0.1420, -0.0079,  0.1744,  0.0128, -0.1580,\n          0.1865, -0.1988, -0.1730,  0.0103, -0.0064,  0.0827, -0.1478,  0.0077,\n          0.0196,  0.1502,  0.1050,  0.1121],\n        [ 0.0321,  0.1179,  0.1856, -0.0836, -0.0296, -0.0091,  0.0302, -0.0503,\n         -0.0619,  0.2022,  0.0739,  0.1310, -0.0542, -0.1624, -0.0704, -0.0310,\n         -0.1064,  0.0227,  0.0340,  0.1100],\n        [-0.1459,  0.0756,  0.0485,  0.0836, -0.1281,  0.1926,  0.1410, -0.0765,\n          0.1589, -0.1235, -0.1969, -0.0570, -0.1642,  0.0887,  0.1618,  0.1387,\n         -0.0799,  0.1972, -0.1697, -0.0063],\n        [-0.0143, -0.0853,  0.0786, -0.0935, -0.0502,  0.0715, -0.0004, -0.1022,\n         -0.0957, -0.0846, -0.0135,  0.2178, -0.1950,  0.1326,  0.0590, -0.0532,\n         -0.2078, -0.0982, -0.0657,  0.0501],\n        [ 0.1886,  0.1358,  0.1752, -0.0197, -0.0511, -0.0238,  0.1033, -0.1690,\n          0.0306,  0.1896, -0.1013,  0.1537, -0.0404,  0.0851, -0.1905,  0.1490,\n          0.0127, -0.0785,  0.1339,  0.1723],\n        [-0.1820,  0.1193,  0.0165, -0.0325, -0.0828,  0.0256,  0.2150, -0.2217,\n          0.1266,  0.2074,  0.1753,  0.1033, -0.0719, -0.0570, -0.0935,  0.1900,\n         -0.0955, -0.0556, -0.0917,  0.0625],\n        [ 0.2032, -0.0141, -0.0490,  0.0346, -0.1584, -0.0118,  0.1326,  0.0612,\n         -0.1890,  0.1078, -0.1737,  0.1801,  0.1142,  0.0856,  0.0515, -0.1514,\n          0.0835,  0.0254,  0.0854, -0.1395],\n        [-0.0290, -0.1689, -0.1208, -0.1215,  0.1633, -0.0089,  0.0530,  0.1502,\n         -0.1788, -0.2097,  0.0318, -0.1125, -0.0078, -0.0254,  0.2207, -0.0758,\n          0.1139,  0.1071, -0.1417, -0.1106],\n        [ 0.0395,  0.1465,  0.1622, -0.0467,  0.1249,  0.0840,  0.0044, -0.1481,\n          0.1429, -0.0511,  0.0573,  0.0646,  0.0064,  0.0193, -0.0401, -0.1677,\n          0.1743, -0.0169, -0.0417,  0.0814],\n        [ 0.0486,  0.1170, -0.0451, -0.2174, -0.0816, -0.0474, -0.1614, -0.2174,\n          0.1824,  0.0134,  0.0127, -0.0067, -0.2125, -0.1663,  0.2163, -0.2002,\n         -0.0432, -0.1737, -0.0651, -0.1258],\n        [ 0.0699,  0.0961,  0.1212, -0.1069,  0.1806, -0.1310,  0.0746,  0.1942,\n         -0.0023, -0.1857, -0.2171, -0.0285,  0.1962,  0.1957, -0.1686, -0.1130,\n         -0.1990,  0.0672,  0.1515,  0.1085],\n        [ 0.1414,  0.1107,  0.0682, -0.2196, -0.1823,  0.1076, -0.1792,  0.1739,\n         -0.0335,  0.2074, -0.1088,  0.0954, -0.1547, -0.1311,  0.0642,  0.0154,\n          0.0334, -0.0198, -0.2217, -0.1501],\n        [-0.0250, -0.0422, -0.0478,  0.1004, -0.0652, -0.0592, -0.0871,  0.2141,\n         -0.1297, -0.1670, -0.1777, -0.0919,  0.1619, -0.0779,  0.1139, -0.0088,\n         -0.0610, -0.1011,  0.0890, -0.0126],\n        [ 0.1141,  0.0826,  0.1827, -0.2003,  0.0909, -0.1180,  0.0336, -0.0884,\n         -0.0291,  0.1520, -0.2074,  0.0164, -0.1647, -0.1009,  0.0448, -0.0729,\n         -0.0533,  0.1825,  0.1163, -0.1576],\n        [-0.0128,  0.1920,  0.1259, -0.0190,  0.0328, -0.0180, -0.2104,  0.1185,\n         -0.1496, -0.0856,  0.0150,  0.1472, -0.0857,  0.0678,  0.1374,  0.1329,\n         -0.0010, -0.0364, -0.0533, -0.0426],\n        [-0.1225,  0.0029,  0.0875, -0.1122, -0.0211, -0.1821, -0.0023,  0.0890,\n         -0.0210, -0.0210,  0.0917, -0.1505,  0.0446,  0.1616, -0.1481, -0.1663,\n          0.2186, -0.0442,  0.0759,  0.1887],\n        [-0.1395,  0.1529,  0.0788,  0.0073, -0.0267,  0.1349,  0.1543,  0.1259,\n          0.0063,  0.0265, -0.0850, -0.1017, -0.0042,  0.1972, -0.1502, -0.1931,\n          0.1695,  0.0441, -0.0423, -0.0601],\n        [ 0.2096, -0.0976, -0.0877,  0.0415,  0.0186,  0.1431,  0.1687,  0.0362,\n         -0.0085, -0.2035, -0.0130, -0.2159,  0.1117,  0.0300, -0.1525, -0.0911,\n          0.0509,  0.1488,  0.0164,  0.1551],\n        [-0.0892,  0.2079,  0.0468,  0.0344, -0.1164,  0.0160, -0.0519, -0.1756,\n          0.1264, -0.0517,  0.0195,  0.1746, -0.2204, -0.1847,  0.2031,  0.0851,\n          0.1026,  0.2081,  0.1263,  0.1789],\n        [ 0.1537,  0.0252,  0.1704,  0.0075,  0.1065, -0.0904, -0.1948, -0.0562,\n          0.0112,  0.1617,  0.0919, -0.1186,  0.0576,  0.1282, -0.0620, -0.1256,\n         -0.0437,  0.0122,  0.0528,  0.1435],\n        [ 0.1914, -0.0287, -0.1675,  0.0782,  0.1915,  0.0366, -0.0107,  0.0113,\n          0.1130, -0.1714, -0.0070,  0.1550, -0.2027,  0.0032,  0.0117,  0.1857,\n          0.0766,  0.0028,  0.1337,  0.0495],\n        [-0.1331,  0.1922, -0.1167,  0.0200, -0.1885,  0.1529, -0.0993, -0.1942,\n         -0.0164,  0.1521, -0.0109, -0.2187,  0.1974,  0.0705,  0.1772,  0.0178,\n         -0.0792,  0.2200, -0.1656,  0.1870],\n        [ 0.0082,  0.0548, -0.0918,  0.1653, -0.0567,  0.1877,  0.1040,  0.0264,\n          0.1894,  0.1160,  0.0999,  0.0736, -0.0533,  0.1705,  0.0992, -0.1611,\n         -0.1853, -0.0293, -0.1177,  0.1839]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1138,  0.0294, -0.0301, -0.2084,  0.0594, -0.1082,  0.2223,  0.0423,\n        -0.1273, -0.0091, -0.1629, -0.2075, -0.0686,  0.2063, -0.2043, -0.1349,\n        -0.1342,  0.0094,  0.1711, -0.2077, -0.0285,  0.0807,  0.1483,  0.2082,\n        -0.0296, -0.0900, -0.0852,  0.0753, -0.0375, -0.0933, -0.0748, -0.1830],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.2859e-02,  1.1921e-01,  3.8572e-03,  6.4153e-02,  5.4751e-02,\n          9.6097e-04,  8.0978e-02,  5.7086e-02,  1.1081e-02,  1.7660e-02,\n         -1.1400e-01, -4.2915e-02,  1.0533e-01, -1.7606e-02,  8.1835e-02,\n          8.4020e-02, -8.3239e-02, -1.1256e-01, -1.5361e-01, -8.6556e-02,\n         -1.7676e-01, -2.5423e-03, -3.7191e-02, -9.1493e-02, -9.8335e-02,\n         -8.3382e-02,  7.3858e-02,  4.6041e-02, -1.9117e-02, -1.3895e-01,\n         -8.0491e-02,  7.4818e-02],\n        [-7.7643e-02, -3.1321e-03, -5.7108e-02,  1.5393e-01, -4.8180e-02,\n          1.0087e-01, -8.4701e-02, -1.1988e-01, -1.4855e-01, -9.9589e-02,\n         -6.8804e-02,  1.2234e-02, -1.5850e-01, -5.3130e-02,  4.3792e-02,\n          6.7469e-02, -1.0596e-01,  7.4191e-02, -1.5350e-01,  1.0038e-01,\n         -1.3232e-01, -2.9365e-02,  9.5308e-02,  9.2827e-02, -1.0279e-01,\n         -6.6130e-02,  1.1277e-01,  1.2769e-01,  8.5930e-02,  8.5114e-02,\n          1.0455e-01,  1.2744e-01],\n        [-7.7084e-02,  1.3758e-01, -2.8349e-02, -8.6276e-02, -1.7240e-01,\n         -1.2896e-01, -1.3105e-01,  1.4513e-01,  7.1519e-02,  1.1685e-01,\n         -6.0011e-02,  7.0192e-02, -7.8323e-02, -1.5648e-02, -7.8204e-02,\n         -3.9489e-02, -5.5950e-02,  1.6700e-01, -4.6076e-02, -8.8140e-03,\n          7.1110e-02,  8.2898e-02,  8.4618e-03,  1.1373e-01, -1.4879e-01,\n         -5.1112e-02, -1.1180e-01, -4.5998e-02,  1.3732e-01,  1.1925e-01,\n          8.2666e-02,  5.3069e-02],\n        [ 6.7007e-02, -9.4158e-02,  3.3549e-02, -1.7376e-01, -1.3488e-01,\n          9.9702e-02,  6.4775e-02, -6.2758e-02, -5.1950e-02, -6.7405e-03,\n         -1.4409e-01,  7.6368e-02, -1.2315e-01, -1.5002e-01, -1.5280e-01,\n         -2.0062e-02,  8.0926e-02, -1.7662e-01,  4.7677e-02,  1.3803e-01,\n          1.4594e-01, -9.0678e-02,  1.1419e-01,  2.1535e-02, -1.1735e-01,\n         -1.0064e-01,  1.1745e-01, -7.0958e-02, -1.6087e-01, -5.7044e-02,\n         -7.8312e-02,  2.5214e-02],\n        [-1.8569e-02, -1.1151e-01,  3.8240e-02, -1.4078e-02,  4.4998e-02,\n          2.6435e-02, -4.8221e-02, -1.1843e-01, -1.6193e-01,  1.7704e-02,\n         -1.7550e-02,  5.0032e-02,  1.7149e-01,  5.8879e-02,  8.9796e-02,\n          1.5958e-01,  1.2443e-01,  1.6488e-01, -7.3287e-02,  1.9841e-02,\n          1.4097e-01,  1.6268e-01, -9.1275e-02,  1.2541e-01, -8.0278e-02,\n          4.3583e-02, -7.7334e-02,  1.1823e-03, -1.0837e-01, -5.8710e-02,\n         -1.2305e-01, -8.0071e-02],\n        [-9.4483e-02, -1.0087e-01,  1.1387e-02,  1.3820e-01, -1.2158e-01,\n          1.2672e-01,  9.4493e-02,  1.4915e-01,  6.9001e-02,  1.5306e-01,\n          8.9978e-02, -1.0244e-01, -1.6436e-01, -7.3642e-02, -7.4760e-02,\n         -4.1421e-03,  1.5334e-01,  9.7715e-02,  4.8489e-02,  1.2563e-01,\n          3.6225e-02,  3.7822e-03,  5.3996e-02, -1.2231e-01,  1.5269e-02,\n          9.6182e-02,  3.2940e-02, -1.2650e-01,  8.8629e-02, -1.3658e-02,\n          5.4749e-02, -6.4516e-02],\n        [-3.3758e-02, -6.7180e-02, -2.1314e-02,  1.3147e-01, -8.8537e-03,\n          1.7577e-01,  7.7026e-02,  1.7529e-01,  1.3751e-01,  1.2513e-01,\n          1.6347e-01,  5.6189e-02,  1.7607e-01, -8.2146e-02, -7.4141e-02,\n         -1.3991e-01,  1.4753e-01, -8.6284e-02,  1.1934e-01,  2.9778e-02,\n         -1.3051e-01,  9.7343e-02,  1.4789e-01, -1.5073e-01,  7.6575e-02,\n          4.9668e-02,  1.3845e-01,  1.5583e-01, -8.5254e-02, -2.5292e-02,\n          3.1707e-02, -4.0046e-02],\n        [ 1.1549e-01, -7.9369e-02,  1.0649e-01, -8.2113e-02,  5.5177e-02,\n         -1.4101e-02,  1.3527e-01,  7.6740e-02,  1.1855e-01, -8.0440e-02,\n          2.3849e-02, -4.9724e-02, -1.9682e-02,  1.6398e-01, -1.9721e-02,\n         -4.3547e-02,  1.7611e-01,  3.7803e-02,  1.3651e-01, -9.5693e-02,\n          1.3724e-01,  3.6176e-02, -5.9927e-02, -1.1040e-01,  1.6095e-02,\n         -9.3676e-02, -9.7637e-02,  6.5609e-02, -1.5444e-01, -1.1464e-01,\n          1.6995e-01, -1.6196e-01],\n        [-4.3503e-02,  1.4559e-01, -8.3278e-02, -1.2140e-01,  1.0712e-01,\n          1.1338e-01,  1.1984e-01,  2.1783e-02, -1.0573e-01,  6.7313e-03,\n          1.4803e-01,  2.2633e-03,  6.7545e-02,  9.1501e-02,  1.3987e-01,\n         -1.6467e-01,  5.2761e-02,  9.5119e-02, -3.8409e-02, -4.2598e-02,\n         -3.3481e-04, -1.9220e-02, -1.7249e-01, -2.6369e-02,  1.1568e-01,\n         -2.6051e-02, -8.2491e-02, -6.4370e-02, -1.3778e-01, -9.7047e-02,\n          6.8109e-02, -2.7193e-03],\n        [ 3.8175e-03, -9.4209e-02, -9.8212e-02,  8.7983e-02,  1.5371e-01,\n          8.8452e-02, -5.7600e-02, -7.1318e-02,  1.0173e-02,  1.2583e-01,\n          9.4381e-02,  2.9796e-02,  1.0597e-01,  9.8893e-02,  8.1822e-02,\n         -9.4992e-02, -1.2951e-01,  6.4387e-02,  4.9440e-02, -7.0131e-02,\n         -4.7382e-02, -1.2923e-01,  5.5325e-02,  1.0118e-01,  5.7358e-02,\n         -1.2159e-01,  8.3495e-02, -1.2550e-01, -1.5565e-01, -5.3382e-02,\n         -1.2860e-01,  6.1441e-02],\n        [ 7.6576e-02, -7.5552e-02, -9.6878e-02,  3.7807e-02, -8.1728e-02,\n          8.6466e-02, -1.1777e-02, -5.5456e-02,  8.7915e-02, -2.8338e-02,\n         -1.6414e-01, -8.4893e-02,  5.1933e-02,  2.4141e-02, -1.3894e-01,\n         -7.0814e-02, -3.7619e-02, -8.1392e-02, -7.6035e-02, -1.6523e-01,\n          1.6458e-01, -1.1134e-02, -5.2497e-02, -1.4079e-01, -1.5306e-02,\n         -4.0508e-02,  1.1286e-01,  1.1889e-01, -7.2959e-02,  7.0282e-02,\n         -7.2763e-02, -1.3066e-01],\n        [-1.1886e-01, -1.6163e-01,  1.7899e-02,  3.1227e-03,  5.1545e-02,\n          1.4797e-01, -1.5937e-01, -1.6118e-01,  8.2355e-02,  1.1408e-01,\n          1.7099e-01, -1.6430e-01,  3.6435e-02, -1.7427e-01,  1.2857e-01,\n          1.1040e-01, -7.4028e-02,  6.6530e-02,  1.5758e-01,  1.6973e-01,\n         -1.0463e-01,  7.5718e-02,  1.1831e-01,  1.7594e-01,  9.2086e-02,\n         -1.4602e-01, -1.1736e-01, -3.5259e-02, -1.6436e-01,  3.4527e-02,\n         -4.7474e-02,  1.5561e-01],\n        [-1.0244e-01,  2.5071e-02,  3.0895e-02, -7.1731e-02,  1.2314e-01,\n         -2.3964e-02, -1.6479e-01,  1.7155e-01, -2.5403e-02,  1.1698e-01,\n          6.3256e-02, -1.6514e-01,  3.1281e-02, -1.3283e-01, -7.2257e-02,\n          1.2816e-01,  1.0751e-01,  6.9783e-02, -1.3308e-01,  5.2577e-02,\n          7.8576e-02,  3.5578e-02,  1.3042e-01, -1.1663e-01,  1.5207e-01,\n         -3.1542e-02,  5.0660e-02, -5.4789e-03,  1.2376e-01,  5.6704e-02,\n         -7.2378e-02, -1.4420e-01],\n        [ 1.2952e-01,  1.5883e-01, -1.7612e-01, -9.1358e-02, -6.3334e-02,\n         -7.0004e-02, -4.0973e-02, -1.7424e-01, -1.6795e-03,  1.3601e-01,\n          5.6114e-02,  1.5468e-01, -1.7113e-01,  4.2665e-03, -1.0546e-02,\n         -1.3671e-01, -5.2714e-02, -1.6731e-01,  8.8532e-03,  1.7405e-01,\n         -5.5554e-02,  5.9727e-02,  2.4320e-02,  2.5757e-02,  9.1804e-04,\n         -1.5852e-01,  9.5928e-02,  1.6751e-01, -6.4088e-02, -8.7883e-02,\n          1.1030e-01, -3.9972e-03],\n        [ 1.6456e-01,  1.2983e-01, -6.6895e-02,  6.8754e-02,  1.3341e-02,\n         -7.9812e-02, -2.7101e-02, -7.8932e-02,  3.7150e-02,  8.0816e-02,\n         -6.5545e-02,  9.2533e-02,  1.6625e-01, -1.6673e-01, -4.0514e-03,\n          1.6819e-01,  9.5779e-02, -9.2910e-03, -5.9982e-02, -5.0426e-02,\n          6.5944e-02,  6.8858e-03,  1.6970e-02, -1.6018e-01, -6.5717e-02,\n          1.2968e-01, -4.1499e-02,  5.5040e-02, -3.7243e-02,  5.2267e-02,\n          1.4432e-01,  1.1483e-01],\n        [ 1.7656e-01, -1.3234e-01,  8.1834e-02, -8.4223e-02,  1.5014e-01,\n         -2.6680e-02, -6.7179e-02,  1.5881e-01, -3.6292e-02,  1.2307e-02,\n         -1.0815e-01,  1.6180e-01, -1.3773e-01, -7.5385e-02, -1.0385e-01,\n          9.0261e-02,  9.4438e-02,  3.6630e-02,  1.2990e-01, -6.4420e-02,\n         -3.1282e-02, -9.2851e-03,  3.7953e-05,  9.5238e-02,  1.1187e-01,\n          5.4129e-02,  3.2236e-02,  4.9357e-02,  4.2094e-02, -6.3207e-02,\n         -1.4933e-01,  5.2072e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0851, -0.0755,  0.1138,  0.0581,  0.0731, -0.1680,  0.0315,  0.0329,\n        -0.0484,  0.0298, -0.0317, -0.0497,  0.0810, -0.0237,  0.1502, -0.1492],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0016, -0.0612, -0.1863, -0.1320,  0.2469, -0.0403, -0.2040, -0.2424,\n          0.2319, -0.2344, -0.2398,  0.1856, -0.1609,  0.2126, -0.2103,  0.2364],\n        [-0.2298, -0.0482,  0.0171,  0.1905, -0.2333,  0.2275, -0.2212, -0.2424,\n         -0.0460,  0.1008, -0.0785, -0.0187,  0.1103, -0.1611,  0.2260,  0.1219],\n        [ 0.1154,  0.1401,  0.1653, -0.0279,  0.2038, -0.1719, -0.2267,  0.0114,\n         -0.2419,  0.1732,  0.0715,  0.1533,  0.0749,  0.1042,  0.0487, -0.1067],\n        [-0.1896,  0.2315, -0.0017, -0.1709, -0.2124, -0.0233,  0.0303,  0.2161,\n         -0.0047,  0.1425, -0.0142, -0.0811, -0.1171,  0.0145, -0.1019,  0.2086],\n        [ 0.1400, -0.0484, -0.0276, -0.0245, -0.0018, -0.0400, -0.1460,  0.2313,\n         -0.1438,  0.1839,  0.2125, -0.2045, -0.0970,  0.1537,  0.1286,  0.1893],\n        [-0.1568, -0.1069, -0.0728, -0.0553, -0.0717,  0.1317, -0.0663, -0.2381,\n         -0.1510, -0.1094, -0.0007, -0.0915,  0.0641, -0.2210,  0.1956, -0.1237],\n        [ 0.2108,  0.1571, -0.1035,  0.1731, -0.0331,  0.0784,  0.0880, -0.1097,\n          0.0372, -0.1389, -0.2233,  0.1354,  0.1755,  0.1333,  0.2463, -0.1314],\n        [-0.1898,  0.2066,  0.1082,  0.2038,  0.0215, -0.0550, -0.1279, -0.2001,\n          0.1257, -0.2313,  0.1706, -0.1813, -0.2458, -0.0991, -0.0481, -0.1294]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1580, -0.1593,  0.0832, -0.0256,  0.1033,  0.1413,  0.1778,  0.0794],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-2.2393e-04,  2.5861e-01,  1.7013e-01, -1.6823e-01, -1.5857e-01,\n         -2.8300e-02,  1.1526e-01,  3.3199e-01],\n        [-1.8060e-01, -3.1386e-01, -1.9641e-01, -2.3061e-01,  2.3386e-01,\n          2.1732e-03, -2.2225e-01,  2.4447e-01],\n        [-3.3215e-01, -1.6435e-01, -1.6371e-01,  6.1348e-03,  3.0580e-01,\n          4.1365e-02, -7.4291e-02, -5.2089e-02],\n        [ 2.2564e-01, -7.2344e-02,  1.6733e-01,  5.4999e-02,  2.4824e-01,\n         -1.1927e-01,  1.8644e-01,  2.2471e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.3100,  0.1486,  0.2498, -0.2198], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x7867e309f590>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "time":	0,
                    "timestamp_buf":	"[0 0 0 ... 0 0 0]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1138,  0.0294, -0.0301, -0.2084,  0.0594, -0.1082,  0.2223,  0.0423,\n        -0.1273, -0.0091, -0.1629, -0.2075, -0.0686,  0.2063, -0.2043, -0.1349,\n        -0.1342,  0.0094,  0.1711, -0.2077, -0.0285,  0.0807,  0.1483,  0.2082,\n        -0.0296, -0.0900, -0.0852,  0.0753, -0.0375, -0.0933, -0.0748, -0.1830],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0569, -0.0352,  0.1709, -0.0086,  0.0114,  0.0218,  0.0069,  0.0581,\n          0.0554,  0.1564,  0.0261,  0.0367,  0.0549,  0.1859, -0.0254, -0.0261,\n          0.1730, -0.1603, -0.0340,  0.1548],\n        [-0.0450,  0.1357,  0.0247, -0.0199, -0.1201,  0.0316,  0.1278, -0.0348,\n         -0.1116, -0.1540, -0.2220,  0.0399,  0.2212,  0.1801, -0.1659,  0.0229,\n         -0.1521, -0.1573, -0.1617, -0.0250],\n        [-0.0288,  0.2133,  0.1953,  0.1269, -0.1860,  0.0462,  0.1961, -0.0660,\n          0.0513,  0.1475,  0.1768,  0.1051, -0.0309, -0.0798, -0.1147, -0.0442,\n         -0.0465,  0.1486, -0.1286,  0.0142],\n        [ 0.1201, -0.0030,  0.0892,  0.0525, -0.0492, -0.1886, -0.1351, -0.1490,\n          0.1888, -0.1964, -0.1594, -0.1194,  0.2005, -0.1306,  0.1530, -0.1185,\n          0.2128, -0.0441,  0.1029, -0.0023],\n        [ 0.1755,  0.1342,  0.0471,  0.1377, -0.1777,  0.2164,  0.1053,  0.1475,\n         -0.0941, -0.1859, -0.0169, -0.1348, -0.1037, -0.1213,  0.1657,  0.0921,\n          0.1020,  0.0630, -0.1079, -0.0997],\n        [ 0.2134,  0.0826,  0.0484, -0.0962,  0.1991,  0.1489,  0.0254,  0.1310,\n          0.0052, -0.0295,  0.0424, -0.2111, -0.1960,  0.1962,  0.0247, -0.1867,\n          0.0747,  0.1384, -0.1169,  0.1127],\n        [ 0.1893,  0.0716, -0.0358,  0.0540, -0.0396, -0.1020,  0.0500, -0.0971,\n          0.0321,  0.0715, -0.0860,  0.0775, -0.1873, -0.0586, -0.0455, -0.0588,\n         -0.1170, -0.1832, -0.1437, -0.0112],\n        [ 0.0999,  0.2215, -0.2006,  0.1984, -0.0790, -0.1501, -0.1283, -0.1348,\n          0.1406,  0.0406,  0.1039,  0.0308, -0.0728, -0.1577,  0.2169,  0.0418,\n          0.2197, -0.1778, -0.1534, -0.1095],\n        [ 0.0909,  0.1813,  0.1232,  0.1620,  0.0387,  0.0666, -0.1405,  0.1779,\n         -0.1683, -0.1578, -0.1006, -0.0021, -0.1568, -0.1119,  0.1075, -0.1573,\n         -0.1007,  0.1662,  0.0561, -0.0027],\n        [ 0.1041,  0.1772,  0.0997,  0.1420, -0.0079,  0.1744,  0.0128, -0.1580,\n          0.1865, -0.1988, -0.1730,  0.0103, -0.0064,  0.0827, -0.1478,  0.0077,\n          0.0196,  0.1502,  0.1050,  0.1121],\n        [ 0.0321,  0.1179,  0.1856, -0.0836, -0.0296, -0.0091,  0.0302, -0.0503,\n         -0.0619,  0.2022,  0.0739,  0.1310, -0.0542, -0.1624, -0.0704, -0.0310,\n         -0.1064,  0.0227,  0.0340,  0.1100],\n        [-0.1459,  0.0756,  0.0485,  0.0836, -0.1281,  0.1926,  0.1410, -0.0765,\n          0.1589, -0.1235, -0.1969, -0.0570, -0.1642,  0.0887,  0.1618,  0.1387,\n         -0.0799,  0.1972, -0.1697, -0.0063],\n        [-0.0143, -0.0853,  0.0786, -0.0935, -0.0502,  0.0715, -0.0004, -0.1022,\n         -0.0957, -0.0846, -0.0135,  0.2178, -0.1950,  0.1326,  0.0590, -0.0532,\n         -0.2078, -0.0982, -0.0657,  0.0501],\n        [ 0.1886,  0.1358,  0.1752, -0.0197, -0.0511, -0.0238,  0.1033, -0.1690,\n          0.0306,  0.1896, -0.1013,  0.1537, -0.0404,  0.0851, -0.1905,  0.1490,\n          0.0127, -0.0785,  0.1339,  0.1723],\n        [-0.1820,  0.1193,  0.0165, -0.0325, -0.0828,  0.0256,  0.2150, -0.2217,\n          0.1266,  0.2074,  0.1753,  0.1033, -0.0719, -0.0570, -0.0935,  0.1900,\n         -0.0955, -0.0556, -0.0917,  0.0625],\n        [ 0.2032, -0.0141, -0.0490,  0.0346, -0.1584, -0.0118,  0.1326,  0.0612,\n         -0.1890,  0.1078, -0.1737,  0.1801,  0.1142,  0.0856,  0.0515, -0.1514,\n          0.0835,  0.0254,  0.0854, -0.1395],\n        [-0.0290, -0.1689, -0.1208, -0.1215,  0.1633, -0.0089,  0.0530,  0.1502,\n         -0.1788, -0.2097,  0.0318, -0.1125, -0.0078, -0.0254,  0.2207, -0.0758,\n          0.1139,  0.1071, -0.1417, -0.1106],\n        [ 0.0395,  0.1465,  0.1622, -0.0467,  0.1249,  0.0840,  0.0044, -0.1481,\n          0.1429, -0.0511,  0.0573,  0.0646,  0.0064,  0.0193, -0.0401, -0.1677,\n          0.1743, -0.0169, -0.0417,  0.0814],\n        [ 0.0486,  0.1170, -0.0451, -0.2174, -0.0816, -0.0474, -0.1614, -0.2174,\n          0.1824,  0.0134,  0.0127, -0.0067, -0.2125, -0.1663,  0.2163, -0.2002,\n         -0.0432, -0.1737, -0.0651, -0.1258],\n        [ 0.0699,  0.0961,  0.1212, -0.1069,  0.1806, -0.1310,  0.0746,  0.1942,\n         -0.0023, -0.1857, -0.2171, -0.0285,  0.1962,  0.1957, -0.1686, -0.1130,\n         -0.1990,  0.0672,  0.1515,  0.1085],\n        [ 0.1414,  0.1107,  0.0682, -0.2196, -0.1823,  0.1076, -0.1792,  0.1739,\n         -0.0335,  0.2074, -0.1088,  0.0954, -0.1547, -0.1311,  0.0642,  0.0154,\n          0.0334, -0.0198, -0.2217, -0.1501],\n        [-0.0250, -0.0422, -0.0478,  0.1004, -0.0652, -0.0592, -0.0871,  0.2141,\n         -0.1297, -0.1670, -0.1777, -0.0919,  0.1619, -0.0779,  0.1139, -0.0088,\n         -0.0610, -0.1011,  0.0890, -0.0126],\n        [ 0.1141,  0.0826,  0.1827, -0.2003,  0.0909, -0.1180,  0.0336, -0.0884,\n         -0.0291,  0.1520, -0.2074,  0.0164, -0.1647, -0.1009,  0.0448, -0.0729,\n         -0.0533,  0.1825,  0.1163, -0.1576],\n        [-0.0128,  0.1920,  0.1259, -0.0190,  0.0328, -0.0180, -0.2104,  0.1185,\n         -0.1496, -0.0856,  0.0150,  0.1472, -0.0857,  0.0678,  0.1374,  0.1329,\n         -0.0010, -0.0364, -0.0533, -0.0426],\n        [-0.1225,  0.0029,  0.0875, -0.1122, -0.0211, -0.1821, -0.0023,  0.0890,\n         -0.0210, -0.0210,  0.0917, -0.1505,  0.0446,  0.1616, -0.1481, -0.1663,\n          0.2186, -0.0442,  0.0759,  0.1887],\n        [-0.1395,  0.1529,  0.0788,  0.0073, -0.0267,  0.1349,  0.1543,  0.1259,\n          0.0063,  0.0265, -0.0850, -0.1017, -0.0042,  0.1972, -0.1502, -0.1931,\n          0.1695,  0.0441, -0.0423, -0.0601],\n        [ 0.2096, -0.0976, -0.0877,  0.0415,  0.0186,  0.1431,  0.1687,  0.0362,\n         -0.0085, -0.2035, -0.0130, -0.2159,  0.1117,  0.0300, -0.1525, -0.0911,\n          0.0509,  0.1488,  0.0164,  0.1551],\n        [-0.0892,  0.2079,  0.0468,  0.0344, -0.1164,  0.0160, -0.0519, -0.1756,\n          0.1264, -0.0517,  0.0195,  0.1746, -0.2204, -0.1847,  0.2031,  0.0851,\n          0.1026,  0.2081,  0.1263,  0.1789],\n        [ 0.1537,  0.0252,  0.1704,  0.0075,  0.1065, -0.0904, -0.1948, -0.0562,\n          0.0112,  0.1617,  0.0919, -0.1186,  0.0576,  0.1282, -0.0620, -0.1256,\n         -0.0437,  0.0122,  0.0528,  0.1435],\n        [ 0.1914, -0.0287, -0.1675,  0.0782,  0.1915,  0.0366, -0.0107,  0.0113,\n          0.1130, -0.1714, -0.0070,  0.1550, -0.2027,  0.0032,  0.0117,  0.1857,\n          0.0766,  0.0028,  0.1337,  0.0495],\n        [-0.1331,  0.1922, -0.1167,  0.0200, -0.1885,  0.1529, -0.0993, -0.1942,\n         -0.0164,  0.1521, -0.0109, -0.2187,  0.1974,  0.0705,  0.1772,  0.0178,\n         -0.0792,  0.2200, -0.1656,  0.1870],\n        [ 0.0082,  0.0548, -0.0918,  0.1653, -0.0567,  0.1877,  0.1040,  0.0264,\n          0.1894,  0.1160,  0.0999,  0.0736, -0.0533,  0.1705,  0.0992, -0.1611,\n         -0.1853, -0.0293, -0.1177,  0.1839]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0851, -0.0755,  0.1138,  0.0581,  0.0731, -0.1680,  0.0315,  0.0329,\n        -0.0484,  0.0298, -0.0317, -0.0497,  0.0810, -0.0237,  0.1502, -0.1492],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.2859e-02,  1.1921e-01,  3.8572e-03,  6.4153e-02,  5.4751e-02,\n          9.6097e-04,  8.0978e-02,  5.7086e-02,  1.1081e-02,  1.7660e-02,\n         -1.1400e-01, -4.2915e-02,  1.0533e-01, -1.7606e-02,  8.1835e-02,\n          8.4020e-02, -8.3239e-02, -1.1256e-01, -1.5361e-01, -8.6556e-02,\n         -1.7676e-01, -2.5423e-03, -3.7191e-02, -9.1493e-02, -9.8335e-02,\n         -8.3382e-02,  7.3858e-02,  4.6041e-02, -1.9117e-02, -1.3895e-01,\n         -8.0491e-02,  7.4818e-02],\n        [-7.7643e-02, -3.1321e-03, -5.7108e-02,  1.5393e-01, -4.8180e-02,\n          1.0087e-01, -8.4701e-02, -1.1988e-01, -1.4855e-01, -9.9589e-02,\n         -6.8804e-02,  1.2234e-02, -1.5850e-01, -5.3130e-02,  4.3792e-02,\n          6.7469e-02, -1.0596e-01,  7.4191e-02, -1.5350e-01,  1.0038e-01,\n         -1.3232e-01, -2.9365e-02,  9.5308e-02,  9.2827e-02, -1.0279e-01,\n         -6.6130e-02,  1.1277e-01,  1.2769e-01,  8.5930e-02,  8.5114e-02,\n          1.0455e-01,  1.2744e-01],\n        [-7.7084e-02,  1.3758e-01, -2.8349e-02, -8.6276e-02, -1.7240e-01,\n         -1.2896e-01, -1.3105e-01,  1.4513e-01,  7.1519e-02,  1.1685e-01,\n         -6.0011e-02,  7.0192e-02, -7.8323e-02, -1.5648e-02, -7.8204e-02,\n         -3.9489e-02, -5.5950e-02,  1.6700e-01, -4.6076e-02, -8.8140e-03,\n          7.1110e-02,  8.2898e-02,  8.4618e-03,  1.1373e-01, -1.4879e-01,\n         -5.1112e-02, -1.1180e-01, -4.5998e-02,  1.3732e-01,  1.1925e-01,\n          8.2666e-02,  5.3069e-02],\n        [ 6.7007e-02, -9.4158e-02,  3.3549e-02, -1.7376e-01, -1.3488e-01,\n          9.9702e-02,  6.4775e-02, -6.2758e-02, -5.1950e-02, -6.7405e-03,\n         -1.4409e-01,  7.6368e-02, -1.2315e-01, -1.5002e-01, -1.5280e-01,\n         -2.0062e-02,  8.0926e-02, -1.7662e-01,  4.7677e-02,  1.3803e-01,\n          1.4594e-01, -9.0678e-02,  1.1419e-01,  2.1535e-02, -1.1735e-01,\n         -1.0064e-01,  1.1745e-01, -7.0958e-02, -1.6087e-01, -5.7044e-02,\n         -7.8312e-02,  2.5214e-02],\n        [-1.8569e-02, -1.1151e-01,  3.8240e-02, -1.4078e-02,  4.4998e-02,\n          2.6435e-02, -4.8221e-02, -1.1843e-01, -1.6193e-01,  1.7704e-02,\n         -1.7550e-02,  5.0032e-02,  1.7149e-01,  5.8879e-02,  8.9796e-02,\n          1.5958e-01,  1.2443e-01,  1.6488e-01, -7.3287e-02,  1.9841e-02,\n          1.4097e-01,  1.6268e-01, -9.1275e-02,  1.2541e-01, -8.0278e-02,\n          4.3583e-02, -7.7334e-02,  1.1823e-03, -1.0837e-01, -5.8710e-02,\n         -1.2305e-01, -8.0071e-02],\n        [-9.4483e-02, -1.0087e-01,  1.1387e-02,  1.3820e-01, -1.2158e-01,\n          1.2672e-01,  9.4493e-02,  1.4915e-01,  6.9001e-02,  1.5306e-01,\n          8.9978e-02, -1.0244e-01, -1.6436e-01, -7.3642e-02, -7.4760e-02,\n         -4.1421e-03,  1.5334e-01,  9.7715e-02,  4.8489e-02,  1.2563e-01,\n          3.6225e-02,  3.7822e-03,  5.3996e-02, -1.2231e-01,  1.5269e-02,\n          9.6182e-02,  3.2940e-02, -1.2650e-01,  8.8629e-02, -1.3658e-02,\n          5.4749e-02, -6.4516e-02],\n        [-3.3758e-02, -6.7180e-02, -2.1314e-02,  1.3147e-01, -8.8537e-03,\n          1.7577e-01,  7.7026e-02,  1.7529e-01,  1.3751e-01,  1.2513e-01,\n          1.6347e-01,  5.6189e-02,  1.7607e-01, -8.2146e-02, -7.4141e-02,\n         -1.3991e-01,  1.4753e-01, -8.6284e-02,  1.1934e-01,  2.9778e-02,\n         -1.3051e-01,  9.7343e-02,  1.4789e-01, -1.5073e-01,  7.6575e-02,\n          4.9668e-02,  1.3845e-01,  1.5583e-01, -8.5254e-02, -2.5292e-02,\n          3.1707e-02, -4.0046e-02],\n        [ 1.1549e-01, -7.9369e-02,  1.0649e-01, -8.2113e-02,  5.5177e-02,\n         -1.4101e-02,  1.3527e-01,  7.6740e-02,  1.1855e-01, -8.0440e-02,\n          2.3849e-02, -4.9724e-02, -1.9682e-02,  1.6398e-01, -1.9721e-02,\n         -4.3547e-02,  1.7611e-01,  3.7803e-02,  1.3651e-01, -9.5693e-02,\n          1.3724e-01,  3.6176e-02, -5.9927e-02, -1.1040e-01,  1.6095e-02,\n         -9.3676e-02, -9.7637e-02,  6.5609e-02, -1.5444e-01, -1.1464e-01,\n          1.6995e-01, -1.6196e-01],\n        [-4.3503e-02,  1.4559e-01, -8.3278e-02, -1.2140e-01,  1.0712e-01,\n          1.1338e-01,  1.1984e-01,  2.1783e-02, -1.0573e-01,  6.7313e-03,\n          1.4803e-01,  2.2633e-03,  6.7545e-02,  9.1501e-02,  1.3987e-01,\n         -1.6467e-01,  5.2761e-02,  9.5119e-02, -3.8409e-02, -4.2598e-02,\n         -3.3481e-04, -1.9220e-02, -1.7249e-01, -2.6369e-02,  1.1568e-01,\n         -2.6051e-02, -8.2491e-02, -6.4370e-02, -1.3778e-01, -9.7047e-02,\n          6.8109e-02, -2.7193e-03],\n        [ 3.8175e-03, -9.4209e-02, -9.8212e-02,  8.7983e-02,  1.5371e-01,\n          8.8452e-02, -5.7600e-02, -7.1318e-02,  1.0173e-02,  1.2583e-01,\n          9.4381e-02,  2.9796e-02,  1.0597e-01,  9.8893e-02,  8.1822e-02,\n         -9.4992e-02, -1.2951e-01,  6.4387e-02,  4.9440e-02, -7.0131e-02,\n         -4.7382e-02, -1.2923e-01,  5.5325e-02,  1.0118e-01,  5.7358e-02,\n         -1.2159e-01,  8.3495e-02, -1.2550e-01, -1.5565e-01, -5.3382e-02,\n         -1.2860e-01,  6.1441e-02],\n        [ 7.6576e-02, -7.5552e-02, -9.6878e-02,  3.7807e-02, -8.1728e-02,\n          8.6466e-02, -1.1777e-02, -5.5456e-02,  8.7915e-02, -2.8338e-02,\n         -1.6414e-01, -8.4893e-02,  5.1933e-02,  2.4141e-02, -1.3894e-01,\n         -7.0814e-02, -3.7619e-02, -8.1392e-02, -7.6035e-02, -1.6523e-01,\n          1.6458e-01, -1.1134e-02, -5.2497e-02, -1.4079e-01, -1.5306e-02,\n         -4.0508e-02,  1.1286e-01,  1.1889e-01, -7.2959e-02,  7.0282e-02,\n         -7.2763e-02, -1.3066e-01],\n        [-1.1886e-01, -1.6163e-01,  1.7899e-02,  3.1227e-03,  5.1545e-02,\n          1.4797e-01, -1.5937e-01, -1.6118e-01,  8.2355e-02,  1.1408e-01,\n          1.7099e-01, -1.6430e-01,  3.6435e-02, -1.7427e-01,  1.2857e-01,\n          1.1040e-01, -7.4028e-02,  6.6530e-02,  1.5758e-01,  1.6973e-01,\n         -1.0463e-01,  7.5718e-02,  1.1831e-01,  1.7594e-01,  9.2086e-02,\n         -1.4602e-01, -1.1736e-01, -3.5259e-02, -1.6436e-01,  3.4527e-02,\n         -4.7474e-02,  1.5561e-01],\n        [-1.0244e-01,  2.5071e-02,  3.0895e-02, -7.1731e-02,  1.2314e-01,\n         -2.3964e-02, -1.6479e-01,  1.7155e-01, -2.5403e-02,  1.1698e-01,\n          6.3256e-02, -1.6514e-01,  3.1281e-02, -1.3283e-01, -7.2257e-02,\n          1.2816e-01,  1.0751e-01,  6.9783e-02, -1.3308e-01,  5.2577e-02,\n          7.8576e-02,  3.5578e-02,  1.3042e-01, -1.1663e-01,  1.5207e-01,\n         -3.1542e-02,  5.0660e-02, -5.4789e-03,  1.2376e-01,  5.6704e-02,\n         -7.2378e-02, -1.4420e-01],\n        [ 1.2952e-01,  1.5883e-01, -1.7612e-01, -9.1358e-02, -6.3334e-02,\n         -7.0004e-02, -4.0973e-02, -1.7424e-01, -1.6795e-03,  1.3601e-01,\n          5.6114e-02,  1.5468e-01, -1.7113e-01,  4.2665e-03, -1.0546e-02,\n         -1.3671e-01, -5.2714e-02, -1.6731e-01,  8.8532e-03,  1.7405e-01,\n         -5.5554e-02,  5.9727e-02,  2.4320e-02,  2.5757e-02,  9.1804e-04,\n         -1.5852e-01,  9.5928e-02,  1.6751e-01, -6.4088e-02, -8.7883e-02,\n          1.1030e-01, -3.9972e-03],\n        [ 1.6456e-01,  1.2983e-01, -6.6895e-02,  6.8754e-02,  1.3341e-02,\n         -7.9812e-02, -2.7101e-02, -7.8932e-02,  3.7150e-02,  8.0816e-02,\n         -6.5545e-02,  9.2533e-02,  1.6625e-01, -1.6673e-01, -4.0514e-03,\n          1.6819e-01,  9.5779e-02, -9.2910e-03, -5.9982e-02, -5.0426e-02,\n          6.5944e-02,  6.8858e-03,  1.6970e-02, -1.6018e-01, -6.5717e-02,\n          1.2968e-01, -4.1499e-02,  5.5040e-02, -3.7243e-02,  5.2267e-02,\n          1.4432e-01,  1.1483e-01],\n        [ 1.7656e-01, -1.3234e-01,  8.1834e-02, -8.4223e-02,  1.5014e-01,\n         -2.6680e-02, -6.7179e-02,  1.5881e-01, -3.6292e-02,  1.2307e-02,\n         -1.0815e-01,  1.6180e-01, -1.3773e-01, -7.5385e-02, -1.0385e-01,\n          9.0261e-02,  9.4438e-02,  3.6630e-02,  1.2990e-01, -6.4420e-02,\n         -3.1282e-02, -9.2851e-03,  3.7953e-05,  9.5238e-02,  1.1187e-01,\n          5.4129e-02,  3.2236e-02,  4.9357e-02,  4.2094e-02, -6.3207e-02,\n         -1.4933e-01,  5.2072e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1580, -0.1593,  0.0832, -0.0256,  0.1033,  0.1413,  0.1778,  0.0794],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0016, -0.0612, -0.1863, -0.1320,  0.2469, -0.0403, -0.2040, -0.2424,\n          0.2319, -0.2344, -0.2398,  0.1856, -0.1609,  0.2126, -0.2103,  0.2364],\n        [-0.2298, -0.0482,  0.0171,  0.1905, -0.2333,  0.2275, -0.2212, -0.2424,\n         -0.0460,  0.1008, -0.0785, -0.0187,  0.1103, -0.1611,  0.2260,  0.1219],\n        [ 0.1154,  0.1401,  0.1653, -0.0279,  0.2038, -0.1719, -0.2267,  0.0114,\n         -0.2419,  0.1732,  0.0715,  0.1533,  0.0749,  0.1042,  0.0487, -0.1067],\n        [-0.1896,  0.2315, -0.0017, -0.1709, -0.2124, -0.0233,  0.0303,  0.2161,\n         -0.0047,  0.1425, -0.0142, -0.0811, -0.1171,  0.0145, -0.1019,  0.2086],\n        [ 0.1400, -0.0484, -0.0276, -0.0245, -0.0018, -0.0400, -0.1460,  0.2313,\n         -0.1438,  0.1839,  0.2125, -0.2045, -0.0970,  0.1537,  0.1286,  0.1893],\n        [-0.1568, -0.1069, -0.0728, -0.0553, -0.0717,  0.1317, -0.0663, -0.2381,\n         -0.1510, -0.1094, -0.0007, -0.0915,  0.0641, -0.2210,  0.1956, -0.1237],\n        [ 0.2108,  0.1571, -0.1035,  0.1731, -0.0331,  0.0784,  0.0880, -0.1097,\n          0.0372, -0.1389, -0.2233,  0.1354,  0.1755,  0.1333,  0.2463, -0.1314],\n        [-0.1898,  0.2066,  0.1082,  0.2038,  0.0215, -0.0550, -0.1279, -0.2001,\n          0.1257, -0.2313,  0.1706, -0.1813, -0.2458, -0.0991, -0.0481, -0.1294]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.3100,  0.1486,  0.2498, -0.2198], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-2.2393e-04,  2.5861e-01,  1.7013e-01, -1.6823e-01, -1.5857e-01,\n         -2.8300e-02,  1.1526e-01,  3.3199e-01],\n        [-1.8060e-01, -3.1386e-01, -1.9641e-01, -2.3061e-01,  2.3386e-01,\n          2.1732e-03, -2.2225e-01,  2.4447e-01],\n        [-3.3215e-01, -1.6435e-01, -1.6371e-01,  6.1348e-03,  3.0580e-01,\n          4.1365e-02, -7.4291e-02, -5.2089e-02],\n        [ 2.2564e-01, -7.2344e-02,  1.6733e-01,  5.4999e-02,  2.4824e-01,\n         -1.1927e-01,  1.8644e-01,  2.2471e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7867e338edd0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s215220000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s215220000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}