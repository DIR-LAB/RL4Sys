{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s235320000"
    },
    "q_lr":	0.0005,
    "seed":	235320000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000002D40979E680>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1413,  0.1742,  0.1147,  0.0334, -0.1410, -0.1892, -0.1349, -0.0785,\n        -0.0482,  0.1439, -0.2029, -0.1850, -0.0446, -0.1347,  0.1393, -0.0311,\n        -0.0612, -0.2014,  0.0183, -0.0008, -0.1966, -0.1936,  0.1621,  0.0355,\n        -0.0497, -0.2130, -0.1877, -0.1020,  0.2175, -0.2109, -0.0100, -0.0505],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0902, -0.0486, -0.1350, -0.0266, -0.1299, -0.0423, -0.0778, -0.1131,\n         -0.0731, -0.1535,  0.0266,  0.1394, -0.1092, -0.2118,  0.0846, -0.2234,\n          0.0813,  0.2079,  0.2099,  0.2037],\n        [ 0.2125,  0.0258,  0.0641, -0.0194, -0.2083,  0.1270, -0.2222, -0.1412,\n         -0.1138, -0.2153,  0.1321, -0.2164,  0.1641, -0.0937, -0.0820,  0.0680,\n          0.1371,  0.0642, -0.1738,  0.0754],\n        [-0.0791,  0.0201,  0.0743,  0.0355, -0.0660,  0.2073,  0.2142,  0.1446,\n          0.1942,  0.1039,  0.0064, -0.0706, -0.0903, -0.0708,  0.0075, -0.1888,\n          0.0292,  0.0053,  0.1861, -0.1952],\n        [-0.1972,  0.0252, -0.1322,  0.1866,  0.0471,  0.0825, -0.1497, -0.1252,\n         -0.1046, -0.0600,  0.1657, -0.1034,  0.0444, -0.0978, -0.0740, -0.1306,\n          0.0251, -0.1037,  0.0142, -0.1574],\n        [-0.1205,  0.0924, -0.0113, -0.1937, -0.2162, -0.0842, -0.1823, -0.0308,\n         -0.1318,  0.1104,  0.1757, -0.0594, -0.1488,  0.1585,  0.2036,  0.0873,\n         -0.1608,  0.1672, -0.1084,  0.2161],\n        [-0.1444, -0.1568,  0.0220,  0.1470,  0.1612, -0.1467, -0.0754, -0.1152,\n          0.0649, -0.0801,  0.0761, -0.0518, -0.0579, -0.1568,  0.0982, -0.2231,\n         -0.0114,  0.1229,  0.0530,  0.2069],\n        [ 0.1804, -0.2062, -0.2168,  0.1624,  0.0074,  0.0473,  0.0361, -0.1866,\n         -0.0709, -0.2228, -0.1152,  0.0657, -0.0772,  0.1362, -0.1613, -0.1751,\n         -0.1323, -0.2175,  0.0410, -0.0169],\n        [-0.1076, -0.0167,  0.1727, -0.1379,  0.0190, -0.1132, -0.0771, -0.0925,\n          0.1539, -0.0918,  0.0833,  0.0722, -0.1263,  0.0965,  0.1400,  0.0502,\n         -0.0284, -0.1129, -0.0635,  0.0916],\n        [-0.1007, -0.1116,  0.2203,  0.1308,  0.1268, -0.2050,  0.0110, -0.1153,\n         -0.1529,  0.1989,  0.0888,  0.1254,  0.1585,  0.0690,  0.1265, -0.0157,\n         -0.0963,  0.0642,  0.1980,  0.2060],\n        [ 0.0185,  0.0756,  0.0853,  0.0718, -0.0159,  0.0174, -0.1537,  0.0313,\n          0.0165,  0.0835,  0.0667,  0.0821,  0.1002, -0.0681,  0.2041, -0.0474,\n          0.2170,  0.1712,  0.0834, -0.0989],\n        [ 0.0768, -0.0678,  0.1166, -0.0389,  0.1438,  0.0475,  0.0856,  0.0794,\n         -0.1909, -0.1478, -0.0895, -0.0118,  0.0208, -0.1591, -0.1052,  0.1975,\n         -0.1602, -0.2020,  0.1786, -0.2160],\n        [ 0.0538,  0.2144, -0.0180, -0.0211,  0.1437,  0.1283, -0.0258,  0.2087,\n         -0.1038,  0.1482, -0.1139, -0.1342,  0.0615, -0.2002, -0.1601,  0.1701,\n         -0.1184, -0.1963,  0.1740, -0.0487],\n        [ 0.2125,  0.0467,  0.0435,  0.0468,  0.2221,  0.0154,  0.1047, -0.1891,\n         -0.0511,  0.0231,  0.1609,  0.0769, -0.1080,  0.0273, -0.1009,  0.2007,\n         -0.2235,  0.1716,  0.1125, -0.2088],\n        [ 0.1651,  0.1968, -0.0192, -0.1396,  0.2025,  0.1290,  0.0928, -0.1881,\n          0.0569, -0.0592, -0.2194,  0.1286,  0.1880,  0.1014,  0.2132, -0.0459,\n          0.0649,  0.1834,  0.1746,  0.1745],\n        [ 0.1525,  0.0324,  0.2081, -0.0674, -0.1628, -0.1193, -0.0777, -0.1569,\n          0.1581, -0.2023, -0.1545,  0.1069,  0.1505,  0.0550,  0.0911, -0.0485,\n          0.0091,  0.1803,  0.1839, -0.0239],\n        [-0.1421,  0.1353, -0.2232, -0.2199,  0.0313,  0.1503,  0.0564,  0.0473,\n          0.0416, -0.0474, -0.0540, -0.0692, -0.1450, -0.1901, -0.1841, -0.0872,\n         -0.0634,  0.1632,  0.0678, -0.1877],\n        [ 0.1418,  0.1528,  0.2087, -0.0411, -0.0063,  0.1121, -0.1162, -0.1631,\n         -0.1172,  0.2207, -0.0718,  0.1563,  0.0969, -0.1183, -0.1489,  0.1704,\n          0.1804,  0.0015,  0.1654,  0.1691],\n        [ 0.0894,  0.1913, -0.0948, -0.0449, -0.0981,  0.1053,  0.1951,  0.1037,\n          0.0616,  0.0130,  0.1984, -0.1150,  0.1719,  0.1661,  0.1362,  0.1578,\n         -0.2002,  0.0267,  0.1219,  0.1747],\n        [-0.1697, -0.1961, -0.1617, -0.0461, -0.0199,  0.1005, -0.1553, -0.0397,\n          0.0421,  0.0335, -0.1654,  0.1447, -0.1678, -0.0121, -0.0240, -0.2047,\n          0.1749, -0.2168,  0.2134, -0.0843],\n        [-0.1150,  0.1581, -0.0386, -0.1949,  0.1254,  0.1700, -0.1988, -0.1953,\n         -0.1109, -0.0899,  0.1236,  0.2063, -0.0416,  0.0090,  0.1713, -0.0764,\n         -0.1755, -0.1415, -0.1570,  0.0062],\n        [ 0.0436, -0.0704, -0.1882,  0.1458,  0.2080,  0.1042,  0.0041, -0.2143,\n          0.0425, -0.0182, -0.1084,  0.0719, -0.1391,  0.0398, -0.0971,  0.0135,\n         -0.0144,  0.0174,  0.1976, -0.1506],\n        [-0.0518,  0.2020, -0.1569,  0.1877, -0.0384, -0.0002, -0.1548, -0.0773,\n         -0.0832,  0.0919, -0.1577, -0.1872,  0.1836, -0.1539,  0.0018,  0.1034,\n         -0.2018,  0.1061,  0.0500,  0.1725],\n        [-0.0439,  0.1930,  0.1270, -0.2052, -0.1546,  0.1804, -0.0471,  0.0031,\n         -0.0722, -0.0192, -0.1608, -0.1950, -0.1371, -0.1509, -0.1958, -0.0639,\n          0.0981, -0.0243,  0.0182,  0.0080],\n        [ 0.2028,  0.1803, -0.1697, -0.2006,  0.0247,  0.0058,  0.0195, -0.0313,\n         -0.0875,  0.0644,  0.0723, -0.0628,  0.1413, -0.1091, -0.1548,  0.2155,\n         -0.0677, -0.1816,  0.0723,  0.0234],\n        [ 0.0676, -0.0940,  0.2044, -0.0295,  0.0781,  0.0403, -0.1446, -0.1799,\n          0.0518,  0.1051, -0.1089,  0.0051,  0.1181, -0.0029, -0.1712,  0.1274,\n         -0.0228,  0.0480, -0.1740, -0.1660],\n        [ 0.0669, -0.1339,  0.0999,  0.1519,  0.0433,  0.2053, -0.1578, -0.1295,\n         -0.0087, -0.0040, -0.2014, -0.1479, -0.0031, -0.1132, -0.1499,  0.0950,\n          0.1733, -0.0699, -0.0603,  0.0202],\n        [-0.2032, -0.2096,  0.1810, -0.1272,  0.1819, -0.1366, -0.0842,  0.1927,\n          0.0598, -0.0940,  0.1363,  0.0907,  0.1965, -0.1709,  0.1898, -0.0547,\n         -0.0972, -0.1367, -0.0550,  0.0073],\n        [-0.0266,  0.1454, -0.1725, -0.1462,  0.0111, -0.0180, -0.1110, -0.0435,\n          0.2218,  0.1084,  0.0756, -0.1404,  0.0773, -0.0910,  0.1430,  0.0510,\n         -0.1216, -0.0630, -0.1522, -0.0759],\n        [ 0.0885, -0.1392, -0.1996, -0.1661, -0.2199, -0.0956, -0.0442,  0.2214,\n         -0.0029,  0.0648, -0.1846, -0.1843,  0.1648, -0.0066, -0.0836, -0.0168,\n         -0.1369,  0.2129,  0.1238,  0.2063],\n        [-0.1984,  0.1200, -0.0461,  0.1035,  0.1419, -0.1826,  0.1409, -0.0246,\n          0.1089,  0.1385,  0.0182, -0.1732,  0.0735, -0.0882,  0.1067,  0.0885,\n         -0.2032,  0.0690, -0.2096, -0.1822],\n        [ 0.1342, -0.0969,  0.0852, -0.1034,  0.0558,  0.1863, -0.2127, -0.0649,\n          0.0489,  0.2195, -0.0969, -0.2158,  0.1340,  0.1854, -0.2073,  0.0168,\n         -0.0291,  0.0325,  0.1166,  0.1387],\n        [ 0.0769,  0.1593,  0.1685, -0.0857, -0.0928, -0.0795, -0.1773,  0.2027,\n         -0.2018,  0.0067,  0.1034, -0.0541, -0.0783,  0.0219, -0.1361, -0.0635,\n          0.1204,  0.0014,  0.1020, -0.0770]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1385, -0.1513, -0.0263, -0.1268, -0.0476,  0.0761, -0.0861, -0.1118,\n        -0.1421,  0.1032,  0.0639, -0.1667, -0.0231, -0.1697, -0.1373, -0.0698],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 5.4638e-02,  6.3949e-02,  6.4241e-02, -1.3696e-01, -2.2197e-02,\n         -9.6711e-02, -4.0891e-02, -5.2645e-02,  1.4141e-05, -5.2115e-02,\n          6.9969e-02, -7.5965e-02,  1.7239e-01,  1.0876e-01,  3.2245e-02,\n         -1.5819e-01, -1.7272e-01,  7.1275e-02,  9.9547e-02, -9.3792e-03,\n          8.5302e-02, -2.2716e-02, -9.8268e-02, -1.4171e-01, -1.1153e-01,\n         -1.1399e-02,  1.1601e-01,  1.5414e-01,  6.6606e-02,  9.6497e-02,\n          1.6832e-01, -1.3788e-01],\n        [ 1.1816e-01,  1.0747e-01, -7.6065e-02, -5.4861e-03,  9.0573e-02,\n         -2.4101e-03, -1.6789e-01, -5.3464e-02,  1.2900e-01, -3.9650e-02,\n         -1.5675e-01, -1.0369e-01,  3.3885e-02,  1.0558e-01,  1.2145e-01,\n         -1.4339e-01,  4.0074e-02, -9.4084e-02, -1.4640e-01, -2.4820e-02,\n          3.5628e-02,  5.4698e-02,  6.5533e-02,  6.9132e-02,  4.2012e-02,\n          1.4187e-01,  4.4080e-02,  1.3061e-01,  6.8665e-02,  1.1915e-02,\n         -1.7459e-01, -7.0312e-02],\n        [-9.8170e-02, -1.0219e-01,  1.3316e-01, -1.3677e-01, -4.8524e-04,\n         -4.1026e-02, -1.7275e-01, -1.7273e-01,  1.1433e-03, -2.6835e-02,\n         -1.3265e-01, -8.3564e-02, -4.4524e-02, -9.3723e-02, -1.4098e-01,\n          8.9776e-02,  2.8029e-02, -1.0385e-01,  2.0106e-02, -3.9289e-02,\n         -1.3029e-01,  2.4055e-02, -1.5745e-01, -1.2082e-01, -1.1775e-01,\n          7.5032e-02,  7.5523e-02, -2.5653e-02,  5.2043e-03,  7.6981e-02,\n          2.3243e-02,  1.9385e-02],\n        [-1.0876e-01,  1.6260e-01, -1.5269e-02,  7.4170e-03, -4.9508e-02,\n          1.3059e-01, -6.8296e-02, -4.5558e-02, -1.5733e-01, -5.0452e-02,\n          5.0428e-02,  1.1388e-01, -2.7487e-02, -5.2980e-02,  6.0657e-02,\n         -7.8470e-02, -3.1315e-02, -1.7568e-02,  2.8913e-02,  1.3769e-01,\n          8.2331e-02, -1.5288e-01,  3.1502e-02,  1.4621e-01,  1.4384e-01,\n          1.2621e-01, -1.5442e-01,  6.8203e-02,  3.7109e-02,  9.5967e-02,\n         -7.9172e-02, -1.2753e-01],\n        [-5.9342e-03,  6.7834e-02, -4.5658e-02, -2.9171e-02, -1.5702e-01,\n         -2.2283e-02,  1.6461e-01, -1.6299e-01,  1.3709e-01,  5.3422e-02,\n         -8.9439e-02, -1.7351e-01,  1.7259e-01, -1.7113e-01, -1.3758e-01,\n         -1.5900e-01,  3.9276e-02,  1.8999e-02, -1.3574e-01,  5.0259e-02,\n          9.5762e-02, -6.8307e-03, -1.3176e-01, -9.4011e-02, -2.8884e-02,\n          1.3945e-01,  1.1154e-01, -3.4535e-03, -1.6055e-01, -1.2660e-01,\n          1.1655e-01, -1.1837e-01],\n        [-3.4239e-02,  1.4903e-01,  1.3277e-01,  1.6186e-01,  7.7421e-02,\n          1.0894e-01, -8.8397e-02, -1.0167e-01,  4.5244e-03, -8.4095e-02,\n         -1.6491e-01, -3.5648e-02, -1.5716e-01,  3.1773e-02, -6.8983e-02,\n          1.4968e-01, -1.5565e-01,  8.4371e-02, -9.4505e-02,  1.1156e-01,\n         -1.2614e-01,  1.6294e-01,  1.7451e-02, -1.6513e-01, -6.7597e-02,\n         -5.8846e-02, -1.3355e-01,  5.6960e-02,  9.2888e-02, -1.5316e-01,\n          1.0549e-01, -7.5796e-02],\n        [ 5.9896e-02,  1.6761e-01, -1.7309e-01, -1.0981e-01,  1.3757e-02,\n          9.9940e-02,  1.4639e-01,  1.3226e-01, -1.0699e-01, -1.1334e-02,\n         -6.8005e-02, -1.4425e-01, -5.7655e-02, -7.9197e-02, -6.2209e-02,\n         -1.1382e-01, -1.2752e-02,  1.5602e-01,  1.5900e-01, -1.4310e-01,\n         -2.0098e-02, -8.9866e-02, -1.3680e-01, -1.1027e-02, -3.3220e-03,\n          8.6925e-02,  1.0174e-01,  1.3598e-01, -6.8485e-02, -6.4829e-02,\n         -1.0508e-01, -3.6641e-03],\n        [-1.7276e-01,  1.6464e-01,  1.4985e-01,  1.2903e-01, -8.9099e-02,\n          5.9171e-02, -1.7675e-01,  4.1310e-02, -1.4255e-01,  1.3737e-01,\n          1.7766e-02,  1.3127e-01,  1.5765e-01,  2.9102e-02,  1.9563e-02,\n         -8.4043e-03, -1.1038e-01, -4.4313e-02, -9.7842e-02,  1.6627e-02,\n          3.9952e-03,  7.8399e-02,  7.4207e-02, -5.2336e-02,  2.2920e-02,\n         -1.1506e-01,  1.3985e-01, -1.4999e-02, -1.4903e-01, -1.1470e-01,\n         -1.5175e-01,  7.2461e-02],\n        [-1.9064e-03, -1.6506e-01, -2.7907e-02,  3.9166e-02, -1.1720e-01,\n          1.5582e-01, -1.1119e-01, -1.7316e-01, -1.3275e-01,  6.4468e-02,\n         -2.6438e-02,  6.4625e-03,  8.4715e-03,  1.1885e-01, -6.7646e-02,\n         -4.6281e-03,  3.0823e-02, -1.0958e-01, -1.4031e-02,  4.2636e-02,\n         -1.3208e-01, -6.6910e-02, -1.2141e-01, -1.2435e-01, -1.0812e-01,\n         -7.3395e-02, -9.9931e-02,  1.7415e-01, -1.3782e-01,  1.6167e-01,\n         -1.1616e-01,  4.2144e-02],\n        [-1.2092e-01, -1.6465e-01, -1.4326e-01, -1.4627e-01,  8.9377e-02,\n         -2.7138e-02,  4.8335e-02,  1.7071e-01,  1.4740e-01,  2.3248e-02,\n          1.1604e-01, -7.7977e-02,  2.0133e-02,  6.7335e-04, -2.3033e-02,\n         -4.7164e-02, -1.6763e-01, -7.1856e-02,  6.2523e-02,  6.2392e-02,\n          1.1564e-01, -8.9419e-02, -4.2449e-02,  3.3049e-02,  1.0135e-01,\n          7.4337e-02,  1.0187e-01,  6.3829e-02, -1.0420e-01,  7.2560e-02,\n          1.1276e-01,  2.4505e-02],\n        [ 1.2063e-01,  1.6422e-01,  8.6775e-02,  1.7246e-01,  1.7185e-01,\n         -5.3309e-02,  1.0252e-01,  1.5702e-01, -1.2273e-01,  3.9926e-02,\n         -4.4637e-02, -5.7944e-03,  1.0655e-01, -1.3664e-01, -1.4723e-01,\n         -2.7487e-02,  1.7568e-01, -4.1736e-02, -6.0219e-02, -4.5871e-02,\n         -1.6573e-01,  1.2707e-01, -1.6955e-02, -1.2497e-01, -1.1684e-01,\n         -1.6787e-01, -1.4602e-01, -1.3645e-01,  1.4081e-01, -9.4077e-02,\n         -1.1575e-01,  3.4256e-02],\n        [ 7.9073e-02, -1.0574e-01,  5.1043e-02, -6.1796e-03,  8.6458e-03,\n         -3.8602e-02,  1.0159e-01,  3.5839e-03, -8.2642e-02,  1.0361e-01,\n          7.9105e-02,  6.0024e-02,  1.2390e-01,  1.4759e-01,  8.0349e-02,\n          3.1297e-02,  1.3806e-01, -8.2062e-03,  9.2380e-02,  6.7008e-02,\n         -6.2116e-02, -6.5809e-03,  7.8476e-02,  1.1848e-01, -9.9903e-02,\n          1.7641e-02, -9.2672e-02,  9.5163e-02,  1.4260e-01, -1.3121e-01,\n          1.3989e-02, -7.8672e-02],\n        [-7.7385e-02,  9.0041e-03,  1.2311e-01, -4.2071e-02, -1.6527e-01,\n         -4.9498e-02,  6.1383e-02,  1.0233e-01,  1.3262e-01,  5.3820e-02,\n          3.6578e-02,  1.3394e-01, -8.2747e-02,  7.7896e-03, -1.7229e-01,\n         -1.7390e-01, -8.6607e-02,  1.0503e-01,  1.7076e-01,  1.1603e-01,\n         -3.5697e-02,  1.7433e-01,  8.4334e-02, -3.1697e-02,  1.1356e-01,\n          8.8739e-02,  2.2511e-02, -1.0065e-01, -1.6994e-01,  1.1528e-01,\n          2.3292e-04, -2.9484e-02],\n        [-5.1965e-03, -1.0472e-02,  1.4997e-01,  1.5845e-01,  5.1303e-02,\n         -8.1929e-02,  1.5214e-01,  1.1238e-01, -1.0590e-01,  1.3256e-01,\n          3.8276e-02,  1.6532e-01,  1.4050e-01, -1.7598e-01, -1.4307e-02,\n         -7.0413e-02, -1.3050e-01, -6.9459e-02,  3.9201e-02,  5.2944e-02,\n          2.1585e-02, -1.4568e-01,  1.7284e-03,  1.5818e-01,  6.3396e-02,\n         -2.3487e-02,  1.0469e-01, -2.9555e-02,  7.6674e-02,  3.9894e-02,\n         -8.1754e-02,  5.1770e-02],\n        [-1.9808e-02, -1.3461e-01, -1.0900e-01, -6.4340e-02,  1.3205e-01,\n          2.0925e-02,  1.2281e-01,  7.1450e-02,  1.3877e-02,  2.6999e-03,\n          1.2825e-01, -1.2428e-01, -1.1926e-01,  5.6702e-02,  1.6591e-01,\n          4.3938e-02,  6.0845e-02, -1.7528e-01,  1.4145e-02, -1.0810e-01,\n         -1.4777e-01,  9.6211e-02,  8.0861e-02,  2.2661e-02,  1.2969e-01,\n         -1.0402e-01, -8.3750e-02,  1.3159e-01,  1.4207e-01,  7.2943e-02,\n          1.3558e-01, -4.0855e-02],\n        [-1.4278e-01, -1.3231e-01,  3.5719e-02, -1.7634e-01,  1.0913e-01,\n          6.8357e-02, -9.5313e-02, -4.0753e-02,  8.6825e-02, -2.4036e-02,\n         -1.1735e-01,  6.2413e-02, -1.4735e-01,  1.3811e-01,  7.4090e-02,\n          6.5553e-02,  9.9630e-02,  2.9354e-02,  7.4836e-02, -6.7891e-02,\n         -1.7279e-01, -1.4855e-01,  2.0071e-02, -1.5268e-01, -1.6370e-02,\n         -1.1310e-01,  4.6900e-02, -4.8450e-02, -5.4731e-02,  7.9076e-02,\n          1.0721e-02, -5.6019e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1058, -0.1444, -0.0931, -0.2330, -0.0928,  0.0334,  0.0836,  0.1276],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0183,  0.2488,  0.0474, -0.2075, -0.2021, -0.2449,  0.0689, -0.0223,\n         -0.1736,  0.0265,  0.1869,  0.1847,  0.1182, -0.1520, -0.1860,  0.0890],\n        [-0.1363,  0.0994, -0.0450,  0.0186, -0.1127,  0.0352, -0.1768,  0.1059,\n          0.2328,  0.0938, -0.0517, -0.1344, -0.2427, -0.0734,  0.2292, -0.0482],\n        [ 0.0036,  0.1553,  0.1337, -0.1452,  0.1375, -0.2285, -0.2342,  0.1285,\n          0.1996, -0.1012,  0.1935,  0.1642,  0.0639,  0.1391, -0.2367, -0.0304],\n        [-0.0917, -0.1889,  0.0766,  0.2402,  0.0625, -0.1677, -0.0526, -0.1659,\n         -0.1428, -0.1395,  0.0967,  0.1145, -0.1014, -0.0407, -0.1564,  0.0061],\n        [-0.0434, -0.1417, -0.1873,  0.1333,  0.0175,  0.2462,  0.1513, -0.0392,\n          0.1330, -0.2212, -0.1355, -0.0699, -0.2235, -0.0731,  0.1132,  0.1435],\n        [ 0.1903,  0.1126, -0.0231,  0.2342, -0.1593,  0.0099,  0.1665,  0.2419,\n          0.0772, -0.1595,  0.0615, -0.0579,  0.0604,  0.0470, -0.1875,  0.0766],\n        [-0.1888,  0.0247, -0.1834,  0.2316, -0.0586,  0.2437,  0.0957, -0.0380,\n          0.2221, -0.1694, -0.1290, -0.1468, -0.0391, -0.0046,  0.1017, -0.1263],\n        [-0.0192,  0.0734, -0.1209, -0.2088, -0.1881, -0.2489,  0.0665, -0.2308,\n          0.1922, -0.2252,  0.0396, -0.1402, -0.0856,  0.1424, -0.1039,  0.0975]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3409], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1572,  0.1573,  0.1145, -0.1772,  0.3499, -0.1336, -0.2285, -0.1872]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0902, -0.0486, -0.1350, -0.0266, -0.1299, -0.0423, -0.0778, -0.1131,\n         -0.0731, -0.1535,  0.0266,  0.1394, -0.1092, -0.2118,  0.0846, -0.2234,\n          0.0813,  0.2079,  0.2099,  0.2037],\n        [ 0.2125,  0.0258,  0.0641, -0.0194, -0.2083,  0.1270, -0.2222, -0.1412,\n         -0.1138, -0.2153,  0.1321, -0.2164,  0.1641, -0.0937, -0.0820,  0.0680,\n          0.1371,  0.0642, -0.1738,  0.0754],\n        [-0.0791,  0.0201,  0.0743,  0.0355, -0.0660,  0.2073,  0.2142,  0.1446,\n          0.1942,  0.1039,  0.0064, -0.0706, -0.0903, -0.0708,  0.0075, -0.1888,\n          0.0292,  0.0053,  0.1861, -0.1952],\n        [-0.1972,  0.0252, -0.1322,  0.1866,  0.0471,  0.0825, -0.1497, -0.1252,\n         -0.1046, -0.0600,  0.1657, -0.1034,  0.0444, -0.0978, -0.0740, -0.1306,\n          0.0251, -0.1037,  0.0142, -0.1574],\n        [-0.1205,  0.0924, -0.0113, -0.1937, -0.2162, -0.0842, -0.1823, -0.0308,\n         -0.1318,  0.1104,  0.1757, -0.0594, -0.1488,  0.1585,  0.2036,  0.0873,\n         -0.1608,  0.1672, -0.1084,  0.2161],\n        [-0.1444, -0.1568,  0.0220,  0.1470,  0.1612, -0.1467, -0.0754, -0.1152,\n          0.0649, -0.0801,  0.0761, -0.0518, -0.0579, -0.1568,  0.0982, -0.2231,\n         -0.0114,  0.1229,  0.0530,  0.2069],\n        [ 0.1804, -0.2062, -0.2168,  0.1624,  0.0074,  0.0473,  0.0361, -0.1866,\n         -0.0709, -0.2228, -0.1152,  0.0657, -0.0772,  0.1362, -0.1613, -0.1751,\n         -0.1323, -0.2175,  0.0410, -0.0169],\n        [-0.1076, -0.0167,  0.1727, -0.1379,  0.0190, -0.1132, -0.0771, -0.0925,\n          0.1539, -0.0918,  0.0833,  0.0722, -0.1263,  0.0965,  0.1400,  0.0502,\n         -0.0284, -0.1129, -0.0635,  0.0916],\n        [-0.1007, -0.1116,  0.2203,  0.1308,  0.1268, -0.2050,  0.0110, -0.1153,\n         -0.1529,  0.1989,  0.0888,  0.1254,  0.1585,  0.0690,  0.1265, -0.0157,\n         -0.0963,  0.0642,  0.1980,  0.2060],\n        [ 0.0185,  0.0756,  0.0853,  0.0718, -0.0159,  0.0174, -0.1537,  0.0313,\n          0.0165,  0.0835,  0.0667,  0.0821,  0.1002, -0.0681,  0.2041, -0.0474,\n          0.2170,  0.1712,  0.0834, -0.0989],\n        [ 0.0768, -0.0678,  0.1166, -0.0389,  0.1438,  0.0475,  0.0856,  0.0794,\n         -0.1909, -0.1478, -0.0895, -0.0118,  0.0208, -0.1591, -0.1052,  0.1975,\n         -0.1602, -0.2020,  0.1786, -0.2160],\n        [ 0.0538,  0.2144, -0.0180, -0.0211,  0.1437,  0.1283, -0.0258,  0.2087,\n         -0.1038,  0.1482, -0.1139, -0.1342,  0.0615, -0.2002, -0.1601,  0.1701,\n         -0.1184, -0.1963,  0.1740, -0.0487],\n        [ 0.2125,  0.0467,  0.0435,  0.0468,  0.2221,  0.0154,  0.1047, -0.1891,\n         -0.0511,  0.0231,  0.1609,  0.0769, -0.1080,  0.0273, -0.1009,  0.2007,\n         -0.2235,  0.1716,  0.1125, -0.2088],\n        [ 0.1651,  0.1968, -0.0192, -0.1396,  0.2025,  0.1290,  0.0928, -0.1881,\n          0.0569, -0.0592, -0.2194,  0.1286,  0.1880,  0.1014,  0.2132, -0.0459,\n          0.0649,  0.1834,  0.1746,  0.1745],\n        [ 0.1525,  0.0324,  0.2081, -0.0674, -0.1628, -0.1193, -0.0777, -0.1569,\n          0.1581, -0.2023, -0.1545,  0.1069,  0.1505,  0.0550,  0.0911, -0.0485,\n          0.0091,  0.1803,  0.1839, -0.0239],\n        [-0.1421,  0.1353, -0.2232, -0.2199,  0.0313,  0.1503,  0.0564,  0.0473,\n          0.0416, -0.0474, -0.0540, -0.0692, -0.1450, -0.1901, -0.1841, -0.0872,\n         -0.0634,  0.1632,  0.0678, -0.1877],\n        [ 0.1418,  0.1528,  0.2087, -0.0411, -0.0063,  0.1121, -0.1162, -0.1631,\n         -0.1172,  0.2207, -0.0718,  0.1563,  0.0969, -0.1183, -0.1489,  0.1704,\n          0.1804,  0.0015,  0.1654,  0.1691],\n        [ 0.0894,  0.1913, -0.0948, -0.0449, -0.0981,  0.1053,  0.1951,  0.1037,\n          0.0616,  0.0130,  0.1984, -0.1150,  0.1719,  0.1661,  0.1362,  0.1578,\n         -0.2002,  0.0267,  0.1219,  0.1747],\n        [-0.1697, -0.1961, -0.1617, -0.0461, -0.0199,  0.1005, -0.1553, -0.0397,\n          0.0421,  0.0335, -0.1654,  0.1447, -0.1678, -0.0121, -0.0240, -0.2047,\n          0.1749, -0.2168,  0.2134, -0.0843],\n        [-0.1150,  0.1581, -0.0386, -0.1949,  0.1254,  0.1700, -0.1988, -0.1953,\n         -0.1109, -0.0899,  0.1236,  0.2063, -0.0416,  0.0090,  0.1713, -0.0764,\n         -0.1755, -0.1415, -0.1570,  0.0062],\n        [ 0.0436, -0.0704, -0.1882,  0.1458,  0.2080,  0.1042,  0.0041, -0.2143,\n          0.0425, -0.0182, -0.1084,  0.0719, -0.1391,  0.0398, -0.0971,  0.0135,\n         -0.0144,  0.0174,  0.1976, -0.1506],\n        [-0.0518,  0.2020, -0.1569,  0.1877, -0.0384, -0.0002, -0.1548, -0.0773,\n         -0.0832,  0.0919, -0.1577, -0.1872,  0.1836, -0.1539,  0.0018,  0.1034,\n         -0.2018,  0.1061,  0.0500,  0.1725],\n        [-0.0439,  0.1930,  0.1270, -0.2052, -0.1546,  0.1804, -0.0471,  0.0031,\n         -0.0722, -0.0192, -0.1608, -0.1950, -0.1371, -0.1509, -0.1958, -0.0639,\n          0.0981, -0.0243,  0.0182,  0.0080],\n        [ 0.2028,  0.1803, -0.1697, -0.2006,  0.0247,  0.0058,  0.0195, -0.0313,\n         -0.0875,  0.0644,  0.0723, -0.0628,  0.1413, -0.1091, -0.1548,  0.2155,\n         -0.0677, -0.1816,  0.0723,  0.0234],\n        [ 0.0676, -0.0940,  0.2044, -0.0295,  0.0781,  0.0403, -0.1446, -0.1799,\n          0.0518,  0.1051, -0.1089,  0.0051,  0.1181, -0.0029, -0.1712,  0.1274,\n         -0.0228,  0.0480, -0.1740, -0.1660],\n        [ 0.0669, -0.1339,  0.0999,  0.1519,  0.0433,  0.2053, -0.1578, -0.1295,\n         -0.0087, -0.0040, -0.2014, -0.1479, -0.0031, -0.1132, -0.1499,  0.0950,\n          0.1733, -0.0699, -0.0603,  0.0202],\n        [-0.2032, -0.2096,  0.1810, -0.1272,  0.1819, -0.1366, -0.0842,  0.1927,\n          0.0598, -0.0940,  0.1363,  0.0907,  0.1965, -0.1709,  0.1898, -0.0547,\n         -0.0972, -0.1367, -0.0550,  0.0073],\n        [-0.0266,  0.1454, -0.1725, -0.1462,  0.0111, -0.0180, -0.1110, -0.0435,\n          0.2218,  0.1084,  0.0756, -0.1404,  0.0773, -0.0910,  0.1430,  0.0510,\n         -0.1216, -0.0630, -0.1522, -0.0759],\n        [ 0.0885, -0.1392, -0.1996, -0.1661, -0.2199, -0.0956, -0.0442,  0.2214,\n         -0.0029,  0.0648, -0.1846, -0.1843,  0.1648, -0.0066, -0.0836, -0.0168,\n         -0.1369,  0.2129,  0.1238,  0.2063],\n        [-0.1984,  0.1200, -0.0461,  0.1035,  0.1419, -0.1826,  0.1409, -0.0246,\n          0.1089,  0.1385,  0.0182, -0.1732,  0.0735, -0.0882,  0.1067,  0.0885,\n         -0.2032,  0.0690, -0.2096, -0.1822],\n        [ 0.1342, -0.0969,  0.0852, -0.1034,  0.0558,  0.1863, -0.2127, -0.0649,\n          0.0489,  0.2195, -0.0969, -0.2158,  0.1340,  0.1854, -0.2073,  0.0168,\n         -0.0291,  0.0325,  0.1166,  0.1387],\n        [ 0.0769,  0.1593,  0.1685, -0.0857, -0.0928, -0.0795, -0.1773,  0.2027,\n         -0.2018,  0.0067,  0.1034, -0.0541, -0.0783,  0.0219, -0.1361, -0.0635,\n          0.1204,  0.0014,  0.1020, -0.0770]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1413,  0.1742,  0.1147,  0.0334, -0.1410, -0.1892, -0.1349, -0.0785,\n        -0.0482,  0.1439, -0.2029, -0.1850, -0.0446, -0.1347,  0.1393, -0.0311,\n        -0.0612, -0.2014,  0.0183, -0.0008, -0.1966, -0.1936,  0.1621,  0.0355,\n        -0.0497, -0.2130, -0.1877, -0.1020,  0.2175, -0.2109, -0.0100, -0.0505],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 5.4638e-02,  6.3949e-02,  6.4241e-02, -1.3696e-01, -2.2197e-02,\n         -9.6711e-02, -4.0891e-02, -5.2645e-02,  1.4141e-05, -5.2115e-02,\n          6.9969e-02, -7.5965e-02,  1.7239e-01,  1.0876e-01,  3.2245e-02,\n         -1.5819e-01, -1.7272e-01,  7.1275e-02,  9.9547e-02, -9.3792e-03,\n          8.5302e-02, -2.2716e-02, -9.8268e-02, -1.4171e-01, -1.1153e-01,\n         -1.1399e-02,  1.1601e-01,  1.5414e-01,  6.6606e-02,  9.6497e-02,\n          1.6832e-01, -1.3788e-01],\n        [ 1.1816e-01,  1.0747e-01, -7.6065e-02, -5.4861e-03,  9.0573e-02,\n         -2.4101e-03, -1.6789e-01, -5.3464e-02,  1.2900e-01, -3.9650e-02,\n         -1.5675e-01, -1.0369e-01,  3.3885e-02,  1.0558e-01,  1.2145e-01,\n         -1.4339e-01,  4.0074e-02, -9.4084e-02, -1.4640e-01, -2.4820e-02,\n          3.5628e-02,  5.4698e-02,  6.5533e-02,  6.9132e-02,  4.2012e-02,\n          1.4187e-01,  4.4080e-02,  1.3061e-01,  6.8665e-02,  1.1915e-02,\n         -1.7459e-01, -7.0312e-02],\n        [-9.8170e-02, -1.0219e-01,  1.3316e-01, -1.3677e-01, -4.8524e-04,\n         -4.1026e-02, -1.7275e-01, -1.7273e-01,  1.1433e-03, -2.6835e-02,\n         -1.3265e-01, -8.3564e-02, -4.4524e-02, -9.3723e-02, -1.4098e-01,\n          8.9776e-02,  2.8029e-02, -1.0385e-01,  2.0106e-02, -3.9289e-02,\n         -1.3029e-01,  2.4055e-02, -1.5745e-01, -1.2082e-01, -1.1775e-01,\n          7.5032e-02,  7.5523e-02, -2.5653e-02,  5.2043e-03,  7.6981e-02,\n          2.3243e-02,  1.9385e-02],\n        [-1.0876e-01,  1.6260e-01, -1.5269e-02,  7.4170e-03, -4.9508e-02,\n          1.3059e-01, -6.8296e-02, -4.5558e-02, -1.5733e-01, -5.0452e-02,\n          5.0428e-02,  1.1388e-01, -2.7487e-02, -5.2980e-02,  6.0657e-02,\n         -7.8470e-02, -3.1315e-02, -1.7568e-02,  2.8913e-02,  1.3769e-01,\n          8.2331e-02, -1.5288e-01,  3.1502e-02,  1.4621e-01,  1.4384e-01,\n          1.2621e-01, -1.5442e-01,  6.8203e-02,  3.7109e-02,  9.5967e-02,\n         -7.9172e-02, -1.2753e-01],\n        [-5.9342e-03,  6.7834e-02, -4.5658e-02, -2.9171e-02, -1.5702e-01,\n         -2.2283e-02,  1.6461e-01, -1.6299e-01,  1.3709e-01,  5.3422e-02,\n         -8.9439e-02, -1.7351e-01,  1.7259e-01, -1.7113e-01, -1.3758e-01,\n         -1.5900e-01,  3.9276e-02,  1.8999e-02, -1.3574e-01,  5.0259e-02,\n          9.5762e-02, -6.8307e-03, -1.3176e-01, -9.4011e-02, -2.8884e-02,\n          1.3945e-01,  1.1154e-01, -3.4535e-03, -1.6055e-01, -1.2660e-01,\n          1.1655e-01, -1.1837e-01],\n        [-3.4239e-02,  1.4903e-01,  1.3277e-01,  1.6186e-01,  7.7421e-02,\n          1.0894e-01, -8.8397e-02, -1.0167e-01,  4.5244e-03, -8.4095e-02,\n         -1.6491e-01, -3.5648e-02, -1.5716e-01,  3.1773e-02, -6.8983e-02,\n          1.4968e-01, -1.5565e-01,  8.4371e-02, -9.4505e-02,  1.1156e-01,\n         -1.2614e-01,  1.6294e-01,  1.7451e-02, -1.6513e-01, -6.7597e-02,\n         -5.8846e-02, -1.3355e-01,  5.6960e-02,  9.2888e-02, -1.5316e-01,\n          1.0549e-01, -7.5796e-02],\n        [ 5.9896e-02,  1.6761e-01, -1.7309e-01, -1.0981e-01,  1.3757e-02,\n          9.9940e-02,  1.4639e-01,  1.3226e-01, -1.0699e-01, -1.1334e-02,\n         -6.8005e-02, -1.4425e-01, -5.7655e-02, -7.9197e-02, -6.2209e-02,\n         -1.1382e-01, -1.2752e-02,  1.5602e-01,  1.5900e-01, -1.4310e-01,\n         -2.0098e-02, -8.9866e-02, -1.3680e-01, -1.1027e-02, -3.3220e-03,\n          8.6925e-02,  1.0174e-01,  1.3598e-01, -6.8485e-02, -6.4829e-02,\n         -1.0508e-01, -3.6641e-03],\n        [-1.7276e-01,  1.6464e-01,  1.4985e-01,  1.2903e-01, -8.9099e-02,\n          5.9171e-02, -1.7675e-01,  4.1310e-02, -1.4255e-01,  1.3737e-01,\n          1.7766e-02,  1.3127e-01,  1.5765e-01,  2.9102e-02,  1.9563e-02,\n         -8.4043e-03, -1.1038e-01, -4.4313e-02, -9.7842e-02,  1.6627e-02,\n          3.9952e-03,  7.8399e-02,  7.4207e-02, -5.2336e-02,  2.2920e-02,\n         -1.1506e-01,  1.3985e-01, -1.4999e-02, -1.4903e-01, -1.1470e-01,\n         -1.5175e-01,  7.2461e-02],\n        [-1.9064e-03, -1.6506e-01, -2.7907e-02,  3.9166e-02, -1.1720e-01,\n          1.5582e-01, -1.1119e-01, -1.7316e-01, -1.3275e-01,  6.4468e-02,\n         -2.6438e-02,  6.4625e-03,  8.4715e-03,  1.1885e-01, -6.7646e-02,\n         -4.6281e-03,  3.0823e-02, -1.0958e-01, -1.4031e-02,  4.2636e-02,\n         -1.3208e-01, -6.6910e-02, -1.2141e-01, -1.2435e-01, -1.0812e-01,\n         -7.3395e-02, -9.9931e-02,  1.7415e-01, -1.3782e-01,  1.6167e-01,\n         -1.1616e-01,  4.2144e-02],\n        [-1.2092e-01, -1.6465e-01, -1.4326e-01, -1.4627e-01,  8.9377e-02,\n         -2.7138e-02,  4.8335e-02,  1.7071e-01,  1.4740e-01,  2.3248e-02,\n          1.1604e-01, -7.7977e-02,  2.0133e-02,  6.7335e-04, -2.3033e-02,\n         -4.7164e-02, -1.6763e-01, -7.1856e-02,  6.2523e-02,  6.2392e-02,\n          1.1564e-01, -8.9419e-02, -4.2449e-02,  3.3049e-02,  1.0135e-01,\n          7.4337e-02,  1.0187e-01,  6.3829e-02, -1.0420e-01,  7.2560e-02,\n          1.1276e-01,  2.4505e-02],\n        [ 1.2063e-01,  1.6422e-01,  8.6775e-02,  1.7246e-01,  1.7185e-01,\n         -5.3309e-02,  1.0252e-01,  1.5702e-01, -1.2273e-01,  3.9926e-02,\n         -4.4637e-02, -5.7944e-03,  1.0655e-01, -1.3664e-01, -1.4723e-01,\n         -2.7487e-02,  1.7568e-01, -4.1736e-02, -6.0219e-02, -4.5871e-02,\n         -1.6573e-01,  1.2707e-01, -1.6955e-02, -1.2497e-01, -1.1684e-01,\n         -1.6787e-01, -1.4602e-01, -1.3645e-01,  1.4081e-01, -9.4077e-02,\n         -1.1575e-01,  3.4256e-02],\n        [ 7.9073e-02, -1.0574e-01,  5.1043e-02, -6.1796e-03,  8.6458e-03,\n         -3.8602e-02,  1.0159e-01,  3.5839e-03, -8.2642e-02,  1.0361e-01,\n          7.9105e-02,  6.0024e-02,  1.2390e-01,  1.4759e-01,  8.0349e-02,\n          3.1297e-02,  1.3806e-01, -8.2062e-03,  9.2380e-02,  6.7008e-02,\n         -6.2116e-02, -6.5809e-03,  7.8476e-02,  1.1848e-01, -9.9903e-02,\n          1.7641e-02, -9.2672e-02,  9.5163e-02,  1.4260e-01, -1.3121e-01,\n          1.3989e-02, -7.8672e-02],\n        [-7.7385e-02,  9.0041e-03,  1.2311e-01, -4.2071e-02, -1.6527e-01,\n         -4.9498e-02,  6.1383e-02,  1.0233e-01,  1.3262e-01,  5.3820e-02,\n          3.6578e-02,  1.3394e-01, -8.2747e-02,  7.7896e-03, -1.7229e-01,\n         -1.7390e-01, -8.6607e-02,  1.0503e-01,  1.7076e-01,  1.1603e-01,\n         -3.5697e-02,  1.7433e-01,  8.4334e-02, -3.1697e-02,  1.1356e-01,\n          8.8739e-02,  2.2511e-02, -1.0065e-01, -1.6994e-01,  1.1528e-01,\n          2.3292e-04, -2.9484e-02],\n        [-5.1965e-03, -1.0472e-02,  1.4997e-01,  1.5845e-01,  5.1303e-02,\n         -8.1929e-02,  1.5214e-01,  1.1238e-01, -1.0590e-01,  1.3256e-01,\n          3.8276e-02,  1.6532e-01,  1.4050e-01, -1.7598e-01, -1.4307e-02,\n         -7.0413e-02, -1.3050e-01, -6.9459e-02,  3.9201e-02,  5.2944e-02,\n          2.1585e-02, -1.4568e-01,  1.7284e-03,  1.5818e-01,  6.3396e-02,\n         -2.3487e-02,  1.0469e-01, -2.9555e-02,  7.6674e-02,  3.9894e-02,\n         -8.1754e-02,  5.1770e-02],\n        [-1.9808e-02, -1.3461e-01, -1.0900e-01, -6.4340e-02,  1.3205e-01,\n          2.0925e-02,  1.2281e-01,  7.1450e-02,  1.3877e-02,  2.6999e-03,\n          1.2825e-01, -1.2428e-01, -1.1926e-01,  5.6702e-02,  1.6591e-01,\n          4.3938e-02,  6.0845e-02, -1.7528e-01,  1.4145e-02, -1.0810e-01,\n         -1.4777e-01,  9.6211e-02,  8.0861e-02,  2.2661e-02,  1.2969e-01,\n         -1.0402e-01, -8.3750e-02,  1.3159e-01,  1.4207e-01,  7.2943e-02,\n          1.3558e-01, -4.0855e-02],\n        [-1.4278e-01, -1.3231e-01,  3.5719e-02, -1.7634e-01,  1.0913e-01,\n          6.8357e-02, -9.5313e-02, -4.0753e-02,  8.6825e-02, -2.4036e-02,\n         -1.1735e-01,  6.2413e-02, -1.4735e-01,  1.3811e-01,  7.4090e-02,\n          6.5553e-02,  9.9630e-02,  2.9354e-02,  7.4836e-02, -6.7891e-02,\n         -1.7279e-01, -1.4855e-01,  2.0071e-02, -1.5268e-01, -1.6370e-02,\n         -1.1310e-01,  4.6900e-02, -4.8450e-02, -5.4731e-02,  7.9076e-02,\n          1.0721e-02, -5.6019e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1385, -0.1513, -0.0263, -0.1268, -0.0476,  0.0761, -0.0861, -0.1118,\n        -0.1421,  0.1032,  0.0639, -0.1667, -0.0231, -0.1697, -0.1373, -0.0698],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0183,  0.2488,  0.0474, -0.2075, -0.2021, -0.2449,  0.0689, -0.0223,\n         -0.1736,  0.0265,  0.1869,  0.1847,  0.1182, -0.1520, -0.1860,  0.0890],\n        [-0.1363,  0.0994, -0.0450,  0.0186, -0.1127,  0.0352, -0.1768,  0.1059,\n          0.2328,  0.0938, -0.0517, -0.1344, -0.2427, -0.0734,  0.2292, -0.0482],\n        [ 0.0036,  0.1553,  0.1337, -0.1452,  0.1375, -0.2285, -0.2342,  0.1285,\n          0.1996, -0.1012,  0.1935,  0.1642,  0.0639,  0.1391, -0.2367, -0.0304],\n        [-0.0917, -0.1889,  0.0766,  0.2402,  0.0625, -0.1677, -0.0526, -0.1659,\n         -0.1428, -0.1395,  0.0967,  0.1145, -0.1014, -0.0407, -0.1564,  0.0061],\n        [-0.0434, -0.1417, -0.1873,  0.1333,  0.0175,  0.2462,  0.1513, -0.0392,\n          0.1330, -0.2212, -0.1355, -0.0699, -0.2235, -0.0731,  0.1132,  0.1435],\n        [ 0.1903,  0.1126, -0.0231,  0.2342, -0.1593,  0.0099,  0.1665,  0.2419,\n          0.0772, -0.1595,  0.0615, -0.0579,  0.0604,  0.0470, -0.1875,  0.0766],\n        [-0.1888,  0.0247, -0.1834,  0.2316, -0.0586,  0.2437,  0.0957, -0.0380,\n          0.2221, -0.1694, -0.1290, -0.1468, -0.0391, -0.0046,  0.1017, -0.1263],\n        [-0.0192,  0.0734, -0.1209, -0.2088, -0.1881, -0.2489,  0.0665, -0.2308,\n          0.1922, -0.2252,  0.0396, -0.1402, -0.0856,  0.1424, -0.1039,  0.0975]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1058, -0.1444, -0.0931, -0.2330, -0.0928,  0.0334,  0.0836,  0.1276],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1572,  0.1573,  0.1145, -0.1772,  0.3499, -0.1336, -0.2285, -0.1872]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3409], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000002D45518B820>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000002D40979E860>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s235320000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='D:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\maze-game\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s235320000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}