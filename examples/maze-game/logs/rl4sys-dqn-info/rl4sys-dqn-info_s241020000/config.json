{
    "__class__":	"DQN",
    "act_dim":	4,
    "batch_size":	64,
    "buf_size":	50000,
    "env_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s241020000"
    },
    "q_lr":	0.0005,
    "seed":	241020000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x72f33d4fe3d0>":	{
            "_act_dim":	4,
            "_batch_size":	64,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0995, -0.0785, -0.1416,  0.2108, -0.0792,  0.0246, -0.1093, -0.1601,\n         0.1010, -0.0142, -0.0526,  0.0672, -0.1674, -0.1951,  0.0146,  0.1055,\n        -0.0645, -0.0650, -0.2098,  0.1636,  0.1378,  0.0576, -0.1296,  0.1677,\n        -0.0813,  0.0426, -0.0952, -0.1165,  0.1483, -0.1343,  0.1961,  0.0972],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.1993e-01, -8.8234e-02,  1.1128e-01,  1.0747e-01,  1.2864e-01,\n         -1.0074e-01,  5.3200e-02, -1.0896e-01, -1.8218e-01,  2.0007e-01,\n         -7.3606e-03, -1.7787e-01,  2.0185e-01,  5.2292e-02,  9.9689e-02,\n         -1.9498e-01, -7.7226e-03,  1.5117e-01,  1.5985e-01,  3.2287e-02],\n        [-1.4749e-01,  1.1229e-01,  6.3380e-02, -1.7170e-02,  1.3644e-01,\n         -1.8374e-01, -3.4621e-03,  7.0836e-02,  1.3587e-01, -1.4180e-02,\n          6.7965e-02, -5.2278e-02, -1.8630e-01, -1.5673e-01, -1.7176e-02,\n          1.4383e-01,  1.5274e-01, -1.6595e-01, -1.8796e-01,  3.1060e-02],\n        [ 1.2632e-01, -2.1456e-01,  1.6767e-01,  7.4965e-02,  1.8029e-01,\n          1.7473e-01, -1.4769e-01,  1.3158e-01,  1.4551e-01, -1.2391e-01,\n          1.8607e-01,  8.1237e-02, -9.6408e-03, -4.7709e-02, -1.1424e-01,\n         -5.8748e-03, -2.2115e-01, -8.3643e-02, -1.7818e-01,  1.2915e-03],\n        [-1.9345e-01, -3.3960e-02, -1.9738e-01,  1.2581e-01, -2.1589e-01,\n          1.5270e-01, -1.5988e-01,  9.1050e-02, -5.7222e-02, -1.2581e-02,\n          1.8389e-01, -1.3766e-01,  1.7191e-01,  1.6751e-01,  2.1282e-01,\n          3.8442e-02, -9.8888e-02,  3.4820e-03,  4.2894e-02, -4.5914e-03],\n        [ 2.1885e-02, -1.7509e-01, -8.1003e-02,  1.2787e-01,  9.1319e-02,\n          9.1801e-02,  5.2611e-02,  2.0145e-01, -7.7061e-02, -2.0980e-01,\n          9.0108e-02, -5.0754e-02, -3.5515e-02,  1.8898e-01, -1.5473e-01,\n         -4.6537e-02,  1.5527e-02,  8.8141e-02, -2.0792e-01, -1.9545e-01],\n        [ 1.2598e-01, -1.6569e-02,  8.7808e-02, -8.6066e-02,  9.8604e-02,\n         -2.3091e-02, -1.6922e-01, -1.8930e-01, -1.4808e-01,  5.4208e-02,\n         -2.1994e-01,  5.8335e-02,  1.3425e-01, -4.0035e-02,  8.0769e-03,\n          1.8881e-01,  1.1063e-01,  1.4277e-01, -1.3688e-01,  1.4284e-02],\n        [-3.2281e-02, -1.8342e-01, -1.2934e-01, -9.4546e-02, -4.3286e-02,\n         -6.4919e-03, -1.9737e-01, -1.9364e-01,  1.1598e-01, -5.2047e-02,\n         -8.6892e-02, -3.6011e-02, -5.8002e-02, -1.8864e-01, -9.9736e-02,\n         -7.3601e-02, -5.6031e-02, -1.7487e-01,  6.3063e-02, -6.1674e-02],\n        [ 2.1510e-01, -8.5460e-02, -1.2970e-01, -1.0252e-01, -1.2529e-01,\n         -2.9532e-02, -6.8944e-03,  2.1145e-02,  1.2219e-01,  1.4599e-01,\n          1.7180e-01, -6.4600e-02, -8.5297e-02, -1.9447e-01,  2.3763e-02,\n         -1.9291e-01,  1.9739e-01,  6.1796e-02,  1.1648e-01,  1.5808e-01],\n        [ 5.4164e-02,  1.9451e-01,  2.0490e-01, -1.6699e-01,  6.3488e-02,\n          1.1014e-01, -9.9973e-02, -4.3624e-02,  1.1161e-01, -9.8094e-03,\n          8.4827e-03,  6.3478e-03, -1.6374e-01, -7.5830e-02,  2.0821e-02,\n          1.3896e-02,  1.5119e-01, -5.8450e-02,  2.2029e-01, -1.9600e-01],\n        [ 5.3560e-02, -1.4210e-01,  1.6878e-01,  1.6266e-01, -1.5623e-01,\n          6.4024e-02, -7.5193e-02,  2.2284e-01, -3.6656e-02, -2.5662e-02,\n         -1.3180e-01, -2.0770e-01, -1.0344e-01,  7.9712e-02, -1.8026e-01,\n          5.2642e-02,  8.9600e-02, -1.6123e-01,  7.7915e-02,  1.0637e-03],\n        [-9.3021e-02,  1.8713e-01,  9.2491e-02,  8.7595e-02,  2.2288e-01,\n          1.1925e-01, -7.4096e-02,  1.3203e-01, -8.0318e-02,  7.6359e-02,\n          2.9985e-03,  4.2011e-02,  9.3677e-02,  8.6032e-02, -1.7641e-01,\n         -1.6303e-01,  1.9287e-01, -9.5224e-02,  2.1303e-01, -1.5049e-01],\n        [ 1.5211e-01,  8.1820e-02, -1.9044e-01, -2.5288e-02,  2.1002e-02,\n         -1.8061e-01,  7.2280e-03,  1.4296e-01,  3.5093e-02,  5.9460e-02,\n          1.8658e-01,  2.0601e-01, -8.0826e-02,  1.6034e-01, -1.4413e-01,\n          1.2664e-01, -7.2624e-04, -1.0083e-01, -5.2173e-02,  1.5878e-02],\n        [-2.0459e-01, -1.7443e-01,  1.7544e-01,  4.5316e-03,  1.1836e-01,\n          1.7052e-01, -1.5132e-01, -1.3301e-01, -4.0769e-02,  1.5753e-01,\n          2.0955e-01,  2.0917e-01,  2.2301e-01,  1.3835e-02, -2.0238e-01,\n          3.0960e-02,  1.1387e-01, -1.0151e-02, -1.1172e-01, -1.7439e-01],\n        [ 1.9742e-01,  2.0861e-01,  1.4665e-01, -1.5504e-01, -1.7778e-01,\n          7.2440e-02,  8.3944e-02, -2.9962e-02,  1.6021e-01,  1.6932e-01,\n         -1.5962e-01, -3.3659e-03, -1.7275e-01, -1.4316e-01,  4.1693e-02,\n          9.0567e-03, -1.8304e-01,  1.9008e-01,  2.9668e-02,  1.4303e-01],\n        [ 1.0308e-01, -1.6448e-02,  2.9841e-02, -8.7223e-02,  6.6674e-02,\n         -5.0289e-02, -7.9058e-02, -2.0368e-01, -6.9804e-02, -2.1530e-01,\n          1.8548e-01, -1.6089e-01,  6.9361e-02,  2.2690e-02, -1.9418e-01,\n          1.9356e-01, -1.0465e-01,  1.0827e-01, -7.2138e-03,  1.8421e-01],\n        [-1.6364e-01,  1.4833e-01,  1.1895e-01, -1.7658e-01,  8.6889e-02,\n         -1.8667e-01,  2.2250e-01,  1.7844e-01, -4.2091e-02, -2.0383e-01,\n          1.4231e-01, -4.9721e-02,  3.0569e-02,  1.6901e-01, -1.2439e-01,\n          1.6473e-01,  5.1675e-02, -1.6904e-01, -3.5615e-02,  2.0813e-01],\n        [-4.6426e-02, -1.8024e-01, -2.0550e-01, -5.3540e-02, -2.5467e-02,\n          1.5305e-01,  2.0331e-01,  3.9045e-02, -1.6163e-01, -2.1010e-01,\n          1.0680e-01,  3.8766e-02,  1.0619e-01, -2.2339e-01, -1.0401e-02,\n          1.5355e-01, -6.5925e-02,  1.6204e-01,  1.2156e-01, -1.9164e-02],\n        [ 1.8636e-01,  8.9125e-02,  4.8287e-02, -8.7991e-02, -3.8781e-02,\n         -1.4977e-01,  1.1924e-01, -1.2144e-01, -5.6870e-03,  9.0425e-02,\n         -9.4499e-02, -5.3536e-02,  5.5489e-02,  9.3851e-02,  1.1293e-01,\n         -5.8702e-02, -9.5570e-03, -7.6004e-02,  3.0407e-02,  1.1361e-01],\n        [ 1.0703e-01,  1.0029e-01,  1.3339e-01,  6.7769e-02, -1.0613e-01,\n         -2.0181e-01,  2.0784e-01, -1.7654e-01,  1.4664e-01,  1.7179e-01,\n          1.3617e-01, -6.6027e-02,  1.5493e-01,  1.8768e-01, -1.3900e-01,\n          2.0269e-01,  6.9126e-02, -1.3411e-01,  6.0388e-02, -1.3917e-01],\n        [-4.6755e-02, -6.3305e-02, -8.3607e-02,  8.0267e-03,  1.2010e-01,\n          7.7179e-02,  2.2097e-01,  8.0627e-02, -3.8160e-03,  1.7009e-01,\n         -2.9532e-02,  6.2546e-02,  8.1093e-02, -3.3952e-02,  1.9562e-01,\n         -2.1248e-01, -1.3009e-01, -2.0588e-01,  2.0014e-01,  1.3829e-01],\n        [ 5.7863e-02,  4.6991e-02, -1.6064e-01,  2.1432e-01, -6.6241e-02,\n          4.4030e-02,  2.0120e-01, -2.0901e-01,  1.2128e-01,  2.1085e-01,\n         -2.7367e-02,  2.0653e-01, -9.9392e-02,  1.5478e-01, -1.3866e-01,\n          5.5883e-02, -1.4174e-01,  2.0273e-01,  4.5102e-02, -1.0856e-01],\n        [-1.7846e-02,  1.3275e-01, -1.9626e-01, -9.7213e-02, -1.9343e-01,\n         -1.7281e-01, -1.5129e-01,  4.7200e-02, -2.8423e-02, -8.5516e-02,\n          5.2144e-02, -2.0046e-01, -4.8274e-02, -1.3391e-01,  9.6046e-02,\n          5.9757e-04, -1.2882e-01,  7.3840e-02, -1.0574e-01,  1.9032e-01],\n        [ 1.2195e-01, -1.5032e-01,  8.5836e-02,  1.7940e-01, -1.5365e-01,\n          1.8894e-01,  1.8644e-01,  2.1980e-01, -1.0209e-01, -2.0283e-01,\n         -9.1773e-03, -1.6389e-01,  5.5227e-03, -1.9217e-01,  1.2033e-01,\n         -1.1649e-01, -3.5884e-02, -3.6730e-02, -2.0770e-01, -1.9844e-01],\n        [-2.0165e-01,  1.7005e-01, -5.5276e-02, -1.1517e-01, -2.0069e-01,\n         -1.5128e-01,  1.4626e-02,  8.7222e-02, -1.6347e-02,  6.8472e-02,\n         -1.9177e-01, -1.2502e-01,  1.7840e-02, -2.0628e-01, -3.5065e-02,\n          1.1833e-02, -2.1518e-01, -8.9706e-02, -1.2071e-02, -8.6714e-02],\n        [ 1.2164e-01, -1.4384e-01, -1.7554e-01,  1.8451e-01, -8.6255e-02,\n         -9.2796e-02,  2.1408e-01, -9.4756e-02,  2.0398e-02, -2.1870e-01,\n          1.1640e-01,  6.9887e-02,  1.7373e-01,  1.7059e-01, -2.1022e-01,\n          4.0650e-03, -1.9176e-01,  2.0144e-01, -1.0388e-01, -1.7030e-01],\n        [-2.1180e-01,  8.1775e-02, -1.9645e-01, -1.8034e-01, -1.6916e-01,\n          1.4649e-01, -4.8180e-02,  3.6722e-03,  1.8273e-01, -2.2259e-01,\n         -4.4780e-03, -6.9629e-02, -1.3994e-01, -1.9382e-04, -1.2512e-02,\n         -6.5493e-03,  9.5429e-02, -5.8270e-02,  7.8508e-02, -8.3293e-02],\n        [ 1.3451e-01, -2.0262e-01,  6.7591e-02,  2.0960e-01, -7.1056e-02,\n          3.4600e-02, -1.6023e-01, -7.3901e-02,  2.3979e-02,  2.1667e-02,\n          7.4635e-02,  7.6001e-02, -4.9564e-02,  1.3186e-01, -1.2204e-01,\n         -3.2597e-02, -1.9040e-01,  2.1201e-01,  2.1343e-01, -1.8689e-01],\n        [-1.4906e-02, -1.6695e-01, -1.7110e-01,  1.0054e-01,  1.0295e-01,\n         -2.0893e-01, -2.1235e-01,  1.9196e-01, -1.6640e-01,  3.4764e-02,\n         -6.3516e-02, -9.2022e-02, -1.2754e-01,  1.9788e-01, -8.9677e-03,\n         -1.3978e-01, -1.6071e-01,  1.5898e-01,  1.1712e-01, -5.7505e-02],\n        [-1.4006e-01, -2.1850e-01, -1.1356e-01,  1.7783e-01,  1.7964e-01,\n          8.5496e-02,  4.7134e-02, -1.9866e-01,  1.2721e-01,  2.1858e-01,\n          5.6745e-02,  6.9458e-02, -6.2252e-02, -1.4877e-01,  2.0532e-01,\n          6.1604e-02,  1.9991e-01, -1.5867e-01,  1.1642e-01, -1.6792e-01],\n        [-5.5797e-02,  9.9706e-02, -8.2178e-02,  1.6551e-02,  1.7367e-01,\n          4.2584e-02,  1.5292e-01,  2.0134e-02, -6.6672e-02,  1.8509e-01,\n         -1.3609e-01,  2.0644e-01,  8.3380e-02, -1.7076e-01, -2.0675e-01,\n          1.2868e-01,  1.6894e-01,  1.2880e-04,  1.1114e-01, -8.7194e-02],\n        [ 1.1016e-01, -8.1709e-02,  9.7167e-02, -1.4578e-01,  2.5177e-02,\n         -1.2173e-01,  2.7131e-02, -3.2683e-02,  1.2128e-01,  1.0484e-01,\n         -8.9929e-02,  1.2256e-01, -1.8751e-01, -1.5073e-01,  4.4846e-04,\n          2.0413e-02, -3.8929e-02, -6.8045e-02, -1.4139e-01,  7.9055e-03],\n        [-1.3970e-03, -7.6707e-02,  2.1030e-03,  1.0355e-01, -2.5485e-02,\n          7.9086e-02, -1.8460e-01,  7.6368e-02,  1.5272e-01,  1.6205e-01,\n          1.9207e-01, -1.2711e-01,  1.2887e-01, -5.5390e-02,  9.8924e-02,\n         -2.3533e-02, -1.8858e-02,  7.8737e-03, -6.2372e-02,  1.4529e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0549, -0.0884, -0.0316,  0.1658, -0.0073,  0.0680,  0.0677,  0.0611,\n        -0.0884, -0.0609, -0.0872,  0.1028,  0.1650,  0.0174, -0.1636,  0.1108],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1489, -0.0540, -0.0034,  0.0477,  0.0100, -0.1572,  0.0684,  0.1481,\n         -0.1440, -0.0481,  0.1598, -0.0751,  0.1499, -0.1275, -0.1062,  0.0580,\n          0.1387,  0.0098, -0.1596,  0.1319,  0.0774,  0.0919, -0.1604,  0.0993,\n         -0.1613, -0.0464,  0.1430,  0.1290, -0.0976, -0.0214,  0.0367,  0.0459],\n        [ 0.1663,  0.1107,  0.1457, -0.0880, -0.1246, -0.1503,  0.1210, -0.0945,\n         -0.0287, -0.1138,  0.0921,  0.0453, -0.0361, -0.1526,  0.0968,  0.0800,\n          0.1320,  0.0896, -0.1246, -0.0182,  0.1196,  0.0178,  0.1714,  0.1665,\n          0.0849,  0.0746, -0.0413,  0.0857, -0.0150,  0.1185,  0.1314,  0.0884],\n        [ 0.1489,  0.0446,  0.1438, -0.1749, -0.0309, -0.1699,  0.0720,  0.1463,\n          0.1406,  0.0595, -0.0893,  0.1585, -0.0736,  0.1645,  0.1375,  0.1508,\n          0.1714,  0.1324,  0.1747,  0.1240,  0.0894, -0.1542, -0.1156, -0.0810,\n          0.0767,  0.0411,  0.1686, -0.0413,  0.0764, -0.0082,  0.1164,  0.0766],\n        [-0.0811, -0.1684, -0.1494,  0.0470, -0.1619,  0.1246, -0.0231,  0.1008,\n          0.0664, -0.1382, -0.0563,  0.1105, -0.0775,  0.1384, -0.0880,  0.1239,\n         -0.0941,  0.0923,  0.0873,  0.1518,  0.0226,  0.0606,  0.0332,  0.1475,\n         -0.0884, -0.0298,  0.0794, -0.1701,  0.1339, -0.1462, -0.0166,  0.1270],\n        [-0.1006,  0.0274,  0.0004, -0.1227, -0.1502,  0.0936, -0.1291,  0.0743,\n          0.1199, -0.1259,  0.1086,  0.1207,  0.0655,  0.0847, -0.0146,  0.1699,\n         -0.1662, -0.1543,  0.0629, -0.1489, -0.1165,  0.0877, -0.1490,  0.1764,\n         -0.0232,  0.0345,  0.1381, -0.0719,  0.0217, -0.0200,  0.0913,  0.0644],\n        [ 0.1740, -0.1497,  0.0090,  0.1444,  0.1195,  0.0248, -0.0086, -0.0332,\n          0.1293, -0.1767,  0.0237, -0.0666,  0.1508,  0.1611,  0.0572, -0.1326,\n         -0.0649,  0.0468, -0.0742,  0.1029, -0.1192, -0.1046,  0.0832,  0.1626,\n         -0.0642,  0.1351,  0.1171,  0.1285, -0.1436, -0.1058,  0.1592, -0.0023],\n        [-0.1751,  0.0334,  0.0185, -0.1133, -0.0622, -0.1629,  0.1750, -0.0420,\n          0.0448,  0.0155,  0.0645,  0.0129,  0.0395,  0.0852, -0.1750, -0.0810,\n          0.0773,  0.1143,  0.1304, -0.0799, -0.0349, -0.1362, -0.0072,  0.0354,\n         -0.0176,  0.1251,  0.0228,  0.0225, -0.1336, -0.1738, -0.1219,  0.1417],\n        [ 0.1511,  0.1668,  0.0755, -0.0633,  0.0342,  0.1270,  0.0464, -0.0840,\n          0.0871,  0.1502,  0.1333, -0.1613,  0.0446,  0.1227,  0.1309, -0.0600,\n         -0.0777,  0.0056, -0.0649, -0.1137,  0.0381, -0.0171, -0.0447, -0.0622,\n          0.1376,  0.0420, -0.0388,  0.1338,  0.1519, -0.1337,  0.0016, -0.1171],\n        [ 0.0254,  0.0673,  0.0882, -0.1111,  0.1201,  0.1113,  0.1586, -0.1554,\n         -0.0808,  0.0200, -0.1254,  0.0227,  0.1388,  0.1007, -0.0255, -0.0156,\n         -0.0874,  0.0660,  0.0181, -0.1066,  0.1376, -0.1131,  0.0486,  0.0954,\n          0.0021,  0.0460,  0.0521,  0.1683, -0.0737,  0.0332, -0.1059, -0.1531],\n        [ 0.0524, -0.0408, -0.1349, -0.0916, -0.1106,  0.1026, -0.1684,  0.1002,\n         -0.1005, -0.0949,  0.0144, -0.0282,  0.0168,  0.1167, -0.1592, -0.1088,\n         -0.0518, -0.1474,  0.0525,  0.0948,  0.0007, -0.1406,  0.1118, -0.0921,\n         -0.0531, -0.0705, -0.0999, -0.0902, -0.1655,  0.0109, -0.0580,  0.1200],\n        [-0.0418,  0.0732,  0.0774,  0.0449,  0.0734, -0.0020,  0.0760,  0.0441,\n         -0.0987, -0.1212,  0.0922, -0.0749, -0.0241, -0.0728, -0.0742,  0.0693,\n          0.1700,  0.0925,  0.1574,  0.0659, -0.0466, -0.0581, -0.0372,  0.0873,\n         -0.1510, -0.0983,  0.1512,  0.0050, -0.0482,  0.0365, -0.0830,  0.0915],\n        [-0.0978,  0.0580, -0.1555,  0.0332, -0.0777, -0.1632, -0.0523, -0.0385,\n          0.1627,  0.0047, -0.0606, -0.0635,  0.0232, -0.0460, -0.0302,  0.0421,\n         -0.0649,  0.1141, -0.1695, -0.1053,  0.1225, -0.0285,  0.1503,  0.0569,\n         -0.0111, -0.1390,  0.0783, -0.1226,  0.0810,  0.1373, -0.0078,  0.0117],\n        [-0.1545, -0.0032, -0.1224,  0.1449, -0.0691, -0.1398,  0.0703,  0.1371,\n          0.1550,  0.0215,  0.1276,  0.0042, -0.0875,  0.0426, -0.0925,  0.0702,\n          0.0307, -0.0681,  0.1669,  0.0287,  0.0120,  0.1169,  0.1104, -0.1282,\n         -0.0633, -0.1092,  0.1488, -0.0825, -0.0359, -0.0071, -0.1099,  0.1548],\n        [-0.1453, -0.0999,  0.1079, -0.0796, -0.0720,  0.1136,  0.0210,  0.0715,\n         -0.0228,  0.1212, -0.1686, -0.0894,  0.0227, -0.0483,  0.1389,  0.1405,\n          0.0669,  0.0490,  0.0582, -0.1069,  0.1652, -0.1021,  0.0060, -0.0150,\n          0.1103, -0.1551,  0.0849,  0.1682,  0.0749,  0.0646,  0.1317, -0.1356],\n        [ 0.1750,  0.1263,  0.0987, -0.0734, -0.0933,  0.1252, -0.0097, -0.0758,\n         -0.0275, -0.1312, -0.1345,  0.0549, -0.1045, -0.0437,  0.1568, -0.0970,\n         -0.1132, -0.1753, -0.0543,  0.0627, -0.0948, -0.1496, -0.0207, -0.1211,\n          0.0709,  0.1119,  0.0800, -0.1408,  0.0873, -0.0786, -0.0846, -0.0218],\n        [ 0.0625,  0.0257,  0.1518,  0.1358, -0.0431,  0.1615,  0.0138,  0.1512,\n         -0.0544,  0.1467,  0.0892, -0.1222,  0.1659, -0.0412, -0.0310, -0.0107,\n          0.1304,  0.1077, -0.0071,  0.0244,  0.0613, -0.1445, -0.0334, -0.0707,\n          0.0373,  0.1507, -0.1653, -0.1364,  0.0807, -0.0646, -0.0798,  0.0076]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0460,  0.1033, -0.0856,  0.0273,  0.1029, -0.0812,  0.2143, -0.0395],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0027, -0.1698,  0.2282, -0.0752, -0.0354, -0.0533, -0.2383,  0.0501,\n         -0.0936, -0.1210,  0.0969, -0.0074, -0.1536, -0.1037, -0.2342,  0.1263],\n        [ 0.1534, -0.2168,  0.0093,  0.2142, -0.0211,  0.2008,  0.0476,  0.2031,\n          0.2066, -0.0911, -0.2030,  0.0850, -0.1123, -0.1341,  0.1534, -0.0093],\n        [-0.0834,  0.1165,  0.2003,  0.0763,  0.0211, -0.2459,  0.0939, -0.0697,\n         -0.0539,  0.0791,  0.2341, -0.2054,  0.1678,  0.2211, -0.2162,  0.1995],\n        [-0.1318, -0.1023,  0.1847, -0.1108,  0.1216, -0.0546, -0.0464, -0.1844,\n          0.0708, -0.0682,  0.1255,  0.2007, -0.1007,  0.1603, -0.2216,  0.1839],\n        [-0.0003, -0.1728,  0.1705, -0.2436,  0.2296,  0.2492, -0.0382,  0.2367,\n          0.1258,  0.0223,  0.1392,  0.2408, -0.2041,  0.1663,  0.2487,  0.1310],\n        [ 0.0817, -0.1083, -0.0595,  0.1757,  0.1275, -0.2224,  0.0904,  0.2296,\n          0.0912,  0.0623, -0.1081, -0.1621, -0.2418,  0.0532,  0.0213,  0.1806],\n        [ 0.0812, -0.0163,  0.0711,  0.2463, -0.1959, -0.0370, -0.1600, -0.1928,\n          0.2047,  0.2264, -0.1426, -0.0003,  0.1512, -0.1547,  0.1296,  0.1243],\n        [ 0.2001, -0.0866,  0.1054, -0.1342,  0.1864, -0.0805,  0.1375, -0.0353,\n          0.1515, -0.1808, -0.2251,  0.0969,  0.0540,  0.1181, -0.0742, -0.1446]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2561, -0.1882,  0.0721,  0.1514], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3097, -0.3337, -0.3246,  0.2915,  0.2240,  0.3029,  0.1646,  0.1549],\n        [-0.2937,  0.1983,  0.1947, -0.1610, -0.2580, -0.3010, -0.1790,  0.0518],\n        [-0.0527,  0.1558,  0.1004,  0.2839, -0.2493, -0.1239,  0.3242, -0.1837],\n        [ 0.3056,  0.2730, -0.0160, -0.3217, -0.1928, -0.3417,  0.2949, -0.2661]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 1.1993e-01, -8.8234e-02,  1.1128e-01,  1.0747e-01,  1.2864e-01,\n         -1.0074e-01,  5.3200e-02, -1.0896e-01, -1.8218e-01,  2.0007e-01,\n         -7.3606e-03, -1.7787e-01,  2.0185e-01,  5.2292e-02,  9.9689e-02,\n         -1.9498e-01, -7.7226e-03,  1.5117e-01,  1.5985e-01,  3.2287e-02],\n        [-1.4749e-01,  1.1229e-01,  6.3380e-02, -1.7170e-02,  1.3644e-01,\n         -1.8374e-01, -3.4621e-03,  7.0836e-02,  1.3587e-01, -1.4180e-02,\n          6.7965e-02, -5.2278e-02, -1.8630e-01, -1.5673e-01, -1.7176e-02,\n          1.4383e-01,  1.5274e-01, -1.6595e-01, -1.8796e-01,  3.1060e-02],\n        [ 1.2632e-01, -2.1456e-01,  1.6767e-01,  7.4965e-02,  1.8029e-01,\n          1.7473e-01, -1.4769e-01,  1.3158e-01,  1.4551e-01, -1.2391e-01,\n          1.8607e-01,  8.1237e-02, -9.6408e-03, -4.7709e-02, -1.1424e-01,\n         -5.8748e-03, -2.2115e-01, -8.3643e-02, -1.7818e-01,  1.2915e-03],\n        [-1.9345e-01, -3.3960e-02, -1.9738e-01,  1.2581e-01, -2.1589e-01,\n          1.5270e-01, -1.5988e-01,  9.1050e-02, -5.7222e-02, -1.2581e-02,\n          1.8389e-01, -1.3766e-01,  1.7191e-01,  1.6751e-01,  2.1282e-01,\n          3.8442e-02, -9.8888e-02,  3.4820e-03,  4.2894e-02, -4.5914e-03],\n        [ 2.1885e-02, -1.7509e-01, -8.1003e-02,  1.2787e-01,  9.1319e-02,\n          9.1801e-02,  5.2611e-02,  2.0145e-01, -7.7061e-02, -2.0980e-01,\n          9.0108e-02, -5.0754e-02, -3.5515e-02,  1.8898e-01, -1.5473e-01,\n         -4.6537e-02,  1.5527e-02,  8.8141e-02, -2.0792e-01, -1.9545e-01],\n        [ 1.2598e-01, -1.6569e-02,  8.7808e-02, -8.6066e-02,  9.8604e-02,\n         -2.3091e-02, -1.6922e-01, -1.8930e-01, -1.4808e-01,  5.4208e-02,\n         -2.1994e-01,  5.8335e-02,  1.3425e-01, -4.0035e-02,  8.0769e-03,\n          1.8881e-01,  1.1063e-01,  1.4277e-01, -1.3688e-01,  1.4284e-02],\n        [-3.2281e-02, -1.8342e-01, -1.2934e-01, -9.4546e-02, -4.3286e-02,\n         -6.4919e-03, -1.9737e-01, -1.9364e-01,  1.1598e-01, -5.2047e-02,\n         -8.6892e-02, -3.6011e-02, -5.8002e-02, -1.8864e-01, -9.9736e-02,\n         -7.3601e-02, -5.6031e-02, -1.7487e-01,  6.3063e-02, -6.1674e-02],\n        [ 2.1510e-01, -8.5460e-02, -1.2970e-01, -1.0252e-01, -1.2529e-01,\n         -2.9532e-02, -6.8944e-03,  2.1145e-02,  1.2219e-01,  1.4599e-01,\n          1.7180e-01, -6.4600e-02, -8.5297e-02, -1.9447e-01,  2.3763e-02,\n         -1.9291e-01,  1.9739e-01,  6.1796e-02,  1.1648e-01,  1.5808e-01],\n        [ 5.4164e-02,  1.9451e-01,  2.0490e-01, -1.6699e-01,  6.3488e-02,\n          1.1014e-01, -9.9973e-02, -4.3624e-02,  1.1161e-01, -9.8094e-03,\n          8.4827e-03,  6.3478e-03, -1.6374e-01, -7.5830e-02,  2.0821e-02,\n          1.3896e-02,  1.5119e-01, -5.8450e-02,  2.2029e-01, -1.9600e-01],\n        [ 5.3560e-02, -1.4210e-01,  1.6878e-01,  1.6266e-01, -1.5623e-01,\n          6.4024e-02, -7.5193e-02,  2.2284e-01, -3.6656e-02, -2.5662e-02,\n         -1.3180e-01, -2.0770e-01, -1.0344e-01,  7.9712e-02, -1.8026e-01,\n          5.2642e-02,  8.9600e-02, -1.6123e-01,  7.7915e-02,  1.0637e-03],\n        [-9.3021e-02,  1.8713e-01,  9.2491e-02,  8.7595e-02,  2.2288e-01,\n          1.1925e-01, -7.4096e-02,  1.3203e-01, -8.0318e-02,  7.6359e-02,\n          2.9985e-03,  4.2011e-02,  9.3677e-02,  8.6032e-02, -1.7641e-01,\n         -1.6303e-01,  1.9287e-01, -9.5224e-02,  2.1303e-01, -1.5049e-01],\n        [ 1.5211e-01,  8.1820e-02, -1.9044e-01, -2.5288e-02,  2.1002e-02,\n         -1.8061e-01,  7.2280e-03,  1.4296e-01,  3.5093e-02,  5.9460e-02,\n          1.8658e-01,  2.0601e-01, -8.0826e-02,  1.6034e-01, -1.4413e-01,\n          1.2664e-01, -7.2624e-04, -1.0083e-01, -5.2173e-02,  1.5878e-02],\n        [-2.0459e-01, -1.7443e-01,  1.7544e-01,  4.5316e-03,  1.1836e-01,\n          1.7052e-01, -1.5132e-01, -1.3301e-01, -4.0769e-02,  1.5753e-01,\n          2.0955e-01,  2.0917e-01,  2.2301e-01,  1.3835e-02, -2.0238e-01,\n          3.0960e-02,  1.1387e-01, -1.0151e-02, -1.1172e-01, -1.7439e-01],\n        [ 1.9742e-01,  2.0861e-01,  1.4665e-01, -1.5504e-01, -1.7778e-01,\n          7.2440e-02,  8.3944e-02, -2.9962e-02,  1.6021e-01,  1.6932e-01,\n         -1.5962e-01, -3.3659e-03, -1.7275e-01, -1.4316e-01,  4.1693e-02,\n          9.0567e-03, -1.8304e-01,  1.9008e-01,  2.9668e-02,  1.4303e-01],\n        [ 1.0308e-01, -1.6448e-02,  2.9841e-02, -8.7223e-02,  6.6674e-02,\n         -5.0289e-02, -7.9058e-02, -2.0368e-01, -6.9804e-02, -2.1530e-01,\n          1.8548e-01, -1.6089e-01,  6.9361e-02,  2.2690e-02, -1.9418e-01,\n          1.9356e-01, -1.0465e-01,  1.0827e-01, -7.2138e-03,  1.8421e-01],\n        [-1.6364e-01,  1.4833e-01,  1.1895e-01, -1.7658e-01,  8.6889e-02,\n         -1.8667e-01,  2.2250e-01,  1.7844e-01, -4.2091e-02, -2.0383e-01,\n          1.4231e-01, -4.9721e-02,  3.0569e-02,  1.6901e-01, -1.2439e-01,\n          1.6473e-01,  5.1675e-02, -1.6904e-01, -3.5615e-02,  2.0813e-01],\n        [-4.6426e-02, -1.8024e-01, -2.0550e-01, -5.3540e-02, -2.5467e-02,\n          1.5305e-01,  2.0331e-01,  3.9045e-02, -1.6163e-01, -2.1010e-01,\n          1.0680e-01,  3.8766e-02,  1.0619e-01, -2.2339e-01, -1.0401e-02,\n          1.5355e-01, -6.5925e-02,  1.6204e-01,  1.2156e-01, -1.9164e-02],\n        [ 1.8636e-01,  8.9125e-02,  4.8287e-02, -8.7991e-02, -3.8781e-02,\n         -1.4977e-01,  1.1924e-01, -1.2144e-01, -5.6870e-03,  9.0425e-02,\n         -9.4499e-02, -5.3536e-02,  5.5489e-02,  9.3851e-02,  1.1293e-01,\n         -5.8702e-02, -9.5570e-03, -7.6004e-02,  3.0407e-02,  1.1361e-01],\n        [ 1.0703e-01,  1.0029e-01,  1.3339e-01,  6.7769e-02, -1.0613e-01,\n         -2.0181e-01,  2.0784e-01, -1.7654e-01,  1.4664e-01,  1.7179e-01,\n          1.3617e-01, -6.6027e-02,  1.5493e-01,  1.8768e-01, -1.3900e-01,\n          2.0269e-01,  6.9126e-02, -1.3411e-01,  6.0388e-02, -1.3917e-01],\n        [-4.6755e-02, -6.3305e-02, -8.3607e-02,  8.0267e-03,  1.2010e-01,\n          7.7179e-02,  2.2097e-01,  8.0627e-02, -3.8160e-03,  1.7009e-01,\n         -2.9532e-02,  6.2546e-02,  8.1093e-02, -3.3952e-02,  1.9562e-01,\n         -2.1248e-01, -1.3009e-01, -2.0588e-01,  2.0014e-01,  1.3829e-01],\n        [ 5.7863e-02,  4.6991e-02, -1.6064e-01,  2.1432e-01, -6.6241e-02,\n          4.4030e-02,  2.0120e-01, -2.0901e-01,  1.2128e-01,  2.1085e-01,\n         -2.7367e-02,  2.0653e-01, -9.9392e-02,  1.5478e-01, -1.3866e-01,\n          5.5883e-02, -1.4174e-01,  2.0273e-01,  4.5102e-02, -1.0856e-01],\n        [-1.7846e-02,  1.3275e-01, -1.9626e-01, -9.7213e-02, -1.9343e-01,\n         -1.7281e-01, -1.5129e-01,  4.7200e-02, -2.8423e-02, -8.5516e-02,\n          5.2144e-02, -2.0046e-01, -4.8274e-02, -1.3391e-01,  9.6046e-02,\n          5.9757e-04, -1.2882e-01,  7.3840e-02, -1.0574e-01,  1.9032e-01],\n        [ 1.2195e-01, -1.5032e-01,  8.5836e-02,  1.7940e-01, -1.5365e-01,\n          1.8894e-01,  1.8644e-01,  2.1980e-01, -1.0209e-01, -2.0283e-01,\n         -9.1773e-03, -1.6389e-01,  5.5227e-03, -1.9217e-01,  1.2033e-01,\n         -1.1649e-01, -3.5884e-02, -3.6730e-02, -2.0770e-01, -1.9844e-01],\n        [-2.0165e-01,  1.7005e-01, -5.5276e-02, -1.1517e-01, -2.0069e-01,\n         -1.5128e-01,  1.4626e-02,  8.7222e-02, -1.6347e-02,  6.8472e-02,\n         -1.9177e-01, -1.2502e-01,  1.7840e-02, -2.0628e-01, -3.5065e-02,\n          1.1833e-02, -2.1518e-01, -8.9706e-02, -1.2071e-02, -8.6714e-02],\n        [ 1.2164e-01, -1.4384e-01, -1.7554e-01,  1.8451e-01, -8.6255e-02,\n         -9.2796e-02,  2.1408e-01, -9.4756e-02,  2.0398e-02, -2.1870e-01,\n          1.1640e-01,  6.9887e-02,  1.7373e-01,  1.7059e-01, -2.1022e-01,\n          4.0650e-03, -1.9176e-01,  2.0144e-01, -1.0388e-01, -1.7030e-01],\n        [-2.1180e-01,  8.1775e-02, -1.9645e-01, -1.8034e-01, -1.6916e-01,\n          1.4649e-01, -4.8180e-02,  3.6722e-03,  1.8273e-01, -2.2259e-01,\n         -4.4780e-03, -6.9629e-02, -1.3994e-01, -1.9382e-04, -1.2512e-02,\n         -6.5493e-03,  9.5429e-02, -5.8270e-02,  7.8508e-02, -8.3293e-02],\n        [ 1.3451e-01, -2.0262e-01,  6.7591e-02,  2.0960e-01, -7.1056e-02,\n          3.4600e-02, -1.6023e-01, -7.3901e-02,  2.3979e-02,  2.1667e-02,\n          7.4635e-02,  7.6001e-02, -4.9564e-02,  1.3186e-01, -1.2204e-01,\n         -3.2597e-02, -1.9040e-01,  2.1201e-01,  2.1343e-01, -1.8689e-01],\n        [-1.4906e-02, -1.6695e-01, -1.7110e-01,  1.0054e-01,  1.0295e-01,\n         -2.0893e-01, -2.1235e-01,  1.9196e-01, -1.6640e-01,  3.4764e-02,\n         -6.3516e-02, -9.2022e-02, -1.2754e-01,  1.9788e-01, -8.9677e-03,\n         -1.3978e-01, -1.6071e-01,  1.5898e-01,  1.1712e-01, -5.7505e-02],\n        [-1.4006e-01, -2.1850e-01, -1.1356e-01,  1.7783e-01,  1.7964e-01,\n          8.5496e-02,  4.7134e-02, -1.9866e-01,  1.2721e-01,  2.1858e-01,\n          5.6745e-02,  6.9458e-02, -6.2252e-02, -1.4877e-01,  2.0532e-01,\n          6.1604e-02,  1.9991e-01, -1.5867e-01,  1.1642e-01, -1.6792e-01],\n        [-5.5797e-02,  9.9706e-02, -8.2178e-02,  1.6551e-02,  1.7367e-01,\n          4.2584e-02,  1.5292e-01,  2.0134e-02, -6.6672e-02,  1.8509e-01,\n         -1.3609e-01,  2.0644e-01,  8.3380e-02, -1.7076e-01, -2.0675e-01,\n          1.2868e-01,  1.6894e-01,  1.2880e-04,  1.1114e-01, -8.7194e-02],\n        [ 1.1016e-01, -8.1709e-02,  9.7167e-02, -1.4578e-01,  2.5177e-02,\n         -1.2173e-01,  2.7131e-02, -3.2683e-02,  1.2128e-01,  1.0484e-01,\n         -8.9929e-02,  1.2256e-01, -1.8751e-01, -1.5073e-01,  4.4846e-04,\n          2.0413e-02, -3.8929e-02, -6.8045e-02, -1.4139e-01,  7.9055e-03],\n        [-1.3970e-03, -7.6707e-02,  2.1030e-03,  1.0355e-01, -2.5485e-02,\n          7.9086e-02, -1.8460e-01,  7.6368e-02,  1.5272e-01,  1.6205e-01,\n          1.9207e-01, -1.2711e-01,  1.2887e-01, -5.5390e-02,  9.8924e-02,\n         -2.3533e-02, -1.8858e-02,  7.8737e-03, -6.2372e-02,  1.4529e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0995, -0.0785, -0.1416,  0.2108, -0.0792,  0.0246, -0.1093, -0.1601,\n         0.1010, -0.0142, -0.0526,  0.0672, -0.1674, -0.1951,  0.0146,  0.1055,\n        -0.0645, -0.0650, -0.2098,  0.1636,  0.1378,  0.0576, -0.1296,  0.1677,\n        -0.0813,  0.0426, -0.0952, -0.1165,  0.1483, -0.1343,  0.1961,  0.0972],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1489, -0.0540, -0.0034,  0.0477,  0.0100, -0.1572,  0.0684,  0.1481,\n         -0.1440, -0.0481,  0.1598, -0.0751,  0.1499, -0.1275, -0.1062,  0.0580,\n          0.1387,  0.0098, -0.1596,  0.1319,  0.0774,  0.0919, -0.1604,  0.0993,\n         -0.1613, -0.0464,  0.1430,  0.1290, -0.0976, -0.0214,  0.0367,  0.0459],\n        [ 0.1663,  0.1107,  0.1457, -0.0880, -0.1246, -0.1503,  0.1210, -0.0945,\n         -0.0287, -0.1138,  0.0921,  0.0453, -0.0361, -0.1526,  0.0968,  0.0800,\n          0.1320,  0.0896, -0.1246, -0.0182,  0.1196,  0.0178,  0.1714,  0.1665,\n          0.0849,  0.0746, -0.0413,  0.0857, -0.0150,  0.1185,  0.1314,  0.0884],\n        [ 0.1489,  0.0446,  0.1438, -0.1749, -0.0309, -0.1699,  0.0720,  0.1463,\n          0.1406,  0.0595, -0.0893,  0.1585, -0.0736,  0.1645,  0.1375,  0.1508,\n          0.1714,  0.1324,  0.1747,  0.1240,  0.0894, -0.1542, -0.1156, -0.0810,\n          0.0767,  0.0411,  0.1686, -0.0413,  0.0764, -0.0082,  0.1164,  0.0766],\n        [-0.0811, -0.1684, -0.1494,  0.0470, -0.1619,  0.1246, -0.0231,  0.1008,\n          0.0664, -0.1382, -0.0563,  0.1105, -0.0775,  0.1384, -0.0880,  0.1239,\n         -0.0941,  0.0923,  0.0873,  0.1518,  0.0226,  0.0606,  0.0332,  0.1475,\n         -0.0884, -0.0298,  0.0794, -0.1701,  0.1339, -0.1462, -0.0166,  0.1270],\n        [-0.1006,  0.0274,  0.0004, -0.1227, -0.1502,  0.0936, -0.1291,  0.0743,\n          0.1199, -0.1259,  0.1086,  0.1207,  0.0655,  0.0847, -0.0146,  0.1699,\n         -0.1662, -0.1543,  0.0629, -0.1489, -0.1165,  0.0877, -0.1490,  0.1764,\n         -0.0232,  0.0345,  0.1381, -0.0719,  0.0217, -0.0200,  0.0913,  0.0644],\n        [ 0.1740, -0.1497,  0.0090,  0.1444,  0.1195,  0.0248, -0.0086, -0.0332,\n          0.1293, -0.1767,  0.0237, -0.0666,  0.1508,  0.1611,  0.0572, -0.1326,\n         -0.0649,  0.0468, -0.0742,  0.1029, -0.1192, -0.1046,  0.0832,  0.1626,\n         -0.0642,  0.1351,  0.1171,  0.1285, -0.1436, -0.1058,  0.1592, -0.0023],\n        [-0.1751,  0.0334,  0.0185, -0.1133, -0.0622, -0.1629,  0.1750, -0.0420,\n          0.0448,  0.0155,  0.0645,  0.0129,  0.0395,  0.0852, -0.1750, -0.0810,\n          0.0773,  0.1143,  0.1304, -0.0799, -0.0349, -0.1362, -0.0072,  0.0354,\n         -0.0176,  0.1251,  0.0228,  0.0225, -0.1336, -0.1738, -0.1219,  0.1417],\n        [ 0.1511,  0.1668,  0.0755, -0.0633,  0.0342,  0.1270,  0.0464, -0.0840,\n          0.0871,  0.1502,  0.1333, -0.1613,  0.0446,  0.1227,  0.1309, -0.0600,\n         -0.0777,  0.0056, -0.0649, -0.1137,  0.0381, -0.0171, -0.0447, -0.0622,\n          0.1376,  0.0420, -0.0388,  0.1338,  0.1519, -0.1337,  0.0016, -0.1171],\n        [ 0.0254,  0.0673,  0.0882, -0.1111,  0.1201,  0.1113,  0.1586, -0.1554,\n         -0.0808,  0.0200, -0.1254,  0.0227,  0.1388,  0.1007, -0.0255, -0.0156,\n         -0.0874,  0.0660,  0.0181, -0.1066,  0.1376, -0.1131,  0.0486,  0.0954,\n          0.0021,  0.0460,  0.0521,  0.1683, -0.0737,  0.0332, -0.1059, -0.1531],\n        [ 0.0524, -0.0408, -0.1349, -0.0916, -0.1106,  0.1026, -0.1684,  0.1002,\n         -0.1005, -0.0949,  0.0144, -0.0282,  0.0168,  0.1167, -0.1592, -0.1088,\n         -0.0518, -0.1474,  0.0525,  0.0948,  0.0007, -0.1406,  0.1118, -0.0921,\n         -0.0531, -0.0705, -0.0999, -0.0902, -0.1655,  0.0109, -0.0580,  0.1200],\n        [-0.0418,  0.0732,  0.0774,  0.0449,  0.0734, -0.0020,  0.0760,  0.0441,\n         -0.0987, -0.1212,  0.0922, -0.0749, -0.0241, -0.0728, -0.0742,  0.0693,\n          0.1700,  0.0925,  0.1574,  0.0659, -0.0466, -0.0581, -0.0372,  0.0873,\n         -0.1510, -0.0983,  0.1512,  0.0050, -0.0482,  0.0365, -0.0830,  0.0915],\n        [-0.0978,  0.0580, -0.1555,  0.0332, -0.0777, -0.1632, -0.0523, -0.0385,\n          0.1627,  0.0047, -0.0606, -0.0635,  0.0232, -0.0460, -0.0302,  0.0421,\n         -0.0649,  0.1141, -0.1695, -0.1053,  0.1225, -0.0285,  0.1503,  0.0569,\n         -0.0111, -0.1390,  0.0783, -0.1226,  0.0810,  0.1373, -0.0078,  0.0117],\n        [-0.1545, -0.0032, -0.1224,  0.1449, -0.0691, -0.1398,  0.0703,  0.1371,\n          0.1550,  0.0215,  0.1276,  0.0042, -0.0875,  0.0426, -0.0925,  0.0702,\n          0.0307, -0.0681,  0.1669,  0.0287,  0.0120,  0.1169,  0.1104, -0.1282,\n         -0.0633, -0.1092,  0.1488, -0.0825, -0.0359, -0.0071, -0.1099,  0.1548],\n        [-0.1453, -0.0999,  0.1079, -0.0796, -0.0720,  0.1136,  0.0210,  0.0715,\n         -0.0228,  0.1212, -0.1686, -0.0894,  0.0227, -0.0483,  0.1389,  0.1405,\n          0.0669,  0.0490,  0.0582, -0.1069,  0.1652, -0.1021,  0.0060, -0.0150,\n          0.1103, -0.1551,  0.0849,  0.1682,  0.0749,  0.0646,  0.1317, -0.1356],\n        [ 0.1750,  0.1263,  0.0987, -0.0734, -0.0933,  0.1252, -0.0097, -0.0758,\n         -0.0275, -0.1312, -0.1345,  0.0549, -0.1045, -0.0437,  0.1568, -0.0970,\n         -0.1132, -0.1753, -0.0543,  0.0627, -0.0948, -0.1496, -0.0207, -0.1211,\n          0.0709,  0.1119,  0.0800, -0.1408,  0.0873, -0.0786, -0.0846, -0.0218],\n        [ 0.0625,  0.0257,  0.1518,  0.1358, -0.0431,  0.1615,  0.0138,  0.1512,\n         -0.0544,  0.1467,  0.0892, -0.1222,  0.1659, -0.0412, -0.0310, -0.0107,\n          0.1304,  0.1077, -0.0071,  0.0244,  0.0613, -0.1445, -0.0334, -0.0707,\n          0.0373,  0.1507, -0.1653, -0.1364,  0.0807, -0.0646, -0.0798,  0.0076]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0549, -0.0884, -0.0316,  0.1658, -0.0073,  0.0680,  0.0677,  0.0611,\n        -0.0884, -0.0609, -0.0872,  0.1028,  0.1650,  0.0174, -0.1636,  0.1108],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0027, -0.1698,  0.2282, -0.0752, -0.0354, -0.0533, -0.2383,  0.0501,\n         -0.0936, -0.1210,  0.0969, -0.0074, -0.1536, -0.1037, -0.2342,  0.1263],\n        [ 0.1534, -0.2168,  0.0093,  0.2142, -0.0211,  0.2008,  0.0476,  0.2031,\n          0.2066, -0.0911, -0.2030,  0.0850, -0.1123, -0.1341,  0.1534, -0.0093],\n        [-0.0834,  0.1165,  0.2003,  0.0763,  0.0211, -0.2459,  0.0939, -0.0697,\n         -0.0539,  0.0791,  0.2341, -0.2054,  0.1678,  0.2211, -0.2162,  0.1995],\n        [-0.1318, -0.1023,  0.1847, -0.1108,  0.1216, -0.0546, -0.0464, -0.1844,\n          0.0708, -0.0682,  0.1255,  0.2007, -0.1007,  0.1603, -0.2216,  0.1839],\n        [-0.0003, -0.1728,  0.1705, -0.2436,  0.2296,  0.2492, -0.0382,  0.2367,\n          0.1258,  0.0223,  0.1392,  0.2408, -0.2041,  0.1663,  0.2487,  0.1310],\n        [ 0.0817, -0.1083, -0.0595,  0.1757,  0.1275, -0.2224,  0.0904,  0.2296,\n          0.0912,  0.0623, -0.1081, -0.1621, -0.2418,  0.0532,  0.0213,  0.1806],\n        [ 0.0812, -0.0163,  0.0711,  0.2463, -0.1959, -0.0370, -0.1600, -0.1928,\n          0.2047,  0.2264, -0.1426, -0.0003,  0.1512, -0.1547,  0.1296,  0.1243],\n        [ 0.2001, -0.0866,  0.1054, -0.1342,  0.1864, -0.0805,  0.1375, -0.0353,\n          0.1515, -0.1808, -0.2251,  0.0969,  0.0540,  0.1181, -0.0742, -0.1446]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0460,  0.1033, -0.0856,  0.0273,  0.1029, -0.0812,  0.2143, -0.0395],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3097, -0.3337, -0.3246,  0.2915,  0.2240,  0.3029,  0.1646,  0.1549],\n        [-0.2937,  0.1983,  0.1947, -0.1610, -0.2580, -0.3010, -0.1790,  0.0518],\n        [-0.0527,  0.1558,  0.1004,  0.2839, -0.2493, -0.1239,  0.3242, -0.1837],\n        [ 0.3056,  0.2730, -0.0160, -0.3217, -0.1928, -0.3417,  0.2949, -0.2661]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2561, -0.1882,  0.0721,  0.1514], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x72f33b4f58d0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "done_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "last_traj_before_training":	-1,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "stale_sample_marker_buf":	"[0 0 0 ... 0 0 0]",
                    "time":	0
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0995, -0.0785, -0.1416,  0.2108, -0.0792,  0.0246, -0.1093, -0.1601,\n         0.1010, -0.0142, -0.0526,  0.0672, -0.1674, -0.1951,  0.0146,  0.1055,\n        -0.0645, -0.0650, -0.2098,  0.1636,  0.1378,  0.0576, -0.1296,  0.1677,\n        -0.0813,  0.0426, -0.0952, -0.1165,  0.1483, -0.1343,  0.1961,  0.0972],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.1993e-01, -8.8234e-02,  1.1128e-01,  1.0747e-01,  1.2864e-01,\n         -1.0074e-01,  5.3200e-02, -1.0896e-01, -1.8218e-01,  2.0007e-01,\n         -7.3606e-03, -1.7787e-01,  2.0185e-01,  5.2292e-02,  9.9689e-02,\n         -1.9498e-01, -7.7226e-03,  1.5117e-01,  1.5985e-01,  3.2287e-02],\n        [-1.4749e-01,  1.1229e-01,  6.3380e-02, -1.7170e-02,  1.3644e-01,\n         -1.8374e-01, -3.4621e-03,  7.0836e-02,  1.3587e-01, -1.4180e-02,\n          6.7965e-02, -5.2278e-02, -1.8630e-01, -1.5673e-01, -1.7176e-02,\n          1.4383e-01,  1.5274e-01, -1.6595e-01, -1.8796e-01,  3.1060e-02],\n        [ 1.2632e-01, -2.1456e-01,  1.6767e-01,  7.4965e-02,  1.8029e-01,\n          1.7473e-01, -1.4769e-01,  1.3158e-01,  1.4551e-01, -1.2391e-01,\n          1.8607e-01,  8.1237e-02, -9.6408e-03, -4.7709e-02, -1.1424e-01,\n         -5.8748e-03, -2.2115e-01, -8.3643e-02, -1.7818e-01,  1.2915e-03],\n        [-1.9345e-01, -3.3960e-02, -1.9738e-01,  1.2581e-01, -2.1589e-01,\n          1.5270e-01, -1.5988e-01,  9.1050e-02, -5.7222e-02, -1.2581e-02,\n          1.8389e-01, -1.3766e-01,  1.7191e-01,  1.6751e-01,  2.1282e-01,\n          3.8442e-02, -9.8888e-02,  3.4820e-03,  4.2894e-02, -4.5914e-03],\n        [ 2.1885e-02, -1.7509e-01, -8.1003e-02,  1.2787e-01,  9.1319e-02,\n          9.1801e-02,  5.2611e-02,  2.0145e-01, -7.7061e-02, -2.0980e-01,\n          9.0108e-02, -5.0754e-02, -3.5515e-02,  1.8898e-01, -1.5473e-01,\n         -4.6537e-02,  1.5527e-02,  8.8141e-02, -2.0792e-01, -1.9545e-01],\n        [ 1.2598e-01, -1.6569e-02,  8.7808e-02, -8.6066e-02,  9.8604e-02,\n         -2.3091e-02, -1.6922e-01, -1.8930e-01, -1.4808e-01,  5.4208e-02,\n         -2.1994e-01,  5.8335e-02,  1.3425e-01, -4.0035e-02,  8.0769e-03,\n          1.8881e-01,  1.1063e-01,  1.4277e-01, -1.3688e-01,  1.4284e-02],\n        [-3.2281e-02, -1.8342e-01, -1.2934e-01, -9.4546e-02, -4.3286e-02,\n         -6.4919e-03, -1.9737e-01, -1.9364e-01,  1.1598e-01, -5.2047e-02,\n         -8.6892e-02, -3.6011e-02, -5.8002e-02, -1.8864e-01, -9.9736e-02,\n         -7.3601e-02, -5.6031e-02, -1.7487e-01,  6.3063e-02, -6.1674e-02],\n        [ 2.1510e-01, -8.5460e-02, -1.2970e-01, -1.0252e-01, -1.2529e-01,\n         -2.9532e-02, -6.8944e-03,  2.1145e-02,  1.2219e-01,  1.4599e-01,\n          1.7180e-01, -6.4600e-02, -8.5297e-02, -1.9447e-01,  2.3763e-02,\n         -1.9291e-01,  1.9739e-01,  6.1796e-02,  1.1648e-01,  1.5808e-01],\n        [ 5.4164e-02,  1.9451e-01,  2.0490e-01, -1.6699e-01,  6.3488e-02,\n          1.1014e-01, -9.9973e-02, -4.3624e-02,  1.1161e-01, -9.8094e-03,\n          8.4827e-03,  6.3478e-03, -1.6374e-01, -7.5830e-02,  2.0821e-02,\n          1.3896e-02,  1.5119e-01, -5.8450e-02,  2.2029e-01, -1.9600e-01],\n        [ 5.3560e-02, -1.4210e-01,  1.6878e-01,  1.6266e-01, -1.5623e-01,\n          6.4024e-02, -7.5193e-02,  2.2284e-01, -3.6656e-02, -2.5662e-02,\n         -1.3180e-01, -2.0770e-01, -1.0344e-01,  7.9712e-02, -1.8026e-01,\n          5.2642e-02,  8.9600e-02, -1.6123e-01,  7.7915e-02,  1.0637e-03],\n        [-9.3021e-02,  1.8713e-01,  9.2491e-02,  8.7595e-02,  2.2288e-01,\n          1.1925e-01, -7.4096e-02,  1.3203e-01, -8.0318e-02,  7.6359e-02,\n          2.9985e-03,  4.2011e-02,  9.3677e-02,  8.6032e-02, -1.7641e-01,\n         -1.6303e-01,  1.9287e-01, -9.5224e-02,  2.1303e-01, -1.5049e-01],\n        [ 1.5211e-01,  8.1820e-02, -1.9044e-01, -2.5288e-02,  2.1002e-02,\n         -1.8061e-01,  7.2280e-03,  1.4296e-01,  3.5093e-02,  5.9460e-02,\n          1.8658e-01,  2.0601e-01, -8.0826e-02,  1.6034e-01, -1.4413e-01,\n          1.2664e-01, -7.2624e-04, -1.0083e-01, -5.2173e-02,  1.5878e-02],\n        [-2.0459e-01, -1.7443e-01,  1.7544e-01,  4.5316e-03,  1.1836e-01,\n          1.7052e-01, -1.5132e-01, -1.3301e-01, -4.0769e-02,  1.5753e-01,\n          2.0955e-01,  2.0917e-01,  2.2301e-01,  1.3835e-02, -2.0238e-01,\n          3.0960e-02,  1.1387e-01, -1.0151e-02, -1.1172e-01, -1.7439e-01],\n        [ 1.9742e-01,  2.0861e-01,  1.4665e-01, -1.5504e-01, -1.7778e-01,\n          7.2440e-02,  8.3944e-02, -2.9962e-02,  1.6021e-01,  1.6932e-01,\n         -1.5962e-01, -3.3659e-03, -1.7275e-01, -1.4316e-01,  4.1693e-02,\n          9.0567e-03, -1.8304e-01,  1.9008e-01,  2.9668e-02,  1.4303e-01],\n        [ 1.0308e-01, -1.6448e-02,  2.9841e-02, -8.7223e-02,  6.6674e-02,\n         -5.0289e-02, -7.9058e-02, -2.0368e-01, -6.9804e-02, -2.1530e-01,\n          1.8548e-01, -1.6089e-01,  6.9361e-02,  2.2690e-02, -1.9418e-01,\n          1.9356e-01, -1.0465e-01,  1.0827e-01, -7.2138e-03,  1.8421e-01],\n        [-1.6364e-01,  1.4833e-01,  1.1895e-01, -1.7658e-01,  8.6889e-02,\n         -1.8667e-01,  2.2250e-01,  1.7844e-01, -4.2091e-02, -2.0383e-01,\n          1.4231e-01, -4.9721e-02,  3.0569e-02,  1.6901e-01, -1.2439e-01,\n          1.6473e-01,  5.1675e-02, -1.6904e-01, -3.5615e-02,  2.0813e-01],\n        [-4.6426e-02, -1.8024e-01, -2.0550e-01, -5.3540e-02, -2.5467e-02,\n          1.5305e-01,  2.0331e-01,  3.9045e-02, -1.6163e-01, -2.1010e-01,\n          1.0680e-01,  3.8766e-02,  1.0619e-01, -2.2339e-01, -1.0401e-02,\n          1.5355e-01, -6.5925e-02,  1.6204e-01,  1.2156e-01, -1.9164e-02],\n        [ 1.8636e-01,  8.9125e-02,  4.8287e-02, -8.7991e-02, -3.8781e-02,\n         -1.4977e-01,  1.1924e-01, -1.2144e-01, -5.6870e-03,  9.0425e-02,\n         -9.4499e-02, -5.3536e-02,  5.5489e-02,  9.3851e-02,  1.1293e-01,\n         -5.8702e-02, -9.5570e-03, -7.6004e-02,  3.0407e-02,  1.1361e-01],\n        [ 1.0703e-01,  1.0029e-01,  1.3339e-01,  6.7769e-02, -1.0613e-01,\n         -2.0181e-01,  2.0784e-01, -1.7654e-01,  1.4664e-01,  1.7179e-01,\n          1.3617e-01, -6.6027e-02,  1.5493e-01,  1.8768e-01, -1.3900e-01,\n          2.0269e-01,  6.9126e-02, -1.3411e-01,  6.0388e-02, -1.3917e-01],\n        [-4.6755e-02, -6.3305e-02, -8.3607e-02,  8.0267e-03,  1.2010e-01,\n          7.7179e-02,  2.2097e-01,  8.0627e-02, -3.8160e-03,  1.7009e-01,\n         -2.9532e-02,  6.2546e-02,  8.1093e-02, -3.3952e-02,  1.9562e-01,\n         -2.1248e-01, -1.3009e-01, -2.0588e-01,  2.0014e-01,  1.3829e-01],\n        [ 5.7863e-02,  4.6991e-02, -1.6064e-01,  2.1432e-01, -6.6241e-02,\n          4.4030e-02,  2.0120e-01, -2.0901e-01,  1.2128e-01,  2.1085e-01,\n         -2.7367e-02,  2.0653e-01, -9.9392e-02,  1.5478e-01, -1.3866e-01,\n          5.5883e-02, -1.4174e-01,  2.0273e-01,  4.5102e-02, -1.0856e-01],\n        [-1.7846e-02,  1.3275e-01, -1.9626e-01, -9.7213e-02, -1.9343e-01,\n         -1.7281e-01, -1.5129e-01,  4.7200e-02, -2.8423e-02, -8.5516e-02,\n          5.2144e-02, -2.0046e-01, -4.8274e-02, -1.3391e-01,  9.6046e-02,\n          5.9757e-04, -1.2882e-01,  7.3840e-02, -1.0574e-01,  1.9032e-01],\n        [ 1.2195e-01, -1.5032e-01,  8.5836e-02,  1.7940e-01, -1.5365e-01,\n          1.8894e-01,  1.8644e-01,  2.1980e-01, -1.0209e-01, -2.0283e-01,\n         -9.1773e-03, -1.6389e-01,  5.5227e-03, -1.9217e-01,  1.2033e-01,\n         -1.1649e-01, -3.5884e-02, -3.6730e-02, -2.0770e-01, -1.9844e-01],\n        [-2.0165e-01,  1.7005e-01, -5.5276e-02, -1.1517e-01, -2.0069e-01,\n         -1.5128e-01,  1.4626e-02,  8.7222e-02, -1.6347e-02,  6.8472e-02,\n         -1.9177e-01, -1.2502e-01,  1.7840e-02, -2.0628e-01, -3.5065e-02,\n          1.1833e-02, -2.1518e-01, -8.9706e-02, -1.2071e-02, -8.6714e-02],\n        [ 1.2164e-01, -1.4384e-01, -1.7554e-01,  1.8451e-01, -8.6255e-02,\n         -9.2796e-02,  2.1408e-01, -9.4756e-02,  2.0398e-02, -2.1870e-01,\n          1.1640e-01,  6.9887e-02,  1.7373e-01,  1.7059e-01, -2.1022e-01,\n          4.0650e-03, -1.9176e-01,  2.0144e-01, -1.0388e-01, -1.7030e-01],\n        [-2.1180e-01,  8.1775e-02, -1.9645e-01, -1.8034e-01, -1.6916e-01,\n          1.4649e-01, -4.8180e-02,  3.6722e-03,  1.8273e-01, -2.2259e-01,\n         -4.4780e-03, -6.9629e-02, -1.3994e-01, -1.9382e-04, -1.2512e-02,\n         -6.5493e-03,  9.5429e-02, -5.8270e-02,  7.8508e-02, -8.3293e-02],\n        [ 1.3451e-01, -2.0262e-01,  6.7591e-02,  2.0960e-01, -7.1056e-02,\n          3.4600e-02, -1.6023e-01, -7.3901e-02,  2.3979e-02,  2.1667e-02,\n          7.4635e-02,  7.6001e-02, -4.9564e-02,  1.3186e-01, -1.2204e-01,\n         -3.2597e-02, -1.9040e-01,  2.1201e-01,  2.1343e-01, -1.8689e-01],\n        [-1.4906e-02, -1.6695e-01, -1.7110e-01,  1.0054e-01,  1.0295e-01,\n         -2.0893e-01, -2.1235e-01,  1.9196e-01, -1.6640e-01,  3.4764e-02,\n         -6.3516e-02, -9.2022e-02, -1.2754e-01,  1.9788e-01, -8.9677e-03,\n         -1.3978e-01, -1.6071e-01,  1.5898e-01,  1.1712e-01, -5.7505e-02],\n        [-1.4006e-01, -2.1850e-01, -1.1356e-01,  1.7783e-01,  1.7964e-01,\n          8.5496e-02,  4.7134e-02, -1.9866e-01,  1.2721e-01,  2.1858e-01,\n          5.6745e-02,  6.9458e-02, -6.2252e-02, -1.4877e-01,  2.0532e-01,\n          6.1604e-02,  1.9991e-01, -1.5867e-01,  1.1642e-01, -1.6792e-01],\n        [-5.5797e-02,  9.9706e-02, -8.2178e-02,  1.6551e-02,  1.7367e-01,\n          4.2584e-02,  1.5292e-01,  2.0134e-02, -6.6672e-02,  1.8509e-01,\n         -1.3609e-01,  2.0644e-01,  8.3380e-02, -1.7076e-01, -2.0675e-01,\n          1.2868e-01,  1.6894e-01,  1.2880e-04,  1.1114e-01, -8.7194e-02],\n        [ 1.1016e-01, -8.1709e-02,  9.7167e-02, -1.4578e-01,  2.5177e-02,\n         -1.2173e-01,  2.7131e-02, -3.2683e-02,  1.2128e-01,  1.0484e-01,\n         -8.9929e-02,  1.2256e-01, -1.8751e-01, -1.5073e-01,  4.4846e-04,\n          2.0413e-02, -3.8929e-02, -6.8045e-02, -1.4139e-01,  7.9055e-03],\n        [-1.3970e-03, -7.6707e-02,  2.1030e-03,  1.0355e-01, -2.5485e-02,\n          7.9086e-02, -1.8460e-01,  7.6368e-02,  1.5272e-01,  1.6205e-01,\n          1.9207e-01, -1.2711e-01,  1.2887e-01, -5.5390e-02,  9.8924e-02,\n         -2.3533e-02, -1.8858e-02,  7.8737e-03, -6.2372e-02,  1.4529e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0549, -0.0884, -0.0316,  0.1658, -0.0073,  0.0680,  0.0677,  0.0611,\n        -0.0884, -0.0609, -0.0872,  0.1028,  0.1650,  0.0174, -0.1636,  0.1108],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1489, -0.0540, -0.0034,  0.0477,  0.0100, -0.1572,  0.0684,  0.1481,\n         -0.1440, -0.0481,  0.1598, -0.0751,  0.1499, -0.1275, -0.1062,  0.0580,\n          0.1387,  0.0098, -0.1596,  0.1319,  0.0774,  0.0919, -0.1604,  0.0993,\n         -0.1613, -0.0464,  0.1430,  0.1290, -0.0976, -0.0214,  0.0367,  0.0459],\n        [ 0.1663,  0.1107,  0.1457, -0.0880, -0.1246, -0.1503,  0.1210, -0.0945,\n         -0.0287, -0.1138,  0.0921,  0.0453, -0.0361, -0.1526,  0.0968,  0.0800,\n          0.1320,  0.0896, -0.1246, -0.0182,  0.1196,  0.0178,  0.1714,  0.1665,\n          0.0849,  0.0746, -0.0413,  0.0857, -0.0150,  0.1185,  0.1314,  0.0884],\n        [ 0.1489,  0.0446,  0.1438, -0.1749, -0.0309, -0.1699,  0.0720,  0.1463,\n          0.1406,  0.0595, -0.0893,  0.1585, -0.0736,  0.1645,  0.1375,  0.1508,\n          0.1714,  0.1324,  0.1747,  0.1240,  0.0894, -0.1542, -0.1156, -0.0810,\n          0.0767,  0.0411,  0.1686, -0.0413,  0.0764, -0.0082,  0.1164,  0.0766],\n        [-0.0811, -0.1684, -0.1494,  0.0470, -0.1619,  0.1246, -0.0231,  0.1008,\n          0.0664, -0.1382, -0.0563,  0.1105, -0.0775,  0.1384, -0.0880,  0.1239,\n         -0.0941,  0.0923,  0.0873,  0.1518,  0.0226,  0.0606,  0.0332,  0.1475,\n         -0.0884, -0.0298,  0.0794, -0.1701,  0.1339, -0.1462, -0.0166,  0.1270],\n        [-0.1006,  0.0274,  0.0004, -0.1227, -0.1502,  0.0936, -0.1291,  0.0743,\n          0.1199, -0.1259,  0.1086,  0.1207,  0.0655,  0.0847, -0.0146,  0.1699,\n         -0.1662, -0.1543,  0.0629, -0.1489, -0.1165,  0.0877, -0.1490,  0.1764,\n         -0.0232,  0.0345,  0.1381, -0.0719,  0.0217, -0.0200,  0.0913,  0.0644],\n        [ 0.1740, -0.1497,  0.0090,  0.1444,  0.1195,  0.0248, -0.0086, -0.0332,\n          0.1293, -0.1767,  0.0237, -0.0666,  0.1508,  0.1611,  0.0572, -0.1326,\n         -0.0649,  0.0468, -0.0742,  0.1029, -0.1192, -0.1046,  0.0832,  0.1626,\n         -0.0642,  0.1351,  0.1171,  0.1285, -0.1436, -0.1058,  0.1592, -0.0023],\n        [-0.1751,  0.0334,  0.0185, -0.1133, -0.0622, -0.1629,  0.1750, -0.0420,\n          0.0448,  0.0155,  0.0645,  0.0129,  0.0395,  0.0852, -0.1750, -0.0810,\n          0.0773,  0.1143,  0.1304, -0.0799, -0.0349, -0.1362, -0.0072,  0.0354,\n         -0.0176,  0.1251,  0.0228,  0.0225, -0.1336, -0.1738, -0.1219,  0.1417],\n        [ 0.1511,  0.1668,  0.0755, -0.0633,  0.0342,  0.1270,  0.0464, -0.0840,\n          0.0871,  0.1502,  0.1333, -0.1613,  0.0446,  0.1227,  0.1309, -0.0600,\n         -0.0777,  0.0056, -0.0649, -0.1137,  0.0381, -0.0171, -0.0447, -0.0622,\n          0.1376,  0.0420, -0.0388,  0.1338,  0.1519, -0.1337,  0.0016, -0.1171],\n        [ 0.0254,  0.0673,  0.0882, -0.1111,  0.1201,  0.1113,  0.1586, -0.1554,\n         -0.0808,  0.0200, -0.1254,  0.0227,  0.1388,  0.1007, -0.0255, -0.0156,\n         -0.0874,  0.0660,  0.0181, -0.1066,  0.1376, -0.1131,  0.0486,  0.0954,\n          0.0021,  0.0460,  0.0521,  0.1683, -0.0737,  0.0332, -0.1059, -0.1531],\n        [ 0.0524, -0.0408, -0.1349, -0.0916, -0.1106,  0.1026, -0.1684,  0.1002,\n         -0.1005, -0.0949,  0.0144, -0.0282,  0.0168,  0.1167, -0.1592, -0.1088,\n         -0.0518, -0.1474,  0.0525,  0.0948,  0.0007, -0.1406,  0.1118, -0.0921,\n         -0.0531, -0.0705, -0.0999, -0.0902, -0.1655,  0.0109, -0.0580,  0.1200],\n        [-0.0418,  0.0732,  0.0774,  0.0449,  0.0734, -0.0020,  0.0760,  0.0441,\n         -0.0987, -0.1212,  0.0922, -0.0749, -0.0241, -0.0728, -0.0742,  0.0693,\n          0.1700,  0.0925,  0.1574,  0.0659, -0.0466, -0.0581, -0.0372,  0.0873,\n         -0.1510, -0.0983,  0.1512,  0.0050, -0.0482,  0.0365, -0.0830,  0.0915],\n        [-0.0978,  0.0580, -0.1555,  0.0332, -0.0777, -0.1632, -0.0523, -0.0385,\n          0.1627,  0.0047, -0.0606, -0.0635,  0.0232, -0.0460, -0.0302,  0.0421,\n         -0.0649,  0.1141, -0.1695, -0.1053,  0.1225, -0.0285,  0.1503,  0.0569,\n         -0.0111, -0.1390,  0.0783, -0.1226,  0.0810,  0.1373, -0.0078,  0.0117],\n        [-0.1545, -0.0032, -0.1224,  0.1449, -0.0691, -0.1398,  0.0703,  0.1371,\n          0.1550,  0.0215,  0.1276,  0.0042, -0.0875,  0.0426, -0.0925,  0.0702,\n          0.0307, -0.0681,  0.1669,  0.0287,  0.0120,  0.1169,  0.1104, -0.1282,\n         -0.0633, -0.1092,  0.1488, -0.0825, -0.0359, -0.0071, -0.1099,  0.1548],\n        [-0.1453, -0.0999,  0.1079, -0.0796, -0.0720,  0.1136,  0.0210,  0.0715,\n         -0.0228,  0.1212, -0.1686, -0.0894,  0.0227, -0.0483,  0.1389,  0.1405,\n          0.0669,  0.0490,  0.0582, -0.1069,  0.1652, -0.1021,  0.0060, -0.0150,\n          0.1103, -0.1551,  0.0849,  0.1682,  0.0749,  0.0646,  0.1317, -0.1356],\n        [ 0.1750,  0.1263,  0.0987, -0.0734, -0.0933,  0.1252, -0.0097, -0.0758,\n         -0.0275, -0.1312, -0.1345,  0.0549, -0.1045, -0.0437,  0.1568, -0.0970,\n         -0.1132, -0.1753, -0.0543,  0.0627, -0.0948, -0.1496, -0.0207, -0.1211,\n          0.0709,  0.1119,  0.0800, -0.1408,  0.0873, -0.0786, -0.0846, -0.0218],\n        [ 0.0625,  0.0257,  0.1518,  0.1358, -0.0431,  0.1615,  0.0138,  0.1512,\n         -0.0544,  0.1467,  0.0892, -0.1222,  0.1659, -0.0412, -0.0310, -0.0107,\n          0.1304,  0.1077, -0.0071,  0.0244,  0.0613, -0.1445, -0.0334, -0.0707,\n          0.0373,  0.1507, -0.1653, -0.1364,  0.0807, -0.0646, -0.0798,  0.0076]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0460,  0.1033, -0.0856,  0.0273,  0.1029, -0.0812,  0.2143, -0.0395],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0027, -0.1698,  0.2282, -0.0752, -0.0354, -0.0533, -0.2383,  0.0501,\n         -0.0936, -0.1210,  0.0969, -0.0074, -0.1536, -0.1037, -0.2342,  0.1263],\n        [ 0.1534, -0.2168,  0.0093,  0.2142, -0.0211,  0.2008,  0.0476,  0.2031,\n          0.2066, -0.0911, -0.2030,  0.0850, -0.1123, -0.1341,  0.1534, -0.0093],\n        [-0.0834,  0.1165,  0.2003,  0.0763,  0.0211, -0.2459,  0.0939, -0.0697,\n         -0.0539,  0.0791,  0.2341, -0.2054,  0.1678,  0.2211, -0.2162,  0.1995],\n        [-0.1318, -0.1023,  0.1847, -0.1108,  0.1216, -0.0546, -0.0464, -0.1844,\n          0.0708, -0.0682,  0.1255,  0.2007, -0.1007,  0.1603, -0.2216,  0.1839],\n        [-0.0003, -0.1728,  0.1705, -0.2436,  0.2296,  0.2492, -0.0382,  0.2367,\n          0.1258,  0.0223,  0.1392,  0.2408, -0.2041,  0.1663,  0.2487,  0.1310],\n        [ 0.0817, -0.1083, -0.0595,  0.1757,  0.1275, -0.2224,  0.0904,  0.2296,\n          0.0912,  0.0623, -0.1081, -0.1621, -0.2418,  0.0532,  0.0213,  0.1806],\n        [ 0.0812, -0.0163,  0.0711,  0.2463, -0.1959, -0.0370, -0.1600, -0.1928,\n          0.2047,  0.2264, -0.1426, -0.0003,  0.1512, -0.1547,  0.1296,  0.1243],\n        [ 0.2001, -0.0866,  0.1054, -0.1342,  0.1864, -0.0805,  0.1375, -0.0353,\n          0.1515, -0.1808, -0.2251,  0.0969,  0.0540,  0.1181, -0.0742, -0.1446]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=4, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2561, -0.1882,  0.0721,  0.1514], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3097, -0.3337, -0.3246,  0.2915,  0.2240,  0.3029,  0.1646,  0.1549],\n        [-0.2937,  0.1983,  0.1947, -0.1610, -0.2580, -0.3010, -0.1790,  0.0518],\n        [-0.0527,  0.1558,  0.1004,  0.2839, -0.2493, -0.1239,  0.3242, -0.1837],\n        [ 0.3056,  0.2730, -0.0160, -0.3217, -0.1928, -0.3417,  0.2949, -0.2661]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	4,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	4,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	false
                }
            },
            "_target_net_update_freq":	300,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x72f33900e1d0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s241020000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/tybg/Documents/GitHub/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s241020000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_freq":	300,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}