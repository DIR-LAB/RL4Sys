{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s304120000"
    },
    "q_lr":	0.0005,
    "seed":	304120000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x00000161A421E680>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2119, -0.1523, -0.1008, -0.1497,  0.0423,  0.0477,  0.2099, -0.1319,\n         0.0633,  0.0488,  0.1990, -0.0241,  0.1088, -0.1036, -0.1329,  0.1307,\n        -0.1507, -0.0875,  0.2201,  0.1642, -0.1280,  0.2216,  0.0533,  0.1193,\n        -0.1292, -0.0096,  0.0354,  0.0817, -0.1263,  0.1407, -0.1615, -0.1268],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.2087e-01, -6.0767e-02,  1.1167e-01,  1.2757e-01,  4.9201e-02,\n         -4.9942e-02, -5.8806e-02,  1.3074e-01,  7.5797e-02, -1.9533e-01,\n          3.8670e-02,  1.1725e-01,  1.3444e-01, -5.4546e-02,  6.4822e-02,\n          5.9069e-02,  1.0101e-01, -9.5509e-02,  5.8989e-02, -1.3840e-01],\n        [-1.4358e-01,  1.5811e-01,  2.0066e-01, -4.3206e-02, -9.6902e-02,\n         -2.7107e-02, -2.0332e-01, -2.0317e-01, -9.4158e-02,  2.2533e-02,\n          1.7155e-01, -5.4084e-02, -9.5755e-05, -1.1343e-01, -1.9764e-01,\n          2.1666e-01, -1.8496e-01,  1.7594e-01, -2.1273e-02, -1.6167e-01],\n        [-1.9697e-01,  1.8136e-01,  9.9945e-02, -9.2230e-02,  1.9119e-01,\n          1.5512e-01, -1.3035e-01,  2.7694e-02, -7.2119e-02, -2.0162e-01,\n          1.8970e-01, -1.6948e-01, -9.8963e-02,  1.0243e-01,  1.1377e-01,\n         -1.8977e-01, -7.6064e-02, -1.2723e-01,  1.7679e-01,  1.8797e-01],\n        [ 6.3367e-02, -1.8093e-01,  5.4894e-02,  9.0509e-02,  1.9947e-02,\n          1.9681e-01, -1.3265e-01,  9.0834e-02, -1.1341e-01, -1.6337e-01,\n          1.7896e-01,  1.5300e-01,  1.0376e-01,  1.6996e-01, -7.0932e-02,\n         -1.0412e-01, -1.5634e-01,  1.0274e-01,  1.5785e-01, -1.7954e-01],\n        [-2.0531e-01,  1.2222e-01, -2.8065e-02,  3.0405e-02, -5.6484e-02,\n         -1.8298e-01,  1.7792e-01, -1.7746e-02,  1.6613e-01, -1.7331e-01,\n         -9.8782e-02,  1.8148e-01, -1.8097e-01, -2.7676e-02, -3.0280e-02,\n          1.6082e-01,  1.0335e-01, -4.6334e-02,  5.0197e-02,  1.8709e-01],\n        [-1.1515e-01,  7.0425e-02, -6.6721e-02, -2.0782e-01, -2.1037e-01,\n         -1.0947e-02,  2.1499e-01, -2.3085e-02, -5.9770e-02,  7.9448e-02,\n          2.2077e-01, -1.4546e-01,  7.7047e-02,  1.4070e-01,  2.7287e-03,\n         -1.7399e-01,  2.2189e-01,  5.0710e-02, -1.3859e-02,  5.9589e-02],\n        [ 1.0058e-01,  1.7746e-01,  1.6690e-01,  2.0782e-01,  5.5893e-02,\n         -6.4780e-02,  1.8665e-01, -1.1249e-01, -2.1423e-01,  1.6679e-01,\n          8.2376e-02, -6.3189e-02, -1.5733e-02, -1.3886e-02, -1.3481e-01,\n         -3.5636e-02, -7.1725e-02, -2.0499e-01, -2.1346e-01, -1.0862e-02],\n        [ 8.2182e-02, -8.3879e-02,  1.3846e-01,  1.5413e-02, -2.0963e-01,\n          1.5744e-01,  5.5709e-02,  3.8380e-02, -1.5312e-01,  5.8879e-02,\n          1.8743e-01,  1.2998e-01,  1.7441e-02,  1.0255e-01,  1.0778e-01,\n         -1.9567e-02, -1.5560e-01, -3.2700e-02,  5.2677e-02,  1.2259e-02],\n        [-1.8763e-01,  2.0497e-01,  1.7415e-01,  1.8915e-01,  1.7825e-01,\n         -2.0244e-01, -5.6266e-02,  2.0326e-01, -2.3425e-02, -6.8354e-02,\n         -1.6911e-01,  9.4093e-02,  4.9275e-02,  4.4332e-02,  1.2988e-01,\n          3.3839e-02, -1.9476e-01,  1.9177e-01,  1.8121e-01,  1.4191e-01],\n        [ 2.7755e-02, -1.5324e-01, -1.5474e-01, -1.4128e-01,  4.2304e-02,\n          9.1656e-02,  9.0280e-02,  7.2342e-02,  1.0076e-02, -1.6261e-01,\n          1.3634e-01,  1.7788e-02,  1.4364e-01, -2.2287e-01,  1.6587e-01,\n          1.9953e-01, -1.3470e-01, -1.7477e-01,  6.0214e-02, -1.7235e-01],\n        [ 1.0317e-01, -4.6579e-02,  1.7164e-01, -1.1490e-01, -1.2158e-01,\n          7.1894e-02, -2.0305e-01, -2.0914e-01,  1.8686e-01, -1.0873e-01,\n          8.0622e-02,  1.7373e-01, -8.3817e-02,  3.7330e-02, -1.3265e-01,\n          5.2295e-02, -2.1257e-01,  1.8990e-01, -1.0096e-01, -2.1441e-01],\n        [-6.3158e-02, -1.1608e-01,  1.3097e-01, -2.2023e-01,  1.0109e-01,\n         -6.4790e-03, -7.4342e-02,  1.7276e-01,  1.8241e-01,  4.0063e-02,\n         -5.9057e-02, -3.1990e-02, -7.6041e-02,  3.4077e-03, -7.5893e-02,\n         -1.7424e-01,  3.3701e-02,  8.6598e-03, -1.3615e-01, -7.0299e-02],\n        [-1.5400e-01,  1.2598e-01, -1.7196e-01, -4.4036e-02,  5.9202e-03,\n          6.3204e-02, -1.7893e-01,  6.9999e-02,  1.1838e-01,  1.7850e-01,\n         -2.1907e-01, -5.0207e-02, -9.7526e-02,  1.3342e-01, -3.2620e-02,\n          1.9095e-01, -8.3796e-02, -1.8264e-01,  1.7544e-01, -7.9310e-02],\n        [ 7.2758e-02,  3.5066e-02, -1.2374e-02,  2.5722e-02, -4.6058e-02,\n         -1.9562e-01, -1.5057e-01,  1.2519e-01,  6.8016e-02, -1.6445e-01,\n          1.4332e-01, -1.2587e-01, -3.6399e-02, -2.0953e-01,  1.0737e-01,\n          4.5607e-02,  7.4014e-02, -2.1768e-01,  2.2161e-02, -1.7716e-01],\n        [-1.4169e-03,  1.1372e-02, -9.7975e-02,  1.4089e-01, -9.3097e-03,\n         -1.8176e-01, -2.6995e-02, -1.7266e-01,  1.2217e-01,  1.4605e-01,\n         -1.7425e-01, -3.1504e-02, -1.8670e-01,  9.0509e-02,  2.1456e-01,\n         -1.9785e-03, -1.0110e-02, -1.1142e-01, -1.5106e-01,  1.5542e-01],\n        [-9.4059e-02, -2.1000e-01,  1.2611e-01, -2.0074e-01, -1.4800e-01,\n         -1.1834e-01, -1.4865e-01, -2.4179e-02,  4.5014e-02,  4.3156e-02,\n          1.7983e-01, -1.0461e-01, -2.0661e-01, -1.1445e-01,  1.4988e-02,\n          6.3622e-02, -1.1898e-01, -9.8094e-02,  4.8036e-03,  2.9891e-02],\n        [-1.0867e-01, -6.7301e-02, -6.1816e-02, -2.5288e-02, -6.3942e-02,\n         -5.5952e-02,  1.2841e-01, -4.3326e-02, -1.6420e-01, -1.6131e-01,\n         -6.1571e-02, -6.6850e-02,  1.6593e-01,  1.0456e-01, -2.0899e-01,\n          1.3068e-01, -2.1379e-01,  2.1049e-01, -2.2020e-01,  1.0545e-01],\n        [-6.1523e-02,  1.1482e-01,  2.0733e-01,  1.6465e-01, -1.3136e-01,\n         -1.6136e-02, -1.2618e-01,  6.9579e-02, -1.9616e-01,  1.4242e-01,\n         -1.7785e-01,  2.0976e-01, -5.1694e-02, -3.5506e-02, -1.6590e-01,\n          2.8676e-02, -8.0701e-02, -1.8526e-02,  1.4633e-01,  1.8652e-01],\n        [ 1.0310e-02,  1.3781e-01, -1.2169e-01, -3.1789e-02, -1.6082e-01,\n         -2.0194e-01,  2.0391e-01, -2.1019e-01,  9.2679e-02,  2.1216e-01,\n         -9.4625e-02,  4.0007e-02, -8.9060e-02,  8.5774e-02, -2.9362e-02,\n          2.1478e-01,  8.7114e-02,  2.1017e-01, -2.3935e-02,  1.6280e-01],\n        [-4.9770e-02, -1.9114e-01, -1.3096e-01,  3.9898e-03,  1.2833e-01,\n         -1.1173e-01,  2.6048e-02,  4.0578e-02, -1.3628e-01,  1.5120e-01,\n         -1.0441e-01,  1.0767e-01, -1.5842e-01,  1.8868e-01, -7.3253e-03,\n          4.0255e-02, -1.9438e-01,  1.1138e-01, -2.0597e-01,  1.1392e-01],\n        [ 1.1899e-01,  1.7952e-01,  1.0308e-01,  1.8054e-01,  1.8911e-01,\n          2.0524e-01, -8.3109e-02,  2.2168e-01,  1.1718e-01,  1.1697e-01,\n          8.8068e-02,  1.4525e-02, -1.9805e-01, -2.1243e-01, -1.3595e-03,\n         -1.5807e-02,  7.1617e-02, -2.1645e-01, -7.6212e-02, -4.2681e-03],\n        [ 1.2660e-01, -1.3290e-01, -1.7356e-01,  3.7222e-02, -1.9555e-01,\n          6.0736e-02,  1.8438e-01, -1.8523e-01, -1.5657e-01, -8.0468e-02,\n          3.4554e-02,  1.0250e-01,  1.6858e-01, -9.1693e-02, -1.6488e-01,\n          7.7492e-02, -5.3430e-02, -1.1057e-01,  2.2057e-01,  1.0390e-02],\n        [ 1.0735e-01,  8.6264e-02,  1.6597e-01, -1.6466e-01, -1.7804e-01,\n         -1.9021e-01,  1.5330e-01,  1.1058e-02,  1.0471e-01,  1.4737e-01,\n          1.9781e-01,  6.1031e-03,  5.3231e-02, -8.7377e-02,  8.1373e-02,\n         -2.2162e-01,  1.4297e-01, -1.2300e-01, -9.5470e-03, -2.0512e-01],\n        [ 1.5415e-01, -1.4730e-01, -1.5359e-01,  1.5733e-01, -1.3331e-01,\n          1.7829e-02,  3.0647e-02, -1.0418e-01, -2.1130e-01, -5.6717e-02,\n         -4.1617e-02, -1.3759e-01,  1.9937e-01,  1.7439e-01,  5.6919e-02,\n          6.7723e-02, -1.1573e-01,  1.7648e-01,  1.9990e-02,  1.6252e-02],\n        [ 2.0982e-01, -5.8510e-02, -1.5541e-01, -8.9353e-02,  4.8334e-02,\n          1.6293e-01, -1.7525e-01, -3.4854e-02,  8.3342e-03,  1.1399e-01,\n         -5.3465e-02, -1.9429e-01, -4.4701e-02, -2.1846e-01,  8.1127e-02,\n          5.2819e-02, -6.2530e-02, -1.7268e-01,  8.4589e-03,  1.9805e-01],\n        [-2.1485e-01,  1.9009e-01, -2.1144e-01, -3.4246e-02, -4.4993e-02,\n         -1.3914e-01,  1.4405e-01, -1.6246e-01,  2.0683e-01, -1.1722e-01,\n          1.8542e-01,  9.7587e-03, -2.2289e-01, -1.6859e-01, -8.4455e-02,\n         -7.6987e-02, -1.9703e-01,  3.6411e-02, -4.6985e-02, -2.1819e-01],\n        [ 2.1753e-01,  1.7760e-01, -6.1262e-02, -1.7766e-01,  4.3477e-02,\n         -1.4168e-01,  1.2151e-01, -1.3765e-01,  1.8017e-02, -1.7926e-01,\n         -1.2131e-01,  5.5146e-04, -3.4874e-02,  1.9229e-01,  2.2280e-02,\n          1.5813e-01, -1.3516e-01, -1.2073e-01, -1.5294e-01, -1.2573e-01],\n        [ 1.1624e-01,  1.4044e-01, -8.5927e-02, -3.3533e-02,  1.8866e-01,\n         -1.9023e-01, -5.7594e-02, -6.7489e-02, -4.0817e-02,  4.5046e-02,\n          3.0130e-02, -1.4119e-01,  1.0081e-01, -3.4013e-02, -2.7085e-02,\n          1.2396e-01, -1.9537e-01,  1.5786e-01,  1.4147e-01,  1.7558e-01],\n        [-2.1009e-01,  1.6576e-01, -2.2254e-01, -8.7030e-02, -2.8337e-02,\n         -2.0479e-01,  9.3857e-02,  5.7591e-02,  1.5760e-02, -2.0952e-01,\n         -4.9856e-02, -1.5003e-02, -1.5853e-02, -5.0056e-02,  1.2501e-01,\n          1.9757e-01,  2.0932e-01, -3.4254e-02, -1.9661e-01,  1.3414e-01],\n        [ 1.5996e-01,  1.7381e-01,  1.4817e-02,  8.3124e-02,  1.3322e-01,\n          1.0548e-01,  2.1626e-02, -1.1575e-01,  1.2523e-01, -1.6775e-01,\n          2.4640e-02,  1.6163e-01, -5.9662e-02,  3.6545e-02, -2.1052e-01,\n         -1.0908e-01, -1.6699e-01, -3.3848e-02,  1.8562e-01,  3.9008e-02],\n        [ 7.9296e-02,  3.7466e-02, -1.1697e-01, -9.1109e-02, -1.2708e-01,\n         -8.4812e-02, -8.5428e-02,  1.3477e-01, -4.8135e-02,  1.2473e-01,\n         -6.7512e-02, -1.0656e-01,  1.0663e-01,  1.5141e-02, -1.5193e-01,\n         -1.5142e-01,  3.5797e-03, -2.3196e-02, -1.9449e-01, -5.1001e-02],\n        [ 2.1943e-01,  6.4433e-03, -2.0921e-01,  1.0548e-01, -6.6222e-02,\n          1.8550e-01,  4.3203e-02,  1.6147e-01, -1.0471e-01, -1.4825e-01,\n         -2.1356e-02, -4.3135e-02,  2.1218e-01,  8.9535e-02, -1.6806e-01,\n         -6.6597e-02,  1.3848e-01,  1.2523e-02,  2.2340e-01, -1.6402e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1084,  0.1017, -0.0761,  0.0729, -0.0573,  0.0944, -0.0464,  0.1155,\n        -0.0528, -0.1645,  0.1531,  0.1683,  0.0705,  0.0302,  0.0237, -0.0847],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1282, -0.1412, -0.1530, -0.0410, -0.0721, -0.1756, -0.1112, -0.0127,\n         -0.1663, -0.1336, -0.1032,  0.1536,  0.0914, -0.0366,  0.1642, -0.0684,\n         -0.1274,  0.1101, -0.0417, -0.0437,  0.1653,  0.0589,  0.1525,  0.0610,\n          0.1402, -0.0084, -0.1714, -0.1717,  0.1332,  0.0653, -0.0038, -0.1491],\n        [ 0.0320, -0.0173,  0.0628,  0.1560,  0.0796, -0.0009,  0.0448, -0.1672,\n         -0.1497, -0.1184,  0.0981,  0.1455, -0.0143, -0.0934, -0.0911, -0.1328,\n          0.1018, -0.1414,  0.1622, -0.0052,  0.0391, -0.0455,  0.1100, -0.0916,\n          0.0743,  0.0191, -0.1134, -0.1397, -0.0092, -0.0947,  0.0620, -0.0083],\n        [-0.1688, -0.0333, -0.0940,  0.0693,  0.0250,  0.1387, -0.1072,  0.1357,\n          0.1344,  0.0881,  0.1289,  0.0159, -0.0004,  0.0843, -0.0248, -0.0627,\n         -0.1091,  0.0547,  0.1738,  0.1481, -0.1690,  0.0029, -0.1294,  0.0388,\n         -0.1374, -0.0315, -0.0626, -0.0212, -0.0117,  0.0675,  0.1344, -0.1501],\n        [-0.1468,  0.0735, -0.1597, -0.1461,  0.0920,  0.0170,  0.0833,  0.0294,\n         -0.1738, -0.1175, -0.1758, -0.1475,  0.1305, -0.1195, -0.0327,  0.1185,\n          0.1025, -0.0925,  0.0756, -0.1664, -0.0391,  0.0278, -0.0942,  0.0493,\n         -0.1727,  0.0219, -0.0170,  0.1119,  0.0647, -0.0324,  0.1648, -0.0570],\n        [ 0.1033,  0.1495,  0.1389, -0.1360,  0.0203,  0.0579, -0.0618,  0.1671,\n          0.0218, -0.0642, -0.1280, -0.0624,  0.0948, -0.0581,  0.1556, -0.0623,\n         -0.0384, -0.1672,  0.0975,  0.1343, -0.1753, -0.1043, -0.1639,  0.1743,\n         -0.1524, -0.1767, -0.0383, -0.0575,  0.0773,  0.1768, -0.1346, -0.0604],\n        [-0.0755, -0.0745,  0.1556,  0.1481,  0.0643, -0.1486,  0.1398, -0.0785,\n          0.0302, -0.1268,  0.0077,  0.0787,  0.0919,  0.1506,  0.1344,  0.0719,\n         -0.0087,  0.0989, -0.0895,  0.0214, -0.1386, -0.0436, -0.0977,  0.0350,\n          0.0425, -0.0318,  0.1672,  0.1082, -0.1039, -0.1145,  0.1328, -0.0268],\n        [ 0.0762,  0.1391,  0.0574,  0.0977,  0.0463,  0.0781, -0.0929,  0.0538,\n          0.1061, -0.0126, -0.0820,  0.0769,  0.0741, -0.1580,  0.0329, -0.1724,\n         -0.1125,  0.0633,  0.0485, -0.0365,  0.1127, -0.1304,  0.0331, -0.1318,\n         -0.1706,  0.0345, -0.1595, -0.0807, -0.1624, -0.0406, -0.1461,  0.0071],\n        [-0.0834, -0.0881, -0.0423, -0.0320,  0.0802, -0.1500,  0.0332,  0.1302,\n          0.0059, -0.0555, -0.0914, -0.0083,  0.1762, -0.0786, -0.0941, -0.0558,\n         -0.0831,  0.1708,  0.1126,  0.1451,  0.0524, -0.1463,  0.0056, -0.0504,\n          0.0228, -0.0169,  0.0730,  0.0946, -0.1263, -0.0358,  0.0516,  0.1072],\n        [-0.1216,  0.1674,  0.1749,  0.1644,  0.1704, -0.0542, -0.0439,  0.1307,\n          0.0825, -0.1024,  0.0488, -0.1565,  0.1175,  0.1096,  0.0680,  0.0619,\n         -0.0179,  0.0886,  0.0164,  0.0165,  0.0478, -0.1328,  0.0916, -0.0639,\n          0.1045, -0.0922,  0.1294, -0.0799, -0.0507,  0.1103,  0.1524, -0.0710],\n        [ 0.0964,  0.1072, -0.1688, -0.0223, -0.0565, -0.1199,  0.1585,  0.1728,\n         -0.0474, -0.0388,  0.0595,  0.0286, -0.0938, -0.1362,  0.0348,  0.0645,\n          0.1615,  0.0453, -0.1023, -0.0171, -0.0978, -0.0232,  0.1560, -0.1063,\n          0.1575, -0.0649,  0.0512, -0.1586, -0.1359, -0.1730,  0.1085, -0.0983],\n        [ 0.1340,  0.1275,  0.0661, -0.1625,  0.0486, -0.0682,  0.0155, -0.0795,\n         -0.1169, -0.1335, -0.0402,  0.0056,  0.1530,  0.1189, -0.0698,  0.0777,\n          0.1265, -0.1446, -0.0332, -0.0833, -0.1626,  0.0912, -0.1567,  0.0243,\n         -0.0814, -0.0374, -0.1637,  0.0104, -0.0139, -0.0364, -0.0567, -0.0334],\n        [-0.0284, -0.0238,  0.1667, -0.1653,  0.0949, -0.1699,  0.0094, -0.0012,\n          0.0776,  0.0298,  0.1760, -0.1440,  0.1346,  0.0812,  0.0270,  0.1674,\n          0.1201, -0.0419, -0.0127, -0.0210,  0.0033,  0.1082,  0.0905, -0.0336,\n          0.1270,  0.1538, -0.1066,  0.0368, -0.0170, -0.0384,  0.0641, -0.1636],\n        [ 0.0423,  0.0031, -0.0618,  0.0839, -0.0932, -0.1041,  0.0763,  0.0602,\n          0.0875,  0.0274,  0.1230,  0.0670, -0.0856, -0.0090,  0.0922,  0.0668,\n         -0.1066, -0.1527, -0.1366, -0.1394, -0.1107, -0.0156,  0.0535,  0.0218,\n          0.1678, -0.1631,  0.1155,  0.0691,  0.0560,  0.0610, -0.0009, -0.1761],\n        [-0.1041,  0.0519,  0.0533,  0.0359,  0.1051, -0.0874,  0.1293,  0.1305,\n          0.0166,  0.1076,  0.0813,  0.1713,  0.0240,  0.0209,  0.1198, -0.0042,\n         -0.0255,  0.0558, -0.0947,  0.0045, -0.1236,  0.0572, -0.0337, -0.0192,\n          0.0607,  0.1468,  0.1561,  0.0392, -0.0443, -0.0632,  0.1383, -0.1300],\n        [-0.1108,  0.1734,  0.0483,  0.0058,  0.0183, -0.1411,  0.0473,  0.0388,\n         -0.1587, -0.0603, -0.0896,  0.0572,  0.0320, -0.0078,  0.0781,  0.1704,\n          0.0447, -0.0455, -0.1605,  0.1224, -0.1087, -0.1480,  0.1159,  0.0059,\n         -0.0575,  0.1120,  0.1578,  0.0302, -0.0008, -0.0379, -0.0454,  0.1542],\n        [-0.1497, -0.1344, -0.1018, -0.1610, -0.1083, -0.0946, -0.1680, -0.0375,\n          0.1329, -0.0916,  0.0398, -0.1603,  0.0304,  0.0092,  0.0149,  0.0639,\n          0.0073, -0.0769, -0.1321,  0.0854, -0.1359, -0.0991, -0.1047,  0.1594,\n          0.1387,  0.0219,  0.0348, -0.0325, -0.0303, -0.1715, -0.1311,  0.1316]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2404, -0.0359,  0.1721, -0.1401, -0.0932,  0.1277, -0.2296,  0.0955],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0593,  0.1082, -0.0516, -0.0249,  0.1849, -0.0152, -0.1963,  0.0783,\n         -0.0097, -0.0494,  0.2050, -0.0709, -0.1936,  0.2399,  0.0007, -0.0387],\n        [-0.0281,  0.2043, -0.1098, -0.2091,  0.1671, -0.1123,  0.0665, -0.0327,\n          0.1693,  0.1659, -0.0872, -0.0081, -0.0848,  0.1288,  0.2173,  0.0131],\n        [-0.0871,  0.1445,  0.0553, -0.1660,  0.1140, -0.1585,  0.1822, -0.2115,\n          0.1293,  0.0595,  0.1035, -0.1942,  0.0536,  0.2250, -0.0236, -0.1945],\n        [ 0.0281, -0.2204,  0.1103,  0.2243,  0.2235,  0.0458,  0.1875,  0.2244,\n         -0.2372,  0.0543,  0.0689, -0.2251, -0.0170, -0.1959, -0.1521, -0.0862],\n        [-0.0084, -0.1614,  0.0460, -0.0837,  0.1245,  0.1177,  0.0137,  0.2175,\n          0.2423,  0.0926,  0.1606,  0.2277, -0.0406,  0.0084, -0.2115,  0.0572],\n        [ 0.1480,  0.1152,  0.0522,  0.0636, -0.1408, -0.2441, -0.0342,  0.1209,\n          0.2416, -0.0878,  0.1921, -0.1835, -0.2448,  0.2289, -0.2213,  0.0448],\n        [-0.0974, -0.0327,  0.1031, -0.0216, -0.1068,  0.1613, -0.0490, -0.1172,\n          0.0574,  0.0347, -0.0660, -0.1354, -0.2413, -0.0929, -0.0243,  0.2412],\n        [ 0.1016, -0.2215, -0.1707, -0.0200, -0.1223, -0.2214,  0.0760,  0.1962,\n         -0.1411, -0.1474, -0.2148, -0.0429, -0.0513, -0.1329, -0.1582,  0.0601]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0249], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1146,  0.2538,  0.2588,  0.0493,  0.1345, -0.0282, -0.3454,  0.1810]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 1.2087e-01, -6.0767e-02,  1.1167e-01,  1.2757e-01,  4.9201e-02,\n         -4.9942e-02, -5.8806e-02,  1.3074e-01,  7.5797e-02, -1.9533e-01,\n          3.8670e-02,  1.1725e-01,  1.3444e-01, -5.4546e-02,  6.4822e-02,\n          5.9069e-02,  1.0101e-01, -9.5509e-02,  5.8989e-02, -1.3840e-01],\n        [-1.4358e-01,  1.5811e-01,  2.0066e-01, -4.3206e-02, -9.6902e-02,\n         -2.7107e-02, -2.0332e-01, -2.0317e-01, -9.4158e-02,  2.2533e-02,\n          1.7155e-01, -5.4084e-02, -9.5755e-05, -1.1343e-01, -1.9764e-01,\n          2.1666e-01, -1.8496e-01,  1.7594e-01, -2.1273e-02, -1.6167e-01],\n        [-1.9697e-01,  1.8136e-01,  9.9945e-02, -9.2230e-02,  1.9119e-01,\n          1.5512e-01, -1.3035e-01,  2.7694e-02, -7.2119e-02, -2.0162e-01,\n          1.8970e-01, -1.6948e-01, -9.8963e-02,  1.0243e-01,  1.1377e-01,\n         -1.8977e-01, -7.6064e-02, -1.2723e-01,  1.7679e-01,  1.8797e-01],\n        [ 6.3367e-02, -1.8093e-01,  5.4894e-02,  9.0509e-02,  1.9947e-02,\n          1.9681e-01, -1.3265e-01,  9.0834e-02, -1.1341e-01, -1.6337e-01,\n          1.7896e-01,  1.5300e-01,  1.0376e-01,  1.6996e-01, -7.0932e-02,\n         -1.0412e-01, -1.5634e-01,  1.0274e-01,  1.5785e-01, -1.7954e-01],\n        [-2.0531e-01,  1.2222e-01, -2.8065e-02,  3.0405e-02, -5.6484e-02,\n         -1.8298e-01,  1.7792e-01, -1.7746e-02,  1.6613e-01, -1.7331e-01,\n         -9.8782e-02,  1.8148e-01, -1.8097e-01, -2.7676e-02, -3.0280e-02,\n          1.6082e-01,  1.0335e-01, -4.6334e-02,  5.0197e-02,  1.8709e-01],\n        [-1.1515e-01,  7.0425e-02, -6.6721e-02, -2.0782e-01, -2.1037e-01,\n         -1.0947e-02,  2.1499e-01, -2.3085e-02, -5.9770e-02,  7.9448e-02,\n          2.2077e-01, -1.4546e-01,  7.7047e-02,  1.4070e-01,  2.7287e-03,\n         -1.7399e-01,  2.2189e-01,  5.0710e-02, -1.3859e-02,  5.9589e-02],\n        [ 1.0058e-01,  1.7746e-01,  1.6690e-01,  2.0782e-01,  5.5893e-02,\n         -6.4780e-02,  1.8665e-01, -1.1249e-01, -2.1423e-01,  1.6679e-01,\n          8.2376e-02, -6.3189e-02, -1.5733e-02, -1.3886e-02, -1.3481e-01,\n         -3.5636e-02, -7.1725e-02, -2.0499e-01, -2.1346e-01, -1.0862e-02],\n        [ 8.2182e-02, -8.3879e-02,  1.3846e-01,  1.5413e-02, -2.0963e-01,\n          1.5744e-01,  5.5709e-02,  3.8380e-02, -1.5312e-01,  5.8879e-02,\n          1.8743e-01,  1.2998e-01,  1.7441e-02,  1.0255e-01,  1.0778e-01,\n         -1.9567e-02, -1.5560e-01, -3.2700e-02,  5.2677e-02,  1.2259e-02],\n        [-1.8763e-01,  2.0497e-01,  1.7415e-01,  1.8915e-01,  1.7825e-01,\n         -2.0244e-01, -5.6266e-02,  2.0326e-01, -2.3425e-02, -6.8354e-02,\n         -1.6911e-01,  9.4093e-02,  4.9275e-02,  4.4332e-02,  1.2988e-01,\n          3.3839e-02, -1.9476e-01,  1.9177e-01,  1.8121e-01,  1.4191e-01],\n        [ 2.7755e-02, -1.5324e-01, -1.5474e-01, -1.4128e-01,  4.2304e-02,\n          9.1656e-02,  9.0280e-02,  7.2342e-02,  1.0076e-02, -1.6261e-01,\n          1.3634e-01,  1.7788e-02,  1.4364e-01, -2.2287e-01,  1.6587e-01,\n          1.9953e-01, -1.3470e-01, -1.7477e-01,  6.0214e-02, -1.7235e-01],\n        [ 1.0317e-01, -4.6579e-02,  1.7164e-01, -1.1490e-01, -1.2158e-01,\n          7.1894e-02, -2.0305e-01, -2.0914e-01,  1.8686e-01, -1.0873e-01,\n          8.0622e-02,  1.7373e-01, -8.3817e-02,  3.7330e-02, -1.3265e-01,\n          5.2295e-02, -2.1257e-01,  1.8990e-01, -1.0096e-01, -2.1441e-01],\n        [-6.3158e-02, -1.1608e-01,  1.3097e-01, -2.2023e-01,  1.0109e-01,\n         -6.4790e-03, -7.4342e-02,  1.7276e-01,  1.8241e-01,  4.0063e-02,\n         -5.9057e-02, -3.1990e-02, -7.6041e-02,  3.4077e-03, -7.5893e-02,\n         -1.7424e-01,  3.3701e-02,  8.6598e-03, -1.3615e-01, -7.0299e-02],\n        [-1.5400e-01,  1.2598e-01, -1.7196e-01, -4.4036e-02,  5.9202e-03,\n          6.3204e-02, -1.7893e-01,  6.9999e-02,  1.1838e-01,  1.7850e-01,\n         -2.1907e-01, -5.0207e-02, -9.7526e-02,  1.3342e-01, -3.2620e-02,\n          1.9095e-01, -8.3796e-02, -1.8264e-01,  1.7544e-01, -7.9310e-02],\n        [ 7.2758e-02,  3.5066e-02, -1.2374e-02,  2.5722e-02, -4.6058e-02,\n         -1.9562e-01, -1.5057e-01,  1.2519e-01,  6.8016e-02, -1.6445e-01,\n          1.4332e-01, -1.2587e-01, -3.6399e-02, -2.0953e-01,  1.0737e-01,\n          4.5607e-02,  7.4014e-02, -2.1768e-01,  2.2161e-02, -1.7716e-01],\n        [-1.4169e-03,  1.1372e-02, -9.7975e-02,  1.4089e-01, -9.3097e-03,\n         -1.8176e-01, -2.6995e-02, -1.7266e-01,  1.2217e-01,  1.4605e-01,\n         -1.7425e-01, -3.1504e-02, -1.8670e-01,  9.0509e-02,  2.1456e-01,\n         -1.9785e-03, -1.0110e-02, -1.1142e-01, -1.5106e-01,  1.5542e-01],\n        [-9.4059e-02, -2.1000e-01,  1.2611e-01, -2.0074e-01, -1.4800e-01,\n         -1.1834e-01, -1.4865e-01, -2.4179e-02,  4.5014e-02,  4.3156e-02,\n          1.7983e-01, -1.0461e-01, -2.0661e-01, -1.1445e-01,  1.4988e-02,\n          6.3622e-02, -1.1898e-01, -9.8094e-02,  4.8036e-03,  2.9891e-02],\n        [-1.0867e-01, -6.7301e-02, -6.1816e-02, -2.5288e-02, -6.3942e-02,\n         -5.5952e-02,  1.2841e-01, -4.3326e-02, -1.6420e-01, -1.6131e-01,\n         -6.1571e-02, -6.6850e-02,  1.6593e-01,  1.0456e-01, -2.0899e-01,\n          1.3068e-01, -2.1379e-01,  2.1049e-01, -2.2020e-01,  1.0545e-01],\n        [-6.1523e-02,  1.1482e-01,  2.0733e-01,  1.6465e-01, -1.3136e-01,\n         -1.6136e-02, -1.2618e-01,  6.9579e-02, -1.9616e-01,  1.4242e-01,\n         -1.7785e-01,  2.0976e-01, -5.1694e-02, -3.5506e-02, -1.6590e-01,\n          2.8676e-02, -8.0701e-02, -1.8526e-02,  1.4633e-01,  1.8652e-01],\n        [ 1.0310e-02,  1.3781e-01, -1.2169e-01, -3.1789e-02, -1.6082e-01,\n         -2.0194e-01,  2.0391e-01, -2.1019e-01,  9.2679e-02,  2.1216e-01,\n         -9.4625e-02,  4.0007e-02, -8.9060e-02,  8.5774e-02, -2.9362e-02,\n          2.1478e-01,  8.7114e-02,  2.1017e-01, -2.3935e-02,  1.6280e-01],\n        [-4.9770e-02, -1.9114e-01, -1.3096e-01,  3.9898e-03,  1.2833e-01,\n         -1.1173e-01,  2.6048e-02,  4.0578e-02, -1.3628e-01,  1.5120e-01,\n         -1.0441e-01,  1.0767e-01, -1.5842e-01,  1.8868e-01, -7.3253e-03,\n          4.0255e-02, -1.9438e-01,  1.1138e-01, -2.0597e-01,  1.1392e-01],\n        [ 1.1899e-01,  1.7952e-01,  1.0308e-01,  1.8054e-01,  1.8911e-01,\n          2.0524e-01, -8.3109e-02,  2.2168e-01,  1.1718e-01,  1.1697e-01,\n          8.8068e-02,  1.4525e-02, -1.9805e-01, -2.1243e-01, -1.3595e-03,\n         -1.5807e-02,  7.1617e-02, -2.1645e-01, -7.6212e-02, -4.2681e-03],\n        [ 1.2660e-01, -1.3290e-01, -1.7356e-01,  3.7222e-02, -1.9555e-01,\n          6.0736e-02,  1.8438e-01, -1.8523e-01, -1.5657e-01, -8.0468e-02,\n          3.4554e-02,  1.0250e-01,  1.6858e-01, -9.1693e-02, -1.6488e-01,\n          7.7492e-02, -5.3430e-02, -1.1057e-01,  2.2057e-01,  1.0390e-02],\n        [ 1.0735e-01,  8.6264e-02,  1.6597e-01, -1.6466e-01, -1.7804e-01,\n         -1.9021e-01,  1.5330e-01,  1.1058e-02,  1.0471e-01,  1.4737e-01,\n          1.9781e-01,  6.1031e-03,  5.3231e-02, -8.7377e-02,  8.1373e-02,\n         -2.2162e-01,  1.4297e-01, -1.2300e-01, -9.5470e-03, -2.0512e-01],\n        [ 1.5415e-01, -1.4730e-01, -1.5359e-01,  1.5733e-01, -1.3331e-01,\n          1.7829e-02,  3.0647e-02, -1.0418e-01, -2.1130e-01, -5.6717e-02,\n         -4.1617e-02, -1.3759e-01,  1.9937e-01,  1.7439e-01,  5.6919e-02,\n          6.7723e-02, -1.1573e-01,  1.7648e-01,  1.9990e-02,  1.6252e-02],\n        [ 2.0982e-01, -5.8510e-02, -1.5541e-01, -8.9353e-02,  4.8334e-02,\n          1.6293e-01, -1.7525e-01, -3.4854e-02,  8.3342e-03,  1.1399e-01,\n         -5.3465e-02, -1.9429e-01, -4.4701e-02, -2.1846e-01,  8.1127e-02,\n          5.2819e-02, -6.2530e-02, -1.7268e-01,  8.4589e-03,  1.9805e-01],\n        [-2.1485e-01,  1.9009e-01, -2.1144e-01, -3.4246e-02, -4.4993e-02,\n         -1.3914e-01,  1.4405e-01, -1.6246e-01,  2.0683e-01, -1.1722e-01,\n          1.8542e-01,  9.7587e-03, -2.2289e-01, -1.6859e-01, -8.4455e-02,\n         -7.6987e-02, -1.9703e-01,  3.6411e-02, -4.6985e-02, -2.1819e-01],\n        [ 2.1753e-01,  1.7760e-01, -6.1262e-02, -1.7766e-01,  4.3477e-02,\n         -1.4168e-01,  1.2151e-01, -1.3765e-01,  1.8017e-02, -1.7926e-01,\n         -1.2131e-01,  5.5146e-04, -3.4874e-02,  1.9229e-01,  2.2280e-02,\n          1.5813e-01, -1.3516e-01, -1.2073e-01, -1.5294e-01, -1.2573e-01],\n        [ 1.1624e-01,  1.4044e-01, -8.5927e-02, -3.3533e-02,  1.8866e-01,\n         -1.9023e-01, -5.7594e-02, -6.7489e-02, -4.0817e-02,  4.5046e-02,\n          3.0130e-02, -1.4119e-01,  1.0081e-01, -3.4013e-02, -2.7085e-02,\n          1.2396e-01, -1.9537e-01,  1.5786e-01,  1.4147e-01,  1.7558e-01],\n        [-2.1009e-01,  1.6576e-01, -2.2254e-01, -8.7030e-02, -2.8337e-02,\n         -2.0479e-01,  9.3857e-02,  5.7591e-02,  1.5760e-02, -2.0952e-01,\n         -4.9856e-02, -1.5003e-02, -1.5853e-02, -5.0056e-02,  1.2501e-01,\n          1.9757e-01,  2.0932e-01, -3.4254e-02, -1.9661e-01,  1.3414e-01],\n        [ 1.5996e-01,  1.7381e-01,  1.4817e-02,  8.3124e-02,  1.3322e-01,\n          1.0548e-01,  2.1626e-02, -1.1575e-01,  1.2523e-01, -1.6775e-01,\n          2.4640e-02,  1.6163e-01, -5.9662e-02,  3.6545e-02, -2.1052e-01,\n         -1.0908e-01, -1.6699e-01, -3.3848e-02,  1.8562e-01,  3.9008e-02],\n        [ 7.9296e-02,  3.7466e-02, -1.1697e-01, -9.1109e-02, -1.2708e-01,\n         -8.4812e-02, -8.5428e-02,  1.3477e-01, -4.8135e-02,  1.2473e-01,\n         -6.7512e-02, -1.0656e-01,  1.0663e-01,  1.5141e-02, -1.5193e-01,\n         -1.5142e-01,  3.5797e-03, -2.3196e-02, -1.9449e-01, -5.1001e-02],\n        [ 2.1943e-01,  6.4433e-03, -2.0921e-01,  1.0548e-01, -6.6222e-02,\n          1.8550e-01,  4.3203e-02,  1.6147e-01, -1.0471e-01, -1.4825e-01,\n         -2.1356e-02, -4.3135e-02,  2.1218e-01,  8.9535e-02, -1.6806e-01,\n         -6.6597e-02,  1.3848e-01,  1.2523e-02,  2.2340e-01, -1.6402e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2119, -0.1523, -0.1008, -0.1497,  0.0423,  0.0477,  0.2099, -0.1319,\n         0.0633,  0.0488,  0.1990, -0.0241,  0.1088, -0.1036, -0.1329,  0.1307,\n        -0.1507, -0.0875,  0.2201,  0.1642, -0.1280,  0.2216,  0.0533,  0.1193,\n        -0.1292, -0.0096,  0.0354,  0.0817, -0.1263,  0.1407, -0.1615, -0.1268],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1282, -0.1412, -0.1530, -0.0410, -0.0721, -0.1756, -0.1112, -0.0127,\n         -0.1663, -0.1336, -0.1032,  0.1536,  0.0914, -0.0366,  0.1642, -0.0684,\n         -0.1274,  0.1101, -0.0417, -0.0437,  0.1653,  0.0589,  0.1525,  0.0610,\n          0.1402, -0.0084, -0.1714, -0.1717,  0.1332,  0.0653, -0.0038, -0.1491],\n        [ 0.0320, -0.0173,  0.0628,  0.1560,  0.0796, -0.0009,  0.0448, -0.1672,\n         -0.1497, -0.1184,  0.0981,  0.1455, -0.0143, -0.0934, -0.0911, -0.1328,\n          0.1018, -0.1414,  0.1622, -0.0052,  0.0391, -0.0455,  0.1100, -0.0916,\n          0.0743,  0.0191, -0.1134, -0.1397, -0.0092, -0.0947,  0.0620, -0.0083],\n        [-0.1688, -0.0333, -0.0940,  0.0693,  0.0250,  0.1387, -0.1072,  0.1357,\n          0.1344,  0.0881,  0.1289,  0.0159, -0.0004,  0.0843, -0.0248, -0.0627,\n         -0.1091,  0.0547,  0.1738,  0.1481, -0.1690,  0.0029, -0.1294,  0.0388,\n         -0.1374, -0.0315, -0.0626, -0.0212, -0.0117,  0.0675,  0.1344, -0.1501],\n        [-0.1468,  0.0735, -0.1597, -0.1461,  0.0920,  0.0170,  0.0833,  0.0294,\n         -0.1738, -0.1175, -0.1758, -0.1475,  0.1305, -0.1195, -0.0327,  0.1185,\n          0.1025, -0.0925,  0.0756, -0.1664, -0.0391,  0.0278, -0.0942,  0.0493,\n         -0.1727,  0.0219, -0.0170,  0.1119,  0.0647, -0.0324,  0.1648, -0.0570],\n        [ 0.1033,  0.1495,  0.1389, -0.1360,  0.0203,  0.0579, -0.0618,  0.1671,\n          0.0218, -0.0642, -0.1280, -0.0624,  0.0948, -0.0581,  0.1556, -0.0623,\n         -0.0384, -0.1672,  0.0975,  0.1343, -0.1753, -0.1043, -0.1639,  0.1743,\n         -0.1524, -0.1767, -0.0383, -0.0575,  0.0773,  0.1768, -0.1346, -0.0604],\n        [-0.0755, -0.0745,  0.1556,  0.1481,  0.0643, -0.1486,  0.1398, -0.0785,\n          0.0302, -0.1268,  0.0077,  0.0787,  0.0919,  0.1506,  0.1344,  0.0719,\n         -0.0087,  0.0989, -0.0895,  0.0214, -0.1386, -0.0436, -0.0977,  0.0350,\n          0.0425, -0.0318,  0.1672,  0.1082, -0.1039, -0.1145,  0.1328, -0.0268],\n        [ 0.0762,  0.1391,  0.0574,  0.0977,  0.0463,  0.0781, -0.0929,  0.0538,\n          0.1061, -0.0126, -0.0820,  0.0769,  0.0741, -0.1580,  0.0329, -0.1724,\n         -0.1125,  0.0633,  0.0485, -0.0365,  0.1127, -0.1304,  0.0331, -0.1318,\n         -0.1706,  0.0345, -0.1595, -0.0807, -0.1624, -0.0406, -0.1461,  0.0071],\n        [-0.0834, -0.0881, -0.0423, -0.0320,  0.0802, -0.1500,  0.0332,  0.1302,\n          0.0059, -0.0555, -0.0914, -0.0083,  0.1762, -0.0786, -0.0941, -0.0558,\n         -0.0831,  0.1708,  0.1126,  0.1451,  0.0524, -0.1463,  0.0056, -0.0504,\n          0.0228, -0.0169,  0.0730,  0.0946, -0.1263, -0.0358,  0.0516,  0.1072],\n        [-0.1216,  0.1674,  0.1749,  0.1644,  0.1704, -0.0542, -0.0439,  0.1307,\n          0.0825, -0.1024,  0.0488, -0.1565,  0.1175,  0.1096,  0.0680,  0.0619,\n         -0.0179,  0.0886,  0.0164,  0.0165,  0.0478, -0.1328,  0.0916, -0.0639,\n          0.1045, -0.0922,  0.1294, -0.0799, -0.0507,  0.1103,  0.1524, -0.0710],\n        [ 0.0964,  0.1072, -0.1688, -0.0223, -0.0565, -0.1199,  0.1585,  0.1728,\n         -0.0474, -0.0388,  0.0595,  0.0286, -0.0938, -0.1362,  0.0348,  0.0645,\n          0.1615,  0.0453, -0.1023, -0.0171, -0.0978, -0.0232,  0.1560, -0.1063,\n          0.1575, -0.0649,  0.0512, -0.1586, -0.1359, -0.1730,  0.1085, -0.0983],\n        [ 0.1340,  0.1275,  0.0661, -0.1625,  0.0486, -0.0682,  0.0155, -0.0795,\n         -0.1169, -0.1335, -0.0402,  0.0056,  0.1530,  0.1189, -0.0698,  0.0777,\n          0.1265, -0.1446, -0.0332, -0.0833, -0.1626,  0.0912, -0.1567,  0.0243,\n         -0.0814, -0.0374, -0.1637,  0.0104, -0.0139, -0.0364, -0.0567, -0.0334],\n        [-0.0284, -0.0238,  0.1667, -0.1653,  0.0949, -0.1699,  0.0094, -0.0012,\n          0.0776,  0.0298,  0.1760, -0.1440,  0.1346,  0.0812,  0.0270,  0.1674,\n          0.1201, -0.0419, -0.0127, -0.0210,  0.0033,  0.1082,  0.0905, -0.0336,\n          0.1270,  0.1538, -0.1066,  0.0368, -0.0170, -0.0384,  0.0641, -0.1636],\n        [ 0.0423,  0.0031, -0.0618,  0.0839, -0.0932, -0.1041,  0.0763,  0.0602,\n          0.0875,  0.0274,  0.1230,  0.0670, -0.0856, -0.0090,  0.0922,  0.0668,\n         -0.1066, -0.1527, -0.1366, -0.1394, -0.1107, -0.0156,  0.0535,  0.0218,\n          0.1678, -0.1631,  0.1155,  0.0691,  0.0560,  0.0610, -0.0009, -0.1761],\n        [-0.1041,  0.0519,  0.0533,  0.0359,  0.1051, -0.0874,  0.1293,  0.1305,\n          0.0166,  0.1076,  0.0813,  0.1713,  0.0240,  0.0209,  0.1198, -0.0042,\n         -0.0255,  0.0558, -0.0947,  0.0045, -0.1236,  0.0572, -0.0337, -0.0192,\n          0.0607,  0.1468,  0.1561,  0.0392, -0.0443, -0.0632,  0.1383, -0.1300],\n        [-0.1108,  0.1734,  0.0483,  0.0058,  0.0183, -0.1411,  0.0473,  0.0388,\n         -0.1587, -0.0603, -0.0896,  0.0572,  0.0320, -0.0078,  0.0781,  0.1704,\n          0.0447, -0.0455, -0.1605,  0.1224, -0.1087, -0.1480,  0.1159,  0.0059,\n         -0.0575,  0.1120,  0.1578,  0.0302, -0.0008, -0.0379, -0.0454,  0.1542],\n        [-0.1497, -0.1344, -0.1018, -0.1610, -0.1083, -0.0946, -0.1680, -0.0375,\n          0.1329, -0.0916,  0.0398, -0.1603,  0.0304,  0.0092,  0.0149,  0.0639,\n          0.0073, -0.0769, -0.1321,  0.0854, -0.1359, -0.0991, -0.1047,  0.1594,\n          0.1387,  0.0219,  0.0348, -0.0325, -0.0303, -0.1715, -0.1311,  0.1316]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1084,  0.1017, -0.0761,  0.0729, -0.0573,  0.0944, -0.0464,  0.1155,\n        -0.0528, -0.1645,  0.1531,  0.1683,  0.0705,  0.0302,  0.0237, -0.0847],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0593,  0.1082, -0.0516, -0.0249,  0.1849, -0.0152, -0.1963,  0.0783,\n         -0.0097, -0.0494,  0.2050, -0.0709, -0.1936,  0.2399,  0.0007, -0.0387],\n        [-0.0281,  0.2043, -0.1098, -0.2091,  0.1671, -0.1123,  0.0665, -0.0327,\n          0.1693,  0.1659, -0.0872, -0.0081, -0.0848,  0.1288,  0.2173,  0.0131],\n        [-0.0871,  0.1445,  0.0553, -0.1660,  0.1140, -0.1585,  0.1822, -0.2115,\n          0.1293,  0.0595,  0.1035, -0.1942,  0.0536,  0.2250, -0.0236, -0.1945],\n        [ 0.0281, -0.2204,  0.1103,  0.2243,  0.2235,  0.0458,  0.1875,  0.2244,\n         -0.2372,  0.0543,  0.0689, -0.2251, -0.0170, -0.1959, -0.1521, -0.0862],\n        [-0.0084, -0.1614,  0.0460, -0.0837,  0.1245,  0.1177,  0.0137,  0.2175,\n          0.2423,  0.0926,  0.1606,  0.2277, -0.0406,  0.0084, -0.2115,  0.0572],\n        [ 0.1480,  0.1152,  0.0522,  0.0636, -0.1408, -0.2441, -0.0342,  0.1209,\n          0.2416, -0.0878,  0.1921, -0.1835, -0.2448,  0.2289, -0.2213,  0.0448],\n        [-0.0974, -0.0327,  0.1031, -0.0216, -0.1068,  0.1613, -0.0490, -0.1172,\n          0.0574,  0.0347, -0.0660, -0.1354, -0.2413, -0.0929, -0.0243,  0.2412],\n        [ 0.1016, -0.2215, -0.1707, -0.0200, -0.1223, -0.2214,  0.0760,  0.1962,\n         -0.1411, -0.1474, -0.2148, -0.0429, -0.0513, -0.1329, -0.1582,  0.0601]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2404, -0.0359,  0.1721, -0.1401, -0.0932,  0.1277, -0.2296,  0.0955],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1146,  0.2538,  0.2588,  0.0493,  0.1345, -0.0282, -0.3454,  0.1810]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0249], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x00000161A4E6F820>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x00000161A421E860>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s304120000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='D:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\maze-game\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s304120000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}