{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s46050000"
    },
    "q_lr":	0.0005,
    "seed":	46050000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x11c4d4c10>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0132, -0.0022, -0.2048, -0.2132,  0.1772, -0.2038,  0.1266,  0.1728,\n        -0.1288, -0.0656, -0.1622,  0.1286,  0.0196,  0.1574, -0.1381,  0.1880,\n         0.1030, -0.2167, -0.1880, -0.1798,  0.2019, -0.1472,  0.1413,  0.0296,\n         0.1637, -0.1144,  0.1737,  0.0728, -0.1524, -0.1274, -0.0261,  0.0172],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-5.3749e-02,  1.0113e-01, -3.7907e-02, -1.4744e-01, -1.6954e-01,\n          6.9015e-02,  1.1372e-01,  1.1466e-01,  1.6194e-01, -9.0520e-02,\n         -2.1780e-01, -1.9283e-03, -1.9895e-02,  1.2029e-01,  1.4378e-01,\n          1.4449e-01, -2.1693e-01, -1.4163e-02, -3.4642e-02,  1.5389e-03],\n        [-1.6503e-01, -1.6293e-01, -7.4006e-02,  5.9165e-02, -1.8182e-01,\n         -1.6744e-01,  2.5374e-02, -9.9648e-03,  5.7618e-02,  1.0325e-01,\n         -3.2232e-02,  1.5692e-02, -1.8367e-02, -1.7559e-01,  1.4653e-01,\n          1.4535e-01, -6.2744e-02, -9.3188e-02, -1.4042e-01, -4.6674e-02],\n        [-1.4510e-01,  7.5927e-02, -1.8009e-01,  1.8271e-01, -1.6587e-01,\n         -2.1252e-01, -1.1136e-01,  1.0025e-01,  1.2394e-01, -1.3018e-01,\n          8.6976e-02, -6.9949e-02,  2.7669e-02,  9.6295e-02, -1.9642e-01,\n          2.9138e-02,  1.9780e-01,  1.4259e-01,  2.1463e-01,  9.2088e-02],\n        [-1.1932e-01, -1.6128e-01, -1.8501e-01,  1.6718e-01,  9.3579e-02,\n         -1.5669e-01, -2.0750e-01, -9.8139e-02, -5.3044e-02, -9.3488e-02,\n          1.6369e-01, -1.1146e-01,  5.2175e-02,  2.2300e-01, -6.8767e-02,\n          9.1444e-02, -1.4113e-01, -1.8191e-02, -2.1519e-01,  2.1045e-04],\n        [ 1.9951e-01, -7.7208e-02, -2.1683e-01,  1.4142e-01, -2.1487e-01,\n          2.1430e-01, -1.6944e-01, -1.2248e-01, -4.7590e-02,  1.6889e-01,\n         -3.9041e-02,  9.5153e-02, -1.6138e-01, -3.2379e-02, -1.8296e-01,\n          8.3799e-02, -6.1201e-02,  1.7446e-02, -1.4281e-01, -1.8740e-01],\n        [-1.0583e-02,  5.3733e-02, -3.7154e-02, -6.1085e-02,  1.4145e-01,\n         -8.9504e-02, -7.2689e-02, -6.7777e-02, -1.8699e-01, -1.5119e-01,\n         -2.3395e-03,  2.0771e-01, -1.0976e-02, -2.3110e-02, -1.5970e-01,\n         -8.8439e-02, -7.4671e-02, -1.3872e-02, -8.5645e-03, -2.0159e-01],\n        [-7.2551e-02, -2.0225e-02,  1.6145e-01, -1.2753e-01, -3.3584e-02,\n         -1.0085e-01, -5.6007e-02,  6.9461e-02, -1.3786e-01, -9.8979e-02,\n         -5.3250e-02, -5.4035e-03, -3.5305e-02,  9.6219e-02, -2.0301e-01,\n         -8.3321e-02,  1.2945e-01, -3.8782e-02,  1.9361e-01, -1.6477e-01],\n        [ 5.4795e-02,  1.6964e-01,  1.7925e-01,  1.5156e-01, -1.3173e-01,\n         -1.2911e-01, -1.6463e-01,  4.3711e-02, -1.2453e-01, -6.6562e-02,\n          3.6622e-02, -1.0846e-01, -8.2802e-02, -1.8988e-01,  5.0850e-02,\n         -2.1277e-01,  2.0770e-01,  8.4401e-02, -1.5456e-01, -2.2271e-01],\n        [-1.8541e-01, -3.6789e-02,  5.0050e-02,  1.9543e-01,  1.0186e-01,\n          4.0874e-02, -1.0986e-02,  2.2215e-01,  4.9315e-02,  2.5910e-02,\n          1.8038e-01, -1.5018e-01,  2.0918e-02, -1.9651e-01,  1.0982e-01,\n         -2.1799e-01,  1.8935e-01, -1.0823e-01,  1.6001e-01,  7.0493e-02],\n        [ 1.9529e-01,  1.4897e-01,  5.6350e-02,  1.7871e-01, -6.8130e-02,\n         -1.2939e-01,  8.2365e-02, -1.2057e-01,  1.3545e-02, -9.4430e-02,\n          8.3120e-02,  1.5347e-01,  1.0945e-01, -1.5085e-02,  1.4602e-01,\n         -1.2281e-01, -1.3331e-01,  1.5218e-01,  1.5263e-01, -1.7926e-01],\n        [-1.7371e-01, -9.7329e-03,  1.9314e-02,  8.1958e-02, -9.7848e-02,\n          8.1368e-02,  1.1385e-01,  2.0638e-01,  1.0327e-01, -4.4945e-03,\n         -5.3968e-02, -8.0128e-02,  2.1723e-01,  6.8614e-02,  1.5689e-02,\n         -1.2811e-01,  6.2361e-02, -8.1178e-02, -3.9241e-02,  1.9265e-01],\n        [ 9.7757e-02,  1.4605e-01, -2.0338e-02,  1.1816e-01, -1.6679e-01,\n          1.6808e-01,  5.6342e-02,  1.4739e-01, -2.0225e-01,  1.9546e-01,\n         -1.3089e-02,  2.1384e-01,  1.2197e-01,  1.4698e-01,  1.5840e-01,\n         -2.0410e-01, -6.9644e-02, -8.3265e-02, -8.2710e-03,  1.4354e-01],\n        [-1.1236e-01,  3.3016e-03,  2.2129e-01,  1.9314e-02, -4.9334e-02,\n         -1.5579e-02, -4.3814e-03, -4.2481e-02,  1.4714e-01, -1.4293e-01,\n         -1.4306e-01, -2.0430e-01, -1.9663e-01, -6.5244e-02, -1.8233e-01,\n          3.7294e-03,  8.0684e-02, -4.0420e-03,  2.0603e-01, -1.0116e-01],\n        [-1.3325e-01,  1.8049e-01,  4.8905e-02,  6.5038e-02,  1.2107e-01,\n          1.6685e-01, -2.1672e-01,  2.0306e-01, -1.9783e-01, -2.0882e-01,\n         -1.4076e-01,  1.9573e-01, -1.7388e-01,  8.7341e-04,  2.0236e-01,\n         -1.4878e-01,  2.1908e-01, -1.7695e-03, -5.3863e-02,  4.4538e-02],\n        [ 1.0461e-02, -1.6121e-01, -1.4344e-01,  5.3962e-02,  3.5626e-03,\n         -4.3937e-02,  2.0608e-01,  1.2560e-01,  1.3725e-01, -1.6905e-01,\n         -3.3159e-02,  8.2384e-02, -1.4143e-01, -7.1052e-02,  1.7418e-01,\n         -7.7098e-02, -3.9167e-02,  6.8172e-02,  2.0340e-01,  2.0464e-01],\n        [-7.5520e-02, -1.8064e-01,  7.8043e-02,  2.0194e-01, -1.1223e-01,\n          1.0779e-01,  1.4454e-01,  1.5421e-01, -1.7841e-02,  5.2688e-02,\n         -4.1450e-02, -1.4622e-01, -3.1499e-03,  9.3496e-02,  1.7833e-02,\n         -9.9630e-02,  1.9844e-01,  2.0281e-01,  1.1962e-01,  2.1295e-01],\n        [ 2.7852e-02, -1.7726e-01,  2.1245e-01, -2.0489e-01,  1.0447e-01,\n          1.4091e-01, -1.8938e-01,  8.5441e-02, -1.6670e-01,  1.2760e-01,\n         -3.8561e-02,  1.7702e-01, -7.2857e-02, -9.9687e-02,  1.7749e-01,\n          2.0898e-01, -1.8388e-01, -1.4835e-01, -1.8239e-01,  1.9271e-02],\n        [-4.8998e-02,  1.6432e-01,  1.7289e-02, -1.0493e-01, -1.4980e-01,\n          1.0752e-01, -4.3299e-02, -8.8836e-02,  1.9519e-01,  1.3078e-01,\n         -2.1072e-01, -3.1793e-03, -1.0081e-01, -4.1999e-02,  6.0346e-02,\n          1.5379e-01, -4.2214e-02, -1.4408e-01, -1.5247e-01, -6.7084e-02],\n        [ 1.6612e-01,  8.7984e-02,  1.5139e-01, -2.0442e-02,  1.6338e-01,\n          1.7600e-01,  1.0771e-01, -5.0974e-02,  7.2336e-02,  1.3141e-01,\n          2.1393e-01, -9.0828e-02, -1.8195e-01,  2.1397e-01,  1.3399e-01,\n         -1.9628e-01, -3.1212e-02, -3.4626e-02,  1.7013e-01,  2.1038e-01],\n        [ 2.0218e-01, -7.8646e-02, -5.5321e-02,  6.0469e-02, -2.1408e-01,\n         -7.9680e-02,  7.8484e-02,  1.2169e-01,  4.9811e-02, -1.0746e-01,\n          1.0440e-01, -1.5149e-03,  1.0720e-01, -1.5967e-01, -1.3729e-01,\n         -2.6573e-02, -2.1602e-01,  2.1239e-01, -1.6244e-01,  4.2610e-02],\n        [-8.1080e-02, -1.4105e-01, -1.1460e-01, -7.1222e-02, -3.7057e-02,\n         -1.0240e-01, -1.6370e-01, -1.9282e-01,  8.5257e-02,  2.2007e-01,\n         -5.7330e-02, -1.3530e-02,  4.2319e-02,  1.8891e-01,  1.8161e-01,\n          1.3626e-03, -2.0583e-01, -2.3443e-02, -1.0546e-01, -2.1260e-01],\n        [-1.5915e-02,  1.4937e-02,  5.7315e-02,  4.3044e-02, -8.7345e-02,\n         -1.5716e-01, -1.0995e-01,  1.9150e-01,  3.7137e-02, -6.2160e-02,\n         -1.6357e-01, -4.7182e-02, -1.0617e-01,  1.9915e-01,  8.5879e-03,\n          1.1535e-01, -2.1511e-01,  1.4155e-01, -9.8532e-02,  9.5955e-02],\n        [-3.3832e-02, -1.3212e-01,  1.7458e-01, -1.7829e-01,  5.2308e-02,\n         -1.1183e-01,  1.7335e-01, -4.6448e-02,  2.0756e-01,  1.7581e-01,\n          8.1413e-02, -1.3823e-01,  1.9650e-01, -5.3158e-02,  1.4024e-01,\n         -1.2148e-01, -1.4905e-01,  4.1748e-03,  4.3586e-02,  1.0745e-01],\n        [ 1.6109e-01, -1.0625e-01,  2.1989e-01, -1.5057e-02,  1.3698e-01,\n         -6.5055e-02, -6.7254e-02, -9.0496e-02,  2.2303e-01,  7.4862e-02,\n         -6.4449e-02, -2.0635e-01,  9.4844e-02, -1.7447e-01,  3.4648e-02,\n         -1.7115e-01,  5.7758e-02, -6.7421e-03,  5.5604e-02, -8.5631e-02],\n        [-7.6825e-02, -1.8070e-02, -2.1444e-01,  7.4898e-02,  4.2782e-02,\n          8.3769e-02, -1.5982e-01, -7.6690e-02,  1.6364e-01, -4.2199e-02,\n          9.5334e-02,  1.5025e-03, -3.5858e-02, -2.0026e-01,  1.8680e-01,\n          2.2329e-01, -2.3954e-02, -1.1049e-01,  1.8063e-02,  8.2318e-02],\n        [-2.4238e-04, -1.3116e-01,  5.1261e-02, -9.1511e-02, -1.4772e-01,\n          1.9197e-01,  1.4967e-01, -1.9627e-01, -1.2653e-01, -1.2468e-01,\n         -2.1589e-01, -1.7260e-01, -5.0253e-02, -2.0797e-01, -2.1876e-01,\n         -6.0009e-02,  1.8906e-01,  1.5859e-01, -1.2176e-01, -3.5790e-02],\n        [-2.2263e-01, -5.8407e-02, -1.3627e-01, -4.3919e-02, -1.3217e-01,\n         -1.2322e-01, -1.0430e-01,  7.3719e-02,  8.3871e-02,  1.6012e-01,\n          5.0587e-02, -4.9101e-02,  1.7815e-01,  1.0561e-01,  4.7983e-02,\n          1.1882e-01, -1.2064e-01,  2.0622e-02,  6.8812e-02, -1.7315e-03],\n        [ 1.7748e-02, -8.3768e-02,  1.5165e-01, -7.9791e-02,  7.5609e-02,\n          7.3363e-02, -5.1852e-02, -5.0695e-02,  2.1876e-01, -1.7935e-01,\n          1.5235e-01,  5.8742e-03, -1.2910e-01, -1.4605e-01,  3.9830e-02,\n          1.3263e-01, -1.8286e-01, -1.2965e-01,  1.9484e-01, -1.9859e-01],\n        [ 1.4104e-01,  3.1234e-02, -7.1541e-02, -2.1062e-01,  1.4191e-01,\n         -1.0620e-01,  9.7220e-02, -1.0709e-01,  2.1025e-01, -7.0477e-02,\n          1.3389e-01,  4.0698e-02, -1.8128e-01, -4.8961e-02,  1.3686e-01,\n         -2.1366e-01, -1.8718e-02,  2.0222e-01, -5.4114e-02, -1.1247e-01],\n        [-6.9095e-03,  1.1970e-02, -2.1508e-01, -1.0962e-01, -1.0092e-01,\n         -4.7002e-02, -8.1838e-02, -3.9934e-02,  2.9581e-02,  2.2086e-01,\n          8.6389e-02,  3.3233e-02, -5.5578e-02,  1.5374e-01,  3.6954e-02,\n          1.9792e-01,  1.7214e-02,  1.2977e-01, -8.1254e-02, -2.5350e-04],\n        [-2.2314e-01,  1.6552e-01,  8.9655e-02,  9.7286e-02, -1.8976e-01,\n         -5.1284e-02,  1.9527e-01,  1.7802e-01,  1.3754e-01,  1.8339e-01,\n         -1.0964e-01,  7.6759e-02,  7.9693e-02,  2.4062e-02, -1.7484e-01,\n          1.5048e-01,  9.9600e-02,  1.5852e-01, -1.2123e-01,  2.1282e-01],\n        [-9.3777e-02, -1.5110e-01, -1.9860e-01,  1.1570e-01, -6.2151e-03,\n         -2.1866e-01,  4.2300e-02,  1.5803e-01, -2.2184e-01,  1.7963e-01,\n          1.9876e-01, -8.4602e-02, -3.4895e-02, -5.1683e-02, -1.9219e-01,\n         -1.1931e-01, -1.5465e-01,  1.6956e-01, -2.0472e-01, -9.6133e-02]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1392, -0.1479,  0.0611, -0.1236,  0.0726,  0.1742,  0.1417,  0.1273,\n        -0.0827, -0.1533,  0.1612,  0.0358, -0.0149, -0.1044, -0.1679, -0.0578],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1292,  0.0590,  0.0766,  0.0607, -0.0471, -0.0099,  0.1755, -0.0088,\n         -0.1579,  0.1682,  0.1342,  0.1152,  0.1062,  0.0281, -0.0933,  0.0248,\n         -0.1623, -0.0498, -0.1212,  0.0989,  0.0833, -0.1591, -0.0204,  0.1614,\n         -0.0044, -0.1224, -0.0638,  0.0012, -0.0168, -0.0151,  0.0126, -0.0007],\n        [-0.0985,  0.0595,  0.0490,  0.1154, -0.0618,  0.0058,  0.0086,  0.0580,\n         -0.1748,  0.1398,  0.0163,  0.0861, -0.0092,  0.1741, -0.0361, -0.1215,\n          0.0246,  0.0508, -0.0439, -0.1448,  0.0665, -0.0443,  0.0096,  0.0153,\n         -0.1099, -0.1016, -0.0402, -0.0480, -0.1060,  0.1215,  0.0685,  0.0340],\n        [ 0.0475, -0.0226,  0.0619, -0.1225, -0.0728, -0.1278, -0.0263, -0.1634,\n          0.1567, -0.1421, -0.0502, -0.1530, -0.1717, -0.1653, -0.0911,  0.0077,\n         -0.0727,  0.0509,  0.1061, -0.0547,  0.0904,  0.0593, -0.0634,  0.0377,\n         -0.0263, -0.0087, -0.0043,  0.0183, -0.1420, -0.1520, -0.1185,  0.0703],\n        [-0.0039,  0.0112, -0.1420, -0.1357, -0.0677, -0.1225, -0.0432, -0.0893,\n         -0.0980,  0.0613, -0.0560, -0.1583,  0.0606,  0.0904,  0.1492, -0.1346,\n          0.0701,  0.1336, -0.1499, -0.0630,  0.0442, -0.1455, -0.0801, -0.0212,\n          0.1504, -0.1462, -0.0495, -0.1385, -0.1032, -0.0025, -0.1644,  0.1082],\n        [-0.0163, -0.0801,  0.1587, -0.0634, -0.1571,  0.0215, -0.1192, -0.1000,\n         -0.1672, -0.1124, -0.1161, -0.0823, -0.1048,  0.1744, -0.1266,  0.0977,\n          0.0029,  0.0969, -0.0680,  0.0612,  0.0742, -0.1302, -0.0160,  0.1331,\n         -0.1004,  0.0662,  0.1436, -0.0009, -0.0556, -0.0425, -0.0296,  0.1205],\n        [ 0.1728, -0.0307, -0.0453,  0.0766, -0.0005,  0.1586,  0.0365, -0.0727,\n          0.1357,  0.1340,  0.1760, -0.0980, -0.0784, -0.1454,  0.1547, -0.0962,\n         -0.0643,  0.0526,  0.0233,  0.1036,  0.0404,  0.0768,  0.1020, -0.1020,\n         -0.0963,  0.1309,  0.1333,  0.0650, -0.1472, -0.0013, -0.1233,  0.1702],\n        [-0.0330, -0.1313, -0.1696,  0.0621,  0.1711,  0.1622,  0.1174, -0.0294,\n          0.0063,  0.1137, -0.1330,  0.0771,  0.1007,  0.0100, -0.1239, -0.1183,\n         -0.1621,  0.0067, -0.1599, -0.0309, -0.1204, -0.0126, -0.1608,  0.1076,\n          0.0175, -0.0776,  0.0371,  0.0707,  0.0016, -0.0741,  0.0373,  0.0385],\n        [ 0.0771,  0.0615,  0.1708, -0.0133,  0.1262,  0.0667, -0.0023, -0.0290,\n         -0.0982, -0.0047, -0.1165,  0.0368, -0.0223, -0.1681, -0.1565,  0.0271,\n          0.1255, -0.0365, -0.1700, -0.0751, -0.0230,  0.1125, -0.1054,  0.1377,\n         -0.1599,  0.1449,  0.0569,  0.0737, -0.0690,  0.1115, -0.0582, -0.0726],\n        [ 0.1112, -0.0055, -0.0619,  0.0911, -0.0187,  0.0191, -0.0789, -0.0806,\n         -0.0458,  0.1708,  0.1560, -0.1418,  0.1275,  0.1337,  0.1001, -0.1642,\n          0.0647, -0.1092, -0.0292,  0.0258,  0.0625,  0.0296,  0.0020, -0.0226,\n         -0.0901, -0.0615, -0.1481, -0.0474,  0.1105,  0.1417, -0.1172,  0.1536],\n        [-0.1117, -0.0407,  0.1351, -0.1242,  0.0411,  0.0427,  0.0850,  0.1221,\n          0.1227,  0.0531,  0.1149, -0.0804, -0.1070,  0.0306, -0.0452, -0.1047,\n          0.0239,  0.1551,  0.0559,  0.0622, -0.0240,  0.1689, -0.1047, -0.1114,\n          0.1645, -0.1058,  0.1381, -0.0367, -0.1591,  0.0486, -0.0181,  0.1665],\n        [-0.0466, -0.1074,  0.0583,  0.1754,  0.0156,  0.0520, -0.0440,  0.0272,\n          0.1430, -0.0417,  0.0950, -0.0868,  0.0551, -0.0355,  0.0618,  0.0585,\n          0.0234, -0.1070, -0.0928,  0.0956,  0.0025, -0.1739, -0.0770, -0.0419,\n         -0.0041,  0.0852,  0.0382, -0.0169,  0.1143, -0.0290,  0.0420, -0.0558],\n        [ 0.1257,  0.0373, -0.0909, -0.1022,  0.1107,  0.1071, -0.0002, -0.0955,\n          0.1213,  0.1330, -0.1749,  0.1571,  0.0118, -0.0976,  0.0896, -0.0938,\n         -0.1195, -0.0367,  0.0995,  0.0120,  0.0225, -0.0140,  0.1689, -0.1548,\n         -0.0556,  0.0175,  0.1103,  0.0638,  0.1199,  0.1632, -0.0237, -0.1473],\n        [ 0.0547, -0.0437, -0.0250, -0.1052,  0.0780,  0.0789,  0.0240,  0.0246,\n          0.1238,  0.0250, -0.1333,  0.1439,  0.1443, -0.1735, -0.1006,  0.0965,\n          0.1529, -0.0438,  0.0498,  0.0946,  0.1194,  0.1363,  0.0040, -0.0175,\n          0.0289, -0.0066,  0.1040,  0.1690, -0.0745, -0.1428, -0.0981,  0.1225],\n        [ 0.1529,  0.1345,  0.1117,  0.0627,  0.1161, -0.0636, -0.0687,  0.1724,\n          0.1132, -0.1315, -0.0414,  0.1467, -0.0055, -0.0213,  0.1649,  0.0893,\n         -0.1422, -0.1050,  0.0880, -0.0018, -0.0396,  0.0322, -0.0672,  0.1206,\n         -0.1729, -0.0135, -0.0485,  0.1024, -0.0747, -0.0823,  0.0369, -0.1101],\n        [-0.0959,  0.0876,  0.1044, -0.1754,  0.1706,  0.0750, -0.1018,  0.1123,\n          0.0657, -0.0609,  0.1368, -0.0744, -0.1182, -0.1251, -0.1760, -0.0801,\n          0.1685,  0.0739,  0.0345,  0.1704, -0.1242,  0.0638,  0.0152, -0.0859,\n         -0.0643,  0.0647,  0.0589, -0.1435, -0.0437, -0.0147, -0.1482,  0.0323],\n        [ 0.1688, -0.0618,  0.0616,  0.0468,  0.0841, -0.0522, -0.1117,  0.0978,\n          0.1353,  0.0739, -0.1239, -0.1724, -0.0067, -0.0608, -0.1222, -0.0438,\n         -0.1660,  0.1351, -0.0992,  0.0858,  0.0232, -0.0608,  0.1696,  0.0324,\n          0.0662, -0.0469, -0.0612, -0.0813,  0.1194,  0.0420,  0.1614,  0.1735]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0446,  0.0153,  0.0871,  0.0971, -0.1912,  0.0581, -0.1865, -0.2408],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0999, -0.1488, -0.1097,  0.0209, -0.1558, -0.0797, -0.2444, -0.1423,\n         -0.1197, -0.0078, -0.1468,  0.1721,  0.0025, -0.2384, -0.0534, -0.0977],\n        [ 0.0422,  0.1639,  0.0732, -0.1567,  0.1816, -0.1906, -0.0868,  0.1766,\n          0.1697,  0.0270,  0.0912,  0.0836, -0.1784,  0.0505, -0.2233,  0.0577],\n        [ 0.1975, -0.0772,  0.1129, -0.2228,  0.1231, -0.0939, -0.1891, -0.1542,\n         -0.0920, -0.0288,  0.0798, -0.2451, -0.0173, -0.0772,  0.2330, -0.2383],\n        [ 0.1076, -0.1566, -0.1623, -0.0352,  0.1323, -0.2315, -0.2039, -0.1854,\n          0.1671, -0.2382,  0.0146, -0.2226,  0.0065, -0.1733,  0.1110,  0.1579],\n        [ 0.0244,  0.0058,  0.1860,  0.2193,  0.0590, -0.0145, -0.0657, -0.0497,\n         -0.2066,  0.1208, -0.0620, -0.1728, -0.1800, -0.0744, -0.1387, -0.2304],\n        [ 0.1338,  0.0783, -0.0907,  0.0041, -0.1066, -0.1161,  0.0422,  0.0702,\n          0.1168,  0.1118,  0.0536,  0.2460,  0.0938,  0.2107,  0.0984,  0.0608],\n        [-0.2063, -0.0363, -0.1389, -0.1553,  0.0061,  0.1627, -0.0562,  0.1250,\n          0.1321, -0.0457, -0.0181, -0.0373, -0.0939,  0.2179, -0.0173,  0.0420],\n        [-0.0949, -0.0547, -0.0613,  0.0904,  0.1138, -0.1462, -0.0060,  0.1391,\n         -0.1915,  0.0057,  0.0095, -0.2263,  0.1648, -0.0923,  0.0209, -0.2178]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1703], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3278,  0.3275, -0.2768,  0.2134,  0.3460,  0.2709,  0.1981,  0.1050]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-5.3749e-02,  1.0113e-01, -3.7907e-02, -1.4744e-01, -1.6954e-01,\n          6.9015e-02,  1.1372e-01,  1.1466e-01,  1.6194e-01, -9.0520e-02,\n         -2.1780e-01, -1.9283e-03, -1.9895e-02,  1.2029e-01,  1.4378e-01,\n          1.4449e-01, -2.1693e-01, -1.4163e-02, -3.4642e-02,  1.5389e-03],\n        [-1.6503e-01, -1.6293e-01, -7.4006e-02,  5.9165e-02, -1.8182e-01,\n         -1.6744e-01,  2.5374e-02, -9.9648e-03,  5.7618e-02,  1.0325e-01,\n         -3.2232e-02,  1.5692e-02, -1.8367e-02, -1.7559e-01,  1.4653e-01,\n          1.4535e-01, -6.2744e-02, -9.3188e-02, -1.4042e-01, -4.6674e-02],\n        [-1.4510e-01,  7.5927e-02, -1.8009e-01,  1.8271e-01, -1.6587e-01,\n         -2.1252e-01, -1.1136e-01,  1.0025e-01,  1.2394e-01, -1.3018e-01,\n          8.6976e-02, -6.9949e-02,  2.7669e-02,  9.6295e-02, -1.9642e-01,\n          2.9138e-02,  1.9780e-01,  1.4259e-01,  2.1463e-01,  9.2088e-02],\n        [-1.1932e-01, -1.6128e-01, -1.8501e-01,  1.6718e-01,  9.3579e-02,\n         -1.5669e-01, -2.0750e-01, -9.8139e-02, -5.3044e-02, -9.3488e-02,\n          1.6369e-01, -1.1146e-01,  5.2175e-02,  2.2300e-01, -6.8767e-02,\n          9.1444e-02, -1.4113e-01, -1.8191e-02, -2.1519e-01,  2.1045e-04],\n        [ 1.9951e-01, -7.7208e-02, -2.1683e-01,  1.4142e-01, -2.1487e-01,\n          2.1430e-01, -1.6944e-01, -1.2248e-01, -4.7590e-02,  1.6889e-01,\n         -3.9041e-02,  9.5153e-02, -1.6138e-01, -3.2379e-02, -1.8296e-01,\n          8.3799e-02, -6.1201e-02,  1.7446e-02, -1.4281e-01, -1.8740e-01],\n        [-1.0583e-02,  5.3733e-02, -3.7154e-02, -6.1085e-02,  1.4145e-01,\n         -8.9504e-02, -7.2689e-02, -6.7777e-02, -1.8699e-01, -1.5119e-01,\n         -2.3395e-03,  2.0771e-01, -1.0976e-02, -2.3110e-02, -1.5970e-01,\n         -8.8439e-02, -7.4671e-02, -1.3872e-02, -8.5645e-03, -2.0159e-01],\n        [-7.2551e-02, -2.0225e-02,  1.6145e-01, -1.2753e-01, -3.3584e-02,\n         -1.0085e-01, -5.6007e-02,  6.9461e-02, -1.3786e-01, -9.8979e-02,\n         -5.3250e-02, -5.4035e-03, -3.5305e-02,  9.6219e-02, -2.0301e-01,\n         -8.3321e-02,  1.2945e-01, -3.8782e-02,  1.9361e-01, -1.6477e-01],\n        [ 5.4795e-02,  1.6964e-01,  1.7925e-01,  1.5156e-01, -1.3173e-01,\n         -1.2911e-01, -1.6463e-01,  4.3711e-02, -1.2453e-01, -6.6562e-02,\n          3.6622e-02, -1.0846e-01, -8.2802e-02, -1.8988e-01,  5.0850e-02,\n         -2.1277e-01,  2.0770e-01,  8.4401e-02, -1.5456e-01, -2.2271e-01],\n        [-1.8541e-01, -3.6789e-02,  5.0050e-02,  1.9543e-01,  1.0186e-01,\n          4.0874e-02, -1.0986e-02,  2.2215e-01,  4.9315e-02,  2.5910e-02,\n          1.8038e-01, -1.5018e-01,  2.0918e-02, -1.9651e-01,  1.0982e-01,\n         -2.1799e-01,  1.8935e-01, -1.0823e-01,  1.6001e-01,  7.0493e-02],\n        [ 1.9529e-01,  1.4897e-01,  5.6350e-02,  1.7871e-01, -6.8130e-02,\n         -1.2939e-01,  8.2365e-02, -1.2057e-01,  1.3545e-02, -9.4430e-02,\n          8.3120e-02,  1.5347e-01,  1.0945e-01, -1.5085e-02,  1.4602e-01,\n         -1.2281e-01, -1.3331e-01,  1.5218e-01,  1.5263e-01, -1.7926e-01],\n        [-1.7371e-01, -9.7329e-03,  1.9314e-02,  8.1958e-02, -9.7848e-02,\n          8.1368e-02,  1.1385e-01,  2.0638e-01,  1.0327e-01, -4.4945e-03,\n         -5.3968e-02, -8.0128e-02,  2.1723e-01,  6.8614e-02,  1.5689e-02,\n         -1.2811e-01,  6.2361e-02, -8.1178e-02, -3.9241e-02,  1.9265e-01],\n        [ 9.7757e-02,  1.4605e-01, -2.0338e-02,  1.1816e-01, -1.6679e-01,\n          1.6808e-01,  5.6342e-02,  1.4739e-01, -2.0225e-01,  1.9546e-01,\n         -1.3089e-02,  2.1384e-01,  1.2197e-01,  1.4698e-01,  1.5840e-01,\n         -2.0410e-01, -6.9644e-02, -8.3265e-02, -8.2710e-03,  1.4354e-01],\n        [-1.1236e-01,  3.3016e-03,  2.2129e-01,  1.9314e-02, -4.9334e-02,\n         -1.5579e-02, -4.3814e-03, -4.2481e-02,  1.4714e-01, -1.4293e-01,\n         -1.4306e-01, -2.0430e-01, -1.9663e-01, -6.5244e-02, -1.8233e-01,\n          3.7294e-03,  8.0684e-02, -4.0420e-03,  2.0603e-01, -1.0116e-01],\n        [-1.3325e-01,  1.8049e-01,  4.8905e-02,  6.5038e-02,  1.2107e-01,\n          1.6685e-01, -2.1672e-01,  2.0306e-01, -1.9783e-01, -2.0882e-01,\n         -1.4076e-01,  1.9573e-01, -1.7388e-01,  8.7341e-04,  2.0236e-01,\n         -1.4878e-01,  2.1908e-01, -1.7695e-03, -5.3863e-02,  4.4538e-02],\n        [ 1.0461e-02, -1.6121e-01, -1.4344e-01,  5.3962e-02,  3.5626e-03,\n         -4.3937e-02,  2.0608e-01,  1.2560e-01,  1.3725e-01, -1.6905e-01,\n         -3.3159e-02,  8.2384e-02, -1.4143e-01, -7.1052e-02,  1.7418e-01,\n         -7.7098e-02, -3.9167e-02,  6.8172e-02,  2.0340e-01,  2.0464e-01],\n        [-7.5520e-02, -1.8064e-01,  7.8043e-02,  2.0194e-01, -1.1223e-01,\n          1.0779e-01,  1.4454e-01,  1.5421e-01, -1.7841e-02,  5.2688e-02,\n         -4.1450e-02, -1.4622e-01, -3.1499e-03,  9.3496e-02,  1.7833e-02,\n         -9.9630e-02,  1.9844e-01,  2.0281e-01,  1.1962e-01,  2.1295e-01],\n        [ 2.7852e-02, -1.7726e-01,  2.1245e-01, -2.0489e-01,  1.0447e-01,\n          1.4091e-01, -1.8938e-01,  8.5441e-02, -1.6670e-01,  1.2760e-01,\n         -3.8561e-02,  1.7702e-01, -7.2857e-02, -9.9687e-02,  1.7749e-01,\n          2.0898e-01, -1.8388e-01, -1.4835e-01, -1.8239e-01,  1.9271e-02],\n        [-4.8998e-02,  1.6432e-01,  1.7289e-02, -1.0493e-01, -1.4980e-01,\n          1.0752e-01, -4.3299e-02, -8.8836e-02,  1.9519e-01,  1.3078e-01,\n         -2.1072e-01, -3.1793e-03, -1.0081e-01, -4.1999e-02,  6.0346e-02,\n          1.5379e-01, -4.2214e-02, -1.4408e-01, -1.5247e-01, -6.7084e-02],\n        [ 1.6612e-01,  8.7984e-02,  1.5139e-01, -2.0442e-02,  1.6338e-01,\n          1.7600e-01,  1.0771e-01, -5.0974e-02,  7.2336e-02,  1.3141e-01,\n          2.1393e-01, -9.0828e-02, -1.8195e-01,  2.1397e-01,  1.3399e-01,\n         -1.9628e-01, -3.1212e-02, -3.4626e-02,  1.7013e-01,  2.1038e-01],\n        [ 2.0218e-01, -7.8646e-02, -5.5321e-02,  6.0469e-02, -2.1408e-01,\n         -7.9680e-02,  7.8484e-02,  1.2169e-01,  4.9811e-02, -1.0746e-01,\n          1.0440e-01, -1.5149e-03,  1.0720e-01, -1.5967e-01, -1.3729e-01,\n         -2.6573e-02, -2.1602e-01,  2.1239e-01, -1.6244e-01,  4.2610e-02],\n        [-8.1080e-02, -1.4105e-01, -1.1460e-01, -7.1222e-02, -3.7057e-02,\n         -1.0240e-01, -1.6370e-01, -1.9282e-01,  8.5257e-02,  2.2007e-01,\n         -5.7330e-02, -1.3530e-02,  4.2319e-02,  1.8891e-01,  1.8161e-01,\n          1.3626e-03, -2.0583e-01, -2.3443e-02, -1.0546e-01, -2.1260e-01],\n        [-1.5915e-02,  1.4937e-02,  5.7315e-02,  4.3044e-02, -8.7345e-02,\n         -1.5716e-01, -1.0995e-01,  1.9150e-01,  3.7137e-02, -6.2160e-02,\n         -1.6357e-01, -4.7182e-02, -1.0617e-01,  1.9915e-01,  8.5879e-03,\n          1.1535e-01, -2.1511e-01,  1.4155e-01, -9.8532e-02,  9.5955e-02],\n        [-3.3832e-02, -1.3212e-01,  1.7458e-01, -1.7829e-01,  5.2308e-02,\n         -1.1183e-01,  1.7335e-01, -4.6448e-02,  2.0756e-01,  1.7581e-01,\n          8.1413e-02, -1.3823e-01,  1.9650e-01, -5.3158e-02,  1.4024e-01,\n         -1.2148e-01, -1.4905e-01,  4.1748e-03,  4.3586e-02,  1.0745e-01],\n        [ 1.6109e-01, -1.0625e-01,  2.1989e-01, -1.5057e-02,  1.3698e-01,\n         -6.5055e-02, -6.7254e-02, -9.0496e-02,  2.2303e-01,  7.4862e-02,\n         -6.4449e-02, -2.0635e-01,  9.4844e-02, -1.7447e-01,  3.4648e-02,\n         -1.7115e-01,  5.7758e-02, -6.7421e-03,  5.5604e-02, -8.5631e-02],\n        [-7.6825e-02, -1.8070e-02, -2.1444e-01,  7.4898e-02,  4.2782e-02,\n          8.3769e-02, -1.5982e-01, -7.6690e-02,  1.6364e-01, -4.2199e-02,\n          9.5334e-02,  1.5025e-03, -3.5858e-02, -2.0026e-01,  1.8680e-01,\n          2.2329e-01, -2.3954e-02, -1.1049e-01,  1.8063e-02,  8.2318e-02],\n        [-2.4238e-04, -1.3116e-01,  5.1261e-02, -9.1511e-02, -1.4772e-01,\n          1.9197e-01,  1.4967e-01, -1.9627e-01, -1.2653e-01, -1.2468e-01,\n         -2.1589e-01, -1.7260e-01, -5.0253e-02, -2.0797e-01, -2.1876e-01,\n         -6.0009e-02,  1.8906e-01,  1.5859e-01, -1.2176e-01, -3.5790e-02],\n        [-2.2263e-01, -5.8407e-02, -1.3627e-01, -4.3919e-02, -1.3217e-01,\n         -1.2322e-01, -1.0430e-01,  7.3719e-02,  8.3871e-02,  1.6012e-01,\n          5.0587e-02, -4.9101e-02,  1.7815e-01,  1.0561e-01,  4.7983e-02,\n          1.1882e-01, -1.2064e-01,  2.0622e-02,  6.8812e-02, -1.7315e-03],\n        [ 1.7748e-02, -8.3768e-02,  1.5165e-01, -7.9791e-02,  7.5609e-02,\n          7.3363e-02, -5.1852e-02, -5.0695e-02,  2.1876e-01, -1.7935e-01,\n          1.5235e-01,  5.8742e-03, -1.2910e-01, -1.4605e-01,  3.9830e-02,\n          1.3263e-01, -1.8286e-01, -1.2965e-01,  1.9484e-01, -1.9859e-01],\n        [ 1.4104e-01,  3.1234e-02, -7.1541e-02, -2.1062e-01,  1.4191e-01,\n         -1.0620e-01,  9.7220e-02, -1.0709e-01,  2.1025e-01, -7.0477e-02,\n          1.3389e-01,  4.0698e-02, -1.8128e-01, -4.8961e-02,  1.3686e-01,\n         -2.1366e-01, -1.8718e-02,  2.0222e-01, -5.4114e-02, -1.1247e-01],\n        [-6.9095e-03,  1.1970e-02, -2.1508e-01, -1.0962e-01, -1.0092e-01,\n         -4.7002e-02, -8.1838e-02, -3.9934e-02,  2.9581e-02,  2.2086e-01,\n          8.6389e-02,  3.3233e-02, -5.5578e-02,  1.5374e-01,  3.6954e-02,\n          1.9792e-01,  1.7214e-02,  1.2977e-01, -8.1254e-02, -2.5350e-04],\n        [-2.2314e-01,  1.6552e-01,  8.9655e-02,  9.7286e-02, -1.8976e-01,\n         -5.1284e-02,  1.9527e-01,  1.7802e-01,  1.3754e-01,  1.8339e-01,\n         -1.0964e-01,  7.6759e-02,  7.9693e-02,  2.4062e-02, -1.7484e-01,\n          1.5048e-01,  9.9600e-02,  1.5852e-01, -1.2123e-01,  2.1282e-01],\n        [-9.3777e-02, -1.5110e-01, -1.9860e-01,  1.1570e-01, -6.2151e-03,\n         -2.1866e-01,  4.2300e-02,  1.5803e-01, -2.2184e-01,  1.7963e-01,\n          1.9876e-01, -8.4602e-02, -3.4895e-02, -5.1683e-02, -1.9219e-01,\n         -1.1931e-01, -1.5465e-01,  1.6956e-01, -2.0472e-01, -9.6133e-02]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0132, -0.0022, -0.2048, -0.2132,  0.1772, -0.2038,  0.1266,  0.1728,\n        -0.1288, -0.0656, -0.1622,  0.1286,  0.0196,  0.1574, -0.1381,  0.1880,\n         0.1030, -0.2167, -0.1880, -0.1798,  0.2019, -0.1472,  0.1413,  0.0296,\n         0.1637, -0.1144,  0.1737,  0.0728, -0.1524, -0.1274, -0.0261,  0.0172],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1292,  0.0590,  0.0766,  0.0607, -0.0471, -0.0099,  0.1755, -0.0088,\n         -0.1579,  0.1682,  0.1342,  0.1152,  0.1062,  0.0281, -0.0933,  0.0248,\n         -0.1623, -0.0498, -0.1212,  0.0989,  0.0833, -0.1591, -0.0204,  0.1614,\n         -0.0044, -0.1224, -0.0638,  0.0012, -0.0168, -0.0151,  0.0126, -0.0007],\n        [-0.0985,  0.0595,  0.0490,  0.1154, -0.0618,  0.0058,  0.0086,  0.0580,\n         -0.1748,  0.1398,  0.0163,  0.0861, -0.0092,  0.1741, -0.0361, -0.1215,\n          0.0246,  0.0508, -0.0439, -0.1448,  0.0665, -0.0443,  0.0096,  0.0153,\n         -0.1099, -0.1016, -0.0402, -0.0480, -0.1060,  0.1215,  0.0685,  0.0340],\n        [ 0.0475, -0.0226,  0.0619, -0.1225, -0.0728, -0.1278, -0.0263, -0.1634,\n          0.1567, -0.1421, -0.0502, -0.1530, -0.1717, -0.1653, -0.0911,  0.0077,\n         -0.0727,  0.0509,  0.1061, -0.0547,  0.0904,  0.0593, -0.0634,  0.0377,\n         -0.0263, -0.0087, -0.0043,  0.0183, -0.1420, -0.1520, -0.1185,  0.0703],\n        [-0.0039,  0.0112, -0.1420, -0.1357, -0.0677, -0.1225, -0.0432, -0.0893,\n         -0.0980,  0.0613, -0.0560, -0.1583,  0.0606,  0.0904,  0.1492, -0.1346,\n          0.0701,  0.1336, -0.1499, -0.0630,  0.0442, -0.1455, -0.0801, -0.0212,\n          0.1504, -0.1462, -0.0495, -0.1385, -0.1032, -0.0025, -0.1644,  0.1082],\n        [-0.0163, -0.0801,  0.1587, -0.0634, -0.1571,  0.0215, -0.1192, -0.1000,\n         -0.1672, -0.1124, -0.1161, -0.0823, -0.1048,  0.1744, -0.1266,  0.0977,\n          0.0029,  0.0969, -0.0680,  0.0612,  0.0742, -0.1302, -0.0160,  0.1331,\n         -0.1004,  0.0662,  0.1436, -0.0009, -0.0556, -0.0425, -0.0296,  0.1205],\n        [ 0.1728, -0.0307, -0.0453,  0.0766, -0.0005,  0.1586,  0.0365, -0.0727,\n          0.1357,  0.1340,  0.1760, -0.0980, -0.0784, -0.1454,  0.1547, -0.0962,\n         -0.0643,  0.0526,  0.0233,  0.1036,  0.0404,  0.0768,  0.1020, -0.1020,\n         -0.0963,  0.1309,  0.1333,  0.0650, -0.1472, -0.0013, -0.1233,  0.1702],\n        [-0.0330, -0.1313, -0.1696,  0.0621,  0.1711,  0.1622,  0.1174, -0.0294,\n          0.0063,  0.1137, -0.1330,  0.0771,  0.1007,  0.0100, -0.1239, -0.1183,\n         -0.1621,  0.0067, -0.1599, -0.0309, -0.1204, -0.0126, -0.1608,  0.1076,\n          0.0175, -0.0776,  0.0371,  0.0707,  0.0016, -0.0741,  0.0373,  0.0385],\n        [ 0.0771,  0.0615,  0.1708, -0.0133,  0.1262,  0.0667, -0.0023, -0.0290,\n         -0.0982, -0.0047, -0.1165,  0.0368, -0.0223, -0.1681, -0.1565,  0.0271,\n          0.1255, -0.0365, -0.1700, -0.0751, -0.0230,  0.1125, -0.1054,  0.1377,\n         -0.1599,  0.1449,  0.0569,  0.0737, -0.0690,  0.1115, -0.0582, -0.0726],\n        [ 0.1112, -0.0055, -0.0619,  0.0911, -0.0187,  0.0191, -0.0789, -0.0806,\n         -0.0458,  0.1708,  0.1560, -0.1418,  0.1275,  0.1337,  0.1001, -0.1642,\n          0.0647, -0.1092, -0.0292,  0.0258,  0.0625,  0.0296,  0.0020, -0.0226,\n         -0.0901, -0.0615, -0.1481, -0.0474,  0.1105,  0.1417, -0.1172,  0.1536],\n        [-0.1117, -0.0407,  0.1351, -0.1242,  0.0411,  0.0427,  0.0850,  0.1221,\n          0.1227,  0.0531,  0.1149, -0.0804, -0.1070,  0.0306, -0.0452, -0.1047,\n          0.0239,  0.1551,  0.0559,  0.0622, -0.0240,  0.1689, -0.1047, -0.1114,\n          0.1645, -0.1058,  0.1381, -0.0367, -0.1591,  0.0486, -0.0181,  0.1665],\n        [-0.0466, -0.1074,  0.0583,  0.1754,  0.0156,  0.0520, -0.0440,  0.0272,\n          0.1430, -0.0417,  0.0950, -0.0868,  0.0551, -0.0355,  0.0618,  0.0585,\n          0.0234, -0.1070, -0.0928,  0.0956,  0.0025, -0.1739, -0.0770, -0.0419,\n         -0.0041,  0.0852,  0.0382, -0.0169,  0.1143, -0.0290,  0.0420, -0.0558],\n        [ 0.1257,  0.0373, -0.0909, -0.1022,  0.1107,  0.1071, -0.0002, -0.0955,\n          0.1213,  0.1330, -0.1749,  0.1571,  0.0118, -0.0976,  0.0896, -0.0938,\n         -0.1195, -0.0367,  0.0995,  0.0120,  0.0225, -0.0140,  0.1689, -0.1548,\n         -0.0556,  0.0175,  0.1103,  0.0638,  0.1199,  0.1632, -0.0237, -0.1473],\n        [ 0.0547, -0.0437, -0.0250, -0.1052,  0.0780,  0.0789,  0.0240,  0.0246,\n          0.1238,  0.0250, -0.1333,  0.1439,  0.1443, -0.1735, -0.1006,  0.0965,\n          0.1529, -0.0438,  0.0498,  0.0946,  0.1194,  0.1363,  0.0040, -0.0175,\n          0.0289, -0.0066,  0.1040,  0.1690, -0.0745, -0.1428, -0.0981,  0.1225],\n        [ 0.1529,  0.1345,  0.1117,  0.0627,  0.1161, -0.0636, -0.0687,  0.1724,\n          0.1132, -0.1315, -0.0414,  0.1467, -0.0055, -0.0213,  0.1649,  0.0893,\n         -0.1422, -0.1050,  0.0880, -0.0018, -0.0396,  0.0322, -0.0672,  0.1206,\n         -0.1729, -0.0135, -0.0485,  0.1024, -0.0747, -0.0823,  0.0369, -0.1101],\n        [-0.0959,  0.0876,  0.1044, -0.1754,  0.1706,  0.0750, -0.1018,  0.1123,\n          0.0657, -0.0609,  0.1368, -0.0744, -0.1182, -0.1251, -0.1760, -0.0801,\n          0.1685,  0.0739,  0.0345,  0.1704, -0.1242,  0.0638,  0.0152, -0.0859,\n         -0.0643,  0.0647,  0.0589, -0.1435, -0.0437, -0.0147, -0.1482,  0.0323],\n        [ 0.1688, -0.0618,  0.0616,  0.0468,  0.0841, -0.0522, -0.1117,  0.0978,\n          0.1353,  0.0739, -0.1239, -0.1724, -0.0067, -0.0608, -0.1222, -0.0438,\n         -0.1660,  0.1351, -0.0992,  0.0858,  0.0232, -0.0608,  0.1696,  0.0324,\n          0.0662, -0.0469, -0.0612, -0.0813,  0.1194,  0.0420,  0.1614,  0.1735]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1392, -0.1479,  0.0611, -0.1236,  0.0726,  0.1742,  0.1417,  0.1273,\n        -0.0827, -0.1533,  0.1612,  0.0358, -0.0149, -0.1044, -0.1679, -0.0578],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0999, -0.1488, -0.1097,  0.0209, -0.1558, -0.0797, -0.2444, -0.1423,\n         -0.1197, -0.0078, -0.1468,  0.1721,  0.0025, -0.2384, -0.0534, -0.0977],\n        [ 0.0422,  0.1639,  0.0732, -0.1567,  0.1816, -0.1906, -0.0868,  0.1766,\n          0.1697,  0.0270,  0.0912,  0.0836, -0.1784,  0.0505, -0.2233,  0.0577],\n        [ 0.1975, -0.0772,  0.1129, -0.2228,  0.1231, -0.0939, -0.1891, -0.1542,\n         -0.0920, -0.0288,  0.0798, -0.2451, -0.0173, -0.0772,  0.2330, -0.2383],\n        [ 0.1076, -0.1566, -0.1623, -0.0352,  0.1323, -0.2315, -0.2039, -0.1854,\n          0.1671, -0.2382,  0.0146, -0.2226,  0.0065, -0.1733,  0.1110,  0.1579],\n        [ 0.0244,  0.0058,  0.1860,  0.2193,  0.0590, -0.0145, -0.0657, -0.0497,\n         -0.2066,  0.1208, -0.0620, -0.1728, -0.1800, -0.0744, -0.1387, -0.2304],\n        [ 0.1338,  0.0783, -0.0907,  0.0041, -0.1066, -0.1161,  0.0422,  0.0702,\n          0.1168,  0.1118,  0.0536,  0.2460,  0.0938,  0.2107,  0.0984,  0.0608],\n        [-0.2063, -0.0363, -0.1389, -0.1553,  0.0061,  0.1627, -0.0562,  0.1250,\n          0.1321, -0.0457, -0.0181, -0.0373, -0.0939,  0.2179, -0.0173,  0.0420],\n        [-0.0949, -0.0547, -0.0613,  0.0904,  0.1138, -0.1462, -0.0060,  0.1391,\n         -0.1915,  0.0057,  0.0095, -0.2263,  0.1648, -0.0923,  0.0209, -0.2178]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0446,  0.0153,  0.0871,  0.0971, -0.1912,  0.0581, -0.1865, -0.2408],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3278,  0.3275, -0.2768,  0.2134,  0.3460,  0.2709,  0.1981,  0.1050]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1703], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x10beee320>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x11c4d4700>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s46050000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s46050000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}