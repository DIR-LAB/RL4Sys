{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s48860000"
    },
    "q_lr":	0.0005,
    "seed":	48860000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x11b538a90>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0330, -0.1249,  0.1625,  0.0299,  0.0365, -0.0893,  0.1337, -0.1821,\n        -0.1267,  0.1784,  0.0982,  0.1937,  0.0362,  0.0271, -0.1251, -0.1946,\n         0.0050, -0.0048,  0.1365,  0.0523,  0.2008, -0.0706,  0.0446,  0.0750,\n         0.0240, -0.0874, -0.1403,  0.0129,  0.0836, -0.1278, -0.0888, -0.0542],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 4.6063e-02,  1.6692e-01,  7.5663e-04,  1.8143e-01, -1.6164e-02,\n          5.6862e-02,  7.8171e-02,  1.9719e-01,  6.5905e-02,  2.7223e-02,\n         -1.1582e-01, -1.2575e-02,  7.4184e-02,  2.7884e-02,  1.6124e-01,\n         -3.5274e-02,  1.8173e-01,  1.2556e-01,  6.7300e-02,  1.7376e-01],\n        [ 2.1005e-01,  1.0691e-01,  5.2060e-02, -1.8047e-01,  1.0929e-01,\n         -5.2334e-02, -2.0623e-01, -4.5149e-02,  2.0833e-01, -8.6853e-03,\n         -5.9523e-02, -6.1989e-03, -9.5848e-02,  1.8213e-01, -1.8549e-01,\n          1.6115e-01,  1.5714e-01,  3.9628e-02,  8.3546e-02,  5.2247e-02],\n        [ 6.8852e-02,  1.1635e-01,  4.6460e-02, -1.3455e-02,  7.0212e-02,\n          1.3408e-01, -1.0342e-01, -3.7444e-02,  2.0434e-01,  1.5649e-01,\n          1.2722e-01,  1.8786e-01, -1.0587e-01,  4.9209e-03,  2.1239e-02,\n          6.0412e-02, -1.5364e-01,  6.8418e-02, -2.3146e-02, -2.2310e-01],\n        [ 5.6984e-02,  2.5424e-02,  1.6054e-01, -6.9575e-02,  1.5010e-01,\n         -1.4281e-01, -2.1250e-01,  1.6080e-01,  8.2926e-03,  1.2413e-01,\n          1.1656e-01, -4.8163e-02, -5.0187e-02, -8.2379e-02, -8.9248e-02,\n         -1.6985e-01, -7.8576e-02,  1.2539e-01,  4.3001e-02, -2.0857e-01],\n        [-6.4468e-02,  1.2137e-01,  1.1438e-01, -1.6979e-01, -3.4245e-02,\n         -1.8165e-01,  2.0525e-01,  6.5797e-02,  3.5786e-02,  7.1993e-02,\n         -1.0147e-01,  1.2230e-02, -9.7303e-02,  1.4282e-01, -3.2287e-03,\n         -7.8775e-02,  4.2839e-02,  1.6532e-01,  8.2230e-02, -3.7493e-03],\n        [ 1.6831e-01, -5.0210e-02,  8.6910e-02,  2.1110e-01, -2.0655e-02,\n          2.1090e-01,  8.7188e-03,  1.9275e-01,  2.1883e-01, -3.5244e-02,\n          1.1142e-01, -5.9313e-02,  4.4578e-02, -1.3888e-04,  1.3041e-01,\n         -6.3626e-02, -5.1087e-02,  2.0136e-02,  8.9139e-02,  1.4969e-01],\n        [-1.0676e-01,  2.0286e-01,  2.8618e-02, -2.1177e-01,  1.0092e-02,\n         -1.4088e-01, -1.9711e-01, -2.0246e-01,  8.9000e-02,  1.1364e-01,\n         -1.2826e-01, -1.1373e-01,  2.1059e-01, -2.1466e-01, -1.4708e-01,\n          1.9021e-01,  6.8264e-03, -2.8205e-02,  1.3495e-01, -4.5843e-02],\n        [ 9.5120e-02, -3.7649e-02,  1.2971e-01,  1.9693e-01, -1.5561e-01,\n         -1.2857e-01, -1.4949e-01,  1.1185e-01,  1.3774e-01,  9.2217e-02,\n          3.6512e-03,  1.7652e-01, -1.4511e-01,  1.1874e-01, -1.5980e-01,\n          9.8197e-02,  6.3623e-02, -7.4666e-02, -1.5449e-01, -1.9338e-01],\n        [ 1.0517e-01,  3.1419e-02,  2.2183e-01,  1.8842e-01,  1.5018e-01,\n         -4.3805e-02, -1.7147e-02,  2.7944e-02,  1.5033e-01,  5.3490e-02,\n          4.0420e-02,  1.2127e-01, -1.0565e-01, -1.2569e-01, -2.0521e-01,\n         -2.4627e-02,  1.0081e-01, -3.0270e-02,  1.4673e-02, -5.1758e-02],\n        [-1.6643e-01, -1.0578e-01,  2.0306e-01, -3.0963e-02,  1.1145e-01,\n         -4.5461e-02,  1.0644e-01, -2.1587e-01, -1.2787e-01,  1.4093e-02,\n          5.4570e-02, -8.5114e-02,  1.8297e-01,  1.2734e-01,  3.6456e-02,\n          1.9859e-01,  2.5337e-02,  3.8580e-03,  8.2872e-03, -1.9732e-01],\n        [-1.6421e-02,  2.1595e-01,  7.6488e-02, -1.6083e-01, -1.6375e-02,\n         -2.0555e-02, -2.1042e-01, -1.2703e-01, -6.3906e-02,  5.9078e-02,\n          3.1745e-02, -1.0305e-01,  1.5403e-01, -1.4218e-02, -1.0141e-01,\n         -1.5516e-01, -1.7687e-01, -1.2233e-01,  1.8480e-02, -1.1237e-01],\n        [ 1.5427e-01, -1.8148e-02, -1.7958e-01, -1.3465e-01, -1.0240e-01,\n          4.0017e-02,  1.9112e-01,  4.3824e-02, -1.3900e-01, -1.1932e-01,\n         -1.1368e-02, -5.1175e-02,  9.4141e-02, -1.9657e-01, -1.8779e-01,\n          2.1210e-01, -2.0020e-01, -8.8045e-02, -1.3389e-01,  3.8402e-02],\n        [-1.0734e-01,  3.7776e-02,  1.6785e-01, -1.4271e-01,  3.1841e-02,\n          1.2259e-01, -1.7062e-01,  1.2665e-02,  6.7520e-02, -2.1967e-01,\n          1.2168e-01,  7.3643e-02,  2.1538e-01,  1.1295e-01, -1.9485e-01,\n          1.4140e-01,  1.7714e-01,  1.8875e-01, -2.9406e-03, -6.2599e-02],\n        [ 4.4293e-02,  2.3112e-02, -9.6619e-02, -6.3968e-02, -2.0169e-01,\n         -1.3036e-01, -1.2474e-01, -1.1900e-01,  3.0010e-02, -8.1181e-02,\n         -1.8637e-01, -1.8264e-01,  2.2349e-01, -1.5904e-01,  1.0856e-01,\n          1.1035e-01, -1.0593e-01, -1.2225e-01,  2.0114e-01,  1.2519e-01],\n        [ 8.5351e-02,  1.1717e-01,  4.4905e-02, -6.0015e-02,  8.3804e-02,\n         -3.5213e-02,  2.0126e-01,  1.5274e-01, -2.3523e-02,  7.8763e-02,\n         -1.2887e-01,  2.1176e-02,  8.9301e-02, -1.3094e-01, -1.2232e-01,\n          8.0536e-02, -6.2686e-02,  1.1188e-01,  1.5835e-02, -1.1078e-01],\n        [-6.4338e-02, -1.9537e-01, -6.9534e-02, -1.5145e-01, -8.0506e-02,\n          4.4679e-02, -1.2489e-02, -1.5718e-01, -6.6705e-02,  6.1899e-02,\n          1.0307e-01,  1.5207e-01, -1.4239e-01,  6.7545e-02,  1.2224e-01,\n          9.7770e-02, -2.0538e-01, -5.3065e-02, -5.2840e-02,  6.8100e-02],\n        [ 8.0094e-03,  7.4832e-02,  1.4284e-01,  1.6313e-01,  9.7401e-02,\n          4.0700e-03,  8.0476e-02, -2.2305e-01,  6.1447e-02,  6.8547e-02,\n         -2.1949e-01, -1.8899e-01,  1.5348e-01, -1.6347e-01,  1.5384e-02,\n         -1.4907e-01,  1.6473e-01,  1.8336e-01,  2.0603e-01, -1.0427e-01],\n        [ 1.6796e-01,  1.9764e-01, -5.0052e-02,  7.3143e-02,  1.2729e-01,\n         -1.1174e-01, -2.0262e-01, -1.5309e-01,  1.9522e-01, -4.7083e-02,\n         -5.0632e-02, -4.6984e-02,  1.9223e-01,  1.1629e-01, -9.4493e-02,\n          2.0648e-01,  7.3252e-02,  1.7641e-01, -4.3131e-02, -1.2724e-01],\n        [-4.6827e-02,  2.5071e-02,  4.9492e-02,  1.0295e-01,  1.9726e-01,\n          2.2206e-01, -7.5779e-02,  9.3218e-02, -4.8119e-02,  2.0050e-01,\n          4.4422e-02,  1.2229e-02,  2.1827e-01, -1.0104e-01, -1.9816e-01,\n          5.3951e-02,  9.5195e-02, -9.1410e-02,  1.2918e-01,  1.5737e-01],\n        [ 1.8137e-01, -2.0322e-01, -1.4431e-01,  1.3592e-01,  1.4530e-01,\n          9.4366e-02,  1.1018e-01,  1.7456e-01, -3.4780e-02, -2.0657e-01,\n         -1.4841e-01,  2.3885e-02,  1.5530e-03, -1.5476e-01, -8.9857e-03,\n          1.1008e-01,  7.2384e-02, -2.1358e-01, -3.7615e-02, -1.2381e-01],\n        [ 2.0760e-01, -1.4190e-01,  1.7297e-02, -8.3164e-02, -7.2710e-02,\n          1.9700e-01, -1.7853e-01, -1.3370e-01, -8.2720e-03,  4.0981e-02,\n          9.3878e-02,  2.6802e-02, -1.5669e-01,  1.1058e-01, -3.6389e-02,\n          1.6129e-01, -1.3283e-01,  7.5436e-02, -2.1418e-01,  1.2926e-01],\n        [ 2.0448e-01,  1.5801e-01,  1.7309e-01,  1.8712e-02,  1.5188e-01,\n          8.4586e-02,  1.7781e-01,  1.2446e-01,  8.7923e-02, -8.1990e-02,\n         -2.8521e-02,  1.8565e-01,  1.7053e-01, -2.1593e-01,  1.7871e-01,\n          6.1510e-02, -1.0728e-01,  1.2660e-01, -1.0323e-01, -2.0166e-01],\n        [-2.1697e-01, -1.8895e-02, -4.1553e-02,  1.4106e-01, -1.1804e-01,\n          1.7260e-02,  2.9119e-02,  1.1746e-01, -5.2288e-02, -1.1604e-01,\n         -1.3014e-01,  1.1711e-01,  1.4621e-01, -8.6355e-03, -5.6253e-02,\n          1.7915e-01, -1.6751e-01,  1.6301e-01, -5.7148e-02, -6.6166e-02],\n        [-1.0154e-01,  9.0155e-02, -8.4826e-02,  1.3688e-01, -1.0099e-02,\n         -9.4235e-02, -2.1663e-01, -4.5241e-02, -7.6945e-02, -1.2155e-01,\n          4.8236e-02,  4.9929e-02,  5.3716e-02, -6.7545e-02, -1.9905e-01,\n          5.7292e-02, -9.7408e-02, -9.9535e-02, -8.4751e-02,  1.6109e-01],\n        [-1.4792e-01,  1.7123e-01, -2.1038e-01, -3.6423e-02, -1.4706e-01,\n          1.6873e-01,  1.5933e-01, -2.0744e-01,  1.9453e-01, -1.3154e-01,\n         -2.1822e-01, -1.1001e-02,  4.9757e-02, -1.7687e-01,  3.6997e-02,\n          1.0725e-01, -1.7538e-01,  1.9030e-01, -1.5937e-01,  1.4664e-01],\n        [-1.0485e-02, -1.7779e-01,  6.3871e-02, -1.9611e-01,  1.9167e-01,\n         -4.6825e-02,  1.8714e-02, -1.5993e-01,  1.6354e-01, -1.5091e-01,\n          1.8265e-01, -2.6206e-02, -8.8048e-02, -2.0801e-01,  9.2543e-02,\n         -3.1171e-02,  1.7633e-01,  3.7753e-02,  6.6122e-02,  9.4746e-02],\n        [-3.1523e-03,  6.4365e-02, -1.4790e-01, -1.4785e-01,  3.0835e-02,\n         -6.1348e-02,  9.1175e-02, -2.2087e-01, -1.0692e-01,  9.7056e-03,\n          1.4658e-01, -1.6550e-01,  9.1118e-02,  2.1762e-01,  3.5996e-02,\n          1.8000e-01,  3.0204e-03,  2.5390e-02, -2.2295e-01, -5.6047e-02],\n        [-1.9703e-03, -8.5149e-02,  1.7239e-01, -1.1320e-02, -1.8641e-01,\n         -1.2188e-01, -1.1555e-01, -4.0561e-02, -1.9141e-01, -4.5199e-02,\n          1.2722e-01,  4.6110e-02, -2.1855e-01,  1.5828e-01, -3.5565e-03,\n         -5.9521e-02,  7.1651e-02,  1.8770e-03, -1.3636e-02,  1.1907e-01],\n        [-2.0414e-01,  1.7541e-01,  5.8631e-02,  8.3594e-02, -1.0593e-01,\n          1.1572e-01, -2.1613e-01,  2.1183e-01,  1.6972e-01, -1.0235e-01,\n          1.5532e-02, -1.8018e-01,  1.2200e-01, -2.1165e-01,  1.2573e-01,\n         -5.9728e-02,  7.2139e-03,  2.0264e-01, -2.1254e-01, -2.6876e-02],\n        [ 1.2096e-02,  2.0643e-01,  1.5946e-01,  1.1881e-01,  1.4403e-01,\n         -2.7009e-02, -3.9730e-02, -1.5793e-02, -1.3872e-01,  1.4245e-01,\n          2.0176e-01,  1.8985e-01, -7.7793e-02, -2.0854e-01,  2.0365e-01,\n          7.7828e-02,  7.6446e-02, -2.2732e-02,  1.7581e-01, -1.4695e-01],\n        [-9.9935e-02, -2.0476e-01,  6.1225e-02, -9.3865e-02, -1.3487e-01,\n          1.9710e-01,  9.9241e-02, -1.5805e-01, -8.6691e-02,  2.1422e-01,\n         -1.1292e-01,  5.8353e-02,  6.7650e-03,  1.6255e-01,  1.7160e-01,\n          3.2265e-02,  1.2789e-01, -8.5496e-02,  1.3425e-01, -1.5031e-02],\n        [-1.4296e-01, -1.9670e-01, -5.7865e-02, -5.8609e-04,  2.1124e-01,\n         -1.6738e-01,  3.1935e-02,  2.1116e-01, -4.9804e-02, -2.9323e-02,\n          1.6827e-01, -1.3916e-01, -1.7560e-01,  1.6324e-01,  1.9189e-01,\n          2.0588e-01,  2.5163e-02,  7.9560e-02, -1.6471e-01, -5.8168e-02]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-9.1938e-02,  9.8354e-02,  1.5956e-01, -1.6923e-01, -6.5054e-02,\n         5.9297e-02, -1.4435e-01,  1.1713e-01,  6.8982e-02,  1.4176e-04,\n         1.1412e-01, -8.1777e-02, -3.2395e-02, -5.3612e-02, -1.4444e-01,\n        -4.1716e-02], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0804,  0.1318,  0.1066, -0.0316,  0.1059, -0.1284, -0.1176, -0.1074,\n          0.0223,  0.0247, -0.1738, -0.1635,  0.0167,  0.0576, -0.0396, -0.0039,\n         -0.0441,  0.0450,  0.0984, -0.0072,  0.0569, -0.0645, -0.0168, -0.1367,\n         -0.0441,  0.0020, -0.0452, -0.1302,  0.0827, -0.1629, -0.0501, -0.0226],\n        [-0.0359,  0.1743, -0.1284,  0.0869,  0.0391, -0.0113, -0.0843,  0.1293,\n         -0.0094,  0.0996, -0.1094, -0.1381,  0.0642, -0.0026,  0.0710,  0.0282,\n         -0.1455, -0.1356, -0.0563, -0.0155,  0.1324, -0.1087,  0.0006, -0.1720,\n         -0.1539,  0.0581,  0.0131, -0.0883, -0.0879,  0.0749,  0.0479, -0.0321],\n        [-0.1469, -0.1252, -0.0700, -0.0088,  0.0676, -0.0179, -0.0188, -0.1332,\n         -0.1136, -0.0734,  0.1626, -0.1497, -0.0990, -0.0602,  0.0920, -0.1414,\n          0.1067, -0.1492, -0.0774, -0.0088,  0.1253,  0.1438, -0.1608, -0.0150,\n         -0.0015, -0.1121, -0.1028, -0.0790, -0.0922,  0.0668,  0.1715,  0.0940],\n        [ 0.0493,  0.0203, -0.1545,  0.1127,  0.0333,  0.0217,  0.1141, -0.1704,\n         -0.0814, -0.1262, -0.1240, -0.1541,  0.1217, -0.0594,  0.1630, -0.1163,\n          0.0302,  0.0351, -0.0438, -0.0015, -0.0350,  0.0658,  0.1654,  0.0737,\n         -0.1018,  0.0290, -0.0266,  0.1206,  0.0681,  0.1179,  0.1432, -0.1302],\n        [-0.1569, -0.1131, -0.0800, -0.0536,  0.1574, -0.1565,  0.0502,  0.0301,\n         -0.1379,  0.0719, -0.1733,  0.0883, -0.0629,  0.1741,  0.1748, -0.1617,\n         -0.0579, -0.0724,  0.1098,  0.1289,  0.0669,  0.1408, -0.0108, -0.1259,\n          0.1492,  0.0416, -0.0496,  0.0199,  0.0143,  0.0699, -0.1490, -0.0808],\n        [-0.0692, -0.0085,  0.1623, -0.0069,  0.0877,  0.0305,  0.1651,  0.1602,\n          0.0941,  0.0262, -0.0149,  0.1365, -0.0998,  0.0181,  0.1701,  0.1550,\n          0.1586, -0.1197,  0.1051, -0.0893,  0.0207, -0.0292, -0.1450,  0.0390,\n         -0.1272, -0.1631,  0.0824,  0.0469,  0.1099,  0.0355, -0.1683,  0.0645],\n        [-0.0340, -0.0601, -0.1106,  0.1634, -0.1667,  0.1079,  0.0134, -0.1164,\n          0.1364, -0.0562, -0.0404, -0.0891,  0.1705,  0.1363,  0.1741,  0.1748,\n          0.0061,  0.1425,  0.1432, -0.1733, -0.1615,  0.0165, -0.0419,  0.0686,\n          0.0753, -0.0550, -0.1297,  0.0263, -0.1629,  0.1349, -0.0789, -0.1263],\n        [ 0.1089,  0.0765, -0.1231, -0.1602,  0.0932,  0.0510, -0.0051, -0.1648,\n         -0.1033, -0.1623,  0.0337,  0.1157, -0.0390, -0.1093,  0.0927, -0.0641,\n         -0.1074,  0.0822, -0.1273,  0.0604, -0.0024,  0.1261, -0.1688,  0.0614,\n          0.0414, -0.0834,  0.0590,  0.1103, -0.0438,  0.1308,  0.0744,  0.0056],\n        [-0.0759,  0.0357, -0.1016,  0.0696, -0.0341,  0.0929, -0.0455, -0.0777,\n         -0.0231, -0.1276, -0.0294, -0.1674,  0.1562, -0.0139,  0.0628,  0.1581,\n         -0.1697,  0.0864, -0.0421, -0.1418,  0.0632, -0.0620, -0.0419, -0.1512,\n         -0.1597,  0.1145, -0.1554,  0.0266,  0.0121,  0.1288, -0.0537, -0.0215],\n        [-0.1388,  0.0117,  0.0411, -0.1659,  0.0023, -0.0209, -0.1627, -0.0137,\n          0.1643,  0.0617,  0.1479, -0.1336,  0.0593, -0.0559,  0.0426,  0.0363,\n         -0.1534, -0.0230,  0.1357, -0.1420,  0.0406, -0.1245,  0.0718,  0.1220,\n         -0.0257,  0.1247, -0.0442, -0.1369,  0.1263,  0.0939, -0.1352,  0.0631],\n        [ 0.1416, -0.1576,  0.0670,  0.1205,  0.1283, -0.1199, -0.1291,  0.1430,\n          0.0852, -0.0917,  0.1299,  0.1659,  0.1186, -0.0559, -0.0571, -0.0243,\n          0.0155, -0.0992, -0.0963, -0.0550,  0.1302, -0.1515,  0.1466, -0.1385,\n         -0.0507,  0.0340, -0.1144,  0.0830,  0.0783,  0.1149, -0.0971, -0.1400],\n        [ 0.0494, -0.0829,  0.0464,  0.1054,  0.1052,  0.0210, -0.0948, -0.0738,\n          0.0520, -0.1510,  0.1094, -0.0827,  0.0518, -0.0362,  0.0092, -0.1756,\n          0.0232,  0.1011,  0.0031, -0.0865, -0.1083,  0.0779,  0.0926, -0.1446,\n         -0.1395, -0.0577, -0.0507,  0.0935,  0.0547,  0.0225, -0.0897,  0.0643],\n        [-0.1138, -0.1327, -0.1180,  0.0309, -0.1320,  0.1404,  0.0566, -0.1533,\n         -0.0759,  0.0832, -0.1162, -0.0428, -0.0429,  0.0439,  0.0794, -0.1610,\n         -0.1034, -0.1292,  0.0704, -0.0551,  0.0735,  0.1377,  0.0259, -0.1330,\n         -0.0084, -0.0808, -0.0655,  0.0934,  0.1605,  0.1042,  0.0129,  0.1069],\n        [-0.0924, -0.0396,  0.1655,  0.0342, -0.1436, -0.0019,  0.0283, -0.1357,\n         -0.0970,  0.1581, -0.1449, -0.0944, -0.0040,  0.1395,  0.1486,  0.0158,\n         -0.0010,  0.1112, -0.1714, -0.1248, -0.1099, -0.0295, -0.0883,  0.0745,\n          0.1045,  0.1070,  0.1766,  0.1264, -0.0212,  0.0349,  0.0203, -0.0386],\n        [ 0.0224,  0.1268,  0.0922, -0.0794,  0.0091, -0.0509, -0.1711,  0.0929,\n         -0.1316, -0.0628, -0.0563,  0.1205,  0.1039, -0.0862,  0.0219, -0.1240,\n         -0.0573, -0.0772, -0.1043, -0.1638,  0.0179, -0.1413, -0.1707, -0.0765,\n          0.1619,  0.0306,  0.0931,  0.0702, -0.0399, -0.0157,  0.0450,  0.1557],\n        [-0.0799,  0.1608,  0.1083, -0.1027,  0.0845,  0.1707, -0.1426, -0.1026,\n         -0.0714, -0.1000, -0.1255, -0.1684,  0.1191, -0.0969,  0.1761,  0.0419,\n         -0.1279,  0.0840,  0.0772, -0.0062,  0.1691, -0.1065,  0.0646, -0.1156,\n          0.1485, -0.0828,  0.0929, -0.1018, -0.0238, -0.0105,  0.1527,  0.0362]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2254, -0.1242, -0.1450, -0.0668,  0.0440,  0.0834, -0.1180,  0.2180],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2008,  0.1497, -0.1525,  0.2088, -0.1912,  0.0911, -0.1490,  0.1846,\n         -0.1575, -0.2165,  0.0878,  0.2246, -0.1175, -0.1255, -0.2162,  0.2395],\n        [-0.0961, -0.0377,  0.1846, -0.0707,  0.2459,  0.1359,  0.0320,  0.2474,\n          0.1987,  0.1336,  0.1660,  0.0357,  0.1198, -0.0107,  0.0480, -0.0358],\n        [-0.0051,  0.0273, -0.0924, -0.0581, -0.2072,  0.1003,  0.1737,  0.0595,\n          0.0889, -0.2170,  0.2361,  0.0595, -0.0160,  0.0734,  0.1912, -0.2004],\n        [ 0.1912,  0.1468, -0.0904,  0.1844,  0.1705,  0.2031, -0.0281,  0.1607,\n          0.0479,  0.1917, -0.2462, -0.0312, -0.2320, -0.1328, -0.1245, -0.0347],\n        [-0.1557, -0.1156, -0.0845,  0.0531, -0.2224, -0.0977,  0.1101, -0.1907,\n         -0.1019, -0.0986,  0.0633, -0.1788, -0.0380,  0.0530,  0.1160, -0.0868],\n        [ 0.1389, -0.2275, -0.1031,  0.2033,  0.1598,  0.2335, -0.1472,  0.1009,\n          0.2393,  0.1082, -0.2387,  0.1111, -0.1280,  0.1645,  0.0356, -0.1688],\n        [ 0.1498, -0.1188, -0.0714, -0.0935,  0.0495, -0.0785, -0.1771,  0.0919,\n         -0.0035, -0.1651,  0.0481, -0.1161,  0.0075,  0.2090,  0.0680,  0.0120],\n        [-0.2474,  0.2096, -0.1676,  0.0389,  0.0594, -0.1961, -0.1768, -0.1130,\n         -0.0083,  0.2368, -0.1613,  0.2016, -0.2337, -0.1615,  0.1269, -0.0792]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0365], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.3102,  0.0297,  0.1730,  0.2649,  0.3462, -0.0811,  0.1124, -0.2347]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 4.6063e-02,  1.6692e-01,  7.5663e-04,  1.8143e-01, -1.6164e-02,\n          5.6862e-02,  7.8171e-02,  1.9719e-01,  6.5905e-02,  2.7223e-02,\n         -1.1582e-01, -1.2575e-02,  7.4184e-02,  2.7884e-02,  1.6124e-01,\n         -3.5274e-02,  1.8173e-01,  1.2556e-01,  6.7300e-02,  1.7376e-01],\n        [ 2.1005e-01,  1.0691e-01,  5.2060e-02, -1.8047e-01,  1.0929e-01,\n         -5.2334e-02, -2.0623e-01, -4.5149e-02,  2.0833e-01, -8.6853e-03,\n         -5.9523e-02, -6.1989e-03, -9.5848e-02,  1.8213e-01, -1.8549e-01,\n          1.6115e-01,  1.5714e-01,  3.9628e-02,  8.3546e-02,  5.2247e-02],\n        [ 6.8852e-02,  1.1635e-01,  4.6460e-02, -1.3455e-02,  7.0212e-02,\n          1.3408e-01, -1.0342e-01, -3.7444e-02,  2.0434e-01,  1.5649e-01,\n          1.2722e-01,  1.8786e-01, -1.0587e-01,  4.9209e-03,  2.1239e-02,\n          6.0412e-02, -1.5364e-01,  6.8418e-02, -2.3146e-02, -2.2310e-01],\n        [ 5.6984e-02,  2.5424e-02,  1.6054e-01, -6.9575e-02,  1.5010e-01,\n         -1.4281e-01, -2.1250e-01,  1.6080e-01,  8.2926e-03,  1.2413e-01,\n          1.1656e-01, -4.8163e-02, -5.0187e-02, -8.2379e-02, -8.9248e-02,\n         -1.6985e-01, -7.8576e-02,  1.2539e-01,  4.3001e-02, -2.0857e-01],\n        [-6.4468e-02,  1.2137e-01,  1.1438e-01, -1.6979e-01, -3.4245e-02,\n         -1.8165e-01,  2.0525e-01,  6.5797e-02,  3.5786e-02,  7.1993e-02,\n         -1.0147e-01,  1.2230e-02, -9.7303e-02,  1.4282e-01, -3.2287e-03,\n         -7.8775e-02,  4.2839e-02,  1.6532e-01,  8.2230e-02, -3.7493e-03],\n        [ 1.6831e-01, -5.0210e-02,  8.6910e-02,  2.1110e-01, -2.0655e-02,\n          2.1090e-01,  8.7188e-03,  1.9275e-01,  2.1883e-01, -3.5244e-02,\n          1.1142e-01, -5.9313e-02,  4.4578e-02, -1.3888e-04,  1.3041e-01,\n         -6.3626e-02, -5.1087e-02,  2.0136e-02,  8.9139e-02,  1.4969e-01],\n        [-1.0676e-01,  2.0286e-01,  2.8618e-02, -2.1177e-01,  1.0092e-02,\n         -1.4088e-01, -1.9711e-01, -2.0246e-01,  8.9000e-02,  1.1364e-01,\n         -1.2826e-01, -1.1373e-01,  2.1059e-01, -2.1466e-01, -1.4708e-01,\n          1.9021e-01,  6.8264e-03, -2.8205e-02,  1.3495e-01, -4.5843e-02],\n        [ 9.5120e-02, -3.7649e-02,  1.2971e-01,  1.9693e-01, -1.5561e-01,\n         -1.2857e-01, -1.4949e-01,  1.1185e-01,  1.3774e-01,  9.2217e-02,\n          3.6512e-03,  1.7652e-01, -1.4511e-01,  1.1874e-01, -1.5980e-01,\n          9.8197e-02,  6.3623e-02, -7.4666e-02, -1.5449e-01, -1.9338e-01],\n        [ 1.0517e-01,  3.1419e-02,  2.2183e-01,  1.8842e-01,  1.5018e-01,\n         -4.3805e-02, -1.7147e-02,  2.7944e-02,  1.5033e-01,  5.3490e-02,\n          4.0420e-02,  1.2127e-01, -1.0565e-01, -1.2569e-01, -2.0521e-01,\n         -2.4627e-02,  1.0081e-01, -3.0270e-02,  1.4673e-02, -5.1758e-02],\n        [-1.6643e-01, -1.0578e-01,  2.0306e-01, -3.0963e-02,  1.1145e-01,\n         -4.5461e-02,  1.0644e-01, -2.1587e-01, -1.2787e-01,  1.4093e-02,\n          5.4570e-02, -8.5114e-02,  1.8297e-01,  1.2734e-01,  3.6456e-02,\n          1.9859e-01,  2.5337e-02,  3.8580e-03,  8.2872e-03, -1.9732e-01],\n        [-1.6421e-02,  2.1595e-01,  7.6488e-02, -1.6083e-01, -1.6375e-02,\n         -2.0555e-02, -2.1042e-01, -1.2703e-01, -6.3906e-02,  5.9078e-02,\n          3.1745e-02, -1.0305e-01,  1.5403e-01, -1.4218e-02, -1.0141e-01,\n         -1.5516e-01, -1.7687e-01, -1.2233e-01,  1.8480e-02, -1.1237e-01],\n        [ 1.5427e-01, -1.8148e-02, -1.7958e-01, -1.3465e-01, -1.0240e-01,\n          4.0017e-02,  1.9112e-01,  4.3824e-02, -1.3900e-01, -1.1932e-01,\n         -1.1368e-02, -5.1175e-02,  9.4141e-02, -1.9657e-01, -1.8779e-01,\n          2.1210e-01, -2.0020e-01, -8.8045e-02, -1.3389e-01,  3.8402e-02],\n        [-1.0734e-01,  3.7776e-02,  1.6785e-01, -1.4271e-01,  3.1841e-02,\n          1.2259e-01, -1.7062e-01,  1.2665e-02,  6.7520e-02, -2.1967e-01,\n          1.2168e-01,  7.3643e-02,  2.1538e-01,  1.1295e-01, -1.9485e-01,\n          1.4140e-01,  1.7714e-01,  1.8875e-01, -2.9406e-03, -6.2599e-02],\n        [ 4.4293e-02,  2.3112e-02, -9.6619e-02, -6.3968e-02, -2.0169e-01,\n         -1.3036e-01, -1.2474e-01, -1.1900e-01,  3.0010e-02, -8.1181e-02,\n         -1.8637e-01, -1.8264e-01,  2.2349e-01, -1.5904e-01,  1.0856e-01,\n          1.1035e-01, -1.0593e-01, -1.2225e-01,  2.0114e-01,  1.2519e-01],\n        [ 8.5351e-02,  1.1717e-01,  4.4905e-02, -6.0015e-02,  8.3804e-02,\n         -3.5213e-02,  2.0126e-01,  1.5274e-01, -2.3523e-02,  7.8763e-02,\n         -1.2887e-01,  2.1176e-02,  8.9301e-02, -1.3094e-01, -1.2232e-01,\n          8.0536e-02, -6.2686e-02,  1.1188e-01,  1.5835e-02, -1.1078e-01],\n        [-6.4338e-02, -1.9537e-01, -6.9534e-02, -1.5145e-01, -8.0506e-02,\n          4.4679e-02, -1.2489e-02, -1.5718e-01, -6.6705e-02,  6.1899e-02,\n          1.0307e-01,  1.5207e-01, -1.4239e-01,  6.7545e-02,  1.2224e-01,\n          9.7770e-02, -2.0538e-01, -5.3065e-02, -5.2840e-02,  6.8100e-02],\n        [ 8.0094e-03,  7.4832e-02,  1.4284e-01,  1.6313e-01,  9.7401e-02,\n          4.0700e-03,  8.0476e-02, -2.2305e-01,  6.1447e-02,  6.8547e-02,\n         -2.1949e-01, -1.8899e-01,  1.5348e-01, -1.6347e-01,  1.5384e-02,\n         -1.4907e-01,  1.6473e-01,  1.8336e-01,  2.0603e-01, -1.0427e-01],\n        [ 1.6796e-01,  1.9764e-01, -5.0052e-02,  7.3143e-02,  1.2729e-01,\n         -1.1174e-01, -2.0262e-01, -1.5309e-01,  1.9522e-01, -4.7083e-02,\n         -5.0632e-02, -4.6984e-02,  1.9223e-01,  1.1629e-01, -9.4493e-02,\n          2.0648e-01,  7.3252e-02,  1.7641e-01, -4.3131e-02, -1.2724e-01],\n        [-4.6827e-02,  2.5071e-02,  4.9492e-02,  1.0295e-01,  1.9726e-01,\n          2.2206e-01, -7.5779e-02,  9.3218e-02, -4.8119e-02,  2.0050e-01,\n          4.4422e-02,  1.2229e-02,  2.1827e-01, -1.0104e-01, -1.9816e-01,\n          5.3951e-02,  9.5195e-02, -9.1410e-02,  1.2918e-01,  1.5737e-01],\n        [ 1.8137e-01, -2.0322e-01, -1.4431e-01,  1.3592e-01,  1.4530e-01,\n          9.4366e-02,  1.1018e-01,  1.7456e-01, -3.4780e-02, -2.0657e-01,\n         -1.4841e-01,  2.3885e-02,  1.5530e-03, -1.5476e-01, -8.9857e-03,\n          1.1008e-01,  7.2384e-02, -2.1358e-01, -3.7615e-02, -1.2381e-01],\n        [ 2.0760e-01, -1.4190e-01,  1.7297e-02, -8.3164e-02, -7.2710e-02,\n          1.9700e-01, -1.7853e-01, -1.3370e-01, -8.2720e-03,  4.0981e-02,\n          9.3878e-02,  2.6802e-02, -1.5669e-01,  1.1058e-01, -3.6389e-02,\n          1.6129e-01, -1.3283e-01,  7.5436e-02, -2.1418e-01,  1.2926e-01],\n        [ 2.0448e-01,  1.5801e-01,  1.7309e-01,  1.8712e-02,  1.5188e-01,\n          8.4586e-02,  1.7781e-01,  1.2446e-01,  8.7923e-02, -8.1990e-02,\n         -2.8521e-02,  1.8565e-01,  1.7053e-01, -2.1593e-01,  1.7871e-01,\n          6.1510e-02, -1.0728e-01,  1.2660e-01, -1.0323e-01, -2.0166e-01],\n        [-2.1697e-01, -1.8895e-02, -4.1553e-02,  1.4106e-01, -1.1804e-01,\n          1.7260e-02,  2.9119e-02,  1.1746e-01, -5.2288e-02, -1.1604e-01,\n         -1.3014e-01,  1.1711e-01,  1.4621e-01, -8.6355e-03, -5.6253e-02,\n          1.7915e-01, -1.6751e-01,  1.6301e-01, -5.7148e-02, -6.6166e-02],\n        [-1.0154e-01,  9.0155e-02, -8.4826e-02,  1.3688e-01, -1.0099e-02,\n         -9.4235e-02, -2.1663e-01, -4.5241e-02, -7.6945e-02, -1.2155e-01,\n          4.8236e-02,  4.9929e-02,  5.3716e-02, -6.7545e-02, -1.9905e-01,\n          5.7292e-02, -9.7408e-02, -9.9535e-02, -8.4751e-02,  1.6109e-01],\n        [-1.4792e-01,  1.7123e-01, -2.1038e-01, -3.6423e-02, -1.4706e-01,\n          1.6873e-01,  1.5933e-01, -2.0744e-01,  1.9453e-01, -1.3154e-01,\n         -2.1822e-01, -1.1001e-02,  4.9757e-02, -1.7687e-01,  3.6997e-02,\n          1.0725e-01, -1.7538e-01,  1.9030e-01, -1.5937e-01,  1.4664e-01],\n        [-1.0485e-02, -1.7779e-01,  6.3871e-02, -1.9611e-01,  1.9167e-01,\n         -4.6825e-02,  1.8714e-02, -1.5993e-01,  1.6354e-01, -1.5091e-01,\n          1.8265e-01, -2.6206e-02, -8.8048e-02, -2.0801e-01,  9.2543e-02,\n         -3.1171e-02,  1.7633e-01,  3.7753e-02,  6.6122e-02,  9.4746e-02],\n        [-3.1523e-03,  6.4365e-02, -1.4790e-01, -1.4785e-01,  3.0835e-02,\n         -6.1348e-02,  9.1175e-02, -2.2087e-01, -1.0692e-01,  9.7056e-03,\n          1.4658e-01, -1.6550e-01,  9.1118e-02,  2.1762e-01,  3.5996e-02,\n          1.8000e-01,  3.0204e-03,  2.5390e-02, -2.2295e-01, -5.6047e-02],\n        [-1.9703e-03, -8.5149e-02,  1.7239e-01, -1.1320e-02, -1.8641e-01,\n         -1.2188e-01, -1.1555e-01, -4.0561e-02, -1.9141e-01, -4.5199e-02,\n          1.2722e-01,  4.6110e-02, -2.1855e-01,  1.5828e-01, -3.5565e-03,\n         -5.9521e-02,  7.1651e-02,  1.8770e-03, -1.3636e-02,  1.1907e-01],\n        [-2.0414e-01,  1.7541e-01,  5.8631e-02,  8.3594e-02, -1.0593e-01,\n          1.1572e-01, -2.1613e-01,  2.1183e-01,  1.6972e-01, -1.0235e-01,\n          1.5532e-02, -1.8018e-01,  1.2200e-01, -2.1165e-01,  1.2573e-01,\n         -5.9728e-02,  7.2139e-03,  2.0264e-01, -2.1254e-01, -2.6876e-02],\n        [ 1.2096e-02,  2.0643e-01,  1.5946e-01,  1.1881e-01,  1.4403e-01,\n         -2.7009e-02, -3.9730e-02, -1.5793e-02, -1.3872e-01,  1.4245e-01,\n          2.0176e-01,  1.8985e-01, -7.7793e-02, -2.0854e-01,  2.0365e-01,\n          7.7828e-02,  7.6446e-02, -2.2732e-02,  1.7581e-01, -1.4695e-01],\n        [-9.9935e-02, -2.0476e-01,  6.1225e-02, -9.3865e-02, -1.3487e-01,\n          1.9710e-01,  9.9241e-02, -1.5805e-01, -8.6691e-02,  2.1422e-01,\n         -1.1292e-01,  5.8353e-02,  6.7650e-03,  1.6255e-01,  1.7160e-01,\n          3.2265e-02,  1.2789e-01, -8.5496e-02,  1.3425e-01, -1.5031e-02],\n        [-1.4296e-01, -1.9670e-01, -5.7865e-02, -5.8609e-04,  2.1124e-01,\n         -1.6738e-01,  3.1935e-02,  2.1116e-01, -4.9804e-02, -2.9323e-02,\n          1.6827e-01, -1.3916e-01, -1.7560e-01,  1.6324e-01,  1.9189e-01,\n          2.0588e-01,  2.5163e-02,  7.9560e-02, -1.6471e-01, -5.8168e-02]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0330, -0.1249,  0.1625,  0.0299,  0.0365, -0.0893,  0.1337, -0.1821,\n        -0.1267,  0.1784,  0.0982,  0.1937,  0.0362,  0.0271, -0.1251, -0.1946,\n         0.0050, -0.0048,  0.1365,  0.0523,  0.2008, -0.0706,  0.0446,  0.0750,\n         0.0240, -0.0874, -0.1403,  0.0129,  0.0836, -0.1278, -0.0888, -0.0542],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0804,  0.1318,  0.1066, -0.0316,  0.1059, -0.1284, -0.1176, -0.1074,\n          0.0223,  0.0247, -0.1738, -0.1635,  0.0167,  0.0576, -0.0396, -0.0039,\n         -0.0441,  0.0450,  0.0984, -0.0072,  0.0569, -0.0645, -0.0168, -0.1367,\n         -0.0441,  0.0020, -0.0452, -0.1302,  0.0827, -0.1629, -0.0501, -0.0226],\n        [-0.0359,  0.1743, -0.1284,  0.0869,  0.0391, -0.0113, -0.0843,  0.1293,\n         -0.0094,  0.0996, -0.1094, -0.1381,  0.0642, -0.0026,  0.0710,  0.0282,\n         -0.1455, -0.1356, -0.0563, -0.0155,  0.1324, -0.1087,  0.0006, -0.1720,\n         -0.1539,  0.0581,  0.0131, -0.0883, -0.0879,  0.0749,  0.0479, -0.0321],\n        [-0.1469, -0.1252, -0.0700, -0.0088,  0.0676, -0.0179, -0.0188, -0.1332,\n         -0.1136, -0.0734,  0.1626, -0.1497, -0.0990, -0.0602,  0.0920, -0.1414,\n          0.1067, -0.1492, -0.0774, -0.0088,  0.1253,  0.1438, -0.1608, -0.0150,\n         -0.0015, -0.1121, -0.1028, -0.0790, -0.0922,  0.0668,  0.1715,  0.0940],\n        [ 0.0493,  0.0203, -0.1545,  0.1127,  0.0333,  0.0217,  0.1141, -0.1704,\n         -0.0814, -0.1262, -0.1240, -0.1541,  0.1217, -0.0594,  0.1630, -0.1163,\n          0.0302,  0.0351, -0.0438, -0.0015, -0.0350,  0.0658,  0.1654,  0.0737,\n         -0.1018,  0.0290, -0.0266,  0.1206,  0.0681,  0.1179,  0.1432, -0.1302],\n        [-0.1569, -0.1131, -0.0800, -0.0536,  0.1574, -0.1565,  0.0502,  0.0301,\n         -0.1379,  0.0719, -0.1733,  0.0883, -0.0629,  0.1741,  0.1748, -0.1617,\n         -0.0579, -0.0724,  0.1098,  0.1289,  0.0669,  0.1408, -0.0108, -0.1259,\n          0.1492,  0.0416, -0.0496,  0.0199,  0.0143,  0.0699, -0.1490, -0.0808],\n        [-0.0692, -0.0085,  0.1623, -0.0069,  0.0877,  0.0305,  0.1651,  0.1602,\n          0.0941,  0.0262, -0.0149,  0.1365, -0.0998,  0.0181,  0.1701,  0.1550,\n          0.1586, -0.1197,  0.1051, -0.0893,  0.0207, -0.0292, -0.1450,  0.0390,\n         -0.1272, -0.1631,  0.0824,  0.0469,  0.1099,  0.0355, -0.1683,  0.0645],\n        [-0.0340, -0.0601, -0.1106,  0.1634, -0.1667,  0.1079,  0.0134, -0.1164,\n          0.1364, -0.0562, -0.0404, -0.0891,  0.1705,  0.1363,  0.1741,  0.1748,\n          0.0061,  0.1425,  0.1432, -0.1733, -0.1615,  0.0165, -0.0419,  0.0686,\n          0.0753, -0.0550, -0.1297,  0.0263, -0.1629,  0.1349, -0.0789, -0.1263],\n        [ 0.1089,  0.0765, -0.1231, -0.1602,  0.0932,  0.0510, -0.0051, -0.1648,\n         -0.1033, -0.1623,  0.0337,  0.1157, -0.0390, -0.1093,  0.0927, -0.0641,\n         -0.1074,  0.0822, -0.1273,  0.0604, -0.0024,  0.1261, -0.1688,  0.0614,\n          0.0414, -0.0834,  0.0590,  0.1103, -0.0438,  0.1308,  0.0744,  0.0056],\n        [-0.0759,  0.0357, -0.1016,  0.0696, -0.0341,  0.0929, -0.0455, -0.0777,\n         -0.0231, -0.1276, -0.0294, -0.1674,  0.1562, -0.0139,  0.0628,  0.1581,\n         -0.1697,  0.0864, -0.0421, -0.1418,  0.0632, -0.0620, -0.0419, -0.1512,\n         -0.1597,  0.1145, -0.1554,  0.0266,  0.0121,  0.1288, -0.0537, -0.0215],\n        [-0.1388,  0.0117,  0.0411, -0.1659,  0.0023, -0.0209, -0.1627, -0.0137,\n          0.1643,  0.0617,  0.1479, -0.1336,  0.0593, -0.0559,  0.0426,  0.0363,\n         -0.1534, -0.0230,  0.1357, -0.1420,  0.0406, -0.1245,  0.0718,  0.1220,\n         -0.0257,  0.1247, -0.0442, -0.1369,  0.1263,  0.0939, -0.1352,  0.0631],\n        [ 0.1416, -0.1576,  0.0670,  0.1205,  0.1283, -0.1199, -0.1291,  0.1430,\n          0.0852, -0.0917,  0.1299,  0.1659,  0.1186, -0.0559, -0.0571, -0.0243,\n          0.0155, -0.0992, -0.0963, -0.0550,  0.1302, -0.1515,  0.1466, -0.1385,\n         -0.0507,  0.0340, -0.1144,  0.0830,  0.0783,  0.1149, -0.0971, -0.1400],\n        [ 0.0494, -0.0829,  0.0464,  0.1054,  0.1052,  0.0210, -0.0948, -0.0738,\n          0.0520, -0.1510,  0.1094, -0.0827,  0.0518, -0.0362,  0.0092, -0.1756,\n          0.0232,  0.1011,  0.0031, -0.0865, -0.1083,  0.0779,  0.0926, -0.1446,\n         -0.1395, -0.0577, -0.0507,  0.0935,  0.0547,  0.0225, -0.0897,  0.0643],\n        [-0.1138, -0.1327, -0.1180,  0.0309, -0.1320,  0.1404,  0.0566, -0.1533,\n         -0.0759,  0.0832, -0.1162, -0.0428, -0.0429,  0.0439,  0.0794, -0.1610,\n         -0.1034, -0.1292,  0.0704, -0.0551,  0.0735,  0.1377,  0.0259, -0.1330,\n         -0.0084, -0.0808, -0.0655,  0.0934,  0.1605,  0.1042,  0.0129,  0.1069],\n        [-0.0924, -0.0396,  0.1655,  0.0342, -0.1436, -0.0019,  0.0283, -0.1357,\n         -0.0970,  0.1581, -0.1449, -0.0944, -0.0040,  0.1395,  0.1486,  0.0158,\n         -0.0010,  0.1112, -0.1714, -0.1248, -0.1099, -0.0295, -0.0883,  0.0745,\n          0.1045,  0.1070,  0.1766,  0.1264, -0.0212,  0.0349,  0.0203, -0.0386],\n        [ 0.0224,  0.1268,  0.0922, -0.0794,  0.0091, -0.0509, -0.1711,  0.0929,\n         -0.1316, -0.0628, -0.0563,  0.1205,  0.1039, -0.0862,  0.0219, -0.1240,\n         -0.0573, -0.0772, -0.1043, -0.1638,  0.0179, -0.1413, -0.1707, -0.0765,\n          0.1619,  0.0306,  0.0931,  0.0702, -0.0399, -0.0157,  0.0450,  0.1557],\n        [-0.0799,  0.1608,  0.1083, -0.1027,  0.0845,  0.1707, -0.1426, -0.1026,\n         -0.0714, -0.1000, -0.1255, -0.1684,  0.1191, -0.0969,  0.1761,  0.0419,\n         -0.1279,  0.0840,  0.0772, -0.0062,  0.1691, -0.1065,  0.0646, -0.1156,\n          0.1485, -0.0828,  0.0929, -0.1018, -0.0238, -0.0105,  0.1527,  0.0362]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-9.1938e-02,  9.8354e-02,  1.5956e-01, -1.6923e-01, -6.5054e-02,\n         5.9297e-02, -1.4435e-01,  1.1713e-01,  6.8982e-02,  1.4176e-04,\n         1.1412e-01, -8.1777e-02, -3.2395e-02, -5.3612e-02, -1.4444e-01,\n        -4.1716e-02], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2008,  0.1497, -0.1525,  0.2088, -0.1912,  0.0911, -0.1490,  0.1846,\n         -0.1575, -0.2165,  0.0878,  0.2246, -0.1175, -0.1255, -0.2162,  0.2395],\n        [-0.0961, -0.0377,  0.1846, -0.0707,  0.2459,  0.1359,  0.0320,  0.2474,\n          0.1987,  0.1336,  0.1660,  0.0357,  0.1198, -0.0107,  0.0480, -0.0358],\n        [-0.0051,  0.0273, -0.0924, -0.0581, -0.2072,  0.1003,  0.1737,  0.0595,\n          0.0889, -0.2170,  0.2361,  0.0595, -0.0160,  0.0734,  0.1912, -0.2004],\n        [ 0.1912,  0.1468, -0.0904,  0.1844,  0.1705,  0.2031, -0.0281,  0.1607,\n          0.0479,  0.1917, -0.2462, -0.0312, -0.2320, -0.1328, -0.1245, -0.0347],\n        [-0.1557, -0.1156, -0.0845,  0.0531, -0.2224, -0.0977,  0.1101, -0.1907,\n         -0.1019, -0.0986,  0.0633, -0.1788, -0.0380,  0.0530,  0.1160, -0.0868],\n        [ 0.1389, -0.2275, -0.1031,  0.2033,  0.1598,  0.2335, -0.1472,  0.1009,\n          0.2393,  0.1082, -0.2387,  0.1111, -0.1280,  0.1645,  0.0356, -0.1688],\n        [ 0.1498, -0.1188, -0.0714, -0.0935,  0.0495, -0.0785, -0.1771,  0.0919,\n         -0.0035, -0.1651,  0.0481, -0.1161,  0.0075,  0.2090,  0.0680,  0.0120],\n        [-0.2474,  0.2096, -0.1676,  0.0389,  0.0594, -0.1961, -0.1768, -0.1130,\n         -0.0083,  0.2368, -0.1613,  0.2016, -0.2337, -0.1615,  0.1269, -0.0792]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2254, -0.1242, -0.1450, -0.0668,  0.0440,  0.0834, -0.1180,  0.2180],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.3102,  0.0297,  0.1730,  0.2649,  0.3462, -0.0811,  0.1124, -0.2347]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0365], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x10a40e350>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x11b538c40>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s48860000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s48860000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}