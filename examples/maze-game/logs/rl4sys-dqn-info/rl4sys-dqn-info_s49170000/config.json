{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s49170000"
    },
    "q_lr":	0.0005,
    "seed":	49170000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x11e4c4c10>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0520, -0.1195, -0.1206, -0.0474, -0.1650, -0.0301, -0.0544,  0.2044,\n         0.0283, -0.2024, -0.0317, -0.0783, -0.0222, -0.1679,  0.2035, -0.1255,\n         0.0007, -0.0639,  0.1466,  0.0693, -0.1446, -0.1477, -0.2010,  0.0136,\n         0.1210,  0.0293, -0.0666,  0.1799, -0.1267,  0.1902,  0.1617,  0.1809],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-5.2079e-02,  1.0734e-01,  1.9321e-01,  2.9510e-02,  3.6320e-03,\n          2.1614e-01,  1.3992e-03, -1.7324e-01,  2.0867e-01,  1.3763e-01,\n          2.2355e-01, -2.1529e-01,  1.7827e-01, -1.7274e-01,  1.9896e-03,\n         -1.5167e-01, -1.4817e-01, -9.0517e-02, -1.5772e-02,  2.1292e-01],\n        [-2.1496e-01, -1.3761e-01,  5.8738e-02, -3.7545e-02,  9.1915e-02,\n          4.1150e-02, -1.4464e-01,  7.7986e-02,  1.8046e-01,  1.9229e-02,\n         -7.5467e-02,  2.1664e-01, -9.1207e-02,  2.0615e-01,  1.5126e-01,\n         -3.9242e-02,  9.3266e-02, -1.7331e-01, -2.1371e-01,  1.6024e-01],\n        [ 1.7824e-01,  1.3694e-01, -1.8263e-01, -2.1315e-01,  3.7496e-02,\n         -5.0968e-02, -9.3874e-02, -1.4675e-01, -1.4491e-01,  8.1355e-02,\n          5.5548e-02, -4.8387e-02,  1.3121e-01,  6.0500e-02, -1.6728e-01,\n          1.0261e-01, -1.6618e-01, -9.6393e-02, -1.1171e-01, -1.5077e-01],\n        [ 7.3054e-02,  8.9358e-02,  1.2748e-01,  8.9427e-02, -1.4042e-01,\n         -6.0261e-02,  1.3551e-01, -1.9018e-01, -1.9926e-01, -7.6041e-03,\n         -2.0257e-02,  1.6241e-01, -5.2343e-02, -1.4170e-01, -1.5239e-04,\n         -1.3421e-01,  9.3699e-02,  2.1571e-01, -1.6448e-01,  1.3706e-01],\n        [-9.2159e-02, -1.3829e-01, -1.7927e-02, -5.8191e-02, -1.4212e-02,\n          9.0053e-02,  1.8609e-01,  2.0378e-01, -3.4061e-02, -1.0433e-01,\n         -1.3907e-02, -1.6484e-01, -6.9301e-02,  1.8741e-01, -1.9805e-01,\n          1.5646e-01,  2.1674e-01,  1.9179e-01, -2.9179e-02, -1.7108e-01],\n        [-6.6409e-02,  1.4040e-01,  1.5091e-01,  1.3122e-01, -5.0094e-02,\n          1.3560e-01, -5.9088e-02, -1.0612e-01,  1.9073e-01,  1.7143e-01,\n          1.0045e-01, -1.1783e-01, -2.0249e-01,  1.0119e-01, -5.2370e-02,\n         -3.5944e-02,  1.4772e-01,  1.6585e-01,  4.4431e-02, -1.0144e-01],\n        [ 1.2088e-01, -2.1145e-01, -3.7535e-02,  6.1319e-02,  6.3868e-02,\n          1.8703e-01, -1.5258e-01, -8.0100e-02,  4.6179e-02,  1.8411e-01,\n         -1.4099e-01,  5.3088e-02,  3.0922e-02,  1.2418e-01, -1.1262e-02,\n          1.8533e-01, -2.1858e-01, -2.5216e-02, -1.3199e-02,  1.3285e-01],\n        [-1.1348e-01,  1.1243e-02, -1.1753e-01,  3.6278e-02, -2.2070e-01,\n         -4.4714e-02, -1.7467e-01,  1.1643e-01,  9.4744e-02,  1.5813e-01,\n          7.0454e-02,  1.3728e-01, -7.1932e-02, -6.6361e-02, -4.9852e-02,\n          9.6793e-02,  1.7374e-01,  2.2275e-01,  1.2420e-02,  4.7772e-02],\n        [ 1.0563e-01,  1.3722e-01,  1.0778e-01, -1.5148e-01, -1.3854e-01,\n          1.9492e-01,  9.6171e-02,  1.7135e-01,  1.8161e-01, -1.6318e-01,\n         -8.2787e-02, -1.9730e-01,  1.4646e-01, -1.3662e-01, -9.5071e-02,\n         -1.9704e-01, -6.7684e-02, -4.4870e-02,  9.4055e-02, -1.4123e-01],\n        [-1.9362e-01,  5.2425e-02,  5.4367e-02, -6.1301e-02,  7.2101e-02,\n         -1.0106e-01, -5.2307e-02, -1.8920e-02,  1.0513e-01,  1.7505e-01,\n          9.8837e-02,  5.5127e-02,  6.8488e-03,  4.4452e-03,  1.1829e-01,\n         -2.0291e-01, -6.7525e-02,  1.7376e-01, -5.8201e-02,  4.0648e-02],\n        [-1.4837e-01, -5.7764e-05, -3.3177e-02,  7.2347e-02, -1.7548e-01,\n          7.0869e-02, -2.8191e-04, -4.9186e-02, -9.8018e-02,  1.2725e-01,\n         -3.6405e-02,  6.5823e-02, -1.5751e-01,  1.5066e-01, -1.5136e-01,\n         -1.2289e-01, -2.1956e-01, -1.5145e-01,  1.8243e-01,  1.4963e-01],\n        [ 1.8790e-01, -3.2610e-02, -2.0490e-01, -9.0023e-02,  3.9818e-02,\n          5.6098e-02, -2.3067e-02, -4.5402e-02, -4.4540e-02, -1.4776e-01,\n         -1.9010e-01, -1.4629e-01, -6.5276e-02,  4.7284e-02, -1.3109e-01,\n          5.8413e-02, -1.9043e-01,  1.2818e-01, -2.0685e-01,  2.6295e-02],\n        [-5.6278e-02, -1.4951e-02,  5.3929e-02,  1.9202e-01,  1.4024e-01,\n          2.1117e-01,  2.0864e-01,  1.0714e-01, -1.0472e-01,  3.0145e-02,\n          1.5793e-01,  6.3679e-02,  6.2768e-02,  3.8204e-02, -1.1577e-01,\n          2.1276e-01, -2.1887e-01,  2.1469e-01,  8.9256e-02,  1.5302e-01],\n        [-1.5487e-01,  1.3847e-01,  1.4102e-01, -9.1877e-02,  2.1477e-01,\n         -2.5006e-02,  9.0422e-02,  1.0072e-01,  9.8871e-02,  1.0245e-01,\n         -8.3455e-02, -1.0012e-02, -2.3080e-02,  9.5278e-02, -2.9510e-02,\n          8.9119e-02,  6.5991e-02, -1.6271e-01,  1.9211e-01, -1.1965e-01],\n        [-1.0575e-01,  2.1167e-01, -5.8578e-02, -1.2722e-01,  9.1829e-02,\n          3.3935e-03, -3.0314e-02,  6.6925e-02,  4.9283e-02,  1.4462e-01,\n         -2.0812e-02,  1.2222e-01,  1.0330e-01,  1.4340e-01,  1.0001e-01,\n         -2.1474e-01,  1.8193e-01, -5.9772e-02,  1.9499e-01, -2.0144e-01],\n        [-3.2523e-02,  5.3261e-02, -1.4434e-01,  8.2593e-02,  1.4513e-02,\n          1.7765e-01,  9.0586e-02,  4.7595e-02, -1.8878e-01, -1.4248e-01,\n         -6.8903e-02,  7.2062e-02, -1.1028e-02,  1.3286e-01,  1.0588e-01,\n         -1.3786e-02,  4.3344e-02,  1.2552e-01,  1.4696e-01,  7.4455e-02],\n        [ 1.1629e-01,  2.5371e-02,  1.6722e-01,  2.1053e-01, -1.1183e-01,\n         -2.5337e-02,  3.7812e-02,  1.2668e-01,  5.7623e-02,  8.2436e-02,\n         -1.2024e-01, -4.6879e-02, -1.5171e-01,  1.7662e-01, -1.9992e-01,\n          1.0125e-01,  1.5891e-01,  2.8104e-02, -1.0174e-01,  1.7336e-02],\n        [ 2.0365e-01,  2.1227e-02, -5.4945e-02, -2.0886e-01, -1.6719e-01,\n          1.3623e-01,  5.6689e-02, -2.2410e-02,  3.8067e-02, -1.0371e-01,\n         -8.0169e-02, -6.3097e-02,  1.4809e-01,  3.9338e-02,  2.6523e-02,\n         -4.6788e-02, -1.1587e-01, -1.3977e-01,  2.0290e-01, -1.7686e-01],\n        [-7.1934e-02, -1.9174e-01, -1.8528e-01, -9.7752e-02,  1.1049e-01,\n          9.5627e-02,  1.6404e-01,  1.1460e-01, -1.6341e-01,  5.6731e-02,\n         -8.9147e-02, -1.0224e-01, -8.3827e-02,  2.1056e-01,  1.9962e-01,\n          5.1233e-02,  1.8697e-01, -2.0276e-01, -2.5633e-02,  1.5342e-01],\n        [ 1.8129e-02,  1.0240e-01,  1.3993e-01,  2.0021e-01,  1.8618e-01,\n         -9.1005e-02, -1.3589e-01,  1.6791e-01,  2.1226e-01,  2.2022e-01,\n         -2.2024e-01, -1.3932e-01, -2.0695e-01, -1.8009e-01,  1.2095e-01,\n         -9.0824e-03, -4.5225e-02, -1.1092e-01, -4.0217e-02, -1.3707e-01],\n        [-1.2723e-01,  1.6505e-01, -5.1084e-02,  1.4768e-03,  1.0256e-01,\n         -1.1024e-02, -2.0324e-01, -1.6808e-02,  6.6400e-05, -2.8093e-02,\n          1.7614e-01, -9.6905e-02,  2.5040e-02, -1.5640e-01,  7.5378e-02,\n          1.8535e-01,  2.1616e-01,  1.9394e-01,  5.6063e-02,  7.8148e-02],\n        [-9.2719e-02, -1.4562e-01,  3.7546e-02, -2.1930e-01, -1.9374e-01,\n         -8.1985e-02,  1.7981e-01, -6.7856e-02, -1.8047e-01, -1.4297e-01,\n          1.8391e-01, -6.6727e-02,  1.5476e-01,  1.6379e-01, -1.0592e-01,\n          1.2145e-01,  1.3406e-01,  2.0477e-01, -2.1361e-01, -2.1095e-01],\n        [-1.5754e-01,  1.0432e-01,  2.1034e-01,  1.7815e-01, -7.7274e-02,\n          5.1574e-02,  4.2959e-02, -9.1245e-02, -4.8441e-02,  8.3816e-02,\n          1.9366e-01,  2.3201e-02, -1.5502e-01,  1.8263e-01,  1.6983e-01,\n         -1.1339e-01, -2.1965e-01, -9.7467e-02,  6.9995e-02, -2.0012e-01],\n        [-1.4245e-01, -1.9409e-01, -9.3450e-02, -5.7689e-02, -4.8398e-03,\n         -2.4512e-02, -3.5084e-02, -1.9025e-01, -2.3556e-02, -1.0696e-01,\n         -1.5178e-01, -1.8663e-01,  1.6065e-01,  1.3604e-01,  2.0334e-01,\n          1.0126e-01, -1.6675e-01, -2.6405e-02, -7.9214e-02, -6.0591e-02],\n        [-4.0022e-02,  4.7914e-02, -2.0188e-01, -1.8880e-01, -1.9200e-01,\n          1.1988e-01,  2.2287e-01, -8.5864e-02,  1.3092e-01,  1.4426e-01,\n          1.3372e-01, -8.9336e-02, -1.7086e-01,  2.0684e-01,  1.8250e-01,\n          9.9909e-02,  1.0517e-01,  7.3530e-02,  6.6203e-04,  8.6512e-02],\n        [ 1.3077e-01, -1.7479e-01, -6.9024e-02,  2.1745e-01,  1.3792e-01,\n         -1.2187e-01, -2.0857e-01, -1.0505e-01, -1.5193e-01,  3.0937e-02,\n         -3.3555e-02, -2.1822e-01, -2.0464e-01,  2.0018e-01,  1.3226e-01,\n          7.0593e-02, -1.1529e-01,  2.3522e-02, -2.4980e-02,  1.6689e-01],\n        [-1.9401e-01,  4.1403e-02, -1.8902e-01,  1.4376e-01,  1.7358e-02,\n          1.9630e-03,  1.0334e-02, -6.6513e-02, -3.0439e-02,  2.0355e-02,\n         -1.1218e-01,  1.8516e-01,  5.3850e-03,  9.7403e-02,  1.5912e-02,\n         -5.3350e-02,  6.1100e-02,  3.9726e-02, -1.2059e-01,  1.5440e-01],\n        [-6.7787e-02,  7.7383e-03,  1.0463e-01,  6.8903e-02, -2.2514e-02,\n         -8.4618e-02, -1.5261e-01,  1.2480e-01, -2.0454e-02, -1.9574e-01,\n         -1.9639e-01, -3.7106e-02, -1.1486e-01,  8.6946e-02, -1.6765e-01,\n         -1.0687e-01, -4.5465e-02, -4.4431e-02, -1.5027e-01,  6.9395e-02],\n        [ 6.8802e-02, -1.1607e-01,  1.5255e-01,  3.7872e-02,  4.6296e-02,\n          1.6012e-01,  6.4048e-03,  2.0097e-01,  2.1946e-01,  7.2874e-03,\n          4.5063e-02,  1.3149e-01,  1.8548e-01,  8.9589e-02, -8.4047e-02,\n          1.9642e-01, -1.4560e-01, -1.1261e-01, -5.5784e-02, -4.7406e-02],\n        [-1.8610e-01, -7.2854e-02, -9.6460e-02, -1.5850e-02,  3.7994e-02,\n          1.6604e-01, -6.9916e-02, -2.1012e-01,  1.9227e-01, -1.9637e-01,\n         -1.9832e-01, -2.0656e-01, -1.9716e-01, -2.3363e-02, -2.0119e-01,\n         -1.1779e-01, -3.9429e-02,  1.9457e-01, -4.4557e-03, -1.8906e-01],\n        [-9.5841e-02, -1.1757e-01,  1.3160e-01,  2.0573e-01, -2.1157e-01,\n         -1.2588e-01, -1.9403e-01, -7.3154e-02, -2.1121e-01, -1.3643e-01,\n         -8.7592e-02,  2.1249e-01, -2.1407e-01,  2.1715e-01, -1.0055e-01,\n          1.8651e-01, -2.8304e-02, -5.8661e-02, -2.7371e-02, -1.8365e-01],\n        [-5.3969e-02,  1.8772e-01,  4.1943e-02, -4.7815e-02, -1.7433e-01,\n          5.6620e-02,  1.4234e-01, -6.7049e-02, -1.9892e-01, -8.5053e-02,\n         -2.9129e-02, -1.4871e-01,  8.0438e-02,  1.0514e-01,  1.0812e-01,\n         -1.8872e-01, -2.1438e-01, -3.6833e-02,  1.8711e-01,  2.1458e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1076, -0.1506, -0.1500,  0.1015,  0.1193, -0.1549, -0.0202, -0.0637,\n         0.0924, -0.1686,  0.0721, -0.1234,  0.1707,  0.1297,  0.0094, -0.0335],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0750, -0.0228, -0.1125,  0.0550, -0.1745, -0.0796, -0.0797, -0.1013,\n         -0.1031,  0.0970, -0.0080, -0.1236,  0.1634,  0.1491, -0.1513,  0.1700,\n         -0.0993,  0.0677, -0.1539, -0.0468, -0.0728, -0.0565,  0.0222,  0.1406,\n         -0.1382,  0.0196,  0.0021,  0.0672,  0.0333,  0.0165,  0.0464, -0.1647],\n        [ 0.1555,  0.0236,  0.0576, -0.0049, -0.0210,  0.0395,  0.0553,  0.0929,\n          0.0429, -0.1104,  0.1315,  0.0290,  0.1464,  0.1204,  0.1083, -0.1149,\n          0.0178,  0.0808,  0.0353,  0.1205,  0.1351, -0.1046,  0.0764, -0.0520,\n          0.1761,  0.0338, -0.1662,  0.0458,  0.1487, -0.0437,  0.0956, -0.0447],\n        [ 0.0598, -0.0889,  0.0021,  0.1318,  0.0935, -0.1124, -0.0882,  0.0540,\n          0.0411,  0.1101, -0.1317,  0.0568, -0.0312, -0.0333,  0.0372,  0.0289,\n         -0.0490,  0.1125, -0.0665,  0.0532,  0.1618, -0.0277, -0.0548, -0.0045,\n          0.0184, -0.0568,  0.0288,  0.1553, -0.0673, -0.0850,  0.0195, -0.1016],\n        [ 0.1191,  0.0501, -0.0652,  0.0688,  0.0541, -0.0358,  0.1675, -0.0725,\n          0.1609, -0.0222, -0.0392,  0.0676,  0.1188,  0.0761,  0.1226, -0.1719,\n          0.1507, -0.0084, -0.0855, -0.1058, -0.0455, -0.0230,  0.0375, -0.0723,\n          0.0901, -0.0477, -0.0333,  0.1458, -0.0321, -0.1290,  0.1253, -0.0236],\n        [ 0.0923, -0.0439,  0.0672, -0.1156,  0.1249, -0.0437,  0.1573, -0.1566,\n          0.0005,  0.1094,  0.0813,  0.0309,  0.0717,  0.1114,  0.0499,  0.1672,\n          0.1172, -0.1647,  0.0966, -0.1597, -0.1669, -0.1066, -0.1187,  0.0752,\n          0.0301, -0.1554, -0.1604, -0.0265,  0.0451,  0.0696,  0.0460,  0.0536],\n        [ 0.1180, -0.0184, -0.0975, -0.0752, -0.0488,  0.1031,  0.0818,  0.1712,\n         -0.1655, -0.0196,  0.1729,  0.0507, -0.1498, -0.0547, -0.0826, -0.0525,\n          0.0443,  0.0298,  0.0004,  0.0730, -0.0215,  0.1034,  0.0084, -0.1673,\n          0.0902,  0.1740,  0.1446, -0.0636,  0.0820, -0.0183, -0.0107,  0.1377],\n        [-0.1476,  0.0635, -0.1350, -0.1624, -0.1604, -0.1534,  0.0930, -0.0410,\n          0.1611,  0.1059,  0.0679, -0.0194, -0.0752,  0.1206,  0.0659,  0.0219,\n         -0.0120,  0.0300, -0.1467,  0.1573,  0.0479, -0.0157,  0.1524,  0.0325,\n          0.0415, -0.0195,  0.0603, -0.0152, -0.0765,  0.1160, -0.1494, -0.0113],\n        [ 0.0080,  0.1182,  0.0625, -0.1519,  0.1156,  0.0844, -0.0669, -0.0210,\n         -0.0101, -0.0454,  0.0997,  0.1598, -0.0288,  0.0584,  0.0877,  0.0650,\n         -0.1600, -0.1116,  0.1227,  0.0236, -0.1070,  0.1389, -0.1305, -0.1486,\n         -0.0738, -0.0818, -0.1335,  0.0688, -0.1690, -0.1418,  0.0365,  0.0266],\n        [ 0.0708,  0.1169,  0.0500, -0.0678, -0.0946,  0.0500, -0.0235,  0.0757,\n          0.0020,  0.0170,  0.1715,  0.0507, -0.0164, -0.0391, -0.0593,  0.1189,\n         -0.1340,  0.0802, -0.1189,  0.1388, -0.0254,  0.0643,  0.1320,  0.1368,\n          0.0460,  0.1422, -0.0384, -0.1459, -0.1044, -0.0258,  0.0505,  0.0409],\n        [ 0.0606, -0.1019,  0.1370, -0.1108, -0.0895,  0.0403, -0.0935,  0.0200,\n          0.0877,  0.1250, -0.1598, -0.1387, -0.0332,  0.0705, -0.0745, -0.0747,\n          0.1370,  0.1766,  0.1050, -0.1595, -0.1222,  0.1077,  0.0991, -0.1058,\n         -0.0702,  0.0298,  0.0488,  0.1039, -0.1434,  0.0432,  0.1553,  0.1251],\n        [-0.1611, -0.0464, -0.0970, -0.0504, -0.0142, -0.1243, -0.1189,  0.0220,\n          0.1565, -0.0345, -0.0223, -0.1334,  0.0981, -0.1670, -0.0929, -0.0824,\n          0.1639, -0.0941,  0.0670, -0.0204, -0.0413,  0.1673, -0.1152, -0.1556,\n          0.0784,  0.0970, -0.0749, -0.0363,  0.1450, -0.1033,  0.1077,  0.1760],\n        [ 0.1096, -0.1255, -0.0841,  0.1004, -0.1088,  0.0881,  0.0220, -0.0389,\n          0.0682,  0.1568, -0.0252,  0.1247,  0.0242, -0.0786, -0.0101,  0.0693,\n          0.0319, -0.1278,  0.0949, -0.0790,  0.0789,  0.0050,  0.0135, -0.0222,\n          0.0351, -0.0125,  0.1547, -0.0367, -0.1472,  0.1148,  0.1280,  0.1115],\n        [-0.0079, -0.0182, -0.1364, -0.0376, -0.1685, -0.0050, -0.0170,  0.1572,\n          0.1226, -0.0124,  0.1249, -0.0558, -0.0089, -0.1313,  0.0055,  0.0440,\n          0.0476,  0.0935, -0.0162, -0.1057, -0.0545,  0.0352,  0.0426,  0.0588,\n         -0.0711, -0.0464, -0.0940,  0.1348, -0.1691, -0.1144, -0.1438,  0.1131],\n        [ 0.1404,  0.0280,  0.1728,  0.1427,  0.0759, -0.0965,  0.0136,  0.1521,\n          0.1203,  0.0211, -0.1695,  0.0486, -0.1678, -0.0682,  0.1624,  0.1379,\n         -0.0832, -0.1309, -0.0389,  0.1115, -0.0098, -0.0122,  0.1337,  0.1379,\n         -0.1327, -0.1383,  0.0302,  0.0635, -0.0638,  0.0831, -0.0306,  0.0347],\n        [ 0.0513,  0.1318, -0.0164, -0.1029,  0.1624,  0.0151, -0.0387, -0.0757,\n         -0.0964, -0.1091, -0.0186, -0.0370, -0.0891, -0.1621, -0.1217, -0.1216,\n          0.1175, -0.1741,  0.0700, -0.0336,  0.0435, -0.0005, -0.0328, -0.1244,\n          0.1598, -0.0715, -0.1684, -0.0084, -0.0717, -0.0246, -0.1736, -0.0048],\n        [-0.1698,  0.0922,  0.1474, -0.0171,  0.1193,  0.1403,  0.0363, -0.0530,\n         -0.1242, -0.0279,  0.1159,  0.0268,  0.0266,  0.1742, -0.1084, -0.0528,\n          0.1403, -0.1607,  0.1202,  0.0175,  0.0351,  0.0381,  0.0502, -0.0350,\n          0.0773,  0.0161,  0.0699,  0.0067,  0.0774,  0.1370,  0.0736, -0.1150]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0898, -0.1788, -0.1366, -0.1754, -0.0881, -0.0105,  0.1988, -0.2047],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0044, -0.1051, -0.1554, -0.0619,  0.0859, -0.1999, -0.0832, -0.1883,\n         -0.2176,  0.0103,  0.1457,  0.2078, -0.0769, -0.0710, -0.0727, -0.0020],\n        [-0.0265,  0.2491, -0.0710, -0.0727,  0.2269,  0.1967, -0.0694, -0.2445,\n         -0.0006,  0.0727,  0.2337, -0.1206,  0.1468, -0.0085, -0.2210,  0.0692],\n        [-0.0746, -0.1668,  0.2150,  0.0723,  0.1346,  0.0549, -0.1585,  0.1202,\n          0.2113, -0.0665, -0.1432,  0.0492, -0.1735, -0.0680, -0.1222, -0.0701],\n        [-0.1582,  0.1302, -0.0901,  0.1954, -0.1121, -0.2420, -0.1554,  0.2419,\n         -0.1136,  0.1816, -0.0688, -0.1042, -0.0240,  0.1162,  0.2148,  0.2436],\n        [-0.1220, -0.1230,  0.0706,  0.1207, -0.0153,  0.1976, -0.2014, -0.1403,\n         -0.1898, -0.1914,  0.0087,  0.0571,  0.0379,  0.1523, -0.1026, -0.2441],\n        [ 0.0252, -0.0504,  0.1040, -0.1681, -0.0146,  0.0896,  0.1579, -0.1787,\n         -0.2300,  0.2281, -0.1885,  0.0485, -0.1484, -0.2194,  0.0572,  0.0322],\n        [-0.1848, -0.0641, -0.1133,  0.2249, -0.0984, -0.2315,  0.1127, -0.1070,\n          0.1549,  0.1243,  0.1933,  0.0747, -0.1695,  0.1253, -0.0217,  0.1258],\n        [ 0.1814, -0.1130,  0.1034, -0.1529, -0.2075, -0.0434, -0.0464,  0.0014,\n          0.0388, -0.1373,  0.0105,  0.1059,  0.0168,  0.0731, -0.0916,  0.0161]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2761], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2244,  0.1807, -0.2117,  0.1119, -0.2825,  0.3355, -0.1198,  0.2339]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-5.2079e-02,  1.0734e-01,  1.9321e-01,  2.9510e-02,  3.6320e-03,\n          2.1614e-01,  1.3992e-03, -1.7324e-01,  2.0867e-01,  1.3763e-01,\n          2.2355e-01, -2.1529e-01,  1.7827e-01, -1.7274e-01,  1.9896e-03,\n         -1.5167e-01, -1.4817e-01, -9.0517e-02, -1.5772e-02,  2.1292e-01],\n        [-2.1496e-01, -1.3761e-01,  5.8738e-02, -3.7545e-02,  9.1915e-02,\n          4.1150e-02, -1.4464e-01,  7.7986e-02,  1.8046e-01,  1.9229e-02,\n         -7.5467e-02,  2.1664e-01, -9.1207e-02,  2.0615e-01,  1.5126e-01,\n         -3.9242e-02,  9.3266e-02, -1.7331e-01, -2.1371e-01,  1.6024e-01],\n        [ 1.7824e-01,  1.3694e-01, -1.8263e-01, -2.1315e-01,  3.7496e-02,\n         -5.0968e-02, -9.3874e-02, -1.4675e-01, -1.4491e-01,  8.1355e-02,\n          5.5548e-02, -4.8387e-02,  1.3121e-01,  6.0500e-02, -1.6728e-01,\n          1.0261e-01, -1.6618e-01, -9.6393e-02, -1.1171e-01, -1.5077e-01],\n        [ 7.3054e-02,  8.9358e-02,  1.2748e-01,  8.9427e-02, -1.4042e-01,\n         -6.0261e-02,  1.3551e-01, -1.9018e-01, -1.9926e-01, -7.6041e-03,\n         -2.0257e-02,  1.6241e-01, -5.2343e-02, -1.4170e-01, -1.5239e-04,\n         -1.3421e-01,  9.3699e-02,  2.1571e-01, -1.6448e-01,  1.3706e-01],\n        [-9.2159e-02, -1.3829e-01, -1.7927e-02, -5.8191e-02, -1.4212e-02,\n          9.0053e-02,  1.8609e-01,  2.0378e-01, -3.4061e-02, -1.0433e-01,\n         -1.3907e-02, -1.6484e-01, -6.9301e-02,  1.8741e-01, -1.9805e-01,\n          1.5646e-01,  2.1674e-01,  1.9179e-01, -2.9179e-02, -1.7108e-01],\n        [-6.6409e-02,  1.4040e-01,  1.5091e-01,  1.3122e-01, -5.0094e-02,\n          1.3560e-01, -5.9088e-02, -1.0612e-01,  1.9073e-01,  1.7143e-01,\n          1.0045e-01, -1.1783e-01, -2.0249e-01,  1.0119e-01, -5.2370e-02,\n         -3.5944e-02,  1.4772e-01,  1.6585e-01,  4.4431e-02, -1.0144e-01],\n        [ 1.2088e-01, -2.1145e-01, -3.7535e-02,  6.1319e-02,  6.3868e-02,\n          1.8703e-01, -1.5258e-01, -8.0100e-02,  4.6179e-02,  1.8411e-01,\n         -1.4099e-01,  5.3088e-02,  3.0922e-02,  1.2418e-01, -1.1262e-02,\n          1.8533e-01, -2.1858e-01, -2.5216e-02, -1.3199e-02,  1.3285e-01],\n        [-1.1348e-01,  1.1243e-02, -1.1753e-01,  3.6278e-02, -2.2070e-01,\n         -4.4714e-02, -1.7467e-01,  1.1643e-01,  9.4744e-02,  1.5813e-01,\n          7.0454e-02,  1.3728e-01, -7.1932e-02, -6.6361e-02, -4.9852e-02,\n          9.6793e-02,  1.7374e-01,  2.2275e-01,  1.2420e-02,  4.7772e-02],\n        [ 1.0563e-01,  1.3722e-01,  1.0778e-01, -1.5148e-01, -1.3854e-01,\n          1.9492e-01,  9.6171e-02,  1.7135e-01,  1.8161e-01, -1.6318e-01,\n         -8.2787e-02, -1.9730e-01,  1.4646e-01, -1.3662e-01, -9.5071e-02,\n         -1.9704e-01, -6.7684e-02, -4.4870e-02,  9.4055e-02, -1.4123e-01],\n        [-1.9362e-01,  5.2425e-02,  5.4367e-02, -6.1301e-02,  7.2101e-02,\n         -1.0106e-01, -5.2307e-02, -1.8920e-02,  1.0513e-01,  1.7505e-01,\n          9.8837e-02,  5.5127e-02,  6.8488e-03,  4.4452e-03,  1.1829e-01,\n         -2.0291e-01, -6.7525e-02,  1.7376e-01, -5.8201e-02,  4.0648e-02],\n        [-1.4837e-01, -5.7764e-05, -3.3177e-02,  7.2347e-02, -1.7548e-01,\n          7.0869e-02, -2.8191e-04, -4.9186e-02, -9.8018e-02,  1.2725e-01,\n         -3.6405e-02,  6.5823e-02, -1.5751e-01,  1.5066e-01, -1.5136e-01,\n         -1.2289e-01, -2.1956e-01, -1.5145e-01,  1.8243e-01,  1.4963e-01],\n        [ 1.8790e-01, -3.2610e-02, -2.0490e-01, -9.0023e-02,  3.9818e-02,\n          5.6098e-02, -2.3067e-02, -4.5402e-02, -4.4540e-02, -1.4776e-01,\n         -1.9010e-01, -1.4629e-01, -6.5276e-02,  4.7284e-02, -1.3109e-01,\n          5.8413e-02, -1.9043e-01,  1.2818e-01, -2.0685e-01,  2.6295e-02],\n        [-5.6278e-02, -1.4951e-02,  5.3929e-02,  1.9202e-01,  1.4024e-01,\n          2.1117e-01,  2.0864e-01,  1.0714e-01, -1.0472e-01,  3.0145e-02,\n          1.5793e-01,  6.3679e-02,  6.2768e-02,  3.8204e-02, -1.1577e-01,\n          2.1276e-01, -2.1887e-01,  2.1469e-01,  8.9256e-02,  1.5302e-01],\n        [-1.5487e-01,  1.3847e-01,  1.4102e-01, -9.1877e-02,  2.1477e-01,\n         -2.5006e-02,  9.0422e-02,  1.0072e-01,  9.8871e-02,  1.0245e-01,\n         -8.3455e-02, -1.0012e-02, -2.3080e-02,  9.5278e-02, -2.9510e-02,\n          8.9119e-02,  6.5991e-02, -1.6271e-01,  1.9211e-01, -1.1965e-01],\n        [-1.0575e-01,  2.1167e-01, -5.8578e-02, -1.2722e-01,  9.1829e-02,\n          3.3935e-03, -3.0314e-02,  6.6925e-02,  4.9283e-02,  1.4462e-01,\n         -2.0812e-02,  1.2222e-01,  1.0330e-01,  1.4340e-01,  1.0001e-01,\n         -2.1474e-01,  1.8193e-01, -5.9772e-02,  1.9499e-01, -2.0144e-01],\n        [-3.2523e-02,  5.3261e-02, -1.4434e-01,  8.2593e-02,  1.4513e-02,\n          1.7765e-01,  9.0586e-02,  4.7595e-02, -1.8878e-01, -1.4248e-01,\n         -6.8903e-02,  7.2062e-02, -1.1028e-02,  1.3286e-01,  1.0588e-01,\n         -1.3786e-02,  4.3344e-02,  1.2552e-01,  1.4696e-01,  7.4455e-02],\n        [ 1.1629e-01,  2.5371e-02,  1.6722e-01,  2.1053e-01, -1.1183e-01,\n         -2.5337e-02,  3.7812e-02,  1.2668e-01,  5.7623e-02,  8.2436e-02,\n         -1.2024e-01, -4.6879e-02, -1.5171e-01,  1.7662e-01, -1.9992e-01,\n          1.0125e-01,  1.5891e-01,  2.8104e-02, -1.0174e-01,  1.7336e-02],\n        [ 2.0365e-01,  2.1227e-02, -5.4945e-02, -2.0886e-01, -1.6719e-01,\n          1.3623e-01,  5.6689e-02, -2.2410e-02,  3.8067e-02, -1.0371e-01,\n         -8.0169e-02, -6.3097e-02,  1.4809e-01,  3.9338e-02,  2.6523e-02,\n         -4.6788e-02, -1.1587e-01, -1.3977e-01,  2.0290e-01, -1.7686e-01],\n        [-7.1934e-02, -1.9174e-01, -1.8528e-01, -9.7752e-02,  1.1049e-01,\n          9.5627e-02,  1.6404e-01,  1.1460e-01, -1.6341e-01,  5.6731e-02,\n         -8.9147e-02, -1.0224e-01, -8.3827e-02,  2.1056e-01,  1.9962e-01,\n          5.1233e-02,  1.8697e-01, -2.0276e-01, -2.5633e-02,  1.5342e-01],\n        [ 1.8129e-02,  1.0240e-01,  1.3993e-01,  2.0021e-01,  1.8618e-01,\n         -9.1005e-02, -1.3589e-01,  1.6791e-01,  2.1226e-01,  2.2022e-01,\n         -2.2024e-01, -1.3932e-01, -2.0695e-01, -1.8009e-01,  1.2095e-01,\n         -9.0824e-03, -4.5225e-02, -1.1092e-01, -4.0217e-02, -1.3707e-01],\n        [-1.2723e-01,  1.6505e-01, -5.1084e-02,  1.4768e-03,  1.0256e-01,\n         -1.1024e-02, -2.0324e-01, -1.6808e-02,  6.6400e-05, -2.8093e-02,\n          1.7614e-01, -9.6905e-02,  2.5040e-02, -1.5640e-01,  7.5378e-02,\n          1.8535e-01,  2.1616e-01,  1.9394e-01,  5.6063e-02,  7.8148e-02],\n        [-9.2719e-02, -1.4562e-01,  3.7546e-02, -2.1930e-01, -1.9374e-01,\n         -8.1985e-02,  1.7981e-01, -6.7856e-02, -1.8047e-01, -1.4297e-01,\n          1.8391e-01, -6.6727e-02,  1.5476e-01,  1.6379e-01, -1.0592e-01,\n          1.2145e-01,  1.3406e-01,  2.0477e-01, -2.1361e-01, -2.1095e-01],\n        [-1.5754e-01,  1.0432e-01,  2.1034e-01,  1.7815e-01, -7.7274e-02,\n          5.1574e-02,  4.2959e-02, -9.1245e-02, -4.8441e-02,  8.3816e-02,\n          1.9366e-01,  2.3201e-02, -1.5502e-01,  1.8263e-01,  1.6983e-01,\n         -1.1339e-01, -2.1965e-01, -9.7467e-02,  6.9995e-02, -2.0012e-01],\n        [-1.4245e-01, -1.9409e-01, -9.3450e-02, -5.7689e-02, -4.8398e-03,\n         -2.4512e-02, -3.5084e-02, -1.9025e-01, -2.3556e-02, -1.0696e-01,\n         -1.5178e-01, -1.8663e-01,  1.6065e-01,  1.3604e-01,  2.0334e-01,\n          1.0126e-01, -1.6675e-01, -2.6405e-02, -7.9214e-02, -6.0591e-02],\n        [-4.0022e-02,  4.7914e-02, -2.0188e-01, -1.8880e-01, -1.9200e-01,\n          1.1988e-01,  2.2287e-01, -8.5864e-02,  1.3092e-01,  1.4426e-01,\n          1.3372e-01, -8.9336e-02, -1.7086e-01,  2.0684e-01,  1.8250e-01,\n          9.9909e-02,  1.0517e-01,  7.3530e-02,  6.6203e-04,  8.6512e-02],\n        [ 1.3077e-01, -1.7479e-01, -6.9024e-02,  2.1745e-01,  1.3792e-01,\n         -1.2187e-01, -2.0857e-01, -1.0505e-01, -1.5193e-01,  3.0937e-02,\n         -3.3555e-02, -2.1822e-01, -2.0464e-01,  2.0018e-01,  1.3226e-01,\n          7.0593e-02, -1.1529e-01,  2.3522e-02, -2.4980e-02,  1.6689e-01],\n        [-1.9401e-01,  4.1403e-02, -1.8902e-01,  1.4376e-01,  1.7358e-02,\n          1.9630e-03,  1.0334e-02, -6.6513e-02, -3.0439e-02,  2.0355e-02,\n         -1.1218e-01,  1.8516e-01,  5.3850e-03,  9.7403e-02,  1.5912e-02,\n         -5.3350e-02,  6.1100e-02,  3.9726e-02, -1.2059e-01,  1.5440e-01],\n        [-6.7787e-02,  7.7383e-03,  1.0463e-01,  6.8903e-02, -2.2514e-02,\n         -8.4618e-02, -1.5261e-01,  1.2480e-01, -2.0454e-02, -1.9574e-01,\n         -1.9639e-01, -3.7106e-02, -1.1486e-01,  8.6946e-02, -1.6765e-01,\n         -1.0687e-01, -4.5465e-02, -4.4431e-02, -1.5027e-01,  6.9395e-02],\n        [ 6.8802e-02, -1.1607e-01,  1.5255e-01,  3.7872e-02,  4.6296e-02,\n          1.6012e-01,  6.4048e-03,  2.0097e-01,  2.1946e-01,  7.2874e-03,\n          4.5063e-02,  1.3149e-01,  1.8548e-01,  8.9589e-02, -8.4047e-02,\n          1.9642e-01, -1.4560e-01, -1.1261e-01, -5.5784e-02, -4.7406e-02],\n        [-1.8610e-01, -7.2854e-02, -9.6460e-02, -1.5850e-02,  3.7994e-02,\n          1.6604e-01, -6.9916e-02, -2.1012e-01,  1.9227e-01, -1.9637e-01,\n         -1.9832e-01, -2.0656e-01, -1.9716e-01, -2.3363e-02, -2.0119e-01,\n         -1.1779e-01, -3.9429e-02,  1.9457e-01, -4.4557e-03, -1.8906e-01],\n        [-9.5841e-02, -1.1757e-01,  1.3160e-01,  2.0573e-01, -2.1157e-01,\n         -1.2588e-01, -1.9403e-01, -7.3154e-02, -2.1121e-01, -1.3643e-01,\n         -8.7592e-02,  2.1249e-01, -2.1407e-01,  2.1715e-01, -1.0055e-01,\n          1.8651e-01, -2.8304e-02, -5.8661e-02, -2.7371e-02, -1.8365e-01],\n        [-5.3969e-02,  1.8772e-01,  4.1943e-02, -4.7815e-02, -1.7433e-01,\n          5.6620e-02,  1.4234e-01, -6.7049e-02, -1.9892e-01, -8.5053e-02,\n         -2.9129e-02, -1.4871e-01,  8.0438e-02,  1.0514e-01,  1.0812e-01,\n         -1.8872e-01, -2.1438e-01, -3.6833e-02,  1.8711e-01,  2.1458e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0520, -0.1195, -0.1206, -0.0474, -0.1650, -0.0301, -0.0544,  0.2044,\n         0.0283, -0.2024, -0.0317, -0.0783, -0.0222, -0.1679,  0.2035, -0.1255,\n         0.0007, -0.0639,  0.1466,  0.0693, -0.1446, -0.1477, -0.2010,  0.0136,\n         0.1210,  0.0293, -0.0666,  0.1799, -0.1267,  0.1902,  0.1617,  0.1809],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0750, -0.0228, -0.1125,  0.0550, -0.1745, -0.0796, -0.0797, -0.1013,\n         -0.1031,  0.0970, -0.0080, -0.1236,  0.1634,  0.1491, -0.1513,  0.1700,\n         -0.0993,  0.0677, -0.1539, -0.0468, -0.0728, -0.0565,  0.0222,  0.1406,\n         -0.1382,  0.0196,  0.0021,  0.0672,  0.0333,  0.0165,  0.0464, -0.1647],\n        [ 0.1555,  0.0236,  0.0576, -0.0049, -0.0210,  0.0395,  0.0553,  0.0929,\n          0.0429, -0.1104,  0.1315,  0.0290,  0.1464,  0.1204,  0.1083, -0.1149,\n          0.0178,  0.0808,  0.0353,  0.1205,  0.1351, -0.1046,  0.0764, -0.0520,\n          0.1761,  0.0338, -0.1662,  0.0458,  0.1487, -0.0437,  0.0956, -0.0447],\n        [ 0.0598, -0.0889,  0.0021,  0.1318,  0.0935, -0.1124, -0.0882,  0.0540,\n          0.0411,  0.1101, -0.1317,  0.0568, -0.0312, -0.0333,  0.0372,  0.0289,\n         -0.0490,  0.1125, -0.0665,  0.0532,  0.1618, -0.0277, -0.0548, -0.0045,\n          0.0184, -0.0568,  0.0288,  0.1553, -0.0673, -0.0850,  0.0195, -0.1016],\n        [ 0.1191,  0.0501, -0.0652,  0.0688,  0.0541, -0.0358,  0.1675, -0.0725,\n          0.1609, -0.0222, -0.0392,  0.0676,  0.1188,  0.0761,  0.1226, -0.1719,\n          0.1507, -0.0084, -0.0855, -0.1058, -0.0455, -0.0230,  0.0375, -0.0723,\n          0.0901, -0.0477, -0.0333,  0.1458, -0.0321, -0.1290,  0.1253, -0.0236],\n        [ 0.0923, -0.0439,  0.0672, -0.1156,  0.1249, -0.0437,  0.1573, -0.1566,\n          0.0005,  0.1094,  0.0813,  0.0309,  0.0717,  0.1114,  0.0499,  0.1672,\n          0.1172, -0.1647,  0.0966, -0.1597, -0.1669, -0.1066, -0.1187,  0.0752,\n          0.0301, -0.1554, -0.1604, -0.0265,  0.0451,  0.0696,  0.0460,  0.0536],\n        [ 0.1180, -0.0184, -0.0975, -0.0752, -0.0488,  0.1031,  0.0818,  0.1712,\n         -0.1655, -0.0196,  0.1729,  0.0507, -0.1498, -0.0547, -0.0826, -0.0525,\n          0.0443,  0.0298,  0.0004,  0.0730, -0.0215,  0.1034,  0.0084, -0.1673,\n          0.0902,  0.1740,  0.1446, -0.0636,  0.0820, -0.0183, -0.0107,  0.1377],\n        [-0.1476,  0.0635, -0.1350, -0.1624, -0.1604, -0.1534,  0.0930, -0.0410,\n          0.1611,  0.1059,  0.0679, -0.0194, -0.0752,  0.1206,  0.0659,  0.0219,\n         -0.0120,  0.0300, -0.1467,  0.1573,  0.0479, -0.0157,  0.1524,  0.0325,\n          0.0415, -0.0195,  0.0603, -0.0152, -0.0765,  0.1160, -0.1494, -0.0113],\n        [ 0.0080,  0.1182,  0.0625, -0.1519,  0.1156,  0.0844, -0.0669, -0.0210,\n         -0.0101, -0.0454,  0.0997,  0.1598, -0.0288,  0.0584,  0.0877,  0.0650,\n         -0.1600, -0.1116,  0.1227,  0.0236, -0.1070,  0.1389, -0.1305, -0.1486,\n         -0.0738, -0.0818, -0.1335,  0.0688, -0.1690, -0.1418,  0.0365,  0.0266],\n        [ 0.0708,  0.1169,  0.0500, -0.0678, -0.0946,  0.0500, -0.0235,  0.0757,\n          0.0020,  0.0170,  0.1715,  0.0507, -0.0164, -0.0391, -0.0593,  0.1189,\n         -0.1340,  0.0802, -0.1189,  0.1388, -0.0254,  0.0643,  0.1320,  0.1368,\n          0.0460,  0.1422, -0.0384, -0.1459, -0.1044, -0.0258,  0.0505,  0.0409],\n        [ 0.0606, -0.1019,  0.1370, -0.1108, -0.0895,  0.0403, -0.0935,  0.0200,\n          0.0877,  0.1250, -0.1598, -0.1387, -0.0332,  0.0705, -0.0745, -0.0747,\n          0.1370,  0.1766,  0.1050, -0.1595, -0.1222,  0.1077,  0.0991, -0.1058,\n         -0.0702,  0.0298,  0.0488,  0.1039, -0.1434,  0.0432,  0.1553,  0.1251],\n        [-0.1611, -0.0464, -0.0970, -0.0504, -0.0142, -0.1243, -0.1189,  0.0220,\n          0.1565, -0.0345, -0.0223, -0.1334,  0.0981, -0.1670, -0.0929, -0.0824,\n          0.1639, -0.0941,  0.0670, -0.0204, -0.0413,  0.1673, -0.1152, -0.1556,\n          0.0784,  0.0970, -0.0749, -0.0363,  0.1450, -0.1033,  0.1077,  0.1760],\n        [ 0.1096, -0.1255, -0.0841,  0.1004, -0.1088,  0.0881,  0.0220, -0.0389,\n          0.0682,  0.1568, -0.0252,  0.1247,  0.0242, -0.0786, -0.0101,  0.0693,\n          0.0319, -0.1278,  0.0949, -0.0790,  0.0789,  0.0050,  0.0135, -0.0222,\n          0.0351, -0.0125,  0.1547, -0.0367, -0.1472,  0.1148,  0.1280,  0.1115],\n        [-0.0079, -0.0182, -0.1364, -0.0376, -0.1685, -0.0050, -0.0170,  0.1572,\n          0.1226, -0.0124,  0.1249, -0.0558, -0.0089, -0.1313,  0.0055,  0.0440,\n          0.0476,  0.0935, -0.0162, -0.1057, -0.0545,  0.0352,  0.0426,  0.0588,\n         -0.0711, -0.0464, -0.0940,  0.1348, -0.1691, -0.1144, -0.1438,  0.1131],\n        [ 0.1404,  0.0280,  0.1728,  0.1427,  0.0759, -0.0965,  0.0136,  0.1521,\n          0.1203,  0.0211, -0.1695,  0.0486, -0.1678, -0.0682,  0.1624,  0.1379,\n         -0.0832, -0.1309, -0.0389,  0.1115, -0.0098, -0.0122,  0.1337,  0.1379,\n         -0.1327, -0.1383,  0.0302,  0.0635, -0.0638,  0.0831, -0.0306,  0.0347],\n        [ 0.0513,  0.1318, -0.0164, -0.1029,  0.1624,  0.0151, -0.0387, -0.0757,\n         -0.0964, -0.1091, -0.0186, -0.0370, -0.0891, -0.1621, -0.1217, -0.1216,\n          0.1175, -0.1741,  0.0700, -0.0336,  0.0435, -0.0005, -0.0328, -0.1244,\n          0.1598, -0.0715, -0.1684, -0.0084, -0.0717, -0.0246, -0.1736, -0.0048],\n        [-0.1698,  0.0922,  0.1474, -0.0171,  0.1193,  0.1403,  0.0363, -0.0530,\n         -0.1242, -0.0279,  0.1159,  0.0268,  0.0266,  0.1742, -0.1084, -0.0528,\n          0.1403, -0.1607,  0.1202,  0.0175,  0.0351,  0.0381,  0.0502, -0.0350,\n          0.0773,  0.0161,  0.0699,  0.0067,  0.0774,  0.1370,  0.0736, -0.1150]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1076, -0.1506, -0.1500,  0.1015,  0.1193, -0.1549, -0.0202, -0.0637,\n         0.0924, -0.1686,  0.0721, -0.1234,  0.1707,  0.1297,  0.0094, -0.0335],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0044, -0.1051, -0.1554, -0.0619,  0.0859, -0.1999, -0.0832, -0.1883,\n         -0.2176,  0.0103,  0.1457,  0.2078, -0.0769, -0.0710, -0.0727, -0.0020],\n        [-0.0265,  0.2491, -0.0710, -0.0727,  0.2269,  0.1967, -0.0694, -0.2445,\n         -0.0006,  0.0727,  0.2337, -0.1206,  0.1468, -0.0085, -0.2210,  0.0692],\n        [-0.0746, -0.1668,  0.2150,  0.0723,  0.1346,  0.0549, -0.1585,  0.1202,\n          0.2113, -0.0665, -0.1432,  0.0492, -0.1735, -0.0680, -0.1222, -0.0701],\n        [-0.1582,  0.1302, -0.0901,  0.1954, -0.1121, -0.2420, -0.1554,  0.2419,\n         -0.1136,  0.1816, -0.0688, -0.1042, -0.0240,  0.1162,  0.2148,  0.2436],\n        [-0.1220, -0.1230,  0.0706,  0.1207, -0.0153,  0.1976, -0.2014, -0.1403,\n         -0.1898, -0.1914,  0.0087,  0.0571,  0.0379,  0.1523, -0.1026, -0.2441],\n        [ 0.0252, -0.0504,  0.1040, -0.1681, -0.0146,  0.0896,  0.1579, -0.1787,\n         -0.2300,  0.2281, -0.1885,  0.0485, -0.1484, -0.2194,  0.0572,  0.0322],\n        [-0.1848, -0.0641, -0.1133,  0.2249, -0.0984, -0.2315,  0.1127, -0.1070,\n          0.1549,  0.1243,  0.1933,  0.0747, -0.1695,  0.1253, -0.0217,  0.1258],\n        [ 0.1814, -0.1130,  0.1034, -0.1529, -0.2075, -0.0434, -0.0464,  0.0014,\n          0.0388, -0.1373,  0.0105,  0.1059,  0.0168,  0.0731, -0.0916,  0.0161]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0898, -0.1788, -0.1366, -0.1754, -0.0881, -0.0105,  0.1988, -0.2047],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2244,  0.1807, -0.2117,  0.1119, -0.2825,  0.3355, -0.1198,  0.2339]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2761], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x10bf3e320>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x11e4c4700>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s49170000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s49170000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}