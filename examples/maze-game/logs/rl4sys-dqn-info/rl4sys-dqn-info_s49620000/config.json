{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s49620000"
    },
    "q_lr":	0.0005,
    "seed":	49620000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x123e2cc40>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1888, -0.0338,  0.1772, -0.1134, -0.0698, -0.2023, -0.0319,  0.1776,\n         0.0565,  0.0562, -0.0714,  0.1097,  0.1363, -0.0952,  0.0699, -0.0007,\n         0.1439,  0.2002,  0.1600, -0.1516,  0.0050, -0.0761,  0.1768, -0.1262,\n        -0.0870, -0.0855,  0.0746,  0.2116, -0.0403,  0.1637, -0.1903,  0.1619],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-8.5536e-02,  1.2665e-01,  1.0815e-01,  8.7634e-02,  1.3998e-01,\n         -5.6332e-02,  1.2491e-01, -6.4397e-02,  1.7812e-01,  1.8878e-01,\n          8.9442e-02, -2.0434e-01,  5.0910e-02, -2.2603e-02, -1.9423e-01,\n         -7.5247e-02, -5.7281e-02, -6.0337e-02, -1.7277e-01,  2.1365e-01],\n        [-9.7835e-02,  8.5734e-02, -1.3592e-01,  1.2191e-01,  1.7055e-01,\n          1.5838e-01,  2.7022e-02, -2.0059e-01,  1.3870e-01, -1.6445e-01,\n          7.6679e-02,  8.1908e-02, -1.3182e-01, -1.8488e-01,  1.9001e-01,\n          1.2848e-01, -5.5297e-02,  3.5399e-02,  1.0515e-01,  1.6532e-01],\n        [-1.4206e-01,  9.5070e-02, -8.0873e-02,  1.9281e-01,  2.0008e-01,\n          1.8637e-01, -1.8113e-02, -1.9701e-01, -8.9830e-02,  2.0422e-01,\n         -3.8893e-02, -4.7931e-02, -1.0751e-01, -8.5763e-02, -1.7235e-01,\n         -1.2746e-01,  3.2055e-02,  4.4764e-02,  5.0673e-02, -1.9249e-01],\n        [ 9.4522e-02,  1.6632e-01,  2.2268e-01,  1.1644e-01,  2.1037e-01,\n          2.0666e-02, -7.0188e-02, -2.1447e-02,  1.5657e-01,  5.5677e-02,\n          1.2495e-03, -1.9546e-02,  1.9980e-01,  7.2054e-03, -5.8386e-02,\n         -1.3755e-01,  1.2170e-01, -5.3231e-02,  7.2467e-02,  5.6070e-02],\n        [ 8.6686e-02,  3.7874e-02, -5.9696e-02, -1.6238e-01,  8.6516e-03,\n         -9.3154e-02,  1.2877e-01,  1.3912e-01, -1.5893e-01,  1.3915e-01,\n         -3.6269e-02, -9.1106e-02, -4.7850e-02,  1.4664e-01,  9.4512e-02,\n          9.3229e-02,  8.6884e-03,  7.1778e-02, -1.2229e-02,  1.1152e-01],\n        [-2.0898e-02,  8.9631e-02,  1.1126e-01, -2.0525e-01,  5.7776e-02,\n          1.4502e-01, -4.4228e-04, -1.5327e-01,  3.4971e-02,  2.0783e-01,\n          1.7101e-01,  1.9106e-02, -2.1307e-01,  8.1727e-02,  6.6450e-02,\n         -4.3929e-02,  2.2280e-01,  7.9305e-02,  3.9175e-02,  7.5515e-02],\n        [-2.9326e-02, -2.6865e-02,  1.5861e-01, -1.9713e-01,  1.9042e-01,\n          1.4101e-01,  2.0873e-01,  8.1661e-02,  1.9636e-01,  2.0342e-01,\n         -6.9302e-02, -1.9732e-01, -1.2436e-01,  1.2406e-01, -8.6022e-03,\n          2.1423e-01, -2.1406e-01, -1.1286e-01,  3.9190e-02,  1.3842e-01],\n        [ 1.4800e-01,  6.1104e-02,  6.8849e-02, -3.6113e-03,  7.5452e-02,\n         -1.3558e-01, -2.9113e-02, -1.7228e-01, -9.2145e-02,  2.3165e-02,\n          2.1230e-01, -1.8605e-01, -2.1770e-01,  2.2106e-01, -1.4909e-01,\n         -1.6707e-01, -7.0215e-02,  1.0241e-01, -1.9263e-01, -1.2495e-01],\n        [-1.3368e-01,  1.6145e-01,  2.2312e-01,  3.2500e-02,  1.4564e-02,\n         -6.5177e-02, -1.8909e-01,  1.3946e-01,  5.3232e-05,  8.4606e-02,\n         -9.3305e-02,  1.2052e-01, -3.7375e-02,  3.3039e-02,  2.0235e-02,\n         -1.6459e-01,  1.2670e-01, -1.4956e-01,  4.0680e-02, -1.0175e-01],\n        [-1.5996e-01,  1.7183e-01, -1.2836e-01,  1.1401e-01, -1.4431e-01,\n          9.2913e-03, -1.0121e-01, -7.9510e-02,  4.0359e-02, -2.2288e-01,\n          6.3136e-02,  1.0268e-01,  1.6650e-01, -7.8343e-03,  7.5017e-02,\n          1.2556e-02, -2.5349e-02, -1.5082e-01, -2.3755e-02,  4.9594e-02],\n        [-1.8424e-01,  2.7434e-02,  7.3608e-02,  9.6855e-02,  2.0392e-01,\n          6.0550e-02,  5.4903e-02, -1.6656e-01,  6.7391e-02, -1.1736e-02,\n          1.6605e-01,  7.5866e-02,  1.9200e-01,  1.4521e-01,  2.1690e-01,\n          8.2427e-02,  4.9130e-02,  4.4479e-02, -6.2235e-02, -1.9356e-01],\n        [-1.7685e-01,  1.7114e-01,  1.4924e-03, -8.8505e-02,  1.7544e-01,\n          6.2927e-02,  1.4677e-01, -2.0380e-01,  8.1681e-02, -9.7018e-02,\n         -1.9993e-01, -1.5014e-01,  4.6469e-02,  5.9054e-02, -1.2010e-01,\n          1.7740e-01, -3.7528e-02, -9.8268e-02,  4.2078e-02,  6.6646e-02],\n        [-8.3508e-02, -1.8730e-01,  2.0105e-02,  4.0544e-02,  1.6890e-01,\n          1.2831e-01,  1.6884e-01, -6.4274e-02,  3.3425e-02, -1.8114e-01,\n         -7.0201e-02, -1.1650e-01, -5.8866e-02,  1.1766e-01,  1.0582e-01,\n         -4.6451e-02, -9.6132e-02, -2.0995e-01, -5.5253e-02, -1.2264e-01],\n        [-1.9360e-01,  2.2237e-01, -3.4136e-02,  1.7515e-01,  1.5625e-01,\n         -6.2674e-02,  2.0267e-01, -2.0329e-01,  1.2593e-01, -2.0921e-01,\n          1.7689e-02, -3.5637e-02, -4.1952e-02, -8.0581e-02,  4.3547e-02,\n         -1.3038e-02,  1.6012e-01, -3.3496e-02, -9.0773e-02,  1.2494e-01],\n        [-1.0342e-01, -1.2402e-01,  1.0828e-01, -1.0367e-01, -1.8202e-01,\n          8.0896e-02, -1.1952e-01, -2.1820e-01, -1.8301e-01, -4.0799e-02,\n         -1.7525e-01,  2.2308e-01,  1.4048e-01, -1.3588e-01,  1.4733e-01,\n         -1.5776e-02, -1.8067e-01, -1.6067e-01, -2.2310e-01,  7.1267e-02],\n        [-2.1713e-01, -1.6461e-01,  1.9577e-01, -1.4496e-01,  5.7208e-02,\n         -2.1028e-01, -1.1518e-01, -9.7824e-02,  1.5420e-01, -8.0151e-02,\n         -1.1367e-01, -2.1046e-01, -1.6227e-02, -1.3525e-01,  1.5786e-01,\n         -9.9558e-02, -2.1685e-01, -5.8707e-02,  1.3130e-01, -2.5941e-02],\n        [-1.2362e-01,  3.0581e-02,  3.2952e-03, -6.0372e-02,  1.9382e-01,\n          1.7606e-01, -1.7564e-01,  1.9494e-01,  1.5522e-01, -1.4347e-01,\n         -2.1555e-01, -1.9057e-01,  1.7962e-01, -7.0013e-02,  5.1912e-02,\n         -5.6141e-02, -1.3015e-01, -8.7833e-02,  3.9275e-02, -9.6743e-02],\n        [-6.4450e-02, -5.3448e-02, -5.7408e-02, -5.1995e-02,  1.3636e-01,\n         -4.8093e-02, -5.5083e-02, -1.7337e-01, -2.1675e-01, -1.8438e-01,\n         -1.5470e-01, -5.4047e-02, -1.8584e-01, -2.5278e-02,  9.0777e-02,\n         -6.5861e-02, -1.3072e-04,  1.8864e-01,  6.0159e-02, -1.5906e-01],\n        [ 7.0251e-02,  1.2837e-01, -1.7908e-01,  1.7908e-01, -6.8073e-02,\n          1.4617e-01,  3.6915e-02,  2.8776e-03,  1.0848e-01, -2.1419e-02,\n         -9.4041e-03, -2.0195e-01,  4.7310e-02, -1.1708e-01, -1.1662e-01,\n          1.5477e-01,  8.7291e-02,  9.9523e-02,  1.6115e-01,  3.5513e-02],\n        [-1.9075e-01, -6.2148e-02, -1.3523e-01,  1.1219e-01, -8.3794e-03,\n         -1.8827e-03, -2.0342e-01, -1.3030e-01,  9.6621e-02, -1.0952e-01,\n         -5.9744e-02,  2.1696e-02,  1.7212e-01, -4.8937e-02,  6.1788e-02,\n          1.1013e-01, -1.8549e-02,  1.6380e-01,  1.4261e-02, -1.0018e-01],\n        [-4.3186e-02, -1.7035e-01,  9.2055e-02, -1.0325e-01,  2.0580e-02,\n         -2.1901e-01, -1.9912e-01,  1.0182e-01,  2.0866e-01, -9.2897e-02,\n         -1.0232e-01,  7.9981e-02,  2.1835e-01,  1.3211e-02,  2.1736e-01,\n          1.3697e-01,  1.1651e-01,  1.2675e-01,  3.6733e-03,  1.9647e-01],\n        [-1.4098e-03,  9.5886e-02,  7.9792e-02, -8.0088e-02, -8.7404e-02,\n          1.6640e-01, -5.9380e-02, -1.5757e-01, -2.1279e-01,  2.7976e-02,\n         -7.8182e-03,  4.1609e-02, -1.9095e-01, -1.1486e-01,  9.9885e-02,\n         -1.9629e-01, -1.3228e-01,  1.2059e-01,  2.6926e-02,  1.3522e-01],\n        [-1.5082e-01, -4.0560e-02,  1.3310e-01,  1.8902e-01,  2.1361e-01,\n         -5.9532e-02,  1.2121e-01, -2.0179e-02, -1.2549e-01,  5.5543e-02,\n          3.3334e-02,  9.1587e-02,  1.3687e-01,  8.0597e-02, -2.0269e-01,\n          1.5074e-01, -8.5132e-02, -1.1072e-01,  1.5393e-01, -1.6712e-01],\n        [ 1.5468e-02,  1.1560e-01, -1.8834e-01,  5.2513e-02,  1.2611e-01,\n         -2.0639e-01, -1.9667e-01,  1.1385e-02, -1.1511e-01, -1.4109e-01,\n          3.7950e-02,  9.4594e-02,  7.2863e-02,  8.6907e-02,  1.9610e-01,\n         -1.6822e-01, -9.6594e-03, -2.0985e-01, -7.2083e-02,  1.3278e-01],\n        [ 1.2090e-01,  1.2224e-01,  3.8538e-02, -1.8129e-01,  1.4226e-01,\n          2.0829e-01,  1.6244e-01, -5.1476e-02, -1.9655e-01, -3.2085e-02,\n         -1.9944e-01,  1.2428e-01,  1.6732e-01,  1.5135e-01, -1.3622e-01,\n          3.6070e-02, -1.8737e-01,  6.5499e-02,  5.9952e-02,  1.9400e-01],\n        [-2.1914e-01,  2.1841e-01,  3.0513e-02, -2.6067e-02,  1.1261e-01,\n          1.7516e-01, -1.3595e-01, -2.2116e-01,  8.9831e-02,  6.4261e-02,\n         -1.9398e-01, -1.5645e-01,  1.3323e-01, -4.5442e-02, -8.3316e-02,\n          1.8910e-01, -1.8614e-01, -1.8513e-01, -1.6701e-01, -1.5600e-01],\n        [ 3.1675e-02,  1.6169e-02, -1.1129e-01, -4.7644e-02,  1.8805e-01,\n          1.9874e-01, -8.4422e-02, -1.0875e-01,  6.9762e-02, -4.2692e-02,\n          1.5064e-01, -2.9365e-02,  2.2326e-01,  3.4381e-02, -1.8391e-01,\n         -8.7894e-02, -1.9636e-01,  9.3043e-02, -7.2491e-02,  1.8837e-01],\n        [-3.1818e-02, -1.4184e-01,  8.7670e-02,  6.3921e-02, -1.8765e-01,\n         -4.2325e-02,  5.6180e-02, -3.7704e-02, -7.4006e-03, -1.8397e-01,\n         -1.9834e-01, -1.8098e-01,  1.5855e-01, -1.1148e-01, -4.1916e-02,\n          1.4140e-01, -1.0211e-01,  4.2392e-02, -6.0968e-02, -4.1859e-02],\n        [ 1.8910e-01, -1.4269e-01,  6.3252e-03, -2.7402e-02,  1.5489e-01,\n         -1.8080e-01, -3.3451e-02, -7.7553e-02, -2.0568e-02,  1.0217e-01,\n          2.1563e-01, -1.9798e-01, -1.1544e-01,  9.5157e-02, -1.2866e-02,\n          1.1838e-01, -1.9529e-01, -2.3026e-02, -8.7071e-02, -3.3673e-02],\n        [ 1.6995e-01,  2.5121e-02, -1.4871e-01,  1.2734e-01, -4.5006e-02,\n          1.1347e-01,  1.7909e-01,  2.1575e-01, -1.3985e-01,  6.4046e-02,\n         -1.6341e-01, -1.3045e-01,  1.3301e-01,  7.4987e-02, -1.5845e-01,\n          1.1902e-01, -1.8127e-01,  1.7142e-01,  1.0856e-02,  1.7345e-01],\n        [ 3.1549e-02,  5.1642e-03,  4.3713e-02, -1.4459e-01, -9.1283e-02,\n          5.9822e-02, -1.9859e-01, -3.3113e-02,  1.3193e-02,  3.3078e-02,\n         -4.3958e-04, -5.7494e-03,  1.1401e-04,  1.4712e-01,  2.7721e-02,\n          1.8279e-01, -2.2186e-01, -6.7375e-02, -1.4519e-01, -1.2255e-01],\n        [-1.6501e-01, -8.8316e-02, -2.0688e-01,  1.9838e-01,  8.4548e-02,\n         -9.1264e-02,  1.8697e-01, -1.1280e-01, -1.4677e-01, -1.7543e-01,\n         -1.2056e-01, -1.9707e-01, -2.1150e-02,  3.6951e-03, -4.6129e-02,\n          6.3601e-02, -2.5701e-02,  1.5135e-01,  1.1801e-01,  1.8975e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0550, -0.0703,  0.1729,  0.0115,  0.0736, -0.0257,  0.1685, -0.1241,\n         0.0994, -0.1549, -0.1727, -0.0673, -0.0790,  0.1254,  0.1706, -0.0132],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0944,  0.1251,  0.1432,  0.0616,  0.1628,  0.0704, -0.1267, -0.0348,\n         -0.1018,  0.1009, -0.1694, -0.0378,  0.0343, -0.1007, -0.0610, -0.1394,\n          0.0453,  0.1071, -0.0345,  0.1066, -0.1446,  0.1354,  0.1298,  0.0296,\n          0.0051, -0.0864,  0.1349, -0.0473,  0.1201, -0.1503,  0.1313, -0.1230],\n        [ 0.1170,  0.0616,  0.1722,  0.0104, -0.0188,  0.0857, -0.0372,  0.1302,\n          0.0576, -0.1491,  0.0393, -0.0964,  0.0953,  0.0717, -0.0161,  0.1016,\n          0.1177,  0.1267, -0.1642,  0.0438, -0.0939,  0.1303, -0.1227,  0.1572,\n          0.0970,  0.1407,  0.0831,  0.1563,  0.1043,  0.1532,  0.0368,  0.1751],\n        [-0.0843,  0.1133,  0.0065, -0.0275, -0.1734,  0.0237,  0.1699,  0.0758,\n         -0.0881, -0.0971, -0.1675,  0.0356, -0.0058,  0.0484, -0.0232,  0.0484,\n          0.1051, -0.1264,  0.1466, -0.0120,  0.0654,  0.1467, -0.0684, -0.1354,\n          0.0422,  0.1539,  0.1066,  0.0116, -0.1701, -0.0053, -0.1184, -0.1104],\n        [ 0.1635, -0.0162, -0.0046,  0.0583,  0.1373, -0.0126,  0.1082, -0.0726,\n         -0.1360, -0.1729, -0.0536, -0.0128, -0.0870, -0.0623, -0.0812, -0.1674,\n          0.0590, -0.0899, -0.0475, -0.1137, -0.1480,  0.0885,  0.1321,  0.0612,\n          0.1700, -0.0698, -0.1269, -0.0318,  0.1459,  0.1369, -0.0321,  0.0025],\n        [-0.1524, -0.0553,  0.0071,  0.0429,  0.1490,  0.0639,  0.0412,  0.0902,\n          0.0482,  0.0050, -0.1245, -0.0093, -0.1659, -0.0065, -0.0689, -0.1199,\n         -0.0143, -0.0432, -0.1280, -0.0315,  0.0244, -0.0568,  0.1577, -0.1699,\n         -0.1206,  0.0988, -0.0339,  0.0031, -0.0889,  0.0817,  0.1513, -0.0450],\n        [ 0.0504, -0.0540, -0.0980, -0.0503, -0.1734, -0.0065, -0.1383,  0.1160,\n          0.1166,  0.0680,  0.1632, -0.1428, -0.0874,  0.0038, -0.1119, -0.0092,\n         -0.0636,  0.0667, -0.1121,  0.1571,  0.0978,  0.1285,  0.1308,  0.1312,\n         -0.0652, -0.1103, -0.0463,  0.1767,  0.0479, -0.0357,  0.0687, -0.0490],\n        [ 0.0927, -0.1244, -0.0269, -0.0330, -0.0630, -0.0824, -0.0636,  0.0513,\n          0.1549,  0.0062, -0.0342,  0.0594,  0.0961,  0.0169, -0.0133,  0.1121,\n         -0.0454,  0.0928, -0.1209, -0.0808,  0.1066,  0.1581, -0.0087, -0.0745,\n          0.1266,  0.0328, -0.0574, -0.0484, -0.1292,  0.0782,  0.1491, -0.1095],\n        [-0.1242,  0.1218, -0.1548, -0.0586,  0.1084,  0.0547,  0.0799,  0.0779,\n          0.0529, -0.0828,  0.1202, -0.0169, -0.0170, -0.0753,  0.0781, -0.0596,\n         -0.1287,  0.0499, -0.0721,  0.1728,  0.0608,  0.0606, -0.1766, -0.1459,\n          0.0154,  0.1762,  0.1155,  0.0390,  0.0968, -0.1735, -0.0344, -0.1482],\n        [ 0.0170,  0.0181,  0.1519, -0.1221, -0.0865, -0.0602,  0.1529, -0.0285,\n         -0.0707, -0.1518,  0.0273,  0.1604, -0.0952,  0.0227, -0.0659, -0.0439,\n         -0.1517, -0.0648, -0.1048,  0.1255,  0.1325,  0.1278, -0.0183,  0.0270,\n          0.1473,  0.0940, -0.0171,  0.0809, -0.0268, -0.1137,  0.0175,  0.1132],\n        [ 0.0226,  0.0454, -0.1120, -0.0651,  0.0709, -0.0293,  0.0017,  0.0103,\n         -0.0820,  0.0346, -0.0353, -0.0008, -0.0865,  0.0219,  0.0545, -0.1686,\n          0.0060,  0.0345, -0.0205, -0.0924,  0.0571,  0.1121, -0.1170, -0.1119,\n         -0.0088, -0.0696,  0.0578,  0.1749, -0.1365,  0.0535,  0.1750,  0.0965],\n        [-0.1444,  0.1505,  0.0896, -0.1735, -0.1517,  0.0270, -0.1095, -0.1037,\n         -0.1296, -0.1680,  0.0702, -0.1487,  0.1213, -0.0866,  0.1590,  0.1420,\n         -0.1721, -0.1170,  0.0170, -0.0347, -0.0654, -0.0984, -0.0130, -0.1165,\n          0.0126,  0.0095, -0.0686, -0.0555, -0.1371, -0.0464,  0.1178,  0.1343],\n        [ 0.0080,  0.1423, -0.0392,  0.1181, -0.0206,  0.1352, -0.1402, -0.0920,\n          0.0134, -0.1058, -0.1353, -0.1608,  0.0710, -0.0857,  0.0206, -0.0902,\n          0.0352,  0.1447, -0.0446,  0.0150,  0.1226, -0.1753, -0.1670, -0.1107,\n          0.0530, -0.1235,  0.1170,  0.0172,  0.1574,  0.0976,  0.0995, -0.0204],\n        [ 0.0851,  0.0529,  0.1008, -0.0777, -0.0006, -0.0527, -0.1572,  0.0531,\n         -0.1759,  0.0529,  0.0062, -0.0789, -0.0264, -0.1658,  0.0997, -0.0124,\n          0.0382,  0.1710,  0.0449, -0.0483, -0.0104,  0.0232, -0.0502, -0.1719,\n         -0.0386,  0.1486, -0.0669,  0.0372, -0.1483,  0.0783,  0.0705,  0.0089],\n        [-0.0899,  0.0175,  0.0452, -0.0398, -0.0282, -0.0249,  0.1664, -0.0825,\n          0.0130, -0.0853,  0.1363,  0.1242, -0.0703, -0.0624,  0.1752,  0.1700,\n         -0.1195, -0.0005,  0.1500,  0.1465, -0.1375,  0.0027, -0.0049,  0.0867,\n         -0.0255, -0.0686, -0.1098, -0.0126, -0.1615, -0.0537,  0.1212,  0.0957],\n        [ 0.0443, -0.0759, -0.0527, -0.1191, -0.0504, -0.0767,  0.1514, -0.0125,\n          0.1568, -0.0266,  0.0632, -0.1355,  0.0739,  0.0897,  0.0091, -0.1109,\n          0.0476, -0.1124,  0.0711, -0.0265, -0.1135, -0.1695,  0.1231,  0.0785,\n          0.1375,  0.0607, -0.1473, -0.0368, -0.0942,  0.0483,  0.0950,  0.0863],\n        [ 0.1394,  0.1058, -0.1661,  0.1336,  0.1179, -0.1007, -0.1700,  0.0458,\n          0.0467, -0.1660,  0.0380,  0.1189, -0.1670, -0.0964, -0.0904,  0.0615,\n         -0.1547, -0.0199, -0.0837,  0.1223, -0.1123,  0.1521,  0.0398,  0.1288,\n         -0.1147,  0.0985,  0.1659,  0.0261, -0.1244,  0.1510,  0.0257,  0.0148]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0330,  0.1538,  0.0100,  0.0635, -0.2230,  0.0922, -0.0043,  0.1196],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1096, -0.2112,  0.0029,  0.2436, -0.2264,  0.2498,  0.0548, -0.1835,\n          0.2260,  0.0651, -0.1308, -0.2473, -0.1841, -0.1055, -0.2466,  0.1934],\n        [ 0.2184,  0.1889,  0.2193, -0.1973, -0.0578, -0.0828,  0.1090, -0.0193,\n          0.1735, -0.0433, -0.2454, -0.0256,  0.2387, -0.2298,  0.0818,  0.0223],\n        [-0.0917, -0.2093, -0.1960, -0.0850,  0.2396,  0.1587,  0.1064,  0.0625,\n          0.2149,  0.2206, -0.1949, -0.0990,  0.1730,  0.0480, -0.0474,  0.1542],\n        [-0.1731, -0.0811,  0.1320, -0.0273,  0.1812, -0.1392, -0.1122,  0.0622,\n         -0.0626,  0.1679, -0.0368,  0.0198, -0.1008, -0.0762, -0.1475, -0.0432],\n        [-0.0550,  0.1661,  0.1335,  0.0699,  0.1600,  0.1226,  0.0587,  0.2225,\n         -0.1626, -0.0661, -0.1954, -0.0258,  0.1404,  0.1230,  0.0243, -0.1363],\n        [-0.0384, -0.0893,  0.0919, -0.1411, -0.0039,  0.0210, -0.0870, -0.1399,\n          0.0520, -0.2256,  0.1322, -0.1714,  0.1350,  0.2261,  0.0233,  0.2256],\n        [ 0.0333, -0.0842, -0.1987,  0.2389, -0.0375, -0.1825, -0.1382, -0.1317,\n         -0.0819, -0.1868, -0.2084,  0.0733, -0.0727,  0.0144, -0.2125,  0.2390],\n        [-0.2223, -0.0575, -0.1890,  0.0530,  0.0116, -0.2134, -0.2337, -0.2373,\n         -0.1545,  0.0252,  0.2207, -0.0510,  0.0710, -0.2138, -0.1126, -0.1194]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1730], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0995,  0.2813, -0.3461, -0.1171,  0.2386,  0.1376,  0.2707, -0.1037]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-8.5536e-02,  1.2665e-01,  1.0815e-01,  8.7634e-02,  1.3998e-01,\n         -5.6332e-02,  1.2491e-01, -6.4397e-02,  1.7812e-01,  1.8878e-01,\n          8.9442e-02, -2.0434e-01,  5.0910e-02, -2.2603e-02, -1.9423e-01,\n         -7.5247e-02, -5.7281e-02, -6.0337e-02, -1.7277e-01,  2.1365e-01],\n        [-9.7835e-02,  8.5734e-02, -1.3592e-01,  1.2191e-01,  1.7055e-01,\n          1.5838e-01,  2.7022e-02, -2.0059e-01,  1.3870e-01, -1.6445e-01,\n          7.6679e-02,  8.1908e-02, -1.3182e-01, -1.8488e-01,  1.9001e-01,\n          1.2848e-01, -5.5297e-02,  3.5399e-02,  1.0515e-01,  1.6532e-01],\n        [-1.4206e-01,  9.5070e-02, -8.0873e-02,  1.9281e-01,  2.0008e-01,\n          1.8637e-01, -1.8113e-02, -1.9701e-01, -8.9830e-02,  2.0422e-01,\n         -3.8893e-02, -4.7931e-02, -1.0751e-01, -8.5763e-02, -1.7235e-01,\n         -1.2746e-01,  3.2055e-02,  4.4764e-02,  5.0673e-02, -1.9249e-01],\n        [ 9.4522e-02,  1.6632e-01,  2.2268e-01,  1.1644e-01,  2.1037e-01,\n          2.0666e-02, -7.0188e-02, -2.1447e-02,  1.5657e-01,  5.5677e-02,\n          1.2495e-03, -1.9546e-02,  1.9980e-01,  7.2054e-03, -5.8386e-02,\n         -1.3755e-01,  1.2170e-01, -5.3231e-02,  7.2467e-02,  5.6070e-02],\n        [ 8.6686e-02,  3.7874e-02, -5.9696e-02, -1.6238e-01,  8.6516e-03,\n         -9.3154e-02,  1.2877e-01,  1.3912e-01, -1.5893e-01,  1.3915e-01,\n         -3.6269e-02, -9.1106e-02, -4.7850e-02,  1.4664e-01,  9.4512e-02,\n          9.3229e-02,  8.6884e-03,  7.1778e-02, -1.2229e-02,  1.1152e-01],\n        [-2.0898e-02,  8.9631e-02,  1.1126e-01, -2.0525e-01,  5.7776e-02,\n          1.4502e-01, -4.4228e-04, -1.5327e-01,  3.4971e-02,  2.0783e-01,\n          1.7101e-01,  1.9106e-02, -2.1307e-01,  8.1727e-02,  6.6450e-02,\n         -4.3929e-02,  2.2280e-01,  7.9305e-02,  3.9175e-02,  7.5515e-02],\n        [-2.9326e-02, -2.6865e-02,  1.5861e-01, -1.9713e-01,  1.9042e-01,\n          1.4101e-01,  2.0873e-01,  8.1661e-02,  1.9636e-01,  2.0342e-01,\n         -6.9302e-02, -1.9732e-01, -1.2436e-01,  1.2406e-01, -8.6022e-03,\n          2.1423e-01, -2.1406e-01, -1.1286e-01,  3.9190e-02,  1.3842e-01],\n        [ 1.4800e-01,  6.1104e-02,  6.8849e-02, -3.6113e-03,  7.5452e-02,\n         -1.3558e-01, -2.9113e-02, -1.7228e-01, -9.2145e-02,  2.3165e-02,\n          2.1230e-01, -1.8605e-01, -2.1770e-01,  2.2106e-01, -1.4909e-01,\n         -1.6707e-01, -7.0215e-02,  1.0241e-01, -1.9263e-01, -1.2495e-01],\n        [-1.3368e-01,  1.6145e-01,  2.2312e-01,  3.2500e-02,  1.4564e-02,\n         -6.5177e-02, -1.8909e-01,  1.3946e-01,  5.3232e-05,  8.4606e-02,\n         -9.3305e-02,  1.2052e-01, -3.7375e-02,  3.3039e-02,  2.0235e-02,\n         -1.6459e-01,  1.2670e-01, -1.4956e-01,  4.0680e-02, -1.0175e-01],\n        [-1.5996e-01,  1.7183e-01, -1.2836e-01,  1.1401e-01, -1.4431e-01,\n          9.2913e-03, -1.0121e-01, -7.9510e-02,  4.0359e-02, -2.2288e-01,\n          6.3136e-02,  1.0268e-01,  1.6650e-01, -7.8343e-03,  7.5017e-02,\n          1.2556e-02, -2.5349e-02, -1.5082e-01, -2.3755e-02,  4.9594e-02],\n        [-1.8424e-01,  2.7434e-02,  7.3608e-02,  9.6855e-02,  2.0392e-01,\n          6.0550e-02,  5.4903e-02, -1.6656e-01,  6.7391e-02, -1.1736e-02,\n          1.6605e-01,  7.5866e-02,  1.9200e-01,  1.4521e-01,  2.1690e-01,\n          8.2427e-02,  4.9130e-02,  4.4479e-02, -6.2235e-02, -1.9356e-01],\n        [-1.7685e-01,  1.7114e-01,  1.4924e-03, -8.8505e-02,  1.7544e-01,\n          6.2927e-02,  1.4677e-01, -2.0380e-01,  8.1681e-02, -9.7018e-02,\n         -1.9993e-01, -1.5014e-01,  4.6469e-02,  5.9054e-02, -1.2010e-01,\n          1.7740e-01, -3.7528e-02, -9.8268e-02,  4.2078e-02,  6.6646e-02],\n        [-8.3508e-02, -1.8730e-01,  2.0105e-02,  4.0544e-02,  1.6890e-01,\n          1.2831e-01,  1.6884e-01, -6.4274e-02,  3.3425e-02, -1.8114e-01,\n         -7.0201e-02, -1.1650e-01, -5.8866e-02,  1.1766e-01,  1.0582e-01,\n         -4.6451e-02, -9.6132e-02, -2.0995e-01, -5.5253e-02, -1.2264e-01],\n        [-1.9360e-01,  2.2237e-01, -3.4136e-02,  1.7515e-01,  1.5625e-01,\n         -6.2674e-02,  2.0267e-01, -2.0329e-01,  1.2593e-01, -2.0921e-01,\n          1.7689e-02, -3.5637e-02, -4.1952e-02, -8.0581e-02,  4.3547e-02,\n         -1.3038e-02,  1.6012e-01, -3.3496e-02, -9.0773e-02,  1.2494e-01],\n        [-1.0342e-01, -1.2402e-01,  1.0828e-01, -1.0367e-01, -1.8202e-01,\n          8.0896e-02, -1.1952e-01, -2.1820e-01, -1.8301e-01, -4.0799e-02,\n         -1.7525e-01,  2.2308e-01,  1.4048e-01, -1.3588e-01,  1.4733e-01,\n         -1.5776e-02, -1.8067e-01, -1.6067e-01, -2.2310e-01,  7.1267e-02],\n        [-2.1713e-01, -1.6461e-01,  1.9577e-01, -1.4496e-01,  5.7208e-02,\n         -2.1028e-01, -1.1518e-01, -9.7824e-02,  1.5420e-01, -8.0151e-02,\n         -1.1367e-01, -2.1046e-01, -1.6227e-02, -1.3525e-01,  1.5786e-01,\n         -9.9558e-02, -2.1685e-01, -5.8707e-02,  1.3130e-01, -2.5941e-02],\n        [-1.2362e-01,  3.0581e-02,  3.2952e-03, -6.0372e-02,  1.9382e-01,\n          1.7606e-01, -1.7564e-01,  1.9494e-01,  1.5522e-01, -1.4347e-01,\n         -2.1555e-01, -1.9057e-01,  1.7962e-01, -7.0013e-02,  5.1912e-02,\n         -5.6141e-02, -1.3015e-01, -8.7833e-02,  3.9275e-02, -9.6743e-02],\n        [-6.4450e-02, -5.3448e-02, -5.7408e-02, -5.1995e-02,  1.3636e-01,\n         -4.8093e-02, -5.5083e-02, -1.7337e-01, -2.1675e-01, -1.8438e-01,\n         -1.5470e-01, -5.4047e-02, -1.8584e-01, -2.5278e-02,  9.0777e-02,\n         -6.5861e-02, -1.3072e-04,  1.8864e-01,  6.0159e-02, -1.5906e-01],\n        [ 7.0251e-02,  1.2837e-01, -1.7908e-01,  1.7908e-01, -6.8073e-02,\n          1.4617e-01,  3.6915e-02,  2.8776e-03,  1.0848e-01, -2.1419e-02,\n         -9.4041e-03, -2.0195e-01,  4.7310e-02, -1.1708e-01, -1.1662e-01,\n          1.5477e-01,  8.7291e-02,  9.9523e-02,  1.6115e-01,  3.5513e-02],\n        [-1.9075e-01, -6.2148e-02, -1.3523e-01,  1.1219e-01, -8.3794e-03,\n         -1.8827e-03, -2.0342e-01, -1.3030e-01,  9.6621e-02, -1.0952e-01,\n         -5.9744e-02,  2.1696e-02,  1.7212e-01, -4.8937e-02,  6.1788e-02,\n          1.1013e-01, -1.8549e-02,  1.6380e-01,  1.4261e-02, -1.0018e-01],\n        [-4.3186e-02, -1.7035e-01,  9.2055e-02, -1.0325e-01,  2.0580e-02,\n         -2.1901e-01, -1.9912e-01,  1.0182e-01,  2.0866e-01, -9.2897e-02,\n         -1.0232e-01,  7.9981e-02,  2.1835e-01,  1.3211e-02,  2.1736e-01,\n          1.3697e-01,  1.1651e-01,  1.2675e-01,  3.6733e-03,  1.9647e-01],\n        [-1.4098e-03,  9.5886e-02,  7.9792e-02, -8.0088e-02, -8.7404e-02,\n          1.6640e-01, -5.9380e-02, -1.5757e-01, -2.1279e-01,  2.7976e-02,\n         -7.8182e-03,  4.1609e-02, -1.9095e-01, -1.1486e-01,  9.9885e-02,\n         -1.9629e-01, -1.3228e-01,  1.2059e-01,  2.6926e-02,  1.3522e-01],\n        [-1.5082e-01, -4.0560e-02,  1.3310e-01,  1.8902e-01,  2.1361e-01,\n         -5.9532e-02,  1.2121e-01, -2.0179e-02, -1.2549e-01,  5.5543e-02,\n          3.3334e-02,  9.1587e-02,  1.3687e-01,  8.0597e-02, -2.0269e-01,\n          1.5074e-01, -8.5132e-02, -1.1072e-01,  1.5393e-01, -1.6712e-01],\n        [ 1.5468e-02,  1.1560e-01, -1.8834e-01,  5.2513e-02,  1.2611e-01,\n         -2.0639e-01, -1.9667e-01,  1.1385e-02, -1.1511e-01, -1.4109e-01,\n          3.7950e-02,  9.4594e-02,  7.2863e-02,  8.6907e-02,  1.9610e-01,\n         -1.6822e-01, -9.6594e-03, -2.0985e-01, -7.2083e-02,  1.3278e-01],\n        [ 1.2090e-01,  1.2224e-01,  3.8538e-02, -1.8129e-01,  1.4226e-01,\n          2.0829e-01,  1.6244e-01, -5.1476e-02, -1.9655e-01, -3.2085e-02,\n         -1.9944e-01,  1.2428e-01,  1.6732e-01,  1.5135e-01, -1.3622e-01,\n          3.6070e-02, -1.8737e-01,  6.5499e-02,  5.9952e-02,  1.9400e-01],\n        [-2.1914e-01,  2.1841e-01,  3.0513e-02, -2.6067e-02,  1.1261e-01,\n          1.7516e-01, -1.3595e-01, -2.2116e-01,  8.9831e-02,  6.4261e-02,\n         -1.9398e-01, -1.5645e-01,  1.3323e-01, -4.5442e-02, -8.3316e-02,\n          1.8910e-01, -1.8614e-01, -1.8513e-01, -1.6701e-01, -1.5600e-01],\n        [ 3.1675e-02,  1.6169e-02, -1.1129e-01, -4.7644e-02,  1.8805e-01,\n          1.9874e-01, -8.4422e-02, -1.0875e-01,  6.9762e-02, -4.2692e-02,\n          1.5064e-01, -2.9365e-02,  2.2326e-01,  3.4381e-02, -1.8391e-01,\n         -8.7894e-02, -1.9636e-01,  9.3043e-02, -7.2491e-02,  1.8837e-01],\n        [-3.1818e-02, -1.4184e-01,  8.7670e-02,  6.3921e-02, -1.8765e-01,\n         -4.2325e-02,  5.6180e-02, -3.7704e-02, -7.4006e-03, -1.8397e-01,\n         -1.9834e-01, -1.8098e-01,  1.5855e-01, -1.1148e-01, -4.1916e-02,\n          1.4140e-01, -1.0211e-01,  4.2392e-02, -6.0968e-02, -4.1859e-02],\n        [ 1.8910e-01, -1.4269e-01,  6.3252e-03, -2.7402e-02,  1.5489e-01,\n         -1.8080e-01, -3.3451e-02, -7.7553e-02, -2.0568e-02,  1.0217e-01,\n          2.1563e-01, -1.9798e-01, -1.1544e-01,  9.5157e-02, -1.2866e-02,\n          1.1838e-01, -1.9529e-01, -2.3026e-02, -8.7071e-02, -3.3673e-02],\n        [ 1.6995e-01,  2.5121e-02, -1.4871e-01,  1.2734e-01, -4.5006e-02,\n          1.1347e-01,  1.7909e-01,  2.1575e-01, -1.3985e-01,  6.4046e-02,\n         -1.6341e-01, -1.3045e-01,  1.3301e-01,  7.4987e-02, -1.5845e-01,\n          1.1902e-01, -1.8127e-01,  1.7142e-01,  1.0856e-02,  1.7345e-01],\n        [ 3.1549e-02,  5.1642e-03,  4.3713e-02, -1.4459e-01, -9.1283e-02,\n          5.9822e-02, -1.9859e-01, -3.3113e-02,  1.3193e-02,  3.3078e-02,\n         -4.3958e-04, -5.7494e-03,  1.1401e-04,  1.4712e-01,  2.7721e-02,\n          1.8279e-01, -2.2186e-01, -6.7375e-02, -1.4519e-01, -1.2255e-01],\n        [-1.6501e-01, -8.8316e-02, -2.0688e-01,  1.9838e-01,  8.4548e-02,\n         -9.1264e-02,  1.8697e-01, -1.1280e-01, -1.4677e-01, -1.7543e-01,\n         -1.2056e-01, -1.9707e-01, -2.1150e-02,  3.6951e-03, -4.6129e-02,\n          6.3601e-02, -2.5701e-02,  1.5135e-01,  1.1801e-01,  1.8975e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1888, -0.0338,  0.1772, -0.1134, -0.0698, -0.2023, -0.0319,  0.1776,\n         0.0565,  0.0562, -0.0714,  0.1097,  0.1363, -0.0952,  0.0699, -0.0007,\n         0.1439,  0.2002,  0.1600, -0.1516,  0.0050, -0.0761,  0.1768, -0.1262,\n        -0.0870, -0.0855,  0.0746,  0.2116, -0.0403,  0.1637, -0.1903,  0.1619],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0944,  0.1251,  0.1432,  0.0616,  0.1628,  0.0704, -0.1267, -0.0348,\n         -0.1018,  0.1009, -0.1694, -0.0378,  0.0343, -0.1007, -0.0610, -0.1394,\n          0.0453,  0.1071, -0.0345,  0.1066, -0.1446,  0.1354,  0.1298,  0.0296,\n          0.0051, -0.0864,  0.1349, -0.0473,  0.1201, -0.1503,  0.1313, -0.1230],\n        [ 0.1170,  0.0616,  0.1722,  0.0104, -0.0188,  0.0857, -0.0372,  0.1302,\n          0.0576, -0.1491,  0.0393, -0.0964,  0.0953,  0.0717, -0.0161,  0.1016,\n          0.1177,  0.1267, -0.1642,  0.0438, -0.0939,  0.1303, -0.1227,  0.1572,\n          0.0970,  0.1407,  0.0831,  0.1563,  0.1043,  0.1532,  0.0368,  0.1751],\n        [-0.0843,  0.1133,  0.0065, -0.0275, -0.1734,  0.0237,  0.1699,  0.0758,\n         -0.0881, -0.0971, -0.1675,  0.0356, -0.0058,  0.0484, -0.0232,  0.0484,\n          0.1051, -0.1264,  0.1466, -0.0120,  0.0654,  0.1467, -0.0684, -0.1354,\n          0.0422,  0.1539,  0.1066,  0.0116, -0.1701, -0.0053, -0.1184, -0.1104],\n        [ 0.1635, -0.0162, -0.0046,  0.0583,  0.1373, -0.0126,  0.1082, -0.0726,\n         -0.1360, -0.1729, -0.0536, -0.0128, -0.0870, -0.0623, -0.0812, -0.1674,\n          0.0590, -0.0899, -0.0475, -0.1137, -0.1480,  0.0885,  0.1321,  0.0612,\n          0.1700, -0.0698, -0.1269, -0.0318,  0.1459,  0.1369, -0.0321,  0.0025],\n        [-0.1524, -0.0553,  0.0071,  0.0429,  0.1490,  0.0639,  0.0412,  0.0902,\n          0.0482,  0.0050, -0.1245, -0.0093, -0.1659, -0.0065, -0.0689, -0.1199,\n         -0.0143, -0.0432, -0.1280, -0.0315,  0.0244, -0.0568,  0.1577, -0.1699,\n         -0.1206,  0.0988, -0.0339,  0.0031, -0.0889,  0.0817,  0.1513, -0.0450],\n        [ 0.0504, -0.0540, -0.0980, -0.0503, -0.1734, -0.0065, -0.1383,  0.1160,\n          0.1166,  0.0680,  0.1632, -0.1428, -0.0874,  0.0038, -0.1119, -0.0092,\n         -0.0636,  0.0667, -0.1121,  0.1571,  0.0978,  0.1285,  0.1308,  0.1312,\n         -0.0652, -0.1103, -0.0463,  0.1767,  0.0479, -0.0357,  0.0687, -0.0490],\n        [ 0.0927, -0.1244, -0.0269, -0.0330, -0.0630, -0.0824, -0.0636,  0.0513,\n          0.1549,  0.0062, -0.0342,  0.0594,  0.0961,  0.0169, -0.0133,  0.1121,\n         -0.0454,  0.0928, -0.1209, -0.0808,  0.1066,  0.1581, -0.0087, -0.0745,\n          0.1266,  0.0328, -0.0574, -0.0484, -0.1292,  0.0782,  0.1491, -0.1095],\n        [-0.1242,  0.1218, -0.1548, -0.0586,  0.1084,  0.0547,  0.0799,  0.0779,\n          0.0529, -0.0828,  0.1202, -0.0169, -0.0170, -0.0753,  0.0781, -0.0596,\n         -0.1287,  0.0499, -0.0721,  0.1728,  0.0608,  0.0606, -0.1766, -0.1459,\n          0.0154,  0.1762,  0.1155,  0.0390,  0.0968, -0.1735, -0.0344, -0.1482],\n        [ 0.0170,  0.0181,  0.1519, -0.1221, -0.0865, -0.0602,  0.1529, -0.0285,\n         -0.0707, -0.1518,  0.0273,  0.1604, -0.0952,  0.0227, -0.0659, -0.0439,\n         -0.1517, -0.0648, -0.1048,  0.1255,  0.1325,  0.1278, -0.0183,  0.0270,\n          0.1473,  0.0940, -0.0171,  0.0809, -0.0268, -0.1137,  0.0175,  0.1132],\n        [ 0.0226,  0.0454, -0.1120, -0.0651,  0.0709, -0.0293,  0.0017,  0.0103,\n         -0.0820,  0.0346, -0.0353, -0.0008, -0.0865,  0.0219,  0.0545, -0.1686,\n          0.0060,  0.0345, -0.0205, -0.0924,  0.0571,  0.1121, -0.1170, -0.1119,\n         -0.0088, -0.0696,  0.0578,  0.1749, -0.1365,  0.0535,  0.1750,  0.0965],\n        [-0.1444,  0.1505,  0.0896, -0.1735, -0.1517,  0.0270, -0.1095, -0.1037,\n         -0.1296, -0.1680,  0.0702, -0.1487,  0.1213, -0.0866,  0.1590,  0.1420,\n         -0.1721, -0.1170,  0.0170, -0.0347, -0.0654, -0.0984, -0.0130, -0.1165,\n          0.0126,  0.0095, -0.0686, -0.0555, -0.1371, -0.0464,  0.1178,  0.1343],\n        [ 0.0080,  0.1423, -0.0392,  0.1181, -0.0206,  0.1352, -0.1402, -0.0920,\n          0.0134, -0.1058, -0.1353, -0.1608,  0.0710, -0.0857,  0.0206, -0.0902,\n          0.0352,  0.1447, -0.0446,  0.0150,  0.1226, -0.1753, -0.1670, -0.1107,\n          0.0530, -0.1235,  0.1170,  0.0172,  0.1574,  0.0976,  0.0995, -0.0204],\n        [ 0.0851,  0.0529,  0.1008, -0.0777, -0.0006, -0.0527, -0.1572,  0.0531,\n         -0.1759,  0.0529,  0.0062, -0.0789, -0.0264, -0.1658,  0.0997, -0.0124,\n          0.0382,  0.1710,  0.0449, -0.0483, -0.0104,  0.0232, -0.0502, -0.1719,\n         -0.0386,  0.1486, -0.0669,  0.0372, -0.1483,  0.0783,  0.0705,  0.0089],\n        [-0.0899,  0.0175,  0.0452, -0.0398, -0.0282, -0.0249,  0.1664, -0.0825,\n          0.0130, -0.0853,  0.1363,  0.1242, -0.0703, -0.0624,  0.1752,  0.1700,\n         -0.1195, -0.0005,  0.1500,  0.1465, -0.1375,  0.0027, -0.0049,  0.0867,\n         -0.0255, -0.0686, -0.1098, -0.0126, -0.1615, -0.0537,  0.1212,  0.0957],\n        [ 0.0443, -0.0759, -0.0527, -0.1191, -0.0504, -0.0767,  0.1514, -0.0125,\n          0.1568, -0.0266,  0.0632, -0.1355,  0.0739,  0.0897,  0.0091, -0.1109,\n          0.0476, -0.1124,  0.0711, -0.0265, -0.1135, -0.1695,  0.1231,  0.0785,\n          0.1375,  0.0607, -0.1473, -0.0368, -0.0942,  0.0483,  0.0950,  0.0863],\n        [ 0.1394,  0.1058, -0.1661,  0.1336,  0.1179, -0.1007, -0.1700,  0.0458,\n          0.0467, -0.1660,  0.0380,  0.1189, -0.1670, -0.0964, -0.0904,  0.0615,\n         -0.1547, -0.0199, -0.0837,  0.1223, -0.1123,  0.1521,  0.0398,  0.1288,\n         -0.1147,  0.0985,  0.1659,  0.0261, -0.1244,  0.1510,  0.0257,  0.0148]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0550, -0.0703,  0.1729,  0.0115,  0.0736, -0.0257,  0.1685, -0.1241,\n         0.0994, -0.1549, -0.1727, -0.0673, -0.0790,  0.1254,  0.1706, -0.0132],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1096, -0.2112,  0.0029,  0.2436, -0.2264,  0.2498,  0.0548, -0.1835,\n          0.2260,  0.0651, -0.1308, -0.2473, -0.1841, -0.1055, -0.2466,  0.1934],\n        [ 0.2184,  0.1889,  0.2193, -0.1973, -0.0578, -0.0828,  0.1090, -0.0193,\n          0.1735, -0.0433, -0.2454, -0.0256,  0.2387, -0.2298,  0.0818,  0.0223],\n        [-0.0917, -0.2093, -0.1960, -0.0850,  0.2396,  0.1587,  0.1064,  0.0625,\n          0.2149,  0.2206, -0.1949, -0.0990,  0.1730,  0.0480, -0.0474,  0.1542],\n        [-0.1731, -0.0811,  0.1320, -0.0273,  0.1812, -0.1392, -0.1122,  0.0622,\n         -0.0626,  0.1679, -0.0368,  0.0198, -0.1008, -0.0762, -0.1475, -0.0432],\n        [-0.0550,  0.1661,  0.1335,  0.0699,  0.1600,  0.1226,  0.0587,  0.2225,\n         -0.1626, -0.0661, -0.1954, -0.0258,  0.1404,  0.1230,  0.0243, -0.1363],\n        [-0.0384, -0.0893,  0.0919, -0.1411, -0.0039,  0.0210, -0.0870, -0.1399,\n          0.0520, -0.2256,  0.1322, -0.1714,  0.1350,  0.2261,  0.0233,  0.2256],\n        [ 0.0333, -0.0842, -0.1987,  0.2389, -0.0375, -0.1825, -0.1382, -0.1317,\n         -0.0819, -0.1868, -0.2084,  0.0733, -0.0727,  0.0144, -0.2125,  0.2390],\n        [-0.2223, -0.0575, -0.1890,  0.0530,  0.0116, -0.2134, -0.2337, -0.2373,\n         -0.1545,  0.0252,  0.2207, -0.0510,  0.0710, -0.2138, -0.1126, -0.1194]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0330,  0.1538,  0.0100,  0.0635, -0.2230,  0.0922, -0.0043,  0.1196],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0995,  0.2813, -0.3461, -0.1171,  0.2386,  0.1376,  0.2707, -0.1037]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1730], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x114a5e350>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x123e2c760>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s49620000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s49620000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}