{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s50080000"
    },
    "q_lr":	0.0005,
    "seed":	50080000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x11c3ccc70>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1326,  0.0723,  0.2017, -0.0844,  0.0465, -0.0257,  0.2214, -0.0511,\n         0.0857, -0.0331, -0.0015, -0.1825,  0.2000, -0.0580,  0.0477,  0.1668,\n        -0.1701, -0.1384,  0.1541,  0.0251,  0.1593, -0.0628, -0.0287, -0.0027,\n         0.1259, -0.1764, -0.0175, -0.1536, -0.1346, -0.0881,  0.1770, -0.0990],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0675, -0.1714, -0.0317, -0.2046, -0.0060,  0.1411,  0.1008, -0.1216,\n         -0.0690, -0.0633, -0.1238, -0.0631, -0.0176,  0.0228, -0.0358,  0.1532,\n          0.2027, -0.0535, -0.1818,  0.0485],\n        [ 0.1791,  0.0147, -0.0247, -0.1105,  0.0931,  0.1967, -0.1098, -0.0523,\n         -0.1335, -0.0743,  0.1192,  0.1387, -0.0257,  0.0934, -0.1881, -0.0344,\n         -0.1712,  0.1520,  0.0658, -0.0851],\n        [-0.0288,  0.0087, -0.0049,  0.2001, -0.1408, -0.2033, -0.0981, -0.1105,\n          0.1331, -0.1651, -0.1589, -0.1078,  0.0618, -0.0391,  0.0057,  0.1902,\n         -0.1042,  0.1582,  0.0710,  0.0418],\n        [-0.0790, -0.0562, -0.0585, -0.2053,  0.2066,  0.0661, -0.1254, -0.2154,\n          0.1130,  0.1825,  0.0779, -0.0151,  0.1781,  0.1828, -0.0272, -0.2163,\n          0.1098, -0.2109, -0.0805, -0.0202],\n        [ 0.0835,  0.0270, -0.0168, -0.1291,  0.1412,  0.0257,  0.0479, -0.1445,\n          0.1710, -0.1003, -0.2023, -0.0594, -0.1878,  0.0195,  0.0698,  0.0974,\n          0.1962, -0.1561,  0.0502,  0.0750],\n        [ 0.2029, -0.2153,  0.1542, -0.1804,  0.0772, -0.0376, -0.0601,  0.1392,\n          0.1263, -0.2210, -0.0581, -0.0259,  0.1529, -0.1347, -0.0437,  0.2015,\n         -0.1360, -0.2107,  0.0533, -0.1397],\n        [-0.1730, -0.0143, -0.1270, -0.1875,  0.1639, -0.1656, -0.0282,  0.0271,\n         -0.0214, -0.1747,  0.0296,  0.1006, -0.0491, -0.0992, -0.0905,  0.0992,\n          0.1121,  0.0488, -0.1288,  0.1496],\n        [ 0.0614, -0.0258,  0.1709, -0.1655,  0.0534, -0.0301, -0.0599,  0.0967,\n          0.0058, -0.0129,  0.2203, -0.2225,  0.2148,  0.1472, -0.0596,  0.0122,\n          0.1257,  0.0876,  0.1206, -0.0627],\n        [ 0.0968, -0.0787,  0.1819,  0.1819, -0.1747, -0.1786, -0.2171,  0.2051,\n         -0.0865, -0.0692,  0.0522, -0.1707,  0.1432, -0.1749,  0.1958, -0.1671,\n         -0.0635,  0.1149,  0.1872, -0.2050],\n        [ 0.2022,  0.1924,  0.2079,  0.0491, -0.0927, -0.1847, -0.0610, -0.1210,\n         -0.1532, -0.0789, -0.1479,  0.0241,  0.1737, -0.0167,  0.1710,  0.1606,\n          0.1287, -0.0061, -0.1048,  0.1650],\n        [ 0.0232, -0.1463,  0.1351, -0.1510, -0.1512,  0.2015, -0.2204,  0.1042,\n         -0.1117,  0.1631,  0.1521, -0.1740, -0.1812,  0.0117, -0.1911, -0.1785,\n         -0.1505,  0.1657,  0.1786, -0.0774],\n        [-0.1700,  0.0222, -0.1059,  0.1948,  0.0632, -0.1044,  0.2173,  0.1028,\n         -0.0061,  0.0814,  0.1970, -0.0905,  0.1568,  0.0245,  0.2002, -0.0365,\n          0.1203,  0.1404,  0.0938,  0.1877],\n        [-0.0782,  0.0947,  0.1757, -0.0918,  0.0948, -0.2160, -0.1777, -0.0505,\n         -0.1795,  0.0442,  0.0362, -0.0906,  0.2218, -0.0934,  0.0805, -0.2223,\n         -0.0991, -0.0387, -0.2006, -0.0104],\n        [ 0.1316,  0.0933, -0.1681, -0.1878, -0.1915,  0.1129,  0.0292,  0.1477,\n         -0.0941,  0.0474,  0.0557,  0.0762, -0.0592, -0.2096,  0.1048,  0.0313,\n          0.1557,  0.2176,  0.1116, -0.0552],\n        [-0.1976, -0.1009, -0.1305,  0.2064, -0.0752,  0.1979,  0.2236,  0.2171,\n          0.1788, -0.1432,  0.1012,  0.1222, -0.1859,  0.1439, -0.1637, -0.0470,\n          0.1644,  0.1281, -0.1527, -0.0733],\n        [-0.1818, -0.0586, -0.0261,  0.1794, -0.1299, -0.1367, -0.0089, -0.0919,\n         -0.1930,  0.1561,  0.0492,  0.0993,  0.1314, -0.1412, -0.0621, -0.1129,\n          0.1879, -0.1731, -0.1215,  0.1687],\n        [ 0.2159, -0.1250,  0.0766, -0.1891,  0.0602, -0.0407,  0.0696, -0.0895,\n          0.1786,  0.1955, -0.0127,  0.1562, -0.2096, -0.1094,  0.1027, -0.0493,\n         -0.1281,  0.1895, -0.1174, -0.0860],\n        [ 0.1128, -0.0784, -0.0332,  0.0627,  0.0438, -0.1427,  0.0333,  0.1766,\n          0.0463, -0.0785, -0.0080,  0.0302, -0.2151, -0.0954,  0.0932,  0.0379,\n          0.1043,  0.0350,  0.1630, -0.0103],\n        [ 0.0590, -0.0168,  0.1342,  0.2082,  0.1440,  0.1115,  0.1040,  0.1575,\n          0.0428, -0.0145, -0.1625, -0.0650,  0.1801,  0.2184, -0.1843, -0.0933,\n          0.0832,  0.0890, -0.0696,  0.1012],\n        [ 0.0229, -0.1663, -0.1300, -0.1297, -0.1092,  0.1317, -0.2056,  0.2039,\n          0.1190, -0.2049, -0.1512,  0.1136, -0.2118, -0.2119,  0.1352, -0.2144,\n          0.0267, -0.0199, -0.0502,  0.0818],\n        [-0.1025, -0.1952, -0.0331,  0.0637,  0.0742, -0.2169, -0.1637,  0.1493,\n          0.1277,  0.0488,  0.1446, -0.1065, -0.1230, -0.0776, -0.0453, -0.1924,\n          0.0172, -0.1830,  0.0690, -0.1230],\n        [ 0.0318, -0.0995, -0.0242, -0.0825, -0.1746,  0.1257, -0.0880,  0.0003,\n         -0.0443,  0.0373,  0.0636,  0.0569,  0.0359,  0.1923,  0.2202,  0.1349,\n          0.1891,  0.0819, -0.0228, -0.0508],\n        [ 0.0307, -0.1875, -0.1075, -0.1545, -0.2150,  0.2014,  0.1791,  0.1708,\n          0.0433,  0.0242, -0.0255,  0.0996, -0.1174, -0.1378, -0.0111, -0.1452,\n          0.0968, -0.0717, -0.1412,  0.0582],\n        [ 0.0967, -0.1865,  0.1755, -0.0258, -0.1452, -0.1012, -0.1294,  0.2130,\n          0.0555,  0.1451, -0.1640,  0.1213,  0.0271, -0.0319,  0.0904, -0.1727,\n          0.1186,  0.0382, -0.1608, -0.1540],\n        [-0.0441, -0.0360, -0.0404,  0.1110, -0.0943, -0.0541,  0.0300, -0.1528,\n          0.0360, -0.0425, -0.1299, -0.1275,  0.1776, -0.0129, -0.0784, -0.0549,\n         -0.1350,  0.0074,  0.1492, -0.0011],\n        [-0.0666,  0.0139,  0.1868,  0.0955, -0.1152,  0.0959, -0.0761,  0.0143,\n          0.0477, -0.1640, -0.0125,  0.1015, -0.0140, -0.1102, -0.1370,  0.0545,\n          0.0257, -0.1023, -0.0838, -0.0859],\n        [ 0.0606,  0.0314,  0.1489, -0.0982, -0.0785, -0.0958,  0.0887,  0.0793,\n          0.2027, -0.1218,  0.0278,  0.2015,  0.0576, -0.1950, -0.1851,  0.0586,\n         -0.1852,  0.1372, -0.2128,  0.1252],\n        [ 0.2132, -0.0628, -0.0813, -0.1177, -0.0712, -0.0386, -0.0134, -0.1319,\n         -0.0083, -0.1932,  0.0856,  0.1268, -0.1263, -0.0832, -0.0992, -0.0540,\n         -0.2105,  0.1239,  0.1285, -0.1165],\n        [-0.2114, -0.1497, -0.2050, -0.1053,  0.1818, -0.1956,  0.1888, -0.1623,\n         -0.1121,  0.1212, -0.0706, -0.0310,  0.0067, -0.1278, -0.0273,  0.2132,\n          0.1585,  0.1411, -0.1830, -0.2043],\n        [ 0.1024, -0.1082,  0.2225, -0.1045, -0.0816,  0.1165, -0.0351,  0.1147,\n         -0.0533, -0.0706,  0.0453,  0.0224, -0.0782,  0.1295, -0.1324,  0.0277,\n         -0.1678,  0.0063, -0.1933,  0.0652],\n        [ 0.0357,  0.2017, -0.0552, -0.1761, -0.1181, -0.1507,  0.1839,  0.0452,\n          0.2155,  0.1698,  0.1292,  0.0096,  0.0490, -0.0942,  0.0355, -0.2072,\n          0.1990, -0.1221,  0.1878,  0.0858],\n        [ 0.1583,  0.1037, -0.2185,  0.2210,  0.0287,  0.1571,  0.0726,  0.1149,\n         -0.1740, -0.2213, -0.1229, -0.0376, -0.1594, -0.1570, -0.0684,  0.1902,\n          0.2230,  0.1772,  0.1061, -0.1260]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0089,  0.1736,  0.1231,  0.1538,  0.0936, -0.1281, -0.0719, -0.0402,\n         0.1171, -0.1463,  0.1232, -0.1317,  0.1165,  0.1561,  0.0533, -0.0338],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.1398e-01, -8.3761e-02,  1.1992e-01,  2.7335e-02, -1.1801e-01,\n         -4.9838e-02, -7.5444e-02, -2.1679e-02,  1.4870e-01,  1.1439e-01,\n         -1.5398e-01,  7.5053e-02, -3.6126e-02, -6.8926e-02,  1.1320e-01,\n          4.1106e-02,  1.9594e-02, -1.2623e-01,  1.2995e-01, -1.5383e-01,\n          9.5321e-02,  1.1530e-01,  1.7308e-01,  1.3424e-01,  1.5424e-01,\n         -1.2727e-01,  1.9897e-02,  1.7604e-01,  1.0243e-01, -1.0306e-02,\n          7.1427e-02,  1.6233e-01],\n        [ 1.3601e-02, -1.7181e-01,  1.2582e-01,  8.0734e-02,  1.6915e-01,\n         -8.5095e-02, -1.3998e-01,  1.7172e-01, -5.2493e-02,  1.0647e-01,\n          1.1426e-01, -6.2924e-03,  3.8187e-02, -6.5537e-02,  5.2273e-02,\n          1.1076e-02,  1.3824e-01, -1.0589e-01,  1.0914e-01,  8.1868e-02,\n          1.4735e-01, -1.2346e-01, -1.7274e-01,  1.1688e-01, -9.2013e-02,\n          8.1220e-03, -1.0285e-01, -8.9425e-02,  6.3154e-03,  1.2858e-01,\n         -1.0109e-01,  1.7477e-01],\n        [ 1.3523e-01,  1.7380e-01, -4.8856e-02, -7.9017e-02,  1.1942e-01,\n         -1.3051e-01,  6.4303e-03, -1.0236e-01, -3.5675e-02,  1.6382e-01,\n         -1.4378e-01,  1.0526e-01, -1.1618e-01,  1.4967e-02,  3.0379e-02,\n          1.0000e-01, -1.2036e-01,  6.1279e-02, -6.8003e-02,  1.1991e-01,\n         -1.6488e-01,  1.1009e-01, -1.0170e-01, -6.3360e-02, -1.3306e-01,\n         -6.2230e-02,  1.4744e-01,  1.6827e-01, -1.6879e-01,  9.6078e-02,\n          4.6716e-02, -6.8603e-02],\n        [-1.5408e-01, -7.3267e-02, -2.6175e-02, -5.7455e-02, -6.5860e-02,\n          5.3571e-02,  2.4829e-04,  8.2980e-02, -3.3205e-02,  1.5479e-01,\n         -1.7048e-01, -5.7079e-02,  1.5805e-01,  1.5284e-01, -5.2320e-02,\n         -1.6184e-01,  8.8498e-02, -2.4220e-02,  1.5843e-01, -1.2185e-01,\n          6.9924e-02,  1.5254e-01, -1.6292e-01, -6.8777e-02,  1.5242e-01,\n         -2.4461e-02,  7.2022e-02,  7.0767e-02,  6.4272e-02,  1.3204e-01,\n         -1.7045e-01, -1.1957e-01],\n        [ 7.6612e-02,  1.1584e-02,  3.6288e-02, -6.0305e-02,  1.3214e-02,\n          9.7923e-02,  1.1895e-01, -1.3780e-01, -1.6257e-01, -1.2030e-01,\n          2.5571e-02, -8.7062e-02,  6.6259e-02, -1.3816e-01, -1.0060e-01,\n         -6.2067e-02, -6.4347e-02, -1.6218e-01, -1.2512e-01, -1.3918e-01,\n          3.1174e-02,  5.6510e-02, -1.5299e-01,  1.0489e-01, -4.5036e-02,\n         -1.0681e-01,  1.1169e-01, -7.4480e-04, -1.2155e-01,  1.3152e-01,\n         -8.2340e-02,  1.1312e-01],\n        [ 8.3136e-02, -1.1882e-01,  7.8521e-02,  1.7810e-02,  1.6433e-01,\n         -6.5846e-02, -7.5705e-02,  7.2892e-02, -4.0166e-02, -1.3498e-01,\n          3.5232e-02, -4.4820e-02,  1.7516e-01, -2.7825e-02,  1.3894e-01,\n          1.6052e-01, -7.3336e-02,  1.3282e-01, -1.5600e-01,  1.0776e-01,\n          1.6613e-02, -1.3960e-02, -5.8799e-02,  5.9350e-02,  1.1201e-01,\n         -7.7072e-02,  1.0664e-01, -1.1192e-01,  3.8910e-02,  1.5183e-01,\n         -1.3612e-01,  1.3371e-01],\n        [ 4.1515e-06,  8.0179e-03, -1.1763e-01,  7.6188e-02,  1.2266e-01,\n         -1.5735e-01, -6.0802e-02,  1.6479e-02, -3.3878e-02, -6.8052e-02,\n          1.7258e-01, -1.4204e-01,  7.9059e-02, -7.0160e-02, -1.4175e-01,\n          5.6629e-02,  8.6139e-03,  3.5612e-02,  1.3759e-01,  8.9790e-02,\n          1.3024e-01, -7.3726e-02,  7.5742e-02, -6.1257e-02,  5.0296e-02,\n         -1.1442e-01, -1.1635e-01, -1.3617e-01, -6.4067e-02,  1.2854e-01,\n         -1.9015e-02,  1.6077e-01],\n        [ 1.6932e-02,  6.3691e-02, -1.1516e-01, -4.9290e-02,  7.4834e-02,\n          3.7241e-02,  7.9418e-02, -7.2081e-02,  6.3245e-02,  1.1163e-01,\n         -1.1190e-01,  1.5999e-01,  1.2640e-01,  1.5147e-01,  5.6648e-02,\n         -1.6251e-01,  1.1579e-01,  1.1742e-01, -1.3696e-02,  1.4466e-01,\n         -1.4751e-01,  6.8843e-02,  1.6774e-02,  1.5862e-04,  3.8657e-02,\n         -8.2491e-02, -8.2712e-02, -6.6110e-02, -5.1701e-02, -1.5243e-01,\n         -8.5449e-02,  6.8745e-02],\n        [-1.6411e-01, -1.5004e-01,  1.0704e-01, -1.2595e-01,  8.1502e-03,\n          8.2268e-02,  1.6453e-01,  1.6361e-01, -1.2739e-01, -2.5600e-02,\n         -6.8986e-02,  2.2477e-02, -8.2285e-03, -1.4334e-01, -1.0256e-01,\n         -1.3053e-01,  3.5825e-06,  1.2265e-01, -1.4861e-01, -1.2554e-01,\n          1.1150e-01,  6.6329e-02,  8.0953e-02,  1.5546e-01, -1.6987e-02,\n          1.6364e-01, -2.4204e-02, -1.1733e-01, -2.5923e-02, -8.7177e-03,\n         -1.3469e-01,  2.8089e-02],\n        [-5.7181e-02, -2.0012e-02, -1.9428e-02,  6.8827e-02, -1.0225e-01,\n          1.1304e-02,  1.0969e-01,  7.5334e-02,  1.7115e-01, -1.2001e-01,\n         -1.5616e-02, -2.5768e-02, -1.2925e-01, -1.0349e-01, -2.2657e-02,\n         -7.1985e-02, -1.4564e-01,  1.4976e-01,  1.7258e-02, -1.3452e-01,\n         -7.9582e-02,  3.0537e-02,  6.4150e-02, -1.6366e-01, -8.0654e-03,\n          2.7230e-02,  2.8822e-02, -2.0329e-02, -8.3953e-02,  8.5912e-02,\n         -1.3776e-01, -6.9550e-02],\n        [-1.4218e-01,  1.1548e-01,  9.8179e-02,  9.1512e-02,  1.4854e-01,\n          5.3532e-02,  3.3723e-02, -1.7159e-01,  1.6685e-02,  4.7113e-02,\n         -4.0514e-02, -1.0031e-01, -2.0186e-02,  1.2410e-01,  4.9656e-02,\n         -2.6680e-02, -6.5919e-02,  9.1478e-02,  5.2877e-02, -1.0719e-01,\n          5.9391e-02, -1.7149e-01,  1.2682e-02,  1.6214e-02, -1.0025e-01,\n          1.7629e-01, -7.8900e-02, -1.7652e-01, -5.6472e-02,  7.3887e-02,\n         -3.7755e-02, -7.7802e-02],\n        [ 1.4725e-01, -6.4728e-02, -3.5764e-02,  6.7115e-02, -1.6584e-01,\n         -2.2750e-02,  3.8838e-02,  1.4842e-01,  1.6901e-02, -9.8722e-02,\n          7.5493e-04, -1.3749e-01, -2.0334e-03,  1.5539e-01,  2.2573e-02,\n         -3.8303e-02,  5.7379e-02,  1.0294e-01, -1.4582e-01,  1.0755e-01,\n         -1.2947e-01, -8.2611e-02, -1.1212e-01, -5.8551e-02, -2.1844e-02,\n          1.5431e-01, -1.3908e-01,  6.3018e-02,  4.1787e-02, -1.7883e-03,\n          7.2349e-02, -6.0300e-02],\n        [-1.0849e-01,  1.6547e-01, -5.4685e-02, -3.9271e-02, -7.2298e-02,\n         -1.6897e-01,  5.1664e-03,  6.0392e-02, -9.2574e-02, -1.1993e-01,\n         -9.5499e-02, -8.5806e-03, -3.8097e-02,  1.3241e-01,  2.7449e-02,\n          2.0150e-02, -1.2367e-01,  5.4376e-02,  6.2005e-02,  4.8922e-02,\n         -1.1769e-01,  1.5938e-01,  3.5691e-02, -6.2929e-02,  1.1426e-01,\n          8.9059e-02,  7.5872e-02, -1.4855e-01, -1.5226e-01,  6.8782e-02,\n          5.2000e-02,  8.8408e-02],\n        [ 9.0627e-02, -3.5935e-02,  1.1440e-01, -1.4191e-01, -1.0882e-01,\n          1.7630e-01, -1.4261e-02, -1.8131e-02, -9.3750e-02, -5.8796e-02,\n          1.2997e-01, -1.7326e-01, -1.4727e-01, -7.8700e-02, -2.8634e-02,\n          5.6659e-02, -1.1979e-01, -5.0860e-02, -1.3616e-01,  1.0524e-01,\n          1.5172e-01,  1.2126e-01,  1.1625e-01, -1.2069e-01,  1.1517e-01,\n         -3.2528e-02,  1.1358e-01,  8.9867e-02, -2.1300e-02,  6.4363e-02,\n          7.6778e-02,  1.5389e-01],\n        [-4.0666e-02, -4.8748e-02, -1.5813e-01,  1.1967e-01,  1.5901e-01,\n          1.6111e-01,  1.1419e-01,  1.7352e-01,  2.8773e-02, -5.8837e-05,\n         -1.2356e-01,  1.1740e-01,  3.6964e-02,  1.4660e-01,  8.7604e-02,\n          1.0499e-01, -1.5605e-01, -1.6633e-01, -1.6842e-01, -7.7169e-02,\n          1.6527e-01, -1.2581e-01,  1.4009e-01,  6.4874e-02,  1.5766e-01,\n          7.2533e-02,  4.1772e-02,  1.8812e-02,  1.4168e-01, -1.4438e-01,\n          6.1783e-02, -6.3719e-02],\n        [-3.6713e-02, -3.7188e-02,  5.8929e-02,  5.1361e-02,  1.4099e-01,\n         -1.4803e-01, -2.8656e-02,  1.7448e-01,  1.2672e-01, -1.0640e-02,\n         -6.4698e-02, -1.0073e-02,  2.4451e-02, -6.2944e-02,  5.1036e-02,\n          1.6134e-01,  1.2763e-01,  2.8255e-02,  3.4414e-02,  5.0701e-03,\n          1.5076e-02,  6.4165e-02, -7.4684e-02,  1.0779e-01,  1.2746e-01,\n          9.4494e-02, -1.2777e-02, -1.5298e-01,  8.9596e-02,  1.6614e-01,\n         -1.3162e-01,  1.7424e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2286, -0.0184,  0.0323,  0.0368, -0.0766,  0.1711, -0.2151,  0.0007],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2213,  0.1427,  0.2399, -0.1466,  0.1468, -0.2412,  0.2370,  0.0436,\n          0.1294,  0.1375, -0.0659, -0.2336, -0.1642, -0.1770, -0.2203,  0.1417],\n        [-0.2377,  0.1338,  0.2378,  0.2313, -0.0065,  0.2209,  0.2068,  0.1958,\n          0.2234, -0.1172, -0.1555,  0.2126,  0.0171,  0.1687,  0.0348,  0.0925],\n        [-0.1487, -0.0236,  0.1557,  0.1075, -0.1912, -0.1187, -0.0140,  0.1498,\n         -0.1842, -0.2213,  0.0129,  0.1966, -0.2047, -0.0458,  0.0554,  0.0370],\n        [-0.0013, -0.1778,  0.0068,  0.1382,  0.1824,  0.0477,  0.2446,  0.1523,\n          0.1561,  0.0250, -0.0182, -0.1446,  0.1616,  0.1485,  0.0117,  0.1360],\n        [ 0.1093, -0.0076, -0.2051, -0.0436,  0.0952,  0.2142, -0.1298,  0.1289,\n          0.0057,  0.2085, -0.2151, -0.0659, -0.0861,  0.0865,  0.1804, -0.2255],\n        [-0.0880,  0.0801, -0.2324,  0.0095,  0.2340, -0.0438,  0.1675,  0.0039,\n          0.1627,  0.0250,  0.0546, -0.0188,  0.1921,  0.0760,  0.1415, -0.0677],\n        [ 0.0004, -0.0766,  0.0776,  0.0577, -0.1292,  0.0809, -0.2069, -0.1398,\n          0.0838,  0.1827, -0.1488, -0.1438, -0.0062,  0.0292,  0.2283, -0.1573],\n        [-0.0047,  0.0046,  0.1134, -0.0902,  0.0052, -0.2125,  0.0256,  0.1438,\n          0.0243, -0.0046, -0.2419,  0.2137, -0.2434, -0.2020, -0.0622, -0.1159]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.3510], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2979, -0.1163,  0.1475,  0.0552,  0.2326, -0.0390, -0.3044,  0.2031]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0675, -0.1714, -0.0317, -0.2046, -0.0060,  0.1411,  0.1008, -0.1216,\n         -0.0690, -0.0633, -0.1238, -0.0631, -0.0176,  0.0228, -0.0358,  0.1532,\n          0.2027, -0.0535, -0.1818,  0.0485],\n        [ 0.1791,  0.0147, -0.0247, -0.1105,  0.0931,  0.1967, -0.1098, -0.0523,\n         -0.1335, -0.0743,  0.1192,  0.1387, -0.0257,  0.0934, -0.1881, -0.0344,\n         -0.1712,  0.1520,  0.0658, -0.0851],\n        [-0.0288,  0.0087, -0.0049,  0.2001, -0.1408, -0.2033, -0.0981, -0.1105,\n          0.1331, -0.1651, -0.1589, -0.1078,  0.0618, -0.0391,  0.0057,  0.1902,\n         -0.1042,  0.1582,  0.0710,  0.0418],\n        [-0.0790, -0.0562, -0.0585, -0.2053,  0.2066,  0.0661, -0.1254, -0.2154,\n          0.1130,  0.1825,  0.0779, -0.0151,  0.1781,  0.1828, -0.0272, -0.2163,\n          0.1098, -0.2109, -0.0805, -0.0202],\n        [ 0.0835,  0.0270, -0.0168, -0.1291,  0.1412,  0.0257,  0.0479, -0.1445,\n          0.1710, -0.1003, -0.2023, -0.0594, -0.1878,  0.0195,  0.0698,  0.0974,\n          0.1962, -0.1561,  0.0502,  0.0750],\n        [ 0.2029, -0.2153,  0.1542, -0.1804,  0.0772, -0.0376, -0.0601,  0.1392,\n          0.1263, -0.2210, -0.0581, -0.0259,  0.1529, -0.1347, -0.0437,  0.2015,\n         -0.1360, -0.2107,  0.0533, -0.1397],\n        [-0.1730, -0.0143, -0.1270, -0.1875,  0.1639, -0.1656, -0.0282,  0.0271,\n         -0.0214, -0.1747,  0.0296,  0.1006, -0.0491, -0.0992, -0.0905,  0.0992,\n          0.1121,  0.0488, -0.1288,  0.1496],\n        [ 0.0614, -0.0258,  0.1709, -0.1655,  0.0534, -0.0301, -0.0599,  0.0967,\n          0.0058, -0.0129,  0.2203, -0.2225,  0.2148,  0.1472, -0.0596,  0.0122,\n          0.1257,  0.0876,  0.1206, -0.0627],\n        [ 0.0968, -0.0787,  0.1819,  0.1819, -0.1747, -0.1786, -0.2171,  0.2051,\n         -0.0865, -0.0692,  0.0522, -0.1707,  0.1432, -0.1749,  0.1958, -0.1671,\n         -0.0635,  0.1149,  0.1872, -0.2050],\n        [ 0.2022,  0.1924,  0.2079,  0.0491, -0.0927, -0.1847, -0.0610, -0.1210,\n         -0.1532, -0.0789, -0.1479,  0.0241,  0.1737, -0.0167,  0.1710,  0.1606,\n          0.1287, -0.0061, -0.1048,  0.1650],\n        [ 0.0232, -0.1463,  0.1351, -0.1510, -0.1512,  0.2015, -0.2204,  0.1042,\n         -0.1117,  0.1631,  0.1521, -0.1740, -0.1812,  0.0117, -0.1911, -0.1785,\n         -0.1505,  0.1657,  0.1786, -0.0774],\n        [-0.1700,  0.0222, -0.1059,  0.1948,  0.0632, -0.1044,  0.2173,  0.1028,\n         -0.0061,  0.0814,  0.1970, -0.0905,  0.1568,  0.0245,  0.2002, -0.0365,\n          0.1203,  0.1404,  0.0938,  0.1877],\n        [-0.0782,  0.0947,  0.1757, -0.0918,  0.0948, -0.2160, -0.1777, -0.0505,\n         -0.1795,  0.0442,  0.0362, -0.0906,  0.2218, -0.0934,  0.0805, -0.2223,\n         -0.0991, -0.0387, -0.2006, -0.0104],\n        [ 0.1316,  0.0933, -0.1681, -0.1878, -0.1915,  0.1129,  0.0292,  0.1477,\n         -0.0941,  0.0474,  0.0557,  0.0762, -0.0592, -0.2096,  0.1048,  0.0313,\n          0.1557,  0.2176,  0.1116, -0.0552],\n        [-0.1976, -0.1009, -0.1305,  0.2064, -0.0752,  0.1979,  0.2236,  0.2171,\n          0.1788, -0.1432,  0.1012,  0.1222, -0.1859,  0.1439, -0.1637, -0.0470,\n          0.1644,  0.1281, -0.1527, -0.0733],\n        [-0.1818, -0.0586, -0.0261,  0.1794, -0.1299, -0.1367, -0.0089, -0.0919,\n         -0.1930,  0.1561,  0.0492,  0.0993,  0.1314, -0.1412, -0.0621, -0.1129,\n          0.1879, -0.1731, -0.1215,  0.1687],\n        [ 0.2159, -0.1250,  0.0766, -0.1891,  0.0602, -0.0407,  0.0696, -0.0895,\n          0.1786,  0.1955, -0.0127,  0.1562, -0.2096, -0.1094,  0.1027, -0.0493,\n         -0.1281,  0.1895, -0.1174, -0.0860],\n        [ 0.1128, -0.0784, -0.0332,  0.0627,  0.0438, -0.1427,  0.0333,  0.1766,\n          0.0463, -0.0785, -0.0080,  0.0302, -0.2151, -0.0954,  0.0932,  0.0379,\n          0.1043,  0.0350,  0.1630, -0.0103],\n        [ 0.0590, -0.0168,  0.1342,  0.2082,  0.1440,  0.1115,  0.1040,  0.1575,\n          0.0428, -0.0145, -0.1625, -0.0650,  0.1801,  0.2184, -0.1843, -0.0933,\n          0.0832,  0.0890, -0.0696,  0.1012],\n        [ 0.0229, -0.1663, -0.1300, -0.1297, -0.1092,  0.1317, -0.2056,  0.2039,\n          0.1190, -0.2049, -0.1512,  0.1136, -0.2118, -0.2119,  0.1352, -0.2144,\n          0.0267, -0.0199, -0.0502,  0.0818],\n        [-0.1025, -0.1952, -0.0331,  0.0637,  0.0742, -0.2169, -0.1637,  0.1493,\n          0.1277,  0.0488,  0.1446, -0.1065, -0.1230, -0.0776, -0.0453, -0.1924,\n          0.0172, -0.1830,  0.0690, -0.1230],\n        [ 0.0318, -0.0995, -0.0242, -0.0825, -0.1746,  0.1257, -0.0880,  0.0003,\n         -0.0443,  0.0373,  0.0636,  0.0569,  0.0359,  0.1923,  0.2202,  0.1349,\n          0.1891,  0.0819, -0.0228, -0.0508],\n        [ 0.0307, -0.1875, -0.1075, -0.1545, -0.2150,  0.2014,  0.1791,  0.1708,\n          0.0433,  0.0242, -0.0255,  0.0996, -0.1174, -0.1378, -0.0111, -0.1452,\n          0.0968, -0.0717, -0.1412,  0.0582],\n        [ 0.0967, -0.1865,  0.1755, -0.0258, -0.1452, -0.1012, -0.1294,  0.2130,\n          0.0555,  0.1451, -0.1640,  0.1213,  0.0271, -0.0319,  0.0904, -0.1727,\n          0.1186,  0.0382, -0.1608, -0.1540],\n        [-0.0441, -0.0360, -0.0404,  0.1110, -0.0943, -0.0541,  0.0300, -0.1528,\n          0.0360, -0.0425, -0.1299, -0.1275,  0.1776, -0.0129, -0.0784, -0.0549,\n         -0.1350,  0.0074,  0.1492, -0.0011],\n        [-0.0666,  0.0139,  0.1868,  0.0955, -0.1152,  0.0959, -0.0761,  0.0143,\n          0.0477, -0.1640, -0.0125,  0.1015, -0.0140, -0.1102, -0.1370,  0.0545,\n          0.0257, -0.1023, -0.0838, -0.0859],\n        [ 0.0606,  0.0314,  0.1489, -0.0982, -0.0785, -0.0958,  0.0887,  0.0793,\n          0.2027, -0.1218,  0.0278,  0.2015,  0.0576, -0.1950, -0.1851,  0.0586,\n         -0.1852,  0.1372, -0.2128,  0.1252],\n        [ 0.2132, -0.0628, -0.0813, -0.1177, -0.0712, -0.0386, -0.0134, -0.1319,\n         -0.0083, -0.1932,  0.0856,  0.1268, -0.1263, -0.0832, -0.0992, -0.0540,\n         -0.2105,  0.1239,  0.1285, -0.1165],\n        [-0.2114, -0.1497, -0.2050, -0.1053,  0.1818, -0.1956,  0.1888, -0.1623,\n         -0.1121,  0.1212, -0.0706, -0.0310,  0.0067, -0.1278, -0.0273,  0.2132,\n          0.1585,  0.1411, -0.1830, -0.2043],\n        [ 0.1024, -0.1082,  0.2225, -0.1045, -0.0816,  0.1165, -0.0351,  0.1147,\n         -0.0533, -0.0706,  0.0453,  0.0224, -0.0782,  0.1295, -0.1324,  0.0277,\n         -0.1678,  0.0063, -0.1933,  0.0652],\n        [ 0.0357,  0.2017, -0.0552, -0.1761, -0.1181, -0.1507,  0.1839,  0.0452,\n          0.2155,  0.1698,  0.1292,  0.0096,  0.0490, -0.0942,  0.0355, -0.2072,\n          0.1990, -0.1221,  0.1878,  0.0858],\n        [ 0.1583,  0.1037, -0.2185,  0.2210,  0.0287,  0.1571,  0.0726,  0.1149,\n         -0.1740, -0.2213, -0.1229, -0.0376, -0.1594, -0.1570, -0.0684,  0.1902,\n          0.2230,  0.1772,  0.1061, -0.1260]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1326,  0.0723,  0.2017, -0.0844,  0.0465, -0.0257,  0.2214, -0.0511,\n         0.0857, -0.0331, -0.0015, -0.1825,  0.2000, -0.0580,  0.0477,  0.1668,\n        -0.1701, -0.1384,  0.1541,  0.0251,  0.1593, -0.0628, -0.0287, -0.0027,\n         0.1259, -0.1764, -0.0175, -0.1536, -0.1346, -0.0881,  0.1770, -0.0990],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.1398e-01, -8.3761e-02,  1.1992e-01,  2.7335e-02, -1.1801e-01,\n         -4.9838e-02, -7.5444e-02, -2.1679e-02,  1.4870e-01,  1.1439e-01,\n         -1.5398e-01,  7.5053e-02, -3.6126e-02, -6.8926e-02,  1.1320e-01,\n          4.1106e-02,  1.9594e-02, -1.2623e-01,  1.2995e-01, -1.5383e-01,\n          9.5321e-02,  1.1530e-01,  1.7308e-01,  1.3424e-01,  1.5424e-01,\n         -1.2727e-01,  1.9897e-02,  1.7604e-01,  1.0243e-01, -1.0306e-02,\n          7.1427e-02,  1.6233e-01],\n        [ 1.3601e-02, -1.7181e-01,  1.2582e-01,  8.0734e-02,  1.6915e-01,\n         -8.5095e-02, -1.3998e-01,  1.7172e-01, -5.2493e-02,  1.0647e-01,\n          1.1426e-01, -6.2924e-03,  3.8187e-02, -6.5537e-02,  5.2273e-02,\n          1.1076e-02,  1.3824e-01, -1.0589e-01,  1.0914e-01,  8.1868e-02,\n          1.4735e-01, -1.2346e-01, -1.7274e-01,  1.1688e-01, -9.2013e-02,\n          8.1220e-03, -1.0285e-01, -8.9425e-02,  6.3154e-03,  1.2858e-01,\n         -1.0109e-01,  1.7477e-01],\n        [ 1.3523e-01,  1.7380e-01, -4.8856e-02, -7.9017e-02,  1.1942e-01,\n         -1.3051e-01,  6.4303e-03, -1.0236e-01, -3.5675e-02,  1.6382e-01,\n         -1.4378e-01,  1.0526e-01, -1.1618e-01,  1.4967e-02,  3.0379e-02,\n          1.0000e-01, -1.2036e-01,  6.1279e-02, -6.8003e-02,  1.1991e-01,\n         -1.6488e-01,  1.1009e-01, -1.0170e-01, -6.3360e-02, -1.3306e-01,\n         -6.2230e-02,  1.4744e-01,  1.6827e-01, -1.6879e-01,  9.6078e-02,\n          4.6716e-02, -6.8603e-02],\n        [-1.5408e-01, -7.3267e-02, -2.6175e-02, -5.7455e-02, -6.5860e-02,\n          5.3571e-02,  2.4829e-04,  8.2980e-02, -3.3205e-02,  1.5479e-01,\n         -1.7048e-01, -5.7079e-02,  1.5805e-01,  1.5284e-01, -5.2320e-02,\n         -1.6184e-01,  8.8498e-02, -2.4220e-02,  1.5843e-01, -1.2185e-01,\n          6.9924e-02,  1.5254e-01, -1.6292e-01, -6.8777e-02,  1.5242e-01,\n         -2.4461e-02,  7.2022e-02,  7.0767e-02,  6.4272e-02,  1.3204e-01,\n         -1.7045e-01, -1.1957e-01],\n        [ 7.6612e-02,  1.1584e-02,  3.6288e-02, -6.0305e-02,  1.3214e-02,\n          9.7923e-02,  1.1895e-01, -1.3780e-01, -1.6257e-01, -1.2030e-01,\n          2.5571e-02, -8.7062e-02,  6.6259e-02, -1.3816e-01, -1.0060e-01,\n         -6.2067e-02, -6.4347e-02, -1.6218e-01, -1.2512e-01, -1.3918e-01,\n          3.1174e-02,  5.6510e-02, -1.5299e-01,  1.0489e-01, -4.5036e-02,\n         -1.0681e-01,  1.1169e-01, -7.4480e-04, -1.2155e-01,  1.3152e-01,\n         -8.2340e-02,  1.1312e-01],\n        [ 8.3136e-02, -1.1882e-01,  7.8521e-02,  1.7810e-02,  1.6433e-01,\n         -6.5846e-02, -7.5705e-02,  7.2892e-02, -4.0166e-02, -1.3498e-01,\n          3.5232e-02, -4.4820e-02,  1.7516e-01, -2.7825e-02,  1.3894e-01,\n          1.6052e-01, -7.3336e-02,  1.3282e-01, -1.5600e-01,  1.0776e-01,\n          1.6613e-02, -1.3960e-02, -5.8799e-02,  5.9350e-02,  1.1201e-01,\n         -7.7072e-02,  1.0664e-01, -1.1192e-01,  3.8910e-02,  1.5183e-01,\n         -1.3612e-01,  1.3371e-01],\n        [ 4.1515e-06,  8.0179e-03, -1.1763e-01,  7.6188e-02,  1.2266e-01,\n         -1.5735e-01, -6.0802e-02,  1.6479e-02, -3.3878e-02, -6.8052e-02,\n          1.7258e-01, -1.4204e-01,  7.9059e-02, -7.0160e-02, -1.4175e-01,\n          5.6629e-02,  8.6139e-03,  3.5612e-02,  1.3759e-01,  8.9790e-02,\n          1.3024e-01, -7.3726e-02,  7.5742e-02, -6.1257e-02,  5.0296e-02,\n         -1.1442e-01, -1.1635e-01, -1.3617e-01, -6.4067e-02,  1.2854e-01,\n         -1.9015e-02,  1.6077e-01],\n        [ 1.6932e-02,  6.3691e-02, -1.1516e-01, -4.9290e-02,  7.4834e-02,\n          3.7241e-02,  7.9418e-02, -7.2081e-02,  6.3245e-02,  1.1163e-01,\n         -1.1190e-01,  1.5999e-01,  1.2640e-01,  1.5147e-01,  5.6648e-02,\n         -1.6251e-01,  1.1579e-01,  1.1742e-01, -1.3696e-02,  1.4466e-01,\n         -1.4751e-01,  6.8843e-02,  1.6774e-02,  1.5862e-04,  3.8657e-02,\n         -8.2491e-02, -8.2712e-02, -6.6110e-02, -5.1701e-02, -1.5243e-01,\n         -8.5449e-02,  6.8745e-02],\n        [-1.6411e-01, -1.5004e-01,  1.0704e-01, -1.2595e-01,  8.1502e-03,\n          8.2268e-02,  1.6453e-01,  1.6361e-01, -1.2739e-01, -2.5600e-02,\n         -6.8986e-02,  2.2477e-02, -8.2285e-03, -1.4334e-01, -1.0256e-01,\n         -1.3053e-01,  3.5825e-06,  1.2265e-01, -1.4861e-01, -1.2554e-01,\n          1.1150e-01,  6.6329e-02,  8.0953e-02,  1.5546e-01, -1.6987e-02,\n          1.6364e-01, -2.4204e-02, -1.1733e-01, -2.5923e-02, -8.7177e-03,\n         -1.3469e-01,  2.8089e-02],\n        [-5.7181e-02, -2.0012e-02, -1.9428e-02,  6.8827e-02, -1.0225e-01,\n          1.1304e-02,  1.0969e-01,  7.5334e-02,  1.7115e-01, -1.2001e-01,\n         -1.5616e-02, -2.5768e-02, -1.2925e-01, -1.0349e-01, -2.2657e-02,\n         -7.1985e-02, -1.4564e-01,  1.4976e-01,  1.7258e-02, -1.3452e-01,\n         -7.9582e-02,  3.0537e-02,  6.4150e-02, -1.6366e-01, -8.0654e-03,\n          2.7230e-02,  2.8822e-02, -2.0329e-02, -8.3953e-02,  8.5912e-02,\n         -1.3776e-01, -6.9550e-02],\n        [-1.4218e-01,  1.1548e-01,  9.8179e-02,  9.1512e-02,  1.4854e-01,\n          5.3532e-02,  3.3723e-02, -1.7159e-01,  1.6685e-02,  4.7113e-02,\n         -4.0514e-02, -1.0031e-01, -2.0186e-02,  1.2410e-01,  4.9656e-02,\n         -2.6680e-02, -6.5919e-02,  9.1478e-02,  5.2877e-02, -1.0719e-01,\n          5.9391e-02, -1.7149e-01,  1.2682e-02,  1.6214e-02, -1.0025e-01,\n          1.7629e-01, -7.8900e-02, -1.7652e-01, -5.6472e-02,  7.3887e-02,\n         -3.7755e-02, -7.7802e-02],\n        [ 1.4725e-01, -6.4728e-02, -3.5764e-02,  6.7115e-02, -1.6584e-01,\n         -2.2750e-02,  3.8838e-02,  1.4842e-01,  1.6901e-02, -9.8722e-02,\n          7.5493e-04, -1.3749e-01, -2.0334e-03,  1.5539e-01,  2.2573e-02,\n         -3.8303e-02,  5.7379e-02,  1.0294e-01, -1.4582e-01,  1.0755e-01,\n         -1.2947e-01, -8.2611e-02, -1.1212e-01, -5.8551e-02, -2.1844e-02,\n          1.5431e-01, -1.3908e-01,  6.3018e-02,  4.1787e-02, -1.7883e-03,\n          7.2349e-02, -6.0300e-02],\n        [-1.0849e-01,  1.6547e-01, -5.4685e-02, -3.9271e-02, -7.2298e-02,\n         -1.6897e-01,  5.1664e-03,  6.0392e-02, -9.2574e-02, -1.1993e-01,\n         -9.5499e-02, -8.5806e-03, -3.8097e-02,  1.3241e-01,  2.7449e-02,\n          2.0150e-02, -1.2367e-01,  5.4376e-02,  6.2005e-02,  4.8922e-02,\n         -1.1769e-01,  1.5938e-01,  3.5691e-02, -6.2929e-02,  1.1426e-01,\n          8.9059e-02,  7.5872e-02, -1.4855e-01, -1.5226e-01,  6.8782e-02,\n          5.2000e-02,  8.8408e-02],\n        [ 9.0627e-02, -3.5935e-02,  1.1440e-01, -1.4191e-01, -1.0882e-01,\n          1.7630e-01, -1.4261e-02, -1.8131e-02, -9.3750e-02, -5.8796e-02,\n          1.2997e-01, -1.7326e-01, -1.4727e-01, -7.8700e-02, -2.8634e-02,\n          5.6659e-02, -1.1979e-01, -5.0860e-02, -1.3616e-01,  1.0524e-01,\n          1.5172e-01,  1.2126e-01,  1.1625e-01, -1.2069e-01,  1.1517e-01,\n         -3.2528e-02,  1.1358e-01,  8.9867e-02, -2.1300e-02,  6.4363e-02,\n          7.6778e-02,  1.5389e-01],\n        [-4.0666e-02, -4.8748e-02, -1.5813e-01,  1.1967e-01,  1.5901e-01,\n          1.6111e-01,  1.1419e-01,  1.7352e-01,  2.8773e-02, -5.8837e-05,\n         -1.2356e-01,  1.1740e-01,  3.6964e-02,  1.4660e-01,  8.7604e-02,\n          1.0499e-01, -1.5605e-01, -1.6633e-01, -1.6842e-01, -7.7169e-02,\n          1.6527e-01, -1.2581e-01,  1.4009e-01,  6.4874e-02,  1.5766e-01,\n          7.2533e-02,  4.1772e-02,  1.8812e-02,  1.4168e-01, -1.4438e-01,\n          6.1783e-02, -6.3719e-02],\n        [-3.6713e-02, -3.7188e-02,  5.8929e-02,  5.1361e-02,  1.4099e-01,\n         -1.4803e-01, -2.8656e-02,  1.7448e-01,  1.2672e-01, -1.0640e-02,\n         -6.4698e-02, -1.0073e-02,  2.4451e-02, -6.2944e-02,  5.1036e-02,\n          1.6134e-01,  1.2763e-01,  2.8255e-02,  3.4414e-02,  5.0701e-03,\n          1.5076e-02,  6.4165e-02, -7.4684e-02,  1.0779e-01,  1.2746e-01,\n          9.4494e-02, -1.2777e-02, -1.5298e-01,  8.9596e-02,  1.6614e-01,\n         -1.3162e-01,  1.7424e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0089,  0.1736,  0.1231,  0.1538,  0.0936, -0.1281, -0.0719, -0.0402,\n         0.1171, -0.1463,  0.1232, -0.1317,  0.1165,  0.1561,  0.0533, -0.0338],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2213,  0.1427,  0.2399, -0.1466,  0.1468, -0.2412,  0.2370,  0.0436,\n          0.1294,  0.1375, -0.0659, -0.2336, -0.1642, -0.1770, -0.2203,  0.1417],\n        [-0.2377,  0.1338,  0.2378,  0.2313, -0.0065,  0.2209,  0.2068,  0.1958,\n          0.2234, -0.1172, -0.1555,  0.2126,  0.0171,  0.1687,  0.0348,  0.0925],\n        [-0.1487, -0.0236,  0.1557,  0.1075, -0.1912, -0.1187, -0.0140,  0.1498,\n         -0.1842, -0.2213,  0.0129,  0.1966, -0.2047, -0.0458,  0.0554,  0.0370],\n        [-0.0013, -0.1778,  0.0068,  0.1382,  0.1824,  0.0477,  0.2446,  0.1523,\n          0.1561,  0.0250, -0.0182, -0.1446,  0.1616,  0.1485,  0.0117,  0.1360],\n        [ 0.1093, -0.0076, -0.2051, -0.0436,  0.0952,  0.2142, -0.1298,  0.1289,\n          0.0057,  0.2085, -0.2151, -0.0659, -0.0861,  0.0865,  0.1804, -0.2255],\n        [-0.0880,  0.0801, -0.2324,  0.0095,  0.2340, -0.0438,  0.1675,  0.0039,\n          0.1627,  0.0250,  0.0546, -0.0188,  0.1921,  0.0760,  0.1415, -0.0677],\n        [ 0.0004, -0.0766,  0.0776,  0.0577, -0.1292,  0.0809, -0.2069, -0.1398,\n          0.0838,  0.1827, -0.1488, -0.1438, -0.0062,  0.0292,  0.2283, -0.1573],\n        [-0.0047,  0.0046,  0.1134, -0.0902,  0.0052, -0.2125,  0.0256,  0.1438,\n          0.0243, -0.0046, -0.2419,  0.2137, -0.2434, -0.2020, -0.0622, -0.1159]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2286, -0.0184,  0.0323,  0.0368, -0.0766,  0.1711, -0.2151,  0.0007],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2979, -0.1163,  0.1475,  0.0552,  0.2326, -0.0390, -0.3044,  0.2031]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3510], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x10c4be380>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x11c3cc790>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s50080000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s50080000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}