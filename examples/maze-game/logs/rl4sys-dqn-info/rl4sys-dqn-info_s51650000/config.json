{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s51650000"
    },
    "q_lr":	0.0005,
    "seed":	51650000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x11a2c0c40>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0645, -0.1740,  0.0142, -0.1256,  0.1425, -0.0817, -0.0238, -0.2098,\n        -0.2076,  0.1183,  0.0729,  0.0318,  0.1359, -0.1305, -0.0194, -0.0076,\n         0.1032,  0.0630, -0.1068, -0.0316,  0.1704, -0.0381, -0.2211, -0.0191,\n        -0.0128, -0.0169, -0.1289,  0.0591,  0.1548,  0.0502,  0.1569,  0.2225],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1787, -0.0877,  0.2175,  0.2211,  0.1777,  0.2201,  0.1461,  0.1046,\n         -0.1196,  0.0789,  0.0529,  0.0934, -0.1975, -0.1593,  0.0944, -0.1879,\n         -0.2005, -0.0616,  0.2100, -0.2106],\n        [-0.0595,  0.2124, -0.2225,  0.2195,  0.0058, -0.1319, -0.1642, -0.0966,\n          0.1724,  0.1963, -0.0028,  0.0535,  0.2179,  0.1395,  0.1182, -0.1801,\n          0.1431,  0.0816, -0.0371,  0.0113],\n        [ 0.0010,  0.0180, -0.0051, -0.0305,  0.1788,  0.1979, -0.1320,  0.2085,\n          0.0043, -0.0557, -0.2030,  0.0210, -0.1772, -0.1039, -0.0432,  0.1504,\n         -0.1837,  0.1869, -0.1549, -0.1138],\n        [-0.1974,  0.0933,  0.2127, -0.1853, -0.1020,  0.1956,  0.0750,  0.0818,\n         -0.0303,  0.1526,  0.1569, -0.1712,  0.0707,  0.0400,  0.2191, -0.1246,\n         -0.1716, -0.1988,  0.1630, -0.0316],\n        [ 0.0099,  0.0793,  0.1622, -0.1008,  0.0297, -0.1510,  0.0211, -0.0434,\n          0.1799,  0.0829,  0.2088,  0.1250, -0.0464, -0.1175,  0.0007,  0.1688,\n          0.1801,  0.2043, -0.0483,  0.0764],\n        [-0.0444,  0.1724, -0.0222, -0.1283,  0.1609,  0.0234,  0.0018, -0.0743,\n          0.0048, -0.1176,  0.1415,  0.0510, -0.1594, -0.0080, -0.0608,  0.0637,\n          0.1422, -0.1474,  0.0086, -0.1208],\n        [-0.0814,  0.2193, -0.0593,  0.1813,  0.1652,  0.2112,  0.0668, -0.0895,\n          0.0012, -0.0063, -0.1959,  0.0643, -0.0627,  0.0265,  0.2017,  0.2100,\n          0.2149,  0.0285,  0.0844, -0.1877],\n        [ 0.0231,  0.0795, -0.1111, -0.1998,  0.0004, -0.0440, -0.1004, -0.0846,\n          0.1775, -0.1912, -0.0889, -0.1000,  0.1227,  0.1181, -0.0541,  0.1203,\n         -0.0394, -0.2228,  0.1679, -0.2007],\n        [-0.1319,  0.0936,  0.1093,  0.1157,  0.0406, -0.1813, -0.0130,  0.1179,\n          0.1701,  0.1048, -0.0788, -0.0711,  0.1521, -0.0540, -0.1836, -0.1450,\n          0.1862, -0.0161,  0.1979, -0.0085],\n        [-0.0817,  0.1006,  0.0064,  0.1604,  0.1695, -0.0158,  0.0889, -0.1622,\n          0.1108, -0.1634,  0.0030, -0.0362, -0.0923, -0.1010,  0.0272,  0.0109,\n         -0.1711,  0.1426, -0.1064,  0.2028],\n        [ 0.1783, -0.0757, -0.1133,  0.2140, -0.1106, -0.1291, -0.1996,  0.0151,\n          0.0717, -0.1842,  0.0196,  0.1858,  0.0222, -0.1623, -0.1269, -0.0314,\n         -0.1954, -0.0229, -0.0228,  0.0641],\n        [-0.1533,  0.0485,  0.0114, -0.0173, -0.0482, -0.0537,  0.0824,  0.0601,\n         -0.0462,  0.0112, -0.1760, -0.1417,  0.1443,  0.0838,  0.0017, -0.0009,\n          0.0557, -0.1819, -0.0914,  0.1067],\n        [-0.2046,  0.1453,  0.2058, -0.0246, -0.2002,  0.0214, -0.2035,  0.0130,\n         -0.0128,  0.0074, -0.0356, -0.2011, -0.0044,  0.2174,  0.0625, -0.1958,\n          0.0113,  0.1140,  0.1003,  0.1337],\n        [ 0.1401,  0.0679, -0.1228, -0.1827, -0.1038, -0.0278, -0.1246, -0.2153,\n         -0.1521,  0.2133, -0.2147,  0.0981, -0.1467, -0.1766,  0.2029,  0.0923,\n         -0.0816, -0.0826,  0.0494, -0.0566],\n        [-0.1651,  0.0576,  0.1997, -0.0453, -0.1615, -0.1776, -0.2210, -0.0502,\n         -0.0038,  0.0492, -0.2208, -0.1185, -0.1299,  0.0273, -0.0034,  0.0942,\n          0.1985, -0.0565, -0.0270, -0.0482],\n        [-0.1933, -0.1346,  0.1200,  0.2233, -0.0651,  0.0213,  0.1201,  0.0040,\n          0.0886,  0.0933,  0.1782, -0.1299, -0.1796, -0.0334, -0.1914,  0.1549,\n         -0.0178,  0.0698, -0.0142, -0.1481],\n        [ 0.0122,  0.0377, -0.1009,  0.1689, -0.1047, -0.2072, -0.0363, -0.0962,\n         -0.0993,  0.1775, -0.1356, -0.0187,  0.0588,  0.0934,  0.0715, -0.2094,\n          0.2223,  0.0970, -0.0459, -0.1799],\n        [ 0.0115,  0.1924, -0.0422,  0.0904,  0.0437, -0.2215,  0.0990,  0.1457,\n          0.0479, -0.0395, -0.0598, -0.1345,  0.1721,  0.1277,  0.0913,  0.0387,\n         -0.0003,  0.1562,  0.2129, -0.1098],\n        [-0.1585, -0.0613, -0.0389, -0.0776,  0.1178, -0.0817, -0.0592, -0.0645,\n          0.1391, -0.1906,  0.1482, -0.1391,  0.0185, -0.1730, -0.1181,  0.2062,\n          0.1553,  0.1468, -0.1523,  0.1020],\n        [-0.1267,  0.1146, -0.0596,  0.0026,  0.0388, -0.0430,  0.0257, -0.2159,\n         -0.1334,  0.0944,  0.0369, -0.0735,  0.1277, -0.0152, -0.0593, -0.0586,\n         -0.1729, -0.0448,  0.2040,  0.1254],\n        [-0.1329, -0.0651,  0.2004, -0.0354, -0.1763,  0.0076, -0.0328,  0.1066,\n          0.1910,  0.0709,  0.0603, -0.0524,  0.2014, -0.0448, -0.1451,  0.0811,\n         -0.0968,  0.1711, -0.1987,  0.0542],\n        [ 0.1166, -0.1437, -0.0874, -0.1515, -0.0796, -0.0551,  0.1519, -0.2083,\n         -0.1095, -0.1513,  0.0402, -0.0626,  0.1646,  0.0802,  0.1323,  0.0293,\n         -0.1332,  0.1756,  0.1699,  0.0482],\n        [-0.1936, -0.0053,  0.1177,  0.0174,  0.0538, -0.0693,  0.0903, -0.1535,\n         -0.0622, -0.0767,  0.1264,  0.1296,  0.0956, -0.0429, -0.1674,  0.1162,\n         -0.1604,  0.1424, -0.1026,  0.0219],\n        [ 0.0024, -0.1057, -0.0200,  0.1571,  0.0630,  0.1505, -0.1832,  0.0325,\n          0.1465, -0.1296, -0.2078, -0.0706, -0.1956,  0.1665, -0.1825, -0.2141,\n          0.1551,  0.1563, -0.1508,  0.1640],\n        [ 0.0550, -0.0636,  0.1760, -0.1268, -0.0006,  0.2034, -0.1031, -0.1802,\n          0.1533,  0.1108, -0.0268,  0.1411,  0.0400, -0.0292,  0.0322,  0.0016,\n         -0.1860, -0.1860, -0.1553,  0.1495],\n        [-0.1423, -0.1386, -0.1322, -0.2070,  0.0039, -0.0875, -0.1287, -0.1565,\n         -0.1261,  0.0867,  0.1389, -0.1544, -0.0987, -0.1809, -0.1204,  0.1503,\n         -0.0269,  0.0093,  0.0733, -0.0997],\n        [-0.1880, -0.1729,  0.1389, -0.1450,  0.1584,  0.1682, -0.1786, -0.1493,\n         -0.0260, -0.1726, -0.0093, -0.1074,  0.2149,  0.0702,  0.1299,  0.1235,\n         -0.1638, -0.0505, -0.0262,  0.0539],\n        [-0.0139,  0.1329, -0.1066, -0.1367,  0.1801,  0.0212,  0.2037,  0.0994,\n          0.1692,  0.1486, -0.2071, -0.1374,  0.1301,  0.1405, -0.1721, -0.0567,\n         -0.1081, -0.1237, -0.0005,  0.0230],\n        [ 0.0956, -0.1292, -0.1845, -0.1906,  0.1154, -0.0820, -0.1473, -0.0424,\n          0.0167, -0.1582,  0.1635,  0.1596,  0.1048,  0.1175,  0.0832,  0.2072,\n         -0.1784, -0.1570, -0.1759, -0.0986],\n        [ 0.1082,  0.0900, -0.2216,  0.2027, -0.0286,  0.0796, -0.0575, -0.0010,\n         -0.1394, -0.1992,  0.0784,  0.0965, -0.1355,  0.0077,  0.0355,  0.0011,\n         -0.0919,  0.0379,  0.0834, -0.1190],\n        [ 0.1108, -0.1625, -0.2233,  0.0564, -0.1507,  0.0733,  0.1686, -0.0565,\n         -0.1868, -0.0571, -0.1322, -0.1499, -0.0741, -0.0782, -0.1307,  0.1732,\n          0.0952,  0.0182,  0.0833, -0.1127],\n        [-0.0151,  0.1207, -0.0088, -0.2012,  0.0684, -0.1189, -0.0116, -0.1393,\n          0.2180,  0.2007,  0.0845, -0.1537, -0.1182,  0.0227, -0.0455,  0.0141,\n         -0.1760, -0.1761,  0.0156, -0.0713]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1469,  0.1748, -0.0829,  0.1705,  0.1410,  0.0838,  0.1358, -0.0705,\n        -0.0031,  0.0853,  0.1639,  0.1245, -0.1765, -0.0185, -0.1477, -0.1437],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.3110e-01, -2.4264e-02, -2.2949e-02,  5.2420e-02, -2.3051e-02,\n         -9.7767e-02,  1.1965e-01, -1.0519e-01, -5.7338e-02,  1.2841e-01,\n          1.6432e-01,  2.6456e-02, -1.2214e-01, -8.3259e-02, -1.2718e-01,\n          1.0734e-01, -9.5759e-02,  2.4274e-02,  5.6327e-02, -5.9540e-03,\n          1.1720e-01,  1.3960e-02,  1.8419e-02,  1.2217e-01,  1.1323e-01,\n          4.6340e-02,  4.7648e-02, -3.1466e-02,  4.0428e-02,  8.8584e-03,\n         -9.7716e-02, -8.2889e-02],\n        [-1.4745e-01, -1.1225e-01, -1.6356e-01, -9.3894e-02,  3.8508e-02,\n         -1.4227e-01,  1.6913e-02,  4.6345e-02, -5.7241e-02,  1.9226e-02,\n         -9.4058e-02, -1.6377e-01, -1.3339e-01, -1.6233e-01,  1.6135e-02,\n          3.3364e-02, -2.5472e-02,  1.4978e-01, -8.0567e-02, -5.5773e-02,\n         -3.8676e-02,  7.8003e-02, -7.8552e-03, -9.5154e-02, -4.0907e-02,\n          8.9840e-02, -8.9020e-03,  4.0222e-02,  1.6556e-01,  5.8608e-03,\n          1.5233e-01,  7.1987e-02],\n        [ 6.5955e-02, -1.6688e-01,  6.4200e-03,  1.0385e-01, -1.2610e-01,\n         -1.2890e-01,  2.1590e-02, -5.0269e-02,  1.2602e-01,  1.6744e-01,\n         -1.0513e-01, -1.2365e-01,  8.1718e-02, -1.3264e-01, -7.7670e-02,\n          3.8485e-02,  1.6689e-01,  1.2135e-01, -1.4199e-01,  2.5627e-02,\n          1.2504e-01,  1.4249e-01, -7.7079e-02,  1.5180e-01, -9.7875e-02,\n          1.3529e-01, -5.9007e-02,  4.6317e-02,  1.0998e-01,  1.0344e-01,\n          1.4264e-01, -5.1454e-02],\n        [ 1.5775e-01,  1.3019e-01, -1.7039e-01, -8.4061e-02, -4.7215e-03,\n         -1.1660e-02, -3.1099e-02, -6.9986e-02, -1.6125e-01,  6.6643e-02,\n          1.6490e-01, -1.5275e-01,  5.1525e-02, -3.5793e-02, -1.5995e-02,\n          1.3979e-01, -7.0049e-02, -1.4738e-01, -1.6040e-01, -1.3582e-01,\n         -1.4293e-01, -7.1200e-02, -1.1951e-01,  5.6351e-02, -1.1641e-01,\n          4.9572e-02,  1.6819e-01,  7.9837e-02, -1.5407e-01, -1.4025e-01,\n         -9.2574e-03, -1.6671e-01],\n        [ 6.3619e-02,  1.3618e-01,  1.7012e-01, -1.2137e-01, -4.2024e-02,\n          1.3616e-02,  1.2707e-01,  1.6073e-01, -4.1667e-02, -1.1454e-01,\n         -4.9162e-02,  7.1041e-02, -9.2475e-02, -6.7184e-02,  1.5054e-01,\n          1.3918e-01,  1.0189e-02,  5.6262e-02,  1.0621e-01, -1.0548e-01,\n         -1.1541e-01,  5.8475e-02, -2.7038e-02,  7.6089e-02,  1.1147e-01,\n         -1.1458e-02,  9.0178e-02,  2.9005e-03,  4.8100e-02, -1.4036e-01,\n         -9.3116e-02,  1.2537e-01],\n        [-1.0075e-01, -1.7363e-01,  7.6128e-02, -4.3534e-03,  3.7888e-02,\n          2.2588e-02, -9.1282e-02, -5.2774e-02, -1.7195e-01, -1.4266e-01,\n          1.7307e-01,  1.5273e-01,  7.9235e-03, -1.0863e-01,  1.1748e-01,\n          9.3763e-02, -4.1977e-02,  8.9999e-02,  2.3893e-02, -1.6847e-02,\n          4.8747e-02,  1.0196e-01,  1.7458e-01, -1.7257e-01,  1.0935e-01,\n         -1.0228e-01,  2.1311e-02, -4.3822e-02, -1.3611e-01,  2.7921e-02,\n         -3.5531e-02, -1.5317e-01],\n        [ 7.8539e-02,  1.6136e-04, -1.4256e-01,  6.4859e-02, -8.3992e-02,\n          8.3831e-02, -1.3602e-01, -1.1459e-01, -9.4707e-02,  5.7726e-02,\n          8.7613e-02, -4.5677e-02, -1.0412e-01,  4.6049e-02,  1.3332e-02,\n         -7.4165e-02, -4.9939e-02, -5.6325e-03,  8.3208e-02, -5.5447e-02,\n          4.0364e-02, -4.3670e-02, -6.5221e-02,  1.4817e-01,  1.5492e-02,\n          5.8301e-02,  1.3151e-01,  1.2259e-01, -1.0940e-01, -1.4274e-01,\n         -1.6609e-01, -1.4990e-01],\n        [-7.8336e-02, -9.5747e-02, -5.3196e-02, -1.0917e-01, -1.5145e-01,\n          1.1238e-01, -1.2214e-01,  5.0133e-02,  1.4497e-01,  1.0697e-01,\n         -1.3060e-01, -5.8647e-02, -4.1693e-02, -1.7554e-01, -9.8243e-02,\n         -1.4722e-01,  6.2850e-02,  9.2903e-02,  6.8018e-02,  2.1792e-02,\n         -1.7847e-02, -1.5216e-01,  1.3737e-02, -1.0329e-01, -1.3702e-01,\n         -1.4821e-01,  1.2112e-01, -3.6793e-02, -1.3008e-01,  1.7351e-01,\n          8.4392e-02, -1.5383e-01],\n        [ 4.7742e-02,  1.6678e-01,  4.2386e-02, -1.0273e-01,  1.4006e-03,\n         -6.6823e-02, -2.9581e-02,  1.3977e-01, -3.6872e-02,  6.9847e-02,\n         -1.1406e-01, -1.7139e-01,  5.9754e-02,  6.8679e-02, -5.2979e-02,\n         -8.8302e-02, -1.6122e-01,  1.0101e-01,  5.9459e-02, -7.1288e-03,\n          7.4020e-02, -1.3365e-01,  8.7732e-02,  1.2231e-02,  6.6700e-02,\n          1.1891e-01,  7.1481e-02,  4.3779e-02,  5.6627e-03,  1.2917e-01,\n          9.6076e-02, -7.6018e-02],\n        [-1.0662e-01, -8.7273e-02, -5.9737e-02, -6.9385e-02, -6.1511e-02,\n         -4.5370e-02,  8.6852e-02, -1.7502e-01,  1.0585e-01,  2.9534e-02,\n          5.7120e-02, -4.5474e-02, -2.5218e-02, -3.2085e-02,  1.8774e-02,\n          1.3443e-01, -9.7993e-02, -1.1467e-01, -1.4649e-01,  1.4639e-01,\n          5.1433e-02, -4.8153e-02,  1.6003e-01, -1.2475e-01, -8.9528e-02,\n         -5.5684e-02,  4.5131e-02, -1.7129e-01, -9.2185e-02, -6.8956e-02,\n          4.4016e-02, -9.5925e-02],\n        [-2.4820e-02,  1.4402e-01,  1.6946e-01,  1.7347e-01, -1.0155e-01,\n          1.6090e-01, -1.0165e-01, -3.1276e-02,  2.9428e-02,  1.6675e-01,\n         -9.0638e-02, -7.4463e-02, -6.0131e-02,  1.3669e-01,  1.0260e-01,\n          1.7942e-02, -1.1199e-01,  5.0067e-02, -6.7823e-02,  9.8768e-02,\n          1.2550e-01, -1.7547e-02, -4.3517e-02,  1.3791e-01,  7.0204e-02,\n         -1.9239e-02, -2.7280e-02,  1.6117e-01, -1.6962e-01,  1.4680e-02,\n         -8.3128e-02,  4.8314e-02],\n        [ 9.8857e-02, -6.6284e-02, -1.4308e-01, -4.6948e-03,  8.1569e-02,\n          8.1953e-02,  1.3055e-01, -1.4831e-01, -1.7529e-01,  4.1805e-02,\n          5.2293e-02, -8.1552e-02,  3.6436e-02,  4.1171e-03,  5.4415e-02,\n          8.0016e-02,  1.2162e-01,  1.0402e-01, -9.0138e-02,  1.3169e-01,\n          1.4416e-01, -2.4434e-02,  5.0041e-02, -1.1408e-01,  3.2410e-02,\n         -9.5798e-02, -1.4331e-01, -1.6114e-01, -1.5037e-01,  1.4535e-01,\n          9.9295e-03, -3.8178e-02],\n        [ 9.5931e-02, -1.4076e-01,  3.6228e-02,  3.0459e-02, -1.2912e-01,\n         -8.0163e-02,  2.7227e-02,  4.1655e-03, -6.7076e-02, -1.3129e-01,\n         -1.7289e-01, -1.4537e-01,  7.0980e-02,  5.7501e-02, -1.4302e-01,\n          1.2937e-01,  9.6751e-03, -1.1842e-01, -1.7592e-01, -1.2576e-01,\n          1.7617e-01,  7.8115e-02,  1.1831e-01, -2.9780e-02, -1.5461e-01,\n         -1.1952e-01,  9.3376e-02, -1.6473e-01, -2.9492e-02,  8.0231e-02,\n          1.4801e-01, -8.5286e-02],\n        [-3.4502e-02,  1.6366e-01, -1.6829e-01,  5.4374e-02,  1.3400e-01,\n          4.0150e-02, -5.1645e-02, -1.2782e-01,  8.0674e-02, -6.2839e-02,\n         -1.4352e-01,  1.1878e-01,  2.6265e-02,  4.1003e-02,  1.4038e-01,\n         -1.1256e-01, -4.7340e-02,  5.4686e-03,  6.3145e-02,  1.7157e-01,\n         -6.5796e-02, -6.9035e-03, -1.3536e-01, -1.6593e-01, -1.0058e-01,\n          2.4897e-02,  9.2564e-02,  1.6603e-01,  6.1270e-02,  1.3345e-01,\n         -1.6831e-02,  9.9668e-02],\n        [ 3.7611e-02,  6.3830e-02, -6.2264e-02, -9.7671e-02, -6.3530e-02,\n         -1.2141e-01, -5.8169e-02,  4.5942e-02,  1.2885e-01,  7.5373e-02,\n          1.3709e-01, -1.3822e-01, -1.5159e-01,  1.6036e-01, -1.1377e-01,\n          9.3311e-02,  1.6902e-01,  9.7457e-02,  7.1346e-02, -1.6105e-01,\n          5.5198e-03, -1.4063e-02,  1.2339e-01, -1.8935e-02,  7.6466e-02,\n          1.0817e-01, -1.4408e-02, -4.2834e-02,  6.8752e-03, -1.2939e-01,\n         -1.7056e-01,  1.3455e-01],\n        [ 1.2403e-01,  2.7523e-02,  3.3421e-03,  2.1337e-02,  1.0784e-01,\n          1.2138e-01,  1.6095e-02,  1.4448e-01, -1.1731e-01,  1.4798e-01,\n         -8.9518e-02,  1.4377e-01,  1.2759e-01,  1.5540e-01, -1.0678e-01,\n          1.2340e-01, -1.6134e-01,  5.9664e-02,  1.3281e-01,  1.0304e-01,\n          1.0178e-01,  1.2066e-03,  2.4535e-02,  1.6121e-01,  2.4885e-02,\n          1.5081e-01, -3.4564e-02, -1.1414e-01, -4.2420e-02,  1.4095e-01,\n          1.0956e-01,  1.5906e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2229, -0.0064,  0.0399, -0.1894,  0.1318, -0.1222,  0.1726,  0.1645],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2344, -0.0784, -0.0283, -0.2284, -0.1961, -0.0646, -0.0046,  0.0909,\n         -0.1747,  0.1132, -0.1846,  0.1661,  0.2105, -0.0396,  0.1748, -0.1657],\n        [ 0.1990,  0.0744,  0.2290, -0.0109, -0.1006, -0.2322, -0.2058,  0.1378,\n         -0.2350, -0.1283, -0.0670,  0.1693,  0.1173, -0.1672,  0.0970,  0.0338],\n        [-0.0765, -0.0689, -0.1365, -0.1062,  0.0374, -0.2251,  0.1923,  0.1148,\n         -0.1404,  0.2050,  0.1651, -0.1440, -0.0855,  0.1174, -0.0043, -0.0983],\n        [-0.0324, -0.0199, -0.0186,  0.1001, -0.0223, -0.0507,  0.1252,  0.2393,\n          0.1670, -0.1227,  0.1960, -0.1166,  0.2451, -0.1067,  0.2116, -0.2103],\n        [ 0.1124,  0.0845,  0.0962, -0.2055,  0.0064, -0.1296,  0.1172,  0.2171,\n         -0.0458, -0.1817,  0.0285,  0.1258, -0.0424,  0.2444,  0.1188,  0.1212],\n        [ 0.1135, -0.0781, -0.1272,  0.2321,  0.0380,  0.2022, -0.0390,  0.0806,\n          0.2095, -0.0779, -0.0767,  0.1053, -0.1684,  0.1466, -0.0367, -0.2303],\n        [ 0.0108,  0.1131,  0.0634, -0.0442, -0.0695, -0.0373, -0.1662,  0.0176,\n         -0.2041, -0.1616, -0.0797, -0.0848, -0.0139,  0.1969,  0.2233, -0.0700],\n        [ 0.1520,  0.2444, -0.1746,  0.2082, -0.2361,  0.2432,  0.0187,  0.0201,\n          0.1359,  0.0084, -0.1175,  0.1940, -0.1567,  0.1393, -0.0933, -0.2267]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2513], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0555,  0.1690,  0.2634,  0.0277,  0.0018, -0.2710, -0.0370, -0.1123]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.1787, -0.0877,  0.2175,  0.2211,  0.1777,  0.2201,  0.1461,  0.1046,\n         -0.1196,  0.0789,  0.0529,  0.0934, -0.1975, -0.1593,  0.0944, -0.1879,\n         -0.2005, -0.0616,  0.2100, -0.2106],\n        [-0.0595,  0.2124, -0.2225,  0.2195,  0.0058, -0.1319, -0.1642, -0.0966,\n          0.1724,  0.1963, -0.0028,  0.0535,  0.2179,  0.1395,  0.1182, -0.1801,\n          0.1431,  0.0816, -0.0371,  0.0113],\n        [ 0.0010,  0.0180, -0.0051, -0.0305,  0.1788,  0.1979, -0.1320,  0.2085,\n          0.0043, -0.0557, -0.2030,  0.0210, -0.1772, -0.1039, -0.0432,  0.1504,\n         -0.1837,  0.1869, -0.1549, -0.1138],\n        [-0.1974,  0.0933,  0.2127, -0.1853, -0.1020,  0.1956,  0.0750,  0.0818,\n         -0.0303,  0.1526,  0.1569, -0.1712,  0.0707,  0.0400,  0.2191, -0.1246,\n         -0.1716, -0.1988,  0.1630, -0.0316],\n        [ 0.0099,  0.0793,  0.1622, -0.1008,  0.0297, -0.1510,  0.0211, -0.0434,\n          0.1799,  0.0829,  0.2088,  0.1250, -0.0464, -0.1175,  0.0007,  0.1688,\n          0.1801,  0.2043, -0.0483,  0.0764],\n        [-0.0444,  0.1724, -0.0222, -0.1283,  0.1609,  0.0234,  0.0018, -0.0743,\n          0.0048, -0.1176,  0.1415,  0.0510, -0.1594, -0.0080, -0.0608,  0.0637,\n          0.1422, -0.1474,  0.0086, -0.1208],\n        [-0.0814,  0.2193, -0.0593,  0.1813,  0.1652,  0.2112,  0.0668, -0.0895,\n          0.0012, -0.0063, -0.1959,  0.0643, -0.0627,  0.0265,  0.2017,  0.2100,\n          0.2149,  0.0285,  0.0844, -0.1877],\n        [ 0.0231,  0.0795, -0.1111, -0.1998,  0.0004, -0.0440, -0.1004, -0.0846,\n          0.1775, -0.1912, -0.0889, -0.1000,  0.1227,  0.1181, -0.0541,  0.1203,\n         -0.0394, -0.2228,  0.1679, -0.2007],\n        [-0.1319,  0.0936,  0.1093,  0.1157,  0.0406, -0.1813, -0.0130,  0.1179,\n          0.1701,  0.1048, -0.0788, -0.0711,  0.1521, -0.0540, -0.1836, -0.1450,\n          0.1862, -0.0161,  0.1979, -0.0085],\n        [-0.0817,  0.1006,  0.0064,  0.1604,  0.1695, -0.0158,  0.0889, -0.1622,\n          0.1108, -0.1634,  0.0030, -0.0362, -0.0923, -0.1010,  0.0272,  0.0109,\n         -0.1711,  0.1426, -0.1064,  0.2028],\n        [ 0.1783, -0.0757, -0.1133,  0.2140, -0.1106, -0.1291, -0.1996,  0.0151,\n          0.0717, -0.1842,  0.0196,  0.1858,  0.0222, -0.1623, -0.1269, -0.0314,\n         -0.1954, -0.0229, -0.0228,  0.0641],\n        [-0.1533,  0.0485,  0.0114, -0.0173, -0.0482, -0.0537,  0.0824,  0.0601,\n         -0.0462,  0.0112, -0.1760, -0.1417,  0.1443,  0.0838,  0.0017, -0.0009,\n          0.0557, -0.1819, -0.0914,  0.1067],\n        [-0.2046,  0.1453,  0.2058, -0.0246, -0.2002,  0.0214, -0.2035,  0.0130,\n         -0.0128,  0.0074, -0.0356, -0.2011, -0.0044,  0.2174,  0.0625, -0.1958,\n          0.0113,  0.1140,  0.1003,  0.1337],\n        [ 0.1401,  0.0679, -0.1228, -0.1827, -0.1038, -0.0278, -0.1246, -0.2153,\n         -0.1521,  0.2133, -0.2147,  0.0981, -0.1467, -0.1766,  0.2029,  0.0923,\n         -0.0816, -0.0826,  0.0494, -0.0566],\n        [-0.1651,  0.0576,  0.1997, -0.0453, -0.1615, -0.1776, -0.2210, -0.0502,\n         -0.0038,  0.0492, -0.2208, -0.1185, -0.1299,  0.0273, -0.0034,  0.0942,\n          0.1985, -0.0565, -0.0270, -0.0482],\n        [-0.1933, -0.1346,  0.1200,  0.2233, -0.0651,  0.0213,  0.1201,  0.0040,\n          0.0886,  0.0933,  0.1782, -0.1299, -0.1796, -0.0334, -0.1914,  0.1549,\n         -0.0178,  0.0698, -0.0142, -0.1481],\n        [ 0.0122,  0.0377, -0.1009,  0.1689, -0.1047, -0.2072, -0.0363, -0.0962,\n         -0.0993,  0.1775, -0.1356, -0.0187,  0.0588,  0.0934,  0.0715, -0.2094,\n          0.2223,  0.0970, -0.0459, -0.1799],\n        [ 0.0115,  0.1924, -0.0422,  0.0904,  0.0437, -0.2215,  0.0990,  0.1457,\n          0.0479, -0.0395, -0.0598, -0.1345,  0.1721,  0.1277,  0.0913,  0.0387,\n         -0.0003,  0.1562,  0.2129, -0.1098],\n        [-0.1585, -0.0613, -0.0389, -0.0776,  0.1178, -0.0817, -0.0592, -0.0645,\n          0.1391, -0.1906,  0.1482, -0.1391,  0.0185, -0.1730, -0.1181,  0.2062,\n          0.1553,  0.1468, -0.1523,  0.1020],\n        [-0.1267,  0.1146, -0.0596,  0.0026,  0.0388, -0.0430,  0.0257, -0.2159,\n         -0.1334,  0.0944,  0.0369, -0.0735,  0.1277, -0.0152, -0.0593, -0.0586,\n         -0.1729, -0.0448,  0.2040,  0.1254],\n        [-0.1329, -0.0651,  0.2004, -0.0354, -0.1763,  0.0076, -0.0328,  0.1066,\n          0.1910,  0.0709,  0.0603, -0.0524,  0.2014, -0.0448, -0.1451,  0.0811,\n         -0.0968,  0.1711, -0.1987,  0.0542],\n        [ 0.1166, -0.1437, -0.0874, -0.1515, -0.0796, -0.0551,  0.1519, -0.2083,\n         -0.1095, -0.1513,  0.0402, -0.0626,  0.1646,  0.0802,  0.1323,  0.0293,\n         -0.1332,  0.1756,  0.1699,  0.0482],\n        [-0.1936, -0.0053,  0.1177,  0.0174,  0.0538, -0.0693,  0.0903, -0.1535,\n         -0.0622, -0.0767,  0.1264,  0.1296,  0.0956, -0.0429, -0.1674,  0.1162,\n         -0.1604,  0.1424, -0.1026,  0.0219],\n        [ 0.0024, -0.1057, -0.0200,  0.1571,  0.0630,  0.1505, -0.1832,  0.0325,\n          0.1465, -0.1296, -0.2078, -0.0706, -0.1956,  0.1665, -0.1825, -0.2141,\n          0.1551,  0.1563, -0.1508,  0.1640],\n        [ 0.0550, -0.0636,  0.1760, -0.1268, -0.0006,  0.2034, -0.1031, -0.1802,\n          0.1533,  0.1108, -0.0268,  0.1411,  0.0400, -0.0292,  0.0322,  0.0016,\n         -0.1860, -0.1860, -0.1553,  0.1495],\n        [-0.1423, -0.1386, -0.1322, -0.2070,  0.0039, -0.0875, -0.1287, -0.1565,\n         -0.1261,  0.0867,  0.1389, -0.1544, -0.0987, -0.1809, -0.1204,  0.1503,\n         -0.0269,  0.0093,  0.0733, -0.0997],\n        [-0.1880, -0.1729,  0.1389, -0.1450,  0.1584,  0.1682, -0.1786, -0.1493,\n         -0.0260, -0.1726, -0.0093, -0.1074,  0.2149,  0.0702,  0.1299,  0.1235,\n         -0.1638, -0.0505, -0.0262,  0.0539],\n        [-0.0139,  0.1329, -0.1066, -0.1367,  0.1801,  0.0212,  0.2037,  0.0994,\n          0.1692,  0.1486, -0.2071, -0.1374,  0.1301,  0.1405, -0.1721, -0.0567,\n         -0.1081, -0.1237, -0.0005,  0.0230],\n        [ 0.0956, -0.1292, -0.1845, -0.1906,  0.1154, -0.0820, -0.1473, -0.0424,\n          0.0167, -0.1582,  0.1635,  0.1596,  0.1048,  0.1175,  0.0832,  0.2072,\n         -0.1784, -0.1570, -0.1759, -0.0986],\n        [ 0.1082,  0.0900, -0.2216,  0.2027, -0.0286,  0.0796, -0.0575, -0.0010,\n         -0.1394, -0.1992,  0.0784,  0.0965, -0.1355,  0.0077,  0.0355,  0.0011,\n         -0.0919,  0.0379,  0.0834, -0.1190],\n        [ 0.1108, -0.1625, -0.2233,  0.0564, -0.1507,  0.0733,  0.1686, -0.0565,\n         -0.1868, -0.0571, -0.1322, -0.1499, -0.0741, -0.0782, -0.1307,  0.1732,\n          0.0952,  0.0182,  0.0833, -0.1127],\n        [-0.0151,  0.1207, -0.0088, -0.2012,  0.0684, -0.1189, -0.0116, -0.1393,\n          0.2180,  0.2007,  0.0845, -0.1537, -0.1182,  0.0227, -0.0455,  0.0141,\n         -0.1760, -0.1761,  0.0156, -0.0713]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0645, -0.1740,  0.0142, -0.1256,  0.1425, -0.0817, -0.0238, -0.2098,\n        -0.2076,  0.1183,  0.0729,  0.0318,  0.1359, -0.1305, -0.0194, -0.0076,\n         0.1032,  0.0630, -0.1068, -0.0316,  0.1704, -0.0381, -0.2211, -0.0191,\n        -0.0128, -0.0169, -0.1289,  0.0591,  0.1548,  0.0502,  0.1569,  0.2225],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.3110e-01, -2.4264e-02, -2.2949e-02,  5.2420e-02, -2.3051e-02,\n         -9.7767e-02,  1.1965e-01, -1.0519e-01, -5.7338e-02,  1.2841e-01,\n          1.6432e-01,  2.6456e-02, -1.2214e-01, -8.3259e-02, -1.2718e-01,\n          1.0734e-01, -9.5759e-02,  2.4274e-02,  5.6327e-02, -5.9540e-03,\n          1.1720e-01,  1.3960e-02,  1.8419e-02,  1.2217e-01,  1.1323e-01,\n          4.6340e-02,  4.7648e-02, -3.1466e-02,  4.0428e-02,  8.8584e-03,\n         -9.7716e-02, -8.2889e-02],\n        [-1.4745e-01, -1.1225e-01, -1.6356e-01, -9.3894e-02,  3.8508e-02,\n         -1.4227e-01,  1.6913e-02,  4.6345e-02, -5.7241e-02,  1.9226e-02,\n         -9.4058e-02, -1.6377e-01, -1.3339e-01, -1.6233e-01,  1.6135e-02,\n          3.3364e-02, -2.5472e-02,  1.4978e-01, -8.0567e-02, -5.5773e-02,\n         -3.8676e-02,  7.8003e-02, -7.8552e-03, -9.5154e-02, -4.0907e-02,\n          8.9840e-02, -8.9020e-03,  4.0222e-02,  1.6556e-01,  5.8608e-03,\n          1.5233e-01,  7.1987e-02],\n        [ 6.5955e-02, -1.6688e-01,  6.4200e-03,  1.0385e-01, -1.2610e-01,\n         -1.2890e-01,  2.1590e-02, -5.0269e-02,  1.2602e-01,  1.6744e-01,\n         -1.0513e-01, -1.2365e-01,  8.1718e-02, -1.3264e-01, -7.7670e-02,\n          3.8485e-02,  1.6689e-01,  1.2135e-01, -1.4199e-01,  2.5627e-02,\n          1.2504e-01,  1.4249e-01, -7.7079e-02,  1.5180e-01, -9.7875e-02,\n          1.3529e-01, -5.9007e-02,  4.6317e-02,  1.0998e-01,  1.0344e-01,\n          1.4264e-01, -5.1454e-02],\n        [ 1.5775e-01,  1.3019e-01, -1.7039e-01, -8.4061e-02, -4.7215e-03,\n         -1.1660e-02, -3.1099e-02, -6.9986e-02, -1.6125e-01,  6.6643e-02,\n          1.6490e-01, -1.5275e-01,  5.1525e-02, -3.5793e-02, -1.5995e-02,\n          1.3979e-01, -7.0049e-02, -1.4738e-01, -1.6040e-01, -1.3582e-01,\n         -1.4293e-01, -7.1200e-02, -1.1951e-01,  5.6351e-02, -1.1641e-01,\n          4.9572e-02,  1.6819e-01,  7.9837e-02, -1.5407e-01, -1.4025e-01,\n         -9.2574e-03, -1.6671e-01],\n        [ 6.3619e-02,  1.3618e-01,  1.7012e-01, -1.2137e-01, -4.2024e-02,\n          1.3616e-02,  1.2707e-01,  1.6073e-01, -4.1667e-02, -1.1454e-01,\n         -4.9162e-02,  7.1041e-02, -9.2475e-02, -6.7184e-02,  1.5054e-01,\n          1.3918e-01,  1.0189e-02,  5.6262e-02,  1.0621e-01, -1.0548e-01,\n         -1.1541e-01,  5.8475e-02, -2.7038e-02,  7.6089e-02,  1.1147e-01,\n         -1.1458e-02,  9.0178e-02,  2.9005e-03,  4.8100e-02, -1.4036e-01,\n         -9.3116e-02,  1.2537e-01],\n        [-1.0075e-01, -1.7363e-01,  7.6128e-02, -4.3534e-03,  3.7888e-02,\n          2.2588e-02, -9.1282e-02, -5.2774e-02, -1.7195e-01, -1.4266e-01,\n          1.7307e-01,  1.5273e-01,  7.9235e-03, -1.0863e-01,  1.1748e-01,\n          9.3763e-02, -4.1977e-02,  8.9999e-02,  2.3893e-02, -1.6847e-02,\n          4.8747e-02,  1.0196e-01,  1.7458e-01, -1.7257e-01,  1.0935e-01,\n         -1.0228e-01,  2.1311e-02, -4.3822e-02, -1.3611e-01,  2.7921e-02,\n         -3.5531e-02, -1.5317e-01],\n        [ 7.8539e-02,  1.6136e-04, -1.4256e-01,  6.4859e-02, -8.3992e-02,\n          8.3831e-02, -1.3602e-01, -1.1459e-01, -9.4707e-02,  5.7726e-02,\n          8.7613e-02, -4.5677e-02, -1.0412e-01,  4.6049e-02,  1.3332e-02,\n         -7.4165e-02, -4.9939e-02, -5.6325e-03,  8.3208e-02, -5.5447e-02,\n          4.0364e-02, -4.3670e-02, -6.5221e-02,  1.4817e-01,  1.5492e-02,\n          5.8301e-02,  1.3151e-01,  1.2259e-01, -1.0940e-01, -1.4274e-01,\n         -1.6609e-01, -1.4990e-01],\n        [-7.8336e-02, -9.5747e-02, -5.3196e-02, -1.0917e-01, -1.5145e-01,\n          1.1238e-01, -1.2214e-01,  5.0133e-02,  1.4497e-01,  1.0697e-01,\n         -1.3060e-01, -5.8647e-02, -4.1693e-02, -1.7554e-01, -9.8243e-02,\n         -1.4722e-01,  6.2850e-02,  9.2903e-02,  6.8018e-02,  2.1792e-02,\n         -1.7847e-02, -1.5216e-01,  1.3737e-02, -1.0329e-01, -1.3702e-01,\n         -1.4821e-01,  1.2112e-01, -3.6793e-02, -1.3008e-01,  1.7351e-01,\n          8.4392e-02, -1.5383e-01],\n        [ 4.7742e-02,  1.6678e-01,  4.2386e-02, -1.0273e-01,  1.4006e-03,\n         -6.6823e-02, -2.9581e-02,  1.3977e-01, -3.6872e-02,  6.9847e-02,\n         -1.1406e-01, -1.7139e-01,  5.9754e-02,  6.8679e-02, -5.2979e-02,\n         -8.8302e-02, -1.6122e-01,  1.0101e-01,  5.9459e-02, -7.1288e-03,\n          7.4020e-02, -1.3365e-01,  8.7732e-02,  1.2231e-02,  6.6700e-02,\n          1.1891e-01,  7.1481e-02,  4.3779e-02,  5.6627e-03,  1.2917e-01,\n          9.6076e-02, -7.6018e-02],\n        [-1.0662e-01, -8.7273e-02, -5.9737e-02, -6.9385e-02, -6.1511e-02,\n         -4.5370e-02,  8.6852e-02, -1.7502e-01,  1.0585e-01,  2.9534e-02,\n          5.7120e-02, -4.5474e-02, -2.5218e-02, -3.2085e-02,  1.8774e-02,\n          1.3443e-01, -9.7993e-02, -1.1467e-01, -1.4649e-01,  1.4639e-01,\n          5.1433e-02, -4.8153e-02,  1.6003e-01, -1.2475e-01, -8.9528e-02,\n         -5.5684e-02,  4.5131e-02, -1.7129e-01, -9.2185e-02, -6.8956e-02,\n          4.4016e-02, -9.5925e-02],\n        [-2.4820e-02,  1.4402e-01,  1.6946e-01,  1.7347e-01, -1.0155e-01,\n          1.6090e-01, -1.0165e-01, -3.1276e-02,  2.9428e-02,  1.6675e-01,\n         -9.0638e-02, -7.4463e-02, -6.0131e-02,  1.3669e-01,  1.0260e-01,\n          1.7942e-02, -1.1199e-01,  5.0067e-02, -6.7823e-02,  9.8768e-02,\n          1.2550e-01, -1.7547e-02, -4.3517e-02,  1.3791e-01,  7.0204e-02,\n         -1.9239e-02, -2.7280e-02,  1.6117e-01, -1.6962e-01,  1.4680e-02,\n         -8.3128e-02,  4.8314e-02],\n        [ 9.8857e-02, -6.6284e-02, -1.4308e-01, -4.6948e-03,  8.1569e-02,\n          8.1953e-02,  1.3055e-01, -1.4831e-01, -1.7529e-01,  4.1805e-02,\n          5.2293e-02, -8.1552e-02,  3.6436e-02,  4.1171e-03,  5.4415e-02,\n          8.0016e-02,  1.2162e-01,  1.0402e-01, -9.0138e-02,  1.3169e-01,\n          1.4416e-01, -2.4434e-02,  5.0041e-02, -1.1408e-01,  3.2410e-02,\n         -9.5798e-02, -1.4331e-01, -1.6114e-01, -1.5037e-01,  1.4535e-01,\n          9.9295e-03, -3.8178e-02],\n        [ 9.5931e-02, -1.4076e-01,  3.6228e-02,  3.0459e-02, -1.2912e-01,\n         -8.0163e-02,  2.7227e-02,  4.1655e-03, -6.7076e-02, -1.3129e-01,\n         -1.7289e-01, -1.4537e-01,  7.0980e-02,  5.7501e-02, -1.4302e-01,\n          1.2937e-01,  9.6751e-03, -1.1842e-01, -1.7592e-01, -1.2576e-01,\n          1.7617e-01,  7.8115e-02,  1.1831e-01, -2.9780e-02, -1.5461e-01,\n         -1.1952e-01,  9.3376e-02, -1.6473e-01, -2.9492e-02,  8.0231e-02,\n          1.4801e-01, -8.5286e-02],\n        [-3.4502e-02,  1.6366e-01, -1.6829e-01,  5.4374e-02,  1.3400e-01,\n          4.0150e-02, -5.1645e-02, -1.2782e-01,  8.0674e-02, -6.2839e-02,\n         -1.4352e-01,  1.1878e-01,  2.6265e-02,  4.1003e-02,  1.4038e-01,\n         -1.1256e-01, -4.7340e-02,  5.4686e-03,  6.3145e-02,  1.7157e-01,\n         -6.5796e-02, -6.9035e-03, -1.3536e-01, -1.6593e-01, -1.0058e-01,\n          2.4897e-02,  9.2564e-02,  1.6603e-01,  6.1270e-02,  1.3345e-01,\n         -1.6831e-02,  9.9668e-02],\n        [ 3.7611e-02,  6.3830e-02, -6.2264e-02, -9.7671e-02, -6.3530e-02,\n         -1.2141e-01, -5.8169e-02,  4.5942e-02,  1.2885e-01,  7.5373e-02,\n          1.3709e-01, -1.3822e-01, -1.5159e-01,  1.6036e-01, -1.1377e-01,\n          9.3311e-02,  1.6902e-01,  9.7457e-02,  7.1346e-02, -1.6105e-01,\n          5.5198e-03, -1.4063e-02,  1.2339e-01, -1.8935e-02,  7.6466e-02,\n          1.0817e-01, -1.4408e-02, -4.2834e-02,  6.8752e-03, -1.2939e-01,\n         -1.7056e-01,  1.3455e-01],\n        [ 1.2403e-01,  2.7523e-02,  3.3421e-03,  2.1337e-02,  1.0784e-01,\n          1.2138e-01,  1.6095e-02,  1.4448e-01, -1.1731e-01,  1.4798e-01,\n         -8.9518e-02,  1.4377e-01,  1.2759e-01,  1.5540e-01, -1.0678e-01,\n          1.2340e-01, -1.6134e-01,  5.9664e-02,  1.3281e-01,  1.0304e-01,\n          1.0178e-01,  1.2066e-03,  2.4535e-02,  1.6121e-01,  2.4885e-02,\n          1.5081e-01, -3.4564e-02, -1.1414e-01, -4.2420e-02,  1.4095e-01,\n          1.0956e-01,  1.5906e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1469,  0.1748, -0.0829,  0.1705,  0.1410,  0.0838,  0.1358, -0.0705,\n        -0.0031,  0.0853,  0.1639,  0.1245, -0.1765, -0.0185, -0.1477, -0.1437],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2344, -0.0784, -0.0283, -0.2284, -0.1961, -0.0646, -0.0046,  0.0909,\n         -0.1747,  0.1132, -0.1846,  0.1661,  0.2105, -0.0396,  0.1748, -0.1657],\n        [ 0.1990,  0.0744,  0.2290, -0.0109, -0.1006, -0.2322, -0.2058,  0.1378,\n         -0.2350, -0.1283, -0.0670,  0.1693,  0.1173, -0.1672,  0.0970,  0.0338],\n        [-0.0765, -0.0689, -0.1365, -0.1062,  0.0374, -0.2251,  0.1923,  0.1148,\n         -0.1404,  0.2050,  0.1651, -0.1440, -0.0855,  0.1174, -0.0043, -0.0983],\n        [-0.0324, -0.0199, -0.0186,  0.1001, -0.0223, -0.0507,  0.1252,  0.2393,\n          0.1670, -0.1227,  0.1960, -0.1166,  0.2451, -0.1067,  0.2116, -0.2103],\n        [ 0.1124,  0.0845,  0.0962, -0.2055,  0.0064, -0.1296,  0.1172,  0.2171,\n         -0.0458, -0.1817,  0.0285,  0.1258, -0.0424,  0.2444,  0.1188,  0.1212],\n        [ 0.1135, -0.0781, -0.1272,  0.2321,  0.0380,  0.2022, -0.0390,  0.0806,\n          0.2095, -0.0779, -0.0767,  0.1053, -0.1684,  0.1466, -0.0367, -0.2303],\n        [ 0.0108,  0.1131,  0.0634, -0.0442, -0.0695, -0.0373, -0.1662,  0.0176,\n         -0.2041, -0.1616, -0.0797, -0.0848, -0.0139,  0.1969,  0.2233, -0.0700],\n        [ 0.1520,  0.2444, -0.1746,  0.2082, -0.2361,  0.2432,  0.0187,  0.0201,\n          0.1359,  0.0084, -0.1175,  0.1940, -0.1567,  0.1393, -0.0933, -0.2267]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2229, -0.0064,  0.0399, -0.1894,  0.1318, -0.1222,  0.1726,  0.1645],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0555,  0.1690,  0.2634,  0.0277,  0.0018, -0.2710, -0.0370, -0.1123]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2513], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x10a75e350>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x11a2c0760>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s51650000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s51650000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}