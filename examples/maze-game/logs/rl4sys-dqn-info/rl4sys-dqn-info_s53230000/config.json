{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s53230000"
    },
    "q_lr":	0.0005,
    "seed":	53230000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x11f828ac0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.2179, -0.1949,  0.0784,  0.1212, -0.0890, -0.0312,  0.0159, -0.0839,\n         0.2091,  0.0610, -0.2055, -0.0944, -0.0646, -0.0518,  0.1468, -0.0067,\n        -0.1955, -0.0931, -0.0498,  0.0783, -0.0612, -0.0662, -0.1916, -0.1947,\n        -0.0008,  0.0118, -0.1067, -0.1987, -0.0072,  0.2198,  0.0431, -0.0290],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 2.1832e-01,  1.8111e-01,  8.8520e-02, -1.3836e-01,  9.8742e-02,\n          1.3963e-01, -6.9912e-02, -1.8781e-01, -8.2476e-02, -1.0379e-01,\n         -2.2771e-02, -1.4003e-01, -1.4781e-01, -1.7463e-02,  1.7118e-02,\n         -4.4904e-02, -1.5481e-01, -1.3946e-01, -7.1338e-02,  2.1275e-01],\n        [ 1.1989e-01, -2.8464e-02, -1.8488e-01, -8.5242e-02,  1.1289e-01,\n          1.7989e-01,  5.7226e-02,  1.4128e-01, -2.1778e-01, -1.2176e-01,\n         -1.2691e-01,  1.2400e-01, -1.8486e-01,  2.2098e-01, -6.0131e-02,\n         -1.9089e-01,  8.1132e-02, -1.0613e-01,  1.9861e-01,  1.2730e-01],\n        [ 1.4107e-01, -1.7789e-01,  3.1437e-02,  1.0623e-01, -1.4706e-01,\n          2.0789e-01, -4.1734e-02,  1.0919e-01, -1.7197e-01, -1.8208e-01,\n          1.7176e-01, -1.8253e-01,  5.9599e-02, -2.0519e-01,  1.5041e-01,\n         -1.4945e-01, -1.3054e-01, -1.8793e-01, -1.8063e-01, -4.2851e-02],\n        [ 7.0568e-02, -2.6877e-02,  2.2164e-02,  1.7676e-01,  1.4741e-01,\n          2.2240e-01,  2.1377e-01, -5.8813e-02,  1.9691e-01,  2.3394e-02,\n         -2.2270e-01, -7.5117e-02,  1.2219e-01,  2.2224e-01,  1.4968e-01,\n         -1.1787e-01, -1.0815e-01, -2.1193e-01, -7.5842e-02,  2.0260e-02],\n        [-1.0070e-01, -2.0753e-01,  1.7139e-01,  8.4271e-02, -1.1087e-02,\n         -1.6552e-01, -3.4604e-02,  6.8569e-02, -2.0676e-01, -4.9446e-02,\n          8.2295e-03,  1.6786e-01, -1.2918e-01,  1.8230e-01, -1.8968e-01,\n          5.6931e-02,  1.2821e-01,  1.8726e-01, -8.3396e-02,  1.7596e-01],\n        [ 5.7242e-02, -1.2746e-01,  1.2377e-02, -1.6435e-01,  1.5433e-01,\n         -7.7798e-02,  9.0219e-02,  1.8058e-01,  2.9926e-03,  1.3881e-01,\n         -3.9041e-02,  3.4892e-02,  1.4652e-01, -8.8256e-02, -1.1001e-01,\n         -1.4147e-01,  1.4881e-02, -2.1220e-01,  1.5763e-01,  1.5889e-01],\n        [-2.0693e-01, -1.0306e-01,  1.8465e-01, -1.3579e-01, -8.8899e-02,\n          1.0836e-01,  1.2417e-01, -1.5095e-02,  2.6315e-02, -1.5575e-01,\n          1.6942e-01, -4.8805e-02, -4.7191e-02,  1.7406e-01,  1.6579e-01,\n          1.1915e-01, -2.0667e-01,  5.2614e-02, -2.1883e-02, -1.2371e-01],\n        [-1.0432e-01,  1.9151e-01,  4.2085e-02, -1.3291e-01,  1.6997e-01,\n          9.4921e-02,  2.0471e-01, -1.8574e-02,  2.1268e-01,  1.4575e-01,\n          1.0918e-01, -4.4853e-02, -4.5601e-02,  6.9265e-02, -4.5622e-02,\n          1.6084e-04, -1.0526e-01,  7.4212e-02,  1.8546e-02,  7.4209e-02],\n        [ 1.2243e-01, -1.3097e-01, -3.2502e-02, -2.2163e-01, -1.2491e-01,\n         -2.1166e-01,  1.8780e-01, -7.9400e-02, -1.4821e-02,  1.1472e-01,\n         -1.9115e-01, -2.0250e-02, -8.9400e-02,  8.2593e-02, -1.2983e-01,\n          1.2702e-01,  2.0089e-01, -7.2935e-02, -1.8074e-01, -1.2313e-02],\n        [ 1.5423e-01, -7.8508e-02, -1.4720e-01,  7.7350e-02,  9.8555e-02,\n         -2.4774e-02, -1.4742e-01, -8.5587e-02,  2.0798e-01, -1.1402e-01,\n         -2.1955e-02, -3.5443e-02,  6.4540e-02, -1.4283e-01, -2.1468e-02,\n         -2.0554e-01,  3.5391e-02,  7.7206e-03, -5.6227e-02, -1.3759e-01],\n        [ 9.9906e-02, -1.6035e-01,  1.5015e-01,  4.4870e-02, -1.5177e-01,\n         -1.6369e-01, -8.9063e-02, -1.5605e-01,  4.5879e-02,  1.6722e-01,\n          4.5511e-02,  1.2797e-01, -1.2303e-01,  8.5456e-02, -1.9257e-01,\n          9.6629e-02, -2.1878e-01,  1.0356e-01, -6.3601e-02, -1.1496e-01],\n        [-5.7348e-02,  7.4679e-02,  1.0965e-01, -1.0117e-01, -5.6759e-03,\n         -1.1354e-01, -1.6070e-01,  1.2689e-01, -1.9338e-01, -2.9826e-02,\n         -1.6969e-01,  1.8232e-01, -1.1956e-02, -1.9234e-01,  1.3167e-01,\n          1.7103e-01,  1.9983e-01,  2.1858e-01,  3.0434e-02,  5.0268e-02],\n        [ 1.3344e-01,  9.9740e-03,  7.9445e-02, -3.6405e-02, -2.0322e-01,\n          7.3811e-02, -2.1250e-01, -2.1441e-01, -6.5818e-03, -1.8537e-01,\n         -2.1933e-01,  3.6003e-02, -3.7501e-02, -4.9181e-02,  2.2301e-01,\n          1.0093e-01,  7.3635e-02,  1.1707e-01, -1.1570e-01, -2.9832e-02],\n        [ 1.1556e-01,  1.0332e-01,  6.1720e-02, -1.4356e-01,  5.3128e-02,\n         -2.6075e-02, -3.0457e-03, -9.8559e-02, -8.4687e-02, -1.4943e-03,\n          4.2247e-02, -3.6234e-02, -1.9790e-02,  1.8825e-01,  1.8092e-01,\n         -1.2079e-01, -5.2847e-02, -1.3255e-01, -1.7643e-01,  5.8567e-02],\n        [-1.3577e-01, -3.7558e-02, -1.0661e-01,  1.4970e-01,  1.4190e-01,\n         -2.6068e-03,  4.3637e-02,  1.0164e-02, -1.6348e-01,  1.1055e-02,\n          1.8345e-01, -1.8310e-02, -1.8620e-01, -7.4046e-02, -2.1206e-01,\n         -3.0899e-02, -7.8075e-02,  2.6880e-02, -8.9666e-02,  1.9984e-01],\n        [-1.0506e-01, -9.2358e-02, -6.8906e-02,  1.5351e-01, -8.9525e-02,\n         -1.8937e-01,  4.1687e-02,  1.1225e-01,  1.2287e-01,  1.3039e-01,\n         -1.4703e-01,  2.7322e-02,  5.7450e-02,  5.7443e-02, -1.0722e-01,\n         -9.7845e-02,  2.6394e-02, -3.7508e-02, -1.7613e-01,  1.2866e-01],\n        [ 1.7442e-01, -2.0232e-01, -3.3880e-02, -8.7755e-02,  6.0583e-02,\n          1.2870e-01,  1.0204e-01,  1.1144e-01,  1.4279e-01, -1.9752e-01,\n          6.1404e-02,  1.3420e-01,  1.1248e-01, -1.0489e-01,  1.6956e-01,\n         -2.0468e-01, -3.2912e-03,  1.7699e-02, -6.7066e-02, -6.9617e-02],\n        [ 1.8402e-01, -1.9870e-01, -3.5854e-03,  1.3637e-01,  1.6067e-01,\n         -5.6999e-02,  4.4968e-03, -1.2303e-02,  1.6189e-01, -1.3539e-02,\n         -1.1237e-01,  2.2310e-01,  1.3454e-01, -5.9609e-02,  5.0455e-02,\n         -1.9911e-01, -8.2927e-02,  9.1143e-02, -1.3623e-01,  1.9577e-01],\n        [ 1.6839e-01, -1.0781e-01,  2.5430e-02, -1.4441e-01, -1.6907e-01,\n          2.0844e-01,  2.2231e-01,  9.6934e-02,  6.4954e-02,  5.6743e-02,\n         -1.1292e-01,  1.6109e-01,  2.1816e-01, -1.1751e-01, -1.9733e-01,\n         -1.6720e-01,  7.2140e-02,  3.7276e-02,  7.4223e-02, -2.2911e-02],\n        [ 8.6842e-02, -5.7587e-02, -7.1274e-02,  4.7069e-02, -8.5641e-02,\n          1.2380e-01,  1.5581e-01, -8.4560e-02, -2.1258e-01,  1.9602e-01,\n         -1.5347e-01, -4.4600e-02,  7.4536e-02, -7.4493e-02,  4.2319e-02,\n         -4.8136e-02, -1.0912e-01, -1.9942e-01,  5.8459e-02,  7.7761e-02],\n        [ 2.0803e-01, -1.8701e-01, -1.9933e-01,  2.1025e-01, -6.6917e-02,\n          1.3460e-01, -1.3649e-01, -3.6281e-02, -1.2207e-01,  2.1105e-01,\n          5.6211e-02,  1.6426e-01,  1.6325e-01,  1.1146e-02, -1.6694e-01,\n         -1.8345e-01,  2.5831e-02, -9.7979e-02,  2.1822e-01, -7.2462e-02],\n        [ 1.9028e-01, -1.7031e-01,  4.3006e-02, -7.0709e-02,  9.8059e-02,\n         -3.6749e-02, -4.5546e-02,  1.5004e-01,  1.7259e-01,  2.9996e-03,\n         -5.1636e-02, -1.4835e-01, -1.1566e-01,  2.9435e-02, -4.3876e-03,\n          1.8364e-01,  1.4394e-01, -1.9309e-01,  2.1977e-01, -7.0084e-02],\n        [-7.5973e-02,  5.8911e-02, -1.2295e-01, -9.1512e-02,  1.9465e-01,\n         -1.9575e-01,  1.0133e-01, -1.1511e-01,  5.1105e-02, -1.3200e-01,\n          2.8316e-02,  1.0856e-01, -1.7488e-01,  1.1450e-01, -1.3493e-01,\n          2.2093e-02, -4.4070e-02, -1.5276e-01,  1.1266e-02, -6.6082e-02],\n        [-1.6812e-01,  9.6240e-02, -1.9309e-02,  1.9050e-01, -2.9911e-02,\n         -1.4785e-01,  1.6685e-01, -7.5437e-06, -1.4861e-01, -1.3965e-01,\n         -6.0310e-02,  2.7871e-02, -7.4845e-02,  3.1012e-03, -9.8796e-02,\n          3.2347e-02, -5.2585e-02, -4.6513e-02,  2.9991e-02,  2.9903e-02],\n        [-2.1926e-01,  2.0019e-01, -1.5803e-01,  2.7297e-02, -4.8175e-04,\n          1.1700e-01,  5.4574e-02,  1.1614e-01,  2.0117e-01, -1.1038e-01,\n          1.5898e-01, -1.2517e-01,  3.9874e-02,  9.2951e-02, -2.1206e-01,\n         -5.1206e-03,  1.7518e-01,  1.7967e-01,  1.6289e-01,  1.1668e-01],\n        [-1.6127e-01,  1.2535e-01, -1.3700e-01,  5.5718e-02,  2.1510e-01,\n          8.2588e-02, -3.8179e-03, -1.4513e-01,  1.1114e-02,  1.5209e-01,\n          1.8293e-01, -1.4441e-01,  1.7822e-01, -9.9498e-02, -1.4591e-01,\n          6.0945e-02,  1.4482e-01, -5.1720e-02,  1.3210e-01,  1.0665e-01],\n        [-1.7638e-01, -2.0919e-01,  2.1000e-02,  1.5409e-01,  1.8488e-01,\n          7.4271e-03,  9.0359e-02, -1.4036e-01,  1.4177e-01, -9.1014e-03,\n         -8.0175e-02, -5.6891e-02, -1.9198e-01,  1.3697e-01, -2.1840e-01,\n          2.1104e-02,  1.5475e-01,  1.0764e-01, -1.1579e-01,  3.3792e-02],\n        [-1.0121e-01,  1.1830e-01,  3.2542e-02,  9.2474e-02,  1.3602e-02,\n          1.4218e-01, -1.8301e-01, -6.7257e-02,  2.0511e-01,  1.3471e-01,\n          1.1407e-01,  2.9171e-02, -1.3326e-01, -1.5423e-01, -3.7750e-02,\n         -2.8886e-02, -5.3914e-02, -2.0019e-01,  6.2006e-02, -1.8528e-01],\n        [ 3.0272e-02, -1.2086e-01,  2.0572e-01, -1.5679e-01, -1.8161e-01,\n         -5.7985e-02,  1.0403e-01,  6.2949e-02, -1.1094e-01,  5.4969e-03,\n         -1.1655e-01, -4.6290e-02,  7.8282e-02, -2.9583e-03, -2.2353e-01,\n          3.2456e-02,  1.0207e-01,  2.0467e-01, -6.8422e-02,  2.1213e-02],\n        [ 2.1085e-01, -1.0319e-01,  1.6144e-01,  4.7035e-02,  2.1080e-01,\n         -8.2427e-02, -2.1390e-01, -2.7879e-02,  1.4945e-02,  8.1479e-02,\n         -9.2251e-03,  1.8334e-01, -8.7054e-02,  1.5327e-01,  2.0725e-01,\n         -8.7123e-03, -1.7544e-01,  2.1064e-02,  6.8464e-02,  2.0742e-01],\n        [-4.9811e-02,  9.4413e-03, -5.0159e-02,  2.0077e-01, -5.8593e-02,\n          1.7089e-02,  3.1372e-02,  3.7198e-02, -8.0837e-02, -6.7899e-02,\n         -8.7231e-02,  9.9657e-03, -9.5872e-02, -1.5183e-01,  1.8952e-01,\n         -2.1076e-01,  4.4419e-02,  1.3855e-01,  1.3738e-02,  4.1171e-02],\n        [ 3.7370e-02, -6.9194e-02, -1.6577e-01,  2.0290e-01, -4.8357e-03,\n         -2.2259e-01,  1.6977e-02,  1.5625e-02, -9.2729e-02,  1.6012e-01,\n          3.7073e-02, -1.7195e-01,  2.7489e-02,  2.0959e-01,  6.5621e-02,\n          6.8173e-02,  1.2026e-01,  1.5659e-01,  1.8983e-02,  1.2454e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1226, -0.1226, -0.0260, -0.1204,  0.0167, -0.1509,  0.1395, -0.0751,\n         0.0578,  0.1466, -0.1383, -0.0931, -0.0654, -0.0290, -0.0043,  0.0022],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1548, -0.1191, -0.0892,  0.0691,  0.0562,  0.1673, -0.0632, -0.1474,\n         -0.1386, -0.0116, -0.1389,  0.1650,  0.0523, -0.0351,  0.0005,  0.1632,\n         -0.1055, -0.0556, -0.0708, -0.0023, -0.0382, -0.1298, -0.0519,  0.0920,\n         -0.1738,  0.0798,  0.0534,  0.0412,  0.0993,  0.0428,  0.1326, -0.1450],\n        [-0.0646, -0.0105,  0.1627, -0.1071, -0.1026,  0.0356, -0.1481,  0.0516,\n         -0.1249, -0.0288, -0.0244,  0.0856,  0.0444, -0.1552, -0.0505, -0.0595,\n         -0.0120, -0.0117,  0.0319,  0.1381, -0.1491,  0.0527,  0.0665,  0.0674,\n         -0.1560,  0.1647, -0.0929, -0.1473, -0.0839,  0.0280, -0.1590,  0.1647],\n        [-0.1159, -0.1034, -0.1344, -0.0162,  0.0993,  0.1166, -0.1428,  0.1280,\n          0.1152, -0.1401,  0.0385,  0.0383, -0.1022,  0.0490, -0.0349, -0.1223,\n         -0.0566,  0.0361,  0.0773,  0.0778,  0.1014,  0.1372, -0.1584,  0.0437,\n         -0.1516,  0.1340,  0.0165, -0.1258,  0.1591,  0.1740, -0.0015,  0.0632],\n        [-0.1437,  0.0770,  0.0141,  0.1215,  0.0206,  0.0733,  0.0227, -0.0560,\n          0.1412,  0.0868, -0.1479,  0.1006, -0.1200, -0.0996, -0.1376, -0.0866,\n          0.0099, -0.1662, -0.1312, -0.0265,  0.1733,  0.1696,  0.0997, -0.0991,\n          0.1622,  0.0155, -0.0733,  0.1423, -0.1303, -0.1368,  0.0625,  0.1069],\n        [ 0.1456, -0.0042, -0.0916, -0.1642,  0.1098, -0.1042,  0.0281, -0.1707,\n          0.1566, -0.0608, -0.1027,  0.0266,  0.0649,  0.0119, -0.0961, -0.1412,\n         -0.0790, -0.0222,  0.0298, -0.1614,  0.0520,  0.0595, -0.0827, -0.0901,\n         -0.0080, -0.0537,  0.1229,  0.0333, -0.1695, -0.0270,  0.1106, -0.0250],\n        [ 0.1745,  0.0603, -0.0582, -0.0046,  0.0121, -0.1298,  0.1643,  0.1514,\n          0.1469,  0.1366,  0.1653, -0.0519,  0.0808,  0.1765, -0.0016, -0.1260,\n         -0.0195,  0.0807,  0.0858, -0.0419, -0.1118,  0.0101, -0.0189,  0.0238,\n         -0.0752,  0.0689,  0.0905, -0.1340, -0.0590,  0.1641, -0.1555, -0.1268],\n        [-0.0381,  0.1485, -0.1391,  0.0617, -0.1646, -0.0286, -0.0741,  0.0486,\n         -0.1372, -0.0549, -0.0552, -0.1579, -0.1222,  0.0669, -0.0384,  0.0428,\n         -0.0752, -0.0035, -0.0167,  0.0747,  0.1574, -0.0012,  0.1653, -0.0960,\n          0.1266,  0.1086, -0.0612, -0.0193,  0.1066,  0.0201,  0.0088, -0.0651],\n        [-0.0089,  0.1115, -0.0432, -0.0912,  0.0767,  0.0615,  0.1237,  0.0178,\n         -0.0748,  0.1302,  0.1315, -0.0059,  0.0877, -0.1340,  0.0864,  0.1159,\n          0.0206, -0.0365,  0.0056, -0.1037, -0.1274, -0.1618, -0.0198,  0.0179,\n          0.0201, -0.1214, -0.1743, -0.1514,  0.0287, -0.0186, -0.0465,  0.1553],\n        [-0.0272,  0.1253,  0.0557, -0.1274,  0.0591,  0.0100, -0.1368, -0.1424,\n         -0.0664,  0.1120,  0.0566, -0.1052, -0.1722,  0.1100, -0.0846,  0.0494,\n         -0.0742, -0.0180,  0.0363, -0.0692, -0.1709,  0.1385,  0.1434, -0.0200,\n          0.1461, -0.1399,  0.1093, -0.0945, -0.1282, -0.0125, -0.0155, -0.1267],\n        [ 0.0427,  0.1504, -0.0673, -0.0529, -0.1010,  0.1436, -0.1418,  0.1016,\n          0.1078, -0.1110,  0.1425,  0.1742,  0.0190,  0.0073, -0.1345, -0.0461,\n         -0.0936,  0.0061, -0.0275, -0.0144,  0.1509,  0.0904, -0.1137, -0.1378,\n          0.1167, -0.1705, -0.0552,  0.1130, -0.0358, -0.1048,  0.1287, -0.1512],\n        [ 0.1547,  0.0843,  0.0489, -0.0677,  0.0987, -0.0203,  0.0295, -0.1090,\n          0.0860, -0.1051,  0.0863,  0.1027, -0.1753,  0.1427,  0.1304, -0.0015,\n         -0.1444,  0.0971, -0.0614, -0.1685,  0.0310,  0.1576, -0.0750, -0.1060,\n          0.0563, -0.1326,  0.1549, -0.0743,  0.1318,  0.1213,  0.1664, -0.1242],\n        [ 0.1052,  0.0084,  0.0830,  0.0556, -0.0999, -0.1629,  0.1154,  0.0945,\n          0.0241, -0.0969,  0.1228, -0.1739, -0.0676, -0.0528,  0.0216,  0.1242,\n          0.1713,  0.1379,  0.0414, -0.1275,  0.1095,  0.1367,  0.1086, -0.0701,\n         -0.0225, -0.0074,  0.0021,  0.1125, -0.0476,  0.0930, -0.0924, -0.0389],\n        [ 0.1461, -0.1351,  0.1669,  0.0605,  0.0695,  0.0228,  0.1609,  0.0755,\n         -0.0676, -0.1400,  0.1339,  0.0448, -0.0217,  0.1345, -0.1196,  0.1659,\n         -0.1753,  0.0717, -0.0536, -0.1552,  0.0538, -0.1403,  0.0697, -0.0553,\n          0.1190, -0.0618, -0.1448, -0.0949, -0.1667, -0.0490,  0.1174,  0.1727],\n        [ 0.0592, -0.0045, -0.0448, -0.0947, -0.1033, -0.1621,  0.1492, -0.0519,\n         -0.1010,  0.1450,  0.1275,  0.0147,  0.0817, -0.0562,  0.1343, -0.1189,\n          0.0598,  0.0382,  0.1390,  0.1074, -0.1701,  0.1765,  0.0166, -0.0750,\n         -0.0270,  0.1425, -0.1402, -0.1192, -0.1422, -0.0712,  0.0708, -0.0270],\n        [ 0.0301,  0.1669, -0.0633, -0.0029, -0.0775,  0.0735,  0.0811, -0.0633,\n         -0.0548, -0.0445, -0.0367, -0.0249, -0.1137,  0.1647, -0.1342, -0.0287,\n         -0.0767,  0.1571, -0.0729,  0.1685,  0.0410,  0.0266, -0.1610,  0.1693,\n          0.0156,  0.1694,  0.0841, -0.1727, -0.0509,  0.0774,  0.1502, -0.1270],\n        [ 0.1664,  0.1516,  0.0812, -0.0223, -0.0449, -0.0796,  0.0833, -0.0798,\n         -0.1726,  0.0529,  0.0953,  0.1327,  0.0141, -0.1749, -0.1125,  0.0251,\n          0.0135, -0.0475, -0.0037,  0.1508,  0.0057, -0.0201, -0.0872, -0.0868,\n         -0.0976,  0.0142, -0.0617, -0.0704,  0.0069,  0.0254,  0.0857, -0.1239]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0496,  0.1691,  0.2190, -0.0902, -0.2408, -0.1465,  0.1071,  0.1573],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0731,  0.0014,  0.0917,  0.1989, -0.0651, -0.1379, -0.2036,  0.1152,\n          0.1629, -0.0805,  0.1745,  0.1123, -0.1856,  0.1093, -0.1895,  0.0189],\n        [-0.2471, -0.1340,  0.2161, -0.0775, -0.1312, -0.0797, -0.0906, -0.1279,\n         -0.0139,  0.2500,  0.1876, -0.0349, -0.2386, -0.1630, -0.2069,  0.2381],\n        [-0.0683,  0.1513, -0.0726,  0.2204, -0.1682, -0.2489,  0.2250,  0.0055,\n          0.1188, -0.1086, -0.0396,  0.2040, -0.1989, -0.1322,  0.0713,  0.1509],\n        [-0.0185,  0.0053, -0.2020,  0.0695,  0.1267,  0.0988, -0.1016,  0.0470,\n          0.0535, -0.2373, -0.0534, -0.0249, -0.0523, -0.1338,  0.1587,  0.1083],\n        [ 0.0171,  0.0720,  0.0677, -0.0443, -0.0757, -0.0594,  0.1348,  0.1072,\n          0.0867, -0.1671, -0.0130,  0.1676,  0.2325,  0.1546, -0.2041, -0.0118],\n        [ 0.1900, -0.0706,  0.2429,  0.0159,  0.1633, -0.0865,  0.1488,  0.0426,\n         -0.1045,  0.1127, -0.0483, -0.1053,  0.0105,  0.1025, -0.0151, -0.1955],\n        [ 0.2443,  0.1059,  0.0851, -0.1700, -0.1229,  0.1186,  0.1788, -0.0058,\n          0.2081,  0.0809, -0.1194,  0.0029,  0.1647, -0.1539,  0.0097, -0.1511],\n        [-0.1028,  0.0279, -0.2056,  0.2384, -0.0508, -0.0972,  0.2257, -0.0429,\n          0.1973, -0.0623,  0.2065, -0.2468, -0.1597, -0.0651,  0.1218, -0.2090]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0462], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1966,  0.2030,  0.3322, -0.0715, -0.0923,  0.2742,  0.2450,  0.1603]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 2.1832e-01,  1.8111e-01,  8.8520e-02, -1.3836e-01,  9.8742e-02,\n          1.3963e-01, -6.9912e-02, -1.8781e-01, -8.2476e-02, -1.0379e-01,\n         -2.2771e-02, -1.4003e-01, -1.4781e-01, -1.7463e-02,  1.7118e-02,\n         -4.4904e-02, -1.5481e-01, -1.3946e-01, -7.1338e-02,  2.1275e-01],\n        [ 1.1989e-01, -2.8464e-02, -1.8488e-01, -8.5242e-02,  1.1289e-01,\n          1.7989e-01,  5.7226e-02,  1.4128e-01, -2.1778e-01, -1.2176e-01,\n         -1.2691e-01,  1.2400e-01, -1.8486e-01,  2.2098e-01, -6.0131e-02,\n         -1.9089e-01,  8.1132e-02, -1.0613e-01,  1.9861e-01,  1.2730e-01],\n        [ 1.4107e-01, -1.7789e-01,  3.1437e-02,  1.0623e-01, -1.4706e-01,\n          2.0789e-01, -4.1734e-02,  1.0919e-01, -1.7197e-01, -1.8208e-01,\n          1.7176e-01, -1.8253e-01,  5.9599e-02, -2.0519e-01,  1.5041e-01,\n         -1.4945e-01, -1.3054e-01, -1.8793e-01, -1.8063e-01, -4.2851e-02],\n        [ 7.0568e-02, -2.6877e-02,  2.2164e-02,  1.7676e-01,  1.4741e-01,\n          2.2240e-01,  2.1377e-01, -5.8813e-02,  1.9691e-01,  2.3394e-02,\n         -2.2270e-01, -7.5117e-02,  1.2219e-01,  2.2224e-01,  1.4968e-01,\n         -1.1787e-01, -1.0815e-01, -2.1193e-01, -7.5842e-02,  2.0260e-02],\n        [-1.0070e-01, -2.0753e-01,  1.7139e-01,  8.4271e-02, -1.1087e-02,\n         -1.6552e-01, -3.4604e-02,  6.8569e-02, -2.0676e-01, -4.9446e-02,\n          8.2295e-03,  1.6786e-01, -1.2918e-01,  1.8230e-01, -1.8968e-01,\n          5.6931e-02,  1.2821e-01,  1.8726e-01, -8.3396e-02,  1.7596e-01],\n        [ 5.7242e-02, -1.2746e-01,  1.2377e-02, -1.6435e-01,  1.5433e-01,\n         -7.7798e-02,  9.0219e-02,  1.8058e-01,  2.9926e-03,  1.3881e-01,\n         -3.9041e-02,  3.4892e-02,  1.4652e-01, -8.8256e-02, -1.1001e-01,\n         -1.4147e-01,  1.4881e-02, -2.1220e-01,  1.5763e-01,  1.5889e-01],\n        [-2.0693e-01, -1.0306e-01,  1.8465e-01, -1.3579e-01, -8.8899e-02,\n          1.0836e-01,  1.2417e-01, -1.5095e-02,  2.6315e-02, -1.5575e-01,\n          1.6942e-01, -4.8805e-02, -4.7191e-02,  1.7406e-01,  1.6579e-01,\n          1.1915e-01, -2.0667e-01,  5.2614e-02, -2.1883e-02, -1.2371e-01],\n        [-1.0432e-01,  1.9151e-01,  4.2085e-02, -1.3291e-01,  1.6997e-01,\n          9.4921e-02,  2.0471e-01, -1.8574e-02,  2.1268e-01,  1.4575e-01,\n          1.0918e-01, -4.4853e-02, -4.5601e-02,  6.9265e-02, -4.5622e-02,\n          1.6084e-04, -1.0526e-01,  7.4212e-02,  1.8546e-02,  7.4209e-02],\n        [ 1.2243e-01, -1.3097e-01, -3.2502e-02, -2.2163e-01, -1.2491e-01,\n         -2.1166e-01,  1.8780e-01, -7.9400e-02, -1.4821e-02,  1.1472e-01,\n         -1.9115e-01, -2.0250e-02, -8.9400e-02,  8.2593e-02, -1.2983e-01,\n          1.2702e-01,  2.0089e-01, -7.2935e-02, -1.8074e-01, -1.2313e-02],\n        [ 1.5423e-01, -7.8508e-02, -1.4720e-01,  7.7350e-02,  9.8555e-02,\n         -2.4774e-02, -1.4742e-01, -8.5587e-02,  2.0798e-01, -1.1402e-01,\n         -2.1955e-02, -3.5443e-02,  6.4540e-02, -1.4283e-01, -2.1468e-02,\n         -2.0554e-01,  3.5391e-02,  7.7206e-03, -5.6227e-02, -1.3759e-01],\n        [ 9.9906e-02, -1.6035e-01,  1.5015e-01,  4.4870e-02, -1.5177e-01,\n         -1.6369e-01, -8.9063e-02, -1.5605e-01,  4.5879e-02,  1.6722e-01,\n          4.5511e-02,  1.2797e-01, -1.2303e-01,  8.5456e-02, -1.9257e-01,\n          9.6629e-02, -2.1878e-01,  1.0356e-01, -6.3601e-02, -1.1496e-01],\n        [-5.7348e-02,  7.4679e-02,  1.0965e-01, -1.0117e-01, -5.6759e-03,\n         -1.1354e-01, -1.6070e-01,  1.2689e-01, -1.9338e-01, -2.9826e-02,\n         -1.6969e-01,  1.8232e-01, -1.1956e-02, -1.9234e-01,  1.3167e-01,\n          1.7103e-01,  1.9983e-01,  2.1858e-01,  3.0434e-02,  5.0268e-02],\n        [ 1.3344e-01,  9.9740e-03,  7.9445e-02, -3.6405e-02, -2.0322e-01,\n          7.3811e-02, -2.1250e-01, -2.1441e-01, -6.5818e-03, -1.8537e-01,\n         -2.1933e-01,  3.6003e-02, -3.7501e-02, -4.9181e-02,  2.2301e-01,\n          1.0093e-01,  7.3635e-02,  1.1707e-01, -1.1570e-01, -2.9832e-02],\n        [ 1.1556e-01,  1.0332e-01,  6.1720e-02, -1.4356e-01,  5.3128e-02,\n         -2.6075e-02, -3.0457e-03, -9.8559e-02, -8.4687e-02, -1.4943e-03,\n          4.2247e-02, -3.6234e-02, -1.9790e-02,  1.8825e-01,  1.8092e-01,\n         -1.2079e-01, -5.2847e-02, -1.3255e-01, -1.7643e-01,  5.8567e-02],\n        [-1.3577e-01, -3.7558e-02, -1.0661e-01,  1.4970e-01,  1.4190e-01,\n         -2.6068e-03,  4.3637e-02,  1.0164e-02, -1.6348e-01,  1.1055e-02,\n          1.8345e-01, -1.8310e-02, -1.8620e-01, -7.4046e-02, -2.1206e-01,\n         -3.0899e-02, -7.8075e-02,  2.6880e-02, -8.9666e-02,  1.9984e-01],\n        [-1.0506e-01, -9.2358e-02, -6.8906e-02,  1.5351e-01, -8.9525e-02,\n         -1.8937e-01,  4.1687e-02,  1.1225e-01,  1.2287e-01,  1.3039e-01,\n         -1.4703e-01,  2.7322e-02,  5.7450e-02,  5.7443e-02, -1.0722e-01,\n         -9.7845e-02,  2.6394e-02, -3.7508e-02, -1.7613e-01,  1.2866e-01],\n        [ 1.7442e-01, -2.0232e-01, -3.3880e-02, -8.7755e-02,  6.0583e-02,\n          1.2870e-01,  1.0204e-01,  1.1144e-01,  1.4279e-01, -1.9752e-01,\n          6.1404e-02,  1.3420e-01,  1.1248e-01, -1.0489e-01,  1.6956e-01,\n         -2.0468e-01, -3.2912e-03,  1.7699e-02, -6.7066e-02, -6.9617e-02],\n        [ 1.8402e-01, -1.9870e-01, -3.5854e-03,  1.3637e-01,  1.6067e-01,\n         -5.6999e-02,  4.4968e-03, -1.2303e-02,  1.6189e-01, -1.3539e-02,\n         -1.1237e-01,  2.2310e-01,  1.3454e-01, -5.9609e-02,  5.0455e-02,\n         -1.9911e-01, -8.2927e-02,  9.1143e-02, -1.3623e-01,  1.9577e-01],\n        [ 1.6839e-01, -1.0781e-01,  2.5430e-02, -1.4441e-01, -1.6907e-01,\n          2.0844e-01,  2.2231e-01,  9.6934e-02,  6.4954e-02,  5.6743e-02,\n         -1.1292e-01,  1.6109e-01,  2.1816e-01, -1.1751e-01, -1.9733e-01,\n         -1.6720e-01,  7.2140e-02,  3.7276e-02,  7.4223e-02, -2.2911e-02],\n        [ 8.6842e-02, -5.7587e-02, -7.1274e-02,  4.7069e-02, -8.5641e-02,\n          1.2380e-01,  1.5581e-01, -8.4560e-02, -2.1258e-01,  1.9602e-01,\n         -1.5347e-01, -4.4600e-02,  7.4536e-02, -7.4493e-02,  4.2319e-02,\n         -4.8136e-02, -1.0912e-01, -1.9942e-01,  5.8459e-02,  7.7761e-02],\n        [ 2.0803e-01, -1.8701e-01, -1.9933e-01,  2.1025e-01, -6.6917e-02,\n          1.3460e-01, -1.3649e-01, -3.6281e-02, -1.2207e-01,  2.1105e-01,\n          5.6211e-02,  1.6426e-01,  1.6325e-01,  1.1146e-02, -1.6694e-01,\n         -1.8345e-01,  2.5831e-02, -9.7979e-02,  2.1822e-01, -7.2462e-02],\n        [ 1.9028e-01, -1.7031e-01,  4.3006e-02, -7.0709e-02,  9.8059e-02,\n         -3.6749e-02, -4.5546e-02,  1.5004e-01,  1.7259e-01,  2.9996e-03,\n         -5.1636e-02, -1.4835e-01, -1.1566e-01,  2.9435e-02, -4.3876e-03,\n          1.8364e-01,  1.4394e-01, -1.9309e-01,  2.1977e-01, -7.0084e-02],\n        [-7.5973e-02,  5.8911e-02, -1.2295e-01, -9.1512e-02,  1.9465e-01,\n         -1.9575e-01,  1.0133e-01, -1.1511e-01,  5.1105e-02, -1.3200e-01,\n          2.8316e-02,  1.0856e-01, -1.7488e-01,  1.1450e-01, -1.3493e-01,\n          2.2093e-02, -4.4070e-02, -1.5276e-01,  1.1266e-02, -6.6082e-02],\n        [-1.6812e-01,  9.6240e-02, -1.9309e-02,  1.9050e-01, -2.9911e-02,\n         -1.4785e-01,  1.6685e-01, -7.5437e-06, -1.4861e-01, -1.3965e-01,\n         -6.0310e-02,  2.7871e-02, -7.4845e-02,  3.1012e-03, -9.8796e-02,\n          3.2347e-02, -5.2585e-02, -4.6513e-02,  2.9991e-02,  2.9903e-02],\n        [-2.1926e-01,  2.0019e-01, -1.5803e-01,  2.7297e-02, -4.8175e-04,\n          1.1700e-01,  5.4574e-02,  1.1614e-01,  2.0117e-01, -1.1038e-01,\n          1.5898e-01, -1.2517e-01,  3.9874e-02,  9.2951e-02, -2.1206e-01,\n         -5.1206e-03,  1.7518e-01,  1.7967e-01,  1.6289e-01,  1.1668e-01],\n        [-1.6127e-01,  1.2535e-01, -1.3700e-01,  5.5718e-02,  2.1510e-01,\n          8.2588e-02, -3.8179e-03, -1.4513e-01,  1.1114e-02,  1.5209e-01,\n          1.8293e-01, -1.4441e-01,  1.7822e-01, -9.9498e-02, -1.4591e-01,\n          6.0945e-02,  1.4482e-01, -5.1720e-02,  1.3210e-01,  1.0665e-01],\n        [-1.7638e-01, -2.0919e-01,  2.1000e-02,  1.5409e-01,  1.8488e-01,\n          7.4271e-03,  9.0359e-02, -1.4036e-01,  1.4177e-01, -9.1014e-03,\n         -8.0175e-02, -5.6891e-02, -1.9198e-01,  1.3697e-01, -2.1840e-01,\n          2.1104e-02,  1.5475e-01,  1.0764e-01, -1.1579e-01,  3.3792e-02],\n        [-1.0121e-01,  1.1830e-01,  3.2542e-02,  9.2474e-02,  1.3602e-02,\n          1.4218e-01, -1.8301e-01, -6.7257e-02,  2.0511e-01,  1.3471e-01,\n          1.1407e-01,  2.9171e-02, -1.3326e-01, -1.5423e-01, -3.7750e-02,\n         -2.8886e-02, -5.3914e-02, -2.0019e-01,  6.2006e-02, -1.8528e-01],\n        [ 3.0272e-02, -1.2086e-01,  2.0572e-01, -1.5679e-01, -1.8161e-01,\n         -5.7985e-02,  1.0403e-01,  6.2949e-02, -1.1094e-01,  5.4969e-03,\n         -1.1655e-01, -4.6290e-02,  7.8282e-02, -2.9583e-03, -2.2353e-01,\n          3.2456e-02,  1.0207e-01,  2.0467e-01, -6.8422e-02,  2.1213e-02],\n        [ 2.1085e-01, -1.0319e-01,  1.6144e-01,  4.7035e-02,  2.1080e-01,\n         -8.2427e-02, -2.1390e-01, -2.7879e-02,  1.4945e-02,  8.1479e-02,\n         -9.2251e-03,  1.8334e-01, -8.7054e-02,  1.5327e-01,  2.0725e-01,\n         -8.7123e-03, -1.7544e-01,  2.1064e-02,  6.8464e-02,  2.0742e-01],\n        [-4.9811e-02,  9.4413e-03, -5.0159e-02,  2.0077e-01, -5.8593e-02,\n          1.7089e-02,  3.1372e-02,  3.7198e-02, -8.0837e-02, -6.7899e-02,\n         -8.7231e-02,  9.9657e-03, -9.5872e-02, -1.5183e-01,  1.8952e-01,\n         -2.1076e-01,  4.4419e-02,  1.3855e-01,  1.3738e-02,  4.1171e-02],\n        [ 3.7370e-02, -6.9194e-02, -1.6577e-01,  2.0290e-01, -4.8357e-03,\n         -2.2259e-01,  1.6977e-02,  1.5625e-02, -9.2729e-02,  1.6012e-01,\n          3.7073e-02, -1.7195e-01,  2.7489e-02,  2.0959e-01,  6.5621e-02,\n          6.8173e-02,  1.2026e-01,  1.5659e-01,  1.8983e-02,  1.2454e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2179, -0.1949,  0.0784,  0.1212, -0.0890, -0.0312,  0.0159, -0.0839,\n         0.2091,  0.0610, -0.2055, -0.0944, -0.0646, -0.0518,  0.1468, -0.0067,\n        -0.1955, -0.0931, -0.0498,  0.0783, -0.0612, -0.0662, -0.1916, -0.1947,\n        -0.0008,  0.0118, -0.1067, -0.1987, -0.0072,  0.2198,  0.0431, -0.0290],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1548, -0.1191, -0.0892,  0.0691,  0.0562,  0.1673, -0.0632, -0.1474,\n         -0.1386, -0.0116, -0.1389,  0.1650,  0.0523, -0.0351,  0.0005,  0.1632,\n         -0.1055, -0.0556, -0.0708, -0.0023, -0.0382, -0.1298, -0.0519,  0.0920,\n         -0.1738,  0.0798,  0.0534,  0.0412,  0.0993,  0.0428,  0.1326, -0.1450],\n        [-0.0646, -0.0105,  0.1627, -0.1071, -0.1026,  0.0356, -0.1481,  0.0516,\n         -0.1249, -0.0288, -0.0244,  0.0856,  0.0444, -0.1552, -0.0505, -0.0595,\n         -0.0120, -0.0117,  0.0319,  0.1381, -0.1491,  0.0527,  0.0665,  0.0674,\n         -0.1560,  0.1647, -0.0929, -0.1473, -0.0839,  0.0280, -0.1590,  0.1647],\n        [-0.1159, -0.1034, -0.1344, -0.0162,  0.0993,  0.1166, -0.1428,  0.1280,\n          0.1152, -0.1401,  0.0385,  0.0383, -0.1022,  0.0490, -0.0349, -0.1223,\n         -0.0566,  0.0361,  0.0773,  0.0778,  0.1014,  0.1372, -0.1584,  0.0437,\n         -0.1516,  0.1340,  0.0165, -0.1258,  0.1591,  0.1740, -0.0015,  0.0632],\n        [-0.1437,  0.0770,  0.0141,  0.1215,  0.0206,  0.0733,  0.0227, -0.0560,\n          0.1412,  0.0868, -0.1479,  0.1006, -0.1200, -0.0996, -0.1376, -0.0866,\n          0.0099, -0.1662, -0.1312, -0.0265,  0.1733,  0.1696,  0.0997, -0.0991,\n          0.1622,  0.0155, -0.0733,  0.1423, -0.1303, -0.1368,  0.0625,  0.1069],\n        [ 0.1456, -0.0042, -0.0916, -0.1642,  0.1098, -0.1042,  0.0281, -0.1707,\n          0.1566, -0.0608, -0.1027,  0.0266,  0.0649,  0.0119, -0.0961, -0.1412,\n         -0.0790, -0.0222,  0.0298, -0.1614,  0.0520,  0.0595, -0.0827, -0.0901,\n         -0.0080, -0.0537,  0.1229,  0.0333, -0.1695, -0.0270,  0.1106, -0.0250],\n        [ 0.1745,  0.0603, -0.0582, -0.0046,  0.0121, -0.1298,  0.1643,  0.1514,\n          0.1469,  0.1366,  0.1653, -0.0519,  0.0808,  0.1765, -0.0016, -0.1260,\n         -0.0195,  0.0807,  0.0858, -0.0419, -0.1118,  0.0101, -0.0189,  0.0238,\n         -0.0752,  0.0689,  0.0905, -0.1340, -0.0590,  0.1641, -0.1555, -0.1268],\n        [-0.0381,  0.1485, -0.1391,  0.0617, -0.1646, -0.0286, -0.0741,  0.0486,\n         -0.1372, -0.0549, -0.0552, -0.1579, -0.1222,  0.0669, -0.0384,  0.0428,\n         -0.0752, -0.0035, -0.0167,  0.0747,  0.1574, -0.0012,  0.1653, -0.0960,\n          0.1266,  0.1086, -0.0612, -0.0193,  0.1066,  0.0201,  0.0088, -0.0651],\n        [-0.0089,  0.1115, -0.0432, -0.0912,  0.0767,  0.0615,  0.1237,  0.0178,\n         -0.0748,  0.1302,  0.1315, -0.0059,  0.0877, -0.1340,  0.0864,  0.1159,\n          0.0206, -0.0365,  0.0056, -0.1037, -0.1274, -0.1618, -0.0198,  0.0179,\n          0.0201, -0.1214, -0.1743, -0.1514,  0.0287, -0.0186, -0.0465,  0.1553],\n        [-0.0272,  0.1253,  0.0557, -0.1274,  0.0591,  0.0100, -0.1368, -0.1424,\n         -0.0664,  0.1120,  0.0566, -0.1052, -0.1722,  0.1100, -0.0846,  0.0494,\n         -0.0742, -0.0180,  0.0363, -0.0692, -0.1709,  0.1385,  0.1434, -0.0200,\n          0.1461, -0.1399,  0.1093, -0.0945, -0.1282, -0.0125, -0.0155, -0.1267],\n        [ 0.0427,  0.1504, -0.0673, -0.0529, -0.1010,  0.1436, -0.1418,  0.1016,\n          0.1078, -0.1110,  0.1425,  0.1742,  0.0190,  0.0073, -0.1345, -0.0461,\n         -0.0936,  0.0061, -0.0275, -0.0144,  0.1509,  0.0904, -0.1137, -0.1378,\n          0.1167, -0.1705, -0.0552,  0.1130, -0.0358, -0.1048,  0.1287, -0.1512],\n        [ 0.1547,  0.0843,  0.0489, -0.0677,  0.0987, -0.0203,  0.0295, -0.1090,\n          0.0860, -0.1051,  0.0863,  0.1027, -0.1753,  0.1427,  0.1304, -0.0015,\n         -0.1444,  0.0971, -0.0614, -0.1685,  0.0310,  0.1576, -0.0750, -0.1060,\n          0.0563, -0.1326,  0.1549, -0.0743,  0.1318,  0.1213,  0.1664, -0.1242],\n        [ 0.1052,  0.0084,  0.0830,  0.0556, -0.0999, -0.1629,  0.1154,  0.0945,\n          0.0241, -0.0969,  0.1228, -0.1739, -0.0676, -0.0528,  0.0216,  0.1242,\n          0.1713,  0.1379,  0.0414, -0.1275,  0.1095,  0.1367,  0.1086, -0.0701,\n         -0.0225, -0.0074,  0.0021,  0.1125, -0.0476,  0.0930, -0.0924, -0.0389],\n        [ 0.1461, -0.1351,  0.1669,  0.0605,  0.0695,  0.0228,  0.1609,  0.0755,\n         -0.0676, -0.1400,  0.1339,  0.0448, -0.0217,  0.1345, -0.1196,  0.1659,\n         -0.1753,  0.0717, -0.0536, -0.1552,  0.0538, -0.1403,  0.0697, -0.0553,\n          0.1190, -0.0618, -0.1448, -0.0949, -0.1667, -0.0490,  0.1174,  0.1727],\n        [ 0.0592, -0.0045, -0.0448, -0.0947, -0.1033, -0.1621,  0.1492, -0.0519,\n         -0.1010,  0.1450,  0.1275,  0.0147,  0.0817, -0.0562,  0.1343, -0.1189,\n          0.0598,  0.0382,  0.1390,  0.1074, -0.1701,  0.1765,  0.0166, -0.0750,\n         -0.0270,  0.1425, -0.1402, -0.1192, -0.1422, -0.0712,  0.0708, -0.0270],\n        [ 0.0301,  0.1669, -0.0633, -0.0029, -0.0775,  0.0735,  0.0811, -0.0633,\n         -0.0548, -0.0445, -0.0367, -0.0249, -0.1137,  0.1647, -0.1342, -0.0287,\n         -0.0767,  0.1571, -0.0729,  0.1685,  0.0410,  0.0266, -0.1610,  0.1693,\n          0.0156,  0.1694,  0.0841, -0.1727, -0.0509,  0.0774,  0.1502, -0.1270],\n        [ 0.1664,  0.1516,  0.0812, -0.0223, -0.0449, -0.0796,  0.0833, -0.0798,\n         -0.1726,  0.0529,  0.0953,  0.1327,  0.0141, -0.1749, -0.1125,  0.0251,\n          0.0135, -0.0475, -0.0037,  0.1508,  0.0057, -0.0201, -0.0872, -0.0868,\n         -0.0976,  0.0142, -0.0617, -0.0704,  0.0069,  0.0254,  0.0857, -0.1239]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1226, -0.1226, -0.0260, -0.1204,  0.0167, -0.1509,  0.1395, -0.0751,\n         0.0578,  0.1466, -0.1383, -0.0931, -0.0654, -0.0290, -0.0043,  0.0022],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0731,  0.0014,  0.0917,  0.1989, -0.0651, -0.1379, -0.2036,  0.1152,\n          0.1629, -0.0805,  0.1745,  0.1123, -0.1856,  0.1093, -0.1895,  0.0189],\n        [-0.2471, -0.1340,  0.2161, -0.0775, -0.1312, -0.0797, -0.0906, -0.1279,\n         -0.0139,  0.2500,  0.1876, -0.0349, -0.2386, -0.1630, -0.2069,  0.2381],\n        [-0.0683,  0.1513, -0.0726,  0.2204, -0.1682, -0.2489,  0.2250,  0.0055,\n          0.1188, -0.1086, -0.0396,  0.2040, -0.1989, -0.1322,  0.0713,  0.1509],\n        [-0.0185,  0.0053, -0.2020,  0.0695,  0.1267,  0.0988, -0.1016,  0.0470,\n          0.0535, -0.2373, -0.0534, -0.0249, -0.0523, -0.1338,  0.1587,  0.1083],\n        [ 0.0171,  0.0720,  0.0677, -0.0443, -0.0757, -0.0594,  0.1348,  0.1072,\n          0.0867, -0.1671, -0.0130,  0.1676,  0.2325,  0.1546, -0.2041, -0.0118],\n        [ 0.1900, -0.0706,  0.2429,  0.0159,  0.1633, -0.0865,  0.1488,  0.0426,\n         -0.1045,  0.1127, -0.0483, -0.1053,  0.0105,  0.1025, -0.0151, -0.1955],\n        [ 0.2443,  0.1059,  0.0851, -0.1700, -0.1229,  0.1186,  0.1788, -0.0058,\n          0.2081,  0.0809, -0.1194,  0.0029,  0.1647, -0.1539,  0.0097, -0.1511],\n        [-0.1028,  0.0279, -0.2056,  0.2384, -0.0508, -0.0972,  0.2257, -0.0429,\n          0.1973, -0.0623,  0.2065, -0.2468, -0.1597, -0.0651,  0.1218, -0.2090]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0496,  0.1691,  0.2190, -0.0902, -0.2408, -0.1465,  0.1071,  0.1573],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1966,  0.2030,  0.3322, -0.0715, -0.0923,  0.2742,  0.2450,  0.1603]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0462], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x10c55e380>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x11f828c70>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s53230000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s53230000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}