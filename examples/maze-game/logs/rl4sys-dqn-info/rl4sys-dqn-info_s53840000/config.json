{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s53840000"
    },
    "q_lr":	0.0005,
    "seed":	53840000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x000001C7EB44E680>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1651,  0.1662,  0.0630, -0.0569,  0.2116,  0.1908,  0.1799,  0.0239,\n        -0.1018, -0.2090, -0.0458, -0.1459, -0.0093, -0.2206, -0.0712,  0.0156,\n         0.0390,  0.0771, -0.1376, -0.0795, -0.0953,  0.0842, -0.0757,  0.0259,\n        -0.0480, -0.1879,  0.1700, -0.0414,  0.0601,  0.1496,  0.0517, -0.1675],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-6.3121e-02,  9.3657e-02,  1.3788e-01, -1.8841e-01,  1.9213e-01,\n         -1.4986e-01,  2.2160e-01,  2.1924e-01, -5.5623e-03, -2.0294e-01,\n          1.2281e-01,  7.1165e-02,  1.7557e-01,  1.1227e-01,  3.3752e-02,\n          1.6371e-01,  9.1844e-02, -1.4936e-01, -2.0378e-01, -3.8161e-02],\n        [-9.7092e-02, -6.4795e-02,  1.4987e-01,  6.5458e-02, -1.3066e-02,\n          3.2711e-02,  1.2595e-01, -8.2502e-02, -2.1864e-01, -7.0614e-03,\n          9.7206e-02, -9.3065e-02, -4.9011e-02, -2.1368e-01, -1.0903e-01,\n          1.6329e-02,  1.0973e-01, -9.2581e-02, -8.7315e-02, -1.2514e-01],\n        [-2.0206e-01,  5.6148e-02, -1.0176e-01,  1.7513e-01,  2.2188e-01,\n         -6.1641e-02,  2.1726e-01, -9.9084e-03,  8.2557e-02, -1.7172e-01,\n         -2.0116e-01, -2.1543e-01,  1.7539e-01, -1.8266e-01,  6.1718e-02,\n         -6.5988e-02,  4.2600e-02,  2.9615e-02,  1.9085e-01, -1.6289e-01],\n        [ 9.0547e-02,  8.2055e-02, -1.4375e-01,  1.4548e-01,  1.0354e-01,\n         -6.2797e-03,  2.6810e-02, -1.7262e-01,  4.4014e-02, -2.2584e-02,\n         -1.3362e-01, -1.8714e-01, -2.1914e-01,  1.7002e-01,  2.0083e-01,\n         -1.6662e-01, -1.5407e-01, -3.3641e-02,  3.5886e-02, -1.6029e-01],\n        [ 1.7424e-01,  1.0755e-01,  1.0047e-01, -1.1437e-01,  2.2682e-02,\n         -7.5502e-02,  1.3735e-02,  9.7283e-02,  1.3609e-01,  1.8314e-01,\n         -1.2453e-01, -1.4493e-01, -2.0475e-01,  1.0860e-01, -1.1628e-01,\n          3.8793e-02,  2.0764e-01, -1.6321e-01,  8.2591e-02, -1.7606e-01],\n        [-1.9278e-01,  8.2621e-02,  1.1793e-01, -1.1395e-01, -7.2636e-02,\n          1.1599e-01,  1.3846e-01,  2.0176e-01, -1.7449e-01, -1.5214e-01,\n         -4.0639e-02,  1.4241e-01,  2.1459e-01, -8.0881e-02,  3.7702e-02,\n          1.4947e-01,  2.0682e-01, -1.8242e-01, -1.0919e-01,  1.6436e-01],\n        [-1.3791e-01, -7.3753e-03,  1.1568e-01, -1.3338e-01,  1.1569e-01,\n          1.4799e-01, -6.6914e-02,  1.2544e-01, -5.2560e-02,  1.9670e-01,\n          2.1896e-01, -1.0667e-01,  2.1796e-01, -7.0858e-02,  1.6994e-01,\n         -1.9013e-01, -6.6253e-02,  1.7612e-01,  4.7571e-02,  1.7800e-01],\n        [-9.2912e-02, -1.3401e-01,  1.3729e-01,  9.2376e-02, -1.2992e-01,\n         -1.1315e-01, -2.2094e-01,  2.1810e-02, -1.2047e-01,  1.2763e-01,\n          1.8731e-01,  9.1670e-02,  1.1038e-01,  2.0783e-01, -1.4580e-01,\n          6.2970e-02, -1.2330e-02, -2.0078e-01,  1.3512e-01,  1.7793e-01],\n        [-2.1175e-01, -9.6221e-02, -2.9482e-02,  1.8327e-02,  1.1796e-01,\n         -4.4150e-02, -1.5609e-01,  8.6570e-02,  1.8504e-01,  1.8723e-01,\n         -1.6311e-01,  1.8982e-01, -2.1326e-01,  1.3005e-01, -5.5606e-02,\n          1.3535e-01,  7.8180e-02,  4.0705e-02,  3.8739e-02,  4.1334e-02],\n        [ 1.1282e-01, -1.0120e-01, -6.8320e-02,  2.2287e-01, -1.7637e-01,\n         -1.2772e-01,  1.9442e-01, -1.8651e-02,  1.3601e-01,  1.1897e-01,\n         -5.2627e-03,  7.8183e-02, -1.5551e-01,  1.6373e-02, -2.1898e-01,\n          1.5067e-01,  1.8966e-01,  5.8803e-02,  9.0740e-02,  4.5790e-02],\n        [-5.2341e-02, -6.5692e-02,  1.5572e-01, -1.9094e-01,  1.4486e-01,\n          3.7762e-02,  1.6810e-01,  1.5703e-02,  7.4901e-02,  1.9687e-01,\n         -5.4260e-02, -1.5951e-01, -2.1689e-01, -1.9235e-01,  1.5972e-01,\n          1.2885e-01, -1.2684e-01, -1.8220e-01,  8.7149e-02, -6.7741e-02],\n        [-5.9303e-02,  1.1152e-01, -2.6428e-02, -1.5562e-02,  1.4645e-01,\n          2.0521e-01, -1.7275e-02, -1.5036e-01,  5.9582e-02,  9.1343e-02,\n          9.5001e-02,  9.5466e-02,  9.7942e-03, -1.9159e-01,  1.6875e-01,\n          1.4763e-01,  5.2934e-02, -2.0462e-01,  2.4984e-02, -2.1758e-01],\n        [ 1.5252e-01, -1.1430e-01,  8.7464e-02, -2.1780e-01, -1.8050e-01,\n          1.3593e-01, -6.6509e-02,  1.0230e-01, -9.5650e-02,  1.2619e-01,\n         -5.1135e-02,  1.7169e-01,  1.3834e-02, -1.8041e-01, -1.1709e-01,\n         -7.6205e-03,  1.9945e-01, -5.3241e-02, -3.2095e-02,  1.1728e-01],\n        [ 3.0892e-02, -1.1994e-01, -3.8368e-02, -1.2004e-01, -8.4997e-02,\n          6.7028e-02, -5.2440e-04, -5.0692e-02,  1.8350e-01, -4.0716e-02,\n         -8.0742e-02, -2.8404e-02,  1.1840e-01, -6.7904e-02, -2.2265e-01,\n          4.8938e-02,  1.4349e-01,  1.9000e-01,  1.8118e-01,  9.0621e-02],\n        [-1.8322e-02, -7.3039e-02, -8.4668e-02, -1.1035e-01, -2.8638e-02,\n          6.4790e-02,  1.3965e-01,  1.2266e-01,  8.9927e-02, -2.1742e-01,\n         -1.9061e-01,  1.6977e-01,  8.9931e-02,  1.9905e-01, -3.4046e-02,\n         -2.0654e-01,  4.9219e-02, -2.2224e-01,  1.5951e-01,  8.4116e-02],\n        [ 4.7271e-02, -9.6663e-03, -1.7592e-01,  8.9665e-02, -2.1087e-01,\n          1.2968e-02, -1.5555e-01,  1.0084e-01,  2.0266e-01,  5.5881e-02,\n         -1.7683e-01,  1.5039e-01,  1.7290e-01, -1.8216e-01,  1.4041e-01,\n         -2.1893e-01, -1.1172e-01, -8.8210e-02,  1.1437e-01,  1.6003e-02],\n        [ 4.4359e-02, -1.0128e-01, -2.0816e-01,  5.4721e-02,  7.6579e-02,\n         -6.3556e-02,  7.3062e-02,  1.8413e-01,  2.0889e-01, -1.0994e-01,\n         -2.0082e-03, -2.1996e-02,  9.4860e-02,  9.1745e-02,  1.1887e-01,\n         -1.8493e-01,  9.5210e-02, -1.0330e-01,  5.3697e-02, -1.1635e-01],\n        [-2.1865e-01, -1.3740e-03, -1.6026e-01,  1.1572e-01, -1.5054e-01,\n          5.6127e-02,  4.6577e-02,  1.6233e-01, -1.1398e-01,  1.3320e-01,\n         -3.3016e-02, -1.8762e-01,  1.4965e-01, -1.4523e-02,  5.1277e-02,\n          2.1776e-01, -3.2476e-02,  1.3166e-01, -2.0930e-01, -6.4297e-02],\n        [ 1.1510e-03, -1.1369e-01,  1.5977e-01,  4.3509e-02,  1.7999e-01,\n         -9.0822e-02,  9.1512e-02,  2.1718e-01,  2.2655e-02,  1.1112e-01,\n         -1.7271e-01,  1.8245e-01,  6.2032e-02,  9.4036e-02, -2.2048e-01,\n          1.6612e-01, -5.6170e-02, -1.4953e-01, -1.2111e-01, -1.6148e-01],\n        [ 2.0345e-01, -1.9155e-01, -1.6971e-01, -6.0339e-02,  2.0801e-01,\n         -1.0938e-01,  5.0759e-02, -1.4095e-01,  7.1497e-02,  1.0478e-01,\n          1.0289e-03, -1.4639e-01, -3.4204e-02, -8.2672e-02,  3.6639e-02,\n         -7.7323e-02,  1.0461e-01, -1.7855e-04, -6.4062e-03,  1.4428e-01],\n        [-3.1643e-02, -2.0905e-01, -2.2056e-01,  1.0129e-01, -1.7750e-01,\n          4.6009e-02,  3.2288e-02, -9.9071e-02,  1.9001e-01,  2.0819e-01,\n          4.8252e-02,  1.0827e-01,  1.0642e-01, -2.1313e-01, -5.0919e-02,\n         -9.7803e-02,  1.9872e-01, -1.9935e-01,  2.1063e-01,  8.2802e-02],\n        [ 1.5421e-01, -3.8336e-02,  1.0006e-02,  1.2191e-01,  2.0702e-01,\n         -1.7243e-01,  3.0743e-02, -6.0467e-02, -2.2207e-01,  5.2188e-02,\n          1.6342e-01, -1.5078e-01, -1.8109e-01,  2.7234e-02, -2.1518e-01,\n          1.6834e-01,  7.5007e-02,  1.0589e-01, -7.0797e-02, -1.0999e-01],\n        [-9.5726e-02,  1.8575e-01,  9.6652e-02,  1.5820e-01, -5.5708e-02,\n         -2.0623e-01,  7.5633e-02, -2.0763e-01, -1.8414e-01,  2.2128e-02,\n          1.2114e-01,  2.1523e-01, -2.1067e-01,  9.9429e-02, -1.9136e-01,\n          7.3130e-02, -1.6137e-01,  1.3784e-01, -5.5355e-02,  1.9530e-01],\n        [-7.9552e-02,  1.4770e-02, -1.0621e-01,  7.0222e-02, -1.4700e-01,\n          4.1625e-02,  1.3165e-01, -9.0123e-02, -1.4719e-01, -1.7958e-01,\n          1.3867e-01,  1.5217e-01, -1.6903e-01,  1.0459e-01, -7.3309e-02,\n          1.3384e-01,  1.2480e-01, -2.0380e-02, -4.3861e-02,  1.7035e-01],\n        [-2.0231e-02, -1.5726e-02,  2.1054e-01, -1.8600e-01,  1.4784e-01,\n         -1.6203e-02,  3.0387e-02,  1.1891e-01, -4.3981e-02, -5.4444e-02,\n          9.5529e-02, -5.8971e-02, -5.8531e-02,  9.8792e-02,  2.0955e-01,\n         -1.4451e-01, -3.0875e-02, -5.6278e-02, -1.8222e-01,  6.6544e-02],\n        [-8.5327e-02, -1.1136e-01,  1.6723e-01, -1.8104e-01, -2.1264e-01,\n          1.4930e-01, -2.4421e-02, -1.9292e-01,  1.0928e-03, -9.2955e-02,\n          4.8975e-02,  7.0539e-02, -1.7038e-01, -8.8061e-02, -6.6121e-02,\n         -1.3444e-01,  4.5166e-02,  2.7096e-02,  1.5482e-01,  1.7946e-01],\n        [ 1.3995e-01,  2.0926e-01,  1.9626e-01,  1.5982e-01, -1.9769e-01,\n          1.5521e-01,  9.4018e-02, -2.0509e-01, -5.6600e-02, -3.3581e-02,\n         -1.5591e-01,  1.9102e-01, -2.0470e-01, -6.4176e-02, -2.0560e-01,\n         -9.9454e-02,  2.1471e-01, -1.0828e-01, -2.0758e-01,  2.1070e-01],\n        [ 9.2392e-02, -1.0018e-01,  5.7314e-03, -2.5933e-02, -2.0735e-01,\n         -5.6635e-02,  7.3635e-02,  7.8928e-02, -2.2043e-01,  1.6319e-01,\n         -1.7513e-01, -6.2252e-02,  1.0390e-01,  1.5875e-01, -8.4913e-02,\n         -1.2636e-01, -1.3786e-01, -1.1745e-01, -7.3355e-02, -1.8483e-01],\n        [ 1.0222e-01,  1.9617e-01, -2.2815e-02, -1.8001e-01, -2.2251e-01,\n          6.2484e-02,  2.1954e-01,  2.6252e-02, -1.1039e-02,  1.8952e-01,\n          6.4759e-03,  1.8558e-01, -9.9589e-02, -1.3821e-01,  4.1336e-02,\n         -1.2660e-01,  1.8779e-01,  2.2129e-01, -1.0523e-01,  9.4190e-02],\n        [-1.2844e-01, -1.2538e-01,  1.9457e-02,  7.7786e-02,  1.8447e-01,\n          1.5797e-01, -2.3419e-02,  1.7587e-01, -4.2815e-02, -2.4629e-02,\n          1.1298e-01, -9.2232e-02,  7.1908e-02,  1.5147e-01,  5.1975e-02,\n         -5.1219e-02, -5.8357e-02,  1.0187e-01, -3.3509e-02, -1.7198e-01],\n        [-2.2112e-01, -6.9515e-02,  2.1094e-01, -1.5878e-01,  1.3116e-01,\n         -7.3657e-03,  4.8446e-02,  1.7323e-01,  2.8846e-02,  1.8214e-01,\n         -1.8152e-01,  9.9616e-03, -8.7738e-02,  1.8907e-01,  5.4683e-02,\n          2.0305e-01, -1.4876e-01,  3.4663e-03,  1.7495e-01, -9.0044e-02],\n        [-5.8775e-02,  6.6184e-02, -2.0895e-01, -1.8733e-01, -2.2305e-02,\n         -1.1086e-02, -1.9581e-01, -1.0945e-01,  1.3108e-01,  1.7751e-01,\n         -7.9935e-02, -7.3509e-02,  1.5973e-01,  2.1696e-01, -2.3812e-02,\n         -9.0710e-02,  1.7483e-01,  1.5047e-02,  1.1712e-01, -2.0456e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1183,  0.1735,  0.0696,  0.0699,  0.1223,  0.1400, -0.1512, -0.1709,\n         0.1572,  0.0677, -0.1037, -0.1206, -0.0192,  0.1251,  0.1283,  0.0251],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0892, -0.1294,  0.0242,  0.0079, -0.1209, -0.1116,  0.0382, -0.1405,\n          0.0104,  0.0791,  0.0311, -0.0622,  0.0529,  0.0329, -0.0977,  0.0144,\n         -0.0506,  0.1505,  0.0147,  0.0154,  0.0660, -0.0991,  0.1172,  0.0566,\n         -0.1242, -0.1143,  0.0963,  0.0856,  0.1067,  0.1711, -0.1013, -0.0273],\n        [-0.1325,  0.0052,  0.0771, -0.0300,  0.1690,  0.1710,  0.1410,  0.0980,\n         -0.0574, -0.0926, -0.0795,  0.0370,  0.0735, -0.1544,  0.0010,  0.1382,\n          0.0021,  0.0022, -0.1560,  0.0234,  0.0118, -0.1416, -0.0487,  0.0038,\n          0.0887,  0.0584, -0.0988,  0.1102,  0.1693,  0.1578, -0.1123,  0.1569],\n        [ 0.0513,  0.1461, -0.0201, -0.0407, -0.1366, -0.0095, -0.0638,  0.1292,\n          0.1735, -0.1152, -0.1177, -0.1003, -0.0726,  0.1414, -0.1707,  0.0364,\n          0.0994, -0.0517, -0.1751, -0.1345,  0.0652, -0.1061, -0.0656, -0.0431,\n         -0.1653, -0.0087,  0.0483,  0.1413,  0.0873, -0.1022, -0.0204,  0.0679],\n        [-0.0071,  0.0550,  0.1673, -0.0372,  0.1218,  0.0991,  0.1564, -0.0771,\n          0.0895, -0.0322,  0.0621,  0.1457, -0.0673,  0.1711,  0.1317,  0.0349,\n         -0.1603,  0.0602,  0.1309, -0.1116, -0.1505, -0.0762,  0.1756, -0.1401,\n         -0.0049,  0.0258,  0.1486,  0.1566,  0.0356, -0.0327,  0.1470,  0.1098],\n        [-0.0704, -0.1161, -0.0360,  0.1137,  0.1212, -0.0524,  0.1064, -0.0707,\n          0.0516,  0.1282,  0.1043, -0.0110, -0.0737,  0.0022,  0.1011, -0.1288,\n          0.0729,  0.0712, -0.1627,  0.0878,  0.0767, -0.0145, -0.0422,  0.1502,\n          0.0244, -0.0005, -0.0525, -0.1108,  0.0678, -0.1766,  0.0008, -0.0749],\n        [-0.1683,  0.0302, -0.0569,  0.0836,  0.1759,  0.1033,  0.0686, -0.0945,\n          0.0858, -0.0038,  0.0390,  0.0459,  0.1407,  0.0330,  0.1326,  0.0615,\n         -0.1036, -0.1152, -0.0920,  0.0473,  0.1058,  0.1166,  0.1569, -0.0761,\n          0.0923,  0.1362, -0.1319, -0.0223,  0.0182,  0.1473,  0.0353,  0.1148],\n        [ 0.0666,  0.0500, -0.0927, -0.0835,  0.0496,  0.0401, -0.1341,  0.0450,\n         -0.0841, -0.0221, -0.0043,  0.0922,  0.0709,  0.0016,  0.1654, -0.0572,\n          0.1363, -0.1195, -0.0253, -0.0306, -0.0303, -0.0167, -0.1722, -0.1108,\n          0.1184,  0.1361,  0.0650, -0.0315, -0.0221,  0.0438,  0.1258,  0.1049],\n        [ 0.0311,  0.0644,  0.0973,  0.0590,  0.0195, -0.0534,  0.0536, -0.1404,\n          0.1322, -0.0454, -0.1517, -0.1701,  0.0787,  0.0084,  0.1232,  0.1560,\n         -0.0189,  0.1327, -0.0089,  0.0863,  0.0606, -0.0804,  0.0506, -0.0876,\n         -0.1083,  0.1286,  0.0065, -0.1733,  0.1233, -0.0264, -0.0460, -0.0251],\n        [-0.0881,  0.1332, -0.1675,  0.1708,  0.1534,  0.1047,  0.0294,  0.0541,\n          0.1616, -0.1135,  0.1011,  0.0506,  0.1551, -0.1753,  0.1629, -0.0379,\n         -0.0410,  0.0360,  0.1697, -0.1534,  0.0272, -0.1017, -0.0544,  0.0929,\n         -0.1172, -0.1526, -0.0153, -0.0999, -0.1047, -0.1418,  0.0616,  0.0485],\n        [-0.0550, -0.1531,  0.0646,  0.0757, -0.1610, -0.1718, -0.0263,  0.1681,\n         -0.0026, -0.0235, -0.0732,  0.1271, -0.0778, -0.0586, -0.0252,  0.1381,\n          0.0011, -0.0647, -0.0518, -0.1455,  0.0939,  0.0061, -0.0850, -0.0919,\n          0.0635,  0.1187, -0.1080,  0.0366,  0.0919,  0.1535,  0.1017,  0.1117],\n        [ 0.1553, -0.0604, -0.0089,  0.1607,  0.0782,  0.0278,  0.1446,  0.1641,\n         -0.0981, -0.0907, -0.0736,  0.0043, -0.1653,  0.0618, -0.1304, -0.0706,\n          0.1421,  0.1010, -0.1301,  0.1609, -0.0645,  0.0485, -0.0977,  0.1344,\n          0.0959,  0.0253, -0.1243, -0.0931,  0.0482, -0.0475, -0.0296, -0.1609],\n        [ 0.1234,  0.1650,  0.1293, -0.0078, -0.0627,  0.1182,  0.1326,  0.0666,\n          0.0995,  0.1254, -0.1491, -0.1237,  0.1752,  0.1277, -0.0506,  0.0557,\n         -0.0565,  0.0400, -0.0294,  0.1438,  0.1028,  0.0883, -0.0593, -0.0718,\n         -0.1350, -0.1437, -0.0306,  0.1708,  0.1531,  0.1198,  0.1721, -0.0897],\n        [ 0.1650, -0.1168, -0.1482,  0.1164,  0.1245, -0.1649,  0.1226, -0.1515,\n         -0.1297,  0.0161,  0.1188,  0.1114, -0.0408, -0.1287,  0.1175,  0.1644,\n          0.1045,  0.1126,  0.1278,  0.0407,  0.0425, -0.1754,  0.1377, -0.1735,\n         -0.0102, -0.0250, -0.0390, -0.1075,  0.1213,  0.0550, -0.1225,  0.0521],\n        [ 0.0472, -0.0057, -0.0289,  0.1339,  0.0381,  0.0960,  0.1165,  0.0447,\n          0.1150,  0.0327, -0.1029,  0.0042, -0.1497, -0.0617,  0.1484, -0.1708,\n         -0.1144, -0.0751,  0.0962,  0.0092, -0.0322, -0.1388, -0.0202, -0.1224,\n         -0.0829, -0.0221, -0.1373,  0.1597,  0.0563,  0.1442, -0.0485, -0.1139],\n        [-0.0860, -0.1468,  0.1665,  0.1180,  0.1578, -0.0825,  0.0483, -0.0855,\n          0.1623,  0.1488, -0.0801, -0.0221, -0.1214,  0.0450, -0.1194,  0.0308,\n         -0.1707, -0.1218,  0.1568, -0.0564,  0.0658,  0.1195,  0.0093, -0.1724,\n         -0.1767,  0.1741,  0.1452, -0.0239,  0.0193, -0.1649,  0.1301,  0.0148],\n        [ 0.1271, -0.0235,  0.0933,  0.0089,  0.1584, -0.1053,  0.1225, -0.0895,\n         -0.1182,  0.1738,  0.1097,  0.0458, -0.0056,  0.0172, -0.0505,  0.0143,\n         -0.1703, -0.0607, -0.1413,  0.0905,  0.1527,  0.0394,  0.0066, -0.0083,\n         -0.1402,  0.0622, -0.0720, -0.0570,  0.0490,  0.0105, -0.0083, -0.0260]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1095,  0.0119,  0.0743, -0.1559, -0.1601, -0.1421,  0.1013, -0.0749],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1649, -0.1472,  0.0239,  0.0786,  0.2230, -0.0735,  0.1192,  0.1569,\n         -0.0294,  0.1644,  0.2281, -0.1364, -0.1994,  0.1042,  0.0427, -0.2400],\n        [ 0.2061,  0.0682, -0.1714,  0.1524, -0.1858, -0.1563,  0.0876, -0.0546,\n          0.1808, -0.1028,  0.2117,  0.2117,  0.0213,  0.0542,  0.1302, -0.0793],\n        [-0.2237, -0.0425, -0.2084,  0.1410, -0.1328, -0.2090,  0.1892,  0.0298,\n         -0.1004, -0.2171,  0.1854, -0.0240,  0.0423,  0.1611, -0.0119,  0.0319],\n        [ 0.0492, -0.1049,  0.0951,  0.0113, -0.0204, -0.1232, -0.0551, -0.0191,\n          0.0920,  0.0295,  0.2495, -0.1426,  0.0568, -0.1141,  0.2434,  0.2220],\n        [-0.2144, -0.0527,  0.1487, -0.1062,  0.1028, -0.0945, -0.1790,  0.2467,\n          0.1689,  0.1599,  0.2271, -0.0903, -0.2287,  0.0974,  0.1560, -0.1469],\n        [-0.1976, -0.1666, -0.0124, -0.2037, -0.0274,  0.2114,  0.0176,  0.2495,\n          0.1371, -0.0333, -0.2386,  0.2265, -0.0378, -0.1286, -0.1863, -0.2428],\n        [-0.1800, -0.0309,  0.1736, -0.2447, -0.2026,  0.0670,  0.2428,  0.0785,\n          0.1836, -0.1462, -0.2114,  0.1649,  0.2333,  0.1745,  0.0554, -0.0621],\n        [ 0.2255, -0.1108,  0.2488, -0.0789,  0.1157,  0.2378,  0.1469, -0.1827,\n         -0.1880,  0.0888,  0.0052, -0.1136, -0.0608, -0.0558, -0.0738,  0.0645]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.0451], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.3281, -0.0477, -0.1645, -0.0075,  0.3129,  0.2634, -0.0392,  0.2477]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-6.3121e-02,  9.3657e-02,  1.3788e-01, -1.8841e-01,  1.9213e-01,\n         -1.4986e-01,  2.2160e-01,  2.1924e-01, -5.5623e-03, -2.0294e-01,\n          1.2281e-01,  7.1165e-02,  1.7557e-01,  1.1227e-01,  3.3752e-02,\n          1.6371e-01,  9.1844e-02, -1.4936e-01, -2.0378e-01, -3.8161e-02],\n        [-9.7092e-02, -6.4795e-02,  1.4987e-01,  6.5458e-02, -1.3066e-02,\n          3.2711e-02,  1.2595e-01, -8.2502e-02, -2.1864e-01, -7.0614e-03,\n          9.7206e-02, -9.3065e-02, -4.9011e-02, -2.1368e-01, -1.0903e-01,\n          1.6329e-02,  1.0973e-01, -9.2581e-02, -8.7315e-02, -1.2514e-01],\n        [-2.0206e-01,  5.6148e-02, -1.0176e-01,  1.7513e-01,  2.2188e-01,\n         -6.1641e-02,  2.1726e-01, -9.9084e-03,  8.2557e-02, -1.7172e-01,\n         -2.0116e-01, -2.1543e-01,  1.7539e-01, -1.8266e-01,  6.1718e-02,\n         -6.5988e-02,  4.2600e-02,  2.9615e-02,  1.9085e-01, -1.6289e-01],\n        [ 9.0547e-02,  8.2055e-02, -1.4375e-01,  1.4548e-01,  1.0354e-01,\n         -6.2797e-03,  2.6810e-02, -1.7262e-01,  4.4014e-02, -2.2584e-02,\n         -1.3362e-01, -1.8714e-01, -2.1914e-01,  1.7002e-01,  2.0083e-01,\n         -1.6662e-01, -1.5407e-01, -3.3641e-02,  3.5886e-02, -1.6029e-01],\n        [ 1.7424e-01,  1.0755e-01,  1.0047e-01, -1.1437e-01,  2.2682e-02,\n         -7.5502e-02,  1.3735e-02,  9.7283e-02,  1.3609e-01,  1.8314e-01,\n         -1.2453e-01, -1.4493e-01, -2.0475e-01,  1.0860e-01, -1.1628e-01,\n          3.8793e-02,  2.0764e-01, -1.6321e-01,  8.2591e-02, -1.7606e-01],\n        [-1.9278e-01,  8.2621e-02,  1.1793e-01, -1.1395e-01, -7.2636e-02,\n          1.1599e-01,  1.3846e-01,  2.0176e-01, -1.7449e-01, -1.5214e-01,\n         -4.0639e-02,  1.4241e-01,  2.1459e-01, -8.0881e-02,  3.7702e-02,\n          1.4947e-01,  2.0682e-01, -1.8242e-01, -1.0919e-01,  1.6436e-01],\n        [-1.3791e-01, -7.3753e-03,  1.1568e-01, -1.3338e-01,  1.1569e-01,\n          1.4799e-01, -6.6914e-02,  1.2544e-01, -5.2560e-02,  1.9670e-01,\n          2.1896e-01, -1.0667e-01,  2.1796e-01, -7.0858e-02,  1.6994e-01,\n         -1.9013e-01, -6.6253e-02,  1.7612e-01,  4.7571e-02,  1.7800e-01],\n        [-9.2912e-02, -1.3401e-01,  1.3729e-01,  9.2376e-02, -1.2992e-01,\n         -1.1315e-01, -2.2094e-01,  2.1810e-02, -1.2047e-01,  1.2763e-01,\n          1.8731e-01,  9.1670e-02,  1.1038e-01,  2.0783e-01, -1.4580e-01,\n          6.2970e-02, -1.2330e-02, -2.0078e-01,  1.3512e-01,  1.7793e-01],\n        [-2.1175e-01, -9.6221e-02, -2.9482e-02,  1.8327e-02,  1.1796e-01,\n         -4.4150e-02, -1.5609e-01,  8.6570e-02,  1.8504e-01,  1.8723e-01,\n         -1.6311e-01,  1.8982e-01, -2.1326e-01,  1.3005e-01, -5.5606e-02,\n          1.3535e-01,  7.8180e-02,  4.0705e-02,  3.8739e-02,  4.1334e-02],\n        [ 1.1282e-01, -1.0120e-01, -6.8320e-02,  2.2287e-01, -1.7637e-01,\n         -1.2772e-01,  1.9442e-01, -1.8651e-02,  1.3601e-01,  1.1897e-01,\n         -5.2627e-03,  7.8183e-02, -1.5551e-01,  1.6373e-02, -2.1898e-01,\n          1.5067e-01,  1.8966e-01,  5.8803e-02,  9.0740e-02,  4.5790e-02],\n        [-5.2341e-02, -6.5692e-02,  1.5572e-01, -1.9094e-01,  1.4486e-01,\n          3.7762e-02,  1.6810e-01,  1.5703e-02,  7.4901e-02,  1.9687e-01,\n         -5.4260e-02, -1.5951e-01, -2.1689e-01, -1.9235e-01,  1.5972e-01,\n          1.2885e-01, -1.2684e-01, -1.8220e-01,  8.7149e-02, -6.7741e-02],\n        [-5.9303e-02,  1.1152e-01, -2.6428e-02, -1.5562e-02,  1.4645e-01,\n          2.0521e-01, -1.7275e-02, -1.5036e-01,  5.9582e-02,  9.1343e-02,\n          9.5001e-02,  9.5466e-02,  9.7942e-03, -1.9159e-01,  1.6875e-01,\n          1.4763e-01,  5.2934e-02, -2.0462e-01,  2.4984e-02, -2.1758e-01],\n        [ 1.5252e-01, -1.1430e-01,  8.7464e-02, -2.1780e-01, -1.8050e-01,\n          1.3593e-01, -6.6509e-02,  1.0230e-01, -9.5650e-02,  1.2619e-01,\n         -5.1135e-02,  1.7169e-01,  1.3834e-02, -1.8041e-01, -1.1709e-01,\n         -7.6205e-03,  1.9945e-01, -5.3241e-02, -3.2095e-02,  1.1728e-01],\n        [ 3.0892e-02, -1.1994e-01, -3.8368e-02, -1.2004e-01, -8.4997e-02,\n          6.7028e-02, -5.2440e-04, -5.0692e-02,  1.8350e-01, -4.0716e-02,\n         -8.0742e-02, -2.8404e-02,  1.1840e-01, -6.7904e-02, -2.2265e-01,\n          4.8938e-02,  1.4349e-01,  1.9000e-01,  1.8118e-01,  9.0621e-02],\n        [-1.8322e-02, -7.3039e-02, -8.4668e-02, -1.1035e-01, -2.8638e-02,\n          6.4790e-02,  1.3965e-01,  1.2266e-01,  8.9927e-02, -2.1742e-01,\n         -1.9061e-01,  1.6977e-01,  8.9931e-02,  1.9905e-01, -3.4046e-02,\n         -2.0654e-01,  4.9219e-02, -2.2224e-01,  1.5951e-01,  8.4116e-02],\n        [ 4.7271e-02, -9.6663e-03, -1.7592e-01,  8.9665e-02, -2.1087e-01,\n          1.2968e-02, -1.5555e-01,  1.0084e-01,  2.0266e-01,  5.5881e-02,\n         -1.7683e-01,  1.5039e-01,  1.7290e-01, -1.8216e-01,  1.4041e-01,\n         -2.1893e-01, -1.1172e-01, -8.8210e-02,  1.1437e-01,  1.6003e-02],\n        [ 4.4359e-02, -1.0128e-01, -2.0816e-01,  5.4721e-02,  7.6579e-02,\n         -6.3556e-02,  7.3062e-02,  1.8413e-01,  2.0889e-01, -1.0994e-01,\n         -2.0082e-03, -2.1996e-02,  9.4860e-02,  9.1745e-02,  1.1887e-01,\n         -1.8493e-01,  9.5210e-02, -1.0330e-01,  5.3697e-02, -1.1635e-01],\n        [-2.1865e-01, -1.3740e-03, -1.6026e-01,  1.1572e-01, -1.5054e-01,\n          5.6127e-02,  4.6577e-02,  1.6233e-01, -1.1398e-01,  1.3320e-01,\n         -3.3016e-02, -1.8762e-01,  1.4965e-01, -1.4523e-02,  5.1277e-02,\n          2.1776e-01, -3.2476e-02,  1.3166e-01, -2.0930e-01, -6.4297e-02],\n        [ 1.1510e-03, -1.1369e-01,  1.5977e-01,  4.3509e-02,  1.7999e-01,\n         -9.0822e-02,  9.1512e-02,  2.1718e-01,  2.2655e-02,  1.1112e-01,\n         -1.7271e-01,  1.8245e-01,  6.2032e-02,  9.4036e-02, -2.2048e-01,\n          1.6612e-01, -5.6170e-02, -1.4953e-01, -1.2111e-01, -1.6148e-01],\n        [ 2.0345e-01, -1.9155e-01, -1.6971e-01, -6.0339e-02,  2.0801e-01,\n         -1.0938e-01,  5.0759e-02, -1.4095e-01,  7.1497e-02,  1.0478e-01,\n          1.0289e-03, -1.4639e-01, -3.4204e-02, -8.2672e-02,  3.6639e-02,\n         -7.7323e-02,  1.0461e-01, -1.7855e-04, -6.4062e-03,  1.4428e-01],\n        [-3.1643e-02, -2.0905e-01, -2.2056e-01,  1.0129e-01, -1.7750e-01,\n          4.6009e-02,  3.2288e-02, -9.9071e-02,  1.9001e-01,  2.0819e-01,\n          4.8252e-02,  1.0827e-01,  1.0642e-01, -2.1313e-01, -5.0919e-02,\n         -9.7803e-02,  1.9872e-01, -1.9935e-01,  2.1063e-01,  8.2802e-02],\n        [ 1.5421e-01, -3.8336e-02,  1.0006e-02,  1.2191e-01,  2.0702e-01,\n         -1.7243e-01,  3.0743e-02, -6.0467e-02, -2.2207e-01,  5.2188e-02,\n          1.6342e-01, -1.5078e-01, -1.8109e-01,  2.7234e-02, -2.1518e-01,\n          1.6834e-01,  7.5007e-02,  1.0589e-01, -7.0797e-02, -1.0999e-01],\n        [-9.5726e-02,  1.8575e-01,  9.6652e-02,  1.5820e-01, -5.5708e-02,\n         -2.0623e-01,  7.5633e-02, -2.0763e-01, -1.8414e-01,  2.2128e-02,\n          1.2114e-01,  2.1523e-01, -2.1067e-01,  9.9429e-02, -1.9136e-01,\n          7.3130e-02, -1.6137e-01,  1.3784e-01, -5.5355e-02,  1.9530e-01],\n        [-7.9552e-02,  1.4770e-02, -1.0621e-01,  7.0222e-02, -1.4700e-01,\n          4.1625e-02,  1.3165e-01, -9.0123e-02, -1.4719e-01, -1.7958e-01,\n          1.3867e-01,  1.5217e-01, -1.6903e-01,  1.0459e-01, -7.3309e-02,\n          1.3384e-01,  1.2480e-01, -2.0380e-02, -4.3861e-02,  1.7035e-01],\n        [-2.0231e-02, -1.5726e-02,  2.1054e-01, -1.8600e-01,  1.4784e-01,\n         -1.6203e-02,  3.0387e-02,  1.1891e-01, -4.3981e-02, -5.4444e-02,\n          9.5529e-02, -5.8971e-02, -5.8531e-02,  9.8792e-02,  2.0955e-01,\n         -1.4451e-01, -3.0875e-02, -5.6278e-02, -1.8222e-01,  6.6544e-02],\n        [-8.5327e-02, -1.1136e-01,  1.6723e-01, -1.8104e-01, -2.1264e-01,\n          1.4930e-01, -2.4421e-02, -1.9292e-01,  1.0928e-03, -9.2955e-02,\n          4.8975e-02,  7.0539e-02, -1.7038e-01, -8.8061e-02, -6.6121e-02,\n         -1.3444e-01,  4.5166e-02,  2.7096e-02,  1.5482e-01,  1.7946e-01],\n        [ 1.3995e-01,  2.0926e-01,  1.9626e-01,  1.5982e-01, -1.9769e-01,\n          1.5521e-01,  9.4018e-02, -2.0509e-01, -5.6600e-02, -3.3581e-02,\n         -1.5591e-01,  1.9102e-01, -2.0470e-01, -6.4176e-02, -2.0560e-01,\n         -9.9454e-02,  2.1471e-01, -1.0828e-01, -2.0758e-01,  2.1070e-01],\n        [ 9.2392e-02, -1.0018e-01,  5.7314e-03, -2.5933e-02, -2.0735e-01,\n         -5.6635e-02,  7.3635e-02,  7.8928e-02, -2.2043e-01,  1.6319e-01,\n         -1.7513e-01, -6.2252e-02,  1.0390e-01,  1.5875e-01, -8.4913e-02,\n         -1.2636e-01, -1.3786e-01, -1.1745e-01, -7.3355e-02, -1.8483e-01],\n        [ 1.0222e-01,  1.9617e-01, -2.2815e-02, -1.8001e-01, -2.2251e-01,\n          6.2484e-02,  2.1954e-01,  2.6252e-02, -1.1039e-02,  1.8952e-01,\n          6.4759e-03,  1.8558e-01, -9.9589e-02, -1.3821e-01,  4.1336e-02,\n         -1.2660e-01,  1.8779e-01,  2.2129e-01, -1.0523e-01,  9.4190e-02],\n        [-1.2844e-01, -1.2538e-01,  1.9457e-02,  7.7786e-02,  1.8447e-01,\n          1.5797e-01, -2.3419e-02,  1.7587e-01, -4.2815e-02, -2.4629e-02,\n          1.1298e-01, -9.2232e-02,  7.1908e-02,  1.5147e-01,  5.1975e-02,\n         -5.1219e-02, -5.8357e-02,  1.0187e-01, -3.3509e-02, -1.7198e-01],\n        [-2.2112e-01, -6.9515e-02,  2.1094e-01, -1.5878e-01,  1.3116e-01,\n         -7.3657e-03,  4.8446e-02,  1.7323e-01,  2.8846e-02,  1.8214e-01,\n         -1.8152e-01,  9.9616e-03, -8.7738e-02,  1.8907e-01,  5.4683e-02,\n          2.0305e-01, -1.4876e-01,  3.4663e-03,  1.7495e-01, -9.0044e-02],\n        [-5.8775e-02,  6.6184e-02, -2.0895e-01, -1.8733e-01, -2.2305e-02,\n         -1.1086e-02, -1.9581e-01, -1.0945e-01,  1.3108e-01,  1.7751e-01,\n         -7.9935e-02, -7.3509e-02,  1.5973e-01,  2.1696e-01, -2.3812e-02,\n         -9.0710e-02,  1.7483e-01,  1.5047e-02,  1.1712e-01, -2.0456e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1651,  0.1662,  0.0630, -0.0569,  0.2116,  0.1908,  0.1799,  0.0239,\n        -0.1018, -0.2090, -0.0458, -0.1459, -0.0093, -0.2206, -0.0712,  0.0156,\n         0.0390,  0.0771, -0.1376, -0.0795, -0.0953,  0.0842, -0.0757,  0.0259,\n        -0.0480, -0.1879,  0.1700, -0.0414,  0.0601,  0.1496,  0.0517, -0.1675],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0892, -0.1294,  0.0242,  0.0079, -0.1209, -0.1116,  0.0382, -0.1405,\n          0.0104,  0.0791,  0.0311, -0.0622,  0.0529,  0.0329, -0.0977,  0.0144,\n         -0.0506,  0.1505,  0.0147,  0.0154,  0.0660, -0.0991,  0.1172,  0.0566,\n         -0.1242, -0.1143,  0.0963,  0.0856,  0.1067,  0.1711, -0.1013, -0.0273],\n        [-0.1325,  0.0052,  0.0771, -0.0300,  0.1690,  0.1710,  0.1410,  0.0980,\n         -0.0574, -0.0926, -0.0795,  0.0370,  0.0735, -0.1544,  0.0010,  0.1382,\n          0.0021,  0.0022, -0.1560,  0.0234,  0.0118, -0.1416, -0.0487,  0.0038,\n          0.0887,  0.0584, -0.0988,  0.1102,  0.1693,  0.1578, -0.1123,  0.1569],\n        [ 0.0513,  0.1461, -0.0201, -0.0407, -0.1366, -0.0095, -0.0638,  0.1292,\n          0.1735, -0.1152, -0.1177, -0.1003, -0.0726,  0.1414, -0.1707,  0.0364,\n          0.0994, -0.0517, -0.1751, -0.1345,  0.0652, -0.1061, -0.0656, -0.0431,\n         -0.1653, -0.0087,  0.0483,  0.1413,  0.0873, -0.1022, -0.0204,  0.0679],\n        [-0.0071,  0.0550,  0.1673, -0.0372,  0.1218,  0.0991,  0.1564, -0.0771,\n          0.0895, -0.0322,  0.0621,  0.1457, -0.0673,  0.1711,  0.1317,  0.0349,\n         -0.1603,  0.0602,  0.1309, -0.1116, -0.1505, -0.0762,  0.1756, -0.1401,\n         -0.0049,  0.0258,  0.1486,  0.1566,  0.0356, -0.0327,  0.1470,  0.1098],\n        [-0.0704, -0.1161, -0.0360,  0.1137,  0.1212, -0.0524,  0.1064, -0.0707,\n          0.0516,  0.1282,  0.1043, -0.0110, -0.0737,  0.0022,  0.1011, -0.1288,\n          0.0729,  0.0712, -0.1627,  0.0878,  0.0767, -0.0145, -0.0422,  0.1502,\n          0.0244, -0.0005, -0.0525, -0.1108,  0.0678, -0.1766,  0.0008, -0.0749],\n        [-0.1683,  0.0302, -0.0569,  0.0836,  0.1759,  0.1033,  0.0686, -0.0945,\n          0.0858, -0.0038,  0.0390,  0.0459,  0.1407,  0.0330,  0.1326,  0.0615,\n         -0.1036, -0.1152, -0.0920,  0.0473,  0.1058,  0.1166,  0.1569, -0.0761,\n          0.0923,  0.1362, -0.1319, -0.0223,  0.0182,  0.1473,  0.0353,  0.1148],\n        [ 0.0666,  0.0500, -0.0927, -0.0835,  0.0496,  0.0401, -0.1341,  0.0450,\n         -0.0841, -0.0221, -0.0043,  0.0922,  0.0709,  0.0016,  0.1654, -0.0572,\n          0.1363, -0.1195, -0.0253, -0.0306, -0.0303, -0.0167, -0.1722, -0.1108,\n          0.1184,  0.1361,  0.0650, -0.0315, -0.0221,  0.0438,  0.1258,  0.1049],\n        [ 0.0311,  0.0644,  0.0973,  0.0590,  0.0195, -0.0534,  0.0536, -0.1404,\n          0.1322, -0.0454, -0.1517, -0.1701,  0.0787,  0.0084,  0.1232,  0.1560,\n         -0.0189,  0.1327, -0.0089,  0.0863,  0.0606, -0.0804,  0.0506, -0.0876,\n         -0.1083,  0.1286,  0.0065, -0.1733,  0.1233, -0.0264, -0.0460, -0.0251],\n        [-0.0881,  0.1332, -0.1675,  0.1708,  0.1534,  0.1047,  0.0294,  0.0541,\n          0.1616, -0.1135,  0.1011,  0.0506,  0.1551, -0.1753,  0.1629, -0.0379,\n         -0.0410,  0.0360,  0.1697, -0.1534,  0.0272, -0.1017, -0.0544,  0.0929,\n         -0.1172, -0.1526, -0.0153, -0.0999, -0.1047, -0.1418,  0.0616,  0.0485],\n        [-0.0550, -0.1531,  0.0646,  0.0757, -0.1610, -0.1718, -0.0263,  0.1681,\n         -0.0026, -0.0235, -0.0732,  0.1271, -0.0778, -0.0586, -0.0252,  0.1381,\n          0.0011, -0.0647, -0.0518, -0.1455,  0.0939,  0.0061, -0.0850, -0.0919,\n          0.0635,  0.1187, -0.1080,  0.0366,  0.0919,  0.1535,  0.1017,  0.1117],\n        [ 0.1553, -0.0604, -0.0089,  0.1607,  0.0782,  0.0278,  0.1446,  0.1641,\n         -0.0981, -0.0907, -0.0736,  0.0043, -0.1653,  0.0618, -0.1304, -0.0706,\n          0.1421,  0.1010, -0.1301,  0.1609, -0.0645,  0.0485, -0.0977,  0.1344,\n          0.0959,  0.0253, -0.1243, -0.0931,  0.0482, -0.0475, -0.0296, -0.1609],\n        [ 0.1234,  0.1650,  0.1293, -0.0078, -0.0627,  0.1182,  0.1326,  0.0666,\n          0.0995,  0.1254, -0.1491, -0.1237,  0.1752,  0.1277, -0.0506,  0.0557,\n         -0.0565,  0.0400, -0.0294,  0.1438,  0.1028,  0.0883, -0.0593, -0.0718,\n         -0.1350, -0.1437, -0.0306,  0.1708,  0.1531,  0.1198,  0.1721, -0.0897],\n        [ 0.1650, -0.1168, -0.1482,  0.1164,  0.1245, -0.1649,  0.1226, -0.1515,\n         -0.1297,  0.0161,  0.1188,  0.1114, -0.0408, -0.1287,  0.1175,  0.1644,\n          0.1045,  0.1126,  0.1278,  0.0407,  0.0425, -0.1754,  0.1377, -0.1735,\n         -0.0102, -0.0250, -0.0390, -0.1075,  0.1213,  0.0550, -0.1225,  0.0521],\n        [ 0.0472, -0.0057, -0.0289,  0.1339,  0.0381,  0.0960,  0.1165,  0.0447,\n          0.1150,  0.0327, -0.1029,  0.0042, -0.1497, -0.0617,  0.1484, -0.1708,\n         -0.1144, -0.0751,  0.0962,  0.0092, -0.0322, -0.1388, -0.0202, -0.1224,\n         -0.0829, -0.0221, -0.1373,  0.1597,  0.0563,  0.1442, -0.0485, -0.1139],\n        [-0.0860, -0.1468,  0.1665,  0.1180,  0.1578, -0.0825,  0.0483, -0.0855,\n          0.1623,  0.1488, -0.0801, -0.0221, -0.1214,  0.0450, -0.1194,  0.0308,\n         -0.1707, -0.1218,  0.1568, -0.0564,  0.0658,  0.1195,  0.0093, -0.1724,\n         -0.1767,  0.1741,  0.1452, -0.0239,  0.0193, -0.1649,  0.1301,  0.0148],\n        [ 0.1271, -0.0235,  0.0933,  0.0089,  0.1584, -0.1053,  0.1225, -0.0895,\n         -0.1182,  0.1738,  0.1097,  0.0458, -0.0056,  0.0172, -0.0505,  0.0143,\n         -0.1703, -0.0607, -0.1413,  0.0905,  0.1527,  0.0394,  0.0066, -0.0083,\n         -0.1402,  0.0622, -0.0720, -0.0570,  0.0490,  0.0105, -0.0083, -0.0260]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1183,  0.1735,  0.0696,  0.0699,  0.1223,  0.1400, -0.1512, -0.1709,\n         0.1572,  0.0677, -0.1037, -0.1206, -0.0192,  0.1251,  0.1283,  0.0251],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1649, -0.1472,  0.0239,  0.0786,  0.2230, -0.0735,  0.1192,  0.1569,\n         -0.0294,  0.1644,  0.2281, -0.1364, -0.1994,  0.1042,  0.0427, -0.2400],\n        [ 0.2061,  0.0682, -0.1714,  0.1524, -0.1858, -0.1563,  0.0876, -0.0546,\n          0.1808, -0.1028,  0.2117,  0.2117,  0.0213,  0.0542,  0.1302, -0.0793],\n        [-0.2237, -0.0425, -0.2084,  0.1410, -0.1328, -0.2090,  0.1892,  0.0298,\n         -0.1004, -0.2171,  0.1854, -0.0240,  0.0423,  0.1611, -0.0119,  0.0319],\n        [ 0.0492, -0.1049,  0.0951,  0.0113, -0.0204, -0.1232, -0.0551, -0.0191,\n          0.0920,  0.0295,  0.2495, -0.1426,  0.0568, -0.1141,  0.2434,  0.2220],\n        [-0.2144, -0.0527,  0.1487, -0.1062,  0.1028, -0.0945, -0.1790,  0.2467,\n          0.1689,  0.1599,  0.2271, -0.0903, -0.2287,  0.0974,  0.1560, -0.1469],\n        [-0.1976, -0.1666, -0.0124, -0.2037, -0.0274,  0.2114,  0.0176,  0.2495,\n          0.1371, -0.0333, -0.2386,  0.2265, -0.0378, -0.1286, -0.1863, -0.2428],\n        [-0.1800, -0.0309,  0.1736, -0.2447, -0.2026,  0.0670,  0.2428,  0.0785,\n          0.1836, -0.1462, -0.2114,  0.1649,  0.2333,  0.1745,  0.0554, -0.0621],\n        [ 0.2255, -0.1108,  0.2488, -0.0789,  0.1157,  0.2378,  0.1469, -0.1827,\n         -0.1880,  0.0888,  0.0052, -0.1136, -0.0608, -0.0558, -0.0738,  0.0645]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1095,  0.0119,  0.0743, -0.1559, -0.1601, -0.1421,  0.1013, -0.0749],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3281, -0.0477, -0.1645, -0.0075,  0.3129,  0.2634, -0.0392,  0.2477]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0451], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x000001C7EC09F820>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001C7EB44E860>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-dqn-info\\rl4sys-dqn-info_s53840000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='D:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\maze-game\\\\./logs/rl4sys-dqn-info\\\\rl4sys-dqn-info_s53840000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}