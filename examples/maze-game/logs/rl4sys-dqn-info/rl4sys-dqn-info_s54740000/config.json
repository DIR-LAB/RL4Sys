{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s54740000"
    },
    "q_lr":	0.0005,
    "seed":	54740000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x11c63cc40>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0880,  0.0567,  0.2097,  0.1312, -0.1595,  0.1467,  0.2106,  0.0161,\n         0.1545,  0.1808, -0.0464,  0.1508,  0.0716,  0.1144, -0.0141, -0.1258,\n         0.0063, -0.0868,  0.1003, -0.1824, -0.0225, -0.1511, -0.0503,  0.0474,\n         0.0824,  0.1644,  0.1465, -0.0867, -0.1744, -0.0882,  0.1271, -0.1567],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0132,  0.2073, -0.0574,  0.2086,  0.1986, -0.1310,  0.2145, -0.2116,\n         -0.0848, -0.2051, -0.1355,  0.1964, -0.0498,  0.1654, -0.2159, -0.0567,\n         -0.2185,  0.2200, -0.0599, -0.1189],\n        [-0.0523,  0.1569, -0.1465,  0.2032,  0.1433, -0.0699, -0.0003,  0.1301,\n         -0.0047,  0.1838, -0.0360, -0.1883,  0.1310, -0.0478,  0.1205,  0.1890,\n         -0.1581,  0.0364, -0.1867,  0.0424],\n        [-0.0787, -0.1274,  0.1804, -0.0401,  0.1550, -0.1698,  0.0983,  0.1153,\n         -0.1961,  0.2107, -0.0019,  0.1082, -0.0421, -0.1946,  0.0446, -0.1699,\n         -0.0448,  0.1703, -0.1723,  0.1318],\n        [-0.1084, -0.0386, -0.1555,  0.1301,  0.0511,  0.2002, -0.1920, -0.0515,\n         -0.0618, -0.0575,  0.1629,  0.0012, -0.2100, -0.0350, -0.0787, -0.0035,\n         -0.0040, -0.0534,  0.0963,  0.1966],\n        [ 0.0431, -0.1374, -0.0914,  0.0298,  0.1077,  0.0155, -0.2143,  0.2226,\n         -0.0695,  0.0210,  0.1252, -0.0630, -0.0469,  0.1692, -0.2111, -0.1472,\n          0.1701,  0.1471,  0.2188, -0.0231],\n        [ 0.1557,  0.0042,  0.1174,  0.1368,  0.1985, -0.0555, -0.0737,  0.1599,\n          0.0072,  0.2072,  0.2041,  0.1515,  0.1218,  0.2010,  0.0579, -0.1516,\n         -0.1168,  0.0808,  0.0355,  0.0321],\n        [-0.1900, -0.2058,  0.0528, -0.0236,  0.0719,  0.1853, -0.2164, -0.1080,\n          0.0885,  0.0998, -0.1298,  0.1264, -0.1719,  0.0977,  0.1348, -0.0215,\n         -0.0472, -0.0087, -0.0024,  0.1939],\n        [ 0.0981,  0.1039,  0.1722, -0.0027,  0.1779,  0.0962, -0.0643,  0.1576,\n          0.1872, -0.1269,  0.1244, -0.0197, -0.0477, -0.0576,  0.0272, -0.0886,\n         -0.1326, -0.2220,  0.1308,  0.0513],\n        [-0.0368,  0.1886,  0.0018,  0.2230,  0.1062, -0.1391,  0.0479, -0.0446,\n         -0.1721,  0.1001, -0.1856, -0.0051,  0.0482, -0.1860,  0.1560, -0.2127,\n         -0.0647,  0.1156,  0.0803,  0.1819],\n        [-0.1996,  0.1943,  0.1916, -0.0103,  0.0377, -0.1990, -0.0781, -0.0882,\n         -0.0344,  0.1170,  0.0981,  0.1443,  0.0406,  0.0868,  0.1652, -0.0218,\n          0.1136,  0.0170, -0.2235, -0.0883],\n        [-0.0220, -0.0952,  0.0685,  0.1675,  0.2046,  0.1429, -0.1363, -0.0209,\n         -0.0808, -0.0892, -0.0566,  0.1100,  0.1209, -0.1914,  0.1166, -0.1595,\n          0.0608,  0.1486, -0.1748, -0.0677],\n        [ 0.1250,  0.0981, -0.1408,  0.0112, -0.0218,  0.0157, -0.1962,  0.1262,\n          0.1287,  0.1550, -0.1564, -0.0068, -0.2169,  0.0244, -0.0915, -0.0723,\n          0.1472, -0.0614, -0.1267, -0.0505],\n        [-0.2138,  0.1174,  0.1575,  0.1971, -0.1232, -0.0329,  0.0279, -0.2098,\n         -0.1263,  0.0409,  0.0990,  0.1336, -0.1850,  0.2137, -0.1762,  0.0504,\n         -0.0886, -0.0983, -0.1889,  0.0034],\n        [ 0.0975,  0.0544,  0.0673, -0.0417,  0.2217,  0.1260, -0.0272,  0.0662,\n          0.1636,  0.0868,  0.0649,  0.0152,  0.0520,  0.1324,  0.0830, -0.0388,\n         -0.0029, -0.1546, -0.1453,  0.1435],\n        [ 0.0272,  0.0202,  0.0817,  0.1484,  0.0303, -0.1819,  0.0522,  0.2008,\n         -0.2112,  0.1741,  0.1627, -0.0434, -0.0651, -0.1809,  0.0022, -0.1814,\n          0.2082, -0.1514, -0.2108,  0.1466],\n        [-0.1122, -0.0818, -0.1203,  0.1629,  0.1540,  0.0699, -0.1114, -0.0610,\n         -0.1392,  0.1908, -0.0532,  0.1320, -0.1243,  0.0843,  0.0354, -0.1262,\n          0.0898,  0.2025,  0.0534, -0.1929],\n        [ 0.1233, -0.1412,  0.0962, -0.1204,  0.0131, -0.1135, -0.1393,  0.1707,\n          0.0071,  0.1954,  0.1526,  0.0357,  0.1346,  0.1718, -0.2139, -0.1843,\n          0.0891, -0.2145, -0.1804, -0.0485],\n        [ 0.0760,  0.0022,  0.1708,  0.2057, -0.0754, -0.1344,  0.0126, -0.1322,\n          0.1269, -0.1812,  0.1219, -0.1521, -0.1061, -0.0235, -0.0826, -0.1727,\n         -0.0788,  0.0128,  0.2133, -0.0954],\n        [-0.1225,  0.1881,  0.1410, -0.1628, -0.0161, -0.1532,  0.0922, -0.0708,\n          0.0025,  0.1855, -0.0953,  0.2057,  0.1236, -0.0534,  0.0382, -0.1168,\n         -0.1067, -0.0740, -0.2095,  0.1416],\n        [ 0.1150,  0.1839, -0.0254, -0.0668, -0.0417,  0.0879,  0.0332,  0.1267,\n         -0.0576,  0.1745, -0.0927,  0.1333,  0.1596,  0.0448,  0.1831,  0.1023,\n          0.2235,  0.0216,  0.1988, -0.1301],\n        [-0.0025, -0.1506,  0.1152,  0.0866, -0.1536, -0.0467, -0.0215,  0.0261,\n          0.1088,  0.1921,  0.0750, -0.0513, -0.2098,  0.2065, -0.1169, -0.1625,\n          0.1877, -0.1706,  0.0984,  0.0951],\n        [ 0.0033, -0.1747,  0.2113,  0.1372,  0.0807,  0.0609, -0.0887, -0.1301,\n          0.0328,  0.2074, -0.0806,  0.0895, -0.0630, -0.2101, -0.0034,  0.0898,\n         -0.1608,  0.0921, -0.2012, -0.1675],\n        [ 0.0271,  0.1963, -0.1013, -0.0758, -0.1723,  0.1635, -0.0668,  0.1321,\n         -0.0954, -0.0622,  0.1535,  0.0643, -0.2227, -0.1436, -0.2001,  0.0971,\n          0.1117, -0.1792,  0.1513,  0.0033],\n        [ 0.0793,  0.1077, -0.2036, -0.0649,  0.2036, -0.2062,  0.0907,  0.0963,\n         -0.1897, -0.1109,  0.1242, -0.0375,  0.0534,  0.0394,  0.0590,  0.0868,\n          0.0018,  0.2200, -0.0383, -0.1298],\n        [-0.0597, -0.0213, -0.1401,  0.1136, -0.1994,  0.1080,  0.0499, -0.1442,\n          0.1020,  0.0518, -0.0699,  0.0192, -0.0156,  0.1173,  0.0645,  0.0471,\n         -0.0673, -0.0417, -0.1018, -0.1688],\n        [ 0.1412, -0.0074, -0.1681,  0.0580,  0.0902,  0.2106,  0.1871, -0.1135,\n         -0.2032,  0.0116,  0.0357, -0.2064,  0.0718, -0.1962, -0.0476,  0.1353,\n          0.1074,  0.0328,  0.0947, -0.0850],\n        [ 0.1835, -0.1515, -0.1088, -0.0412, -0.1252, -0.0866, -0.2192,  0.0956,\n         -0.0085, -0.1511,  0.0943,  0.0528, -0.0084, -0.1953,  0.1481,  0.0779,\n          0.2094, -0.1468, -0.1773, -0.0286],\n        [-0.1956,  0.0054, -0.2186, -0.0796, -0.0984, -0.0789, -0.0101,  0.0126,\n          0.1001, -0.1709, -0.1443,  0.1314,  0.0139, -0.0251,  0.2140,  0.1520,\n         -0.0161, -0.1202,  0.0432, -0.1093],\n        [ 0.1319, -0.0129,  0.1889,  0.0119, -0.1190,  0.0520, -0.0287,  0.1884,\n         -0.1945,  0.0405,  0.0900,  0.0520, -0.1277,  0.0591,  0.0673, -0.1541,\n         -0.0249,  0.1286,  0.1328, -0.1317],\n        [ 0.1190, -0.0723,  0.0438,  0.2096,  0.2192, -0.1635,  0.0178,  0.1600,\n          0.1561, -0.0962, -0.1169, -0.0831, -0.1602, -0.1387,  0.0040,  0.1831,\n          0.0945, -0.0045,  0.1778, -0.0066],\n        [ 0.0189, -0.0796,  0.0259,  0.2229,  0.0556, -0.0736, -0.0508, -0.1329,\n          0.0192, -0.0707,  0.0746,  0.1147,  0.1171, -0.0144,  0.1381,  0.1547,\n         -0.2049,  0.0789, -0.1157, -0.1761],\n        [ 0.2137, -0.1436,  0.0841,  0.1670, -0.0161,  0.1448,  0.2171, -0.2236,\n         -0.1043,  0.0142,  0.2183,  0.0636,  0.1792, -0.0046,  0.1448,  0.0094,\n          0.1294, -0.1023,  0.0035,  0.0486]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1652,  0.0054,  0.0881, -0.1040, -0.1315,  0.0306, -0.1610,  0.1338,\n         0.0065,  0.0327,  0.0357, -0.0335,  0.0568, -0.1575, -0.1514, -0.0233],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-3.3188e-02,  2.0591e-02, -8.7802e-03,  3.8746e-02, -4.2968e-02,\n          5.1132e-02,  1.5270e-01, -1.5583e-01, -1.5448e-01,  9.6050e-02,\n         -1.5501e-01,  1.6833e-01,  1.7615e-01, -1.5212e-01, -1.6681e-01,\n          1.7066e-01,  9.9154e-02,  3.5003e-02,  4.2337e-02, -3.8908e-02,\n         -8.3586e-03,  5.7935e-03,  1.5951e-02,  1.0058e-01,  3.8370e-02,\n         -1.4971e-01, -1.3451e-01,  1.6504e-01,  7.1236e-02,  9.2151e-02,\n         -1.0728e-01, -1.0199e-01],\n        [-1.1264e-01, -1.6813e-01, -8.5347e-02,  1.2351e-01, -1.0012e-02,\n          1.2141e-01, -1.8292e-02, -1.6058e-01,  3.2756e-02, -4.9301e-02,\n          1.0156e-01,  3.9947e-02, -1.0592e-02,  1.3222e-01, -1.2336e-01,\n          9.0050e-02, -1.6177e-02,  8.3146e-03,  1.1181e-01,  1.3939e-02,\n         -3.7821e-02, -1.6653e-01,  1.0018e-01,  1.1440e-01, -7.3013e-02,\n         -3.5783e-02, -1.4239e-01, -1.1397e-01,  9.0997e-02, -1.1389e-01,\n         -1.6164e-01,  1.1243e-01],\n        [-1.0299e-01,  7.2029e-02, -1.4973e-01,  5.0677e-02, -1.7500e-01,\n         -6.9628e-02,  1.6978e-01, -1.7526e-01,  1.7427e-02,  1.2130e-01,\n          2.3350e-02, -9.8134e-02, -1.5989e-01,  8.5470e-02, -1.6044e-02,\n          1.6811e-02,  1.0191e-01,  6.4090e-03, -5.9135e-02, -1.1985e-01,\n          1.1102e-01, -1.4010e-01, -7.8219e-02, -1.1606e-01, -1.3568e-01,\n         -1.6850e-01,  1.9419e-02, -7.5862e-02, -9.7990e-02, -1.2057e-01,\n          5.9106e-02,  1.5114e-01],\n        [ 5.2226e-03,  5.0160e-02, -1.1908e-01, -8.5516e-02,  1.3229e-01,\n          1.2538e-01, -2.7513e-03,  1.4385e-01,  5.8612e-02,  1.1155e-01,\n         -1.0664e-01,  1.6899e-02, -4.5769e-02, -1.6814e-01,  5.0428e-02,\n         -1.4782e-01,  3.0753e-02, -1.3773e-01, -9.8089e-02, -9.0577e-02,\n         -1.6423e-01, -3.3471e-02,  8.5789e-02, -8.9391e-02, -1.7231e-01,\n          7.4427e-02,  9.7401e-02,  1.6726e-01, -1.0750e-01, -7.2400e-02,\n         -7.1581e-02, -1.6881e-01],\n        [ 1.3848e-01, -1.5251e-01,  6.9497e-02, -1.7463e-01, -6.8567e-02,\n          4.5674e-02, -1.3894e-01,  2.3003e-02, -1.3494e-01, -7.9214e-03,\n         -7.8997e-02,  7.1255e-02, -1.8463e-02, -8.9439e-02, -1.3332e-02,\n         -4.3171e-02, -1.7208e-01,  5.6005e-02,  1.2229e-01,  1.4426e-01,\n         -9.5425e-04,  1.9243e-02,  1.2212e-01, -1.4835e-01, -1.7170e-01,\n         -3.0323e-03,  1.1600e-01, -1.0966e-01,  1.5369e-01, -8.5417e-02,\n         -5.0913e-02,  4.5889e-02],\n        [-9.5576e-02,  1.2009e-01, -6.4134e-02, -8.7342e-02, -8.1151e-02,\n          1.1472e-01,  1.0970e-01, -1.1177e-01,  8.8739e-02,  1.0199e-01,\n          6.7246e-02,  1.3128e-02,  1.5773e-02, -1.4620e-01, -6.5484e-02,\n          6.3424e-02, -7.1432e-02,  6.8316e-03,  1.7227e-02, -1.4713e-01,\n          9.8265e-02,  3.5248e-02, -4.9282e-02,  1.5082e-01,  2.3876e-02,\n         -6.1759e-02, -1.2669e-01, -4.9713e-02,  6.4349e-02, -4.7835e-02,\n          1.6921e-01, -2.6323e-02],\n        [ 5.7226e-02,  1.4542e-01,  9.0369e-02, -7.1986e-02,  1.6704e-01,\n          2.4869e-02,  9.5362e-02,  1.1011e-02, -1.4789e-01,  9.3133e-02,\n         -1.4017e-01,  9.4445e-02, -1.2658e-01, -4.9495e-02, -1.2890e-01,\n         -7.2023e-03, -1.3281e-01,  1.4053e-01, -1.1911e-01, -9.6142e-02,\n         -1.6477e-01, -8.5301e-02,  1.4109e-01,  1.6490e-01, -9.7538e-02,\n         -1.3338e-01, -3.6855e-02,  1.3007e-04, -4.8676e-02, -1.5496e-01,\n          9.4915e-02, -5.6720e-02],\n        [ 1.1404e-02,  6.9273e-02, -1.4560e-01, -1.1642e-01, -5.2199e-02,\n          7.8865e-02,  1.5291e-01, -4.8013e-02, -7.6011e-02, -1.7464e-03,\n          1.0898e-01,  5.0733e-02,  1.2633e-02,  5.7837e-02,  9.7105e-02,\n         -1.3292e-01,  2.7501e-02, -1.0066e-01, -1.6275e-01, -3.3850e-02,\n          1.5760e-01, -6.2212e-02, -9.7648e-03,  1.7553e-01,  7.5570e-02,\n          3.2383e-03,  6.2560e-02,  5.8186e-02, -3.2416e-02, -8.5579e-02,\n          1.7164e-01, -1.4460e-02],\n        [-9.1698e-02,  1.7650e-01,  4.8464e-02, -3.9829e-02,  4.0476e-02,\n         -1.5033e-01, -7.0894e-02,  1.5693e-01, -8.7030e-02, -1.5159e-02,\n         -8.9956e-04, -1.6720e-01,  8.9177e-02, -1.1051e-01, -8.6027e-02,\n         -1.0688e-02, -1.0924e-01,  7.1626e-02,  1.5417e-01, -1.7640e-01,\n         -4.2601e-02, -6.6653e-02,  4.6080e-02, -9.4703e-02,  3.1954e-02,\n         -1.3622e-01, -1.8433e-02, -1.1240e-01,  1.0293e-01,  7.2562e-02,\n         -1.0095e-01,  9.1767e-02],\n        [ 9.3214e-02,  1.1296e-01,  6.2484e-02, -9.2080e-02, -7.1297e-03,\n         -1.1851e-01,  6.5613e-03,  1.0067e-01,  4.3912e-02, -1.5947e-01,\n          6.5181e-02, -1.6641e-01, -6.5069e-02,  1.1465e-01,  2.3078e-02,\n          2.0762e-02,  1.0879e-01, -1.6718e-01, -5.7367e-02, -1.6450e-01,\n         -1.7875e-02,  1.0203e-01,  1.6932e-01,  1.3259e-01,  4.9310e-02,\n          1.1941e-01,  1.5749e-01, -1.4051e-01,  5.4308e-02, -1.5171e-01,\n          5.3341e-02,  1.6516e-01],\n        [-1.6905e-01,  8.9633e-02,  1.3456e-02, -5.5168e-02,  1.6131e-01,\n          1.0873e-01,  5.0107e-02,  3.8832e-02, -5.8129e-02, -1.0233e-01,\n         -4.8411e-02,  1.6300e-02, -1.4669e-01,  7.2391e-02, -1.0525e-01,\n          7.3254e-02,  1.0821e-01, -8.8221e-02, -7.4594e-03,  3.2393e-03,\n          1.6415e-01,  1.6488e-01, -9.3875e-02,  1.0243e-02, -1.8431e-02,\n          1.5004e-01,  1.6179e-01,  3.1849e-02,  1.5436e-01,  1.5784e-01,\n         -9.6839e-02,  1.5233e-01],\n        [-1.1091e-02, -5.9668e-03,  1.4135e-01, -4.2875e-02, -2.4728e-02,\n         -1.2963e-01,  1.7569e-02, -1.7653e-01, -1.5311e-01, -8.1803e-03,\n          2.6278e-02, -1.3608e-01, -1.1242e-02, -1.1731e-01, -1.3267e-01,\n          8.1053e-02, -4.5235e-03,  6.9141e-02, -7.8147e-03,  4.7429e-02,\n         -8.8160e-02, -7.4962e-03, -1.2876e-01,  4.9608e-02,  1.4071e-01,\n         -4.6276e-02,  1.1415e-01,  1.2216e-01, -5.4571e-02,  1.5294e-01,\n         -1.6556e-01,  2.4618e-02],\n        [-1.0230e-01,  1.0180e-01, -5.1751e-02,  1.1043e-01, -1.0305e-01,\n          4.8024e-02,  5.1162e-02, -7.2178e-02, -1.1515e-01, -4.9719e-02,\n         -2.9755e-02,  1.7474e-01,  1.6803e-01, -1.7467e-01,  1.9479e-02,\n          1.7417e-01,  1.3553e-01,  5.5579e-02,  1.5407e-01,  5.9090e-02,\n         -1.5911e-01,  1.2335e-01,  1.5573e-01, -1.6305e-01,  9.0141e-02,\n         -6.0189e-02, -1.2853e-01,  1.1758e-01, -5.0250e-02,  1.5459e-01,\n          1.5204e-01,  8.0388e-03],\n        [-1.2258e-01, -9.8576e-02,  1.8923e-03, -5.9724e-02, -9.5927e-02,\n         -1.4734e-01,  1.1306e-01, -5.1322e-02,  8.9085e-02, -6.0440e-02,\n          4.6115e-02,  1.7623e-01, -1.4689e-01, -1.4366e-01, -3.5733e-02,\n         -9.1445e-02, -3.6153e-02,  1.5093e-01, -2.4375e-02, -1.2342e-01,\n          1.5237e-01, -1.2211e-01,  1.4865e-01,  1.0769e-01, -7.2792e-02,\n          8.5461e-02, -7.4997e-02,  8.9197e-02,  3.6495e-02,  2.1157e-02,\n          1.1810e-02, -6.2504e-02],\n        [ 1.3616e-01, -3.1599e-02,  4.1432e-02,  3.2048e-02, -1.6947e-01,\n          6.7117e-02,  1.7006e-01, -5.7993e-02,  1.2004e-02,  9.6837e-02,\n         -6.3412e-02, -7.5288e-02,  9.1765e-03, -8.4402e-02,  3.1882e-03,\n         -2.5665e-02,  9.0680e-02, -6.7160e-02,  1.3880e-01, -9.1034e-03,\n         -1.0995e-01,  6.0014e-02,  4.0186e-02,  1.1450e-01,  5.9369e-02,\n          9.4225e-03,  2.2377e-03, -7.8515e-02,  4.1444e-02,  2.4987e-02,\n         -1.0868e-01, -1.6224e-01],\n        [ 9.4856e-02, -1.7565e-01, -4.9048e-02, -1.0011e-01, -1.0120e-01,\n         -1.3472e-01, -1.3845e-01,  1.6461e-01,  1.5195e-01,  5.2929e-02,\n          6.8625e-02, -1.0382e-02, -4.8783e-02,  1.5258e-01, -1.4461e-01,\n          1.7551e-01, -4.8889e-02,  5.7946e-02,  9.8555e-03,  5.8155e-02,\n          3.9626e-02,  1.1022e-01,  2.5522e-02, -1.3878e-01, -1.4424e-01,\n         -1.3319e-02, -1.4898e-02, -1.0825e-01,  3.3249e-02, -6.0466e-02,\n          6.8282e-02, -1.3146e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0920, -0.2336, -0.1002, -0.2196, -0.2473,  0.0158,  0.1147,  0.2017],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1646, -0.0519,  0.0220,  0.0862,  0.1761, -0.1953, -0.0187,  0.0744,\n         -0.0164, -0.0070,  0.1839,  0.1421, -0.1358, -0.1433,  0.0614, -0.0662],\n        [ 0.1906,  0.1501, -0.0847,  0.0041,  0.2304, -0.0191,  0.0079, -0.1112,\n          0.2333, -0.0945, -0.1415,  0.2431, -0.0127, -0.2106, -0.0647, -0.2133],\n        [-0.1964, -0.1719, -0.0480,  0.1787, -0.1962,  0.2296, -0.1982, -0.0808,\n         -0.1217, -0.2163, -0.0193,  0.1737,  0.0818,  0.1031,  0.0467,  0.1958],\n        [-0.1346,  0.0254,  0.0489, -0.0300,  0.1226,  0.0495, -0.1530,  0.0157,\n          0.0054,  0.0658, -0.1808,  0.1541,  0.1306,  0.1162, -0.1506, -0.1169],\n        [-0.1846,  0.0038,  0.0166,  0.0857, -0.0129, -0.1503, -0.2338, -0.0826,\n         -0.0750, -0.0349, -0.1593,  0.1804,  0.0173, -0.1374,  0.0707,  0.0148],\n        [ 0.1616,  0.1069, -0.1530, -0.1653, -0.0823,  0.2441,  0.2396,  0.1948,\n          0.2439,  0.1803, -0.1493, -0.0957, -0.0167, -0.2345,  0.0517, -0.1622],\n        [-0.0633, -0.1819, -0.1255,  0.2411,  0.1868,  0.2090, -0.2124, -0.0517,\n         -0.1068,  0.1943, -0.2024,  0.2032, -0.2488, -0.1315,  0.0852, -0.1301],\n        [ 0.0967,  0.1275, -0.1609, -0.0348,  0.0362,  0.1116, -0.0223, -0.0801,\n         -0.1340,  0.0539, -0.0226,  0.0941, -0.1849,  0.1932, -0.2023,  0.2120]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2499], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1271, -0.3101, -0.2449, -0.2215, -0.2751,  0.0247, -0.1911, -0.2927]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0132,  0.2073, -0.0574,  0.2086,  0.1986, -0.1310,  0.2145, -0.2116,\n         -0.0848, -0.2051, -0.1355,  0.1964, -0.0498,  0.1654, -0.2159, -0.0567,\n         -0.2185,  0.2200, -0.0599, -0.1189],\n        [-0.0523,  0.1569, -0.1465,  0.2032,  0.1433, -0.0699, -0.0003,  0.1301,\n         -0.0047,  0.1838, -0.0360, -0.1883,  0.1310, -0.0478,  0.1205,  0.1890,\n         -0.1581,  0.0364, -0.1867,  0.0424],\n        [-0.0787, -0.1274,  0.1804, -0.0401,  0.1550, -0.1698,  0.0983,  0.1153,\n         -0.1961,  0.2107, -0.0019,  0.1082, -0.0421, -0.1946,  0.0446, -0.1699,\n         -0.0448,  0.1703, -0.1723,  0.1318],\n        [-0.1084, -0.0386, -0.1555,  0.1301,  0.0511,  0.2002, -0.1920, -0.0515,\n         -0.0618, -0.0575,  0.1629,  0.0012, -0.2100, -0.0350, -0.0787, -0.0035,\n         -0.0040, -0.0534,  0.0963,  0.1966],\n        [ 0.0431, -0.1374, -0.0914,  0.0298,  0.1077,  0.0155, -0.2143,  0.2226,\n         -0.0695,  0.0210,  0.1252, -0.0630, -0.0469,  0.1692, -0.2111, -0.1472,\n          0.1701,  0.1471,  0.2188, -0.0231],\n        [ 0.1557,  0.0042,  0.1174,  0.1368,  0.1985, -0.0555, -0.0737,  0.1599,\n          0.0072,  0.2072,  0.2041,  0.1515,  0.1218,  0.2010,  0.0579, -0.1516,\n         -0.1168,  0.0808,  0.0355,  0.0321],\n        [-0.1900, -0.2058,  0.0528, -0.0236,  0.0719,  0.1853, -0.2164, -0.1080,\n          0.0885,  0.0998, -0.1298,  0.1264, -0.1719,  0.0977,  0.1348, -0.0215,\n         -0.0472, -0.0087, -0.0024,  0.1939],\n        [ 0.0981,  0.1039,  0.1722, -0.0027,  0.1779,  0.0962, -0.0643,  0.1576,\n          0.1872, -0.1269,  0.1244, -0.0197, -0.0477, -0.0576,  0.0272, -0.0886,\n         -0.1326, -0.2220,  0.1308,  0.0513],\n        [-0.0368,  0.1886,  0.0018,  0.2230,  0.1062, -0.1391,  0.0479, -0.0446,\n         -0.1721,  0.1001, -0.1856, -0.0051,  0.0482, -0.1860,  0.1560, -0.2127,\n         -0.0647,  0.1156,  0.0803,  0.1819],\n        [-0.1996,  0.1943,  0.1916, -0.0103,  0.0377, -0.1990, -0.0781, -0.0882,\n         -0.0344,  0.1170,  0.0981,  0.1443,  0.0406,  0.0868,  0.1652, -0.0218,\n          0.1136,  0.0170, -0.2235, -0.0883],\n        [-0.0220, -0.0952,  0.0685,  0.1675,  0.2046,  0.1429, -0.1363, -0.0209,\n         -0.0808, -0.0892, -0.0566,  0.1100,  0.1209, -0.1914,  0.1166, -0.1595,\n          0.0608,  0.1486, -0.1748, -0.0677],\n        [ 0.1250,  0.0981, -0.1408,  0.0112, -0.0218,  0.0157, -0.1962,  0.1262,\n          0.1287,  0.1550, -0.1564, -0.0068, -0.2169,  0.0244, -0.0915, -0.0723,\n          0.1472, -0.0614, -0.1267, -0.0505],\n        [-0.2138,  0.1174,  0.1575,  0.1971, -0.1232, -0.0329,  0.0279, -0.2098,\n         -0.1263,  0.0409,  0.0990,  0.1336, -0.1850,  0.2137, -0.1762,  0.0504,\n         -0.0886, -0.0983, -0.1889,  0.0034],\n        [ 0.0975,  0.0544,  0.0673, -0.0417,  0.2217,  0.1260, -0.0272,  0.0662,\n          0.1636,  0.0868,  0.0649,  0.0152,  0.0520,  0.1324,  0.0830, -0.0388,\n         -0.0029, -0.1546, -0.1453,  0.1435],\n        [ 0.0272,  0.0202,  0.0817,  0.1484,  0.0303, -0.1819,  0.0522,  0.2008,\n         -0.2112,  0.1741,  0.1627, -0.0434, -0.0651, -0.1809,  0.0022, -0.1814,\n          0.2082, -0.1514, -0.2108,  0.1466],\n        [-0.1122, -0.0818, -0.1203,  0.1629,  0.1540,  0.0699, -0.1114, -0.0610,\n         -0.1392,  0.1908, -0.0532,  0.1320, -0.1243,  0.0843,  0.0354, -0.1262,\n          0.0898,  0.2025,  0.0534, -0.1929],\n        [ 0.1233, -0.1412,  0.0962, -0.1204,  0.0131, -0.1135, -0.1393,  0.1707,\n          0.0071,  0.1954,  0.1526,  0.0357,  0.1346,  0.1718, -0.2139, -0.1843,\n          0.0891, -0.2145, -0.1804, -0.0485],\n        [ 0.0760,  0.0022,  0.1708,  0.2057, -0.0754, -0.1344,  0.0126, -0.1322,\n          0.1269, -0.1812,  0.1219, -0.1521, -0.1061, -0.0235, -0.0826, -0.1727,\n         -0.0788,  0.0128,  0.2133, -0.0954],\n        [-0.1225,  0.1881,  0.1410, -0.1628, -0.0161, -0.1532,  0.0922, -0.0708,\n          0.0025,  0.1855, -0.0953,  0.2057,  0.1236, -0.0534,  0.0382, -0.1168,\n         -0.1067, -0.0740, -0.2095,  0.1416],\n        [ 0.1150,  0.1839, -0.0254, -0.0668, -0.0417,  0.0879,  0.0332,  0.1267,\n         -0.0576,  0.1745, -0.0927,  0.1333,  0.1596,  0.0448,  0.1831,  0.1023,\n          0.2235,  0.0216,  0.1988, -0.1301],\n        [-0.0025, -0.1506,  0.1152,  0.0866, -0.1536, -0.0467, -0.0215,  0.0261,\n          0.1088,  0.1921,  0.0750, -0.0513, -0.2098,  0.2065, -0.1169, -0.1625,\n          0.1877, -0.1706,  0.0984,  0.0951],\n        [ 0.0033, -0.1747,  0.2113,  0.1372,  0.0807,  0.0609, -0.0887, -0.1301,\n          0.0328,  0.2074, -0.0806,  0.0895, -0.0630, -0.2101, -0.0034,  0.0898,\n         -0.1608,  0.0921, -0.2012, -0.1675],\n        [ 0.0271,  0.1963, -0.1013, -0.0758, -0.1723,  0.1635, -0.0668,  0.1321,\n         -0.0954, -0.0622,  0.1535,  0.0643, -0.2227, -0.1436, -0.2001,  0.0971,\n          0.1117, -0.1792,  0.1513,  0.0033],\n        [ 0.0793,  0.1077, -0.2036, -0.0649,  0.2036, -0.2062,  0.0907,  0.0963,\n         -0.1897, -0.1109,  0.1242, -0.0375,  0.0534,  0.0394,  0.0590,  0.0868,\n          0.0018,  0.2200, -0.0383, -0.1298],\n        [-0.0597, -0.0213, -0.1401,  0.1136, -0.1994,  0.1080,  0.0499, -0.1442,\n          0.1020,  0.0518, -0.0699,  0.0192, -0.0156,  0.1173,  0.0645,  0.0471,\n         -0.0673, -0.0417, -0.1018, -0.1688],\n        [ 0.1412, -0.0074, -0.1681,  0.0580,  0.0902,  0.2106,  0.1871, -0.1135,\n         -0.2032,  0.0116,  0.0357, -0.2064,  0.0718, -0.1962, -0.0476,  0.1353,\n          0.1074,  0.0328,  0.0947, -0.0850],\n        [ 0.1835, -0.1515, -0.1088, -0.0412, -0.1252, -0.0866, -0.2192,  0.0956,\n         -0.0085, -0.1511,  0.0943,  0.0528, -0.0084, -0.1953,  0.1481,  0.0779,\n          0.2094, -0.1468, -0.1773, -0.0286],\n        [-0.1956,  0.0054, -0.2186, -0.0796, -0.0984, -0.0789, -0.0101,  0.0126,\n          0.1001, -0.1709, -0.1443,  0.1314,  0.0139, -0.0251,  0.2140,  0.1520,\n         -0.0161, -0.1202,  0.0432, -0.1093],\n        [ 0.1319, -0.0129,  0.1889,  0.0119, -0.1190,  0.0520, -0.0287,  0.1884,\n         -0.1945,  0.0405,  0.0900,  0.0520, -0.1277,  0.0591,  0.0673, -0.1541,\n         -0.0249,  0.1286,  0.1328, -0.1317],\n        [ 0.1190, -0.0723,  0.0438,  0.2096,  0.2192, -0.1635,  0.0178,  0.1600,\n          0.1561, -0.0962, -0.1169, -0.0831, -0.1602, -0.1387,  0.0040,  0.1831,\n          0.0945, -0.0045,  0.1778, -0.0066],\n        [ 0.0189, -0.0796,  0.0259,  0.2229,  0.0556, -0.0736, -0.0508, -0.1329,\n          0.0192, -0.0707,  0.0746,  0.1147,  0.1171, -0.0144,  0.1381,  0.1547,\n         -0.2049,  0.0789, -0.1157, -0.1761],\n        [ 0.2137, -0.1436,  0.0841,  0.1670, -0.0161,  0.1448,  0.2171, -0.2236,\n         -0.1043,  0.0142,  0.2183,  0.0636,  0.1792, -0.0046,  0.1448,  0.0094,\n          0.1294, -0.1023,  0.0035,  0.0486]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0880,  0.0567,  0.2097,  0.1312, -0.1595,  0.1467,  0.2106,  0.0161,\n         0.1545,  0.1808, -0.0464,  0.1508,  0.0716,  0.1144, -0.0141, -0.1258,\n         0.0063, -0.0868,  0.1003, -0.1824, -0.0225, -0.1511, -0.0503,  0.0474,\n         0.0824,  0.1644,  0.1465, -0.0867, -0.1744, -0.0882,  0.1271, -0.1567],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-3.3188e-02,  2.0591e-02, -8.7802e-03,  3.8746e-02, -4.2968e-02,\n          5.1132e-02,  1.5270e-01, -1.5583e-01, -1.5448e-01,  9.6050e-02,\n         -1.5501e-01,  1.6833e-01,  1.7615e-01, -1.5212e-01, -1.6681e-01,\n          1.7066e-01,  9.9154e-02,  3.5003e-02,  4.2337e-02, -3.8908e-02,\n         -8.3586e-03,  5.7935e-03,  1.5951e-02,  1.0058e-01,  3.8370e-02,\n         -1.4971e-01, -1.3451e-01,  1.6504e-01,  7.1236e-02,  9.2151e-02,\n         -1.0728e-01, -1.0199e-01],\n        [-1.1264e-01, -1.6813e-01, -8.5347e-02,  1.2351e-01, -1.0012e-02,\n          1.2141e-01, -1.8292e-02, -1.6058e-01,  3.2756e-02, -4.9301e-02,\n          1.0156e-01,  3.9947e-02, -1.0592e-02,  1.3222e-01, -1.2336e-01,\n          9.0050e-02, -1.6177e-02,  8.3146e-03,  1.1181e-01,  1.3939e-02,\n         -3.7821e-02, -1.6653e-01,  1.0018e-01,  1.1440e-01, -7.3013e-02,\n         -3.5783e-02, -1.4239e-01, -1.1397e-01,  9.0997e-02, -1.1389e-01,\n         -1.6164e-01,  1.1243e-01],\n        [-1.0299e-01,  7.2029e-02, -1.4973e-01,  5.0677e-02, -1.7500e-01,\n         -6.9628e-02,  1.6978e-01, -1.7526e-01,  1.7427e-02,  1.2130e-01,\n          2.3350e-02, -9.8134e-02, -1.5989e-01,  8.5470e-02, -1.6044e-02,\n          1.6811e-02,  1.0191e-01,  6.4090e-03, -5.9135e-02, -1.1985e-01,\n          1.1102e-01, -1.4010e-01, -7.8219e-02, -1.1606e-01, -1.3568e-01,\n         -1.6850e-01,  1.9419e-02, -7.5862e-02, -9.7990e-02, -1.2057e-01,\n          5.9106e-02,  1.5114e-01],\n        [ 5.2226e-03,  5.0160e-02, -1.1908e-01, -8.5516e-02,  1.3229e-01,\n          1.2538e-01, -2.7513e-03,  1.4385e-01,  5.8612e-02,  1.1155e-01,\n         -1.0664e-01,  1.6899e-02, -4.5769e-02, -1.6814e-01,  5.0428e-02,\n         -1.4782e-01,  3.0753e-02, -1.3773e-01, -9.8089e-02, -9.0577e-02,\n         -1.6423e-01, -3.3471e-02,  8.5789e-02, -8.9391e-02, -1.7231e-01,\n          7.4427e-02,  9.7401e-02,  1.6726e-01, -1.0750e-01, -7.2400e-02,\n         -7.1581e-02, -1.6881e-01],\n        [ 1.3848e-01, -1.5251e-01,  6.9497e-02, -1.7463e-01, -6.8567e-02,\n          4.5674e-02, -1.3894e-01,  2.3003e-02, -1.3494e-01, -7.9214e-03,\n         -7.8997e-02,  7.1255e-02, -1.8463e-02, -8.9439e-02, -1.3332e-02,\n         -4.3171e-02, -1.7208e-01,  5.6005e-02,  1.2229e-01,  1.4426e-01,\n         -9.5425e-04,  1.9243e-02,  1.2212e-01, -1.4835e-01, -1.7170e-01,\n         -3.0323e-03,  1.1600e-01, -1.0966e-01,  1.5369e-01, -8.5417e-02,\n         -5.0913e-02,  4.5889e-02],\n        [-9.5576e-02,  1.2009e-01, -6.4134e-02, -8.7342e-02, -8.1151e-02,\n          1.1472e-01,  1.0970e-01, -1.1177e-01,  8.8739e-02,  1.0199e-01,\n          6.7246e-02,  1.3128e-02,  1.5773e-02, -1.4620e-01, -6.5484e-02,\n          6.3424e-02, -7.1432e-02,  6.8316e-03,  1.7227e-02, -1.4713e-01,\n          9.8265e-02,  3.5248e-02, -4.9282e-02,  1.5082e-01,  2.3876e-02,\n         -6.1759e-02, -1.2669e-01, -4.9713e-02,  6.4349e-02, -4.7835e-02,\n          1.6921e-01, -2.6323e-02],\n        [ 5.7226e-02,  1.4542e-01,  9.0369e-02, -7.1986e-02,  1.6704e-01,\n          2.4869e-02,  9.5362e-02,  1.1011e-02, -1.4789e-01,  9.3133e-02,\n         -1.4017e-01,  9.4445e-02, -1.2658e-01, -4.9495e-02, -1.2890e-01,\n         -7.2023e-03, -1.3281e-01,  1.4053e-01, -1.1911e-01, -9.6142e-02,\n         -1.6477e-01, -8.5301e-02,  1.4109e-01,  1.6490e-01, -9.7538e-02,\n         -1.3338e-01, -3.6855e-02,  1.3007e-04, -4.8676e-02, -1.5496e-01,\n          9.4915e-02, -5.6720e-02],\n        [ 1.1404e-02,  6.9273e-02, -1.4560e-01, -1.1642e-01, -5.2199e-02,\n          7.8865e-02,  1.5291e-01, -4.8013e-02, -7.6011e-02, -1.7464e-03,\n          1.0898e-01,  5.0733e-02,  1.2633e-02,  5.7837e-02,  9.7105e-02,\n         -1.3292e-01,  2.7501e-02, -1.0066e-01, -1.6275e-01, -3.3850e-02,\n          1.5760e-01, -6.2212e-02, -9.7648e-03,  1.7553e-01,  7.5570e-02,\n          3.2383e-03,  6.2560e-02,  5.8186e-02, -3.2416e-02, -8.5579e-02,\n          1.7164e-01, -1.4460e-02],\n        [-9.1698e-02,  1.7650e-01,  4.8464e-02, -3.9829e-02,  4.0476e-02,\n         -1.5033e-01, -7.0894e-02,  1.5693e-01, -8.7030e-02, -1.5159e-02,\n         -8.9956e-04, -1.6720e-01,  8.9177e-02, -1.1051e-01, -8.6027e-02,\n         -1.0688e-02, -1.0924e-01,  7.1626e-02,  1.5417e-01, -1.7640e-01,\n         -4.2601e-02, -6.6653e-02,  4.6080e-02, -9.4703e-02,  3.1954e-02,\n         -1.3622e-01, -1.8433e-02, -1.1240e-01,  1.0293e-01,  7.2562e-02,\n         -1.0095e-01,  9.1767e-02],\n        [ 9.3214e-02,  1.1296e-01,  6.2484e-02, -9.2080e-02, -7.1297e-03,\n         -1.1851e-01,  6.5613e-03,  1.0067e-01,  4.3912e-02, -1.5947e-01,\n          6.5181e-02, -1.6641e-01, -6.5069e-02,  1.1465e-01,  2.3078e-02,\n          2.0762e-02,  1.0879e-01, -1.6718e-01, -5.7367e-02, -1.6450e-01,\n         -1.7875e-02,  1.0203e-01,  1.6932e-01,  1.3259e-01,  4.9310e-02,\n          1.1941e-01,  1.5749e-01, -1.4051e-01,  5.4308e-02, -1.5171e-01,\n          5.3341e-02,  1.6516e-01],\n        [-1.6905e-01,  8.9633e-02,  1.3456e-02, -5.5168e-02,  1.6131e-01,\n          1.0873e-01,  5.0107e-02,  3.8832e-02, -5.8129e-02, -1.0233e-01,\n         -4.8411e-02,  1.6300e-02, -1.4669e-01,  7.2391e-02, -1.0525e-01,\n          7.3254e-02,  1.0821e-01, -8.8221e-02, -7.4594e-03,  3.2393e-03,\n          1.6415e-01,  1.6488e-01, -9.3875e-02,  1.0243e-02, -1.8431e-02,\n          1.5004e-01,  1.6179e-01,  3.1849e-02,  1.5436e-01,  1.5784e-01,\n         -9.6839e-02,  1.5233e-01],\n        [-1.1091e-02, -5.9668e-03,  1.4135e-01, -4.2875e-02, -2.4728e-02,\n         -1.2963e-01,  1.7569e-02, -1.7653e-01, -1.5311e-01, -8.1803e-03,\n          2.6278e-02, -1.3608e-01, -1.1242e-02, -1.1731e-01, -1.3267e-01,\n          8.1053e-02, -4.5235e-03,  6.9141e-02, -7.8147e-03,  4.7429e-02,\n         -8.8160e-02, -7.4962e-03, -1.2876e-01,  4.9608e-02,  1.4071e-01,\n         -4.6276e-02,  1.1415e-01,  1.2216e-01, -5.4571e-02,  1.5294e-01,\n         -1.6556e-01,  2.4618e-02],\n        [-1.0230e-01,  1.0180e-01, -5.1751e-02,  1.1043e-01, -1.0305e-01,\n          4.8024e-02,  5.1162e-02, -7.2178e-02, -1.1515e-01, -4.9719e-02,\n         -2.9755e-02,  1.7474e-01,  1.6803e-01, -1.7467e-01,  1.9479e-02,\n          1.7417e-01,  1.3553e-01,  5.5579e-02,  1.5407e-01,  5.9090e-02,\n         -1.5911e-01,  1.2335e-01,  1.5573e-01, -1.6305e-01,  9.0141e-02,\n         -6.0189e-02, -1.2853e-01,  1.1758e-01, -5.0250e-02,  1.5459e-01,\n          1.5204e-01,  8.0388e-03],\n        [-1.2258e-01, -9.8576e-02,  1.8923e-03, -5.9724e-02, -9.5927e-02,\n         -1.4734e-01,  1.1306e-01, -5.1322e-02,  8.9085e-02, -6.0440e-02,\n          4.6115e-02,  1.7623e-01, -1.4689e-01, -1.4366e-01, -3.5733e-02,\n         -9.1445e-02, -3.6153e-02,  1.5093e-01, -2.4375e-02, -1.2342e-01,\n          1.5237e-01, -1.2211e-01,  1.4865e-01,  1.0769e-01, -7.2792e-02,\n          8.5461e-02, -7.4997e-02,  8.9197e-02,  3.6495e-02,  2.1157e-02,\n          1.1810e-02, -6.2504e-02],\n        [ 1.3616e-01, -3.1599e-02,  4.1432e-02,  3.2048e-02, -1.6947e-01,\n          6.7117e-02,  1.7006e-01, -5.7993e-02,  1.2004e-02,  9.6837e-02,\n         -6.3412e-02, -7.5288e-02,  9.1765e-03, -8.4402e-02,  3.1882e-03,\n         -2.5665e-02,  9.0680e-02, -6.7160e-02,  1.3880e-01, -9.1034e-03,\n         -1.0995e-01,  6.0014e-02,  4.0186e-02,  1.1450e-01,  5.9369e-02,\n          9.4225e-03,  2.2377e-03, -7.8515e-02,  4.1444e-02,  2.4987e-02,\n         -1.0868e-01, -1.6224e-01],\n        [ 9.4856e-02, -1.7565e-01, -4.9048e-02, -1.0011e-01, -1.0120e-01,\n         -1.3472e-01, -1.3845e-01,  1.6461e-01,  1.5195e-01,  5.2929e-02,\n          6.8625e-02, -1.0382e-02, -4.8783e-02,  1.5258e-01, -1.4461e-01,\n          1.7551e-01, -4.8889e-02,  5.7946e-02,  9.8555e-03,  5.8155e-02,\n          3.9626e-02,  1.1022e-01,  2.5522e-02, -1.3878e-01, -1.4424e-01,\n         -1.3319e-02, -1.4898e-02, -1.0825e-01,  3.3249e-02, -6.0466e-02,\n          6.8282e-02, -1.3146e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1652,  0.0054,  0.0881, -0.1040, -0.1315,  0.0306, -0.1610,  0.1338,\n         0.0065,  0.0327,  0.0357, -0.0335,  0.0568, -0.1575, -0.1514, -0.0233],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1646, -0.0519,  0.0220,  0.0862,  0.1761, -0.1953, -0.0187,  0.0744,\n         -0.0164, -0.0070,  0.1839,  0.1421, -0.1358, -0.1433,  0.0614, -0.0662],\n        [ 0.1906,  0.1501, -0.0847,  0.0041,  0.2304, -0.0191,  0.0079, -0.1112,\n          0.2333, -0.0945, -0.1415,  0.2431, -0.0127, -0.2106, -0.0647, -0.2133],\n        [-0.1964, -0.1719, -0.0480,  0.1787, -0.1962,  0.2296, -0.1982, -0.0808,\n         -0.1217, -0.2163, -0.0193,  0.1737,  0.0818,  0.1031,  0.0467,  0.1958],\n        [-0.1346,  0.0254,  0.0489, -0.0300,  0.1226,  0.0495, -0.1530,  0.0157,\n          0.0054,  0.0658, -0.1808,  0.1541,  0.1306,  0.1162, -0.1506, -0.1169],\n        [-0.1846,  0.0038,  0.0166,  0.0857, -0.0129, -0.1503, -0.2338, -0.0826,\n         -0.0750, -0.0349, -0.1593,  0.1804,  0.0173, -0.1374,  0.0707,  0.0148],\n        [ 0.1616,  0.1069, -0.1530, -0.1653, -0.0823,  0.2441,  0.2396,  0.1948,\n          0.2439,  0.1803, -0.1493, -0.0957, -0.0167, -0.2345,  0.0517, -0.1622],\n        [-0.0633, -0.1819, -0.1255,  0.2411,  0.1868,  0.2090, -0.2124, -0.0517,\n         -0.1068,  0.1943, -0.2024,  0.2032, -0.2488, -0.1315,  0.0852, -0.1301],\n        [ 0.0967,  0.1275, -0.1609, -0.0348,  0.0362,  0.1116, -0.0223, -0.0801,\n         -0.1340,  0.0539, -0.0226,  0.0941, -0.1849,  0.1932, -0.2023,  0.2120]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0920, -0.2336, -0.1002, -0.2196, -0.2473,  0.0158,  0.1147,  0.2017],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1271, -0.3101, -0.2449, -0.2215, -0.2751,  0.0247, -0.1911, -0.2927]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2499], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x10cabe350>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x11c63c760>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s54740000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s54740000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}