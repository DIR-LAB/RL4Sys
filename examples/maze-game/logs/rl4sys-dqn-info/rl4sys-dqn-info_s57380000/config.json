{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s57380000"
    },
    "q_lr":	0.0005,
    "seed":	57380000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x125b18c40>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0370, -0.0840, -0.1321, -0.1424, -0.0326, -0.1637, -0.1255,  0.0408,\n        -0.0712,  0.1417, -0.1694, -0.0905,  0.0138,  0.1999,  0.1828, -0.1160,\n         0.1346, -0.1246, -0.1006, -0.0443, -0.1587,  0.1090,  0.1326,  0.0460,\n        -0.0814,  0.1716,  0.1650,  0.0313,  0.0727,  0.2054,  0.0853,  0.0506],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2060,  0.0085,  0.1950,  0.1815,  0.0670, -0.1902,  0.0876, -0.1805,\n         -0.1447, -0.2014,  0.1968,  0.0324,  0.1710, -0.1589,  0.0497, -0.0361,\n          0.1845, -0.0819, -0.1461,  0.0330],\n        [ 0.1296,  0.1588,  0.0783, -0.0159,  0.1063, -0.0847,  0.1608, -0.0079,\n          0.1408,  0.0428,  0.0263,  0.1911, -0.0150, -0.2003, -0.0458, -0.1466,\n         -0.2017, -0.0639,  0.0339,  0.0715],\n        [ 0.0314, -0.0550, -0.0777, -0.0383,  0.1832, -0.0248,  0.0479,  0.2050,\n          0.0121, -0.0030,  0.1644,  0.1419, -0.1695,  0.2190,  0.1042,  0.1193,\n          0.1567,  0.2010,  0.1015, -0.0390],\n        [ 0.1273,  0.0715, -0.0999, -0.1679,  0.1512,  0.0004, -0.0085,  0.0785,\n         -0.1023, -0.0667, -0.2234, -0.1901, -0.1578, -0.2061, -0.1392,  0.2148,\n          0.0688,  0.0356,  0.1379, -0.1140],\n        [ 0.0258,  0.1264, -0.1397,  0.1742, -0.0368, -0.2210,  0.0303, -0.1409,\n          0.0571, -0.0664, -0.1042,  0.0402, -0.0667,  0.1479, -0.0746, -0.1304,\n         -0.2228, -0.1364,  0.0354, -0.0698],\n        [ 0.0203,  0.1324,  0.2154,  0.1072, -0.0266,  0.0291,  0.1425,  0.1857,\n          0.1813, -0.1909,  0.2226,  0.0018, -0.1816, -0.1676, -0.1443, -0.1011,\n          0.0587,  0.0317,  0.0355,  0.2105],\n        [ 0.0036, -0.1975,  0.1060, -0.0662,  0.0554,  0.0176, -0.0474,  0.0559,\n         -0.1579, -0.1283, -0.1148,  0.2000, -0.1414, -0.0753,  0.0800, -0.1960,\n          0.1580, -0.1842,  0.2098, -0.0420],\n        [ 0.0901, -0.0648, -0.1891,  0.0362, -0.2067, -0.2215, -0.2069,  0.1687,\n         -0.0053, -0.2200,  0.0418,  0.1982,  0.1062,  0.1144,  0.1316,  0.1548,\n          0.1652,  0.2049,  0.0728,  0.1688],\n        [ 0.1715,  0.1340, -0.0307,  0.1830, -0.0239, -0.0564,  0.0472,  0.1510,\n          0.0816,  0.1523, -0.0233,  0.1678,  0.1027,  0.0285, -0.1927, -0.0012,\n         -0.0438,  0.0523, -0.0471,  0.0380],\n        [ 0.0941,  0.1364, -0.1528,  0.0382,  0.0821, -0.1713,  0.2171,  0.1308,\n          0.0388,  0.1173, -0.2148,  0.0073,  0.2128, -0.1571, -0.0689, -0.1691,\n          0.1282, -0.0461,  0.0146, -0.0421],\n        [ 0.0285, -0.0796, -0.1419,  0.1445, -0.0357, -0.2163,  0.2062,  0.0948,\n         -0.0186,  0.0561,  0.0169,  0.1263,  0.0701,  0.1180,  0.0572,  0.0024,\n          0.1242, -0.0098, -0.0007, -0.0317],\n        [-0.0567,  0.0092,  0.1541, -0.1433, -0.1703,  0.0900,  0.2075, -0.1133,\n         -0.0880,  0.2092,  0.1015, -0.1439,  0.1277, -0.0056, -0.0925,  0.1964,\n         -0.1767,  0.1134, -0.0753, -0.0726],\n        [ 0.1746,  0.1882,  0.1059,  0.0401,  0.0265,  0.1759, -0.0051,  0.1786,\n          0.0643,  0.1308, -0.1303,  0.1725,  0.2100, -0.1331,  0.0545, -0.2003,\n          0.0847, -0.0294,  0.1177, -0.1273],\n        [-0.0214,  0.0207, -0.0082, -0.1552,  0.2203,  0.1058, -0.1626, -0.2000,\n         -0.1287, -0.2034, -0.2119, -0.1682,  0.1613, -0.1275, -0.0784, -0.1826,\n         -0.0355,  0.0292,  0.0221, -0.0073],\n        [-0.1440,  0.2225,  0.2025, -0.1492, -0.0111,  0.1476, -0.1232, -0.0554,\n          0.0431,  0.1220, -0.0771,  0.1900,  0.1477,  0.0781,  0.0327, -0.0236,\n         -0.0262,  0.1635,  0.1182, -0.1115],\n        [ 0.1428,  0.1038,  0.0938, -0.1685, -0.1112, -0.1186, -0.0014, -0.0345,\n          0.1825,  0.2059,  0.1895,  0.2004, -0.1778,  0.0311,  0.1495, -0.0160,\n          0.0658, -0.0296, -0.0242,  0.0479],\n        [-0.0800, -0.1648,  0.0809, -0.1101,  0.1076,  0.0750,  0.0559,  0.1448,\n          0.1445,  0.0780,  0.2130,  0.0976, -0.0560,  0.1935,  0.2019,  0.0962,\n          0.0965, -0.1321, -0.2011,  0.1932],\n        [ 0.0211, -0.0800, -0.0175, -0.1416, -0.0586, -0.0524, -0.1171, -0.0594,\n         -0.1989,  0.2118, -0.0709,  0.0849,  0.0218,  0.1266, -0.1846,  0.0311,\n         -0.0802, -0.0383,  0.2129, -0.1411],\n        [ 0.2155, -0.1675,  0.0922,  0.1077, -0.0789,  0.0505, -0.0690,  0.1332,\n         -0.1571, -0.0242,  0.0818,  0.2218,  0.1484, -0.1952, -0.0362, -0.1423,\n         -0.1845, -0.1448,  0.0184, -0.1943],\n        [ 0.2032, -0.0112,  0.0309,  0.0162, -0.1567,  0.1551, -0.0964,  0.1876,\n         -0.0312,  0.0908, -0.1276, -0.2132, -0.0115,  0.0841,  0.0618, -0.1817,\n          0.1833,  0.0196, -0.0523, -0.2173],\n        [ 0.2011,  0.0163, -0.1031,  0.1792,  0.1690, -0.0900,  0.1697, -0.0083,\n         -0.0675, -0.0473,  0.0461,  0.2122,  0.0888, -0.2033,  0.2119,  0.1816,\n         -0.0332, -0.2169, -0.0250,  0.0427],\n        [ 0.0829,  0.0981, -0.1412, -0.0199,  0.1199,  0.0317, -0.0442,  0.1721,\n         -0.2200, -0.0583, -0.0653, -0.1724, -0.0694, -0.1988,  0.1479, -0.0154,\n         -0.0646, -0.0880, -0.1282,  0.2194],\n        [-0.0393, -0.1955,  0.2123, -0.0987, -0.0620, -0.1672,  0.1972, -0.1397,\n         -0.1092,  0.1256, -0.1717,  0.1313,  0.0166,  0.0110,  0.1996,  0.1275,\n         -0.0149, -0.1892,  0.1526, -0.1034],\n        [-0.1030,  0.2073,  0.0203, -0.0394, -0.0845,  0.0830,  0.1011,  0.0389,\n          0.0346,  0.0973, -0.0593,  0.0900,  0.1631, -0.0017, -0.2121,  0.0976,\n         -0.0749,  0.1268,  0.1800, -0.1886],\n        [-0.1904,  0.2124,  0.0966, -0.1198, -0.1497, -0.1006, -0.2211, -0.1945,\n          0.1432,  0.2098,  0.0378, -0.2105,  0.2111, -0.1287,  0.2075,  0.0707,\n         -0.0804,  0.1060, -0.0791, -0.1298],\n        [-0.0491, -0.1798, -0.1673,  0.0278, -0.1805,  0.0227,  0.0826, -0.0432,\n          0.1643,  0.1333, -0.1153, -0.0541, -0.1287,  0.1837,  0.0791,  0.0237,\n         -0.1765,  0.1509, -0.0373,  0.1192],\n        [-0.1933, -0.0248, -0.0288,  0.1108,  0.0285,  0.1841,  0.0483,  0.0420,\n         -0.2090,  0.0306, -0.0840,  0.0702, -0.0437,  0.2081,  0.1430, -0.2210,\n          0.2159, -0.0021, -0.0444,  0.1257],\n        [-0.0205, -0.0728, -0.0012, -0.2011, -0.2032,  0.1478,  0.0016, -0.0362,\n         -0.1493, -0.0123,  0.0383,  0.0109,  0.0743, -0.0556, -0.2187,  0.0639,\n         -0.0936,  0.0854,  0.0820,  0.1537],\n        [ 0.0377, -0.1613, -0.0428,  0.0295, -0.0471, -0.2219,  0.0995, -0.1352,\n          0.1498, -0.1976,  0.0481, -0.0953, -0.0156,  0.0453, -0.1030, -0.1449,\n          0.2022,  0.1039, -0.2042, -0.0422],\n        [ 0.0852, -0.1593, -0.1638,  0.1107,  0.1547,  0.1075, -0.0604, -0.1864,\n          0.2106, -0.0172,  0.0046,  0.1864,  0.1405,  0.0832,  0.0371,  0.2003,\n         -0.1386, -0.1334,  0.1940, -0.1026],\n        [ 0.1585,  0.1983, -0.1190, -0.1040, -0.1448,  0.2170,  0.0258, -0.1132,\n         -0.1579,  0.0554,  0.1717, -0.1798, -0.0228, -0.0337,  0.1794, -0.0504,\n         -0.1770,  0.0449, -0.1938,  0.2219],\n        [ 0.1359, -0.2080, -0.1851,  0.0584,  0.1221, -0.2063, -0.1081, -0.1163,\n          0.0286,  0.1107, -0.2166,  0.0948,  0.0685, -0.0332,  0.0762, -0.1972,\n          0.2106, -0.0288, -0.1722, -0.0014]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0818, -0.0996,  0.0679,  0.1517, -0.0219,  0.0441,  0.0063, -0.0064,\n        -0.0857,  0.0933, -0.0467,  0.0546,  0.0345, -0.1027,  0.1757,  0.1741],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-1.0170e-01, -1.6609e-01, -1.5761e-01,  1.1616e-01,  1.9245e-02,\n          6.4376e-02, -1.7646e-01,  1.5578e-01,  8.1621e-02, -1.2918e-01,\n          9.3082e-02,  5.9229e-02, -5.0255e-02,  1.0425e-01, -1.2722e-01,\n         -1.0196e-01,  1.9369e-02, -3.7177e-03,  1.3550e-01, -1.2705e-01,\n         -4.9517e-02, -7.6741e-02, -6.4330e-02, -1.0805e-01,  8.7787e-02,\n         -2.5961e-02,  1.3613e-01, -6.9482e-02, -1.1996e-01,  5.6312e-02,\n          9.3746e-02, -1.2992e-01],\n        [-1.7043e-01, -5.3929e-02, -9.6298e-02, -6.8864e-02, -8.4070e-02,\n          1.5324e-01, -4.3836e-02,  1.1306e-01,  8.2026e-02, -6.2796e-02,\n         -1.5129e-01, -1.6811e-01, -1.4185e-01,  1.1133e-01, -1.3438e-01,\n          3.5072e-02,  2.1136e-02, -6.6011e-02, -1.5118e-01,  7.5604e-02,\n          1.3913e-02, -1.4324e-01,  1.4589e-02, -3.7861e-02, -5.4850e-02,\n         -8.6965e-02, -8.9004e-02, -1.5736e-01, -6.6017e-02, -1.6057e-01,\n          1.6204e-02,  1.1914e-01],\n        [ 3.8737e-02, -1.3384e-01, -1.5388e-01, -5.1072e-02,  1.2452e-02,\n          1.4560e-01, -1.3627e-01, -3.4444e-02,  2.6617e-02, -1.0716e-01,\n          6.5192e-02,  9.7020e-02,  1.1739e-01, -1.4199e-02, -1.1683e-01,\n         -1.3350e-01, -1.4241e-01,  4.3409e-02, -3.0875e-02,  1.0795e-01,\n          7.0999e-02, -1.0311e-02, -6.5740e-02,  8.0675e-02,  9.8671e-02,\n         -4.6852e-02,  5.8280e-02, -1.5269e-01,  1.9240e-02, -1.1077e-01,\n         -8.5285e-02,  4.1702e-02],\n        [-1.2371e-01,  2.6134e-02, -1.1842e-01, -8.9140e-02, -1.4076e-01,\n          3.2192e-02,  4.0129e-02,  9.3133e-02,  9.4781e-02, -5.4289e-03,\n         -1.4463e-01,  8.3724e-02,  4.8921e-02, -2.9041e-02, -7.6518e-02,\n          1.2666e-01,  1.7378e-01,  6.8703e-02, -1.0414e-01,  1.6422e-01,\n          7.5511e-02,  1.2955e-01,  6.9924e-02,  1.2425e-01,  5.1259e-02,\n          1.0113e-01,  4.7470e-02,  2.6545e-02, -1.1124e-01, -1.5487e-01,\n          3.4230e-03,  6.2369e-02],\n        [ 1.2718e-01, -1.6173e-01,  6.1753e-02,  9.8219e-02,  3.7350e-02,\n         -1.3579e-02, -8.8900e-02, -4.0834e-02, -1.0937e-01,  8.3008e-02,\n         -1.6400e-01, -1.0291e-01,  1.5464e-01, -1.4380e-01, -1.0216e-01,\n          7.4255e-02, -1.7191e-01, -2.8472e-02, -1.8692e-02,  1.6823e-02,\n         -6.5504e-02,  1.4984e-01,  1.5714e-01, -7.5070e-02,  8.0967e-02,\n          1.4305e-02, -1.3869e-01,  2.1601e-02, -7.9648e-02,  6.8769e-02,\n         -1.3458e-01, -8.1929e-02],\n        [ 1.1824e-01,  1.0041e-01,  7.6132e-02, -1.3916e-01,  1.1557e-01,\n          7.9328e-02, -9.5608e-02,  1.6031e-02, -1.4831e-01,  9.7387e-02,\n          5.5315e-02, -7.2208e-02, -1.7158e-01,  1.3175e-01, -3.3723e-02,\n          1.2184e-01, -9.4515e-02,  3.7955e-02,  1.7521e-01, -2.9532e-03,\n          1.3257e-02,  6.9290e-02, -1.0734e-01, -8.5002e-02,  1.6664e-01,\n         -1.7293e-01,  6.3770e-02, -1.3396e-01, -1.1401e-01, -3.0788e-02,\n         -1.1792e-01,  2.6354e-02],\n        [-2.3952e-02,  5.0994e-02, -1.2904e-01,  6.7218e-02, -1.3138e-01,\n          1.5239e-01, -1.1748e-01,  1.5612e-01,  5.4131e-02, -2.3370e-02,\n         -3.1950e-02,  6.2822e-02, -1.7576e-02,  1.0672e-01, -8.5683e-02,\n          1.1178e-01, -7.9377e-02,  3.6551e-02, -1.7577e-01, -1.0858e-03,\n          1.5321e-01,  7.0369e-02,  1.0749e-01,  1.4668e-01,  1.1682e-02,\n         -1.0567e-01, -6.6732e-02,  1.2491e-01, -2.9588e-02, -1.3133e-01,\n          7.8055e-02, -1.4277e-01],\n        [ 2.5876e-02, -1.6620e-01, -2.5260e-03, -1.0982e-01,  1.3950e-01,\n          1.1686e-01,  1.1743e-01, -1.1945e-03, -1.4300e-01,  4.3185e-02,\n          1.3508e-01, -6.0373e-02, -1.1555e-01,  1.8405e-02, -1.7420e-01,\n         -5.9210e-03, -1.0948e-02, -1.6650e-01,  2.5087e-02, -1.4012e-01,\n          9.7608e-04, -9.8016e-02,  7.7103e-02,  2.5247e-02, -9.0211e-02,\n         -1.1303e-01, -5.9012e-02, -1.3949e-01,  1.7116e-01, -5.7403e-03,\n         -1.6130e-02, -1.0421e-01],\n        [-1.4205e-01,  1.1144e-01, -1.2711e-01,  1.1885e-01,  7.6776e-02,\n          5.4092e-02,  9.8315e-02,  5.2074e-02,  1.1524e-01, -1.1134e-01,\n          1.5104e-01, -1.7428e-01, -1.0908e-02, -4.0633e-02, -7.3941e-02,\n         -8.4276e-02,  2.6917e-02,  1.1311e-01,  1.5029e-01, -1.0775e-01,\n          1.6601e-01, -1.6922e-01, -7.2639e-02, -6.1614e-02, -1.3172e-01,\n          1.0326e-01, -1.2838e-02,  2.2626e-02, -5.3053e-02,  6.9286e-02,\n         -1.1252e-01, -1.4227e-01],\n        [-7.4251e-02,  9.9483e-02,  1.4285e-01,  2.0131e-02,  8.7928e-02,\n          5.4128e-02,  1.2101e-01, -4.8880e-03,  4.9036e-02,  1.5745e-01,\n         -8.9915e-02, -5.3570e-02, -5.0085e-02, -2.1579e-02,  4.0033e-04,\n         -7.1535e-02, -2.0013e-02, -2.1430e-04,  1.3398e-01, -1.7447e-01,\n         -1.7297e-01, -6.8547e-02,  4.5849e-02,  3.1067e-02, -1.6672e-01,\n          5.6962e-02,  1.4625e-01, -3.7960e-02,  7.8298e-02, -1.8459e-02,\n          5.3324e-02, -9.3580e-02],\n        [ 1.5926e-01,  1.3308e-01, -1.1087e-01,  1.5729e-01,  6.9048e-02,\n         -5.1128e-02, -1.0592e-01,  9.3955e-02, -1.0492e-01,  1.3315e-02,\n          2.1626e-02, -5.6758e-02, -1.2134e-02,  1.4453e-01, -7.3356e-02,\n          5.2557e-05, -9.0784e-02, -6.2476e-02, -8.2035e-02, -7.6562e-02,\n         -1.6724e-04, -1.2233e-01,  7.5160e-02,  3.1701e-02, -1.4945e-01,\n         -1.4239e-01, -1.6495e-01,  1.5003e-01,  1.0201e-01,  6.3350e-02,\n         -1.8615e-02, -7.6800e-02],\n        [-2.1126e-02, -1.0779e-01,  1.0782e-01,  1.6219e-01,  1.4099e-01,\n          3.0783e-02,  8.9899e-02,  1.5258e-01,  3.9861e-02, -9.6814e-02,\n          1.5272e-02,  1.3023e-01, -1.2340e-01,  7.0984e-02,  5.8770e-02,\n          2.2846e-02, -1.5902e-01,  1.0212e-01, -7.8317e-02,  1.0150e-01,\n          5.8702e-02, -1.1046e-01,  6.6850e-02, -8.2416e-02,  9.9805e-02,\n         -4.6080e-02, -1.5726e-01,  1.2873e-01, -7.5139e-02, -3.1413e-02,\n          4.3859e-02,  1.4228e-01],\n        [ 1.2319e-01, -5.0328e-02,  1.6423e-01, -1.1634e-01,  9.7814e-02,\n          5.7009e-02,  1.6781e-01,  1.5779e-01, -6.0810e-02,  1.3958e-01,\n          6.0557e-02,  4.9207e-03,  2.0104e-02, -3.9564e-02,  1.6948e-01,\n          1.3961e-01, -3.3689e-02,  1.2790e-01, -1.5719e-01, -1.1847e-01,\n          1.6792e-01,  6.7760e-02,  3.5858e-02, -1.4142e-01, -1.6816e-01,\n         -1.3218e-01,  1.1826e-01,  7.3280e-02,  7.6655e-02,  9.2150e-02,\n          6.8555e-02, -4.2000e-02],\n        [ 7.5205e-02, -1.5904e-01, -1.5034e-01, -1.8872e-02,  3.2240e-02,\n          8.9968e-02, -1.3073e-01, -1.4735e-01,  1.0941e-01,  2.5325e-03,\n          1.8730e-02,  1.7377e-01, -9.7168e-02,  5.9876e-02,  1.5477e-01,\n          1.0930e-01, -3.1922e-02,  1.1443e-01, -1.5108e-01,  7.8438e-02,\n          1.2005e-01, -3.4481e-02,  1.2429e-01,  4.6414e-02, -1.2260e-01,\n         -1.3829e-01, -1.0749e-01, -1.5271e-01, -4.4664e-02, -4.5066e-02,\n          7.6559e-02,  1.7091e-01],\n        [-8.4002e-02,  8.2721e-02,  1.4606e-01,  3.2719e-02, -3.2232e-02,\n          1.6053e-01,  5.5287e-02, -3.2439e-03,  3.0295e-02,  1.1435e-01,\n          1.5494e-01,  1.2405e-02, -1.4597e-02,  5.3919e-02, -4.6946e-02,\n         -7.4082e-02,  1.6628e-01, -7.4647e-02,  1.6390e-01,  8.5168e-02,\n         -1.1401e-01,  1.3816e-01, -1.4334e-01,  1.2724e-01,  2.3523e-02,\n          1.4470e-01, -1.3595e-02,  5.3746e-02, -9.7549e-02, -1.5623e-01,\n         -3.2205e-02, -1.5255e-01],\n        [-9.4418e-02, -5.4561e-02, -1.4188e-01,  1.3924e-01, -1.6007e-01,\n         -3.5750e-02,  2.4387e-02, -1.5989e-01, -1.5813e-01, -6.0060e-02,\n          6.5288e-02, -1.2842e-01, -2.7339e-02, -1.1156e-01, -7.8107e-02,\n          2.6569e-04, -3.7066e-02, -5.8602e-02, -7.7830e-03,  1.8958e-02,\n         -1.2652e-02, -1.5847e-01,  1.2697e-01,  3.7453e-03, -3.1699e-02,\n          1.5759e-01, -8.0743e-04,  1.5878e-01,  1.6127e-01,  1.5908e-01,\n         -1.5163e-01, -3.3689e-03]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2107, -0.1349,  0.1669,  0.0221,  0.0124,  0.1211,  0.0441, -0.0926],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1352,  0.1691, -0.1113,  0.2167,  0.0886,  0.2156, -0.2255,  0.0907,\n          0.1004,  0.2052,  0.2337, -0.0355, -0.1324,  0.1074,  0.1376, -0.2259],\n        [ 0.1110,  0.2116,  0.1869, -0.0790, -0.1922,  0.1403, -0.0053,  0.0790,\n         -0.1008,  0.1719,  0.0012,  0.1627, -0.2076,  0.1955, -0.1545, -0.1104],\n        [ 0.2128,  0.2213, -0.0937, -0.0937, -0.2075,  0.2283, -0.2194,  0.0266,\n         -0.0926,  0.1267, -0.0614,  0.2423,  0.0244,  0.1513, -0.1228,  0.1123],\n        [-0.1541, -0.1660,  0.0725, -0.0003, -0.1533,  0.0342, -0.0663,  0.0481,\n          0.1898, -0.2429,  0.1870, -0.0548, -0.0225, -0.2352, -0.1777,  0.0815],\n        [-0.2212,  0.1120,  0.2339,  0.0008,  0.0318,  0.1031,  0.0187, -0.0945,\n         -0.1901, -0.1487,  0.1380,  0.1711, -0.1067, -0.2404,  0.0563, -0.1585],\n        [-0.0884, -0.1067,  0.0025,  0.1414, -0.0490, -0.0112, -0.1876, -0.2298,\n         -0.1314,  0.2289,  0.0950,  0.1093, -0.1710, -0.1992,  0.1056, -0.1949],\n        [ 0.2175,  0.1216,  0.1083, -0.2249,  0.1351, -0.0502,  0.1764,  0.2314,\n          0.2395,  0.0313, -0.1195, -0.1758,  0.1313,  0.0096,  0.2189,  0.2282],\n        [ 0.0876,  0.0760, -0.0948, -0.0384,  0.2121,  0.0845, -0.0056, -0.0379,\n          0.2463, -0.1291, -0.1970, -0.1053, -0.2229, -0.2208, -0.2454, -0.2374]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.2429], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1567, -0.3092, -0.0211,  0.0159, -0.0552, -0.2409, -0.2798,  0.2765]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2060,  0.0085,  0.1950,  0.1815,  0.0670, -0.1902,  0.0876, -0.1805,\n         -0.1447, -0.2014,  0.1968,  0.0324,  0.1710, -0.1589,  0.0497, -0.0361,\n          0.1845, -0.0819, -0.1461,  0.0330],\n        [ 0.1296,  0.1588,  0.0783, -0.0159,  0.1063, -0.0847,  0.1608, -0.0079,\n          0.1408,  0.0428,  0.0263,  0.1911, -0.0150, -0.2003, -0.0458, -0.1466,\n         -0.2017, -0.0639,  0.0339,  0.0715],\n        [ 0.0314, -0.0550, -0.0777, -0.0383,  0.1832, -0.0248,  0.0479,  0.2050,\n          0.0121, -0.0030,  0.1644,  0.1419, -0.1695,  0.2190,  0.1042,  0.1193,\n          0.1567,  0.2010,  0.1015, -0.0390],\n        [ 0.1273,  0.0715, -0.0999, -0.1679,  0.1512,  0.0004, -0.0085,  0.0785,\n         -0.1023, -0.0667, -0.2234, -0.1901, -0.1578, -0.2061, -0.1392,  0.2148,\n          0.0688,  0.0356,  0.1379, -0.1140],\n        [ 0.0258,  0.1264, -0.1397,  0.1742, -0.0368, -0.2210,  0.0303, -0.1409,\n          0.0571, -0.0664, -0.1042,  0.0402, -0.0667,  0.1479, -0.0746, -0.1304,\n         -0.2228, -0.1364,  0.0354, -0.0698],\n        [ 0.0203,  0.1324,  0.2154,  0.1072, -0.0266,  0.0291,  0.1425,  0.1857,\n          0.1813, -0.1909,  0.2226,  0.0018, -0.1816, -0.1676, -0.1443, -0.1011,\n          0.0587,  0.0317,  0.0355,  0.2105],\n        [ 0.0036, -0.1975,  0.1060, -0.0662,  0.0554,  0.0176, -0.0474,  0.0559,\n         -0.1579, -0.1283, -0.1148,  0.2000, -0.1414, -0.0753,  0.0800, -0.1960,\n          0.1580, -0.1842,  0.2098, -0.0420],\n        [ 0.0901, -0.0648, -0.1891,  0.0362, -0.2067, -0.2215, -0.2069,  0.1687,\n         -0.0053, -0.2200,  0.0418,  0.1982,  0.1062,  0.1144,  0.1316,  0.1548,\n          0.1652,  0.2049,  0.0728,  0.1688],\n        [ 0.1715,  0.1340, -0.0307,  0.1830, -0.0239, -0.0564,  0.0472,  0.1510,\n          0.0816,  0.1523, -0.0233,  0.1678,  0.1027,  0.0285, -0.1927, -0.0012,\n         -0.0438,  0.0523, -0.0471,  0.0380],\n        [ 0.0941,  0.1364, -0.1528,  0.0382,  0.0821, -0.1713,  0.2171,  0.1308,\n          0.0388,  0.1173, -0.2148,  0.0073,  0.2128, -0.1571, -0.0689, -0.1691,\n          0.1282, -0.0461,  0.0146, -0.0421],\n        [ 0.0285, -0.0796, -0.1419,  0.1445, -0.0357, -0.2163,  0.2062,  0.0948,\n         -0.0186,  0.0561,  0.0169,  0.1263,  0.0701,  0.1180,  0.0572,  0.0024,\n          0.1242, -0.0098, -0.0007, -0.0317],\n        [-0.0567,  0.0092,  0.1541, -0.1433, -0.1703,  0.0900,  0.2075, -0.1133,\n         -0.0880,  0.2092,  0.1015, -0.1439,  0.1277, -0.0056, -0.0925,  0.1964,\n         -0.1767,  0.1134, -0.0753, -0.0726],\n        [ 0.1746,  0.1882,  0.1059,  0.0401,  0.0265,  0.1759, -0.0051,  0.1786,\n          0.0643,  0.1308, -0.1303,  0.1725,  0.2100, -0.1331,  0.0545, -0.2003,\n          0.0847, -0.0294,  0.1177, -0.1273],\n        [-0.0214,  0.0207, -0.0082, -0.1552,  0.2203,  0.1058, -0.1626, -0.2000,\n         -0.1287, -0.2034, -0.2119, -0.1682,  0.1613, -0.1275, -0.0784, -0.1826,\n         -0.0355,  0.0292,  0.0221, -0.0073],\n        [-0.1440,  0.2225,  0.2025, -0.1492, -0.0111,  0.1476, -0.1232, -0.0554,\n          0.0431,  0.1220, -0.0771,  0.1900,  0.1477,  0.0781,  0.0327, -0.0236,\n         -0.0262,  0.1635,  0.1182, -0.1115],\n        [ 0.1428,  0.1038,  0.0938, -0.1685, -0.1112, -0.1186, -0.0014, -0.0345,\n          0.1825,  0.2059,  0.1895,  0.2004, -0.1778,  0.0311,  0.1495, -0.0160,\n          0.0658, -0.0296, -0.0242,  0.0479],\n        [-0.0800, -0.1648,  0.0809, -0.1101,  0.1076,  0.0750,  0.0559,  0.1448,\n          0.1445,  0.0780,  0.2130,  0.0976, -0.0560,  0.1935,  0.2019,  0.0962,\n          0.0965, -0.1321, -0.2011,  0.1932],\n        [ 0.0211, -0.0800, -0.0175, -0.1416, -0.0586, -0.0524, -0.1171, -0.0594,\n         -0.1989,  0.2118, -0.0709,  0.0849,  0.0218,  0.1266, -0.1846,  0.0311,\n         -0.0802, -0.0383,  0.2129, -0.1411],\n        [ 0.2155, -0.1675,  0.0922,  0.1077, -0.0789,  0.0505, -0.0690,  0.1332,\n         -0.1571, -0.0242,  0.0818,  0.2218,  0.1484, -0.1952, -0.0362, -0.1423,\n         -0.1845, -0.1448,  0.0184, -0.1943],\n        [ 0.2032, -0.0112,  0.0309,  0.0162, -0.1567,  0.1551, -0.0964,  0.1876,\n         -0.0312,  0.0908, -0.1276, -0.2132, -0.0115,  0.0841,  0.0618, -0.1817,\n          0.1833,  0.0196, -0.0523, -0.2173],\n        [ 0.2011,  0.0163, -0.1031,  0.1792,  0.1690, -0.0900,  0.1697, -0.0083,\n         -0.0675, -0.0473,  0.0461,  0.2122,  0.0888, -0.2033,  0.2119,  0.1816,\n         -0.0332, -0.2169, -0.0250,  0.0427],\n        [ 0.0829,  0.0981, -0.1412, -0.0199,  0.1199,  0.0317, -0.0442,  0.1721,\n         -0.2200, -0.0583, -0.0653, -0.1724, -0.0694, -0.1988,  0.1479, -0.0154,\n         -0.0646, -0.0880, -0.1282,  0.2194],\n        [-0.0393, -0.1955,  0.2123, -0.0987, -0.0620, -0.1672,  0.1972, -0.1397,\n         -0.1092,  0.1256, -0.1717,  0.1313,  0.0166,  0.0110,  0.1996,  0.1275,\n         -0.0149, -0.1892,  0.1526, -0.1034],\n        [-0.1030,  0.2073,  0.0203, -0.0394, -0.0845,  0.0830,  0.1011,  0.0389,\n          0.0346,  0.0973, -0.0593,  0.0900,  0.1631, -0.0017, -0.2121,  0.0976,\n         -0.0749,  0.1268,  0.1800, -0.1886],\n        [-0.1904,  0.2124,  0.0966, -0.1198, -0.1497, -0.1006, -0.2211, -0.1945,\n          0.1432,  0.2098,  0.0378, -0.2105,  0.2111, -0.1287,  0.2075,  0.0707,\n         -0.0804,  0.1060, -0.0791, -0.1298],\n        [-0.0491, -0.1798, -0.1673,  0.0278, -0.1805,  0.0227,  0.0826, -0.0432,\n          0.1643,  0.1333, -0.1153, -0.0541, -0.1287,  0.1837,  0.0791,  0.0237,\n         -0.1765,  0.1509, -0.0373,  0.1192],\n        [-0.1933, -0.0248, -0.0288,  0.1108,  0.0285,  0.1841,  0.0483,  0.0420,\n         -0.2090,  0.0306, -0.0840,  0.0702, -0.0437,  0.2081,  0.1430, -0.2210,\n          0.2159, -0.0021, -0.0444,  0.1257],\n        [-0.0205, -0.0728, -0.0012, -0.2011, -0.2032,  0.1478,  0.0016, -0.0362,\n         -0.1493, -0.0123,  0.0383,  0.0109,  0.0743, -0.0556, -0.2187,  0.0639,\n         -0.0936,  0.0854,  0.0820,  0.1537],\n        [ 0.0377, -0.1613, -0.0428,  0.0295, -0.0471, -0.2219,  0.0995, -0.1352,\n          0.1498, -0.1976,  0.0481, -0.0953, -0.0156,  0.0453, -0.1030, -0.1449,\n          0.2022,  0.1039, -0.2042, -0.0422],\n        [ 0.0852, -0.1593, -0.1638,  0.1107,  0.1547,  0.1075, -0.0604, -0.1864,\n          0.2106, -0.0172,  0.0046,  0.1864,  0.1405,  0.0832,  0.0371,  0.2003,\n         -0.1386, -0.1334,  0.1940, -0.1026],\n        [ 0.1585,  0.1983, -0.1190, -0.1040, -0.1448,  0.2170,  0.0258, -0.1132,\n         -0.1579,  0.0554,  0.1717, -0.1798, -0.0228, -0.0337,  0.1794, -0.0504,\n         -0.1770,  0.0449, -0.1938,  0.2219],\n        [ 0.1359, -0.2080, -0.1851,  0.0584,  0.1221, -0.2063, -0.1081, -0.1163,\n          0.0286,  0.1107, -0.2166,  0.0948,  0.0685, -0.0332,  0.0762, -0.1972,\n          0.2106, -0.0288, -0.1722, -0.0014]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0370, -0.0840, -0.1321, -0.1424, -0.0326, -0.1637, -0.1255,  0.0408,\n        -0.0712,  0.1417, -0.1694, -0.0905,  0.0138,  0.1999,  0.1828, -0.1160,\n         0.1346, -0.1246, -0.1006, -0.0443, -0.1587,  0.1090,  0.1326,  0.0460,\n        -0.0814,  0.1716,  0.1650,  0.0313,  0.0727,  0.2054,  0.0853,  0.0506],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-1.0170e-01, -1.6609e-01, -1.5761e-01,  1.1616e-01,  1.9245e-02,\n          6.4376e-02, -1.7646e-01,  1.5578e-01,  8.1621e-02, -1.2918e-01,\n          9.3082e-02,  5.9229e-02, -5.0255e-02,  1.0425e-01, -1.2722e-01,\n         -1.0196e-01,  1.9369e-02, -3.7177e-03,  1.3550e-01, -1.2705e-01,\n         -4.9517e-02, -7.6741e-02, -6.4330e-02, -1.0805e-01,  8.7787e-02,\n         -2.5961e-02,  1.3613e-01, -6.9482e-02, -1.1996e-01,  5.6312e-02,\n          9.3746e-02, -1.2992e-01],\n        [-1.7043e-01, -5.3929e-02, -9.6298e-02, -6.8864e-02, -8.4070e-02,\n          1.5324e-01, -4.3836e-02,  1.1306e-01,  8.2026e-02, -6.2796e-02,\n         -1.5129e-01, -1.6811e-01, -1.4185e-01,  1.1133e-01, -1.3438e-01,\n          3.5072e-02,  2.1136e-02, -6.6011e-02, -1.5118e-01,  7.5604e-02,\n          1.3913e-02, -1.4324e-01,  1.4589e-02, -3.7861e-02, -5.4850e-02,\n         -8.6965e-02, -8.9004e-02, -1.5736e-01, -6.6017e-02, -1.6057e-01,\n          1.6204e-02,  1.1914e-01],\n        [ 3.8737e-02, -1.3384e-01, -1.5388e-01, -5.1072e-02,  1.2452e-02,\n          1.4560e-01, -1.3627e-01, -3.4444e-02,  2.6617e-02, -1.0716e-01,\n          6.5192e-02,  9.7020e-02,  1.1739e-01, -1.4199e-02, -1.1683e-01,\n         -1.3350e-01, -1.4241e-01,  4.3409e-02, -3.0875e-02,  1.0795e-01,\n          7.0999e-02, -1.0311e-02, -6.5740e-02,  8.0675e-02,  9.8671e-02,\n         -4.6852e-02,  5.8280e-02, -1.5269e-01,  1.9240e-02, -1.1077e-01,\n         -8.5285e-02,  4.1702e-02],\n        [-1.2371e-01,  2.6134e-02, -1.1842e-01, -8.9140e-02, -1.4076e-01,\n          3.2192e-02,  4.0129e-02,  9.3133e-02,  9.4781e-02, -5.4289e-03,\n         -1.4463e-01,  8.3724e-02,  4.8921e-02, -2.9041e-02, -7.6518e-02,\n          1.2666e-01,  1.7378e-01,  6.8703e-02, -1.0414e-01,  1.6422e-01,\n          7.5511e-02,  1.2955e-01,  6.9924e-02,  1.2425e-01,  5.1259e-02,\n          1.0113e-01,  4.7470e-02,  2.6545e-02, -1.1124e-01, -1.5487e-01,\n          3.4230e-03,  6.2369e-02],\n        [ 1.2718e-01, -1.6173e-01,  6.1753e-02,  9.8219e-02,  3.7350e-02,\n         -1.3579e-02, -8.8900e-02, -4.0834e-02, -1.0937e-01,  8.3008e-02,\n         -1.6400e-01, -1.0291e-01,  1.5464e-01, -1.4380e-01, -1.0216e-01,\n          7.4255e-02, -1.7191e-01, -2.8472e-02, -1.8692e-02,  1.6823e-02,\n         -6.5504e-02,  1.4984e-01,  1.5714e-01, -7.5070e-02,  8.0967e-02,\n          1.4305e-02, -1.3869e-01,  2.1601e-02, -7.9648e-02,  6.8769e-02,\n         -1.3458e-01, -8.1929e-02],\n        [ 1.1824e-01,  1.0041e-01,  7.6132e-02, -1.3916e-01,  1.1557e-01,\n          7.9328e-02, -9.5608e-02,  1.6031e-02, -1.4831e-01,  9.7387e-02,\n          5.5315e-02, -7.2208e-02, -1.7158e-01,  1.3175e-01, -3.3723e-02,\n          1.2184e-01, -9.4515e-02,  3.7955e-02,  1.7521e-01, -2.9532e-03,\n          1.3257e-02,  6.9290e-02, -1.0734e-01, -8.5002e-02,  1.6664e-01,\n         -1.7293e-01,  6.3770e-02, -1.3396e-01, -1.1401e-01, -3.0788e-02,\n         -1.1792e-01,  2.6354e-02],\n        [-2.3952e-02,  5.0994e-02, -1.2904e-01,  6.7218e-02, -1.3138e-01,\n          1.5239e-01, -1.1748e-01,  1.5612e-01,  5.4131e-02, -2.3370e-02,\n         -3.1950e-02,  6.2822e-02, -1.7576e-02,  1.0672e-01, -8.5683e-02,\n          1.1178e-01, -7.9377e-02,  3.6551e-02, -1.7577e-01, -1.0858e-03,\n          1.5321e-01,  7.0369e-02,  1.0749e-01,  1.4668e-01,  1.1682e-02,\n         -1.0567e-01, -6.6732e-02,  1.2491e-01, -2.9588e-02, -1.3133e-01,\n          7.8055e-02, -1.4277e-01],\n        [ 2.5876e-02, -1.6620e-01, -2.5260e-03, -1.0982e-01,  1.3950e-01,\n          1.1686e-01,  1.1743e-01, -1.1945e-03, -1.4300e-01,  4.3185e-02,\n          1.3508e-01, -6.0373e-02, -1.1555e-01,  1.8405e-02, -1.7420e-01,\n         -5.9210e-03, -1.0948e-02, -1.6650e-01,  2.5087e-02, -1.4012e-01,\n          9.7608e-04, -9.8016e-02,  7.7103e-02,  2.5247e-02, -9.0211e-02,\n         -1.1303e-01, -5.9012e-02, -1.3949e-01,  1.7116e-01, -5.7403e-03,\n         -1.6130e-02, -1.0421e-01],\n        [-1.4205e-01,  1.1144e-01, -1.2711e-01,  1.1885e-01,  7.6776e-02,\n          5.4092e-02,  9.8315e-02,  5.2074e-02,  1.1524e-01, -1.1134e-01,\n          1.5104e-01, -1.7428e-01, -1.0908e-02, -4.0633e-02, -7.3941e-02,\n         -8.4276e-02,  2.6917e-02,  1.1311e-01,  1.5029e-01, -1.0775e-01,\n          1.6601e-01, -1.6922e-01, -7.2639e-02, -6.1614e-02, -1.3172e-01,\n          1.0326e-01, -1.2838e-02,  2.2626e-02, -5.3053e-02,  6.9286e-02,\n         -1.1252e-01, -1.4227e-01],\n        [-7.4251e-02,  9.9483e-02,  1.4285e-01,  2.0131e-02,  8.7928e-02,\n          5.4128e-02,  1.2101e-01, -4.8880e-03,  4.9036e-02,  1.5745e-01,\n         -8.9915e-02, -5.3570e-02, -5.0085e-02, -2.1579e-02,  4.0033e-04,\n         -7.1535e-02, -2.0013e-02, -2.1430e-04,  1.3398e-01, -1.7447e-01,\n         -1.7297e-01, -6.8547e-02,  4.5849e-02,  3.1067e-02, -1.6672e-01,\n          5.6962e-02,  1.4625e-01, -3.7960e-02,  7.8298e-02, -1.8459e-02,\n          5.3324e-02, -9.3580e-02],\n        [ 1.5926e-01,  1.3308e-01, -1.1087e-01,  1.5729e-01,  6.9048e-02,\n         -5.1128e-02, -1.0592e-01,  9.3955e-02, -1.0492e-01,  1.3315e-02,\n          2.1626e-02, -5.6758e-02, -1.2134e-02,  1.4453e-01, -7.3356e-02,\n          5.2557e-05, -9.0784e-02, -6.2476e-02, -8.2035e-02, -7.6562e-02,\n         -1.6724e-04, -1.2233e-01,  7.5160e-02,  3.1701e-02, -1.4945e-01,\n         -1.4239e-01, -1.6495e-01,  1.5003e-01,  1.0201e-01,  6.3350e-02,\n         -1.8615e-02, -7.6800e-02],\n        [-2.1126e-02, -1.0779e-01,  1.0782e-01,  1.6219e-01,  1.4099e-01,\n          3.0783e-02,  8.9899e-02,  1.5258e-01,  3.9861e-02, -9.6814e-02,\n          1.5272e-02,  1.3023e-01, -1.2340e-01,  7.0984e-02,  5.8770e-02,\n          2.2846e-02, -1.5902e-01,  1.0212e-01, -7.8317e-02,  1.0150e-01,\n          5.8702e-02, -1.1046e-01,  6.6850e-02, -8.2416e-02,  9.9805e-02,\n         -4.6080e-02, -1.5726e-01,  1.2873e-01, -7.5139e-02, -3.1413e-02,\n          4.3859e-02,  1.4228e-01],\n        [ 1.2319e-01, -5.0328e-02,  1.6423e-01, -1.1634e-01,  9.7814e-02,\n          5.7009e-02,  1.6781e-01,  1.5779e-01, -6.0810e-02,  1.3958e-01,\n          6.0557e-02,  4.9207e-03,  2.0104e-02, -3.9564e-02,  1.6948e-01,\n          1.3961e-01, -3.3689e-02,  1.2790e-01, -1.5719e-01, -1.1847e-01,\n          1.6792e-01,  6.7760e-02,  3.5858e-02, -1.4142e-01, -1.6816e-01,\n         -1.3218e-01,  1.1826e-01,  7.3280e-02,  7.6655e-02,  9.2150e-02,\n          6.8555e-02, -4.2000e-02],\n        [ 7.5205e-02, -1.5904e-01, -1.5034e-01, -1.8872e-02,  3.2240e-02,\n          8.9968e-02, -1.3073e-01, -1.4735e-01,  1.0941e-01,  2.5325e-03,\n          1.8730e-02,  1.7377e-01, -9.7168e-02,  5.9876e-02,  1.5477e-01,\n          1.0930e-01, -3.1922e-02,  1.1443e-01, -1.5108e-01,  7.8438e-02,\n          1.2005e-01, -3.4481e-02,  1.2429e-01,  4.6414e-02, -1.2260e-01,\n         -1.3829e-01, -1.0749e-01, -1.5271e-01, -4.4664e-02, -4.5066e-02,\n          7.6559e-02,  1.7091e-01],\n        [-8.4002e-02,  8.2721e-02,  1.4606e-01,  3.2719e-02, -3.2232e-02,\n          1.6053e-01,  5.5287e-02, -3.2439e-03,  3.0295e-02,  1.1435e-01,\n          1.5494e-01,  1.2405e-02, -1.4597e-02,  5.3919e-02, -4.6946e-02,\n         -7.4082e-02,  1.6628e-01, -7.4647e-02,  1.6390e-01,  8.5168e-02,\n         -1.1401e-01,  1.3816e-01, -1.4334e-01,  1.2724e-01,  2.3523e-02,\n          1.4470e-01, -1.3595e-02,  5.3746e-02, -9.7549e-02, -1.5623e-01,\n         -3.2205e-02, -1.5255e-01],\n        [-9.4418e-02, -5.4561e-02, -1.4188e-01,  1.3924e-01, -1.6007e-01,\n         -3.5750e-02,  2.4387e-02, -1.5989e-01, -1.5813e-01, -6.0060e-02,\n          6.5288e-02, -1.2842e-01, -2.7339e-02, -1.1156e-01, -7.8107e-02,\n          2.6569e-04, -3.7066e-02, -5.8602e-02, -7.7830e-03,  1.8958e-02,\n         -1.2652e-02, -1.5847e-01,  1.2697e-01,  3.7453e-03, -3.1699e-02,\n          1.5759e-01, -8.0743e-04,  1.5878e-01,  1.6127e-01,  1.5908e-01,\n         -1.5163e-01, -3.3689e-03]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0818, -0.0996,  0.0679,  0.1517, -0.0219,  0.0441,  0.0063, -0.0064,\n        -0.0857,  0.0933, -0.0467,  0.0546,  0.0345, -0.1027,  0.1757,  0.1741],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1352,  0.1691, -0.1113,  0.2167,  0.0886,  0.2156, -0.2255,  0.0907,\n          0.1004,  0.2052,  0.2337, -0.0355, -0.1324,  0.1074,  0.1376, -0.2259],\n        [ 0.1110,  0.2116,  0.1869, -0.0790, -0.1922,  0.1403, -0.0053,  0.0790,\n         -0.1008,  0.1719,  0.0012,  0.1627, -0.2076,  0.1955, -0.1545, -0.1104],\n        [ 0.2128,  0.2213, -0.0937, -0.0937, -0.2075,  0.2283, -0.2194,  0.0266,\n         -0.0926,  0.1267, -0.0614,  0.2423,  0.0244,  0.1513, -0.1228,  0.1123],\n        [-0.1541, -0.1660,  0.0725, -0.0003, -0.1533,  0.0342, -0.0663,  0.0481,\n          0.1898, -0.2429,  0.1870, -0.0548, -0.0225, -0.2352, -0.1777,  0.0815],\n        [-0.2212,  0.1120,  0.2339,  0.0008,  0.0318,  0.1031,  0.0187, -0.0945,\n         -0.1901, -0.1487,  0.1380,  0.1711, -0.1067, -0.2404,  0.0563, -0.1585],\n        [-0.0884, -0.1067,  0.0025,  0.1414, -0.0490, -0.0112, -0.1876, -0.2298,\n         -0.1314,  0.2289,  0.0950,  0.1093, -0.1710, -0.1992,  0.1056, -0.1949],\n        [ 0.2175,  0.1216,  0.1083, -0.2249,  0.1351, -0.0502,  0.1764,  0.2314,\n          0.2395,  0.0313, -0.1195, -0.1758,  0.1313,  0.0096,  0.2189,  0.2282],\n        [ 0.0876,  0.0760, -0.0948, -0.0384,  0.2121,  0.0845, -0.0056, -0.0379,\n          0.2463, -0.1291, -0.1970, -0.1053, -0.2229, -0.2208, -0.2454, -0.2374]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2107, -0.1349,  0.1669,  0.0221,  0.0124,  0.1211,  0.0441, -0.0926],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1567, -0.3092, -0.0211,  0.0159, -0.0552, -0.2409, -0.2798,  0.2765]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2429], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x11550e350>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x125b18760>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s57380000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s57380000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}