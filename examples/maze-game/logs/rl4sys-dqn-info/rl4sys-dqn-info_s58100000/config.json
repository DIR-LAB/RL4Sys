{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s58100000"
    },
    "q_lr":	0.0005,
    "seed":	58100000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x111dccbe0>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1778, -0.0668,  0.0054, -0.0238,  0.1190, -0.0852, -0.0793, -0.1436,\n        -0.0929, -0.1273, -0.1608, -0.0247,  0.1457, -0.1692,  0.2076, -0.1551,\n         0.2128, -0.1952, -0.1494,  0.1736, -0.1785, -0.2093, -0.0469,  0.1586,\n         0.0910, -0.2070, -0.2218, -0.0244, -0.0162, -0.1686, -0.1752,  0.1270],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-5.4398e-02,  1.9477e-02,  1.9009e-01, -5.4469e-02,  4.3776e-02,\n          1.1481e-01, -6.1554e-02, -1.4086e-01,  1.1198e-01,  8.1012e-02,\n          2.7447e-02,  2.6465e-02, -1.4859e-01, -3.9663e-02, -7.3860e-03,\n          1.0376e-01, -2.0066e-01,  1.0026e-01,  1.5092e-02, -1.1101e-01],\n        [-9.2282e-02, -6.6070e-02, -1.2088e-01,  2.0589e-01, -1.9743e-01,\n         -5.0331e-02,  4.4274e-02,  1.1300e-01,  6.1154e-03, -2.2287e-01,\n          1.5761e-01, -1.0607e-01, -2.1154e-01,  9.4908e-02,  4.4955e-02,\n          5.0432e-02, -5.8642e-02, -2.0771e-03,  4.0867e-02,  4.2906e-02],\n        [-2.2081e-01,  2.1177e-01,  2.1032e-01,  7.8405e-03,  1.1086e-01,\n         -3.8370e-02,  1.2874e-01, -1.9603e-01,  7.1460e-02, -1.8452e-01,\n          1.2167e-01, -3.3408e-02,  1.5267e-01,  1.7503e-01,  3.9277e-02,\n         -2.1098e-01, -6.5026e-02,  9.8162e-02, -1.1059e-01, -8.4810e-02],\n        [-4.2005e-02,  1.8967e-01,  1.0121e-01, -1.2811e-01, -1.3224e-01,\n          1.8656e-01, -1.0578e-01,  4.0271e-02, -2.2705e-02, -1.2257e-01,\n         -1.5168e-01, -1.2289e-02, -2.0651e-01, -2.7117e-02,  1.8746e-01,\n          1.8435e-01,  1.1424e-01, -1.2814e-02,  9.6271e-02,  2.2222e-02],\n        [-1.2823e-01,  1.1180e-02,  1.6668e-01, -1.5742e-01,  6.7022e-02,\n         -1.7365e-01, -1.0457e-01, -7.4602e-02,  6.2441e-02, -1.0341e-01,\n         -2.1970e-02, -1.0296e-01, -1.6507e-01,  3.1358e-02, -2.0740e-01,\n          2.2355e-01,  8.4778e-02,  4.3146e-02,  1.8206e-01,  1.4595e-01],\n        [-1.3428e-01,  1.6672e-01,  1.8638e-01, -1.3683e-01,  1.0544e-01,\n          2.3774e-02, -1.6633e-01,  2.0427e-01, -6.4478e-02,  1.7620e-01,\n         -1.6198e-01,  8.4512e-02, -1.1739e-01,  1.1380e-01,  4.9946e-02,\n          2.3714e-02, -1.1344e-01, -1.5220e-01, -7.3189e-02, -3.3484e-02],\n        [ 6.7054e-02,  2.1386e-01,  2.0482e-01,  6.2422e-02,  2.2021e-01,\n          1.0896e-02, -2.0282e-01,  8.1531e-02,  7.8889e-02,  1.6035e-01,\n          1.7058e-02,  1.8248e-01, -1.4675e-01, -1.9625e-01, -6.5408e-02,\n          1.4561e-03,  1.9920e-01, -9.9177e-02, -1.3334e-01, -4.8585e-02],\n        [ 1.2716e-01, -1.4643e-01, -8.8904e-02,  1.8826e-01, -1.8156e-01,\n          4.4728e-02, -1.0907e-02,  3.8411e-02,  2.9272e-02, -5.0271e-02,\n          7.4955e-02,  1.9367e-01, -2.2246e-01, -2.1891e-01,  1.0303e-01,\n          7.9589e-03,  6.3569e-02, -5.1097e-02,  1.7302e-01, -1.5290e-01],\n        [ 1.7727e-01,  1.1770e-01, -2.1897e-01,  1.4153e-01,  1.9588e-01,\n          9.7261e-03,  1.7749e-01,  3.2101e-02,  8.4624e-02,  3.5259e-02,\n          1.2492e-01,  1.9582e-01, -1.2110e-01,  1.1142e-01, -1.4377e-01,\n         -2.2368e-02, -1.5095e-01, -2.8797e-02, -1.9803e-01, -2.3920e-03],\n        [-1.8676e-01,  2.0685e-01, -1.9505e-01,  7.5257e-02, -1.4364e-01,\n          1.4681e-01,  6.3373e-02,  1.6508e-02,  1.8767e-01,  4.4673e-02,\n          4.7240e-02,  3.9045e-02,  6.2387e-02,  9.3896e-02,  7.1851e-02,\n          1.2768e-01,  1.0923e-01, -4.9351e-02, -4.2467e-02,  1.8325e-03],\n        [-4.0946e-02, -1.4511e-01,  2.0464e-02, -2.0421e-02,  1.4622e-01,\n          1.2307e-01,  9.5863e-03,  2.9410e-02,  2.1942e-01,  4.6983e-02,\n         -1.2605e-01, -9.8995e-02,  2.1468e-01,  1.2963e-01,  2.2109e-01,\n          8.6598e-02, -1.0391e-01,  1.4963e-02, -1.3188e-01, -9.3844e-02],\n        [-2.6789e-02,  1.4553e-01, -6.7305e-02,  1.5055e-01, -3.6959e-03,\n         -1.6678e-01,  1.9961e-01,  2.1324e-01, -1.3590e-01, -7.0929e-02,\n         -8.7916e-02, -7.7043e-02, -2.0171e-01,  3.1027e-02,  6.6571e-02,\n         -5.1207e-02, -2.1884e-01,  1.5426e-01,  6.1714e-02,  1.8436e-01],\n        [-2.0359e-01,  2.3393e-02,  1.7752e-01, -2.1664e-01,  1.9602e-01,\n          6.1665e-02,  2.0793e-01,  1.4490e-01,  5.0569e-02,  1.6427e-02,\n          5.3748e-02,  2.0472e-01, -7.3347e-02, -1.5528e-01, -2.0570e-01,\n         -2.0246e-01,  1.5791e-01, -1.3277e-01,  1.9402e-01, -6.2632e-02],\n        [ 9.4264e-02, -1.0118e-01,  1.6532e-01, -3.4956e-02, -2.5337e-02,\n         -2.1650e-01,  1.1012e-01,  1.5419e-01, -7.6559e-02,  1.0604e-01,\n          6.1772e-02,  4.3380e-02,  3.9616e-02,  2.0358e-01, -1.9850e-01,\n         -4.7240e-02,  1.2176e-01,  2.0812e-01, -1.2365e-01, -1.4009e-01],\n        [ 1.2481e-01, -6.9933e-02, -6.0654e-02,  6.8119e-02, -2.0463e-01,\n          6.2859e-02, -5.6036e-02, -1.8434e-01,  1.5101e-01,  8.7080e-02,\n          8.2475e-02, -9.5700e-02, -3.2714e-02, -1.1085e-01, -1.6478e-01,\n          9.8667e-02, -5.8015e-02, -8.9418e-02, -4.9915e-02,  4.9942e-02],\n        [-1.2069e-01, -9.6701e-02,  2.0845e-01,  1.3818e-01, -1.2981e-02,\n         -1.6669e-01,  1.3793e-01,  4.5653e-03, -6.5113e-02, -1.2720e-04,\n         -8.8971e-02,  2.2249e-01,  1.3458e-01, -3.6059e-02,  1.4153e-01,\n         -1.1789e-01, -2.6320e-02, -3.2542e-02, -2.0910e-01, -1.5265e-01],\n        [-3.7676e-02, -1.6291e-01, -7.7324e-02,  4.7588e-02, -3.0338e-02,\n         -1.4706e-01,  1.0061e-01, -1.8545e-01,  1.4543e-01, -1.8220e-01,\n          2.0471e-01,  2.7299e-02,  1.5060e-01,  1.2221e-01,  1.6172e-01,\n         -9.0571e-02,  8.1236e-02,  1.7974e-01,  2.3539e-02, -1.3360e-01],\n        [ 1.3973e-01,  2.9259e-02,  3.1382e-02,  9.8032e-02,  1.6748e-01,\n         -7.6166e-02,  1.1677e-01,  8.8923e-02, -1.6719e-01,  2.0148e-01,\n          1.4181e-01, -9.2495e-02, -5.3740e-03, -4.9907e-02, -1.1552e-02,\n         -3.9944e-02,  2.0774e-01,  2.1520e-01, -1.9647e-01,  1.6656e-01],\n        [ 2.0650e-02,  1.9100e-01,  2.0213e-01,  1.0032e-01, -6.9817e-02,\n         -1.8908e-01, -1.9876e-01, -1.3914e-01,  1.5468e-02,  5.0688e-02,\n          2.0625e-01, -1.0398e-01, -3.5289e-03,  1.8294e-01,  2.0553e-01,\n          1.7418e-02, -1.9330e-01,  5.1505e-02, -2.0570e-01, -1.4389e-01],\n        [-1.5107e-01, -1.1547e-01,  3.8420e-02, -7.1539e-02, -4.4038e-02,\n          2.0651e-01,  3.1658e-02, -2.1306e-01, -1.7298e-01, -1.4693e-01,\n          1.9514e-01,  1.7463e-01, -1.8185e-01,  3.3539e-02,  1.5336e-01,\n          1.9313e-01, -8.2709e-02,  4.1627e-02,  1.4218e-01,  5.8048e-02],\n        [-9.8931e-02,  6.0354e-02, -1.5183e-01,  1.4548e-01,  3.3443e-02,\n          1.8907e-01, -1.0193e-01,  7.7178e-02, -1.5931e-01, -1.9329e-01,\n         -2.0520e-01,  2.0842e-01,  1.1540e-01,  2.2068e-01,  3.3372e-02,\n          8.0812e-02,  1.7284e-01, -1.1445e-02,  2.8312e-02,  9.4436e-03],\n        [ 4.4368e-02,  1.0195e-02,  1.0181e-01,  1.9570e-01, -1.2817e-01,\n          1.1477e-01,  1.6932e-01,  7.4257e-02,  1.5120e-01,  1.5427e-01,\n          3.1649e-02, -3.1256e-02, -2.1423e-01, -1.9024e-01,  1.0139e-02,\n          1.9075e-01, -1.4725e-01, -5.9702e-02,  1.0983e-02,  2.0463e-02],\n        [ 1.9104e-02,  1.9243e-01,  7.2049e-03, -1.3617e-01,  1.5150e-01,\n          1.7909e-01,  2.2242e-01,  1.8434e-01, -4.3445e-02, -1.2303e-01,\n         -4.3975e-02, -8.4699e-03,  2.9391e-02,  1.7815e-01,  2.0383e-01,\n          5.2578e-03, -2.2121e-01, -8.3965e-02,  2.9256e-02, -1.3861e-01],\n        [-1.0460e-01,  1.7614e-01, -2.0450e-02, -1.6691e-01, -1.4160e-01,\n          2.8292e-03,  2.2023e-02,  1.0725e-01,  8.5284e-02,  1.7492e-01,\n          6.2491e-02,  1.3531e-01,  2.1536e-01,  1.1522e-01, -1.8899e-01,\n         -1.4173e-01,  1.0479e-02, -6.4106e-02,  1.0987e-01,  6.8897e-02],\n        [ 2.0641e-01, -1.9459e-01,  2.0908e-01,  2.0599e-01, -9.9865e-02,\n         -8.7452e-02,  6.8052e-02,  2.0576e-01, -1.4198e-01, -2.1335e-01,\n         -2.1378e-01,  1.0186e-01,  1.5381e-01, -4.4634e-02, -2.1697e-01,\n         -8.6524e-02,  8.9442e-02,  1.4469e-01, -1.1071e-03, -7.7723e-02],\n        [-1.2535e-01,  1.0368e-01,  2.5944e-02, -2.0398e-01, -1.1944e-01,\n          2.1968e-01,  4.1744e-02, -2.0103e-01,  3.2336e-02, -5.1419e-02,\n          1.0327e-01,  5.5496e-02,  1.4131e-02, -2.1988e-01, -1.2159e-01,\n          1.6511e-01, -1.0132e-01,  4.4579e-02, -1.6384e-01, -9.7751e-02],\n        [ 9.0444e-03,  8.5858e-02,  1.4166e-01, -1.8144e-02,  1.2766e-01,\n          1.3110e-01, -3.1578e-02,  1.7624e-01, -2.2151e-02,  1.0181e-02,\n          6.3797e-02, -5.1871e-02,  9.3697e-02, -6.3054e-02, -1.2536e-01,\n          8.2270e-02,  1.1673e-01,  1.0958e-01, -7.0492e-03, -1.0543e-01],\n        [ 1.7630e-01, -4.8736e-02,  7.9775e-02,  1.8938e-01, -7.3377e-02,\n         -1.6081e-01, -5.8106e-02,  7.7529e-02, -1.0085e-01,  1.7482e-01,\n          8.3623e-02,  1.5420e-01, -1.7050e-01, -2.0181e-01, -1.3806e-01,\n          2.1899e-01,  1.0543e-01, -3.0703e-02,  2.9160e-02,  1.6979e-01],\n        [-2.1402e-03, -9.9917e-02,  1.5799e-01,  2.2287e-01, -8.2699e-03,\n         -1.4765e-01,  1.7290e-01,  1.5062e-01,  1.2838e-01, -2.0332e-02,\n          2.2283e-02,  4.5528e-02,  1.8186e-01,  5.1476e-02, -2.2165e-01,\n         -1.2472e-01, -2.2971e-02, -4.9787e-02,  5.8494e-02,  1.0702e-01],\n        [-8.1729e-03, -1.2646e-01, -1.0784e-01, -1.5839e-01, -1.8682e-01,\n          7.8030e-02, -6.5126e-02, -1.7038e-01, -1.0805e-01,  1.3853e-01,\n         -6.8626e-02, -5.4366e-02, -8.5484e-03, -4.9113e-02,  1.1226e-01,\n         -9.2965e-02,  9.6921e-03, -7.6261e-02,  6.2077e-03,  1.8528e-02],\n        [-5.4354e-02,  6.5367e-03,  1.3932e-01,  1.3766e-01, -6.8040e-02,\n         -1.5274e-04,  2.9356e-02, -2.7234e-02,  1.6840e-01,  2.0386e-01,\n          1.4871e-01, -2.1623e-01,  9.8788e-02, -4.5762e-02, -6.5619e-02,\n          9.3326e-02, -7.2877e-02, -2.0672e-01, -2.0218e-02,  1.7275e-02],\n        [-4.9633e-02,  1.9871e-02,  1.1628e-02,  1.3543e-01,  2.4297e-03,\n         -1.1755e-05,  9.6571e-03, -1.6874e-01,  1.3051e-01,  1.5447e-01,\n          8.9107e-03,  2.0973e-01,  4.1523e-02,  1.4025e-01, -1.1768e-01,\n         -1.6499e-01, -7.4540e-02, -1.9633e-01, -1.4150e-01, -1.5467e-01]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0525,  0.0541, -0.1603,  0.0511, -0.0818, -0.1044,  0.0127,  0.0593,\n         0.0926,  0.0815,  0.0199,  0.1717, -0.0510, -0.0362, -0.0380,  0.0995],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.5606e-01, -7.6403e-02,  3.4836e-02, -1.6471e-01, -1.6136e-01,\n         -4.2377e-02,  7.5235e-02,  1.3786e-01, -5.3009e-02, -1.6281e-01,\n         -8.6055e-02,  1.1235e-01, -1.6242e-01, -1.4966e-01,  1.6095e-01,\n         -1.6357e-01, -6.2266e-03,  9.0776e-03, -2.9045e-02,  1.0389e-01,\n          1.3666e-01, -8.6099e-02, -1.3593e-01, -1.2887e-01,  9.7793e-04,\n          1.5606e-01,  1.5149e-01, -2.6495e-02,  1.1606e-01,  6.7220e-02,\n         -3.5739e-02, -6.7235e-02],\n        [ 5.7301e-02,  1.1763e-02,  1.4281e-01, -9.9940e-02, -1.3985e-01,\n          8.3441e-02,  1.3296e-01,  1.8238e-02, -1.3544e-01, -1.3476e-01,\n          1.4084e-01, -1.3553e-01, -1.4751e-02, -3.9471e-02,  8.2833e-02,\n          2.0631e-03, -8.7535e-02,  4.0824e-02, -7.6236e-02, -1.2435e-03,\n         -1.3650e-01, -2.5871e-02, -1.7540e-01, -9.8323e-02, -1.1645e-01,\n          1.7234e-01,  9.1077e-02, -1.2831e-01,  1.2958e-01,  1.0992e-01,\n          1.5628e-01,  8.6222e-02],\n        [-2.2607e-02, -1.2798e-01, -8.6279e-02,  6.4059e-02, -1.5298e-01,\n         -1.0604e-01, -4.3266e-02,  1.0328e-01, -3.1046e-02,  3.1129e-02,\n         -1.3941e-01, -8.9010e-02, -6.4963e-03, -1.2993e-01, -3.5078e-02,\n          7.1380e-02, -5.8003e-02,  1.0399e-01,  1.2241e-01, -1.5720e-01,\n         -1.0310e-01,  9.2322e-02, -6.3348e-02,  1.6497e-02, -6.5481e-02,\n          2.5957e-02, -1.6074e-01, -9.1666e-02,  1.7527e-01,  9.9327e-02,\n         -1.7672e-01, -9.6256e-03],\n        [ 7.2040e-02,  4.2639e-02, -1.1125e-01,  1.0813e-01,  7.8628e-03,\n         -4.2908e-02, -1.1617e-01,  2.6125e-02, -1.5008e-01,  1.6595e-02,\n         -2.7932e-02,  5.7900e-02,  1.7063e-01,  1.7659e-01, -5.2852e-03,\n         -1.2707e-01,  1.5723e-01,  1.6238e-01,  2.1641e-02, -9.9542e-02,\n         -6.3989e-02,  5.1899e-03, -3.3351e-02, -1.0076e-02,  4.0024e-02,\n         -1.4963e-01, -1.0262e-01,  1.3250e-01,  3.4798e-02, -9.7245e-03,\n         -6.7027e-02, -1.3479e-01],\n        [ 1.3582e-01, -5.8978e-02,  1.0411e-01,  1.5647e-01,  1.6232e-01,\n          2.7669e-02,  4.0252e-02,  1.0653e-01,  7.3400e-02, -2.2193e-02,\n         -1.4283e-01,  6.2085e-02,  1.1310e-01,  3.7942e-02, -1.1441e-01,\n          1.3356e-01, -1.1781e-03,  8.0605e-02,  4.3599e-02,  9.4051e-02,\n          1.7498e-01,  1.1356e-01, -1.4553e-01, -1.1002e-01,  5.4773e-02,\n         -6.9634e-02,  1.6485e-01, -8.2035e-02,  6.8124e-03,  2.6774e-03,\n          9.8367e-02, -3.4246e-02],\n        [-1.5045e-01, -8.2272e-02,  7.8783e-04, -6.7055e-02,  1.0221e-01,\n         -4.8714e-02,  8.8842e-02,  1.5594e-01,  1.0230e-01, -2.5778e-02,\n          1.7059e-01,  1.3978e-01,  1.7382e-01, -7.7231e-02,  3.7282e-02,\n         -1.0844e-01,  3.7810e-02, -6.6256e-02,  9.7802e-03, -1.3619e-01,\n         -3.7740e-02,  1.1598e-02,  1.2823e-03,  1.0399e-01,  6.9928e-02,\n         -5.7624e-02,  1.3887e-01, -1.3823e-01, -2.0311e-02,  1.1972e-01,\n          1.1828e-01, -2.5364e-02],\n        [-5.5353e-02, -1.7380e-01,  1.5612e-01,  1.1442e-01, -3.9391e-02,\n          1.1436e-01,  1.6490e-01,  2.0415e-02, -9.8849e-02,  1.1396e-01,\n          2.3001e-03, -1.0731e-01, -4.6260e-02,  1.1822e-01,  1.4058e-01,\n         -5.0886e-02,  6.5194e-02,  9.1820e-02,  8.3729e-03, -1.5833e-01,\n          6.1605e-02,  1.2519e-01, -1.0834e-02,  5.8851e-02,  1.5875e-02,\n          9.1380e-02,  1.4039e-01,  3.8884e-02, -1.0410e-01,  9.4763e-02,\n         -9.0825e-03,  1.0670e-01],\n        [ 1.1955e-01, -8.9995e-02, -6.4890e-02, -1.1640e-02,  1.3085e-01,\n          5.7996e-02, -6.4270e-02, -1.6474e-01,  1.3833e-01,  9.4181e-02,\n          5.2279e-02,  1.1626e-01, -1.6639e-01, -9.9758e-02, -1.3024e-01,\n          1.6318e-01,  1.2280e-01, -3.0903e-02,  4.0162e-02, -1.1004e-01,\n         -1.5586e-01, -6.4249e-03,  1.6205e-01, -4.4493e-02,  9.9020e-02,\n          7.5080e-02, -3.3942e-02,  9.0669e-02,  6.8493e-03, -4.6603e-02,\n          4.3451e-02, -1.8607e-02],\n        [ 3.1294e-02, -1.1552e-01,  2.5810e-02, -1.3038e-01, -4.5263e-02,\n         -1.6963e-01, -1.3902e-01,  5.1129e-03,  5.9456e-02,  5.5724e-02,\n         -7.7540e-02,  1.1987e-01,  1.5188e-01,  1.6520e-02, -1.1898e-01,\n          3.5746e-02,  1.1527e-01,  1.0967e-01, -2.0379e-02,  1.4556e-01,\n          1.0018e-01, -5.0295e-02, -6.9453e-02, -1.1599e-01,  1.5413e-01,\n         -5.5660e-02,  6.2557e-02,  4.7819e-02, -9.7183e-02, -1.5421e-01,\n          2.2138e-02,  7.3619e-03],\n        [-1.2647e-01,  1.2703e-02,  5.5808e-02, -1.7522e-01,  1.7527e-01,\n         -4.1742e-02,  1.2932e-01,  2.7116e-02,  1.6533e-01, -1.0341e-01,\n         -3.4701e-02, -3.7528e-02, -1.6051e-02,  1.6847e-01,  1.1577e-01,\n          1.3823e-01,  1.3913e-01, -7.5856e-02, -9.5238e-02, -1.2297e-02,\n         -1.7630e-01,  2.8950e-02, -2.6734e-02,  5.4258e-02, -9.7681e-02,\n          1.5528e-01, -1.1699e-01, -1.6879e-01, -1.8424e-02,  1.0971e-01,\n          2.6272e-02, -2.6168e-02],\n        [-6.6591e-02,  7.1620e-02,  1.4508e-01, -1.1771e-01,  6.8222e-02,\n          2.0961e-02,  1.4596e-01,  6.4206e-02,  1.6498e-01,  9.6073e-02,\n         -1.0371e-01,  1.2560e-02, -4.8848e-02, -1.0695e-01,  1.2229e-01,\n          3.1727e-02,  1.6695e-02, -8.7235e-02,  1.2327e-01,  2.1964e-02,\n         -3.4120e-02,  7.3114e-02,  1.2668e-01,  7.7890e-02,  1.3479e-01,\n         -1.0786e-01,  1.3328e-02,  2.8103e-02, -4.8177e-03,  3.1752e-02,\n          1.7660e-01, -3.5841e-02],\n        [ 2.6206e-02,  9.2965e-02, -6.2590e-02, -1.3727e-03, -4.5554e-02,\n          9.5837e-02, -1.2622e-01, -1.5891e-01,  1.3949e-01,  1.0103e-03,\n         -4.4869e-02,  1.2255e-01, -1.6585e-01, -1.5539e-01,  1.1340e-01,\n          1.1590e-01, -6.3288e-02,  1.7045e-01, -1.4842e-01,  1.0993e-01,\n          1.5988e-01, -1.1334e-01, -1.9280e-02, -7.4120e-03,  8.1781e-02,\n         -1.5481e-01,  1.6492e-01,  1.0470e-02, -1.3411e-01,  1.3153e-01,\n         -7.3466e-02,  1.7540e-01],\n        [ 8.9897e-02, -3.1321e-02,  1.2272e-02, -1.4653e-01,  1.2587e-01,\n         -8.1748e-02, -1.4105e-01, -6.3791e-02, -1.7182e-02, -1.5560e-01,\n          1.9909e-02, -6.1295e-02,  5.1079e-02,  1.6296e-01, -1.5559e-01,\n          9.9115e-02,  1.3452e-01, -6.0858e-02, -1.0812e-01,  1.1587e-01,\n         -1.0487e-03, -1.3104e-01, -1.5965e-01, -9.7829e-02, -5.8592e-02,\n          1.5206e-02,  7.8086e-02, -1.2983e-01,  1.0010e-01,  1.5956e-01,\n          5.8203e-02, -7.5429e-02],\n        [ 8.5351e-02, -5.0156e-02, -8.1939e-02,  8.7171e-03,  1.3615e-01,\n          1.6694e-01, -1.7601e-01, -8.7298e-02,  1.4017e-01,  1.0806e-02,\n          3.2902e-03,  1.2781e-01,  1.0896e-01, -1.0055e-01, -2.7563e-02,\n         -5.2623e-02,  1.3622e-04, -1.6179e-02, -9.6189e-03,  1.1152e-01,\n          1.4986e-01,  8.6178e-02,  1.0799e-01,  7.2384e-02,  9.9279e-02,\n          1.1201e-01,  1.1356e-01, -1.3495e-01, -9.0110e-02,  8.9726e-02,\n         -1.3903e-01, -8.0797e-02],\n        [ 3.3695e-02,  4.2885e-02,  8.5158e-02,  1.1514e-01,  1.0117e-01,\n         -1.1839e-01,  1.7545e-01, -4.8219e-02,  6.4661e-02, -8.4566e-03,\n         -2.8360e-02,  1.6911e-01,  1.7593e-01, -1.3263e-01, -1.7793e-02,\n         -3.4934e-02,  1.6581e-01, -6.6289e-02, -5.0579e-02, -6.6559e-02,\n         -1.8924e-02,  5.0168e-02, -1.5397e-01,  1.1955e-01, -2.3628e-02,\n          2.6235e-02,  1.7516e-01,  7.3103e-02, -1.6057e-01,  5.3291e-02,\n          2.9550e-02,  9.6153e-02],\n        [ 1.5477e-01, -1.7519e-01, -1.4654e-01, -1.1629e-01, -1.8337e-02,\n         -5.8539e-02, -1.2318e-01, -3.8383e-02, -8.1323e-03, -1.1975e-01,\n         -1.1442e-01, -1.4321e-01, -8.4107e-02, -1.1852e-01, -1.6679e-01,\n          2.5733e-02, -6.1014e-03, -6.9669e-02,  1.7481e-01,  1.4248e-01,\n          1.3403e-01, -4.5706e-02,  1.5774e-01, -4.9415e-02, -1.6229e-01,\n          1.5196e-02, -9.0367e-02,  1.3074e-01,  1.5220e-01, -7.1043e-04,\n         -7.9728e-02,  1.3802e-01]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1874,  0.2020,  0.2147, -0.0414,  0.1595,  0.1032, -0.0217, -0.0492],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.1288,  0.1156, -0.2012, -0.2234, -0.1029,  0.1161, -0.2196, -0.1225,\n          0.1211, -0.0316,  0.2494, -0.0060,  0.2190, -0.2400,  0.1136,  0.0155],\n        [-0.1157,  0.2435,  0.0916, -0.1586,  0.0358, -0.0651,  0.2361,  0.1110,\n         -0.1942, -0.2010, -0.0870, -0.2443,  0.2456, -0.0079, -0.0238,  0.0878],\n        [ 0.0679, -0.2204, -0.2014,  0.1906,  0.0380,  0.1494,  0.2252,  0.0179,\n         -0.1202, -0.1625, -0.0986,  0.0356,  0.0653,  0.2314,  0.0787, -0.0927],\n        [ 0.1107,  0.0906,  0.1306, -0.2420,  0.1641, -0.2411,  0.0158, -0.2228,\n          0.0084, -0.0609, -0.0010, -0.0375, -0.1081,  0.1188,  0.2384, -0.1592],\n        [ 0.0574,  0.1586,  0.2217, -0.0319, -0.1107, -0.0355,  0.0513, -0.2301,\n         -0.0167, -0.1581, -0.1757, -0.1384,  0.0160,  0.0836,  0.0293,  0.1096],\n        [ 0.1757, -0.0144,  0.0102, -0.2320, -0.1567, -0.1458,  0.1980,  0.2198,\n          0.1169, -0.0428, -0.0109, -0.2169,  0.0482, -0.0411,  0.1605,  0.0179],\n        [-0.0071, -0.2264,  0.1960, -0.1535, -0.0606,  0.0899, -0.1407, -0.2258,\n         -0.1447,  0.0997,  0.1210,  0.0224, -0.0478,  0.2348, -0.1265,  0.1683],\n        [ 0.2355, -0.0996, -0.1285, -0.0436,  0.0717, -0.0049,  0.2482,  0.1686,\n          0.0692,  0.1390,  0.1987, -0.0768, -0.0858, -0.0219,  0.1412,  0.2044]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.2097], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1791,  0.3361, -0.3192,  0.2719, -0.0568,  0.0130,  0.3253, -0.2649]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-5.4398e-02,  1.9477e-02,  1.9009e-01, -5.4469e-02,  4.3776e-02,\n          1.1481e-01, -6.1554e-02, -1.4086e-01,  1.1198e-01,  8.1012e-02,\n          2.7447e-02,  2.6465e-02, -1.4859e-01, -3.9663e-02, -7.3860e-03,\n          1.0376e-01, -2.0066e-01,  1.0026e-01,  1.5092e-02, -1.1101e-01],\n        [-9.2282e-02, -6.6070e-02, -1.2088e-01,  2.0589e-01, -1.9743e-01,\n         -5.0331e-02,  4.4274e-02,  1.1300e-01,  6.1154e-03, -2.2287e-01,\n          1.5761e-01, -1.0607e-01, -2.1154e-01,  9.4908e-02,  4.4955e-02,\n          5.0432e-02, -5.8642e-02, -2.0771e-03,  4.0867e-02,  4.2906e-02],\n        [-2.2081e-01,  2.1177e-01,  2.1032e-01,  7.8405e-03,  1.1086e-01,\n         -3.8370e-02,  1.2874e-01, -1.9603e-01,  7.1460e-02, -1.8452e-01,\n          1.2167e-01, -3.3408e-02,  1.5267e-01,  1.7503e-01,  3.9277e-02,\n         -2.1098e-01, -6.5026e-02,  9.8162e-02, -1.1059e-01, -8.4810e-02],\n        [-4.2005e-02,  1.8967e-01,  1.0121e-01, -1.2811e-01, -1.3224e-01,\n          1.8656e-01, -1.0578e-01,  4.0271e-02, -2.2705e-02, -1.2257e-01,\n         -1.5168e-01, -1.2289e-02, -2.0651e-01, -2.7117e-02,  1.8746e-01,\n          1.8435e-01,  1.1424e-01, -1.2814e-02,  9.6271e-02,  2.2222e-02],\n        [-1.2823e-01,  1.1180e-02,  1.6668e-01, -1.5742e-01,  6.7022e-02,\n         -1.7365e-01, -1.0457e-01, -7.4602e-02,  6.2441e-02, -1.0341e-01,\n         -2.1970e-02, -1.0296e-01, -1.6507e-01,  3.1358e-02, -2.0740e-01,\n          2.2355e-01,  8.4778e-02,  4.3146e-02,  1.8206e-01,  1.4595e-01],\n        [-1.3428e-01,  1.6672e-01,  1.8638e-01, -1.3683e-01,  1.0544e-01,\n          2.3774e-02, -1.6633e-01,  2.0427e-01, -6.4478e-02,  1.7620e-01,\n         -1.6198e-01,  8.4512e-02, -1.1739e-01,  1.1380e-01,  4.9946e-02,\n          2.3714e-02, -1.1344e-01, -1.5220e-01, -7.3189e-02, -3.3484e-02],\n        [ 6.7054e-02,  2.1386e-01,  2.0482e-01,  6.2422e-02,  2.2021e-01,\n          1.0896e-02, -2.0282e-01,  8.1531e-02,  7.8889e-02,  1.6035e-01,\n          1.7058e-02,  1.8248e-01, -1.4675e-01, -1.9625e-01, -6.5408e-02,\n          1.4561e-03,  1.9920e-01, -9.9177e-02, -1.3334e-01, -4.8585e-02],\n        [ 1.2716e-01, -1.4643e-01, -8.8904e-02,  1.8826e-01, -1.8156e-01,\n          4.4728e-02, -1.0907e-02,  3.8411e-02,  2.9272e-02, -5.0271e-02,\n          7.4955e-02,  1.9367e-01, -2.2246e-01, -2.1891e-01,  1.0303e-01,\n          7.9589e-03,  6.3569e-02, -5.1097e-02,  1.7302e-01, -1.5290e-01],\n        [ 1.7727e-01,  1.1770e-01, -2.1897e-01,  1.4153e-01,  1.9588e-01,\n          9.7261e-03,  1.7749e-01,  3.2101e-02,  8.4624e-02,  3.5259e-02,\n          1.2492e-01,  1.9582e-01, -1.2110e-01,  1.1142e-01, -1.4377e-01,\n         -2.2368e-02, -1.5095e-01, -2.8797e-02, -1.9803e-01, -2.3920e-03],\n        [-1.8676e-01,  2.0685e-01, -1.9505e-01,  7.5257e-02, -1.4364e-01,\n          1.4681e-01,  6.3373e-02,  1.6508e-02,  1.8767e-01,  4.4673e-02,\n          4.7240e-02,  3.9045e-02,  6.2387e-02,  9.3896e-02,  7.1851e-02,\n          1.2768e-01,  1.0923e-01, -4.9351e-02, -4.2467e-02,  1.8325e-03],\n        [-4.0946e-02, -1.4511e-01,  2.0464e-02, -2.0421e-02,  1.4622e-01,\n          1.2307e-01,  9.5863e-03,  2.9410e-02,  2.1942e-01,  4.6983e-02,\n         -1.2605e-01, -9.8995e-02,  2.1468e-01,  1.2963e-01,  2.2109e-01,\n          8.6598e-02, -1.0391e-01,  1.4963e-02, -1.3188e-01, -9.3844e-02],\n        [-2.6789e-02,  1.4553e-01, -6.7305e-02,  1.5055e-01, -3.6959e-03,\n         -1.6678e-01,  1.9961e-01,  2.1324e-01, -1.3590e-01, -7.0929e-02,\n         -8.7916e-02, -7.7043e-02, -2.0171e-01,  3.1027e-02,  6.6571e-02,\n         -5.1207e-02, -2.1884e-01,  1.5426e-01,  6.1714e-02,  1.8436e-01],\n        [-2.0359e-01,  2.3393e-02,  1.7752e-01, -2.1664e-01,  1.9602e-01,\n          6.1665e-02,  2.0793e-01,  1.4490e-01,  5.0569e-02,  1.6427e-02,\n          5.3748e-02,  2.0472e-01, -7.3347e-02, -1.5528e-01, -2.0570e-01,\n         -2.0246e-01,  1.5791e-01, -1.3277e-01,  1.9402e-01, -6.2632e-02],\n        [ 9.4264e-02, -1.0118e-01,  1.6532e-01, -3.4956e-02, -2.5337e-02,\n         -2.1650e-01,  1.1012e-01,  1.5419e-01, -7.6559e-02,  1.0604e-01,\n          6.1772e-02,  4.3380e-02,  3.9616e-02,  2.0358e-01, -1.9850e-01,\n         -4.7240e-02,  1.2176e-01,  2.0812e-01, -1.2365e-01, -1.4009e-01],\n        [ 1.2481e-01, -6.9933e-02, -6.0654e-02,  6.8119e-02, -2.0463e-01,\n          6.2859e-02, -5.6036e-02, -1.8434e-01,  1.5101e-01,  8.7080e-02,\n          8.2475e-02, -9.5700e-02, -3.2714e-02, -1.1085e-01, -1.6478e-01,\n          9.8667e-02, -5.8015e-02, -8.9418e-02, -4.9915e-02,  4.9942e-02],\n        [-1.2069e-01, -9.6701e-02,  2.0845e-01,  1.3818e-01, -1.2981e-02,\n         -1.6669e-01,  1.3793e-01,  4.5653e-03, -6.5113e-02, -1.2720e-04,\n         -8.8971e-02,  2.2249e-01,  1.3458e-01, -3.6059e-02,  1.4153e-01,\n         -1.1789e-01, -2.6320e-02, -3.2542e-02, -2.0910e-01, -1.5265e-01],\n        [-3.7676e-02, -1.6291e-01, -7.7324e-02,  4.7588e-02, -3.0338e-02,\n         -1.4706e-01,  1.0061e-01, -1.8545e-01,  1.4543e-01, -1.8220e-01,\n          2.0471e-01,  2.7299e-02,  1.5060e-01,  1.2221e-01,  1.6172e-01,\n         -9.0571e-02,  8.1236e-02,  1.7974e-01,  2.3539e-02, -1.3360e-01],\n        [ 1.3973e-01,  2.9259e-02,  3.1382e-02,  9.8032e-02,  1.6748e-01,\n         -7.6166e-02,  1.1677e-01,  8.8923e-02, -1.6719e-01,  2.0148e-01,\n          1.4181e-01, -9.2495e-02, -5.3740e-03, -4.9907e-02, -1.1552e-02,\n         -3.9944e-02,  2.0774e-01,  2.1520e-01, -1.9647e-01,  1.6656e-01],\n        [ 2.0650e-02,  1.9100e-01,  2.0213e-01,  1.0032e-01, -6.9817e-02,\n         -1.8908e-01, -1.9876e-01, -1.3914e-01,  1.5468e-02,  5.0688e-02,\n          2.0625e-01, -1.0398e-01, -3.5289e-03,  1.8294e-01,  2.0553e-01,\n          1.7418e-02, -1.9330e-01,  5.1505e-02, -2.0570e-01, -1.4389e-01],\n        [-1.5107e-01, -1.1547e-01,  3.8420e-02, -7.1539e-02, -4.4038e-02,\n          2.0651e-01,  3.1658e-02, -2.1306e-01, -1.7298e-01, -1.4693e-01,\n          1.9514e-01,  1.7463e-01, -1.8185e-01,  3.3539e-02,  1.5336e-01,\n          1.9313e-01, -8.2709e-02,  4.1627e-02,  1.4218e-01,  5.8048e-02],\n        [-9.8931e-02,  6.0354e-02, -1.5183e-01,  1.4548e-01,  3.3443e-02,\n          1.8907e-01, -1.0193e-01,  7.7178e-02, -1.5931e-01, -1.9329e-01,\n         -2.0520e-01,  2.0842e-01,  1.1540e-01,  2.2068e-01,  3.3372e-02,\n          8.0812e-02,  1.7284e-01, -1.1445e-02,  2.8312e-02,  9.4436e-03],\n        [ 4.4368e-02,  1.0195e-02,  1.0181e-01,  1.9570e-01, -1.2817e-01,\n          1.1477e-01,  1.6932e-01,  7.4257e-02,  1.5120e-01,  1.5427e-01,\n          3.1649e-02, -3.1256e-02, -2.1423e-01, -1.9024e-01,  1.0139e-02,\n          1.9075e-01, -1.4725e-01, -5.9702e-02,  1.0983e-02,  2.0463e-02],\n        [ 1.9104e-02,  1.9243e-01,  7.2049e-03, -1.3617e-01,  1.5150e-01,\n          1.7909e-01,  2.2242e-01,  1.8434e-01, -4.3445e-02, -1.2303e-01,\n         -4.3975e-02, -8.4699e-03,  2.9391e-02,  1.7815e-01,  2.0383e-01,\n          5.2578e-03, -2.2121e-01, -8.3965e-02,  2.9256e-02, -1.3861e-01],\n        [-1.0460e-01,  1.7614e-01, -2.0450e-02, -1.6691e-01, -1.4160e-01,\n          2.8292e-03,  2.2023e-02,  1.0725e-01,  8.5284e-02,  1.7492e-01,\n          6.2491e-02,  1.3531e-01,  2.1536e-01,  1.1522e-01, -1.8899e-01,\n         -1.4173e-01,  1.0479e-02, -6.4106e-02,  1.0987e-01,  6.8897e-02],\n        [ 2.0641e-01, -1.9459e-01,  2.0908e-01,  2.0599e-01, -9.9865e-02,\n         -8.7452e-02,  6.8052e-02,  2.0576e-01, -1.4198e-01, -2.1335e-01,\n         -2.1378e-01,  1.0186e-01,  1.5381e-01, -4.4634e-02, -2.1697e-01,\n         -8.6524e-02,  8.9442e-02,  1.4469e-01, -1.1071e-03, -7.7723e-02],\n        [-1.2535e-01,  1.0368e-01,  2.5944e-02, -2.0398e-01, -1.1944e-01,\n          2.1968e-01,  4.1744e-02, -2.0103e-01,  3.2336e-02, -5.1419e-02,\n          1.0327e-01,  5.5496e-02,  1.4131e-02, -2.1988e-01, -1.2159e-01,\n          1.6511e-01, -1.0132e-01,  4.4579e-02, -1.6384e-01, -9.7751e-02],\n        [ 9.0444e-03,  8.5858e-02,  1.4166e-01, -1.8144e-02,  1.2766e-01,\n          1.3110e-01, -3.1578e-02,  1.7624e-01, -2.2151e-02,  1.0181e-02,\n          6.3797e-02, -5.1871e-02,  9.3697e-02, -6.3054e-02, -1.2536e-01,\n          8.2270e-02,  1.1673e-01,  1.0958e-01, -7.0492e-03, -1.0543e-01],\n        [ 1.7630e-01, -4.8736e-02,  7.9775e-02,  1.8938e-01, -7.3377e-02,\n         -1.6081e-01, -5.8106e-02,  7.7529e-02, -1.0085e-01,  1.7482e-01,\n          8.3623e-02,  1.5420e-01, -1.7050e-01, -2.0181e-01, -1.3806e-01,\n          2.1899e-01,  1.0543e-01, -3.0703e-02,  2.9160e-02,  1.6979e-01],\n        [-2.1402e-03, -9.9917e-02,  1.5799e-01,  2.2287e-01, -8.2699e-03,\n         -1.4765e-01,  1.7290e-01,  1.5062e-01,  1.2838e-01, -2.0332e-02,\n          2.2283e-02,  4.5528e-02,  1.8186e-01,  5.1476e-02, -2.2165e-01,\n         -1.2472e-01, -2.2971e-02, -4.9787e-02,  5.8494e-02,  1.0702e-01],\n        [-8.1729e-03, -1.2646e-01, -1.0784e-01, -1.5839e-01, -1.8682e-01,\n          7.8030e-02, -6.5126e-02, -1.7038e-01, -1.0805e-01,  1.3853e-01,\n         -6.8626e-02, -5.4366e-02, -8.5484e-03, -4.9113e-02,  1.1226e-01,\n         -9.2965e-02,  9.6921e-03, -7.6261e-02,  6.2077e-03,  1.8528e-02],\n        [-5.4354e-02,  6.5367e-03,  1.3932e-01,  1.3766e-01, -6.8040e-02,\n         -1.5274e-04,  2.9356e-02, -2.7234e-02,  1.6840e-01,  2.0386e-01,\n          1.4871e-01, -2.1623e-01,  9.8788e-02, -4.5762e-02, -6.5619e-02,\n          9.3326e-02, -7.2877e-02, -2.0672e-01, -2.0218e-02,  1.7275e-02],\n        [-4.9633e-02,  1.9871e-02,  1.1628e-02,  1.3543e-01,  2.4297e-03,\n         -1.1755e-05,  9.6571e-03, -1.6874e-01,  1.3051e-01,  1.5447e-01,\n          8.9107e-03,  2.0973e-01,  4.1523e-02,  1.4025e-01, -1.1768e-01,\n         -1.6499e-01, -7.4540e-02, -1.9633e-01, -1.4150e-01, -1.5467e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1778, -0.0668,  0.0054, -0.0238,  0.1190, -0.0852, -0.0793, -0.1436,\n        -0.0929, -0.1273, -0.1608, -0.0247,  0.1457, -0.1692,  0.2076, -0.1551,\n         0.2128, -0.1952, -0.1494,  0.1736, -0.1785, -0.2093, -0.0469,  0.1586,\n         0.0910, -0.2070, -0.2218, -0.0244, -0.0162, -0.1686, -0.1752,  0.1270],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.5606e-01, -7.6403e-02,  3.4836e-02, -1.6471e-01, -1.6136e-01,\n         -4.2377e-02,  7.5235e-02,  1.3786e-01, -5.3009e-02, -1.6281e-01,\n         -8.6055e-02,  1.1235e-01, -1.6242e-01, -1.4966e-01,  1.6095e-01,\n         -1.6357e-01, -6.2266e-03,  9.0776e-03, -2.9045e-02,  1.0389e-01,\n          1.3666e-01, -8.6099e-02, -1.3593e-01, -1.2887e-01,  9.7793e-04,\n          1.5606e-01,  1.5149e-01, -2.6495e-02,  1.1606e-01,  6.7220e-02,\n         -3.5739e-02, -6.7235e-02],\n        [ 5.7301e-02,  1.1763e-02,  1.4281e-01, -9.9940e-02, -1.3985e-01,\n          8.3441e-02,  1.3296e-01,  1.8238e-02, -1.3544e-01, -1.3476e-01,\n          1.4084e-01, -1.3553e-01, -1.4751e-02, -3.9471e-02,  8.2833e-02,\n          2.0631e-03, -8.7535e-02,  4.0824e-02, -7.6236e-02, -1.2435e-03,\n         -1.3650e-01, -2.5871e-02, -1.7540e-01, -9.8323e-02, -1.1645e-01,\n          1.7234e-01,  9.1077e-02, -1.2831e-01,  1.2958e-01,  1.0992e-01,\n          1.5628e-01,  8.6222e-02],\n        [-2.2607e-02, -1.2798e-01, -8.6279e-02,  6.4059e-02, -1.5298e-01,\n         -1.0604e-01, -4.3266e-02,  1.0328e-01, -3.1046e-02,  3.1129e-02,\n         -1.3941e-01, -8.9010e-02, -6.4963e-03, -1.2993e-01, -3.5078e-02,\n          7.1380e-02, -5.8003e-02,  1.0399e-01,  1.2241e-01, -1.5720e-01,\n         -1.0310e-01,  9.2322e-02, -6.3348e-02,  1.6497e-02, -6.5481e-02,\n          2.5957e-02, -1.6074e-01, -9.1666e-02,  1.7527e-01,  9.9327e-02,\n         -1.7672e-01, -9.6256e-03],\n        [ 7.2040e-02,  4.2639e-02, -1.1125e-01,  1.0813e-01,  7.8628e-03,\n         -4.2908e-02, -1.1617e-01,  2.6125e-02, -1.5008e-01,  1.6595e-02,\n         -2.7932e-02,  5.7900e-02,  1.7063e-01,  1.7659e-01, -5.2852e-03,\n         -1.2707e-01,  1.5723e-01,  1.6238e-01,  2.1641e-02, -9.9542e-02,\n         -6.3989e-02,  5.1899e-03, -3.3351e-02, -1.0076e-02,  4.0024e-02,\n         -1.4963e-01, -1.0262e-01,  1.3250e-01,  3.4798e-02, -9.7245e-03,\n         -6.7027e-02, -1.3479e-01],\n        [ 1.3582e-01, -5.8978e-02,  1.0411e-01,  1.5647e-01,  1.6232e-01,\n          2.7669e-02,  4.0252e-02,  1.0653e-01,  7.3400e-02, -2.2193e-02,\n         -1.4283e-01,  6.2085e-02,  1.1310e-01,  3.7942e-02, -1.1441e-01,\n          1.3356e-01, -1.1781e-03,  8.0605e-02,  4.3599e-02,  9.4051e-02,\n          1.7498e-01,  1.1356e-01, -1.4553e-01, -1.1002e-01,  5.4773e-02,\n         -6.9634e-02,  1.6485e-01, -8.2035e-02,  6.8124e-03,  2.6774e-03,\n          9.8367e-02, -3.4246e-02],\n        [-1.5045e-01, -8.2272e-02,  7.8783e-04, -6.7055e-02,  1.0221e-01,\n         -4.8714e-02,  8.8842e-02,  1.5594e-01,  1.0230e-01, -2.5778e-02,\n          1.7059e-01,  1.3978e-01,  1.7382e-01, -7.7231e-02,  3.7282e-02,\n         -1.0844e-01,  3.7810e-02, -6.6256e-02,  9.7802e-03, -1.3619e-01,\n         -3.7740e-02,  1.1598e-02,  1.2823e-03,  1.0399e-01,  6.9928e-02,\n         -5.7624e-02,  1.3887e-01, -1.3823e-01, -2.0311e-02,  1.1972e-01,\n          1.1828e-01, -2.5364e-02],\n        [-5.5353e-02, -1.7380e-01,  1.5612e-01,  1.1442e-01, -3.9391e-02,\n          1.1436e-01,  1.6490e-01,  2.0415e-02, -9.8849e-02,  1.1396e-01,\n          2.3001e-03, -1.0731e-01, -4.6260e-02,  1.1822e-01,  1.4058e-01,\n         -5.0886e-02,  6.5194e-02,  9.1820e-02,  8.3729e-03, -1.5833e-01,\n          6.1605e-02,  1.2519e-01, -1.0834e-02,  5.8851e-02,  1.5875e-02,\n          9.1380e-02,  1.4039e-01,  3.8884e-02, -1.0410e-01,  9.4763e-02,\n         -9.0825e-03,  1.0670e-01],\n        [ 1.1955e-01, -8.9995e-02, -6.4890e-02, -1.1640e-02,  1.3085e-01,\n          5.7996e-02, -6.4270e-02, -1.6474e-01,  1.3833e-01,  9.4181e-02,\n          5.2279e-02,  1.1626e-01, -1.6639e-01, -9.9758e-02, -1.3024e-01,\n          1.6318e-01,  1.2280e-01, -3.0903e-02,  4.0162e-02, -1.1004e-01,\n         -1.5586e-01, -6.4249e-03,  1.6205e-01, -4.4493e-02,  9.9020e-02,\n          7.5080e-02, -3.3942e-02,  9.0669e-02,  6.8493e-03, -4.6603e-02,\n          4.3451e-02, -1.8607e-02],\n        [ 3.1294e-02, -1.1552e-01,  2.5810e-02, -1.3038e-01, -4.5263e-02,\n         -1.6963e-01, -1.3902e-01,  5.1129e-03,  5.9456e-02,  5.5724e-02,\n         -7.7540e-02,  1.1987e-01,  1.5188e-01,  1.6520e-02, -1.1898e-01,\n          3.5746e-02,  1.1527e-01,  1.0967e-01, -2.0379e-02,  1.4556e-01,\n          1.0018e-01, -5.0295e-02, -6.9453e-02, -1.1599e-01,  1.5413e-01,\n         -5.5660e-02,  6.2557e-02,  4.7819e-02, -9.7183e-02, -1.5421e-01,\n          2.2138e-02,  7.3619e-03],\n        [-1.2647e-01,  1.2703e-02,  5.5808e-02, -1.7522e-01,  1.7527e-01,\n         -4.1742e-02,  1.2932e-01,  2.7116e-02,  1.6533e-01, -1.0341e-01,\n         -3.4701e-02, -3.7528e-02, -1.6051e-02,  1.6847e-01,  1.1577e-01,\n          1.3823e-01,  1.3913e-01, -7.5856e-02, -9.5238e-02, -1.2297e-02,\n         -1.7630e-01,  2.8950e-02, -2.6734e-02,  5.4258e-02, -9.7681e-02,\n          1.5528e-01, -1.1699e-01, -1.6879e-01, -1.8424e-02,  1.0971e-01,\n          2.6272e-02, -2.6168e-02],\n        [-6.6591e-02,  7.1620e-02,  1.4508e-01, -1.1771e-01,  6.8222e-02,\n          2.0961e-02,  1.4596e-01,  6.4206e-02,  1.6498e-01,  9.6073e-02,\n         -1.0371e-01,  1.2560e-02, -4.8848e-02, -1.0695e-01,  1.2229e-01,\n          3.1727e-02,  1.6695e-02, -8.7235e-02,  1.2327e-01,  2.1964e-02,\n         -3.4120e-02,  7.3114e-02,  1.2668e-01,  7.7890e-02,  1.3479e-01,\n         -1.0786e-01,  1.3328e-02,  2.8103e-02, -4.8177e-03,  3.1752e-02,\n          1.7660e-01, -3.5841e-02],\n        [ 2.6206e-02,  9.2965e-02, -6.2590e-02, -1.3727e-03, -4.5554e-02,\n          9.5837e-02, -1.2622e-01, -1.5891e-01,  1.3949e-01,  1.0103e-03,\n         -4.4869e-02,  1.2255e-01, -1.6585e-01, -1.5539e-01,  1.1340e-01,\n          1.1590e-01, -6.3288e-02,  1.7045e-01, -1.4842e-01,  1.0993e-01,\n          1.5988e-01, -1.1334e-01, -1.9280e-02, -7.4120e-03,  8.1781e-02,\n         -1.5481e-01,  1.6492e-01,  1.0470e-02, -1.3411e-01,  1.3153e-01,\n         -7.3466e-02,  1.7540e-01],\n        [ 8.9897e-02, -3.1321e-02,  1.2272e-02, -1.4653e-01,  1.2587e-01,\n         -8.1748e-02, -1.4105e-01, -6.3791e-02, -1.7182e-02, -1.5560e-01,\n          1.9909e-02, -6.1295e-02,  5.1079e-02,  1.6296e-01, -1.5559e-01,\n          9.9115e-02,  1.3452e-01, -6.0858e-02, -1.0812e-01,  1.1587e-01,\n         -1.0487e-03, -1.3104e-01, -1.5965e-01, -9.7829e-02, -5.8592e-02,\n          1.5206e-02,  7.8086e-02, -1.2983e-01,  1.0010e-01,  1.5956e-01,\n          5.8203e-02, -7.5429e-02],\n        [ 8.5351e-02, -5.0156e-02, -8.1939e-02,  8.7171e-03,  1.3615e-01,\n          1.6694e-01, -1.7601e-01, -8.7298e-02,  1.4017e-01,  1.0806e-02,\n          3.2902e-03,  1.2781e-01,  1.0896e-01, -1.0055e-01, -2.7563e-02,\n         -5.2623e-02,  1.3622e-04, -1.6179e-02, -9.6189e-03,  1.1152e-01,\n          1.4986e-01,  8.6178e-02,  1.0799e-01,  7.2384e-02,  9.9279e-02,\n          1.1201e-01,  1.1356e-01, -1.3495e-01, -9.0110e-02,  8.9726e-02,\n         -1.3903e-01, -8.0797e-02],\n        [ 3.3695e-02,  4.2885e-02,  8.5158e-02,  1.1514e-01,  1.0117e-01,\n         -1.1839e-01,  1.7545e-01, -4.8219e-02,  6.4661e-02, -8.4566e-03,\n         -2.8360e-02,  1.6911e-01,  1.7593e-01, -1.3263e-01, -1.7793e-02,\n         -3.4934e-02,  1.6581e-01, -6.6289e-02, -5.0579e-02, -6.6559e-02,\n         -1.8924e-02,  5.0168e-02, -1.5397e-01,  1.1955e-01, -2.3628e-02,\n          2.6235e-02,  1.7516e-01,  7.3103e-02, -1.6057e-01,  5.3291e-02,\n          2.9550e-02,  9.6153e-02],\n        [ 1.5477e-01, -1.7519e-01, -1.4654e-01, -1.1629e-01, -1.8337e-02,\n         -5.8539e-02, -1.2318e-01, -3.8383e-02, -8.1323e-03, -1.1975e-01,\n         -1.1442e-01, -1.4321e-01, -8.4107e-02, -1.1852e-01, -1.6679e-01,\n          2.5733e-02, -6.1014e-03, -6.9669e-02,  1.7481e-01,  1.4248e-01,\n          1.3403e-01, -4.5706e-02,  1.5774e-01, -4.9415e-02, -1.6229e-01,\n          1.5196e-02, -9.0367e-02,  1.3074e-01,  1.5220e-01, -7.1043e-04,\n         -7.9728e-02,  1.3802e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0525,  0.0541, -0.1603,  0.0511, -0.0818, -0.1044,  0.0127,  0.0593,\n         0.0926,  0.0815,  0.0199,  0.1717, -0.0510, -0.0362, -0.0380,  0.0995],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1288,  0.1156, -0.2012, -0.2234, -0.1029,  0.1161, -0.2196, -0.1225,\n          0.1211, -0.0316,  0.2494, -0.0060,  0.2190, -0.2400,  0.1136,  0.0155],\n        [-0.1157,  0.2435,  0.0916, -0.1586,  0.0358, -0.0651,  0.2361,  0.1110,\n         -0.1942, -0.2010, -0.0870, -0.2443,  0.2456, -0.0079, -0.0238,  0.0878],\n        [ 0.0679, -0.2204, -0.2014,  0.1906,  0.0380,  0.1494,  0.2252,  0.0179,\n         -0.1202, -0.1625, -0.0986,  0.0356,  0.0653,  0.2314,  0.0787, -0.0927],\n        [ 0.1107,  0.0906,  0.1306, -0.2420,  0.1641, -0.2411,  0.0158, -0.2228,\n          0.0084, -0.0609, -0.0010, -0.0375, -0.1081,  0.1188,  0.2384, -0.1592],\n        [ 0.0574,  0.1586,  0.2217, -0.0319, -0.1107, -0.0355,  0.0513, -0.2301,\n         -0.0167, -0.1581, -0.1757, -0.1384,  0.0160,  0.0836,  0.0293,  0.1096],\n        [ 0.1757, -0.0144,  0.0102, -0.2320, -0.1567, -0.1458,  0.1980,  0.2198,\n          0.1169, -0.0428, -0.0109, -0.2169,  0.0482, -0.0411,  0.1605,  0.0179],\n        [-0.0071, -0.2264,  0.1960, -0.1535, -0.0606,  0.0899, -0.1407, -0.2258,\n         -0.1447,  0.0997,  0.1210,  0.0224, -0.0478,  0.2348, -0.1265,  0.1683],\n        [ 0.2355, -0.0996, -0.1285, -0.0436,  0.0717, -0.0049,  0.2482,  0.1686,\n          0.0692,  0.1390,  0.1987, -0.0768, -0.0858, -0.0219,  0.1412,  0.2044]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1874,  0.2020,  0.2147, -0.0414,  0.1595,  0.1032, -0.0217, -0.0492],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1791,  0.3361, -0.3192,  0.2719, -0.0568,  0.0130,  0.3253, -0.2649]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2097], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x10beb22f0>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x111dcc7f0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s58100000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s58100000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}