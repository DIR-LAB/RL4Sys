{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s68890000"
    },
    "q_lr":	0.0005,
    "seed":	68890000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x10f808a90>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1983, -0.0727, -0.1940,  0.2032, -0.1540,  0.0907, -0.1374,  0.1857,\n         0.0101,  0.1035, -0.1302,  0.0708, -0.0937, -0.1169, -0.1680,  0.1012,\n        -0.1452, -0.1211, -0.0980,  0.0181, -0.1395, -0.0368, -0.1703,  0.2119,\n         0.0472,  0.1299,  0.0057, -0.1456, -0.0219,  0.1528,  0.2090, -0.1345],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0205,  0.0297,  0.0098, -0.1123,  0.0190,  0.1280,  0.1410,  0.1007,\n         -0.2052, -0.0669,  0.0782,  0.0525, -0.0239, -0.1901, -0.1725,  0.0006,\n          0.2109,  0.0112,  0.1107, -0.1494],\n        [-0.0703,  0.1537, -0.0020, -0.0065, -0.1090,  0.0183, -0.0539,  0.0765,\n          0.0410,  0.0876, -0.1617, -0.1672, -0.0081, -0.0445,  0.1285, -0.1853,\n          0.1699, -0.0871, -0.0117, -0.0039],\n        [-0.1258, -0.0552, -0.0100,  0.1759,  0.0923, -0.1776, -0.0063,  0.0411,\n         -0.0294, -0.0006, -0.0201, -0.0651, -0.0962,  0.0786,  0.2096,  0.0338,\n         -0.1621, -0.1965, -0.0605, -0.1215],\n        [ 0.1360, -0.1608, -0.1872,  0.0285,  0.1690,  0.1310,  0.1588, -0.0177,\n         -0.0410,  0.0624, -0.1669, -0.0613,  0.1232, -0.0517, -0.1394,  0.1630,\n         -0.0329, -0.1424,  0.1671,  0.1055],\n        [-0.1836,  0.1003,  0.1419, -0.1048,  0.1533,  0.0419, -0.1205,  0.1232,\n          0.1425, -0.0142, -0.0847, -0.0808, -0.0514, -0.0869, -0.1813,  0.1810,\n          0.1219, -0.1425, -0.2136, -0.1593],\n        [ 0.0395,  0.0605,  0.0553, -0.1763, -0.1490,  0.2141,  0.0585, -0.1785,\n          0.0081,  0.1245,  0.1712, -0.1520, -0.1375,  0.2147, -0.0996, -0.0619,\n          0.0038,  0.1921,  0.0891,  0.1520],\n        [ 0.1486,  0.1330,  0.0993, -0.1987,  0.1367,  0.0962,  0.1058,  0.2202,\n         -0.2075, -0.0435, -0.0404, -0.0372,  0.1204,  0.1654, -0.1600,  0.0651,\n          0.0846, -0.0339,  0.1553, -0.0809],\n        [ 0.2221, -0.2230,  0.0148,  0.1917, -0.1373, -0.0186, -0.1228,  0.0360,\n          0.0757,  0.1453,  0.1589,  0.1426,  0.1520, -0.0087, -0.2155, -0.2041,\n          0.0739, -0.1566,  0.1363, -0.1089],\n        [-0.0044,  0.0639,  0.0532, -0.1338,  0.1346, -0.0303, -0.1185, -0.0985,\n         -0.0201,  0.0207,  0.0550,  0.0134,  0.1080,  0.2219,  0.2204,  0.2160,\n          0.0931, -0.0798,  0.2174, -0.2059],\n        [ 0.1636,  0.0680, -0.1897, -0.1238,  0.0911, -0.0246,  0.1565,  0.0231,\n          0.0523,  0.0865, -0.1628,  0.0377, -0.1872,  0.0737,  0.1654, -0.0486,\n         -0.0803,  0.2121,  0.0030, -0.1655],\n        [-0.1028, -0.1361,  0.2114,  0.1106, -0.0124, -0.1711, -0.1960,  0.1868,\n          0.1264, -0.0839, -0.0329,  0.1311,  0.1907,  0.0299, -0.0519,  0.1128,\n         -0.0024,  0.0569, -0.1167, -0.0939],\n        [ 0.0163,  0.1887,  0.0557,  0.0762, -0.0921, -0.1390, -0.0529,  0.0050,\n          0.1084, -0.0494, -0.1197, -0.0753,  0.1127, -0.0149, -0.0473,  0.1759,\n         -0.0496, -0.0830, -0.0235,  0.2080],\n        [ 0.0639, -0.1880, -0.0832,  0.1908, -0.1794,  0.0271,  0.2202,  0.0725,\n         -0.0300,  0.0727,  0.2063,  0.1938, -0.0847, -0.1963,  0.1751,  0.0923,\n         -0.1636,  0.1652, -0.2200, -0.1099],\n        [-0.1833,  0.1897, -0.0083, -0.1448, -0.2229, -0.0817,  0.1918,  0.1635,\n         -0.1544,  0.2226, -0.1617,  0.1234, -0.0325,  0.0894,  0.0190, -0.1605,\n         -0.1918, -0.1865,  0.0732, -0.0574],\n        [ 0.0420,  0.1161,  0.0605, -0.0036, -0.0430, -0.2030,  0.0891, -0.1093,\n         -0.1974, -0.0506,  0.1589,  0.1664, -0.1182,  0.0347, -0.0449,  0.0222,\n         -0.1980,  0.0788, -0.0663, -0.2130],\n        [ 0.1334, -0.2012, -0.0465,  0.1752, -0.1359, -0.0442, -0.0983,  0.0915,\n          0.0049, -0.1879,  0.1912,  0.1062, -0.1434, -0.0445, -0.0267, -0.1854,\n          0.1817,  0.1934, -0.0754,  0.0536],\n        [ 0.0785, -0.1157, -0.0627,  0.0999,  0.1402, -0.0685, -0.0406,  0.2062,\n         -0.0291,  0.1335, -0.0105,  0.1226,  0.1003, -0.1834,  0.0453, -0.0127,\n         -0.0767,  0.1106,  0.1582, -0.0883],\n        [-0.2224, -0.0620,  0.0257, -0.1831,  0.0900, -0.1860,  0.1893, -0.1872,\n          0.0571, -0.1660,  0.1041,  0.0975,  0.1547,  0.2164, -0.1097, -0.0863,\n          0.1136,  0.2149,  0.1823,  0.0519],\n        [ 0.1164, -0.1175, -0.2058,  0.0874,  0.0807, -0.1441,  0.0059,  0.1953,\n         -0.2034, -0.0171,  0.1840,  0.0856,  0.1402, -0.0022, -0.1022, -0.2137,\n          0.0034,  0.0066, -0.0267,  0.1724],\n        [ 0.1887,  0.0813, -0.1975,  0.0117,  0.1202, -0.2226,  0.2139, -0.0344,\n          0.2206,  0.1454,  0.1039,  0.1882,  0.1359, -0.1471, -0.0846, -0.1096,\n          0.1303, -0.1761, -0.1132, -0.0535],\n        [-0.0478, -0.1121,  0.1072, -0.0087,  0.0287,  0.0338,  0.2160, -0.1513,\n         -0.1670, -0.1530,  0.2096, -0.2067,  0.0032, -0.0765,  0.1894, -0.1193,\n          0.0880,  0.1304, -0.1528,  0.1675],\n        [ 0.2117, -0.0853, -0.2206,  0.0273,  0.0949,  0.1185,  0.0771, -0.0562,\n          0.1948,  0.0123,  0.1799, -0.2149,  0.0406,  0.0645,  0.0459, -0.1047,\n         -0.0021, -0.1983, -0.0781,  0.0206],\n        [ 0.1869,  0.1345, -0.1160,  0.0997,  0.0079,  0.1377, -0.1443, -0.1480,\n         -0.1232, -0.0066, -0.1155, -0.1752, -0.0978, -0.1364, -0.0381,  0.0111,\n          0.1687,  0.0672,  0.0166, -0.1414],\n        [-0.1803,  0.0435, -0.1458, -0.0360, -0.1503, -0.1490, -0.0672,  0.0311,\n         -0.0260, -0.1132,  0.1909,  0.1487,  0.0376,  0.2095, -0.1810, -0.0472,\n         -0.1622,  0.0413, -0.0841, -0.0548],\n        [-0.1569,  0.0097,  0.0861,  0.1092, -0.1424,  0.0007,  0.1077, -0.0373,\n         -0.1110,  0.0093, -0.1033,  0.2105,  0.1249,  0.1260,  0.1704,  0.1129,\n         -0.1272,  0.2143,  0.1665,  0.0899],\n        [-0.0890,  0.0430, -0.1468, -0.1691, -0.0362,  0.1134,  0.1523, -0.1305,\n          0.1337, -0.1700,  0.1966,  0.1736, -0.0008,  0.1094, -0.1854, -0.2014,\n          0.0420,  0.0724, -0.1279, -0.2024],\n        [-0.0348,  0.1352,  0.0359, -0.0819, -0.0211,  0.1882, -0.0819,  0.1877,\n         -0.0013,  0.1629, -0.1402,  0.1450,  0.1723,  0.1423,  0.1567,  0.1486,\n         -0.1877, -0.1954,  0.0074, -0.1311],\n        [-0.0863,  0.1450,  0.0913,  0.0970,  0.0547,  0.0377, -0.1169,  0.0099,\n          0.1832,  0.1926,  0.0305, -0.0384,  0.0452, -0.0433,  0.0982,  0.0812,\n         -0.0529, -0.1551,  0.2151,  0.0042],\n        [ 0.0555, -0.1436, -0.0662,  0.1655, -0.2111,  0.1746, -0.2027,  0.0096,\n         -0.0910, -0.0514, -0.1034, -0.2223,  0.2042,  0.0007,  0.0547, -0.1883,\n         -0.0384,  0.2035,  0.0252,  0.0822],\n        [ 0.1133,  0.1465, -0.0380, -0.1523, -0.0120,  0.1012,  0.0836, -0.2152,\n          0.0215,  0.0784,  0.0998, -0.0187, -0.1578, -0.2110,  0.1088, -0.0639,\n          0.0465,  0.0517,  0.1464,  0.0999],\n        [-0.2140,  0.0752,  0.0102, -0.1594, -0.1940, -0.1481,  0.1558,  0.1442,\n          0.1467, -0.2025, -0.0365,  0.1797,  0.1334, -0.0811,  0.2005,  0.0965,\n         -0.0134,  0.1373,  0.0809, -0.1027],\n        [ 0.0482,  0.0474, -0.0167,  0.1087,  0.0150, -0.0958,  0.1977, -0.0586,\n          0.0089,  0.0288,  0.0006,  0.1115,  0.0775, -0.1360, -0.0403, -0.0064,\n          0.2190, -0.2224, -0.0912, -0.1439]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0136, -0.0726,  0.1017, -0.0153,  0.0109,  0.1204,  0.0242,  0.1206,\n        -0.1622,  0.0243, -0.0529,  0.0149, -0.0511,  0.1653,  0.0730,  0.0065],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.4936e-01, -1.2745e-01, -6.2337e-02, -1.2840e-01,  1.5554e-01,\n         -3.6527e-02, -9.7433e-02,  1.5940e-01, -2.5624e-02,  1.7116e-01,\n         -1.5297e-01, -6.0738e-03,  1.3859e-01, -1.5072e-01,  1.7447e-01,\n          1.4748e-01,  1.7436e-01,  9.8186e-02, -1.6030e-01, -1.4209e-01,\n         -1.3553e-01,  5.9171e-02,  5.0454e-02, -1.4878e-01,  1.0015e-01,\n         -1.4014e-01, -1.2603e-01, -7.9149e-02,  1.0894e-01, -1.6389e-01,\n          8.4585e-02, -1.3419e-01],\n        [-4.0239e-02,  2.0315e-02,  1.6590e-01, -8.8094e-02, -3.0320e-03,\n         -6.0110e-02, -7.7777e-02,  3.8549e-02, -3.5862e-02,  8.9319e-02,\n          8.1966e-02,  1.3754e-01,  4.9069e-02, -4.6166e-02, -8.9386e-02,\n         -2.8595e-02,  4.2422e-02, -3.7895e-02,  2.8662e-02, -1.3610e-01,\n         -1.9682e-02, -1.6189e-01,  6.6451e-02,  5.6066e-02,  6.0119e-02,\n         -5.4639e-02,  4.9545e-02,  1.3405e-01,  5.6229e-02,  1.4900e-01,\n         -6.4747e-02,  3.1810e-02],\n        [ 7.0553e-03,  1.4620e-01, -5.5218e-02,  1.2669e-01, -2.2772e-02,\n          7.1703e-03,  5.1172e-02,  1.0441e-01, -1.4656e-01, -3.2022e-02,\n         -1.3999e-01,  1.8365e-02,  4.6450e-02,  3.9470e-02, -5.1947e-02,\n         -4.2103e-03, -1.3056e-01,  9.5049e-03,  7.7275e-02,  1.0418e-01,\n          7.2161e-02, -5.7312e-02,  6.4840e-02,  9.9468e-02, -1.0369e-01,\n          8.7407e-02,  6.3893e-02,  1.6248e-01,  3.0338e-02,  6.4938e-02,\n         -1.4264e-01, -7.8402e-02],\n        [-1.1414e-01,  2.1061e-02,  5.0217e-02,  3.5067e-02, -4.3749e-02,\n         -1.2602e-01,  1.5392e-01, -4.3724e-02,  8.8878e-02,  5.3190e-02,\n         -8.1105e-02,  1.1304e-01, -1.5851e-01,  8.2320e-02,  4.4892e-03,\n         -1.4841e-01, -3.7849e-02, -2.7315e-02,  1.4350e-01, -1.1983e-01,\n          6.4540e-02, -4.7521e-02,  2.9838e-02,  1.7526e-01,  9.3715e-02,\n          1.1339e-01, -4.9519e-02,  1.4202e-01, -1.0753e-01,  1.0906e-01,\n         -7.5605e-02, -1.1644e-01],\n        [ 1.0454e-01,  1.7437e-01,  5.9674e-02,  1.3761e-01,  1.3652e-01,\n          1.1997e-01, -1.2728e-02,  1.1740e-01,  1.3672e-02,  1.2642e-01,\n          1.0140e-02,  3.9642e-03,  6.9125e-02, -5.0543e-02, -1.1336e-01,\n          7.9806e-02, -1.3078e-01,  9.2554e-02,  6.8916e-02,  3.7551e-02,\n         -5.6932e-02,  1.4784e-01, -9.0853e-02,  1.1855e-01, -9.9074e-02,\n         -7.9047e-02,  8.1385e-02,  1.2586e-01, -8.8008e-02, -1.8725e-02,\n          1.5598e-01,  1.5280e-01],\n        [-1.6317e-01, -1.7358e-01,  1.2718e-01, -1.4536e-01, -4.4757e-02,\n          2.8940e-02, -1.5600e-01,  8.8280e-02,  9.2828e-02,  1.4170e-01,\n          1.4369e-01, -1.4387e-01,  9.7731e-03, -8.5199e-03,  1.3989e-01,\n         -1.4785e-01, -7.9328e-02, -3.5342e-02, -8.1849e-02, -8.0676e-02,\n          1.2760e-01, -9.7954e-02,  9.8837e-03, -7.3273e-03,  6.6498e-02,\n          1.4720e-01,  7.0702e-02,  4.3790e-02, -7.6305e-03,  3.6768e-02,\n         -1.1718e-01,  9.6392e-02],\n        [-6.9045e-02, -1.7393e-02,  6.5367e-02,  1.3104e-01, -2.0395e-02,\n         -1.7200e-01,  5.3973e-03,  9.3400e-02,  1.7321e-01,  7.8505e-02,\n         -5.3318e-02, -1.4225e-01,  8.9918e-02, -3.9308e-02, -1.3919e-01,\n          6.3467e-03,  9.2942e-02,  6.7904e-02,  8.8700e-02,  1.0578e-01,\n         -1.2678e-01,  2.5661e-02, -1.6159e-01,  4.1778e-02, -1.1987e-01,\n          6.4489e-02, -1.3698e-01, -6.5826e-02, -2.2765e-02, -1.6399e-01,\n         -1.0331e-01, -1.3606e-01],\n        [-1.1254e-01,  8.0455e-02,  1.8579e-02,  2.5363e-02,  1.0124e-01,\n          6.8504e-02, -8.4947e-03,  1.4880e-01, -1.1333e-02, -8.8084e-02,\n         -1.5283e-01,  9.9066e-03,  1.5977e-01,  2.2756e-02,  1.1529e-01,\n         -9.6375e-02,  6.2258e-02,  1.1488e-01,  5.3022e-02,  8.9148e-02,\n          1.5220e-02, -1.4092e-01, -1.0924e-01,  1.6025e-01,  1.9921e-02,\n         -2.3544e-02,  1.0315e-01,  5.0343e-02,  1.0373e-01, -5.8618e-02,\n          1.2612e-01,  3.3235e-02],\n        [ 6.6704e-02, -9.8127e-02, -1.1079e-01, -1.6791e-01,  1.6941e-02,\n          1.7178e-02, -5.1207e-02,  4.7762e-02,  1.2954e-01,  6.0236e-02,\n          8.0083e-02, -6.2440e-02, -1.9811e-02,  1.5647e-01, -1.0088e-01,\n          9.8745e-02,  1.7498e-01,  1.4384e-01,  1.0600e-01, -1.3172e-01,\n          1.2753e-01, -1.4876e-01, -1.0570e-01, -9.0458e-02, -3.3942e-02,\n         -9.7604e-02,  1.5880e-01, -1.7003e-01,  2.3755e-02, -1.4475e-01,\n          1.5545e-01,  1.3722e-01],\n        [ 1.3796e-01, -8.3036e-02, -9.6566e-02,  5.5288e-02,  7.2146e-02,\n         -1.0057e-01, -7.2761e-02, -1.4457e-01, -1.6417e-01,  1.6645e-03,\n         -4.3523e-02, -5.5658e-02,  1.4099e-01,  8.7598e-03,  1.4305e-01,\n          1.6812e-01, -6.3677e-02,  1.1513e-01, -8.4350e-02,  7.0829e-02,\n          1.5841e-02,  8.5204e-02,  1.1448e-01,  3.5254e-02,  7.8369e-02,\n         -3.4767e-02,  1.7267e-01, -1.7768e-02, -1.1342e-02,  1.0264e-01,\n         -1.3801e-01, -9.5320e-02],\n        [ 1.6259e-01,  1.6407e-03, -3.1932e-02, -2.2796e-02, -8.1666e-02,\n         -1.3995e-01,  4.8696e-02, -1.6225e-01,  1.3947e-01,  3.3172e-02,\n         -2.2598e-02, -5.0942e-03, -2.0908e-02,  3.0927e-02, -8.9787e-02,\n          2.9296e-02,  1.7086e-01, -1.4453e-01, -3.3365e-02,  1.0395e-01,\n          1.7320e-01,  3.9472e-02,  1.1400e-01,  9.3936e-02, -7.0870e-02,\n         -6.8723e-02, -1.6528e-01,  6.7701e-02, -5.0118e-02,  6.1337e-03,\n          1.6492e-02,  1.1780e-01],\n        [-4.7594e-02, -1.7620e-01, -1.8162e-02,  2.2253e-02,  6.5837e-02,\n          1.1851e-01, -7.6558e-02,  3.0580e-02,  1.2863e-01,  1.3636e-01,\n          1.1306e-01, -1.3051e-01,  1.3057e-01, -1.4751e-01,  1.3650e-01,\n         -3.3289e-02,  1.2217e-01, -8.9390e-03,  5.4568e-02,  1.4813e-01,\n         -1.7162e-01, -1.5928e-01,  3.5606e-02,  8.5723e-02,  1.6265e-01,\n          3.0517e-02,  1.2025e-01, -1.0563e-01, -6.9861e-02, -3.7775e-03,\n         -7.5276e-02,  1.6277e-01],\n        [-1.4925e-02,  1.6953e-01,  6.9006e-02, -1.1359e-01,  6.6967e-02,\n          2.6842e-02,  6.6795e-02, -4.7483e-02,  7.7497e-02,  1.7353e-01,\n          1.7489e-01,  1.6165e-01,  1.1598e-01,  1.4297e-01, -1.7316e-01,\n          1.7018e-01,  7.6188e-03,  1.0448e-01,  1.1213e-01, -4.0834e-02,\n          5.9234e-02, -4.0123e-03,  9.1548e-02,  1.1645e-01, -4.7490e-02,\n         -1.1239e-01, -1.5641e-01, -9.0480e-02,  1.7482e-01,  1.3405e-01,\n         -6.2654e-02,  7.5748e-02],\n        [ 1.2810e-01,  1.6739e-01,  1.0024e-01,  1.5321e-01, -1.2939e-01,\n         -5.7492e-02,  1.6467e-01, -1.7342e-01,  1.4755e-02, -1.7007e-01,\n          9.8889e-02,  1.3520e-01, -6.6933e-02,  6.3540e-02,  1.3632e-02,\n         -7.3399e-02,  5.3516e-02, -8.6075e-02,  1.0906e-01,  4.4399e-02,\n         -2.6172e-02,  1.2170e-01,  7.7340e-02,  8.7032e-02, -1.2145e-01,\n         -6.0133e-02, -2.2564e-02, -3.9298e-02,  6.9870e-02,  6.6383e-02,\n         -9.6797e-02, -1.1184e-01],\n        [-1.5251e-01,  4.4245e-03, -1.0049e-01, -1.3436e-01, -3.1663e-02,\n          6.7584e-03,  1.2429e-01, -5.1017e-02, -8.4662e-02,  1.5223e-01,\n          6.2823e-02,  2.7961e-02, -1.6302e-01, -1.1165e-02,  1.3558e-01,\n         -3.5833e-02,  4.4182e-02, -1.7365e-01,  3.1232e-02,  1.3839e-01,\n         -1.1492e-01,  1.5715e-01, -7.3669e-02,  3.9857e-02, -1.0216e-01,\n         -9.8920e-02,  1.6761e-01, -1.6263e-01, -1.7568e-01, -2.6958e-02,\n          1.2981e-01,  1.6965e-01],\n        [ 1.6341e-01, -1.4660e-01,  6.9863e-02,  2.5711e-02,  6.3702e-02,\n         -1.5844e-01,  5.7194e-02, -1.5416e-01, -3.8839e-02, -1.0790e-01,\n          9.5100e-02, -1.7340e-02,  1.4159e-01,  8.0848e-02, -1.6982e-01,\n          8.6533e-02,  1.0809e-01,  8.8129e-05,  1.0224e-01, -9.1339e-02,\n         -5.4724e-02,  1.7177e-01, -9.8901e-02,  8.3525e-03, -1.0888e-01,\n         -1.3986e-01,  6.9446e-02,  1.6341e-01,  5.6870e-02,  5.1233e-02,\n         -2.9816e-03, -8.9286e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1470, -0.2165, -0.0349, -0.1625,  0.0831,  0.1229, -0.0110, -0.0979],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1381, -0.0302, -0.0983,  0.0757,  0.0338, -0.0124, -0.0044,  0.0130,\n          0.2192,  0.2450, -0.1988,  0.1482, -0.1600, -0.0323, -0.1778, -0.0655],\n        [ 0.2256, -0.2443,  0.1188, -0.0448, -0.2077, -0.1774,  0.1792,  0.1065,\n          0.0518, -0.1395, -0.0087,  0.2057, -0.0646, -0.2170, -0.1532, -0.0614],\n        [ 0.1286,  0.0971,  0.0872,  0.1079,  0.0354, -0.0561,  0.1731,  0.2328,\n          0.0564, -0.2413,  0.0877, -0.0992, -0.2155,  0.2160,  0.0542,  0.0176],\n        [-0.1420, -0.2039, -0.2191,  0.0710, -0.0090, -0.0446, -0.1416, -0.0564,\n         -0.0006,  0.0485, -0.1804,  0.2028, -0.1695,  0.1441,  0.2312,  0.0300],\n        [ 0.1560,  0.0390,  0.0976, -0.0861, -0.0152, -0.1539,  0.0256,  0.0814,\n          0.1952,  0.0457,  0.1010, -0.1098, -0.1883, -0.0886,  0.0677, -0.0587],\n        [-0.2500,  0.1787, -0.0610,  0.0214, -0.2123, -0.0177,  0.1281,  0.1140,\n          0.0104, -0.0986,  0.1240,  0.0462,  0.1159,  0.1662, -0.0723, -0.2067],\n        [-0.2399, -0.0091, -0.1966, -0.0611,  0.2230,  0.2107,  0.1522, -0.1608,\n          0.1296, -0.1317, -0.1565, -0.1694, -0.2198, -0.0030, -0.0431,  0.1862],\n        [ 0.1247, -0.1961, -0.1823, -0.0978, -0.2276, -0.2119,  0.2404, -0.0333,\n         -0.1066, -0.1248,  0.0298, -0.2135, -0.0515,  0.0638,  0.1171,  0.1851]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1781], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0727, -0.0273, -0.1865, -0.1904,  0.1330, -0.1120, -0.3306,  0.1182]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0205,  0.0297,  0.0098, -0.1123,  0.0190,  0.1280,  0.1410,  0.1007,\n         -0.2052, -0.0669,  0.0782,  0.0525, -0.0239, -0.1901, -0.1725,  0.0006,\n          0.2109,  0.0112,  0.1107, -0.1494],\n        [-0.0703,  0.1537, -0.0020, -0.0065, -0.1090,  0.0183, -0.0539,  0.0765,\n          0.0410,  0.0876, -0.1617, -0.1672, -0.0081, -0.0445,  0.1285, -0.1853,\n          0.1699, -0.0871, -0.0117, -0.0039],\n        [-0.1258, -0.0552, -0.0100,  0.1759,  0.0923, -0.1776, -0.0063,  0.0411,\n         -0.0294, -0.0006, -0.0201, -0.0651, -0.0962,  0.0786,  0.2096,  0.0338,\n         -0.1621, -0.1965, -0.0605, -0.1215],\n        [ 0.1360, -0.1608, -0.1872,  0.0285,  0.1690,  0.1310,  0.1588, -0.0177,\n         -0.0410,  0.0624, -0.1669, -0.0613,  0.1232, -0.0517, -0.1394,  0.1630,\n         -0.0329, -0.1424,  0.1671,  0.1055],\n        [-0.1836,  0.1003,  0.1419, -0.1048,  0.1533,  0.0419, -0.1205,  0.1232,\n          0.1425, -0.0142, -0.0847, -0.0808, -0.0514, -0.0869, -0.1813,  0.1810,\n          0.1219, -0.1425, -0.2136, -0.1593],\n        [ 0.0395,  0.0605,  0.0553, -0.1763, -0.1490,  0.2141,  0.0585, -0.1785,\n          0.0081,  0.1245,  0.1712, -0.1520, -0.1375,  0.2147, -0.0996, -0.0619,\n          0.0038,  0.1921,  0.0891,  0.1520],\n        [ 0.1486,  0.1330,  0.0993, -0.1987,  0.1367,  0.0962,  0.1058,  0.2202,\n         -0.2075, -0.0435, -0.0404, -0.0372,  0.1204,  0.1654, -0.1600,  0.0651,\n          0.0846, -0.0339,  0.1553, -0.0809],\n        [ 0.2221, -0.2230,  0.0148,  0.1917, -0.1373, -0.0186, -0.1228,  0.0360,\n          0.0757,  0.1453,  0.1589,  0.1426,  0.1520, -0.0087, -0.2155, -0.2041,\n          0.0739, -0.1566,  0.1363, -0.1089],\n        [-0.0044,  0.0639,  0.0532, -0.1338,  0.1346, -0.0303, -0.1185, -0.0985,\n         -0.0201,  0.0207,  0.0550,  0.0134,  0.1080,  0.2219,  0.2204,  0.2160,\n          0.0931, -0.0798,  0.2174, -0.2059],\n        [ 0.1636,  0.0680, -0.1897, -0.1238,  0.0911, -0.0246,  0.1565,  0.0231,\n          0.0523,  0.0865, -0.1628,  0.0377, -0.1872,  0.0737,  0.1654, -0.0486,\n         -0.0803,  0.2121,  0.0030, -0.1655],\n        [-0.1028, -0.1361,  0.2114,  0.1106, -0.0124, -0.1711, -0.1960,  0.1868,\n          0.1264, -0.0839, -0.0329,  0.1311,  0.1907,  0.0299, -0.0519,  0.1128,\n         -0.0024,  0.0569, -0.1167, -0.0939],\n        [ 0.0163,  0.1887,  0.0557,  0.0762, -0.0921, -0.1390, -0.0529,  0.0050,\n          0.1084, -0.0494, -0.1197, -0.0753,  0.1127, -0.0149, -0.0473,  0.1759,\n         -0.0496, -0.0830, -0.0235,  0.2080],\n        [ 0.0639, -0.1880, -0.0832,  0.1908, -0.1794,  0.0271,  0.2202,  0.0725,\n         -0.0300,  0.0727,  0.2063,  0.1938, -0.0847, -0.1963,  0.1751,  0.0923,\n         -0.1636,  0.1652, -0.2200, -0.1099],\n        [-0.1833,  0.1897, -0.0083, -0.1448, -0.2229, -0.0817,  0.1918,  0.1635,\n         -0.1544,  0.2226, -0.1617,  0.1234, -0.0325,  0.0894,  0.0190, -0.1605,\n         -0.1918, -0.1865,  0.0732, -0.0574],\n        [ 0.0420,  0.1161,  0.0605, -0.0036, -0.0430, -0.2030,  0.0891, -0.1093,\n         -0.1974, -0.0506,  0.1589,  0.1664, -0.1182,  0.0347, -0.0449,  0.0222,\n         -0.1980,  0.0788, -0.0663, -0.2130],\n        [ 0.1334, -0.2012, -0.0465,  0.1752, -0.1359, -0.0442, -0.0983,  0.0915,\n          0.0049, -0.1879,  0.1912,  0.1062, -0.1434, -0.0445, -0.0267, -0.1854,\n          0.1817,  0.1934, -0.0754,  0.0536],\n        [ 0.0785, -0.1157, -0.0627,  0.0999,  0.1402, -0.0685, -0.0406,  0.2062,\n         -0.0291,  0.1335, -0.0105,  0.1226,  0.1003, -0.1834,  0.0453, -0.0127,\n         -0.0767,  0.1106,  0.1582, -0.0883],\n        [-0.2224, -0.0620,  0.0257, -0.1831,  0.0900, -0.1860,  0.1893, -0.1872,\n          0.0571, -0.1660,  0.1041,  0.0975,  0.1547,  0.2164, -0.1097, -0.0863,\n          0.1136,  0.2149,  0.1823,  0.0519],\n        [ 0.1164, -0.1175, -0.2058,  0.0874,  0.0807, -0.1441,  0.0059,  0.1953,\n         -0.2034, -0.0171,  0.1840,  0.0856,  0.1402, -0.0022, -0.1022, -0.2137,\n          0.0034,  0.0066, -0.0267,  0.1724],\n        [ 0.1887,  0.0813, -0.1975,  0.0117,  0.1202, -0.2226,  0.2139, -0.0344,\n          0.2206,  0.1454,  0.1039,  0.1882,  0.1359, -0.1471, -0.0846, -0.1096,\n          0.1303, -0.1761, -0.1132, -0.0535],\n        [-0.0478, -0.1121,  0.1072, -0.0087,  0.0287,  0.0338,  0.2160, -0.1513,\n         -0.1670, -0.1530,  0.2096, -0.2067,  0.0032, -0.0765,  0.1894, -0.1193,\n          0.0880,  0.1304, -0.1528,  0.1675],\n        [ 0.2117, -0.0853, -0.2206,  0.0273,  0.0949,  0.1185,  0.0771, -0.0562,\n          0.1948,  0.0123,  0.1799, -0.2149,  0.0406,  0.0645,  0.0459, -0.1047,\n         -0.0021, -0.1983, -0.0781,  0.0206],\n        [ 0.1869,  0.1345, -0.1160,  0.0997,  0.0079,  0.1377, -0.1443, -0.1480,\n         -0.1232, -0.0066, -0.1155, -0.1752, -0.0978, -0.1364, -0.0381,  0.0111,\n          0.1687,  0.0672,  0.0166, -0.1414],\n        [-0.1803,  0.0435, -0.1458, -0.0360, -0.1503, -0.1490, -0.0672,  0.0311,\n         -0.0260, -0.1132,  0.1909,  0.1487,  0.0376,  0.2095, -0.1810, -0.0472,\n         -0.1622,  0.0413, -0.0841, -0.0548],\n        [-0.1569,  0.0097,  0.0861,  0.1092, -0.1424,  0.0007,  0.1077, -0.0373,\n         -0.1110,  0.0093, -0.1033,  0.2105,  0.1249,  0.1260,  0.1704,  0.1129,\n         -0.1272,  0.2143,  0.1665,  0.0899],\n        [-0.0890,  0.0430, -0.1468, -0.1691, -0.0362,  0.1134,  0.1523, -0.1305,\n          0.1337, -0.1700,  0.1966,  0.1736, -0.0008,  0.1094, -0.1854, -0.2014,\n          0.0420,  0.0724, -0.1279, -0.2024],\n        [-0.0348,  0.1352,  0.0359, -0.0819, -0.0211,  0.1882, -0.0819,  0.1877,\n         -0.0013,  0.1629, -0.1402,  0.1450,  0.1723,  0.1423,  0.1567,  0.1486,\n         -0.1877, -0.1954,  0.0074, -0.1311],\n        [-0.0863,  0.1450,  0.0913,  0.0970,  0.0547,  0.0377, -0.1169,  0.0099,\n          0.1832,  0.1926,  0.0305, -0.0384,  0.0452, -0.0433,  0.0982,  0.0812,\n         -0.0529, -0.1551,  0.2151,  0.0042],\n        [ 0.0555, -0.1436, -0.0662,  0.1655, -0.2111,  0.1746, -0.2027,  0.0096,\n         -0.0910, -0.0514, -0.1034, -0.2223,  0.2042,  0.0007,  0.0547, -0.1883,\n         -0.0384,  0.2035,  0.0252,  0.0822],\n        [ 0.1133,  0.1465, -0.0380, -0.1523, -0.0120,  0.1012,  0.0836, -0.2152,\n          0.0215,  0.0784,  0.0998, -0.0187, -0.1578, -0.2110,  0.1088, -0.0639,\n          0.0465,  0.0517,  0.1464,  0.0999],\n        [-0.2140,  0.0752,  0.0102, -0.1594, -0.1940, -0.1481,  0.1558,  0.1442,\n          0.1467, -0.2025, -0.0365,  0.1797,  0.1334, -0.0811,  0.2005,  0.0965,\n         -0.0134,  0.1373,  0.0809, -0.1027],\n        [ 0.0482,  0.0474, -0.0167,  0.1087,  0.0150, -0.0958,  0.1977, -0.0586,\n          0.0089,  0.0288,  0.0006,  0.1115,  0.0775, -0.1360, -0.0403, -0.0064,\n          0.2190, -0.2224, -0.0912, -0.1439]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1983, -0.0727, -0.1940,  0.2032, -0.1540,  0.0907, -0.1374,  0.1857,\n         0.0101,  0.1035, -0.1302,  0.0708, -0.0937, -0.1169, -0.1680,  0.1012,\n        -0.1452, -0.1211, -0.0980,  0.0181, -0.1395, -0.0368, -0.1703,  0.2119,\n         0.0472,  0.1299,  0.0057, -0.1456, -0.0219,  0.1528,  0.2090, -0.1345],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.4936e-01, -1.2745e-01, -6.2337e-02, -1.2840e-01,  1.5554e-01,\n         -3.6527e-02, -9.7433e-02,  1.5940e-01, -2.5624e-02,  1.7116e-01,\n         -1.5297e-01, -6.0738e-03,  1.3859e-01, -1.5072e-01,  1.7447e-01,\n          1.4748e-01,  1.7436e-01,  9.8186e-02, -1.6030e-01, -1.4209e-01,\n         -1.3553e-01,  5.9171e-02,  5.0454e-02, -1.4878e-01,  1.0015e-01,\n         -1.4014e-01, -1.2603e-01, -7.9149e-02,  1.0894e-01, -1.6389e-01,\n          8.4585e-02, -1.3419e-01],\n        [-4.0239e-02,  2.0315e-02,  1.6590e-01, -8.8094e-02, -3.0320e-03,\n         -6.0110e-02, -7.7777e-02,  3.8549e-02, -3.5862e-02,  8.9319e-02,\n          8.1966e-02,  1.3754e-01,  4.9069e-02, -4.6166e-02, -8.9386e-02,\n         -2.8595e-02,  4.2422e-02, -3.7895e-02,  2.8662e-02, -1.3610e-01,\n         -1.9682e-02, -1.6189e-01,  6.6451e-02,  5.6066e-02,  6.0119e-02,\n         -5.4639e-02,  4.9545e-02,  1.3405e-01,  5.6229e-02,  1.4900e-01,\n         -6.4747e-02,  3.1810e-02],\n        [ 7.0553e-03,  1.4620e-01, -5.5218e-02,  1.2669e-01, -2.2772e-02,\n          7.1703e-03,  5.1172e-02,  1.0441e-01, -1.4656e-01, -3.2022e-02,\n         -1.3999e-01,  1.8365e-02,  4.6450e-02,  3.9470e-02, -5.1947e-02,\n         -4.2103e-03, -1.3056e-01,  9.5049e-03,  7.7275e-02,  1.0418e-01,\n          7.2161e-02, -5.7312e-02,  6.4840e-02,  9.9468e-02, -1.0369e-01,\n          8.7407e-02,  6.3893e-02,  1.6248e-01,  3.0338e-02,  6.4938e-02,\n         -1.4264e-01, -7.8402e-02],\n        [-1.1414e-01,  2.1061e-02,  5.0217e-02,  3.5067e-02, -4.3749e-02,\n         -1.2602e-01,  1.5392e-01, -4.3724e-02,  8.8878e-02,  5.3190e-02,\n         -8.1105e-02,  1.1304e-01, -1.5851e-01,  8.2320e-02,  4.4892e-03,\n         -1.4841e-01, -3.7849e-02, -2.7315e-02,  1.4350e-01, -1.1983e-01,\n          6.4540e-02, -4.7521e-02,  2.9838e-02,  1.7526e-01,  9.3715e-02,\n          1.1339e-01, -4.9519e-02,  1.4202e-01, -1.0753e-01,  1.0906e-01,\n         -7.5605e-02, -1.1644e-01],\n        [ 1.0454e-01,  1.7437e-01,  5.9674e-02,  1.3761e-01,  1.3652e-01,\n          1.1997e-01, -1.2728e-02,  1.1740e-01,  1.3672e-02,  1.2642e-01,\n          1.0140e-02,  3.9642e-03,  6.9125e-02, -5.0543e-02, -1.1336e-01,\n          7.9806e-02, -1.3078e-01,  9.2554e-02,  6.8916e-02,  3.7551e-02,\n         -5.6932e-02,  1.4784e-01, -9.0853e-02,  1.1855e-01, -9.9074e-02,\n         -7.9047e-02,  8.1385e-02,  1.2586e-01, -8.8008e-02, -1.8725e-02,\n          1.5598e-01,  1.5280e-01],\n        [-1.6317e-01, -1.7358e-01,  1.2718e-01, -1.4536e-01, -4.4757e-02,\n          2.8940e-02, -1.5600e-01,  8.8280e-02,  9.2828e-02,  1.4170e-01,\n          1.4369e-01, -1.4387e-01,  9.7731e-03, -8.5199e-03,  1.3989e-01,\n         -1.4785e-01, -7.9328e-02, -3.5342e-02, -8.1849e-02, -8.0676e-02,\n          1.2760e-01, -9.7954e-02,  9.8837e-03, -7.3273e-03,  6.6498e-02,\n          1.4720e-01,  7.0702e-02,  4.3790e-02, -7.6305e-03,  3.6768e-02,\n         -1.1718e-01,  9.6392e-02],\n        [-6.9045e-02, -1.7393e-02,  6.5367e-02,  1.3104e-01, -2.0395e-02,\n         -1.7200e-01,  5.3973e-03,  9.3400e-02,  1.7321e-01,  7.8505e-02,\n         -5.3318e-02, -1.4225e-01,  8.9918e-02, -3.9308e-02, -1.3919e-01,\n          6.3467e-03,  9.2942e-02,  6.7904e-02,  8.8700e-02,  1.0578e-01,\n         -1.2678e-01,  2.5661e-02, -1.6159e-01,  4.1778e-02, -1.1987e-01,\n          6.4489e-02, -1.3698e-01, -6.5826e-02, -2.2765e-02, -1.6399e-01,\n         -1.0331e-01, -1.3606e-01],\n        [-1.1254e-01,  8.0455e-02,  1.8579e-02,  2.5363e-02,  1.0124e-01,\n          6.8504e-02, -8.4947e-03,  1.4880e-01, -1.1333e-02, -8.8084e-02,\n         -1.5283e-01,  9.9066e-03,  1.5977e-01,  2.2756e-02,  1.1529e-01,\n         -9.6375e-02,  6.2258e-02,  1.1488e-01,  5.3022e-02,  8.9148e-02,\n          1.5220e-02, -1.4092e-01, -1.0924e-01,  1.6025e-01,  1.9921e-02,\n         -2.3544e-02,  1.0315e-01,  5.0343e-02,  1.0373e-01, -5.8618e-02,\n          1.2612e-01,  3.3235e-02],\n        [ 6.6704e-02, -9.8127e-02, -1.1079e-01, -1.6791e-01,  1.6941e-02,\n          1.7178e-02, -5.1207e-02,  4.7762e-02,  1.2954e-01,  6.0236e-02,\n          8.0083e-02, -6.2440e-02, -1.9811e-02,  1.5647e-01, -1.0088e-01,\n          9.8745e-02,  1.7498e-01,  1.4384e-01,  1.0600e-01, -1.3172e-01,\n          1.2753e-01, -1.4876e-01, -1.0570e-01, -9.0458e-02, -3.3942e-02,\n         -9.7604e-02,  1.5880e-01, -1.7003e-01,  2.3755e-02, -1.4475e-01,\n          1.5545e-01,  1.3722e-01],\n        [ 1.3796e-01, -8.3036e-02, -9.6566e-02,  5.5288e-02,  7.2146e-02,\n         -1.0057e-01, -7.2761e-02, -1.4457e-01, -1.6417e-01,  1.6645e-03,\n         -4.3523e-02, -5.5658e-02,  1.4099e-01,  8.7598e-03,  1.4305e-01,\n          1.6812e-01, -6.3677e-02,  1.1513e-01, -8.4350e-02,  7.0829e-02,\n          1.5841e-02,  8.5204e-02,  1.1448e-01,  3.5254e-02,  7.8369e-02,\n         -3.4767e-02,  1.7267e-01, -1.7768e-02, -1.1342e-02,  1.0264e-01,\n         -1.3801e-01, -9.5320e-02],\n        [ 1.6259e-01,  1.6407e-03, -3.1932e-02, -2.2796e-02, -8.1666e-02,\n         -1.3995e-01,  4.8696e-02, -1.6225e-01,  1.3947e-01,  3.3172e-02,\n         -2.2598e-02, -5.0942e-03, -2.0908e-02,  3.0927e-02, -8.9787e-02,\n          2.9296e-02,  1.7086e-01, -1.4453e-01, -3.3365e-02,  1.0395e-01,\n          1.7320e-01,  3.9472e-02,  1.1400e-01,  9.3936e-02, -7.0870e-02,\n         -6.8723e-02, -1.6528e-01,  6.7701e-02, -5.0118e-02,  6.1337e-03,\n          1.6492e-02,  1.1780e-01],\n        [-4.7594e-02, -1.7620e-01, -1.8162e-02,  2.2253e-02,  6.5837e-02,\n          1.1851e-01, -7.6558e-02,  3.0580e-02,  1.2863e-01,  1.3636e-01,\n          1.1306e-01, -1.3051e-01,  1.3057e-01, -1.4751e-01,  1.3650e-01,\n         -3.3289e-02,  1.2217e-01, -8.9390e-03,  5.4568e-02,  1.4813e-01,\n         -1.7162e-01, -1.5928e-01,  3.5606e-02,  8.5723e-02,  1.6265e-01,\n          3.0517e-02,  1.2025e-01, -1.0563e-01, -6.9861e-02, -3.7775e-03,\n         -7.5276e-02,  1.6277e-01],\n        [-1.4925e-02,  1.6953e-01,  6.9006e-02, -1.1359e-01,  6.6967e-02,\n          2.6842e-02,  6.6795e-02, -4.7483e-02,  7.7497e-02,  1.7353e-01,\n          1.7489e-01,  1.6165e-01,  1.1598e-01,  1.4297e-01, -1.7316e-01,\n          1.7018e-01,  7.6188e-03,  1.0448e-01,  1.1213e-01, -4.0834e-02,\n          5.9234e-02, -4.0123e-03,  9.1548e-02,  1.1645e-01, -4.7490e-02,\n         -1.1239e-01, -1.5641e-01, -9.0480e-02,  1.7482e-01,  1.3405e-01,\n         -6.2654e-02,  7.5748e-02],\n        [ 1.2810e-01,  1.6739e-01,  1.0024e-01,  1.5321e-01, -1.2939e-01,\n         -5.7492e-02,  1.6467e-01, -1.7342e-01,  1.4755e-02, -1.7007e-01,\n          9.8889e-02,  1.3520e-01, -6.6933e-02,  6.3540e-02,  1.3632e-02,\n         -7.3399e-02,  5.3516e-02, -8.6075e-02,  1.0906e-01,  4.4399e-02,\n         -2.6172e-02,  1.2170e-01,  7.7340e-02,  8.7032e-02, -1.2145e-01,\n         -6.0133e-02, -2.2564e-02, -3.9298e-02,  6.9870e-02,  6.6383e-02,\n         -9.6797e-02, -1.1184e-01],\n        [-1.5251e-01,  4.4245e-03, -1.0049e-01, -1.3436e-01, -3.1663e-02,\n          6.7584e-03,  1.2429e-01, -5.1017e-02, -8.4662e-02,  1.5223e-01,\n          6.2823e-02,  2.7961e-02, -1.6302e-01, -1.1165e-02,  1.3558e-01,\n         -3.5833e-02,  4.4182e-02, -1.7365e-01,  3.1232e-02,  1.3839e-01,\n         -1.1492e-01,  1.5715e-01, -7.3669e-02,  3.9857e-02, -1.0216e-01,\n         -9.8920e-02,  1.6761e-01, -1.6263e-01, -1.7568e-01, -2.6958e-02,\n          1.2981e-01,  1.6965e-01],\n        [ 1.6341e-01, -1.4660e-01,  6.9863e-02,  2.5711e-02,  6.3702e-02,\n         -1.5844e-01,  5.7194e-02, -1.5416e-01, -3.8839e-02, -1.0790e-01,\n          9.5100e-02, -1.7340e-02,  1.4159e-01,  8.0848e-02, -1.6982e-01,\n          8.6533e-02,  1.0809e-01,  8.8129e-05,  1.0224e-01, -9.1339e-02,\n         -5.4724e-02,  1.7177e-01, -9.8901e-02,  8.3525e-03, -1.0888e-01,\n         -1.3986e-01,  6.9446e-02,  1.6341e-01,  5.6870e-02,  5.1233e-02,\n         -2.9816e-03, -8.9286e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0136, -0.0726,  0.1017, -0.0153,  0.0109,  0.1204,  0.0242,  0.1206,\n        -0.1622,  0.0243, -0.0529,  0.0149, -0.0511,  0.1653,  0.0730,  0.0065],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1381, -0.0302, -0.0983,  0.0757,  0.0338, -0.0124, -0.0044,  0.0130,\n          0.2192,  0.2450, -0.1988,  0.1482, -0.1600, -0.0323, -0.1778, -0.0655],\n        [ 0.2256, -0.2443,  0.1188, -0.0448, -0.2077, -0.1774,  0.1792,  0.1065,\n          0.0518, -0.1395, -0.0087,  0.2057, -0.0646, -0.2170, -0.1532, -0.0614],\n        [ 0.1286,  0.0971,  0.0872,  0.1079,  0.0354, -0.0561,  0.1731,  0.2328,\n          0.0564, -0.2413,  0.0877, -0.0992, -0.2155,  0.2160,  0.0542,  0.0176],\n        [-0.1420, -0.2039, -0.2191,  0.0710, -0.0090, -0.0446, -0.1416, -0.0564,\n         -0.0006,  0.0485, -0.1804,  0.2028, -0.1695,  0.1441,  0.2312,  0.0300],\n        [ 0.1560,  0.0390,  0.0976, -0.0861, -0.0152, -0.1539,  0.0256,  0.0814,\n          0.1952,  0.0457,  0.1010, -0.1098, -0.1883, -0.0886,  0.0677, -0.0587],\n        [-0.2500,  0.1787, -0.0610,  0.0214, -0.2123, -0.0177,  0.1281,  0.1140,\n          0.0104, -0.0986,  0.1240,  0.0462,  0.1159,  0.1662, -0.0723, -0.2067],\n        [-0.2399, -0.0091, -0.1966, -0.0611,  0.2230,  0.2107,  0.1522, -0.1608,\n          0.1296, -0.1317, -0.1565, -0.1694, -0.2198, -0.0030, -0.0431,  0.1862],\n        [ 0.1247, -0.1961, -0.1823, -0.0978, -0.2276, -0.2119,  0.2404, -0.0333,\n         -0.1066, -0.1248,  0.0298, -0.2135, -0.0515,  0.0638,  0.1171,  0.1851]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1470, -0.2165, -0.0349, -0.1625,  0.0831,  0.1229, -0.0110, -0.0979],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0727, -0.0273, -0.1865, -0.1904,  0.1330, -0.1120, -0.3306,  0.1182]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.1781], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x1098f2290>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1983, -0.0727, -0.1940,  0.2032, -0.1540,  0.0907, -0.1374,  0.1857,\n         0.0101,  0.1035, -0.1302,  0.0708, -0.0937, -0.1169, -0.1680,  0.1012,\n        -0.1452, -0.1211, -0.0980,  0.0181, -0.1395, -0.0368, -0.1703,  0.2119,\n         0.0472,  0.1299,  0.0057, -0.1456, -0.0219,  0.1528,  0.2090, -0.1345],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0205,  0.0297,  0.0098, -0.1123,  0.0190,  0.1280,  0.1410,  0.1007,\n         -0.2052, -0.0669,  0.0782,  0.0525, -0.0239, -0.1901, -0.1725,  0.0006,\n          0.2109,  0.0112,  0.1107, -0.1494],\n        [-0.0703,  0.1537, -0.0020, -0.0065, -0.1090,  0.0183, -0.0539,  0.0765,\n          0.0410,  0.0876, -0.1617, -0.1672, -0.0081, -0.0445,  0.1285, -0.1853,\n          0.1699, -0.0871, -0.0117, -0.0039],\n        [-0.1258, -0.0552, -0.0100,  0.1759,  0.0923, -0.1776, -0.0063,  0.0411,\n         -0.0294, -0.0006, -0.0201, -0.0651, -0.0962,  0.0786,  0.2096,  0.0338,\n         -0.1621, -0.1965, -0.0605, -0.1215],\n        [ 0.1360, -0.1608, -0.1872,  0.0285,  0.1690,  0.1310,  0.1588, -0.0177,\n         -0.0410,  0.0624, -0.1669, -0.0613,  0.1232, -0.0517, -0.1394,  0.1630,\n         -0.0329, -0.1424,  0.1671,  0.1055],\n        [-0.1836,  0.1003,  0.1419, -0.1048,  0.1533,  0.0419, -0.1205,  0.1232,\n          0.1425, -0.0142, -0.0847, -0.0808, -0.0514, -0.0869, -0.1813,  0.1810,\n          0.1219, -0.1425, -0.2136, -0.1593],\n        [ 0.0395,  0.0605,  0.0553, -0.1763, -0.1490,  0.2141,  0.0585, -0.1785,\n          0.0081,  0.1245,  0.1712, -0.1520, -0.1375,  0.2147, -0.0996, -0.0619,\n          0.0038,  0.1921,  0.0891,  0.1520],\n        [ 0.1486,  0.1330,  0.0993, -0.1987,  0.1367,  0.0962,  0.1058,  0.2202,\n         -0.2075, -0.0435, -0.0404, -0.0372,  0.1204,  0.1654, -0.1600,  0.0651,\n          0.0846, -0.0339,  0.1553, -0.0809],\n        [ 0.2221, -0.2230,  0.0148,  0.1917, -0.1373, -0.0186, -0.1228,  0.0360,\n          0.0757,  0.1453,  0.1589,  0.1426,  0.1520, -0.0087, -0.2155, -0.2041,\n          0.0739, -0.1566,  0.1363, -0.1089],\n        [-0.0044,  0.0639,  0.0532, -0.1338,  0.1346, -0.0303, -0.1185, -0.0985,\n         -0.0201,  0.0207,  0.0550,  0.0134,  0.1080,  0.2219,  0.2204,  0.2160,\n          0.0931, -0.0798,  0.2174, -0.2059],\n        [ 0.1636,  0.0680, -0.1897, -0.1238,  0.0911, -0.0246,  0.1565,  0.0231,\n          0.0523,  0.0865, -0.1628,  0.0377, -0.1872,  0.0737,  0.1654, -0.0486,\n         -0.0803,  0.2121,  0.0030, -0.1655],\n        [-0.1028, -0.1361,  0.2114,  0.1106, -0.0124, -0.1711, -0.1960,  0.1868,\n          0.1264, -0.0839, -0.0329,  0.1311,  0.1907,  0.0299, -0.0519,  0.1128,\n         -0.0024,  0.0569, -0.1167, -0.0939],\n        [ 0.0163,  0.1887,  0.0557,  0.0762, -0.0921, -0.1390, -0.0529,  0.0050,\n          0.1084, -0.0494, -0.1197, -0.0753,  0.1127, -0.0149, -0.0473,  0.1759,\n         -0.0496, -0.0830, -0.0235,  0.2080],\n        [ 0.0639, -0.1880, -0.0832,  0.1908, -0.1794,  0.0271,  0.2202,  0.0725,\n         -0.0300,  0.0727,  0.2063,  0.1938, -0.0847, -0.1963,  0.1751,  0.0923,\n         -0.1636,  0.1652, -0.2200, -0.1099],\n        [-0.1833,  0.1897, -0.0083, -0.1448, -0.2229, -0.0817,  0.1918,  0.1635,\n         -0.1544,  0.2226, -0.1617,  0.1234, -0.0325,  0.0894,  0.0190, -0.1605,\n         -0.1918, -0.1865,  0.0732, -0.0574],\n        [ 0.0420,  0.1161,  0.0605, -0.0036, -0.0430, -0.2030,  0.0891, -0.1093,\n         -0.1974, -0.0506,  0.1589,  0.1664, -0.1182,  0.0347, -0.0449,  0.0222,\n         -0.1980,  0.0788, -0.0663, -0.2130],\n        [ 0.1334, -0.2012, -0.0465,  0.1752, -0.1359, -0.0442, -0.0983,  0.0915,\n          0.0049, -0.1879,  0.1912,  0.1062, -0.1434, -0.0445, -0.0267, -0.1854,\n          0.1817,  0.1934, -0.0754,  0.0536],\n        [ 0.0785, -0.1157, -0.0627,  0.0999,  0.1402, -0.0685, -0.0406,  0.2062,\n         -0.0291,  0.1335, -0.0105,  0.1226,  0.1003, -0.1834,  0.0453, -0.0127,\n         -0.0767,  0.1106,  0.1582, -0.0883],\n        [-0.2224, -0.0620,  0.0257, -0.1831,  0.0900, -0.1860,  0.1893, -0.1872,\n          0.0571, -0.1660,  0.1041,  0.0975,  0.1547,  0.2164, -0.1097, -0.0863,\n          0.1136,  0.2149,  0.1823,  0.0519],\n        [ 0.1164, -0.1175, -0.2058,  0.0874,  0.0807, -0.1441,  0.0059,  0.1953,\n         -0.2034, -0.0171,  0.1840,  0.0856,  0.1402, -0.0022, -0.1022, -0.2137,\n          0.0034,  0.0066, -0.0267,  0.1724],\n        [ 0.1887,  0.0813, -0.1975,  0.0117,  0.1202, -0.2226,  0.2139, -0.0344,\n          0.2206,  0.1454,  0.1039,  0.1882,  0.1359, -0.1471, -0.0846, -0.1096,\n          0.1303, -0.1761, -0.1132, -0.0535],\n        [-0.0478, -0.1121,  0.1072, -0.0087,  0.0287,  0.0338,  0.2160, -0.1513,\n         -0.1670, -0.1530,  0.2096, -0.2067,  0.0032, -0.0765,  0.1894, -0.1193,\n          0.0880,  0.1304, -0.1528,  0.1675],\n        [ 0.2117, -0.0853, -0.2206,  0.0273,  0.0949,  0.1185,  0.0771, -0.0562,\n          0.1948,  0.0123,  0.1799, -0.2149,  0.0406,  0.0645,  0.0459, -0.1047,\n         -0.0021, -0.1983, -0.0781,  0.0206],\n        [ 0.1869,  0.1345, -0.1160,  0.0997,  0.0079,  0.1377, -0.1443, -0.1480,\n         -0.1232, -0.0066, -0.1155, -0.1752, -0.0978, -0.1364, -0.0381,  0.0111,\n          0.1687,  0.0672,  0.0166, -0.1414],\n        [-0.1803,  0.0435, -0.1458, -0.0360, -0.1503, -0.1490, -0.0672,  0.0311,\n         -0.0260, -0.1132,  0.1909,  0.1487,  0.0376,  0.2095, -0.1810, -0.0472,\n         -0.1622,  0.0413, -0.0841, -0.0548],\n        [-0.1569,  0.0097,  0.0861,  0.1092, -0.1424,  0.0007,  0.1077, -0.0373,\n         -0.1110,  0.0093, -0.1033,  0.2105,  0.1249,  0.1260,  0.1704,  0.1129,\n         -0.1272,  0.2143,  0.1665,  0.0899],\n        [-0.0890,  0.0430, -0.1468, -0.1691, -0.0362,  0.1134,  0.1523, -0.1305,\n          0.1337, -0.1700,  0.1966,  0.1736, -0.0008,  0.1094, -0.1854, -0.2014,\n          0.0420,  0.0724, -0.1279, -0.2024],\n        [-0.0348,  0.1352,  0.0359, -0.0819, -0.0211,  0.1882, -0.0819,  0.1877,\n         -0.0013,  0.1629, -0.1402,  0.1450,  0.1723,  0.1423,  0.1567,  0.1486,\n         -0.1877, -0.1954,  0.0074, -0.1311],\n        [-0.0863,  0.1450,  0.0913,  0.0970,  0.0547,  0.0377, -0.1169,  0.0099,\n          0.1832,  0.1926,  0.0305, -0.0384,  0.0452, -0.0433,  0.0982,  0.0812,\n         -0.0529, -0.1551,  0.2151,  0.0042],\n        [ 0.0555, -0.1436, -0.0662,  0.1655, -0.2111,  0.1746, -0.2027,  0.0096,\n         -0.0910, -0.0514, -0.1034, -0.2223,  0.2042,  0.0007,  0.0547, -0.1883,\n         -0.0384,  0.2035,  0.0252,  0.0822],\n        [ 0.1133,  0.1465, -0.0380, -0.1523, -0.0120,  0.1012,  0.0836, -0.2152,\n          0.0215,  0.0784,  0.0998, -0.0187, -0.1578, -0.2110,  0.1088, -0.0639,\n          0.0465,  0.0517,  0.1464,  0.0999],\n        [-0.2140,  0.0752,  0.0102, -0.1594, -0.1940, -0.1481,  0.1558,  0.1442,\n          0.1467, -0.2025, -0.0365,  0.1797,  0.1334, -0.0811,  0.2005,  0.0965,\n         -0.0134,  0.1373,  0.0809, -0.1027],\n        [ 0.0482,  0.0474, -0.0167,  0.1087,  0.0150, -0.0958,  0.1977, -0.0586,\n          0.0089,  0.0288,  0.0006,  0.1115,  0.0775, -0.1360, -0.0403, -0.0064,\n          0.2190, -0.2224, -0.0912, -0.1439]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.0136, -0.0726,  0.1017, -0.0153,  0.0109,  0.1204,  0.0242,  0.1206,\n        -0.1622,  0.0243, -0.0529,  0.0149, -0.0511,  0.1653,  0.0730,  0.0065],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 1.4936e-01, -1.2745e-01, -6.2337e-02, -1.2840e-01,  1.5554e-01,\n         -3.6527e-02, -9.7433e-02,  1.5940e-01, -2.5624e-02,  1.7116e-01,\n         -1.5297e-01, -6.0738e-03,  1.3859e-01, -1.5072e-01,  1.7447e-01,\n          1.4748e-01,  1.7436e-01,  9.8186e-02, -1.6030e-01, -1.4209e-01,\n         -1.3553e-01,  5.9171e-02,  5.0454e-02, -1.4878e-01,  1.0015e-01,\n         -1.4014e-01, -1.2603e-01, -7.9149e-02,  1.0894e-01, -1.6389e-01,\n          8.4585e-02, -1.3419e-01],\n        [-4.0239e-02,  2.0315e-02,  1.6590e-01, -8.8094e-02, -3.0320e-03,\n         -6.0110e-02, -7.7777e-02,  3.8549e-02, -3.5862e-02,  8.9319e-02,\n          8.1966e-02,  1.3754e-01,  4.9069e-02, -4.6166e-02, -8.9386e-02,\n         -2.8595e-02,  4.2422e-02, -3.7895e-02,  2.8662e-02, -1.3610e-01,\n         -1.9682e-02, -1.6189e-01,  6.6451e-02,  5.6066e-02,  6.0119e-02,\n         -5.4639e-02,  4.9545e-02,  1.3405e-01,  5.6229e-02,  1.4900e-01,\n         -6.4747e-02,  3.1810e-02],\n        [ 7.0553e-03,  1.4620e-01, -5.5218e-02,  1.2669e-01, -2.2772e-02,\n          7.1703e-03,  5.1172e-02,  1.0441e-01, -1.4656e-01, -3.2022e-02,\n         -1.3999e-01,  1.8365e-02,  4.6450e-02,  3.9470e-02, -5.1947e-02,\n         -4.2103e-03, -1.3056e-01,  9.5049e-03,  7.7275e-02,  1.0418e-01,\n          7.2161e-02, -5.7312e-02,  6.4840e-02,  9.9468e-02, -1.0369e-01,\n          8.7407e-02,  6.3893e-02,  1.6248e-01,  3.0338e-02,  6.4938e-02,\n         -1.4264e-01, -7.8402e-02],\n        [-1.1414e-01,  2.1061e-02,  5.0217e-02,  3.5067e-02, -4.3749e-02,\n         -1.2602e-01,  1.5392e-01, -4.3724e-02,  8.8878e-02,  5.3190e-02,\n         -8.1105e-02,  1.1304e-01, -1.5851e-01,  8.2320e-02,  4.4892e-03,\n         -1.4841e-01, -3.7849e-02, -2.7315e-02,  1.4350e-01, -1.1983e-01,\n          6.4540e-02, -4.7521e-02,  2.9838e-02,  1.7526e-01,  9.3715e-02,\n          1.1339e-01, -4.9519e-02,  1.4202e-01, -1.0753e-01,  1.0906e-01,\n         -7.5605e-02, -1.1644e-01],\n        [ 1.0454e-01,  1.7437e-01,  5.9674e-02,  1.3761e-01,  1.3652e-01,\n          1.1997e-01, -1.2728e-02,  1.1740e-01,  1.3672e-02,  1.2642e-01,\n          1.0140e-02,  3.9642e-03,  6.9125e-02, -5.0543e-02, -1.1336e-01,\n          7.9806e-02, -1.3078e-01,  9.2554e-02,  6.8916e-02,  3.7551e-02,\n         -5.6932e-02,  1.4784e-01, -9.0853e-02,  1.1855e-01, -9.9074e-02,\n         -7.9047e-02,  8.1385e-02,  1.2586e-01, -8.8008e-02, -1.8725e-02,\n          1.5598e-01,  1.5280e-01],\n        [-1.6317e-01, -1.7358e-01,  1.2718e-01, -1.4536e-01, -4.4757e-02,\n          2.8940e-02, -1.5600e-01,  8.8280e-02,  9.2828e-02,  1.4170e-01,\n          1.4369e-01, -1.4387e-01,  9.7731e-03, -8.5199e-03,  1.3989e-01,\n         -1.4785e-01, -7.9328e-02, -3.5342e-02, -8.1849e-02, -8.0676e-02,\n          1.2760e-01, -9.7954e-02,  9.8837e-03, -7.3273e-03,  6.6498e-02,\n          1.4720e-01,  7.0702e-02,  4.3790e-02, -7.6305e-03,  3.6768e-02,\n         -1.1718e-01,  9.6392e-02],\n        [-6.9045e-02, -1.7393e-02,  6.5367e-02,  1.3104e-01, -2.0395e-02,\n         -1.7200e-01,  5.3973e-03,  9.3400e-02,  1.7321e-01,  7.8505e-02,\n         -5.3318e-02, -1.4225e-01,  8.9918e-02, -3.9308e-02, -1.3919e-01,\n          6.3467e-03,  9.2942e-02,  6.7904e-02,  8.8700e-02,  1.0578e-01,\n         -1.2678e-01,  2.5661e-02, -1.6159e-01,  4.1778e-02, -1.1987e-01,\n          6.4489e-02, -1.3698e-01, -6.5826e-02, -2.2765e-02, -1.6399e-01,\n         -1.0331e-01, -1.3606e-01],\n        [-1.1254e-01,  8.0455e-02,  1.8579e-02,  2.5363e-02,  1.0124e-01,\n          6.8504e-02, -8.4947e-03,  1.4880e-01, -1.1333e-02, -8.8084e-02,\n         -1.5283e-01,  9.9066e-03,  1.5977e-01,  2.2756e-02,  1.1529e-01,\n         -9.6375e-02,  6.2258e-02,  1.1488e-01,  5.3022e-02,  8.9148e-02,\n          1.5220e-02, -1.4092e-01, -1.0924e-01,  1.6025e-01,  1.9921e-02,\n         -2.3544e-02,  1.0315e-01,  5.0343e-02,  1.0373e-01, -5.8618e-02,\n          1.2612e-01,  3.3235e-02],\n        [ 6.6704e-02, -9.8127e-02, -1.1079e-01, -1.6791e-01,  1.6941e-02,\n          1.7178e-02, -5.1207e-02,  4.7762e-02,  1.2954e-01,  6.0236e-02,\n          8.0083e-02, -6.2440e-02, -1.9811e-02,  1.5647e-01, -1.0088e-01,\n          9.8745e-02,  1.7498e-01,  1.4384e-01,  1.0600e-01, -1.3172e-01,\n          1.2753e-01, -1.4876e-01, -1.0570e-01, -9.0458e-02, -3.3942e-02,\n         -9.7604e-02,  1.5880e-01, -1.7003e-01,  2.3755e-02, -1.4475e-01,\n          1.5545e-01,  1.3722e-01],\n        [ 1.3796e-01, -8.3036e-02, -9.6566e-02,  5.5288e-02,  7.2146e-02,\n         -1.0057e-01, -7.2761e-02, -1.4457e-01, -1.6417e-01,  1.6645e-03,\n         -4.3523e-02, -5.5658e-02,  1.4099e-01,  8.7598e-03,  1.4305e-01,\n          1.6812e-01, -6.3677e-02,  1.1513e-01, -8.4350e-02,  7.0829e-02,\n          1.5841e-02,  8.5204e-02,  1.1448e-01,  3.5254e-02,  7.8369e-02,\n         -3.4767e-02,  1.7267e-01, -1.7768e-02, -1.1342e-02,  1.0264e-01,\n         -1.3801e-01, -9.5320e-02],\n        [ 1.6259e-01,  1.6407e-03, -3.1932e-02, -2.2796e-02, -8.1666e-02,\n         -1.3995e-01,  4.8696e-02, -1.6225e-01,  1.3947e-01,  3.3172e-02,\n         -2.2598e-02, -5.0942e-03, -2.0908e-02,  3.0927e-02, -8.9787e-02,\n          2.9296e-02,  1.7086e-01, -1.4453e-01, -3.3365e-02,  1.0395e-01,\n          1.7320e-01,  3.9472e-02,  1.1400e-01,  9.3936e-02, -7.0870e-02,\n         -6.8723e-02, -1.6528e-01,  6.7701e-02, -5.0118e-02,  6.1337e-03,\n          1.6492e-02,  1.1780e-01],\n        [-4.7594e-02, -1.7620e-01, -1.8162e-02,  2.2253e-02,  6.5837e-02,\n          1.1851e-01, -7.6558e-02,  3.0580e-02,  1.2863e-01,  1.3636e-01,\n          1.1306e-01, -1.3051e-01,  1.3057e-01, -1.4751e-01,  1.3650e-01,\n         -3.3289e-02,  1.2217e-01, -8.9390e-03,  5.4568e-02,  1.4813e-01,\n         -1.7162e-01, -1.5928e-01,  3.5606e-02,  8.5723e-02,  1.6265e-01,\n          3.0517e-02,  1.2025e-01, -1.0563e-01, -6.9861e-02, -3.7775e-03,\n         -7.5276e-02,  1.6277e-01],\n        [-1.4925e-02,  1.6953e-01,  6.9006e-02, -1.1359e-01,  6.6967e-02,\n          2.6842e-02,  6.6795e-02, -4.7483e-02,  7.7497e-02,  1.7353e-01,\n          1.7489e-01,  1.6165e-01,  1.1598e-01,  1.4297e-01, -1.7316e-01,\n          1.7018e-01,  7.6188e-03,  1.0448e-01,  1.1213e-01, -4.0834e-02,\n          5.9234e-02, -4.0123e-03,  9.1548e-02,  1.1645e-01, -4.7490e-02,\n         -1.1239e-01, -1.5641e-01, -9.0480e-02,  1.7482e-01,  1.3405e-01,\n         -6.2654e-02,  7.5748e-02],\n        [ 1.2810e-01,  1.6739e-01,  1.0024e-01,  1.5321e-01, -1.2939e-01,\n         -5.7492e-02,  1.6467e-01, -1.7342e-01,  1.4755e-02, -1.7007e-01,\n          9.8889e-02,  1.3520e-01, -6.6933e-02,  6.3540e-02,  1.3632e-02,\n         -7.3399e-02,  5.3516e-02, -8.6075e-02,  1.0906e-01,  4.4399e-02,\n         -2.6172e-02,  1.2170e-01,  7.7340e-02,  8.7032e-02, -1.2145e-01,\n         -6.0133e-02, -2.2564e-02, -3.9298e-02,  6.9870e-02,  6.6383e-02,\n         -9.6797e-02, -1.1184e-01],\n        [-1.5251e-01,  4.4245e-03, -1.0049e-01, -1.3436e-01, -3.1663e-02,\n          6.7584e-03,  1.2429e-01, -5.1017e-02, -8.4662e-02,  1.5223e-01,\n          6.2823e-02,  2.7961e-02, -1.6302e-01, -1.1165e-02,  1.3558e-01,\n         -3.5833e-02,  4.4182e-02, -1.7365e-01,  3.1232e-02,  1.3839e-01,\n         -1.1492e-01,  1.5715e-01, -7.3669e-02,  3.9857e-02, -1.0216e-01,\n         -9.8920e-02,  1.6761e-01, -1.6263e-01, -1.7568e-01, -2.6958e-02,\n          1.2981e-01,  1.6965e-01],\n        [ 1.6341e-01, -1.4660e-01,  6.9863e-02,  2.5711e-02,  6.3702e-02,\n         -1.5844e-01,  5.7194e-02, -1.5416e-01, -3.8839e-02, -1.0790e-01,\n          9.5100e-02, -1.7340e-02,  1.4159e-01,  8.0848e-02, -1.6982e-01,\n          8.6533e-02,  1.0809e-01,  8.8129e-05,  1.0224e-01, -9.1339e-02,\n         -5.4724e-02,  1.7177e-01, -9.8901e-02,  8.3525e-03, -1.0888e-01,\n         -1.3986e-01,  6.9446e-02,  1.6341e-01,  5.6870e-02,  5.1233e-02,\n         -2.9816e-03, -8.9286e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1470, -0.2165, -0.0349, -0.1625,  0.0831,  0.1229, -0.0110, -0.0979],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.1381, -0.0302, -0.0983,  0.0757,  0.0338, -0.0124, -0.0044,  0.0130,\n          0.2192,  0.2450, -0.1988,  0.1482, -0.1600, -0.0323, -0.1778, -0.0655],\n        [ 0.2256, -0.2443,  0.1188, -0.0448, -0.2077, -0.1774,  0.1792,  0.1065,\n          0.0518, -0.1395, -0.0087,  0.2057, -0.0646, -0.2170, -0.1532, -0.0614],\n        [ 0.1286,  0.0971,  0.0872,  0.1079,  0.0354, -0.0561,  0.1731,  0.2328,\n          0.0564, -0.2413,  0.0877, -0.0992, -0.2155,  0.2160,  0.0542,  0.0176],\n        [-0.1420, -0.2039, -0.2191,  0.0710, -0.0090, -0.0446, -0.1416, -0.0564,\n         -0.0006,  0.0485, -0.1804,  0.2028, -0.1695,  0.1441,  0.2312,  0.0300],\n        [ 0.1560,  0.0390,  0.0976, -0.0861, -0.0152, -0.1539,  0.0256,  0.0814,\n          0.1952,  0.0457,  0.1010, -0.1098, -0.1883, -0.0886,  0.0677, -0.0587],\n        [-0.2500,  0.1787, -0.0610,  0.0214, -0.2123, -0.0177,  0.1281,  0.1140,\n          0.0104, -0.0986,  0.1240,  0.0462,  0.1159,  0.1662, -0.0723, -0.2067],\n        [-0.2399, -0.0091, -0.1966, -0.0611,  0.2230,  0.2107,  0.1522, -0.1608,\n          0.1296, -0.1317, -0.1565, -0.1694, -0.2198, -0.0030, -0.0431,  0.1862],\n        [ 0.1247, -0.1961, -0.1823, -0.0978, -0.2276, -0.2119,  0.2404, -0.0333,\n         -0.1066, -0.1248,  0.0298, -0.2135, -0.0515,  0.0638,  0.1171,  0.1851]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([0.1781], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.0727, -0.0273, -0.1865, -0.1904,  0.1330, -0.1120, -0.3306,  0.1182]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_frequency":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x10f808df0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s68890000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s68890000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_frequency":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}