{
    "__class__":	"DQN",
    "act_dim":	1,
    "batch_size":	32,
    "buf_size":	50000,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "epsilon":	1.0,
    "epsilon_decay":	0.001,
    "epsilon_min":	0.01,
    "exp_name":	"rl4sys-dqn-info",
    "gamma":	0.95,
    "kernel_dim":	4,
    "kernel_size":	5,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-dqn-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s77770000"
    },
    "q_lr":	0.0005,
    "seed":	77770000,
    "self":	{
        "<algorithms.DQN.DQN.DQN object at 0x149cd8c40>":	{
            "_act_dim":	1,
            "_batch_size":	32,
            "_buf_size":	50000,
            "_epsilon":	1.0,
            "_epsilon_decay":	0.001,
            "_epsilon_min":	0.01,
            "_gamma":	0.95,
            "_kernel_dim":	4,
            "_kernel_size":	5,
            "_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1000, -0.0757, -0.0967, -0.0927,  0.0111,  0.1784, -0.1560,  0.0108,\n         0.2065,  0.0343,  0.1678,  0.0176,  0.1938, -0.1253,  0.0046, -0.0350,\n        -0.1259,  0.0228, -0.2062, -0.1546,  0.2139,  0.1136,  0.1565, -0.0340,\n         0.0672,  0.1528, -0.0131,  0.1613,  0.1440,  0.2097, -0.0495,  0.1632],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0825, -0.2106,  0.1544, -0.0370, -0.0545,  0.0568,  0.1635, -0.0930,\n          0.0326,  0.0419,  0.0223,  0.1904, -0.0440, -0.0759, -0.1685, -0.1180,\n         -0.1310,  0.0209, -0.1771, -0.1025],\n        [-0.1399,  0.0492,  0.1191,  0.1913,  0.1242,  0.0759,  0.1949,  0.0774,\n         -0.0695,  0.0523,  0.2223,  0.1947,  0.2074,  0.0776,  0.1090, -0.0563,\n          0.0546, -0.1137, -0.0220, -0.0216],\n        [-0.1491, -0.2164,  0.0129,  0.2219, -0.1322,  0.0649,  0.1524,  0.0753,\n          0.2169,  0.1504, -0.2160,  0.0896,  0.1142,  0.0840,  0.0461, -0.0307,\n          0.1083, -0.1000, -0.1842, -0.0719],\n        [-0.1716,  0.2062,  0.0807,  0.1578, -0.0593, -0.0716,  0.2219,  0.0812,\n          0.0134,  0.2148, -0.0730,  0.0423,  0.0678, -0.0597, -0.2021,  0.2096,\n          0.0476,  0.1629, -0.0611,  0.1652],\n        [-0.0219, -0.0041,  0.0261, -0.0821,  0.1713,  0.1153, -0.1682, -0.1692,\n          0.1424, -0.0338,  0.1780, -0.0244,  0.0604, -0.0472,  0.2138, -0.0465,\n          0.0566,  0.0261,  0.1673,  0.1173],\n        [-0.0790, -0.0825, -0.0378,  0.0248, -0.1490,  0.0465,  0.1690,  0.0318,\n         -0.1020, -0.0593,  0.1755,  0.0877,  0.2206,  0.1532,  0.0229, -0.0920,\n         -0.1249,  0.0502,  0.1107,  0.2212],\n        [ 0.0133, -0.1486,  0.1612, -0.1516,  0.1805,  0.1843,  0.1790, -0.1891,\n         -0.0572,  0.0646, -0.1899,  0.0088,  0.1773, -0.0320, -0.0038,  0.1267,\n          0.1133, -0.0468,  0.0505, -0.0733],\n        [-0.0902,  0.0777,  0.1244,  0.0042,  0.0468, -0.1965,  0.0975,  0.0166,\n         -0.0522,  0.2011, -0.1146, -0.1384, -0.0580, -0.0850,  0.1123, -0.0678,\n          0.1884, -0.0647, -0.0682,  0.1129],\n        [-0.1026,  0.2215,  0.0335, -0.1163,  0.0666,  0.0137, -0.2008, -0.1755,\n          0.1098, -0.0400,  0.0059, -0.1581,  0.0260,  0.0616, -0.1665, -0.0115,\n          0.0112,  0.1986,  0.0240,  0.0037],\n        [-0.1687, -0.0019, -0.1099,  0.1600,  0.0594, -0.1790,  0.1695, -0.0724,\n          0.0076, -0.0751, -0.1221,  0.0638, -0.1840,  0.0562,  0.1555,  0.0214,\n          0.1317,  0.1046,  0.2052,  0.1504],\n        [-0.0946,  0.1062, -0.1263,  0.0961,  0.0229, -0.1444, -0.1489,  0.0415,\n         -0.1000,  0.1190, -0.0667,  0.1596,  0.0233, -0.1154, -0.1862, -0.0360,\n         -0.0095, -0.1791,  0.1774,  0.2095],\n        [ 0.0086,  0.1331,  0.0762,  0.0836, -0.2133,  0.1899, -0.1912,  0.0815,\n          0.0902, -0.1003,  0.0593,  0.0753,  0.0228,  0.0307,  0.1720,  0.2193,\n          0.0315, -0.2207,  0.0560,  0.1090],\n        [-0.1280,  0.0785,  0.0245,  0.0877,  0.1320, -0.0103,  0.0809, -0.1177,\n          0.1430,  0.1269, -0.0692, -0.0429, -0.0756,  0.1790, -0.0678, -0.1290,\n          0.1531, -0.0116, -0.0435,  0.0367],\n        [-0.0451,  0.0021,  0.2035, -0.0606,  0.2088, -0.1046, -0.0530, -0.0315,\n          0.0545,  0.0479,  0.1870,  0.1474,  0.2124,  0.0773, -0.1718, -0.1327,\n          0.2080, -0.0418, -0.1077, -0.1574],\n        [ 0.2105,  0.0187, -0.0934,  0.1127,  0.1075, -0.1981, -0.0142, -0.2011,\n          0.0178,  0.2161, -0.0368,  0.2211, -0.1122, -0.1446, -0.1596,  0.1241,\n         -0.0754,  0.0361,  0.2021,  0.1268],\n        [-0.0303,  0.0513, -0.1996, -0.0552,  0.0653,  0.1002, -0.1882, -0.1094,\n          0.0452, -0.1787, -0.0234, -0.0872, -0.0342,  0.0681, -0.1772, -0.0432,\n          0.0081, -0.2022, -0.1708,  0.0813],\n        [ 0.1255,  0.0572, -0.1429,  0.1427, -0.0999,  0.2076,  0.0063, -0.1051,\n          0.0023, -0.0535, -0.1203,  0.1221, -0.1480, -0.1503, -0.1838,  0.2109,\n         -0.1014, -0.1524,  0.0533,  0.0894],\n        [ 0.2029, -0.0483, -0.1826, -0.1179,  0.2144,  0.0781, -0.1819,  0.0031,\n          0.2125,  0.1508,  0.2038, -0.1876,  0.2027, -0.0758, -0.0834,  0.1270,\n         -0.0043, -0.2121, -0.1235,  0.0507],\n        [ 0.1268,  0.1204,  0.0839,  0.1746, -0.0631,  0.0602,  0.0797, -0.2004,\n          0.0792, -0.1033, -0.0806,  0.0717,  0.0463, -0.1521, -0.0952,  0.0312,\n         -0.1766, -0.1213,  0.1429, -0.0060],\n        [-0.1745,  0.0172, -0.0919,  0.1101, -0.1775, -0.1542, -0.1039,  0.0252,\n         -0.0275, -0.2207, -0.1134, -0.1235,  0.1394, -0.0805, -0.1888, -0.0114,\n          0.0846, -0.1138, -0.0104,  0.2120],\n        [-0.1663, -0.2054,  0.1843,  0.0124,  0.1655, -0.0711,  0.1636,  0.0985,\n         -0.0119,  0.0627, -0.0301, -0.0474,  0.1923,  0.2057,  0.0023, -0.0516,\n         -0.0759,  0.0836, -0.2035,  0.1391],\n        [-0.1777, -0.1495, -0.0964, -0.2081,  0.1749,  0.0598,  0.1830,  0.0803,\n          0.1134, -0.0860,  0.2167,  0.1983,  0.0022,  0.1446,  0.0007, -0.0258,\n          0.0212, -0.0414, -0.1819,  0.1956],\n        [-0.0014, -0.0768, -0.2190,  0.1995,  0.2222,  0.2079, -0.1935,  0.1195,\n         -0.2121, -0.1353, -0.2159, -0.1528, -0.0586,  0.0158,  0.0429,  0.1266,\n         -0.0491,  0.1035, -0.2075,  0.0383],\n        [ 0.1567, -0.1568, -0.0152,  0.1181,  0.1237,  0.1773,  0.0418,  0.2080,\n         -0.1924, -0.2009,  0.0124, -0.0476,  0.2173, -0.0164, -0.0584, -0.0263,\n          0.0500,  0.0062,  0.1047, -0.1939],\n        [-0.1589, -0.0994, -0.0111,  0.1801, -0.1137, -0.2062,  0.0135, -0.1865,\n         -0.2146,  0.0271, -0.0266,  0.2106, -0.1601,  0.0508,  0.0376,  0.1399,\n          0.1842, -0.1500,  0.0933,  0.2224],\n        [-0.1989,  0.0840, -0.0649,  0.0831, -0.2014, -0.0682, -0.0843, -0.2145,\n         -0.0880, -0.1105,  0.1781, -0.1217, -0.0722, -0.1962,  0.0868,  0.1130,\n         -0.0354, -0.0051, -0.0123,  0.1542],\n        [-0.0052,  0.1377,  0.1563, -0.1079, -0.1133,  0.1892, -0.0100,  0.0746,\n          0.1446,  0.1141,  0.2057,  0.2169, -0.1468, -0.0802,  0.1365,  0.0339,\n          0.2171, -0.0733, -0.1738,  0.1167],\n        [-0.1175, -0.1584,  0.1775,  0.1878, -0.0077, -0.2045, -0.0839,  0.2110,\n         -0.1009, -0.0568,  0.0859,  0.0231, -0.0372,  0.2226,  0.1824, -0.0941,\n          0.1520, -0.1461, -0.1593, -0.0539],\n        [ 0.1877,  0.0015,  0.0448, -0.1516,  0.0032, -0.0718,  0.0281,  0.0422,\n         -0.1198, -0.1961, -0.1517,  0.0083, -0.2052,  0.0049,  0.1438,  0.0593,\n         -0.0697, -0.1725,  0.2132,  0.0079],\n        [-0.0488, -0.0191, -0.1971, -0.0990, -0.1240, -0.1121, -0.0812, -0.1106,\n          0.1600, -0.1544,  0.1890, -0.0145, -0.0257, -0.1890,  0.1276,  0.0928,\n         -0.0416, -0.2109,  0.1404, -0.1278],\n        [-0.0710, -0.0519,  0.1585, -0.1535,  0.1307,  0.0959, -0.1619, -0.1239,\n          0.0561,  0.0028,  0.1224, -0.0674, -0.0594,  0.0342,  0.0400, -0.1986,\n          0.0182,  0.0389,  0.1527, -0.0022],\n        [-0.1529,  0.0584, -0.0958,  0.0372,  0.1101,  0.1598, -0.0354,  0.1663,\n         -0.0208, -0.0439, -0.0842,  0.0341,  0.0458, -0.1476,  0.0080,  0.1026,\n          0.1814,  0.0094, -0.0571,  0.1936]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	true
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0792, -0.1434, -0.0737,  0.1596,  0.0862, -0.1184, -0.0959,  0.1744,\n        -0.1005,  0.0448,  0.0131,  0.1397, -0.0541, -0.0736,  0.0967,  0.0543],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 7.1123e-02, -1.2930e-02, -6.8829e-02,  5.4319e-02, -2.1144e-02,\n          5.7908e-02,  1.4029e-01, -1.0711e-01,  7.8328e-03,  1.4257e-01,\n         -3.4143e-02,  1.2315e-01, -8.5427e-02,  2.3268e-02,  1.3435e-01,\n          2.6922e-02,  9.4113e-02,  9.7471e-02,  1.0297e-02, -1.2108e-01,\n          1.3637e-01, -3.5337e-02,  1.0461e-01,  8.6438e-02, -1.2778e-01,\n         -1.3750e-01, -4.5726e-02,  1.0314e-01, -1.6093e-01,  4.1710e-02,\n          1.4905e-02, -1.2173e-01],\n        [-1.2328e-01,  1.7107e-01, -8.8130e-02, -9.6810e-02, -8.4473e-02,\n         -1.7087e-01,  7.1879e-02, -3.6421e-02, -7.7394e-03, -9.3652e-02,\n         -1.0358e-01,  1.5657e-01,  1.3802e-01, -5.6999e-02, -1.7964e-02,\n          1.6858e-01, -1.7586e-01, -2.0715e-02,  1.2748e-01, -3.7223e-02,\n         -1.3727e-01,  1.2478e-01,  8.6972e-02, -1.3542e-01, -1.6101e-01,\n          6.6426e-02,  3.2055e-02, -4.6385e-02, -9.6225e-02,  1.1717e-01,\n          1.7274e-02,  5.2105e-02],\n        [-8.3072e-03,  3.3035e-02,  3.8006e-02, -2.2528e-02, -3.0174e-02,\n         -3.4895e-02,  1.5882e-01,  1.2571e-01,  1.6975e-01, -1.5940e-01,\n          1.3209e-01,  1.0791e-01,  1.4256e-01,  9.7357e-02,  1.6046e-01,\n          8.4935e-02,  1.6777e-01, -9.4830e-02, -6.6766e-02,  1.0144e-01,\n         -3.4747e-02,  1.1396e-01,  9.0235e-02,  1.5541e-01,  5.8834e-02,\n         -1.4369e-01,  9.3903e-02,  1.2021e-01,  1.7645e-01, -1.6697e-01,\n         -6.9281e-03, -3.9601e-02],\n        [ 1.1915e-01, -2.4877e-02,  6.0534e-03,  2.4372e-03,  3.8453e-02,\n          6.3484e-02,  1.6232e-02, -7.2263e-02, -7.0731e-02,  1.0070e-01,\n         -1.2876e-01,  2.4472e-02, -6.9945e-02,  9.2513e-02,  3.5849e-02,\n          1.5416e-01,  1.4932e-01, -1.3228e-01, -1.5037e-01,  1.2007e-01,\n          1.4756e-01,  1.2572e-01, -1.1073e-02, -7.5755e-02,  1.6889e-01,\n         -3.9388e-02,  8.4418e-02,  1.6867e-01,  1.7072e-01, -1.1357e-01,\n          1.6418e-01, -1.3218e-01],\n        [-7.4091e-02,  4.9064e-02,  7.1515e-02, -7.5576e-02,  1.3516e-01,\n         -2.1096e-02, -1.4323e-01,  1.4846e-01, -3.6778e-02,  8.9814e-03,\n         -4.3213e-02,  1.2309e-01, -1.3101e-01,  1.5407e-01,  6.6059e-02,\n         -4.2439e-02, -1.1828e-01, -8.6537e-02,  1.3579e-01, -1.1444e-01,\n          1.1526e-01,  1.5853e-01,  9.6973e-02,  4.0107e-02, -7.7793e-03,\n          1.3300e-01, -1.2184e-01,  6.0793e-02,  1.7307e-02,  1.3790e-01,\n         -1.8641e-02, -1.1930e-01],\n        [-5.6371e-05, -1.7642e-01,  2.2821e-02, -1.2585e-01, -8.3827e-02,\n         -2.1924e-03,  3.1656e-02,  1.7036e-01,  2.5975e-02,  1.2510e-01,\n         -2.1952e-03, -1.3310e-01,  1.0647e-02,  3.3971e-02, -1.0535e-01,\n         -7.8212e-02, -7.4782e-02, -7.7151e-02, -3.4170e-02,  1.4548e-02,\n          1.3443e-01,  1.6923e-01, -3.9001e-02, -8.9046e-02,  5.2948e-02,\n          1.0388e-01,  1.9140e-02, -3.8304e-02, -1.6604e-01,  6.0334e-02,\n         -1.7306e-01, -1.3521e-01],\n        [ 9.4988e-02,  1.1427e-01, -1.1151e-01, -2.8244e-03, -1.5505e-01,\n         -9.2876e-02, -3.3167e-02, -1.2753e-01,  1.1465e-01, -3.2834e-02,\n         -1.7176e-01, -1.0197e-01, -1.5679e-01,  3.1804e-02,  8.0811e-02,\n         -1.2608e-01, -8.4152e-02,  4.9472e-02,  5.5561e-02,  6.7319e-02,\n         -1.2619e-01,  7.4941e-02, -1.4539e-01,  1.1711e-01, -1.0836e-01,\n         -6.8566e-02, -2.9339e-02,  7.8956e-02,  5.6924e-02, -1.2275e-01,\n          7.2598e-02, -7.6081e-02],\n        [ 1.0902e-01,  1.4867e-01, -1.1016e-01,  2.3218e-02,  9.6696e-02,\n          5.0888e-02, -6.7203e-02, -5.4653e-02, -1.2232e-01,  1.2450e-01,\n          1.2337e-01,  4.8099e-02,  1.3440e-01, -1.1800e-01,  4.6618e-02,\n         -3.7434e-03, -1.4345e-01,  1.0279e-01,  2.2256e-02, -1.2090e-01,\n         -4.7358e-03, -1.6517e-02, -5.0020e-02, -5.1095e-03, -1.3566e-01,\n          4.6330e-02,  1.3128e-01, -3.8384e-02,  2.3096e-02, -1.2190e-01,\n         -1.0849e-01,  9.8522e-02],\n        [-2.1835e-02, -1.3455e-01, -6.6108e-02,  1.6872e-01,  2.8968e-02,\n         -1.3587e-01, -1.5861e-02,  5.1525e-02, -7.9609e-02,  8.4446e-02,\n          1.6268e-01,  1.1653e-01, -1.5453e-01,  1.2810e-01,  6.1938e-02,\n          1.5418e-01, -2.8195e-02,  1.0399e-01,  1.7334e-01, -4.5376e-02,\n          6.3950e-02, -1.2852e-01,  1.4657e-01,  1.1329e-01,  3.0335e-02,\n         -6.5736e-02, -1.6527e-01, -1.4642e-01,  7.9876e-02, -1.4133e-01,\n          9.9169e-02,  9.9624e-02],\n        [-6.7254e-02,  1.3773e-02,  5.0711e-02, -2.1762e-02,  2.1151e-02,\n         -1.6087e-01,  2.8925e-02, -1.6338e-01,  1.5693e-01,  1.4601e-01,\n          1.3668e-01,  7.0956e-02,  5.7075e-02,  1.5589e-01, -1.1456e-01,\n         -1.1403e-01,  5.6087e-02,  8.6720e-02, -1.3386e-01, -1.8087e-02,\n          1.6208e-01, -6.8784e-02, -8.6947e-02,  6.3881e-02, -1.5129e-01,\n         -1.4464e-01,  5.6837e-02,  5.9924e-02,  4.7939e-03,  1.4687e-01,\n         -1.6229e-01,  4.7134e-02],\n        [-3.6921e-02,  7.9922e-02, -6.7306e-02,  1.6324e-01, -2.8956e-02,\n         -1.0480e-02, -1.7001e-01, -5.2595e-02, -6.4600e-03,  5.1813e-02,\n          8.0814e-03, -1.3076e-01, -8.1497e-02, -1.2941e-02,  2.5288e-03,\n          1.1650e-01, -1.0615e-01,  1.2454e-01, -9.7116e-02, -4.9048e-02,\n          1.0712e-01,  1.5655e-01,  1.2484e-01, -1.3697e-01,  1.6637e-01,\n          1.4830e-01,  1.7228e-01,  7.0801e-02,  7.8408e-02,  1.2880e-01,\n          1.1523e-01, -2.5409e-02],\n        [-1.0418e-01,  5.5226e-02, -1.5149e-01, -1.4091e-01, -9.0921e-02,\n         -7.2105e-02,  1.4942e-01, -4.7257e-02, -4.1239e-03,  1.5958e-01,\n          1.8800e-02, -4.4841e-02,  1.1812e-01, -1.3044e-01, -1.6932e-01,\n         -1.2551e-01,  1.2537e-02,  1.2367e-01,  7.7835e-02,  5.6758e-02,\n         -3.1506e-02,  1.7669e-01,  1.0071e-01, -8.7675e-02,  8.3900e-02,\n          4.0416e-02,  3.2859e-03,  1.1403e-02, -9.0393e-02,  1.2012e-01,\n         -1.3159e-02, -8.5012e-02],\n        [-1.0738e-01, -1.7072e-01, -1.2300e-01,  9.9705e-02, -1.6285e-01,\n         -1.5742e-01,  1.0996e-01, -9.8963e-02,  1.9693e-03,  6.6734e-02,\n         -1.0053e-01,  7.6996e-02,  3.3208e-03,  5.7760e-02, -1.3539e-01,\n          3.8056e-02,  1.4051e-01, -1.2034e-01,  1.2789e-01,  1.4220e-01,\n          3.8845e-02,  1.2524e-01,  1.9345e-04, -3.9071e-02, -4.2329e-02,\n         -4.9801e-02,  6.4259e-02,  9.0467e-02, -9.5724e-02,  2.1435e-02,\n         -7.9176e-02, -1.1329e-01],\n        [-1.3486e-01,  1.0828e-01, -6.5432e-02,  1.4571e-01,  1.1055e-01,\n         -1.2931e-01,  9.7901e-02, -1.6021e-01, -1.1700e-01,  1.0438e-01,\n         -1.1891e-01, -1.3434e-01,  1.1648e-01,  1.1593e-01,  3.6742e-02,\n         -4.2722e-02, -9.5574e-02, -1.1106e-01, -9.2139e-02, -2.8043e-02,\n         -1.6544e-01, -1.0824e-01,  1.4954e-01,  6.7357e-03, -1.2713e-01,\n         -3.3341e-02, -2.2243e-02, -3.7818e-02, -3.7927e-03, -9.8433e-02,\n         -2.7308e-02, -1.4640e-01],\n        [ 1.6143e-01, -1.4434e-01,  6.4805e-02,  6.5413e-03, -8.5030e-02,\n          1.1107e-01, -9.8786e-02, -9.3075e-02,  3.2812e-02, -1.4847e-01,\n          1.6433e-01,  7.5189e-02, -8.8849e-02,  1.5940e-01,  1.6354e-01,\n         -8.0950e-02,  2.5040e-02,  1.4234e-01,  5.1223e-03,  1.3997e-01,\n          8.4420e-02,  3.0350e-02, -8.2410e-02, -4.5476e-02, -1.5389e-01,\n          4.9630e-02,  8.5404e-02,  7.7788e-02, -7.9953e-02,  8.3437e-02,\n         -6.8866e-02, -1.0954e-01],\n        [-4.9806e-02, -9.2441e-02,  1.3024e-01,  1.5733e-01,  4.4242e-02,\n         -5.9268e-02,  4.3253e-02, -1.7087e-01,  3.0631e-02, -1.1044e-01,\n         -1.6620e-01,  1.4735e-01, -1.0530e-01, -1.6400e-01,  1.0254e-01,\n         -8.4601e-02, -2.0405e-02,  1.3565e-01, -1.4761e-01, -4.9437e-02,\n         -1.4827e-01, -1.6185e-01,  7.4288e-02,  2.6587e-03,  6.6654e-02,\n         -9.6044e-02,  1.1765e-01, -1.5589e-01,  1.7379e-01, -2.9837e-02,\n          1.3200e-01,  2.4771e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	true
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1446,  0.0780, -0.2117,  0.1776,  0.0052, -0.0861,  0.1730, -0.2060],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2328,  0.0355, -0.1000, -0.1117,  0.0604,  0.1749,  0.1165, -0.0481,\n         -0.0915, -0.0225,  0.2309, -0.2339,  0.0549,  0.1291, -0.0356,  0.1984],\n        [-0.0697,  0.0625,  0.1759,  0.2114, -0.0887,  0.1989, -0.1670, -0.0915,\n         -0.2171,  0.0450, -0.0344,  0.2461,  0.2282, -0.1143,  0.1108,  0.2456],\n        [-0.0119, -0.2035, -0.2193, -0.1615,  0.0015,  0.2026,  0.1291, -0.1584,\n         -0.0262, -0.1315,  0.1854, -0.1751, -0.1854, -0.2368, -0.1982,  0.0941],\n        [ 0.1212, -0.1506, -0.1262,  0.1221,  0.0711,  0.2467, -0.0560,  0.0952,\n         -0.2360, -0.0150, -0.1078, -0.0636, -0.0990,  0.2000, -0.1840, -0.2218],\n        [ 0.2066,  0.1369, -0.2289, -0.0796, -0.1475,  0.0555, -0.0804,  0.0692,\n          0.2225, -0.1383,  0.1795,  0.2328,  0.2473,  0.1910,  0.1133,  0.0523],\n        [-0.1930,  0.0805,  0.1531, -0.1215,  0.1077, -0.1572,  0.0447, -0.0685,\n          0.0048, -0.2240, -0.0203,  0.1325,  0.0271,  0.1084,  0.0469,  0.0578],\n        [ 0.2466,  0.2357, -0.1327, -0.1809,  0.0423,  0.0150,  0.1076,  0.2194,\n          0.0552,  0.1919, -0.2477,  0.0991,  0.2376, -0.2364,  0.0275, -0.1864],\n        [-0.0033,  0.2157,  0.1181,  0.0674, -0.2186,  0.2277, -0.1431, -0.2445,\n         -0.2326,  0.1662, -0.0023, -0.1030, -0.2386, -0.1496,  0.1523,  0.1117]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	true
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	true
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1752], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2703, -0.0526, -0.2864,  0.1638, -0.1363,  0.2052, -0.0261, -0.1004]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	true
                }
            },
            "_num_round":	0,
            "_q_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0005\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0005,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0005,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0825, -0.2106,  0.1544, -0.0370, -0.0545,  0.0568,  0.1635, -0.0930,\n          0.0326,  0.0419,  0.0223,  0.1904, -0.0440, -0.0759, -0.1685, -0.1180,\n         -0.1310,  0.0209, -0.1771, -0.1025],\n        [-0.1399,  0.0492,  0.1191,  0.1913,  0.1242,  0.0759,  0.1949,  0.0774,\n         -0.0695,  0.0523,  0.2223,  0.1947,  0.2074,  0.0776,  0.1090, -0.0563,\n          0.0546, -0.1137, -0.0220, -0.0216],\n        [-0.1491, -0.2164,  0.0129,  0.2219, -0.1322,  0.0649,  0.1524,  0.0753,\n          0.2169,  0.1504, -0.2160,  0.0896,  0.1142,  0.0840,  0.0461, -0.0307,\n          0.1083, -0.1000, -0.1842, -0.0719],\n        [-0.1716,  0.2062,  0.0807,  0.1578, -0.0593, -0.0716,  0.2219,  0.0812,\n          0.0134,  0.2148, -0.0730,  0.0423,  0.0678, -0.0597, -0.2021,  0.2096,\n          0.0476,  0.1629, -0.0611,  0.1652],\n        [-0.0219, -0.0041,  0.0261, -0.0821,  0.1713,  0.1153, -0.1682, -0.1692,\n          0.1424, -0.0338,  0.1780, -0.0244,  0.0604, -0.0472,  0.2138, -0.0465,\n          0.0566,  0.0261,  0.1673,  0.1173],\n        [-0.0790, -0.0825, -0.0378,  0.0248, -0.1490,  0.0465,  0.1690,  0.0318,\n         -0.1020, -0.0593,  0.1755,  0.0877,  0.2206,  0.1532,  0.0229, -0.0920,\n         -0.1249,  0.0502,  0.1107,  0.2212],\n        [ 0.0133, -0.1486,  0.1612, -0.1516,  0.1805,  0.1843,  0.1790, -0.1891,\n         -0.0572,  0.0646, -0.1899,  0.0088,  0.1773, -0.0320, -0.0038,  0.1267,\n          0.1133, -0.0468,  0.0505, -0.0733],\n        [-0.0902,  0.0777,  0.1244,  0.0042,  0.0468, -0.1965,  0.0975,  0.0166,\n         -0.0522,  0.2011, -0.1146, -0.1384, -0.0580, -0.0850,  0.1123, -0.0678,\n          0.1884, -0.0647, -0.0682,  0.1129],\n        [-0.1026,  0.2215,  0.0335, -0.1163,  0.0666,  0.0137, -0.2008, -0.1755,\n          0.1098, -0.0400,  0.0059, -0.1581,  0.0260,  0.0616, -0.1665, -0.0115,\n          0.0112,  0.1986,  0.0240,  0.0037],\n        [-0.1687, -0.0019, -0.1099,  0.1600,  0.0594, -0.1790,  0.1695, -0.0724,\n          0.0076, -0.0751, -0.1221,  0.0638, -0.1840,  0.0562,  0.1555,  0.0214,\n          0.1317,  0.1046,  0.2052,  0.1504],\n        [-0.0946,  0.1062, -0.1263,  0.0961,  0.0229, -0.1444, -0.1489,  0.0415,\n         -0.1000,  0.1190, -0.0667,  0.1596,  0.0233, -0.1154, -0.1862, -0.0360,\n         -0.0095, -0.1791,  0.1774,  0.2095],\n        [ 0.0086,  0.1331,  0.0762,  0.0836, -0.2133,  0.1899, -0.1912,  0.0815,\n          0.0902, -0.1003,  0.0593,  0.0753,  0.0228,  0.0307,  0.1720,  0.2193,\n          0.0315, -0.2207,  0.0560,  0.1090],\n        [-0.1280,  0.0785,  0.0245,  0.0877,  0.1320, -0.0103,  0.0809, -0.1177,\n          0.1430,  0.1269, -0.0692, -0.0429, -0.0756,  0.1790, -0.0678, -0.1290,\n          0.1531, -0.0116, -0.0435,  0.0367],\n        [-0.0451,  0.0021,  0.2035, -0.0606,  0.2088, -0.1046, -0.0530, -0.0315,\n          0.0545,  0.0479,  0.1870,  0.1474,  0.2124,  0.0773, -0.1718, -0.1327,\n          0.2080, -0.0418, -0.1077, -0.1574],\n        [ 0.2105,  0.0187, -0.0934,  0.1127,  0.1075, -0.1981, -0.0142, -0.2011,\n          0.0178,  0.2161, -0.0368,  0.2211, -0.1122, -0.1446, -0.1596,  0.1241,\n         -0.0754,  0.0361,  0.2021,  0.1268],\n        [-0.0303,  0.0513, -0.1996, -0.0552,  0.0653,  0.1002, -0.1882, -0.1094,\n          0.0452, -0.1787, -0.0234, -0.0872, -0.0342,  0.0681, -0.1772, -0.0432,\n          0.0081, -0.2022, -0.1708,  0.0813],\n        [ 0.1255,  0.0572, -0.1429,  0.1427, -0.0999,  0.2076,  0.0063, -0.1051,\n          0.0023, -0.0535, -0.1203,  0.1221, -0.1480, -0.1503, -0.1838,  0.2109,\n         -0.1014, -0.1524,  0.0533,  0.0894],\n        [ 0.2029, -0.0483, -0.1826, -0.1179,  0.2144,  0.0781, -0.1819,  0.0031,\n          0.2125,  0.1508,  0.2038, -0.1876,  0.2027, -0.0758, -0.0834,  0.1270,\n         -0.0043, -0.2121, -0.1235,  0.0507],\n        [ 0.1268,  0.1204,  0.0839,  0.1746, -0.0631,  0.0602,  0.0797, -0.2004,\n          0.0792, -0.1033, -0.0806,  0.0717,  0.0463, -0.1521, -0.0952,  0.0312,\n         -0.1766, -0.1213,  0.1429, -0.0060],\n        [-0.1745,  0.0172, -0.0919,  0.1101, -0.1775, -0.1542, -0.1039,  0.0252,\n         -0.0275, -0.2207, -0.1134, -0.1235,  0.1394, -0.0805, -0.1888, -0.0114,\n          0.0846, -0.1138, -0.0104,  0.2120],\n        [-0.1663, -0.2054,  0.1843,  0.0124,  0.1655, -0.0711,  0.1636,  0.0985,\n         -0.0119,  0.0627, -0.0301, -0.0474,  0.1923,  0.2057,  0.0023, -0.0516,\n         -0.0759,  0.0836, -0.2035,  0.1391],\n        [-0.1777, -0.1495, -0.0964, -0.2081,  0.1749,  0.0598,  0.1830,  0.0803,\n          0.1134, -0.0860,  0.2167,  0.1983,  0.0022,  0.1446,  0.0007, -0.0258,\n          0.0212, -0.0414, -0.1819,  0.1956],\n        [-0.0014, -0.0768, -0.2190,  0.1995,  0.2222,  0.2079, -0.1935,  0.1195,\n         -0.2121, -0.1353, -0.2159, -0.1528, -0.0586,  0.0158,  0.0429,  0.1266,\n         -0.0491,  0.1035, -0.2075,  0.0383],\n        [ 0.1567, -0.1568, -0.0152,  0.1181,  0.1237,  0.1773,  0.0418,  0.2080,\n         -0.1924, -0.2009,  0.0124, -0.0476,  0.2173, -0.0164, -0.0584, -0.0263,\n          0.0500,  0.0062,  0.1047, -0.1939],\n        [-0.1589, -0.0994, -0.0111,  0.1801, -0.1137, -0.2062,  0.0135, -0.1865,\n         -0.2146,  0.0271, -0.0266,  0.2106, -0.1601,  0.0508,  0.0376,  0.1399,\n          0.1842, -0.1500,  0.0933,  0.2224],\n        [-0.1989,  0.0840, -0.0649,  0.0831, -0.2014, -0.0682, -0.0843, -0.2145,\n         -0.0880, -0.1105,  0.1781, -0.1217, -0.0722, -0.1962,  0.0868,  0.1130,\n         -0.0354, -0.0051, -0.0123,  0.1542],\n        [-0.0052,  0.1377,  0.1563, -0.1079, -0.1133,  0.1892, -0.0100,  0.0746,\n          0.1446,  0.1141,  0.2057,  0.2169, -0.1468, -0.0802,  0.1365,  0.0339,\n          0.2171, -0.0733, -0.1738,  0.1167],\n        [-0.1175, -0.1584,  0.1775,  0.1878, -0.0077, -0.2045, -0.0839,  0.2110,\n         -0.1009, -0.0568,  0.0859,  0.0231, -0.0372,  0.2226,  0.1824, -0.0941,\n          0.1520, -0.1461, -0.1593, -0.0539],\n        [ 0.1877,  0.0015,  0.0448, -0.1516,  0.0032, -0.0718,  0.0281,  0.0422,\n         -0.1198, -0.1961, -0.1517,  0.0083, -0.2052,  0.0049,  0.1438,  0.0593,\n         -0.0697, -0.1725,  0.2132,  0.0079],\n        [-0.0488, -0.0191, -0.1971, -0.0990, -0.1240, -0.1121, -0.0812, -0.1106,\n          0.1600, -0.1544,  0.1890, -0.0145, -0.0257, -0.1890,  0.1276,  0.0928,\n         -0.0416, -0.2109,  0.1404, -0.1278],\n        [-0.0710, -0.0519,  0.1585, -0.1535,  0.1307,  0.0959, -0.1619, -0.1239,\n          0.0561,  0.0028,  0.1224, -0.0674, -0.0594,  0.0342,  0.0400, -0.1986,\n          0.0182,  0.0389,  0.1527, -0.0022],\n        [-0.1529,  0.0584, -0.0958,  0.0372,  0.1101,  0.1598, -0.0354,  0.1663,\n         -0.0208, -0.0439, -0.0842,  0.0341,  0.0458, -0.1476,  0.0080,  0.1026,\n          0.1814,  0.0094, -0.0571,  0.1936]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1000, -0.0757, -0.0967, -0.0927,  0.0111,  0.1784, -0.1560,  0.0108,\n         0.2065,  0.0343,  0.1678,  0.0176,  0.1938, -0.1253,  0.0046, -0.0350,\n        -0.1259,  0.0228, -0.2062, -0.1546,  0.2139,  0.1136,  0.1565, -0.0340,\n         0.0672,  0.1528, -0.0131,  0.1613,  0.1440,  0.2097, -0.0495,  0.1632],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 7.1123e-02, -1.2930e-02, -6.8829e-02,  5.4319e-02, -2.1144e-02,\n          5.7908e-02,  1.4029e-01, -1.0711e-01,  7.8328e-03,  1.4257e-01,\n         -3.4143e-02,  1.2315e-01, -8.5427e-02,  2.3268e-02,  1.3435e-01,\n          2.6922e-02,  9.4113e-02,  9.7471e-02,  1.0297e-02, -1.2108e-01,\n          1.3637e-01, -3.5337e-02,  1.0461e-01,  8.6438e-02, -1.2778e-01,\n         -1.3750e-01, -4.5726e-02,  1.0314e-01, -1.6093e-01,  4.1710e-02,\n          1.4905e-02, -1.2173e-01],\n        [-1.2328e-01,  1.7107e-01, -8.8130e-02, -9.6810e-02, -8.4473e-02,\n         -1.7087e-01,  7.1879e-02, -3.6421e-02, -7.7394e-03, -9.3652e-02,\n         -1.0358e-01,  1.5657e-01,  1.3802e-01, -5.6999e-02, -1.7964e-02,\n          1.6858e-01, -1.7586e-01, -2.0715e-02,  1.2748e-01, -3.7223e-02,\n         -1.3727e-01,  1.2478e-01,  8.6972e-02, -1.3542e-01, -1.6101e-01,\n          6.6426e-02,  3.2055e-02, -4.6385e-02, -9.6225e-02,  1.1717e-01,\n          1.7274e-02,  5.2105e-02],\n        [-8.3072e-03,  3.3035e-02,  3.8006e-02, -2.2528e-02, -3.0174e-02,\n         -3.4895e-02,  1.5882e-01,  1.2571e-01,  1.6975e-01, -1.5940e-01,\n          1.3209e-01,  1.0791e-01,  1.4256e-01,  9.7357e-02,  1.6046e-01,\n          8.4935e-02,  1.6777e-01, -9.4830e-02, -6.6766e-02,  1.0144e-01,\n         -3.4747e-02,  1.1396e-01,  9.0235e-02,  1.5541e-01,  5.8834e-02,\n         -1.4369e-01,  9.3903e-02,  1.2021e-01,  1.7645e-01, -1.6697e-01,\n         -6.9281e-03, -3.9601e-02],\n        [ 1.1915e-01, -2.4877e-02,  6.0534e-03,  2.4372e-03,  3.8453e-02,\n          6.3484e-02,  1.6232e-02, -7.2263e-02, -7.0731e-02,  1.0070e-01,\n         -1.2876e-01,  2.4472e-02, -6.9945e-02,  9.2513e-02,  3.5849e-02,\n          1.5416e-01,  1.4932e-01, -1.3228e-01, -1.5037e-01,  1.2007e-01,\n          1.4756e-01,  1.2572e-01, -1.1073e-02, -7.5755e-02,  1.6889e-01,\n         -3.9388e-02,  8.4418e-02,  1.6867e-01,  1.7072e-01, -1.1357e-01,\n          1.6418e-01, -1.3218e-01],\n        [-7.4091e-02,  4.9064e-02,  7.1515e-02, -7.5576e-02,  1.3516e-01,\n         -2.1096e-02, -1.4323e-01,  1.4846e-01, -3.6778e-02,  8.9814e-03,\n         -4.3213e-02,  1.2309e-01, -1.3101e-01,  1.5407e-01,  6.6059e-02,\n         -4.2439e-02, -1.1828e-01, -8.6537e-02,  1.3579e-01, -1.1444e-01,\n          1.1526e-01,  1.5853e-01,  9.6973e-02,  4.0107e-02, -7.7793e-03,\n          1.3300e-01, -1.2184e-01,  6.0793e-02,  1.7307e-02,  1.3790e-01,\n         -1.8641e-02, -1.1930e-01],\n        [-5.6371e-05, -1.7642e-01,  2.2821e-02, -1.2585e-01, -8.3827e-02,\n         -2.1924e-03,  3.1656e-02,  1.7036e-01,  2.5975e-02,  1.2510e-01,\n         -2.1952e-03, -1.3310e-01,  1.0647e-02,  3.3971e-02, -1.0535e-01,\n         -7.8212e-02, -7.4782e-02, -7.7151e-02, -3.4170e-02,  1.4548e-02,\n          1.3443e-01,  1.6923e-01, -3.9001e-02, -8.9046e-02,  5.2948e-02,\n          1.0388e-01,  1.9140e-02, -3.8304e-02, -1.6604e-01,  6.0334e-02,\n         -1.7306e-01, -1.3521e-01],\n        [ 9.4988e-02,  1.1427e-01, -1.1151e-01, -2.8244e-03, -1.5505e-01,\n         -9.2876e-02, -3.3167e-02, -1.2753e-01,  1.1465e-01, -3.2834e-02,\n         -1.7176e-01, -1.0197e-01, -1.5679e-01,  3.1804e-02,  8.0811e-02,\n         -1.2608e-01, -8.4152e-02,  4.9472e-02,  5.5561e-02,  6.7319e-02,\n         -1.2619e-01,  7.4941e-02, -1.4539e-01,  1.1711e-01, -1.0836e-01,\n         -6.8566e-02, -2.9339e-02,  7.8956e-02,  5.6924e-02, -1.2275e-01,\n          7.2598e-02, -7.6081e-02],\n        [ 1.0902e-01,  1.4867e-01, -1.1016e-01,  2.3218e-02,  9.6696e-02,\n          5.0888e-02, -6.7203e-02, -5.4653e-02, -1.2232e-01,  1.2450e-01,\n          1.2337e-01,  4.8099e-02,  1.3440e-01, -1.1800e-01,  4.6618e-02,\n         -3.7434e-03, -1.4345e-01,  1.0279e-01,  2.2256e-02, -1.2090e-01,\n         -4.7358e-03, -1.6517e-02, -5.0020e-02, -5.1095e-03, -1.3566e-01,\n          4.6330e-02,  1.3128e-01, -3.8384e-02,  2.3096e-02, -1.2190e-01,\n         -1.0849e-01,  9.8522e-02],\n        [-2.1835e-02, -1.3455e-01, -6.6108e-02,  1.6872e-01,  2.8968e-02,\n         -1.3587e-01, -1.5861e-02,  5.1525e-02, -7.9609e-02,  8.4446e-02,\n          1.6268e-01,  1.1653e-01, -1.5453e-01,  1.2810e-01,  6.1938e-02,\n          1.5418e-01, -2.8195e-02,  1.0399e-01,  1.7334e-01, -4.5376e-02,\n          6.3950e-02, -1.2852e-01,  1.4657e-01,  1.1329e-01,  3.0335e-02,\n         -6.5736e-02, -1.6527e-01, -1.4642e-01,  7.9876e-02, -1.4133e-01,\n          9.9169e-02,  9.9624e-02],\n        [-6.7254e-02,  1.3773e-02,  5.0711e-02, -2.1762e-02,  2.1151e-02,\n         -1.6087e-01,  2.8925e-02, -1.6338e-01,  1.5693e-01,  1.4601e-01,\n          1.3668e-01,  7.0956e-02,  5.7075e-02,  1.5589e-01, -1.1456e-01,\n         -1.1403e-01,  5.6087e-02,  8.6720e-02, -1.3386e-01, -1.8087e-02,\n          1.6208e-01, -6.8784e-02, -8.6947e-02,  6.3881e-02, -1.5129e-01,\n         -1.4464e-01,  5.6837e-02,  5.9924e-02,  4.7939e-03,  1.4687e-01,\n         -1.6229e-01,  4.7134e-02],\n        [-3.6921e-02,  7.9922e-02, -6.7306e-02,  1.6324e-01, -2.8956e-02,\n         -1.0480e-02, -1.7001e-01, -5.2595e-02, -6.4600e-03,  5.1813e-02,\n          8.0814e-03, -1.3076e-01, -8.1497e-02, -1.2941e-02,  2.5288e-03,\n          1.1650e-01, -1.0615e-01,  1.2454e-01, -9.7116e-02, -4.9048e-02,\n          1.0712e-01,  1.5655e-01,  1.2484e-01, -1.3697e-01,  1.6637e-01,\n          1.4830e-01,  1.7228e-01,  7.0801e-02,  7.8408e-02,  1.2880e-01,\n          1.1523e-01, -2.5409e-02],\n        [-1.0418e-01,  5.5226e-02, -1.5149e-01, -1.4091e-01, -9.0921e-02,\n         -7.2105e-02,  1.4942e-01, -4.7257e-02, -4.1239e-03,  1.5958e-01,\n          1.8800e-02, -4.4841e-02,  1.1812e-01, -1.3044e-01, -1.6932e-01,\n         -1.2551e-01,  1.2537e-02,  1.2367e-01,  7.7835e-02,  5.6758e-02,\n         -3.1506e-02,  1.7669e-01,  1.0071e-01, -8.7675e-02,  8.3900e-02,\n          4.0416e-02,  3.2859e-03,  1.1403e-02, -9.0393e-02,  1.2012e-01,\n         -1.3159e-02, -8.5012e-02],\n        [-1.0738e-01, -1.7072e-01, -1.2300e-01,  9.9705e-02, -1.6285e-01,\n         -1.5742e-01,  1.0996e-01, -9.8963e-02,  1.9693e-03,  6.6734e-02,\n         -1.0053e-01,  7.6996e-02,  3.3208e-03,  5.7760e-02, -1.3539e-01,\n          3.8056e-02,  1.4051e-01, -1.2034e-01,  1.2789e-01,  1.4220e-01,\n          3.8845e-02,  1.2524e-01,  1.9345e-04, -3.9071e-02, -4.2329e-02,\n         -4.9801e-02,  6.4259e-02,  9.0467e-02, -9.5724e-02,  2.1435e-02,\n         -7.9176e-02, -1.1329e-01],\n        [-1.3486e-01,  1.0828e-01, -6.5432e-02,  1.4571e-01,  1.1055e-01,\n         -1.2931e-01,  9.7901e-02, -1.6021e-01, -1.1700e-01,  1.0438e-01,\n         -1.1891e-01, -1.3434e-01,  1.1648e-01,  1.1593e-01,  3.6742e-02,\n         -4.2722e-02, -9.5574e-02, -1.1106e-01, -9.2139e-02, -2.8043e-02,\n         -1.6544e-01, -1.0824e-01,  1.4954e-01,  6.7357e-03, -1.2713e-01,\n         -3.3341e-02, -2.2243e-02, -3.7818e-02, -3.7927e-03, -9.8433e-02,\n         -2.7308e-02, -1.4640e-01],\n        [ 1.6143e-01, -1.4434e-01,  6.4805e-02,  6.5413e-03, -8.5030e-02,\n          1.1107e-01, -9.8786e-02, -9.3075e-02,  3.2812e-02, -1.4847e-01,\n          1.6433e-01,  7.5189e-02, -8.8849e-02,  1.5940e-01,  1.6354e-01,\n         -8.0950e-02,  2.5040e-02,  1.4234e-01,  5.1223e-03,  1.3997e-01,\n          8.4420e-02,  3.0350e-02, -8.2410e-02, -4.5476e-02, -1.5389e-01,\n          4.9630e-02,  8.5404e-02,  7.7788e-02, -7.9953e-02,  8.3437e-02,\n         -6.8866e-02, -1.0954e-01],\n        [-4.9806e-02, -9.2441e-02,  1.3024e-01,  1.5733e-01,  4.4242e-02,\n         -5.9268e-02,  4.3253e-02, -1.7087e-01,  3.0631e-02, -1.1044e-01,\n         -1.6620e-01,  1.4735e-01, -1.0530e-01, -1.6400e-01,  1.0254e-01,\n         -8.4601e-02, -2.0405e-02,  1.3565e-01, -1.4761e-01, -4.9437e-02,\n         -1.4827e-01, -1.6185e-01,  7.4288e-02,  2.6587e-03,  6.6654e-02,\n         -9.6044e-02,  1.1765e-01, -1.5589e-01,  1.7379e-01, -2.9837e-02,\n          1.3200e-01,  2.4771e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0792, -0.1434, -0.0737,  0.1596,  0.0862, -0.1184, -0.0959,  0.1744,\n        -0.1005,  0.0448,  0.0131,  0.1397, -0.0541, -0.0736,  0.0967,  0.0543],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2328,  0.0355, -0.1000, -0.1117,  0.0604,  0.1749,  0.1165, -0.0481,\n         -0.0915, -0.0225,  0.2309, -0.2339,  0.0549,  0.1291, -0.0356,  0.1984],\n        [-0.0697,  0.0625,  0.1759,  0.2114, -0.0887,  0.1989, -0.1670, -0.0915,\n         -0.2171,  0.0450, -0.0344,  0.2461,  0.2282, -0.1143,  0.1108,  0.2456],\n        [-0.0119, -0.2035, -0.2193, -0.1615,  0.0015,  0.2026,  0.1291, -0.1584,\n         -0.0262, -0.1315,  0.1854, -0.1751, -0.1854, -0.2368, -0.1982,  0.0941],\n        [ 0.1212, -0.1506, -0.1262,  0.1221,  0.0711,  0.2467, -0.0560,  0.0952,\n         -0.2360, -0.0150, -0.1078, -0.0636, -0.0990,  0.2000, -0.1840, -0.2218],\n        [ 0.2066,  0.1369, -0.2289, -0.0796, -0.1475,  0.0555, -0.0804,  0.0692,\n          0.2225, -0.1383,  0.1795,  0.2328,  0.2473,  0.1910,  0.1133,  0.0523],\n        [-0.1930,  0.0805,  0.1531, -0.1215,  0.1077, -0.1572,  0.0447, -0.0685,\n          0.0048, -0.2240, -0.0203,  0.1325,  0.0271,  0.1084,  0.0469,  0.0578],\n        [ 0.2466,  0.2357, -0.1327, -0.1809,  0.0423,  0.0150,  0.1076,  0.2194,\n          0.0552,  0.1919, -0.2477,  0.0991,  0.2376, -0.2364,  0.0275, -0.1864],\n        [-0.0033,  0.2157,  0.1181,  0.0674, -0.2186,  0.2277, -0.1431, -0.2445,\n         -0.2326,  0.1662, -0.0023, -0.1030, -0.2386, -0.1496,  0.1523,  0.1117]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1446,  0.0780, -0.2117,  0.1776,  0.0052, -0.0861,  0.1730, -0.2060],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2703, -0.0526, -0.2864,  0.1638, -0.1363,  0.2052, -0.0261, -0.1004]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1752], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.DQN.replay_buffer.ReplayBuffer object at 0x117e12290>":	{
                    "act_buf":	"[0 0 0 ... 0 0 0]",
                    "capacity":	50000,
                    "epsilon":	1.0,
                    "gamma":	0.95,
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "next_obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "q_val_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_model":	{
                "DeepQNetwork(\n  (q_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_epsilon":	1.0,
                    "_epsilon_decay":	0.001,
                    "_epsilon_min":	0.01,
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "q_network":	{
                            "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "0":	{
                                        "Linear(in_features=20, out_features=32, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1000, -0.0757, -0.0967, -0.0927,  0.0111,  0.1784, -0.1560,  0.0108,\n         0.2065,  0.0343,  0.1678,  0.0176,  0.1938, -0.1253,  0.0046, -0.0350,\n        -0.1259,  0.0228, -0.2062, -0.1546,  0.2139,  0.1136,  0.1565, -0.0340,\n         0.0672,  0.1528, -0.0131,  0.1613,  0.1440,  0.2097, -0.0495,  0.1632],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.0825, -0.2106,  0.1544, -0.0370, -0.0545,  0.0568,  0.1635, -0.0930,\n          0.0326,  0.0419,  0.0223,  0.1904, -0.0440, -0.0759, -0.1685, -0.1180,\n         -0.1310,  0.0209, -0.1771, -0.1025],\n        [-0.1399,  0.0492,  0.1191,  0.1913,  0.1242,  0.0759,  0.1949,  0.0774,\n         -0.0695,  0.0523,  0.2223,  0.1947,  0.2074,  0.0776,  0.1090, -0.0563,\n          0.0546, -0.1137, -0.0220, -0.0216],\n        [-0.1491, -0.2164,  0.0129,  0.2219, -0.1322,  0.0649,  0.1524,  0.0753,\n          0.2169,  0.1504, -0.2160,  0.0896,  0.1142,  0.0840,  0.0461, -0.0307,\n          0.1083, -0.1000, -0.1842, -0.0719],\n        [-0.1716,  0.2062,  0.0807,  0.1578, -0.0593, -0.0716,  0.2219,  0.0812,\n          0.0134,  0.2148, -0.0730,  0.0423,  0.0678, -0.0597, -0.2021,  0.2096,\n          0.0476,  0.1629, -0.0611,  0.1652],\n        [-0.0219, -0.0041,  0.0261, -0.0821,  0.1713,  0.1153, -0.1682, -0.1692,\n          0.1424, -0.0338,  0.1780, -0.0244,  0.0604, -0.0472,  0.2138, -0.0465,\n          0.0566,  0.0261,  0.1673,  0.1173],\n        [-0.0790, -0.0825, -0.0378,  0.0248, -0.1490,  0.0465,  0.1690,  0.0318,\n         -0.1020, -0.0593,  0.1755,  0.0877,  0.2206,  0.1532,  0.0229, -0.0920,\n         -0.1249,  0.0502,  0.1107,  0.2212],\n        [ 0.0133, -0.1486,  0.1612, -0.1516,  0.1805,  0.1843,  0.1790, -0.1891,\n         -0.0572,  0.0646, -0.1899,  0.0088,  0.1773, -0.0320, -0.0038,  0.1267,\n          0.1133, -0.0468,  0.0505, -0.0733],\n        [-0.0902,  0.0777,  0.1244,  0.0042,  0.0468, -0.1965,  0.0975,  0.0166,\n         -0.0522,  0.2011, -0.1146, -0.1384, -0.0580, -0.0850,  0.1123, -0.0678,\n          0.1884, -0.0647, -0.0682,  0.1129],\n        [-0.1026,  0.2215,  0.0335, -0.1163,  0.0666,  0.0137, -0.2008, -0.1755,\n          0.1098, -0.0400,  0.0059, -0.1581,  0.0260,  0.0616, -0.1665, -0.0115,\n          0.0112,  0.1986,  0.0240,  0.0037],\n        [-0.1687, -0.0019, -0.1099,  0.1600,  0.0594, -0.1790,  0.1695, -0.0724,\n          0.0076, -0.0751, -0.1221,  0.0638, -0.1840,  0.0562,  0.1555,  0.0214,\n          0.1317,  0.1046,  0.2052,  0.1504],\n        [-0.0946,  0.1062, -0.1263,  0.0961,  0.0229, -0.1444, -0.1489,  0.0415,\n         -0.1000,  0.1190, -0.0667,  0.1596,  0.0233, -0.1154, -0.1862, -0.0360,\n         -0.0095, -0.1791,  0.1774,  0.2095],\n        [ 0.0086,  0.1331,  0.0762,  0.0836, -0.2133,  0.1899, -0.1912,  0.0815,\n          0.0902, -0.1003,  0.0593,  0.0753,  0.0228,  0.0307,  0.1720,  0.2193,\n          0.0315, -0.2207,  0.0560,  0.1090],\n        [-0.1280,  0.0785,  0.0245,  0.0877,  0.1320, -0.0103,  0.0809, -0.1177,\n          0.1430,  0.1269, -0.0692, -0.0429, -0.0756,  0.1790, -0.0678, -0.1290,\n          0.1531, -0.0116, -0.0435,  0.0367],\n        [-0.0451,  0.0021,  0.2035, -0.0606,  0.2088, -0.1046, -0.0530, -0.0315,\n          0.0545,  0.0479,  0.1870,  0.1474,  0.2124,  0.0773, -0.1718, -0.1327,\n          0.2080, -0.0418, -0.1077, -0.1574],\n        [ 0.2105,  0.0187, -0.0934,  0.1127,  0.1075, -0.1981, -0.0142, -0.2011,\n          0.0178,  0.2161, -0.0368,  0.2211, -0.1122, -0.1446, -0.1596,  0.1241,\n         -0.0754,  0.0361,  0.2021,  0.1268],\n        [-0.0303,  0.0513, -0.1996, -0.0552,  0.0653,  0.1002, -0.1882, -0.1094,\n          0.0452, -0.1787, -0.0234, -0.0872, -0.0342,  0.0681, -0.1772, -0.0432,\n          0.0081, -0.2022, -0.1708,  0.0813],\n        [ 0.1255,  0.0572, -0.1429,  0.1427, -0.0999,  0.2076,  0.0063, -0.1051,\n          0.0023, -0.0535, -0.1203,  0.1221, -0.1480, -0.1503, -0.1838,  0.2109,\n         -0.1014, -0.1524,  0.0533,  0.0894],\n        [ 0.2029, -0.0483, -0.1826, -0.1179,  0.2144,  0.0781, -0.1819,  0.0031,\n          0.2125,  0.1508,  0.2038, -0.1876,  0.2027, -0.0758, -0.0834,  0.1270,\n         -0.0043, -0.2121, -0.1235,  0.0507],\n        [ 0.1268,  0.1204,  0.0839,  0.1746, -0.0631,  0.0602,  0.0797, -0.2004,\n          0.0792, -0.1033, -0.0806,  0.0717,  0.0463, -0.1521, -0.0952,  0.0312,\n         -0.1766, -0.1213,  0.1429, -0.0060],\n        [-0.1745,  0.0172, -0.0919,  0.1101, -0.1775, -0.1542, -0.1039,  0.0252,\n         -0.0275, -0.2207, -0.1134, -0.1235,  0.1394, -0.0805, -0.1888, -0.0114,\n          0.0846, -0.1138, -0.0104,  0.2120],\n        [-0.1663, -0.2054,  0.1843,  0.0124,  0.1655, -0.0711,  0.1636,  0.0985,\n         -0.0119,  0.0627, -0.0301, -0.0474,  0.1923,  0.2057,  0.0023, -0.0516,\n         -0.0759,  0.0836, -0.2035,  0.1391],\n        [-0.1777, -0.1495, -0.0964, -0.2081,  0.1749,  0.0598,  0.1830,  0.0803,\n          0.1134, -0.0860,  0.2167,  0.1983,  0.0022,  0.1446,  0.0007, -0.0258,\n          0.0212, -0.0414, -0.1819,  0.1956],\n        [-0.0014, -0.0768, -0.2190,  0.1995,  0.2222,  0.2079, -0.1935,  0.1195,\n         -0.2121, -0.1353, -0.2159, -0.1528, -0.0586,  0.0158,  0.0429,  0.1266,\n         -0.0491,  0.1035, -0.2075,  0.0383],\n        [ 0.1567, -0.1568, -0.0152,  0.1181,  0.1237,  0.1773,  0.0418,  0.2080,\n         -0.1924, -0.2009,  0.0124, -0.0476,  0.2173, -0.0164, -0.0584, -0.0263,\n          0.0500,  0.0062,  0.1047, -0.1939],\n        [-0.1589, -0.0994, -0.0111,  0.1801, -0.1137, -0.2062,  0.0135, -0.1865,\n         -0.2146,  0.0271, -0.0266,  0.2106, -0.1601,  0.0508,  0.0376,  0.1399,\n          0.1842, -0.1500,  0.0933,  0.2224],\n        [-0.1989,  0.0840, -0.0649,  0.0831, -0.2014, -0.0682, -0.0843, -0.2145,\n         -0.0880, -0.1105,  0.1781, -0.1217, -0.0722, -0.1962,  0.0868,  0.1130,\n         -0.0354, -0.0051, -0.0123,  0.1542],\n        [-0.0052,  0.1377,  0.1563, -0.1079, -0.1133,  0.1892, -0.0100,  0.0746,\n          0.1446,  0.1141,  0.2057,  0.2169, -0.1468, -0.0802,  0.1365,  0.0339,\n          0.2171, -0.0733, -0.1738,  0.1167],\n        [-0.1175, -0.1584,  0.1775,  0.1878, -0.0077, -0.2045, -0.0839,  0.2110,\n         -0.1009, -0.0568,  0.0859,  0.0231, -0.0372,  0.2226,  0.1824, -0.0941,\n          0.1520, -0.1461, -0.1593, -0.0539],\n        [ 0.1877,  0.0015,  0.0448, -0.1516,  0.0032, -0.0718,  0.0281,  0.0422,\n         -0.1198, -0.1961, -0.1517,  0.0083, -0.2052,  0.0049,  0.1438,  0.0593,\n         -0.0697, -0.1725,  0.2132,  0.0079],\n        [-0.0488, -0.0191, -0.1971, -0.0990, -0.1240, -0.1121, -0.0812, -0.1106,\n          0.1600, -0.1544,  0.1890, -0.0145, -0.0257, -0.1890,  0.1276,  0.0928,\n         -0.0416, -0.2109,  0.1404, -0.1278],\n        [-0.0710, -0.0519,  0.1585, -0.1535,  0.1307,  0.0959, -0.1619, -0.1239,\n          0.0561,  0.0028,  0.1224, -0.0674, -0.0594,  0.0342,  0.0400, -0.1986,\n          0.0182,  0.0389,  0.1527, -0.0022],\n        [-0.1529,  0.0584, -0.0958,  0.0372,  0.1101,  0.1598, -0.0354,  0.1663,\n         -0.0208, -0.0439, -0.0842,  0.0341,  0.0458, -0.1476,  0.0080,  0.1026,\n          0.1814,  0.0094, -0.0571,  0.1936]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	20,
                                            "out_features":	32,
                                            "training":	false
                                        }
                                    },
                                    "1":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "2":	{
                                        "Linear(in_features=32, out_features=16, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.0792, -0.1434, -0.0737,  0.1596,  0.0862, -0.1184, -0.0959,  0.1744,\n        -0.1005,  0.0448,  0.0131,  0.1397, -0.0541, -0.0736,  0.0967,  0.0543],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 7.1123e-02, -1.2930e-02, -6.8829e-02,  5.4319e-02, -2.1144e-02,\n          5.7908e-02,  1.4029e-01, -1.0711e-01,  7.8328e-03,  1.4257e-01,\n         -3.4143e-02,  1.2315e-01, -8.5427e-02,  2.3268e-02,  1.3435e-01,\n          2.6922e-02,  9.4113e-02,  9.7471e-02,  1.0297e-02, -1.2108e-01,\n          1.3637e-01, -3.5337e-02,  1.0461e-01,  8.6438e-02, -1.2778e-01,\n         -1.3750e-01, -4.5726e-02,  1.0314e-01, -1.6093e-01,  4.1710e-02,\n          1.4905e-02, -1.2173e-01],\n        [-1.2328e-01,  1.7107e-01, -8.8130e-02, -9.6810e-02, -8.4473e-02,\n         -1.7087e-01,  7.1879e-02, -3.6421e-02, -7.7394e-03, -9.3652e-02,\n         -1.0358e-01,  1.5657e-01,  1.3802e-01, -5.6999e-02, -1.7964e-02,\n          1.6858e-01, -1.7586e-01, -2.0715e-02,  1.2748e-01, -3.7223e-02,\n         -1.3727e-01,  1.2478e-01,  8.6972e-02, -1.3542e-01, -1.6101e-01,\n          6.6426e-02,  3.2055e-02, -4.6385e-02, -9.6225e-02,  1.1717e-01,\n          1.7274e-02,  5.2105e-02],\n        [-8.3072e-03,  3.3035e-02,  3.8006e-02, -2.2528e-02, -3.0174e-02,\n         -3.4895e-02,  1.5882e-01,  1.2571e-01,  1.6975e-01, -1.5940e-01,\n          1.3209e-01,  1.0791e-01,  1.4256e-01,  9.7357e-02,  1.6046e-01,\n          8.4935e-02,  1.6777e-01, -9.4830e-02, -6.6766e-02,  1.0144e-01,\n         -3.4747e-02,  1.1396e-01,  9.0235e-02,  1.5541e-01,  5.8834e-02,\n         -1.4369e-01,  9.3903e-02,  1.2021e-01,  1.7645e-01, -1.6697e-01,\n         -6.9281e-03, -3.9601e-02],\n        [ 1.1915e-01, -2.4877e-02,  6.0534e-03,  2.4372e-03,  3.8453e-02,\n          6.3484e-02,  1.6232e-02, -7.2263e-02, -7.0731e-02,  1.0070e-01,\n         -1.2876e-01,  2.4472e-02, -6.9945e-02,  9.2513e-02,  3.5849e-02,\n          1.5416e-01,  1.4932e-01, -1.3228e-01, -1.5037e-01,  1.2007e-01,\n          1.4756e-01,  1.2572e-01, -1.1073e-02, -7.5755e-02,  1.6889e-01,\n         -3.9388e-02,  8.4418e-02,  1.6867e-01,  1.7072e-01, -1.1357e-01,\n          1.6418e-01, -1.3218e-01],\n        [-7.4091e-02,  4.9064e-02,  7.1515e-02, -7.5576e-02,  1.3516e-01,\n         -2.1096e-02, -1.4323e-01,  1.4846e-01, -3.6778e-02,  8.9814e-03,\n         -4.3213e-02,  1.2309e-01, -1.3101e-01,  1.5407e-01,  6.6059e-02,\n         -4.2439e-02, -1.1828e-01, -8.6537e-02,  1.3579e-01, -1.1444e-01,\n          1.1526e-01,  1.5853e-01,  9.6973e-02,  4.0107e-02, -7.7793e-03,\n          1.3300e-01, -1.2184e-01,  6.0793e-02,  1.7307e-02,  1.3790e-01,\n         -1.8641e-02, -1.1930e-01],\n        [-5.6371e-05, -1.7642e-01,  2.2821e-02, -1.2585e-01, -8.3827e-02,\n         -2.1924e-03,  3.1656e-02,  1.7036e-01,  2.5975e-02,  1.2510e-01,\n         -2.1952e-03, -1.3310e-01,  1.0647e-02,  3.3971e-02, -1.0535e-01,\n         -7.8212e-02, -7.4782e-02, -7.7151e-02, -3.4170e-02,  1.4548e-02,\n          1.3443e-01,  1.6923e-01, -3.9001e-02, -8.9046e-02,  5.2948e-02,\n          1.0388e-01,  1.9140e-02, -3.8304e-02, -1.6604e-01,  6.0334e-02,\n         -1.7306e-01, -1.3521e-01],\n        [ 9.4988e-02,  1.1427e-01, -1.1151e-01, -2.8244e-03, -1.5505e-01,\n         -9.2876e-02, -3.3167e-02, -1.2753e-01,  1.1465e-01, -3.2834e-02,\n         -1.7176e-01, -1.0197e-01, -1.5679e-01,  3.1804e-02,  8.0811e-02,\n         -1.2608e-01, -8.4152e-02,  4.9472e-02,  5.5561e-02,  6.7319e-02,\n         -1.2619e-01,  7.4941e-02, -1.4539e-01,  1.1711e-01, -1.0836e-01,\n         -6.8566e-02, -2.9339e-02,  7.8956e-02,  5.6924e-02, -1.2275e-01,\n          7.2598e-02, -7.6081e-02],\n        [ 1.0902e-01,  1.4867e-01, -1.1016e-01,  2.3218e-02,  9.6696e-02,\n          5.0888e-02, -6.7203e-02, -5.4653e-02, -1.2232e-01,  1.2450e-01,\n          1.2337e-01,  4.8099e-02,  1.3440e-01, -1.1800e-01,  4.6618e-02,\n         -3.7434e-03, -1.4345e-01,  1.0279e-01,  2.2256e-02, -1.2090e-01,\n         -4.7358e-03, -1.6517e-02, -5.0020e-02, -5.1095e-03, -1.3566e-01,\n          4.6330e-02,  1.3128e-01, -3.8384e-02,  2.3096e-02, -1.2190e-01,\n         -1.0849e-01,  9.8522e-02],\n        [-2.1835e-02, -1.3455e-01, -6.6108e-02,  1.6872e-01,  2.8968e-02,\n         -1.3587e-01, -1.5861e-02,  5.1525e-02, -7.9609e-02,  8.4446e-02,\n          1.6268e-01,  1.1653e-01, -1.5453e-01,  1.2810e-01,  6.1938e-02,\n          1.5418e-01, -2.8195e-02,  1.0399e-01,  1.7334e-01, -4.5376e-02,\n          6.3950e-02, -1.2852e-01,  1.4657e-01,  1.1329e-01,  3.0335e-02,\n         -6.5736e-02, -1.6527e-01, -1.4642e-01,  7.9876e-02, -1.4133e-01,\n          9.9169e-02,  9.9624e-02],\n        [-6.7254e-02,  1.3773e-02,  5.0711e-02, -2.1762e-02,  2.1151e-02,\n         -1.6087e-01,  2.8925e-02, -1.6338e-01,  1.5693e-01,  1.4601e-01,\n          1.3668e-01,  7.0956e-02,  5.7075e-02,  1.5589e-01, -1.1456e-01,\n         -1.1403e-01,  5.6087e-02,  8.6720e-02, -1.3386e-01, -1.8087e-02,\n          1.6208e-01, -6.8784e-02, -8.6947e-02,  6.3881e-02, -1.5129e-01,\n         -1.4464e-01,  5.6837e-02,  5.9924e-02,  4.7939e-03,  1.4687e-01,\n         -1.6229e-01,  4.7134e-02],\n        [-3.6921e-02,  7.9922e-02, -6.7306e-02,  1.6324e-01, -2.8956e-02,\n         -1.0480e-02, -1.7001e-01, -5.2595e-02, -6.4600e-03,  5.1813e-02,\n          8.0814e-03, -1.3076e-01, -8.1497e-02, -1.2941e-02,  2.5288e-03,\n          1.1650e-01, -1.0615e-01,  1.2454e-01, -9.7116e-02, -4.9048e-02,\n          1.0712e-01,  1.5655e-01,  1.2484e-01, -1.3697e-01,  1.6637e-01,\n          1.4830e-01,  1.7228e-01,  7.0801e-02,  7.8408e-02,  1.2880e-01,\n          1.1523e-01, -2.5409e-02],\n        [-1.0418e-01,  5.5226e-02, -1.5149e-01, -1.4091e-01, -9.0921e-02,\n         -7.2105e-02,  1.4942e-01, -4.7257e-02, -4.1239e-03,  1.5958e-01,\n          1.8800e-02, -4.4841e-02,  1.1812e-01, -1.3044e-01, -1.6932e-01,\n         -1.2551e-01,  1.2537e-02,  1.2367e-01,  7.7835e-02,  5.6758e-02,\n         -3.1506e-02,  1.7669e-01,  1.0071e-01, -8.7675e-02,  8.3900e-02,\n          4.0416e-02,  3.2859e-03,  1.1403e-02, -9.0393e-02,  1.2012e-01,\n         -1.3159e-02, -8.5012e-02],\n        [-1.0738e-01, -1.7072e-01, -1.2300e-01,  9.9705e-02, -1.6285e-01,\n         -1.5742e-01,  1.0996e-01, -9.8963e-02,  1.9693e-03,  6.6734e-02,\n         -1.0053e-01,  7.6996e-02,  3.3208e-03,  5.7760e-02, -1.3539e-01,\n          3.8056e-02,  1.4051e-01, -1.2034e-01,  1.2789e-01,  1.4220e-01,\n          3.8845e-02,  1.2524e-01,  1.9345e-04, -3.9071e-02, -4.2329e-02,\n         -4.9801e-02,  6.4259e-02,  9.0467e-02, -9.5724e-02,  2.1435e-02,\n         -7.9176e-02, -1.1329e-01],\n        [-1.3486e-01,  1.0828e-01, -6.5432e-02,  1.4571e-01,  1.1055e-01,\n         -1.2931e-01,  9.7901e-02, -1.6021e-01, -1.1700e-01,  1.0438e-01,\n         -1.1891e-01, -1.3434e-01,  1.1648e-01,  1.1593e-01,  3.6742e-02,\n         -4.2722e-02, -9.5574e-02, -1.1106e-01, -9.2139e-02, -2.8043e-02,\n         -1.6544e-01, -1.0824e-01,  1.4954e-01,  6.7357e-03, -1.2713e-01,\n         -3.3341e-02, -2.2243e-02, -3.7818e-02, -3.7927e-03, -9.8433e-02,\n         -2.7308e-02, -1.4640e-01],\n        [ 1.6143e-01, -1.4434e-01,  6.4805e-02,  6.5413e-03, -8.5030e-02,\n          1.1107e-01, -9.8786e-02, -9.3075e-02,  3.2812e-02, -1.4847e-01,\n          1.6433e-01,  7.5189e-02, -8.8849e-02,  1.5940e-01,  1.6354e-01,\n         -8.0950e-02,  2.5040e-02,  1.4234e-01,  5.1223e-03,  1.3997e-01,\n          8.4420e-02,  3.0350e-02, -8.2410e-02, -4.5476e-02, -1.5389e-01,\n          4.9630e-02,  8.5404e-02,  7.7788e-02, -7.9953e-02,  8.3437e-02,\n         -6.8866e-02, -1.0954e-01],\n        [-4.9806e-02, -9.2441e-02,  1.3024e-01,  1.5733e-01,  4.4242e-02,\n         -5.9268e-02,  4.3253e-02, -1.7087e-01,  3.0631e-02, -1.1044e-01,\n         -1.6620e-01,  1.4735e-01, -1.0530e-01, -1.6400e-01,  1.0254e-01,\n         -8.4601e-02, -2.0405e-02,  1.3565e-01, -1.4761e-01, -4.9437e-02,\n         -1.4827e-01, -1.6185e-01,  7.4288e-02,  2.6587e-03,  6.6654e-02,\n         -9.6044e-02,  1.1765e-01, -1.5589e-01,  1.7379e-01, -2.9837e-02,\n          1.3200e-01,  2.4771e-02]], requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	32,
                                            "out_features":	16,
                                            "training":	false
                                        }
                                    },
                                    "3":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "4":	{
                                        "Linear(in_features=16, out_features=8, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([ 0.1446,  0.0780, -0.2117,  0.1776,  0.0052, -0.0861,  0.1730, -0.2060],\n       requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[ 0.2328,  0.0355, -0.1000, -0.1117,  0.0604,  0.1749,  0.1165, -0.0481,\n         -0.0915, -0.0225,  0.2309, -0.2339,  0.0549,  0.1291, -0.0356,  0.1984],\n        [-0.0697,  0.0625,  0.1759,  0.2114, -0.0887,  0.1989, -0.1670, -0.0915,\n         -0.2171,  0.0450, -0.0344,  0.2461,  0.2282, -0.1143,  0.1108,  0.2456],\n        [-0.0119, -0.2035, -0.2193, -0.1615,  0.0015,  0.2026,  0.1291, -0.1584,\n         -0.0262, -0.1315,  0.1854, -0.1751, -0.1854, -0.2368, -0.1982,  0.0941],\n        [ 0.1212, -0.1506, -0.1262,  0.1221,  0.0711,  0.2467, -0.0560,  0.0952,\n         -0.2360, -0.0150, -0.1078, -0.0636, -0.0990,  0.2000, -0.1840, -0.2218],\n        [ 0.2066,  0.1369, -0.2289, -0.0796, -0.1475,  0.0555, -0.0804,  0.0692,\n          0.2225, -0.1383,  0.1795,  0.2328,  0.2473,  0.1910,  0.1133,  0.0523],\n        [-0.1930,  0.0805,  0.1531, -0.1215,  0.1077, -0.1572,  0.0447, -0.0685,\n          0.0048, -0.2240, -0.0203,  0.1325,  0.0271,  0.1084,  0.0469,  0.0578],\n        [ 0.2466,  0.2357, -0.1327, -0.1809,  0.0423,  0.0150,  0.1076,  0.2194,\n          0.0552,  0.1919, -0.2477,  0.0991,  0.2376, -0.2364,  0.0275, -0.1864],\n        [-0.0033,  0.2157,  0.1181,  0.0674, -0.2186,  0.2277, -0.1431, -0.2445,\n         -0.2326,  0.1662, -0.0023, -0.1030, -0.2386, -0.1496,  0.1523,  0.1117]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	16,
                                            "out_features":	8,
                                            "training":	false
                                        }
                                    },
                                    "5":	{
                                        "ReLU()":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "inplace":	false,
                                            "training":	false
                                        }
                                    },
                                    "6":	{
                                        "Linear(in_features=8, out_features=1, bias=True)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{},
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{
                                                "bias":	"Parameter containing:\ntensor([-0.1752], requires_grad=True)",
                                                "weight":	"Parameter containing:\ntensor([[-0.2703, -0.0526, -0.2864,  0.1638, -0.1363,  0.2052, -0.0261, -0.1004]],\n       requires_grad=True)"
                                            },
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "in_features":	8,
                                            "out_features":	1,
                                            "training":	false
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "training":	false
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "act_dim":	1,
                    "kernel_dim":	5,
                    "kernel_size":	4,
                    "training":	false
                }
            },
            "_target_net_update_frequency":	10,
            "_train_q_iters":	80,
            "_train_update_freq":	8,
            "_traj_per_epoch":	3,
            "logger":	{
                "<utils.logger.EpochLogger object at 0x149cd85e0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-dqn-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s77770000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-dqn-info/rl4sys-dqn-info_s77770000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_net_update_frequency":	10,
    "train_q_iters":	80,
    "train_update_freq":	8,
    "traj_per_epoch":	3
}