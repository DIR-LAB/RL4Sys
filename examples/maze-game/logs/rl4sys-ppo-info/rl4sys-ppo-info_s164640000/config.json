{
    "__class__":	"PPO",
    "buf_size":	50000,
    "clip_ratio":	0.1,
    "env_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game",
    "exp_name":	"rl4sys-ppo-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	5,
    "lam":	0.97,
    "log_data_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-info",
        "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-ppo-info\\rl4sys-ppo-info_s164640000"
    },
    "pi_lr":	0.0003,
    "seed":	164640000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x0000023A1D7AECB0>":	{
            "_clip_ratio":	0.1,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (pi_network): Sequential(\n      (0): Linear(in_features=4, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n    )\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (pi_network): Sequential(\n    (0): Linear(in_features=4, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.4847,  0.1773,  0.3386,  0.0835, -0.0233, -0.3558,  0.4859,  0.3116,\n         0.1138,  0.3007,  0.0101, -0.1357, -0.1556,  0.0969, -0.3825, -0.0677,\n        -0.3481,  0.4441,  0.4354,  0.2295,  0.4115, -0.3398, -0.2661, -0.2496,\n        -0.0978,  0.3797, -0.2283, -0.0836, -0.1102,  0.3900, -0.2894,  0.1867],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1762,  0.4720,  0.1914, -0.3992],\n        [ 0.1609,  0.2798, -0.3592, -0.1591],\n        [ 0.2800,  0.4086, -0.2098,  0.0296],\n        [ 0.4398,  0.3522,  0.1632,  0.2698],\n        [ 0.0779,  0.0243, -0.1421,  0.1684],\n        [ 0.1444,  0.2771,  0.1037,  0.1572],\n        [-0.2354, -0.2151,  0.1782,  0.3794],\n        [ 0.0290, -0.1721,  0.1222, -0.3076],\n        [-0.4192, -0.4832, -0.2052, -0.3043],\n        [-0.4802, -0.1562, -0.1439,  0.3863],\n        [ 0.2091,  0.4271, -0.1104,  0.4101],\n        [ 0.1108, -0.1192,  0.0679,  0.3415],\n        [-0.1891, -0.0042,  0.3748, -0.4372],\n        [ 0.3285,  0.3456,  0.4491, -0.2543],\n        [ 0.2519,  0.2972,  0.0796,  0.2787],\n        [ 0.4884,  0.4654, -0.3165, -0.3845],\n        [-0.4263,  0.0769,  0.2908,  0.3363],\n        [ 0.4677,  0.1079,  0.1226,  0.4350],\n        [-0.0748, -0.2122, -0.2793,  0.2505],\n        [-0.1157,  0.3676,  0.0775,  0.0946],\n        [ 0.0537, -0.1765, -0.0460,  0.4125],\n        [-0.3723,  0.2423, -0.3807, -0.1552],\n        [ 0.4778,  0.2676,  0.1997,  0.4084],\n        [ 0.3270, -0.3518,  0.2598,  0.2662],\n        [ 0.0016,  0.1794,  0.2101,  0.1818],\n        [-0.4966,  0.1967, -0.2494, -0.3673],\n        [ 0.0197,  0.4603, -0.4816,  0.1942],\n        [ 0.1874, -0.4762,  0.3933, -0.1724],\n        [ 0.4988, -0.1541,  0.4898,  0.2915],\n        [-0.4449, -0.1526,  0.2401,  0.0184],\n        [-0.1719, -0.1511,  0.0992, -0.2411],\n        [-0.0806,  0.0019,  0.0960, -0.4800]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0443,  0.0098, -0.0133, -0.0838,  0.1700,  0.1242,  0.1730, -0.1274,\n        -0.0419, -0.0234, -0.0621, -0.1539,  0.0349,  0.0701,  0.0592,  0.0836],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 7.1930e-02,  1.1806e-01, -8.8694e-02,  1.1324e-01,  3.7584e-02,\n         -6.0043e-02, -1.4766e-01,  4.6790e-02,  8.2428e-02,  2.1361e-02,\n         -1.5648e-01,  6.0621e-02, -4.7825e-02, -3.2747e-02, -7.8376e-02,\n          1.6432e-01, -7.9297e-02,  1.0582e-01,  1.5946e-01, -7.3758e-02,\n         -2.9546e-02, -1.5267e-01,  4.4630e-02, -1.5087e-01,  3.1014e-02,\n         -9.6035e-02,  1.7564e-01,  6.9451e-02, -1.1997e-01,  5.3042e-02,\n          1.2463e-01,  6.6150e-02],\n        [-1.6382e-01,  5.2288e-02,  1.0234e-01, -1.3313e-01, -1.3520e-01,\n         -1.4360e-01,  1.3450e-01,  2.8205e-04,  1.5764e-01,  3.4592e-02,\n          6.0916e-03, -9.3645e-02, -1.2206e-01,  1.8407e-03, -3.8582e-02,\n         -2.5596e-02, -1.6113e-01,  1.7231e-01,  7.5850e-02,  1.2895e-01,\n         -9.5992e-02,  9.0742e-03, -5.8208e-02,  9.9889e-02, -6.1914e-02,\n         -1.4416e-01, -1.9655e-03,  6.8866e-02,  7.6702e-02,  2.4019e-02,\n         -3.4258e-02, -1.6802e-01],\n        [ 1.7364e-01, -3.9810e-02, -1.1312e-01, -1.7055e-01, -1.9279e-02,\n         -1.7117e-02, -9.8489e-02,  1.2736e-01, -1.2439e-01, -1.0615e-01,\n          1.0917e-01, -1.4982e-01, -1.6519e-01,  1.7431e-01, -2.3777e-02,\n         -2.4868e-02, -1.1509e-01, -1.3366e-01,  1.4468e-01,  1.2153e-01,\n         -2.8130e-02, -1.6098e-01,  8.6119e-02, -3.6142e-02,  1.6311e-01,\n          7.7325e-02,  1.4527e-01,  8.1565e-02,  1.2764e-01,  7.6613e-02,\n         -1.7009e-01, -9.3330e-02],\n        [-1.5961e-01, -1.0940e-01,  2.6066e-02, -1.1690e-03, -1.6678e-01,\n          7.1341e-02, -1.5805e-01, -1.1898e-01,  4.3134e-02, -8.5429e-02,\n         -1.3433e-01, -5.5347e-02,  5.0141e-02,  2.8168e-02, -1.3491e-03,\n         -6.0351e-02,  3.9822e-02,  1.6747e-01,  1.2823e-01,  5.4144e-03,\n          2.1696e-02,  1.3314e-01,  8.1211e-02,  6.1212e-02,  1.2281e-01,\n         -3.4402e-02,  6.8342e-02,  8.9671e-02, -1.2837e-01,  1.0852e-01,\n         -1.6585e-01,  1.2746e-01],\n        [-9.6850e-02,  8.2658e-02, -1.5520e-03, -8.4733e-02, -7.9070e-02,\n          4.7594e-02, -1.6532e-01, -1.0450e-01, -4.6830e-02,  1.9593e-02,\n          1.3518e-01,  1.0971e-01,  1.6982e-01, -1.1329e-02, -5.6694e-02,\n         -1.4630e-01, -1.3508e-01,  9.4313e-02,  2.3841e-02, -1.4874e-01,\n          1.7365e-01, -2.3870e-02,  1.4828e-01,  8.1155e-02, -3.4117e-02,\n         -1.7081e-01, -8.3020e-02,  8.8832e-02, -1.3768e-01, -1.4724e-01,\n          9.7500e-02, -1.2135e-01],\n        [ 1.1017e-01,  1.3230e-01,  1.0523e-01,  1.2006e-01, -1.1263e-01,\n         -1.0132e-01, -3.3688e-02, -4.8715e-02, -2.4506e-03,  9.9838e-04,\n         -2.5212e-02, -9.8262e-02, -4.2491e-02, -1.1945e-01,  1.0767e-01,\n         -9.2712e-02,  9.3454e-02, -2.4000e-02,  1.6397e-01,  3.3668e-02,\n         -1.6139e-01,  1.3942e-01,  8.1882e-02,  6.7302e-02, -6.4350e-02,\n         -1.7136e-01,  8.6558e-02, -1.4166e-02,  8.1267e-02, -9.2594e-02,\n         -7.5114e-02,  7.9391e-02],\n        [-9.6439e-02,  3.7288e-02, -9.4424e-02,  1.7568e-01, -9.8402e-02,\n         -1.4775e-01, -5.9759e-02, -4.2667e-02, -5.4529e-02,  9.5020e-02,\n         -1.0438e-01, -1.3997e-01, -1.4993e-01, -1.0385e-04,  1.6027e-01,\n         -2.3447e-02,  7.1199e-02,  8.7326e-02,  1.4737e-01, -5.7005e-02,\n         -2.1212e-02, -1.4504e-01,  3.3554e-02,  2.4720e-02, -1.6887e-01,\n          8.9338e-02, -1.6135e-01, -4.1762e-02,  2.3028e-02, -5.5466e-02,\n          4.4740e-02,  3.1371e-02],\n        [ 6.2314e-02,  8.0229e-03, -7.7865e-02, -4.8546e-02, -1.5824e-01,\n         -1.6007e-01, -1.6404e-01, -1.5847e-01,  2.5596e-02, -1.5967e-01,\n          3.0560e-02, -8.7102e-02,  4.9499e-02,  1.1423e-01, -7.7975e-02,\n         -9.0843e-02,  7.1742e-04, -1.3818e-01, -1.4116e-01, -1.7454e-01,\n         -1.3529e-01, -2.9469e-02,  2.1594e-02,  8.4221e-03, -8.2375e-02,\n         -7.3183e-03, -1.3989e-01,  1.2589e-01,  1.2213e-01,  4.2725e-02,\n         -9.9546e-03,  3.7401e-02],\n        [ 1.2574e-01,  1.8560e-02, -1.0285e-02,  7.5363e-02,  7.0974e-02,\n          1.5411e-01, -5.0388e-02,  1.7554e-01,  5.2129e-02,  5.3495e-02,\n         -6.5526e-02,  1.7500e-01,  9.3874e-02,  8.7850e-02,  1.0942e-01,\n         -7.9362e-02, -8.3712e-02,  1.3148e-01, -1.2312e-01, -4.0908e-02,\n          8.9646e-02, -7.8980e-02, -7.1853e-02,  1.5798e-01, -1.3050e-01,\n         -1.4917e-01, -1.5646e-01, -8.5311e-02, -1.2134e-01,  9.3864e-02,\n          7.0079e-02,  8.7521e-02],\n        [-1.5580e-01,  2.6865e-02,  1.1971e-01,  3.7677e-03, -1.2294e-01,\n         -1.2247e-01,  3.3242e-02,  7.3004e-02, -1.0242e-01, -1.2379e-01,\n          4.8045e-02, -1.7623e-01,  1.6527e-01,  1.0673e-01, -1.5611e-01,\n          9.5570e-02,  1.9933e-02,  1.1622e-01,  1.3789e-01, -1.0811e-01,\n          9.9742e-03, -6.1200e-03, -1.7329e-01, -7.4185e-02,  1.4720e-01,\n         -2.5311e-02,  1.1355e-01,  1.1829e-01, -1.4411e-02, -1.1389e-01,\n         -3.9351e-02, -1.0154e-01],\n        [ 2.9639e-02,  6.7207e-02,  1.7276e-01,  3.1442e-02, -1.5656e-01,\n         -6.3708e-02,  7.9594e-03,  1.6966e-01, -2.6765e-02,  9.9935e-02,\n         -2.0239e-02,  1.1984e-01,  1.3259e-01, -1.9756e-02,  8.9714e-02,\n          1.0401e-01,  3.3516e-02,  1.3939e-01, -1.1373e-01,  7.0273e-03,\n         -6.2448e-02, -9.0163e-02, -1.7556e-01, -4.0830e-02,  4.1484e-02,\n          6.6859e-02, -9.1460e-02,  7.3457e-02,  1.1596e-01,  1.4966e-01,\n         -1.5501e-01,  9.6002e-02],\n        [-5.7952e-03, -5.3901e-02, -1.5842e-01,  1.6371e-01,  1.4416e-01,\n         -1.2288e-01,  7.9758e-02, -3.7688e-03,  1.7363e-01, -3.6461e-02,\n         -1.0488e-01,  9.5368e-02, -4.2219e-02, -1.2429e-01,  7.9461e-02,\n         -3.7970e-02,  6.5341e-02, -1.3311e-02, -1.2928e-01, -1.4598e-01,\n         -9.5933e-02, -5.2945e-02,  1.0928e-01,  1.5712e-01,  1.7604e-01,\n         -5.6213e-04,  1.2826e-01, -9.7801e-03,  4.5859e-02,  1.5408e-01,\n         -1.1303e-01,  1.2906e-01],\n        [ 1.3989e-01, -6.1045e-02, -7.0661e-02, -4.3237e-02,  7.8375e-02,\n         -3.6659e-02, -9.5282e-02, -1.2108e-01,  9.1208e-02, -1.2933e-01,\n          1.6372e-02,  1.6369e-01, -1.0014e-01,  1.0068e-01,  3.4716e-02,\n          1.6133e-02, -1.2560e-02,  6.9187e-02, -2.7626e-02,  9.0136e-02,\n         -1.6103e-01, -1.4332e-02, -1.2223e-02, -1.5354e-02, -1.3573e-01,\n          1.5277e-01,  1.2594e-01,  1.3821e-01,  1.1572e-01, -1.4245e-01,\n          1.5661e-01, -1.2137e-01],\n        [ 7.6516e-02,  8.8214e-02,  6.1823e-02, -3.6080e-02,  9.3986e-02,\n         -1.2914e-01, -3.4947e-02,  7.8252e-02, -1.2450e-01, -8.9563e-02,\n         -1.6662e-01,  6.8655e-02, -1.4928e-01, -9.3907e-03, -1.2811e-01,\n         -4.9963e-02, -9.5978e-03, -3.1781e-02,  5.7060e-02, -2.4790e-03,\n         -8.2056e-02, -7.8290e-02, -1.3599e-01, -8.2451e-02, -2.0945e-02,\n         -3.7132e-02,  1.2483e-01, -6.6291e-02, -7.0512e-03, -1.1773e-01,\n          9.9896e-03,  4.8920e-02],\n        [ 1.0908e-01, -1.0158e-01,  5.9593e-02,  7.5204e-03,  1.6644e-01,\n         -1.3583e-01, -1.7037e-01,  8.2155e-02, -1.2893e-01,  1.7403e-01,\n         -7.3792e-02, -1.6300e-01, -1.2082e-01,  4.3844e-02,  4.3627e-02,\n         -1.4272e-01,  1.6889e-01, -1.2561e-01, -9.4857e-02,  1.5670e-01,\n          8.1969e-02, -2.3782e-02,  6.2096e-02, -6.4690e-02,  4.5727e-02,\n          1.5305e-01,  1.6758e-01,  7.9557e-02, -1.1660e-01, -7.9027e-03,\n          1.1802e-01, -1.5097e-01],\n        [-1.0240e-01,  1.1526e-02,  2.4804e-02, -6.6175e-02,  5.9652e-02,\n          6.8894e-02, -9.9778e-02,  1.6975e-02, -6.6550e-02, -7.9399e-02,\n         -7.8469e-02,  8.3920e-02, -1.1038e-01, -1.5431e-01,  1.1260e-01,\n          8.5387e-03, -1.1130e-01, -8.2774e-02,  1.1247e-01,  6.6700e-02,\n         -1.3668e-01, -1.4825e-01, -1.4484e-01, -5.0529e-02,  1.1237e-01,\n         -6.0608e-02,  1.6966e-01, -2.5010e-02, -4.7722e-02, -1.2500e-01,\n          1.1112e-01,  1.3521e-01]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1675, -0.2071,  0.1533, -0.0691, -0.2411,  0.0372, -0.2157,  0.1648],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1831,  0.1335, -0.0547,  0.1088, -0.0736,  0.1548,  0.0095, -0.1600,\n          0.0203,  0.2360,  0.1656,  0.1018, -0.2453,  0.2488, -0.1995,  0.1233],\n        [-0.0971, -0.2381, -0.2104,  0.1113, -0.1421, -0.0666,  0.0669,  0.1532,\n         -0.0113, -0.0534,  0.0014, -0.0780,  0.1678, -0.2197,  0.2443, -0.2389],\n        [-0.1619, -0.1204,  0.1551, -0.0924, -0.2030, -0.0220, -0.1330,  0.0622,\n         -0.0552,  0.0780,  0.0414,  0.0403,  0.1308,  0.0878,  0.0408,  0.0189],\n        [-0.2205,  0.1501, -0.1362,  0.1899,  0.2053, -0.0265,  0.0306, -0.0644,\n          0.1751,  0.2439, -0.1322, -0.1247,  0.2115,  0.0690, -0.1971,  0.1150],\n        [ 0.0947, -0.2335,  0.2409,  0.2120,  0.1563,  0.0190, -0.0986,  0.1008,\n         -0.0157, -0.1318,  0.1625,  0.2141, -0.0315,  0.0251, -0.0981,  0.1089],\n        [ 0.0829,  0.1686,  0.0313,  0.0757,  0.0919,  0.1304,  0.0581,  0.1594,\n         -0.0051, -0.0727, -0.0872,  0.0768,  0.1098,  0.1476, -0.2031,  0.1786],\n        [-0.0732,  0.0386,  0.1222,  0.1414, -0.0497,  0.0647,  0.2065,  0.1194,\n          0.1583,  0.2493,  0.0602,  0.0585, -0.0233,  0.0368,  0.0761, -0.2221],\n        [ 0.2468,  0.0362,  0.1092, -0.2241, -0.2482, -0.1814,  0.2379,  0.0884,\n         -0.1253, -0.0643, -0.1887, -0.0177,  0.0461, -0.0464,  0.0087, -0.1259]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0930], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.2322,  0.0503, -0.3067, -0.1460, -0.2192, -0.1872, -0.2683,  0.0594]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "kernel_dim":	4,
                                "kernel_size":	5,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2059, -0.0308,  0.1669,  0.2233, -0.0429,  0.1891, -0.1770, -0.1720,\n        -0.0120, -0.1850, -0.2102, -0.1549, -0.1451,  0.0427, -0.1361,  0.1775,\n         0.1669,  0.0450, -0.0311, -0.0953, -0.1148, -0.1621,  0.0747,  0.1458,\n        -0.1784,  0.0542,  0.0056, -0.1645,  0.1009,  0.0550,  0.0375,  0.1024],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 1.5763e-01, -3.1415e-02,  6.5427e-02, -2.0677e-01, -1.0749e-01,\n          1.1618e-01,  1.1668e-01,  8.6987e-02,  4.7628e-02,  1.9216e-01,\n          1.4486e-01,  1.9514e-01,  1.8353e-01, -2.0356e-01, -1.7696e-01,\n         -8.9994e-02,  1.1563e-01,  2.8631e-02,  1.1957e-02,  3.5686e-02],\n        [ 9.7420e-02, -1.3468e-01, -2.4682e-02,  7.8883e-02, -1.5580e-01,\n          3.3793e-02,  8.4051e-02, -1.0062e-01,  1.8738e-01,  2.1013e-01,\n         -1.9486e-02,  2.0226e-02, -3.6694e-02,  2.1001e-01,  4.1281e-02,\n          1.8380e-03,  4.2292e-02,  1.7453e-01,  3.6365e-02, -9.5356e-02],\n        [-1.7874e-01,  8.8300e-03, -1.6959e-01, -5.7157e-02, -1.0376e-01,\n          1.8187e-02,  1.3403e-01,  5.7056e-02, -2.0146e-01, -9.5391e-03,\n          6.4013e-02,  4.5438e-03,  1.6126e-01, -1.1114e-01,  1.0251e-01,\n          2.1139e-01,  1.4476e-01,  2.0811e-01, -1.0420e-02, -4.5787e-02],\n        [-5.6709e-02, -1.0552e-01, -1.8603e-02,  1.9211e-02, -1.6944e-01,\n         -1.9480e-01,  7.7712e-02,  1.0627e-01, -2.0242e-01,  2.1100e-02,\n          1.7499e-01, -2.0228e-01,  2.0417e-01,  1.9666e-01,  1.6101e-01,\n          1.7436e-02,  1.2623e-03, -6.0467e-02,  4.5326e-03,  1.8352e-02],\n        [-8.6117e-02,  9.7084e-02,  1.8748e-01, -3.7441e-02,  7.5133e-02,\n         -1.3664e-01,  1.4330e-02, -1.7183e-01, -4.6051e-03, -1.9119e-03,\n         -1.3138e-01, -2.7653e-02, -1.9915e-01,  1.7444e-01, -9.5609e-02,\n         -4.6111e-02, -6.5715e-02,  1.4820e-01, -1.9490e-01,  4.5627e-02],\n        [ 7.3317e-02,  1.7438e-01, -2.0938e-02, -1.7035e-01, -6.0257e-02,\n         -1.8195e-01,  8.4958e-02, -6.8271e-02, -1.8247e-01, -1.6298e-01,\n          1.7222e-01, -5.9347e-03,  1.9449e-02, -8.0913e-02,  1.3105e-01,\n         -9.6799e-02,  3.7088e-02,  1.6493e-01, -6.5612e-02, -2.1472e-01],\n        [-5.1585e-02, -9.1826e-02, -5.2177e-02, -1.3111e-01,  2.8220e-02,\n          9.9897e-02,  1.1248e-01, -6.0174e-02, -3.3233e-04,  2.1806e-01,\n          1.6479e-01,  3.2556e-02, -2.1954e-01, -6.4487e-03, -1.2796e-01,\n         -1.4636e-01,  5.4691e-02, -1.1134e-01, -5.9979e-02, -1.2814e-01],\n        [ 2.2115e-01,  1.6546e-01, -1.8235e-01, -3.7472e-02,  1.8797e-01,\n          1.2474e-01, -7.2886e-02, -1.8009e-01, -4.1660e-02, -8.6441e-02,\n          1.9094e-01,  1.3250e-01,  1.4059e-01,  6.6710e-02,  7.5823e-02,\n          1.9372e-01, -2.0614e-01,  5.7357e-02, -1.0926e-01, -8.4412e-02],\n        [ 2.0960e-01,  1.6937e-01,  4.8988e-02, -1.3107e-01,  1.7282e-01,\n         -1.8700e-01,  1.9868e-02,  6.8664e-02,  7.0771e-02, -2.2146e-01,\n         -3.2108e-02, -1.9695e-01, -1.7160e-02, -1.9212e-01, -1.8258e-01,\n          1.0010e-01,  9.3952e-02, -5.2388e-02, -1.2732e-01,  8.1828e-02],\n        [ 2.5657e-03,  1.8541e-01,  1.5245e-01, -8.8355e-02, -2.0725e-01,\n          1.1448e-01,  3.4023e-02,  2.1367e-01, -9.6168e-03,  1.5761e-01,\n          4.4120e-02, -1.1626e-01,  1.1868e-01, -8.8313e-02,  3.9313e-02,\n         -5.6307e-02,  2.2309e-01, -1.0883e-01,  1.4511e-01,  1.4748e-01],\n        [-5.0834e-02,  1.0610e-01,  2.0941e-01, -1.9619e-02, -1.6665e-01,\n         -1.7797e-01,  1.7652e-02, -2.5802e-03,  1.8771e-02, -1.1897e-01,\n          1.9541e-01,  1.7555e-01, -1.1839e-01, -1.8989e-01, -9.8611e-03,\n          1.3915e-02, -1.9495e-01,  2.0358e-01,  8.8915e-02,  2.0769e-01],\n        [-1.2355e-01,  3.0323e-02,  2.0515e-01, -1.0010e-01, -1.4435e-01,\n          1.3475e-01,  1.8629e-01,  2.1407e-01,  1.0146e-01,  4.4326e-02,\n          3.9130e-03,  1.6151e-01, -2.1560e-01, -1.4301e-01,  1.1444e-01,\n          6.1485e-02,  1.4109e-01,  6.4085e-02, -5.9148e-02, -1.4727e-01],\n        [-8.9458e-02, -1.7544e-01, -1.3932e-01, -4.6214e-03, -4.9997e-02,\n          2.0943e-01, -1.7251e-01, -7.8386e-02, -1.7451e-01,  2.0069e-01,\n         -7.3460e-02,  7.4718e-02,  2.2191e-01,  1.7720e-01,  1.6905e-01,\n         -1.3016e-01,  1.7583e-01, -1.4857e-01, -1.0721e-01, -6.2239e-02],\n        [-7.6798e-02,  1.4490e-01,  1.4281e-01, -2.2020e-01, -1.4390e-01,\n          1.4864e-01,  1.0360e-01,  2.0178e-01,  6.1626e-02,  1.4065e-02,\n         -9.6833e-02,  1.8359e-01, -1.4067e-01, -1.3019e-01,  1.8796e-01,\n         -4.9302e-02,  3.2198e-02, -3.4228e-03,  1.9134e-01, -1.0085e-01],\n        [ 1.6375e-01,  1.4070e-01, -3.0790e-02, -1.7020e-02,  1.7240e-01,\n          2.0306e-01,  2.1816e-01, -8.7412e-03, -3.5989e-02,  1.9281e-01,\n          6.9233e-02, -2.6296e-03, -1.1492e-01,  1.0024e-01, -2.0138e-01,\n          2.9013e-02, -7.5215e-02,  1.7882e-01, -1.0183e-01, -1.2024e-01],\n        [-8.7033e-02, -9.9656e-02, -8.2036e-02,  2.0027e-01,  1.0314e-01,\n          2.1588e-01, -2.0641e-01,  9.5514e-02, -1.4691e-01,  2.1287e-01,\n          3.8183e-02, -1.2590e-01, -1.0019e-01, -7.6539e-02,  5.1698e-02,\n         -1.4372e-01,  8.4545e-02,  1.0977e-01, -1.0075e-01,  9.9739e-02],\n        [ 1.4618e-02, -1.1160e-01,  2.1497e-01,  4.5718e-02, -1.5091e-01,\n         -6.2664e-03,  1.6300e-01, -2.7342e-02, -2.3088e-02,  4.0817e-02,\n         -5.9655e-02,  2.1537e-01, -2.1514e-01,  6.4727e-02,  4.7034e-02,\n          1.6799e-01,  6.6313e-02, -9.5410e-02, -1.0792e-01,  9.6092e-02],\n        [ 1.9912e-01,  1.0040e-01,  6.3510e-03, -1.6498e-01,  2.0298e-02,\n          1.9455e-01,  8.3528e-02,  9.7555e-02, -1.7776e-01,  5.7936e-02,\n         -4.2144e-02, -1.9284e-01, -1.4968e-01,  1.6038e-01,  4.4854e-02,\n          1.5633e-01,  1.9698e-01, -1.2182e-01, -2.7329e-02, -5.5481e-02],\n        [ 2.8251e-02,  7.7269e-02, -2.7250e-02, -2.1260e-01,  1.6188e-01,\n          6.6098e-02, -6.9047e-02,  2.5005e-02,  1.4513e-01,  1.7541e-01,\n         -1.2044e-01, -2.2152e-01, -1.2170e-01,  7.2714e-02,  8.1523e-02,\n         -1.3713e-02,  1.6591e-01, -1.9219e-01, -5.6916e-02, -2.2284e-01],\n        [-3.8834e-02,  1.8928e-01, -1.6646e-01,  1.9702e-01, -4.0562e-03,\n          1.0560e-01, -1.1601e-01, -9.9153e-02,  9.8485e-02, -9.3274e-02,\n         -2.1937e-01,  3.3612e-02, -8.0778e-02,  1.9822e-01,  9.4200e-02,\n         -9.5188e-02,  4.5762e-02,  1.5255e-01,  2.0802e-01,  1.0956e-01],\n        [-5.0886e-02, -9.2553e-02, -1.7384e-01,  5.1622e-02,  5.0171e-02,\n          1.2184e-01, -8.4943e-02, -1.0372e-01, -1.2981e-01, -3.5130e-02,\n          8.4108e-02,  7.9080e-02, -2.0090e-01,  7.4513e-03, -1.8908e-01,\n         -1.9989e-01, -1.1195e-01, -2.1536e-01,  6.3462e-02, -1.0247e-02],\n        [ 2.6346e-02, -2.1372e-01, -7.8703e-02,  5.5594e-02, -8.7413e-02,\n          2.0372e-01,  1.4965e-02,  2.0087e-01, -6.1256e-02, -1.3898e-01,\n         -1.4168e-01,  1.8731e-02, -1.7891e-01, -2.0025e-01,  2.6904e-02,\n         -5.0214e-02,  8.5858e-02, -3.6991e-02,  1.2769e-01,  2.0909e-01],\n        [-6.7819e-02, -3.9387e-04,  4.6367e-02,  1.7646e-01, -3.0685e-03,\n          6.0394e-02,  1.0514e-01,  1.0718e-01, -3.3430e-03,  1.2943e-01,\n         -1.6791e-02,  2.4313e-02, -1.6723e-01,  1.9767e-01,  1.4120e-01,\n          1.1266e-01, -2.9077e-03, -1.8972e-01, -2.9397e-02, -1.6682e-01],\n        [ 5.7244e-02, -5.8025e-02,  1.2087e-01, -8.0549e-02, -8.3732e-02,\n         -4.0941e-02,  2.1025e-01,  8.7276e-02,  1.4374e-01, -1.3604e-01,\n          4.3719e-04, -1.5073e-01, -4.7240e-02,  1.0547e-01, -1.5986e-01,\n         -2.2273e-02,  9.6040e-02, -2.0192e-01, -1.9246e-01, -5.1321e-03],\n        [-3.4568e-02, -7.8596e-02,  9.8409e-02, -1.9450e-01,  1.5686e-01,\n          7.0411e-02, -9.7590e-02, -1.9407e-01,  8.6669e-02,  9.0771e-03,\n         -1.0560e-01, -1.1568e-01,  1.3155e-01, -1.4383e-01, -6.6254e-02,\n          3.7938e-02, -1.2604e-02,  2.2358e-01,  1.8040e-01, -9.9302e-02],\n        [-2.1986e-01,  1.6893e-01, -1.3870e-01, -6.2892e-02, -2.1910e-01,\n         -2.2594e-02,  3.5104e-02, -5.3939e-02,  6.5472e-02,  3.7406e-02,\n          2.0327e-01,  4.9990e-02, -1.5522e-01,  2.0253e-01,  4.2758e-02,\n         -2.0929e-01, -1.6943e-01,  1.3685e-01,  1.0731e-01,  1.0756e-01],\n        [ 1.7817e-01, -6.6027e-02,  4.8001e-02, -1.7670e-01,  1.1340e-01,\n         -2.1854e-01,  2.2095e-01,  1.1050e-01, -1.8222e-02,  1.3987e-01,\n         -9.0680e-02,  1.2865e-01, -5.5998e-02,  8.1445e-02,  7.5347e-02,\n          9.6755e-02,  2.0489e-01, -2.2078e-01,  2.1200e-01,  2.4993e-02],\n        [ 7.9358e-02,  2.2200e-01, -6.0424e-02, -1.0485e-01, -1.7230e-01,\n         -1.7200e-01,  1.3768e-01,  7.2528e-02, -1.3857e-01,  1.0092e-01,\n          1.9745e-01, -1.6288e-01,  3.8970e-03,  2.1039e-01,  1.6575e-04,\n          8.6236e-02,  1.2618e-01, -1.5527e-01,  1.6011e-02, -1.0337e-02],\n        [-2.2304e-01,  1.2066e-02,  1.3371e-01, -3.8224e-02, -3.1041e-03,\n          1.1506e-01,  1.1764e-01,  7.4544e-02,  1.7466e-01, -1.3841e-01,\n         -1.1114e-01,  7.9010e-02,  2.1000e-01,  1.9150e-01,  1.1395e-01,\n         -1.4695e-01,  1.2336e-01,  1.0178e-01,  6.8969e-02,  1.6878e-01],\n        [-6.6863e-02, -2.1099e-01,  2.0291e-01, -1.6923e-01, -1.4169e-01,\n          5.2131e-02,  4.1343e-02, -1.9399e-02, -1.8153e-01, -2.1769e-01,\n         -2.2074e-01, -2.6875e-02,  1.6033e-01, -1.3501e-01, -2.0063e-01,\n          5.4572e-02,  7.6367e-02, -8.9225e-02, -1.3864e-01, -1.0063e-01],\n        [-9.2912e-02, -1.4922e-01,  4.4485e-02,  1.4156e-01,  2.0624e-01,\n         -1.6953e-01, -2.7812e-02,  1.0863e-01,  1.7192e-01, -1.1652e-01,\n          6.7065e-02,  1.6046e-01, -3.4697e-02,  5.0684e-02, -3.5490e-02,\n          1.0551e-02,  1.3386e-01,  1.2104e-03, -1.2591e-01,  1.8619e-01],\n        [-1.5959e-01,  1.3705e-01,  2.0664e-01,  1.0801e-02, -1.7683e-01,\n         -8.8577e-02,  5.1967e-02,  1.8415e-01,  5.0406e-02, -1.3490e-01,\n         -8.5316e-02, -2.4693e-02, -1.9218e-01,  2.0332e-01,  1.6252e-01,\n          3.2910e-02, -7.8091e-02, -1.4149e-01, -8.9178e-02, -2.0909e-01]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1445,  0.1683,  0.0327,  0.0260, -0.1136,  0.0476,  0.0492, -0.1374,\n         0.0941,  0.0984, -0.1606,  0.1702,  0.1035, -0.1050,  0.0226, -0.0644],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0360,  0.0733, -0.1738, -0.1528, -0.0373, -0.1374, -0.1141, -0.0864,\n          0.0022, -0.0030,  0.0775,  0.0189, -0.0907,  0.1048, -0.1390,  0.0144,\n         -0.1306, -0.1305, -0.0800, -0.0618,  0.0943, -0.0237,  0.0030, -0.0561,\n         -0.1730, -0.1674,  0.0312,  0.0823,  0.0422, -0.1235, -0.1290,  0.1599],\n        [ 0.1640,  0.1032, -0.1056,  0.1280,  0.0279,  0.0224, -0.1457,  0.0435,\n          0.0749,  0.0296,  0.1387,  0.0771,  0.0492,  0.0436, -0.1125, -0.1383,\n          0.0366, -0.1489,  0.0322,  0.1197, -0.0601, -0.1515,  0.0469,  0.1055,\n         -0.1372, -0.0249,  0.1096,  0.0710, -0.1052, -0.1432,  0.0469,  0.1448],\n        [ 0.0831,  0.1762,  0.1478,  0.1146,  0.1592, -0.1556,  0.1540,  0.0880,\n         -0.1640, -0.1572, -0.0202, -0.1759,  0.0613, -0.0278,  0.0150,  0.0648,\n         -0.1499,  0.0649,  0.1545, -0.0673, -0.0607,  0.0936, -0.1329,  0.1246,\n          0.0589,  0.0491,  0.1386, -0.1565, -0.0730,  0.0372, -0.0309,  0.0966],\n        [ 0.0232,  0.1193,  0.0082, -0.0940, -0.0295,  0.1643, -0.1121, -0.0505,\n         -0.1562,  0.0551, -0.1078,  0.1336,  0.0198, -0.1490,  0.1100, -0.1489,\n         -0.0540,  0.1408, -0.0363, -0.0108, -0.1306,  0.0213, -0.1187,  0.0488,\n          0.0094, -0.0558,  0.1692,  0.1394,  0.1396,  0.1059,  0.0279,  0.0187],\n        [ 0.0638,  0.0968, -0.0747, -0.0158,  0.0672, -0.0920,  0.1108,  0.0415,\n         -0.0127, -0.0500,  0.0424,  0.0451, -0.1611,  0.1220,  0.1128,  0.0589,\n          0.1445, -0.1125, -0.1373,  0.0470,  0.1336,  0.1364, -0.1734,  0.0033,\n         -0.0957, -0.0359, -0.0730,  0.0652, -0.0586,  0.1752,  0.1012, -0.0523],\n        [ 0.0837, -0.0076, -0.1465,  0.0195, -0.1437,  0.1665, -0.0562,  0.0666,\n         -0.1654,  0.1722,  0.1448, -0.0452,  0.0224, -0.0824, -0.1514, -0.1382,\n          0.0941,  0.1528, -0.1091, -0.1413,  0.0070, -0.1041,  0.0716,  0.1394,\n          0.1520, -0.1138,  0.0112, -0.0651, -0.0434,  0.0787,  0.0758,  0.0565],\n        [ 0.0870, -0.0212,  0.0295,  0.0653,  0.1031, -0.0577,  0.1232,  0.0481,\n          0.0848,  0.1604,  0.0414, -0.0749,  0.1403, -0.0376, -0.1103, -0.0894,\n          0.1158,  0.1499,  0.0400, -0.1490,  0.0125, -0.1081,  0.0787, -0.1400,\n          0.1281, -0.0004, -0.1300, -0.0705, -0.1210,  0.0363, -0.1469,  0.0569],\n        [ 0.0468,  0.1283, -0.0688,  0.1503, -0.0371, -0.0730,  0.0163,  0.0939,\n         -0.1276,  0.0070, -0.0098,  0.1353,  0.0423,  0.1730, -0.1466, -0.1124,\n         -0.0964, -0.1172,  0.0868, -0.0753, -0.0469,  0.1188,  0.1531,  0.0153,\n         -0.1503,  0.0168,  0.0412, -0.0892,  0.0963, -0.1735, -0.0863, -0.0958],\n        [-0.1299, -0.0273, -0.0710,  0.0375, -0.1027,  0.0671, -0.1389,  0.0835,\n         -0.1149, -0.1091, -0.0328, -0.0664,  0.0493, -0.1206, -0.0602,  0.0970,\n         -0.0099,  0.1122,  0.1352,  0.0105,  0.0618, -0.0391,  0.0610,  0.1455,\n          0.1460,  0.0393,  0.0124,  0.1497, -0.0175, -0.0824,  0.1242,  0.1389],\n        [-0.0768,  0.0686, -0.0578, -0.0573, -0.0584, -0.0240, -0.0110,  0.1534,\n          0.0954, -0.1462, -0.0534, -0.0138, -0.1528,  0.0408, -0.0542, -0.0023,\n          0.0969, -0.0071, -0.1742,  0.0631,  0.0338, -0.0761, -0.1328, -0.1227,\n         -0.0275, -0.0649, -0.0158,  0.0935,  0.1133,  0.1296,  0.0645, -0.1430],\n        [-0.0515,  0.0789, -0.0235, -0.1357,  0.0727,  0.1390,  0.0847, -0.0784,\n          0.0563, -0.1195, -0.1572, -0.0079, -0.1057,  0.0463,  0.0546,  0.0262,\n         -0.0808,  0.0278, -0.0467,  0.0495, -0.1652,  0.0217, -0.0653,  0.0531,\n         -0.0535, -0.0747,  0.0370,  0.0944, -0.0418,  0.0133, -0.0993,  0.1167],\n        [-0.0996, -0.1192, -0.1591,  0.1189, -0.0565, -0.1682, -0.0583,  0.0241,\n          0.1469,  0.1735, -0.0931,  0.0382, -0.1432,  0.0666,  0.1459, -0.0613,\n          0.0588, -0.0310,  0.0169,  0.1608,  0.1384,  0.1578,  0.0569, -0.0458,\n         -0.0321, -0.0396,  0.0535, -0.0315,  0.0200,  0.0250,  0.0531, -0.0482],\n        [ 0.0781,  0.0836,  0.1450,  0.0480, -0.0841, -0.0703, -0.0726, -0.1030,\n         -0.1298,  0.0647, -0.0676, -0.0073, -0.0990,  0.1322,  0.0204, -0.0402,\n         -0.0413,  0.1722, -0.1449, -0.0583,  0.1094,  0.1605,  0.0753,  0.0307,\n         -0.0156, -0.0999, -0.0027, -0.0884, -0.1653,  0.0952,  0.0296,  0.0512],\n        [ 0.0472,  0.1746,  0.0448,  0.0417,  0.1201,  0.1087,  0.1252, -0.0678,\n         -0.0162,  0.1240, -0.0848,  0.0748, -0.1498,  0.1294,  0.0174,  0.0856,\n         -0.0852, -0.0202,  0.1722, -0.1768,  0.1309, -0.0989, -0.1062, -0.0390,\n          0.0744, -0.1024,  0.0221,  0.1003, -0.1617, -0.0776, -0.1030, -0.1292],\n        [-0.1302, -0.1148, -0.0572,  0.0381, -0.1078,  0.0036,  0.1362, -0.0277,\n         -0.1359,  0.0197, -0.0096,  0.1378,  0.1445,  0.1615,  0.1280, -0.0068,\n         -0.0663,  0.0371, -0.0270, -0.0367, -0.1712, -0.1681,  0.0928, -0.1260,\n         -0.1741,  0.0858, -0.0846,  0.0863, -0.1330,  0.1283, -0.1201, -0.0994],\n        [ 0.1089,  0.1716, -0.1689,  0.1515,  0.0591,  0.0209, -0.0224, -0.1636,\n          0.1324, -0.0368,  0.0454, -0.1473, -0.1463,  0.1101, -0.0268,  0.1121,\n          0.1323,  0.0781,  0.1749, -0.1208, -0.0423, -0.0615, -0.0098, -0.0344,\n          0.0488,  0.0500, -0.1589,  0.0817, -0.0122,  0.0080,  0.0416,  0.1349]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1023, -0.0410, -0.0197, -0.1280,  0.1171,  0.0262, -0.2321,  0.1146],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0161,  0.1703, -0.0769,  0.1916, -0.1058, -0.1985,  0.1694, -0.1366,\n         -0.0919, -0.2359,  0.1201,  0.1380,  0.0506,  0.0047,  0.1061,  0.0552],\n        [ 0.2066, -0.2274,  0.2013, -0.1045, -0.2146, -0.0711,  0.0658, -0.1044,\n          0.0728,  0.0799, -0.0708,  0.0881,  0.1238, -0.1409,  0.1231, -0.0912],\n        [-0.1428,  0.0524,  0.2006,  0.1229, -0.0165,  0.1642,  0.0555,  0.0106,\n         -0.0476,  0.2002, -0.2459, -0.2224, -0.0604,  0.0138,  0.2069,  0.1542],\n        [-0.1063,  0.2413, -0.0152,  0.1964, -0.2006,  0.2131,  0.0580, -0.0891,\n         -0.2056, -0.2221,  0.1485, -0.0824, -0.1535,  0.1804, -0.0765,  0.0442],\n        [ 0.1742, -0.0716,  0.2234,  0.0601, -0.1727,  0.0861, -0.2432, -0.0485,\n          0.1298,  0.0499, -0.1355,  0.0936, -0.1021,  0.0475, -0.0187, -0.1698],\n        [-0.1160,  0.2232,  0.0401,  0.0497, -0.1486,  0.1854, -0.1029,  0.2288,\n         -0.0315,  0.2084,  0.1356, -0.0923,  0.0435, -0.2189, -0.1289, -0.0948],\n        [ 0.0839, -0.1289, -0.0891, -0.0226,  0.1308, -0.0796,  0.1566,  0.0948,\n         -0.0414, -0.0239,  0.2468,  0.2290,  0.2234,  0.0081, -0.2369, -0.1701],\n        [ 0.1180,  0.1938,  0.0294, -0.1317,  0.0025,  0.0358,  0.0932,  0.1248,\n         -0.1665,  0.1703,  0.1945,  0.1680,  0.2435, -0.0679, -0.2063,  0.1824]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2303], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0600,  0.0253,  0.2862, -0.1646, -0.2817, -0.2346, -0.3366, -0.3401]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    20,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	20,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "flatten_obs_dim":	20,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1762,  0.4720,  0.1914, -0.3992],\n        [ 0.1609,  0.2798, -0.3592, -0.1591],\n        [ 0.2800,  0.4086, -0.2098,  0.0296],\n        [ 0.4398,  0.3522,  0.1632,  0.2698],\n        [ 0.0779,  0.0243, -0.1421,  0.1684],\n        [ 0.1444,  0.2771,  0.1037,  0.1572],\n        [-0.2354, -0.2151,  0.1782,  0.3794],\n        [ 0.0290, -0.1721,  0.1222, -0.3076],\n        [-0.4192, -0.4832, -0.2052, -0.3043],\n        [-0.4802, -0.1562, -0.1439,  0.3863],\n        [ 0.2091,  0.4271, -0.1104,  0.4101],\n        [ 0.1108, -0.1192,  0.0679,  0.3415],\n        [-0.1891, -0.0042,  0.3748, -0.4372],\n        [ 0.3285,  0.3456,  0.4491, -0.2543],\n        [ 0.2519,  0.2972,  0.0796,  0.2787],\n        [ 0.4884,  0.4654, -0.3165, -0.3845],\n        [-0.4263,  0.0769,  0.2908,  0.3363],\n        [ 0.4677,  0.1079,  0.1226,  0.4350],\n        [-0.0748, -0.2122, -0.2793,  0.2505],\n        [-0.1157,  0.3676,  0.0775,  0.0946],\n        [ 0.0537, -0.1765, -0.0460,  0.4125],\n        [-0.3723,  0.2423, -0.3807, -0.1552],\n        [ 0.4778,  0.2676,  0.1997,  0.4084],\n        [ 0.3270, -0.3518,  0.2598,  0.2662],\n        [ 0.0016,  0.1794,  0.2101,  0.1818],\n        [-0.4966,  0.1967, -0.2494, -0.3673],\n        [ 0.0197,  0.4603, -0.4816,  0.1942],\n        [ 0.1874, -0.4762,  0.3933, -0.1724],\n        [ 0.4988, -0.1541,  0.4898,  0.2915],\n        [-0.4449, -0.1526,  0.2401,  0.0184],\n        [-0.1719, -0.1511,  0.0992, -0.2411],\n        [-0.0806,  0.0019,  0.0960, -0.4800]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.4847,  0.1773,  0.3386,  0.0835, -0.0233, -0.3558,  0.4859,  0.3116,\n         0.1138,  0.3007,  0.0101, -0.1357, -0.1556,  0.0969, -0.3825, -0.0677,\n        -0.3481,  0.4441,  0.4354,  0.2295,  0.4115, -0.3398, -0.2661, -0.2496,\n        -0.0978,  0.3797, -0.2283, -0.0836, -0.1102,  0.3900, -0.2894,  0.1867],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 7.1930e-02,  1.1806e-01, -8.8694e-02,  1.1324e-01,  3.7584e-02,\n         -6.0043e-02, -1.4766e-01,  4.6790e-02,  8.2428e-02,  2.1361e-02,\n         -1.5648e-01,  6.0621e-02, -4.7825e-02, -3.2747e-02, -7.8376e-02,\n          1.6432e-01, -7.9297e-02,  1.0582e-01,  1.5946e-01, -7.3758e-02,\n         -2.9546e-02, -1.5267e-01,  4.4630e-02, -1.5087e-01,  3.1014e-02,\n         -9.6035e-02,  1.7564e-01,  6.9451e-02, -1.1997e-01,  5.3042e-02,\n          1.2463e-01,  6.6150e-02],\n        [-1.6382e-01,  5.2288e-02,  1.0234e-01, -1.3313e-01, -1.3520e-01,\n         -1.4360e-01,  1.3450e-01,  2.8205e-04,  1.5764e-01,  3.4592e-02,\n          6.0916e-03, -9.3645e-02, -1.2206e-01,  1.8407e-03, -3.8582e-02,\n         -2.5596e-02, -1.6113e-01,  1.7231e-01,  7.5850e-02,  1.2895e-01,\n         -9.5992e-02,  9.0742e-03, -5.8208e-02,  9.9889e-02, -6.1914e-02,\n         -1.4416e-01, -1.9655e-03,  6.8866e-02,  7.6702e-02,  2.4019e-02,\n         -3.4258e-02, -1.6802e-01],\n        [ 1.7364e-01, -3.9810e-02, -1.1312e-01, -1.7055e-01, -1.9279e-02,\n         -1.7117e-02, -9.8489e-02,  1.2736e-01, -1.2439e-01, -1.0615e-01,\n          1.0917e-01, -1.4982e-01, -1.6519e-01,  1.7431e-01, -2.3777e-02,\n         -2.4868e-02, -1.1509e-01, -1.3366e-01,  1.4468e-01,  1.2153e-01,\n         -2.8130e-02, -1.6098e-01,  8.6119e-02, -3.6142e-02,  1.6311e-01,\n          7.7325e-02,  1.4527e-01,  8.1565e-02,  1.2764e-01,  7.6613e-02,\n         -1.7009e-01, -9.3330e-02],\n        [-1.5961e-01, -1.0940e-01,  2.6066e-02, -1.1690e-03, -1.6678e-01,\n          7.1341e-02, -1.5805e-01, -1.1898e-01,  4.3134e-02, -8.5429e-02,\n         -1.3433e-01, -5.5347e-02,  5.0141e-02,  2.8168e-02, -1.3491e-03,\n         -6.0351e-02,  3.9822e-02,  1.6747e-01,  1.2823e-01,  5.4144e-03,\n          2.1696e-02,  1.3314e-01,  8.1211e-02,  6.1212e-02,  1.2281e-01,\n         -3.4402e-02,  6.8342e-02,  8.9671e-02, -1.2837e-01,  1.0852e-01,\n         -1.6585e-01,  1.2746e-01],\n        [-9.6850e-02,  8.2658e-02, -1.5520e-03, -8.4733e-02, -7.9070e-02,\n          4.7594e-02, -1.6532e-01, -1.0450e-01, -4.6830e-02,  1.9593e-02,\n          1.3518e-01,  1.0971e-01,  1.6982e-01, -1.1329e-02, -5.6694e-02,\n         -1.4630e-01, -1.3508e-01,  9.4313e-02,  2.3841e-02, -1.4874e-01,\n          1.7365e-01, -2.3870e-02,  1.4828e-01,  8.1155e-02, -3.4117e-02,\n         -1.7081e-01, -8.3020e-02,  8.8832e-02, -1.3768e-01, -1.4724e-01,\n          9.7500e-02, -1.2135e-01],\n        [ 1.1017e-01,  1.3230e-01,  1.0523e-01,  1.2006e-01, -1.1263e-01,\n         -1.0132e-01, -3.3688e-02, -4.8715e-02, -2.4506e-03,  9.9838e-04,\n         -2.5212e-02, -9.8262e-02, -4.2491e-02, -1.1945e-01,  1.0767e-01,\n         -9.2712e-02,  9.3454e-02, -2.4000e-02,  1.6397e-01,  3.3668e-02,\n         -1.6139e-01,  1.3942e-01,  8.1882e-02,  6.7302e-02, -6.4350e-02,\n         -1.7136e-01,  8.6558e-02, -1.4166e-02,  8.1267e-02, -9.2594e-02,\n         -7.5114e-02,  7.9391e-02],\n        [-9.6439e-02,  3.7288e-02, -9.4424e-02,  1.7568e-01, -9.8402e-02,\n         -1.4775e-01, -5.9759e-02, -4.2667e-02, -5.4529e-02,  9.5020e-02,\n         -1.0438e-01, -1.3997e-01, -1.4993e-01, -1.0385e-04,  1.6027e-01,\n         -2.3447e-02,  7.1199e-02,  8.7326e-02,  1.4737e-01, -5.7005e-02,\n         -2.1212e-02, -1.4504e-01,  3.3554e-02,  2.4720e-02, -1.6887e-01,\n          8.9338e-02, -1.6135e-01, -4.1762e-02,  2.3028e-02, -5.5466e-02,\n          4.4740e-02,  3.1371e-02],\n        [ 6.2314e-02,  8.0229e-03, -7.7865e-02, -4.8546e-02, -1.5824e-01,\n         -1.6007e-01, -1.6404e-01, -1.5847e-01,  2.5596e-02, -1.5967e-01,\n          3.0560e-02, -8.7102e-02,  4.9499e-02,  1.1423e-01, -7.7975e-02,\n         -9.0843e-02,  7.1742e-04, -1.3818e-01, -1.4116e-01, -1.7454e-01,\n         -1.3529e-01, -2.9469e-02,  2.1594e-02,  8.4221e-03, -8.2375e-02,\n         -7.3183e-03, -1.3989e-01,  1.2589e-01,  1.2213e-01,  4.2725e-02,\n         -9.9546e-03,  3.7401e-02],\n        [ 1.2574e-01,  1.8560e-02, -1.0285e-02,  7.5363e-02,  7.0974e-02,\n          1.5411e-01, -5.0388e-02,  1.7554e-01,  5.2129e-02,  5.3495e-02,\n         -6.5526e-02,  1.7500e-01,  9.3874e-02,  8.7850e-02,  1.0942e-01,\n         -7.9362e-02, -8.3712e-02,  1.3148e-01, -1.2312e-01, -4.0908e-02,\n          8.9646e-02, -7.8980e-02, -7.1853e-02,  1.5798e-01, -1.3050e-01,\n         -1.4917e-01, -1.5646e-01, -8.5311e-02, -1.2134e-01,  9.3864e-02,\n          7.0079e-02,  8.7521e-02],\n        [-1.5580e-01,  2.6865e-02,  1.1971e-01,  3.7677e-03, -1.2294e-01,\n         -1.2247e-01,  3.3242e-02,  7.3004e-02, -1.0242e-01, -1.2379e-01,\n          4.8045e-02, -1.7623e-01,  1.6527e-01,  1.0673e-01, -1.5611e-01,\n          9.5570e-02,  1.9933e-02,  1.1622e-01,  1.3789e-01, -1.0811e-01,\n          9.9742e-03, -6.1200e-03, -1.7329e-01, -7.4185e-02,  1.4720e-01,\n         -2.5311e-02,  1.1355e-01,  1.1829e-01, -1.4411e-02, -1.1389e-01,\n         -3.9351e-02, -1.0154e-01],\n        [ 2.9639e-02,  6.7207e-02,  1.7276e-01,  3.1442e-02, -1.5656e-01,\n         -6.3708e-02,  7.9594e-03,  1.6966e-01, -2.6765e-02,  9.9935e-02,\n         -2.0239e-02,  1.1984e-01,  1.3259e-01, -1.9756e-02,  8.9714e-02,\n          1.0401e-01,  3.3516e-02,  1.3939e-01, -1.1373e-01,  7.0273e-03,\n         -6.2448e-02, -9.0163e-02, -1.7556e-01, -4.0830e-02,  4.1484e-02,\n          6.6859e-02, -9.1460e-02,  7.3457e-02,  1.1596e-01,  1.4966e-01,\n         -1.5501e-01,  9.6002e-02],\n        [-5.7952e-03, -5.3901e-02, -1.5842e-01,  1.6371e-01,  1.4416e-01,\n         -1.2288e-01,  7.9758e-02, -3.7688e-03,  1.7363e-01, -3.6461e-02,\n         -1.0488e-01,  9.5368e-02, -4.2219e-02, -1.2429e-01,  7.9461e-02,\n         -3.7970e-02,  6.5341e-02, -1.3311e-02, -1.2928e-01, -1.4598e-01,\n         -9.5933e-02, -5.2945e-02,  1.0928e-01,  1.5712e-01,  1.7604e-01,\n         -5.6213e-04,  1.2826e-01, -9.7801e-03,  4.5859e-02,  1.5408e-01,\n         -1.1303e-01,  1.2906e-01],\n        [ 1.3989e-01, -6.1045e-02, -7.0661e-02, -4.3237e-02,  7.8375e-02,\n         -3.6659e-02, -9.5282e-02, -1.2108e-01,  9.1208e-02, -1.2933e-01,\n          1.6372e-02,  1.6369e-01, -1.0014e-01,  1.0068e-01,  3.4716e-02,\n          1.6133e-02, -1.2560e-02,  6.9187e-02, -2.7626e-02,  9.0136e-02,\n         -1.6103e-01, -1.4332e-02, -1.2223e-02, -1.5354e-02, -1.3573e-01,\n          1.5277e-01,  1.2594e-01,  1.3821e-01,  1.1572e-01, -1.4245e-01,\n          1.5661e-01, -1.2137e-01],\n        [ 7.6516e-02,  8.8214e-02,  6.1823e-02, -3.6080e-02,  9.3986e-02,\n         -1.2914e-01, -3.4947e-02,  7.8252e-02, -1.2450e-01, -8.9563e-02,\n         -1.6662e-01,  6.8655e-02, -1.4928e-01, -9.3907e-03, -1.2811e-01,\n         -4.9963e-02, -9.5978e-03, -3.1781e-02,  5.7060e-02, -2.4790e-03,\n         -8.2056e-02, -7.8290e-02, -1.3599e-01, -8.2451e-02, -2.0945e-02,\n         -3.7132e-02,  1.2483e-01, -6.6291e-02, -7.0512e-03, -1.1773e-01,\n          9.9896e-03,  4.8920e-02],\n        [ 1.0908e-01, -1.0158e-01,  5.9593e-02,  7.5204e-03,  1.6644e-01,\n         -1.3583e-01, -1.7037e-01,  8.2155e-02, -1.2893e-01,  1.7403e-01,\n         -7.3792e-02, -1.6300e-01, -1.2082e-01,  4.3844e-02,  4.3627e-02,\n         -1.4272e-01,  1.6889e-01, -1.2561e-01, -9.4857e-02,  1.5670e-01,\n          8.1969e-02, -2.3782e-02,  6.2096e-02, -6.4690e-02,  4.5727e-02,\n          1.5305e-01,  1.6758e-01,  7.9557e-02, -1.1660e-01, -7.9027e-03,\n          1.1802e-01, -1.5097e-01],\n        [-1.0240e-01,  1.1526e-02,  2.4804e-02, -6.6175e-02,  5.9652e-02,\n          6.8894e-02, -9.9778e-02,  1.6975e-02, -6.6550e-02, -7.9399e-02,\n         -7.8469e-02,  8.3920e-02, -1.1038e-01, -1.5431e-01,  1.1260e-01,\n          8.5387e-03, -1.1130e-01, -8.2774e-02,  1.1247e-01,  6.6700e-02,\n         -1.3668e-01, -1.4825e-01, -1.4484e-01, -5.0529e-02,  1.1237e-01,\n         -6.0608e-02,  1.6966e-01, -2.5010e-02, -4.7722e-02, -1.2500e-01,\n          1.1112e-01,  1.3521e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0443,  0.0098, -0.0133, -0.0838,  0.1700,  0.1242,  0.1730, -0.1274,\n        -0.0419, -0.0234, -0.0621, -0.1539,  0.0349,  0.0701,  0.0592,  0.0836],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1831,  0.1335, -0.0547,  0.1088, -0.0736,  0.1548,  0.0095, -0.1600,\n          0.0203,  0.2360,  0.1656,  0.1018, -0.2453,  0.2488, -0.1995,  0.1233],\n        [-0.0971, -0.2381, -0.2104,  0.1113, -0.1421, -0.0666,  0.0669,  0.1532,\n         -0.0113, -0.0534,  0.0014, -0.0780,  0.1678, -0.2197,  0.2443, -0.2389],\n        [-0.1619, -0.1204,  0.1551, -0.0924, -0.2030, -0.0220, -0.1330,  0.0622,\n         -0.0552,  0.0780,  0.0414,  0.0403,  0.1308,  0.0878,  0.0408,  0.0189],\n        [-0.2205,  0.1501, -0.1362,  0.1899,  0.2053, -0.0265,  0.0306, -0.0644,\n          0.1751,  0.2439, -0.1322, -0.1247,  0.2115,  0.0690, -0.1971,  0.1150],\n        [ 0.0947, -0.2335,  0.2409,  0.2120,  0.1563,  0.0190, -0.0986,  0.1008,\n         -0.0157, -0.1318,  0.1625,  0.2141, -0.0315,  0.0251, -0.0981,  0.1089],\n        [ 0.0829,  0.1686,  0.0313,  0.0757,  0.0919,  0.1304,  0.0581,  0.1594,\n         -0.0051, -0.0727, -0.0872,  0.0768,  0.1098,  0.1476, -0.2031,  0.1786],\n        [-0.0732,  0.0386,  0.1222,  0.1414, -0.0497,  0.0647,  0.2065,  0.1194,\n          0.1583,  0.2493,  0.0602,  0.0585, -0.0233,  0.0368,  0.0761, -0.2221],\n        [ 0.2468,  0.0362,  0.1092, -0.2241, -0.2482, -0.1814,  0.2379,  0.0884,\n         -0.1253, -0.0643, -0.1887, -0.0177,  0.0461, -0.0464,  0.0087, -0.1259]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1675, -0.2071,  0.1533, -0.0691, -0.2411,  0.0372, -0.2157,  0.1648],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2322,  0.0503, -0.3067, -0.1460, -0.2192, -0.1872, -0.2683,  0.0594]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0930], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x0000023A1D7AEC20>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	50000,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	40,
            "_train_v_iters":	40,
            "_traj_per_epoch":	5,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 1.5763e-01, -3.1415e-02,  6.5427e-02, -2.0677e-01, -1.0749e-01,\n          1.1618e-01,  1.1668e-01,  8.6987e-02,  4.7628e-02,  1.9216e-01,\n          1.4486e-01,  1.9514e-01,  1.8353e-01, -2.0356e-01, -1.7696e-01,\n         -8.9994e-02,  1.1563e-01,  2.8631e-02,  1.1957e-02,  3.5686e-02],\n        [ 9.7420e-02, -1.3468e-01, -2.4682e-02,  7.8883e-02, -1.5580e-01,\n          3.3793e-02,  8.4051e-02, -1.0062e-01,  1.8738e-01,  2.1013e-01,\n         -1.9486e-02,  2.0226e-02, -3.6694e-02,  2.1001e-01,  4.1281e-02,\n          1.8380e-03,  4.2292e-02,  1.7453e-01,  3.6365e-02, -9.5356e-02],\n        [-1.7874e-01,  8.8300e-03, -1.6959e-01, -5.7157e-02, -1.0376e-01,\n          1.8187e-02,  1.3403e-01,  5.7056e-02, -2.0146e-01, -9.5391e-03,\n          6.4013e-02,  4.5438e-03,  1.6126e-01, -1.1114e-01,  1.0251e-01,\n          2.1139e-01,  1.4476e-01,  2.0811e-01, -1.0420e-02, -4.5787e-02],\n        [-5.6709e-02, -1.0552e-01, -1.8603e-02,  1.9211e-02, -1.6944e-01,\n         -1.9480e-01,  7.7712e-02,  1.0627e-01, -2.0242e-01,  2.1100e-02,\n          1.7499e-01, -2.0228e-01,  2.0417e-01,  1.9666e-01,  1.6101e-01,\n          1.7436e-02,  1.2623e-03, -6.0467e-02,  4.5326e-03,  1.8352e-02],\n        [-8.6117e-02,  9.7084e-02,  1.8748e-01, -3.7441e-02,  7.5133e-02,\n         -1.3664e-01,  1.4330e-02, -1.7183e-01, -4.6051e-03, -1.9119e-03,\n         -1.3138e-01, -2.7653e-02, -1.9915e-01,  1.7444e-01, -9.5609e-02,\n         -4.6111e-02, -6.5715e-02,  1.4820e-01, -1.9490e-01,  4.5627e-02],\n        [ 7.3317e-02,  1.7438e-01, -2.0938e-02, -1.7035e-01, -6.0257e-02,\n         -1.8195e-01,  8.4958e-02, -6.8271e-02, -1.8247e-01, -1.6298e-01,\n          1.7222e-01, -5.9347e-03,  1.9449e-02, -8.0913e-02,  1.3105e-01,\n         -9.6799e-02,  3.7088e-02,  1.6493e-01, -6.5612e-02, -2.1472e-01],\n        [-5.1585e-02, -9.1826e-02, -5.2177e-02, -1.3111e-01,  2.8220e-02,\n          9.9897e-02,  1.1248e-01, -6.0174e-02, -3.3233e-04,  2.1806e-01,\n          1.6479e-01,  3.2556e-02, -2.1954e-01, -6.4487e-03, -1.2796e-01,\n         -1.4636e-01,  5.4691e-02, -1.1134e-01, -5.9979e-02, -1.2814e-01],\n        [ 2.2115e-01,  1.6546e-01, -1.8235e-01, -3.7472e-02,  1.8797e-01,\n          1.2474e-01, -7.2886e-02, -1.8009e-01, -4.1660e-02, -8.6441e-02,\n          1.9094e-01,  1.3250e-01,  1.4059e-01,  6.6710e-02,  7.5823e-02,\n          1.9372e-01, -2.0614e-01,  5.7357e-02, -1.0926e-01, -8.4412e-02],\n        [ 2.0960e-01,  1.6937e-01,  4.8988e-02, -1.3107e-01,  1.7282e-01,\n         -1.8700e-01,  1.9868e-02,  6.8664e-02,  7.0771e-02, -2.2146e-01,\n         -3.2108e-02, -1.9695e-01, -1.7160e-02, -1.9212e-01, -1.8258e-01,\n          1.0010e-01,  9.3952e-02, -5.2388e-02, -1.2732e-01,  8.1828e-02],\n        [ 2.5657e-03,  1.8541e-01,  1.5245e-01, -8.8355e-02, -2.0725e-01,\n          1.1448e-01,  3.4023e-02,  2.1367e-01, -9.6168e-03,  1.5761e-01,\n          4.4120e-02, -1.1626e-01,  1.1868e-01, -8.8313e-02,  3.9313e-02,\n         -5.6307e-02,  2.2309e-01, -1.0883e-01,  1.4511e-01,  1.4748e-01],\n        [-5.0834e-02,  1.0610e-01,  2.0941e-01, -1.9619e-02, -1.6665e-01,\n         -1.7797e-01,  1.7652e-02, -2.5802e-03,  1.8771e-02, -1.1897e-01,\n          1.9541e-01,  1.7555e-01, -1.1839e-01, -1.8989e-01, -9.8611e-03,\n          1.3915e-02, -1.9495e-01,  2.0358e-01,  8.8915e-02,  2.0769e-01],\n        [-1.2355e-01,  3.0323e-02,  2.0515e-01, -1.0010e-01, -1.4435e-01,\n          1.3475e-01,  1.8629e-01,  2.1407e-01,  1.0146e-01,  4.4326e-02,\n          3.9130e-03,  1.6151e-01, -2.1560e-01, -1.4301e-01,  1.1444e-01,\n          6.1485e-02,  1.4109e-01,  6.4085e-02, -5.9148e-02, -1.4727e-01],\n        [-8.9458e-02, -1.7544e-01, -1.3932e-01, -4.6214e-03, -4.9997e-02,\n          2.0943e-01, -1.7251e-01, -7.8386e-02, -1.7451e-01,  2.0069e-01,\n         -7.3460e-02,  7.4718e-02,  2.2191e-01,  1.7720e-01,  1.6905e-01,\n         -1.3016e-01,  1.7583e-01, -1.4857e-01, -1.0721e-01, -6.2239e-02],\n        [-7.6798e-02,  1.4490e-01,  1.4281e-01, -2.2020e-01, -1.4390e-01,\n          1.4864e-01,  1.0360e-01,  2.0178e-01,  6.1626e-02,  1.4065e-02,\n         -9.6833e-02,  1.8359e-01, -1.4067e-01, -1.3019e-01,  1.8796e-01,\n         -4.9302e-02,  3.2198e-02, -3.4228e-03,  1.9134e-01, -1.0085e-01],\n        [ 1.6375e-01,  1.4070e-01, -3.0790e-02, -1.7020e-02,  1.7240e-01,\n          2.0306e-01,  2.1816e-01, -8.7412e-03, -3.5989e-02,  1.9281e-01,\n          6.9233e-02, -2.6296e-03, -1.1492e-01,  1.0024e-01, -2.0138e-01,\n          2.9013e-02, -7.5215e-02,  1.7882e-01, -1.0183e-01, -1.2024e-01],\n        [-8.7033e-02, -9.9656e-02, -8.2036e-02,  2.0027e-01,  1.0314e-01,\n          2.1588e-01, -2.0641e-01,  9.5514e-02, -1.4691e-01,  2.1287e-01,\n          3.8183e-02, -1.2590e-01, -1.0019e-01, -7.6539e-02,  5.1698e-02,\n         -1.4372e-01,  8.4545e-02,  1.0977e-01, -1.0075e-01,  9.9739e-02],\n        [ 1.4618e-02, -1.1160e-01,  2.1497e-01,  4.5718e-02, -1.5091e-01,\n         -6.2664e-03,  1.6300e-01, -2.7342e-02, -2.3088e-02,  4.0817e-02,\n         -5.9655e-02,  2.1537e-01, -2.1514e-01,  6.4727e-02,  4.7034e-02,\n          1.6799e-01,  6.6313e-02, -9.5410e-02, -1.0792e-01,  9.6092e-02],\n        [ 1.9912e-01,  1.0040e-01,  6.3510e-03, -1.6498e-01,  2.0298e-02,\n          1.9455e-01,  8.3528e-02,  9.7555e-02, -1.7776e-01,  5.7936e-02,\n         -4.2144e-02, -1.9284e-01, -1.4968e-01,  1.6038e-01,  4.4854e-02,\n          1.5633e-01,  1.9698e-01, -1.2182e-01, -2.7329e-02, -5.5481e-02],\n        [ 2.8251e-02,  7.7269e-02, -2.7250e-02, -2.1260e-01,  1.6188e-01,\n          6.6098e-02, -6.9047e-02,  2.5005e-02,  1.4513e-01,  1.7541e-01,\n         -1.2044e-01, -2.2152e-01, -1.2170e-01,  7.2714e-02,  8.1523e-02,\n         -1.3713e-02,  1.6591e-01, -1.9219e-01, -5.6916e-02, -2.2284e-01],\n        [-3.8834e-02,  1.8928e-01, -1.6646e-01,  1.9702e-01, -4.0562e-03,\n          1.0560e-01, -1.1601e-01, -9.9153e-02,  9.8485e-02, -9.3274e-02,\n         -2.1937e-01,  3.3612e-02, -8.0778e-02,  1.9822e-01,  9.4200e-02,\n         -9.5188e-02,  4.5762e-02,  1.5255e-01,  2.0802e-01,  1.0956e-01],\n        [-5.0886e-02, -9.2553e-02, -1.7384e-01,  5.1622e-02,  5.0171e-02,\n          1.2184e-01, -8.4943e-02, -1.0372e-01, -1.2981e-01, -3.5130e-02,\n          8.4108e-02,  7.9080e-02, -2.0090e-01,  7.4513e-03, -1.8908e-01,\n         -1.9989e-01, -1.1195e-01, -2.1536e-01,  6.3462e-02, -1.0247e-02],\n        [ 2.6346e-02, -2.1372e-01, -7.8703e-02,  5.5594e-02, -8.7413e-02,\n          2.0372e-01,  1.4965e-02,  2.0087e-01, -6.1256e-02, -1.3898e-01,\n         -1.4168e-01,  1.8731e-02, -1.7891e-01, -2.0025e-01,  2.6904e-02,\n         -5.0214e-02,  8.5858e-02, -3.6991e-02,  1.2769e-01,  2.0909e-01],\n        [-6.7819e-02, -3.9387e-04,  4.6367e-02,  1.7646e-01, -3.0685e-03,\n          6.0394e-02,  1.0514e-01,  1.0718e-01, -3.3430e-03,  1.2943e-01,\n         -1.6791e-02,  2.4313e-02, -1.6723e-01,  1.9767e-01,  1.4120e-01,\n          1.1266e-01, -2.9077e-03, -1.8972e-01, -2.9397e-02, -1.6682e-01],\n        [ 5.7244e-02, -5.8025e-02,  1.2087e-01, -8.0549e-02, -8.3732e-02,\n         -4.0941e-02,  2.1025e-01,  8.7276e-02,  1.4374e-01, -1.3604e-01,\n          4.3719e-04, -1.5073e-01, -4.7240e-02,  1.0547e-01, -1.5986e-01,\n         -2.2273e-02,  9.6040e-02, -2.0192e-01, -1.9246e-01, -5.1321e-03],\n        [-3.4568e-02, -7.8596e-02,  9.8409e-02, -1.9450e-01,  1.5686e-01,\n          7.0411e-02, -9.7590e-02, -1.9407e-01,  8.6669e-02,  9.0771e-03,\n         -1.0560e-01, -1.1568e-01,  1.3155e-01, -1.4383e-01, -6.6254e-02,\n          3.7938e-02, -1.2604e-02,  2.2358e-01,  1.8040e-01, -9.9302e-02],\n        [-2.1986e-01,  1.6893e-01, -1.3870e-01, -6.2892e-02, -2.1910e-01,\n         -2.2594e-02,  3.5104e-02, -5.3939e-02,  6.5472e-02,  3.7406e-02,\n          2.0327e-01,  4.9990e-02, -1.5522e-01,  2.0253e-01,  4.2758e-02,\n         -2.0929e-01, -1.6943e-01,  1.3685e-01,  1.0731e-01,  1.0756e-01],\n        [ 1.7817e-01, -6.6027e-02,  4.8001e-02, -1.7670e-01,  1.1340e-01,\n         -2.1854e-01,  2.2095e-01,  1.1050e-01, -1.8222e-02,  1.3987e-01,\n         -9.0680e-02,  1.2865e-01, -5.5998e-02,  8.1445e-02,  7.5347e-02,\n          9.6755e-02,  2.0489e-01, -2.2078e-01,  2.1200e-01,  2.4993e-02],\n        [ 7.9358e-02,  2.2200e-01, -6.0424e-02, -1.0485e-01, -1.7230e-01,\n         -1.7200e-01,  1.3768e-01,  7.2528e-02, -1.3857e-01,  1.0092e-01,\n          1.9745e-01, -1.6288e-01,  3.8970e-03,  2.1039e-01,  1.6575e-04,\n          8.6236e-02,  1.2618e-01, -1.5527e-01,  1.6011e-02, -1.0337e-02],\n        [-2.2304e-01,  1.2066e-02,  1.3371e-01, -3.8224e-02, -3.1041e-03,\n          1.1506e-01,  1.1764e-01,  7.4544e-02,  1.7466e-01, -1.3841e-01,\n         -1.1114e-01,  7.9010e-02,  2.1000e-01,  1.9150e-01,  1.1395e-01,\n         -1.4695e-01,  1.2336e-01,  1.0178e-01,  6.8969e-02,  1.6878e-01],\n        [-6.6863e-02, -2.1099e-01,  2.0291e-01, -1.6923e-01, -1.4169e-01,\n          5.2131e-02,  4.1343e-02, -1.9399e-02, -1.8153e-01, -2.1769e-01,\n         -2.2074e-01, -2.6875e-02,  1.6033e-01, -1.3501e-01, -2.0063e-01,\n          5.4572e-02,  7.6367e-02, -8.9225e-02, -1.3864e-01, -1.0063e-01],\n        [-9.2912e-02, -1.4922e-01,  4.4485e-02,  1.4156e-01,  2.0624e-01,\n         -1.6953e-01, -2.7812e-02,  1.0863e-01,  1.7192e-01, -1.1652e-01,\n          6.7065e-02,  1.6046e-01, -3.4697e-02,  5.0684e-02, -3.5490e-02,\n          1.0551e-02,  1.3386e-01,  1.2104e-03, -1.2591e-01,  1.8619e-01],\n        [-1.5959e-01,  1.3705e-01,  2.0664e-01,  1.0801e-02, -1.7683e-01,\n         -8.8577e-02,  5.1967e-02,  1.8415e-01,  5.0406e-02, -1.3490e-01,\n         -8.5316e-02, -2.4693e-02, -1.9218e-01,  2.0332e-01,  1.6252e-01,\n          3.2910e-02, -7.8091e-02, -1.4149e-01, -8.9178e-02, -2.0909e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2059, -0.0308,  0.1669,  0.2233, -0.0429,  0.1891, -0.1770, -0.1720,\n        -0.0120, -0.1850, -0.2102, -0.1549, -0.1451,  0.0427, -0.1361,  0.1775,\n         0.1669,  0.0450, -0.0311, -0.0953, -0.1148, -0.1621,  0.0747,  0.1458,\n        -0.1784,  0.0542,  0.0056, -0.1645,  0.1009,  0.0550,  0.0375,  0.1024],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0360,  0.0733, -0.1738, -0.1528, -0.0373, -0.1374, -0.1141, -0.0864,\n          0.0022, -0.0030,  0.0775,  0.0189, -0.0907,  0.1048, -0.1390,  0.0144,\n         -0.1306, -0.1305, -0.0800, -0.0618,  0.0943, -0.0237,  0.0030, -0.0561,\n         -0.1730, -0.1674,  0.0312,  0.0823,  0.0422, -0.1235, -0.1290,  0.1599],\n        [ 0.1640,  0.1032, -0.1056,  0.1280,  0.0279,  0.0224, -0.1457,  0.0435,\n          0.0749,  0.0296,  0.1387,  0.0771,  0.0492,  0.0436, -0.1125, -0.1383,\n          0.0366, -0.1489,  0.0322,  0.1197, -0.0601, -0.1515,  0.0469,  0.1055,\n         -0.1372, -0.0249,  0.1096,  0.0710, -0.1052, -0.1432,  0.0469,  0.1448],\n        [ 0.0831,  0.1762,  0.1478,  0.1146,  0.1592, -0.1556,  0.1540,  0.0880,\n         -0.1640, -0.1572, -0.0202, -0.1759,  0.0613, -0.0278,  0.0150,  0.0648,\n         -0.1499,  0.0649,  0.1545, -0.0673, -0.0607,  0.0936, -0.1329,  0.1246,\n          0.0589,  0.0491,  0.1386, -0.1565, -0.0730,  0.0372, -0.0309,  0.0966],\n        [ 0.0232,  0.1193,  0.0082, -0.0940, -0.0295,  0.1643, -0.1121, -0.0505,\n         -0.1562,  0.0551, -0.1078,  0.1336,  0.0198, -0.1490,  0.1100, -0.1489,\n         -0.0540,  0.1408, -0.0363, -0.0108, -0.1306,  0.0213, -0.1187,  0.0488,\n          0.0094, -0.0558,  0.1692,  0.1394,  0.1396,  0.1059,  0.0279,  0.0187],\n        [ 0.0638,  0.0968, -0.0747, -0.0158,  0.0672, -0.0920,  0.1108,  0.0415,\n         -0.0127, -0.0500,  0.0424,  0.0451, -0.1611,  0.1220,  0.1128,  0.0589,\n          0.1445, -0.1125, -0.1373,  0.0470,  0.1336,  0.1364, -0.1734,  0.0033,\n         -0.0957, -0.0359, -0.0730,  0.0652, -0.0586,  0.1752,  0.1012, -0.0523],\n        [ 0.0837, -0.0076, -0.1465,  0.0195, -0.1437,  0.1665, -0.0562,  0.0666,\n         -0.1654,  0.1722,  0.1448, -0.0452,  0.0224, -0.0824, -0.1514, -0.1382,\n          0.0941,  0.1528, -0.1091, -0.1413,  0.0070, -0.1041,  0.0716,  0.1394,\n          0.1520, -0.1138,  0.0112, -0.0651, -0.0434,  0.0787,  0.0758,  0.0565],\n        [ 0.0870, -0.0212,  0.0295,  0.0653,  0.1031, -0.0577,  0.1232,  0.0481,\n          0.0848,  0.1604,  0.0414, -0.0749,  0.1403, -0.0376, -0.1103, -0.0894,\n          0.1158,  0.1499,  0.0400, -0.1490,  0.0125, -0.1081,  0.0787, -0.1400,\n          0.1281, -0.0004, -0.1300, -0.0705, -0.1210,  0.0363, -0.1469,  0.0569],\n        [ 0.0468,  0.1283, -0.0688,  0.1503, -0.0371, -0.0730,  0.0163,  0.0939,\n         -0.1276,  0.0070, -0.0098,  0.1353,  0.0423,  0.1730, -0.1466, -0.1124,\n         -0.0964, -0.1172,  0.0868, -0.0753, -0.0469,  0.1188,  0.1531,  0.0153,\n         -0.1503,  0.0168,  0.0412, -0.0892,  0.0963, -0.1735, -0.0863, -0.0958],\n        [-0.1299, -0.0273, -0.0710,  0.0375, -0.1027,  0.0671, -0.1389,  0.0835,\n         -0.1149, -0.1091, -0.0328, -0.0664,  0.0493, -0.1206, -0.0602,  0.0970,\n         -0.0099,  0.1122,  0.1352,  0.0105,  0.0618, -0.0391,  0.0610,  0.1455,\n          0.1460,  0.0393,  0.0124,  0.1497, -0.0175, -0.0824,  0.1242,  0.1389],\n        [-0.0768,  0.0686, -0.0578, -0.0573, -0.0584, -0.0240, -0.0110,  0.1534,\n          0.0954, -0.1462, -0.0534, -0.0138, -0.1528,  0.0408, -0.0542, -0.0023,\n          0.0969, -0.0071, -0.1742,  0.0631,  0.0338, -0.0761, -0.1328, -0.1227,\n         -0.0275, -0.0649, -0.0158,  0.0935,  0.1133,  0.1296,  0.0645, -0.1430],\n        [-0.0515,  0.0789, -0.0235, -0.1357,  0.0727,  0.1390,  0.0847, -0.0784,\n          0.0563, -0.1195, -0.1572, -0.0079, -0.1057,  0.0463,  0.0546,  0.0262,\n         -0.0808,  0.0278, -0.0467,  0.0495, -0.1652,  0.0217, -0.0653,  0.0531,\n         -0.0535, -0.0747,  0.0370,  0.0944, -0.0418,  0.0133, -0.0993,  0.1167],\n        [-0.0996, -0.1192, -0.1591,  0.1189, -0.0565, -0.1682, -0.0583,  0.0241,\n          0.1469,  0.1735, -0.0931,  0.0382, -0.1432,  0.0666,  0.1459, -0.0613,\n          0.0588, -0.0310,  0.0169,  0.1608,  0.1384,  0.1578,  0.0569, -0.0458,\n         -0.0321, -0.0396,  0.0535, -0.0315,  0.0200,  0.0250,  0.0531, -0.0482],\n        [ 0.0781,  0.0836,  0.1450,  0.0480, -0.0841, -0.0703, -0.0726, -0.1030,\n         -0.1298,  0.0647, -0.0676, -0.0073, -0.0990,  0.1322,  0.0204, -0.0402,\n         -0.0413,  0.1722, -0.1449, -0.0583,  0.1094,  0.1605,  0.0753,  0.0307,\n         -0.0156, -0.0999, -0.0027, -0.0884, -0.1653,  0.0952,  0.0296,  0.0512],\n        [ 0.0472,  0.1746,  0.0448,  0.0417,  0.1201,  0.1087,  0.1252, -0.0678,\n         -0.0162,  0.1240, -0.0848,  0.0748, -0.1498,  0.1294,  0.0174,  0.0856,\n         -0.0852, -0.0202,  0.1722, -0.1768,  0.1309, -0.0989, -0.1062, -0.0390,\n          0.0744, -0.1024,  0.0221,  0.1003, -0.1617, -0.0776, -0.1030, -0.1292],\n        [-0.1302, -0.1148, -0.0572,  0.0381, -0.1078,  0.0036,  0.1362, -0.0277,\n         -0.1359,  0.0197, -0.0096,  0.1378,  0.1445,  0.1615,  0.1280, -0.0068,\n         -0.0663,  0.0371, -0.0270, -0.0367, -0.1712, -0.1681,  0.0928, -0.1260,\n         -0.1741,  0.0858, -0.0846,  0.0863, -0.1330,  0.1283, -0.1201, -0.0994],\n        [ 0.1089,  0.1716, -0.1689,  0.1515,  0.0591,  0.0209, -0.0224, -0.1636,\n          0.1324, -0.0368,  0.0454, -0.1473, -0.1463,  0.1101, -0.0268,  0.1121,\n          0.1323,  0.0781,  0.1749, -0.1208, -0.0423, -0.0615, -0.0098, -0.0344,\n          0.0488,  0.0500, -0.1589,  0.0817, -0.0122,  0.0080,  0.0416,  0.1349]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1445,  0.1683,  0.0327,  0.0260, -0.1136,  0.0476,  0.0492, -0.1374,\n         0.0941,  0.0984, -0.1606,  0.1702,  0.1035, -0.1050,  0.0226, -0.0644],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0161,  0.1703, -0.0769,  0.1916, -0.1058, -0.1985,  0.1694, -0.1366,\n         -0.0919, -0.2359,  0.1201,  0.1380,  0.0506,  0.0047,  0.1061,  0.0552],\n        [ 0.2066, -0.2274,  0.2013, -0.1045, -0.2146, -0.0711,  0.0658, -0.1044,\n          0.0728,  0.0799, -0.0708,  0.0881,  0.1238, -0.1409,  0.1231, -0.0912],\n        [-0.1428,  0.0524,  0.2006,  0.1229, -0.0165,  0.1642,  0.0555,  0.0106,\n         -0.0476,  0.2002, -0.2459, -0.2224, -0.0604,  0.0138,  0.2069,  0.1542],\n        [-0.1063,  0.2413, -0.0152,  0.1964, -0.2006,  0.2131,  0.0580, -0.0891,\n         -0.2056, -0.2221,  0.1485, -0.0824, -0.1535,  0.1804, -0.0765,  0.0442],\n        [ 0.1742, -0.0716,  0.2234,  0.0601, -0.1727,  0.0861, -0.2432, -0.0485,\n          0.1298,  0.0499, -0.1355,  0.0936, -0.1021,  0.0475, -0.0187, -0.1698],\n        [-0.1160,  0.2232,  0.0401,  0.0497, -0.1486,  0.1854, -0.1029,  0.2288,\n         -0.0315,  0.2084,  0.1356, -0.0923,  0.0435, -0.2189, -0.1289, -0.0948],\n        [ 0.0839, -0.1289, -0.0891, -0.0226,  0.1308, -0.0796,  0.1566,  0.0948,\n         -0.0414, -0.0239,  0.2468,  0.2290,  0.2234,  0.0081, -0.2369, -0.1701],\n        [ 0.1180,  0.1938,  0.0294, -0.1317,  0.0025,  0.0358,  0.0932,  0.1248,\n         -0.1665,  0.1703,  0.1945,  0.1680,  0.2435, -0.0679, -0.2063,  0.1824]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1023, -0.0410, -0.0197, -0.1280,  0.1171,  0.0262, -0.2321,  0.1146],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0600,  0.0253,  0.2862, -0.1646, -0.2817, -0.2346, -0.3366, -0.3401]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2303], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x0000023A1D7AF070>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-ppo-info\\rl4sys-ppo-info_s164640000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='D:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\maze-game\\\\./logs/rl4sys-ppo-info\\\\rl4sys-ppo-info_s164640000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	40,
    "train_v_iters":	40,
    "traj_per_epoch":	5,
    "vf_lr":	0.0003
}