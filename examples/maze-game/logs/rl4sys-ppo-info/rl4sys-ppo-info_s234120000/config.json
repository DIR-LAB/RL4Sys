{
    "__class__":	"PPO",
    "buf_size":	50000,
    "clip_ratio":	0.1,
    "env_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game",
    "exp_name":	"rl4sys-ppo-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	5,
    "lam":	0.97,
    "log_data_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-info",
        "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-ppo-info\\rl4sys-ppo-info_s234120000"
    },
    "pi_lr":	0.0003,
    "seed":	234120000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x000001312D79EC80>":	{
            "_clip_ratio":	0.1,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (pi_network): Sequential(\n      (0): Linear(in_features=4, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n    )\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (pi_network): Sequential(\n    (0): Linear(in_features=4, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-2.9443e-01,  3.2479e-01,  4.6133e-01,  2.4609e-01, -3.7585e-01,\n         4.8005e-01,  1.8530e-01,  3.5669e-01,  3.4416e-01, -4.9966e-01,\n         2.4421e-01, -4.9625e-01, -4.6373e-01, -3.8862e-01, -3.2765e-01,\n         3.8421e-04,  2.8529e-01, -2.9218e-01,  1.8187e-01, -2.8287e-01,\n         1.5504e-01,  4.7146e-01,  7.5392e-02,  3.4499e-01, -2.4821e-01,\n         2.2887e-01, -5.1911e-02,  9.3081e-02,  4.7103e-01,  2.5730e-01,\n         2.4778e-01,  3.0837e-01], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0368,  0.4024,  0.0600,  0.3453],\n        [ 0.2569, -0.2270,  0.3931,  0.0276],\n        [ 0.4580, -0.4917, -0.2337, -0.2198],\n        [ 0.2807, -0.2251,  0.2905, -0.2077],\n        [-0.1562,  0.2983,  0.1265,  0.4048],\n        [ 0.2391,  0.1715, -0.4767,  0.1850],\n        [-0.1136, -0.4741,  0.2751, -0.2583],\n        [-0.3602,  0.0585,  0.4408,  0.2939],\n        [ 0.1330,  0.4988, -0.1246,  0.0664],\n        [-0.0939, -0.2940, -0.3858, -0.1416],\n        [-0.3928,  0.3728,  0.2947, -0.3038],\n        [-0.3983,  0.2546, -0.3054, -0.4755],\n        [-0.2352, -0.2763,  0.4421, -0.2853],\n        [-0.3196,  0.1075, -0.3576,  0.2864],\n        [ 0.3824, -0.0215,  0.1759, -0.0954],\n        [-0.2932,  0.3822,  0.3044,  0.3285],\n        [ 0.2993,  0.4683,  0.1917,  0.0222],\n        [-0.1020,  0.4192,  0.4739,  0.2653],\n        [-0.2209,  0.0018,  0.3842,  0.4383],\n        [ 0.3849, -0.2940, -0.3884,  0.0481],\n        [ 0.4166,  0.3954, -0.2288,  0.4804],\n        [ 0.2113, -0.3466,  0.2230, -0.2613],\n        [ 0.1275,  0.1468, -0.0662, -0.0072],\n        [ 0.3353, -0.2327,  0.2842,  0.0240],\n        [-0.0249,  0.1615,  0.2849,  0.2310],\n        [-0.3452,  0.4031,  0.4414, -0.2418],\n        [-0.2414, -0.2988, -0.3245,  0.1019],\n        [ 0.3524,  0.2812, -0.3571,  0.2165],\n        [-0.3717, -0.4497,  0.1197, -0.2254],\n        [-0.1188,  0.0432,  0.3604,  0.0149],\n        [ 0.2204, -0.0609,  0.3123, -0.3263],\n        [ 0.3863, -0.0301, -0.0311, -0.4649]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1304, -0.1744, -0.0228,  0.0108,  0.1068, -0.1648,  0.1286, -0.0491,\n         0.0442, -0.0966,  0.1407,  0.0479,  0.1127, -0.0289,  0.1230,  0.1060],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0442, -0.1506, -0.1671,  0.0383, -0.0648,  0.1386, -0.0970,  0.1537,\n         -0.0795,  0.1294, -0.0208, -0.0617, -0.1275, -0.1626, -0.1338, -0.0897,\n         -0.0043,  0.1494,  0.0580,  0.0182, -0.0586, -0.1635,  0.1469,  0.1475,\n          0.0665,  0.1081,  0.1365,  0.0712, -0.1280,  0.0392, -0.1629,  0.1679],\n        [-0.1648,  0.1500,  0.1489, -0.0986, -0.0754,  0.1281, -0.0626, -0.1681,\n          0.1380, -0.0887, -0.0586, -0.0145, -0.1199,  0.0027,  0.0206,  0.1111,\n         -0.0429, -0.0856, -0.0281, -0.0758,  0.1139,  0.1314, -0.0464, -0.1716,\n         -0.0017, -0.1691, -0.1148,  0.0647, -0.1696,  0.1050, -0.0986,  0.0438],\n        [ 0.0364,  0.0788, -0.0793,  0.1406,  0.0294, -0.1546,  0.1236,  0.1441,\n         -0.1308, -0.0822, -0.1363,  0.1289, -0.0166, -0.0310, -0.0343,  0.0715,\n          0.1010, -0.1321, -0.0389, -0.0667,  0.1747, -0.1699,  0.0226, -0.0893,\n         -0.1737, -0.1562, -0.0080, -0.1064, -0.0051,  0.0213, -0.1542, -0.0463],\n        [ 0.0906, -0.0533, -0.1000, -0.1509, -0.0283, -0.0198,  0.1749,  0.0586,\n          0.0735, -0.0018, -0.1728,  0.1311, -0.1230,  0.0360,  0.1448,  0.1320,\n         -0.0936,  0.0719, -0.0595, -0.0232,  0.1315, -0.0210,  0.1080, -0.1695,\n         -0.0139,  0.1029, -0.0682, -0.0851, -0.0401,  0.1352, -0.0809, -0.0500],\n        [ 0.1727,  0.1645, -0.1692, -0.1575,  0.1717,  0.1379, -0.1350,  0.1140,\n          0.1126, -0.1427,  0.0366,  0.1329,  0.1223, -0.0503, -0.0983, -0.0651,\n         -0.0543,  0.1743,  0.1033,  0.1593, -0.0790,  0.0392,  0.1520, -0.1455,\n          0.0290,  0.1222, -0.0762,  0.0695, -0.0713,  0.0387,  0.1571,  0.0556],\n        [-0.1071, -0.0203, -0.1482, -0.1467, -0.1259,  0.1273,  0.0343,  0.1767,\n          0.1361,  0.1704, -0.1241, -0.1145, -0.1031, -0.0325,  0.0421, -0.1557,\n          0.0043, -0.0286, -0.1630,  0.1282,  0.0942, -0.1501,  0.0839,  0.1086,\n          0.0926, -0.0810, -0.0997, -0.1153, -0.1281,  0.1083, -0.1631, -0.0374],\n        [-0.1406, -0.1727, -0.0627,  0.1668,  0.0837,  0.0692,  0.0608,  0.1486,\n          0.0460, -0.0286, -0.1139,  0.0219,  0.0667,  0.0298, -0.1635,  0.1261,\n         -0.0956,  0.1505,  0.0180, -0.0599,  0.0951,  0.0409, -0.1238,  0.0480,\n         -0.0577,  0.1531,  0.1227,  0.0477,  0.0964,  0.1129,  0.1685, -0.0394],\n        [-0.1724,  0.1592, -0.1363,  0.0671, -0.1621, -0.0820, -0.1385, -0.1163,\n          0.0669, -0.0194, -0.1025, -0.0667,  0.0773,  0.1249,  0.1378, -0.1665,\n          0.1300, -0.0927,  0.1624, -0.0124,  0.0840, -0.0431,  0.0172,  0.0670,\n          0.1546,  0.0580, -0.1088,  0.1670, -0.0987,  0.0384, -0.1486, -0.0113],\n        [-0.0323,  0.1017, -0.0360, -0.0653,  0.0232, -0.0530,  0.1017,  0.0531,\n         -0.0907, -0.1340,  0.0564, -0.0777, -0.0810,  0.0225, -0.1749, -0.0956,\n         -0.1127,  0.0381, -0.0650,  0.0404,  0.1045,  0.0859, -0.1024, -0.1534,\n          0.1569,  0.0575, -0.1585,  0.1513,  0.0936, -0.0367, -0.1412,  0.0336],\n        [-0.1111, -0.1634,  0.1363,  0.0306, -0.1508,  0.0719, -0.0837, -0.0710,\n         -0.1702, -0.1020,  0.1157, -0.0204, -0.1577,  0.0154, -0.1180,  0.0737,\n          0.1162,  0.0494, -0.1670, -0.1518, -0.1124, -0.1140, -0.0984,  0.1746,\n         -0.1072, -0.1521,  0.1044, -0.0718, -0.0899, -0.0580, -0.1269, -0.1182],\n        [-0.0419, -0.1412, -0.0643, -0.0468,  0.1596, -0.1482,  0.1534,  0.1094,\n          0.0974, -0.0450,  0.0751,  0.0377,  0.1083, -0.1182, -0.1605,  0.1411,\n         -0.1753,  0.1274,  0.0549,  0.1112, -0.0514,  0.1766,  0.0851,  0.0198,\n          0.0532,  0.0928,  0.1533, -0.1046,  0.1320,  0.1471,  0.1499, -0.0195],\n        [ 0.0083,  0.0114,  0.1308, -0.0467,  0.1442, -0.1748,  0.1120,  0.0434,\n          0.1716,  0.0321, -0.0674,  0.1009,  0.0056,  0.0297,  0.0081,  0.1489,\n          0.0876, -0.0880, -0.0327, -0.0525, -0.1537,  0.1718,  0.1155,  0.1337,\n         -0.0159, -0.1637, -0.0504,  0.1282,  0.0002,  0.1561, -0.0623, -0.0856],\n        [-0.0806,  0.0462,  0.0383,  0.0145,  0.0945,  0.1604, -0.0035,  0.0655,\n         -0.0642,  0.1499, -0.0773, -0.1591, -0.1551,  0.0526, -0.0840,  0.0201,\n          0.0176,  0.0336,  0.1357, -0.1702,  0.1497,  0.0667,  0.1735,  0.0887,\n         -0.0480, -0.1754, -0.1540, -0.0661, -0.1212, -0.0230, -0.1166, -0.1326],\n        [ 0.0995, -0.0861,  0.0940,  0.0550, -0.1663, -0.0824, -0.0041, -0.1409,\n          0.1682,  0.0679,  0.1166,  0.0314, -0.1112, -0.0052, -0.1232,  0.1150,\n         -0.0290,  0.1487, -0.1354, -0.1073,  0.0484,  0.1268,  0.0908, -0.0342,\n          0.0545,  0.1256, -0.0577, -0.0280,  0.1321, -0.1477,  0.1041,  0.1255],\n        [-0.1426,  0.0026, -0.0204,  0.1475,  0.1150,  0.0917,  0.1516,  0.0419,\n         -0.0091, -0.1764,  0.0116,  0.1581, -0.1557, -0.0805,  0.0812,  0.0716,\n          0.0300,  0.0137, -0.0169, -0.1627, -0.0574,  0.0835, -0.0929, -0.0965,\n         -0.1683, -0.0779,  0.0283, -0.0158,  0.0861, -0.1047, -0.0380,  0.0080],\n        [ 0.1648, -0.0643, -0.1304, -0.0191, -0.0213,  0.1346,  0.1490, -0.0874,\n         -0.0309, -0.0947, -0.0343,  0.1389,  0.1028, -0.1216, -0.0068,  0.1111,\n          0.1585, -0.0650,  0.1068, -0.1163, -0.1101, -0.0578,  0.1281,  0.1692,\n         -0.1212,  0.0062,  0.1514,  0.0958,  0.1006, -0.0752, -0.1687,  0.1096]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0499,  0.2223,  0.0822,  0.0336,  0.0888, -0.1864,  0.0241, -0.1762],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0535,  0.0804,  0.2073,  0.1414, -0.0090,  0.2401,  0.1719, -0.2096,\n         -0.0968,  0.2273,  0.1979, -0.0618, -0.2473, -0.2461, -0.0553,  0.1361],\n        [-0.2414,  0.0951,  0.1976, -0.1897,  0.1271, -0.0909, -0.0502, -0.0280,\n         -0.1980,  0.1283,  0.1878,  0.1932, -0.1429,  0.2146, -0.0501,  0.1161],\n        [ 0.1670, -0.0665, -0.1960,  0.1711,  0.1570,  0.1939,  0.0818, -0.0222,\n         -0.0239, -0.0107, -0.0967, -0.0516, -0.0986, -0.0204,  0.1092, -0.0211],\n        [-0.1283,  0.0566,  0.0382, -0.1819, -0.1606, -0.1696, -0.1285,  0.1212,\n         -0.0435, -0.1686,  0.1286,  0.1050,  0.0719, -0.0760, -0.0588, -0.1265],\n        [ 0.1250, -0.2150,  0.0617, -0.0153,  0.0890, -0.0962,  0.0445,  0.0660,\n          0.2398, -0.1879,  0.2033,  0.0211, -0.0261,  0.0531,  0.1679,  0.0020],\n        [ 0.1636, -0.1859,  0.0430, -0.1646, -0.1885,  0.1852,  0.0099, -0.1994,\n          0.0027, -0.0050,  0.0356,  0.1810,  0.2432,  0.1125, -0.1774, -0.2149],\n        [ 0.0984,  0.1936, -0.1188, -0.2440, -0.1157,  0.2224, -0.0339, -0.1610,\n          0.2184, -0.0055, -0.2374,  0.2426, -0.1583,  0.1855,  0.1557, -0.0381],\n        [-0.1773, -0.2138,  0.2183,  0.0822,  0.1656,  0.0945, -0.1027,  0.0015,\n          0.0829,  0.0185, -0.0541,  0.1436, -0.0708, -0.0917, -0.0253,  0.2451]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([0.0617], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.2424,  0.2518,  0.2620, -0.0609, -0.2526,  0.0120, -0.1657, -0.3074]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "kernel_dim":	4,
                                "kernel_size":	5,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1318, -0.0659,  0.1274,  0.1155, -0.1115,  0.2207,  0.1279, -0.0134,\n        -0.1960,  0.0985, -0.2158, -0.1411,  0.1374, -0.0316, -0.1732,  0.1169,\n         0.1711,  0.0068, -0.2036,  0.1954,  0.1077, -0.2168,  0.0714, -0.2155,\n        -0.0622,  0.0077, -0.0289, -0.1352, -0.0493,  0.0433, -0.2080, -0.1268],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-9.9820e-02, -2.2063e-01,  2.9930e-02, -2.2292e-01, -2.1637e-01,\n         -2.4615e-02, -5.9852e-03, -1.8134e-01,  2.9113e-02,  2.2170e-01,\n          1.7326e-01,  1.9996e-01, -1.0634e-01, -4.1951e-02, -4.8759e-02,\n          1.2669e-01, -1.3048e-01, -7.5952e-02, -1.9501e-01,  8.6309e-02],\n        [ 1.1273e-04, -1.2409e-01, -7.9147e-02,  1.0885e-01, -1.4132e-01,\n          1.9371e-01,  1.0285e-01,  5.5946e-03, -1.9811e-01, -2.7686e-02,\n          7.5364e-03,  1.2913e-01, -4.3773e-02, -1.0011e-01, -1.4594e-01,\n          1.9275e-01,  2.3091e-02, -1.0484e-01, -5.4072e-02, -1.2169e-01],\n        [ 1.9869e-01, -1.2535e-01,  2.0284e-01, -5.6657e-02,  2.2015e-01,\n          1.3395e-01, -8.9288e-02, -1.5905e-01,  1.1149e-01,  3.1996e-02,\n         -4.6082e-02, -7.5015e-03,  5.0891e-02, -2.5076e-02, -1.3623e-01,\n          2.6895e-02,  1.5190e-01, -1.8198e-01, -2.8860e-02, -1.8120e-01],\n        [-2.3963e-02,  1.1111e-01,  7.9868e-02,  8.6052e-02, -1.9419e-01,\n         -2.1832e-02,  1.0333e-01, -1.4896e-01, -1.6512e-01,  1.3112e-01,\n         -1.2819e-01, -1.5176e-01,  2.1036e-01,  1.9992e-02,  1.7036e-01,\n         -1.8521e-01,  3.5165e-02,  9.0741e-02, -4.1461e-02, -1.0878e-01],\n        [-1.2464e-01, -1.0445e-01,  2.3061e-02, -7.2700e-02,  2.0930e-01,\n         -1.7016e-01,  2.1333e-02,  1.7813e-01,  1.6024e-01,  2.1323e-01,\n          1.9511e-01, -6.2491e-02, -2.1426e-01,  6.2324e-02, -1.0862e-01,\n         -6.1957e-02, -3.8972e-03, -1.0904e-01, -1.4775e-01,  1.0917e-01],\n        [ 1.4610e-01,  9.4396e-02, -1.6531e-01,  1.7146e-01,  2.6236e-02,\n         -6.6667e-02,  1.7697e-01,  4.1700e-03, -1.9659e-01,  4.6971e-02,\n         -1.4129e-01,  3.2565e-02,  9.3983e-02,  1.6315e-01,  1.0273e-01,\n         -1.7593e-01,  2.9133e-02,  1.3196e-01, -2.1757e-01, -9.4674e-02],\n        [-3.8795e-02,  3.8133e-03,  1.8562e-01, -2.1653e-01, -7.0037e-02,\n         -6.7239e-02,  5.4953e-02, -1.8258e-01,  1.4685e-01, -9.3437e-02,\n         -4.2673e-02,  2.2046e-01, -1.0149e-01, -1.0695e-01,  3.2610e-02,\n          1.9327e-01, -2.3792e-02,  1.0041e-01,  1.2858e-01, -1.0499e-01],\n        [ 2.0492e-01, -1.3110e-01,  7.3145e-02, -1.4731e-01,  6.1030e-02,\n         -1.9201e-01,  1.6496e-01, -8.1341e-02, -3.7834e-02, -1.2704e-02,\n          1.6484e-01, -5.9799e-02, -1.1574e-02,  1.0745e-01,  1.8057e-01,\n         -4.5827e-02,  1.7822e-02, -1.0847e-01, -1.5267e-01, -1.8480e-01],\n        [-8.7041e-03,  1.1057e-01, -2.0292e-01, -6.8849e-03,  8.8728e-02,\n          1.4361e-01,  5.1850e-02, -1.6991e-01,  1.2777e-01,  2.0879e-01,\n         -4.8674e-02, -1.1717e-01, -1.9583e-01, -1.4494e-01, -1.1200e-01,\n          9.3929e-02, -8.7422e-02, -5.4267e-02, -6.8387e-02,  4.0077e-02],\n        [ 2.2093e-01, -1.8438e-01, -1.8151e-01, -4.8368e-02, -4.2641e-03,\n          1.2656e-01,  4.7209e-02, -1.4636e-02,  4.3442e-02,  1.5494e-01,\n         -2.0277e-01,  2.1508e-01, -9.0827e-02, -2.0719e-01, -3.3302e-02,\n         -2.1190e-01, -5.8787e-02, -9.9212e-02,  8.2616e-02,  9.8854e-02],\n        [-3.8102e-02,  3.7582e-02, -1.0490e-01,  1.7503e-01, -1.1278e-01,\n         -6.8854e-02,  8.2261e-02, -1.0807e-01,  1.1468e-01, -3.7257e-02,\n         -2.7683e-02,  1.5223e-01,  8.2185e-03,  8.9204e-02,  2.8618e-02,\n         -3.8596e-02, -1.4672e-01,  4.1602e-02, -2.2253e-01, -1.4508e-01],\n        [ 5.7196e-02,  2.2268e-01,  6.1693e-03, -2.7486e-02, -4.7031e-02,\n         -5.7688e-02,  2.1085e-01,  2.1096e-01,  1.4669e-01, -1.9009e-01,\n          1.2996e-01,  2.9068e-02, -1.9480e-01, -1.0451e-01, -5.7134e-02,\n         -1.4837e-01, -6.3350e-02, -2.3952e-02,  6.8608e-02, -1.5391e-01],\n        [-1.5709e-02,  2.0909e-01,  6.2257e-02, -2.2079e-01, -1.5543e-01,\n          1.0982e-02, -1.1671e-01, -3.4411e-02,  2.0303e-01,  1.5646e-01,\n         -5.0188e-02, -4.6793e-02,  1.5441e-01,  1.2020e-01, -1.6342e-01,\n         -1.2101e-01,  1.5631e-01, -1.8001e-01, -1.0151e-01, -8.2864e-02],\n        [-1.9423e-01, -4.9052e-02, -1.4262e-01,  2.0127e-01,  1.7290e-01,\n          1.2747e-01,  1.5839e-01,  2.0560e-01,  2.2298e-01,  1.4004e-01,\n          1.1841e-01, -4.2741e-02, -1.9305e-02, -1.9118e-01, -1.5471e-02,\n         -3.5673e-02, -1.1179e-01, -4.1360e-02,  9.3002e-02, -1.1643e-01],\n        [-1.6373e-01,  6.2178e-02, -4.9186e-02,  1.0462e-01, -1.1810e-01,\n         -1.0519e-01,  1.5231e-01,  1.9759e-01,  1.5856e-01, -8.8722e-02,\n          2.2359e-01, -1.5475e-01, -6.1983e-02,  4.4903e-02, -5.5247e-02,\n          1.2585e-01,  9.5387e-02,  9.4118e-02, -1.5240e-01, -5.4168e-02],\n        [ 1.1847e-02,  2.0482e-01,  2.0265e-01, -1.4281e-02, -7.4466e-02,\n          2.1525e-01,  9.3996e-02,  3.0603e-02, -1.5009e-02,  9.1246e-02,\n          6.5229e-02,  1.5412e-02,  1.9987e-01, -7.0989e-02, -4.1095e-02,\n          1.7197e-01,  1.2972e-01,  8.7828e-02,  1.2269e-01, -1.1277e-01],\n        [-8.3495e-02,  1.6858e-01, -8.4335e-02,  1.9729e-01, -2.1065e-01,\n          1.0615e-01, -1.6446e-01,  7.0919e-02,  3.9489e-02,  1.6583e-01,\n          1.7102e-01, -1.0080e-02, -9.9916e-02,  1.4473e-01, -1.0835e-02,\n         -3.5155e-02, -2.4021e-02, -2.1200e-02, -1.0950e-01,  1.1616e-01],\n        [-6.4312e-02, -1.0349e-01,  1.1399e-01,  2.3938e-02,  5.1158e-02,\n          1.8045e-01, -8.7985e-02,  5.7051e-03, -1.7687e-01, -7.3963e-02,\n          1.1043e-01,  2.1787e-01,  1.9207e-01, -3.4115e-02,  1.8613e-01,\n          1.0705e-01,  1.2774e-01,  1.6215e-01, -1.4806e-01,  7.4266e-02],\n        [ 4.1834e-02,  1.9213e-02, -1.4198e-01, -6.0617e-02, -2.9515e-02,\n         -1.0672e-02, -1.8833e-01, -4.5560e-02,  1.3789e-01,  1.5812e-01,\n         -1.3588e-01,  3.4427e-02, -1.2916e-02, -1.6743e-01,  4.1222e-02,\n         -2.1022e-02, -8.4938e-02,  1.0880e-01,  1.6382e-01, -1.6904e-01],\n        [-2.0108e-01, -2.0004e-01,  2.0653e-01, -1.7241e-02, -1.5169e-01,\n          1.1309e-01, -6.4610e-02,  1.0739e-02, -5.1273e-02, -1.1369e-01,\n          7.7857e-02,  1.2407e-01, -1.6333e-01,  2.3803e-02, -5.6916e-02,\n         -1.6322e-01, -9.7624e-02, -1.6137e-01,  1.9672e-01, -1.3164e-01],\n        [ 1.6834e-02, -1.8507e-01,  1.8040e-01, -5.6281e-02, -2.2042e-01,\n          2.2818e-02, -3.2209e-02, -4.7825e-02,  5.8774e-02, -2.0004e-01,\n          1.2790e-02,  1.3627e-01, -1.9250e-01, -1.5903e-01,  1.6063e-01,\n          8.7906e-02,  9.5239e-02,  7.3248e-04,  1.5198e-01, -1.8654e-02],\n        [-1.6596e-02, -9.7652e-02, -1.6641e-01,  1.1268e-02, -1.0935e-01,\n         -7.5611e-02, -6.7847e-02,  2.1163e-01, -1.7766e-02, -1.8243e-01,\n          1.8341e-01,  2.8752e-02, -1.0448e-01,  1.6542e-01, -3.1241e-02,\n         -1.4108e-01, -9.8260e-02, -1.6943e-01, -1.8214e-01,  1.9493e-01],\n        [ 1.8106e-01,  5.2526e-02, -1.6396e-02, -2.0715e-01, -1.0277e-01,\n         -1.2497e-01, -1.6112e-01,  1.1279e-01, -1.9399e-01, -1.3724e-01,\n         -9.6789e-02, -9.1404e-02,  6.1019e-04,  1.6604e-03,  1.0865e-03,\n         -1.1516e-01, -2.4442e-02,  5.7156e-02,  7.9019e-02, -8.3117e-02],\n        [ 1.2734e-01,  1.5636e-01, -1.7541e-01,  7.1878e-03, -1.5718e-02,\n         -7.5755e-02, -7.8375e-02, -1.2270e-01, -2.3717e-02,  1.8591e-01,\n          2.2045e-01,  1.8934e-01, -1.3820e-01, -2.2199e-02,  7.6157e-02,\n          1.8198e-01, -1.5618e-01, -2.0821e-01, -1.5400e-01,  2.2301e-01],\n        [ 8.2711e-02,  2.0507e-01,  1.5697e-02, -8.5991e-02, -1.1098e-01,\n          1.8350e-01,  4.2443e-02,  8.1441e-02,  1.6092e-01, -1.5618e-01,\n         -4.4295e-02,  4.9804e-02, -2.1850e-02,  1.4946e-01,  5.2222e-02,\n         -1.0549e-01, -1.9969e-01,  1.1954e-01,  1.9954e-01, -2.2239e-01],\n        [-1.9883e-01, -2.1550e-02, -1.0690e-01, -2.0072e-02, -3.0144e-03,\n          1.0066e-01, -2.1217e-01,  1.8880e-01, -5.7615e-02,  3.5019e-02,\n          1.7535e-01, -2.1346e-01, -1.2635e-01, -1.8406e-01, -4.0925e-02,\n         -1.1892e-01,  4.4118e-02, -1.0977e-01,  1.6138e-01, -1.0398e-01],\n        [-1.9928e-01,  1.5534e-01, -2.2054e-01,  1.1764e-01,  2.1346e-01,\n          3.2607e-02,  2.0607e-01, -1.8287e-02, -1.0943e-01,  1.2701e-01,\n         -6.4749e-03,  1.4637e-01,  1.1956e-01, -8.0174e-02, -7.6816e-02,\n         -4.1509e-02,  1.1412e-01, -2.1006e-01,  1.1948e-01,  4.4846e-02],\n        [-2.0208e-01, -2.4553e-02, -6.4320e-02, -1.0905e-01, -1.9016e-01,\n         -4.0774e-02,  9.3237e-02, -4.6716e-02, -1.1132e-01, -7.7437e-02,\n         -1.4136e-01, -5.5869e-02,  1.9529e-01, -1.5871e-01,  1.2705e-01,\n          1.4555e-01,  1.1970e-01, -4.4443e-02, -2.0929e-01, -2.0089e-01],\n        [ 1.4838e-02,  7.9197e-02, -8.6803e-02,  1.9035e-01, -1.9379e-01,\n         -6.4590e-02, -1.9543e-01,  5.9410e-02, -6.8486e-03, -1.6944e-01,\n         -1.7176e-02,  1.7227e-02, -4.2472e-02,  1.8464e-01, -1.1425e-01,\n          9.4298e-02, -2.0203e-01,  1.2425e-03, -9.0145e-02,  4.8817e-02],\n        [ 6.1714e-02,  7.5734e-02, -1.4053e-01,  1.7522e-01,  2.7787e-02,\n          2.1951e-01,  5.5724e-02,  2.0683e-01,  1.8449e-01, -8.0642e-02,\n         -1.0033e-02, -1.8185e-01,  2.0263e-01, -1.9203e-01, -1.9811e-01,\n          2.0867e-01, -4.4203e-02, -2.0897e-01,  5.7883e-03, -1.2009e-01],\n        [ 2.0369e-01,  1.5826e-01, -4.4055e-02, -1.9326e-01, -9.9067e-02,\n          7.2745e-02,  6.0219e-02, -1.6856e-01, -1.5773e-01, -1.9142e-02,\n         -1.4550e-03, -8.5079e-02,  7.5198e-02,  4.9830e-02,  1.7166e-01,\n          6.5418e-02, -2.1596e-01, -1.8865e-01, -1.5519e-01, -1.0983e-02],\n        [ 4.5756e-02,  8.7060e-02, -1.4226e-01,  1.0961e-01, -1.3057e-01,\n         -1.2602e-01,  1.4436e-01,  7.2360e-02,  7.1772e-02,  9.4596e-02,\n         -5.1584e-02, -2.1815e-01,  1.4979e-01,  2.3095e-02,  8.9645e-05,\n          5.0926e-02,  1.8261e-01, -2.0071e-02, -1.3602e-01, -5.3495e-02]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1121, -0.1675, -0.0432, -0.0013,  0.1176,  0.1577,  0.1249, -0.0437,\n        -0.1268, -0.1470, -0.0723,  0.1689, -0.0629, -0.0795,  0.0007,  0.0028],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-2.0856e-02, -1.0267e-01,  2.3339e-02, -1.4274e-01, -7.3446e-02,\n          3.6371e-02, -9.9847e-02, -9.8846e-02, -8.2093e-03,  1.6841e-01,\n         -1.4535e-01, -3.7314e-02, -1.7076e-01,  1.6927e-01, -1.3688e-01,\n          8.3668e-02, -7.8711e-02, -1.1139e-01, -1.1036e-01, -1.6284e-02,\n          8.4078e-02,  1.1092e-02,  4.9721e-02, -2.6663e-02, -1.8108e-02,\n          1.5005e-01,  1.5656e-01,  1.1987e-01,  1.2211e-01, -5.0372e-02,\n         -9.8078e-02, -2.4229e-02],\n        [ 5.0506e-02, -2.5892e-02,  1.1823e-01,  8.5353e-02, -4.6333e-02,\n          1.3766e-01, -1.2607e-01,  1.6865e-01, -3.2979e-02, -9.3310e-02,\n          1.7258e-01, -1.4444e-01,  1.4916e-01, -1.3432e-01,  1.5709e-01,\n         -1.1324e-01,  2.8339e-02,  1.2710e-01,  5.9444e-02,  1.6369e-01,\n          1.5895e-02,  3.9211e-02,  1.5846e-01,  2.9371e-02, -9.7102e-02,\n          1.7681e-02,  1.0975e-01,  4.6412e-02,  2.7128e-02, -8.4242e-02,\n         -1.3254e-01, -4.6406e-02],\n        [-1.1945e-01, -2.6172e-03, -6.9412e-02,  1.2323e-01, -2.9747e-02,\n         -1.2990e-01, -7.9325e-02, -8.3558e-02,  4.9298e-03,  3.6339e-02,\n          2.7867e-02,  1.5668e-01, -7.2345e-02,  1.6101e-01, -6.8799e-03,\n         -7.9392e-02,  6.2788e-02, -4.6288e-03, -6.8624e-02, -1.4112e-01,\n         -1.2631e-01, -7.9598e-02,  1.7390e-01, -5.5837e-02, -8.7577e-02,\n         -2.6463e-02, -1.1686e-01, -1.1014e-01, -1.6269e-01,  4.2336e-02,\n          1.2020e-01, -9.1018e-02],\n        [ 3.0751e-02,  1.0197e-01,  1.3427e-01, -3.7504e-02, -1.0906e-01,\n          9.7860e-02,  6.1332e-02,  9.5512e-02,  1.2387e-01,  1.1511e-01,\n         -1.6634e-03,  1.3816e-01, -8.9989e-02, -4.7323e-02,  4.2399e-02,\n         -1.1064e-01,  1.6488e-01,  1.2680e-02,  9.1183e-02, -5.3009e-02,\n         -1.6114e-02, -1.5278e-01,  1.1132e-01,  1.5492e-01, -3.1443e-02,\n          2.5398e-02, -1.0745e-01, -6.6736e-02, -9.0074e-02,  1.3083e-02,\n         -1.1931e-01,  1.7442e-01],\n        [-1.6926e-01,  1.4120e-01,  3.5427e-03,  1.5427e-01,  1.2170e-01,\n          1.2964e-02, -3.0644e-02, -3.4287e-02,  2.7113e-02,  1.6029e-01,\n         -9.6997e-03, -2.6913e-02, -7.5190e-02, -1.6435e-01,  1.8869e-02,\n          8.4701e-02, -7.7349e-02, -2.9102e-02, -6.6716e-02,  4.0849e-02,\n          6.8068e-02, -7.0048e-02,  9.5211e-02,  1.2290e-01, -3.9347e-02,\n         -6.2562e-03, -1.1021e-01,  1.7433e-01, -1.6429e-01,  1.4271e-01,\n         -1.4365e-02,  1.5025e-01],\n        [-1.3448e-01, -5.5472e-02,  4.8110e-02,  7.9738e-02,  4.2203e-02,\n         -3.1043e-02, -1.1324e-01, -9.3385e-02, -1.3803e-01,  1.2299e-01,\n          8.3294e-02,  1.3373e-01, -5.2565e-02,  7.5288e-03, -8.0476e-02,\n          1.1392e-01,  4.5387e-02, -2.2257e-02,  1.6327e-01, -1.5962e-01,\n         -1.3508e-01, -1.4214e-01,  1.7244e-01, -3.6566e-02,  1.2385e-01,\n          4.2415e-02,  6.6853e-02, -1.0506e-03, -1.1206e-02, -1.1090e-01,\n          1.2402e-02,  5.1809e-02],\n        [-1.1233e-01,  1.3771e-01,  1.2185e-01,  4.3402e-02, -1.1602e-01,\n          1.3417e-01,  1.9068e-02,  6.8655e-03, -8.9609e-02,  8.6128e-02,\n          1.4586e-01, -2.7502e-02, -4.3809e-02, -1.4090e-01, -2.7364e-02,\n          1.0241e-01, -1.4494e-01,  1.0125e-01,  7.8871e-02,  1.0687e-02,\n          1.8082e-03, -1.5044e-01,  3.1177e-02, -2.1911e-02, -1.4994e-01,\n         -1.5376e-02,  3.8978e-02, -8.4068e-02,  9.6095e-02,  8.8626e-02,\n          1.5174e-01, -1.5831e-01],\n        [-1.3686e-01, -1.6650e-01, -1.4875e-01,  9.6070e-02,  1.4039e-02,\n          3.1311e-02, -5.2074e-02, -1.4004e-02, -1.4839e-01, -9.5387e-02,\n          2.8363e-02, -1.7388e-01,  8.7763e-02,  1.3956e-01,  1.7261e-01,\n          1.6677e-01, -1.2661e-01,  1.5220e-01,  1.7257e-01, -1.6498e-02,\n         -1.0617e-01,  4.9165e-02, -7.3568e-02, -1.6737e-01,  1.3994e-01,\n          8.0045e-02,  5.7124e-02,  1.4654e-01,  1.6949e-01, -2.2194e-02,\n         -4.3797e-02,  8.4673e-02],\n        [-8.2403e-02, -1.0158e-01, -6.3334e-02,  7.4581e-02, -8.1808e-03,\n         -5.2482e-02,  1.5364e-01,  1.5364e-01,  1.4415e-01,  5.1270e-02,\n          1.3602e-02,  7.8213e-02,  3.5133e-02,  1.3668e-01, -8.2532e-02,\n         -3.1019e-02,  1.4514e-01, -2.4687e-02, -7.5822e-02,  7.7764e-03,\n          1.1271e-01, -1.0577e-01,  5.3273e-02, -1.1509e-01, -1.0282e-01,\n          2.1136e-02,  3.9174e-02, -6.1441e-02, -1.5289e-01,  1.4579e-01,\n          1.6554e-01, -8.9985e-02],\n        [ 7.1620e-02,  4.5216e-02,  1.7449e-01,  2.2392e-02, -1.1014e-01,\n         -1.5997e-01,  1.6508e-01,  1.5563e-01,  4.9818e-03,  1.8932e-02,\n          1.6926e-01, -5.0283e-02,  1.4836e-01, -4.5207e-02, -1.3374e-01,\n          9.5216e-02,  7.4068e-02,  3.5449e-02,  8.6217e-02,  8.3719e-02,\n          1.4242e-01,  2.8189e-02,  1.2728e-01,  1.0686e-01,  1.1016e-01,\n         -1.3680e-01,  8.2191e-02,  5.3151e-02,  7.0023e-02, -2.2309e-02,\n          4.1950e-02, -1.9622e-02],\n        [ 3.6406e-02,  2.6940e-02, -5.7349e-03,  1.3164e-01, -2.8264e-02,\n         -1.4644e-01, -7.2529e-02, -3.2178e-02, -9.1713e-03, -1.6382e-01,\n         -3.3378e-02, -1.5639e-01, -2.5033e-02,  1.5699e-01,  3.4700e-02,\n          3.6648e-02,  9.1546e-02,  4.3773e-02,  1.4696e-01, -8.1109e-03,\n         -1.8270e-02,  3.7004e-02,  1.6613e-01, -1.8655e-02, -5.3819e-02,\n         -3.8727e-02, -1.2767e-01, -1.6486e-01, -5.6457e-02, -2.2652e-02,\n          1.4973e-01, -1.0032e-02],\n        [ 4.2277e-02,  1.2080e-01,  3.7675e-03, -8.2755e-02, -1.0469e-01,\n          1.5684e-01, -1.0685e-01, -4.9224e-02, -5.3243e-02,  6.0973e-02,\n          6.2087e-02,  7.6998e-02,  1.4513e-01,  1.3598e-01, -1.3153e-01,\n          1.6020e-01,  1.0794e-02, -1.4083e-01,  8.1877e-02, -9.6102e-02,\n         -8.5342e-02,  1.2878e-01,  7.6506e-02,  8.5454e-02, -8.8232e-02,\n          9.5102e-02, -3.5775e-02,  1.3895e-01, -6.1990e-02, -4.5402e-02,\n         -1.4395e-01, -4.6362e-02],\n        [-9.3545e-02,  5.0813e-02, -1.3918e-01, -1.2854e-02, -5.4957e-02,\n         -7.8877e-02,  1.2468e-01,  2.5654e-03,  1.1159e-01,  1.3127e-01,\n          1.1669e-01, -1.5957e-01,  4.6296e-02, -1.3095e-01, -1.0398e-01,\n          2.3851e-02, -1.4008e-01,  2.6715e-02,  3.0159e-02,  5.9245e-02,\n         -2.4360e-02,  1.0639e-02, -5.8674e-02, -1.6605e-01, -2.9472e-02,\n         -1.2020e-01,  1.3394e-01, -7.5543e-02,  1.1418e-01, -1.3727e-01,\n          1.1951e-01, -1.7120e-02],\n        [-6.8233e-02,  8.2650e-02, -9.8061e-02, -7.0917e-02, -1.4920e-01,\n         -1.5390e-01, -9.0966e-02,  6.9671e-02,  7.4412e-02,  9.1616e-02,\n          1.7123e-01,  7.4660e-02, -6.6061e-02,  2.4598e-03,  1.6442e-01,\n          9.7588e-02,  7.7340e-02,  1.5469e-01, -6.8184e-02,  2.8361e-02,\n         -1.5601e-01,  6.4543e-02, -1.0415e-01,  6.0671e-02, -3.8524e-02,\n          1.1119e-01,  1.2397e-01, -5.9856e-02, -1.6304e-01,  8.3914e-02,\n          2.9409e-02, -1.5902e-01],\n        [-1.5743e-01, -1.1488e-01, -1.0817e-01,  1.5483e-02, -1.4273e-01,\n          7.1743e-02,  1.1849e-01,  1.4343e-02,  1.2127e-02,  1.2190e-01,\n          1.3227e-01,  1.0240e-01,  9.5366e-02, -4.6853e-02,  7.9804e-02,\n         -7.0197e-02, -5.9841e-03, -1.7653e-01, -1.5062e-01, -2.5236e-03,\n         -1.5692e-01,  6.3155e-02, -5.6274e-02, -1.7357e-01, -2.2491e-02,\n          9.7366e-02, -5.8891e-02,  4.8131e-05,  6.0233e-02,  8.6879e-02,\n         -8.7442e-02, -9.6025e-02],\n        [ 1.1781e-01,  3.0939e-04, -1.2199e-01,  1.6003e-01, -1.0653e-01,\n         -3.1618e-02,  2.0335e-02, -3.7451e-02,  7.0387e-02,  1.5937e-01,\n         -1.4574e-01, -2.6567e-03, -1.5378e-01,  1.6770e-01, -4.8725e-02,\n          6.2579e-02, -7.1663e-04,  6.7577e-02,  1.5791e-01, -1.3550e-01,\n         -1.3793e-01, -1.3855e-01,  1.6577e-01,  5.8366e-02,  1.8876e-02,\n         -1.6682e-01, -9.8589e-02,  1.0119e-01, -1.4029e-01, -1.1492e-01,\n          6.5554e-02, -1.2560e-01]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.2465,  0.0873, -0.1908,  0.2489,  0.0888,  0.0403, -0.0639, -0.1380],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1727, -0.0609,  0.1178, -0.2034,  0.0397,  0.1771, -0.1795, -0.0497,\n          0.2260, -0.2270, -0.0520, -0.1947, -0.2203,  0.2136,  0.1457,  0.0296],\n        [-0.0751,  0.1690,  0.0745, -0.0613, -0.0032,  0.1037, -0.0330,  0.1584,\n         -0.1034, -0.1685,  0.1720,  0.2268, -0.0638, -0.2285, -0.1014, -0.1248],\n        [-0.1444, -0.0234,  0.0924,  0.2154,  0.0157, -0.1571,  0.0481, -0.1882,\n          0.0345, -0.1795,  0.0041,  0.0391,  0.2019, -0.1964,  0.0617,  0.0885],\n        [-0.1243,  0.0462,  0.1742, -0.1004, -0.0413,  0.2363,  0.2373,  0.1927,\n          0.0401,  0.0363,  0.1011, -0.0517,  0.0335,  0.0883, -0.1377, -0.2113],\n        [ 0.0642, -0.0427,  0.1210, -0.0975,  0.1215, -0.1387, -0.0151, -0.2289,\n         -0.1350,  0.1330, -0.1041, -0.2500, -0.2479,  0.1570,  0.0518, -0.0010],\n        [-0.0010, -0.2459, -0.1353,  0.0777,  0.0995, -0.0924,  0.0163,  0.0698,\n         -0.0042, -0.2180,  0.2006, -0.2019,  0.2257,  0.0432, -0.1983, -0.0494],\n        [ 0.1465, -0.0784, -0.1492, -0.1161, -0.1401,  0.1454,  0.1155,  0.1445,\n          0.0908, -0.0550,  0.1212, -0.2214,  0.0042, -0.0352,  0.1833,  0.0358],\n        [-0.1073,  0.1681,  0.1762, -0.1209,  0.2348, -0.1612,  0.1927,  0.2392,\n         -0.0484, -0.2188,  0.1297,  0.1560,  0.1546,  0.2016,  0.2203,  0.1292]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([0.0822], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1920, -0.1811,  0.2219, -0.2458, -0.1106, -0.3258,  0.1183, -0.0661]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    20,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	20,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "flatten_obs_dim":	20,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0368,  0.4024,  0.0600,  0.3453],\n        [ 0.2569, -0.2270,  0.3931,  0.0276],\n        [ 0.4580, -0.4917, -0.2337, -0.2198],\n        [ 0.2807, -0.2251,  0.2905, -0.2077],\n        [-0.1562,  0.2983,  0.1265,  0.4048],\n        [ 0.2391,  0.1715, -0.4767,  0.1850],\n        [-0.1136, -0.4741,  0.2751, -0.2583],\n        [-0.3602,  0.0585,  0.4408,  0.2939],\n        [ 0.1330,  0.4988, -0.1246,  0.0664],\n        [-0.0939, -0.2940, -0.3858, -0.1416],\n        [-0.3928,  0.3728,  0.2947, -0.3038],\n        [-0.3983,  0.2546, -0.3054, -0.4755],\n        [-0.2352, -0.2763,  0.4421, -0.2853],\n        [-0.3196,  0.1075, -0.3576,  0.2864],\n        [ 0.3824, -0.0215,  0.1759, -0.0954],\n        [-0.2932,  0.3822,  0.3044,  0.3285],\n        [ 0.2993,  0.4683,  0.1917,  0.0222],\n        [-0.1020,  0.4192,  0.4739,  0.2653],\n        [-0.2209,  0.0018,  0.3842,  0.4383],\n        [ 0.3849, -0.2940, -0.3884,  0.0481],\n        [ 0.4166,  0.3954, -0.2288,  0.4804],\n        [ 0.2113, -0.3466,  0.2230, -0.2613],\n        [ 0.1275,  0.1468, -0.0662, -0.0072],\n        [ 0.3353, -0.2327,  0.2842,  0.0240],\n        [-0.0249,  0.1615,  0.2849,  0.2310],\n        [-0.3452,  0.4031,  0.4414, -0.2418],\n        [-0.2414, -0.2988, -0.3245,  0.1019],\n        [ 0.3524,  0.2812, -0.3571,  0.2165],\n        [-0.3717, -0.4497,  0.1197, -0.2254],\n        [-0.1188,  0.0432,  0.3604,  0.0149],\n        [ 0.2204, -0.0609,  0.3123, -0.3263],\n        [ 0.3863, -0.0301, -0.0311, -0.4649]], requires_grad=True)",
                                "Parameter containing:\ntensor([-2.9443e-01,  3.2479e-01,  4.6133e-01,  2.4609e-01, -3.7585e-01,\n         4.8005e-01,  1.8530e-01,  3.5669e-01,  3.4416e-01, -4.9966e-01,\n         2.4421e-01, -4.9625e-01, -4.6373e-01, -3.8862e-01, -3.2765e-01,\n         3.8421e-04,  2.8529e-01, -2.9218e-01,  1.8187e-01, -2.8287e-01,\n         1.5504e-01,  4.7146e-01,  7.5392e-02,  3.4499e-01, -2.4821e-01,\n         2.2887e-01, -5.1911e-02,  9.3081e-02,  4.7103e-01,  2.5730e-01,\n         2.4778e-01,  3.0837e-01], requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0442, -0.1506, -0.1671,  0.0383, -0.0648,  0.1386, -0.0970,  0.1537,\n         -0.0795,  0.1294, -0.0208, -0.0617, -0.1275, -0.1626, -0.1338, -0.0897,\n         -0.0043,  0.1494,  0.0580,  0.0182, -0.0586, -0.1635,  0.1469,  0.1475,\n          0.0665,  0.1081,  0.1365,  0.0712, -0.1280,  0.0392, -0.1629,  0.1679],\n        [-0.1648,  0.1500,  0.1489, -0.0986, -0.0754,  0.1281, -0.0626, -0.1681,\n          0.1380, -0.0887, -0.0586, -0.0145, -0.1199,  0.0027,  0.0206,  0.1111,\n         -0.0429, -0.0856, -0.0281, -0.0758,  0.1139,  0.1314, -0.0464, -0.1716,\n         -0.0017, -0.1691, -0.1148,  0.0647, -0.1696,  0.1050, -0.0986,  0.0438],\n        [ 0.0364,  0.0788, -0.0793,  0.1406,  0.0294, -0.1546,  0.1236,  0.1441,\n         -0.1308, -0.0822, -0.1363,  0.1289, -0.0166, -0.0310, -0.0343,  0.0715,\n          0.1010, -0.1321, -0.0389, -0.0667,  0.1747, -0.1699,  0.0226, -0.0893,\n         -0.1737, -0.1562, -0.0080, -0.1064, -0.0051,  0.0213, -0.1542, -0.0463],\n        [ 0.0906, -0.0533, -0.1000, -0.1509, -0.0283, -0.0198,  0.1749,  0.0586,\n          0.0735, -0.0018, -0.1728,  0.1311, -0.1230,  0.0360,  0.1448,  0.1320,\n         -0.0936,  0.0719, -0.0595, -0.0232,  0.1315, -0.0210,  0.1080, -0.1695,\n         -0.0139,  0.1029, -0.0682, -0.0851, -0.0401,  0.1352, -0.0809, -0.0500],\n        [ 0.1727,  0.1645, -0.1692, -0.1575,  0.1717,  0.1379, -0.1350,  0.1140,\n          0.1126, -0.1427,  0.0366,  0.1329,  0.1223, -0.0503, -0.0983, -0.0651,\n         -0.0543,  0.1743,  0.1033,  0.1593, -0.0790,  0.0392,  0.1520, -0.1455,\n          0.0290,  0.1222, -0.0762,  0.0695, -0.0713,  0.0387,  0.1571,  0.0556],\n        [-0.1071, -0.0203, -0.1482, -0.1467, -0.1259,  0.1273,  0.0343,  0.1767,\n          0.1361,  0.1704, -0.1241, -0.1145, -0.1031, -0.0325,  0.0421, -0.1557,\n          0.0043, -0.0286, -0.1630,  0.1282,  0.0942, -0.1501,  0.0839,  0.1086,\n          0.0926, -0.0810, -0.0997, -0.1153, -0.1281,  0.1083, -0.1631, -0.0374],\n        [-0.1406, -0.1727, -0.0627,  0.1668,  0.0837,  0.0692,  0.0608,  0.1486,\n          0.0460, -0.0286, -0.1139,  0.0219,  0.0667,  0.0298, -0.1635,  0.1261,\n         -0.0956,  0.1505,  0.0180, -0.0599,  0.0951,  0.0409, -0.1238,  0.0480,\n         -0.0577,  0.1531,  0.1227,  0.0477,  0.0964,  0.1129,  0.1685, -0.0394],\n        [-0.1724,  0.1592, -0.1363,  0.0671, -0.1621, -0.0820, -0.1385, -0.1163,\n          0.0669, -0.0194, -0.1025, -0.0667,  0.0773,  0.1249,  0.1378, -0.1665,\n          0.1300, -0.0927,  0.1624, -0.0124,  0.0840, -0.0431,  0.0172,  0.0670,\n          0.1546,  0.0580, -0.1088,  0.1670, -0.0987,  0.0384, -0.1486, -0.0113],\n        [-0.0323,  0.1017, -0.0360, -0.0653,  0.0232, -0.0530,  0.1017,  0.0531,\n         -0.0907, -0.1340,  0.0564, -0.0777, -0.0810,  0.0225, -0.1749, -0.0956,\n         -0.1127,  0.0381, -0.0650,  0.0404,  0.1045,  0.0859, -0.1024, -0.1534,\n          0.1569,  0.0575, -0.1585,  0.1513,  0.0936, -0.0367, -0.1412,  0.0336],\n        [-0.1111, -0.1634,  0.1363,  0.0306, -0.1508,  0.0719, -0.0837, -0.0710,\n         -0.1702, -0.1020,  0.1157, -0.0204, -0.1577,  0.0154, -0.1180,  0.0737,\n          0.1162,  0.0494, -0.1670, -0.1518, -0.1124, -0.1140, -0.0984,  0.1746,\n         -0.1072, -0.1521,  0.1044, -0.0718, -0.0899, -0.0580, -0.1269, -0.1182],\n        [-0.0419, -0.1412, -0.0643, -0.0468,  0.1596, -0.1482,  0.1534,  0.1094,\n          0.0974, -0.0450,  0.0751,  0.0377,  0.1083, -0.1182, -0.1605,  0.1411,\n         -0.1753,  0.1274,  0.0549,  0.1112, -0.0514,  0.1766,  0.0851,  0.0198,\n          0.0532,  0.0928,  0.1533, -0.1046,  0.1320,  0.1471,  0.1499, -0.0195],\n        [ 0.0083,  0.0114,  0.1308, -0.0467,  0.1442, -0.1748,  0.1120,  0.0434,\n          0.1716,  0.0321, -0.0674,  0.1009,  0.0056,  0.0297,  0.0081,  0.1489,\n          0.0876, -0.0880, -0.0327, -0.0525, -0.1537,  0.1718,  0.1155,  0.1337,\n         -0.0159, -0.1637, -0.0504,  0.1282,  0.0002,  0.1561, -0.0623, -0.0856],\n        [-0.0806,  0.0462,  0.0383,  0.0145,  0.0945,  0.1604, -0.0035,  0.0655,\n         -0.0642,  0.1499, -0.0773, -0.1591, -0.1551,  0.0526, -0.0840,  0.0201,\n          0.0176,  0.0336,  0.1357, -0.1702,  0.1497,  0.0667,  0.1735,  0.0887,\n         -0.0480, -0.1754, -0.1540, -0.0661, -0.1212, -0.0230, -0.1166, -0.1326],\n        [ 0.0995, -0.0861,  0.0940,  0.0550, -0.1663, -0.0824, -0.0041, -0.1409,\n          0.1682,  0.0679,  0.1166,  0.0314, -0.1112, -0.0052, -0.1232,  0.1150,\n         -0.0290,  0.1487, -0.1354, -0.1073,  0.0484,  0.1268,  0.0908, -0.0342,\n          0.0545,  0.1256, -0.0577, -0.0280,  0.1321, -0.1477,  0.1041,  0.1255],\n        [-0.1426,  0.0026, -0.0204,  0.1475,  0.1150,  0.0917,  0.1516,  0.0419,\n         -0.0091, -0.1764,  0.0116,  0.1581, -0.1557, -0.0805,  0.0812,  0.0716,\n          0.0300,  0.0137, -0.0169, -0.1627, -0.0574,  0.0835, -0.0929, -0.0965,\n         -0.1683, -0.0779,  0.0283, -0.0158,  0.0861, -0.1047, -0.0380,  0.0080],\n        [ 0.1648, -0.0643, -0.1304, -0.0191, -0.0213,  0.1346,  0.1490, -0.0874,\n         -0.0309, -0.0947, -0.0343,  0.1389,  0.1028, -0.1216, -0.0068,  0.1111,\n          0.1585, -0.0650,  0.1068, -0.1163, -0.1101, -0.0578,  0.1281,  0.1692,\n         -0.1212,  0.0062,  0.1514,  0.0958,  0.1006, -0.0752, -0.1687,  0.1096]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1304, -0.1744, -0.0228,  0.0108,  0.1068, -0.1648,  0.1286, -0.0491,\n         0.0442, -0.0966,  0.1407,  0.0479,  0.1127, -0.0289,  0.1230,  0.1060],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0535,  0.0804,  0.2073,  0.1414, -0.0090,  0.2401,  0.1719, -0.2096,\n         -0.0968,  0.2273,  0.1979, -0.0618, -0.2473, -0.2461, -0.0553,  0.1361],\n        [-0.2414,  0.0951,  0.1976, -0.1897,  0.1271, -0.0909, -0.0502, -0.0280,\n         -0.1980,  0.1283,  0.1878,  0.1932, -0.1429,  0.2146, -0.0501,  0.1161],\n        [ 0.1670, -0.0665, -0.1960,  0.1711,  0.1570,  0.1939,  0.0818, -0.0222,\n         -0.0239, -0.0107, -0.0967, -0.0516, -0.0986, -0.0204,  0.1092, -0.0211],\n        [-0.1283,  0.0566,  0.0382, -0.1819, -0.1606, -0.1696, -0.1285,  0.1212,\n         -0.0435, -0.1686,  0.1286,  0.1050,  0.0719, -0.0760, -0.0588, -0.1265],\n        [ 0.1250, -0.2150,  0.0617, -0.0153,  0.0890, -0.0962,  0.0445,  0.0660,\n          0.2398, -0.1879,  0.2033,  0.0211, -0.0261,  0.0531,  0.1679,  0.0020],\n        [ 0.1636, -0.1859,  0.0430, -0.1646, -0.1885,  0.1852,  0.0099, -0.1994,\n          0.0027, -0.0050,  0.0356,  0.1810,  0.2432,  0.1125, -0.1774, -0.2149],\n        [ 0.0984,  0.1936, -0.1188, -0.2440, -0.1157,  0.2224, -0.0339, -0.1610,\n          0.2184, -0.0055, -0.2374,  0.2426, -0.1583,  0.1855,  0.1557, -0.0381],\n        [-0.1773, -0.2138,  0.2183,  0.0822,  0.1656,  0.0945, -0.1027,  0.0015,\n          0.0829,  0.0185, -0.0541,  0.1436, -0.0708, -0.0917, -0.0253,  0.2451]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0499,  0.2223,  0.0822,  0.0336,  0.0888, -0.1864,  0.0241, -0.1762],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2424,  0.2518,  0.2620, -0.0609, -0.2526,  0.0120, -0.1657, -0.3074]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0617], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x000001312D79EBF0>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	50000,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	40,
            "_train_v_iters":	40,
            "_traj_per_epoch":	5,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-9.9820e-02, -2.2063e-01,  2.9930e-02, -2.2292e-01, -2.1637e-01,\n         -2.4615e-02, -5.9852e-03, -1.8134e-01,  2.9113e-02,  2.2170e-01,\n          1.7326e-01,  1.9996e-01, -1.0634e-01, -4.1951e-02, -4.8759e-02,\n          1.2669e-01, -1.3048e-01, -7.5952e-02, -1.9501e-01,  8.6309e-02],\n        [ 1.1273e-04, -1.2409e-01, -7.9147e-02,  1.0885e-01, -1.4132e-01,\n          1.9371e-01,  1.0285e-01,  5.5946e-03, -1.9811e-01, -2.7686e-02,\n          7.5364e-03,  1.2913e-01, -4.3773e-02, -1.0011e-01, -1.4594e-01,\n          1.9275e-01,  2.3091e-02, -1.0484e-01, -5.4072e-02, -1.2169e-01],\n        [ 1.9869e-01, -1.2535e-01,  2.0284e-01, -5.6657e-02,  2.2015e-01,\n          1.3395e-01, -8.9288e-02, -1.5905e-01,  1.1149e-01,  3.1996e-02,\n         -4.6082e-02, -7.5015e-03,  5.0891e-02, -2.5076e-02, -1.3623e-01,\n          2.6895e-02,  1.5190e-01, -1.8198e-01, -2.8860e-02, -1.8120e-01],\n        [-2.3963e-02,  1.1111e-01,  7.9868e-02,  8.6052e-02, -1.9419e-01,\n         -2.1832e-02,  1.0333e-01, -1.4896e-01, -1.6512e-01,  1.3112e-01,\n         -1.2819e-01, -1.5176e-01,  2.1036e-01,  1.9992e-02,  1.7036e-01,\n         -1.8521e-01,  3.5165e-02,  9.0741e-02, -4.1461e-02, -1.0878e-01],\n        [-1.2464e-01, -1.0445e-01,  2.3061e-02, -7.2700e-02,  2.0930e-01,\n         -1.7016e-01,  2.1333e-02,  1.7813e-01,  1.6024e-01,  2.1323e-01,\n          1.9511e-01, -6.2491e-02, -2.1426e-01,  6.2324e-02, -1.0862e-01,\n         -6.1957e-02, -3.8972e-03, -1.0904e-01, -1.4775e-01,  1.0917e-01],\n        [ 1.4610e-01,  9.4396e-02, -1.6531e-01,  1.7146e-01,  2.6236e-02,\n         -6.6667e-02,  1.7697e-01,  4.1700e-03, -1.9659e-01,  4.6971e-02,\n         -1.4129e-01,  3.2565e-02,  9.3983e-02,  1.6315e-01,  1.0273e-01,\n         -1.7593e-01,  2.9133e-02,  1.3196e-01, -2.1757e-01, -9.4674e-02],\n        [-3.8795e-02,  3.8133e-03,  1.8562e-01, -2.1653e-01, -7.0037e-02,\n         -6.7239e-02,  5.4953e-02, -1.8258e-01,  1.4685e-01, -9.3437e-02,\n         -4.2673e-02,  2.2046e-01, -1.0149e-01, -1.0695e-01,  3.2610e-02,\n          1.9327e-01, -2.3792e-02,  1.0041e-01,  1.2858e-01, -1.0499e-01],\n        [ 2.0492e-01, -1.3110e-01,  7.3145e-02, -1.4731e-01,  6.1030e-02,\n         -1.9201e-01,  1.6496e-01, -8.1341e-02, -3.7834e-02, -1.2704e-02,\n          1.6484e-01, -5.9799e-02, -1.1574e-02,  1.0745e-01,  1.8057e-01,\n         -4.5827e-02,  1.7822e-02, -1.0847e-01, -1.5267e-01, -1.8480e-01],\n        [-8.7041e-03,  1.1057e-01, -2.0292e-01, -6.8849e-03,  8.8728e-02,\n          1.4361e-01,  5.1850e-02, -1.6991e-01,  1.2777e-01,  2.0879e-01,\n         -4.8674e-02, -1.1717e-01, -1.9583e-01, -1.4494e-01, -1.1200e-01,\n          9.3929e-02, -8.7422e-02, -5.4267e-02, -6.8387e-02,  4.0077e-02],\n        [ 2.2093e-01, -1.8438e-01, -1.8151e-01, -4.8368e-02, -4.2641e-03,\n          1.2656e-01,  4.7209e-02, -1.4636e-02,  4.3442e-02,  1.5494e-01,\n         -2.0277e-01,  2.1508e-01, -9.0827e-02, -2.0719e-01, -3.3302e-02,\n         -2.1190e-01, -5.8787e-02, -9.9212e-02,  8.2616e-02,  9.8854e-02],\n        [-3.8102e-02,  3.7582e-02, -1.0490e-01,  1.7503e-01, -1.1278e-01,\n         -6.8854e-02,  8.2261e-02, -1.0807e-01,  1.1468e-01, -3.7257e-02,\n         -2.7683e-02,  1.5223e-01,  8.2185e-03,  8.9204e-02,  2.8618e-02,\n         -3.8596e-02, -1.4672e-01,  4.1602e-02, -2.2253e-01, -1.4508e-01],\n        [ 5.7196e-02,  2.2268e-01,  6.1693e-03, -2.7486e-02, -4.7031e-02,\n         -5.7688e-02,  2.1085e-01,  2.1096e-01,  1.4669e-01, -1.9009e-01,\n          1.2996e-01,  2.9068e-02, -1.9480e-01, -1.0451e-01, -5.7134e-02,\n         -1.4837e-01, -6.3350e-02, -2.3952e-02,  6.8608e-02, -1.5391e-01],\n        [-1.5709e-02,  2.0909e-01,  6.2257e-02, -2.2079e-01, -1.5543e-01,\n          1.0982e-02, -1.1671e-01, -3.4411e-02,  2.0303e-01,  1.5646e-01,\n         -5.0188e-02, -4.6793e-02,  1.5441e-01,  1.2020e-01, -1.6342e-01,\n         -1.2101e-01,  1.5631e-01, -1.8001e-01, -1.0151e-01, -8.2864e-02],\n        [-1.9423e-01, -4.9052e-02, -1.4262e-01,  2.0127e-01,  1.7290e-01,\n          1.2747e-01,  1.5839e-01,  2.0560e-01,  2.2298e-01,  1.4004e-01,\n          1.1841e-01, -4.2741e-02, -1.9305e-02, -1.9118e-01, -1.5471e-02,\n         -3.5673e-02, -1.1179e-01, -4.1360e-02,  9.3002e-02, -1.1643e-01],\n        [-1.6373e-01,  6.2178e-02, -4.9186e-02,  1.0462e-01, -1.1810e-01,\n         -1.0519e-01,  1.5231e-01,  1.9759e-01,  1.5856e-01, -8.8722e-02,\n          2.2359e-01, -1.5475e-01, -6.1983e-02,  4.4903e-02, -5.5247e-02,\n          1.2585e-01,  9.5387e-02,  9.4118e-02, -1.5240e-01, -5.4168e-02],\n        [ 1.1847e-02,  2.0482e-01,  2.0265e-01, -1.4281e-02, -7.4466e-02,\n          2.1525e-01,  9.3996e-02,  3.0603e-02, -1.5009e-02,  9.1246e-02,\n          6.5229e-02,  1.5412e-02,  1.9987e-01, -7.0989e-02, -4.1095e-02,\n          1.7197e-01,  1.2972e-01,  8.7828e-02,  1.2269e-01, -1.1277e-01],\n        [-8.3495e-02,  1.6858e-01, -8.4335e-02,  1.9729e-01, -2.1065e-01,\n          1.0615e-01, -1.6446e-01,  7.0919e-02,  3.9489e-02,  1.6583e-01,\n          1.7102e-01, -1.0080e-02, -9.9916e-02,  1.4473e-01, -1.0835e-02,\n         -3.5155e-02, -2.4021e-02, -2.1200e-02, -1.0950e-01,  1.1616e-01],\n        [-6.4312e-02, -1.0349e-01,  1.1399e-01,  2.3938e-02,  5.1158e-02,\n          1.8045e-01, -8.7985e-02,  5.7051e-03, -1.7687e-01, -7.3963e-02,\n          1.1043e-01,  2.1787e-01,  1.9207e-01, -3.4115e-02,  1.8613e-01,\n          1.0705e-01,  1.2774e-01,  1.6215e-01, -1.4806e-01,  7.4266e-02],\n        [ 4.1834e-02,  1.9213e-02, -1.4198e-01, -6.0617e-02, -2.9515e-02,\n         -1.0672e-02, -1.8833e-01, -4.5560e-02,  1.3789e-01,  1.5812e-01,\n         -1.3588e-01,  3.4427e-02, -1.2916e-02, -1.6743e-01,  4.1222e-02,\n         -2.1022e-02, -8.4938e-02,  1.0880e-01,  1.6382e-01, -1.6904e-01],\n        [-2.0108e-01, -2.0004e-01,  2.0653e-01, -1.7241e-02, -1.5169e-01,\n          1.1309e-01, -6.4610e-02,  1.0739e-02, -5.1273e-02, -1.1369e-01,\n          7.7857e-02,  1.2407e-01, -1.6333e-01,  2.3803e-02, -5.6916e-02,\n         -1.6322e-01, -9.7624e-02, -1.6137e-01,  1.9672e-01, -1.3164e-01],\n        [ 1.6834e-02, -1.8507e-01,  1.8040e-01, -5.6281e-02, -2.2042e-01,\n          2.2818e-02, -3.2209e-02, -4.7825e-02,  5.8774e-02, -2.0004e-01,\n          1.2790e-02,  1.3627e-01, -1.9250e-01, -1.5903e-01,  1.6063e-01,\n          8.7906e-02,  9.5239e-02,  7.3248e-04,  1.5198e-01, -1.8654e-02],\n        [-1.6596e-02, -9.7652e-02, -1.6641e-01,  1.1268e-02, -1.0935e-01,\n         -7.5611e-02, -6.7847e-02,  2.1163e-01, -1.7766e-02, -1.8243e-01,\n          1.8341e-01,  2.8752e-02, -1.0448e-01,  1.6542e-01, -3.1241e-02,\n         -1.4108e-01, -9.8260e-02, -1.6943e-01, -1.8214e-01,  1.9493e-01],\n        [ 1.8106e-01,  5.2526e-02, -1.6396e-02, -2.0715e-01, -1.0277e-01,\n         -1.2497e-01, -1.6112e-01,  1.1279e-01, -1.9399e-01, -1.3724e-01,\n         -9.6789e-02, -9.1404e-02,  6.1019e-04,  1.6604e-03,  1.0865e-03,\n         -1.1516e-01, -2.4442e-02,  5.7156e-02,  7.9019e-02, -8.3117e-02],\n        [ 1.2734e-01,  1.5636e-01, -1.7541e-01,  7.1878e-03, -1.5718e-02,\n         -7.5755e-02, -7.8375e-02, -1.2270e-01, -2.3717e-02,  1.8591e-01,\n          2.2045e-01,  1.8934e-01, -1.3820e-01, -2.2199e-02,  7.6157e-02,\n          1.8198e-01, -1.5618e-01, -2.0821e-01, -1.5400e-01,  2.2301e-01],\n        [ 8.2711e-02,  2.0507e-01,  1.5697e-02, -8.5991e-02, -1.1098e-01,\n          1.8350e-01,  4.2443e-02,  8.1441e-02,  1.6092e-01, -1.5618e-01,\n         -4.4295e-02,  4.9804e-02, -2.1850e-02,  1.4946e-01,  5.2222e-02,\n         -1.0549e-01, -1.9969e-01,  1.1954e-01,  1.9954e-01, -2.2239e-01],\n        [-1.9883e-01, -2.1550e-02, -1.0690e-01, -2.0072e-02, -3.0144e-03,\n          1.0066e-01, -2.1217e-01,  1.8880e-01, -5.7615e-02,  3.5019e-02,\n          1.7535e-01, -2.1346e-01, -1.2635e-01, -1.8406e-01, -4.0925e-02,\n         -1.1892e-01,  4.4118e-02, -1.0977e-01,  1.6138e-01, -1.0398e-01],\n        [-1.9928e-01,  1.5534e-01, -2.2054e-01,  1.1764e-01,  2.1346e-01,\n          3.2607e-02,  2.0607e-01, -1.8287e-02, -1.0943e-01,  1.2701e-01,\n         -6.4749e-03,  1.4637e-01,  1.1956e-01, -8.0174e-02, -7.6816e-02,\n         -4.1509e-02,  1.1412e-01, -2.1006e-01,  1.1948e-01,  4.4846e-02],\n        [-2.0208e-01, -2.4553e-02, -6.4320e-02, -1.0905e-01, -1.9016e-01,\n         -4.0774e-02,  9.3237e-02, -4.6716e-02, -1.1132e-01, -7.7437e-02,\n         -1.4136e-01, -5.5869e-02,  1.9529e-01, -1.5871e-01,  1.2705e-01,\n          1.4555e-01,  1.1970e-01, -4.4443e-02, -2.0929e-01, -2.0089e-01],\n        [ 1.4838e-02,  7.9197e-02, -8.6803e-02,  1.9035e-01, -1.9379e-01,\n         -6.4590e-02, -1.9543e-01,  5.9410e-02, -6.8486e-03, -1.6944e-01,\n         -1.7176e-02,  1.7227e-02, -4.2472e-02,  1.8464e-01, -1.1425e-01,\n          9.4298e-02, -2.0203e-01,  1.2425e-03, -9.0145e-02,  4.8817e-02],\n        [ 6.1714e-02,  7.5734e-02, -1.4053e-01,  1.7522e-01,  2.7787e-02,\n          2.1951e-01,  5.5724e-02,  2.0683e-01,  1.8449e-01, -8.0642e-02,\n         -1.0033e-02, -1.8185e-01,  2.0263e-01, -1.9203e-01, -1.9811e-01,\n          2.0867e-01, -4.4203e-02, -2.0897e-01,  5.7883e-03, -1.2009e-01],\n        [ 2.0369e-01,  1.5826e-01, -4.4055e-02, -1.9326e-01, -9.9067e-02,\n          7.2745e-02,  6.0219e-02, -1.6856e-01, -1.5773e-01, -1.9142e-02,\n         -1.4550e-03, -8.5079e-02,  7.5198e-02,  4.9830e-02,  1.7166e-01,\n          6.5418e-02, -2.1596e-01, -1.8865e-01, -1.5519e-01, -1.0983e-02],\n        [ 4.5756e-02,  8.7060e-02, -1.4226e-01,  1.0961e-01, -1.3057e-01,\n         -1.2602e-01,  1.4436e-01,  7.2360e-02,  7.1772e-02,  9.4596e-02,\n         -5.1584e-02, -2.1815e-01,  1.4979e-01,  2.3095e-02,  8.9645e-05,\n          5.0926e-02,  1.8261e-01, -2.0071e-02, -1.3602e-01, -5.3495e-02]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1318, -0.0659,  0.1274,  0.1155, -0.1115,  0.2207,  0.1279, -0.0134,\n        -0.1960,  0.0985, -0.2158, -0.1411,  0.1374, -0.0316, -0.1732,  0.1169,\n         0.1711,  0.0068, -0.2036,  0.1954,  0.1077, -0.2168,  0.0714, -0.2155,\n        -0.0622,  0.0077, -0.0289, -0.1352, -0.0493,  0.0433, -0.2080, -0.1268],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-2.0856e-02, -1.0267e-01,  2.3339e-02, -1.4274e-01, -7.3446e-02,\n          3.6371e-02, -9.9847e-02, -9.8846e-02, -8.2093e-03,  1.6841e-01,\n         -1.4535e-01, -3.7314e-02, -1.7076e-01,  1.6927e-01, -1.3688e-01,\n          8.3668e-02, -7.8711e-02, -1.1139e-01, -1.1036e-01, -1.6284e-02,\n          8.4078e-02,  1.1092e-02,  4.9721e-02, -2.6663e-02, -1.8108e-02,\n          1.5005e-01,  1.5656e-01,  1.1987e-01,  1.2211e-01, -5.0372e-02,\n         -9.8078e-02, -2.4229e-02],\n        [ 5.0506e-02, -2.5892e-02,  1.1823e-01,  8.5353e-02, -4.6333e-02,\n          1.3766e-01, -1.2607e-01,  1.6865e-01, -3.2979e-02, -9.3310e-02,\n          1.7258e-01, -1.4444e-01,  1.4916e-01, -1.3432e-01,  1.5709e-01,\n         -1.1324e-01,  2.8339e-02,  1.2710e-01,  5.9444e-02,  1.6369e-01,\n          1.5895e-02,  3.9211e-02,  1.5846e-01,  2.9371e-02, -9.7102e-02,\n          1.7681e-02,  1.0975e-01,  4.6412e-02,  2.7128e-02, -8.4242e-02,\n         -1.3254e-01, -4.6406e-02],\n        [-1.1945e-01, -2.6172e-03, -6.9412e-02,  1.2323e-01, -2.9747e-02,\n         -1.2990e-01, -7.9325e-02, -8.3558e-02,  4.9298e-03,  3.6339e-02,\n          2.7867e-02,  1.5668e-01, -7.2345e-02,  1.6101e-01, -6.8799e-03,\n         -7.9392e-02,  6.2788e-02, -4.6288e-03, -6.8624e-02, -1.4112e-01,\n         -1.2631e-01, -7.9598e-02,  1.7390e-01, -5.5837e-02, -8.7577e-02,\n         -2.6463e-02, -1.1686e-01, -1.1014e-01, -1.6269e-01,  4.2336e-02,\n          1.2020e-01, -9.1018e-02],\n        [ 3.0751e-02,  1.0197e-01,  1.3427e-01, -3.7504e-02, -1.0906e-01,\n          9.7860e-02,  6.1332e-02,  9.5512e-02,  1.2387e-01,  1.1511e-01,\n         -1.6634e-03,  1.3816e-01, -8.9989e-02, -4.7323e-02,  4.2399e-02,\n         -1.1064e-01,  1.6488e-01,  1.2680e-02,  9.1183e-02, -5.3009e-02,\n         -1.6114e-02, -1.5278e-01,  1.1132e-01,  1.5492e-01, -3.1443e-02,\n          2.5398e-02, -1.0745e-01, -6.6736e-02, -9.0074e-02,  1.3083e-02,\n         -1.1931e-01,  1.7442e-01],\n        [-1.6926e-01,  1.4120e-01,  3.5427e-03,  1.5427e-01,  1.2170e-01,\n          1.2964e-02, -3.0644e-02, -3.4287e-02,  2.7113e-02,  1.6029e-01,\n         -9.6997e-03, -2.6913e-02, -7.5190e-02, -1.6435e-01,  1.8869e-02,\n          8.4701e-02, -7.7349e-02, -2.9102e-02, -6.6716e-02,  4.0849e-02,\n          6.8068e-02, -7.0048e-02,  9.5211e-02,  1.2290e-01, -3.9347e-02,\n         -6.2562e-03, -1.1021e-01,  1.7433e-01, -1.6429e-01,  1.4271e-01,\n         -1.4365e-02,  1.5025e-01],\n        [-1.3448e-01, -5.5472e-02,  4.8110e-02,  7.9738e-02,  4.2203e-02,\n         -3.1043e-02, -1.1324e-01, -9.3385e-02, -1.3803e-01,  1.2299e-01,\n          8.3294e-02,  1.3373e-01, -5.2565e-02,  7.5288e-03, -8.0476e-02,\n          1.1392e-01,  4.5387e-02, -2.2257e-02,  1.6327e-01, -1.5962e-01,\n         -1.3508e-01, -1.4214e-01,  1.7244e-01, -3.6566e-02,  1.2385e-01,\n          4.2415e-02,  6.6853e-02, -1.0506e-03, -1.1206e-02, -1.1090e-01,\n          1.2402e-02,  5.1809e-02],\n        [-1.1233e-01,  1.3771e-01,  1.2185e-01,  4.3402e-02, -1.1602e-01,\n          1.3417e-01,  1.9068e-02,  6.8655e-03, -8.9609e-02,  8.6128e-02,\n          1.4586e-01, -2.7502e-02, -4.3809e-02, -1.4090e-01, -2.7364e-02,\n          1.0241e-01, -1.4494e-01,  1.0125e-01,  7.8871e-02,  1.0687e-02,\n          1.8082e-03, -1.5044e-01,  3.1177e-02, -2.1911e-02, -1.4994e-01,\n         -1.5376e-02,  3.8978e-02, -8.4068e-02,  9.6095e-02,  8.8626e-02,\n          1.5174e-01, -1.5831e-01],\n        [-1.3686e-01, -1.6650e-01, -1.4875e-01,  9.6070e-02,  1.4039e-02,\n          3.1311e-02, -5.2074e-02, -1.4004e-02, -1.4839e-01, -9.5387e-02,\n          2.8363e-02, -1.7388e-01,  8.7763e-02,  1.3956e-01,  1.7261e-01,\n          1.6677e-01, -1.2661e-01,  1.5220e-01,  1.7257e-01, -1.6498e-02,\n         -1.0617e-01,  4.9165e-02, -7.3568e-02, -1.6737e-01,  1.3994e-01,\n          8.0045e-02,  5.7124e-02,  1.4654e-01,  1.6949e-01, -2.2194e-02,\n         -4.3797e-02,  8.4673e-02],\n        [-8.2403e-02, -1.0158e-01, -6.3334e-02,  7.4581e-02, -8.1808e-03,\n         -5.2482e-02,  1.5364e-01,  1.5364e-01,  1.4415e-01,  5.1270e-02,\n          1.3602e-02,  7.8213e-02,  3.5133e-02,  1.3668e-01, -8.2532e-02,\n         -3.1019e-02,  1.4514e-01, -2.4687e-02, -7.5822e-02,  7.7764e-03,\n          1.1271e-01, -1.0577e-01,  5.3273e-02, -1.1509e-01, -1.0282e-01,\n          2.1136e-02,  3.9174e-02, -6.1441e-02, -1.5289e-01,  1.4579e-01,\n          1.6554e-01, -8.9985e-02],\n        [ 7.1620e-02,  4.5216e-02,  1.7449e-01,  2.2392e-02, -1.1014e-01,\n         -1.5997e-01,  1.6508e-01,  1.5563e-01,  4.9818e-03,  1.8932e-02,\n          1.6926e-01, -5.0283e-02,  1.4836e-01, -4.5207e-02, -1.3374e-01,\n          9.5216e-02,  7.4068e-02,  3.5449e-02,  8.6217e-02,  8.3719e-02,\n          1.4242e-01,  2.8189e-02,  1.2728e-01,  1.0686e-01,  1.1016e-01,\n         -1.3680e-01,  8.2191e-02,  5.3151e-02,  7.0023e-02, -2.2309e-02,\n          4.1950e-02, -1.9622e-02],\n        [ 3.6406e-02,  2.6940e-02, -5.7349e-03,  1.3164e-01, -2.8264e-02,\n         -1.4644e-01, -7.2529e-02, -3.2178e-02, -9.1713e-03, -1.6382e-01,\n         -3.3378e-02, -1.5639e-01, -2.5033e-02,  1.5699e-01,  3.4700e-02,\n          3.6648e-02,  9.1546e-02,  4.3773e-02,  1.4696e-01, -8.1109e-03,\n         -1.8270e-02,  3.7004e-02,  1.6613e-01, -1.8655e-02, -5.3819e-02,\n         -3.8727e-02, -1.2767e-01, -1.6486e-01, -5.6457e-02, -2.2652e-02,\n          1.4973e-01, -1.0032e-02],\n        [ 4.2277e-02,  1.2080e-01,  3.7675e-03, -8.2755e-02, -1.0469e-01,\n          1.5684e-01, -1.0685e-01, -4.9224e-02, -5.3243e-02,  6.0973e-02,\n          6.2087e-02,  7.6998e-02,  1.4513e-01,  1.3598e-01, -1.3153e-01,\n          1.6020e-01,  1.0794e-02, -1.4083e-01,  8.1877e-02, -9.6102e-02,\n         -8.5342e-02,  1.2878e-01,  7.6506e-02,  8.5454e-02, -8.8232e-02,\n          9.5102e-02, -3.5775e-02,  1.3895e-01, -6.1990e-02, -4.5402e-02,\n         -1.4395e-01, -4.6362e-02],\n        [-9.3545e-02,  5.0813e-02, -1.3918e-01, -1.2854e-02, -5.4957e-02,\n         -7.8877e-02,  1.2468e-01,  2.5654e-03,  1.1159e-01,  1.3127e-01,\n          1.1669e-01, -1.5957e-01,  4.6296e-02, -1.3095e-01, -1.0398e-01,\n          2.3851e-02, -1.4008e-01,  2.6715e-02,  3.0159e-02,  5.9245e-02,\n         -2.4360e-02,  1.0639e-02, -5.8674e-02, -1.6605e-01, -2.9472e-02,\n         -1.2020e-01,  1.3394e-01, -7.5543e-02,  1.1418e-01, -1.3727e-01,\n          1.1951e-01, -1.7120e-02],\n        [-6.8233e-02,  8.2650e-02, -9.8061e-02, -7.0917e-02, -1.4920e-01,\n         -1.5390e-01, -9.0966e-02,  6.9671e-02,  7.4412e-02,  9.1616e-02,\n          1.7123e-01,  7.4660e-02, -6.6061e-02,  2.4598e-03,  1.6442e-01,\n          9.7588e-02,  7.7340e-02,  1.5469e-01, -6.8184e-02,  2.8361e-02,\n         -1.5601e-01,  6.4543e-02, -1.0415e-01,  6.0671e-02, -3.8524e-02,\n          1.1119e-01,  1.2397e-01, -5.9856e-02, -1.6304e-01,  8.3914e-02,\n          2.9409e-02, -1.5902e-01],\n        [-1.5743e-01, -1.1488e-01, -1.0817e-01,  1.5483e-02, -1.4273e-01,\n          7.1743e-02,  1.1849e-01,  1.4343e-02,  1.2127e-02,  1.2190e-01,\n          1.3227e-01,  1.0240e-01,  9.5366e-02, -4.6853e-02,  7.9804e-02,\n         -7.0197e-02, -5.9841e-03, -1.7653e-01, -1.5062e-01, -2.5236e-03,\n         -1.5692e-01,  6.3155e-02, -5.6274e-02, -1.7357e-01, -2.2491e-02,\n          9.7366e-02, -5.8891e-02,  4.8131e-05,  6.0233e-02,  8.6879e-02,\n         -8.7442e-02, -9.6025e-02],\n        [ 1.1781e-01,  3.0939e-04, -1.2199e-01,  1.6003e-01, -1.0653e-01,\n         -3.1618e-02,  2.0335e-02, -3.7451e-02,  7.0387e-02,  1.5937e-01,\n         -1.4574e-01, -2.6567e-03, -1.5378e-01,  1.6770e-01, -4.8725e-02,\n          6.2579e-02, -7.1663e-04,  6.7577e-02,  1.5791e-01, -1.3550e-01,\n         -1.3793e-01, -1.3855e-01,  1.6577e-01,  5.8366e-02,  1.8876e-02,\n         -1.6682e-01, -9.8589e-02,  1.0119e-01, -1.4029e-01, -1.1492e-01,\n          6.5554e-02, -1.2560e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1121, -0.1675, -0.0432, -0.0013,  0.1176,  0.1577,  0.1249, -0.0437,\n        -0.1268, -0.1470, -0.0723,  0.1689, -0.0629, -0.0795,  0.0007,  0.0028],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1727, -0.0609,  0.1178, -0.2034,  0.0397,  0.1771, -0.1795, -0.0497,\n          0.2260, -0.2270, -0.0520, -0.1947, -0.2203,  0.2136,  0.1457,  0.0296],\n        [-0.0751,  0.1690,  0.0745, -0.0613, -0.0032,  0.1037, -0.0330,  0.1584,\n         -0.1034, -0.1685,  0.1720,  0.2268, -0.0638, -0.2285, -0.1014, -0.1248],\n        [-0.1444, -0.0234,  0.0924,  0.2154,  0.0157, -0.1571,  0.0481, -0.1882,\n          0.0345, -0.1795,  0.0041,  0.0391,  0.2019, -0.1964,  0.0617,  0.0885],\n        [-0.1243,  0.0462,  0.1742, -0.1004, -0.0413,  0.2363,  0.2373,  0.1927,\n          0.0401,  0.0363,  0.1011, -0.0517,  0.0335,  0.0883, -0.1377, -0.2113],\n        [ 0.0642, -0.0427,  0.1210, -0.0975,  0.1215, -0.1387, -0.0151, -0.2289,\n         -0.1350,  0.1330, -0.1041, -0.2500, -0.2479,  0.1570,  0.0518, -0.0010],\n        [-0.0010, -0.2459, -0.1353,  0.0777,  0.0995, -0.0924,  0.0163,  0.0698,\n         -0.0042, -0.2180,  0.2006, -0.2019,  0.2257,  0.0432, -0.1983, -0.0494],\n        [ 0.1465, -0.0784, -0.1492, -0.1161, -0.1401,  0.1454,  0.1155,  0.1445,\n          0.0908, -0.0550,  0.1212, -0.2214,  0.0042, -0.0352,  0.1833,  0.0358],\n        [-0.1073,  0.1681,  0.1762, -0.1209,  0.2348, -0.1612,  0.1927,  0.2392,\n         -0.0484, -0.2188,  0.1297,  0.1560,  0.1546,  0.2016,  0.2203,  0.1292]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2465,  0.0873, -0.1908,  0.2489,  0.0888,  0.0403, -0.0639, -0.1380],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1920, -0.1811,  0.2219, -0.2458, -0.1106, -0.3258,  0.1183, -0.0661]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0822], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001312D79F040>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-ppo-info\\rl4sys-ppo-info_s234120000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='D:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\maze-game\\\\./logs/rl4sys-ppo-info\\\\rl4sys-ppo-info_s234120000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	40,
    "train_v_iters":	40,
    "traj_per_epoch":	5,
    "vf_lr":	0.0003
}