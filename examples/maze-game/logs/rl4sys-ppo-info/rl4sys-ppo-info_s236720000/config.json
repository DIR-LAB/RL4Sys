{
    "__class__":	"PPO",
    "buf_size":	50000,
    "clip_ratio":	0.1,
    "env_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game",
    "exp_name":	"rl4sys-ppo-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	5,
    "lam":	0.97,
    "log_data_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-info",
        "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-ppo-info\\rl4sys-ppo-info_s236720000"
    },
    "pi_lr":	0.0003,
    "seed":	236720000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x000001BF1428EC80>":	{
            "_clip_ratio":	0.1,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (pi_network): Sequential(\n      (0): Linear(in_features=4, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n    )\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (pi_network): Sequential(\n    (0): Linear(in_features=4, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.2064,  0.0043, -0.3348, -0.3983,  0.1947,  0.2997, -0.4807,  0.0095,\n         0.3971, -0.4541, -0.0341, -0.0520, -0.0793, -0.3871, -0.2526, -0.1254,\n        -0.2895, -0.1998,  0.1125, -0.1528,  0.2952,  0.3481, -0.0559, -0.1519,\n         0.1480, -0.3310,  0.2982, -0.3335, -0.0386, -0.2588,  0.1494,  0.3746],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.2951, -0.4564, -0.3964, -0.0430],\n        [-0.1024,  0.3944,  0.2538, -0.3133],\n        [-0.4332,  0.1696, -0.2764,  0.1306],\n        [ 0.1555,  0.4964, -0.1053,  0.0908],\n        [ 0.1151,  0.1046, -0.4503,  0.4207],\n        [-0.3930,  0.0457, -0.2834,  0.4202],\n        [ 0.4302, -0.4618,  0.1685, -0.4231],\n        [ 0.1000,  0.4234,  0.3685,  0.3131],\n        [ 0.0564,  0.4671, -0.0480,  0.0647],\n        [-0.4175,  0.4509,  0.0892,  0.1741],\n        [ 0.3373, -0.3645, -0.2688,  0.1982],\n        [ 0.0635,  0.1552,  0.2083, -0.1519],\n        [ 0.0514, -0.2451, -0.3379, -0.0660],\n        [ 0.2755,  0.2628, -0.3310, -0.4047],\n        [ 0.3670, -0.3103, -0.0108, -0.0806],\n        [ 0.1842,  0.1123, -0.2858, -0.4900],\n        [-0.2109,  0.3875,  0.0879, -0.2523],\n        [ 0.4778,  0.2566,  0.4297,  0.4131],\n        [-0.4759, -0.4089,  0.3891,  0.4799],\n        [ 0.1643,  0.0925,  0.0190,  0.3544],\n        [ 0.0868, -0.1658,  0.1821, -0.1065],\n        [-0.1419, -0.4481,  0.2679, -0.1647],\n        [-0.4498, -0.3970,  0.0268, -0.4875],\n        [-0.2096, -0.3769,  0.4738, -0.2334],\n        [ 0.4267,  0.1861, -0.1051,  0.4755],\n        [ 0.3516,  0.2999,  0.0168, -0.3555],\n        [-0.4010,  0.2889, -0.1929, -0.4784],\n        [ 0.1707, -0.3407,  0.0627,  0.1049],\n        [-0.0168, -0.3910, -0.1777,  0.0386],\n        [-0.2371,  0.4125, -0.0211, -0.3695],\n        [-0.1315,  0.1272, -0.3992,  0.0729],\n        [-0.2507, -0.0005, -0.0093,  0.2039]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0616, -0.0308,  0.0211,  0.0206,  0.0560,  0.0316,  0.1317, -0.1096,\n        -0.0433, -0.0540,  0.0216,  0.1408, -0.0039, -0.0700, -0.1437, -0.1358],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-2.4320e-02,  4.5218e-02,  9.6151e-02, -7.3806e-02,  1.1766e-01,\n         -1.4315e-01,  1.2708e-01,  9.3242e-02, -1.6065e-01, -9.6204e-03,\n         -3.7261e-02, -2.1537e-02, -1.7505e-01, -3.8918e-02, -3.3511e-02,\n         -3.4263e-02, -1.8751e-02,  1.4676e-02, -1.4433e-01, -1.7296e-01,\n         -7.8217e-02,  8.8152e-02,  1.1500e-01, -1.4427e-01, -1.0983e-01,\n          4.6109e-02, -1.1863e-01,  1.1680e-01,  5.7292e-02,  9.4554e-02,\n          1.1445e-02,  9.5593e-02],\n        [-1.1758e-01, -1.5862e-01,  2.0744e-02, -1.5883e-01,  9.3906e-02,\n         -1.4002e-02,  8.7013e-02, -1.7446e-01, -9.7843e-02, -5.6312e-02,\n         -1.6527e-01,  1.5047e-02,  1.0391e-01,  1.0991e-01, -1.3441e-01,\n         -5.4873e-02,  5.0217e-06, -1.2651e-01,  1.7184e-01,  1.6306e-01,\n          3.2625e-02, -8.9074e-02,  2.7442e-02, -3.7973e-02, -7.1255e-02,\n          1.3075e-01, -1.5289e-01, -1.2791e-01, -4.6148e-02,  1.4447e-01,\n         -3.0664e-02, -1.7468e-01],\n        [ 1.4046e-01,  2.2246e-02, -1.2507e-01,  7.8343e-02, -1.6552e-01,\n          8.2227e-02, -1.2485e-01, -3.7459e-03, -1.0165e-01,  4.3586e-03,\n          7.8279e-02,  8.3550e-03,  6.2118e-02,  7.6246e-02, -1.1055e-01,\n          8.4211e-02, -5.1694e-02,  4.9128e-02,  9.5216e-02, -1.0538e-01,\n          1.3516e-01,  1.5002e-01, -7.8371e-02, -9.0658e-03, -1.1854e-01,\n         -9.5768e-03,  1.6670e-01, -1.2279e-05, -2.7031e-02,  2.9097e-02,\n          1.4942e-01, -9.9946e-02],\n        [-5.8295e-02, -4.2103e-02,  1.0648e-01,  1.0642e-01, -1.5970e-01,\n          5.3135e-02, -1.2807e-01,  4.3077e-02, -1.4003e-01,  7.3915e-02,\n          1.4460e-01,  2.8569e-02,  1.6278e-01, -8.5146e-02, -1.2302e-01,\n         -8.3454e-02, -1.3541e-01, -1.6920e-01,  2.7572e-02, -4.3569e-02,\n         -1.5748e-01,  4.1133e-02, -1.5217e-01, -1.3920e-01, -1.7132e-01,\n         -1.1022e-01, -9.7017e-02,  1.2664e-01,  3.2039e-02, -1.3756e-01,\n          1.0502e-01,  1.1478e-02],\n        [ 1.5372e-01, -6.8312e-02, -1.7312e-01, -1.6263e-02,  1.3055e-01,\n          2.6041e-02, -8.0178e-02, -7.8969e-02,  9.4886e-02, -1.5557e-01,\n         -5.0613e-02,  8.3459e-02,  3.8144e-02,  1.4335e-01,  5.1064e-02,\n         -7.2107e-02,  1.7505e-01, -1.5244e-01, -1.5701e-01, -4.7237e-02,\n         -1.0146e-01, -8.8715e-02, -8.3616e-02,  1.2445e-01, -1.9492e-03,\n          9.2354e-02,  5.8611e-02,  8.7468e-02,  5.5291e-02, -1.4255e-01,\n         -9.0757e-03, -1.2104e-02],\n        [ 1.0375e-01,  6.8837e-02, -2.7288e-02, -1.3986e-01, -7.2502e-02,\n          1.1986e-01,  1.1976e-01, -8.9844e-02, -1.2533e-01,  1.8763e-02,\n         -1.3824e-01, -1.4875e-01, -5.9096e-02, -1.2607e-01, -1.2816e-01,\n          8.4586e-02,  1.2812e-03, -8.7334e-02, -1.0419e-01,  1.6290e-01,\n         -3.2139e-02, -1.4213e-01,  9.8335e-02,  2.0335e-02, -1.3937e-01,\n          1.2592e-01,  1.5348e-02,  1.4016e-02, -6.7087e-02, -1.5070e-01,\n          3.3929e-02,  2.2012e-02],\n        [-9.1081e-02, -7.1465e-02, -1.5440e-01, -6.5796e-02, -1.0943e-01,\n         -6.6427e-02,  8.5730e-02,  1.3081e-01,  4.4414e-02, -1.7548e-01,\n         -3.0258e-02,  6.9516e-02, -1.3827e-01, -1.4626e-01,  1.7177e-01,\n         -1.5921e-01, -3.8451e-02, -1.3361e-01, -1.3006e-01,  7.2827e-02,\n          1.8717e-02, -1.0082e-01, -1.7727e-02,  1.6974e-01, -3.4091e-02,\n         -1.1765e-01,  8.2182e-02, -8.4686e-02,  1.4812e-01,  1.3446e-01,\n          7.5266e-02,  1.2719e-01],\n        [ 8.9666e-02, -1.6856e-01, -4.9677e-03, -1.1181e-01, -4.6004e-02,\n          1.6734e-01, -4.7893e-02, -8.8826e-02, -7.7757e-02,  1.7516e-01,\n          4.1866e-02,  8.1780e-02, -1.2412e-01,  1.0229e-01,  1.6579e-01,\n         -6.8607e-03,  2.0868e-02,  9.2355e-02, -6.8308e-02, -3.0849e-02,\n         -5.6690e-02, -3.5963e-02,  1.6350e-01,  1.0847e-01,  7.1180e-02,\n         -1.4891e-01, -4.3512e-02, -6.1698e-02, -1.1763e-01, -6.2196e-02,\n         -5.1172e-02,  1.5049e-01],\n        [ 8.6447e-02,  1.7103e-01,  1.0351e-01,  1.1969e-01, -1.5386e-01,\n          1.5745e-01,  1.2043e-01, -5.7139e-02, -1.7436e-01,  1.0910e-01,\n          1.5386e-01, -2.0911e-03, -9.8860e-02, -6.6696e-02,  1.1387e-01,\n          1.1561e-01, -1.6058e-01,  1.2822e-02, -9.2903e-03, -2.7956e-02,\n          2.6723e-02,  1.3002e-01, -1.8061e-02, -2.5132e-02, -2.8234e-02,\n          7.8925e-02, -1.7288e-01, -5.5733e-04, -1.1198e-01, -1.5665e-02,\n         -3.4976e-02,  1.5757e-02],\n        [ 6.9582e-02, -5.0816e-02, -1.7668e-01, -8.5722e-02, -3.6699e-02,\n          9.3409e-02, -1.1955e-01, -1.0040e-01,  8.5435e-02,  1.1394e-01,\n         -4.4491e-02, -1.2937e-02,  1.6983e-01,  4.5360e-02, -4.6500e-02,\n          5.9169e-02,  7.5912e-02, -1.4893e-01, -4.6462e-02,  8.6995e-02,\n         -1.5355e-01,  4.8374e-03, -8.1338e-02,  1.5649e-01, -1.7281e-01,\n          1.7429e-01,  7.0995e-02, -1.1431e-01, -2.5339e-02, -6.5863e-02,\n         -1.6240e-01, -1.5741e-01],\n        [-1.7460e-02, -1.5583e-01, -1.3599e-01,  8.3063e-02, -1.2228e-01,\n         -1.7464e-01, -2.1753e-03, -8.9034e-02, -1.7509e-01,  1.3122e-01,\n          3.4690e-02,  1.3959e-01, -4.0958e-02, -1.1910e-01,  1.0269e-01,\n          1.0157e-03, -1.6640e-01,  1.0794e-01,  1.0478e-01, -1.6547e-01,\n         -1.3454e-01,  1.7234e-02,  7.4960e-03,  2.0754e-03, -1.1896e-01,\n         -6.9282e-03, -1.6003e-01,  7.7098e-02,  1.6804e-01,  1.1744e-01,\n         -9.4236e-02,  1.2834e-01],\n        [-1.5270e-01, -1.7086e-01,  1.4026e-01,  1.4333e-01, -1.6018e-01,\n         -1.0100e-01, -8.7606e-02, -1.2341e-01, -1.1103e-01,  5.4709e-02,\n         -9.6026e-02,  3.1266e-02, -9.1593e-02,  2.3757e-03, -1.3610e-01,\n          1.0956e-01,  1.3567e-01, -6.4970e-03, -1.8982e-02,  1.4965e-01,\n         -3.4958e-05,  1.7555e-01, -1.3758e-02,  1.6301e-01,  7.3762e-02,\n          3.5298e-02, -3.6669e-02, -9.7900e-02,  9.6366e-02, -6.2063e-03,\n          2.1897e-03,  4.8375e-02],\n        [ 1.3429e-01,  9.3161e-02,  6.8153e-02, -1.6453e-01,  5.9687e-04,\n         -1.8544e-02,  3.2553e-02, -1.9022e-02,  1.0205e-01,  4.2471e-02,\n         -4.2831e-02, -3.7230e-02,  5.6634e-02, -1.5960e-01, -9.8817e-02,\n         -9.4395e-02, -6.4964e-02,  3.8801e-02, -1.6580e-01,  5.6655e-02,\n          3.2910e-02,  8.4284e-02,  8.1365e-03, -3.4956e-02,  1.3017e-01,\n          1.7646e-01, -1.3393e-01,  4.8934e-02, -8.5671e-02,  7.9304e-02,\n          1.5865e-01,  9.6797e-02],\n        [-1.2532e-02, -8.4400e-02,  4.0264e-02,  4.3532e-02,  1.3962e-01,\n         -9.3115e-02,  1.0065e-01,  9.2826e-03, -1.4377e-01,  1.1553e-01,\n          8.0982e-03, -5.2863e-03, -1.6681e-01, -1.4909e-01, -1.1292e-01,\n          7.7291e-03,  1.0535e-01,  1.6786e-01, -1.3710e-01,  4.7705e-02,\n          3.9568e-02,  8.2788e-03, -5.1748e-02,  5.5071e-02,  1.1873e-01,\n         -1.5271e-01,  7.7795e-02, -1.5522e-01,  5.0674e-02, -9.3254e-02,\n          1.7566e-01, -9.5069e-02],\n        [ 1.4987e-01, -4.6616e-02,  1.6776e-01, -1.4444e-01,  8.5551e-03,\n          3.2402e-02,  1.3584e-02, -4.2179e-02,  5.9896e-02,  1.1987e-01,\n         -1.1206e-01,  4.9056e-02,  1.2809e-01, -8.2027e-02, -7.4568e-02,\n          3.3496e-02, -1.3507e-01, -1.2411e-01, -1.3944e-01,  9.0136e-02,\n          5.5252e-02,  4.1186e-02,  1.0203e-01, -1.5018e-01, -1.1750e-01,\n         -1.1752e-01, -1.2791e-01, -1.1182e-01,  3.3826e-03, -6.5571e-02,\n         -1.2099e-01,  8.1042e-02],\n        [ 9.9705e-02, -7.9024e-02, -8.4297e-02, -1.3261e-01,  2.4962e-02,\n         -7.3665e-02,  9.4116e-02, -5.1465e-02,  1.0856e-01,  4.1498e-02,\n          1.4214e-01, -3.1482e-02, -1.3557e-01,  2.0442e-02,  6.3668e-03,\n         -4.1103e-02,  3.4274e-02, -7.3056e-02,  3.3006e-02,  2.8494e-02,\n         -7.1171e-02,  1.5983e-01, -1.0389e-01,  1.3078e-01, -1.1345e-01,\n          9.6691e-02, -1.0780e-01,  4.2356e-02,  1.5717e-01, -6.2890e-02,\n         -3.2184e-02, -1.4693e-01]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2184, -0.0528,  0.1470,  0.1923, -0.2057,  0.1799,  0.0187, -0.0411],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1262, -0.0514, -0.1693, -0.1065, -0.2117, -0.1597,  0.1222, -0.1401,\n          0.0097,  0.1289, -0.1396,  0.0748,  0.0729,  0.2284, -0.1427,  0.0948],\n        [-0.0598, -0.1944, -0.1666, -0.1039,  0.0330,  0.0053, -0.0707,  0.0964,\n          0.2333, -0.0958, -0.1006,  0.0758,  0.1702,  0.2171,  0.1718,  0.0797],\n        [-0.2351, -0.1508, -0.1066,  0.1803, -0.0556,  0.0410, -0.1133,  0.0475,\n         -0.1858,  0.2283,  0.1745,  0.0460, -0.1352,  0.1239, -0.1116,  0.0962],\n        [ 0.0818, -0.0031, -0.0845, -0.0960, -0.0996,  0.1441, -0.1319, -0.0867,\n          0.1378,  0.1372,  0.0709, -0.0278,  0.0010, -0.0119,  0.1288, -0.0582],\n        [-0.0218, -0.0153, -0.1783,  0.1684,  0.1974,  0.0147,  0.1312, -0.1630,\n         -0.2160, -0.0291,  0.1787, -0.0449,  0.0536,  0.0024, -0.0206,  0.1637],\n        [ 0.0808,  0.1870, -0.2459, -0.1871,  0.0686, -0.1943, -0.1672,  0.0361,\n         -0.2342, -0.0547, -0.1404,  0.2454, -0.2460,  0.2348,  0.0352,  0.1593],\n        [ 0.1726, -0.0739,  0.2481, -0.2087, -0.1241, -0.0878,  0.1137,  0.2247,\n          0.0726,  0.0252,  0.2446,  0.1547, -0.2227, -0.0722, -0.1682,  0.1488],\n        [ 0.2479, -0.1514, -0.2321,  0.0822,  0.2489,  0.0311,  0.0219, -0.1442,\n         -0.1301,  0.2035, -0.1890, -0.0769, -0.0763,  0.0348,  0.0974, -0.0558]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.3350], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.2890,  0.0892,  0.3352,  0.2294,  0.2209, -0.2580,  0.2955, -0.2886]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "kernel_dim":	4,
                                "kernel_size":	5,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0011, -0.1087,  0.0553,  0.2162, -0.1184, -0.1990, -0.0046, -0.2143,\n         0.2201,  0.1346,  0.1459,  0.1515,  0.1878,  0.1394,  0.0699, -0.1859,\n         0.1926, -0.2070, -0.0257,  0.1629, -0.0449,  0.0780, -0.2120, -0.1855,\n        -0.2087, -0.0403, -0.0524, -0.0648,  0.1812,  0.0568,  0.1120, -0.1004],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 3.1819e-02, -1.9322e-01, -7.0367e-02,  1.4016e-01,  1.0684e-01,\n         -2.1079e-01, -1.4693e-01, -2.1880e-01, -3.8784e-02,  2.0076e-01,\n         -1.1813e-01, -7.2086e-03, -9.7781e-02,  1.1615e-01,  1.1380e-01,\n          1.4018e-01,  1.7808e-01, -1.7884e-01, -3.4437e-02, -2.1399e-01],\n        [ 9.8490e-02,  3.4965e-02, -2.0517e-02, -7.9081e-02, -7.5965e-02,\n          2.1622e-01, -2.9064e-02,  1.9266e-01, -5.1617e-02,  1.0188e-01,\n          1.2123e-01, -1.4690e-01,  3.9310e-02,  1.5293e-02, -8.0243e-02,\n          8.0778e-02, -1.1738e-01,  2.6573e-02, -6.9588e-06,  1.3576e-01],\n        [-1.5565e-01, -1.3627e-01, -1.6961e-03,  7.0543e-02,  1.5892e-01,\n         -1.9391e-01, -5.2815e-03, -1.5978e-01,  2.9315e-02,  2.0593e-01,\n         -1.6767e-01,  1.4109e-02,  7.4948e-02, -1.8597e-01,  1.5021e-01,\n         -5.7172e-02,  9.4211e-02, -7.2851e-02, -1.4696e-01, -2.1336e-01],\n        [-1.2648e-01,  4.8892e-02,  2.1475e-01,  1.0933e-01, -9.2337e-02,\n         -1.3698e-02, -1.8746e-01, -2.0903e-01, -1.6857e-01, -5.6113e-02,\n         -1.5902e-01, -9.7726e-02,  4.1217e-02,  1.9946e-01,  1.2181e-01,\n          1.2493e-01, -2.1007e-01, -8.2379e-02, -7.9954e-03,  1.9332e-01],\n        [ 4.6314e-02, -1.6392e-01, -2.2134e-01, -1.7449e-02,  2.1771e-02,\n          1.5554e-01,  2.1406e-01, -2.2360e-01,  2.0357e-01, -1.9605e-01,\n          1.9967e-01, -2.0490e-01, -1.8158e-01,  7.0415e-02, -1.6243e-01,\n          1.5298e-01,  1.9204e-01, -2.0721e-01, -1.2292e-01, -2.1121e-01],\n        [ 8.2620e-02, -5.0591e-02, -8.9491e-02, -5.6972e-02, -3.1854e-02,\n         -1.1820e-01,  5.3307e-02,  1.2867e-01, -9.1018e-02,  1.4272e-01,\n          1.0625e-01, -5.5635e-02, -1.6323e-01, -9.2312e-02,  4.5499e-02,\n         -9.9749e-02,  3.1924e-02,  1.5098e-01, -8.2738e-02,  2.2015e-01],\n        [ 3.1531e-03, -5.6567e-02, -1.1728e-01,  4.9849e-02,  5.8843e-02,\n         -1.1158e-02, -1.5550e-01,  4.3147e-02,  1.5754e-01,  5.4394e-02,\n          1.9454e-01, -3.3826e-02,  5.9714e-02, -1.3345e-01,  1.6352e-01,\n          8.6411e-02, -4.8698e-02,  2.2337e-01, -5.0680e-02,  4.7351e-02],\n        [-4.2637e-02,  1.7585e-01, -2.1822e-01, -4.8746e-03,  8.0025e-02,\n          6.7046e-02,  9.6276e-02,  1.8028e-01,  1.6872e-01,  1.4086e-01,\n          5.3888e-02,  2.2284e-02, -7.9142e-02, -2.2194e-01, -1.4585e-01,\n          5.2018e-02, -1.4203e-01, -3.3545e-02,  7.5303e-02, -1.3252e-01],\n        [-1.5573e-01,  6.8302e-02,  1.4954e-01,  1.0615e-01, -2.0018e-01,\n          1.8766e-01,  8.2101e-02,  8.3660e-02,  1.0271e-01, -7.4428e-02,\n          9.4505e-02,  1.7501e-01,  7.4978e-02, -7.3551e-02,  7.3098e-02,\n         -3.5556e-02, -2.8686e-02,  1.4609e-01,  4.8982e-02,  1.8591e-01],\n        [ 1.2499e-01, -1.7069e-01,  1.3616e-01,  1.0753e-01, -1.3886e-01,\n          9.4598e-02, -2.1722e-01,  1.8909e-01, -1.5942e-01,  3.3855e-02,\n         -1.1942e-01,  7.7629e-02,  1.5993e-01,  6.8468e-02, -1.6936e-01,\n          1.6691e-01, -7.9676e-02, -1.7481e-01,  1.2796e-01, -4.0314e-02],\n        [-4.2717e-02,  1.0989e-01,  1.3876e-01, -1.4927e-01, -8.0134e-02,\n          1.7538e-01,  6.4856e-02, -2.1028e-01, -2.6868e-02, -1.5697e-01,\n         -1.8895e-03,  1.0530e-01,  1.4190e-02,  2.1746e-01,  2.1490e-01,\n          1.0618e-01,  1.9677e-01,  1.0837e-01,  1.4044e-02,  2.0723e-01],\n        [ 1.0666e-01, -1.2874e-01, -2.9564e-02, -8.0515e-02, -1.2186e-01,\n         -1.4283e-01,  1.3781e-01,  1.5034e-01,  1.1834e-01, -2.6845e-03,\n          5.4332e-02, -7.4963e-02, -1.3988e-01, -8.8859e-02, -4.7742e-02,\n         -5.5335e-02, -5.3508e-02, -1.6187e-01, -2.0305e-02,  5.1788e-02],\n        [-1.6393e-01,  1.0980e-01,  1.0596e-01, -1.5808e-01,  1.2281e-01,\n          9.1878e-02, -7.6466e-02,  7.5460e-02, -5.4482e-02, -1.5568e-01,\n          1.4997e-01, -3.3087e-02,  7.8822e-02,  1.1565e-01, -2.0004e-01,\n         -1.7067e-01, -5.6754e-02, -1.9693e-01,  2.1450e-01, -3.5426e-02],\n        [ 2.1131e-01, -1.5860e-01,  6.0976e-02,  1.9957e-02, -2.0248e-01,\n          6.9235e-02, -1.7937e-01,  1.2608e-01, -1.5681e-01, -1.1868e-02,\n         -1.2878e-01,  1.5166e-01,  7.2821e-02, -1.7347e-01, -6.3026e-03,\n         -9.4969e-02,  1.4431e-02, -7.2362e-02, -1.3216e-01, -1.8882e-01],\n        [-3.3280e-02,  4.7230e-02, -1.5686e-01,  2.2288e-01, -1.0463e-01,\n          1.7265e-01, -7.6149e-02, -1.3199e-01, -1.3417e-01, -1.7683e-01,\n          1.3769e-01,  1.9298e-01,  6.7165e-04,  3.9745e-02,  1.7177e-01,\n         -2.0890e-01, -1.6570e-01,  1.2878e-02,  5.5730e-02,  7.9018e-02],\n        [-1.1084e-01, -1.5555e-02,  1.9673e-01, -1.1137e-01, -2.0958e-01,\n         -1.9356e-01,  1.2988e-01, -1.2434e-01,  8.3827e-02,  1.0214e-01,\n          5.9659e-02,  1.0438e-01, -3.3657e-02, -2.4850e-02, -1.8403e-01,\n          1.5594e-01, -3.4011e-02, -1.7082e-01, -1.6052e-01,  5.6204e-03],\n        [ 2.1708e-01,  1.5354e-01,  7.7518e-02,  1.2970e-01,  1.1193e-02,\n         -9.4692e-02,  9.3037e-02, -1.0663e-01,  3.9036e-02, -1.5263e-01,\n         -7.7897e-02,  1.6958e-01, -1.9785e-01,  1.2415e-01,  1.3919e-02,\n         -2.0432e-01,  1.9415e-01,  1.5237e-02, -1.0197e-01, -1.4914e-01],\n        [ 3.8825e-03, -1.8743e-01,  1.7307e-02,  2.1160e-02,  6.7178e-02,\n          8.7898e-02, -1.0567e-01, -1.8150e-01,  1.0919e-01, -5.0721e-02,\n          7.9379e-02, -1.9310e-02,  1.3164e-01, -8.2298e-02, -1.4386e-01,\n         -1.5243e-01,  2.1876e-01, -1.4451e-01,  1.6403e-01,  6.3016e-02],\n        [-3.3345e-02,  1.4894e-01, -7.4155e-02, -2.6155e-03,  6.4291e-03,\n         -1.0665e-01,  1.7436e-01, -1.5325e-01, -1.8735e-02,  1.1097e-01,\n         -6.2387e-02, -1.2491e-01,  1.5984e-01, -1.9886e-01, -1.1160e-01,\n         -2.3314e-02,  2.0051e-01,  1.2139e-01,  1.0500e-01,  5.7702e-02],\n        [-1.3352e-01, -1.4214e-02, -7.9071e-02,  5.7634e-02,  3.8932e-02,\n          9.8965e-02, -1.2450e-01,  1.8564e-01, -1.1163e-01,  1.0867e-01,\n         -2.1436e-01,  1.5014e-01,  1.5450e-01, -1.6690e-01,  6.3131e-02,\n         -2.1031e-01, -1.4141e-02,  2.0192e-03,  1.3369e-01, -8.2821e-02],\n        [ 1.9509e-01, -8.0578e-02,  4.3935e-02, -9.8779e-02, -1.9320e-01,\n          2.0936e-01,  4.0781e-02, -1.0129e-01, -1.9880e-01,  1.8043e-01,\n         -1.1595e-01, -1.7852e-02,  2.0347e-01,  1.7308e-01,  1.7784e-01,\n          1.1564e-01, -4.2920e-02, -1.5658e-02,  1.0518e-01,  1.1528e-02],\n        [-1.6729e-01,  3.1723e-02, -7.8497e-03,  2.1830e-01,  3.8169e-02,\n          1.2231e-01, -4.9433e-02, -1.9933e-01, -2.6171e-02, -2.1200e-01,\n          1.5178e-03, -1.6181e-01,  8.5160e-02,  1.2251e-01,  2.7359e-02,\n          1.8531e-01,  3.0405e-02, -3.7493e-02,  1.7099e-01,  9.9179e-03],\n        [ 5.3692e-02, -1.1413e-01, -2.1279e-02,  1.9307e-01, -4.3103e-02,\n          1.6619e-01, -1.5299e-01,  1.3588e-01, -9.0507e-03,  7.9188e-02,\n          6.1487e-02,  3.7480e-03,  1.4814e-01,  1.4292e-01,  2.8903e-02,\n          3.1207e-02, -2.0120e-01,  1.6874e-01,  1.7342e-01,  5.0034e-02],\n        [ 1.6485e-02, -1.4573e-01,  1.4540e-01,  1.2143e-01,  5.4226e-02,\n         -2.3384e-02,  1.3056e-02, -5.8067e-02,  1.4638e-01,  1.7091e-02,\n          1.6690e-01, -4.4778e-02, -1.7286e-02, -2.0449e-01,  1.2923e-02,\n          1.0271e-01, -7.1974e-03,  6.9103e-02,  3.8713e-02, -1.9777e-01],\n        [ 5.4852e-02,  1.2423e-01, -1.9860e-01, -2.1646e-02, -1.7469e-01,\n          9.5293e-02, -5.8640e-02, -1.1618e-01,  1.9823e-01, -8.7785e-02,\n         -2.1287e-02, -1.9243e-01,  4.1530e-02,  9.4257e-02, -1.5891e-01,\n         -4.6067e-02,  3.8807e-02, -1.6284e-01,  1.3952e-01, -2.1339e-01],\n        [ 1.3595e-01, -8.2160e-02,  2.0680e-01, -3.5831e-02,  7.8858e-02,\n         -1.2464e-01, -1.6595e-01,  1.1477e-01,  1.1009e-01,  4.4305e-02,\n         -1.4772e-01, -1.6033e-01, -1.6659e-01, -2.1889e-01,  1.7384e-01,\n          1.7215e-01,  1.3987e-01,  1.8542e-01,  1.0284e-01,  2.3392e-02],\n        [ 8.3062e-02, -1.0580e-01,  1.0313e-01,  1.2769e-01, -1.7558e-02,\n          3.7137e-02, -1.4375e-02,  3.0367e-02, -6.8897e-02,  2.1439e-01,\n          8.2464e-02,  2.6356e-02, -7.5291e-02,  1.0935e-01,  1.8952e-01,\n         -2.2358e-02, -1.8603e-02,  1.6848e-01,  1.5389e-01, -1.7947e-01],\n        [-1.3195e-01, -1.7695e-01, -1.7012e-01,  9.8381e-02,  1.1858e-01,\n          2.1537e-01, -4.4816e-02,  1.9167e-01,  1.0306e-01,  1.3341e-01,\n          8.1013e-03,  2.2016e-01, -1.1329e-01, -3.3957e-03,  1.7985e-01,\n         -1.3758e-01,  2.0585e-01, -1.6821e-01, -4.4650e-02, -2.2340e-01],\n        [ 7.2518e-02, -4.4904e-03, -1.6390e-01,  2.0832e-01, -1.7257e-01,\n         -2.0304e-01,  1.4314e-01, -1.5117e-01,  1.8538e-01,  8.0411e-02,\n          1.9081e-01, -1.7388e-01,  1.8605e-01, -1.1222e-02,  1.4672e-01,\n          1.4018e-02,  1.2376e-01,  1.9986e-01, -1.0009e-01, -1.4847e-01],\n        [ 1.6116e-01,  1.9727e-01,  6.9119e-02,  8.2738e-02,  2.3763e-02,\n          2.0788e-01,  1.1988e-01,  7.2764e-02, -3.2885e-02,  4.5256e-02,\n          1.0267e-01,  1.1198e-01, -1.8612e-01, -1.9953e-01, -1.6843e-01,\n          3.3595e-02,  1.5220e-01,  1.8032e-01,  1.4465e-01,  4.2304e-02],\n        [-5.8649e-02, -1.0836e-01,  1.8763e-01,  1.7834e-01,  8.0234e-02,\n         -8.1331e-02, -1.3862e-01, -1.2141e-02, -1.1253e-02, -1.6753e-01,\n         -3.3061e-02, -2.7284e-03, -1.4528e-01,  5.9621e-02,  2.5640e-02,\n         -2.1183e-01,  1.3060e-01,  1.4978e-01, -1.1986e-01,  1.0868e-01],\n        [ 2.8176e-02, -1.6882e-01,  1.4153e-01, -1.6666e-01, -1.0502e-02,\n          1.2535e-01,  2.1426e-01, -8.9809e-02,  4.8290e-02, -1.7584e-01,\n          1.9989e-01, -1.3972e-02,  2.1133e-01, -2.0380e-01,  1.6567e-01,\n          8.7763e-02,  1.1142e-01,  1.2097e-01,  4.1262e-02,  6.9339e-02]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1690,  0.1447, -0.0585, -0.1317,  0.1302, -0.1630, -0.1347,  0.0806,\n        -0.0861,  0.0725, -0.0833,  0.0193,  0.1193, -0.1222, -0.1003, -0.0620],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0738, -0.0602,  0.1027, -0.0479,  0.1575,  0.1762,  0.1513, -0.1094,\n         -0.0301, -0.1053, -0.0070, -0.0917,  0.1464,  0.1030, -0.0386, -0.0065,\n          0.1728, -0.0284, -0.1120,  0.1191,  0.0972,  0.1379,  0.0230,  0.0124,\n          0.0406, -0.1286, -0.0065,  0.1172, -0.0137, -0.1508, -0.0033, -0.0250],\n        [-0.0689,  0.0676,  0.1525,  0.0217, -0.1704,  0.0369,  0.1717,  0.0459,\n          0.1012, -0.1686, -0.0608,  0.1767,  0.0827,  0.0792, -0.1133,  0.1457,\n         -0.1143, -0.0845,  0.0914, -0.1027,  0.1606, -0.0215, -0.1418,  0.1486,\n         -0.0344,  0.1016,  0.0098,  0.0776, -0.0290,  0.0653,  0.0241,  0.0777],\n        [-0.1316, -0.1224, -0.1495,  0.0481,  0.0654, -0.1416, -0.1194, -0.0248,\n         -0.0982, -0.1536,  0.0328, -0.0466,  0.1703, -0.1474, -0.1233,  0.0082,\n          0.1481,  0.1248, -0.0732, -0.0400, -0.0861, -0.0848,  0.0994, -0.1305,\n          0.1150,  0.1463,  0.0280, -0.0762, -0.1382,  0.0590, -0.1475, -0.0306],\n        [-0.0437,  0.0267, -0.0418, -0.1125, -0.1317,  0.0330,  0.0733, -0.0466,\n          0.1448,  0.1719, -0.0415, -0.1604,  0.0863, -0.0198, -0.1250, -0.0306,\n         -0.1119,  0.1436, -0.1067,  0.0376, -0.0165, -0.1658, -0.1061, -0.0995,\n         -0.1019,  0.1326,  0.0047,  0.0969, -0.0786, -0.0041, -0.1215, -0.0293],\n        [ 0.1377,  0.0884, -0.1487,  0.1268,  0.0954,  0.0611,  0.0298, -0.1209,\n         -0.0328,  0.1762, -0.0158, -0.0035,  0.1092,  0.0650,  0.0409, -0.0635,\n          0.1003,  0.1390, -0.1012,  0.1256,  0.1153,  0.0356,  0.1500,  0.0751,\n         -0.0834, -0.1688,  0.0872,  0.0331,  0.1479,  0.0920, -0.1314, -0.1116],\n        [-0.1576,  0.1626, -0.0585,  0.0220,  0.0662, -0.1068, -0.1089, -0.0231,\n         -0.0740,  0.1260,  0.0733,  0.1445, -0.1759,  0.1440, -0.0041, -0.0386,\n         -0.1176, -0.0133, -0.1559,  0.1045,  0.0624, -0.1343,  0.1722,  0.1525,\n          0.1444, -0.1345,  0.0658, -0.0586, -0.0698,  0.0679, -0.0392,  0.0036],\n        [-0.0747,  0.1058, -0.1229,  0.1608, -0.0094,  0.0870, -0.0215, -0.0846,\n         -0.1768,  0.1390, -0.0897,  0.0832, -0.1379,  0.0467, -0.1532, -0.0142,\n         -0.0412,  0.0574, -0.0837,  0.1682, -0.1528, -0.0975,  0.0260, -0.0635,\n         -0.1389, -0.1395,  0.0542,  0.0088, -0.1166,  0.1758,  0.0443,  0.1386],\n        [-0.0009, -0.1059, -0.1523,  0.0163, -0.0228, -0.0489, -0.0395,  0.0020,\n         -0.1539, -0.0899,  0.0803,  0.0386,  0.0298, -0.1536,  0.1094,  0.1503,\n         -0.1091,  0.1250, -0.1374,  0.0353,  0.1320, -0.0858,  0.1216,  0.0352,\n         -0.0207,  0.0913,  0.0991,  0.0269, -0.0542, -0.0527, -0.0017,  0.0413],\n        [-0.1598,  0.0991,  0.1764,  0.1350, -0.0383, -0.0582,  0.0126, -0.0541,\n          0.1638, -0.0282,  0.1320, -0.1240, -0.1079,  0.0142,  0.1127,  0.0405,\n          0.1446, -0.1287, -0.0954,  0.1746, -0.0050, -0.0731,  0.0797, -0.0109,\n         -0.1637,  0.1669,  0.1696, -0.0826, -0.0102, -0.1748, -0.0878,  0.0491],\n        [ 0.0485,  0.1417,  0.1054, -0.0988,  0.1510,  0.1097,  0.1081, -0.1120,\n          0.0879,  0.1714, -0.1292,  0.1493,  0.0665, -0.1700,  0.0739, -0.0352,\n         -0.0186, -0.0416,  0.0695,  0.1349, -0.0576,  0.0993, -0.0419, -0.1086,\n         -0.0753, -0.0070,  0.0999, -0.0625, -0.1376, -0.0310,  0.0565, -0.0718],\n        [ 0.1502, -0.1077, -0.0808,  0.0481,  0.0949,  0.0786,  0.0556,  0.0761,\n         -0.0415, -0.1056,  0.1734,  0.1469,  0.0094,  0.1400,  0.0502,  0.1133,\n          0.0452, -0.0086,  0.0374, -0.0265,  0.1303, -0.1286, -0.0720, -0.1690,\n          0.0708, -0.0506,  0.0575,  0.0927, -0.1130, -0.0247, -0.0790, -0.1757],\n        [ 0.0323, -0.0126,  0.0016, -0.0950,  0.0387, -0.0652,  0.1002,  0.0474,\n         -0.1192, -0.0038, -0.1366,  0.0245,  0.0004, -0.0861,  0.1053, -0.1603,\n         -0.0547,  0.0532,  0.1084,  0.1629, -0.1747, -0.0140, -0.0054,  0.1756,\n          0.1045,  0.0339, -0.0601, -0.1590,  0.1332, -0.0614, -0.0714, -0.0651],\n        [ 0.0765, -0.0447, -0.0688,  0.1063,  0.1430, -0.1110, -0.1458, -0.1720,\n         -0.0548,  0.0833, -0.0437,  0.0304,  0.0262, -0.1228, -0.1492, -0.1274,\n          0.1012,  0.0424,  0.1431,  0.0190, -0.0495,  0.0813, -0.1200, -0.0680,\n         -0.1137,  0.1086, -0.0194,  0.0916, -0.1295,  0.1050,  0.0100, -0.0008],\n        [-0.0166,  0.0914, -0.1684, -0.1354,  0.0965,  0.1301,  0.0174,  0.1343,\n          0.0050,  0.0481,  0.0036, -0.0641,  0.0304, -0.1295, -0.0764, -0.0632,\n         -0.0452, -0.0478,  0.0844, -0.0135,  0.0046,  0.0705, -0.0562, -0.0495,\n         -0.0952, -0.1667, -0.0771,  0.1726, -0.1392,  0.1330, -0.1735, -0.1556],\n        [ 0.1173,  0.0234,  0.1111, -0.1518, -0.0775, -0.0950,  0.1118,  0.0250,\n         -0.0266,  0.0717, -0.0467,  0.0985, -0.0670, -0.1703,  0.0261, -0.1240,\n         -0.1306, -0.0525, -0.0936, -0.1004, -0.1192,  0.0117,  0.0632,  0.1237,\n         -0.1698,  0.0032, -0.1645, -0.1548,  0.0056,  0.0984, -0.1041,  0.0198],\n        [-0.1697,  0.1650,  0.0320, -0.1245,  0.0229,  0.0598, -0.1692,  0.0068,\n         -0.1541, -0.1683,  0.1328, -0.0084, -0.1073,  0.1509,  0.1525, -0.0860,\n         -0.1401,  0.0298, -0.1283,  0.1458,  0.0401,  0.1014,  0.1348, -0.1208,\n          0.0217, -0.0021, -0.1577,  0.0475, -0.0814, -0.1679,  0.0162,  0.1239]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1510, -0.0261,  0.1307,  0.0919, -0.0104, -0.2309,  0.2231,  0.0259],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1364, -0.0540, -0.1656, -0.0190,  0.0345, -0.0861, -0.0933,  0.1028,\n          0.0207,  0.2050, -0.0630, -0.0170,  0.0494, -0.2259,  0.0563,  0.0023],\n        [-0.1617, -0.0289, -0.0627,  0.1899,  0.2167, -0.2116,  0.1478, -0.2270,\n          0.2141,  0.2330,  0.0901, -0.1578, -0.1565,  0.0463, -0.2243, -0.1239],\n        [ 0.1317, -0.2424, -0.0824,  0.2025, -0.1204, -0.1508, -0.1102, -0.0946,\n         -0.2433,  0.1175, -0.1623,  0.0859,  0.0139, -0.1080, -0.1638, -0.1836],\n        [ 0.2257,  0.1239, -0.1959, -0.1839, -0.0752, -0.2451,  0.1432, -0.0902,\n         -0.1020,  0.1929, -0.2047,  0.0622, -0.0962, -0.0074,  0.0990, -0.1081],\n        [ 0.0699, -0.1360, -0.0275,  0.1945, -0.0914, -0.1225, -0.2114, -0.0139,\n          0.0266, -0.1452, -0.0245,  0.0025,  0.1433, -0.0845,  0.1342,  0.0851],\n        [ 0.1071, -0.0597,  0.1279, -0.1294, -0.0254, -0.1167,  0.2281, -0.1553,\n          0.2271, -0.1010, -0.2218,  0.1285, -0.1817, -0.2110, -0.0273, -0.2228],\n        [ 0.0645,  0.1793,  0.1600,  0.1257,  0.1368, -0.0919, -0.2390, -0.0999,\n         -0.2251,  0.0464,  0.1744,  0.1377,  0.0469,  0.0926, -0.2130, -0.0759],\n        [-0.0492, -0.0224, -0.1253, -0.2197, -0.1948,  0.2448,  0.1121,  0.2482,\n          0.2470, -0.1931, -0.1238, -0.0421,  0.0126,  0.1211, -0.1232, -0.0098]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([0.2208], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1243,  0.3292, -0.1236, -0.0485,  0.1216, -0.0350,  0.1695, -0.1386]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    20,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	20,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "flatten_obs_dim":	20,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.2951, -0.4564, -0.3964, -0.0430],\n        [-0.1024,  0.3944,  0.2538, -0.3133],\n        [-0.4332,  0.1696, -0.2764,  0.1306],\n        [ 0.1555,  0.4964, -0.1053,  0.0908],\n        [ 0.1151,  0.1046, -0.4503,  0.4207],\n        [-0.3930,  0.0457, -0.2834,  0.4202],\n        [ 0.4302, -0.4618,  0.1685, -0.4231],\n        [ 0.1000,  0.4234,  0.3685,  0.3131],\n        [ 0.0564,  0.4671, -0.0480,  0.0647],\n        [-0.4175,  0.4509,  0.0892,  0.1741],\n        [ 0.3373, -0.3645, -0.2688,  0.1982],\n        [ 0.0635,  0.1552,  0.2083, -0.1519],\n        [ 0.0514, -0.2451, -0.3379, -0.0660],\n        [ 0.2755,  0.2628, -0.3310, -0.4047],\n        [ 0.3670, -0.3103, -0.0108, -0.0806],\n        [ 0.1842,  0.1123, -0.2858, -0.4900],\n        [-0.2109,  0.3875,  0.0879, -0.2523],\n        [ 0.4778,  0.2566,  0.4297,  0.4131],\n        [-0.4759, -0.4089,  0.3891,  0.4799],\n        [ 0.1643,  0.0925,  0.0190,  0.3544],\n        [ 0.0868, -0.1658,  0.1821, -0.1065],\n        [-0.1419, -0.4481,  0.2679, -0.1647],\n        [-0.4498, -0.3970,  0.0268, -0.4875],\n        [-0.2096, -0.3769,  0.4738, -0.2334],\n        [ 0.4267,  0.1861, -0.1051,  0.4755],\n        [ 0.3516,  0.2999,  0.0168, -0.3555],\n        [-0.4010,  0.2889, -0.1929, -0.4784],\n        [ 0.1707, -0.3407,  0.0627,  0.1049],\n        [-0.0168, -0.3910, -0.1777,  0.0386],\n        [-0.2371,  0.4125, -0.0211, -0.3695],\n        [-0.1315,  0.1272, -0.3992,  0.0729],\n        [-0.2507, -0.0005, -0.0093,  0.2039]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.2064,  0.0043, -0.3348, -0.3983,  0.1947,  0.2997, -0.4807,  0.0095,\n         0.3971, -0.4541, -0.0341, -0.0520, -0.0793, -0.3871, -0.2526, -0.1254,\n        -0.2895, -0.1998,  0.1125, -0.1528,  0.2952,  0.3481, -0.0559, -0.1519,\n         0.1480, -0.3310,  0.2982, -0.3335, -0.0386, -0.2588,  0.1494,  0.3746],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-2.4320e-02,  4.5218e-02,  9.6151e-02, -7.3806e-02,  1.1766e-01,\n         -1.4315e-01,  1.2708e-01,  9.3242e-02, -1.6065e-01, -9.6204e-03,\n         -3.7261e-02, -2.1537e-02, -1.7505e-01, -3.8918e-02, -3.3511e-02,\n         -3.4263e-02, -1.8751e-02,  1.4676e-02, -1.4433e-01, -1.7296e-01,\n         -7.8217e-02,  8.8152e-02,  1.1500e-01, -1.4427e-01, -1.0983e-01,\n          4.6109e-02, -1.1863e-01,  1.1680e-01,  5.7292e-02,  9.4554e-02,\n          1.1445e-02,  9.5593e-02],\n        [-1.1758e-01, -1.5862e-01,  2.0744e-02, -1.5883e-01,  9.3906e-02,\n         -1.4002e-02,  8.7013e-02, -1.7446e-01, -9.7843e-02, -5.6312e-02,\n         -1.6527e-01,  1.5047e-02,  1.0391e-01,  1.0991e-01, -1.3441e-01,\n         -5.4873e-02,  5.0217e-06, -1.2651e-01,  1.7184e-01,  1.6306e-01,\n          3.2625e-02, -8.9074e-02,  2.7442e-02, -3.7973e-02, -7.1255e-02,\n          1.3075e-01, -1.5289e-01, -1.2791e-01, -4.6148e-02,  1.4447e-01,\n         -3.0664e-02, -1.7468e-01],\n        [ 1.4046e-01,  2.2246e-02, -1.2507e-01,  7.8343e-02, -1.6552e-01,\n          8.2227e-02, -1.2485e-01, -3.7459e-03, -1.0165e-01,  4.3586e-03,\n          7.8279e-02,  8.3550e-03,  6.2118e-02,  7.6246e-02, -1.1055e-01,\n          8.4211e-02, -5.1694e-02,  4.9128e-02,  9.5216e-02, -1.0538e-01,\n          1.3516e-01,  1.5002e-01, -7.8371e-02, -9.0658e-03, -1.1854e-01,\n         -9.5768e-03,  1.6670e-01, -1.2279e-05, -2.7031e-02,  2.9097e-02,\n          1.4942e-01, -9.9946e-02],\n        [-5.8295e-02, -4.2103e-02,  1.0648e-01,  1.0642e-01, -1.5970e-01,\n          5.3135e-02, -1.2807e-01,  4.3077e-02, -1.4003e-01,  7.3915e-02,\n          1.4460e-01,  2.8569e-02,  1.6278e-01, -8.5146e-02, -1.2302e-01,\n         -8.3454e-02, -1.3541e-01, -1.6920e-01,  2.7572e-02, -4.3569e-02,\n         -1.5748e-01,  4.1133e-02, -1.5217e-01, -1.3920e-01, -1.7132e-01,\n         -1.1022e-01, -9.7017e-02,  1.2664e-01,  3.2039e-02, -1.3756e-01,\n          1.0502e-01,  1.1478e-02],\n        [ 1.5372e-01, -6.8312e-02, -1.7312e-01, -1.6263e-02,  1.3055e-01,\n          2.6041e-02, -8.0178e-02, -7.8969e-02,  9.4886e-02, -1.5557e-01,\n         -5.0613e-02,  8.3459e-02,  3.8144e-02,  1.4335e-01,  5.1064e-02,\n         -7.2107e-02,  1.7505e-01, -1.5244e-01, -1.5701e-01, -4.7237e-02,\n         -1.0146e-01, -8.8715e-02, -8.3616e-02,  1.2445e-01, -1.9492e-03,\n          9.2354e-02,  5.8611e-02,  8.7468e-02,  5.5291e-02, -1.4255e-01,\n         -9.0757e-03, -1.2104e-02],\n        [ 1.0375e-01,  6.8837e-02, -2.7288e-02, -1.3986e-01, -7.2502e-02,\n          1.1986e-01,  1.1976e-01, -8.9844e-02, -1.2533e-01,  1.8763e-02,\n         -1.3824e-01, -1.4875e-01, -5.9096e-02, -1.2607e-01, -1.2816e-01,\n          8.4586e-02,  1.2812e-03, -8.7334e-02, -1.0419e-01,  1.6290e-01,\n         -3.2139e-02, -1.4213e-01,  9.8335e-02,  2.0335e-02, -1.3937e-01,\n          1.2592e-01,  1.5348e-02,  1.4016e-02, -6.7087e-02, -1.5070e-01,\n          3.3929e-02,  2.2012e-02],\n        [-9.1081e-02, -7.1465e-02, -1.5440e-01, -6.5796e-02, -1.0943e-01,\n         -6.6427e-02,  8.5730e-02,  1.3081e-01,  4.4414e-02, -1.7548e-01,\n         -3.0258e-02,  6.9516e-02, -1.3827e-01, -1.4626e-01,  1.7177e-01,\n         -1.5921e-01, -3.8451e-02, -1.3361e-01, -1.3006e-01,  7.2827e-02,\n          1.8717e-02, -1.0082e-01, -1.7727e-02,  1.6974e-01, -3.4091e-02,\n         -1.1765e-01,  8.2182e-02, -8.4686e-02,  1.4812e-01,  1.3446e-01,\n          7.5266e-02,  1.2719e-01],\n        [ 8.9666e-02, -1.6856e-01, -4.9677e-03, -1.1181e-01, -4.6004e-02,\n          1.6734e-01, -4.7893e-02, -8.8826e-02, -7.7757e-02,  1.7516e-01,\n          4.1866e-02,  8.1780e-02, -1.2412e-01,  1.0229e-01,  1.6579e-01,\n         -6.8607e-03,  2.0868e-02,  9.2355e-02, -6.8308e-02, -3.0849e-02,\n         -5.6690e-02, -3.5963e-02,  1.6350e-01,  1.0847e-01,  7.1180e-02,\n         -1.4891e-01, -4.3512e-02, -6.1698e-02, -1.1763e-01, -6.2196e-02,\n         -5.1172e-02,  1.5049e-01],\n        [ 8.6447e-02,  1.7103e-01,  1.0351e-01,  1.1969e-01, -1.5386e-01,\n          1.5745e-01,  1.2043e-01, -5.7139e-02, -1.7436e-01,  1.0910e-01,\n          1.5386e-01, -2.0911e-03, -9.8860e-02, -6.6696e-02,  1.1387e-01,\n          1.1561e-01, -1.6058e-01,  1.2822e-02, -9.2903e-03, -2.7956e-02,\n          2.6723e-02,  1.3002e-01, -1.8061e-02, -2.5132e-02, -2.8234e-02,\n          7.8925e-02, -1.7288e-01, -5.5733e-04, -1.1198e-01, -1.5665e-02,\n         -3.4976e-02,  1.5757e-02],\n        [ 6.9582e-02, -5.0816e-02, -1.7668e-01, -8.5722e-02, -3.6699e-02,\n          9.3409e-02, -1.1955e-01, -1.0040e-01,  8.5435e-02,  1.1394e-01,\n         -4.4491e-02, -1.2937e-02,  1.6983e-01,  4.5360e-02, -4.6500e-02,\n          5.9169e-02,  7.5912e-02, -1.4893e-01, -4.6462e-02,  8.6995e-02,\n         -1.5355e-01,  4.8374e-03, -8.1338e-02,  1.5649e-01, -1.7281e-01,\n          1.7429e-01,  7.0995e-02, -1.1431e-01, -2.5339e-02, -6.5863e-02,\n         -1.6240e-01, -1.5741e-01],\n        [-1.7460e-02, -1.5583e-01, -1.3599e-01,  8.3063e-02, -1.2228e-01,\n         -1.7464e-01, -2.1753e-03, -8.9034e-02, -1.7509e-01,  1.3122e-01,\n          3.4690e-02,  1.3959e-01, -4.0958e-02, -1.1910e-01,  1.0269e-01,\n          1.0157e-03, -1.6640e-01,  1.0794e-01,  1.0478e-01, -1.6547e-01,\n         -1.3454e-01,  1.7234e-02,  7.4960e-03,  2.0754e-03, -1.1896e-01,\n         -6.9282e-03, -1.6003e-01,  7.7098e-02,  1.6804e-01,  1.1744e-01,\n         -9.4236e-02,  1.2834e-01],\n        [-1.5270e-01, -1.7086e-01,  1.4026e-01,  1.4333e-01, -1.6018e-01,\n         -1.0100e-01, -8.7606e-02, -1.2341e-01, -1.1103e-01,  5.4709e-02,\n         -9.6026e-02,  3.1266e-02, -9.1593e-02,  2.3757e-03, -1.3610e-01,\n          1.0956e-01,  1.3567e-01, -6.4970e-03, -1.8982e-02,  1.4965e-01,\n         -3.4958e-05,  1.7555e-01, -1.3758e-02,  1.6301e-01,  7.3762e-02,\n          3.5298e-02, -3.6669e-02, -9.7900e-02,  9.6366e-02, -6.2063e-03,\n          2.1897e-03,  4.8375e-02],\n        [ 1.3429e-01,  9.3161e-02,  6.8153e-02, -1.6453e-01,  5.9687e-04,\n         -1.8544e-02,  3.2553e-02, -1.9022e-02,  1.0205e-01,  4.2471e-02,\n         -4.2831e-02, -3.7230e-02,  5.6634e-02, -1.5960e-01, -9.8817e-02,\n         -9.4395e-02, -6.4964e-02,  3.8801e-02, -1.6580e-01,  5.6655e-02,\n          3.2910e-02,  8.4284e-02,  8.1365e-03, -3.4956e-02,  1.3017e-01,\n          1.7646e-01, -1.3393e-01,  4.8934e-02, -8.5671e-02,  7.9304e-02,\n          1.5865e-01,  9.6797e-02],\n        [-1.2532e-02, -8.4400e-02,  4.0264e-02,  4.3532e-02,  1.3962e-01,\n         -9.3115e-02,  1.0065e-01,  9.2826e-03, -1.4377e-01,  1.1553e-01,\n          8.0982e-03, -5.2863e-03, -1.6681e-01, -1.4909e-01, -1.1292e-01,\n          7.7291e-03,  1.0535e-01,  1.6786e-01, -1.3710e-01,  4.7705e-02,\n          3.9568e-02,  8.2788e-03, -5.1748e-02,  5.5071e-02,  1.1873e-01,\n         -1.5271e-01,  7.7795e-02, -1.5522e-01,  5.0674e-02, -9.3254e-02,\n          1.7566e-01, -9.5069e-02],\n        [ 1.4987e-01, -4.6616e-02,  1.6776e-01, -1.4444e-01,  8.5551e-03,\n          3.2402e-02,  1.3584e-02, -4.2179e-02,  5.9896e-02,  1.1987e-01,\n         -1.1206e-01,  4.9056e-02,  1.2809e-01, -8.2027e-02, -7.4568e-02,\n          3.3496e-02, -1.3507e-01, -1.2411e-01, -1.3944e-01,  9.0136e-02,\n          5.5252e-02,  4.1186e-02,  1.0203e-01, -1.5018e-01, -1.1750e-01,\n         -1.1752e-01, -1.2791e-01, -1.1182e-01,  3.3826e-03, -6.5571e-02,\n         -1.2099e-01,  8.1042e-02],\n        [ 9.9705e-02, -7.9024e-02, -8.4297e-02, -1.3261e-01,  2.4962e-02,\n         -7.3665e-02,  9.4116e-02, -5.1465e-02,  1.0856e-01,  4.1498e-02,\n          1.4214e-01, -3.1482e-02, -1.3557e-01,  2.0442e-02,  6.3668e-03,\n         -4.1103e-02,  3.4274e-02, -7.3056e-02,  3.3006e-02,  2.8494e-02,\n         -7.1171e-02,  1.5983e-01, -1.0389e-01,  1.3078e-01, -1.1345e-01,\n          9.6691e-02, -1.0780e-01,  4.2356e-02,  1.5717e-01, -6.2890e-02,\n         -3.2184e-02, -1.4693e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0616, -0.0308,  0.0211,  0.0206,  0.0560,  0.0316,  0.1317, -0.1096,\n        -0.0433, -0.0540,  0.0216,  0.1408, -0.0039, -0.0700, -0.1437, -0.1358],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1262, -0.0514, -0.1693, -0.1065, -0.2117, -0.1597,  0.1222, -0.1401,\n          0.0097,  0.1289, -0.1396,  0.0748,  0.0729,  0.2284, -0.1427,  0.0948],\n        [-0.0598, -0.1944, -0.1666, -0.1039,  0.0330,  0.0053, -0.0707,  0.0964,\n          0.2333, -0.0958, -0.1006,  0.0758,  0.1702,  0.2171,  0.1718,  0.0797],\n        [-0.2351, -0.1508, -0.1066,  0.1803, -0.0556,  0.0410, -0.1133,  0.0475,\n         -0.1858,  0.2283,  0.1745,  0.0460, -0.1352,  0.1239, -0.1116,  0.0962],\n        [ 0.0818, -0.0031, -0.0845, -0.0960, -0.0996,  0.1441, -0.1319, -0.0867,\n          0.1378,  0.1372,  0.0709, -0.0278,  0.0010, -0.0119,  0.1288, -0.0582],\n        [-0.0218, -0.0153, -0.1783,  0.1684,  0.1974,  0.0147,  0.1312, -0.1630,\n         -0.2160, -0.0291,  0.1787, -0.0449,  0.0536,  0.0024, -0.0206,  0.1637],\n        [ 0.0808,  0.1870, -0.2459, -0.1871,  0.0686, -0.1943, -0.1672,  0.0361,\n         -0.2342, -0.0547, -0.1404,  0.2454, -0.2460,  0.2348,  0.0352,  0.1593],\n        [ 0.1726, -0.0739,  0.2481, -0.2087, -0.1241, -0.0878,  0.1137,  0.2247,\n          0.0726,  0.0252,  0.2446,  0.1547, -0.2227, -0.0722, -0.1682,  0.1488],\n        [ 0.2479, -0.1514, -0.2321,  0.0822,  0.2489,  0.0311,  0.0219, -0.1442,\n         -0.1301,  0.2035, -0.1890, -0.0769, -0.0763,  0.0348,  0.0974, -0.0558]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2184, -0.0528,  0.1470,  0.1923, -0.2057,  0.1799,  0.0187, -0.0411],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2890,  0.0892,  0.3352,  0.2294,  0.2209, -0.2580,  0.2955, -0.2886]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.3350], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x000001BF1428EBF0>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	50000,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	40,
            "_train_v_iters":	40,
            "_traj_per_epoch":	5,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 3.1819e-02, -1.9322e-01, -7.0367e-02,  1.4016e-01,  1.0684e-01,\n         -2.1079e-01, -1.4693e-01, -2.1880e-01, -3.8784e-02,  2.0076e-01,\n         -1.1813e-01, -7.2086e-03, -9.7781e-02,  1.1615e-01,  1.1380e-01,\n          1.4018e-01,  1.7808e-01, -1.7884e-01, -3.4437e-02, -2.1399e-01],\n        [ 9.8490e-02,  3.4965e-02, -2.0517e-02, -7.9081e-02, -7.5965e-02,\n          2.1622e-01, -2.9064e-02,  1.9266e-01, -5.1617e-02,  1.0188e-01,\n          1.2123e-01, -1.4690e-01,  3.9310e-02,  1.5293e-02, -8.0243e-02,\n          8.0778e-02, -1.1738e-01,  2.6573e-02, -6.9588e-06,  1.3576e-01],\n        [-1.5565e-01, -1.3627e-01, -1.6961e-03,  7.0543e-02,  1.5892e-01,\n         -1.9391e-01, -5.2815e-03, -1.5978e-01,  2.9315e-02,  2.0593e-01,\n         -1.6767e-01,  1.4109e-02,  7.4948e-02, -1.8597e-01,  1.5021e-01,\n         -5.7172e-02,  9.4211e-02, -7.2851e-02, -1.4696e-01, -2.1336e-01],\n        [-1.2648e-01,  4.8892e-02,  2.1475e-01,  1.0933e-01, -9.2337e-02,\n         -1.3698e-02, -1.8746e-01, -2.0903e-01, -1.6857e-01, -5.6113e-02,\n         -1.5902e-01, -9.7726e-02,  4.1217e-02,  1.9946e-01,  1.2181e-01,\n          1.2493e-01, -2.1007e-01, -8.2379e-02, -7.9954e-03,  1.9332e-01],\n        [ 4.6314e-02, -1.6392e-01, -2.2134e-01, -1.7449e-02,  2.1771e-02,\n          1.5554e-01,  2.1406e-01, -2.2360e-01,  2.0357e-01, -1.9605e-01,\n          1.9967e-01, -2.0490e-01, -1.8158e-01,  7.0415e-02, -1.6243e-01,\n          1.5298e-01,  1.9204e-01, -2.0721e-01, -1.2292e-01, -2.1121e-01],\n        [ 8.2620e-02, -5.0591e-02, -8.9491e-02, -5.6972e-02, -3.1854e-02,\n         -1.1820e-01,  5.3307e-02,  1.2867e-01, -9.1018e-02,  1.4272e-01,\n          1.0625e-01, -5.5635e-02, -1.6323e-01, -9.2312e-02,  4.5499e-02,\n         -9.9749e-02,  3.1924e-02,  1.5098e-01, -8.2738e-02,  2.2015e-01],\n        [ 3.1531e-03, -5.6567e-02, -1.1728e-01,  4.9849e-02,  5.8843e-02,\n         -1.1158e-02, -1.5550e-01,  4.3147e-02,  1.5754e-01,  5.4394e-02,\n          1.9454e-01, -3.3826e-02,  5.9714e-02, -1.3345e-01,  1.6352e-01,\n          8.6411e-02, -4.8698e-02,  2.2337e-01, -5.0680e-02,  4.7351e-02],\n        [-4.2637e-02,  1.7585e-01, -2.1822e-01, -4.8746e-03,  8.0025e-02,\n          6.7046e-02,  9.6276e-02,  1.8028e-01,  1.6872e-01,  1.4086e-01,\n          5.3888e-02,  2.2284e-02, -7.9142e-02, -2.2194e-01, -1.4585e-01,\n          5.2018e-02, -1.4203e-01, -3.3545e-02,  7.5303e-02, -1.3252e-01],\n        [-1.5573e-01,  6.8302e-02,  1.4954e-01,  1.0615e-01, -2.0018e-01,\n          1.8766e-01,  8.2101e-02,  8.3660e-02,  1.0271e-01, -7.4428e-02,\n          9.4505e-02,  1.7501e-01,  7.4978e-02, -7.3551e-02,  7.3098e-02,\n         -3.5556e-02, -2.8686e-02,  1.4609e-01,  4.8982e-02,  1.8591e-01],\n        [ 1.2499e-01, -1.7069e-01,  1.3616e-01,  1.0753e-01, -1.3886e-01,\n          9.4598e-02, -2.1722e-01,  1.8909e-01, -1.5942e-01,  3.3855e-02,\n         -1.1942e-01,  7.7629e-02,  1.5993e-01,  6.8468e-02, -1.6936e-01,\n          1.6691e-01, -7.9676e-02, -1.7481e-01,  1.2796e-01, -4.0314e-02],\n        [-4.2717e-02,  1.0989e-01,  1.3876e-01, -1.4927e-01, -8.0134e-02,\n          1.7538e-01,  6.4856e-02, -2.1028e-01, -2.6868e-02, -1.5697e-01,\n         -1.8895e-03,  1.0530e-01,  1.4190e-02,  2.1746e-01,  2.1490e-01,\n          1.0618e-01,  1.9677e-01,  1.0837e-01,  1.4044e-02,  2.0723e-01],\n        [ 1.0666e-01, -1.2874e-01, -2.9564e-02, -8.0515e-02, -1.2186e-01,\n         -1.4283e-01,  1.3781e-01,  1.5034e-01,  1.1834e-01, -2.6845e-03,\n          5.4332e-02, -7.4963e-02, -1.3988e-01, -8.8859e-02, -4.7742e-02,\n         -5.5335e-02, -5.3508e-02, -1.6187e-01, -2.0305e-02,  5.1788e-02],\n        [-1.6393e-01,  1.0980e-01,  1.0596e-01, -1.5808e-01,  1.2281e-01,\n          9.1878e-02, -7.6466e-02,  7.5460e-02, -5.4482e-02, -1.5568e-01,\n          1.4997e-01, -3.3087e-02,  7.8822e-02,  1.1565e-01, -2.0004e-01,\n         -1.7067e-01, -5.6754e-02, -1.9693e-01,  2.1450e-01, -3.5426e-02],\n        [ 2.1131e-01, -1.5860e-01,  6.0976e-02,  1.9957e-02, -2.0248e-01,\n          6.9235e-02, -1.7937e-01,  1.2608e-01, -1.5681e-01, -1.1868e-02,\n         -1.2878e-01,  1.5166e-01,  7.2821e-02, -1.7347e-01, -6.3026e-03,\n         -9.4969e-02,  1.4431e-02, -7.2362e-02, -1.3216e-01, -1.8882e-01],\n        [-3.3280e-02,  4.7230e-02, -1.5686e-01,  2.2288e-01, -1.0463e-01,\n          1.7265e-01, -7.6149e-02, -1.3199e-01, -1.3417e-01, -1.7683e-01,\n          1.3769e-01,  1.9298e-01,  6.7165e-04,  3.9745e-02,  1.7177e-01,\n         -2.0890e-01, -1.6570e-01,  1.2878e-02,  5.5730e-02,  7.9018e-02],\n        [-1.1084e-01, -1.5555e-02,  1.9673e-01, -1.1137e-01, -2.0958e-01,\n         -1.9356e-01,  1.2988e-01, -1.2434e-01,  8.3827e-02,  1.0214e-01,\n          5.9659e-02,  1.0438e-01, -3.3657e-02, -2.4850e-02, -1.8403e-01,\n          1.5594e-01, -3.4011e-02, -1.7082e-01, -1.6052e-01,  5.6204e-03],\n        [ 2.1708e-01,  1.5354e-01,  7.7518e-02,  1.2970e-01,  1.1193e-02,\n         -9.4692e-02,  9.3037e-02, -1.0663e-01,  3.9036e-02, -1.5263e-01,\n         -7.7897e-02,  1.6958e-01, -1.9785e-01,  1.2415e-01,  1.3919e-02,\n         -2.0432e-01,  1.9415e-01,  1.5237e-02, -1.0197e-01, -1.4914e-01],\n        [ 3.8825e-03, -1.8743e-01,  1.7307e-02,  2.1160e-02,  6.7178e-02,\n          8.7898e-02, -1.0567e-01, -1.8150e-01,  1.0919e-01, -5.0721e-02,\n          7.9379e-02, -1.9310e-02,  1.3164e-01, -8.2298e-02, -1.4386e-01,\n         -1.5243e-01,  2.1876e-01, -1.4451e-01,  1.6403e-01,  6.3016e-02],\n        [-3.3345e-02,  1.4894e-01, -7.4155e-02, -2.6155e-03,  6.4291e-03,\n         -1.0665e-01,  1.7436e-01, -1.5325e-01, -1.8735e-02,  1.1097e-01,\n         -6.2387e-02, -1.2491e-01,  1.5984e-01, -1.9886e-01, -1.1160e-01,\n         -2.3314e-02,  2.0051e-01,  1.2139e-01,  1.0500e-01,  5.7702e-02],\n        [-1.3352e-01, -1.4214e-02, -7.9071e-02,  5.7634e-02,  3.8932e-02,\n          9.8965e-02, -1.2450e-01,  1.8564e-01, -1.1163e-01,  1.0867e-01,\n         -2.1436e-01,  1.5014e-01,  1.5450e-01, -1.6690e-01,  6.3131e-02,\n         -2.1031e-01, -1.4141e-02,  2.0192e-03,  1.3369e-01, -8.2821e-02],\n        [ 1.9509e-01, -8.0578e-02,  4.3935e-02, -9.8779e-02, -1.9320e-01,\n          2.0936e-01,  4.0781e-02, -1.0129e-01, -1.9880e-01,  1.8043e-01,\n         -1.1595e-01, -1.7852e-02,  2.0347e-01,  1.7308e-01,  1.7784e-01,\n          1.1564e-01, -4.2920e-02, -1.5658e-02,  1.0518e-01,  1.1528e-02],\n        [-1.6729e-01,  3.1723e-02, -7.8497e-03,  2.1830e-01,  3.8169e-02,\n          1.2231e-01, -4.9433e-02, -1.9933e-01, -2.6171e-02, -2.1200e-01,\n          1.5178e-03, -1.6181e-01,  8.5160e-02,  1.2251e-01,  2.7359e-02,\n          1.8531e-01,  3.0405e-02, -3.7493e-02,  1.7099e-01,  9.9179e-03],\n        [ 5.3692e-02, -1.1413e-01, -2.1279e-02,  1.9307e-01, -4.3103e-02,\n          1.6619e-01, -1.5299e-01,  1.3588e-01, -9.0507e-03,  7.9188e-02,\n          6.1487e-02,  3.7480e-03,  1.4814e-01,  1.4292e-01,  2.8903e-02,\n          3.1207e-02, -2.0120e-01,  1.6874e-01,  1.7342e-01,  5.0034e-02],\n        [ 1.6485e-02, -1.4573e-01,  1.4540e-01,  1.2143e-01,  5.4226e-02,\n         -2.3384e-02,  1.3056e-02, -5.8067e-02,  1.4638e-01,  1.7091e-02,\n          1.6690e-01, -4.4778e-02, -1.7286e-02, -2.0449e-01,  1.2923e-02,\n          1.0271e-01, -7.1974e-03,  6.9103e-02,  3.8713e-02, -1.9777e-01],\n        [ 5.4852e-02,  1.2423e-01, -1.9860e-01, -2.1646e-02, -1.7469e-01,\n          9.5293e-02, -5.8640e-02, -1.1618e-01,  1.9823e-01, -8.7785e-02,\n         -2.1287e-02, -1.9243e-01,  4.1530e-02,  9.4257e-02, -1.5891e-01,\n         -4.6067e-02,  3.8807e-02, -1.6284e-01,  1.3952e-01, -2.1339e-01],\n        [ 1.3595e-01, -8.2160e-02,  2.0680e-01, -3.5831e-02,  7.8858e-02,\n         -1.2464e-01, -1.6595e-01,  1.1477e-01,  1.1009e-01,  4.4305e-02,\n         -1.4772e-01, -1.6033e-01, -1.6659e-01, -2.1889e-01,  1.7384e-01,\n          1.7215e-01,  1.3987e-01,  1.8542e-01,  1.0284e-01,  2.3392e-02],\n        [ 8.3062e-02, -1.0580e-01,  1.0313e-01,  1.2769e-01, -1.7558e-02,\n          3.7137e-02, -1.4375e-02,  3.0367e-02, -6.8897e-02,  2.1439e-01,\n          8.2464e-02,  2.6356e-02, -7.5291e-02,  1.0935e-01,  1.8952e-01,\n         -2.2358e-02, -1.8603e-02,  1.6848e-01,  1.5389e-01, -1.7947e-01],\n        [-1.3195e-01, -1.7695e-01, -1.7012e-01,  9.8381e-02,  1.1858e-01,\n          2.1537e-01, -4.4816e-02,  1.9167e-01,  1.0306e-01,  1.3341e-01,\n          8.1013e-03,  2.2016e-01, -1.1329e-01, -3.3957e-03,  1.7985e-01,\n         -1.3758e-01,  2.0585e-01, -1.6821e-01, -4.4650e-02, -2.2340e-01],\n        [ 7.2518e-02, -4.4904e-03, -1.6390e-01,  2.0832e-01, -1.7257e-01,\n         -2.0304e-01,  1.4314e-01, -1.5117e-01,  1.8538e-01,  8.0411e-02,\n          1.9081e-01, -1.7388e-01,  1.8605e-01, -1.1222e-02,  1.4672e-01,\n          1.4018e-02,  1.2376e-01,  1.9986e-01, -1.0009e-01, -1.4847e-01],\n        [ 1.6116e-01,  1.9727e-01,  6.9119e-02,  8.2738e-02,  2.3763e-02,\n          2.0788e-01,  1.1988e-01,  7.2764e-02, -3.2885e-02,  4.5256e-02,\n          1.0267e-01,  1.1198e-01, -1.8612e-01, -1.9953e-01, -1.6843e-01,\n          3.3595e-02,  1.5220e-01,  1.8032e-01,  1.4465e-01,  4.2304e-02],\n        [-5.8649e-02, -1.0836e-01,  1.8763e-01,  1.7834e-01,  8.0234e-02,\n         -8.1331e-02, -1.3862e-01, -1.2141e-02, -1.1253e-02, -1.6753e-01,\n         -3.3061e-02, -2.7284e-03, -1.4528e-01,  5.9621e-02,  2.5640e-02,\n         -2.1183e-01,  1.3060e-01,  1.4978e-01, -1.1986e-01,  1.0868e-01],\n        [ 2.8176e-02, -1.6882e-01,  1.4153e-01, -1.6666e-01, -1.0502e-02,\n          1.2535e-01,  2.1426e-01, -8.9809e-02,  4.8290e-02, -1.7584e-01,\n          1.9989e-01, -1.3972e-02,  2.1133e-01, -2.0380e-01,  1.6567e-01,\n          8.7763e-02,  1.1142e-01,  1.2097e-01,  4.1262e-02,  6.9339e-02]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0011, -0.1087,  0.0553,  0.2162, -0.1184, -0.1990, -0.0046, -0.2143,\n         0.2201,  0.1346,  0.1459,  0.1515,  0.1878,  0.1394,  0.0699, -0.1859,\n         0.1926, -0.2070, -0.0257,  0.1629, -0.0449,  0.0780, -0.2120, -0.1855,\n        -0.2087, -0.0403, -0.0524, -0.0648,  0.1812,  0.0568,  0.1120, -0.1004],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0738, -0.0602,  0.1027, -0.0479,  0.1575,  0.1762,  0.1513, -0.1094,\n         -0.0301, -0.1053, -0.0070, -0.0917,  0.1464,  0.1030, -0.0386, -0.0065,\n          0.1728, -0.0284, -0.1120,  0.1191,  0.0972,  0.1379,  0.0230,  0.0124,\n          0.0406, -0.1286, -0.0065,  0.1172, -0.0137, -0.1508, -0.0033, -0.0250],\n        [-0.0689,  0.0676,  0.1525,  0.0217, -0.1704,  0.0369,  0.1717,  0.0459,\n          0.1012, -0.1686, -0.0608,  0.1767,  0.0827,  0.0792, -0.1133,  0.1457,\n         -0.1143, -0.0845,  0.0914, -0.1027,  0.1606, -0.0215, -0.1418,  0.1486,\n         -0.0344,  0.1016,  0.0098,  0.0776, -0.0290,  0.0653,  0.0241,  0.0777],\n        [-0.1316, -0.1224, -0.1495,  0.0481,  0.0654, -0.1416, -0.1194, -0.0248,\n         -0.0982, -0.1536,  0.0328, -0.0466,  0.1703, -0.1474, -0.1233,  0.0082,\n          0.1481,  0.1248, -0.0732, -0.0400, -0.0861, -0.0848,  0.0994, -0.1305,\n          0.1150,  0.1463,  0.0280, -0.0762, -0.1382,  0.0590, -0.1475, -0.0306],\n        [-0.0437,  0.0267, -0.0418, -0.1125, -0.1317,  0.0330,  0.0733, -0.0466,\n          0.1448,  0.1719, -0.0415, -0.1604,  0.0863, -0.0198, -0.1250, -0.0306,\n         -0.1119,  0.1436, -0.1067,  0.0376, -0.0165, -0.1658, -0.1061, -0.0995,\n         -0.1019,  0.1326,  0.0047,  0.0969, -0.0786, -0.0041, -0.1215, -0.0293],\n        [ 0.1377,  0.0884, -0.1487,  0.1268,  0.0954,  0.0611,  0.0298, -0.1209,\n         -0.0328,  0.1762, -0.0158, -0.0035,  0.1092,  0.0650,  0.0409, -0.0635,\n          0.1003,  0.1390, -0.1012,  0.1256,  0.1153,  0.0356,  0.1500,  0.0751,\n         -0.0834, -0.1688,  0.0872,  0.0331,  0.1479,  0.0920, -0.1314, -0.1116],\n        [-0.1576,  0.1626, -0.0585,  0.0220,  0.0662, -0.1068, -0.1089, -0.0231,\n         -0.0740,  0.1260,  0.0733,  0.1445, -0.1759,  0.1440, -0.0041, -0.0386,\n         -0.1176, -0.0133, -0.1559,  0.1045,  0.0624, -0.1343,  0.1722,  0.1525,\n          0.1444, -0.1345,  0.0658, -0.0586, -0.0698,  0.0679, -0.0392,  0.0036],\n        [-0.0747,  0.1058, -0.1229,  0.1608, -0.0094,  0.0870, -0.0215, -0.0846,\n         -0.1768,  0.1390, -0.0897,  0.0832, -0.1379,  0.0467, -0.1532, -0.0142,\n         -0.0412,  0.0574, -0.0837,  0.1682, -0.1528, -0.0975,  0.0260, -0.0635,\n         -0.1389, -0.1395,  0.0542,  0.0088, -0.1166,  0.1758,  0.0443,  0.1386],\n        [-0.0009, -0.1059, -0.1523,  0.0163, -0.0228, -0.0489, -0.0395,  0.0020,\n         -0.1539, -0.0899,  0.0803,  0.0386,  0.0298, -0.1536,  0.1094,  0.1503,\n         -0.1091,  0.1250, -0.1374,  0.0353,  0.1320, -0.0858,  0.1216,  0.0352,\n         -0.0207,  0.0913,  0.0991,  0.0269, -0.0542, -0.0527, -0.0017,  0.0413],\n        [-0.1598,  0.0991,  0.1764,  0.1350, -0.0383, -0.0582,  0.0126, -0.0541,\n          0.1638, -0.0282,  0.1320, -0.1240, -0.1079,  0.0142,  0.1127,  0.0405,\n          0.1446, -0.1287, -0.0954,  0.1746, -0.0050, -0.0731,  0.0797, -0.0109,\n         -0.1637,  0.1669,  0.1696, -0.0826, -0.0102, -0.1748, -0.0878,  0.0491],\n        [ 0.0485,  0.1417,  0.1054, -0.0988,  0.1510,  0.1097,  0.1081, -0.1120,\n          0.0879,  0.1714, -0.1292,  0.1493,  0.0665, -0.1700,  0.0739, -0.0352,\n         -0.0186, -0.0416,  0.0695,  0.1349, -0.0576,  0.0993, -0.0419, -0.1086,\n         -0.0753, -0.0070,  0.0999, -0.0625, -0.1376, -0.0310,  0.0565, -0.0718],\n        [ 0.1502, -0.1077, -0.0808,  0.0481,  0.0949,  0.0786,  0.0556,  0.0761,\n         -0.0415, -0.1056,  0.1734,  0.1469,  0.0094,  0.1400,  0.0502,  0.1133,\n          0.0452, -0.0086,  0.0374, -0.0265,  0.1303, -0.1286, -0.0720, -0.1690,\n          0.0708, -0.0506,  0.0575,  0.0927, -0.1130, -0.0247, -0.0790, -0.1757],\n        [ 0.0323, -0.0126,  0.0016, -0.0950,  0.0387, -0.0652,  0.1002,  0.0474,\n         -0.1192, -0.0038, -0.1366,  0.0245,  0.0004, -0.0861,  0.1053, -0.1603,\n         -0.0547,  0.0532,  0.1084,  0.1629, -0.1747, -0.0140, -0.0054,  0.1756,\n          0.1045,  0.0339, -0.0601, -0.1590,  0.1332, -0.0614, -0.0714, -0.0651],\n        [ 0.0765, -0.0447, -0.0688,  0.1063,  0.1430, -0.1110, -0.1458, -0.1720,\n         -0.0548,  0.0833, -0.0437,  0.0304,  0.0262, -0.1228, -0.1492, -0.1274,\n          0.1012,  0.0424,  0.1431,  0.0190, -0.0495,  0.0813, -0.1200, -0.0680,\n         -0.1137,  0.1086, -0.0194,  0.0916, -0.1295,  0.1050,  0.0100, -0.0008],\n        [-0.0166,  0.0914, -0.1684, -0.1354,  0.0965,  0.1301,  0.0174,  0.1343,\n          0.0050,  0.0481,  0.0036, -0.0641,  0.0304, -0.1295, -0.0764, -0.0632,\n         -0.0452, -0.0478,  0.0844, -0.0135,  0.0046,  0.0705, -0.0562, -0.0495,\n         -0.0952, -0.1667, -0.0771,  0.1726, -0.1392,  0.1330, -0.1735, -0.1556],\n        [ 0.1173,  0.0234,  0.1111, -0.1518, -0.0775, -0.0950,  0.1118,  0.0250,\n         -0.0266,  0.0717, -0.0467,  0.0985, -0.0670, -0.1703,  0.0261, -0.1240,\n         -0.1306, -0.0525, -0.0936, -0.1004, -0.1192,  0.0117,  0.0632,  0.1237,\n         -0.1698,  0.0032, -0.1645, -0.1548,  0.0056,  0.0984, -0.1041,  0.0198],\n        [-0.1697,  0.1650,  0.0320, -0.1245,  0.0229,  0.0598, -0.1692,  0.0068,\n         -0.1541, -0.1683,  0.1328, -0.0084, -0.1073,  0.1509,  0.1525, -0.0860,\n         -0.1401,  0.0298, -0.1283,  0.1458,  0.0401,  0.1014,  0.1348, -0.1208,\n          0.0217, -0.0021, -0.1577,  0.0475, -0.0814, -0.1679,  0.0162,  0.1239]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1690,  0.1447, -0.0585, -0.1317,  0.1302, -0.1630, -0.1347,  0.0806,\n        -0.0861,  0.0725, -0.0833,  0.0193,  0.1193, -0.1222, -0.1003, -0.0620],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1364, -0.0540, -0.1656, -0.0190,  0.0345, -0.0861, -0.0933,  0.1028,\n          0.0207,  0.2050, -0.0630, -0.0170,  0.0494, -0.2259,  0.0563,  0.0023],\n        [-0.1617, -0.0289, -0.0627,  0.1899,  0.2167, -0.2116,  0.1478, -0.2270,\n          0.2141,  0.2330,  0.0901, -0.1578, -0.1565,  0.0463, -0.2243, -0.1239],\n        [ 0.1317, -0.2424, -0.0824,  0.2025, -0.1204, -0.1508, -0.1102, -0.0946,\n         -0.2433,  0.1175, -0.1623,  0.0859,  0.0139, -0.1080, -0.1638, -0.1836],\n        [ 0.2257,  0.1239, -0.1959, -0.1839, -0.0752, -0.2451,  0.1432, -0.0902,\n         -0.1020,  0.1929, -0.2047,  0.0622, -0.0962, -0.0074,  0.0990, -0.1081],\n        [ 0.0699, -0.1360, -0.0275,  0.1945, -0.0914, -0.1225, -0.2114, -0.0139,\n          0.0266, -0.1452, -0.0245,  0.0025,  0.1433, -0.0845,  0.1342,  0.0851],\n        [ 0.1071, -0.0597,  0.1279, -0.1294, -0.0254, -0.1167,  0.2281, -0.1553,\n          0.2271, -0.1010, -0.2218,  0.1285, -0.1817, -0.2110, -0.0273, -0.2228],\n        [ 0.0645,  0.1793,  0.1600,  0.1257,  0.1368, -0.0919, -0.2390, -0.0999,\n         -0.2251,  0.0464,  0.1744,  0.1377,  0.0469,  0.0926, -0.2130, -0.0759],\n        [-0.0492, -0.0224, -0.1253, -0.2197, -0.1948,  0.2448,  0.1121,  0.2482,\n          0.2470, -0.1931, -0.1238, -0.0421,  0.0126,  0.1211, -0.1232, -0.0098]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1510, -0.0261,  0.1307,  0.0919, -0.0104, -0.2309,  0.2231,  0.0259],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1243,  0.3292, -0.1236, -0.0485,  0.1216, -0.0350,  0.1695, -0.1386]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.2208], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x000001BF1428F040>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-ppo-info\\rl4sys-ppo-info_s236720000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='D:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\maze-game\\\\./logs/rl4sys-ppo-info\\\\rl4sys-ppo-info_s236720000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	40,
    "train_v_iters":	40,
    "traj_per_epoch":	5,
    "vf_lr":	0.0003
}