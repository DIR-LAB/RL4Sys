{
    "__class__":	"PPO",
    "buf_size":	50000,
    "clip_ratio":	0.1,
    "env_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game",
    "exp_name":	"rl4sys-ppo-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	5,
    "lam":	0.97,
    "log_data_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-info",
        "output_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s252160000"
    },
    "pi_lr":	0.0003,
    "seed":	252160000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x7af63ade7310>":	{
            "_clip_ratio":	0.1,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (pi_network): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=4, bias=True)\n    )\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (pi_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1897, -0.1467, -0.0566, -0.0861, -0.1298, -0.1547,  0.2107, -0.0693,\n        -0.0693, -0.0207,  0.0458,  0.0103, -0.0381,  0.1207, -0.1436, -0.0538,\n         0.1081, -0.0165, -0.1541,  0.0217,  0.0891, -0.1269, -0.1187, -0.0299,\n        -0.1857, -0.1565, -0.2223, -0.2067,  0.0853, -0.2005,  0.1282, -0.1445],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1459, -0.0215,  0.1425, -0.1887,  0.2170, -0.1735,  0.0678, -0.1899,\n         -0.1519, -0.0158,  0.1540, -0.0215,  0.0065,  0.0468, -0.1240, -0.1933,\n          0.0217, -0.0032,  0.1773,  0.1863],\n        [ 0.0292, -0.1714,  0.1060, -0.2110,  0.2113,  0.0134, -0.0522, -0.0308,\n         -0.0058,  0.0025,  0.2221, -0.1909, -0.1324, -0.1084, -0.0450,  0.1461,\n          0.0691,  0.0120, -0.0350,  0.1386],\n        [ 0.2118,  0.1878, -0.2084, -0.0614,  0.0062,  0.1456, -0.0392,  0.1323,\n         -0.1727,  0.0905,  0.0194,  0.1994, -0.1672, -0.2111,  0.1699,  0.0054,\n          0.0498, -0.0429, -0.0643, -0.0149],\n        [ 0.0810, -0.1023, -0.0385, -0.0110, -0.0098,  0.2069, -0.1084, -0.1010,\n         -0.0838, -0.1384, -0.2201, -0.0617,  0.2140,  0.0752, -0.0558,  0.1020,\n          0.1511,  0.0288,  0.1314, -0.2063],\n        [-0.1242,  0.1927,  0.0957,  0.0476,  0.0707, -0.0199,  0.0861,  0.0904,\n         -0.1185,  0.0518, -0.1271, -0.0019,  0.0258, -0.0931,  0.0258, -0.1409,\n          0.0873, -0.0987,  0.1463,  0.1608],\n        [-0.1738,  0.0073, -0.0184,  0.1069,  0.0928,  0.1939,  0.0704, -0.1234,\n          0.0804,  0.1644,  0.0552, -0.0298,  0.0877,  0.1843, -0.2119,  0.1415,\n         -0.1311,  0.2219, -0.0636, -0.0120],\n        [-0.0769,  0.1864, -0.2056, -0.0092,  0.0822, -0.1857,  0.0581, -0.1659,\n          0.1873, -0.2153,  0.0859,  0.0247, -0.1899, -0.0510, -0.0845, -0.0199,\n         -0.2073,  0.1016, -0.0503, -0.0893],\n        [ 0.1765,  0.1357, -0.0252, -0.0058, -0.0712,  0.0420,  0.1440,  0.0771,\n         -0.1214, -0.1621, -0.1838, -0.0622, -0.1414, -0.0114,  0.1400,  0.0612,\n         -0.0612,  0.1933, -0.1663,  0.0295],\n        [-0.0790, -0.0823,  0.0658, -0.0494,  0.1932, -0.1684, -0.0366, -0.0008,\n         -0.0535, -0.1643, -0.0463, -0.0786,  0.1105, -0.2216, -0.1721, -0.0182,\n         -0.0909,  0.0824, -0.0444,  0.0480],\n        [ 0.1767,  0.1372, -0.0491,  0.1074, -0.1867, -0.1686,  0.2038,  0.1161,\n         -0.0019, -0.1985, -0.1707, -0.0009, -0.1577,  0.0075, -0.1554,  0.1725,\n          0.1976, -0.2027, -0.0619, -0.1924],\n        [-0.1344, -0.0490, -0.0058, -0.0198, -0.1153, -0.1884, -0.1148, -0.0311,\n         -0.0793,  0.0842,  0.1048,  0.0558,  0.0220,  0.0865, -0.1401,  0.0028,\n          0.0585, -0.1072, -0.0766, -0.0485],\n        [ 0.1367, -0.0877, -0.2227,  0.0034,  0.2106, -0.1927, -0.1143,  0.1454,\n          0.0877, -0.0439, -0.0910, -0.0261, -0.0205, -0.0013,  0.0854,  0.1531,\n          0.1423,  0.0561,  0.1927,  0.0086],\n        [ 0.0486, -0.0707,  0.0709,  0.1211,  0.0745,  0.0815,  0.1325, -0.1042,\n         -0.0406, -0.1289,  0.1473,  0.1897, -0.0642, -0.0862,  0.0711,  0.1945,\n          0.1008, -0.0429, -0.1334, -0.2010],\n        [-0.0695,  0.0791, -0.1650,  0.0377, -0.1683, -0.1000,  0.0374, -0.2015,\n         -0.0299, -0.1574,  0.0763, -0.0844, -0.1122,  0.0852, -0.1267, -0.1002,\n          0.1297,  0.1656,  0.0298,  0.1091],\n        [ 0.1281, -0.0092,  0.0590, -0.0386,  0.0931, -0.1250,  0.0337, -0.0042,\n         -0.1032,  0.1535,  0.1548, -0.1884, -0.0869, -0.2124, -0.0544,  0.2228,\n          0.1379,  0.0495, -0.0856, -0.1348],\n        [ 0.0211,  0.2036, -0.0339, -0.2223,  0.2082,  0.0256,  0.0924, -0.1569,\n          0.1140,  0.0428,  0.0157, -0.0212,  0.2073,  0.0726, -0.1496,  0.0023,\n          0.0431, -0.0065,  0.1379,  0.0823],\n        [-0.0047,  0.1560,  0.1239,  0.2180,  0.1928, -0.2180,  0.0620, -0.1601,\n          0.1472,  0.0642,  0.1778, -0.1753,  0.0005, -0.0662, -0.0517, -0.0918,\n          0.0988,  0.1599,  0.1106, -0.0572],\n        [ 0.1075,  0.1862, -0.2120, -0.1575, -0.1304, -0.1038,  0.0376,  0.2192,\n         -0.1349,  0.1934, -0.0129,  0.1875, -0.0616, -0.0232,  0.0469,  0.1456,\n          0.2236,  0.2052, -0.1259, -0.1031],\n        [ 0.1489, -0.2116, -0.0471,  0.1478, -0.1222, -0.1118,  0.2024, -0.1648,\n         -0.0389,  0.1488,  0.2100, -0.2125, -0.0521,  0.2214, -0.0959,  0.2139,\n          0.1245, -0.1341,  0.0417, -0.0105],\n        [ 0.0155, -0.1248, -0.0934, -0.1066,  0.1673, -0.1014,  0.0062,  0.1803,\n          0.1609,  0.1066, -0.0054, -0.0393,  0.1984, -0.2114,  0.0496, -0.0804,\n          0.1232, -0.1231,  0.1675, -0.1199],\n        [-0.1544, -0.1560,  0.0968,  0.0771, -0.1395, -0.0582,  0.1713,  0.1090,\n          0.0123, -0.1650,  0.1707,  0.2209, -0.0968,  0.0939, -0.1110,  0.0301,\n         -0.1897,  0.0443, -0.0584, -0.0726],\n        [-0.1628, -0.0164, -0.1017,  0.1379, -0.1244,  0.1946,  0.0525, -0.0433,\n         -0.0040, -0.0217,  0.1661, -0.0602,  0.0733, -0.0030, -0.1844, -0.1440,\n          0.0276, -0.0982,  0.0735, -0.0932],\n        [-0.1940,  0.0862,  0.1833,  0.0261, -0.1520, -0.0099,  0.0114,  0.1594,\n         -0.0604, -0.0215,  0.0133, -0.2158, -0.0691, -0.0753,  0.0770, -0.1447,\n         -0.1918,  0.0146,  0.1126,  0.2003],\n        [-0.1019, -0.1148, -0.0292,  0.0061, -0.2182, -0.0358, -0.0560,  0.0163,\n          0.2218, -0.0471,  0.0436, -0.1886,  0.2043, -0.0441, -0.0176, -0.1729,\n          0.1178,  0.0697, -0.0490, -0.0185],\n        [-0.0068,  0.0171, -0.2078,  0.0842,  0.2224,  0.1045, -0.0984, -0.0221,\n          0.0008, -0.1269,  0.1430, -0.0150,  0.1795, -0.1835, -0.1497,  0.1535,\n          0.1033,  0.1559, -0.1013, -0.0735],\n        [-0.0057, -0.1567,  0.2219, -0.0206, -0.0765, -0.0762, -0.0652,  0.0812,\n         -0.0403,  0.1758,  0.2218,  0.0914, -0.1369, -0.1578, -0.0574,  0.1855,\n          0.0092, -0.0238, -0.0488,  0.1756],\n        [-0.1827,  0.0916, -0.1155, -0.1436, -0.1344,  0.0205,  0.2012, -0.0318,\n         -0.0163,  0.1916,  0.0688,  0.0860,  0.0326, -0.0061,  0.0022,  0.1532,\n         -0.0671, -0.0333, -0.0097,  0.1250],\n        [ 0.0561, -0.1417,  0.0992, -0.0015,  0.1139, -0.0923,  0.1855,  0.1595,\n         -0.0350, -0.2225,  0.1873, -0.0558, -0.0481,  0.1363, -0.1872,  0.0558,\n          0.0128,  0.1773, -0.0761, -0.2138],\n        [ 0.0062, -0.0558, -0.0709, -0.1282,  0.0279, -0.1336, -0.1577,  0.2192,\n          0.0856,  0.0916,  0.1256,  0.0553, -0.1244,  0.0336,  0.2102, -0.2072,\n         -0.1595,  0.1620, -0.0963,  0.2067],\n        [-0.1444, -0.1933, -0.0987, -0.0092,  0.1092, -0.0730, -0.0103, -0.2227,\n         -0.0294,  0.1034, -0.0373,  0.1964,  0.2067, -0.1923, -0.0929,  0.0012,\n         -0.1924,  0.0422,  0.2063, -0.1511],\n        [-0.2074,  0.1612, -0.1566,  0.0126,  0.0491, -0.0104, -0.1506,  0.1669,\n          0.1476,  0.1862, -0.1778, -0.0174,  0.1908, -0.2109,  0.1739,  0.0246,\n          0.1390,  0.1932, -0.1973,  0.0536],\n        [-0.0458, -0.0047,  0.2110, -0.0524,  0.1045,  0.1030,  0.1814,  0.0169,\n         -0.1428, -0.0771, -0.1715,  0.0620, -0.1814,  0.0813, -0.1013,  0.0542,\n          0.0409,  0.0303,  0.0546,  0.0040]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1487, -0.0490, -0.1446,  0.1572,  0.0238, -0.0235,  0.1724, -0.0732,\n         0.1535, -0.0763, -0.1238,  0.0820,  0.1562, -0.0471, -0.0828,  0.1281],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1263,  0.0269,  0.0675,  0.1765, -0.1152, -0.0437,  0.1410,  0.0205,\n          0.1212, -0.1097,  0.1096,  0.0520, -0.1368,  0.0182, -0.1501,  0.0802,\n          0.1244,  0.1689,  0.1207, -0.0471, -0.1611, -0.0685, -0.1360, -0.0052,\n         -0.0565, -0.0869, -0.1531,  0.1093, -0.0957,  0.0435, -0.0286, -0.0550],\n        [ 0.1455,  0.0154,  0.1157, -0.1363, -0.0828,  0.0227,  0.0575, -0.1481,\n          0.0084, -0.0520, -0.1176,  0.1043,  0.0770,  0.1437, -0.0259,  0.0212,\n         -0.0350, -0.1380,  0.0470,  0.0597, -0.0064, -0.0388, -0.1455, -0.0806,\n         -0.0603,  0.0248, -0.0086, -0.1317, -0.0673,  0.0406, -0.1171, -0.0835],\n        [-0.0189, -0.0102,  0.1618,  0.0757, -0.0670,  0.1485,  0.1316,  0.1012,\n          0.0415, -0.1614, -0.1719,  0.0585,  0.0441,  0.0101, -0.1570,  0.1022,\n          0.1104, -0.1060, -0.1022, -0.1378,  0.1554, -0.0346, -0.0507, -0.0573,\n          0.0548,  0.0951, -0.0596, -0.0968, -0.0351, -0.0503,  0.0789, -0.0106],\n        [ 0.1183, -0.1608, -0.1360, -0.0204, -0.0021,  0.1154,  0.0103, -0.0263,\n         -0.1183,  0.0409, -0.0651,  0.1481, -0.0564,  0.0377,  0.1240,  0.1535,\n          0.0181, -0.0190, -0.0911, -0.1630,  0.0764,  0.0258,  0.1552,  0.0117,\n         -0.1077,  0.0099,  0.0153,  0.1339, -0.0428, -0.0416,  0.1673, -0.0593],\n        [-0.1532,  0.0131, -0.0897,  0.1078, -0.1515, -0.0657,  0.0056,  0.1102,\n          0.0965,  0.1538, -0.1100,  0.0734, -0.0618, -0.0638,  0.1131, -0.0022,\n          0.0151, -0.0003,  0.0140,  0.1747,  0.1686,  0.0658, -0.0933, -0.0405,\n          0.0124,  0.0367,  0.0305,  0.1044,  0.1418, -0.1354, -0.0313,  0.1507],\n        [-0.0035,  0.1549,  0.1635, -0.0328, -0.1228, -0.0916, -0.1135, -0.0802,\n         -0.1549,  0.0146, -0.1176,  0.1580,  0.0512, -0.0760, -0.0694, -0.1066,\n         -0.0867,  0.1379, -0.0798,  0.1540,  0.1642, -0.0481, -0.0137, -0.0656,\n          0.1628, -0.1233,  0.1385, -0.0754, -0.0943,  0.0678, -0.0226, -0.0878],\n        [-0.0911, -0.0163,  0.0723, -0.1008,  0.1247,  0.1329,  0.0283,  0.1630,\n         -0.0940,  0.1462, -0.0768,  0.0703,  0.1538,  0.0237, -0.0653, -0.0800,\n          0.1619, -0.0220, -0.1747,  0.0666,  0.1166, -0.0277,  0.0939, -0.1500,\n          0.1115,  0.0203,  0.0272, -0.0260,  0.0542, -0.1680,  0.1419, -0.1348],\n        [-0.1167, -0.1025,  0.1316, -0.1466, -0.0003, -0.0324, -0.0779,  0.0448,\n          0.0820, -0.0506,  0.0662, -0.1678,  0.1725,  0.0404,  0.0792, -0.1455,\n          0.0941, -0.0180, -0.1187,  0.0237, -0.0973, -0.1511, -0.1093,  0.1118,\n          0.1071, -0.1734,  0.0241, -0.0074,  0.1026,  0.0740,  0.0206,  0.0598],\n        [ 0.1256,  0.0692, -0.0168, -0.1099,  0.0743, -0.0952, -0.1700,  0.1347,\n          0.1449,  0.0984,  0.0517,  0.1338,  0.0611,  0.0584, -0.0248,  0.0353,\n          0.1351, -0.1496,  0.0280, -0.1108, -0.0778, -0.0474,  0.0268,  0.0140,\n         -0.0804, -0.0403, -0.0436, -0.0472,  0.1709,  0.0826, -0.0081,  0.0353],\n        [ 0.0227, -0.0219, -0.0875, -0.0049,  0.1743,  0.0921, -0.0072, -0.1589,\n          0.0781, -0.1693, -0.1345, -0.1390,  0.1294,  0.0797, -0.0448,  0.0152,\n          0.0080,  0.1397,  0.0945, -0.1456,  0.0638,  0.0859, -0.0193,  0.1501,\n         -0.0014,  0.1327,  0.0906,  0.1071, -0.0291, -0.0192,  0.1744, -0.1628],\n        [-0.1163, -0.0207, -0.0628, -0.0845,  0.0374,  0.0591,  0.1576,  0.0634,\n          0.0493, -0.0022,  0.0527,  0.0244,  0.1308, -0.1509,  0.1020, -0.1504,\n         -0.1505, -0.1319,  0.1410,  0.1478,  0.0428,  0.1741, -0.0835,  0.0544,\n          0.1767,  0.0470, -0.0394, -0.0449, -0.0940, -0.1303, -0.0665,  0.1287],\n        [ 0.0488,  0.0198,  0.0209,  0.0900,  0.0805,  0.1645, -0.0024, -0.0929,\n          0.1339,  0.0720,  0.0515,  0.0251, -0.1669,  0.0598,  0.1511, -0.0454,\n         -0.0562,  0.1495,  0.1096, -0.1358, -0.1038,  0.0525,  0.0611,  0.1625,\n         -0.1687,  0.0231, -0.0228, -0.0230, -0.1767,  0.1663, -0.0956,  0.0463],\n        [-0.1256, -0.0869,  0.0778, -0.1449,  0.1480,  0.0428, -0.1171, -0.1256,\n          0.1210, -0.1483,  0.0637,  0.0374, -0.1555,  0.1532, -0.0403,  0.0710,\n         -0.0021,  0.0437,  0.1695,  0.0936,  0.1040, -0.0933, -0.0622,  0.0328,\n          0.1438,  0.1689,  0.1322, -0.1362,  0.1122,  0.1037, -0.0480, -0.0915],\n        [ 0.1616,  0.1474,  0.1364, -0.0905,  0.0736, -0.0142,  0.0332, -0.0827,\n         -0.1759, -0.0315, -0.0383,  0.1168,  0.0964,  0.1314, -0.0336,  0.1510,\n         -0.0005,  0.1596,  0.0537,  0.1237, -0.0189,  0.0768,  0.1059, -0.0719,\n         -0.1458,  0.1470,  0.1428,  0.1084, -0.0793,  0.0530,  0.0002,  0.1608],\n        [-0.1498, -0.1709,  0.0816,  0.0013,  0.0584, -0.1235, -0.1497, -0.0888,\n          0.0924, -0.0263, -0.1284, -0.1735,  0.1270,  0.1624,  0.0532, -0.1719,\n         -0.1311,  0.1138, -0.0781,  0.1767, -0.1338,  0.1132, -0.1322, -0.0593,\n         -0.1094,  0.0341,  0.1498, -0.1507, -0.0792, -0.1731,  0.1756,  0.0287],\n        [ 0.1738,  0.0671, -0.0695,  0.0271, -0.1394,  0.0283,  0.0093, -0.1485,\n         -0.0213,  0.1193,  0.1330,  0.0231,  0.0091,  0.1043,  0.0119,  0.0740,\n          0.0387,  0.0225,  0.0621,  0.0540, -0.1117,  0.1739,  0.0740, -0.0682,\n          0.0923,  0.0806, -0.1412, -0.1072,  0.0634,  0.0021, -0.0387,  0.0363]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1249, -0.1384,  0.0749, -0.0695, -0.1821, -0.0598, -0.2252, -0.1277],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0190, -0.1973,  0.0882,  0.2124, -0.1096, -0.0185, -0.1097, -0.1656,\n          0.1624, -0.2215, -0.0563,  0.1005,  0.1631, -0.2031, -0.1516, -0.1008],\n        [-0.0688, -0.0734,  0.1473,  0.0911, -0.1002, -0.2447, -0.0734,  0.2379,\n          0.0299, -0.0508, -0.1380, -0.1878,  0.1460, -0.2019,  0.1818,  0.2129],\n        [-0.0760,  0.0716, -0.0694, -0.0741,  0.2008, -0.1421, -0.0026,  0.2164,\n         -0.1578,  0.0634,  0.0516,  0.0587,  0.2326,  0.1927, -0.1793, -0.0193],\n        [-0.1864,  0.2173,  0.0228, -0.1551,  0.0934, -0.1892,  0.1446,  0.0928,\n          0.1706,  0.0306, -0.1530,  0.0854,  0.1620,  0.1886,  0.1798,  0.1840],\n        [-0.0153,  0.2261, -0.0011,  0.0843,  0.2081, -0.0505, -0.1179,  0.0969,\n          0.2301, -0.0745,  0.1472,  0.1545, -0.0347, -0.0440,  0.1460,  0.0694],\n        [-0.2353,  0.1344,  0.1717, -0.0063, -0.1504, -0.0534,  0.0777, -0.1159,\n          0.0783,  0.2086, -0.0176, -0.1559,  0.0081,  0.2250,  0.1839,  0.1551],\n        [-0.0047,  0.0773,  0.0938,  0.0629, -0.0116,  0.1606, -0.0939, -0.1184,\n          0.2454,  0.0748, -0.0903, -0.1821, -0.0722,  0.2319, -0.0059, -0.1796],\n        [ 0.0646, -0.0259, -0.0829, -0.2409,  0.0899,  0.1539,  0.1868,  0.1955,\n         -0.1144, -0.2491, -0.1925,  0.1489,  0.0365,  0.0049, -0.1256, -0.1231]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=4, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1310,  0.3068,  0.1051, -0.1526], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0787, -0.0959,  0.1714,  0.0486,  0.1280, -0.3402,  0.0076, -0.1982],\n        [-0.2825,  0.3175, -0.2727,  0.1929, -0.1924,  0.0947, -0.2352,  0.2687],\n        [-0.3389,  0.2355, -0.1665, -0.1630,  0.0208, -0.0495, -0.2520,  0.0120],\n        [-0.2427, -0.0390, -0.0230, -0.0854, -0.1959,  0.0307, -0.1409, -0.1351]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	4,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "kernel_dim":	4,
                                "kernel_size":	5,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0213, -0.1298,  0.1494,  0.0809, -0.1441, -0.0997,  0.0280,  0.0439,\n        -0.1265, -0.0771, -0.1182, -0.0963,  0.0449, -0.0448, -0.1050,  0.0768,\n        -0.0940,  0.0201,  0.1034,  0.2181, -0.0611, -0.1550, -0.1660,  0.0085,\n         0.1345,  0.0992,  0.2176, -0.2167,  0.2042,  0.1071,  0.1153, -0.0852],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 2.1153e-01,  1.0759e-01, -1.9298e-02, -2.1217e-01, -1.7598e-01,\n          6.0451e-02,  1.2098e-02,  2.1791e-02, -5.8877e-02, -2.5071e-02,\n          2.2155e-01, -1.2808e-01, -9.8299e-02, -1.5761e-01,  1.5412e-01,\n         -4.9983e-02, -4.7160e-02, -1.7065e-01, -1.3726e-01, -6.3054e-02],\n        [-1.4514e-02,  5.5757e-02, -1.9903e-01, -2.2296e-01, -1.7985e-01,\n          3.0624e-02,  1.8145e-02, -1.8665e-01, -4.6970e-02,  1.3509e-01,\n          1.7987e-01,  1.2251e-02,  2.1527e-01,  1.1848e-03,  4.0761e-02,\n          1.7111e-01,  8.0530e-02, -5.8743e-02,  1.2544e-01,  1.9649e-02],\n        [-1.4463e-01, -1.6619e-01, -8.7778e-03,  7.6257e-02, -1.9648e-01,\n         -3.6029e-02, -3.3263e-02,  4.5312e-02, -8.1234e-02,  2.7475e-02,\n          5.0953e-02, -9.0207e-02, -1.4220e-01, -1.4244e-01,  4.7253e-02,\n          1.2858e-01,  4.3958e-02, -1.6473e-02, -7.3002e-03,  1.9940e-01],\n        [-3.5951e-03, -1.2260e-01,  1.5649e-01,  1.2542e-02, -2.1560e-01,\n          1.8351e-01, -5.9239e-02,  1.8775e-01,  3.1102e-02, -1.4881e-01,\n         -1.1047e-01,  9.5599e-03, -2.2739e-03,  1.9117e-01, -1.5434e-02,\n         -1.8532e-01, -1.5356e-01, -1.3501e-01, -1.2640e-02,  1.2656e-01],\n        [ 6.0856e-02, -1.7472e-01,  3.4812e-02,  9.7065e-02, -9.5498e-04,\n         -2.0158e-01,  7.2481e-02,  5.4802e-02, -8.0611e-02,  1.1445e-01,\n         -3.4552e-02, -2.1272e-01, -1.2302e-01, -1.0125e-01, -1.0648e-01,\n         -1.6318e-01, -7.1156e-02, -9.4038e-02, -1.1566e-01,  1.4798e-01],\n        [ 1.2092e-01, -9.7809e-02,  1.8348e-01, -9.2172e-02, -3.6967e-02,\n          1.7573e-01, -1.1274e-01, -4.5881e-02, -9.6223e-02, -1.5673e-01,\n         -1.9088e-01,  1.4104e-01,  9.4230e-02, -1.5825e-01,  1.3024e-01,\n          2.4580e-02, -1.9152e-01,  1.4771e-01,  1.3032e-02,  2.4713e-02],\n        [-1.7399e-01,  2.1383e-01, -1.6247e-01,  1.8692e-01, -2.2221e-01,\n         -2.1002e-01, -2.1146e-01, -2.1671e-02,  2.0886e-01,  1.3254e-01,\n         -5.3092e-02,  5.6998e-02,  1.6466e-01,  1.8213e-01, -1.5918e-01,\n          2.5182e-02, -2.0578e-02,  1.6604e-01,  1.1437e-01, -6.0526e-02],\n        [-4.8765e-02,  3.9411e-02, -7.2472e-02,  1.9281e-01, -5.7505e-02,\n         -1.2915e-01,  1.4493e-01, -8.8343e-02, -2.0459e-01, -1.4721e-01,\n          1.5840e-02, -1.2381e-01, -5.6881e-02, -1.3123e-01, -1.6872e-01,\n          1.7904e-01,  9.3063e-02, -1.0261e-01, -8.9609e-02, -7.1299e-02],\n        [-4.5288e-02, -1.5943e-01, -6.9470e-03,  1.9209e-02,  1.4574e-01,\n         -1.0187e-01, -1.0605e-01, -3.0114e-02, -1.7285e-01, -5.9130e-02,\n          2.1888e-01,  5.6636e-02, -1.1654e-01, -2.9452e-02, -1.9034e-01,\n          1.4082e-01, -1.5808e-01,  1.6544e-01, -2.1590e-02, -1.2132e-01],\n        [-7.0630e-02,  1.1099e-01, -1.9734e-01,  6.0971e-03, -6.2674e-02,\n          1.8744e-01, -2.3790e-02,  1.1771e-01, -1.8063e-01, -4.3548e-02,\n          3.2214e-02, -2.2709e-02,  4.6297e-02, -1.7961e-01, -5.8387e-02,\n          8.3799e-03,  1.6838e-01, -2.0194e-01,  1.6591e-01, -1.8639e-01],\n        [ 1.6361e-01,  1.3834e-01,  3.4308e-02,  1.4497e-02,  1.7965e-01,\n         -1.4286e-01, -1.7585e-01, -4.2203e-03,  1.3999e-02, -6.7220e-02,\n         -7.3359e-03, -1.8650e-01, -5.4287e-02, -3.0036e-02,  7.6552e-02,\n         -1.6475e-01,  1.3644e-01,  2.9665e-02, -8.0026e-02,  6.2822e-02],\n        [-2.2256e-02, -6.9399e-02,  1.1470e-01,  2.7325e-02,  1.4668e-01,\n         -1.1269e-01,  1.1394e-01,  6.9033e-02,  1.1652e-02,  1.0286e-02,\n         -9.4868e-02, -7.4234e-02, -1.4418e-01, -9.3034e-02,  9.6048e-02,\n         -4.1754e-02,  4.8025e-02, -1.9729e-01, -8.0453e-02,  1.5167e-01],\n        [-6.2097e-02, -1.6993e-01, -1.0444e-04,  9.7573e-02, -1.8191e-01,\n          8.7981e-02, -1.6533e-02, -1.8537e-01, -8.3292e-02,  1.1293e-01,\n          9.8854e-02,  6.8770e-02,  8.9332e-03,  1.2142e-01, -8.5988e-02,\n         -2.0756e-01, -4.4047e-02,  1.9014e-01, -4.0092e-02, -2.1983e-01],\n        [ 1.1573e-02,  1.7340e-01,  8.9518e-02,  1.7199e-01, -2.0562e-01,\n         -4.8198e-02,  1.7163e-01, -8.3718e-02,  3.8735e-02, -1.6652e-01,\n         -1.5136e-01, -1.8681e-01, -9.2344e-02, -4.6199e-02,  8.2820e-02,\n          1.0617e-01,  1.1917e-01, -9.6578e-02, -1.4746e-01, -3.5234e-02],\n        [ 1.9472e-01,  1.7573e-01, -1.8400e-01, -1.0947e-01, -9.9027e-02,\n          1.2983e-01,  1.5768e-01, -4.6387e-02,  1.6540e-01,  1.5838e-01,\n         -6.5598e-02, -2.1388e-01,  3.3706e-02, -8.0422e-03,  2.2270e-02,\n         -1.5727e-01, -4.4513e-02, -7.4914e-02, -3.9503e-02,  1.0648e-01],\n        [-2.1197e-01,  1.3529e-01,  1.3668e-01, -2.0731e-01,  1.9075e-01,\n          1.3467e-02,  9.9198e-02,  1.1526e-01,  1.4430e-01,  6.8344e-02,\n         -7.4809e-02,  1.2436e-01,  2.2141e-01, -8.0522e-02,  1.9247e-01,\n          1.0972e-01,  7.2344e-02, -4.2402e-03, -1.6260e-01, -2.0592e-01],\n        [ 1.5121e-01, -2.9826e-02, -1.7882e-03,  2.0600e-01, -7.5041e-03,\n          1.8150e-01,  1.1485e-01,  4.9126e-02, -1.3074e-01, -1.2004e-01,\n         -1.3978e-01, -8.8564e-02, -6.5734e-02, -1.7719e-01,  1.7280e-01,\n          1.3466e-02,  4.6593e-02, -2.1112e-01,  2.1217e-01, -1.4677e-01],\n        [ 2.6878e-02, -1.6220e-02, -1.4221e-01,  7.7560e-02,  6.9775e-02,\n          1.1481e-01,  4.1190e-02, -2.0378e-01, -1.7538e-01, -1.3639e-01,\n         -1.0363e-01, -9.8977e-02,  1.7625e-01,  1.7461e-01, -5.5339e-02,\n          1.0991e-01, -1.1363e-01, -9.2910e-02, -1.2536e-01, -1.8625e-02],\n        [-5.2523e-02,  1.3814e-01, -1.9501e-02,  2.0443e-01,  9.1093e-02,\n          1.3813e-03,  2.3804e-04, -9.5409e-02, -8.4514e-02, -3.0762e-02,\n          1.5443e-01, -1.8907e-01,  8.3917e-02, -6.3427e-02,  3.5699e-02,\n         -4.1701e-02,  8.1756e-02,  1.7821e-01, -9.5682e-02,  1.4150e-01],\n        [-1.2980e-01, -1.6772e-03, -1.0303e-01, -8.8553e-02,  7.0093e-02,\n         -6.0929e-02, -2.0615e-01,  6.6441e-02,  1.1128e-01,  1.7356e-01,\n          9.1254e-02, -1.7308e-01, -1.8006e-01, -1.8640e-01, -1.0348e-01,\n          2.1223e-01, -3.4603e-02,  3.0383e-02, -1.3091e-01, -2.1951e-01],\n        [-1.5963e-01, -1.0515e-02, -6.9699e-02, -1.0663e-01, -1.1788e-01,\n          1.0317e-01,  9.2193e-02,  1.8449e-02, -1.1386e-01, -2.0762e-02,\n         -5.6779e-02, -2.0847e-01,  2.0427e-01, -7.6198e-02, -1.4818e-01,\n         -1.1413e-01,  2.1868e-01, -1.4701e-01,  1.7139e-01, -9.7020e-02],\n        [-1.5355e-01,  1.7691e-01, -5.6854e-02, -1.8702e-02, -2.2028e-01,\n         -1.0529e-01,  1.4036e-01,  6.0634e-02,  1.9441e-01, -2.1362e-01,\n          8.3548e-02, -2.9050e-03, -7.3031e-02, -1.2461e-01, -1.2356e-01,\n         -1.7112e-01,  1.0590e-01,  4.7370e-02, -1.1925e-01,  1.8141e-01],\n        [-1.0521e-01,  1.1920e-01,  5.3053e-03, -1.0616e-01, -9.7270e-02,\n         -2.0417e-01,  6.3812e-02,  1.6902e-01, -1.7210e-01, -6.0906e-02,\n         -2.5891e-03,  1.7808e-02,  1.9280e-01, -2.1542e-01, -6.5587e-02,\n         -2.4250e-02, -1.0922e-01,  2.4261e-02, -7.2803e-02,  6.0753e-02],\n        [-1.9676e-01,  1.7655e-01,  2.2516e-02, -1.8374e-01, -8.5336e-02,\n          1.7650e-01,  1.6972e-01,  5.4212e-02, -3.3765e-02, -7.3609e-02,\n          4.1434e-02,  9.2596e-02, -7.1246e-02,  1.4677e-01, -4.9530e-02,\n          1.0079e-01, -2.0951e-01,  3.2734e-02, -9.0839e-02,  2.1047e-01],\n        [-9.3622e-02,  1.8018e-01, -1.0452e-01, -1.8005e-01, -6.7490e-02,\n          9.9776e-02,  1.7005e-01, -6.3779e-02,  3.4957e-02,  1.8986e-01,\n         -1.6834e-01,  4.6057e-02,  1.2204e-02, -1.7619e-01, -9.7919e-02,\n         -1.7131e-01, -2.0401e-01, -1.6879e-01,  4.0455e-02,  2.0527e-01],\n        [ 1.2325e-01, -1.1294e-01,  1.9460e-01, -2.2292e-01,  1.7751e-02,\n          4.9538e-02, -1.8401e-01,  1.6535e-01, -2.0613e-01,  2.6609e-02,\n          1.9727e-01,  1.2725e-01, -6.8002e-02,  6.2396e-03,  1.6778e-01,\n         -1.8820e-01,  4.4493e-02, -1.0608e-01, -1.4514e-01,  7.0107e-02],\n        [-4.2953e-02,  1.9444e-01,  6.5617e-02, -2.1993e-01,  1.5799e-01,\n          2.5085e-02,  5.5231e-03, -1.5898e-01,  1.2833e-01, -1.8047e-01,\n         -1.8475e-01, -1.1300e-01,  1.0257e-01, -9.8372e-02, -1.9737e-01,\n          5.8686e-02,  8.4736e-02,  2.0251e-01, -2.1657e-02,  9.3578e-02],\n        [ 2.0236e-01, -5.4917e-02, -2.0478e-01,  9.7964e-02, -3.3793e-02,\n         -1.6297e-01,  1.6269e-01, -5.2877e-02, -2.1472e-02,  1.9553e-01,\n         -2.1255e-01, -2.1098e-01, -1.7396e-01, -6.0333e-02,  9.4745e-02,\n         -1.7670e-01,  2.0490e-01,  2.0290e-01, -2.5055e-02, -2.0305e-01],\n        [-1.0665e-01,  6.3872e-03,  3.9126e-02,  1.3383e-01, -1.9399e-01,\n         -1.8744e-01, -9.2556e-02,  3.9765e-02,  1.1860e-02,  1.9292e-01,\n          1.6756e-01,  1.3927e-01,  2.9105e-02,  1.7423e-01,  2.2300e-01,\n         -1.3785e-01, -1.2244e-01, -1.1021e-02,  1.3158e-01, -2.8832e-02],\n        [-1.9772e-02,  1.1447e-01, -6.8798e-02,  1.1777e-01, -9.1629e-02,\n         -2.1211e-01,  1.5560e-01,  3.2799e-02, -1.6501e-01, -9.9935e-02,\n          8.3314e-02,  1.7978e-01, -7.8162e-03, -1.7986e-01, -5.8520e-02,\n          2.2159e-01, -7.3059e-02,  2.1270e-01, -1.7467e-01, -1.9492e-01],\n        [-8.7005e-02, -5.6207e-02, -1.0285e-01, -3.1067e-02,  1.9591e-01,\n         -1.9166e-01, -2.0598e-01,  1.2112e-01, -2.0159e-03,  1.0221e-01,\n         -3.4366e-02,  9.7307e-02, -1.2075e-01,  3.5004e-02, -8.2808e-02,\n          6.1590e-02, -2.1841e-01,  1.9914e-01, -1.5764e-01, -1.6547e-01],\n        [-4.3375e-02,  5.1435e-02, -1.9577e-01, -7.4312e-02,  4.5198e-02,\n         -9.2387e-02, -2.1429e-01,  2.1144e-01,  1.3680e-01,  1.8550e-01,\n          1.0614e-01,  4.8711e-02, -6.9032e-02, -1.5607e-01,  1.8671e-01,\n         -9.7662e-02, -1.5752e-01,  1.6273e-01,  1.7126e-03, -7.0848e-02]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0399,  0.0716, -0.0917, -0.0452, -0.0418,  0.1229, -0.1710, -0.1199,\n         0.1756, -0.0872,  0.1371,  0.1767,  0.0033,  0.0843,  0.1763,  0.0910],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 1.7321e-01, -3.9835e-02,  8.1581e-02,  1.5475e-01, -6.0005e-02,\n         -8.1167e-02,  1.5396e-01, -6.3757e-02,  8.0530e-02,  3.6333e-02,\n          3.9509e-02, -7.2804e-03, -6.9765e-02, -1.3510e-01,  3.5539e-02,\n         -1.6985e-01, -1.5790e-01,  3.8498e-02,  1.2206e-01,  1.3546e-01,\n         -1.4501e-02,  1.1494e-01, -2.4281e-02,  1.2965e-01,  1.4070e-01,\n          2.0847e-02,  1.5058e-01, -1.3154e-01,  1.6872e-01,  5.9680e-02,\n          1.2084e-01,  5.0207e-02],\n        [-1.4755e-01, -9.1797e-02, -1.2538e-01, -5.7398e-02,  1.6696e-01,\n         -9.4260e-02,  6.1960e-02,  3.9786e-02,  1.2700e-01, -6.1247e-02,\n         -9.9317e-02, -6.0430e-02,  2.3674e-02, -3.9420e-02, -5.3800e-02,\n          1.1349e-01,  8.9481e-02,  9.4060e-02, -2.9509e-02,  3.4087e-02,\n          1.4996e-01,  5.7630e-02, -1.5485e-01,  1.0815e-01,  4.7295e-02,\n         -1.4354e-01,  9.8807e-02,  1.3451e-02,  1.6653e-01,  3.3330e-02,\n         -7.5330e-02,  4.3703e-02],\n        [-1.5060e-02, -1.6782e-01, -4.7851e-03,  1.6883e-01, -1.1602e-01,\n         -1.0992e-01,  1.5784e-01, -1.2820e-01,  1.6113e-01, -1.3864e-01,\n          2.9320e-02, -3.3698e-02, -1.1756e-01, -4.4444e-02,  3.6279e-02,\n          1.4551e-01,  3.8198e-03, -1.7509e-02,  1.2078e-01, -5.6730e-02,\n         -6.9666e-02,  8.8907e-04, -8.9689e-02, -1.2193e-01, -3.1958e-02,\n         -1.0607e-01,  1.6550e-01, -1.2444e-01,  4.0850e-02,  5.3026e-02,\n         -5.2711e-02,  1.5079e-01],\n        [ 1.0207e-01, -5.5996e-02,  3.7218e-02,  1.1018e-01,  1.5766e-01,\n          1.5322e-01,  2.9087e-02,  1.5640e-01,  9.5170e-02, -3.2932e-02,\n         -1.4502e-01,  5.6334e-02, -1.2399e-01,  1.4553e-01, -1.2195e-01,\n         -1.4997e-01, -1.5922e-01,  1.1090e-01, -1.4546e-01,  1.0163e-01,\n          8.9449e-02, -1.3159e-01, -9.5742e-02,  1.1879e-01,  1.3167e-01,\n          1.1269e-01, -8.1987e-02,  1.4512e-01, -1.8487e-02,  9.2175e-02,\n         -9.9536e-02, -1.4541e-01],\n        [ 7.2591e-02,  1.2277e-01, -1.5829e-01,  1.2907e-01, -1.3821e-01,\n          1.6084e-01,  1.1656e-01,  1.4614e-02, -1.3464e-01, -8.0003e-02,\n          1.7003e-01,  1.5798e-01, -3.4576e-02, -5.1833e-02, -1.1924e-02,\n         -8.5944e-02,  7.5890e-02,  9.1715e-03,  2.4874e-02, -1.5035e-01,\n         -1.0560e-01,  1.7231e-01,  5.5749e-02,  1.0622e-01,  7.2472e-02,\n         -7.5635e-02, -1.2871e-01,  1.7270e-01,  1.5536e-01,  1.3445e-01,\n          1.5144e-01,  5.9658e-02],\n        [-1.6513e-01,  9.3027e-02,  7.5765e-03,  3.6136e-02, -8.9953e-03,\n          1.1566e-01,  1.2898e-01,  1.5988e-01,  1.2935e-01,  8.9428e-02,\n          3.2149e-02, -2.2597e-02, -8.9483e-02, -1.1258e-01, -1.5877e-01,\n          2.1956e-02,  1.5470e-01,  1.5909e-01,  9.1992e-02, -1.3751e-01,\n          2.0476e-02, -1.3115e-01, -9.0605e-02,  1.6574e-01, -6.8623e-03,\n         -1.6448e-01, -9.3491e-02, -8.8827e-02,  8.0335e-02, -1.5686e-01,\n          1.7491e-01, -1.1239e-01],\n        [ 5.8894e-02, -1.7172e-01,  1.1935e-01, -1.1984e-01,  1.0146e-01,\n          5.6345e-02, -7.7197e-02, -9.3647e-02,  2.8522e-03, -1.6406e-01,\n          1.6544e-01,  1.3716e-01, -1.4152e-01, -8.9590e-02, -6.3157e-02,\n          1.3302e-01, -1.1318e-01,  1.0375e-01, -8.2579e-02,  6.8917e-02,\n          9.7127e-02,  1.1147e-01,  6.0015e-02,  9.5846e-02, -5.0808e-05,\n          1.1632e-01, -7.3203e-02, -6.8954e-02, -1.1738e-01, -3.1817e-02,\n         -1.6403e-01, -1.1579e-01],\n        [-6.2059e-03, -4.9294e-02, -1.7092e-01,  1.5169e-01,  1.5074e-01,\n         -1.5160e-01,  2.5669e-02, -7.9722e-02,  8.0965e-02, -1.2104e-01,\n         -1.7566e-01, -1.3944e-01, -6.6731e-02,  4.6255e-02, -1.2678e-01,\n          5.5217e-02,  9.8204e-02, -9.7037e-02, -1.7285e-02, -4.2046e-02,\n         -3.6523e-03, -2.9393e-02, -1.0642e-01,  8.2181e-02, -2.6674e-02,\n         -1.1371e-01,  1.1575e-01,  8.7554e-02,  1.3547e-01,  1.5568e-01,\n          5.1978e-02,  7.8500e-02],\n        [ 7.0059e-02, -1.6959e-01, -9.9663e-02, -5.0672e-02,  4.0700e-02,\n          9.3116e-02, -1.0466e-01, -6.2059e-03, -8.2826e-03,  1.5637e-03,\n          1.3588e-01, -3.3191e-02, -1.5429e-01, -9.9950e-02, -1.0443e-01,\n         -1.2391e-01, -7.5183e-02, -1.1890e-01, -8.3704e-02, -1.2567e-01,\n         -4.6007e-02, -1.0028e-02,  9.0625e-02, -4.5462e-02,  1.4795e-03,\n          4.5883e-02,  1.7164e-01,  1.7059e-01,  1.6056e-01,  8.9703e-02,\n          1.5660e-01,  7.3047e-02],\n        [ 1.5525e-01, -1.0583e-01,  1.6403e-03,  1.1509e-02,  1.4428e-01,\n          2.9811e-02, -4.6082e-02,  4.5831e-02, -9.4556e-02, -1.6557e-01,\n          1.6219e-01,  1.2530e-01,  1.4001e-01, -2.5157e-02,  1.1680e-02,\n         -3.2595e-02,  7.7096e-02, -3.7439e-02,  6.6390e-02, -9.3360e-02,\n          6.9507e-02, -7.9997e-02,  5.0871e-04,  1.5954e-01,  1.4010e-01,\n          5.5176e-02, -6.5873e-03,  1.6582e-01,  6.4490e-03,  1.3551e-01,\n         -1.2313e-01, -1.4200e-01],\n        [ 4.5264e-02, -1.7177e-01, -1.6580e-01,  7.5086e-02, -1.2663e-01,\n         -1.0909e-01,  1.5699e-01,  1.5655e-01, -1.5739e-01,  1.5478e-01,\n         -3.0070e-02, -9.0484e-02, -1.3924e-01, -2.5670e-02,  1.4455e-01,\n         -1.4100e-01, -3.6514e-02,  1.4199e-01, -5.2369e-02,  3.9980e-02,\n         -3.7648e-02, -4.7955e-02,  7.1135e-02, -1.5148e-01,  3.0451e-02,\n         -9.2657e-02, -8.8233e-02, -1.7248e-01, -1.3654e-02, -6.3634e-02,\n         -1.2243e-01, -1.5744e-01],\n        [-9.6061e-02, -7.1432e-02, -1.7452e-01, -1.2877e-01, -8.9398e-02,\n         -3.4454e-02,  2.8226e-02, -1.1999e-02, -7.3431e-02,  4.0518e-02,\n         -1.5491e-01,  6.5108e-02,  1.4891e-01,  5.0086e-02,  3.5968e-02,\n          1.5578e-01,  3.1191e-03,  1.4016e-01,  6.3053e-02,  8.6090e-02,\n         -8.0083e-02, -1.0799e-01, -6.5916e-02, -5.1856e-03, -1.4810e-01,\n          2.4669e-02, -5.9490e-02,  7.1066e-02, -1.6571e-01, -5.6605e-02,\n         -9.3397e-02,  8.2393e-02],\n        [ 1.5475e-01,  1.6692e-01,  6.6120e-02,  4.9813e-02,  3.6499e-02,\n          1.4526e-01, -9.2019e-02, -1.4070e-01,  9.0471e-02,  1.0519e-01,\n         -9.3252e-02, -1.2125e-01,  9.9332e-02, -6.6692e-02, -1.6683e-01,\n         -4.1029e-02,  6.0078e-02, -9.8945e-02, -1.3939e-01, -3.6565e-02,\n          1.0279e-02, -1.1462e-01,  9.7975e-03, -1.1025e-01, -2.6867e-02,\n          1.5383e-01, -1.6442e-01, -1.1814e-01, -1.1490e-01, -1.2452e-01,\n         -1.6236e-01, -1.2476e-01],\n        [ 1.0248e-02, -1.4012e-02, -1.1250e-01, -1.3985e-01, -1.6938e-01,\n          5.5115e-02, -1.8151e-02, -3.2281e-02, -1.4760e-01, -5.9961e-03,\n          1.1766e-01,  1.2395e-02,  1.5566e-01,  7.6862e-02, -1.3332e-01,\n          2.8430e-02, -1.4488e-01,  9.4333e-02, -1.6112e-02,  5.4746e-02,\n          3.3148e-02, -6.8040e-02,  1.4259e-01,  1.0099e-01,  1.0066e-01,\n          1.0741e-01,  7.7694e-02,  2.2737e-02,  1.2627e-01,  8.8886e-02,\n         -8.9714e-02,  1.6338e-01],\n        [ 1.5436e-01, -1.3939e-01,  1.0673e-01,  6.1495e-02,  8.8337e-02,\n          1.7476e-01, -1.2104e-01,  1.2421e-01, -9.0863e-02, -1.2674e-01,\n         -2.2855e-02, -4.1134e-02,  1.3281e-01,  6.0461e-02,  8.6097e-02,\n          8.7423e-02,  1.8786e-02, -1.0204e-01, -4.2256e-02,  1.7907e-02,\n          1.4041e-01,  1.5967e-01,  7.8550e-02, -6.4199e-02,  1.5238e-01,\n         -2.8279e-02,  9.2573e-02,  6.6537e-02,  1.6507e-01, -3.6872e-02,\n          1.5538e-02,  1.3269e-01],\n        [ 7.0855e-02,  1.4328e-01,  1.5980e-03, -3.3588e-02,  1.2090e-01,\n         -1.0323e-01, -1.8705e-02, -1.4247e-01, -1.2280e-01,  1.4199e-01,\n         -1.6030e-01, -1.2567e-01, -8.8275e-02, -6.7877e-02, -1.4166e-01,\n          4.2831e-02, -3.4848e-02, -6.3844e-02, -8.2357e-02,  6.8939e-02,\n         -2.6029e-02,  6.1826e-02,  1.1156e-01, -5.6265e-03, -8.6949e-02,\n         -1.1921e-01, -1.1827e-01,  2.2526e-02,  5.7897e-02,  8.8630e-02,\n          1.8933e-02, -1.1444e-02]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1320,  0.2499, -0.1257, -0.1534, -0.2427, -0.1438, -0.1874, -0.1013],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0687,  0.0303, -0.0912, -0.2422, -0.1928,  0.0456, -0.1614,  0.1897,\n          0.0852,  0.1279, -0.0012, -0.0281, -0.1208, -0.2361, -0.0513,  0.0801],\n        [-0.1873,  0.0239, -0.0292, -0.1105, -0.1316,  0.1224,  0.2239, -0.1293,\n         -0.1273,  0.1417, -0.1588, -0.1382,  0.2387,  0.0811,  0.1382,  0.0069],\n        [ 0.2267, -0.1136, -0.1400,  0.0573,  0.1739, -0.0343, -0.2083,  0.0434,\n          0.1591,  0.0800, -0.1154, -0.2257, -0.1951, -0.0458,  0.2042, -0.0187],\n        [-0.0032, -0.1013,  0.0071,  0.1466, -0.1294, -0.0497, -0.0824,  0.0772,\n          0.0816, -0.2372,  0.2395,  0.0212,  0.0378, -0.1214, -0.1271, -0.2077],\n        [ 0.1442,  0.1923,  0.0030,  0.1353, -0.1962,  0.1197,  0.1296, -0.0762,\n         -0.1780, -0.1370, -0.2183,  0.2240,  0.1210,  0.2345,  0.2193,  0.1853],\n        [ 0.2112, -0.1844, -0.1753,  0.0809,  0.1330,  0.1327,  0.1303, -0.0208,\n         -0.0769, -0.1095,  0.2199, -0.2181,  0.1322, -0.1515,  0.1521, -0.1931],\n        [-0.1980,  0.1855,  0.2077,  0.2305,  0.0028,  0.0519, -0.0038,  0.0890,\n         -0.2460, -0.0062, -0.0326,  0.2431, -0.0462,  0.0353,  0.2238,  0.1314],\n        [-0.1336, -0.1807,  0.1776,  0.2365, -0.1242,  0.1836, -0.0402,  0.0217,\n         -0.1817,  0.2424,  0.2151,  0.1438, -0.0306, -0.0239, -0.1790,  0.1757]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0055], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0016,  0.0682,  0.2491,  0.0253, -0.0731, -0.3119, -0.1936, -0.0763]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    20,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	20,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "flatten_obs_dim":	20,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1459, -0.0215,  0.1425, -0.1887,  0.2170, -0.1735,  0.0678, -0.1899,\n         -0.1519, -0.0158,  0.1540, -0.0215,  0.0065,  0.0468, -0.1240, -0.1933,\n          0.0217, -0.0032,  0.1773,  0.1863],\n        [ 0.0292, -0.1714,  0.1060, -0.2110,  0.2113,  0.0134, -0.0522, -0.0308,\n         -0.0058,  0.0025,  0.2221, -0.1909, -0.1324, -0.1084, -0.0450,  0.1461,\n          0.0691,  0.0120, -0.0350,  0.1386],\n        [ 0.2118,  0.1878, -0.2084, -0.0614,  0.0062,  0.1456, -0.0392,  0.1323,\n         -0.1727,  0.0905,  0.0194,  0.1994, -0.1672, -0.2111,  0.1699,  0.0054,\n          0.0498, -0.0429, -0.0643, -0.0149],\n        [ 0.0810, -0.1023, -0.0385, -0.0110, -0.0098,  0.2069, -0.1084, -0.1010,\n         -0.0838, -0.1384, -0.2201, -0.0617,  0.2140,  0.0752, -0.0558,  0.1020,\n          0.1511,  0.0288,  0.1314, -0.2063],\n        [-0.1242,  0.1927,  0.0957,  0.0476,  0.0707, -0.0199,  0.0861,  0.0904,\n         -0.1185,  0.0518, -0.1271, -0.0019,  0.0258, -0.0931,  0.0258, -0.1409,\n          0.0873, -0.0987,  0.1463,  0.1608],\n        [-0.1738,  0.0073, -0.0184,  0.1069,  0.0928,  0.1939,  0.0704, -0.1234,\n          0.0804,  0.1644,  0.0552, -0.0298,  0.0877,  0.1843, -0.2119,  0.1415,\n         -0.1311,  0.2219, -0.0636, -0.0120],\n        [-0.0769,  0.1864, -0.2056, -0.0092,  0.0822, -0.1857,  0.0581, -0.1659,\n          0.1873, -0.2153,  0.0859,  0.0247, -0.1899, -0.0510, -0.0845, -0.0199,\n         -0.2073,  0.1016, -0.0503, -0.0893],\n        [ 0.1765,  0.1357, -0.0252, -0.0058, -0.0712,  0.0420,  0.1440,  0.0771,\n         -0.1214, -0.1621, -0.1838, -0.0622, -0.1414, -0.0114,  0.1400,  0.0612,\n         -0.0612,  0.1933, -0.1663,  0.0295],\n        [-0.0790, -0.0823,  0.0658, -0.0494,  0.1932, -0.1684, -0.0366, -0.0008,\n         -0.0535, -0.1643, -0.0463, -0.0786,  0.1105, -0.2216, -0.1721, -0.0182,\n         -0.0909,  0.0824, -0.0444,  0.0480],\n        [ 0.1767,  0.1372, -0.0491,  0.1074, -0.1867, -0.1686,  0.2038,  0.1161,\n         -0.0019, -0.1985, -0.1707, -0.0009, -0.1577,  0.0075, -0.1554,  0.1725,\n          0.1976, -0.2027, -0.0619, -0.1924],\n        [-0.1344, -0.0490, -0.0058, -0.0198, -0.1153, -0.1884, -0.1148, -0.0311,\n         -0.0793,  0.0842,  0.1048,  0.0558,  0.0220,  0.0865, -0.1401,  0.0028,\n          0.0585, -0.1072, -0.0766, -0.0485],\n        [ 0.1367, -0.0877, -0.2227,  0.0034,  0.2106, -0.1927, -0.1143,  0.1454,\n          0.0877, -0.0439, -0.0910, -0.0261, -0.0205, -0.0013,  0.0854,  0.1531,\n          0.1423,  0.0561,  0.1927,  0.0086],\n        [ 0.0486, -0.0707,  0.0709,  0.1211,  0.0745,  0.0815,  0.1325, -0.1042,\n         -0.0406, -0.1289,  0.1473,  0.1897, -0.0642, -0.0862,  0.0711,  0.1945,\n          0.1008, -0.0429, -0.1334, -0.2010],\n        [-0.0695,  0.0791, -0.1650,  0.0377, -0.1683, -0.1000,  0.0374, -0.2015,\n         -0.0299, -0.1574,  0.0763, -0.0844, -0.1122,  0.0852, -0.1267, -0.1002,\n          0.1297,  0.1656,  0.0298,  0.1091],\n        [ 0.1281, -0.0092,  0.0590, -0.0386,  0.0931, -0.1250,  0.0337, -0.0042,\n         -0.1032,  0.1535,  0.1548, -0.1884, -0.0869, -0.2124, -0.0544,  0.2228,\n          0.1379,  0.0495, -0.0856, -0.1348],\n        [ 0.0211,  0.2036, -0.0339, -0.2223,  0.2082,  0.0256,  0.0924, -0.1569,\n          0.1140,  0.0428,  0.0157, -0.0212,  0.2073,  0.0726, -0.1496,  0.0023,\n          0.0431, -0.0065,  0.1379,  0.0823],\n        [-0.0047,  0.1560,  0.1239,  0.2180,  0.1928, -0.2180,  0.0620, -0.1601,\n          0.1472,  0.0642,  0.1778, -0.1753,  0.0005, -0.0662, -0.0517, -0.0918,\n          0.0988,  0.1599,  0.1106, -0.0572],\n        [ 0.1075,  0.1862, -0.2120, -0.1575, -0.1304, -0.1038,  0.0376,  0.2192,\n         -0.1349,  0.1934, -0.0129,  0.1875, -0.0616, -0.0232,  0.0469,  0.1456,\n          0.2236,  0.2052, -0.1259, -0.1031],\n        [ 0.1489, -0.2116, -0.0471,  0.1478, -0.1222, -0.1118,  0.2024, -0.1648,\n         -0.0389,  0.1488,  0.2100, -0.2125, -0.0521,  0.2214, -0.0959,  0.2139,\n          0.1245, -0.1341,  0.0417, -0.0105],\n        [ 0.0155, -0.1248, -0.0934, -0.1066,  0.1673, -0.1014,  0.0062,  0.1803,\n          0.1609,  0.1066, -0.0054, -0.0393,  0.1984, -0.2114,  0.0496, -0.0804,\n          0.1232, -0.1231,  0.1675, -0.1199],\n        [-0.1544, -0.1560,  0.0968,  0.0771, -0.1395, -0.0582,  0.1713,  0.1090,\n          0.0123, -0.1650,  0.1707,  0.2209, -0.0968,  0.0939, -0.1110,  0.0301,\n         -0.1897,  0.0443, -0.0584, -0.0726],\n        [-0.1628, -0.0164, -0.1017,  0.1379, -0.1244,  0.1946,  0.0525, -0.0433,\n         -0.0040, -0.0217,  0.1661, -0.0602,  0.0733, -0.0030, -0.1844, -0.1440,\n          0.0276, -0.0982,  0.0735, -0.0932],\n        [-0.1940,  0.0862,  0.1833,  0.0261, -0.1520, -0.0099,  0.0114,  0.1594,\n         -0.0604, -0.0215,  0.0133, -0.2158, -0.0691, -0.0753,  0.0770, -0.1447,\n         -0.1918,  0.0146,  0.1126,  0.2003],\n        [-0.1019, -0.1148, -0.0292,  0.0061, -0.2182, -0.0358, -0.0560,  0.0163,\n          0.2218, -0.0471,  0.0436, -0.1886,  0.2043, -0.0441, -0.0176, -0.1729,\n          0.1178,  0.0697, -0.0490, -0.0185],\n        [-0.0068,  0.0171, -0.2078,  0.0842,  0.2224,  0.1045, -0.0984, -0.0221,\n          0.0008, -0.1269,  0.1430, -0.0150,  0.1795, -0.1835, -0.1497,  0.1535,\n          0.1033,  0.1559, -0.1013, -0.0735],\n        [-0.0057, -0.1567,  0.2219, -0.0206, -0.0765, -0.0762, -0.0652,  0.0812,\n         -0.0403,  0.1758,  0.2218,  0.0914, -0.1369, -0.1578, -0.0574,  0.1855,\n          0.0092, -0.0238, -0.0488,  0.1756],\n        [-0.1827,  0.0916, -0.1155, -0.1436, -0.1344,  0.0205,  0.2012, -0.0318,\n         -0.0163,  0.1916,  0.0688,  0.0860,  0.0326, -0.0061,  0.0022,  0.1532,\n         -0.0671, -0.0333, -0.0097,  0.1250],\n        [ 0.0561, -0.1417,  0.0992, -0.0015,  0.1139, -0.0923,  0.1855,  0.1595,\n         -0.0350, -0.2225,  0.1873, -0.0558, -0.0481,  0.1363, -0.1872,  0.0558,\n          0.0128,  0.1773, -0.0761, -0.2138],\n        [ 0.0062, -0.0558, -0.0709, -0.1282,  0.0279, -0.1336, -0.1577,  0.2192,\n          0.0856,  0.0916,  0.1256,  0.0553, -0.1244,  0.0336,  0.2102, -0.2072,\n         -0.1595,  0.1620, -0.0963,  0.2067],\n        [-0.1444, -0.1933, -0.0987, -0.0092,  0.1092, -0.0730, -0.0103, -0.2227,\n         -0.0294,  0.1034, -0.0373,  0.1964,  0.2067, -0.1923, -0.0929,  0.0012,\n         -0.1924,  0.0422,  0.2063, -0.1511],\n        [-0.2074,  0.1612, -0.1566,  0.0126,  0.0491, -0.0104, -0.1506,  0.1669,\n          0.1476,  0.1862, -0.1778, -0.0174,  0.1908, -0.2109,  0.1739,  0.0246,\n          0.1390,  0.1932, -0.1973,  0.0536],\n        [-0.0458, -0.0047,  0.2110, -0.0524,  0.1045,  0.1030,  0.1814,  0.0169,\n         -0.1428, -0.0771, -0.1715,  0.0620, -0.1814,  0.0813, -0.1013,  0.0542,\n          0.0409,  0.0303,  0.0546,  0.0040]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1897, -0.1467, -0.0566, -0.0861, -0.1298, -0.1547,  0.2107, -0.0693,\n        -0.0693, -0.0207,  0.0458,  0.0103, -0.0381,  0.1207, -0.1436, -0.0538,\n         0.1081, -0.0165, -0.1541,  0.0217,  0.0891, -0.1269, -0.1187, -0.0299,\n        -0.1857, -0.1565, -0.2223, -0.2067,  0.0853, -0.2005,  0.1282, -0.1445],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1263,  0.0269,  0.0675,  0.1765, -0.1152, -0.0437,  0.1410,  0.0205,\n          0.1212, -0.1097,  0.1096,  0.0520, -0.1368,  0.0182, -0.1501,  0.0802,\n          0.1244,  0.1689,  0.1207, -0.0471, -0.1611, -0.0685, -0.1360, -0.0052,\n         -0.0565, -0.0869, -0.1531,  0.1093, -0.0957,  0.0435, -0.0286, -0.0550],\n        [ 0.1455,  0.0154,  0.1157, -0.1363, -0.0828,  0.0227,  0.0575, -0.1481,\n          0.0084, -0.0520, -0.1176,  0.1043,  0.0770,  0.1437, -0.0259,  0.0212,\n         -0.0350, -0.1380,  0.0470,  0.0597, -0.0064, -0.0388, -0.1455, -0.0806,\n         -0.0603,  0.0248, -0.0086, -0.1317, -0.0673,  0.0406, -0.1171, -0.0835],\n        [-0.0189, -0.0102,  0.1618,  0.0757, -0.0670,  0.1485,  0.1316,  0.1012,\n          0.0415, -0.1614, -0.1719,  0.0585,  0.0441,  0.0101, -0.1570,  0.1022,\n          0.1104, -0.1060, -0.1022, -0.1378,  0.1554, -0.0346, -0.0507, -0.0573,\n          0.0548,  0.0951, -0.0596, -0.0968, -0.0351, -0.0503,  0.0789, -0.0106],\n        [ 0.1183, -0.1608, -0.1360, -0.0204, -0.0021,  0.1154,  0.0103, -0.0263,\n         -0.1183,  0.0409, -0.0651,  0.1481, -0.0564,  0.0377,  0.1240,  0.1535,\n          0.0181, -0.0190, -0.0911, -0.1630,  0.0764,  0.0258,  0.1552,  0.0117,\n         -0.1077,  0.0099,  0.0153,  0.1339, -0.0428, -0.0416,  0.1673, -0.0593],\n        [-0.1532,  0.0131, -0.0897,  0.1078, -0.1515, -0.0657,  0.0056,  0.1102,\n          0.0965,  0.1538, -0.1100,  0.0734, -0.0618, -0.0638,  0.1131, -0.0022,\n          0.0151, -0.0003,  0.0140,  0.1747,  0.1686,  0.0658, -0.0933, -0.0405,\n          0.0124,  0.0367,  0.0305,  0.1044,  0.1418, -0.1354, -0.0313,  0.1507],\n        [-0.0035,  0.1549,  0.1635, -0.0328, -0.1228, -0.0916, -0.1135, -0.0802,\n         -0.1549,  0.0146, -0.1176,  0.1580,  0.0512, -0.0760, -0.0694, -0.1066,\n         -0.0867,  0.1379, -0.0798,  0.1540,  0.1642, -0.0481, -0.0137, -0.0656,\n          0.1628, -0.1233,  0.1385, -0.0754, -0.0943,  0.0678, -0.0226, -0.0878],\n        [-0.0911, -0.0163,  0.0723, -0.1008,  0.1247,  0.1329,  0.0283,  0.1630,\n         -0.0940,  0.1462, -0.0768,  0.0703,  0.1538,  0.0237, -0.0653, -0.0800,\n          0.1619, -0.0220, -0.1747,  0.0666,  0.1166, -0.0277,  0.0939, -0.1500,\n          0.1115,  0.0203,  0.0272, -0.0260,  0.0542, -0.1680,  0.1419, -0.1348],\n        [-0.1167, -0.1025,  0.1316, -0.1466, -0.0003, -0.0324, -0.0779,  0.0448,\n          0.0820, -0.0506,  0.0662, -0.1678,  0.1725,  0.0404,  0.0792, -0.1455,\n          0.0941, -0.0180, -0.1187,  0.0237, -0.0973, -0.1511, -0.1093,  0.1118,\n          0.1071, -0.1734,  0.0241, -0.0074,  0.1026,  0.0740,  0.0206,  0.0598],\n        [ 0.1256,  0.0692, -0.0168, -0.1099,  0.0743, -0.0952, -0.1700,  0.1347,\n          0.1449,  0.0984,  0.0517,  0.1338,  0.0611,  0.0584, -0.0248,  0.0353,\n          0.1351, -0.1496,  0.0280, -0.1108, -0.0778, -0.0474,  0.0268,  0.0140,\n         -0.0804, -0.0403, -0.0436, -0.0472,  0.1709,  0.0826, -0.0081,  0.0353],\n        [ 0.0227, -0.0219, -0.0875, -0.0049,  0.1743,  0.0921, -0.0072, -0.1589,\n          0.0781, -0.1693, -0.1345, -0.1390,  0.1294,  0.0797, -0.0448,  0.0152,\n          0.0080,  0.1397,  0.0945, -0.1456,  0.0638,  0.0859, -0.0193,  0.1501,\n         -0.0014,  0.1327,  0.0906,  0.1071, -0.0291, -0.0192,  0.1744, -0.1628],\n        [-0.1163, -0.0207, -0.0628, -0.0845,  0.0374,  0.0591,  0.1576,  0.0634,\n          0.0493, -0.0022,  0.0527,  0.0244,  0.1308, -0.1509,  0.1020, -0.1504,\n         -0.1505, -0.1319,  0.1410,  0.1478,  0.0428,  0.1741, -0.0835,  0.0544,\n          0.1767,  0.0470, -0.0394, -0.0449, -0.0940, -0.1303, -0.0665,  0.1287],\n        [ 0.0488,  0.0198,  0.0209,  0.0900,  0.0805,  0.1645, -0.0024, -0.0929,\n          0.1339,  0.0720,  0.0515,  0.0251, -0.1669,  0.0598,  0.1511, -0.0454,\n         -0.0562,  0.1495,  0.1096, -0.1358, -0.1038,  0.0525,  0.0611,  0.1625,\n         -0.1687,  0.0231, -0.0228, -0.0230, -0.1767,  0.1663, -0.0956,  0.0463],\n        [-0.1256, -0.0869,  0.0778, -0.1449,  0.1480,  0.0428, -0.1171, -0.1256,\n          0.1210, -0.1483,  0.0637,  0.0374, -0.1555,  0.1532, -0.0403,  0.0710,\n         -0.0021,  0.0437,  0.1695,  0.0936,  0.1040, -0.0933, -0.0622,  0.0328,\n          0.1438,  0.1689,  0.1322, -0.1362,  0.1122,  0.1037, -0.0480, -0.0915],\n        [ 0.1616,  0.1474,  0.1364, -0.0905,  0.0736, -0.0142,  0.0332, -0.0827,\n         -0.1759, -0.0315, -0.0383,  0.1168,  0.0964,  0.1314, -0.0336,  0.1510,\n         -0.0005,  0.1596,  0.0537,  0.1237, -0.0189,  0.0768,  0.1059, -0.0719,\n         -0.1458,  0.1470,  0.1428,  0.1084, -0.0793,  0.0530,  0.0002,  0.1608],\n        [-0.1498, -0.1709,  0.0816,  0.0013,  0.0584, -0.1235, -0.1497, -0.0888,\n          0.0924, -0.0263, -0.1284, -0.1735,  0.1270,  0.1624,  0.0532, -0.1719,\n         -0.1311,  0.1138, -0.0781,  0.1767, -0.1338,  0.1132, -0.1322, -0.0593,\n         -0.1094,  0.0341,  0.1498, -0.1507, -0.0792, -0.1731,  0.1756,  0.0287],\n        [ 0.1738,  0.0671, -0.0695,  0.0271, -0.1394,  0.0283,  0.0093, -0.1485,\n         -0.0213,  0.1193,  0.1330,  0.0231,  0.0091,  0.1043,  0.0119,  0.0740,\n          0.0387,  0.0225,  0.0621,  0.0540, -0.1117,  0.1739,  0.0740, -0.0682,\n          0.0923,  0.0806, -0.1412, -0.1072,  0.0634,  0.0021, -0.0387,  0.0363]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1487, -0.0490, -0.1446,  0.1572,  0.0238, -0.0235,  0.1724, -0.0732,\n         0.1535, -0.0763, -0.1238,  0.0820,  0.1562, -0.0471, -0.0828,  0.1281],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0190, -0.1973,  0.0882,  0.2124, -0.1096, -0.0185, -0.1097, -0.1656,\n          0.1624, -0.2215, -0.0563,  0.1005,  0.1631, -0.2031, -0.1516, -0.1008],\n        [-0.0688, -0.0734,  0.1473,  0.0911, -0.1002, -0.2447, -0.0734,  0.2379,\n          0.0299, -0.0508, -0.1380, -0.1878,  0.1460, -0.2019,  0.1818,  0.2129],\n        [-0.0760,  0.0716, -0.0694, -0.0741,  0.2008, -0.1421, -0.0026,  0.2164,\n         -0.1578,  0.0634,  0.0516,  0.0587,  0.2326,  0.1927, -0.1793, -0.0193],\n        [-0.1864,  0.2173,  0.0228, -0.1551,  0.0934, -0.1892,  0.1446,  0.0928,\n          0.1706,  0.0306, -0.1530,  0.0854,  0.1620,  0.1886,  0.1798,  0.1840],\n        [-0.0153,  0.2261, -0.0011,  0.0843,  0.2081, -0.0505, -0.1179,  0.0969,\n          0.2301, -0.0745,  0.1472,  0.1545, -0.0347, -0.0440,  0.1460,  0.0694],\n        [-0.2353,  0.1344,  0.1717, -0.0063, -0.1504, -0.0534,  0.0777, -0.1159,\n          0.0783,  0.2086, -0.0176, -0.1559,  0.0081,  0.2250,  0.1839,  0.1551],\n        [-0.0047,  0.0773,  0.0938,  0.0629, -0.0116,  0.1606, -0.0939, -0.1184,\n          0.2454,  0.0748, -0.0903, -0.1821, -0.0722,  0.2319, -0.0059, -0.1796],\n        [ 0.0646, -0.0259, -0.0829, -0.2409,  0.0899,  0.1539,  0.1868,  0.1955,\n         -0.1144, -0.2491, -0.1925,  0.1489,  0.0365,  0.0049, -0.1256, -0.1231]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1249, -0.1384,  0.0749, -0.0695, -0.1821, -0.0598, -0.2252, -0.1277],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0787, -0.0959,  0.1714,  0.0486,  0.1280, -0.3402,  0.0076, -0.1982],\n        [-0.2825,  0.3175, -0.2727,  0.1929, -0.1924,  0.0947, -0.2352,  0.2687],\n        [-0.3389,  0.2355, -0.1665, -0.1630,  0.0208, -0.0495, -0.2520,  0.0120],\n        [-0.2427, -0.0390, -0.0230, -0.0854, -0.1959,  0.0307, -0.1409, -0.1351]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1310,  0.3068,  0.1051, -0.1526], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x7af63ade7460>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	50000,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	40,
            "_train_v_iters":	40,
            "_traj_per_epoch":	5,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 2.1153e-01,  1.0759e-01, -1.9298e-02, -2.1217e-01, -1.7598e-01,\n          6.0451e-02,  1.2098e-02,  2.1791e-02, -5.8877e-02, -2.5071e-02,\n          2.2155e-01, -1.2808e-01, -9.8299e-02, -1.5761e-01,  1.5412e-01,\n         -4.9983e-02, -4.7160e-02, -1.7065e-01, -1.3726e-01, -6.3054e-02],\n        [-1.4514e-02,  5.5757e-02, -1.9903e-01, -2.2296e-01, -1.7985e-01,\n          3.0624e-02,  1.8145e-02, -1.8665e-01, -4.6970e-02,  1.3509e-01,\n          1.7987e-01,  1.2251e-02,  2.1527e-01,  1.1848e-03,  4.0761e-02,\n          1.7111e-01,  8.0530e-02, -5.8743e-02,  1.2544e-01,  1.9649e-02],\n        [-1.4463e-01, -1.6619e-01, -8.7778e-03,  7.6257e-02, -1.9648e-01,\n         -3.6029e-02, -3.3263e-02,  4.5312e-02, -8.1234e-02,  2.7475e-02,\n          5.0953e-02, -9.0207e-02, -1.4220e-01, -1.4244e-01,  4.7253e-02,\n          1.2858e-01,  4.3958e-02, -1.6473e-02, -7.3002e-03,  1.9940e-01],\n        [-3.5951e-03, -1.2260e-01,  1.5649e-01,  1.2542e-02, -2.1560e-01,\n          1.8351e-01, -5.9239e-02,  1.8775e-01,  3.1102e-02, -1.4881e-01,\n         -1.1047e-01,  9.5599e-03, -2.2739e-03,  1.9117e-01, -1.5434e-02,\n         -1.8532e-01, -1.5356e-01, -1.3501e-01, -1.2640e-02,  1.2656e-01],\n        [ 6.0856e-02, -1.7472e-01,  3.4812e-02,  9.7065e-02, -9.5498e-04,\n         -2.0158e-01,  7.2481e-02,  5.4802e-02, -8.0611e-02,  1.1445e-01,\n         -3.4552e-02, -2.1272e-01, -1.2302e-01, -1.0125e-01, -1.0648e-01,\n         -1.6318e-01, -7.1156e-02, -9.4038e-02, -1.1566e-01,  1.4798e-01],\n        [ 1.2092e-01, -9.7809e-02,  1.8348e-01, -9.2172e-02, -3.6967e-02,\n          1.7573e-01, -1.1274e-01, -4.5881e-02, -9.6223e-02, -1.5673e-01,\n         -1.9088e-01,  1.4104e-01,  9.4230e-02, -1.5825e-01,  1.3024e-01,\n          2.4580e-02, -1.9152e-01,  1.4771e-01,  1.3032e-02,  2.4713e-02],\n        [-1.7399e-01,  2.1383e-01, -1.6247e-01,  1.8692e-01, -2.2221e-01,\n         -2.1002e-01, -2.1146e-01, -2.1671e-02,  2.0886e-01,  1.3254e-01,\n         -5.3092e-02,  5.6998e-02,  1.6466e-01,  1.8213e-01, -1.5918e-01,\n          2.5182e-02, -2.0578e-02,  1.6604e-01,  1.1437e-01, -6.0526e-02],\n        [-4.8765e-02,  3.9411e-02, -7.2472e-02,  1.9281e-01, -5.7505e-02,\n         -1.2915e-01,  1.4493e-01, -8.8343e-02, -2.0459e-01, -1.4721e-01,\n          1.5840e-02, -1.2381e-01, -5.6881e-02, -1.3123e-01, -1.6872e-01,\n          1.7904e-01,  9.3063e-02, -1.0261e-01, -8.9609e-02, -7.1299e-02],\n        [-4.5288e-02, -1.5943e-01, -6.9470e-03,  1.9209e-02,  1.4574e-01,\n         -1.0187e-01, -1.0605e-01, -3.0114e-02, -1.7285e-01, -5.9130e-02,\n          2.1888e-01,  5.6636e-02, -1.1654e-01, -2.9452e-02, -1.9034e-01,\n          1.4082e-01, -1.5808e-01,  1.6544e-01, -2.1590e-02, -1.2132e-01],\n        [-7.0630e-02,  1.1099e-01, -1.9734e-01,  6.0971e-03, -6.2674e-02,\n          1.8744e-01, -2.3790e-02,  1.1771e-01, -1.8063e-01, -4.3548e-02,\n          3.2214e-02, -2.2709e-02,  4.6297e-02, -1.7961e-01, -5.8387e-02,\n          8.3799e-03,  1.6838e-01, -2.0194e-01,  1.6591e-01, -1.8639e-01],\n        [ 1.6361e-01,  1.3834e-01,  3.4308e-02,  1.4497e-02,  1.7965e-01,\n         -1.4286e-01, -1.7585e-01, -4.2203e-03,  1.3999e-02, -6.7220e-02,\n         -7.3359e-03, -1.8650e-01, -5.4287e-02, -3.0036e-02,  7.6552e-02,\n         -1.6475e-01,  1.3644e-01,  2.9665e-02, -8.0026e-02,  6.2822e-02],\n        [-2.2256e-02, -6.9399e-02,  1.1470e-01,  2.7325e-02,  1.4668e-01,\n         -1.1269e-01,  1.1394e-01,  6.9033e-02,  1.1652e-02,  1.0286e-02,\n         -9.4868e-02, -7.4234e-02, -1.4418e-01, -9.3034e-02,  9.6048e-02,\n         -4.1754e-02,  4.8025e-02, -1.9729e-01, -8.0453e-02,  1.5167e-01],\n        [-6.2097e-02, -1.6993e-01, -1.0444e-04,  9.7573e-02, -1.8191e-01,\n          8.7981e-02, -1.6533e-02, -1.8537e-01, -8.3292e-02,  1.1293e-01,\n          9.8854e-02,  6.8770e-02,  8.9332e-03,  1.2142e-01, -8.5988e-02,\n         -2.0756e-01, -4.4047e-02,  1.9014e-01, -4.0092e-02, -2.1983e-01],\n        [ 1.1573e-02,  1.7340e-01,  8.9518e-02,  1.7199e-01, -2.0562e-01,\n         -4.8198e-02,  1.7163e-01, -8.3718e-02,  3.8735e-02, -1.6652e-01,\n         -1.5136e-01, -1.8681e-01, -9.2344e-02, -4.6199e-02,  8.2820e-02,\n          1.0617e-01,  1.1917e-01, -9.6578e-02, -1.4746e-01, -3.5234e-02],\n        [ 1.9472e-01,  1.7573e-01, -1.8400e-01, -1.0947e-01, -9.9027e-02,\n          1.2983e-01,  1.5768e-01, -4.6387e-02,  1.6540e-01,  1.5838e-01,\n         -6.5598e-02, -2.1388e-01,  3.3706e-02, -8.0422e-03,  2.2270e-02,\n         -1.5727e-01, -4.4513e-02, -7.4914e-02, -3.9503e-02,  1.0648e-01],\n        [-2.1197e-01,  1.3529e-01,  1.3668e-01, -2.0731e-01,  1.9075e-01,\n          1.3467e-02,  9.9198e-02,  1.1526e-01,  1.4430e-01,  6.8344e-02,\n         -7.4809e-02,  1.2436e-01,  2.2141e-01, -8.0522e-02,  1.9247e-01,\n          1.0972e-01,  7.2344e-02, -4.2402e-03, -1.6260e-01, -2.0592e-01],\n        [ 1.5121e-01, -2.9826e-02, -1.7882e-03,  2.0600e-01, -7.5041e-03,\n          1.8150e-01,  1.1485e-01,  4.9126e-02, -1.3074e-01, -1.2004e-01,\n         -1.3978e-01, -8.8564e-02, -6.5734e-02, -1.7719e-01,  1.7280e-01,\n          1.3466e-02,  4.6593e-02, -2.1112e-01,  2.1217e-01, -1.4677e-01],\n        [ 2.6878e-02, -1.6220e-02, -1.4221e-01,  7.7560e-02,  6.9775e-02,\n          1.1481e-01,  4.1190e-02, -2.0378e-01, -1.7538e-01, -1.3639e-01,\n         -1.0363e-01, -9.8977e-02,  1.7625e-01,  1.7461e-01, -5.5339e-02,\n          1.0991e-01, -1.1363e-01, -9.2910e-02, -1.2536e-01, -1.8625e-02],\n        [-5.2523e-02,  1.3814e-01, -1.9501e-02,  2.0443e-01,  9.1093e-02,\n          1.3813e-03,  2.3804e-04, -9.5409e-02, -8.4514e-02, -3.0762e-02,\n          1.5443e-01, -1.8907e-01,  8.3917e-02, -6.3427e-02,  3.5699e-02,\n         -4.1701e-02,  8.1756e-02,  1.7821e-01, -9.5682e-02,  1.4150e-01],\n        [-1.2980e-01, -1.6772e-03, -1.0303e-01, -8.8553e-02,  7.0093e-02,\n         -6.0929e-02, -2.0615e-01,  6.6441e-02,  1.1128e-01,  1.7356e-01,\n          9.1254e-02, -1.7308e-01, -1.8006e-01, -1.8640e-01, -1.0348e-01,\n          2.1223e-01, -3.4603e-02,  3.0383e-02, -1.3091e-01, -2.1951e-01],\n        [-1.5963e-01, -1.0515e-02, -6.9699e-02, -1.0663e-01, -1.1788e-01,\n          1.0317e-01,  9.2193e-02,  1.8449e-02, -1.1386e-01, -2.0762e-02,\n         -5.6779e-02, -2.0847e-01,  2.0427e-01, -7.6198e-02, -1.4818e-01,\n         -1.1413e-01,  2.1868e-01, -1.4701e-01,  1.7139e-01, -9.7020e-02],\n        [-1.5355e-01,  1.7691e-01, -5.6854e-02, -1.8702e-02, -2.2028e-01,\n         -1.0529e-01,  1.4036e-01,  6.0634e-02,  1.9441e-01, -2.1362e-01,\n          8.3548e-02, -2.9050e-03, -7.3031e-02, -1.2461e-01, -1.2356e-01,\n         -1.7112e-01,  1.0590e-01,  4.7370e-02, -1.1925e-01,  1.8141e-01],\n        [-1.0521e-01,  1.1920e-01,  5.3053e-03, -1.0616e-01, -9.7270e-02,\n         -2.0417e-01,  6.3812e-02,  1.6902e-01, -1.7210e-01, -6.0906e-02,\n         -2.5891e-03,  1.7808e-02,  1.9280e-01, -2.1542e-01, -6.5587e-02,\n         -2.4250e-02, -1.0922e-01,  2.4261e-02, -7.2803e-02,  6.0753e-02],\n        [-1.9676e-01,  1.7655e-01,  2.2516e-02, -1.8374e-01, -8.5336e-02,\n          1.7650e-01,  1.6972e-01,  5.4212e-02, -3.3765e-02, -7.3609e-02,\n          4.1434e-02,  9.2596e-02, -7.1246e-02,  1.4677e-01, -4.9530e-02,\n          1.0079e-01, -2.0951e-01,  3.2734e-02, -9.0839e-02,  2.1047e-01],\n        [-9.3622e-02,  1.8018e-01, -1.0452e-01, -1.8005e-01, -6.7490e-02,\n          9.9776e-02,  1.7005e-01, -6.3779e-02,  3.4957e-02,  1.8986e-01,\n         -1.6834e-01,  4.6057e-02,  1.2204e-02, -1.7619e-01, -9.7919e-02,\n         -1.7131e-01, -2.0401e-01, -1.6879e-01,  4.0455e-02,  2.0527e-01],\n        [ 1.2325e-01, -1.1294e-01,  1.9460e-01, -2.2292e-01,  1.7751e-02,\n          4.9538e-02, -1.8401e-01,  1.6535e-01, -2.0613e-01,  2.6609e-02,\n          1.9727e-01,  1.2725e-01, -6.8002e-02,  6.2396e-03,  1.6778e-01,\n         -1.8820e-01,  4.4493e-02, -1.0608e-01, -1.4514e-01,  7.0107e-02],\n        [-4.2953e-02,  1.9444e-01,  6.5617e-02, -2.1993e-01,  1.5799e-01,\n          2.5085e-02,  5.5231e-03, -1.5898e-01,  1.2833e-01, -1.8047e-01,\n         -1.8475e-01, -1.1300e-01,  1.0257e-01, -9.8372e-02, -1.9737e-01,\n          5.8686e-02,  8.4736e-02,  2.0251e-01, -2.1657e-02,  9.3578e-02],\n        [ 2.0236e-01, -5.4917e-02, -2.0478e-01,  9.7964e-02, -3.3793e-02,\n         -1.6297e-01,  1.6269e-01, -5.2877e-02, -2.1472e-02,  1.9553e-01,\n         -2.1255e-01, -2.1098e-01, -1.7396e-01, -6.0333e-02,  9.4745e-02,\n         -1.7670e-01,  2.0490e-01,  2.0290e-01, -2.5055e-02, -2.0305e-01],\n        [-1.0665e-01,  6.3872e-03,  3.9126e-02,  1.3383e-01, -1.9399e-01,\n         -1.8744e-01, -9.2556e-02,  3.9765e-02,  1.1860e-02,  1.9292e-01,\n          1.6756e-01,  1.3927e-01,  2.9105e-02,  1.7423e-01,  2.2300e-01,\n         -1.3785e-01, -1.2244e-01, -1.1021e-02,  1.3158e-01, -2.8832e-02],\n        [-1.9772e-02,  1.1447e-01, -6.8798e-02,  1.1777e-01, -9.1629e-02,\n         -2.1211e-01,  1.5560e-01,  3.2799e-02, -1.6501e-01, -9.9935e-02,\n          8.3314e-02,  1.7978e-01, -7.8162e-03, -1.7986e-01, -5.8520e-02,\n          2.2159e-01, -7.3059e-02,  2.1270e-01, -1.7467e-01, -1.9492e-01],\n        [-8.7005e-02, -5.6207e-02, -1.0285e-01, -3.1067e-02,  1.9591e-01,\n         -1.9166e-01, -2.0598e-01,  1.2112e-01, -2.0159e-03,  1.0221e-01,\n         -3.4366e-02,  9.7307e-02, -1.2075e-01,  3.5004e-02, -8.2808e-02,\n          6.1590e-02, -2.1841e-01,  1.9914e-01, -1.5764e-01, -1.6547e-01],\n        [-4.3375e-02,  5.1435e-02, -1.9577e-01, -7.4312e-02,  4.5198e-02,\n         -9.2387e-02, -2.1429e-01,  2.1144e-01,  1.3680e-01,  1.8550e-01,\n          1.0614e-01,  4.8711e-02, -6.9032e-02, -1.5607e-01,  1.8671e-01,\n         -9.7662e-02, -1.5752e-01,  1.6273e-01,  1.7126e-03, -7.0848e-02]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0213, -0.1298,  0.1494,  0.0809, -0.1441, -0.0997,  0.0280,  0.0439,\n        -0.1265, -0.0771, -0.1182, -0.0963,  0.0449, -0.0448, -0.1050,  0.0768,\n        -0.0940,  0.0201,  0.1034,  0.2181, -0.0611, -0.1550, -0.1660,  0.0085,\n         0.1345,  0.0992,  0.2176, -0.2167,  0.2042,  0.1071,  0.1153, -0.0852],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.7321e-01, -3.9835e-02,  8.1581e-02,  1.5475e-01, -6.0005e-02,\n         -8.1167e-02,  1.5396e-01, -6.3757e-02,  8.0530e-02,  3.6333e-02,\n          3.9509e-02, -7.2804e-03, -6.9765e-02, -1.3510e-01,  3.5539e-02,\n         -1.6985e-01, -1.5790e-01,  3.8498e-02,  1.2206e-01,  1.3546e-01,\n         -1.4501e-02,  1.1494e-01, -2.4281e-02,  1.2965e-01,  1.4070e-01,\n          2.0847e-02,  1.5058e-01, -1.3154e-01,  1.6872e-01,  5.9680e-02,\n          1.2084e-01,  5.0207e-02],\n        [-1.4755e-01, -9.1797e-02, -1.2538e-01, -5.7398e-02,  1.6696e-01,\n         -9.4260e-02,  6.1960e-02,  3.9786e-02,  1.2700e-01, -6.1247e-02,\n         -9.9317e-02, -6.0430e-02,  2.3674e-02, -3.9420e-02, -5.3800e-02,\n          1.1349e-01,  8.9481e-02,  9.4060e-02, -2.9509e-02,  3.4087e-02,\n          1.4996e-01,  5.7630e-02, -1.5485e-01,  1.0815e-01,  4.7295e-02,\n         -1.4354e-01,  9.8807e-02,  1.3451e-02,  1.6653e-01,  3.3330e-02,\n         -7.5330e-02,  4.3703e-02],\n        [-1.5060e-02, -1.6782e-01, -4.7851e-03,  1.6883e-01, -1.1602e-01,\n         -1.0992e-01,  1.5784e-01, -1.2820e-01,  1.6113e-01, -1.3864e-01,\n          2.9320e-02, -3.3698e-02, -1.1756e-01, -4.4444e-02,  3.6279e-02,\n          1.4551e-01,  3.8198e-03, -1.7509e-02,  1.2078e-01, -5.6730e-02,\n         -6.9666e-02,  8.8907e-04, -8.9689e-02, -1.2193e-01, -3.1958e-02,\n         -1.0607e-01,  1.6550e-01, -1.2444e-01,  4.0850e-02,  5.3026e-02,\n         -5.2711e-02,  1.5079e-01],\n        [ 1.0207e-01, -5.5996e-02,  3.7218e-02,  1.1018e-01,  1.5766e-01,\n          1.5322e-01,  2.9087e-02,  1.5640e-01,  9.5170e-02, -3.2932e-02,\n         -1.4502e-01,  5.6334e-02, -1.2399e-01,  1.4553e-01, -1.2195e-01,\n         -1.4997e-01, -1.5922e-01,  1.1090e-01, -1.4546e-01,  1.0163e-01,\n          8.9449e-02, -1.3159e-01, -9.5742e-02,  1.1879e-01,  1.3167e-01,\n          1.1269e-01, -8.1987e-02,  1.4512e-01, -1.8487e-02,  9.2175e-02,\n         -9.9536e-02, -1.4541e-01],\n        [ 7.2591e-02,  1.2277e-01, -1.5829e-01,  1.2907e-01, -1.3821e-01,\n          1.6084e-01,  1.1656e-01,  1.4614e-02, -1.3464e-01, -8.0003e-02,\n          1.7003e-01,  1.5798e-01, -3.4576e-02, -5.1833e-02, -1.1924e-02,\n         -8.5944e-02,  7.5890e-02,  9.1715e-03,  2.4874e-02, -1.5035e-01,\n         -1.0560e-01,  1.7231e-01,  5.5749e-02,  1.0622e-01,  7.2472e-02,\n         -7.5635e-02, -1.2871e-01,  1.7270e-01,  1.5536e-01,  1.3445e-01,\n          1.5144e-01,  5.9658e-02],\n        [-1.6513e-01,  9.3027e-02,  7.5765e-03,  3.6136e-02, -8.9953e-03,\n          1.1566e-01,  1.2898e-01,  1.5988e-01,  1.2935e-01,  8.9428e-02,\n          3.2149e-02, -2.2597e-02, -8.9483e-02, -1.1258e-01, -1.5877e-01,\n          2.1956e-02,  1.5470e-01,  1.5909e-01,  9.1992e-02, -1.3751e-01,\n          2.0476e-02, -1.3115e-01, -9.0605e-02,  1.6574e-01, -6.8623e-03,\n         -1.6448e-01, -9.3491e-02, -8.8827e-02,  8.0335e-02, -1.5686e-01,\n          1.7491e-01, -1.1239e-01],\n        [ 5.8894e-02, -1.7172e-01,  1.1935e-01, -1.1984e-01,  1.0146e-01,\n          5.6345e-02, -7.7197e-02, -9.3647e-02,  2.8522e-03, -1.6406e-01,\n          1.6544e-01,  1.3716e-01, -1.4152e-01, -8.9590e-02, -6.3157e-02,\n          1.3302e-01, -1.1318e-01,  1.0375e-01, -8.2579e-02,  6.8917e-02,\n          9.7127e-02,  1.1147e-01,  6.0015e-02,  9.5846e-02, -5.0808e-05,\n          1.1632e-01, -7.3203e-02, -6.8954e-02, -1.1738e-01, -3.1817e-02,\n         -1.6403e-01, -1.1579e-01],\n        [-6.2059e-03, -4.9294e-02, -1.7092e-01,  1.5169e-01,  1.5074e-01,\n         -1.5160e-01,  2.5669e-02, -7.9722e-02,  8.0965e-02, -1.2104e-01,\n         -1.7566e-01, -1.3944e-01, -6.6731e-02,  4.6255e-02, -1.2678e-01,\n          5.5217e-02,  9.8204e-02, -9.7037e-02, -1.7285e-02, -4.2046e-02,\n         -3.6523e-03, -2.9393e-02, -1.0642e-01,  8.2181e-02, -2.6674e-02,\n         -1.1371e-01,  1.1575e-01,  8.7554e-02,  1.3547e-01,  1.5568e-01,\n          5.1978e-02,  7.8500e-02],\n        [ 7.0059e-02, -1.6959e-01, -9.9663e-02, -5.0672e-02,  4.0700e-02,\n          9.3116e-02, -1.0466e-01, -6.2059e-03, -8.2826e-03,  1.5637e-03,\n          1.3588e-01, -3.3191e-02, -1.5429e-01, -9.9950e-02, -1.0443e-01,\n         -1.2391e-01, -7.5183e-02, -1.1890e-01, -8.3704e-02, -1.2567e-01,\n         -4.6007e-02, -1.0028e-02,  9.0625e-02, -4.5462e-02,  1.4795e-03,\n          4.5883e-02,  1.7164e-01,  1.7059e-01,  1.6056e-01,  8.9703e-02,\n          1.5660e-01,  7.3047e-02],\n        [ 1.5525e-01, -1.0583e-01,  1.6403e-03,  1.1509e-02,  1.4428e-01,\n          2.9811e-02, -4.6082e-02,  4.5831e-02, -9.4556e-02, -1.6557e-01,\n          1.6219e-01,  1.2530e-01,  1.4001e-01, -2.5157e-02,  1.1680e-02,\n         -3.2595e-02,  7.7096e-02, -3.7439e-02,  6.6390e-02, -9.3360e-02,\n          6.9507e-02, -7.9997e-02,  5.0871e-04,  1.5954e-01,  1.4010e-01,\n          5.5176e-02, -6.5873e-03,  1.6582e-01,  6.4490e-03,  1.3551e-01,\n         -1.2313e-01, -1.4200e-01],\n        [ 4.5264e-02, -1.7177e-01, -1.6580e-01,  7.5086e-02, -1.2663e-01,\n         -1.0909e-01,  1.5699e-01,  1.5655e-01, -1.5739e-01,  1.5478e-01,\n         -3.0070e-02, -9.0484e-02, -1.3924e-01, -2.5670e-02,  1.4455e-01,\n         -1.4100e-01, -3.6514e-02,  1.4199e-01, -5.2369e-02,  3.9980e-02,\n         -3.7648e-02, -4.7955e-02,  7.1135e-02, -1.5148e-01,  3.0451e-02,\n         -9.2657e-02, -8.8233e-02, -1.7248e-01, -1.3654e-02, -6.3634e-02,\n         -1.2243e-01, -1.5744e-01],\n        [-9.6061e-02, -7.1432e-02, -1.7452e-01, -1.2877e-01, -8.9398e-02,\n         -3.4454e-02,  2.8226e-02, -1.1999e-02, -7.3431e-02,  4.0518e-02,\n         -1.5491e-01,  6.5108e-02,  1.4891e-01,  5.0086e-02,  3.5968e-02,\n          1.5578e-01,  3.1191e-03,  1.4016e-01,  6.3053e-02,  8.6090e-02,\n         -8.0083e-02, -1.0799e-01, -6.5916e-02, -5.1856e-03, -1.4810e-01,\n          2.4669e-02, -5.9490e-02,  7.1066e-02, -1.6571e-01, -5.6605e-02,\n         -9.3397e-02,  8.2393e-02],\n        [ 1.5475e-01,  1.6692e-01,  6.6120e-02,  4.9813e-02,  3.6499e-02,\n          1.4526e-01, -9.2019e-02, -1.4070e-01,  9.0471e-02,  1.0519e-01,\n         -9.3252e-02, -1.2125e-01,  9.9332e-02, -6.6692e-02, -1.6683e-01,\n         -4.1029e-02,  6.0078e-02, -9.8945e-02, -1.3939e-01, -3.6565e-02,\n          1.0279e-02, -1.1462e-01,  9.7975e-03, -1.1025e-01, -2.6867e-02,\n          1.5383e-01, -1.6442e-01, -1.1814e-01, -1.1490e-01, -1.2452e-01,\n         -1.6236e-01, -1.2476e-01],\n        [ 1.0248e-02, -1.4012e-02, -1.1250e-01, -1.3985e-01, -1.6938e-01,\n          5.5115e-02, -1.8151e-02, -3.2281e-02, -1.4760e-01, -5.9961e-03,\n          1.1766e-01,  1.2395e-02,  1.5566e-01,  7.6862e-02, -1.3332e-01,\n          2.8430e-02, -1.4488e-01,  9.4333e-02, -1.6112e-02,  5.4746e-02,\n          3.3148e-02, -6.8040e-02,  1.4259e-01,  1.0099e-01,  1.0066e-01,\n          1.0741e-01,  7.7694e-02,  2.2737e-02,  1.2627e-01,  8.8886e-02,\n         -8.9714e-02,  1.6338e-01],\n        [ 1.5436e-01, -1.3939e-01,  1.0673e-01,  6.1495e-02,  8.8337e-02,\n          1.7476e-01, -1.2104e-01,  1.2421e-01, -9.0863e-02, -1.2674e-01,\n         -2.2855e-02, -4.1134e-02,  1.3281e-01,  6.0461e-02,  8.6097e-02,\n          8.7423e-02,  1.8786e-02, -1.0204e-01, -4.2256e-02,  1.7907e-02,\n          1.4041e-01,  1.5967e-01,  7.8550e-02, -6.4199e-02,  1.5238e-01,\n         -2.8279e-02,  9.2573e-02,  6.6537e-02,  1.6507e-01, -3.6872e-02,\n          1.5538e-02,  1.3269e-01],\n        [ 7.0855e-02,  1.4328e-01,  1.5980e-03, -3.3588e-02,  1.2090e-01,\n         -1.0323e-01, -1.8705e-02, -1.4247e-01, -1.2280e-01,  1.4199e-01,\n         -1.6030e-01, -1.2567e-01, -8.8275e-02, -6.7877e-02, -1.4166e-01,\n          4.2831e-02, -3.4848e-02, -6.3844e-02, -8.2357e-02,  6.8939e-02,\n         -2.6029e-02,  6.1826e-02,  1.1156e-01, -5.6265e-03, -8.6949e-02,\n         -1.1921e-01, -1.1827e-01,  2.2526e-02,  5.7897e-02,  8.8630e-02,\n          1.8933e-02, -1.1444e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0399,  0.0716, -0.0917, -0.0452, -0.0418,  0.1229, -0.1710, -0.1199,\n         0.1756, -0.0872,  0.1371,  0.1767,  0.0033,  0.0843,  0.1763,  0.0910],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0687,  0.0303, -0.0912, -0.2422, -0.1928,  0.0456, -0.1614,  0.1897,\n          0.0852,  0.1279, -0.0012, -0.0281, -0.1208, -0.2361, -0.0513,  0.0801],\n        [-0.1873,  0.0239, -0.0292, -0.1105, -0.1316,  0.1224,  0.2239, -0.1293,\n         -0.1273,  0.1417, -0.1588, -0.1382,  0.2387,  0.0811,  0.1382,  0.0069],\n        [ 0.2267, -0.1136, -0.1400,  0.0573,  0.1739, -0.0343, -0.2083,  0.0434,\n          0.1591,  0.0800, -0.1154, -0.2257, -0.1951, -0.0458,  0.2042, -0.0187],\n        [-0.0032, -0.1013,  0.0071,  0.1466, -0.1294, -0.0497, -0.0824,  0.0772,\n          0.0816, -0.2372,  0.2395,  0.0212,  0.0378, -0.1214, -0.1271, -0.2077],\n        [ 0.1442,  0.1923,  0.0030,  0.1353, -0.1962,  0.1197,  0.1296, -0.0762,\n         -0.1780, -0.1370, -0.2183,  0.2240,  0.1210,  0.2345,  0.2193,  0.1853],\n        [ 0.2112, -0.1844, -0.1753,  0.0809,  0.1330,  0.1327,  0.1303, -0.0208,\n         -0.0769, -0.1095,  0.2199, -0.2181,  0.1322, -0.1515,  0.1521, -0.1931],\n        [-0.1980,  0.1855,  0.2077,  0.2305,  0.0028,  0.0519, -0.0038,  0.0890,\n         -0.2460, -0.0062, -0.0326,  0.2431, -0.0462,  0.0353,  0.2238,  0.1314],\n        [-0.1336, -0.1807,  0.1776,  0.2365, -0.1242,  0.1836, -0.0402,  0.0217,\n         -0.1817,  0.2424,  0.2151,  0.1438, -0.0306, -0.0239, -0.1790,  0.1757]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1320,  0.2499, -0.1257, -0.1534, -0.2427, -0.1438, -0.1874, -0.1013],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0016,  0.0682,  0.2491,  0.0253, -0.0731, -0.3119, -0.1936, -0.0763]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0055], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7af63ade4340>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s252160000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s252160000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	40,
    "train_v_iters":	40,
    "traj_per_epoch":	5,
    "vf_lr":	0.0003
}