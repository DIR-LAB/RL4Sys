{
    "__class__":	"PPO",
    "buf_size":	50000,
    "clip_ratio":	0.1,
    "env_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game",
    "exp_name":	"rl4sys-ppo-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	5,
    "lam":	0.97,
    "log_data_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-info",
        "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-ppo-info\\rl4sys-ppo-info_s260000000"
    },
    "pi_lr":	0.0003,
    "seed":	260000000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x00000267ADA9EC80>":	{
            "_clip_ratio":	0.1,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (pi_network): Sequential(\n      (0): Linear(in_features=4, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n    )\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (pi_network): Sequential(\n    (0): Linear(in_features=4, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1025, -0.1246, -0.0952, -0.2667,  0.2124, -0.0634,  0.4983,  0.2735,\n         0.2108,  0.4594,  0.2696,  0.2969,  0.1500, -0.4251,  0.0351,  0.2284,\n         0.2417,  0.2053,  0.3836,  0.4437,  0.4001, -0.2652,  0.0149,  0.1459,\n        -0.3730,  0.4599, -0.2341,  0.3566, -0.0478,  0.3394,  0.3130,  0.4832],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0732,  0.1805, -0.1178, -0.3609],\n        [-0.0518, -0.4379, -0.1462, -0.3578],\n        [ 0.0287,  0.4820,  0.3131, -0.0949],\n        [ 0.1759,  0.3685, -0.3021, -0.1899],\n        [-0.2641,  0.1862, -0.1275, -0.2323],\n        [ 0.0877,  0.4482,  0.2080,  0.4276],\n        [-0.3162, -0.4032, -0.1858, -0.2597],\n        [-0.1379,  0.1055, -0.2795,  0.0628],\n        [-0.2980,  0.1340, -0.4925,  0.2668],\n        [-0.0078, -0.3513, -0.0863,  0.4016],\n        [-0.3180, -0.2615, -0.1589, -0.4519],\n        [ 0.4357, -0.2354, -0.0487,  0.2272],\n        [-0.1072,  0.3641,  0.1315, -0.2046],\n        [-0.4621,  0.1395, -0.2327,  0.3287],\n        [-0.4346, -0.3911,  0.4646,  0.3704],\n        [-0.3348,  0.2834,  0.1641,  0.4143],\n        [ 0.2791,  0.3265, -0.0968,  0.2275],\n        [-0.4745,  0.4287,  0.4445, -0.4122],\n        [-0.4013, -0.4644,  0.3323, -0.0825],\n        [-0.0749, -0.0620,  0.0567, -0.0459],\n        [ 0.4221, -0.2503, -0.3792, -0.4568],\n        [-0.3990,  0.3894,  0.0287,  0.3764],\n        [-0.2304, -0.3271, -0.2118, -0.3910],\n        [ 0.2030, -0.3689,  0.3551, -0.0796],\n        [ 0.2088,  0.0346,  0.0722,  0.3081],\n        [ 0.1051,  0.4146, -0.1923, -0.4589],\n        [-0.4647, -0.0672, -0.0198,  0.2678],\n        [ 0.3961, -0.1127,  0.3403,  0.3376],\n        [ 0.4425,  0.2560,  0.3537,  0.4614],\n        [ 0.4009, -0.3435, -0.0654, -0.3899],\n        [ 0.4169, -0.0019,  0.0248,  0.0137],\n        [ 0.2363,  0.4028, -0.3968, -0.4131]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0137,  0.0414, -0.1406,  0.1720, -0.1480,  0.1360, -0.0550, -0.1657,\n         0.0448,  0.0886, -0.0694,  0.1399, -0.1285,  0.0767,  0.1012,  0.1294],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1216, -0.0549, -0.1047, -0.0176,  0.1152,  0.1462,  0.1293,  0.1137,\n          0.1359, -0.1429, -0.0800, -0.1310,  0.1560, -0.0879, -0.0449,  0.0237,\n         -0.1580,  0.0466, -0.0343, -0.1282,  0.0653, -0.0668, -0.0440,  0.0553,\n         -0.0884,  0.1542, -0.1389,  0.0339, -0.0410,  0.0505, -0.1374, -0.1629],\n        [ 0.0426,  0.1083,  0.0182,  0.0625,  0.1692,  0.1721, -0.1752,  0.1714,\n          0.0388,  0.0835,  0.1256, -0.0401, -0.0426,  0.1694, -0.1505,  0.1042,\n          0.1364, -0.0073,  0.0988, -0.0725,  0.1407, -0.0646, -0.0165, -0.0788,\n          0.1743, -0.0042,  0.1357, -0.0744, -0.0566, -0.1271, -0.1489, -0.0687],\n        [ 0.1736, -0.1045, -0.1432, -0.1162,  0.1361,  0.0113,  0.1219, -0.0390,\n          0.1004, -0.0438,  0.0773, -0.1606, -0.0387, -0.0062, -0.0088, -0.1505,\n          0.0874, -0.1619,  0.0611,  0.1697,  0.0700,  0.0582,  0.0649,  0.0664,\n         -0.1560, -0.0570, -0.0082,  0.1297,  0.0700,  0.0706, -0.1291, -0.0688],\n        [-0.0261, -0.0364, -0.0069, -0.1464,  0.1332, -0.0756,  0.1122,  0.0890,\n         -0.1631,  0.0710,  0.0303,  0.1297,  0.0583,  0.1604, -0.0969,  0.0924,\n          0.0279,  0.0644,  0.0751, -0.1105, -0.0219, -0.0022,  0.1213, -0.0517,\n          0.0052, -0.1189,  0.0840,  0.0787, -0.0187,  0.0360,  0.1336,  0.0965],\n        [-0.0469,  0.0226, -0.1424, -0.0623,  0.1303,  0.1220,  0.1614,  0.1196,\n         -0.0102, -0.1160, -0.1736,  0.0683, -0.0855,  0.1553, -0.1312,  0.0209,\n         -0.0645, -0.0757, -0.1368, -0.0405,  0.0081,  0.0636,  0.0907, -0.0024,\n          0.0667,  0.1036,  0.0167,  0.0625, -0.0432, -0.1455, -0.1085,  0.0367],\n        [ 0.0389,  0.0037, -0.1630, -0.1518,  0.1141, -0.0279, -0.1730,  0.0145,\n          0.1021,  0.0759, -0.0985, -0.0162, -0.1371,  0.1708, -0.1330, -0.0701,\n         -0.0194,  0.0216, -0.0225, -0.0197,  0.0047,  0.0462,  0.0996,  0.0493,\n         -0.0338,  0.0770, -0.0087,  0.0108,  0.0511, -0.0111, -0.0532, -0.0526],\n        [-0.1611,  0.0417, -0.0426, -0.0830, -0.0486, -0.0871, -0.0190, -0.1045,\n         -0.1641,  0.0167, -0.0368,  0.0680,  0.0066,  0.0444, -0.1596, -0.0740,\n         -0.1483,  0.0233,  0.0355,  0.1672, -0.0322,  0.0916, -0.1061,  0.0432,\n         -0.1023,  0.0095,  0.1168, -0.1683,  0.0356,  0.0899, -0.0285,  0.0398],\n        [ 0.1018, -0.1482,  0.0603,  0.0933, -0.1281,  0.0734, -0.0855,  0.1762,\n         -0.1637,  0.1022,  0.1462, -0.1632,  0.1417, -0.1661, -0.1024,  0.0758,\n          0.0481, -0.0720,  0.1483,  0.0040, -0.1533, -0.0406,  0.0403,  0.1721,\n          0.1413, -0.0956, -0.0692, -0.0664,  0.0391,  0.0464, -0.0219, -0.1602],\n        [ 0.1722, -0.0851, -0.1299, -0.0266, -0.0246, -0.1122,  0.1513,  0.0004,\n         -0.1522,  0.0570,  0.1235,  0.0505,  0.0790,  0.0074, -0.0580,  0.1550,\n         -0.0718, -0.0981,  0.0759, -0.0456,  0.1262,  0.0500, -0.0514,  0.0091,\n          0.1164,  0.1297, -0.1748,  0.0154, -0.1220,  0.1670,  0.1472,  0.0871],\n        [ 0.0682, -0.0982, -0.1175,  0.0699,  0.1705, -0.0077, -0.0401,  0.0517,\n         -0.0615, -0.0551, -0.0295, -0.0582,  0.1316, -0.1722, -0.1024,  0.0831,\n          0.1428, -0.0445, -0.0986,  0.0258, -0.1020,  0.0476,  0.1402,  0.0876,\n         -0.1373,  0.1203, -0.0293, -0.0598, -0.0555,  0.0555, -0.0788,  0.0327],\n        [-0.1048, -0.0594,  0.0722,  0.0178,  0.0239,  0.1106,  0.0386, -0.1626,\n          0.1115, -0.0193,  0.1367, -0.0133, -0.1637,  0.0889,  0.0007, -0.0970,\n          0.0621,  0.0553, -0.1642, -0.0957,  0.0469, -0.0474, -0.0514, -0.0797,\n         -0.1535, -0.1489, -0.0793, -0.1155,  0.0491, -0.0270,  0.1139, -0.0606],\n        [ 0.0452,  0.1157, -0.1146, -0.0273, -0.1284, -0.1662,  0.0977, -0.0211,\n          0.1330,  0.0503,  0.0651,  0.1591,  0.1688, -0.0063,  0.0465, -0.0381,\n         -0.1036, -0.0462, -0.0177,  0.0775, -0.0979, -0.1275, -0.0226, -0.1514,\n         -0.1406, -0.0748, -0.1377, -0.1736, -0.0857, -0.1584, -0.1680, -0.1474],\n        [ 0.0869,  0.0175,  0.1465,  0.0025, -0.0334, -0.1068,  0.0443,  0.0010,\n          0.0109,  0.0452,  0.0341,  0.1314, -0.0869,  0.0489, -0.0206, -0.1258,\n          0.0322,  0.0173,  0.1565, -0.1340, -0.0071, -0.0817,  0.0050,  0.1095,\n          0.0214,  0.1015, -0.1516, -0.0733, -0.1734, -0.0328, -0.0978,  0.0320],\n        [-0.1245,  0.0677, -0.0398,  0.1397, -0.0497,  0.1756, -0.1062,  0.1477,\n         -0.1703, -0.1418,  0.0793,  0.0307, -0.1204,  0.1357, -0.0735,  0.0785,\n          0.0768, -0.1684,  0.0439,  0.1259,  0.0065,  0.0250, -0.0361,  0.0441,\n          0.0509,  0.1360,  0.1335, -0.1670, -0.0334,  0.1144,  0.0610,  0.0406],\n        [ 0.0359, -0.0240, -0.0027, -0.0175,  0.0972,  0.1075, -0.1259,  0.1190,\n          0.0531,  0.0742,  0.0504, -0.0335, -0.0904,  0.1111, -0.1562, -0.0482,\n          0.1591, -0.0133, -0.0795,  0.1246, -0.1299,  0.1147,  0.0963, -0.0125,\n          0.0117,  0.0113, -0.1212, -0.0200, -0.0733, -0.0350, -0.0642, -0.0011],\n        [ 0.0803,  0.1307,  0.0623, -0.0140, -0.0980,  0.0439, -0.1338, -0.0827,\n         -0.1455,  0.0757, -0.0536,  0.1541, -0.0658, -0.0480,  0.1606,  0.0863,\n         -0.0721,  0.1495, -0.0881,  0.0048,  0.1009, -0.0727,  0.1583, -0.0022,\n         -0.1185, -0.0111, -0.0235,  0.0963,  0.1724, -0.0656,  0.0795, -0.0819]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1782, -0.0225,  0.1425, -0.1918, -0.1088,  0.1595,  0.2080, -0.0692],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.2439,  0.0810, -0.1850, -0.1713, -0.1626, -0.0122, -0.1304, -0.2492,\n         -0.1523,  0.0607, -0.1753, -0.0316, -0.1747,  0.1368, -0.0406,  0.0838],\n        [ 0.0358, -0.1821, -0.1363, -0.1276, -0.2293, -0.1663,  0.1334, -0.0996,\n         -0.0399, -0.1666,  0.0659, -0.0986, -0.1989, -0.1802,  0.1869, -0.1851],\n        [ 0.0320,  0.1896,  0.0671,  0.1272,  0.1189,  0.0602,  0.1114,  0.2461,\n          0.0632, -0.0655,  0.1971,  0.1572,  0.1075,  0.1103,  0.1193,  0.1207],\n        [-0.0749,  0.0738,  0.0086, -0.2427,  0.0147,  0.1208, -0.0934, -0.1335,\n          0.0675,  0.0257,  0.1559, -0.0444, -0.2272,  0.0627, -0.1247, -0.1001],\n        [-0.2396, -0.0088,  0.2434,  0.1469,  0.2160, -0.1906,  0.2212,  0.2290,\n          0.1672,  0.0793,  0.2162,  0.2270,  0.0226,  0.2107,  0.1984, -0.0029],\n        [-0.0988,  0.1718,  0.0809, -0.0436, -0.1733, -0.0425, -0.1064,  0.0168,\n         -0.0833,  0.1054, -0.0442, -0.0747,  0.2334, -0.0346, -0.2138, -0.2008],\n        [ 0.0008,  0.0267, -0.1721,  0.1846,  0.2083,  0.0974,  0.2193, -0.1907,\n         -0.1004, -0.1712, -0.1216,  0.1924,  0.0654, -0.0699, -0.2408, -0.1062],\n        [-0.1644,  0.0742, -0.1817,  0.1116, -0.2126, -0.1433, -0.1136,  0.0160,\n         -0.0896, -0.0168,  0.2468, -0.1118, -0.2483,  0.1927, -0.1101, -0.0590]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1879], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0169, -0.1528, -0.2783,  0.3015, -0.3479,  0.0184,  0.1342, -0.1705]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "kernel_dim":	4,
                                "kernel_size":	5,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-2.0962e-01, -2.0355e-01, -1.2858e-01,  2.2883e-02, -2.1842e-01,\n         1.8604e-01,  1.1224e-01,  1.2775e-01,  8.1940e-02,  1.8477e-02,\n        -1.6699e-01,  6.8832e-02, -1.0770e-01,  2.1844e-01,  6.5826e-02,\n         3.4684e-02, -5.1230e-05, -8.4650e-02, -1.0070e-01,  2.1595e-01,\n         2.0057e-01,  1.2741e-02,  1.9130e-01, -1.0392e-01,  1.0574e-01,\n         1.2585e-01,  1.3570e-01,  1.1719e-01,  1.0790e-01,  1.5232e-01,\n         7.0689e-02,  1.7938e-01], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 1.8588e-01, -7.1413e-02,  1.6881e-01, -4.4854e-02,  2.1157e-01,\n          7.8178e-02, -1.8456e-01,  8.4132e-02, -6.9395e-02, -1.0350e-01,\n          1.5051e-01,  3.4927e-02, -4.9848e-02, -2.3767e-02,  3.8930e-03,\n          1.3922e-02, -2.0130e-01, -1.4498e-01,  5.7887e-02,  1.7384e-01],\n        [-1.3464e-01, -1.8433e-01, -2.1444e-01,  1.7835e-01, -5.1678e-02,\n          3.0719e-02,  2.0435e-01,  9.6098e-03, -1.5282e-01, -2.5469e-02,\n         -1.6739e-01,  2.8424e-02, -1.2478e-01,  9.7294e-02, -4.5649e-02,\n         -1.1322e-01,  6.3879e-02,  2.7969e-02,  1.0687e-01, -1.1061e-01],\n        [-1.3380e-01, -1.9596e-01,  1.7929e-01,  1.8465e-01,  1.0272e-01,\n          1.8624e-01, -1.6430e-01,  1.6868e-01,  2.0540e-01, -2.1726e-01,\n          5.9991e-02, -1.5763e-01, -1.4698e-01,  1.5302e-01, -1.4700e-01,\n          2.1344e-01, -7.9962e-02, -1.6930e-01,  1.5465e-01,  7.6255e-02],\n        [-8.6678e-02, -1.0874e-01,  3.7758e-03,  1.7351e-01, -8.3300e-02,\n          6.8674e-02, -6.9185e-02,  6.9313e-02,  2.1493e-01, -1.9695e-01,\n         -1.7649e-01, -1.2858e-01, -4.8870e-02, -1.1119e-01,  2.2296e-01,\n          2.1113e-01, -1.1163e-01, -1.8279e-01, -7.1536e-02, -1.2213e-01],\n        [ 7.1427e-02,  6.9729e-02, -2.0776e-01,  1.8151e-01, -2.2336e-01,\n          1.6395e-01, -1.9659e-01,  9.8847e-02, -3.9149e-03, -1.3191e-01,\n         -3.8504e-02,  1.2260e-01,  2.0307e-01, -1.8239e-02,  3.9353e-02,\n          8.8325e-02,  1.8775e-01, -1.9587e-01,  2.9798e-02,  3.6499e-02],\n        [-5.3833e-02,  1.0804e-02, -9.5338e-02, -4.1260e-02,  4.8670e-02,\n          1.1278e-01,  5.2068e-02,  8.4497e-02, -1.9234e-01, -2.2596e-04,\n         -8.3436e-02, -1.2894e-01, -6.3463e-02,  1.3498e-01,  2.0834e-02,\n         -8.6329e-02, -1.9371e-01,  1.5846e-01, -4.0865e-02,  2.0123e-01],\n        [ 6.7832e-02,  1.3298e-01,  1.6715e-01,  1.2694e-01,  5.5106e-03,\n          1.6368e-01,  7.9184e-02,  1.9645e-01, -8.8113e-02, -5.5041e-02,\n         -4.9220e-02, -9.6049e-02,  1.2464e-01, -1.1003e-01, -1.6767e-02,\n         -1.3708e-01,  1.2370e-01, -2.0075e-01, -1.5644e-01,  1.0705e-01],\n        [-1.5888e-01, -6.2210e-02, -9.5450e-02,  2.0239e-01, -4.4881e-02,\n          6.7900e-02, -1.8938e-01, -9.2367e-02, -2.1251e-02,  3.3867e-02,\n          9.7081e-02, -4.5234e-02, -1.7589e-01,  1.2411e-01, -1.4008e-01,\n          4.5337e-02, -1.0989e-01, -2.1125e-01, -4.4212e-03,  5.5575e-02],\n        [ 1.5641e-01,  1.6487e-01,  1.1829e-01, -1.8769e-02,  9.2290e-02,\n          1.8148e-01, -1.9103e-01, -1.7491e-01, -2.7504e-02, -1.9405e-01,\n         -9.4920e-02, -1.6907e-01,  1.8651e-01,  1.9076e-01,  2.0126e-01,\n          1.1900e-01, -2.0625e-01,  1.3446e-01,  1.2660e-01,  1.5219e-01],\n        [ 1.4912e-01, -1.9485e-01,  1.9663e-01, -6.4923e-02, -1.4578e-01,\n         -1.2739e-01, -2.2354e-01,  1.6650e-01, -5.0168e-02, -5.4307e-02,\n         -5.2334e-02,  8.8894e-03,  6.0483e-03, -1.8507e-01,  4.8500e-02,\n          1.3596e-01,  7.1814e-02, -1.7591e-01,  2.1051e-03, -1.9271e-01],\n        [-2.7844e-02,  1.9906e-01,  6.0660e-02, -1.1680e-03, -1.7613e-02,\n         -1.4639e-01,  9.3639e-02,  2.1098e-01,  8.5875e-02, -1.1569e-01,\n         -3.1204e-02, -1.0254e-01, -1.6222e-01,  1.7313e-01, -1.3620e-01,\n          7.8453e-02, -1.8271e-01, -1.2152e-01, -1.6333e-02,  2.1931e-01],\n        [-9.0137e-02, -8.4616e-02, -1.6698e-01, -1.5183e-01, -3.6439e-02,\n         -4.1305e-02, -2.6241e-02, -5.3221e-02, -2.0246e-01, -1.4644e-01,\n         -2.0510e-01, -2.3137e-04,  1.7893e-01, -4.7458e-02,  1.2603e-01,\n         -1.8056e-01, -2.1928e-01, -1.5223e-01, -9.7834e-03,  1.1310e-01],\n        [ 7.8736e-02,  1.6775e-01, -8.2835e-02, -1.8033e-01,  5.5143e-02,\n         -1.1299e-01, -1.2643e-01, -3.6745e-03, -1.7823e-01, -1.6157e-01,\n          1.2271e-01,  5.3537e-02, -1.1501e-01,  5.8073e-02, -1.5390e-01,\n          1.3559e-01,  1.5797e-01,  7.5984e-03, -1.9913e-01,  3.7902e-02],\n        [-3.8712e-02,  8.5283e-03,  1.5600e-01,  6.1275e-03,  1.4243e-02,\n         -5.2170e-02, -6.3074e-02,  8.7294e-03,  1.1609e-01, -1.6779e-02,\n          1.6016e-01, -4.8799e-02,  5.8873e-02,  1.6075e-01,  1.8010e-01,\n         -1.5478e-01,  2.5895e-02, -1.2023e-01,  1.1815e-01,  1.4972e-01],\n        [ 8.7000e-02, -3.4286e-02, -6.0029e-02, -2.2316e-01, -1.0507e-01,\n          1.2530e-01,  1.0450e-01,  7.0039e-02, -1.9535e-02,  1.7479e-01,\n         -1.9775e-01, -1.7815e-01,  3.7579e-03,  4.6259e-02, -1.5753e-01,\n         -4.7816e-02, -7.7638e-02,  8.4884e-02,  5.4711e-02, -1.1979e-01],\n        [-1.4006e-01,  2.0216e-01, -1.1853e-01,  1.4272e-01,  2.1009e-01,\n         -4.5686e-02, -8.8275e-02, -1.5247e-01, -5.1277e-02,  3.8278e-02,\n         -3.6147e-02,  8.2720e-03,  3.3442e-03, -1.9473e-01, -1.2027e-01,\n          7.6002e-02, -1.3234e-01, -2.1239e-01, -8.5632e-02,  1.9448e-01],\n        [ 1.4730e-01, -1.4702e-03,  9.7668e-02,  5.6976e-02,  1.9973e-01,\n          1.8190e-01,  1.7984e-01,  7.8235e-02,  1.3865e-01, -1.3058e-01,\n          1.8169e-02,  8.9681e-02,  1.2467e-01, -1.1634e-01, -4.7010e-02,\n         -1.9056e-02, -9.4203e-02,  1.9002e-01,  1.6039e-01,  5.6720e-02],\n        [-8.8009e-03,  1.5033e-01, -1.6482e-01, -1.2438e-01,  8.3894e-02,\n          2.9562e-02,  3.3696e-02,  1.1120e-01,  1.5895e-01,  2.3123e-02,\n         -2.1869e-02,  5.8708e-02,  7.8719e-02,  1.3943e-01, -1.3621e-01,\n         -1.4669e-01,  5.5695e-02, -1.1456e-01,  1.7331e-02,  1.1512e-01],\n        [-1.2054e-01,  2.0103e-01,  1.4879e-01,  7.5818e-03, -7.9233e-03,\n          3.4895e-02,  1.5577e-01,  4.3305e-02,  7.7401e-02,  2.3494e-02,\n         -6.2738e-03,  1.5322e-01, -2.0179e-01, -1.4853e-01,  6.0374e-02,\n         -1.6457e-01, -8.9256e-02, -5.3981e-02,  1.3611e-01,  9.2638e-02],\n        [-2.0025e-01, -1.4866e-01, -1.5086e-01, -1.3209e-01, -2.1631e-01,\n         -1.2581e-01, -1.9141e-01, -1.9596e-01,  1.2608e-02,  9.1438e-02,\n          2.1367e-03, -1.9390e-01, -2.1437e-01,  1.1155e-01, -4.9255e-02,\n          1.1165e-01,  3.2279e-02, -1.7461e-02, -5.0900e-02,  2.0210e-01],\n        [-1.1075e-01, -8.8563e-02,  2.1040e-01, -2.2075e-01,  1.7469e-01,\n          1.1920e-01,  2.1212e-01, -3.2429e-02, -6.0442e-03, -2.1119e-01,\n          4.9636e-02,  1.5896e-01,  8.7333e-02,  1.6893e-01, -8.1630e-02,\n          3.5229e-02,  2.1338e-01,  1.1091e-01,  1.2213e-01,  1.3546e-01],\n        [ 6.7103e-02, -1.4791e-01, -1.8587e-01,  1.2055e-01,  5.3181e-04,\n         -1.1907e-01,  1.7946e-01, -8.9093e-02,  2.2891e-02, -1.6605e-02,\n         -8.7819e-02,  1.6212e-01,  1.4887e-01,  1.2992e-01, -6.6629e-02,\n         -8.9068e-02, -1.5614e-01, -4.3388e-02, -6.3539e-02, -1.2261e-01],\n        [-4.3627e-02, -2.1620e-01,  1.4620e-01,  7.0314e-02, -2.0014e-01,\n          1.0973e-02, -1.6635e-01,  9.5412e-02,  4.9108e-02, -9.5701e-02,\n          8.9204e-02,  8.9153e-02, -3.2390e-02, -7.9895e-02,  1.1436e-01,\n          7.2707e-02,  1.5725e-02, -8.0690e-04,  1.0427e-01, -4.0621e-02],\n        [-1.3309e-01,  1.4304e-01,  1.5772e-01,  1.4821e-01, -9.2204e-02,\n          2.1459e-01, -6.3026e-02,  1.8311e-01,  7.7862e-02,  4.5320e-02,\n          1.2778e-01, -6.1251e-02,  2.1961e-01, -2.7061e-02,  1.4124e-01,\n          1.7156e-01, -3.3818e-04,  1.6128e-02, -2.4343e-02, -1.3471e-01],\n        [-1.5281e-01,  1.7438e-01, -1.8734e-01, -4.9030e-02,  1.1139e-01,\n          1.2615e-01, -1.2781e-01, -1.2337e-01, -2.0295e-01,  1.7028e-01,\n         -7.9624e-03,  2.2191e-01,  8.3132e-02,  2.0465e-01,  5.4918e-02,\n          1.7633e-01,  3.7275e-02, -9.5128e-03, -2.1647e-01, -3.3538e-02],\n        [-5.7433e-02, -8.6316e-03,  8.5087e-02,  2.1445e-01,  2.1666e-01,\n          1.6805e-02,  1.8647e-01, -1.4470e-01, -7.9388e-02, -2.1461e-01,\n         -8.5266e-02, -3.9228e-02,  1.6822e-01, -7.2057e-02, -6.3654e-02,\n         -5.9321e-02,  7.1833e-02,  7.8532e-02, -6.1292e-02, -2.1187e-01],\n        [ 1.2537e-01, -2.7659e-02,  1.1671e-01,  8.5954e-02,  1.2851e-01,\n          1.6669e-01,  1.1058e-01, -2.1164e-01, -5.4374e-05,  1.0111e-02,\n         -9.5932e-02,  1.5720e-02,  1.4766e-01,  9.4132e-02,  1.0589e-01,\n         -8.8388e-02, -1.3111e-01,  1.9791e-01,  2.1288e-01,  1.5799e-01],\n        [ 1.3707e-01, -4.8221e-02, -4.7296e-02,  2.1231e-01, -6.1706e-02,\n          1.2793e-01, -1.5629e-01,  5.7353e-02, -2.0283e-01, -1.4713e-01,\n         -5.9841e-02, -1.0644e-01, -1.7724e-01, -1.6656e-01,  9.2087e-02,\n          1.6297e-01,  1.3651e-01, -1.4802e-03, -1.7746e-01, -1.9081e-03],\n        [ 1.0809e-01,  2.0756e-01,  2.2128e-01, -2.1553e-01, -4.7573e-02,\n         -1.3524e-01, -1.8955e-01,  2.1035e-01, -4.8929e-02, -1.5483e-01,\n         -6.2003e-03, -1.0880e-01, -1.7589e-01, -1.0836e-01, -1.6791e-02,\n          1.4705e-01,  1.0866e-01,  1.6981e-01,  1.9640e-02,  2.1019e-01],\n        [ 1.5634e-01, -1.0930e-01, -7.5596e-02, -7.0320e-02,  8.7445e-02,\n         -5.4479e-02, -9.6104e-02, -7.1265e-02,  1.7306e-02, -5.8466e-02,\n          4.9387e-02,  3.0988e-02,  2.2151e-01,  1.0155e-02, -4.4582e-02,\n         -8.8677e-02, -6.6255e-02, -1.4820e-01, -8.4695e-02, -1.5275e-01],\n        [ 1.3092e-01,  1.0447e-01, -3.9589e-03, -1.7938e-01,  1.0530e-01,\n         -2.5947e-03,  2.2003e-02, -1.8827e-01, -3.4528e-02,  5.3226e-02,\n          1.8495e-01,  1.1187e-01,  7.6386e-02, -3.3055e-02, -2.2741e-02,\n         -3.2540e-02, -1.4835e-01,  6.3587e-02, -1.6795e-01, -7.8856e-02],\n        [ 1.3538e-01,  1.2567e-01,  5.3254e-04, -1.8651e-01,  2.7821e-03,\n          4.5402e-02, -4.7592e-02, -4.9500e-02,  1.4199e-01,  1.7827e-01,\n         -1.8708e-01, -4.1091e-02, -1.2648e-01,  1.6742e-01, -2.2047e-02,\n          1.4823e-02, -1.2896e-01,  1.1124e-01,  6.3061e-02, -1.4025e-01]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1586, -0.0335, -0.1220, -0.0322, -0.0735,  0.0013,  0.0074,  0.1269,\n        -0.1089, -0.0501, -0.0601, -0.1564, -0.0077,  0.0765,  0.0067,  0.1175],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 8.3757e-02, -1.7254e-01, -6.0324e-02, -9.0945e-02,  1.3589e-01,\n         -8.3933e-02,  9.5435e-02,  3.3815e-03, -3.4786e-02, -1.7393e-01,\n          1.0255e-01, -1.2781e-01,  6.2331e-02,  6.1509e-02, -1.2458e-01,\n         -9.6499e-03, -9.4833e-02, -5.7634e-02, -2.0248e-02,  4.0771e-02,\n          1.4011e-01,  1.4533e-01, -9.5102e-02,  1.3986e-01,  8.3740e-02,\n          1.6875e-01,  6.3545e-03, -1.4330e-01, -1.3448e-01,  4.8176e-03,\n          1.6451e-01,  1.4188e-02],\n        [-1.6421e-01, -7.2638e-03, -5.0887e-02,  1.1740e-01,  4.5759e-02,\n         -2.9181e-04, -3.0166e-02,  6.7257e-02, -5.3581e-02,  1.6714e-01,\n         -1.6154e-01, -1.4198e-01,  1.3781e-01, -9.5325e-02,  4.5043e-02,\n         -1.0623e-01,  4.9661e-02,  2.7702e-02,  1.5469e-01, -7.8882e-02,\n         -1.5522e-01,  1.6169e-01,  1.7043e-01,  1.7246e-01, -1.6134e-02,\n         -3.0307e-02, -7.2787e-02,  3.8482e-02, -9.4631e-02, -3.4080e-02,\n          1.5595e-01,  1.5522e-01],\n        [ 1.4342e-01, -6.2813e-02, -1.4565e-01,  2.5958e-02,  1.3042e-01,\n          6.7906e-02, -1.5401e-01, -3.9377e-02,  3.8009e-02, -1.3292e-01,\n          6.5569e-03,  6.3711e-02, -3.8494e-02, -1.3720e-01,  1.4866e-01,\n         -1.3102e-01, -1.4715e-01,  1.2665e-02, -5.4099e-02,  2.2462e-02,\n          1.3709e-01, -9.5225e-02,  7.1495e-02, -1.5070e-01, -9.8508e-02,\n          8.9523e-02, -5.1093e-02,  1.7073e-01, -2.2135e-02,  1.0042e-01,\n         -8.7820e-02, -8.6122e-02],\n        [-8.1550e-02,  1.5604e-01, -7.3473e-02, -1.8698e-02, -4.0722e-02,\n         -7.6547e-02, -5.4468e-02,  1.1690e-01,  1.1607e-01,  1.3009e-01,\n          6.1540e-02,  6.4216e-02,  7.9245e-02, -1.1516e-01, -5.8362e-02,\n          8.9408e-02, -9.3774e-03,  6.2719e-02,  6.0636e-02,  4.2364e-02,\n          5.6308e-03, -1.7246e-01,  7.7407e-02,  9.4052e-02,  1.3958e-01,\n         -1.2854e-01,  4.0701e-02,  8.6348e-02, -1.1008e-01,  1.5746e-01,\n         -3.2182e-02,  1.0105e-01],\n        [ 1.0348e-01, -1.4796e-01,  9.9843e-02, -7.3468e-02, -4.1366e-02,\n         -8.6228e-02,  1.2120e-01,  1.0211e-02, -1.4526e-01,  8.7429e-02,\n         -1.7443e-01,  4.3209e-02,  7.4502e-02, -4.7863e-02, -1.2308e-01,\n          2.6126e-02, -1.4609e-01, -7.1078e-03, -1.5165e-01,  4.4914e-02,\n         -1.2458e-01,  6.8693e-02, -1.6892e-01, -2.6000e-03,  1.0914e-01,\n          1.4031e-01,  1.7550e-01, -7.1728e-03, -4.8313e-02,  4.4166e-02,\n          8.7652e-02, -9.5574e-02],\n        [-1.7021e-02,  1.5291e-01, -6.5634e-02, -9.6785e-02, -9.5403e-02,\n         -6.7738e-02, -1.2424e-01,  1.7519e-01, -1.8799e-02, -7.6787e-02,\n         -6.3654e-02,  8.1775e-02,  6.8141e-02, -1.1883e-01, -4.2077e-02,\n         -1.1862e-01, -1.6484e-01, -3.0807e-02, -6.4035e-02,  1.3050e-01,\n          4.4740e-02,  6.2863e-02,  3.6921e-02,  1.7515e-01, -9.5524e-02,\n          3.4685e-02,  5.5402e-03,  1.1526e-01,  1.0954e-01,  1.3570e-01,\n         -1.2606e-01, -6.0887e-02],\n        [ 9.6553e-02, -3.7414e-02, -3.5568e-02, -1.6028e-01, -3.7829e-02,\n          1.5184e-01,  4.7365e-02, -7.7759e-02,  1.0020e-01, -5.4533e-02,\n         -1.2026e-01,  4.8080e-02,  4.1885e-02, -1.0722e-01, -1.6055e-01,\n          3.3256e-02, -8.0702e-02, -3.7252e-02, -3.9728e-02,  1.4680e-01,\n          1.2443e-01, -1.7645e-01, -1.4573e-01, -9.7758e-02, -1.6882e-04,\n          5.5719e-02,  8.9656e-02, -7.5366e-02, -6.1694e-02, -1.0450e-01,\n          4.4246e-02,  1.7019e-01],\n        [-1.2210e-01, -4.0513e-02, -1.5831e-01,  1.1467e-02, -6.7236e-02,\n          9.8709e-02,  4.8945e-02, -1.0836e-01, -2.4442e-02, -1.3609e-01,\n         -3.2697e-03, -1.0083e-01,  1.1260e-01, -1.6547e-01, -8.4417e-02,\n         -4.7080e-02,  1.2231e-01, -6.2531e-02,  1.1639e-01, -4.6326e-02,\n          1.2754e-01,  2.3510e-02, -1.4332e-01,  1.4308e-01, -1.2048e-01,\n         -7.9945e-02, -7.4512e-02,  1.6646e-01, -6.2343e-02,  1.5646e-01,\n         -1.4400e-01,  3.9562e-02],\n        [-1.2711e-01, -1.0389e-01,  2.5393e-02,  1.5703e-01,  1.5062e-01,\n          2.4318e-02, -1.4058e-01, -3.3186e-02, -1.3033e-01,  1.2677e-01,\n          1.4391e-01,  1.2081e-02,  7.0194e-02,  8.5394e-02, -1.6579e-01,\n          5.9953e-02,  2.3988e-02, -2.8569e-02,  1.3413e-02, -9.5324e-02,\n          3.9198e-02, -1.0124e-01, -1.0877e-01, -1.3354e-01, -5.9359e-02,\n          1.7126e-01,  1.4237e-01, -1.5575e-01, -5.3576e-02,  2.5732e-02,\n         -1.3659e-01, -5.3288e-02],\n        [ 7.3868e-02, -6.5916e-02, -7.0542e-02,  1.3585e-01, -3.9529e-02,\n          2.7177e-02,  8.9173e-02, -1.5719e-01,  4.9091e-02, -1.4394e-01,\n          1.0455e-01, -1.1473e-01,  7.3229e-02,  1.6714e-01, -1.2943e-01,\n         -1.8405e-02, -1.2226e-02, -1.0636e-01,  1.7229e-01,  6.8393e-02,\n         -1.1316e-01,  4.9444e-02,  1.1048e-01, -8.3651e-02,  2.1383e-02,\n          1.0145e-01, -1.6794e-01,  1.5921e-01, -1.7136e-02,  7.4406e-02,\n         -1.5229e-01,  1.9505e-02],\n        [-3.1326e-03,  2.8691e-02,  5.5569e-02,  1.0174e-01, -5.4369e-02,\n         -1.4190e-01,  5.3147e-02,  1.0192e-01,  9.7879e-02,  1.3874e-01,\n         -1.5723e-01,  6.1150e-02,  1.6967e-03, -1.5721e-01,  6.6987e-02,\n          9.7668e-02,  1.7110e-01,  3.4945e-02, -8.8127e-02, -8.7078e-02,\n          8.9473e-03,  8.7246e-03, -1.2523e-01,  1.3559e-01,  1.5825e-01,\n          2.2184e-02,  1.4710e-01, -1.6698e-01,  1.0065e-01, -9.1245e-02,\n         -8.2445e-03, -9.8464e-02],\n        [-1.1442e-01,  1.2878e-02, -4.4398e-02, -1.0407e-01, -1.2891e-01,\n         -1.6420e-01, -1.7000e-01, -1.0772e-01,  1.0741e-01,  3.3042e-02,\n          3.3754e-03, -1.7135e-01,  6.4592e-02, -1.5846e-01,  9.1090e-02,\n         -1.5009e-01,  1.0293e-02, -2.6208e-02,  1.7421e-01, -6.7396e-02,\n         -2.2694e-02,  1.2387e-01, -6.8010e-02,  1.2920e-02, -1.3402e-01,\n          8.0388e-02,  1.3678e-01, -1.3411e-01,  9.5207e-02, -1.0533e-01,\n          6.8139e-04, -4.2464e-02],\n        [ 1.1919e-02,  1.3927e-01,  1.1376e-01,  7.2269e-02, -8.2772e-02,\n          2.7283e-02, -6.9165e-02,  4.5170e-02,  1.2871e-01,  6.4034e-02,\n          1.6902e-01,  1.9911e-02,  3.5765e-02,  9.0063e-02, -1.1193e-01,\n         -2.3481e-02,  1.4103e-01,  1.0392e-01,  7.0320e-02,  1.1335e-01,\n         -1.6452e-01,  1.3686e-01, -5.8302e-02, -4.3064e-02, -6.2297e-02,\n         -1.5063e-01, -4.2981e-02, -8.1362e-02, -1.6391e-01, -1.0189e-01,\n          1.1641e-01, -8.9994e-02],\n        [ 1.5593e-01,  2.3330e-02, -2.8193e-03, -3.4506e-02, -1.5922e-01,\n         -3.5309e-02, -1.6883e-01,  1.6628e-01,  8.8196e-02,  1.6719e-01,\n         -7.6936e-02,  3.5540e-02, -7.4582e-03,  1.4051e-01, -1.5164e-01,\n         -1.2813e-01, -4.3858e-03,  8.4956e-02,  1.0023e-01,  1.1886e-03,\n         -3.5910e-02, -2.7551e-02,  6.2589e-02, -1.4651e-01,  1.2786e-01,\n          5.6739e-02,  1.3246e-01,  1.7034e-01,  5.0802e-03, -1.1580e-01,\n         -1.4285e-01, -1.3444e-01],\n        [ 7.5604e-02,  7.6789e-02, -1.5316e-02, -1.6581e-02, -1.5739e-01,\n          2.9579e-02,  1.1951e-01,  1.6699e-01,  4.0035e-02, -1.2474e-01,\n          1.0572e-01,  3.3024e-04,  1.6982e-01, -8.7050e-02,  1.8462e-02,\n          9.1502e-02,  9.8229e-03,  1.5807e-01,  7.5814e-03,  5.6773e-02,\n         -1.5249e-01, -1.0060e-01, -2.1541e-02,  9.0501e-02, -1.4290e-03,\n         -1.0856e-02,  9.3295e-02, -2.4663e-02,  1.2683e-01, -2.6409e-02,\n         -1.5640e-01, -1.0769e-01],\n        [ 1.5726e-01,  5.9493e-02,  5.2513e-02, -1.3222e-01,  1.7568e-01,\n          5.0259e-03, -2.6062e-02, -7.4907e-02, -2.4950e-03,  6.0908e-02,\n          9.6067e-03, -8.8035e-02,  7.0137e-02, -3.4962e-02, -1.6194e-01,\n          1.0103e-02,  1.3628e-01,  7.0747e-02,  1.6987e-01, -1.6334e-01,\n          5.8989e-02, -4.8963e-02, -1.6696e-01, -5.3382e-02,  4.7802e-02,\n         -6.0838e-02,  5.5452e-02,  7.7049e-02, -1.1325e-01,  1.7212e-02,\n          2.0771e-02,  4.8659e-02]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2163,  0.1108, -0.1023, -0.1619, -0.0055,  0.1177, -0.0474, -0.0590],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1633,  0.0704,  0.1902,  0.2419, -0.1175,  0.1601,  0.1908,  0.0937,\n         -0.1944,  0.2183, -0.0094, -0.0077, -0.1318, -0.2251,  0.2090, -0.0322],\n        [-0.0229, -0.0940,  0.0731,  0.0813, -0.2270, -0.0915, -0.2262,  0.1844,\n         -0.0661, -0.0244,  0.0894,  0.2188,  0.0799,  0.1827,  0.0556,  0.0903],\n        [ 0.0368, -0.0116, -0.2380,  0.0815,  0.0320, -0.0532,  0.1156, -0.1400,\n         -0.1983, -0.1508, -0.0724, -0.0809,  0.1014,  0.1418, -0.1708, -0.0814],\n        [ 0.0420, -0.1174,  0.1099, -0.1513,  0.0193,  0.0017,  0.0519, -0.0127,\n         -0.0574, -0.0235,  0.1988,  0.1720,  0.0330,  0.1775,  0.1590, -0.1249],\n        [-0.1040, -0.0942,  0.0050,  0.1558, -0.0676, -0.0939,  0.0635,  0.1866,\n          0.0612,  0.2224,  0.1595, -0.1026,  0.0585, -0.1167,  0.0570,  0.1630],\n        [-0.1768,  0.1771, -0.2088, -0.0552,  0.2158, -0.1917, -0.1136,  0.0702,\n          0.1865, -0.1641,  0.0828,  0.1918,  0.0997,  0.1320, -0.0118, -0.1393],\n        [ 0.0224,  0.1444, -0.0410,  0.1048,  0.0737,  0.1534,  0.1728, -0.2205,\n          0.2014, -0.0907, -0.2349,  0.2057, -0.1703, -0.2185,  0.1697,  0.0278],\n        [-0.0885,  0.1245,  0.1694, -0.1154,  0.1909,  0.2330, -0.0540,  0.0573,\n          0.0268,  0.2057, -0.1461,  0.1353, -0.2327,  0.1731,  0.0063,  0.0937]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0821], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1024, -0.2275,  0.0124,  0.0077, -0.1555, -0.0161, -0.0652,  0.2460]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    20,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	20,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "flatten_obs_dim":	20,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.0732,  0.1805, -0.1178, -0.3609],\n        [-0.0518, -0.4379, -0.1462, -0.3578],\n        [ 0.0287,  0.4820,  0.3131, -0.0949],\n        [ 0.1759,  0.3685, -0.3021, -0.1899],\n        [-0.2641,  0.1862, -0.1275, -0.2323],\n        [ 0.0877,  0.4482,  0.2080,  0.4276],\n        [-0.3162, -0.4032, -0.1858, -0.2597],\n        [-0.1379,  0.1055, -0.2795,  0.0628],\n        [-0.2980,  0.1340, -0.4925,  0.2668],\n        [-0.0078, -0.3513, -0.0863,  0.4016],\n        [-0.3180, -0.2615, -0.1589, -0.4519],\n        [ 0.4357, -0.2354, -0.0487,  0.2272],\n        [-0.1072,  0.3641,  0.1315, -0.2046],\n        [-0.4621,  0.1395, -0.2327,  0.3287],\n        [-0.4346, -0.3911,  0.4646,  0.3704],\n        [-0.3348,  0.2834,  0.1641,  0.4143],\n        [ 0.2791,  0.3265, -0.0968,  0.2275],\n        [-0.4745,  0.4287,  0.4445, -0.4122],\n        [-0.4013, -0.4644,  0.3323, -0.0825],\n        [-0.0749, -0.0620,  0.0567, -0.0459],\n        [ 0.4221, -0.2503, -0.3792, -0.4568],\n        [-0.3990,  0.3894,  0.0287,  0.3764],\n        [-0.2304, -0.3271, -0.2118, -0.3910],\n        [ 0.2030, -0.3689,  0.3551, -0.0796],\n        [ 0.2088,  0.0346,  0.0722,  0.3081],\n        [ 0.1051,  0.4146, -0.1923, -0.4589],\n        [-0.4647, -0.0672, -0.0198,  0.2678],\n        [ 0.3961, -0.1127,  0.3403,  0.3376],\n        [ 0.4425,  0.2560,  0.3537,  0.4614],\n        [ 0.4009, -0.3435, -0.0654, -0.3899],\n        [ 0.4169, -0.0019,  0.0248,  0.0137],\n        [ 0.2363,  0.4028, -0.3968, -0.4131]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1025, -0.1246, -0.0952, -0.2667,  0.2124, -0.0634,  0.4983,  0.2735,\n         0.2108,  0.4594,  0.2696,  0.2969,  0.1500, -0.4251,  0.0351,  0.2284,\n         0.2417,  0.2053,  0.3836,  0.4437,  0.4001, -0.2652,  0.0149,  0.1459,\n        -0.3730,  0.4599, -0.2341,  0.3566, -0.0478,  0.3394,  0.3130,  0.4832],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1216, -0.0549, -0.1047, -0.0176,  0.1152,  0.1462,  0.1293,  0.1137,\n          0.1359, -0.1429, -0.0800, -0.1310,  0.1560, -0.0879, -0.0449,  0.0237,\n         -0.1580,  0.0466, -0.0343, -0.1282,  0.0653, -0.0668, -0.0440,  0.0553,\n         -0.0884,  0.1542, -0.1389,  0.0339, -0.0410,  0.0505, -0.1374, -0.1629],\n        [ 0.0426,  0.1083,  0.0182,  0.0625,  0.1692,  0.1721, -0.1752,  0.1714,\n          0.0388,  0.0835,  0.1256, -0.0401, -0.0426,  0.1694, -0.1505,  0.1042,\n          0.1364, -0.0073,  0.0988, -0.0725,  0.1407, -0.0646, -0.0165, -0.0788,\n          0.1743, -0.0042,  0.1357, -0.0744, -0.0566, -0.1271, -0.1489, -0.0687],\n        [ 0.1736, -0.1045, -0.1432, -0.1162,  0.1361,  0.0113,  0.1219, -0.0390,\n          0.1004, -0.0438,  0.0773, -0.1606, -0.0387, -0.0062, -0.0088, -0.1505,\n          0.0874, -0.1619,  0.0611,  0.1697,  0.0700,  0.0582,  0.0649,  0.0664,\n         -0.1560, -0.0570, -0.0082,  0.1297,  0.0700,  0.0706, -0.1291, -0.0688],\n        [-0.0261, -0.0364, -0.0069, -0.1464,  0.1332, -0.0756,  0.1122,  0.0890,\n         -0.1631,  0.0710,  0.0303,  0.1297,  0.0583,  0.1604, -0.0969,  0.0924,\n          0.0279,  0.0644,  0.0751, -0.1105, -0.0219, -0.0022,  0.1213, -0.0517,\n          0.0052, -0.1189,  0.0840,  0.0787, -0.0187,  0.0360,  0.1336,  0.0965],\n        [-0.0469,  0.0226, -0.1424, -0.0623,  0.1303,  0.1220,  0.1614,  0.1196,\n         -0.0102, -0.1160, -0.1736,  0.0683, -0.0855,  0.1553, -0.1312,  0.0209,\n         -0.0645, -0.0757, -0.1368, -0.0405,  0.0081,  0.0636,  0.0907, -0.0024,\n          0.0667,  0.1036,  0.0167,  0.0625, -0.0432, -0.1455, -0.1085,  0.0367],\n        [ 0.0389,  0.0037, -0.1630, -0.1518,  0.1141, -0.0279, -0.1730,  0.0145,\n          0.1021,  0.0759, -0.0985, -0.0162, -0.1371,  0.1708, -0.1330, -0.0701,\n         -0.0194,  0.0216, -0.0225, -0.0197,  0.0047,  0.0462,  0.0996,  0.0493,\n         -0.0338,  0.0770, -0.0087,  0.0108,  0.0511, -0.0111, -0.0532, -0.0526],\n        [-0.1611,  0.0417, -0.0426, -0.0830, -0.0486, -0.0871, -0.0190, -0.1045,\n         -0.1641,  0.0167, -0.0368,  0.0680,  0.0066,  0.0444, -0.1596, -0.0740,\n         -0.1483,  0.0233,  0.0355,  0.1672, -0.0322,  0.0916, -0.1061,  0.0432,\n         -0.1023,  0.0095,  0.1168, -0.1683,  0.0356,  0.0899, -0.0285,  0.0398],\n        [ 0.1018, -0.1482,  0.0603,  0.0933, -0.1281,  0.0734, -0.0855,  0.1762,\n         -0.1637,  0.1022,  0.1462, -0.1632,  0.1417, -0.1661, -0.1024,  0.0758,\n          0.0481, -0.0720,  0.1483,  0.0040, -0.1533, -0.0406,  0.0403,  0.1721,\n          0.1413, -0.0956, -0.0692, -0.0664,  0.0391,  0.0464, -0.0219, -0.1602],\n        [ 0.1722, -0.0851, -0.1299, -0.0266, -0.0246, -0.1122,  0.1513,  0.0004,\n         -0.1522,  0.0570,  0.1235,  0.0505,  0.0790,  0.0074, -0.0580,  0.1550,\n         -0.0718, -0.0981,  0.0759, -0.0456,  0.1262,  0.0500, -0.0514,  0.0091,\n          0.1164,  0.1297, -0.1748,  0.0154, -0.1220,  0.1670,  0.1472,  0.0871],\n        [ 0.0682, -0.0982, -0.1175,  0.0699,  0.1705, -0.0077, -0.0401,  0.0517,\n         -0.0615, -0.0551, -0.0295, -0.0582,  0.1316, -0.1722, -0.1024,  0.0831,\n          0.1428, -0.0445, -0.0986,  0.0258, -0.1020,  0.0476,  0.1402,  0.0876,\n         -0.1373,  0.1203, -0.0293, -0.0598, -0.0555,  0.0555, -0.0788,  0.0327],\n        [-0.1048, -0.0594,  0.0722,  0.0178,  0.0239,  0.1106,  0.0386, -0.1626,\n          0.1115, -0.0193,  0.1367, -0.0133, -0.1637,  0.0889,  0.0007, -0.0970,\n          0.0621,  0.0553, -0.1642, -0.0957,  0.0469, -0.0474, -0.0514, -0.0797,\n         -0.1535, -0.1489, -0.0793, -0.1155,  0.0491, -0.0270,  0.1139, -0.0606],\n        [ 0.0452,  0.1157, -0.1146, -0.0273, -0.1284, -0.1662,  0.0977, -0.0211,\n          0.1330,  0.0503,  0.0651,  0.1591,  0.1688, -0.0063,  0.0465, -0.0381,\n         -0.1036, -0.0462, -0.0177,  0.0775, -0.0979, -0.1275, -0.0226, -0.1514,\n         -0.1406, -0.0748, -0.1377, -0.1736, -0.0857, -0.1584, -0.1680, -0.1474],\n        [ 0.0869,  0.0175,  0.1465,  0.0025, -0.0334, -0.1068,  0.0443,  0.0010,\n          0.0109,  0.0452,  0.0341,  0.1314, -0.0869,  0.0489, -0.0206, -0.1258,\n          0.0322,  0.0173,  0.1565, -0.1340, -0.0071, -0.0817,  0.0050,  0.1095,\n          0.0214,  0.1015, -0.1516, -0.0733, -0.1734, -0.0328, -0.0978,  0.0320],\n        [-0.1245,  0.0677, -0.0398,  0.1397, -0.0497,  0.1756, -0.1062,  0.1477,\n         -0.1703, -0.1418,  0.0793,  0.0307, -0.1204,  0.1357, -0.0735,  0.0785,\n          0.0768, -0.1684,  0.0439,  0.1259,  0.0065,  0.0250, -0.0361,  0.0441,\n          0.0509,  0.1360,  0.1335, -0.1670, -0.0334,  0.1144,  0.0610,  0.0406],\n        [ 0.0359, -0.0240, -0.0027, -0.0175,  0.0972,  0.1075, -0.1259,  0.1190,\n          0.0531,  0.0742,  0.0504, -0.0335, -0.0904,  0.1111, -0.1562, -0.0482,\n          0.1591, -0.0133, -0.0795,  0.1246, -0.1299,  0.1147,  0.0963, -0.0125,\n          0.0117,  0.0113, -0.1212, -0.0200, -0.0733, -0.0350, -0.0642, -0.0011],\n        [ 0.0803,  0.1307,  0.0623, -0.0140, -0.0980,  0.0439, -0.1338, -0.0827,\n         -0.1455,  0.0757, -0.0536,  0.1541, -0.0658, -0.0480,  0.1606,  0.0863,\n         -0.0721,  0.1495, -0.0881,  0.0048,  0.1009, -0.0727,  0.1583, -0.0022,\n         -0.1185, -0.0111, -0.0235,  0.0963,  0.1724, -0.0656,  0.0795, -0.0819]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0137,  0.0414, -0.1406,  0.1720, -0.1480,  0.1360, -0.0550, -0.1657,\n         0.0448,  0.0886, -0.0694,  0.1399, -0.1285,  0.0767,  0.1012,  0.1294],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2439,  0.0810, -0.1850, -0.1713, -0.1626, -0.0122, -0.1304, -0.2492,\n         -0.1523,  0.0607, -0.1753, -0.0316, -0.1747,  0.1368, -0.0406,  0.0838],\n        [ 0.0358, -0.1821, -0.1363, -0.1276, -0.2293, -0.1663,  0.1334, -0.0996,\n         -0.0399, -0.1666,  0.0659, -0.0986, -0.1989, -0.1802,  0.1869, -0.1851],\n        [ 0.0320,  0.1896,  0.0671,  0.1272,  0.1189,  0.0602,  0.1114,  0.2461,\n          0.0632, -0.0655,  0.1971,  0.1572,  0.1075,  0.1103,  0.1193,  0.1207],\n        [-0.0749,  0.0738,  0.0086, -0.2427,  0.0147,  0.1208, -0.0934, -0.1335,\n          0.0675,  0.0257,  0.1559, -0.0444, -0.2272,  0.0627, -0.1247, -0.1001],\n        [-0.2396, -0.0088,  0.2434,  0.1469,  0.2160, -0.1906,  0.2212,  0.2290,\n          0.1672,  0.0793,  0.2162,  0.2270,  0.0226,  0.2107,  0.1984, -0.0029],\n        [-0.0988,  0.1718,  0.0809, -0.0436, -0.1733, -0.0425, -0.1064,  0.0168,\n         -0.0833,  0.1054, -0.0442, -0.0747,  0.2334, -0.0346, -0.2138, -0.2008],\n        [ 0.0008,  0.0267, -0.1721,  0.1846,  0.2083,  0.0974,  0.2193, -0.1907,\n         -0.1004, -0.1712, -0.1216,  0.1924,  0.0654, -0.0699, -0.2408, -0.1062],\n        [-0.1644,  0.0742, -0.1817,  0.1116, -0.2126, -0.1433, -0.1136,  0.0160,\n         -0.0896, -0.0168,  0.2468, -0.1118, -0.2483,  0.1927, -0.1101, -0.0590]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1782, -0.0225,  0.1425, -0.1918, -0.1088,  0.1595,  0.2080, -0.0692],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0169, -0.1528, -0.2783,  0.3015, -0.3479,  0.0184,  0.1342, -0.1705]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1879], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x00000267ADA9EBF0>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	50000,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	40,
            "_train_v_iters":	40,
            "_traj_per_epoch":	5,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 1.8588e-01, -7.1413e-02,  1.6881e-01, -4.4854e-02,  2.1157e-01,\n          7.8178e-02, -1.8456e-01,  8.4132e-02, -6.9395e-02, -1.0350e-01,\n          1.5051e-01,  3.4927e-02, -4.9848e-02, -2.3767e-02,  3.8930e-03,\n          1.3922e-02, -2.0130e-01, -1.4498e-01,  5.7887e-02,  1.7384e-01],\n        [-1.3464e-01, -1.8433e-01, -2.1444e-01,  1.7835e-01, -5.1678e-02,\n          3.0719e-02,  2.0435e-01,  9.6098e-03, -1.5282e-01, -2.5469e-02,\n         -1.6739e-01,  2.8424e-02, -1.2478e-01,  9.7294e-02, -4.5649e-02,\n         -1.1322e-01,  6.3879e-02,  2.7969e-02,  1.0687e-01, -1.1061e-01],\n        [-1.3380e-01, -1.9596e-01,  1.7929e-01,  1.8465e-01,  1.0272e-01,\n          1.8624e-01, -1.6430e-01,  1.6868e-01,  2.0540e-01, -2.1726e-01,\n          5.9991e-02, -1.5763e-01, -1.4698e-01,  1.5302e-01, -1.4700e-01,\n          2.1344e-01, -7.9962e-02, -1.6930e-01,  1.5465e-01,  7.6255e-02],\n        [-8.6678e-02, -1.0874e-01,  3.7758e-03,  1.7351e-01, -8.3300e-02,\n          6.8674e-02, -6.9185e-02,  6.9313e-02,  2.1493e-01, -1.9695e-01,\n         -1.7649e-01, -1.2858e-01, -4.8870e-02, -1.1119e-01,  2.2296e-01,\n          2.1113e-01, -1.1163e-01, -1.8279e-01, -7.1536e-02, -1.2213e-01],\n        [ 7.1427e-02,  6.9729e-02, -2.0776e-01,  1.8151e-01, -2.2336e-01,\n          1.6395e-01, -1.9659e-01,  9.8847e-02, -3.9149e-03, -1.3191e-01,\n         -3.8504e-02,  1.2260e-01,  2.0307e-01, -1.8239e-02,  3.9353e-02,\n          8.8325e-02,  1.8775e-01, -1.9587e-01,  2.9798e-02,  3.6499e-02],\n        [-5.3833e-02,  1.0804e-02, -9.5338e-02, -4.1260e-02,  4.8670e-02,\n          1.1278e-01,  5.2068e-02,  8.4497e-02, -1.9234e-01, -2.2596e-04,\n         -8.3436e-02, -1.2894e-01, -6.3463e-02,  1.3498e-01,  2.0834e-02,\n         -8.6329e-02, -1.9371e-01,  1.5846e-01, -4.0865e-02,  2.0123e-01],\n        [ 6.7832e-02,  1.3298e-01,  1.6715e-01,  1.2694e-01,  5.5106e-03,\n          1.6368e-01,  7.9184e-02,  1.9645e-01, -8.8113e-02, -5.5041e-02,\n         -4.9220e-02, -9.6049e-02,  1.2464e-01, -1.1003e-01, -1.6767e-02,\n         -1.3708e-01,  1.2370e-01, -2.0075e-01, -1.5644e-01,  1.0705e-01],\n        [-1.5888e-01, -6.2210e-02, -9.5450e-02,  2.0239e-01, -4.4881e-02,\n          6.7900e-02, -1.8938e-01, -9.2367e-02, -2.1251e-02,  3.3867e-02,\n          9.7081e-02, -4.5234e-02, -1.7589e-01,  1.2411e-01, -1.4008e-01,\n          4.5337e-02, -1.0989e-01, -2.1125e-01, -4.4212e-03,  5.5575e-02],\n        [ 1.5641e-01,  1.6487e-01,  1.1829e-01, -1.8769e-02,  9.2290e-02,\n          1.8148e-01, -1.9103e-01, -1.7491e-01, -2.7504e-02, -1.9405e-01,\n         -9.4920e-02, -1.6907e-01,  1.8651e-01,  1.9076e-01,  2.0126e-01,\n          1.1900e-01, -2.0625e-01,  1.3446e-01,  1.2660e-01,  1.5219e-01],\n        [ 1.4912e-01, -1.9485e-01,  1.9663e-01, -6.4923e-02, -1.4578e-01,\n         -1.2739e-01, -2.2354e-01,  1.6650e-01, -5.0168e-02, -5.4307e-02,\n         -5.2334e-02,  8.8894e-03,  6.0483e-03, -1.8507e-01,  4.8500e-02,\n          1.3596e-01,  7.1814e-02, -1.7591e-01,  2.1051e-03, -1.9271e-01],\n        [-2.7844e-02,  1.9906e-01,  6.0660e-02, -1.1680e-03, -1.7613e-02,\n         -1.4639e-01,  9.3639e-02,  2.1098e-01,  8.5875e-02, -1.1569e-01,\n         -3.1204e-02, -1.0254e-01, -1.6222e-01,  1.7313e-01, -1.3620e-01,\n          7.8453e-02, -1.8271e-01, -1.2152e-01, -1.6333e-02,  2.1931e-01],\n        [-9.0137e-02, -8.4616e-02, -1.6698e-01, -1.5183e-01, -3.6439e-02,\n         -4.1305e-02, -2.6241e-02, -5.3221e-02, -2.0246e-01, -1.4644e-01,\n         -2.0510e-01, -2.3137e-04,  1.7893e-01, -4.7458e-02,  1.2603e-01,\n         -1.8056e-01, -2.1928e-01, -1.5223e-01, -9.7834e-03,  1.1310e-01],\n        [ 7.8736e-02,  1.6775e-01, -8.2835e-02, -1.8033e-01,  5.5143e-02,\n         -1.1299e-01, -1.2643e-01, -3.6745e-03, -1.7823e-01, -1.6157e-01,\n          1.2271e-01,  5.3537e-02, -1.1501e-01,  5.8073e-02, -1.5390e-01,\n          1.3559e-01,  1.5797e-01,  7.5984e-03, -1.9913e-01,  3.7902e-02],\n        [-3.8712e-02,  8.5283e-03,  1.5600e-01,  6.1275e-03,  1.4243e-02,\n         -5.2170e-02, -6.3074e-02,  8.7294e-03,  1.1609e-01, -1.6779e-02,\n          1.6016e-01, -4.8799e-02,  5.8873e-02,  1.6075e-01,  1.8010e-01,\n         -1.5478e-01,  2.5895e-02, -1.2023e-01,  1.1815e-01,  1.4972e-01],\n        [ 8.7000e-02, -3.4286e-02, -6.0029e-02, -2.2316e-01, -1.0507e-01,\n          1.2530e-01,  1.0450e-01,  7.0039e-02, -1.9535e-02,  1.7479e-01,\n         -1.9775e-01, -1.7815e-01,  3.7579e-03,  4.6259e-02, -1.5753e-01,\n         -4.7816e-02, -7.7638e-02,  8.4884e-02,  5.4711e-02, -1.1979e-01],\n        [-1.4006e-01,  2.0216e-01, -1.1853e-01,  1.4272e-01,  2.1009e-01,\n         -4.5686e-02, -8.8275e-02, -1.5247e-01, -5.1277e-02,  3.8278e-02,\n         -3.6147e-02,  8.2720e-03,  3.3442e-03, -1.9473e-01, -1.2027e-01,\n          7.6002e-02, -1.3234e-01, -2.1239e-01, -8.5632e-02,  1.9448e-01],\n        [ 1.4730e-01, -1.4702e-03,  9.7668e-02,  5.6976e-02,  1.9973e-01,\n          1.8190e-01,  1.7984e-01,  7.8235e-02,  1.3865e-01, -1.3058e-01,\n          1.8169e-02,  8.9681e-02,  1.2467e-01, -1.1634e-01, -4.7010e-02,\n         -1.9056e-02, -9.4203e-02,  1.9002e-01,  1.6039e-01,  5.6720e-02],\n        [-8.8009e-03,  1.5033e-01, -1.6482e-01, -1.2438e-01,  8.3894e-02,\n          2.9562e-02,  3.3696e-02,  1.1120e-01,  1.5895e-01,  2.3123e-02,\n         -2.1869e-02,  5.8708e-02,  7.8719e-02,  1.3943e-01, -1.3621e-01,\n         -1.4669e-01,  5.5695e-02, -1.1456e-01,  1.7331e-02,  1.1512e-01],\n        [-1.2054e-01,  2.0103e-01,  1.4879e-01,  7.5818e-03, -7.9233e-03,\n          3.4895e-02,  1.5577e-01,  4.3305e-02,  7.7401e-02,  2.3494e-02,\n         -6.2738e-03,  1.5322e-01, -2.0179e-01, -1.4853e-01,  6.0374e-02,\n         -1.6457e-01, -8.9256e-02, -5.3981e-02,  1.3611e-01,  9.2638e-02],\n        [-2.0025e-01, -1.4866e-01, -1.5086e-01, -1.3209e-01, -2.1631e-01,\n         -1.2581e-01, -1.9141e-01, -1.9596e-01,  1.2608e-02,  9.1438e-02,\n          2.1367e-03, -1.9390e-01, -2.1437e-01,  1.1155e-01, -4.9255e-02,\n          1.1165e-01,  3.2279e-02, -1.7461e-02, -5.0900e-02,  2.0210e-01],\n        [-1.1075e-01, -8.8563e-02,  2.1040e-01, -2.2075e-01,  1.7469e-01,\n          1.1920e-01,  2.1212e-01, -3.2429e-02, -6.0442e-03, -2.1119e-01,\n          4.9636e-02,  1.5896e-01,  8.7333e-02,  1.6893e-01, -8.1630e-02,\n          3.5229e-02,  2.1338e-01,  1.1091e-01,  1.2213e-01,  1.3546e-01],\n        [ 6.7103e-02, -1.4791e-01, -1.8587e-01,  1.2055e-01,  5.3181e-04,\n         -1.1907e-01,  1.7946e-01, -8.9093e-02,  2.2891e-02, -1.6605e-02,\n         -8.7819e-02,  1.6212e-01,  1.4887e-01,  1.2992e-01, -6.6629e-02,\n         -8.9068e-02, -1.5614e-01, -4.3388e-02, -6.3539e-02, -1.2261e-01],\n        [-4.3627e-02, -2.1620e-01,  1.4620e-01,  7.0314e-02, -2.0014e-01,\n          1.0973e-02, -1.6635e-01,  9.5412e-02,  4.9108e-02, -9.5701e-02,\n          8.9204e-02,  8.9153e-02, -3.2390e-02, -7.9895e-02,  1.1436e-01,\n          7.2707e-02,  1.5725e-02, -8.0690e-04,  1.0427e-01, -4.0621e-02],\n        [-1.3309e-01,  1.4304e-01,  1.5772e-01,  1.4821e-01, -9.2204e-02,\n          2.1459e-01, -6.3026e-02,  1.8311e-01,  7.7862e-02,  4.5320e-02,\n          1.2778e-01, -6.1251e-02,  2.1961e-01, -2.7061e-02,  1.4124e-01,\n          1.7156e-01, -3.3818e-04,  1.6128e-02, -2.4343e-02, -1.3471e-01],\n        [-1.5281e-01,  1.7438e-01, -1.8734e-01, -4.9030e-02,  1.1139e-01,\n          1.2615e-01, -1.2781e-01, -1.2337e-01, -2.0295e-01,  1.7028e-01,\n         -7.9624e-03,  2.2191e-01,  8.3132e-02,  2.0465e-01,  5.4918e-02,\n          1.7633e-01,  3.7275e-02, -9.5128e-03, -2.1647e-01, -3.3538e-02],\n        [-5.7433e-02, -8.6316e-03,  8.5087e-02,  2.1445e-01,  2.1666e-01,\n          1.6805e-02,  1.8647e-01, -1.4470e-01, -7.9388e-02, -2.1461e-01,\n         -8.5266e-02, -3.9228e-02,  1.6822e-01, -7.2057e-02, -6.3654e-02,\n         -5.9321e-02,  7.1833e-02,  7.8532e-02, -6.1292e-02, -2.1187e-01],\n        [ 1.2537e-01, -2.7659e-02,  1.1671e-01,  8.5954e-02,  1.2851e-01,\n          1.6669e-01,  1.1058e-01, -2.1164e-01, -5.4374e-05,  1.0111e-02,\n         -9.5932e-02,  1.5720e-02,  1.4766e-01,  9.4132e-02,  1.0589e-01,\n         -8.8388e-02, -1.3111e-01,  1.9791e-01,  2.1288e-01,  1.5799e-01],\n        [ 1.3707e-01, -4.8221e-02, -4.7296e-02,  2.1231e-01, -6.1706e-02,\n          1.2793e-01, -1.5629e-01,  5.7353e-02, -2.0283e-01, -1.4713e-01,\n         -5.9841e-02, -1.0644e-01, -1.7724e-01, -1.6656e-01,  9.2087e-02,\n          1.6297e-01,  1.3651e-01, -1.4802e-03, -1.7746e-01, -1.9081e-03],\n        [ 1.0809e-01,  2.0756e-01,  2.2128e-01, -2.1553e-01, -4.7573e-02,\n         -1.3524e-01, -1.8955e-01,  2.1035e-01, -4.8929e-02, -1.5483e-01,\n         -6.2003e-03, -1.0880e-01, -1.7589e-01, -1.0836e-01, -1.6791e-02,\n          1.4705e-01,  1.0866e-01,  1.6981e-01,  1.9640e-02,  2.1019e-01],\n        [ 1.5634e-01, -1.0930e-01, -7.5596e-02, -7.0320e-02,  8.7445e-02,\n         -5.4479e-02, -9.6104e-02, -7.1265e-02,  1.7306e-02, -5.8466e-02,\n          4.9387e-02,  3.0988e-02,  2.2151e-01,  1.0155e-02, -4.4582e-02,\n         -8.8677e-02, -6.6255e-02, -1.4820e-01, -8.4695e-02, -1.5275e-01],\n        [ 1.3092e-01,  1.0447e-01, -3.9589e-03, -1.7938e-01,  1.0530e-01,\n         -2.5947e-03,  2.2003e-02, -1.8827e-01, -3.4528e-02,  5.3226e-02,\n          1.8495e-01,  1.1187e-01,  7.6386e-02, -3.3055e-02, -2.2741e-02,\n         -3.2540e-02, -1.4835e-01,  6.3587e-02, -1.6795e-01, -7.8856e-02],\n        [ 1.3538e-01,  1.2567e-01,  5.3254e-04, -1.8651e-01,  2.7821e-03,\n          4.5402e-02, -4.7592e-02, -4.9500e-02,  1.4199e-01,  1.7827e-01,\n         -1.8708e-01, -4.1091e-02, -1.2648e-01,  1.6742e-01, -2.2047e-02,\n          1.4823e-02, -1.2896e-01,  1.1124e-01,  6.3061e-02, -1.4025e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-2.0962e-01, -2.0355e-01, -1.2858e-01,  2.2883e-02, -2.1842e-01,\n         1.8604e-01,  1.1224e-01,  1.2775e-01,  8.1940e-02,  1.8477e-02,\n        -1.6699e-01,  6.8832e-02, -1.0770e-01,  2.1844e-01,  6.5826e-02,\n         3.4684e-02, -5.1230e-05, -8.4650e-02, -1.0070e-01,  2.1595e-01,\n         2.0057e-01,  1.2741e-02,  1.9130e-01, -1.0392e-01,  1.0574e-01,\n         1.2585e-01,  1.3570e-01,  1.1719e-01,  1.0790e-01,  1.5232e-01,\n         7.0689e-02,  1.7938e-01], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 8.3757e-02, -1.7254e-01, -6.0324e-02, -9.0945e-02,  1.3589e-01,\n         -8.3933e-02,  9.5435e-02,  3.3815e-03, -3.4786e-02, -1.7393e-01,\n          1.0255e-01, -1.2781e-01,  6.2331e-02,  6.1509e-02, -1.2458e-01,\n         -9.6499e-03, -9.4833e-02, -5.7634e-02, -2.0248e-02,  4.0771e-02,\n          1.4011e-01,  1.4533e-01, -9.5102e-02,  1.3986e-01,  8.3740e-02,\n          1.6875e-01,  6.3545e-03, -1.4330e-01, -1.3448e-01,  4.8176e-03,\n          1.6451e-01,  1.4188e-02],\n        [-1.6421e-01, -7.2638e-03, -5.0887e-02,  1.1740e-01,  4.5759e-02,\n         -2.9181e-04, -3.0166e-02,  6.7257e-02, -5.3581e-02,  1.6714e-01,\n         -1.6154e-01, -1.4198e-01,  1.3781e-01, -9.5325e-02,  4.5043e-02,\n         -1.0623e-01,  4.9661e-02,  2.7702e-02,  1.5469e-01, -7.8882e-02,\n         -1.5522e-01,  1.6169e-01,  1.7043e-01,  1.7246e-01, -1.6134e-02,\n         -3.0307e-02, -7.2787e-02,  3.8482e-02, -9.4631e-02, -3.4080e-02,\n          1.5595e-01,  1.5522e-01],\n        [ 1.4342e-01, -6.2813e-02, -1.4565e-01,  2.5958e-02,  1.3042e-01,\n          6.7906e-02, -1.5401e-01, -3.9377e-02,  3.8009e-02, -1.3292e-01,\n          6.5569e-03,  6.3711e-02, -3.8494e-02, -1.3720e-01,  1.4866e-01,\n         -1.3102e-01, -1.4715e-01,  1.2665e-02, -5.4099e-02,  2.2462e-02,\n          1.3709e-01, -9.5225e-02,  7.1495e-02, -1.5070e-01, -9.8508e-02,\n          8.9523e-02, -5.1093e-02,  1.7073e-01, -2.2135e-02,  1.0042e-01,\n         -8.7820e-02, -8.6122e-02],\n        [-8.1550e-02,  1.5604e-01, -7.3473e-02, -1.8698e-02, -4.0722e-02,\n         -7.6547e-02, -5.4468e-02,  1.1690e-01,  1.1607e-01,  1.3009e-01,\n          6.1540e-02,  6.4216e-02,  7.9245e-02, -1.1516e-01, -5.8362e-02,\n          8.9408e-02, -9.3774e-03,  6.2719e-02,  6.0636e-02,  4.2364e-02,\n          5.6308e-03, -1.7246e-01,  7.7407e-02,  9.4052e-02,  1.3958e-01,\n         -1.2854e-01,  4.0701e-02,  8.6348e-02, -1.1008e-01,  1.5746e-01,\n         -3.2182e-02,  1.0105e-01],\n        [ 1.0348e-01, -1.4796e-01,  9.9843e-02, -7.3468e-02, -4.1366e-02,\n         -8.6228e-02,  1.2120e-01,  1.0211e-02, -1.4526e-01,  8.7429e-02,\n         -1.7443e-01,  4.3209e-02,  7.4502e-02, -4.7863e-02, -1.2308e-01,\n          2.6126e-02, -1.4609e-01, -7.1078e-03, -1.5165e-01,  4.4914e-02,\n         -1.2458e-01,  6.8693e-02, -1.6892e-01, -2.6000e-03,  1.0914e-01,\n          1.4031e-01,  1.7550e-01, -7.1728e-03, -4.8313e-02,  4.4166e-02,\n          8.7652e-02, -9.5574e-02],\n        [-1.7021e-02,  1.5291e-01, -6.5634e-02, -9.6785e-02, -9.5403e-02,\n         -6.7738e-02, -1.2424e-01,  1.7519e-01, -1.8799e-02, -7.6787e-02,\n         -6.3654e-02,  8.1775e-02,  6.8141e-02, -1.1883e-01, -4.2077e-02,\n         -1.1862e-01, -1.6484e-01, -3.0807e-02, -6.4035e-02,  1.3050e-01,\n          4.4740e-02,  6.2863e-02,  3.6921e-02,  1.7515e-01, -9.5524e-02,\n          3.4685e-02,  5.5402e-03,  1.1526e-01,  1.0954e-01,  1.3570e-01,\n         -1.2606e-01, -6.0887e-02],\n        [ 9.6553e-02, -3.7414e-02, -3.5568e-02, -1.6028e-01, -3.7829e-02,\n          1.5184e-01,  4.7365e-02, -7.7759e-02,  1.0020e-01, -5.4533e-02,\n         -1.2026e-01,  4.8080e-02,  4.1885e-02, -1.0722e-01, -1.6055e-01,\n          3.3256e-02, -8.0702e-02, -3.7252e-02, -3.9728e-02,  1.4680e-01,\n          1.2443e-01, -1.7645e-01, -1.4573e-01, -9.7758e-02, -1.6882e-04,\n          5.5719e-02,  8.9656e-02, -7.5366e-02, -6.1694e-02, -1.0450e-01,\n          4.4246e-02,  1.7019e-01],\n        [-1.2210e-01, -4.0513e-02, -1.5831e-01,  1.1467e-02, -6.7236e-02,\n          9.8709e-02,  4.8945e-02, -1.0836e-01, -2.4442e-02, -1.3609e-01,\n         -3.2697e-03, -1.0083e-01,  1.1260e-01, -1.6547e-01, -8.4417e-02,\n         -4.7080e-02,  1.2231e-01, -6.2531e-02,  1.1639e-01, -4.6326e-02,\n          1.2754e-01,  2.3510e-02, -1.4332e-01,  1.4308e-01, -1.2048e-01,\n         -7.9945e-02, -7.4512e-02,  1.6646e-01, -6.2343e-02,  1.5646e-01,\n         -1.4400e-01,  3.9562e-02],\n        [-1.2711e-01, -1.0389e-01,  2.5393e-02,  1.5703e-01,  1.5062e-01,\n          2.4318e-02, -1.4058e-01, -3.3186e-02, -1.3033e-01,  1.2677e-01,\n          1.4391e-01,  1.2081e-02,  7.0194e-02,  8.5394e-02, -1.6579e-01,\n          5.9953e-02,  2.3988e-02, -2.8569e-02,  1.3413e-02, -9.5324e-02,\n          3.9198e-02, -1.0124e-01, -1.0877e-01, -1.3354e-01, -5.9359e-02,\n          1.7126e-01,  1.4237e-01, -1.5575e-01, -5.3576e-02,  2.5732e-02,\n         -1.3659e-01, -5.3288e-02],\n        [ 7.3868e-02, -6.5916e-02, -7.0542e-02,  1.3585e-01, -3.9529e-02,\n          2.7177e-02,  8.9173e-02, -1.5719e-01,  4.9091e-02, -1.4394e-01,\n          1.0455e-01, -1.1473e-01,  7.3229e-02,  1.6714e-01, -1.2943e-01,\n         -1.8405e-02, -1.2226e-02, -1.0636e-01,  1.7229e-01,  6.8393e-02,\n         -1.1316e-01,  4.9444e-02,  1.1048e-01, -8.3651e-02,  2.1383e-02,\n          1.0145e-01, -1.6794e-01,  1.5921e-01, -1.7136e-02,  7.4406e-02,\n         -1.5229e-01,  1.9505e-02],\n        [-3.1326e-03,  2.8691e-02,  5.5569e-02,  1.0174e-01, -5.4369e-02,\n         -1.4190e-01,  5.3147e-02,  1.0192e-01,  9.7879e-02,  1.3874e-01,\n         -1.5723e-01,  6.1150e-02,  1.6967e-03, -1.5721e-01,  6.6987e-02,\n          9.7668e-02,  1.7110e-01,  3.4945e-02, -8.8127e-02, -8.7078e-02,\n          8.9473e-03,  8.7246e-03, -1.2523e-01,  1.3559e-01,  1.5825e-01,\n          2.2184e-02,  1.4710e-01, -1.6698e-01,  1.0065e-01, -9.1245e-02,\n         -8.2445e-03, -9.8464e-02],\n        [-1.1442e-01,  1.2878e-02, -4.4398e-02, -1.0407e-01, -1.2891e-01,\n         -1.6420e-01, -1.7000e-01, -1.0772e-01,  1.0741e-01,  3.3042e-02,\n          3.3754e-03, -1.7135e-01,  6.4592e-02, -1.5846e-01,  9.1090e-02,\n         -1.5009e-01,  1.0293e-02, -2.6208e-02,  1.7421e-01, -6.7396e-02,\n         -2.2694e-02,  1.2387e-01, -6.8010e-02,  1.2920e-02, -1.3402e-01,\n          8.0388e-02,  1.3678e-01, -1.3411e-01,  9.5207e-02, -1.0533e-01,\n          6.8139e-04, -4.2464e-02],\n        [ 1.1919e-02,  1.3927e-01,  1.1376e-01,  7.2269e-02, -8.2772e-02,\n          2.7283e-02, -6.9165e-02,  4.5170e-02,  1.2871e-01,  6.4034e-02,\n          1.6902e-01,  1.9911e-02,  3.5765e-02,  9.0063e-02, -1.1193e-01,\n         -2.3481e-02,  1.4103e-01,  1.0392e-01,  7.0320e-02,  1.1335e-01,\n         -1.6452e-01,  1.3686e-01, -5.8302e-02, -4.3064e-02, -6.2297e-02,\n         -1.5063e-01, -4.2981e-02, -8.1362e-02, -1.6391e-01, -1.0189e-01,\n          1.1641e-01, -8.9994e-02],\n        [ 1.5593e-01,  2.3330e-02, -2.8193e-03, -3.4506e-02, -1.5922e-01,\n         -3.5309e-02, -1.6883e-01,  1.6628e-01,  8.8196e-02,  1.6719e-01,\n         -7.6936e-02,  3.5540e-02, -7.4582e-03,  1.4051e-01, -1.5164e-01,\n         -1.2813e-01, -4.3858e-03,  8.4956e-02,  1.0023e-01,  1.1886e-03,\n         -3.5910e-02, -2.7551e-02,  6.2589e-02, -1.4651e-01,  1.2786e-01,\n          5.6739e-02,  1.3246e-01,  1.7034e-01,  5.0802e-03, -1.1580e-01,\n         -1.4285e-01, -1.3444e-01],\n        [ 7.5604e-02,  7.6789e-02, -1.5316e-02, -1.6581e-02, -1.5739e-01,\n          2.9579e-02,  1.1951e-01,  1.6699e-01,  4.0035e-02, -1.2474e-01,\n          1.0572e-01,  3.3024e-04,  1.6982e-01, -8.7050e-02,  1.8462e-02,\n          9.1502e-02,  9.8229e-03,  1.5807e-01,  7.5814e-03,  5.6773e-02,\n         -1.5249e-01, -1.0060e-01, -2.1541e-02,  9.0501e-02, -1.4290e-03,\n         -1.0856e-02,  9.3295e-02, -2.4663e-02,  1.2683e-01, -2.6409e-02,\n         -1.5640e-01, -1.0769e-01],\n        [ 1.5726e-01,  5.9493e-02,  5.2513e-02, -1.3222e-01,  1.7568e-01,\n          5.0259e-03, -2.6062e-02, -7.4907e-02, -2.4950e-03,  6.0908e-02,\n          9.6067e-03, -8.8035e-02,  7.0137e-02, -3.4962e-02, -1.6194e-01,\n          1.0103e-02,  1.3628e-01,  7.0747e-02,  1.6987e-01, -1.6334e-01,\n          5.8989e-02, -4.8963e-02, -1.6696e-01, -5.3382e-02,  4.7802e-02,\n         -6.0838e-02,  5.5452e-02,  7.7049e-02, -1.1325e-01,  1.7212e-02,\n          2.0771e-02,  4.8659e-02]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1586, -0.0335, -0.1220, -0.0322, -0.0735,  0.0013,  0.0074,  0.1269,\n        -0.1089, -0.0501, -0.0601, -0.1564, -0.0077,  0.0765,  0.0067,  0.1175],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1633,  0.0704,  0.1902,  0.2419, -0.1175,  0.1601,  0.1908,  0.0937,\n         -0.1944,  0.2183, -0.0094, -0.0077, -0.1318, -0.2251,  0.2090, -0.0322],\n        [-0.0229, -0.0940,  0.0731,  0.0813, -0.2270, -0.0915, -0.2262,  0.1844,\n         -0.0661, -0.0244,  0.0894,  0.2188,  0.0799,  0.1827,  0.0556,  0.0903],\n        [ 0.0368, -0.0116, -0.2380,  0.0815,  0.0320, -0.0532,  0.1156, -0.1400,\n         -0.1983, -0.1508, -0.0724, -0.0809,  0.1014,  0.1418, -0.1708, -0.0814],\n        [ 0.0420, -0.1174,  0.1099, -0.1513,  0.0193,  0.0017,  0.0519, -0.0127,\n         -0.0574, -0.0235,  0.1988,  0.1720,  0.0330,  0.1775,  0.1590, -0.1249],\n        [-0.1040, -0.0942,  0.0050,  0.1558, -0.0676, -0.0939,  0.0635,  0.1866,\n          0.0612,  0.2224,  0.1595, -0.1026,  0.0585, -0.1167,  0.0570,  0.1630],\n        [-0.1768,  0.1771, -0.2088, -0.0552,  0.2158, -0.1917, -0.1136,  0.0702,\n          0.1865, -0.1641,  0.0828,  0.1918,  0.0997,  0.1320, -0.0118, -0.1393],\n        [ 0.0224,  0.1444, -0.0410,  0.1048,  0.0737,  0.1534,  0.1728, -0.2205,\n          0.2014, -0.0907, -0.2349,  0.2057, -0.1703, -0.2185,  0.1697,  0.0278],\n        [-0.0885,  0.1245,  0.1694, -0.1154,  0.1909,  0.2330, -0.0540,  0.0573,\n          0.0268,  0.2057, -0.1461,  0.1353, -0.2327,  0.1731,  0.0063,  0.0937]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2163,  0.1108, -0.1023, -0.1619, -0.0055,  0.1177, -0.0474, -0.0590],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1024, -0.2275,  0.0124,  0.0077, -0.1555, -0.0161, -0.0652,  0.2460]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0821], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x00000267ADA9F040>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"D:\\Projects\\0_Udel\\RL4Sys\\examples\\maze-game\\./logs/rl4sys-ppo-info\\rl4sys-ppo-info_s260000000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='D:\\\\Projects\\\\0_Udel\\\\RL4Sys\\\\examples\\\\maze-game\\\\./logs/rl4sys-ppo-info\\\\rl4sys-ppo-info_s260000000\\\\progress.txt' mode='w' encoding='cp936'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	40,
    "train_v_iters":	40,
    "traj_per_epoch":	5,
    "vf_lr":	0.0003
}