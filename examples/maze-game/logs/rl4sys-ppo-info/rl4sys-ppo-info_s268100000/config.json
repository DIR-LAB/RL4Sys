{
    "__class__":	"PPO",
    "buf_size":	50000,
    "clip_ratio":	0.1,
    "env_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game",
    "exp_name":	"rl4sys-ppo-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	5,
    "lam":	0.97,
    "log_data_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-info",
        "output_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s268100000"
    },
    "pi_lr":	0.0003,
    "seed":	268100000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x7b6176aef0d0>":	{
            "_clip_ratio":	0.1,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (pi_network): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=4, bias=True)\n    )\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (pi_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1053,  0.1416, -0.1512, -0.1164, -0.0994, -0.1400, -0.2175, -0.1227,\n         0.0748, -0.1948,  0.0455, -0.0916, -0.1889,  0.1639, -0.2030,  0.1912,\n        -0.2173,  0.0788, -0.0466,  0.2066,  0.1947,  0.0048,  0.0142,  0.0128,\n         0.0250, -0.0217,  0.1262,  0.0756,  0.0244,  0.1515,  0.1361,  0.1512],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 5.5267e-02, -1.7303e-01, -2.1576e-01,  6.0218e-02, -1.5345e-01,\n         -1.8114e-01,  4.9536e-02, -1.6103e-01, -1.0960e-01,  5.3675e-02,\n          1.6870e-01,  5.8408e-02,  9.2141e-02,  7.4422e-02, -1.3562e-02,\n         -4.5921e-02, -1.8111e-01, -1.6439e-02,  1.9301e-01,  1.5707e-01],\n        [-1.8155e-01,  2.1039e-02,  8.3108e-02,  1.5618e-01, -1.2129e-02,\n         -1.9842e-01, -1.4206e-01,  2.1091e-01,  1.4200e-02,  4.9804e-02,\n         -1.8424e-01, -4.6667e-02,  1.8459e-01,  1.7484e-02,  1.4912e-01,\n          1.0904e-01,  1.4655e-01,  1.5807e-01, -1.0465e-01, -2.8946e-02],\n        [-1.1333e-01,  7.4914e-02,  1.9102e-01,  7.4451e-02, -2.1533e-02,\n          2.0965e-01,  1.1480e-01,  7.0719e-02,  4.7431e-02, -9.9777e-02,\n         -1.2020e-01, -5.3719e-02,  1.8841e-01,  1.4011e-01,  4.2555e-02,\n          1.2183e-01, -1.5608e-01,  2.0002e-01, -1.7329e-01, -1.1917e-01],\n        [ 1.5272e-01,  1.0771e-01, -5.9726e-02,  2.0605e-01,  1.2976e-01,\n          1.9098e-01, -1.8564e-01,  1.6920e-02, -2.0452e-01, -1.6602e-01,\n         -1.9594e-01,  5.6088e-03, -1.5362e-01, -9.4945e-02,  7.3002e-03,\n          1.5459e-01,  1.7260e-01, -1.8214e-01, -2.1971e-02,  1.2736e-01],\n        [-1.6331e-01,  2.2323e-01,  7.3249e-02,  2.0944e-01,  8.0574e-03,\n          1.1932e-02, -4.8523e-02, -2.1828e-01, -1.9779e-01, -9.2720e-02,\n          1.7242e-01, -1.7146e-01, -9.3842e-02,  1.5824e-01, -1.0137e-01,\n          1.1496e-01,  3.9435e-02,  1.1756e-01, -1.4277e-01,  1.2904e-01],\n        [-1.4530e-01, -3.2549e-02, -1.8819e-01, -2.0899e-01,  2.0278e-01,\n         -1.6171e-01, -1.0848e-01,  5.4614e-02,  1.0643e-01, -1.4738e-01,\n         -7.5677e-02,  7.0229e-02,  1.0547e-01, -2.1148e-01, -1.3339e-01,\n         -9.4762e-02, -1.1096e-01, -2.5726e-02,  1.4232e-01,  1.2405e-01],\n        [-7.6356e-02, -1.8865e-01,  1.1855e-01,  1.2859e-01, -8.4290e-02,\n         -1.4343e-01, -2.1436e-01, -2.1770e-01,  6.2202e-02,  1.1850e-01,\n          9.6700e-02,  1.3100e-01,  8.4339e-03, -1.1521e-01,  2.6772e-02,\n         -1.5410e-01,  5.3874e-02, -6.3423e-02,  2.0120e-01,  2.2261e-01],\n        [ 5.9137e-02, -1.9891e-01, -2.0386e-01, -3.2198e-02, -3.5044e-02,\n         -1.2315e-01, -7.9270e-02,  2.1967e-01,  5.3951e-02,  3.2146e-02,\n          1.1973e-01, -2.0866e-01,  1.4139e-01, -5.3647e-02, -9.1106e-02,\n         -1.5575e-01,  1.5372e-01, -1.6512e-01, -1.4497e-01, -1.1233e-01],\n        [-4.8287e-02, -1.4132e-01,  2.2148e-01,  9.7860e-02, -1.7765e-01,\n          5.9516e-02,  2.1498e-01, -4.7302e-02, -3.0519e-02,  4.0666e-02,\n         -6.9045e-02,  2.0976e-01, -7.6270e-02, -1.6177e-01, -7.9196e-02,\n          1.7363e-01,  7.0087e-02,  1.9229e-01, -5.7248e-02,  4.3802e-02],\n        [-1.1329e-01, -5.4254e-02, -9.7939e-02, -1.2541e-01, -2.1181e-01,\n         -1.2046e-01,  5.2129e-02, -9.0551e-02, -1.3979e-01, -4.7024e-02,\n         -9.8070e-02, -1.4947e-01, -1.7024e-01, -9.9303e-02, -8.5563e-02,\n         -7.2683e-02, -2.5190e-02,  2.9870e-02, -8.9132e-02,  1.7174e-01],\n        [-3.5932e-02, -1.5139e-02, -1.4559e-01,  7.7083e-02,  6.5026e-02,\n          4.6979e-02,  7.6048e-02,  1.9332e-01,  1.8807e-01, -1.5627e-01,\n          1.5341e-02, -1.2334e-01,  2.2749e-02, -1.2115e-01,  2.0453e-01,\n         -8.9073e-02,  1.7982e-01, -1.4191e-01,  5.3175e-02, -1.4594e-02],\n        [-6.3296e-02,  1.9283e-01,  4.6559e-02,  2.0813e-01, -1.8143e-01,\n         -1.5591e-01, -1.4875e-02, -8.5406e-04,  1.6498e-01, -3.5389e-02,\n          1.3604e-01,  9.9606e-02, -7.2365e-02, -1.7620e-01, -1.4707e-01,\n         -1.3266e-01,  1.2409e-01,  1.2311e-01, -1.9798e-01,  2.1413e-01],\n        [-1.4951e-01, -1.5978e-01,  1.4975e-02,  1.1787e-01,  1.3680e-01,\n          7.6693e-02,  1.1504e-01, -1.1799e-01, -2.5791e-02, -2.0235e-01,\n          1.4007e-01, -1.3816e-01, -3.6378e-02, -1.9059e-01,  1.9211e-02,\n          8.5462e-02,  1.2248e-01, -8.8829e-02,  1.7288e-02, -1.5166e-01],\n        [-7.5918e-02,  2.2064e-01, -1.2276e-01,  5.4821e-02,  4.4592e-02,\n         -5.0325e-02, -2.4086e-02, -2.0335e-01,  5.4444e-02, -2.6127e-02,\n          4.4417e-03,  1.4190e-01,  1.5953e-01,  2.2300e-01, -1.6316e-01,\n         -1.7194e-01,  1.9989e-01,  8.9323e-02, -1.1300e-01,  1.9675e-01],\n        [-7.8978e-02,  2.0412e-01, -5.0972e-02, -6.7121e-02, -1.9404e-02,\n          2.0187e-01,  1.9799e-01,  2.1492e-01, -4.5149e-02, -1.4816e-01,\n          1.5519e-04,  1.2926e-02, -4.6442e-02,  4.7292e-02, -1.7640e-01,\n          2.1550e-01,  1.9707e-01,  8.0685e-02, -4.6045e-02, -7.8533e-02],\n        [ 1.9195e-01, -1.9068e-01,  1.8627e-01,  1.2028e-01, -8.9450e-02,\n         -5.3965e-02, -1.0016e-01,  2.8515e-02, -1.3317e-01,  7.4732e-02,\n         -1.4548e-01, -6.9679e-02, -1.5696e-01, -1.3589e-01, -1.2951e-01,\n          1.9526e-01,  2.0588e-01,  1.4706e-01,  6.4582e-02,  1.9451e-01],\n        [ 6.6832e-02, -9.4251e-02, -2.5196e-02, -4.5957e-02,  1.8874e-02,\n          2.0473e-01, -1.6878e-01, -2.0108e-01,  1.7847e-01,  4.6458e-02,\n          2.0337e-01,  4.1982e-03, -5.7218e-02,  1.8576e-01,  4.8038e-02,\n         -1.8110e-01,  1.3224e-01,  1.6630e-01, -3.3067e-02,  1.2179e-01],\n        [ 6.0869e-02,  9.1297e-02,  8.1935e-02,  3.5501e-02,  3.0647e-02,\n         -1.0691e-01, -1.7199e-01, -1.3351e-01,  1.9711e-01, -7.2035e-02,\n          1.2301e-01, -6.3901e-02,  2.8550e-02,  3.5556e-02, -8.6542e-02,\n          2.3137e-02,  6.5264e-02, -1.9047e-01, -3.2110e-02, -1.6018e-01],\n        [-9.3287e-02, -1.9310e-01, -1.1080e-01,  1.0437e-01,  1.2839e-01,\n         -1.4475e-01,  1.9623e-02, -1.0140e-02,  2.0279e-01,  7.1762e-02,\n         -6.9594e-02,  2.1642e-02,  9.6382e-03, -1.8000e-02,  6.5178e-02,\n          1.6378e-01,  6.3838e-02, -2.1887e-01, -2.7342e-02, -7.6176e-02],\n        [ 4.0834e-02,  2.7968e-02, -1.0882e-01,  1.6029e-01,  7.1264e-02,\n         -4.2145e-02, -1.5187e-01, -4.1434e-02,  1.5710e-01, -1.6682e-01,\n         -1.9830e-03, -2.0798e-01,  7.1502e-02,  6.2040e-02,  8.7428e-02,\n          6.5215e-02,  2.9402e-02,  1.5965e-01, -1.5995e-01,  2.8118e-02],\n        [-1.4008e-03, -6.5407e-02, -1.0320e-01, -8.5696e-02, -3.4920e-02,\n          7.7006e-02,  4.0675e-02,  1.2491e-01,  1.9267e-01,  2.1198e-01,\n          4.1249e-02,  1.5828e-01,  1.5095e-01, -8.1817e-02,  2.6775e-02,\n          2.0774e-01, -3.8536e-02,  2.2036e-01, -1.6191e-01, -1.6528e-01],\n        [ 2.0710e-01,  4.5536e-02, -4.7888e-02,  5.8512e-02,  5.3110e-02,\n         -1.4756e-01, -1.4395e-01,  4.1146e-02, -1.3828e-02,  1.3951e-01,\n          2.2252e-01,  1.1585e-01, -2.1479e-02, -5.4607e-02,  1.6226e-01,\n          1.4227e-01,  1.2835e-01, -7.4818e-02,  6.4686e-02, -1.3049e-01],\n        [-8.3883e-02, -6.3258e-02,  1.0039e-01, -3.1996e-02, -7.9539e-02,\n          1.3084e-01, -2.1547e-01,  1.2716e-01, -1.0906e-01, -1.0904e-01,\n          9.2409e-02, -1.5850e-01,  1.1622e-01, -1.4001e-01,  7.4786e-02,\n         -3.4712e-02,  2.1268e-01, -7.3590e-02, -1.5693e-01,  4.3073e-02],\n        [ 1.8778e-01, -4.3216e-02,  2.2148e-01, -8.4067e-02,  1.4216e-01,\n         -1.1626e-01,  1.1079e-01, -1.1414e-01, -7.4622e-02, -1.4735e-01,\n          1.3659e-01, -1.5925e-01,  4.0595e-02, -7.2866e-02, -1.2160e-01,\n          8.8379e-02,  9.3844e-02, -9.2431e-02,  2.0334e-01,  1.6857e-01],\n        [ 1.7599e-01,  1.4102e-01, -3.6700e-02, -1.9051e-01,  1.9789e-01,\n          1.7692e-01, -1.9339e-02,  1.9960e-01, -1.7196e-01,  2.1887e-01,\n          7.2245e-02, -3.7244e-02,  1.5929e-01, -2.6588e-02,  7.3777e-02,\n         -5.8589e-02, -1.6331e-01,  1.2027e-03, -1.3607e-01, -1.9313e-01],\n        [ 1.4989e-04,  5.5824e-02,  1.4032e-01, -1.8783e-01,  1.3093e-01,\n          5.2002e-02, -9.7200e-02,  1.9651e-02, -1.8469e-01,  1.8478e-01,\n         -1.6005e-01, -1.3550e-01,  1.2472e-01,  6.6999e-02, -5.1167e-03,\n          4.3351e-02, -1.4552e-01,  1.3814e-01,  8.5914e-02,  2.1737e-01],\n        [ 5.7420e-02, -1.5155e-01, -2.5554e-02,  1.8667e-01,  1.8066e-01,\n          1.0391e-01,  1.2966e-01, -1.8941e-01, -1.5047e-01, -1.3217e-01,\n          1.1492e-01, -4.2383e-02,  1.2393e-01,  1.6456e-01, -1.3576e-01,\n         -9.3037e-02, -3.2847e-02,  1.9328e-01,  1.2542e-01,  9.4211e-02],\n        [-1.6553e-01, -2.1955e-01, -1.2246e-01, -2.1772e-01,  1.5944e-01,\n         -3.9975e-02, -1.6425e-01, -1.0955e-01,  7.3514e-02, -1.2142e-01,\n         -1.4497e-01, -8.5951e-02, -6.9088e-02,  1.0545e-02, -8.9620e-02,\n          1.2235e-01,  2.1746e-01,  1.2856e-01, -8.7728e-02,  2.4271e-02],\n        [ 1.9082e-01, -1.5589e-01,  2.0872e-01, -1.7810e-01,  2.1348e-01,\n          6.1692e-02,  1.4525e-01,  1.0363e-01, -2.1940e-01, -9.3518e-02,\n         -6.1640e-02,  1.5729e-01, -6.6232e-02,  2.0364e-01, -6.5639e-02,\n         -9.3859e-02, -1.6304e-01,  1.0067e-01, -2.2002e-01,  8.6729e-02],\n        [ 2.1904e-01,  4.8208e-02,  1.1317e-01,  1.2310e-01,  2.1696e-01,\n         -1.0825e-01,  1.2156e-01, -9.9961e-02,  1.8760e-01,  3.9259e-02,\n         -1.0224e-02,  1.3446e-01,  1.6654e-01,  2.3861e-02, -2.7375e-03,\n         -7.2344e-02,  1.1889e-01,  5.6811e-02, -1.3208e-02, -2.4001e-02],\n        [ 2.2307e-01,  2.1776e-01,  7.0485e-02,  2.1769e-01, -2.1253e-01,\n         -1.9486e-01, -1.2127e-01, -1.5184e-01, -1.2374e-02,  1.8970e-01,\n          6.1813e-02, -1.5485e-01, -2.1881e-01,  2.9705e-02,  1.8783e-01,\n         -1.1267e-01,  2.8200e-02,  1.3045e-01, -2.0547e-01, -2.2098e-01],\n        [-2.1549e-01, -2.9176e-02,  1.1732e-01, -3.7070e-02, -9.8225e-02,\n         -1.7196e-02,  1.2878e-01,  4.7090e-02,  1.4542e-01, -8.7825e-02,\n         -1.5233e-01,  2.6747e-03,  1.2594e-02, -1.9281e-02, -9.4225e-02,\n         -1.1079e-01, -2.1839e-01, -2.0814e-01, -4.3257e-02,  1.4905e-01]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1082, -0.1304, -0.1285, -0.1455,  0.1270, -0.0564,  0.0919,  0.0105,\n         0.0017,  0.1311,  0.0328,  0.0439, -0.1595,  0.1257, -0.1457, -0.1710],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-5.0285e-02,  1.0222e-01,  1.3862e-01,  1.9889e-02,  2.6543e-02,\n          6.6823e-02,  4.7170e-02, -1.3686e-01,  1.1087e-01,  1.3269e-01,\n         -4.8459e-03, -1.4784e-01,  9.5230e-02,  1.5495e-01,  3.4856e-02,\n         -3.6443e-02, -3.2487e-02,  1.4987e-01,  6.5387e-02, -1.6060e-01,\n         -1.6290e-01,  9.6289e-02, -1.1561e-01,  1.2603e-01, -8.9283e-02,\n          1.2424e-01,  1.1761e-01, -1.0656e-01, -1.5648e-01,  7.5247e-02,\n          1.8698e-02, -1.7017e-01],\n        [ 1.6307e-01,  2.4278e-02,  2.1210e-02, -1.5044e-01,  1.7139e-02,\n         -1.3955e-01, -9.5056e-02, -1.0294e-01,  3.6492e-02,  1.9705e-03,\n          1.3740e-01,  7.4059e-02,  1.6145e-01, -1.5354e-01, -1.4945e-01,\n          1.7289e-01, -3.9414e-04,  1.4875e-01, -1.1153e-01,  1.7112e-01,\n          8.0770e-02, -1.4081e-01,  1.7603e-01,  1.6050e-01, -1.0157e-01,\n         -1.0778e-01, -1.5009e-01, -1.6331e-01, -1.2336e-01, -4.0691e-02,\n          9.0213e-02,  1.3208e-01],\n        [ 6.9992e-02,  1.1494e-01, -1.6797e-03, -4.8001e-02,  6.3002e-02,\n          1.6230e-01, -1.6860e-01,  1.8441e-02, -1.7627e-01, -4.2524e-02,\n         -1.6360e-01, -9.8632e-02, -1.4619e-01,  2.4390e-02,  2.4246e-02,\n          7.5787e-02,  7.1187e-02,  1.5364e-01, -6.8570e-02, -1.2082e-01,\n          3.3705e-02,  8.7668e-02, -1.7530e-01,  1.0102e-01, -1.6008e-01,\n          1.6179e-01,  1.2319e-01, -1.5924e-01, -5.4598e-03, -7.8936e-02,\n          4.5979e-02, -2.3530e-02],\n        [-1.1263e-02, -3.0962e-02, -2.0698e-02,  6.9257e-02, -6.0464e-02,\n         -1.1001e-01, -1.5976e-01, -9.8052e-02,  1.0510e-01,  1.5882e-01,\n         -1.3791e-01, -9.0039e-02,  1.3798e-01, -1.1453e-01,  1.3003e-01,\n          5.8689e-02,  1.3607e-01, -1.0305e-01,  1.5899e-01, -8.6266e-02,\n          1.5338e-01, -1.0470e-01,  1.5267e-01,  1.5968e-01, -5.3884e-02,\n          1.1334e-01,  1.1710e-01,  1.1895e-01, -4.2675e-02, -1.3870e-01,\n          1.8192e-02,  1.4155e-01],\n        [-1.4982e-01,  1.3694e-01,  4.9110e-02, -7.9742e-02, -1.1521e-01,\n         -6.1401e-02,  4.3865e-02,  2.1272e-02,  1.8739e-02, -1.6612e-01,\n         -1.6324e-01,  1.1438e-01, -1.0528e-01, -1.4343e-01,  1.6694e-01,\n         -3.4168e-03, -6.7632e-02,  4.0123e-02,  6.0964e-02,  2.2330e-02,\n         -1.4699e-01, -1.1183e-01,  3.9772e-02, -1.1196e-01, -1.5371e-01,\n         -3.9582e-02, -5.7422e-02,  1.3649e-01, -9.3838e-02, -1.5196e-01,\n          1.0716e-01, -1.5181e-01],\n        [-1.6718e-02, -1.6574e-01,  1.7481e-01,  9.7849e-02,  1.7467e-01,\n          1.4081e-01, -3.8981e-02, -2.9280e-02,  3.0648e-02, -3.8814e-02,\n         -1.5583e-01,  4.7842e-02, -1.2693e-01,  2.7507e-03, -1.7450e-01,\n         -2.2057e-02,  7.6763e-03, -1.4196e-02,  1.6396e-02, -9.0369e-02,\n         -7.3178e-02,  1.1214e-01,  9.1558e-02, -2.0755e-02, -2.2785e-03,\n         -7.5885e-02, -1.7380e-01, -6.2102e-02, -3.0140e-02, -1.0956e-01,\n         -6.2758e-02, -1.0077e-01],\n        [ 1.2213e-01, -1.3445e-01,  7.4224e-02,  1.4117e-01, -2.7749e-02,\n         -3.7470e-03, -1.3167e-02, -8.6641e-02, -6.0167e-02, -1.7843e-02,\n          5.6951e-02,  1.5343e-01,  8.0096e-02,  1.3512e-01,  5.1371e-02,\n         -3.2366e-02,  4.8693e-02, -1.2111e-01,  1.7019e-01,  1.6649e-01,\n          1.3873e-01, -1.6167e-01, -1.4018e-01, -1.3726e-01, -9.7715e-02,\n          1.6149e-01, -5.8588e-02, -6.0451e-02,  1.7386e-01, -1.6761e-01,\n         -1.7207e-01,  1.6309e-01],\n        [-1.0634e-01,  1.2015e-01, -1.2485e-01, -1.7080e-01, -7.1667e-03,\n          2.3045e-02,  1.4839e-01, -1.0279e-01, -1.0404e-02, -6.8262e-02,\n         -1.5674e-02, -6.7195e-02,  8.9449e-02, -1.3774e-01,  1.2639e-01,\n         -1.0799e-01, -9.2493e-02, -1.4866e-01, -5.4040e-02,  8.9764e-02,\n          2.4676e-02,  1.2815e-01, -1.9703e-02,  1.4170e-01,  3.4292e-03,\n          4.1147e-02, -2.7103e-02, -8.5184e-02, -1.0683e-01,  3.5000e-02,\n         -6.8270e-02, -1.5402e-01],\n        [-1.6289e-01, -2.9784e-02,  3.0747e-02, -7.8499e-02,  1.5561e-01,\n         -1.2583e-01,  1.2188e-01,  6.2353e-02, -2.9169e-02,  2.5066e-02,\n         -8.6941e-02, -3.9736e-02,  1.5697e-01,  1.5086e-01, -1.4523e-01,\n         -1.1512e-04,  5.1980e-02, -6.8285e-02, -8.9923e-03,  6.4433e-02,\n          4.8054e-02,  6.4649e-02, -2.3376e-02,  1.5374e-01,  1.4365e-01,\n          5.7434e-03, -9.4998e-02, -1.4178e-01,  2.9452e-02, -9.0839e-02,\n         -4.6380e-02,  3.9567e-02],\n        [-4.4306e-02,  4.9426e-02, -1.3332e-01, -1.2979e-02, -8.5998e-02,\n          7.4346e-02, -1.5267e-01,  1.7022e-01, -1.5001e-01,  1.5986e-01,\n          1.4351e-01, -1.0909e-01, -1.7054e-01,  4.6059e-02,  8.4485e-02,\n          5.8021e-02,  4.0942e-02,  1.6012e-01,  9.7137e-02, -8.7295e-02,\n         -1.5669e-01,  1.1762e-01, -2.5774e-02,  1.2869e-02, -7.3865e-02,\n         -7.6283e-02, -1.4185e-02,  1.4820e-01,  1.2414e-01, -1.1667e-01,\n          1.7158e-01, -1.0219e-01],\n        [ 7.4473e-02,  1.4083e-01, -1.4227e-01,  4.5352e-02,  1.0152e-01,\n          8.8256e-02,  1.7782e-03,  1.4609e-01, -1.4330e-01,  1.1555e-01,\n          3.5637e-03, -1.4855e-01, -1.3805e-01, -7.9800e-02,  7.9688e-02,\n         -1.3278e-02, -1.0698e-01,  2.3043e-02,  6.0500e-02, -2.4844e-02,\n          1.6268e-01,  9.9827e-02,  1.7575e-01, -1.5771e-01, -6.9149e-03,\n          1.2512e-01,  1.7596e-02, -9.9286e-02, -1.2842e-01,  1.1917e-02,\n         -1.7478e-01, -1.4079e-01],\n        [ 2.1932e-02,  1.1914e-02, -1.2180e-01, -1.1532e-01,  5.4106e-02,\n          1.1652e-01,  1.6835e-01,  7.8796e-03,  5.4527e-02,  1.2646e-01,\n         -1.0591e-01,  4.3355e-02, -1.4009e-02, -1.1636e-01, -8.9866e-02,\n         -1.6352e-01, -1.5214e-01,  1.3103e-01,  2.1401e-02,  1.2994e-01,\n         -1.0905e-01,  2.9889e-03,  1.6344e-01, -2.6959e-02, -7.6056e-02,\n         -5.0592e-03,  1.2794e-01, -1.2743e-01,  8.5905e-03,  6.6874e-02,\n          1.7544e-01, -9.7170e-02],\n        [-9.4687e-02,  1.2402e-01,  1.1764e-01, -2.1338e-02, -1.6666e-01,\n          1.4158e-01, -3.1226e-02,  1.5455e-01,  1.6290e-01,  1.3070e-01,\n          6.7495e-02,  1.7196e-01, -3.3637e-02, -3.3745e-02,  1.5913e-01,\n         -1.6042e-01, -4.0084e-03, -6.2763e-03,  7.5633e-04,  8.0478e-02,\n         -8.3352e-02,  3.0318e-02,  8.9957e-02,  1.7548e-01,  1.5022e-01,\n          4.7574e-02,  1.4010e-01,  1.2268e-01,  1.3335e-01, -1.2473e-01,\n         -5.8418e-02,  3.7481e-02],\n        [ 1.7260e-01,  1.6160e-01, -2.2786e-02, -2.8665e-02,  6.9883e-02,\n          9.7747e-02,  7.9469e-02,  2.3475e-02,  1.2602e-02, -7.2371e-02,\n          1.4637e-01,  1.1144e-01, -1.4672e-01,  1.3615e-01, -1.1668e-01,\n         -7.2946e-02, -3.3145e-02,  3.3453e-02,  1.2914e-01,  1.3712e-01,\n          8.6696e-02,  1.1007e-01, -7.6355e-02, -1.1213e-01,  1.4027e-01,\n          9.9812e-02, -1.4481e-01, -4.4815e-02,  1.1790e-01, -5.2516e-03,\n          1.0666e-01,  1.5226e-01],\n        [ 1.5314e-01,  1.0455e-01,  1.4417e-01,  3.4085e-03,  1.6426e-01,\n          5.0967e-02, -1.7491e-01, -6.5988e-02,  1.2102e-01, -1.6495e-01,\n         -4.3194e-02,  1.4829e-01, -1.4021e-01, -6.9545e-02,  1.6541e-01,\n          6.2094e-02, -1.2183e-02,  9.2808e-02, -3.1978e-02, -1.4971e-01,\n         -2.6468e-03,  3.7871e-02, -5.4899e-02,  1.2266e-01,  7.8228e-02,\n         -2.5470e-03, -1.7217e-01,  1.7035e-01,  7.1920e-02, -1.2398e-01,\n         -4.7369e-02,  3.2229e-02],\n        [ 1.7205e-01,  1.1947e-01, -9.4582e-02, -1.7095e-01, -7.3986e-02,\n          1.2981e-01, -2.7304e-02,  6.4234e-02,  1.4315e-01, -1.2079e-01,\n          1.1721e-01, -7.7797e-02, -1.6862e-01,  2.4253e-03, -1.4185e-01,\n         -8.7302e-02,  9.7146e-02, -9.6363e-02, -7.7150e-02, -1.0158e-01,\n         -1.0922e-01,  2.9787e-02,  1.4823e-01,  1.5295e-01,  2.6932e-02,\n         -1.3655e-01,  1.7077e-01, -1.8744e-02,  5.1501e-02, -1.2330e-01,\n          8.5743e-02,  1.2731e-01]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0073,  0.0321,  0.2310, -0.0749,  0.0697, -0.0038, -0.2482, -0.1971],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.2042,  0.0544,  0.1644, -0.1555, -0.1639,  0.2324, -0.0193, -0.1559,\n          0.0786, -0.0084, -0.1006, -0.0492, -0.2039,  0.1630, -0.2195,  0.1807],\n        [ 0.0003, -0.1655,  0.1560,  0.2312,  0.2162, -0.0935,  0.1947, -0.0810,\n          0.2481,  0.2391, -0.1801,  0.1618,  0.0589,  0.1963, -0.1608,  0.2133],\n        [-0.0387,  0.1438, -0.1723, -0.0933,  0.1589, -0.0227, -0.2208, -0.0142,\n          0.0739, -0.0949, -0.1820,  0.1973, -0.0672,  0.0812,  0.0732,  0.2398],\n        [ 0.2137,  0.0880,  0.0464, -0.0791, -0.1192,  0.2038, -0.1335,  0.2212,\n          0.2396,  0.1365,  0.0057,  0.1606, -0.1342, -0.2066, -0.0742,  0.0883],\n        [-0.0946,  0.2202,  0.2340, -0.1459,  0.0097,  0.1194, -0.1926,  0.1086,\n         -0.1310,  0.2200, -0.0799,  0.0046, -0.2277,  0.0999, -0.0788, -0.0365],\n        [-0.1823, -0.2161, -0.0012,  0.0029, -0.1161,  0.1467, -0.1208,  0.2271,\n         -0.1755, -0.1330, -0.0208,  0.0187,  0.0771, -0.1446,  0.0695,  0.0982],\n        [-0.1430,  0.0255,  0.2057, -0.1799, -0.0333, -0.1585, -0.2396, -0.1088,\n         -0.1169,  0.0606,  0.2303, -0.1445, -0.0779,  0.0140, -0.1663,  0.1539],\n        [-0.0316,  0.1142, -0.1325, -0.0265,  0.0725, -0.0839, -0.2068, -0.1706,\n          0.0714,  0.1164, -0.1012, -0.2457, -0.1949,  0.0269,  0.0566,  0.1532]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=4, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1584, -0.1396, -0.0748, -0.1411], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0416,  0.2857, -0.0188, -0.1382,  0.0445,  0.0411,  0.2666,  0.0044],\n        [-0.3319, -0.0916,  0.3417, -0.2715, -0.2914, -0.2109,  0.0431, -0.2358],\n        [-0.2079,  0.2404, -0.0149, -0.1984,  0.1397, -0.2057,  0.1379,  0.1930],\n        [-0.1073,  0.2216, -0.2006, -0.1108,  0.0738,  0.1071,  0.2276, -0.1907]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	4,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "kernel_dim":	4,
                                "kernel_size":	5,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0601,  0.0726,  0.0402, -0.0135,  0.2173,  0.0731,  0.0952,  0.0507,\n        -0.0614, -0.0297,  0.0435, -0.0198, -0.0145,  0.0597,  0.0176, -0.1633,\n         0.1906,  0.0179, -0.0395, -0.1665,  0.1956,  0.1963, -0.1503, -0.1768,\n         0.0975,  0.2141, -0.1583,  0.1193,  0.0336,  0.1038, -0.0022, -0.1665],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 9.8678e-02, -1.6115e-01, -1.6383e-01,  1.3449e-01,  6.7232e-02,\n          7.5245e-02, -5.8193e-02, -1.9065e-01,  5.5048e-02, -8.5745e-02,\n          2.1311e-01, -1.3375e-01, -1.2955e-01, -2.1692e-01,  2.1873e-02,\n          2.0478e-01, -2.6995e-02, -1.1627e-01,  1.5205e-01, -8.9993e-02],\n        [-2.1695e-01,  1.0575e-01,  1.6679e-01,  1.3863e-01, -1.9284e-01,\n         -1.8752e-01, -1.5435e-01, -8.2458e-02,  2.9961e-02, -1.3166e-01,\n          1.3366e-01,  2.0334e-01,  3.8012e-02,  2.0461e-01,  1.9073e-01,\n          2.1817e-01,  1.0879e-01,  1.5894e-01, -9.3625e-02, -1.4977e-01],\n        [ 2.1590e-01, -1.1887e-01, -1.5117e-01,  2.1203e-01,  1.3664e-01,\n         -9.4132e-02, -1.4156e-01, -3.8164e-02, -1.2170e-01,  6.8680e-02,\n          1.5170e-01,  2.5074e-02, -5.4714e-02,  4.8998e-02,  1.3129e-01,\n          4.3165e-02, -1.5042e-01,  4.0677e-02,  1.8953e-01, -9.7787e-02],\n        [ 5.5889e-02, -2.0747e-01, -3.3571e-02, -1.7239e-01,  8.2289e-02,\n          3.9194e-02,  2.1398e-02, -1.0293e-01, -5.9949e-02,  1.2533e-01,\n         -3.2601e-02,  6.9660e-02, -1.3426e-01, -1.2145e-01,  7.8573e-02,\n         -1.7827e-01, -1.7620e-03, -2.0574e-01,  1.9659e-01,  2.0175e-01],\n        [ 1.7386e-01, -1.6430e-02,  5.2488e-03,  9.5193e-02, -3.9424e-02,\n         -1.1541e-01, -1.6949e-01, -9.9811e-02,  1.0641e-01,  1.2540e-01,\n         -6.1180e-02, -1.2442e-01,  8.0041e-02,  6.3566e-02,  9.0358e-02,\n          6.3770e-02,  2.0496e-01, -2.0106e-01, -1.2887e-01,  2.3077e-02],\n        [-1.2101e-01,  8.4866e-02,  7.4008e-02,  1.4942e-01, -1.3976e-01,\n          2.8017e-02, -2.0414e-01,  6.3857e-03, -2.0763e-01, -2.7369e-02,\n         -3.7956e-02, -9.6651e-02,  1.4107e-01, -7.8955e-02, -8.6904e-02,\n          1.9318e-01,  8.1097e-02, -1.4612e-02,  1.5330e-01, -1.1317e-01],\n        [ 1.2688e-01,  1.2954e-01,  1.2754e-01, -8.2898e-02,  6.8517e-03,\n          1.1594e-01, -1.3490e-01, -1.6444e-01,  4.3232e-02, -3.6610e-02,\n          1.4681e-01,  1.3536e-01, -1.2156e-01, -3.7557e-02,  7.6561e-02,\n          9.9208e-02,  8.7118e-02,  4.5831e-02, -1.4455e-01,  3.9454e-02],\n        [-5.2728e-04,  1.6463e-01,  2.0748e-01, -2.4139e-02,  6.0720e-02,\n          1.7343e-01,  1.2632e-01,  4.1703e-02, -1.6446e-01,  8.6151e-02,\n          6.3386e-02, -7.3950e-02,  1.0597e-01, -1.0297e-01, -2.0860e-01,\n         -1.4245e-01,  1.9352e-01, -8.3775e-02,  2.0699e-01, -9.5295e-02],\n        [ 4.6112e-02, -6.1274e-02,  8.0248e-02,  2.0277e-02, -5.0890e-03,\n         -1.1544e-01,  5.4346e-04, -7.0941e-02,  1.9431e-01,  7.4607e-03,\n          2.2344e-01,  8.8873e-02,  1.8386e-01,  1.5668e-01,  3.7077e-02,\n          4.5140e-02,  1.4917e-01,  6.4639e-02,  1.3716e-01, -5.5961e-02],\n        [ 1.6779e-01, -1.2637e-02, -2.1916e-01,  2.0768e-01, -1.0937e-01,\n         -2.2238e-02, -9.9210e-02,  1.2272e-01,  4.0796e-02, -2.1406e-02,\n         -3.9037e-02, -1.8867e-01, -3.0599e-02, -2.1342e-01, -1.9408e-01,\n         -1.1606e-01,  8.1512e-02,  1.9201e-01,  1.6602e-02, -1.1098e-01],\n        [ 3.9141e-02,  1.8458e-01, -5.8213e-02,  1.3727e-01, -1.3138e-01,\n          2.0108e-01, -2.1470e-01, -7.7616e-02,  2.1288e-01,  1.3464e-01,\n         -1.5365e-01, -5.3070e-02, -9.9306e-02,  7.3017e-02, -1.8756e-01,\n         -4.7514e-02,  5.9561e-02, -1.4061e-01,  2.0770e-01,  6.0844e-03],\n        [-1.5524e-02, -1.0827e-01, -1.8244e-01,  2.1763e-01,  5.5315e-03,\n          9.4410e-02,  1.6508e-01,  1.5591e-01, -4.9745e-02, -3.4313e-02,\n         -6.7689e-02, -1.7566e-01,  7.7388e-02, -1.3676e-01, -1.0097e-01,\n         -7.4009e-02, -1.1589e-01,  6.3570e-02, -1.1576e-01,  1.3583e-01],\n        [ 1.9360e-01, -1.9959e-02,  1.1306e-01,  2.0644e-01,  1.6118e-02,\n          1.9461e-01,  2.0855e-01,  6.5612e-03,  1.9508e-01,  1.1960e-01,\n          6.5968e-02, -1.5712e-02,  9.5185e-02, -3.0707e-03,  1.6373e-01,\n         -1.7754e-01,  9.6733e-02,  1.7613e-01, -7.1818e-02, -1.9958e-01],\n        [-1.0613e-01,  2.1613e-01, -9.5123e-02,  5.5512e-02,  1.0987e-01,\n          1.3916e-01, -1.0856e-02, -1.7771e-02, -9.0449e-02,  4.8713e-02,\n          5.7690e-02,  1.3540e-01, -1.8750e-02,  7.6508e-03, -2.9463e-02,\n         -8.1920e-02, -1.3292e-01, -1.5713e-01, -1.4448e-01, -8.4060e-03],\n        [-1.2982e-01,  1.7749e-01,  2.2029e-01, -5.2988e-02, -1.1130e-01,\n         -1.5056e-01, -1.1230e-01,  8.1562e-02, -6.8761e-02, -1.2907e-01,\n         -1.0273e-01, -1.2510e-01,  2.1636e-01, -1.6336e-01,  1.2825e-01,\n          1.6787e-01,  6.7908e-02,  9.5052e-02, -6.1509e-02,  4.7661e-02],\n        [-1.8308e-01, -1.3962e-01, -1.1320e-01,  1.4125e-01, -1.5682e-01,\n          5.2465e-02, -2.7534e-03, -1.9357e-01,  1.4218e-02, -2.1043e-01,\n          8.6745e-02, -9.4848e-02, -5.4437e-02,  1.6738e-01,  2.2173e-01,\n          1.6729e-01,  1.2520e-01, -7.5845e-02, -5.7976e-02, -1.9667e-01],\n        [ 1.8666e-01,  1.6834e-01,  1.3120e-01, -1.1956e-01,  1.3435e-01,\n         -2.0999e-01, -1.4750e-01, -1.4370e-01,  1.7746e-01,  6.6653e-02,\n          1.5534e-01, -1.0036e-01,  1.6096e-01,  3.4047e-02,  1.4118e-01,\n          7.9211e-04,  1.7436e-01,  1.0808e-01,  7.7430e-02, -7.0962e-02],\n        [ 1.1526e-01, -7.5667e-03, -4.7372e-02, -1.0031e-01,  1.4097e-01,\n         -1.9092e-01,  1.1353e-01, -9.1539e-02,  1.7521e-02, -1.6729e-02,\n          1.1727e-01, -3.1176e-02, -1.6215e-01,  4.1776e-02,  4.8528e-02,\n         -1.7362e-01,  2.0703e-01, -1.5336e-02, -8.2473e-02, -1.8481e-02],\n        [-1.4842e-01, -8.9725e-02, -1.4743e-02, -3.0705e-03,  1.8355e-02,\n         -3.6813e-02,  5.0002e-02,  1.9609e-01, -1.3349e-01,  7.2182e-02,\n          1.3457e-01,  1.1963e-01, -1.7988e-01, -1.0172e-01, -1.6881e-01,\n         -1.4538e-01, -1.5854e-01, -2.6972e-02,  3.7419e-03, -1.6202e-01],\n        [ 1.3757e-04,  1.8599e-01, -1.3488e-01, -1.5501e-01,  1.3529e-01,\n          3.6941e-02, -6.9069e-02,  4.7819e-02,  1.2649e-01, -1.7029e-02,\n          8.5653e-02, -1.4935e-01,  1.0603e-01, -1.0386e-01,  1.0869e-01,\n          1.9874e-01,  1.6046e-01, -8.6903e-02, -4.3094e-02, -2.2371e-02],\n        [ 1.5230e-01, -1.9575e-01,  1.8255e-02,  4.7770e-04,  2.0650e-01,\n         -1.3610e-01,  1.2607e-01,  2.1115e-01,  1.5027e-01,  1.6859e-01,\n          3.0548e-02,  2.0659e-01, -2.5435e-02, -1.9031e-01, -1.1986e-01,\n         -9.9073e-02, -5.1593e-02,  4.8048e-02,  1.5829e-01,  2.0434e-01],\n        [ 1.3274e-01,  4.9029e-02, -1.9872e-01, -3.2954e-02, -1.4994e-01,\n         -1.0387e-01, -1.5025e-01,  1.6538e-01, -9.2226e-02, -1.7875e-01,\n          1.1329e-01, -1.6333e-01, -7.9881e-02,  1.8253e-01, -2.2224e-01,\n         -1.0350e-01, -1.0292e-01, -1.8035e-01, -1.1461e-01,  1.0313e-01],\n        [ 4.4631e-02, -2.1248e-01,  1.4722e-01,  1.4431e-01, -6.7879e-02,\n          1.6248e-01, -1.0244e-01, -2.4488e-02,  1.9454e-01,  1.6783e-01,\n          2.7004e-02,  1.9097e-01,  1.6210e-01,  8.1539e-02, -1.8115e-01,\n         -4.3900e-02, -5.5770e-02,  1.4813e-01,  1.4010e-01,  9.7069e-02],\n        [ 1.6115e-01,  4.0066e-02,  1.0388e-01,  1.4077e-01, -2.2050e-01,\n         -1.6865e-01, -6.2243e-02,  1.0588e-01, -4.5404e-02, -2.1196e-02,\n          1.3204e-01, -8.8090e-02,  1.1015e-01, -3.1874e-02, -1.4170e-01,\n         -9.2710e-02, -1.4538e-01,  1.3292e-02,  1.9691e-01, -1.7266e-01],\n        [ 1.1983e-01,  2.4651e-02, -1.2420e-01,  7.3444e-02,  1.5139e-01,\n         -7.7114e-02, -1.3150e-01,  2.3224e-02, -2.1098e-01,  3.3066e-02,\n         -1.1384e-01, -2.0121e-01,  1.5028e-01,  1.0885e-01, -1.6023e-01,\n         -1.7979e-01, -4.5096e-02, -1.4041e-01, -1.2410e-01, -1.5834e-01],\n        [-1.5967e-01,  1.4787e-01,  5.7299e-02, -2.1331e-01,  8.5285e-02,\n          1.4998e-01, -2.5372e-02, -5.8993e-02, -2.1342e-01,  1.6759e-01,\n         -1.4644e-01, -2.2242e-01, -1.2249e-01, -2.2175e-01,  1.0023e-01,\n         -9.6662e-02, -3.5018e-02, -2.0563e-01, -1.1045e-01,  2.6684e-02],\n        [-1.9143e-01, -1.3482e-01, -1.7254e-01, -9.3345e-03,  1.6978e-01,\n         -6.2972e-02,  8.2206e-02,  4.3022e-02, -1.5541e-01,  1.2205e-01,\n         -1.0384e-01, -4.1892e-02, -3.5505e-02, -5.4791e-02,  1.1356e-01,\n         -1.8766e-01, -1.5998e-01,  2.0048e-01, -2.0430e-01,  9.3265e-02],\n        [-5.4062e-03, -1.0681e-01,  2.1815e-01, -1.5185e-01,  5.8259e-02,\n         -1.2613e-01, -8.7778e-02,  8.6161e-02, -1.7098e-01,  1.4457e-01,\n          1.8872e-02,  6.1717e-02,  8.8230e-02, -1.5069e-01,  9.9846e-02,\n         -4.7340e-02, -1.1381e-01,  2.7226e-03,  3.5851e-02,  1.4841e-01],\n        [ 2.2273e-01, -1.8447e-01,  1.0682e-01, -6.5353e-02,  1.8162e-03,\n          1.3285e-01, -1.9906e-01,  1.0331e-01, -1.9742e-01,  6.2655e-02,\n          1.3640e-01, -1.2473e-01, -1.9909e-01, -9.1118e-03,  6.2554e-02,\n         -1.5420e-01,  3.8090e-02,  1.6322e-01,  1.0047e-01,  2.2072e-02],\n        [-7.4224e-02,  9.1676e-02,  6.3468e-02, -1.9536e-01,  5.8602e-02,\n         -5.0490e-02,  7.6858e-02,  1.2038e-02,  1.5971e-01,  2.0608e-01,\n          1.2603e-01,  2.2973e-02, -6.8259e-02, -9.5946e-02, -2.0482e-01,\n          1.1253e-01, -1.5095e-01,  1.9007e-01, -3.4040e-03, -8.3152e-02],\n        [ 1.0719e-01, -1.9616e-01,  1.3440e-02, -2.0723e-01, -2.4704e-03,\n         -5.6282e-02,  1.3862e-02,  2.0744e-01, -2.0940e-01,  1.2498e-01,\n          1.7627e-01,  2.0479e-02, -1.4425e-01,  1.7643e-01, -2.1000e-01,\n         -1.3631e-01, -1.2092e-01, -1.3508e-01, -2.0515e-01,  1.6297e-01],\n        [-1.2060e-01,  6.0829e-02, -6.7266e-02, -2.1540e-01, -8.2167e-02,\n          1.3514e-01,  5.9855e-02, -1.5523e-01, -9.5631e-02, -8.4839e-02,\n          5.4010e-02, -1.0112e-02, -8.1682e-02,  1.7484e-01, -1.5508e-01,\n          1.7293e-01, -3.3841e-02,  1.4991e-01,  4.3596e-02, -1.9718e-01]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1156, -0.0549, -0.0046,  0.1337, -0.1484,  0.0444,  0.1593, -0.0948,\n        -0.0786, -0.1341, -0.1250, -0.0615,  0.1059, -0.0223,  0.1598,  0.0363],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1121,  0.0835,  0.0458,  0.0085,  0.0564, -0.1149,  0.1226, -0.0110,\n          0.0296,  0.0023,  0.0401,  0.0735, -0.0796, -0.1051,  0.0429,  0.0842,\n         -0.0366,  0.0768,  0.1252,  0.1183, -0.0610, -0.1562,  0.0003,  0.1749,\n         -0.1572, -0.0570, -0.1545,  0.0764, -0.0415, -0.1731,  0.0979,  0.0687],\n        [ 0.0463, -0.1628, -0.1505, -0.1757, -0.1298,  0.0624, -0.1310, -0.0372,\n         -0.1739, -0.1387, -0.0042, -0.1185, -0.0258,  0.0983,  0.1125,  0.1661,\n          0.0462, -0.0393,  0.0849,  0.1171,  0.0813,  0.1557,  0.0809,  0.1656,\n         -0.0960, -0.0826, -0.0725,  0.1651, -0.0588,  0.1615, -0.1257, -0.1645],\n        [ 0.1320, -0.1152, -0.1620,  0.0669, -0.0370,  0.0868,  0.0168, -0.0672,\n          0.0516, -0.1065,  0.0232,  0.1541, -0.1476, -0.0590,  0.0108,  0.0933,\n          0.0160,  0.0153,  0.1316, -0.1736,  0.1348,  0.0937, -0.0425, -0.0110,\n          0.0716, -0.1658, -0.0889, -0.1444, -0.1151, -0.1689,  0.0047,  0.0460],\n        [ 0.0182, -0.1404, -0.0215, -0.0741, -0.0221,  0.0353,  0.1341,  0.1581,\n         -0.0952, -0.1404,  0.0217, -0.0956,  0.1594,  0.1268, -0.1553, -0.0566,\n          0.1700, -0.0392, -0.0408, -0.0825,  0.0675,  0.0933, -0.0492, -0.0753,\n         -0.1764,  0.0977, -0.1356, -0.0435, -0.1023, -0.0765, -0.0832, -0.1089],\n        [-0.1041, -0.0736,  0.1647,  0.0477, -0.0014, -0.0086,  0.0618,  0.0543,\n          0.0845, -0.1439, -0.1416, -0.0965,  0.0900, -0.1509, -0.1733,  0.0359,\n          0.1465, -0.1147,  0.0808,  0.0642, -0.1476, -0.1241, -0.0325,  0.1445,\n          0.1737, -0.1713,  0.0136, -0.1640, -0.0399,  0.1090,  0.0456,  0.0907],\n        [ 0.0125,  0.0845, -0.1695, -0.1385,  0.0088, -0.0372,  0.0862, -0.0307,\n          0.0979,  0.0038, -0.0632, -0.0922, -0.0045, -0.1111,  0.0729, -0.0389,\n          0.1258, -0.1655,  0.1106, -0.0548, -0.1213, -0.1444, -0.1117,  0.0639,\n         -0.1115,  0.0823, -0.0794, -0.0370, -0.1678, -0.1524, -0.0134, -0.0130],\n        [-0.0414,  0.0831, -0.1535,  0.0178,  0.0477, -0.0537,  0.0950, -0.0243,\n         -0.0634,  0.1132,  0.0384,  0.0021, -0.0726,  0.0963,  0.0189,  0.1368,\n         -0.0321, -0.1404, -0.0094, -0.0244, -0.1215, -0.0508, -0.0928,  0.1276,\n         -0.0048, -0.1490, -0.0465, -0.0093, -0.1031, -0.1552,  0.0721,  0.1389],\n        [-0.1037, -0.0803, -0.1385, -0.0826, -0.0113,  0.1512, -0.0176,  0.0246,\n         -0.1171,  0.1037,  0.1626,  0.0013,  0.1438, -0.0133,  0.1287,  0.0886,\n          0.1098, -0.0706, -0.1074,  0.1216,  0.0984,  0.1227,  0.0861, -0.1621,\n          0.0540, -0.1281,  0.0718,  0.0141, -0.0084,  0.0874,  0.0180, -0.0612],\n        [-0.0184,  0.0109,  0.0213, -0.0164,  0.0475,  0.0322,  0.0210,  0.0071,\n         -0.0779,  0.1294, -0.0346, -0.1178, -0.1636,  0.0097, -0.1425, -0.0749,\n         -0.1730, -0.1554, -0.1648,  0.0905,  0.0179,  0.1468, -0.0959,  0.0021,\n          0.0888, -0.0863, -0.0854,  0.0611,  0.0418, -0.0241,  0.0185, -0.0502],\n        [ 0.1594,  0.1682, -0.0495,  0.0166,  0.0146, -0.0520, -0.0445, -0.0549,\n         -0.0418, -0.1268,  0.0529, -0.1504, -0.1493, -0.0812,  0.0642,  0.1273,\n          0.0017,  0.0049, -0.1284,  0.0835, -0.0589, -0.0449,  0.0839,  0.1549,\n         -0.0594, -0.1312, -0.0187, -0.1528,  0.1676, -0.1449,  0.0590,  0.0641],\n        [ 0.0919,  0.1090, -0.0412,  0.0405, -0.1351, -0.0868,  0.0688,  0.1022,\n          0.0202,  0.1382, -0.0817, -0.0422, -0.1544,  0.1327,  0.0505,  0.0974,\n          0.1763,  0.0493, -0.0779, -0.1547, -0.0256,  0.0139, -0.1052,  0.0572,\n         -0.1446, -0.0364, -0.0078, -0.1416,  0.1655, -0.0171,  0.0895,  0.0789],\n        [ 0.0536, -0.0919,  0.0902,  0.1709,  0.0791, -0.0851,  0.0866, -0.1719,\n         -0.0134, -0.0797, -0.0375, -0.1453,  0.0548,  0.0513, -0.0928,  0.0869,\n         -0.1599, -0.1416,  0.0643, -0.0381,  0.1721,  0.1009, -0.1196, -0.0584,\n         -0.1682, -0.1699, -0.0181, -0.1374,  0.0008,  0.0453,  0.0907,  0.1096],\n        [-0.0705, -0.0747, -0.1359, -0.0803,  0.0105,  0.0865,  0.1640,  0.1228,\n          0.1064,  0.0509, -0.1179, -0.0123,  0.0209, -0.0779,  0.0984, -0.1384,\n          0.0674, -0.0163,  0.0722, -0.0318,  0.0128,  0.0517,  0.0579, -0.1061,\n         -0.1151, -0.1460, -0.0578, -0.1577, -0.1378,  0.0658, -0.0685, -0.0946],\n        [ 0.1156,  0.0669,  0.1403, -0.0917,  0.0189,  0.1451,  0.0165,  0.0290,\n         -0.0968,  0.0359, -0.0857,  0.1269,  0.0253,  0.0281,  0.0098,  0.1408,\n         -0.0718,  0.1499,  0.0161, -0.0172,  0.1095, -0.0694,  0.1726, -0.1352,\n         -0.1010, -0.1615, -0.0646,  0.1225, -0.1464, -0.0709, -0.1037, -0.0067],\n        [-0.0232,  0.0619,  0.1007, -0.0698,  0.0119, -0.0377,  0.0467,  0.0523,\n          0.0514,  0.1679, -0.0312,  0.0548,  0.0667,  0.0070,  0.1111,  0.1161,\n          0.0138, -0.0484,  0.1177,  0.0256, -0.0721, -0.1607,  0.0766, -0.0173,\n         -0.0193,  0.1545,  0.0105, -0.0335, -0.0405,  0.0709,  0.1445, -0.1589],\n        [-0.1125, -0.0960,  0.0327, -0.1218,  0.0431, -0.1688,  0.0356, -0.1039,\n          0.0486, -0.0063,  0.0458, -0.1106, -0.1518,  0.1087,  0.0309,  0.0693,\n          0.0224,  0.0168,  0.0166, -0.0095, -0.1065, -0.0635, -0.0574,  0.0741,\n         -0.0748,  0.1078,  0.0012,  0.0918,  0.0498, -0.0370,  0.1007, -0.0691]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2028,  0.2482, -0.1171,  0.2342,  0.0516,  0.0482, -0.1813, -0.2087],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1743,  0.1771,  0.1405,  0.0186,  0.2444, -0.1264,  0.1043,  0.1317,\n         -0.0867, -0.1353, -0.1349,  0.1070,  0.2156,  0.2289, -0.1951,  0.1824],\n        [-0.0277, -0.1001, -0.0707,  0.1581,  0.0073, -0.2090, -0.1459, -0.2450,\n         -0.1849, -0.2372, -0.0306, -0.2201,  0.2300, -0.0274,  0.0799, -0.1399],\n        [ 0.1545, -0.2360, -0.0287, -0.1932, -0.1776, -0.1124,  0.2076,  0.2276,\n          0.1537, -0.1750, -0.0743,  0.0331,  0.0202, -0.0508, -0.2068,  0.0223],\n        [ 0.0417,  0.1710, -0.2215, -0.2185,  0.1016,  0.0008, -0.0762,  0.2244,\n         -0.2294, -0.0217, -0.1236,  0.0874,  0.2243,  0.1062, -0.1560,  0.0840],\n        [-0.1266, -0.0639,  0.1397, -0.1743,  0.2488, -0.0782,  0.1759, -0.1330,\n         -0.1009, -0.0323,  0.0554, -0.0699, -0.2021, -0.1927,  0.0337, -0.1034],\n        [-0.2450,  0.1068,  0.2307,  0.0438,  0.2490, -0.1239,  0.0402,  0.0711,\n         -0.0791, -0.1729, -0.1055,  0.0911, -0.2177,  0.1919, -0.1933,  0.0018],\n        [-0.2301,  0.2061,  0.0857, -0.0109, -0.0365,  0.2241, -0.1689, -0.1651,\n          0.0620,  0.1024, -0.1465, -0.0398, -0.0528, -0.2147, -0.0872, -0.0004],\n        [-0.2455, -0.2244,  0.1154,  0.2407,  0.1425,  0.0540,  0.1869,  0.1403,\n          0.0003,  0.1861, -0.0028, -0.1889, -0.0412,  0.0653, -0.1239,  0.0972]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2619], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.3176, -0.3036, -0.2845,  0.1326, -0.0586,  0.0184,  0.0786, -0.0183]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    20,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	20,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "flatten_obs_dim":	20,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 5.5267e-02, -1.7303e-01, -2.1576e-01,  6.0218e-02, -1.5345e-01,\n         -1.8114e-01,  4.9536e-02, -1.6103e-01, -1.0960e-01,  5.3675e-02,\n          1.6870e-01,  5.8408e-02,  9.2141e-02,  7.4422e-02, -1.3562e-02,\n         -4.5921e-02, -1.8111e-01, -1.6439e-02,  1.9301e-01,  1.5707e-01],\n        [-1.8155e-01,  2.1039e-02,  8.3108e-02,  1.5618e-01, -1.2129e-02,\n         -1.9842e-01, -1.4206e-01,  2.1091e-01,  1.4200e-02,  4.9804e-02,\n         -1.8424e-01, -4.6667e-02,  1.8459e-01,  1.7484e-02,  1.4912e-01,\n          1.0904e-01,  1.4655e-01,  1.5807e-01, -1.0465e-01, -2.8946e-02],\n        [-1.1333e-01,  7.4914e-02,  1.9102e-01,  7.4451e-02, -2.1533e-02,\n          2.0965e-01,  1.1480e-01,  7.0719e-02,  4.7431e-02, -9.9777e-02,\n         -1.2020e-01, -5.3719e-02,  1.8841e-01,  1.4011e-01,  4.2555e-02,\n          1.2183e-01, -1.5608e-01,  2.0002e-01, -1.7329e-01, -1.1917e-01],\n        [ 1.5272e-01,  1.0771e-01, -5.9726e-02,  2.0605e-01,  1.2976e-01,\n          1.9098e-01, -1.8564e-01,  1.6920e-02, -2.0452e-01, -1.6602e-01,\n         -1.9594e-01,  5.6088e-03, -1.5362e-01, -9.4945e-02,  7.3002e-03,\n          1.5459e-01,  1.7260e-01, -1.8214e-01, -2.1971e-02,  1.2736e-01],\n        [-1.6331e-01,  2.2323e-01,  7.3249e-02,  2.0944e-01,  8.0574e-03,\n          1.1932e-02, -4.8523e-02, -2.1828e-01, -1.9779e-01, -9.2720e-02,\n          1.7242e-01, -1.7146e-01, -9.3842e-02,  1.5824e-01, -1.0137e-01,\n          1.1496e-01,  3.9435e-02,  1.1756e-01, -1.4277e-01,  1.2904e-01],\n        [-1.4530e-01, -3.2549e-02, -1.8819e-01, -2.0899e-01,  2.0278e-01,\n         -1.6171e-01, -1.0848e-01,  5.4614e-02,  1.0643e-01, -1.4738e-01,\n         -7.5677e-02,  7.0229e-02,  1.0547e-01, -2.1148e-01, -1.3339e-01,\n         -9.4762e-02, -1.1096e-01, -2.5726e-02,  1.4232e-01,  1.2405e-01],\n        [-7.6356e-02, -1.8865e-01,  1.1855e-01,  1.2859e-01, -8.4290e-02,\n         -1.4343e-01, -2.1436e-01, -2.1770e-01,  6.2202e-02,  1.1850e-01,\n          9.6700e-02,  1.3100e-01,  8.4339e-03, -1.1521e-01,  2.6772e-02,\n         -1.5410e-01,  5.3874e-02, -6.3423e-02,  2.0120e-01,  2.2261e-01],\n        [ 5.9137e-02, -1.9891e-01, -2.0386e-01, -3.2198e-02, -3.5044e-02,\n         -1.2315e-01, -7.9270e-02,  2.1967e-01,  5.3951e-02,  3.2146e-02,\n          1.1973e-01, -2.0866e-01,  1.4139e-01, -5.3647e-02, -9.1106e-02,\n         -1.5575e-01,  1.5372e-01, -1.6512e-01, -1.4497e-01, -1.1233e-01],\n        [-4.8287e-02, -1.4132e-01,  2.2148e-01,  9.7860e-02, -1.7765e-01,\n          5.9516e-02,  2.1498e-01, -4.7302e-02, -3.0519e-02,  4.0666e-02,\n         -6.9045e-02,  2.0976e-01, -7.6270e-02, -1.6177e-01, -7.9196e-02,\n          1.7363e-01,  7.0087e-02,  1.9229e-01, -5.7248e-02,  4.3802e-02],\n        [-1.1329e-01, -5.4254e-02, -9.7939e-02, -1.2541e-01, -2.1181e-01,\n         -1.2046e-01,  5.2129e-02, -9.0551e-02, -1.3979e-01, -4.7024e-02,\n         -9.8070e-02, -1.4947e-01, -1.7024e-01, -9.9303e-02, -8.5563e-02,\n         -7.2683e-02, -2.5190e-02,  2.9870e-02, -8.9132e-02,  1.7174e-01],\n        [-3.5932e-02, -1.5139e-02, -1.4559e-01,  7.7083e-02,  6.5026e-02,\n          4.6979e-02,  7.6048e-02,  1.9332e-01,  1.8807e-01, -1.5627e-01,\n          1.5341e-02, -1.2334e-01,  2.2749e-02, -1.2115e-01,  2.0453e-01,\n         -8.9073e-02,  1.7982e-01, -1.4191e-01,  5.3175e-02, -1.4594e-02],\n        [-6.3296e-02,  1.9283e-01,  4.6559e-02,  2.0813e-01, -1.8143e-01,\n         -1.5591e-01, -1.4875e-02, -8.5406e-04,  1.6498e-01, -3.5389e-02,\n          1.3604e-01,  9.9606e-02, -7.2365e-02, -1.7620e-01, -1.4707e-01,\n         -1.3266e-01,  1.2409e-01,  1.2311e-01, -1.9798e-01,  2.1413e-01],\n        [-1.4951e-01, -1.5978e-01,  1.4975e-02,  1.1787e-01,  1.3680e-01,\n          7.6693e-02,  1.1504e-01, -1.1799e-01, -2.5791e-02, -2.0235e-01,\n          1.4007e-01, -1.3816e-01, -3.6378e-02, -1.9059e-01,  1.9211e-02,\n          8.5462e-02,  1.2248e-01, -8.8829e-02,  1.7288e-02, -1.5166e-01],\n        [-7.5918e-02,  2.2064e-01, -1.2276e-01,  5.4821e-02,  4.4592e-02,\n         -5.0325e-02, -2.4086e-02, -2.0335e-01,  5.4444e-02, -2.6127e-02,\n          4.4417e-03,  1.4190e-01,  1.5953e-01,  2.2300e-01, -1.6316e-01,\n         -1.7194e-01,  1.9989e-01,  8.9323e-02, -1.1300e-01,  1.9675e-01],\n        [-7.8978e-02,  2.0412e-01, -5.0972e-02, -6.7121e-02, -1.9404e-02,\n          2.0187e-01,  1.9799e-01,  2.1492e-01, -4.5149e-02, -1.4816e-01,\n          1.5519e-04,  1.2926e-02, -4.6442e-02,  4.7292e-02, -1.7640e-01,\n          2.1550e-01,  1.9707e-01,  8.0685e-02, -4.6045e-02, -7.8533e-02],\n        [ 1.9195e-01, -1.9068e-01,  1.8627e-01,  1.2028e-01, -8.9450e-02,\n         -5.3965e-02, -1.0016e-01,  2.8515e-02, -1.3317e-01,  7.4732e-02,\n         -1.4548e-01, -6.9679e-02, -1.5696e-01, -1.3589e-01, -1.2951e-01,\n          1.9526e-01,  2.0588e-01,  1.4706e-01,  6.4582e-02,  1.9451e-01],\n        [ 6.6832e-02, -9.4251e-02, -2.5196e-02, -4.5957e-02,  1.8874e-02,\n          2.0473e-01, -1.6878e-01, -2.0108e-01,  1.7847e-01,  4.6458e-02,\n          2.0337e-01,  4.1982e-03, -5.7218e-02,  1.8576e-01,  4.8038e-02,\n         -1.8110e-01,  1.3224e-01,  1.6630e-01, -3.3067e-02,  1.2179e-01],\n        [ 6.0869e-02,  9.1297e-02,  8.1935e-02,  3.5501e-02,  3.0647e-02,\n         -1.0691e-01, -1.7199e-01, -1.3351e-01,  1.9711e-01, -7.2035e-02,\n          1.2301e-01, -6.3901e-02,  2.8550e-02,  3.5556e-02, -8.6542e-02,\n          2.3137e-02,  6.5264e-02, -1.9047e-01, -3.2110e-02, -1.6018e-01],\n        [-9.3287e-02, -1.9310e-01, -1.1080e-01,  1.0437e-01,  1.2839e-01,\n         -1.4475e-01,  1.9623e-02, -1.0140e-02,  2.0279e-01,  7.1762e-02,\n         -6.9594e-02,  2.1642e-02,  9.6382e-03, -1.8000e-02,  6.5178e-02,\n          1.6378e-01,  6.3838e-02, -2.1887e-01, -2.7342e-02, -7.6176e-02],\n        [ 4.0834e-02,  2.7968e-02, -1.0882e-01,  1.6029e-01,  7.1264e-02,\n         -4.2145e-02, -1.5187e-01, -4.1434e-02,  1.5710e-01, -1.6682e-01,\n         -1.9830e-03, -2.0798e-01,  7.1502e-02,  6.2040e-02,  8.7428e-02,\n          6.5215e-02,  2.9402e-02,  1.5965e-01, -1.5995e-01,  2.8118e-02],\n        [-1.4008e-03, -6.5407e-02, -1.0320e-01, -8.5696e-02, -3.4920e-02,\n          7.7006e-02,  4.0675e-02,  1.2491e-01,  1.9267e-01,  2.1198e-01,\n          4.1249e-02,  1.5828e-01,  1.5095e-01, -8.1817e-02,  2.6775e-02,\n          2.0774e-01, -3.8536e-02,  2.2036e-01, -1.6191e-01, -1.6528e-01],\n        [ 2.0710e-01,  4.5536e-02, -4.7888e-02,  5.8512e-02,  5.3110e-02,\n         -1.4756e-01, -1.4395e-01,  4.1146e-02, -1.3828e-02,  1.3951e-01,\n          2.2252e-01,  1.1585e-01, -2.1479e-02, -5.4607e-02,  1.6226e-01,\n          1.4227e-01,  1.2835e-01, -7.4818e-02,  6.4686e-02, -1.3049e-01],\n        [-8.3883e-02, -6.3258e-02,  1.0039e-01, -3.1996e-02, -7.9539e-02,\n          1.3084e-01, -2.1547e-01,  1.2716e-01, -1.0906e-01, -1.0904e-01,\n          9.2409e-02, -1.5850e-01,  1.1622e-01, -1.4001e-01,  7.4786e-02,\n         -3.4712e-02,  2.1268e-01, -7.3590e-02, -1.5693e-01,  4.3073e-02],\n        [ 1.8778e-01, -4.3216e-02,  2.2148e-01, -8.4067e-02,  1.4216e-01,\n         -1.1626e-01,  1.1079e-01, -1.1414e-01, -7.4622e-02, -1.4735e-01,\n          1.3659e-01, -1.5925e-01,  4.0595e-02, -7.2866e-02, -1.2160e-01,\n          8.8379e-02,  9.3844e-02, -9.2431e-02,  2.0334e-01,  1.6857e-01],\n        [ 1.7599e-01,  1.4102e-01, -3.6700e-02, -1.9051e-01,  1.9789e-01,\n          1.7692e-01, -1.9339e-02,  1.9960e-01, -1.7196e-01,  2.1887e-01,\n          7.2245e-02, -3.7244e-02,  1.5929e-01, -2.6588e-02,  7.3777e-02,\n         -5.8589e-02, -1.6331e-01,  1.2027e-03, -1.3607e-01, -1.9313e-01],\n        [ 1.4989e-04,  5.5824e-02,  1.4032e-01, -1.8783e-01,  1.3093e-01,\n          5.2002e-02, -9.7200e-02,  1.9651e-02, -1.8469e-01,  1.8478e-01,\n         -1.6005e-01, -1.3550e-01,  1.2472e-01,  6.6999e-02, -5.1167e-03,\n          4.3351e-02, -1.4552e-01,  1.3814e-01,  8.5914e-02,  2.1737e-01],\n        [ 5.7420e-02, -1.5155e-01, -2.5554e-02,  1.8667e-01,  1.8066e-01,\n          1.0391e-01,  1.2966e-01, -1.8941e-01, -1.5047e-01, -1.3217e-01,\n          1.1492e-01, -4.2383e-02,  1.2393e-01,  1.6456e-01, -1.3576e-01,\n         -9.3037e-02, -3.2847e-02,  1.9328e-01,  1.2542e-01,  9.4211e-02],\n        [-1.6553e-01, -2.1955e-01, -1.2246e-01, -2.1772e-01,  1.5944e-01,\n         -3.9975e-02, -1.6425e-01, -1.0955e-01,  7.3514e-02, -1.2142e-01,\n         -1.4497e-01, -8.5951e-02, -6.9088e-02,  1.0545e-02, -8.9620e-02,\n          1.2235e-01,  2.1746e-01,  1.2856e-01, -8.7728e-02,  2.4271e-02],\n        [ 1.9082e-01, -1.5589e-01,  2.0872e-01, -1.7810e-01,  2.1348e-01,\n          6.1692e-02,  1.4525e-01,  1.0363e-01, -2.1940e-01, -9.3518e-02,\n         -6.1640e-02,  1.5729e-01, -6.6232e-02,  2.0364e-01, -6.5639e-02,\n         -9.3859e-02, -1.6304e-01,  1.0067e-01, -2.2002e-01,  8.6729e-02],\n        [ 2.1904e-01,  4.8208e-02,  1.1317e-01,  1.2310e-01,  2.1696e-01,\n         -1.0825e-01,  1.2156e-01, -9.9961e-02,  1.8760e-01,  3.9259e-02,\n         -1.0224e-02,  1.3446e-01,  1.6654e-01,  2.3861e-02, -2.7375e-03,\n         -7.2344e-02,  1.1889e-01,  5.6811e-02, -1.3208e-02, -2.4001e-02],\n        [ 2.2307e-01,  2.1776e-01,  7.0485e-02,  2.1769e-01, -2.1253e-01,\n         -1.9486e-01, -1.2127e-01, -1.5184e-01, -1.2374e-02,  1.8970e-01,\n          6.1813e-02, -1.5485e-01, -2.1881e-01,  2.9705e-02,  1.8783e-01,\n         -1.1267e-01,  2.8200e-02,  1.3045e-01, -2.0547e-01, -2.2098e-01],\n        [-2.1549e-01, -2.9176e-02,  1.1732e-01, -3.7070e-02, -9.8225e-02,\n         -1.7196e-02,  1.2878e-01,  4.7090e-02,  1.4542e-01, -8.7825e-02,\n         -1.5233e-01,  2.6747e-03,  1.2594e-02, -1.9281e-02, -9.4225e-02,\n         -1.1079e-01, -2.1839e-01, -2.0814e-01, -4.3257e-02,  1.4905e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1053,  0.1416, -0.1512, -0.1164, -0.0994, -0.1400, -0.2175, -0.1227,\n         0.0748, -0.1948,  0.0455, -0.0916, -0.1889,  0.1639, -0.2030,  0.1912,\n        -0.2173,  0.0788, -0.0466,  0.2066,  0.1947,  0.0048,  0.0142,  0.0128,\n         0.0250, -0.0217,  0.1262,  0.0756,  0.0244,  0.1515,  0.1361,  0.1512],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-5.0285e-02,  1.0222e-01,  1.3862e-01,  1.9889e-02,  2.6543e-02,\n          6.6823e-02,  4.7170e-02, -1.3686e-01,  1.1087e-01,  1.3269e-01,\n         -4.8459e-03, -1.4784e-01,  9.5230e-02,  1.5495e-01,  3.4856e-02,\n         -3.6443e-02, -3.2487e-02,  1.4987e-01,  6.5387e-02, -1.6060e-01,\n         -1.6290e-01,  9.6289e-02, -1.1561e-01,  1.2603e-01, -8.9283e-02,\n          1.2424e-01,  1.1761e-01, -1.0656e-01, -1.5648e-01,  7.5247e-02,\n          1.8698e-02, -1.7017e-01],\n        [ 1.6307e-01,  2.4278e-02,  2.1210e-02, -1.5044e-01,  1.7139e-02,\n         -1.3955e-01, -9.5056e-02, -1.0294e-01,  3.6492e-02,  1.9705e-03,\n          1.3740e-01,  7.4059e-02,  1.6145e-01, -1.5354e-01, -1.4945e-01,\n          1.7289e-01, -3.9414e-04,  1.4875e-01, -1.1153e-01,  1.7112e-01,\n          8.0770e-02, -1.4081e-01,  1.7603e-01,  1.6050e-01, -1.0157e-01,\n         -1.0778e-01, -1.5009e-01, -1.6331e-01, -1.2336e-01, -4.0691e-02,\n          9.0213e-02,  1.3208e-01],\n        [ 6.9992e-02,  1.1494e-01, -1.6797e-03, -4.8001e-02,  6.3002e-02,\n          1.6230e-01, -1.6860e-01,  1.8441e-02, -1.7627e-01, -4.2524e-02,\n         -1.6360e-01, -9.8632e-02, -1.4619e-01,  2.4390e-02,  2.4246e-02,\n          7.5787e-02,  7.1187e-02,  1.5364e-01, -6.8570e-02, -1.2082e-01,\n          3.3705e-02,  8.7668e-02, -1.7530e-01,  1.0102e-01, -1.6008e-01,\n          1.6179e-01,  1.2319e-01, -1.5924e-01, -5.4598e-03, -7.8936e-02,\n          4.5979e-02, -2.3530e-02],\n        [-1.1263e-02, -3.0962e-02, -2.0698e-02,  6.9257e-02, -6.0464e-02,\n         -1.1001e-01, -1.5976e-01, -9.8052e-02,  1.0510e-01,  1.5882e-01,\n         -1.3791e-01, -9.0039e-02,  1.3798e-01, -1.1453e-01,  1.3003e-01,\n          5.8689e-02,  1.3607e-01, -1.0305e-01,  1.5899e-01, -8.6266e-02,\n          1.5338e-01, -1.0470e-01,  1.5267e-01,  1.5968e-01, -5.3884e-02,\n          1.1334e-01,  1.1710e-01,  1.1895e-01, -4.2675e-02, -1.3870e-01,\n          1.8192e-02,  1.4155e-01],\n        [-1.4982e-01,  1.3694e-01,  4.9110e-02, -7.9742e-02, -1.1521e-01,\n         -6.1401e-02,  4.3865e-02,  2.1272e-02,  1.8739e-02, -1.6612e-01,\n         -1.6324e-01,  1.1438e-01, -1.0528e-01, -1.4343e-01,  1.6694e-01,\n         -3.4168e-03, -6.7632e-02,  4.0123e-02,  6.0964e-02,  2.2330e-02,\n         -1.4699e-01, -1.1183e-01,  3.9772e-02, -1.1196e-01, -1.5371e-01,\n         -3.9582e-02, -5.7422e-02,  1.3649e-01, -9.3838e-02, -1.5196e-01,\n          1.0716e-01, -1.5181e-01],\n        [-1.6718e-02, -1.6574e-01,  1.7481e-01,  9.7849e-02,  1.7467e-01,\n          1.4081e-01, -3.8981e-02, -2.9280e-02,  3.0648e-02, -3.8814e-02,\n         -1.5583e-01,  4.7842e-02, -1.2693e-01,  2.7507e-03, -1.7450e-01,\n         -2.2057e-02,  7.6763e-03, -1.4196e-02,  1.6396e-02, -9.0369e-02,\n         -7.3178e-02,  1.1214e-01,  9.1558e-02, -2.0755e-02, -2.2785e-03,\n         -7.5885e-02, -1.7380e-01, -6.2102e-02, -3.0140e-02, -1.0956e-01,\n         -6.2758e-02, -1.0077e-01],\n        [ 1.2213e-01, -1.3445e-01,  7.4224e-02,  1.4117e-01, -2.7749e-02,\n         -3.7470e-03, -1.3167e-02, -8.6641e-02, -6.0167e-02, -1.7843e-02,\n          5.6951e-02,  1.5343e-01,  8.0096e-02,  1.3512e-01,  5.1371e-02,\n         -3.2366e-02,  4.8693e-02, -1.2111e-01,  1.7019e-01,  1.6649e-01,\n          1.3873e-01, -1.6167e-01, -1.4018e-01, -1.3726e-01, -9.7715e-02,\n          1.6149e-01, -5.8588e-02, -6.0451e-02,  1.7386e-01, -1.6761e-01,\n         -1.7207e-01,  1.6309e-01],\n        [-1.0634e-01,  1.2015e-01, -1.2485e-01, -1.7080e-01, -7.1667e-03,\n          2.3045e-02,  1.4839e-01, -1.0279e-01, -1.0404e-02, -6.8262e-02,\n         -1.5674e-02, -6.7195e-02,  8.9449e-02, -1.3774e-01,  1.2639e-01,\n         -1.0799e-01, -9.2493e-02, -1.4866e-01, -5.4040e-02,  8.9764e-02,\n          2.4676e-02,  1.2815e-01, -1.9703e-02,  1.4170e-01,  3.4292e-03,\n          4.1147e-02, -2.7103e-02, -8.5184e-02, -1.0683e-01,  3.5000e-02,\n         -6.8270e-02, -1.5402e-01],\n        [-1.6289e-01, -2.9784e-02,  3.0747e-02, -7.8499e-02,  1.5561e-01,\n         -1.2583e-01,  1.2188e-01,  6.2353e-02, -2.9169e-02,  2.5066e-02,\n         -8.6941e-02, -3.9736e-02,  1.5697e-01,  1.5086e-01, -1.4523e-01,\n         -1.1512e-04,  5.1980e-02, -6.8285e-02, -8.9923e-03,  6.4433e-02,\n          4.8054e-02,  6.4649e-02, -2.3376e-02,  1.5374e-01,  1.4365e-01,\n          5.7434e-03, -9.4998e-02, -1.4178e-01,  2.9452e-02, -9.0839e-02,\n         -4.6380e-02,  3.9567e-02],\n        [-4.4306e-02,  4.9426e-02, -1.3332e-01, -1.2979e-02, -8.5998e-02,\n          7.4346e-02, -1.5267e-01,  1.7022e-01, -1.5001e-01,  1.5986e-01,\n          1.4351e-01, -1.0909e-01, -1.7054e-01,  4.6059e-02,  8.4485e-02,\n          5.8021e-02,  4.0942e-02,  1.6012e-01,  9.7137e-02, -8.7295e-02,\n         -1.5669e-01,  1.1762e-01, -2.5774e-02,  1.2869e-02, -7.3865e-02,\n         -7.6283e-02, -1.4185e-02,  1.4820e-01,  1.2414e-01, -1.1667e-01,\n          1.7158e-01, -1.0219e-01],\n        [ 7.4473e-02,  1.4083e-01, -1.4227e-01,  4.5352e-02,  1.0152e-01,\n          8.8256e-02,  1.7782e-03,  1.4609e-01, -1.4330e-01,  1.1555e-01,\n          3.5637e-03, -1.4855e-01, -1.3805e-01, -7.9800e-02,  7.9688e-02,\n         -1.3278e-02, -1.0698e-01,  2.3043e-02,  6.0500e-02, -2.4844e-02,\n          1.6268e-01,  9.9827e-02,  1.7575e-01, -1.5771e-01, -6.9149e-03,\n          1.2512e-01,  1.7596e-02, -9.9286e-02, -1.2842e-01,  1.1917e-02,\n         -1.7478e-01, -1.4079e-01],\n        [ 2.1932e-02,  1.1914e-02, -1.2180e-01, -1.1532e-01,  5.4106e-02,\n          1.1652e-01,  1.6835e-01,  7.8796e-03,  5.4527e-02,  1.2646e-01,\n         -1.0591e-01,  4.3355e-02, -1.4009e-02, -1.1636e-01, -8.9866e-02,\n         -1.6352e-01, -1.5214e-01,  1.3103e-01,  2.1401e-02,  1.2994e-01,\n         -1.0905e-01,  2.9889e-03,  1.6344e-01, -2.6959e-02, -7.6056e-02,\n         -5.0592e-03,  1.2794e-01, -1.2743e-01,  8.5905e-03,  6.6874e-02,\n          1.7544e-01, -9.7170e-02],\n        [-9.4687e-02,  1.2402e-01,  1.1764e-01, -2.1338e-02, -1.6666e-01,\n          1.4158e-01, -3.1226e-02,  1.5455e-01,  1.6290e-01,  1.3070e-01,\n          6.7495e-02,  1.7196e-01, -3.3637e-02, -3.3745e-02,  1.5913e-01,\n         -1.6042e-01, -4.0084e-03, -6.2763e-03,  7.5633e-04,  8.0478e-02,\n         -8.3352e-02,  3.0318e-02,  8.9957e-02,  1.7548e-01,  1.5022e-01,\n          4.7574e-02,  1.4010e-01,  1.2268e-01,  1.3335e-01, -1.2473e-01,\n         -5.8418e-02,  3.7481e-02],\n        [ 1.7260e-01,  1.6160e-01, -2.2786e-02, -2.8665e-02,  6.9883e-02,\n          9.7747e-02,  7.9469e-02,  2.3475e-02,  1.2602e-02, -7.2371e-02,\n          1.4637e-01,  1.1144e-01, -1.4672e-01,  1.3615e-01, -1.1668e-01,\n         -7.2946e-02, -3.3145e-02,  3.3453e-02,  1.2914e-01,  1.3712e-01,\n          8.6696e-02,  1.1007e-01, -7.6355e-02, -1.1213e-01,  1.4027e-01,\n          9.9812e-02, -1.4481e-01, -4.4815e-02,  1.1790e-01, -5.2516e-03,\n          1.0666e-01,  1.5226e-01],\n        [ 1.5314e-01,  1.0455e-01,  1.4417e-01,  3.4085e-03,  1.6426e-01,\n          5.0967e-02, -1.7491e-01, -6.5988e-02,  1.2102e-01, -1.6495e-01,\n         -4.3194e-02,  1.4829e-01, -1.4021e-01, -6.9545e-02,  1.6541e-01,\n          6.2094e-02, -1.2183e-02,  9.2808e-02, -3.1978e-02, -1.4971e-01,\n         -2.6468e-03,  3.7871e-02, -5.4899e-02,  1.2266e-01,  7.8228e-02,\n         -2.5470e-03, -1.7217e-01,  1.7035e-01,  7.1920e-02, -1.2398e-01,\n         -4.7369e-02,  3.2229e-02],\n        [ 1.7205e-01,  1.1947e-01, -9.4582e-02, -1.7095e-01, -7.3986e-02,\n          1.2981e-01, -2.7304e-02,  6.4234e-02,  1.4315e-01, -1.2079e-01,\n          1.1721e-01, -7.7797e-02, -1.6862e-01,  2.4253e-03, -1.4185e-01,\n         -8.7302e-02,  9.7146e-02, -9.6363e-02, -7.7150e-02, -1.0158e-01,\n         -1.0922e-01,  2.9787e-02,  1.4823e-01,  1.5295e-01,  2.6932e-02,\n         -1.3655e-01,  1.7077e-01, -1.8744e-02,  5.1501e-02, -1.2330e-01,\n          8.5743e-02,  1.2731e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1082, -0.1304, -0.1285, -0.1455,  0.1270, -0.0564,  0.0919,  0.0105,\n         0.0017,  0.1311,  0.0328,  0.0439, -0.1595,  0.1257, -0.1457, -0.1710],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2042,  0.0544,  0.1644, -0.1555, -0.1639,  0.2324, -0.0193, -0.1559,\n          0.0786, -0.0084, -0.1006, -0.0492, -0.2039,  0.1630, -0.2195,  0.1807],\n        [ 0.0003, -0.1655,  0.1560,  0.2312,  0.2162, -0.0935,  0.1947, -0.0810,\n          0.2481,  0.2391, -0.1801,  0.1618,  0.0589,  0.1963, -0.1608,  0.2133],\n        [-0.0387,  0.1438, -0.1723, -0.0933,  0.1589, -0.0227, -0.2208, -0.0142,\n          0.0739, -0.0949, -0.1820,  0.1973, -0.0672,  0.0812,  0.0732,  0.2398],\n        [ 0.2137,  0.0880,  0.0464, -0.0791, -0.1192,  0.2038, -0.1335,  0.2212,\n          0.2396,  0.1365,  0.0057,  0.1606, -0.1342, -0.2066, -0.0742,  0.0883],\n        [-0.0946,  0.2202,  0.2340, -0.1459,  0.0097,  0.1194, -0.1926,  0.1086,\n         -0.1310,  0.2200, -0.0799,  0.0046, -0.2277,  0.0999, -0.0788, -0.0365],\n        [-0.1823, -0.2161, -0.0012,  0.0029, -0.1161,  0.1467, -0.1208,  0.2271,\n         -0.1755, -0.1330, -0.0208,  0.0187,  0.0771, -0.1446,  0.0695,  0.0982],\n        [-0.1430,  0.0255,  0.2057, -0.1799, -0.0333, -0.1585, -0.2396, -0.1088,\n         -0.1169,  0.0606,  0.2303, -0.1445, -0.0779,  0.0140, -0.1663,  0.1539],\n        [-0.0316,  0.1142, -0.1325, -0.0265,  0.0725, -0.0839, -0.2068, -0.1706,\n          0.0714,  0.1164, -0.1012, -0.2457, -0.1949,  0.0269,  0.0566,  0.1532]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0073,  0.0321,  0.2310, -0.0749,  0.0697, -0.0038, -0.2482, -0.1971],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0416,  0.2857, -0.0188, -0.1382,  0.0445,  0.0411,  0.2666,  0.0044],\n        [-0.3319, -0.0916,  0.3417, -0.2715, -0.2914, -0.2109,  0.0431, -0.2358],\n        [-0.2079,  0.2404, -0.0149, -0.1984,  0.1397, -0.2057,  0.1379,  0.1930],\n        [-0.1073,  0.2216, -0.2006, -0.1108,  0.0738,  0.1071,  0.2276, -0.1907]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1584, -0.1396, -0.0748, -0.1411], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x7b6176aeef80>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	50000,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	40,
            "_train_v_iters":	40,
            "_traj_per_epoch":	5,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 9.8678e-02, -1.6115e-01, -1.6383e-01,  1.3449e-01,  6.7232e-02,\n          7.5245e-02, -5.8193e-02, -1.9065e-01,  5.5048e-02, -8.5745e-02,\n          2.1311e-01, -1.3375e-01, -1.2955e-01, -2.1692e-01,  2.1873e-02,\n          2.0478e-01, -2.6995e-02, -1.1627e-01,  1.5205e-01, -8.9993e-02],\n        [-2.1695e-01,  1.0575e-01,  1.6679e-01,  1.3863e-01, -1.9284e-01,\n         -1.8752e-01, -1.5435e-01, -8.2458e-02,  2.9961e-02, -1.3166e-01,\n          1.3366e-01,  2.0334e-01,  3.8012e-02,  2.0461e-01,  1.9073e-01,\n          2.1817e-01,  1.0879e-01,  1.5894e-01, -9.3625e-02, -1.4977e-01],\n        [ 2.1590e-01, -1.1887e-01, -1.5117e-01,  2.1203e-01,  1.3664e-01,\n         -9.4132e-02, -1.4156e-01, -3.8164e-02, -1.2170e-01,  6.8680e-02,\n          1.5170e-01,  2.5074e-02, -5.4714e-02,  4.8998e-02,  1.3129e-01,\n          4.3165e-02, -1.5042e-01,  4.0677e-02,  1.8953e-01, -9.7787e-02],\n        [ 5.5889e-02, -2.0747e-01, -3.3571e-02, -1.7239e-01,  8.2289e-02,\n          3.9194e-02,  2.1398e-02, -1.0293e-01, -5.9949e-02,  1.2533e-01,\n         -3.2601e-02,  6.9660e-02, -1.3426e-01, -1.2145e-01,  7.8573e-02,\n         -1.7827e-01, -1.7620e-03, -2.0574e-01,  1.9659e-01,  2.0175e-01],\n        [ 1.7386e-01, -1.6430e-02,  5.2488e-03,  9.5193e-02, -3.9424e-02,\n         -1.1541e-01, -1.6949e-01, -9.9811e-02,  1.0641e-01,  1.2540e-01,\n         -6.1180e-02, -1.2442e-01,  8.0041e-02,  6.3566e-02,  9.0358e-02,\n          6.3770e-02,  2.0496e-01, -2.0106e-01, -1.2887e-01,  2.3077e-02],\n        [-1.2101e-01,  8.4866e-02,  7.4008e-02,  1.4942e-01, -1.3976e-01,\n          2.8017e-02, -2.0414e-01,  6.3857e-03, -2.0763e-01, -2.7369e-02,\n         -3.7956e-02, -9.6651e-02,  1.4107e-01, -7.8955e-02, -8.6904e-02,\n          1.9318e-01,  8.1097e-02, -1.4612e-02,  1.5330e-01, -1.1317e-01],\n        [ 1.2688e-01,  1.2954e-01,  1.2754e-01, -8.2898e-02,  6.8517e-03,\n          1.1594e-01, -1.3490e-01, -1.6444e-01,  4.3232e-02, -3.6610e-02,\n          1.4681e-01,  1.3536e-01, -1.2156e-01, -3.7557e-02,  7.6561e-02,\n          9.9208e-02,  8.7118e-02,  4.5831e-02, -1.4455e-01,  3.9454e-02],\n        [-5.2728e-04,  1.6463e-01,  2.0748e-01, -2.4139e-02,  6.0720e-02,\n          1.7343e-01,  1.2632e-01,  4.1703e-02, -1.6446e-01,  8.6151e-02,\n          6.3386e-02, -7.3950e-02,  1.0597e-01, -1.0297e-01, -2.0860e-01,\n         -1.4245e-01,  1.9352e-01, -8.3775e-02,  2.0699e-01, -9.5295e-02],\n        [ 4.6112e-02, -6.1274e-02,  8.0248e-02,  2.0277e-02, -5.0890e-03,\n         -1.1544e-01,  5.4346e-04, -7.0941e-02,  1.9431e-01,  7.4607e-03,\n          2.2344e-01,  8.8873e-02,  1.8386e-01,  1.5668e-01,  3.7077e-02,\n          4.5140e-02,  1.4917e-01,  6.4639e-02,  1.3716e-01, -5.5961e-02],\n        [ 1.6779e-01, -1.2637e-02, -2.1916e-01,  2.0768e-01, -1.0937e-01,\n         -2.2238e-02, -9.9210e-02,  1.2272e-01,  4.0796e-02, -2.1406e-02,\n         -3.9037e-02, -1.8867e-01, -3.0599e-02, -2.1342e-01, -1.9408e-01,\n         -1.1606e-01,  8.1512e-02,  1.9201e-01,  1.6602e-02, -1.1098e-01],\n        [ 3.9141e-02,  1.8458e-01, -5.8213e-02,  1.3727e-01, -1.3138e-01,\n          2.0108e-01, -2.1470e-01, -7.7616e-02,  2.1288e-01,  1.3464e-01,\n         -1.5365e-01, -5.3070e-02, -9.9306e-02,  7.3017e-02, -1.8756e-01,\n         -4.7514e-02,  5.9561e-02, -1.4061e-01,  2.0770e-01,  6.0844e-03],\n        [-1.5524e-02, -1.0827e-01, -1.8244e-01,  2.1763e-01,  5.5315e-03,\n          9.4410e-02,  1.6508e-01,  1.5591e-01, -4.9745e-02, -3.4313e-02,\n         -6.7689e-02, -1.7566e-01,  7.7388e-02, -1.3676e-01, -1.0097e-01,\n         -7.4009e-02, -1.1589e-01,  6.3570e-02, -1.1576e-01,  1.3583e-01],\n        [ 1.9360e-01, -1.9959e-02,  1.1306e-01,  2.0644e-01,  1.6118e-02,\n          1.9461e-01,  2.0855e-01,  6.5612e-03,  1.9508e-01,  1.1960e-01,\n          6.5968e-02, -1.5712e-02,  9.5185e-02, -3.0707e-03,  1.6373e-01,\n         -1.7754e-01,  9.6733e-02,  1.7613e-01, -7.1818e-02, -1.9958e-01],\n        [-1.0613e-01,  2.1613e-01, -9.5123e-02,  5.5512e-02,  1.0987e-01,\n          1.3916e-01, -1.0856e-02, -1.7771e-02, -9.0449e-02,  4.8713e-02,\n          5.7690e-02,  1.3540e-01, -1.8750e-02,  7.6508e-03, -2.9463e-02,\n         -8.1920e-02, -1.3292e-01, -1.5713e-01, -1.4448e-01, -8.4060e-03],\n        [-1.2982e-01,  1.7749e-01,  2.2029e-01, -5.2988e-02, -1.1130e-01,\n         -1.5056e-01, -1.1230e-01,  8.1562e-02, -6.8761e-02, -1.2907e-01,\n         -1.0273e-01, -1.2510e-01,  2.1636e-01, -1.6336e-01,  1.2825e-01,\n          1.6787e-01,  6.7908e-02,  9.5052e-02, -6.1509e-02,  4.7661e-02],\n        [-1.8308e-01, -1.3962e-01, -1.1320e-01,  1.4125e-01, -1.5682e-01,\n          5.2465e-02, -2.7534e-03, -1.9357e-01,  1.4218e-02, -2.1043e-01,\n          8.6745e-02, -9.4848e-02, -5.4437e-02,  1.6738e-01,  2.2173e-01,\n          1.6729e-01,  1.2520e-01, -7.5845e-02, -5.7976e-02, -1.9667e-01],\n        [ 1.8666e-01,  1.6834e-01,  1.3120e-01, -1.1956e-01,  1.3435e-01,\n         -2.0999e-01, -1.4750e-01, -1.4370e-01,  1.7746e-01,  6.6653e-02,\n          1.5534e-01, -1.0036e-01,  1.6096e-01,  3.4047e-02,  1.4118e-01,\n          7.9211e-04,  1.7436e-01,  1.0808e-01,  7.7430e-02, -7.0962e-02],\n        [ 1.1526e-01, -7.5667e-03, -4.7372e-02, -1.0031e-01,  1.4097e-01,\n         -1.9092e-01,  1.1353e-01, -9.1539e-02,  1.7521e-02, -1.6729e-02,\n          1.1727e-01, -3.1176e-02, -1.6215e-01,  4.1776e-02,  4.8528e-02,\n         -1.7362e-01,  2.0703e-01, -1.5336e-02, -8.2473e-02, -1.8481e-02],\n        [-1.4842e-01, -8.9725e-02, -1.4743e-02, -3.0705e-03,  1.8355e-02,\n         -3.6813e-02,  5.0002e-02,  1.9609e-01, -1.3349e-01,  7.2182e-02,\n          1.3457e-01,  1.1963e-01, -1.7988e-01, -1.0172e-01, -1.6881e-01,\n         -1.4538e-01, -1.5854e-01, -2.6972e-02,  3.7419e-03, -1.6202e-01],\n        [ 1.3757e-04,  1.8599e-01, -1.3488e-01, -1.5501e-01,  1.3529e-01,\n          3.6941e-02, -6.9069e-02,  4.7819e-02,  1.2649e-01, -1.7029e-02,\n          8.5653e-02, -1.4935e-01,  1.0603e-01, -1.0386e-01,  1.0869e-01,\n          1.9874e-01,  1.6046e-01, -8.6903e-02, -4.3094e-02, -2.2371e-02],\n        [ 1.5230e-01, -1.9575e-01,  1.8255e-02,  4.7770e-04,  2.0650e-01,\n         -1.3610e-01,  1.2607e-01,  2.1115e-01,  1.5027e-01,  1.6859e-01,\n          3.0548e-02,  2.0659e-01, -2.5435e-02, -1.9031e-01, -1.1986e-01,\n         -9.9073e-02, -5.1593e-02,  4.8048e-02,  1.5829e-01,  2.0434e-01],\n        [ 1.3274e-01,  4.9029e-02, -1.9872e-01, -3.2954e-02, -1.4994e-01,\n         -1.0387e-01, -1.5025e-01,  1.6538e-01, -9.2226e-02, -1.7875e-01,\n          1.1329e-01, -1.6333e-01, -7.9881e-02,  1.8253e-01, -2.2224e-01,\n         -1.0350e-01, -1.0292e-01, -1.8035e-01, -1.1461e-01,  1.0313e-01],\n        [ 4.4631e-02, -2.1248e-01,  1.4722e-01,  1.4431e-01, -6.7879e-02,\n          1.6248e-01, -1.0244e-01, -2.4488e-02,  1.9454e-01,  1.6783e-01,\n          2.7004e-02,  1.9097e-01,  1.6210e-01,  8.1539e-02, -1.8115e-01,\n         -4.3900e-02, -5.5770e-02,  1.4813e-01,  1.4010e-01,  9.7069e-02],\n        [ 1.6115e-01,  4.0066e-02,  1.0388e-01,  1.4077e-01, -2.2050e-01,\n         -1.6865e-01, -6.2243e-02,  1.0588e-01, -4.5404e-02, -2.1196e-02,\n          1.3204e-01, -8.8090e-02,  1.1015e-01, -3.1874e-02, -1.4170e-01,\n         -9.2710e-02, -1.4538e-01,  1.3292e-02,  1.9691e-01, -1.7266e-01],\n        [ 1.1983e-01,  2.4651e-02, -1.2420e-01,  7.3444e-02,  1.5139e-01,\n         -7.7114e-02, -1.3150e-01,  2.3224e-02, -2.1098e-01,  3.3066e-02,\n         -1.1384e-01, -2.0121e-01,  1.5028e-01,  1.0885e-01, -1.6023e-01,\n         -1.7979e-01, -4.5096e-02, -1.4041e-01, -1.2410e-01, -1.5834e-01],\n        [-1.5967e-01,  1.4787e-01,  5.7299e-02, -2.1331e-01,  8.5285e-02,\n          1.4998e-01, -2.5372e-02, -5.8993e-02, -2.1342e-01,  1.6759e-01,\n         -1.4644e-01, -2.2242e-01, -1.2249e-01, -2.2175e-01,  1.0023e-01,\n         -9.6662e-02, -3.5018e-02, -2.0563e-01, -1.1045e-01,  2.6684e-02],\n        [-1.9143e-01, -1.3482e-01, -1.7254e-01, -9.3345e-03,  1.6978e-01,\n         -6.2972e-02,  8.2206e-02,  4.3022e-02, -1.5541e-01,  1.2205e-01,\n         -1.0384e-01, -4.1892e-02, -3.5505e-02, -5.4791e-02,  1.1356e-01,\n         -1.8766e-01, -1.5998e-01,  2.0048e-01, -2.0430e-01,  9.3265e-02],\n        [-5.4062e-03, -1.0681e-01,  2.1815e-01, -1.5185e-01,  5.8259e-02,\n         -1.2613e-01, -8.7778e-02,  8.6161e-02, -1.7098e-01,  1.4457e-01,\n          1.8872e-02,  6.1717e-02,  8.8230e-02, -1.5069e-01,  9.9846e-02,\n         -4.7340e-02, -1.1381e-01,  2.7226e-03,  3.5851e-02,  1.4841e-01],\n        [ 2.2273e-01, -1.8447e-01,  1.0682e-01, -6.5353e-02,  1.8162e-03,\n          1.3285e-01, -1.9906e-01,  1.0331e-01, -1.9742e-01,  6.2655e-02,\n          1.3640e-01, -1.2473e-01, -1.9909e-01, -9.1118e-03,  6.2554e-02,\n         -1.5420e-01,  3.8090e-02,  1.6322e-01,  1.0047e-01,  2.2072e-02],\n        [-7.4224e-02,  9.1676e-02,  6.3468e-02, -1.9536e-01,  5.8602e-02,\n         -5.0490e-02,  7.6858e-02,  1.2038e-02,  1.5971e-01,  2.0608e-01,\n          1.2603e-01,  2.2973e-02, -6.8259e-02, -9.5946e-02, -2.0482e-01,\n          1.1253e-01, -1.5095e-01,  1.9007e-01, -3.4040e-03, -8.3152e-02],\n        [ 1.0719e-01, -1.9616e-01,  1.3440e-02, -2.0723e-01, -2.4704e-03,\n         -5.6282e-02,  1.3862e-02,  2.0744e-01, -2.0940e-01,  1.2498e-01,\n          1.7627e-01,  2.0479e-02, -1.4425e-01,  1.7643e-01, -2.1000e-01,\n         -1.3631e-01, -1.2092e-01, -1.3508e-01, -2.0515e-01,  1.6297e-01],\n        [-1.2060e-01,  6.0829e-02, -6.7266e-02, -2.1540e-01, -8.2167e-02,\n          1.3514e-01,  5.9855e-02, -1.5523e-01, -9.5631e-02, -8.4839e-02,\n          5.4010e-02, -1.0112e-02, -8.1682e-02,  1.7484e-01, -1.5508e-01,\n          1.7293e-01, -3.3841e-02,  1.4991e-01,  4.3596e-02, -1.9718e-01]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0601,  0.0726,  0.0402, -0.0135,  0.2173,  0.0731,  0.0952,  0.0507,\n        -0.0614, -0.0297,  0.0435, -0.0198, -0.0145,  0.0597,  0.0176, -0.1633,\n         0.1906,  0.0179, -0.0395, -0.1665,  0.1956,  0.1963, -0.1503, -0.1768,\n         0.0975,  0.2141, -0.1583,  0.1193,  0.0336,  0.1038, -0.0022, -0.1665],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1121,  0.0835,  0.0458,  0.0085,  0.0564, -0.1149,  0.1226, -0.0110,\n          0.0296,  0.0023,  0.0401,  0.0735, -0.0796, -0.1051,  0.0429,  0.0842,\n         -0.0366,  0.0768,  0.1252,  0.1183, -0.0610, -0.1562,  0.0003,  0.1749,\n         -0.1572, -0.0570, -0.1545,  0.0764, -0.0415, -0.1731,  0.0979,  0.0687],\n        [ 0.0463, -0.1628, -0.1505, -0.1757, -0.1298,  0.0624, -0.1310, -0.0372,\n         -0.1739, -0.1387, -0.0042, -0.1185, -0.0258,  0.0983,  0.1125,  0.1661,\n          0.0462, -0.0393,  0.0849,  0.1171,  0.0813,  0.1557,  0.0809,  0.1656,\n         -0.0960, -0.0826, -0.0725,  0.1651, -0.0588,  0.1615, -0.1257, -0.1645],\n        [ 0.1320, -0.1152, -0.1620,  0.0669, -0.0370,  0.0868,  0.0168, -0.0672,\n          0.0516, -0.1065,  0.0232,  0.1541, -0.1476, -0.0590,  0.0108,  0.0933,\n          0.0160,  0.0153,  0.1316, -0.1736,  0.1348,  0.0937, -0.0425, -0.0110,\n          0.0716, -0.1658, -0.0889, -0.1444, -0.1151, -0.1689,  0.0047,  0.0460],\n        [ 0.0182, -0.1404, -0.0215, -0.0741, -0.0221,  0.0353,  0.1341,  0.1581,\n         -0.0952, -0.1404,  0.0217, -0.0956,  0.1594,  0.1268, -0.1553, -0.0566,\n          0.1700, -0.0392, -0.0408, -0.0825,  0.0675,  0.0933, -0.0492, -0.0753,\n         -0.1764,  0.0977, -0.1356, -0.0435, -0.1023, -0.0765, -0.0832, -0.1089],\n        [-0.1041, -0.0736,  0.1647,  0.0477, -0.0014, -0.0086,  0.0618,  0.0543,\n          0.0845, -0.1439, -0.1416, -0.0965,  0.0900, -0.1509, -0.1733,  0.0359,\n          0.1465, -0.1147,  0.0808,  0.0642, -0.1476, -0.1241, -0.0325,  0.1445,\n          0.1737, -0.1713,  0.0136, -0.1640, -0.0399,  0.1090,  0.0456,  0.0907],\n        [ 0.0125,  0.0845, -0.1695, -0.1385,  0.0088, -0.0372,  0.0862, -0.0307,\n          0.0979,  0.0038, -0.0632, -0.0922, -0.0045, -0.1111,  0.0729, -0.0389,\n          0.1258, -0.1655,  0.1106, -0.0548, -0.1213, -0.1444, -0.1117,  0.0639,\n         -0.1115,  0.0823, -0.0794, -0.0370, -0.1678, -0.1524, -0.0134, -0.0130],\n        [-0.0414,  0.0831, -0.1535,  0.0178,  0.0477, -0.0537,  0.0950, -0.0243,\n         -0.0634,  0.1132,  0.0384,  0.0021, -0.0726,  0.0963,  0.0189,  0.1368,\n         -0.0321, -0.1404, -0.0094, -0.0244, -0.1215, -0.0508, -0.0928,  0.1276,\n         -0.0048, -0.1490, -0.0465, -0.0093, -0.1031, -0.1552,  0.0721,  0.1389],\n        [-0.1037, -0.0803, -0.1385, -0.0826, -0.0113,  0.1512, -0.0176,  0.0246,\n         -0.1171,  0.1037,  0.1626,  0.0013,  0.1438, -0.0133,  0.1287,  0.0886,\n          0.1098, -0.0706, -0.1074,  0.1216,  0.0984,  0.1227,  0.0861, -0.1621,\n          0.0540, -0.1281,  0.0718,  0.0141, -0.0084,  0.0874,  0.0180, -0.0612],\n        [-0.0184,  0.0109,  0.0213, -0.0164,  0.0475,  0.0322,  0.0210,  0.0071,\n         -0.0779,  0.1294, -0.0346, -0.1178, -0.1636,  0.0097, -0.1425, -0.0749,\n         -0.1730, -0.1554, -0.1648,  0.0905,  0.0179,  0.1468, -0.0959,  0.0021,\n          0.0888, -0.0863, -0.0854,  0.0611,  0.0418, -0.0241,  0.0185, -0.0502],\n        [ 0.1594,  0.1682, -0.0495,  0.0166,  0.0146, -0.0520, -0.0445, -0.0549,\n         -0.0418, -0.1268,  0.0529, -0.1504, -0.1493, -0.0812,  0.0642,  0.1273,\n          0.0017,  0.0049, -0.1284,  0.0835, -0.0589, -0.0449,  0.0839,  0.1549,\n         -0.0594, -0.1312, -0.0187, -0.1528,  0.1676, -0.1449,  0.0590,  0.0641],\n        [ 0.0919,  0.1090, -0.0412,  0.0405, -0.1351, -0.0868,  0.0688,  0.1022,\n          0.0202,  0.1382, -0.0817, -0.0422, -0.1544,  0.1327,  0.0505,  0.0974,\n          0.1763,  0.0493, -0.0779, -0.1547, -0.0256,  0.0139, -0.1052,  0.0572,\n         -0.1446, -0.0364, -0.0078, -0.1416,  0.1655, -0.0171,  0.0895,  0.0789],\n        [ 0.0536, -0.0919,  0.0902,  0.1709,  0.0791, -0.0851,  0.0866, -0.1719,\n         -0.0134, -0.0797, -0.0375, -0.1453,  0.0548,  0.0513, -0.0928,  0.0869,\n         -0.1599, -0.1416,  0.0643, -0.0381,  0.1721,  0.1009, -0.1196, -0.0584,\n         -0.1682, -0.1699, -0.0181, -0.1374,  0.0008,  0.0453,  0.0907,  0.1096],\n        [-0.0705, -0.0747, -0.1359, -0.0803,  0.0105,  0.0865,  0.1640,  0.1228,\n          0.1064,  0.0509, -0.1179, -0.0123,  0.0209, -0.0779,  0.0984, -0.1384,\n          0.0674, -0.0163,  0.0722, -0.0318,  0.0128,  0.0517,  0.0579, -0.1061,\n         -0.1151, -0.1460, -0.0578, -0.1577, -0.1378,  0.0658, -0.0685, -0.0946],\n        [ 0.1156,  0.0669,  0.1403, -0.0917,  0.0189,  0.1451,  0.0165,  0.0290,\n         -0.0968,  0.0359, -0.0857,  0.1269,  0.0253,  0.0281,  0.0098,  0.1408,\n         -0.0718,  0.1499,  0.0161, -0.0172,  0.1095, -0.0694,  0.1726, -0.1352,\n         -0.1010, -0.1615, -0.0646,  0.1225, -0.1464, -0.0709, -0.1037, -0.0067],\n        [-0.0232,  0.0619,  0.1007, -0.0698,  0.0119, -0.0377,  0.0467,  0.0523,\n          0.0514,  0.1679, -0.0312,  0.0548,  0.0667,  0.0070,  0.1111,  0.1161,\n          0.0138, -0.0484,  0.1177,  0.0256, -0.0721, -0.1607,  0.0766, -0.0173,\n         -0.0193,  0.1545,  0.0105, -0.0335, -0.0405,  0.0709,  0.1445, -0.1589],\n        [-0.1125, -0.0960,  0.0327, -0.1218,  0.0431, -0.1688,  0.0356, -0.1039,\n          0.0486, -0.0063,  0.0458, -0.1106, -0.1518,  0.1087,  0.0309,  0.0693,\n          0.0224,  0.0168,  0.0166, -0.0095, -0.1065, -0.0635, -0.0574,  0.0741,\n         -0.0748,  0.1078,  0.0012,  0.0918,  0.0498, -0.0370,  0.1007, -0.0691]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1156, -0.0549, -0.0046,  0.1337, -0.1484,  0.0444,  0.1593, -0.0948,\n        -0.0786, -0.1341, -0.1250, -0.0615,  0.1059, -0.0223,  0.1598,  0.0363],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.1743,  0.1771,  0.1405,  0.0186,  0.2444, -0.1264,  0.1043,  0.1317,\n         -0.0867, -0.1353, -0.1349,  0.1070,  0.2156,  0.2289, -0.1951,  0.1824],\n        [-0.0277, -0.1001, -0.0707,  0.1581,  0.0073, -0.2090, -0.1459, -0.2450,\n         -0.1849, -0.2372, -0.0306, -0.2201,  0.2300, -0.0274,  0.0799, -0.1399],\n        [ 0.1545, -0.2360, -0.0287, -0.1932, -0.1776, -0.1124,  0.2076,  0.2276,\n          0.1537, -0.1750, -0.0743,  0.0331,  0.0202, -0.0508, -0.2068,  0.0223],\n        [ 0.0417,  0.1710, -0.2215, -0.2185,  0.1016,  0.0008, -0.0762,  0.2244,\n         -0.2294, -0.0217, -0.1236,  0.0874,  0.2243,  0.1062, -0.1560,  0.0840],\n        [-0.1266, -0.0639,  0.1397, -0.1743,  0.2488, -0.0782,  0.1759, -0.1330,\n         -0.1009, -0.0323,  0.0554, -0.0699, -0.2021, -0.1927,  0.0337, -0.1034],\n        [-0.2450,  0.1068,  0.2307,  0.0438,  0.2490, -0.1239,  0.0402,  0.0711,\n         -0.0791, -0.1729, -0.1055,  0.0911, -0.2177,  0.1919, -0.1933,  0.0018],\n        [-0.2301,  0.2061,  0.0857, -0.0109, -0.0365,  0.2241, -0.1689, -0.1651,\n          0.0620,  0.1024, -0.1465, -0.0398, -0.0528, -0.2147, -0.0872, -0.0004],\n        [-0.2455, -0.2244,  0.1154,  0.2407,  0.1425,  0.0540,  0.1869,  0.1403,\n          0.0003,  0.1861, -0.0028, -0.1889, -0.0412,  0.0653, -0.1239,  0.0972]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2028,  0.2482, -0.1171,  0.2342,  0.0516,  0.0482, -0.1813, -0.2087],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.3176, -0.3036, -0.2845,  0.1326, -0.0586,  0.0184,  0.0786, -0.0183]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2619], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x7b6176aeec80>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s268100000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s268100000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	40,
    "train_v_iters":	40,
    "traj_per_epoch":	5,
    "vf_lr":	0.0003
}