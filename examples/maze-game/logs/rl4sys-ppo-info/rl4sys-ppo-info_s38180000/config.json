{
    "__class__":	"PPO",
    "buf_size":	50000,
    "clip_ratio":	0.1,
    "env_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game",
    "exp_name":	"rl4sys-ppo-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	5,
    "lam":	0.97,
    "log_data_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-info",
        "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s38180000"
    },
    "pi_lr":	0.0003,
    "seed":	38180000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x10fb90f10>":	{
            "_clip_ratio":	0.1,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (pi_network): Sequential(\n      (0): Linear(in_features=4, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n    )\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (pi_network): Sequential(\n    (0): Linear(in_features=4, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=4, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=4, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2205,  0.2472, -0.2525, -0.1125,  0.4888, -0.4616, -0.3609, -0.4120,\n         0.1544, -0.1298,  0.3635, -0.3798,  0.0308,  0.0206, -0.3258, -0.0599,\n         0.4426, -0.3620, -0.2833, -0.3660, -0.3639,  0.4879,  0.3522,  0.1222,\n        -0.0812,  0.0477, -0.1494,  0.3055, -0.3764, -0.3337, -0.4640, -0.0310],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0632, -0.4419,  0.3563,  0.2165],\n        [ 0.2095,  0.0356, -0.1185, -0.3154],\n        [ 0.0717, -0.0210, -0.2454, -0.3737],\n        [ 0.4463,  0.2779,  0.1329, -0.3670],\n        [ 0.1552, -0.1251,  0.0185,  0.1468],\n        [-0.3943,  0.4977,  0.3398, -0.1852],\n        [ 0.2781,  0.2587,  0.1379, -0.2130],\n        [-0.1416,  0.4271,  0.2758, -0.3295],\n        [-0.3293, -0.3753, -0.4520,  0.2479],\n        [-0.1351, -0.4139,  0.4458,  0.3377],\n        [ 0.2305, -0.0384,  0.0072, -0.3062],\n        [-0.1072, -0.1312,  0.3387,  0.1578],\n        [-0.3407,  0.4706, -0.3454, -0.0457],\n        [ 0.3513,  0.3823,  0.3258,  0.3299],\n        [ 0.4326, -0.3508, -0.4905,  0.1367],\n        [ 0.2463, -0.4672, -0.4511,  0.3856],\n        [-0.3135,  0.2919, -0.4915,  0.3666],\n        [-0.1271, -0.0574, -0.2147,  0.4327],\n        [-0.1119,  0.0751,  0.2946, -0.3747],\n        [-0.3645, -0.2759, -0.0303, -0.4298],\n        [ 0.4937,  0.0489, -0.0897, -0.0142],\n        [-0.4062,  0.1403,  0.1774,  0.4790],\n        [-0.2001, -0.4438, -0.2746, -0.2724],\n        [ 0.3276,  0.4617, -0.0917,  0.0179],\n        [-0.1970, -0.1517, -0.2264, -0.0473],\n        [ 0.2983,  0.4599,  0.0143, -0.3361],\n        [-0.2633,  0.0238, -0.1670, -0.0008],\n        [ 0.0431,  0.4538, -0.2475, -0.0347],\n        [-0.0446, -0.0874,  0.0425, -0.3430],\n        [ 0.1025, -0.4714, -0.4374,  0.0166],\n        [ 0.3876, -0.3774,  0.0841, -0.2666],\n        [ 0.4966,  0.4791, -0.2885, -0.4277]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	4,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1336,  0.0491,  0.0139,  0.1640,  0.1271, -0.0285, -0.0042,  0.0683,\n         0.1641,  0.0781, -0.1460,  0.0571,  0.1644,  0.1513,  0.0821,  0.0927],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0116,  0.0362,  0.0357, -0.0681, -0.0096,  0.0402,  0.0933,  0.0627,\n          0.1338, -0.0582,  0.1000, -0.1377,  0.0646,  0.0568, -0.1581, -0.0210,\n          0.1303,  0.0524, -0.0190, -0.0171, -0.1240, -0.1516, -0.0299,  0.1588,\n          0.1563, -0.1170, -0.0379,  0.0253, -0.1557, -0.0086, -0.0760,  0.1109],\n        [-0.0699, -0.1249, -0.0102, -0.1067, -0.0336, -0.0869, -0.0853, -0.0623,\n          0.1483, -0.0720, -0.0643,  0.0572,  0.0467, -0.0015,  0.0302,  0.1657,\n         -0.1587,  0.0095, -0.1337,  0.1371,  0.0169, -0.0407, -0.0749, -0.0840,\n         -0.1684, -0.1752, -0.1545, -0.1681, -0.0575, -0.1763, -0.0494, -0.0071],\n        [ 0.0265,  0.0352, -0.1207,  0.0112,  0.1151,  0.1354,  0.1550,  0.1204,\n          0.0005, -0.1102, -0.0630, -0.0192,  0.0184, -0.1438, -0.0651,  0.1688,\n         -0.0710, -0.0499,  0.1090, -0.0332, -0.0504, -0.1150,  0.0753,  0.1176,\n         -0.0644,  0.0606,  0.0933,  0.1330,  0.1095,  0.0392,  0.0220,  0.0576],\n        [-0.0652,  0.0824,  0.0610,  0.0377,  0.0363,  0.0249, -0.0530, -0.1654,\n         -0.1585, -0.1128,  0.0544,  0.1259,  0.0927,  0.0528,  0.0209,  0.1737,\n         -0.1717,  0.1395, -0.0519,  0.1228, -0.0776,  0.1304, -0.0973, -0.0256,\n         -0.1626, -0.1207,  0.0861,  0.0182, -0.0175,  0.0877, -0.1536, -0.0250],\n        [ 0.0814,  0.0027,  0.0147,  0.0736,  0.1442, -0.0734, -0.1580, -0.1635,\n          0.1626,  0.0831,  0.1284, -0.0475,  0.0957, -0.1435, -0.0829,  0.1581,\n          0.1427, -0.0447,  0.0101,  0.0020, -0.0346, -0.0790,  0.0522, -0.0652,\n          0.1683,  0.0407,  0.0213,  0.0276, -0.0496, -0.0387, -0.0507, -0.0121],\n        [-0.0150,  0.1633, -0.0194, -0.1308, -0.1689, -0.0198,  0.0766, -0.0592,\n         -0.0439,  0.0842, -0.1553,  0.0066,  0.0194,  0.0336,  0.1615, -0.1491,\n          0.0695, -0.1714,  0.1504,  0.0912, -0.0393,  0.0636,  0.0381,  0.0616,\n          0.0222, -0.1407,  0.1165, -0.0321,  0.0529,  0.1067,  0.0814,  0.0711],\n        [-0.1437,  0.1305,  0.0990,  0.1636, -0.0198,  0.1353, -0.0352, -0.1353,\n         -0.1673, -0.0449,  0.1054, -0.1228, -0.0006,  0.1484,  0.0705,  0.1552,\n          0.1081,  0.1309,  0.1012, -0.1286,  0.0365, -0.1728, -0.1566,  0.0218,\n          0.0286, -0.1484,  0.0966,  0.0461,  0.0699, -0.1191,  0.0513,  0.0956],\n        [-0.1488, -0.1385,  0.0875,  0.1694, -0.1289,  0.0888,  0.0248, -0.1082,\n          0.0535,  0.0744, -0.0176, -0.0456, -0.1449, -0.1756, -0.0115,  0.1755,\n         -0.0014, -0.0425, -0.1561, -0.1718, -0.0903, -0.1352, -0.0768,  0.0811,\n         -0.1470, -0.0284, -0.1685, -0.0086,  0.0685, -0.0174, -0.1326, -0.1311],\n        [-0.0083,  0.1227, -0.0544, -0.0293, -0.1480, -0.1255,  0.1108,  0.0441,\n         -0.1371, -0.1177, -0.0390, -0.0433,  0.1317, -0.0408, -0.0833,  0.0320,\n         -0.0509, -0.0671, -0.0058,  0.0651, -0.0738, -0.0028, -0.0445,  0.0267,\n          0.0585, -0.1452, -0.0663,  0.1153,  0.1606, -0.0142,  0.0971,  0.1016],\n        [ 0.0444,  0.1712, -0.1285, -0.0533,  0.0938, -0.1202,  0.0791,  0.1530,\n          0.0176, -0.1683, -0.0213, -0.0369,  0.0553, -0.0619,  0.1502,  0.0005,\n         -0.0792, -0.1194, -0.1015,  0.0889, -0.0541,  0.1625,  0.0717,  0.1616,\n          0.0299,  0.0862, -0.1723,  0.0221, -0.0051, -0.0897, -0.0997,  0.0997],\n        [ 0.1298, -0.0679, -0.0641, -0.1758,  0.1423,  0.0170, -0.0065, -0.0076,\n         -0.0185,  0.0312,  0.1373,  0.0653,  0.0121,  0.1090,  0.1132, -0.1189,\n          0.0043,  0.0803,  0.1460, -0.0886,  0.1309, -0.0559, -0.0084,  0.1669,\n         -0.0768, -0.1610, -0.1648,  0.0251, -0.0861,  0.1650, -0.0456, -0.0634],\n        [ 0.0500, -0.1115,  0.1324,  0.0757, -0.0854,  0.1298, -0.0573, -0.0923,\n         -0.0659, -0.0248,  0.0091, -0.1040,  0.0973,  0.1144, -0.0426, -0.1708,\n         -0.0362,  0.1697,  0.0442,  0.0261, -0.1396,  0.0557,  0.0541, -0.0625,\n          0.0694, -0.0746, -0.0971,  0.0878, -0.1760, -0.0419,  0.0397, -0.0247],\n        [ 0.1690, -0.0251,  0.0547,  0.0103,  0.0756, -0.0336, -0.1580,  0.1513,\n          0.1673,  0.0997, -0.1690,  0.1751,  0.1003,  0.1185, -0.1290, -0.1308,\n         -0.0415, -0.1423,  0.0541,  0.1497,  0.1462, -0.0319,  0.1463, -0.1742,\n         -0.1486,  0.1611, -0.1676,  0.0579, -0.1755, -0.0120,  0.1536,  0.1164],\n        [-0.0523,  0.1443,  0.1281, -0.0079, -0.0675,  0.0989,  0.1171,  0.1326,\n          0.0847,  0.0841,  0.0060,  0.0477,  0.1512,  0.0271, -0.0688,  0.0738,\n          0.0280, -0.1474, -0.0257, -0.1530, -0.1189,  0.1683,  0.0546,  0.0369,\n         -0.0857, -0.0696,  0.0178,  0.0691, -0.1031, -0.0093, -0.0847,  0.1498],\n        [ 0.0025,  0.0039, -0.0922,  0.0166, -0.0749,  0.0663, -0.0449, -0.1499,\n         -0.0243, -0.0348, -0.1196,  0.0741, -0.0092,  0.1700, -0.1569,  0.0782,\n          0.0328,  0.0262, -0.0510, -0.1574, -0.0761, -0.0415,  0.0749,  0.0056,\n         -0.0531, -0.0157,  0.1395, -0.1577, -0.1098,  0.0169,  0.0521, -0.0445],\n        [ 0.0110, -0.1461,  0.0832,  0.0714,  0.0133,  0.0962,  0.0656,  0.1469,\n         -0.1388,  0.0979, -0.1291,  0.1562, -0.0990, -0.0598,  0.0191, -0.1255,\n          0.0740, -0.1264, -0.1661,  0.1665,  0.0605,  0.1657, -0.0082,  0.1573,\n          0.0511, -0.1278,  0.0219, -0.1082,  0.0444,  0.0216,  0.1318, -0.0230]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1663,  0.1198, -0.2030,  0.0764, -0.2439,  0.1818,  0.1226,  0.0039],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.1589, -0.1379,  0.0516,  0.1929, -0.1686,  0.1280,  0.0831,  0.1186,\n         -0.2435,  0.1155,  0.2314, -0.2167, -0.2052, -0.1340, -0.1583,  0.0925],\n        [ 0.0661, -0.2397,  0.2310,  0.2433,  0.2097, -0.0121, -0.1277, -0.0828,\n          0.2482,  0.0983, -0.1192,  0.0183, -0.1286, -0.0711,  0.1154,  0.1608],\n        [-0.0817, -0.1972,  0.0203,  0.0695, -0.1696, -0.1641,  0.1845, -0.0312,\n          0.2491, -0.1499, -0.0513,  0.1198,  0.1735,  0.2378, -0.1886,  0.2235],\n        [-0.1411, -0.0065,  0.0722, -0.0542,  0.1835, -0.1541,  0.1686, -0.0089,\n          0.0493,  0.1441,  0.2106, -0.0241, -0.0933, -0.2415, -0.0193,  0.0208],\n        [-0.1054,  0.1030,  0.2346,  0.1592,  0.1515,  0.0823, -0.1069,  0.1256,\n         -0.1380,  0.0694, -0.0629, -0.1330,  0.2006, -0.1465, -0.2311, -0.1813],\n        [ 0.2434, -0.2245,  0.2260,  0.2107, -0.0029,  0.1146, -0.0922, -0.2049,\n         -0.0080, -0.0107, -0.1809, -0.0072, -0.2219,  0.1300,  0.2473, -0.1781],\n        [ 0.0184,  0.2327,  0.2055,  0.1104, -0.0464, -0.1505, -0.0965, -0.2320,\n         -0.0532,  0.1589,  0.1070, -0.2049, -0.1569,  0.1039,  0.1606,  0.0103],\n        [ 0.1838,  0.2001,  0.2227, -0.1088, -0.0516,  0.1971, -0.1135,  0.0076,\n         -0.1830, -0.1323,  0.1223,  0.0431,  0.2247, -0.1696,  0.0732,  0.1769]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2412], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.2695,  0.0086,  0.0678,  0.0502,  0.0154, -0.2418,  0.2852, -0.0594]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "kernel_dim":	4,
                                "kernel_size":	5,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.0652,  0.0879,  0.1528,  0.1849,  0.2168,  0.1597,  0.0194, -0.2120,\n        -0.1130, -0.0617, -0.0948, -0.1830, -0.1599,  0.1440,  0.2135, -0.0561,\n         0.0694, -0.1728, -0.0573,  0.1050, -0.0044,  0.1586, -0.0632,  0.0109,\n        -0.2065, -0.0399,  0.1805, -0.1390,  0.0444, -0.1823, -0.1552, -0.0602],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 1.8801e-01,  1.1243e-01, -3.4134e-02, -4.0000e-02, -4.9381e-02,\n         -1.1615e-01, -2.2121e-01,  2.0366e-01,  2.3945e-02,  1.7725e-01,\n          8.8106e-03,  1.2925e-01,  4.5483e-02, -6.9034e-02,  2.0176e-01,\n         -1.4892e-01, -2.0769e-01, -1.7339e-01, -1.5885e-01, -1.5754e-01],\n        [ 2.0840e-01,  1.3724e-01, -8.9089e-02,  1.3800e-01,  2.0577e-01,\n          5.2711e-02, -9.6116e-02, -1.4832e-01,  1.3698e-01, -2.4120e-02,\n          1.0061e-01,  5.3775e-02, -1.5570e-02,  7.6753e-02, -3.0296e-02,\n          3.8507e-02,  1.3707e-01,  1.8889e-02, -9.5702e-02, -3.0434e-02],\n        [ 9.0559e-02, -1.2412e-01, -5.0395e-02,  1.7237e-01,  1.4628e-01,\n         -5.4664e-02,  1.0429e-01, -1.2032e-01, -1.3275e-01,  2.2031e-01,\n         -4.5230e-02,  4.5706e-02, -1.3823e-01, -8.8763e-02, -1.2435e-01,\n         -5.9168e-02,  2.1520e-01,  8.1299e-02,  1.3979e-01,  2.6494e-03],\n        [ 6.0551e-02, -2.1787e-01, -2.0698e-01,  5.2164e-02,  8.1458e-02,\n          4.6994e-02, -1.6340e-02, -2.0946e-02, -1.5908e-02, -2.1187e-01,\n         -2.3213e-02,  9.5485e-03, -7.1915e-02,  2.1025e-01, -2.0255e-02,\n         -2.3059e-02, -1.6677e-01, -1.9382e-01, -1.1604e-01, -1.0754e-01],\n        [-5.5014e-03,  2.1868e-01, -1.3660e-01, -1.9126e-01,  1.6443e-01,\n         -2.7885e-02, -2.0066e-01,  5.5803e-02, -1.9308e-01, -1.8607e-01,\n         -1.6858e-01,  2.7283e-02, -7.6867e-02, -1.4666e-01,  5.0283e-02,\n         -2.3255e-02, -1.4357e-01, -1.9953e-01, -5.2285e-02,  2.6771e-02],\n        [ 3.6544e-02,  4.5343e-02,  1.8599e-01, -1.8087e-01,  1.3931e-01,\n          1.8681e-01,  2.0565e-01,  1.3965e-01,  1.8968e-01, -7.3341e-02,\n          1.6976e-01, -8.4367e-02, -1.4753e-01,  2.1450e-01,  4.3090e-02,\n         -2.1752e-01, -3.6102e-02, -6.7443e-02,  1.7514e-01,  1.3014e-01],\n        [-4.4126e-02, -3.2031e-02,  1.9995e-01, -2.0826e-02,  1.1498e-01,\n         -1.6128e-01,  9.3597e-02,  1.5243e-01,  1.1672e-01,  2.9792e-02,\n         -4.6309e-02, -1.6075e-01, -9.8251e-02,  1.8163e-01,  6.2315e-02,\n         -5.3270e-02, -1.5918e-01, -2.4804e-02, -1.7310e-01, -1.4061e-01],\n        [-2.1653e-01,  1.2575e-01, -1.0291e-01, -7.2356e-02, -1.8144e-01,\n         -2.1608e-01, -1.5423e-01,  1.8235e-01, -3.5848e-02, -5.4766e-03,\n         -2.0117e-01,  1.9588e-01,  1.1174e-01, -9.5058e-02, -2.2030e-01,\n         -1.4675e-01,  9.0053e-02, -1.6298e-01, -1.5353e-01,  8.5798e-02],\n        [ 1.9105e-01, -1.4307e-01,  1.0489e-01,  7.5907e-02, -7.1487e-02,\n         -1.0883e-01,  1.5756e-02, -3.7232e-02, -5.1092e-02,  1.1471e-01,\n         -1.6155e-01,  7.9441e-02, -2.2151e-01, -2.2291e-01, -1.8407e-01,\n         -9.5160e-02, -4.3251e-02, -6.3477e-02, -1.4080e-01,  2.1126e-01],\n        [ 1.3354e-01, -1.9036e-01,  1.9554e-01,  1.6569e-01, -1.7877e-01,\n          2.1583e-01, -1.4401e-01,  2.9067e-02,  7.1468e-02, -1.3113e-01,\n         -5.9876e-02,  1.1734e-01, -1.8042e-01, -1.6167e-02, -8.7035e-03,\n          1.8857e-01, -7.8170e-02, -4.7574e-02,  2.0257e-01,  2.1000e-01],\n        [ 1.0049e-01,  5.4411e-02, -5.4294e-02, -1.5685e-01,  1.0091e-01,\n          1.2528e-01, -9.3059e-02,  5.6180e-02, -4.7347e-02, -8.0352e-03,\n         -1.5625e-01, -1.6086e-01,  1.7425e-01,  4.8215e-04,  1.0358e-01,\n          1.5367e-01, -2.1376e-01, -2.1115e-01,  5.0744e-02,  2.1238e-01],\n        [ 6.0933e-02,  1.0314e-01, -2.1813e-01, -3.0036e-02,  1.1983e-01,\n         -1.4590e-01,  1.3782e-01,  1.7987e-02,  5.9536e-02,  1.7260e-01,\n         -1.0687e-01, -3.9547e-02,  1.1216e-01,  1.9587e-01,  1.8920e-01,\n          1.5861e-01, -1.1046e-01,  1.4984e-01,  5.8074e-02, -9.5319e-04],\n        [ 9.0363e-02,  7.0810e-02, -1.9964e-01, -7.2943e-02, -1.5089e-01,\n         -9.5556e-02,  8.7073e-02, -9.3929e-02,  4.7275e-02,  3.9449e-02,\n          1.2208e-01, -1.5599e-01, -2.9729e-02, -3.3709e-03, -1.7982e-01,\n          1.5350e-01, -6.0866e-03,  8.4750e-02, -3.2187e-02, -1.3847e-01],\n        [-2.0558e-01,  3.3473e-02, -3.2938e-02, -1.6025e-01,  5.8676e-02,\n         -2.1372e-01,  1.1618e-01, -1.7599e-01, -1.0444e-02, -7.0881e-02,\n          2.5438e-02,  4.7993e-02,  5.6784e-02, -1.4320e-01, -5.0792e-02,\n         -1.8950e-01,  7.6758e-02,  4.6221e-02,  9.5130e-02,  2.2147e-01],\n        [-1.5621e-01, -3.0688e-02, -1.4653e-02, -1.1249e-01, -1.5023e-01,\n         -1.7148e-02, -2.8234e-02, -2.0870e-01, -2.0059e-01,  1.6734e-01,\n         -1.9317e-01, -8.4389e-02,  9.8673e-03, -1.3571e-01, -3.0620e-02,\n         -2.1156e-02, -1.4744e-01,  2.5241e-02, -1.6584e-01, -5.8782e-03],\n        [ 8.3593e-02,  6.0766e-02, -1.6334e-01, -1.2139e-01,  1.6154e-01,\n          6.5601e-02,  7.1174e-04, -2.2341e-01,  1.6064e-01,  7.2798e-02,\n          2.6763e-02, -1.3920e-01,  1.4803e-01, -8.0913e-02,  1.5750e-01,\n         -1.0597e-01,  8.9131e-02, -8.1385e-02,  2.1147e-01, -9.3045e-02],\n        [-7.5282e-03,  2.1853e-01, -1.1344e-01,  1.3856e-01,  2.1832e-01,\n          5.4166e-02, -3.4030e-02,  1.1130e-01, -8.8501e-02, -2.1174e-01,\n          5.4715e-03, -1.5794e-01, -5.7099e-02, -1.3077e-01, -9.4606e-02,\n          1.9522e-01,  2.3634e-02, -1.2319e-01,  1.5432e-01,  9.5826e-03],\n        [-5.0410e-02,  2.1496e-01,  1.8354e-01, -2.2121e-01,  4.4270e-02,\n         -2.1411e-01, -3.6953e-02, -1.2448e-01,  5.1905e-02,  6.8742e-02,\n          2.0070e-01, -1.8979e-01, -3.3683e-02,  4.5276e-02,  6.9683e-02,\n         -2.5656e-02, -2.2095e-01,  5.5965e-02, -1.1492e-01, -1.6436e-01],\n        [ 5.3827e-02,  2.1886e-01,  1.5473e-01,  9.6268e-02,  1.4730e-02,\n          1.2482e-01,  1.5307e-01, -2.0147e-01,  1.9793e-01, -8.7295e-02,\n         -2.2509e-02,  6.7707e-02,  8.2821e-02, -2.0054e-01,  1.4258e-01,\n         -4.8845e-02,  1.8891e-01,  1.0808e-01,  8.6249e-02, -1.2913e-01],\n        [ 1.8013e-01,  6.1808e-02, -1.0304e-01,  8.5183e-02, -2.0797e-01,\n          1.4191e-01, -9.7683e-02,  1.6502e-01,  1.5658e-01,  1.6905e-01,\n         -5.9166e-02,  2.0721e-01,  7.4223e-02,  1.4431e-01, -1.2276e-01,\n         -1.7620e-01,  2.1095e-01, -1.9197e-01, -2.4483e-02, -2.1301e-01],\n        [-8.1655e-02, -1.4909e-01,  1.7920e-02, -9.7853e-02,  7.8726e-02,\n         -1.0910e-01,  1.9320e-01, -3.2770e-02,  1.8567e-01, -7.1892e-02,\n         -5.8134e-02, -2.6014e-02,  9.9795e-02, -1.7735e-01, -1.4511e-01,\n          3.6126e-02,  1.4247e-01,  7.1346e-02,  1.7797e-01, -6.6481e-02],\n        [-2.0981e-02, -1.4246e-01,  9.4116e-03,  1.9230e-01, -5.0205e-02,\n         -1.1326e-01,  1.1240e-01,  1.8395e-01, -1.6506e-01, -3.8271e-02,\n          6.7977e-02, -1.9834e-01, -1.5585e-02,  7.6288e-02, -9.4688e-02,\n          2.1757e-01,  7.7202e-02,  9.5321e-02, -1.9914e-01,  1.9169e-01],\n        [ 2.0961e-01,  1.5555e-01, -8.3831e-02, -1.9944e-01,  8.1309e-02,\n          3.1555e-02,  1.8735e-01,  1.1135e-01, -1.8488e-01,  5.7583e-02,\n          2.0973e-01,  1.2120e-01, -2.0515e-01,  3.3819e-02, -1.4589e-01,\n          1.2106e-01, -2.5804e-02,  8.7036e-02, -1.9869e-01,  5.1659e-03],\n        [ 7.3889e-02,  1.3008e-01, -1.3501e-01, -6.9123e-02,  2.0939e-02,\n          1.4279e-01,  1.4072e-01,  1.5853e-01,  1.1510e-01,  1.0382e-01,\n         -2.0023e-01, -2.9755e-03,  1.9727e-01, -1.8856e-01, -4.5614e-02,\n          1.8628e-01, -7.1386e-02,  4.3048e-03, -8.9549e-02,  1.9670e-02],\n        [-1.5516e-01, -4.2055e-02,  1.1003e-01,  5.4645e-02,  1.8142e-02,\n          1.2883e-01,  1.6340e-01, -8.7411e-02,  3.8126e-02, -2.4041e-03,\n          8.3614e-02,  5.6662e-02,  4.7429e-02, -2.0219e-01,  3.7138e-02,\n          4.3895e-02,  1.3907e-01, -1.6407e-01, -1.5603e-01,  4.8885e-02],\n        [ 1.8521e-01, -1.7285e-01,  1.5712e-02,  8.9517e-02,  1.8134e-01,\n          1.4123e-01,  1.6139e-01, -9.5239e-02,  8.4087e-02,  1.6558e-01,\n          7.9640e-02, -9.2888e-02, -1.8874e-01, -1.9639e-02, -7.6445e-02,\n          1.2734e-01, -2.0771e-01,  3.2548e-02,  1.7688e-01,  8.4989e-02],\n        [ 1.5672e-01, -3.3281e-02,  9.9708e-03, -1.7173e-01, -3.3034e-03,\n         -8.1386e-02,  3.8977e-02,  1.6675e-02, -8.4997e-02,  1.8771e-01,\n         -2.1996e-01,  6.0205e-02,  1.5065e-01, -1.3707e-01,  1.2638e-04,\n         -1.4011e-01, -2.2227e-01, -1.5114e-01,  4.8555e-03, -1.7756e-01],\n        [-1.5958e-01,  1.9990e-01, -1.1501e-01, -6.5293e-02,  1.1484e-01,\n         -6.8726e-02, -2.7489e-02,  2.5368e-02,  6.9966e-02,  1.2319e-01,\n          1.5755e-01, -1.7751e-01, -2.6884e-02, -3.4782e-02,  1.9717e-01,\n          1.6568e-01,  5.7988e-03,  1.4031e-01, -4.6856e-02, -1.5191e-01],\n        [-3.7077e-02, -1.2561e-01, -2.0876e-01,  1.9666e-01,  5.6781e-02,\n          1.6362e-03,  1.0206e-01,  4.7419e-02,  1.3638e-01,  7.2296e-02,\n          1.9308e-01, -1.4665e-01, -7.0423e-02,  5.9850e-02,  1.6657e-01,\n         -1.0526e-01, -2.6654e-02,  7.0083e-02, -3.9492e-02,  1.6936e-01],\n        [-5.6932e-02,  1.8325e-01, -1.9685e-01,  2.1064e-01,  2.2277e-01,\n          2.7684e-02, -1.7882e-01,  1.6601e-01,  1.0063e-01, -5.8036e-02,\n          1.7474e-01, -1.0718e-01, -1.6344e-01,  1.6302e-01,  5.7594e-02,\n          4.1836e-02,  1.6008e-01, -1.4438e-01,  1.2561e-01,  7.0519e-02],\n        [-1.7789e-01, -1.6392e-01,  5.5731e-02, -3.5654e-02, -1.7137e-01,\n          1.5724e-01,  1.5948e-01,  1.3690e-01, -9.3825e-02, -7.1903e-02,\n         -2.0968e-03, -2.0889e-01,  7.6270e-02, -7.7856e-02,  1.3577e-01,\n         -2.1535e-01,  2.0485e-01, -1.4668e-01,  2.2327e-01,  6.6186e-02],\n        [-5.2220e-02,  1.2311e-01, -1.7264e-01, -3.8529e-02,  5.6280e-02,\n         -7.3536e-02, -1.9149e-01,  2.7162e-02,  1.7381e-01,  2.1924e-01,\n          1.3855e-01, -1.7132e-01, -1.4871e-01,  4.4587e-02, -8.7145e-02,\n         -1.5971e-01,  2.0088e-01, -1.8876e-01, -1.5788e-01,  8.6600e-02]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1004,  0.0268,  0.0659, -0.0664,  0.0863,  0.1684,  0.0995, -0.1731,\n        -0.0348, -0.0829,  0.1019, -0.1434, -0.0143,  0.1292, -0.0548, -0.1314],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 4.6623e-03,  9.2448e-02,  8.1225e-02,  1.6996e-02,  1.2393e-01,\n          3.1542e-02, -1.7323e-02, -9.7961e-02, -1.0359e-01, -3.5987e-02,\n          1.5164e-01, -1.4054e-01,  1.1892e-01,  6.6194e-02,  1.7267e-01,\n         -1.5310e-01,  5.4809e-02, -1.6615e-01, -3.1546e-02, -1.3195e-01,\n          7.9201e-02,  6.8535e-02, -8.8169e-02,  1.1161e-01, -1.5562e-01,\n          1.3617e-01,  1.3535e-01, -1.4421e-01, -1.6935e-01,  4.1849e-02,\n         -1.5217e-01,  1.2056e-04],\n        [ 3.2901e-02, -1.7481e-01, -1.2263e-01, -1.4384e-01,  1.6142e-01,\n         -1.7202e-03,  1.6426e-01, -6.0329e-02, -8.2258e-02,  2.8513e-02,\n          1.2764e-01, -6.7546e-02,  9.7226e-02,  1.4544e-01,  4.1572e-02,\n          1.1855e-01, -1.3407e-01, -1.7027e-01, -5.9691e-02,  1.7588e-01,\n          1.0970e-01,  4.6822e-02,  1.5408e-01,  5.7133e-02, -1.0116e-02,\n         -4.4328e-02, -1.1959e-01, -5.1144e-02,  6.7510e-02, -1.3352e-01,\n          9.5034e-02,  5.2071e-02],\n        [ 1.1003e-01, -2.6628e-02,  9.9006e-02, -3.6202e-02,  5.4401e-02,\n         -1.2379e-01, -6.0661e-02,  1.3586e-01, -1.7041e-01, -1.4568e-01,\n         -4.4769e-02, -5.3265e-02, -4.6246e-02,  1.6276e-01,  1.7558e-01,\n         -8.2859e-02,  6.2452e-02, -1.2460e-01,  7.4462e-02,  8.8316e-03,\n         -4.2460e-02,  6.8347e-02, -7.2096e-02,  1.9788e-02,  1.3639e-01,\n          5.5230e-02, -3.7819e-02, -1.4252e-01, -2.2767e-02,  1.7275e-01,\n         -7.5573e-02,  1.7665e-01],\n        [ 2.0681e-02, -1.4715e-01,  1.2749e-02, -9.4068e-02,  1.5457e-01,\n         -1.5328e-01, -7.1709e-02, -5.8690e-02,  1.4370e-01,  2.3275e-02,\n         -1.5109e-01, -4.8113e-03, -9.4339e-02, -5.1558e-02,  1.4258e-01,\n         -2.7090e-02, -9.0417e-02,  1.0470e-02, -6.4819e-02,  9.0577e-02,\n         -1.5447e-01,  6.8490e-02, -4.3918e-02,  1.1024e-01,  3.3316e-02,\n          1.4759e-01,  6.2234e-02,  1.2606e-02, -1.2603e-01,  1.7064e-01,\n         -1.7187e-01,  1.1773e-01],\n        [-6.1240e-02,  7.2067e-03, -1.5929e-01, -1.1471e-01, -1.6523e-02,\n         -9.7612e-02,  1.2590e-01,  1.7132e-01,  1.3044e-01, -1.1423e-01,\n         -1.5658e-01,  7.2335e-02, -1.5787e-01,  1.4445e-02, -2.7652e-02,\n          5.8000e-03,  5.3477e-02, -5.1769e-02,  1.2452e-01,  1.6840e-01,\n         -5.1389e-02,  7.5651e-02,  6.8204e-02, -5.6842e-03, -5.8430e-02,\n         -1.6278e-01, -1.2515e-01, -1.2432e-02, -1.2178e-01,  1.5407e-01,\n         -2.8927e-02,  1.2804e-01],\n        [ 6.7486e-02, -1.2107e-01,  3.5846e-02,  8.8424e-02, -1.5640e-01,\n         -8.7039e-03, -1.5230e-01,  1.3430e-01, -4.7172e-03,  3.8505e-02,\n          1.1350e-01,  1.2314e-01,  9.2766e-03,  1.0656e-01, -5.1735e-02,\n         -4.9432e-02,  6.8583e-02, -1.6729e-01, -1.7193e-01,  6.6670e-02,\n          1.7621e-01,  1.0118e-01, -7.5325e-02, -1.9363e-02, -9.4289e-02,\n         -1.7448e-01, -1.3544e-01, -1.3055e-03,  1.3974e-01,  7.1879e-02,\n          1.6874e-01, -5.9230e-02],\n        [-1.7152e-01,  5.3901e-02, -6.8018e-02,  2.4357e-03,  1.2298e-01,\n          9.4643e-02,  4.4285e-02,  4.9419e-03, -5.5308e-02,  6.8228e-02,\n          1.3670e-01, -1.4135e-01,  1.2181e-01,  2.4425e-02,  6.2252e-02,\n         -1.4969e-01,  6.1690e-02, -2.9515e-02,  1.0991e-01, -1.7027e-01,\n          6.5769e-02, -2.6484e-03,  8.8494e-02, -3.7652e-03,  7.1536e-02,\n         -1.2899e-01, -1.7030e-01, -7.0752e-02, -1.6071e-01, -1.4144e-01,\n          1.4031e-01, -5.9727e-02],\n        [-1.1880e-01,  8.5264e-02,  3.4641e-02,  1.3932e-03,  9.4805e-02,\n          1.6100e-01,  2.3359e-02, -9.1045e-02, -1.0869e-01,  9.3326e-02,\n         -8.2464e-02, -6.0605e-03,  6.7642e-02, -9.4741e-02, -8.7970e-02,\n         -1.2045e-03,  1.5448e-01, -6.8623e-02, -1.7517e-01, -3.3308e-03,\n          1.1381e-01, -3.8958e-02, -3.3124e-02, -9.3447e-02, -1.6751e-01,\n          1.3960e-01,  1.6431e-01, -8.7614e-02, -8.2335e-02,  1.1930e-02,\n         -6.5296e-02, -1.3764e-01],\n        [ 1.5817e-01, -3.1863e-02,  9.2168e-02,  5.7622e-03,  1.1031e-01,\n         -1.9086e-02,  2.8246e-02,  4.9309e-02,  1.0714e-01, -8.6440e-02,\n          9.3578e-02, -8.0888e-02,  7.6931e-02, -6.6669e-02, -9.7025e-02,\n          1.0099e-01, -7.6941e-02,  1.3246e-01,  7.9546e-02,  2.1361e-02,\n         -6.0091e-03,  2.2552e-02,  1.6427e-01,  1.6075e-01,  1.3550e-02,\n         -1.6292e-01, -3.4252e-02, -8.2837e-02,  1.3187e-01, -1.5267e-01,\n         -5.0615e-02, -1.2538e-01],\n        [-1.1392e-01,  1.6969e-01,  3.7409e-03, -3.0063e-02, -6.5220e-02,\n          1.5835e-01,  6.1701e-02, -1.4849e-02, -1.7538e-01,  1.3009e-01,\n          1.3762e-01, -1.0654e-01, -5.3428e-02,  1.1483e-01,  1.4997e-01,\n          5.5432e-02, -1.7096e-01, -1.3098e-01, -1.4701e-01, -9.9579e-02,\n          1.6501e-01,  5.0246e-02,  1.0135e-01,  1.0346e-01, -1.3947e-01,\n          1.3179e-03, -1.3675e-01,  1.7481e-01, -4.0547e-02, -1.2672e-01,\n         -4.1043e-03,  1.3955e-01],\n        [ 9.9497e-03,  6.1824e-02,  7.0436e-02,  1.3817e-01, -8.3629e-02,\n          8.5328e-02, -9.0814e-02, -5.1538e-02,  7.0297e-02, -1.6917e-01,\n          1.5697e-01,  2.3125e-02, -1.3969e-01,  1.2364e-01, -8.1618e-03,\n         -1.1767e-01,  1.3854e-02, -1.3917e-01, -1.2570e-01, -1.2417e-01,\n          9.4766e-02, -8.7636e-02, -2.0018e-02, -5.0042e-02, -5.9178e-04,\n         -5.6147e-02, -3.7346e-02,  7.2015e-03, -1.4575e-01, -3.7263e-02,\n         -7.3059e-02,  2.6463e-02],\n        [-6.3769e-02,  2.1218e-02,  1.3541e-02, -1.2087e-01, -1.4099e-01,\n          6.4242e-02,  5.6581e-02,  1.3956e-01,  2.0116e-02,  1.3767e-01,\n          3.4109e-02, -2.2252e-02,  7.9284e-02,  7.0319e-02, -1.4828e-01,\n          1.3785e-02, -3.6392e-02, -1.5279e-01,  1.9958e-02, -7.2151e-02,\n         -1.0741e-01,  1.1192e-01,  7.7751e-02,  1.1245e-01, -5.2507e-02,\n          1.9668e-02, -1.3843e-01, -4.7254e-02,  7.6925e-02, -9.8041e-02,\n         -1.5812e-01, -1.7173e-01],\n        [ 6.4906e-02,  1.3827e-01, -1.3610e-01,  1.4922e-01,  1.5452e-01,\n          1.5140e-01, -1.5659e-01, -1.2018e-01,  2.0577e-02,  1.5024e-01,\n          7.0362e-02,  1.3814e-01, -1.2847e-02,  6.9968e-02, -1.3718e-01,\n         -1.1906e-01, -1.6076e-01,  5.2729e-02,  1.7483e-01, -6.3462e-03,\n         -2.1095e-03, -1.0304e-01, -6.3541e-04, -1.3559e-01, -4.5898e-02,\n         -2.3952e-02,  4.6414e-02,  1.2307e-01,  1.4496e-01,  1.6931e-01,\n          8.9046e-02,  1.5107e-01],\n        [ 9.2693e-02, -2.6500e-02, -1.4645e-01,  1.1776e-01,  1.2395e-01,\n         -1.3439e-01, -1.1231e-02, -1.1205e-01, -1.9115e-02,  9.0832e-02,\n         -1.5395e-01, -1.4803e-01,  4.3161e-02, -6.3699e-02,  1.4730e-02,\n         -1.1967e-03,  1.3527e-01,  4.6354e-03, -1.1051e-01,  1.4855e-01,\n          8.7370e-02,  1.7125e-01, -1.0084e-01, -1.6860e-01,  4.7421e-02,\n          1.4554e-02,  1.7645e-01,  4.9448e-02, -3.3021e-02, -9.6003e-02,\n          1.4351e-01, -8.9978e-02],\n        [-4.1064e-02, -6.6222e-02,  4.9875e-02, -1.0884e-01, -6.1865e-02,\n         -4.0354e-02,  1.0153e-04, -9.2600e-02,  7.6463e-02,  2.9492e-02,\n         -1.6306e-02, -4.5840e-03, -9.8045e-02,  8.3140e-02,  1.3531e-01,\n          4.8207e-02,  3.6174e-02,  6.6025e-02, -9.4849e-02,  1.6718e-01,\n          4.3675e-02,  2.7908e-02, -4.8016e-02,  5.1710e-02,  1.3462e-01,\n         -8.2470e-02, -8.1850e-02, -9.6620e-03, -1.4878e-01,  1.6955e-01,\n          1.9878e-03, -9.7326e-02],\n        [-4.3022e-02, -1.0972e-01,  1.6634e-01,  1.3900e-01, -7.9853e-02,\n          5.8582e-03, -9.1798e-02, -1.6997e-01,  1.5857e-01,  1.4814e-02,\n         -6.8724e-02,  1.4816e-01,  2.5922e-02,  1.3629e-01,  1.1748e-02,\n          3.1494e-02,  1.1662e-01, -4.6159e-02,  8.7967e-02, -7.0631e-02,\n         -2.1621e-02,  9.1070e-02,  5.5696e-02, -5.6680e-02,  1.6212e-02,\n          9.2048e-02, -1.3052e-01,  6.1482e-02,  4.7582e-02, -3.0755e-02,\n         -1.2217e-01,  1.0964e-01]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0214,  0.0615, -0.0951, -0.2465, -0.2279, -0.1584,  0.0472,  0.2338],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0713, -0.0726, -0.1160,  0.0147,  0.1710, -0.0243,  0.2491,  0.2027,\n          0.2479,  0.1164, -0.2179,  0.0760, -0.0489, -0.1785,  0.1216,  0.1303],\n        [ 0.0358,  0.1248, -0.1380, -0.0214, -0.0997,  0.2382, -0.0926, -0.2314,\n         -0.1595, -0.0705, -0.1166, -0.2343, -0.0191,  0.0186, -0.0808, -0.2200],\n        [ 0.1172, -0.2258, -0.1489, -0.1113, -0.0055,  0.1032,  0.0835, -0.1986,\n         -0.1349,  0.1569, -0.2058, -0.1557,  0.1451,  0.2152, -0.1822,  0.0386],\n        [ 0.0683,  0.1675, -0.2169,  0.1256,  0.0756, -0.0782, -0.1978, -0.1371,\n          0.0012,  0.0141,  0.0928, -0.0235, -0.1773,  0.1466, -0.0551,  0.2082],\n        [ 0.2148, -0.1022,  0.1015, -0.1741, -0.1145, -0.0169,  0.0671, -0.0490,\n         -0.2009,  0.0196,  0.1233,  0.0476, -0.0645, -0.1109, -0.1020, -0.0137],\n        [-0.1703, -0.0012,  0.1337,  0.0526,  0.0156,  0.0207, -0.1976, -0.1662,\n         -0.0282, -0.0615,  0.1988,  0.2311, -0.1279,  0.1157, -0.0158,  0.0336],\n        [ 0.0794,  0.1336, -0.0651,  0.1407, -0.2302, -0.0861,  0.0866, -0.2279,\n         -0.1712,  0.0512, -0.0554, -0.0949, -0.1044, -0.1554,  0.1404,  0.1884],\n        [-0.1625,  0.0011,  0.1859,  0.1217, -0.0724, -0.2104, -0.1767,  0.1821,\n         -0.1765, -0.2116,  0.1256,  0.1698,  0.1037, -0.0174, -0.0367,  0.2172]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.1910], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.2780, -0.0132, -0.3306, -0.1766, -0.3214,  0.1177,  0.0866, -0.2512]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    20,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	20,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "flatten_obs_dim":	20,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 0.0632, -0.4419,  0.3563,  0.2165],\n        [ 0.2095,  0.0356, -0.1185, -0.3154],\n        [ 0.0717, -0.0210, -0.2454, -0.3737],\n        [ 0.4463,  0.2779,  0.1329, -0.3670],\n        [ 0.1552, -0.1251,  0.0185,  0.1468],\n        [-0.3943,  0.4977,  0.3398, -0.1852],\n        [ 0.2781,  0.2587,  0.1379, -0.2130],\n        [-0.1416,  0.4271,  0.2758, -0.3295],\n        [-0.3293, -0.3753, -0.4520,  0.2479],\n        [-0.1351, -0.4139,  0.4458,  0.3377],\n        [ 0.2305, -0.0384,  0.0072, -0.3062],\n        [-0.1072, -0.1312,  0.3387,  0.1578],\n        [-0.3407,  0.4706, -0.3454, -0.0457],\n        [ 0.3513,  0.3823,  0.3258,  0.3299],\n        [ 0.4326, -0.3508, -0.4905,  0.1367],\n        [ 0.2463, -0.4672, -0.4511,  0.3856],\n        [-0.3135,  0.2919, -0.4915,  0.3666],\n        [-0.1271, -0.0574, -0.2147,  0.4327],\n        [-0.1119,  0.0751,  0.2946, -0.3747],\n        [-0.3645, -0.2759, -0.0303, -0.4298],\n        [ 0.4937,  0.0489, -0.0897, -0.0142],\n        [-0.4062,  0.1403,  0.1774,  0.4790],\n        [-0.2001, -0.4438, -0.2746, -0.2724],\n        [ 0.3276,  0.4617, -0.0917,  0.0179],\n        [-0.1970, -0.1517, -0.2264, -0.0473],\n        [ 0.2983,  0.4599,  0.0143, -0.3361],\n        [-0.2633,  0.0238, -0.1670, -0.0008],\n        [ 0.0431,  0.4538, -0.2475, -0.0347],\n        [-0.0446, -0.0874,  0.0425, -0.3430],\n        [ 0.1025, -0.4714, -0.4374,  0.0166],\n        [ 0.3876, -0.3774,  0.0841, -0.2666],\n        [ 0.4966,  0.4791, -0.2885, -0.4277]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2205,  0.2472, -0.2525, -0.1125,  0.4888, -0.4616, -0.3609, -0.4120,\n         0.1544, -0.1298,  0.3635, -0.3798,  0.0308,  0.0206, -0.3258, -0.0599,\n         0.4426, -0.3620, -0.2833, -0.3660, -0.3639,  0.4879,  0.3522,  0.1222,\n        -0.0812,  0.0477, -0.1494,  0.3055, -0.3764, -0.3337, -0.4640, -0.0310],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0116,  0.0362,  0.0357, -0.0681, -0.0096,  0.0402,  0.0933,  0.0627,\n          0.1338, -0.0582,  0.1000, -0.1377,  0.0646,  0.0568, -0.1581, -0.0210,\n          0.1303,  0.0524, -0.0190, -0.0171, -0.1240, -0.1516, -0.0299,  0.1588,\n          0.1563, -0.1170, -0.0379,  0.0253, -0.1557, -0.0086, -0.0760,  0.1109],\n        [-0.0699, -0.1249, -0.0102, -0.1067, -0.0336, -0.0869, -0.0853, -0.0623,\n          0.1483, -0.0720, -0.0643,  0.0572,  0.0467, -0.0015,  0.0302,  0.1657,\n         -0.1587,  0.0095, -0.1337,  0.1371,  0.0169, -0.0407, -0.0749, -0.0840,\n         -0.1684, -0.1752, -0.1545, -0.1681, -0.0575, -0.1763, -0.0494, -0.0071],\n        [ 0.0265,  0.0352, -0.1207,  0.0112,  0.1151,  0.1354,  0.1550,  0.1204,\n          0.0005, -0.1102, -0.0630, -0.0192,  0.0184, -0.1438, -0.0651,  0.1688,\n         -0.0710, -0.0499,  0.1090, -0.0332, -0.0504, -0.1150,  0.0753,  0.1176,\n         -0.0644,  0.0606,  0.0933,  0.1330,  0.1095,  0.0392,  0.0220,  0.0576],\n        [-0.0652,  0.0824,  0.0610,  0.0377,  0.0363,  0.0249, -0.0530, -0.1654,\n         -0.1585, -0.1128,  0.0544,  0.1259,  0.0927,  0.0528,  0.0209,  0.1737,\n         -0.1717,  0.1395, -0.0519,  0.1228, -0.0776,  0.1304, -0.0973, -0.0256,\n         -0.1626, -0.1207,  0.0861,  0.0182, -0.0175,  0.0877, -0.1536, -0.0250],\n        [ 0.0814,  0.0027,  0.0147,  0.0736,  0.1442, -0.0734, -0.1580, -0.1635,\n          0.1626,  0.0831,  0.1284, -0.0475,  0.0957, -0.1435, -0.0829,  0.1581,\n          0.1427, -0.0447,  0.0101,  0.0020, -0.0346, -0.0790,  0.0522, -0.0652,\n          0.1683,  0.0407,  0.0213,  0.0276, -0.0496, -0.0387, -0.0507, -0.0121],\n        [-0.0150,  0.1633, -0.0194, -0.1308, -0.1689, -0.0198,  0.0766, -0.0592,\n         -0.0439,  0.0842, -0.1553,  0.0066,  0.0194,  0.0336,  0.1615, -0.1491,\n          0.0695, -0.1714,  0.1504,  0.0912, -0.0393,  0.0636,  0.0381,  0.0616,\n          0.0222, -0.1407,  0.1165, -0.0321,  0.0529,  0.1067,  0.0814,  0.0711],\n        [-0.1437,  0.1305,  0.0990,  0.1636, -0.0198,  0.1353, -0.0352, -0.1353,\n         -0.1673, -0.0449,  0.1054, -0.1228, -0.0006,  0.1484,  0.0705,  0.1552,\n          0.1081,  0.1309,  0.1012, -0.1286,  0.0365, -0.1728, -0.1566,  0.0218,\n          0.0286, -0.1484,  0.0966,  0.0461,  0.0699, -0.1191,  0.0513,  0.0956],\n        [-0.1488, -0.1385,  0.0875,  0.1694, -0.1289,  0.0888,  0.0248, -0.1082,\n          0.0535,  0.0744, -0.0176, -0.0456, -0.1449, -0.1756, -0.0115,  0.1755,\n         -0.0014, -0.0425, -0.1561, -0.1718, -0.0903, -0.1352, -0.0768,  0.0811,\n         -0.1470, -0.0284, -0.1685, -0.0086,  0.0685, -0.0174, -0.1326, -0.1311],\n        [-0.0083,  0.1227, -0.0544, -0.0293, -0.1480, -0.1255,  0.1108,  0.0441,\n         -0.1371, -0.1177, -0.0390, -0.0433,  0.1317, -0.0408, -0.0833,  0.0320,\n         -0.0509, -0.0671, -0.0058,  0.0651, -0.0738, -0.0028, -0.0445,  0.0267,\n          0.0585, -0.1452, -0.0663,  0.1153,  0.1606, -0.0142,  0.0971,  0.1016],\n        [ 0.0444,  0.1712, -0.1285, -0.0533,  0.0938, -0.1202,  0.0791,  0.1530,\n          0.0176, -0.1683, -0.0213, -0.0369,  0.0553, -0.0619,  0.1502,  0.0005,\n         -0.0792, -0.1194, -0.1015,  0.0889, -0.0541,  0.1625,  0.0717,  0.1616,\n          0.0299,  0.0862, -0.1723,  0.0221, -0.0051, -0.0897, -0.0997,  0.0997],\n        [ 0.1298, -0.0679, -0.0641, -0.1758,  0.1423,  0.0170, -0.0065, -0.0076,\n         -0.0185,  0.0312,  0.1373,  0.0653,  0.0121,  0.1090,  0.1132, -0.1189,\n          0.0043,  0.0803,  0.1460, -0.0886,  0.1309, -0.0559, -0.0084,  0.1669,\n         -0.0768, -0.1610, -0.1648,  0.0251, -0.0861,  0.1650, -0.0456, -0.0634],\n        [ 0.0500, -0.1115,  0.1324,  0.0757, -0.0854,  0.1298, -0.0573, -0.0923,\n         -0.0659, -0.0248,  0.0091, -0.1040,  0.0973,  0.1144, -0.0426, -0.1708,\n         -0.0362,  0.1697,  0.0442,  0.0261, -0.1396,  0.0557,  0.0541, -0.0625,\n          0.0694, -0.0746, -0.0971,  0.0878, -0.1760, -0.0419,  0.0397, -0.0247],\n        [ 0.1690, -0.0251,  0.0547,  0.0103,  0.0756, -0.0336, -0.1580,  0.1513,\n          0.1673,  0.0997, -0.1690,  0.1751,  0.1003,  0.1185, -0.1290, -0.1308,\n         -0.0415, -0.1423,  0.0541,  0.1497,  0.1462, -0.0319,  0.1463, -0.1742,\n         -0.1486,  0.1611, -0.1676,  0.0579, -0.1755, -0.0120,  0.1536,  0.1164],\n        [-0.0523,  0.1443,  0.1281, -0.0079, -0.0675,  0.0989,  0.1171,  0.1326,\n          0.0847,  0.0841,  0.0060,  0.0477,  0.1512,  0.0271, -0.0688,  0.0738,\n          0.0280, -0.1474, -0.0257, -0.1530, -0.1189,  0.1683,  0.0546,  0.0369,\n         -0.0857, -0.0696,  0.0178,  0.0691, -0.1031, -0.0093, -0.0847,  0.1498],\n        [ 0.0025,  0.0039, -0.0922,  0.0166, -0.0749,  0.0663, -0.0449, -0.1499,\n         -0.0243, -0.0348, -0.1196,  0.0741, -0.0092,  0.1700, -0.1569,  0.0782,\n          0.0328,  0.0262, -0.0510, -0.1574, -0.0761, -0.0415,  0.0749,  0.0056,\n         -0.0531, -0.0157,  0.1395, -0.1577, -0.1098,  0.0169,  0.0521, -0.0445],\n        [ 0.0110, -0.1461,  0.0832,  0.0714,  0.0133,  0.0962,  0.0656,  0.1469,\n         -0.1388,  0.0979, -0.1291,  0.1562, -0.0990, -0.0598,  0.0191, -0.1255,\n          0.0740, -0.1264, -0.1661,  0.1665,  0.0605,  0.1657, -0.0082,  0.1573,\n          0.0511, -0.1278,  0.0219, -0.1082,  0.0444,  0.0216,  0.1318, -0.0230]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1336,  0.0491,  0.0139,  0.1640,  0.1271, -0.0285, -0.0042,  0.0683,\n         0.1641,  0.0781, -0.1460,  0.0571,  0.1644,  0.1513,  0.0821,  0.0927],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.1589, -0.1379,  0.0516,  0.1929, -0.1686,  0.1280,  0.0831,  0.1186,\n         -0.2435,  0.1155,  0.2314, -0.2167, -0.2052, -0.1340, -0.1583,  0.0925],\n        [ 0.0661, -0.2397,  0.2310,  0.2433,  0.2097, -0.0121, -0.1277, -0.0828,\n          0.2482,  0.0983, -0.1192,  0.0183, -0.1286, -0.0711,  0.1154,  0.1608],\n        [-0.0817, -0.1972,  0.0203,  0.0695, -0.1696, -0.1641,  0.1845, -0.0312,\n          0.2491, -0.1499, -0.0513,  0.1198,  0.1735,  0.2378, -0.1886,  0.2235],\n        [-0.1411, -0.0065,  0.0722, -0.0542,  0.1835, -0.1541,  0.1686, -0.0089,\n          0.0493,  0.1441,  0.2106, -0.0241, -0.0933, -0.2415, -0.0193,  0.0208],\n        [-0.1054,  0.1030,  0.2346,  0.1592,  0.1515,  0.0823, -0.1069,  0.1256,\n         -0.1380,  0.0694, -0.0629, -0.1330,  0.2006, -0.1465, -0.2311, -0.1813],\n        [ 0.2434, -0.2245,  0.2260,  0.2107, -0.0029,  0.1146, -0.0922, -0.2049,\n         -0.0080, -0.0107, -0.1809, -0.0072, -0.2219,  0.1300,  0.2473, -0.1781],\n        [ 0.0184,  0.2327,  0.2055,  0.1104, -0.0464, -0.1505, -0.0965, -0.2320,\n         -0.0532,  0.1589,  0.1070, -0.2049, -0.1569,  0.1039,  0.1606,  0.0103],\n        [ 0.1838,  0.2001,  0.2227, -0.1088, -0.0516,  0.1971, -0.1135,  0.0076,\n         -0.1830, -0.1323,  0.1223,  0.0431,  0.2247, -0.1696,  0.0732,  0.1769]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1663,  0.1198, -0.2030,  0.0764, -0.2439,  0.1818,  0.1226,  0.0039],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.2695,  0.0086,  0.0678,  0.0502,  0.0154, -0.2418,  0.2852, -0.0594]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2412], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x10fb90dc0>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	50000,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	40,
            "_train_v_iters":	40,
            "_traj_per_epoch":	5,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 1.8801e-01,  1.1243e-01, -3.4134e-02, -4.0000e-02, -4.9381e-02,\n         -1.1615e-01, -2.2121e-01,  2.0366e-01,  2.3945e-02,  1.7725e-01,\n          8.8106e-03,  1.2925e-01,  4.5483e-02, -6.9034e-02,  2.0176e-01,\n         -1.4892e-01, -2.0769e-01, -1.7339e-01, -1.5885e-01, -1.5754e-01],\n        [ 2.0840e-01,  1.3724e-01, -8.9089e-02,  1.3800e-01,  2.0577e-01,\n          5.2711e-02, -9.6116e-02, -1.4832e-01,  1.3698e-01, -2.4120e-02,\n          1.0061e-01,  5.3775e-02, -1.5570e-02,  7.6753e-02, -3.0296e-02,\n          3.8507e-02,  1.3707e-01,  1.8889e-02, -9.5702e-02, -3.0434e-02],\n        [ 9.0559e-02, -1.2412e-01, -5.0395e-02,  1.7237e-01,  1.4628e-01,\n         -5.4664e-02,  1.0429e-01, -1.2032e-01, -1.3275e-01,  2.2031e-01,\n         -4.5230e-02,  4.5706e-02, -1.3823e-01, -8.8763e-02, -1.2435e-01,\n         -5.9168e-02,  2.1520e-01,  8.1299e-02,  1.3979e-01,  2.6494e-03],\n        [ 6.0551e-02, -2.1787e-01, -2.0698e-01,  5.2164e-02,  8.1458e-02,\n          4.6994e-02, -1.6340e-02, -2.0946e-02, -1.5908e-02, -2.1187e-01,\n         -2.3213e-02,  9.5485e-03, -7.1915e-02,  2.1025e-01, -2.0255e-02,\n         -2.3059e-02, -1.6677e-01, -1.9382e-01, -1.1604e-01, -1.0754e-01],\n        [-5.5014e-03,  2.1868e-01, -1.3660e-01, -1.9126e-01,  1.6443e-01,\n         -2.7885e-02, -2.0066e-01,  5.5803e-02, -1.9308e-01, -1.8607e-01,\n         -1.6858e-01,  2.7283e-02, -7.6867e-02, -1.4666e-01,  5.0283e-02,\n         -2.3255e-02, -1.4357e-01, -1.9953e-01, -5.2285e-02,  2.6771e-02],\n        [ 3.6544e-02,  4.5343e-02,  1.8599e-01, -1.8087e-01,  1.3931e-01,\n          1.8681e-01,  2.0565e-01,  1.3965e-01,  1.8968e-01, -7.3341e-02,\n          1.6976e-01, -8.4367e-02, -1.4753e-01,  2.1450e-01,  4.3090e-02,\n         -2.1752e-01, -3.6102e-02, -6.7443e-02,  1.7514e-01,  1.3014e-01],\n        [-4.4126e-02, -3.2031e-02,  1.9995e-01, -2.0826e-02,  1.1498e-01,\n         -1.6128e-01,  9.3597e-02,  1.5243e-01,  1.1672e-01,  2.9792e-02,\n         -4.6309e-02, -1.6075e-01, -9.8251e-02,  1.8163e-01,  6.2315e-02,\n         -5.3270e-02, -1.5918e-01, -2.4804e-02, -1.7310e-01, -1.4061e-01],\n        [-2.1653e-01,  1.2575e-01, -1.0291e-01, -7.2356e-02, -1.8144e-01,\n         -2.1608e-01, -1.5423e-01,  1.8235e-01, -3.5848e-02, -5.4766e-03,\n         -2.0117e-01,  1.9588e-01,  1.1174e-01, -9.5058e-02, -2.2030e-01,\n         -1.4675e-01,  9.0053e-02, -1.6298e-01, -1.5353e-01,  8.5798e-02],\n        [ 1.9105e-01, -1.4307e-01,  1.0489e-01,  7.5907e-02, -7.1487e-02,\n         -1.0883e-01,  1.5756e-02, -3.7232e-02, -5.1092e-02,  1.1471e-01,\n         -1.6155e-01,  7.9441e-02, -2.2151e-01, -2.2291e-01, -1.8407e-01,\n         -9.5160e-02, -4.3251e-02, -6.3477e-02, -1.4080e-01,  2.1126e-01],\n        [ 1.3354e-01, -1.9036e-01,  1.9554e-01,  1.6569e-01, -1.7877e-01,\n          2.1583e-01, -1.4401e-01,  2.9067e-02,  7.1468e-02, -1.3113e-01,\n         -5.9876e-02,  1.1734e-01, -1.8042e-01, -1.6167e-02, -8.7035e-03,\n          1.8857e-01, -7.8170e-02, -4.7574e-02,  2.0257e-01,  2.1000e-01],\n        [ 1.0049e-01,  5.4411e-02, -5.4294e-02, -1.5685e-01,  1.0091e-01,\n          1.2528e-01, -9.3059e-02,  5.6180e-02, -4.7347e-02, -8.0352e-03,\n         -1.5625e-01, -1.6086e-01,  1.7425e-01,  4.8215e-04,  1.0358e-01,\n          1.5367e-01, -2.1376e-01, -2.1115e-01,  5.0744e-02,  2.1238e-01],\n        [ 6.0933e-02,  1.0314e-01, -2.1813e-01, -3.0036e-02,  1.1983e-01,\n         -1.4590e-01,  1.3782e-01,  1.7987e-02,  5.9536e-02,  1.7260e-01,\n         -1.0687e-01, -3.9547e-02,  1.1216e-01,  1.9587e-01,  1.8920e-01,\n          1.5861e-01, -1.1046e-01,  1.4984e-01,  5.8074e-02, -9.5319e-04],\n        [ 9.0363e-02,  7.0810e-02, -1.9964e-01, -7.2943e-02, -1.5089e-01,\n         -9.5556e-02,  8.7073e-02, -9.3929e-02,  4.7275e-02,  3.9449e-02,\n          1.2208e-01, -1.5599e-01, -2.9729e-02, -3.3709e-03, -1.7982e-01,\n          1.5350e-01, -6.0866e-03,  8.4750e-02, -3.2187e-02, -1.3847e-01],\n        [-2.0558e-01,  3.3473e-02, -3.2938e-02, -1.6025e-01,  5.8676e-02,\n         -2.1372e-01,  1.1618e-01, -1.7599e-01, -1.0444e-02, -7.0881e-02,\n          2.5438e-02,  4.7993e-02,  5.6784e-02, -1.4320e-01, -5.0792e-02,\n         -1.8950e-01,  7.6758e-02,  4.6221e-02,  9.5130e-02,  2.2147e-01],\n        [-1.5621e-01, -3.0688e-02, -1.4653e-02, -1.1249e-01, -1.5023e-01,\n         -1.7148e-02, -2.8234e-02, -2.0870e-01, -2.0059e-01,  1.6734e-01,\n         -1.9317e-01, -8.4389e-02,  9.8673e-03, -1.3571e-01, -3.0620e-02,\n         -2.1156e-02, -1.4744e-01,  2.5241e-02, -1.6584e-01, -5.8782e-03],\n        [ 8.3593e-02,  6.0766e-02, -1.6334e-01, -1.2139e-01,  1.6154e-01,\n          6.5601e-02,  7.1174e-04, -2.2341e-01,  1.6064e-01,  7.2798e-02,\n          2.6763e-02, -1.3920e-01,  1.4803e-01, -8.0913e-02,  1.5750e-01,\n         -1.0597e-01,  8.9131e-02, -8.1385e-02,  2.1147e-01, -9.3045e-02],\n        [-7.5282e-03,  2.1853e-01, -1.1344e-01,  1.3856e-01,  2.1832e-01,\n          5.4166e-02, -3.4030e-02,  1.1130e-01, -8.8501e-02, -2.1174e-01,\n          5.4715e-03, -1.5794e-01, -5.7099e-02, -1.3077e-01, -9.4606e-02,\n          1.9522e-01,  2.3634e-02, -1.2319e-01,  1.5432e-01,  9.5826e-03],\n        [-5.0410e-02,  2.1496e-01,  1.8354e-01, -2.2121e-01,  4.4270e-02,\n         -2.1411e-01, -3.6953e-02, -1.2448e-01,  5.1905e-02,  6.8742e-02,\n          2.0070e-01, -1.8979e-01, -3.3683e-02,  4.5276e-02,  6.9683e-02,\n         -2.5656e-02, -2.2095e-01,  5.5965e-02, -1.1492e-01, -1.6436e-01],\n        [ 5.3827e-02,  2.1886e-01,  1.5473e-01,  9.6268e-02,  1.4730e-02,\n          1.2482e-01,  1.5307e-01, -2.0147e-01,  1.9793e-01, -8.7295e-02,\n         -2.2509e-02,  6.7707e-02,  8.2821e-02, -2.0054e-01,  1.4258e-01,\n         -4.8845e-02,  1.8891e-01,  1.0808e-01,  8.6249e-02, -1.2913e-01],\n        [ 1.8013e-01,  6.1808e-02, -1.0304e-01,  8.5183e-02, -2.0797e-01,\n          1.4191e-01, -9.7683e-02,  1.6502e-01,  1.5658e-01,  1.6905e-01,\n         -5.9166e-02,  2.0721e-01,  7.4223e-02,  1.4431e-01, -1.2276e-01,\n         -1.7620e-01,  2.1095e-01, -1.9197e-01, -2.4483e-02, -2.1301e-01],\n        [-8.1655e-02, -1.4909e-01,  1.7920e-02, -9.7853e-02,  7.8726e-02,\n         -1.0910e-01,  1.9320e-01, -3.2770e-02,  1.8567e-01, -7.1892e-02,\n         -5.8134e-02, -2.6014e-02,  9.9795e-02, -1.7735e-01, -1.4511e-01,\n          3.6126e-02,  1.4247e-01,  7.1346e-02,  1.7797e-01, -6.6481e-02],\n        [-2.0981e-02, -1.4246e-01,  9.4116e-03,  1.9230e-01, -5.0205e-02,\n         -1.1326e-01,  1.1240e-01,  1.8395e-01, -1.6506e-01, -3.8271e-02,\n          6.7977e-02, -1.9834e-01, -1.5585e-02,  7.6288e-02, -9.4688e-02,\n          2.1757e-01,  7.7202e-02,  9.5321e-02, -1.9914e-01,  1.9169e-01],\n        [ 2.0961e-01,  1.5555e-01, -8.3831e-02, -1.9944e-01,  8.1309e-02,\n          3.1555e-02,  1.8735e-01,  1.1135e-01, -1.8488e-01,  5.7583e-02,\n          2.0973e-01,  1.2120e-01, -2.0515e-01,  3.3819e-02, -1.4589e-01,\n          1.2106e-01, -2.5804e-02,  8.7036e-02, -1.9869e-01,  5.1659e-03],\n        [ 7.3889e-02,  1.3008e-01, -1.3501e-01, -6.9123e-02,  2.0939e-02,\n          1.4279e-01,  1.4072e-01,  1.5853e-01,  1.1510e-01,  1.0382e-01,\n         -2.0023e-01, -2.9755e-03,  1.9727e-01, -1.8856e-01, -4.5614e-02,\n          1.8628e-01, -7.1386e-02,  4.3048e-03, -8.9549e-02,  1.9670e-02],\n        [-1.5516e-01, -4.2055e-02,  1.1003e-01,  5.4645e-02,  1.8142e-02,\n          1.2883e-01,  1.6340e-01, -8.7411e-02,  3.8126e-02, -2.4041e-03,\n          8.3614e-02,  5.6662e-02,  4.7429e-02, -2.0219e-01,  3.7138e-02,\n          4.3895e-02,  1.3907e-01, -1.6407e-01, -1.5603e-01,  4.8885e-02],\n        [ 1.8521e-01, -1.7285e-01,  1.5712e-02,  8.9517e-02,  1.8134e-01,\n          1.4123e-01,  1.6139e-01, -9.5239e-02,  8.4087e-02,  1.6558e-01,\n          7.9640e-02, -9.2888e-02, -1.8874e-01, -1.9639e-02, -7.6445e-02,\n          1.2734e-01, -2.0771e-01,  3.2548e-02,  1.7688e-01,  8.4989e-02],\n        [ 1.5672e-01, -3.3281e-02,  9.9708e-03, -1.7173e-01, -3.3034e-03,\n         -8.1386e-02,  3.8977e-02,  1.6675e-02, -8.4997e-02,  1.8771e-01,\n         -2.1996e-01,  6.0205e-02,  1.5065e-01, -1.3707e-01,  1.2638e-04,\n         -1.4011e-01, -2.2227e-01, -1.5114e-01,  4.8555e-03, -1.7756e-01],\n        [-1.5958e-01,  1.9990e-01, -1.1501e-01, -6.5293e-02,  1.1484e-01,\n         -6.8726e-02, -2.7489e-02,  2.5368e-02,  6.9966e-02,  1.2319e-01,\n          1.5755e-01, -1.7751e-01, -2.6884e-02, -3.4782e-02,  1.9717e-01,\n          1.6568e-01,  5.7988e-03,  1.4031e-01, -4.6856e-02, -1.5191e-01],\n        [-3.7077e-02, -1.2561e-01, -2.0876e-01,  1.9666e-01,  5.6781e-02,\n          1.6362e-03,  1.0206e-01,  4.7419e-02,  1.3638e-01,  7.2296e-02,\n          1.9308e-01, -1.4665e-01, -7.0423e-02,  5.9850e-02,  1.6657e-01,\n         -1.0526e-01, -2.6654e-02,  7.0083e-02, -3.9492e-02,  1.6936e-01],\n        [-5.6932e-02,  1.8325e-01, -1.9685e-01,  2.1064e-01,  2.2277e-01,\n          2.7684e-02, -1.7882e-01,  1.6601e-01,  1.0063e-01, -5.8036e-02,\n          1.7474e-01, -1.0718e-01, -1.6344e-01,  1.6302e-01,  5.7594e-02,\n          4.1836e-02,  1.6008e-01, -1.4438e-01,  1.2561e-01,  7.0519e-02],\n        [-1.7789e-01, -1.6392e-01,  5.5731e-02, -3.5654e-02, -1.7137e-01,\n          1.5724e-01,  1.5948e-01,  1.3690e-01, -9.3825e-02, -7.1903e-02,\n         -2.0968e-03, -2.0889e-01,  7.6270e-02, -7.7856e-02,  1.3577e-01,\n         -2.1535e-01,  2.0485e-01, -1.4668e-01,  2.2327e-01,  6.6186e-02],\n        [-5.2220e-02,  1.2311e-01, -1.7264e-01, -3.8529e-02,  5.6280e-02,\n         -7.3536e-02, -1.9149e-01,  2.7162e-02,  1.7381e-01,  2.1924e-01,\n          1.3855e-01, -1.7132e-01, -1.4871e-01,  4.4587e-02, -8.7145e-02,\n         -1.5971e-01,  2.0088e-01, -1.8876e-01, -1.5788e-01,  8.6600e-02]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.0652,  0.0879,  0.1528,  0.1849,  0.2168,  0.1597,  0.0194, -0.2120,\n        -0.1130, -0.0617, -0.0948, -0.1830, -0.1599,  0.1440,  0.2135, -0.0561,\n         0.0694, -0.1728, -0.0573,  0.1050, -0.0044,  0.1586, -0.0632,  0.0109,\n        -0.2065, -0.0399,  0.1805, -0.1390,  0.0444, -0.1823, -0.1552, -0.0602],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 4.6623e-03,  9.2448e-02,  8.1225e-02,  1.6996e-02,  1.2393e-01,\n          3.1542e-02, -1.7323e-02, -9.7961e-02, -1.0359e-01, -3.5987e-02,\n          1.5164e-01, -1.4054e-01,  1.1892e-01,  6.6194e-02,  1.7267e-01,\n         -1.5310e-01,  5.4809e-02, -1.6615e-01, -3.1546e-02, -1.3195e-01,\n          7.9201e-02,  6.8535e-02, -8.8169e-02,  1.1161e-01, -1.5562e-01,\n          1.3617e-01,  1.3535e-01, -1.4421e-01, -1.6935e-01,  4.1849e-02,\n         -1.5217e-01,  1.2056e-04],\n        [ 3.2901e-02, -1.7481e-01, -1.2263e-01, -1.4384e-01,  1.6142e-01,\n         -1.7202e-03,  1.6426e-01, -6.0329e-02, -8.2258e-02,  2.8513e-02,\n          1.2764e-01, -6.7546e-02,  9.7226e-02,  1.4544e-01,  4.1572e-02,\n          1.1855e-01, -1.3407e-01, -1.7027e-01, -5.9691e-02,  1.7588e-01,\n          1.0970e-01,  4.6822e-02,  1.5408e-01,  5.7133e-02, -1.0116e-02,\n         -4.4328e-02, -1.1959e-01, -5.1144e-02,  6.7510e-02, -1.3352e-01,\n          9.5034e-02,  5.2071e-02],\n        [ 1.1003e-01, -2.6628e-02,  9.9006e-02, -3.6202e-02,  5.4401e-02,\n         -1.2379e-01, -6.0661e-02,  1.3586e-01, -1.7041e-01, -1.4568e-01,\n         -4.4769e-02, -5.3265e-02, -4.6246e-02,  1.6276e-01,  1.7558e-01,\n         -8.2859e-02,  6.2452e-02, -1.2460e-01,  7.4462e-02,  8.8316e-03,\n         -4.2460e-02,  6.8347e-02, -7.2096e-02,  1.9788e-02,  1.3639e-01,\n          5.5230e-02, -3.7819e-02, -1.4252e-01, -2.2767e-02,  1.7275e-01,\n         -7.5573e-02,  1.7665e-01],\n        [ 2.0681e-02, -1.4715e-01,  1.2749e-02, -9.4068e-02,  1.5457e-01,\n         -1.5328e-01, -7.1709e-02, -5.8690e-02,  1.4370e-01,  2.3275e-02,\n         -1.5109e-01, -4.8113e-03, -9.4339e-02, -5.1558e-02,  1.4258e-01,\n         -2.7090e-02, -9.0417e-02,  1.0470e-02, -6.4819e-02,  9.0577e-02,\n         -1.5447e-01,  6.8490e-02, -4.3918e-02,  1.1024e-01,  3.3316e-02,\n          1.4759e-01,  6.2234e-02,  1.2606e-02, -1.2603e-01,  1.7064e-01,\n         -1.7187e-01,  1.1773e-01],\n        [-6.1240e-02,  7.2067e-03, -1.5929e-01, -1.1471e-01, -1.6523e-02,\n         -9.7612e-02,  1.2590e-01,  1.7132e-01,  1.3044e-01, -1.1423e-01,\n         -1.5658e-01,  7.2335e-02, -1.5787e-01,  1.4445e-02, -2.7652e-02,\n          5.8000e-03,  5.3477e-02, -5.1769e-02,  1.2452e-01,  1.6840e-01,\n         -5.1389e-02,  7.5651e-02,  6.8204e-02, -5.6842e-03, -5.8430e-02,\n         -1.6278e-01, -1.2515e-01, -1.2432e-02, -1.2178e-01,  1.5407e-01,\n         -2.8927e-02,  1.2804e-01],\n        [ 6.7486e-02, -1.2107e-01,  3.5846e-02,  8.8424e-02, -1.5640e-01,\n         -8.7039e-03, -1.5230e-01,  1.3430e-01, -4.7172e-03,  3.8505e-02,\n          1.1350e-01,  1.2314e-01,  9.2766e-03,  1.0656e-01, -5.1735e-02,\n         -4.9432e-02,  6.8583e-02, -1.6729e-01, -1.7193e-01,  6.6670e-02,\n          1.7621e-01,  1.0118e-01, -7.5325e-02, -1.9363e-02, -9.4289e-02,\n         -1.7448e-01, -1.3544e-01, -1.3055e-03,  1.3974e-01,  7.1879e-02,\n          1.6874e-01, -5.9230e-02],\n        [-1.7152e-01,  5.3901e-02, -6.8018e-02,  2.4357e-03,  1.2298e-01,\n          9.4643e-02,  4.4285e-02,  4.9419e-03, -5.5308e-02,  6.8228e-02,\n          1.3670e-01, -1.4135e-01,  1.2181e-01,  2.4425e-02,  6.2252e-02,\n         -1.4969e-01,  6.1690e-02, -2.9515e-02,  1.0991e-01, -1.7027e-01,\n          6.5769e-02, -2.6484e-03,  8.8494e-02, -3.7652e-03,  7.1536e-02,\n         -1.2899e-01, -1.7030e-01, -7.0752e-02, -1.6071e-01, -1.4144e-01,\n          1.4031e-01, -5.9727e-02],\n        [-1.1880e-01,  8.5264e-02,  3.4641e-02,  1.3932e-03,  9.4805e-02,\n          1.6100e-01,  2.3359e-02, -9.1045e-02, -1.0869e-01,  9.3326e-02,\n         -8.2464e-02, -6.0605e-03,  6.7642e-02, -9.4741e-02, -8.7970e-02,\n         -1.2045e-03,  1.5448e-01, -6.8623e-02, -1.7517e-01, -3.3308e-03,\n          1.1381e-01, -3.8958e-02, -3.3124e-02, -9.3447e-02, -1.6751e-01,\n          1.3960e-01,  1.6431e-01, -8.7614e-02, -8.2335e-02,  1.1930e-02,\n         -6.5296e-02, -1.3764e-01],\n        [ 1.5817e-01, -3.1863e-02,  9.2168e-02,  5.7622e-03,  1.1031e-01,\n         -1.9086e-02,  2.8246e-02,  4.9309e-02,  1.0714e-01, -8.6440e-02,\n          9.3578e-02, -8.0888e-02,  7.6931e-02, -6.6669e-02, -9.7025e-02,\n          1.0099e-01, -7.6941e-02,  1.3246e-01,  7.9546e-02,  2.1361e-02,\n         -6.0091e-03,  2.2552e-02,  1.6427e-01,  1.6075e-01,  1.3550e-02,\n         -1.6292e-01, -3.4252e-02, -8.2837e-02,  1.3187e-01, -1.5267e-01,\n         -5.0615e-02, -1.2538e-01],\n        [-1.1392e-01,  1.6969e-01,  3.7409e-03, -3.0063e-02, -6.5220e-02,\n          1.5835e-01,  6.1701e-02, -1.4849e-02, -1.7538e-01,  1.3009e-01,\n          1.3762e-01, -1.0654e-01, -5.3428e-02,  1.1483e-01,  1.4997e-01,\n          5.5432e-02, -1.7096e-01, -1.3098e-01, -1.4701e-01, -9.9579e-02,\n          1.6501e-01,  5.0246e-02,  1.0135e-01,  1.0346e-01, -1.3947e-01,\n          1.3179e-03, -1.3675e-01,  1.7481e-01, -4.0547e-02, -1.2672e-01,\n         -4.1043e-03,  1.3955e-01],\n        [ 9.9497e-03,  6.1824e-02,  7.0436e-02,  1.3817e-01, -8.3629e-02,\n          8.5328e-02, -9.0814e-02, -5.1538e-02,  7.0297e-02, -1.6917e-01,\n          1.5697e-01,  2.3125e-02, -1.3969e-01,  1.2364e-01, -8.1618e-03,\n         -1.1767e-01,  1.3854e-02, -1.3917e-01, -1.2570e-01, -1.2417e-01,\n          9.4766e-02, -8.7636e-02, -2.0018e-02, -5.0042e-02, -5.9178e-04,\n         -5.6147e-02, -3.7346e-02,  7.2015e-03, -1.4575e-01, -3.7263e-02,\n         -7.3059e-02,  2.6463e-02],\n        [-6.3769e-02,  2.1218e-02,  1.3541e-02, -1.2087e-01, -1.4099e-01,\n          6.4242e-02,  5.6581e-02,  1.3956e-01,  2.0116e-02,  1.3767e-01,\n          3.4109e-02, -2.2252e-02,  7.9284e-02,  7.0319e-02, -1.4828e-01,\n          1.3785e-02, -3.6392e-02, -1.5279e-01,  1.9958e-02, -7.2151e-02,\n         -1.0741e-01,  1.1192e-01,  7.7751e-02,  1.1245e-01, -5.2507e-02,\n          1.9668e-02, -1.3843e-01, -4.7254e-02,  7.6925e-02, -9.8041e-02,\n         -1.5812e-01, -1.7173e-01],\n        [ 6.4906e-02,  1.3827e-01, -1.3610e-01,  1.4922e-01,  1.5452e-01,\n          1.5140e-01, -1.5659e-01, -1.2018e-01,  2.0577e-02,  1.5024e-01,\n          7.0362e-02,  1.3814e-01, -1.2847e-02,  6.9968e-02, -1.3718e-01,\n         -1.1906e-01, -1.6076e-01,  5.2729e-02,  1.7483e-01, -6.3462e-03,\n         -2.1095e-03, -1.0304e-01, -6.3541e-04, -1.3559e-01, -4.5898e-02,\n         -2.3952e-02,  4.6414e-02,  1.2307e-01,  1.4496e-01,  1.6931e-01,\n          8.9046e-02,  1.5107e-01],\n        [ 9.2693e-02, -2.6500e-02, -1.4645e-01,  1.1776e-01,  1.2395e-01,\n         -1.3439e-01, -1.1231e-02, -1.1205e-01, -1.9115e-02,  9.0832e-02,\n         -1.5395e-01, -1.4803e-01,  4.3161e-02, -6.3699e-02,  1.4730e-02,\n         -1.1967e-03,  1.3527e-01,  4.6354e-03, -1.1051e-01,  1.4855e-01,\n          8.7370e-02,  1.7125e-01, -1.0084e-01, -1.6860e-01,  4.7421e-02,\n          1.4554e-02,  1.7645e-01,  4.9448e-02, -3.3021e-02, -9.6003e-02,\n          1.4351e-01, -8.9978e-02],\n        [-4.1064e-02, -6.6222e-02,  4.9875e-02, -1.0884e-01, -6.1865e-02,\n         -4.0354e-02,  1.0153e-04, -9.2600e-02,  7.6463e-02,  2.9492e-02,\n         -1.6306e-02, -4.5840e-03, -9.8045e-02,  8.3140e-02,  1.3531e-01,\n          4.8207e-02,  3.6174e-02,  6.6025e-02, -9.4849e-02,  1.6718e-01,\n          4.3675e-02,  2.7908e-02, -4.8016e-02,  5.1710e-02,  1.3462e-01,\n         -8.2470e-02, -8.1850e-02, -9.6620e-03, -1.4878e-01,  1.6955e-01,\n          1.9878e-03, -9.7326e-02],\n        [-4.3022e-02, -1.0972e-01,  1.6634e-01,  1.3900e-01, -7.9853e-02,\n          5.8582e-03, -9.1798e-02, -1.6997e-01,  1.5857e-01,  1.4814e-02,\n         -6.8724e-02,  1.4816e-01,  2.5922e-02,  1.3629e-01,  1.1748e-02,\n          3.1494e-02,  1.1662e-01, -4.6159e-02,  8.7967e-02, -7.0631e-02,\n         -2.1621e-02,  9.1070e-02,  5.5696e-02, -5.6680e-02,  1.6212e-02,\n          9.2048e-02, -1.3052e-01,  6.1482e-02,  4.7582e-02, -3.0755e-02,\n         -1.2217e-01,  1.0964e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1004,  0.0268,  0.0659, -0.0664,  0.0863,  0.1684,  0.0995, -0.1731,\n        -0.0348, -0.0829,  0.1019, -0.1434, -0.0143,  0.1292, -0.0548, -0.1314],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0713, -0.0726, -0.1160,  0.0147,  0.1710, -0.0243,  0.2491,  0.2027,\n          0.2479,  0.1164, -0.2179,  0.0760, -0.0489, -0.1785,  0.1216,  0.1303],\n        [ 0.0358,  0.1248, -0.1380, -0.0214, -0.0997,  0.2382, -0.0926, -0.2314,\n         -0.1595, -0.0705, -0.1166, -0.2343, -0.0191,  0.0186, -0.0808, -0.2200],\n        [ 0.1172, -0.2258, -0.1489, -0.1113, -0.0055,  0.1032,  0.0835, -0.1986,\n         -0.1349,  0.1569, -0.2058, -0.1557,  0.1451,  0.2152, -0.1822,  0.0386],\n        [ 0.0683,  0.1675, -0.2169,  0.1256,  0.0756, -0.0782, -0.1978, -0.1371,\n          0.0012,  0.0141,  0.0928, -0.0235, -0.1773,  0.1466, -0.0551,  0.2082],\n        [ 0.2148, -0.1022,  0.1015, -0.1741, -0.1145, -0.0169,  0.0671, -0.0490,\n         -0.2009,  0.0196,  0.1233,  0.0476, -0.0645, -0.1109, -0.1020, -0.0137],\n        [-0.1703, -0.0012,  0.1337,  0.0526,  0.0156,  0.0207, -0.1976, -0.1662,\n         -0.0282, -0.0615,  0.1988,  0.2311, -0.1279,  0.1157, -0.0158,  0.0336],\n        [ 0.0794,  0.1336, -0.0651,  0.1407, -0.2302, -0.0861,  0.0866, -0.2279,\n         -0.1712,  0.0512, -0.0554, -0.0949, -0.1044, -0.1554,  0.1404,  0.1884],\n        [-0.1625,  0.0011,  0.1859,  0.1217, -0.0724, -0.2104, -0.1767,  0.1821,\n         -0.1765, -0.2116,  0.1256,  0.1698,  0.1037, -0.0174, -0.0367,  0.2172]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0214,  0.0615, -0.0951, -0.2465, -0.2279, -0.1584,  0.0472,  0.2338],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2780, -0.0132, -0.3306, -0.1766, -0.3214,  0.1177,  0.0866, -0.2512]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.1910], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x10fb912a0>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s38180000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/Users/girigiri_yomi/Udel_Proj/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s38180000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	40,
    "train_v_iters":	40,
    "traj_per_epoch":	5,
    "vf_lr":	0.0003
}