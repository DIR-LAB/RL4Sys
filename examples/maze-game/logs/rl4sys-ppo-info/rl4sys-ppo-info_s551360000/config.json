{
    "__class__":	"PPO",
    "buf_size":	50000,
    "clip_ratio":	0.1,
    "env_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game",
    "exp_name":	"rl4sys-ppo-info",
    "gamma":	0.99,
    "kernel_dim":	4,
    "kernel_size":	5,
    "lam":	0.97,
    "log_data_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/",
    "logger_kwargs":	{
        "exp_name":	"rl4sys-ppo-info",
        "output_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s551360000"
    },
    "pi_lr":	0.0003,
    "seed":	551360000,
    "self":	{
        "<algorithms.PPO.PPO.PPO object at 0x75d46ba2beb0>":	{
            "_clip_ratio":	0.1,
            "_model":	{
                "RLActorCritic(\n  (pi): RLActor(\n    (pi_network): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=4, bias=True)\n    )\n  )\n  (v): RLCritic(\n    (v_net): Sequential(\n      (0): Linear(in_features=20, out_features=32, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=32, out_features=16, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=16, out_features=8, bias=True)\n      (5): ReLU()\n      (6): Linear(in_features=8, out_features=1, bias=True)\n      (7): Identity()\n    )\n  )\n)":	{
                    "_backward_hooks":	{},
                    "_backward_pre_hooks":	{},
                    "_buffers":	{},
                    "_forward_hooks":	{},
                    "_forward_hooks_always_called":	{},
                    "_forward_hooks_with_kwargs":	{},
                    "_forward_pre_hooks":	{},
                    "_forward_pre_hooks_with_kwargs":	{},
                    "_is_full_backward_hook":	null,
                    "_load_state_dict_post_hooks":	{},
                    "_load_state_dict_pre_hooks":	{},
                    "_modules":	{
                        "pi":	{
                            "RLActor(\n  (pi_network): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=4, bias=True)\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "pi_network":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=4, bias=True)\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0690, -0.1046,  0.0276,  0.0462, -0.1417, -0.1345,  0.2157,  0.1809,\n        -0.0043, -0.1446,  0.1444, -0.1464,  0.0141, -0.1739, -0.2144, -0.0954,\n         0.1798,  0.0049, -0.1598, -0.1517,  0.0856,  0.1609,  0.0963, -0.1475,\n         0.0440, -0.0837, -0.0148,  0.1364, -0.0315,  0.0659,  0.1900,  0.2017],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.1798,  0.1571, -0.0386, -0.0226,  0.0768, -0.0768, -0.0452,  0.0737,\n         -0.0393,  0.2213, -0.1566, -0.0967, -0.2209, -0.1103,  0.1429,  0.2029,\n          0.0759,  0.2189,  0.0079,  0.0285],\n        [ 0.1180, -0.0287,  0.1425, -0.0831, -0.0618,  0.1839,  0.0055,  0.1836,\n          0.1351,  0.1629, -0.0435,  0.1768, -0.0821,  0.0429,  0.0899, -0.1113,\n         -0.0447, -0.1361, -0.0600,  0.2066],\n        [ 0.1616,  0.1258,  0.1356,  0.0747, -0.0506, -0.2146, -0.0304, -0.0242,\n         -0.0912,  0.2038, -0.0164, -0.1072, -0.1618, -0.1731,  0.0578,  0.1764,\n          0.2085, -0.1635,  0.0827, -0.1894],\n        [-0.0653,  0.1191,  0.1276,  0.1236,  0.0074,  0.1635,  0.1667, -0.1485,\n         -0.2185,  0.1714, -0.0778,  0.0976,  0.1648,  0.1068,  0.0246,  0.1873,\n         -0.0378,  0.0608,  0.1549,  0.0368],\n        [ 0.0490,  0.2184, -0.2023, -0.2236,  0.1737, -0.1973,  0.1133,  0.1572,\n         -0.1782, -0.1943,  0.0524, -0.0905,  0.0092,  0.0114, -0.0506,  0.0238,\n          0.0053, -0.2116,  0.1951,  0.2043],\n        [ 0.1180,  0.0357,  0.1459,  0.1854, -0.0012,  0.1529, -0.2212,  0.0663,\n         -0.0453,  0.1718, -0.0250, -0.1961, -0.1155, -0.1217,  0.0543, -0.0705,\n         -0.0353,  0.1123, -0.2139, -0.1295],\n        [-0.1708,  0.0846,  0.0896, -0.0034,  0.1292, -0.0449,  0.0737,  0.0961,\n          0.1019,  0.0303, -0.0779, -0.1468, -0.0032,  0.0241,  0.1656,  0.1956,\n          0.1912, -0.1225,  0.0183, -0.1688],\n        [-0.2166,  0.1036,  0.0791,  0.0853, -0.1208,  0.0702,  0.1406, -0.0370,\n         -0.1324, -0.1830,  0.1609, -0.0924,  0.1335, -0.0089,  0.0782,  0.1571,\n         -0.1734,  0.0854, -0.0096,  0.0653],\n        [-0.0387, -0.0480,  0.1583,  0.1522, -0.1016,  0.0522,  0.1211, -0.1517,\n          0.1643,  0.0919, -0.0867,  0.1041,  0.0516, -0.0718,  0.0020, -0.0581,\n         -0.1186, -0.0482,  0.1896,  0.1790],\n        [ 0.0300, -0.0656, -0.1044, -0.0685,  0.1110,  0.0646,  0.2004, -0.0924,\n         -0.1948, -0.1681, -0.0865, -0.0504, -0.1578,  0.1925,  0.1595, -0.0290,\n         -0.0887,  0.0659, -0.0444,  0.0068],\n        [ 0.1910, -0.1447,  0.1141,  0.0341,  0.0249,  0.1479,  0.1414,  0.1118,\n          0.2161, -0.1032,  0.1106, -0.0252,  0.2233,  0.1955,  0.0309, -0.1656,\n         -0.0862,  0.1360, -0.0309, -0.0238],\n        [-0.0676, -0.1721, -0.1876, -0.0205, -0.0101, -0.1851, -0.1335,  0.0201,\n         -0.1564, -0.0160, -0.0676,  0.0702,  0.0809, -0.1803,  0.1798, -0.0469,\n         -0.1939,  0.1875,  0.0420, -0.0524],\n        [-0.0306,  0.1751, -0.1375,  0.0952, -0.0549, -0.1174,  0.0907,  0.1514,\n         -0.1814,  0.1168,  0.1420, -0.0461, -0.0343,  0.0727,  0.1237, -0.0772,\n         -0.0859,  0.0719,  0.1697, -0.1578],\n        [-0.0497, -0.1427, -0.0847, -0.1855, -0.0682, -0.1207,  0.1974,  0.0166,\n          0.1044, -0.1770, -0.2073, -0.1310,  0.1731, -0.1368,  0.0984,  0.1064,\n         -0.1411,  0.1818, -0.1692, -0.0517],\n        [-0.1761,  0.2082,  0.0635,  0.2122,  0.1130,  0.0768,  0.1757,  0.0895,\n         -0.0170,  0.0350,  0.0555,  0.1014, -0.0405, -0.0237, -0.0142, -0.0863,\n          0.0666,  0.0690, -0.1394, -0.1471],\n        [-0.0735, -0.1651, -0.0281, -0.1452, -0.0926,  0.1703,  0.1496,  0.2190,\n          0.0365, -0.1087,  0.1368,  0.0087, -0.0538,  0.2040,  0.1246,  0.0336,\n          0.0599, -0.1688,  0.1104,  0.1260],\n        [-0.1373,  0.1417,  0.1780,  0.1909, -0.0476, -0.1859, -0.0368,  0.0559,\n         -0.2153,  0.1894,  0.1477,  0.1032,  0.1820,  0.1335, -0.1360,  0.0466,\n          0.1893,  0.1332, -0.0272, -0.0731],\n        [-0.0871,  0.1701,  0.1375,  0.0740, -0.1539, -0.1592,  0.0500, -0.1014,\n         -0.0889,  0.0167, -0.0532, -0.1547,  0.1300,  0.0191, -0.2120, -0.0230,\n          0.2083,  0.0065,  0.2229, -0.2087],\n        [ 0.1217,  0.1013, -0.0417,  0.1859, -0.2176,  0.0522, -0.0305, -0.2158,\n         -0.1084,  0.2188, -0.1191, -0.0330, -0.1335,  0.0303,  0.1167, -0.1396,\n          0.1585,  0.1864,  0.2051, -0.0174],\n        [ 0.0851, -0.2119, -0.1561, -0.0057,  0.1534, -0.1780, -0.1837,  0.0148,\n         -0.1744,  0.0422,  0.0944, -0.0065,  0.0956, -0.0757,  0.1895,  0.1192,\n          0.1515, -0.0894, -0.0330,  0.0671],\n        [ 0.0505,  0.0276, -0.0105, -0.1979,  0.0477, -0.1395,  0.0331, -0.1984,\n         -0.0320,  0.0492, -0.0295, -0.0669,  0.1360,  0.1421,  0.1791, -0.2138,\n         -0.1466, -0.0103, -0.0198,  0.0775],\n        [-0.2217,  0.0582, -0.0530,  0.2224,  0.0449,  0.0775,  0.0418,  0.0849,\n         -0.1532,  0.0653,  0.1099, -0.0919,  0.1267,  0.1694, -0.1380,  0.0237,\n          0.1772,  0.0941,  0.1078, -0.0405],\n        [ 0.0880, -0.0292,  0.1505, -0.0621, -0.2219, -0.0899,  0.1044,  0.0714,\n          0.0532,  0.1511,  0.0288, -0.1890, -0.0263, -0.0326, -0.1719,  0.1080,\n         -0.0568,  0.2025, -0.1797, -0.0552],\n        [ 0.1113,  0.1944, -0.0710, -0.1610, -0.1648, -0.2189, -0.1410,  0.1850,\n          0.1832,  0.0668,  0.2136,  0.1735,  0.0316, -0.2199, -0.1358,  0.1448,\n          0.1983, -0.0572,  0.0442,  0.1214],\n        [-0.0841, -0.0265,  0.2045, -0.1158,  0.1195,  0.0813, -0.1819,  0.0488,\n         -0.0612, -0.0392, -0.0323,  0.0973,  0.0776, -0.2060, -0.1948,  0.1177,\n         -0.0480,  0.1490, -0.1119, -0.1235],\n        [-0.1164, -0.0967, -0.1339,  0.1335,  0.2093,  0.1739, -0.2043,  0.1563,\n         -0.2040,  0.1785,  0.0128, -0.1709, -0.1207,  0.2051,  0.1972,  0.0755,\n          0.0845, -0.0802,  0.1838,  0.0529],\n        [ 0.1356,  0.1061,  0.0613, -0.2081,  0.0384,  0.0315, -0.1627, -0.1067,\n         -0.0700, -0.1423, -0.1401,  0.0096,  0.1088, -0.0760, -0.2091,  0.0048,\n         -0.0869, -0.2017,  0.0456,  0.1173],\n        [ 0.1143, -0.0886,  0.2215,  0.1811, -0.0928, -0.0772, -0.1198,  0.0368,\n          0.0015, -0.2034, -0.1501,  0.0647,  0.2100,  0.0553,  0.0871,  0.2225,\n          0.0458, -0.0512,  0.1269, -0.2082],\n        [ 0.0229,  0.1904,  0.0647,  0.1139, -0.0780,  0.1295, -0.1334,  0.0850,\n         -0.0923,  0.0863,  0.1319, -0.0078, -0.1103, -0.1623, -0.1745, -0.1060,\n         -0.1948, -0.0142,  0.0299,  0.1151],\n        [ 0.2189, -0.1201,  0.1089,  0.1997,  0.0819,  0.1649,  0.1683, -0.0571,\n         -0.1757,  0.0050, -0.0619,  0.2040, -0.0665,  0.2067,  0.1964, -0.0705,\n         -0.0486,  0.1873,  0.1033, -0.1078],\n        [-0.0434,  0.1027,  0.0481,  0.1088,  0.0955, -0.0490,  0.0915,  0.1472,\n          0.0080,  0.0636,  0.0501, -0.1121,  0.1915, -0.0167, -0.0730,  0.0705,\n          0.1671, -0.0351, -0.0685, -0.0135],\n        [ 0.1733, -0.1366, -0.1815,  0.1576, -0.0426, -0.1976,  0.0257,  0.1096,\n          0.1886, -0.2194,  0.2078, -0.2180,  0.1084,  0.1895,  0.1771, -0.0571,\n         -0.1812, -0.1733,  0.2047, -0.1462]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1552, -0.1744, -0.0837, -0.0305,  0.1475,  0.1287,  0.1679, -0.1150,\n        -0.1409, -0.1490,  0.0787, -0.0433,  0.0267,  0.1404,  0.1098,  0.0454],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0370,  0.0318,  0.1130,  0.1405, -0.0503, -0.0921, -0.1634, -0.1442,\n         -0.1622,  0.1151,  0.1586,  0.1459, -0.1531,  0.1585,  0.0078,  0.1101,\n          0.0994,  0.1575, -0.0453, -0.0139, -0.0616,  0.1703, -0.1043,  0.1207,\n          0.0090, -0.0875, -0.1144,  0.0917,  0.1285, -0.0287, -0.0114, -0.0005],\n        [ 0.0091, -0.1097,  0.0987,  0.1508, -0.1213, -0.0626, -0.1532,  0.1012,\n          0.1765,  0.1131,  0.0895,  0.0039,  0.0240, -0.0911, -0.0479, -0.0019,\n         -0.1527, -0.0393,  0.0791,  0.0757, -0.1395,  0.0544, -0.1417, -0.0928,\n          0.1051, -0.1098,  0.0860,  0.0400, -0.1227, -0.0103,  0.1612,  0.1621],\n        [ 0.0566,  0.0564, -0.0182, -0.0250, -0.0286, -0.1447, -0.1128, -0.0386,\n         -0.1675, -0.1099,  0.0259,  0.1333, -0.1124, -0.1751, -0.0473, -0.1123,\n         -0.0122,  0.1235,  0.0401, -0.1424, -0.1148, -0.0978,  0.1685,  0.0768,\n         -0.0653,  0.1537, -0.0060, -0.0892,  0.0707,  0.1056,  0.1752,  0.0494],\n        [-0.1131,  0.0688, -0.0978,  0.1493, -0.1182,  0.0534,  0.1656,  0.1190,\n         -0.0548,  0.0787,  0.0664, -0.1595, -0.1611,  0.0684, -0.0327,  0.1400,\n         -0.0858, -0.1413,  0.1377, -0.0683, -0.1290,  0.0163,  0.1192,  0.0604,\n          0.0581, -0.1732, -0.1676,  0.1210,  0.1422,  0.0579,  0.0674,  0.1359],\n        [-0.0432, -0.0238, -0.0017,  0.1152,  0.0134, -0.0152, -0.0502, -0.0007,\n         -0.1702, -0.1412, -0.0878, -0.1299, -0.1368,  0.0988,  0.1322,  0.1642,\n          0.0088, -0.0216, -0.0461, -0.0785,  0.1320, -0.1156, -0.1379,  0.1429,\n          0.1280,  0.0845, -0.1144, -0.1675,  0.1230, -0.1645, -0.0225,  0.1188],\n        [-0.0707,  0.1024, -0.1481,  0.0606,  0.1762,  0.1163,  0.1549, -0.1626,\n          0.0954, -0.0912, -0.1581, -0.1354,  0.0044,  0.0197,  0.1021, -0.0248,\n         -0.0820,  0.0867, -0.0110,  0.0542, -0.0714, -0.1439,  0.0731, -0.0535,\n          0.0126,  0.1141, -0.0731, -0.0694,  0.0116,  0.0497, -0.0473, -0.0761],\n        [-0.0104,  0.0904, -0.0301, -0.1256,  0.0815, -0.0114,  0.1745,  0.0231,\n          0.1629, -0.0058, -0.0401,  0.0052,  0.1152, -0.1656, -0.1384,  0.0896,\n          0.0723, -0.0285,  0.0544, -0.1496,  0.0026,  0.0695, -0.0990,  0.1243,\n         -0.1056, -0.0623,  0.0909, -0.0850, -0.1327, -0.1635,  0.1542, -0.0826],\n        [-0.1328,  0.0541,  0.1213, -0.1194, -0.0484,  0.0760, -0.0084,  0.1379,\n          0.1692,  0.0375, -0.1367,  0.0197, -0.1434,  0.1223, -0.0985, -0.1494,\n          0.1435,  0.0549, -0.1329, -0.1683, -0.0993,  0.0864,  0.0571,  0.1398,\n         -0.1416,  0.1239, -0.0286, -0.0326, -0.0441,  0.0848,  0.0901,  0.0119],\n        [ 0.1152, -0.0521,  0.0587, -0.0422,  0.0914,  0.0784, -0.0867,  0.1199,\n         -0.0218, -0.0662,  0.0466, -0.0050,  0.0441, -0.1663, -0.0357, -0.0720,\n         -0.1465,  0.1511,  0.1688,  0.1431, -0.1372, -0.1718,  0.1330,  0.0892,\n          0.1428, -0.0267, -0.0793, -0.1457,  0.0372, -0.0671, -0.0101,  0.1210],\n        [-0.0506, -0.0853, -0.0058,  0.0385, -0.0807, -0.0943,  0.0966,  0.1600,\n          0.0596, -0.0878, -0.1353, -0.1305,  0.0800, -0.1538,  0.1528, -0.0011,\n          0.0077, -0.0875, -0.1685, -0.0300, -0.0187, -0.0696,  0.0546,  0.0537,\n         -0.1356,  0.0627, -0.0655,  0.0748, -0.1595,  0.1206, -0.0677,  0.0834],\n        [-0.1759,  0.0380,  0.0687, -0.1669, -0.0226, -0.1167, -0.0310,  0.0708,\n         -0.0599, -0.0682,  0.0664,  0.1070, -0.1326,  0.1485, -0.0168, -0.0129,\n          0.0514,  0.0128, -0.1736,  0.1315, -0.1059,  0.0730,  0.1263, -0.1714,\n         -0.0986, -0.0970,  0.0608, -0.0090, -0.0797, -0.0188, -0.0897,  0.1592],\n        [-0.0703,  0.0116,  0.1571, -0.0409, -0.1113,  0.0922, -0.0333,  0.0241,\n         -0.0708,  0.1598,  0.0306, -0.1088,  0.0144,  0.1074, -0.0920, -0.0143,\n          0.1182, -0.1479,  0.0957,  0.1298, -0.0526,  0.0361,  0.1684, -0.1042,\n         -0.1506, -0.1310,  0.1575, -0.0136, -0.0206, -0.0935, -0.0420,  0.0866],\n        [ 0.0981,  0.0502, -0.0316, -0.0965,  0.0134, -0.1284,  0.0012,  0.1231,\n          0.1167, -0.1699,  0.1432, -0.0495,  0.0020,  0.1684, -0.1763, -0.1376,\n         -0.1112, -0.0619, -0.1361, -0.0465,  0.0285, -0.0976,  0.0426,  0.1088,\n         -0.0342, -0.0298,  0.0459, -0.0449,  0.0501, -0.1475,  0.1242, -0.1269],\n        [-0.0509, -0.0697,  0.0510,  0.0165, -0.0720,  0.1682,  0.0934,  0.0123,\n          0.1058, -0.0942, -0.0143, -0.0038,  0.0543,  0.0311,  0.0337,  0.0803,\n         -0.1172, -0.1529, -0.0981, -0.0509,  0.0679,  0.0662,  0.0712,  0.1292,\n          0.0831, -0.0675,  0.0813,  0.0690,  0.0453,  0.0620,  0.0944, -0.1176],\n        [-0.0819,  0.0710,  0.0678, -0.0536, -0.1678, -0.0768,  0.1506, -0.0606,\n          0.0240,  0.0560,  0.0846, -0.1083,  0.1039, -0.0772, -0.0386,  0.0196,\n          0.1393,  0.0831,  0.0652,  0.0304, -0.0818,  0.0249,  0.0290,  0.1009,\n         -0.0656, -0.0012, -0.1569,  0.0536,  0.1398, -0.1591,  0.0480,  0.0340],\n        [ 0.0235, -0.1619, -0.1682,  0.0392, -0.0684, -0.1625,  0.0601,  0.0411,\n         -0.0355, -0.0406, -0.0854, -0.1604,  0.1482,  0.1019, -0.1724,  0.0527,\n          0.0739,  0.1146,  0.1569, -0.0072,  0.0653, -0.0096, -0.1645,  0.0645,\n          0.1687,  0.0282, -0.0917,  0.1620,  0.1272,  0.1662, -0.1475,  0.0905]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2081, -0.0151, -0.0200, -0.0689,  0.1535,  0.2143,  0.0764,  0.1188],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 0.0769, -0.2464, -0.1078,  0.0968, -0.1614, -0.0301, -0.0554, -0.1903,\n         -0.2366, -0.0436, -0.1503,  0.1843,  0.1440, -0.1996,  0.1125,  0.0277],\n        [-0.2091, -0.1844,  0.2035,  0.0629,  0.1267, -0.1583,  0.1340, -0.2342,\n          0.0927, -0.1095,  0.1068, -0.2323, -0.0467,  0.1106, -0.1955,  0.0867],\n        [ 0.1258, -0.0061,  0.1918, -0.0203, -0.1712,  0.2349, -0.2047, -0.1930,\n          0.0977, -0.1453,  0.2401,  0.0965, -0.0077, -0.0112,  0.0163, -0.2433],\n        [-0.0277,  0.0491,  0.2409,  0.0635,  0.2097, -0.0167,  0.1748, -0.0004,\n         -0.0169, -0.0028,  0.1096, -0.2470, -0.2250, -0.1227, -0.1102, -0.1517],\n        [ 0.1986, -0.0414, -0.1028, -0.1812, -0.1393, -0.1728, -0.1524,  0.0360,\n         -0.1974,  0.1147, -0.0990, -0.1058,  0.2112, -0.0125, -0.1607, -0.1378],\n        [-0.1338,  0.1199,  0.1178,  0.1398, -0.2209,  0.2158, -0.0198, -0.2043,\n         -0.1282,  0.0115, -0.0529,  0.2042, -0.2243, -0.0963,  0.0554, -0.1741],\n        [-0.2217, -0.1558,  0.0301,  0.1167,  0.0069,  0.1458, -0.1571,  0.1827,\n          0.1560,  0.2303, -0.2035,  0.0511,  0.0162, -0.0142,  0.0698,  0.2198],\n        [ 0.2478,  0.0279, -0.0978, -0.0431, -0.1551,  0.0911, -0.2294, -0.1238,\n          0.0814, -0.0807, -0.0725, -0.1298, -0.2004, -0.1184,  0.0294,  0.1381]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=4, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([-0.2250,  0.0574, -0.0797,  0.0597], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.2882, -0.1637,  0.0554,  0.3422,  0.0850,  0.0698,  0.0633,  0.2283],\n        [-0.1864, -0.1592, -0.1523,  0.2655, -0.1168, -0.2277, -0.2044,  0.0182],\n        [-0.3381, -0.1205,  0.2506,  0.2090,  0.1149,  0.1780,  0.2314,  0.1659],\n        [-0.3355, -0.0569, -0.1264,  0.1084, -0.2734, -0.0167,  0.2578,  0.2636]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	4,
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "kernel_dim":	4,
                                "kernel_size":	5,
                                "training":	true
                            }
                        },
                        "v":	{
                            "RLCritic(\n  (v_net): Sequential(\n    (0): Linear(in_features=20, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=8, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=8, out_features=1, bias=True)\n    (7): Identity()\n  )\n)":	{
                                "_backward_hooks":	{},
                                "_backward_pre_hooks":	{},
                                "_buffers":	{},
                                "_forward_hooks":	{},
                                "_forward_hooks_always_called":	{},
                                "_forward_hooks_with_kwargs":	{},
                                "_forward_pre_hooks":	{},
                                "_forward_pre_hooks_with_kwargs":	{},
                                "_is_full_backward_hook":	null,
                                "_load_state_dict_post_hooks":	{},
                                "_load_state_dict_pre_hooks":	{},
                                "_modules":	{
                                    "v_net":	{
                                        "Sequential(\n  (0): Linear(in_features=20, out_features=32, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=32, out_features=16, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=16, out_features=8, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=8, out_features=1, bias=True)\n  (7): Identity()\n)":	{
                                            "_backward_hooks":	{},
                                            "_backward_pre_hooks":	{},
                                            "_buffers":	{},
                                            "_forward_hooks":	{},
                                            "_forward_hooks_always_called":	{},
                                            "_forward_hooks_with_kwargs":	{},
                                            "_forward_pre_hooks":	{},
                                            "_forward_pre_hooks_with_kwargs":	{},
                                            "_is_full_backward_hook":	null,
                                            "_load_state_dict_post_hooks":	{},
                                            "_load_state_dict_pre_hooks":	{},
                                            "_modules":	{
                                                "0":	{
                                                    "Linear(in_features=20, out_features=32, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 1.7102e-01,  3.9722e-02, -2.0094e-01, -1.1154e-01,  2.7902e-02,\n        -1.4391e-01, -8.3410e-03, -1.3625e-01,  1.3148e-01,  9.7367e-02,\n         1.5225e-01,  1.4520e-01, -1.7442e-01,  7.5066e-02,  7.7733e-02,\n        -1.5639e-01, -1.6158e-01, -1.5456e-01,  4.3690e-02, -1.2020e-01,\n        -3.2982e-02,  9.2430e-02,  6.9679e-05,  2.2143e-02,  1.1057e-01,\n         5.9008e-02,  7.7185e-03,  1.2206e-01,  2.7748e-02, -1.7068e-01,\n         8.2053e-02,  1.4179e-01], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 2.8302e-02,  1.2616e-01,  1.9737e-01,  3.6493e-02,  9.0623e-03,\n         -1.9456e-01,  1.9012e-01, -1.0676e-02, -3.0347e-02, -1.9985e-01,\n          9.2118e-02,  1.9668e-01, -5.7542e-02, -1.0756e-01,  1.4418e-02,\n          2.0768e-01, -1.4965e-01,  2.0301e-01, -7.4856e-02,  8.0293e-03],\n        [ 1.7402e-01,  3.2941e-02,  1.0136e-01, -1.4378e-01, -1.5407e-01,\n         -1.8382e-01, -7.7320e-02, -1.2093e-01, -6.4964e-02,  1.6500e-01,\n         -1.1145e-01,  7.7004e-02,  9.1445e-02, -1.7510e-01,  1.5052e-01,\n         -1.1591e-01,  1.3810e-02,  9.4536e-02,  1.2466e-02,  1.3075e-01],\n        [ 1.3986e-01,  1.3737e-01, -1.6735e-01, -9.9068e-02, -2.3870e-03,\n         -5.0201e-02, -1.2455e-01,  1.3484e-01,  1.0573e-01,  7.9073e-02,\n          8.9689e-02,  1.4506e-01, -6.4551e-02,  1.7587e-01,  2.0827e-01,\n         -1.1353e-01, -1.9941e-01, -1.2779e-01, -7.1385e-03, -4.2808e-02],\n        [-1.9200e-01,  3.3889e-02,  1.8901e-01,  1.3303e-01,  1.6781e-01,\n          8.6226e-02,  1.3248e-02, -1.9069e-01, -1.2402e-01,  1.8242e-01,\n          2.9357e-02, -1.6833e-01,  2.0432e-01,  2.2293e-02,  2.1621e-01,\n         -6.6168e-03, -2.2766e-02,  1.3750e-01, -2.2227e-01, -1.8860e-01],\n        [ 1.1501e-01,  1.8330e-01,  7.1968e-02,  8.2319e-02, -2.0609e-01,\n          4.9653e-02,  1.1293e-01,  1.8238e-01,  1.2517e-01, -4.3949e-03,\n         -1.3955e-01,  1.1497e-01,  2.0227e-01,  2.2272e-01, -1.2201e-01,\n         -3.3231e-02, -3.3156e-02, -1.0720e-01, -1.0428e-03,  5.5520e-02],\n        [ 4.1576e-02,  5.2734e-02,  6.0091e-02, -1.0810e-01, -2.5248e-02,\n          1.6878e-01, -1.3783e-01,  7.8083e-03, -1.6819e-01, -2.0920e-01,\n         -2.1656e-01, -5.6520e-02,  1.0268e-01, -2.0147e-01, -1.2136e-02,\n          3.8716e-02,  1.4608e-01, -1.7070e-02,  8.5982e-02,  1.5449e-01],\n        [-9.6178e-02,  1.0991e-01, -1.3890e-01,  2.0509e-01,  4.9827e-02,\n         -1.3949e-01,  1.0901e-01, -1.8317e-01, -1.3767e-01, -1.6890e-01,\n         -1.9527e-01, -1.3270e-01, -2.2292e-01, -2.5359e-02,  1.1364e-01,\n          1.0046e-01,  1.1592e-01,  5.3717e-02, -1.7440e-01, -2.1714e-01],\n        [ 4.1975e-02,  9.1671e-02,  2.5334e-02, -9.3996e-03,  2.1274e-01,\n         -1.4510e-01,  2.1477e-01, -1.5111e-01, -4.9957e-02, -1.7282e-01,\n         -4.8656e-02,  8.6320e-02,  1.6433e-01,  8.4265e-02,  2.1707e-01,\n         -1.6526e-01, -1.6622e-01,  1.6502e-01, -1.3544e-01,  1.0837e-01],\n        [-1.4839e-01,  1.1411e-01,  1.2096e-01, -1.9329e-01, -2.1122e-01,\n         -6.4949e-02, -7.3103e-03,  1.3669e-02,  8.1890e-03, -7.9851e-02,\n          1.6700e-01, -1.3011e-01, -7.2706e-02,  1.3250e-01,  6.8107e-02,\n         -8.1758e-02, -1.2138e-01,  1.5603e-01, -1.1462e-01,  2.1429e-02],\n        [-2.0639e-01,  5.8342e-02, -9.3061e-02, -5.9064e-02, -1.1842e-02,\n         -4.3947e-02, -4.5557e-02,  1.3237e-01, -5.0671e-02, -2.2275e-01,\n         -2.0710e-01, -1.9179e-01, -2.2212e-01,  1.5203e-01, -6.4570e-02,\n          1.0785e-01, -1.8698e-01,  2.0722e-01,  1.0730e-01, -1.6223e-01],\n        [-1.9234e-01,  1.4076e-01, -1.8407e-01,  2.4002e-02, -1.9269e-01,\n          2.1295e-01, -1.0710e-01,  4.7645e-02,  8.8735e-02,  1.7094e-01,\n          1.0962e-01,  6.9582e-02,  1.1145e-01,  2.1583e-01, -1.0124e-01,\n          6.8846e-02, -8.6846e-02, -1.3447e-01,  1.9224e-01, -7.4907e-02],\n        [ 7.7173e-02,  1.1824e-01,  2.1391e-01,  1.0008e-01,  7.8738e-02,\n         -2.0043e-01, -1.6299e-01, -1.6396e-01,  6.1301e-02,  2.4207e-02,\n          3.7309e-02, -1.5493e-01, -2.1928e-01,  5.4802e-02, -1.5667e-01,\n          4.4056e-02,  1.3808e-01,  1.8337e-01, -2.8774e-02,  1.8679e-01],\n        [-1.1778e-02,  4.1652e-03,  1.5537e-01, -1.9526e-01, -6.7827e-02,\n          1.4890e-01, -1.4533e-01, -2.2357e-02, -3.5448e-02, -3.3574e-02,\n         -8.1382e-03, -8.6191e-02, -1.6807e-01,  8.1837e-02, -1.5637e-01,\n          5.2115e-02, -1.8472e-01,  3.8122e-02,  1.7139e-01, -1.9016e-01],\n        [ 1.4741e-01,  1.1302e-01,  2.1669e-01, -1.6403e-01,  1.0905e-02,\n          7.7438e-02,  1.2091e-01,  3.2654e-05, -1.7174e-01, -5.5512e-02,\n         -1.8841e-01,  4.5032e-02, -1.7320e-03, -9.8715e-02,  9.0664e-03,\n         -1.7926e-01,  6.6694e-02,  3.2034e-02, -3.9163e-02, -9.7560e-02],\n        [ 1.6908e-01, -4.4884e-02, -2.1214e-01,  1.1054e-02, -1.3695e-01,\n          1.6429e-01, -8.1785e-02,  1.9651e-01,  1.3588e-01, -1.9135e-01,\n         -3.5708e-02, -1.6608e-01, -1.1818e-01, -4.2490e-02,  1.0031e-02,\n          1.2595e-01, -5.1102e-02,  6.9412e-02, -5.4245e-02,  1.5356e-01],\n        [-2.1557e-01,  1.4495e-01,  1.6395e-01, -1.1279e-01, -1.9187e-02,\n         -1.1287e-02, -1.8868e-01,  3.0742e-02, -3.4899e-02,  1.7048e-01,\n          1.3966e-01,  1.1364e-01,  1.4038e-01, -1.0663e-01, -8.2252e-03,\n         -2.0211e-01,  5.8858e-02,  5.5824e-02,  3.9798e-02,  1.3624e-01],\n        [ 1.1795e-01, -2.0133e-01,  2.1594e-01,  1.7257e-01, -4.1536e-02,\n          1.5833e-01,  7.7171e-02, -1.4667e-01, -1.3466e-01, -2.0269e-02,\n         -1.0233e-01,  1.7804e-01,  5.4775e-02, -6.0482e-02,  1.4690e-01,\n         -1.7832e-01,  1.8214e-01,  4.4041e-02,  1.2045e-01,  8.5783e-03],\n        [-1.0318e-01, -1.2022e-01,  1.2821e-01, -1.6069e-01, -1.1174e-01,\n         -1.3306e-01, -2.1481e-01,  4.4382e-02, -7.0767e-02, -3.9252e-02,\n          2.0316e-01, -2.1036e-01,  1.9576e-01, -4.7302e-02, -6.1490e-03,\n          1.2846e-01, -8.1006e-02,  1.4907e-01,  1.7157e-01,  1.4541e-01],\n        [-2.5566e-03, -9.1286e-02, -1.2780e-01,  1.2445e-01,  4.9820e-02,\n          1.1673e-03,  1.4890e-01, -1.1447e-02, -2.1849e-01,  1.4742e-01,\n         -5.6703e-02, -2.2169e-01, -2.1590e-01,  2.9863e-03, -1.7664e-01,\n         -1.5373e-01, -2.8973e-02,  6.3047e-03,  1.6013e-01,  1.0316e-01],\n        [-1.8279e-01, -1.9412e-01,  5.7929e-02,  2.0861e-02,  1.8531e-01,\n          1.7576e-01,  2.0054e-01, -1.9977e-01, -2.1732e-01,  8.2242e-02,\n         -2.1432e-01, -1.8546e-01, -1.7541e-01, -1.8690e-01, -1.6944e-01,\n          1.6403e-01, -1.2863e-01,  2.0213e-01, -1.8942e-01, -1.9478e-01],\n        [ 1.9070e-01, -1.1546e-01, -1.6436e-01,  4.4907e-02,  5.6768e-03,\n          1.5614e-01, -1.3113e-01,  1.4987e-01,  7.2504e-02, -1.4653e-01,\n          2.1443e-01, -1.0126e-01,  2.3520e-02,  1.6974e-01,  1.0196e-01,\n         -1.4211e-01, -4.3596e-02, -1.8353e-02, -9.0993e-02,  2.0982e-01],\n        [-1.4704e-01, -8.3836e-02, -1.0901e-01, -1.7193e-01, -9.7994e-02,\n          1.0638e-01, -6.0328e-02,  8.9419e-02,  6.7898e-02,  1.7472e-01,\n         -1.5193e-01, -9.8392e-02, -2.0171e-01, -6.4195e-02,  6.5422e-02,\n          1.1262e-01, -1.0993e-01, -1.3410e-01, -6.8997e-02,  4.0319e-02],\n        [-2.5190e-02, -2.0967e-01,  2.0441e-01,  2.4353e-02, -1.7920e-01,\n          2.2173e-01, -2.5666e-02,  1.5788e-01,  3.8671e-02, -1.5518e-01,\n         -5.1859e-02,  2.2258e-01,  2.2684e-03,  1.3970e-01,  1.6050e-01,\n         -8.5124e-02,  1.3598e-01,  1.2321e-01,  8.5227e-02,  5.1449e-02],\n        [-1.8621e-01, -1.4521e-01, -1.7839e-01, -1.2390e-01,  1.8734e-01,\n         -4.1450e-02,  1.7330e-01,  2.0275e-01, -6.2927e-02, -1.0490e-01,\n          1.0342e-01,  1.7354e-01, -5.6083e-03,  4.8235e-02,  1.1699e-01,\n         -2.0282e-01,  1.0036e-01, -3.2985e-02,  2.0475e-01,  1.1554e-01],\n        [ 7.4140e-02,  1.2598e-02,  1.0233e-02,  8.3234e-02,  3.8265e-02,\n         -1.3205e-01, -5.9874e-02,  1.4588e-01,  1.4312e-01, -7.1629e-02,\n         -2.1534e-01, -8.0675e-02, -2.1830e-01, -6.0864e-02, -1.2124e-01,\n          1.0082e-02,  2.0583e-01,  8.5075e-02,  8.6937e-02,  5.0321e-02],\n        [ 5.6396e-02, -1.8465e-01, -1.3896e-01,  5.9803e-02, -7.4154e-04,\n         -1.7416e-01,  1.7115e-01,  3.8717e-02, -1.1163e-01,  1.7077e-01,\n         -8.0603e-02, -1.5402e-01, -1.2896e-01, -1.2855e-01, -5.4234e-02,\n         -1.9879e-01,  1.5851e-01,  1.3564e-01, -1.8346e-01, -1.6577e-01],\n        [ 6.6788e-02,  1.3024e-01, -1.5775e-01, -1.6372e-01, -1.3342e-01,\n         -1.6198e-01,  2.0500e-02, -1.7160e-01,  1.6636e-01, -1.9896e-01,\n          1.7074e-02,  1.6675e-01, -2.0230e-01, -1.9199e-01,  9.8394e-02,\n         -8.8468e-02, -2.0649e-01, -1.7479e-01,  2.1411e-01, -3.2618e-02],\n        [ 4.4173e-02,  2.0570e-01, -2.1145e-01,  7.1168e-02, -1.4264e-01,\n          1.0683e-01,  1.4247e-01,  1.3441e-01,  1.7946e-01, -1.7634e-01,\n          1.9777e-01, -1.2535e-01, -6.4430e-02,  1.0673e-01,  6.8983e-02,\n         -2.0380e-01, -1.4911e-01, -1.2077e-01, -1.1907e-01, -2.7558e-02],\n        [ 2.8225e-02,  1.1885e-01,  1.5261e-01,  3.6360e-02,  7.1426e-02,\n         -1.3969e-01, -3.1936e-02, -1.3579e-01,  1.5083e-01,  5.7759e-02,\n          1.8713e-01, -1.9232e-02, -9.2016e-02, -2.4395e-02,  1.8722e-02,\n         -9.1690e-02,  1.3955e-01, -1.5274e-01, -4.3733e-02, -1.8996e-01],\n        [-3.3135e-02,  8.4819e-02, -1.5244e-01,  3.2111e-02, -8.6630e-02,\n          1.0755e-01, -1.8418e-01, -4.6082e-02, -9.2870e-02, -1.0702e-02,\n          1.0033e-01,  6.8053e-02, -4.5643e-02,  7.5136e-02,  1.6205e-01,\n          1.4840e-01,  4.5588e-02, -1.4791e-01,  2.3464e-02, -1.7014e-01],\n        [-2.0241e-01, -7.7441e-02,  1.1168e-02,  3.7080e-02, -1.2606e-01,\n          5.8405e-02,  4.6105e-02,  1.3236e-01, -2.2144e-01, -2.0153e-01,\n          1.4242e-01,  7.5791e-03, -1.5933e-01, -2.1944e-01, -2.0689e-01,\n         -1.9971e-02,  9.0241e-02, -5.3731e-02, -1.6532e-01,  1.2849e-01],\n        [-1.8367e-01,  1.7830e-01,  1.9349e-01, -1.5432e-01,  1.7467e-01,\n         -1.0729e-01,  1.6433e-01, -5.7253e-03,  3.8015e-02, -8.9598e-02,\n          6.5364e-02,  9.9353e-02, -6.9536e-02,  1.2107e-01,  4.5678e-02,\n          1.4510e-01,  9.9135e-02, -1.9693e-02,  1.9627e-01,  8.7988e-02]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	20,
                                                        "out_features":	32,
                                                        "training":	true
                                                    }
                                                },
                                                "1":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "2":	{
                                                    "Linear(in_features=32, out_features=16, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.0082,  0.0881, -0.1762, -0.0418, -0.0448,  0.1047,  0.0682, -0.1730,\n        -0.0637,  0.0507, -0.1500, -0.1511, -0.1699, -0.0254, -0.0504,  0.0111],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[ 1.4150e-01,  1.1853e-01, -9.6394e-02, -9.5001e-02, -7.1525e-02,\n          3.6820e-02, -1.2028e-01,  8.2925e-02, -1.3165e-01,  1.6530e-01,\n          4.3390e-02,  1.3648e-02,  7.2997e-02,  1.3690e-01,  8.2497e-03,\n          1.5668e-01,  1.3605e-01,  1.4915e-01, -1.4609e-01,  3.2758e-02,\n         -1.0294e-01, -1.2886e-01,  6.1835e-02,  7.1925e-02,  6.6270e-02,\n         -1.0837e-01, -2.7625e-02, -1.5456e-01,  1.0721e-01,  1.5375e-01,\n         -1.4737e-01,  3.0225e-02],\n        [ 1.2005e-01,  1.5997e-01, -1.1408e-01,  1.0243e-01,  1.0954e-01,\n          1.2787e-01, -1.1481e-01, -1.6229e-01,  1.7541e-01, -7.9665e-02,\n         -5.0857e-02,  1.5019e-02,  1.3026e-01, -8.9467e-02, -9.8712e-02,\n         -1.3301e-01,  1.2913e-01,  1.6636e-03, -4.4934e-02,  1.1238e-01,\n         -1.2620e-01, -1.7494e-01,  1.1226e-01, -5.0246e-02,  8.4156e-02,\n          9.2756e-02, -1.1815e-01,  6.1591e-02,  3.2890e-02, -1.1740e-01,\n         -1.0702e-01,  5.1381e-02],\n        [-5.6233e-02, -1.1254e-02,  3.1101e-02,  3.0624e-02, -1.4187e-01,\n          4.8702e-02,  8.2259e-02,  2.4246e-03, -7.3875e-02, -5.3801e-02,\n         -1.3005e-01,  1.5101e-01,  9.6640e-02, -1.5359e-02,  1.2641e-01,\n          1.5861e-01, -2.5810e-02,  1.7249e-01, -1.3539e-02,  1.3220e-01,\n         -1.0110e-01,  1.0046e-01, -9.8510e-02,  1.1137e-01,  1.7171e-01,\n          8.0503e-02, -1.6263e-01, -9.7389e-02,  1.4724e-01,  1.4171e-01,\n          6.1378e-02, -1.5412e-01],\n        [-5.0403e-02,  4.7110e-02,  1.3329e-01,  7.0282e-02, -1.5092e-01,\n          1.5365e-01, -1.5337e-01, -7.5779e-02, -7.0466e-02,  1.1629e-01,\n          2.2864e-02,  6.9250e-02, -1.3254e-01,  8.6658e-02, -1.6129e-01,\n         -7.6984e-02, -1.9157e-02, -8.9689e-02, -9.2216e-02,  1.7627e-01,\n          8.8957e-02,  1.6350e-01, -1.2418e-01, -1.2547e-01, -1.6792e-01,\n          5.7273e-02, -3.0012e-02,  1.3476e-01, -6.5641e-02, -7.8852e-02,\n         -6.7852e-02, -1.8922e-02],\n        [ 3.4918e-02, -1.1927e-01, -7.7008e-02,  1.4169e-01, -1.5177e-01,\n         -1.1912e-01, -9.7695e-03, -1.4217e-01,  1.0648e-01,  1.3827e-01,\n          8.3167e-02, -4.3594e-02, -1.1338e-01, -1.6902e-01, -7.8393e-02,\n         -4.6690e-04, -1.0980e-01, -1.6668e-02,  8.2959e-02,  8.9314e-03,\n         -1.4125e-01,  1.3279e-01,  7.1015e-02,  1.3172e-01, -1.5384e-01,\n         -1.7208e-01, -8.5349e-02, -1.0440e-01,  4.3879e-02,  5.0265e-02,\n          3.3199e-02, -9.4322e-02],\n        [-1.4490e-01, -5.3136e-02, -1.6066e-01, -7.7236e-02,  1.4688e-03,\n         -1.2220e-02,  9.7822e-02, -1.2144e-01, -9.6070e-03,  1.2488e-01,\n          2.1641e-03,  1.1651e-01, -1.2110e-01,  2.3824e-02,  3.5632e-02,\n          5.7502e-03, -2.2354e-02,  1.3590e-01, -1.3628e-01, -1.5510e-01,\n          9.8486e-03,  1.0219e-01,  1.2985e-01, -1.6359e-01, -1.3558e-01,\n         -8.5551e-02, -1.3648e-01, -1.6579e-01, -1.1025e-01, -1.1072e-01,\n         -7.0481e-02,  1.3963e-01],\n        [-1.5436e-01, -3.1946e-02,  3.9528e-02,  1.6378e-01,  1.8604e-02,\n         -1.5626e-02,  1.3926e-01, -2.5158e-02, -1.1278e-01,  3.0450e-02,\n         -3.1729e-02,  1.3615e-01,  1.2591e-01,  3.8193e-02, -8.1712e-02,\n         -2.8856e-02, -9.7828e-02, -5.2792e-02,  1.2460e-01, -5.3643e-03,\n          6.4122e-02, -1.5844e-01, -8.0775e-02,  9.6462e-02,  1.1585e-01,\n          1.7077e-01, -9.1753e-03, -2.4759e-03, -2.8886e-02,  3.8559e-02,\n          4.3754e-02,  1.7008e-01],\n        [ 1.7449e-01,  2.6509e-02,  2.8031e-02,  6.1539e-02,  1.3258e-01,\n         -1.6228e-01,  1.5989e-01,  1.0190e-01,  1.0916e-01, -1.2312e-01,\n          1.5856e-01,  1.3662e-02, -7.8713e-02, -1.3395e-01, -8.7752e-02,\n         -3.6917e-02,  8.5972e-02,  1.8113e-02,  9.2552e-02,  3.9073e-02,\n         -1.3914e-01,  1.5720e-01, -1.1804e-01,  5.3021e-02,  1.6067e-01,\n          5.1160e-02, -2.6592e-02, -6.9348e-02, -1.6183e-01, -7.7249e-02,\n          3.3396e-02, -5.7282e-02],\n        [ 1.3863e-01, -9.5178e-03,  9.1492e-02, -4.3900e-02,  9.9118e-02,\n          1.4893e-01,  1.1557e-01,  7.7275e-02,  1.5083e-01,  1.7062e-01,\n          1.5360e-01, -9.1154e-02, -1.6057e-01,  1.0449e-02, -1.7296e-01,\n          9.0110e-02, -4.2679e-02,  1.7167e-01,  1.3125e-01, -1.1445e-01,\n          8.8184e-02, -4.0645e-02,  3.4907e-02, -4.1953e-02,  7.5194e-02,\n         -9.4229e-02, -9.9683e-03, -1.6522e-02,  9.3176e-02, -1.6305e-01,\n          1.5253e-01,  1.1151e-02],\n        [ 3.4695e-02,  6.7044e-02,  1.5941e-01, -9.7369e-02, -8.7186e-02,\n          1.3662e-01, -2.5587e-02,  1.0881e-01, -2.8986e-03, -9.4102e-02,\n          4.2394e-02, -1.4143e-01,  1.7213e-01, -1.3663e-01,  5.3341e-02,\n          1.3508e-01, -1.5179e-01,  7.0173e-02,  4.0378e-02, -1.0361e-01,\n         -1.4623e-01,  1.5103e-01,  8.8067e-02, -1.5845e-01,  5.2659e-02,\n          1.3292e-02,  1.0195e-01,  4.9440e-02, -8.7791e-03,  8.0421e-02,\n          7.1490e-02,  2.7041e-02],\n        [-9.9841e-02,  1.2328e-01, -1.6198e-01, -1.0896e-01,  8.0383e-02,\n         -1.2755e-01,  5.1433e-02, -1.3539e-01,  9.9768e-02,  7.8071e-02,\n          1.7412e-01,  7.8243e-02, -1.2104e-01, -1.5379e-01,  9.2137e-02,\n         -1.6946e-01, -1.4148e-01, -1.5198e-01,  1.6881e-01, -9.5362e-02,\n         -9.3748e-02,  4.3403e-02, -8.7824e-02, -4.9672e-02,  1.3977e-01,\n         -1.2467e-02, -8.8441e-04, -1.5973e-01,  5.3127e-02,  1.6882e-01,\n         -3.2016e-02, -3.4026e-02],\n        [ 7.8435e-02, -1.6814e-01,  9.8955e-03,  6.1081e-02,  1.3178e-01,\n         -5.6417e-03,  1.1466e-01,  2.0362e-02,  2.2956e-03,  1.5791e-01,\n         -1.7206e-02,  1.2153e-02, -8.1878e-02, -1.5683e-01,  1.3850e-01,\n          7.3713e-02, -9.0716e-02, -1.0392e-01, -8.9968e-02, -7.3374e-02,\n         -1.4587e-01,  6.3743e-03,  3.7984e-02,  1.4947e-01, -1.1679e-02,\n         -1.0403e-01, -5.9837e-02, -1.0448e-01,  9.5830e-02,  9.0476e-02,\n         -9.8563e-02,  1.2367e-01],\n        [ 9.1095e-02, -1.5015e-02, -6.0378e-02,  1.2963e-01,  1.7358e-01,\n          7.1752e-02, -1.0373e-01,  2.3525e-02, -1.6658e-01,  4.1771e-02,\n          5.0764e-02, -1.3134e-01,  1.3284e-01, -3.3948e-02,  6.2755e-03,\n         -1.5079e-01,  6.7252e-02,  1.2751e-01, -1.1694e-01,  1.4731e-01,\n         -3.4226e-02,  5.7294e-02,  1.4377e-01, -1.2884e-02, -4.1519e-02,\n         -7.5462e-02, -2.7469e-02, -7.8669e-02, -5.8263e-02, -4.8364e-05,\n         -3.8848e-02,  7.8689e-02],\n        [ 9.4914e-02,  2.8891e-02,  6.9815e-02,  1.5062e-01, -4.8667e-02,\n         -1.5668e-01, -1.5302e-01, -1.6169e-01, -1.2777e-01,  7.1184e-02,\n          5.8239e-02,  1.3794e-01, -1.4777e-01, -1.7319e-01,  7.3800e-02,\n         -3.3717e-02, -7.1668e-03, -1.3165e-02, -5.0997e-02, -1.3538e-01,\n         -1.2831e-01, -1.2050e-01,  4.4147e-02,  1.3996e-01,  3.7132e-02,\n          4.0844e-02,  1.5788e-01,  1.1372e-01,  2.6260e-02, -8.8281e-02,\n         -6.4388e-02, -1.5860e-01],\n        [ 8.0737e-02, -3.1168e-02, -1.1539e-01, -7.3360e-02, -1.6368e-01,\n         -1.3037e-01,  1.7341e-01,  3.3365e-03,  1.4699e-01,  9.8497e-02,\n         -1.4614e-01, -6.3625e-02, -1.2331e-01,  8.0552e-02, -1.0003e-01,\n         -8.7328e-02, -4.1120e-02,  1.2893e-01,  5.2755e-02, -1.2063e-01,\n          1.4801e-01,  1.1545e-01,  7.3405e-02,  4.8035e-02, -1.3791e-01,\n         -1.1671e-01,  6.4933e-02, -1.2390e-01,  1.0913e-01,  9.4587e-02,\n          1.7206e-01, -7.4101e-02],\n        [-8.7147e-02, -1.4919e-03, -1.5115e-01, -9.5615e-02,  4.3767e-02,\n         -1.5772e-01,  1.1329e-01,  1.7423e-01,  4.7687e-02,  1.6534e-01,\n          3.0357e-02,  1.4373e-01,  5.2991e-02,  1.0164e-01,  1.2135e-01,\n          1.6628e-01,  1.1781e-01, -7.1302e-02, -4.8296e-02,  1.1456e-01,\n         -8.9152e-02, -1.7375e-01,  1.4579e-01, -1.5689e-01,  3.5061e-02,\n         -1.4168e-01,  3.8522e-02,  4.0479e-02, -7.8315e-02, -7.2896e-03,\n         -1.1146e-01,  1.3112e-01]], requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	32,
                                                        "out_features":	16,
                                                        "training":	true
                                                    }
                                                },
                                                "3":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "4":	{
                                                    "Linear(in_features=16, out_features=8, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([ 0.1427,  0.1440,  0.1089, -0.2224, -0.1821,  0.1911, -0.0775, -0.2159],\n       requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.2191,  0.1863, -0.2167, -0.1194,  0.1158,  0.1382,  0.1773,  0.0520,\n          0.2258, -0.2492,  0.2116,  0.0322, -0.0982, -0.0670, -0.2161, -0.0777],\n        [ 0.1356, -0.1698, -0.2238, -0.2160, -0.0367,  0.1367,  0.2080,  0.1240,\n         -0.0991, -0.2413,  0.0726,  0.0074, -0.1506, -0.2186, -0.1260, -0.1191],\n        [-0.0454,  0.0838,  0.1974, -0.0243, -0.1217, -0.0651, -0.0713,  0.0907,\n          0.1454,  0.0713, -0.0378,  0.1308, -0.2170, -0.1912, -0.2227, -0.1738],\n        [ 0.1012, -0.0257,  0.1428,  0.0657, -0.1809, -0.0755,  0.1676, -0.1214,\n          0.0169, -0.0878, -0.0068, -0.0018, -0.2053,  0.0761,  0.1633, -0.1674],\n        [ 0.0708, -0.0846,  0.1275,  0.1419,  0.0313, -0.1769,  0.0340, -0.1491,\n          0.2488, -0.0553, -0.0871,  0.0918,  0.2102,  0.0521, -0.1314,  0.1830],\n        [ 0.2301,  0.1938, -0.1670, -0.0151,  0.0578,  0.1494,  0.2339, -0.0470,\n          0.1064,  0.0589,  0.0118,  0.0210, -0.1229, -0.1698, -0.1957, -0.1114],\n        [ 0.0276, -0.1869,  0.0464,  0.1278, -0.1858,  0.2145, -0.0995, -0.1424,\n          0.0700, -0.0154,  0.1872, -0.0365, -0.0706, -0.0210, -0.0129,  0.2118],\n        [ 0.1968, -0.1576, -0.2261, -0.1183, -0.2023, -0.2289,  0.2058,  0.0986,\n          0.1082, -0.0332, -0.1916,  0.0837,  0.1580, -0.1723,  0.0441,  0.2394]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	16,
                                                        "out_features":	8,
                                                        "training":	true
                                                    }
                                                },
                                                "5":	{
                                                    "ReLU()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "inplace":	false,
                                                        "training":	true
                                                    }
                                                },
                                                "6":	{
                                                    "Linear(in_features=8, out_features=1, bias=True)":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{
                                                            "bias":	"Parameter containing:\ntensor([0.0805], requires_grad=True)",
                                                            "weight":	"Parameter containing:\ntensor([[-0.0172, -0.2877,  0.2396, -0.3276, -0.3151,  0.0512,  0.2990, -0.2753]],\n       requires_grad=True)"
                                                        },
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "in_features":	8,
                                                        "out_features":	1,
                                                        "training":	true
                                                    }
                                                },
                                                "7":	{
                                                    "Identity()":	{
                                                        "_backward_hooks":	{},
                                                        "_backward_pre_hooks":	{},
                                                        "_buffers":	{},
                                                        "_forward_hooks":	{},
                                                        "_forward_hooks_always_called":	{},
                                                        "_forward_hooks_with_kwargs":	{},
                                                        "_forward_pre_hooks":	{},
                                                        "_forward_pre_hooks_with_kwargs":	{},
                                                        "_is_full_backward_hook":	null,
                                                        "_load_state_dict_post_hooks":	{},
                                                        "_load_state_dict_pre_hooks":	{},
                                                        "_modules":	{},
                                                        "_non_persistent_buffers_set":	"set()",
                                                        "_parameters":	{},
                                                        "_state_dict_hooks":	{},
                                                        "_state_dict_pre_hooks":	{},
                                                        "training":	true
                                                    }
                                                }
                                            },
                                            "_non_persistent_buffers_set":	"set()",
                                            "_parameters":	{},
                                            "_state_dict_hooks":	{},
                                            "_state_dict_pre_hooks":	{},
                                            "training":	true
                                        }
                                    }
                                },
                                "_non_persistent_buffers_set":	"set()",
                                "_parameters":	{},
                                "_state_dict_hooks":	{},
                                "_state_dict_pre_hooks":	{},
                                "activation":	"ReLU",
                                "layer_sizes":	[
                                    20,
                                    32,
                                    16,
                                    8,
                                    1
                                ],
                                "obs_dim":	20,
                                "training":	true
                            }
                        }
                    },
                    "_non_persistent_buffers_set":	"set()",
                    "_parameters":	{},
                    "_state_dict_hooks":	{},
                    "_state_dict_pre_hooks":	{},
                    "custom_network":	null,
                    "flatten_obs_dim":	20,
                    "kernel_dim":	4,
                    "kernel_size":	5,
                    "training":	true
                }
            },
            "_pi_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[-0.1798,  0.1571, -0.0386, -0.0226,  0.0768, -0.0768, -0.0452,  0.0737,\n         -0.0393,  0.2213, -0.1566, -0.0967, -0.2209, -0.1103,  0.1429,  0.2029,\n          0.0759,  0.2189,  0.0079,  0.0285],\n        [ 0.1180, -0.0287,  0.1425, -0.0831, -0.0618,  0.1839,  0.0055,  0.1836,\n          0.1351,  0.1629, -0.0435,  0.1768, -0.0821,  0.0429,  0.0899, -0.1113,\n         -0.0447, -0.1361, -0.0600,  0.2066],\n        [ 0.1616,  0.1258,  0.1356,  0.0747, -0.0506, -0.2146, -0.0304, -0.0242,\n         -0.0912,  0.2038, -0.0164, -0.1072, -0.1618, -0.1731,  0.0578,  0.1764,\n          0.2085, -0.1635,  0.0827, -0.1894],\n        [-0.0653,  0.1191,  0.1276,  0.1236,  0.0074,  0.1635,  0.1667, -0.1485,\n         -0.2185,  0.1714, -0.0778,  0.0976,  0.1648,  0.1068,  0.0246,  0.1873,\n         -0.0378,  0.0608,  0.1549,  0.0368],\n        [ 0.0490,  0.2184, -0.2023, -0.2236,  0.1737, -0.1973,  0.1133,  0.1572,\n         -0.1782, -0.1943,  0.0524, -0.0905,  0.0092,  0.0114, -0.0506,  0.0238,\n          0.0053, -0.2116,  0.1951,  0.2043],\n        [ 0.1180,  0.0357,  0.1459,  0.1854, -0.0012,  0.1529, -0.2212,  0.0663,\n         -0.0453,  0.1718, -0.0250, -0.1961, -0.1155, -0.1217,  0.0543, -0.0705,\n         -0.0353,  0.1123, -0.2139, -0.1295],\n        [-0.1708,  0.0846,  0.0896, -0.0034,  0.1292, -0.0449,  0.0737,  0.0961,\n          0.1019,  0.0303, -0.0779, -0.1468, -0.0032,  0.0241,  0.1656,  0.1956,\n          0.1912, -0.1225,  0.0183, -0.1688],\n        [-0.2166,  0.1036,  0.0791,  0.0853, -0.1208,  0.0702,  0.1406, -0.0370,\n         -0.1324, -0.1830,  0.1609, -0.0924,  0.1335, -0.0089,  0.0782,  0.1571,\n         -0.1734,  0.0854, -0.0096,  0.0653],\n        [-0.0387, -0.0480,  0.1583,  0.1522, -0.1016,  0.0522,  0.1211, -0.1517,\n          0.1643,  0.0919, -0.0867,  0.1041,  0.0516, -0.0718,  0.0020, -0.0581,\n         -0.1186, -0.0482,  0.1896,  0.1790],\n        [ 0.0300, -0.0656, -0.1044, -0.0685,  0.1110,  0.0646,  0.2004, -0.0924,\n         -0.1948, -0.1681, -0.0865, -0.0504, -0.1578,  0.1925,  0.1595, -0.0290,\n         -0.0887,  0.0659, -0.0444,  0.0068],\n        [ 0.1910, -0.1447,  0.1141,  0.0341,  0.0249,  0.1479,  0.1414,  0.1118,\n          0.2161, -0.1032,  0.1106, -0.0252,  0.2233,  0.1955,  0.0309, -0.1656,\n         -0.0862,  0.1360, -0.0309, -0.0238],\n        [-0.0676, -0.1721, -0.1876, -0.0205, -0.0101, -0.1851, -0.1335,  0.0201,\n         -0.1564, -0.0160, -0.0676,  0.0702,  0.0809, -0.1803,  0.1798, -0.0469,\n         -0.1939,  0.1875,  0.0420, -0.0524],\n        [-0.0306,  0.1751, -0.1375,  0.0952, -0.0549, -0.1174,  0.0907,  0.1514,\n         -0.1814,  0.1168,  0.1420, -0.0461, -0.0343,  0.0727,  0.1237, -0.0772,\n         -0.0859,  0.0719,  0.1697, -0.1578],\n        [-0.0497, -0.1427, -0.0847, -0.1855, -0.0682, -0.1207,  0.1974,  0.0166,\n          0.1044, -0.1770, -0.2073, -0.1310,  0.1731, -0.1368,  0.0984,  0.1064,\n         -0.1411,  0.1818, -0.1692, -0.0517],\n        [-0.1761,  0.2082,  0.0635,  0.2122,  0.1130,  0.0768,  0.1757,  0.0895,\n         -0.0170,  0.0350,  0.0555,  0.1014, -0.0405, -0.0237, -0.0142, -0.0863,\n          0.0666,  0.0690, -0.1394, -0.1471],\n        [-0.0735, -0.1651, -0.0281, -0.1452, -0.0926,  0.1703,  0.1496,  0.2190,\n          0.0365, -0.1087,  0.1368,  0.0087, -0.0538,  0.2040,  0.1246,  0.0336,\n          0.0599, -0.1688,  0.1104,  0.1260],\n        [-0.1373,  0.1417,  0.1780,  0.1909, -0.0476, -0.1859, -0.0368,  0.0559,\n         -0.2153,  0.1894,  0.1477,  0.1032,  0.1820,  0.1335, -0.1360,  0.0466,\n          0.1893,  0.1332, -0.0272, -0.0731],\n        [-0.0871,  0.1701,  0.1375,  0.0740, -0.1539, -0.1592,  0.0500, -0.1014,\n         -0.0889,  0.0167, -0.0532, -0.1547,  0.1300,  0.0191, -0.2120, -0.0230,\n          0.2083,  0.0065,  0.2229, -0.2087],\n        [ 0.1217,  0.1013, -0.0417,  0.1859, -0.2176,  0.0522, -0.0305, -0.2158,\n         -0.1084,  0.2188, -0.1191, -0.0330, -0.1335,  0.0303,  0.1167, -0.1396,\n          0.1585,  0.1864,  0.2051, -0.0174],\n        [ 0.0851, -0.2119, -0.1561, -0.0057,  0.1534, -0.1780, -0.1837,  0.0148,\n         -0.1744,  0.0422,  0.0944, -0.0065,  0.0956, -0.0757,  0.1895,  0.1192,\n          0.1515, -0.0894, -0.0330,  0.0671],\n        [ 0.0505,  0.0276, -0.0105, -0.1979,  0.0477, -0.1395,  0.0331, -0.1984,\n         -0.0320,  0.0492, -0.0295, -0.0669,  0.1360,  0.1421,  0.1791, -0.2138,\n         -0.1466, -0.0103, -0.0198,  0.0775],\n        [-0.2217,  0.0582, -0.0530,  0.2224,  0.0449,  0.0775,  0.0418,  0.0849,\n         -0.1532,  0.0653,  0.1099, -0.0919,  0.1267,  0.1694, -0.1380,  0.0237,\n          0.1772,  0.0941,  0.1078, -0.0405],\n        [ 0.0880, -0.0292,  0.1505, -0.0621, -0.2219, -0.0899,  0.1044,  0.0714,\n          0.0532,  0.1511,  0.0288, -0.1890, -0.0263, -0.0326, -0.1719,  0.1080,\n         -0.0568,  0.2025, -0.1797, -0.0552],\n        [ 0.1113,  0.1944, -0.0710, -0.1610, -0.1648, -0.2189, -0.1410,  0.1850,\n          0.1832,  0.0668,  0.2136,  0.1735,  0.0316, -0.2199, -0.1358,  0.1448,\n          0.1983, -0.0572,  0.0442,  0.1214],\n        [-0.0841, -0.0265,  0.2045, -0.1158,  0.1195,  0.0813, -0.1819,  0.0488,\n         -0.0612, -0.0392, -0.0323,  0.0973,  0.0776, -0.2060, -0.1948,  0.1177,\n         -0.0480,  0.1490, -0.1119, -0.1235],\n        [-0.1164, -0.0967, -0.1339,  0.1335,  0.2093,  0.1739, -0.2043,  0.1563,\n         -0.2040,  0.1785,  0.0128, -0.1709, -0.1207,  0.2051,  0.1972,  0.0755,\n          0.0845, -0.0802,  0.1838,  0.0529],\n        [ 0.1356,  0.1061,  0.0613, -0.2081,  0.0384,  0.0315, -0.1627, -0.1067,\n         -0.0700, -0.1423, -0.1401,  0.0096,  0.1088, -0.0760, -0.2091,  0.0048,\n         -0.0869, -0.2017,  0.0456,  0.1173],\n        [ 0.1143, -0.0886,  0.2215,  0.1811, -0.0928, -0.0772, -0.1198,  0.0368,\n          0.0015, -0.2034, -0.1501,  0.0647,  0.2100,  0.0553,  0.0871,  0.2225,\n          0.0458, -0.0512,  0.1269, -0.2082],\n        [ 0.0229,  0.1904,  0.0647,  0.1139, -0.0780,  0.1295, -0.1334,  0.0850,\n         -0.0923,  0.0863,  0.1319, -0.0078, -0.1103, -0.1623, -0.1745, -0.1060,\n         -0.1948, -0.0142,  0.0299,  0.1151],\n        [ 0.2189, -0.1201,  0.1089,  0.1997,  0.0819,  0.1649,  0.1683, -0.0571,\n         -0.1757,  0.0050, -0.0619,  0.2040, -0.0665,  0.2067,  0.1964, -0.0705,\n         -0.0486,  0.1873,  0.1033, -0.1078],\n        [-0.0434,  0.1027,  0.0481,  0.1088,  0.0955, -0.0490,  0.0915,  0.1472,\n          0.0080,  0.0636,  0.0501, -0.1121,  0.1915, -0.0167, -0.0730,  0.0705,\n          0.1671, -0.0351, -0.0685, -0.0135],\n        [ 0.1733, -0.1366, -0.1815,  0.1576, -0.0426, -0.1976,  0.0257,  0.1096,\n          0.1886, -0.2194,  0.2078, -0.2180,  0.1084,  0.1895,  0.1771, -0.0571,\n         -0.1812, -0.1733,  0.2047, -0.1462]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0690, -0.1046,  0.0276,  0.0462, -0.1417, -0.1345,  0.2157,  0.1809,\n        -0.0043, -0.1446,  0.1444, -0.1464,  0.0141, -0.1739, -0.2144, -0.0954,\n         0.1798,  0.0049, -0.1598, -0.1517,  0.0856,  0.1609,  0.0963, -0.1475,\n         0.0440, -0.0837, -0.0148,  0.1364, -0.0315,  0.0659,  0.1900,  0.2017],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0370,  0.0318,  0.1130,  0.1405, -0.0503, -0.0921, -0.1634, -0.1442,\n         -0.1622,  0.1151,  0.1586,  0.1459, -0.1531,  0.1585,  0.0078,  0.1101,\n          0.0994,  0.1575, -0.0453, -0.0139, -0.0616,  0.1703, -0.1043,  0.1207,\n          0.0090, -0.0875, -0.1144,  0.0917,  0.1285, -0.0287, -0.0114, -0.0005],\n        [ 0.0091, -0.1097,  0.0987,  0.1508, -0.1213, -0.0626, -0.1532,  0.1012,\n          0.1765,  0.1131,  0.0895,  0.0039,  0.0240, -0.0911, -0.0479, -0.0019,\n         -0.1527, -0.0393,  0.0791,  0.0757, -0.1395,  0.0544, -0.1417, -0.0928,\n          0.1051, -0.1098,  0.0860,  0.0400, -0.1227, -0.0103,  0.1612,  0.1621],\n        [ 0.0566,  0.0564, -0.0182, -0.0250, -0.0286, -0.1447, -0.1128, -0.0386,\n         -0.1675, -0.1099,  0.0259,  0.1333, -0.1124, -0.1751, -0.0473, -0.1123,\n         -0.0122,  0.1235,  0.0401, -0.1424, -0.1148, -0.0978,  0.1685,  0.0768,\n         -0.0653,  0.1537, -0.0060, -0.0892,  0.0707,  0.1056,  0.1752,  0.0494],\n        [-0.1131,  0.0688, -0.0978,  0.1493, -0.1182,  0.0534,  0.1656,  0.1190,\n         -0.0548,  0.0787,  0.0664, -0.1595, -0.1611,  0.0684, -0.0327,  0.1400,\n         -0.0858, -0.1413,  0.1377, -0.0683, -0.1290,  0.0163,  0.1192,  0.0604,\n          0.0581, -0.1732, -0.1676,  0.1210,  0.1422,  0.0579,  0.0674,  0.1359],\n        [-0.0432, -0.0238, -0.0017,  0.1152,  0.0134, -0.0152, -0.0502, -0.0007,\n         -0.1702, -0.1412, -0.0878, -0.1299, -0.1368,  0.0988,  0.1322,  0.1642,\n          0.0088, -0.0216, -0.0461, -0.0785,  0.1320, -0.1156, -0.1379,  0.1429,\n          0.1280,  0.0845, -0.1144, -0.1675,  0.1230, -0.1645, -0.0225,  0.1188],\n        [-0.0707,  0.1024, -0.1481,  0.0606,  0.1762,  0.1163,  0.1549, -0.1626,\n          0.0954, -0.0912, -0.1581, -0.1354,  0.0044,  0.0197,  0.1021, -0.0248,\n         -0.0820,  0.0867, -0.0110,  0.0542, -0.0714, -0.1439,  0.0731, -0.0535,\n          0.0126,  0.1141, -0.0731, -0.0694,  0.0116,  0.0497, -0.0473, -0.0761],\n        [-0.0104,  0.0904, -0.0301, -0.1256,  0.0815, -0.0114,  0.1745,  0.0231,\n          0.1629, -0.0058, -0.0401,  0.0052,  0.1152, -0.1656, -0.1384,  0.0896,\n          0.0723, -0.0285,  0.0544, -0.1496,  0.0026,  0.0695, -0.0990,  0.1243,\n         -0.1056, -0.0623,  0.0909, -0.0850, -0.1327, -0.1635,  0.1542, -0.0826],\n        [-0.1328,  0.0541,  0.1213, -0.1194, -0.0484,  0.0760, -0.0084,  0.1379,\n          0.1692,  0.0375, -0.1367,  0.0197, -0.1434,  0.1223, -0.0985, -0.1494,\n          0.1435,  0.0549, -0.1329, -0.1683, -0.0993,  0.0864,  0.0571,  0.1398,\n         -0.1416,  0.1239, -0.0286, -0.0326, -0.0441,  0.0848,  0.0901,  0.0119],\n        [ 0.1152, -0.0521,  0.0587, -0.0422,  0.0914,  0.0784, -0.0867,  0.1199,\n         -0.0218, -0.0662,  0.0466, -0.0050,  0.0441, -0.1663, -0.0357, -0.0720,\n         -0.1465,  0.1511,  0.1688,  0.1431, -0.1372, -0.1718,  0.1330,  0.0892,\n          0.1428, -0.0267, -0.0793, -0.1457,  0.0372, -0.0671, -0.0101,  0.1210],\n        [-0.0506, -0.0853, -0.0058,  0.0385, -0.0807, -0.0943,  0.0966,  0.1600,\n          0.0596, -0.0878, -0.1353, -0.1305,  0.0800, -0.1538,  0.1528, -0.0011,\n          0.0077, -0.0875, -0.1685, -0.0300, -0.0187, -0.0696,  0.0546,  0.0537,\n         -0.1356,  0.0627, -0.0655,  0.0748, -0.1595,  0.1206, -0.0677,  0.0834],\n        [-0.1759,  0.0380,  0.0687, -0.1669, -0.0226, -0.1167, -0.0310,  0.0708,\n         -0.0599, -0.0682,  0.0664,  0.1070, -0.1326,  0.1485, -0.0168, -0.0129,\n          0.0514,  0.0128, -0.1736,  0.1315, -0.1059,  0.0730,  0.1263, -0.1714,\n         -0.0986, -0.0970,  0.0608, -0.0090, -0.0797, -0.0188, -0.0897,  0.1592],\n        [-0.0703,  0.0116,  0.1571, -0.0409, -0.1113,  0.0922, -0.0333,  0.0241,\n         -0.0708,  0.1598,  0.0306, -0.1088,  0.0144,  0.1074, -0.0920, -0.0143,\n          0.1182, -0.1479,  0.0957,  0.1298, -0.0526,  0.0361,  0.1684, -0.1042,\n         -0.1506, -0.1310,  0.1575, -0.0136, -0.0206, -0.0935, -0.0420,  0.0866],\n        [ 0.0981,  0.0502, -0.0316, -0.0965,  0.0134, -0.1284,  0.0012,  0.1231,\n          0.1167, -0.1699,  0.1432, -0.0495,  0.0020,  0.1684, -0.1763, -0.1376,\n         -0.1112, -0.0619, -0.1361, -0.0465,  0.0285, -0.0976,  0.0426,  0.1088,\n         -0.0342, -0.0298,  0.0459, -0.0449,  0.0501, -0.1475,  0.1242, -0.1269],\n        [-0.0509, -0.0697,  0.0510,  0.0165, -0.0720,  0.1682,  0.0934,  0.0123,\n          0.1058, -0.0942, -0.0143, -0.0038,  0.0543,  0.0311,  0.0337,  0.0803,\n         -0.1172, -0.1529, -0.0981, -0.0509,  0.0679,  0.0662,  0.0712,  0.1292,\n          0.0831, -0.0675,  0.0813,  0.0690,  0.0453,  0.0620,  0.0944, -0.1176],\n        [-0.0819,  0.0710,  0.0678, -0.0536, -0.1678, -0.0768,  0.1506, -0.0606,\n          0.0240,  0.0560,  0.0846, -0.1083,  0.1039, -0.0772, -0.0386,  0.0196,\n          0.1393,  0.0831,  0.0652,  0.0304, -0.0818,  0.0249,  0.0290,  0.1009,\n         -0.0656, -0.0012, -0.1569,  0.0536,  0.1398, -0.1591,  0.0480,  0.0340],\n        [ 0.0235, -0.1619, -0.1682,  0.0392, -0.0684, -0.1625,  0.0601,  0.0411,\n         -0.0355, -0.0406, -0.0854, -0.1604,  0.1482,  0.1019, -0.1724,  0.0527,\n          0.0739,  0.1146,  0.1569, -0.0072,  0.0653, -0.0096, -0.1645,  0.0645,\n          0.1687,  0.0282, -0.0917,  0.1620,  0.1272,  0.1662, -0.1475,  0.0905]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1552, -0.1744, -0.0837, -0.0305,  0.1475,  0.1287,  0.1679, -0.1150,\n        -0.1409, -0.1490,  0.0787, -0.0433,  0.0267,  0.1404,  0.1098,  0.0454],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[ 0.0769, -0.2464, -0.1078,  0.0968, -0.1614, -0.0301, -0.0554, -0.1903,\n         -0.2366, -0.0436, -0.1503,  0.1843,  0.1440, -0.1996,  0.1125,  0.0277],\n        [-0.2091, -0.1844,  0.2035,  0.0629,  0.1267, -0.1583,  0.1340, -0.2342,\n          0.0927, -0.1095,  0.1068, -0.2323, -0.0467,  0.1106, -0.1955,  0.0867],\n        [ 0.1258, -0.0061,  0.1918, -0.0203, -0.1712,  0.2349, -0.2047, -0.1930,\n          0.0977, -0.1453,  0.2401,  0.0965, -0.0077, -0.0112,  0.0163, -0.2433],\n        [-0.0277,  0.0491,  0.2409,  0.0635,  0.2097, -0.0167,  0.1748, -0.0004,\n         -0.0169, -0.0028,  0.1096, -0.2470, -0.2250, -0.1227, -0.1102, -0.1517],\n        [ 0.1986, -0.0414, -0.1028, -0.1812, -0.1393, -0.1728, -0.1524,  0.0360,\n         -0.1974,  0.1147, -0.0990, -0.1058,  0.2112, -0.0125, -0.1607, -0.1378],\n        [-0.1338,  0.1199,  0.1178,  0.1398, -0.2209,  0.2158, -0.0198, -0.2043,\n         -0.1282,  0.0115, -0.0529,  0.2042, -0.2243, -0.0963,  0.0554, -0.1741],\n        [-0.2217, -0.1558,  0.0301,  0.1167,  0.0069,  0.1458, -0.1571,  0.1827,\n          0.1560,  0.2303, -0.2035,  0.0511,  0.0162, -0.0142,  0.0698,  0.2198],\n        [ 0.2478,  0.0279, -0.0978, -0.0431, -0.1551,  0.0911, -0.2294, -0.1238,\n          0.0814, -0.0807, -0.0725, -0.1298, -0.2004, -0.1184,  0.0294,  0.1381]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2081, -0.0151, -0.0200, -0.0689,  0.1535,  0.2143,  0.0764,  0.1188],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2882, -0.1637,  0.0554,  0.3422,  0.0850,  0.0698,  0.0633,  0.2283],\n        [-0.1864, -0.1592, -0.1523,  0.2655, -0.1168, -0.2277, -0.2044,  0.0182],\n        [-0.3381, -0.1205,  0.2506,  0.2090,  0.1149,  0.1780,  0.2314,  0.1659],\n        [-0.3355, -0.0569, -0.1264,  0.1084, -0.2734, -0.0167,  0.2578,  0.2636]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([-0.2250,  0.0574, -0.0797,  0.0597], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "_replay_buffer":	{
                "<algorithms.PPO.replay_buffer.ReplayBuffer object at 0x75d46ba2bfd0>":	{
                    "act_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "adv_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "capacity":	50000,
                    "cobs_buf":	null,
                    "gamma":	0.99,
                    "lam":	0.97,
                    "logp_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "mask_buf":	"[[0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n ...\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]\n [0. 0. 0. 0. 0.]]",
                    "max_size":	50000,
                    "obs_buf":	"[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n ...\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]",
                    "path_start_idx":	0,
                    "ptr":	0,
                    "ret_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "rew_buf":	"[0. 0. 0. ... 0. 0. 0.]",
                    "val_buf":	"[0. 0. 0. ... 0. 0. 0.]"
                }
            },
            "_target_kl":	0.01,
            "_train_pi_iters":	40,
            "_train_v_iters":	40,
            "_traj_per_epoch":	5,
            "_vf_optimizer":	{
                "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)":	{
                    "_optimizer_load_state_dict_post_hooks":	{},
                    "_optimizer_load_state_dict_pre_hooks":	{},
                    "_optimizer_state_dict_post_hooks":	{},
                    "_optimizer_state_dict_pre_hooks":	{},
                    "_optimizer_step_post_hooks":	{},
                    "_optimizer_step_pre_hooks":	{},
                    "_warned_capturable_if_run_uncaptured":	true,
                    "_zero_grad_profile_name":	"Optimizer.zero_grad#Adam.zero_grad",
                    "defaults":	{
                        "amsgrad":	false,
                        "betas":	[
                            0.9,
                            0.999
                        ],
                        "capturable":	false,
                        "differentiable":	false,
                        "eps":	1e-08,
                        "foreach":	null,
                        "fused":	null,
                        "lr":	0.0003,
                        "maximize":	false,
                        "weight_decay":	0
                    },
                    "param_groups":	[
                        {
                            "amsgrad":	false,
                            "betas":	[
                                0.9,
                                0.999
                            ],
                            "capturable":	false,
                            "differentiable":	false,
                            "eps":	1e-08,
                            "foreach":	null,
                            "fused":	null,
                            "lr":	0.0003,
                            "maximize":	false,
                            "params":	[
                                "Parameter containing:\ntensor([[ 2.8302e-02,  1.2616e-01,  1.9737e-01,  3.6493e-02,  9.0623e-03,\n         -1.9456e-01,  1.9012e-01, -1.0676e-02, -3.0347e-02, -1.9985e-01,\n          9.2118e-02,  1.9668e-01, -5.7542e-02, -1.0756e-01,  1.4418e-02,\n          2.0768e-01, -1.4965e-01,  2.0301e-01, -7.4856e-02,  8.0293e-03],\n        [ 1.7402e-01,  3.2941e-02,  1.0136e-01, -1.4378e-01, -1.5407e-01,\n         -1.8382e-01, -7.7320e-02, -1.2093e-01, -6.4964e-02,  1.6500e-01,\n         -1.1145e-01,  7.7004e-02,  9.1445e-02, -1.7510e-01,  1.5052e-01,\n         -1.1591e-01,  1.3810e-02,  9.4536e-02,  1.2466e-02,  1.3075e-01],\n        [ 1.3986e-01,  1.3737e-01, -1.6735e-01, -9.9068e-02, -2.3870e-03,\n         -5.0201e-02, -1.2455e-01,  1.3484e-01,  1.0573e-01,  7.9073e-02,\n          8.9689e-02,  1.4506e-01, -6.4551e-02,  1.7587e-01,  2.0827e-01,\n         -1.1353e-01, -1.9941e-01, -1.2779e-01, -7.1385e-03, -4.2808e-02],\n        [-1.9200e-01,  3.3889e-02,  1.8901e-01,  1.3303e-01,  1.6781e-01,\n          8.6226e-02,  1.3248e-02, -1.9069e-01, -1.2402e-01,  1.8242e-01,\n          2.9357e-02, -1.6833e-01,  2.0432e-01,  2.2293e-02,  2.1621e-01,\n         -6.6168e-03, -2.2766e-02,  1.3750e-01, -2.2227e-01, -1.8860e-01],\n        [ 1.1501e-01,  1.8330e-01,  7.1968e-02,  8.2319e-02, -2.0609e-01,\n          4.9653e-02,  1.1293e-01,  1.8238e-01,  1.2517e-01, -4.3949e-03,\n         -1.3955e-01,  1.1497e-01,  2.0227e-01,  2.2272e-01, -1.2201e-01,\n         -3.3231e-02, -3.3156e-02, -1.0720e-01, -1.0428e-03,  5.5520e-02],\n        [ 4.1576e-02,  5.2734e-02,  6.0091e-02, -1.0810e-01, -2.5248e-02,\n          1.6878e-01, -1.3783e-01,  7.8083e-03, -1.6819e-01, -2.0920e-01,\n         -2.1656e-01, -5.6520e-02,  1.0268e-01, -2.0147e-01, -1.2136e-02,\n          3.8716e-02,  1.4608e-01, -1.7070e-02,  8.5982e-02,  1.5449e-01],\n        [-9.6178e-02,  1.0991e-01, -1.3890e-01,  2.0509e-01,  4.9827e-02,\n         -1.3949e-01,  1.0901e-01, -1.8317e-01, -1.3767e-01, -1.6890e-01,\n         -1.9527e-01, -1.3270e-01, -2.2292e-01, -2.5359e-02,  1.1364e-01,\n          1.0046e-01,  1.1592e-01,  5.3717e-02, -1.7440e-01, -2.1714e-01],\n        [ 4.1975e-02,  9.1671e-02,  2.5334e-02, -9.3996e-03,  2.1274e-01,\n         -1.4510e-01,  2.1477e-01, -1.5111e-01, -4.9957e-02, -1.7282e-01,\n         -4.8656e-02,  8.6320e-02,  1.6433e-01,  8.4265e-02,  2.1707e-01,\n         -1.6526e-01, -1.6622e-01,  1.6502e-01, -1.3544e-01,  1.0837e-01],\n        [-1.4839e-01,  1.1411e-01,  1.2096e-01, -1.9329e-01, -2.1122e-01,\n         -6.4949e-02, -7.3103e-03,  1.3669e-02,  8.1890e-03, -7.9851e-02,\n          1.6700e-01, -1.3011e-01, -7.2706e-02,  1.3250e-01,  6.8107e-02,\n         -8.1758e-02, -1.2138e-01,  1.5603e-01, -1.1462e-01,  2.1429e-02],\n        [-2.0639e-01,  5.8342e-02, -9.3061e-02, -5.9064e-02, -1.1842e-02,\n         -4.3947e-02, -4.5557e-02,  1.3237e-01, -5.0671e-02, -2.2275e-01,\n         -2.0710e-01, -1.9179e-01, -2.2212e-01,  1.5203e-01, -6.4570e-02,\n          1.0785e-01, -1.8698e-01,  2.0722e-01,  1.0730e-01, -1.6223e-01],\n        [-1.9234e-01,  1.4076e-01, -1.8407e-01,  2.4002e-02, -1.9269e-01,\n          2.1295e-01, -1.0710e-01,  4.7645e-02,  8.8735e-02,  1.7094e-01,\n          1.0962e-01,  6.9582e-02,  1.1145e-01,  2.1583e-01, -1.0124e-01,\n          6.8846e-02, -8.6846e-02, -1.3447e-01,  1.9224e-01, -7.4907e-02],\n        [ 7.7173e-02,  1.1824e-01,  2.1391e-01,  1.0008e-01,  7.8738e-02,\n         -2.0043e-01, -1.6299e-01, -1.6396e-01,  6.1301e-02,  2.4207e-02,\n          3.7309e-02, -1.5493e-01, -2.1928e-01,  5.4802e-02, -1.5667e-01,\n          4.4056e-02,  1.3808e-01,  1.8337e-01, -2.8774e-02,  1.8679e-01],\n        [-1.1778e-02,  4.1652e-03,  1.5537e-01, -1.9526e-01, -6.7827e-02,\n          1.4890e-01, -1.4533e-01, -2.2357e-02, -3.5448e-02, -3.3574e-02,\n         -8.1382e-03, -8.6191e-02, -1.6807e-01,  8.1837e-02, -1.5637e-01,\n          5.2115e-02, -1.8472e-01,  3.8122e-02,  1.7139e-01, -1.9016e-01],\n        [ 1.4741e-01,  1.1302e-01,  2.1669e-01, -1.6403e-01,  1.0905e-02,\n          7.7438e-02,  1.2091e-01,  3.2654e-05, -1.7174e-01, -5.5512e-02,\n         -1.8841e-01,  4.5032e-02, -1.7320e-03, -9.8715e-02,  9.0664e-03,\n         -1.7926e-01,  6.6694e-02,  3.2034e-02, -3.9163e-02, -9.7560e-02],\n        [ 1.6908e-01, -4.4884e-02, -2.1214e-01,  1.1054e-02, -1.3695e-01,\n          1.6429e-01, -8.1785e-02,  1.9651e-01,  1.3588e-01, -1.9135e-01,\n         -3.5708e-02, -1.6608e-01, -1.1818e-01, -4.2490e-02,  1.0031e-02,\n          1.2595e-01, -5.1102e-02,  6.9412e-02, -5.4245e-02,  1.5356e-01],\n        [-2.1557e-01,  1.4495e-01,  1.6395e-01, -1.1279e-01, -1.9187e-02,\n         -1.1287e-02, -1.8868e-01,  3.0742e-02, -3.4899e-02,  1.7048e-01,\n          1.3966e-01,  1.1364e-01,  1.4038e-01, -1.0663e-01, -8.2252e-03,\n         -2.0211e-01,  5.8858e-02,  5.5824e-02,  3.9798e-02,  1.3624e-01],\n        [ 1.1795e-01, -2.0133e-01,  2.1594e-01,  1.7257e-01, -4.1536e-02,\n          1.5833e-01,  7.7171e-02, -1.4667e-01, -1.3466e-01, -2.0269e-02,\n         -1.0233e-01,  1.7804e-01,  5.4775e-02, -6.0482e-02,  1.4690e-01,\n         -1.7832e-01,  1.8214e-01,  4.4041e-02,  1.2045e-01,  8.5783e-03],\n        [-1.0318e-01, -1.2022e-01,  1.2821e-01, -1.6069e-01, -1.1174e-01,\n         -1.3306e-01, -2.1481e-01,  4.4382e-02, -7.0767e-02, -3.9252e-02,\n          2.0316e-01, -2.1036e-01,  1.9576e-01, -4.7302e-02, -6.1490e-03,\n          1.2846e-01, -8.1006e-02,  1.4907e-01,  1.7157e-01,  1.4541e-01],\n        [-2.5566e-03, -9.1286e-02, -1.2780e-01,  1.2445e-01,  4.9820e-02,\n          1.1673e-03,  1.4890e-01, -1.1447e-02, -2.1849e-01,  1.4742e-01,\n         -5.6703e-02, -2.2169e-01, -2.1590e-01,  2.9863e-03, -1.7664e-01,\n         -1.5373e-01, -2.8973e-02,  6.3047e-03,  1.6013e-01,  1.0316e-01],\n        [-1.8279e-01, -1.9412e-01,  5.7929e-02,  2.0861e-02,  1.8531e-01,\n          1.7576e-01,  2.0054e-01, -1.9977e-01, -2.1732e-01,  8.2242e-02,\n         -2.1432e-01, -1.8546e-01, -1.7541e-01, -1.8690e-01, -1.6944e-01,\n          1.6403e-01, -1.2863e-01,  2.0213e-01, -1.8942e-01, -1.9478e-01],\n        [ 1.9070e-01, -1.1546e-01, -1.6436e-01,  4.4907e-02,  5.6768e-03,\n          1.5614e-01, -1.3113e-01,  1.4987e-01,  7.2504e-02, -1.4653e-01,\n          2.1443e-01, -1.0126e-01,  2.3520e-02,  1.6974e-01,  1.0196e-01,\n         -1.4211e-01, -4.3596e-02, -1.8353e-02, -9.0993e-02,  2.0982e-01],\n        [-1.4704e-01, -8.3836e-02, -1.0901e-01, -1.7193e-01, -9.7994e-02,\n          1.0638e-01, -6.0328e-02,  8.9419e-02,  6.7898e-02,  1.7472e-01,\n         -1.5193e-01, -9.8392e-02, -2.0171e-01, -6.4195e-02,  6.5422e-02,\n          1.1262e-01, -1.0993e-01, -1.3410e-01, -6.8997e-02,  4.0319e-02],\n        [-2.5190e-02, -2.0967e-01,  2.0441e-01,  2.4353e-02, -1.7920e-01,\n          2.2173e-01, -2.5666e-02,  1.5788e-01,  3.8671e-02, -1.5518e-01,\n         -5.1859e-02,  2.2258e-01,  2.2684e-03,  1.3970e-01,  1.6050e-01,\n         -8.5124e-02,  1.3598e-01,  1.2321e-01,  8.5227e-02,  5.1449e-02],\n        [-1.8621e-01, -1.4521e-01, -1.7839e-01, -1.2390e-01,  1.8734e-01,\n         -4.1450e-02,  1.7330e-01,  2.0275e-01, -6.2927e-02, -1.0490e-01,\n          1.0342e-01,  1.7354e-01, -5.6083e-03,  4.8235e-02,  1.1699e-01,\n         -2.0282e-01,  1.0036e-01, -3.2985e-02,  2.0475e-01,  1.1554e-01],\n        [ 7.4140e-02,  1.2598e-02,  1.0233e-02,  8.3234e-02,  3.8265e-02,\n         -1.3205e-01, -5.9874e-02,  1.4588e-01,  1.4312e-01, -7.1629e-02,\n         -2.1534e-01, -8.0675e-02, -2.1830e-01, -6.0864e-02, -1.2124e-01,\n          1.0082e-02,  2.0583e-01,  8.5075e-02,  8.6937e-02,  5.0321e-02],\n        [ 5.6396e-02, -1.8465e-01, -1.3896e-01,  5.9803e-02, -7.4154e-04,\n         -1.7416e-01,  1.7115e-01,  3.8717e-02, -1.1163e-01,  1.7077e-01,\n         -8.0603e-02, -1.5402e-01, -1.2896e-01, -1.2855e-01, -5.4234e-02,\n         -1.9879e-01,  1.5851e-01,  1.3564e-01, -1.8346e-01, -1.6577e-01],\n        [ 6.6788e-02,  1.3024e-01, -1.5775e-01, -1.6372e-01, -1.3342e-01,\n         -1.6198e-01,  2.0500e-02, -1.7160e-01,  1.6636e-01, -1.9896e-01,\n          1.7074e-02,  1.6675e-01, -2.0230e-01, -1.9199e-01,  9.8394e-02,\n         -8.8468e-02, -2.0649e-01, -1.7479e-01,  2.1411e-01, -3.2618e-02],\n        [ 4.4173e-02,  2.0570e-01, -2.1145e-01,  7.1168e-02, -1.4264e-01,\n          1.0683e-01,  1.4247e-01,  1.3441e-01,  1.7946e-01, -1.7634e-01,\n          1.9777e-01, -1.2535e-01, -6.4430e-02,  1.0673e-01,  6.8983e-02,\n         -2.0380e-01, -1.4911e-01, -1.2077e-01, -1.1907e-01, -2.7558e-02],\n        [ 2.8225e-02,  1.1885e-01,  1.5261e-01,  3.6360e-02,  7.1426e-02,\n         -1.3969e-01, -3.1936e-02, -1.3579e-01,  1.5083e-01,  5.7759e-02,\n          1.8713e-01, -1.9232e-02, -9.2016e-02, -2.4395e-02,  1.8722e-02,\n         -9.1690e-02,  1.3955e-01, -1.5274e-01, -4.3733e-02, -1.8996e-01],\n        [-3.3135e-02,  8.4819e-02, -1.5244e-01,  3.2111e-02, -8.6630e-02,\n          1.0755e-01, -1.8418e-01, -4.6082e-02, -9.2870e-02, -1.0702e-02,\n          1.0033e-01,  6.8053e-02, -4.5643e-02,  7.5136e-02,  1.6205e-01,\n          1.4840e-01,  4.5588e-02, -1.4791e-01,  2.3464e-02, -1.7014e-01],\n        [-2.0241e-01, -7.7441e-02,  1.1168e-02,  3.7080e-02, -1.2606e-01,\n          5.8405e-02,  4.6105e-02,  1.3236e-01, -2.2144e-01, -2.0153e-01,\n          1.4242e-01,  7.5791e-03, -1.5933e-01, -2.1944e-01, -2.0689e-01,\n         -1.9971e-02,  9.0241e-02, -5.3731e-02, -1.6532e-01,  1.2849e-01],\n        [-1.8367e-01,  1.7830e-01,  1.9349e-01, -1.5432e-01,  1.7467e-01,\n         -1.0729e-01,  1.6433e-01, -5.7253e-03,  3.8015e-02, -8.9598e-02,\n          6.5364e-02,  9.9353e-02, -6.9536e-02,  1.2107e-01,  4.5678e-02,\n          1.4510e-01,  9.9135e-02, -1.9693e-02,  1.9627e-01,  8.7988e-02]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 1.7102e-01,  3.9722e-02, -2.0094e-01, -1.1154e-01,  2.7902e-02,\n        -1.4391e-01, -8.3410e-03, -1.3625e-01,  1.3148e-01,  9.7367e-02,\n         1.5225e-01,  1.4520e-01, -1.7442e-01,  7.5066e-02,  7.7733e-02,\n        -1.5639e-01, -1.6158e-01, -1.5456e-01,  4.3690e-02, -1.2020e-01,\n        -3.2982e-02,  9.2430e-02,  6.9679e-05,  2.2143e-02,  1.1057e-01,\n         5.9008e-02,  7.7185e-03,  1.2206e-01,  2.7748e-02, -1.7068e-01,\n         8.2053e-02,  1.4179e-01], requires_grad=True)",
                                "Parameter containing:\ntensor([[ 1.4150e-01,  1.1853e-01, -9.6394e-02, -9.5001e-02, -7.1525e-02,\n          3.6820e-02, -1.2028e-01,  8.2925e-02, -1.3165e-01,  1.6530e-01,\n          4.3390e-02,  1.3648e-02,  7.2997e-02,  1.3690e-01,  8.2497e-03,\n          1.5668e-01,  1.3605e-01,  1.4915e-01, -1.4609e-01,  3.2758e-02,\n         -1.0294e-01, -1.2886e-01,  6.1835e-02,  7.1925e-02,  6.6270e-02,\n         -1.0837e-01, -2.7625e-02, -1.5456e-01,  1.0721e-01,  1.5375e-01,\n         -1.4737e-01,  3.0225e-02],\n        [ 1.2005e-01,  1.5997e-01, -1.1408e-01,  1.0243e-01,  1.0954e-01,\n          1.2787e-01, -1.1481e-01, -1.6229e-01,  1.7541e-01, -7.9665e-02,\n         -5.0857e-02,  1.5019e-02,  1.3026e-01, -8.9467e-02, -9.8712e-02,\n         -1.3301e-01,  1.2913e-01,  1.6636e-03, -4.4934e-02,  1.1238e-01,\n         -1.2620e-01, -1.7494e-01,  1.1226e-01, -5.0246e-02,  8.4156e-02,\n          9.2756e-02, -1.1815e-01,  6.1591e-02,  3.2890e-02, -1.1740e-01,\n         -1.0702e-01,  5.1381e-02],\n        [-5.6233e-02, -1.1254e-02,  3.1101e-02,  3.0624e-02, -1.4187e-01,\n          4.8702e-02,  8.2259e-02,  2.4246e-03, -7.3875e-02, -5.3801e-02,\n         -1.3005e-01,  1.5101e-01,  9.6640e-02, -1.5359e-02,  1.2641e-01,\n          1.5861e-01, -2.5810e-02,  1.7249e-01, -1.3539e-02,  1.3220e-01,\n         -1.0110e-01,  1.0046e-01, -9.8510e-02,  1.1137e-01,  1.7171e-01,\n          8.0503e-02, -1.6263e-01, -9.7389e-02,  1.4724e-01,  1.4171e-01,\n          6.1378e-02, -1.5412e-01],\n        [-5.0403e-02,  4.7110e-02,  1.3329e-01,  7.0282e-02, -1.5092e-01,\n          1.5365e-01, -1.5337e-01, -7.5779e-02, -7.0466e-02,  1.1629e-01,\n          2.2864e-02,  6.9250e-02, -1.3254e-01,  8.6658e-02, -1.6129e-01,\n         -7.6984e-02, -1.9157e-02, -8.9689e-02, -9.2216e-02,  1.7627e-01,\n          8.8957e-02,  1.6350e-01, -1.2418e-01, -1.2547e-01, -1.6792e-01,\n          5.7273e-02, -3.0012e-02,  1.3476e-01, -6.5641e-02, -7.8852e-02,\n         -6.7852e-02, -1.8922e-02],\n        [ 3.4918e-02, -1.1927e-01, -7.7008e-02,  1.4169e-01, -1.5177e-01,\n         -1.1912e-01, -9.7695e-03, -1.4217e-01,  1.0648e-01,  1.3827e-01,\n          8.3167e-02, -4.3594e-02, -1.1338e-01, -1.6902e-01, -7.8393e-02,\n         -4.6690e-04, -1.0980e-01, -1.6668e-02,  8.2959e-02,  8.9314e-03,\n         -1.4125e-01,  1.3279e-01,  7.1015e-02,  1.3172e-01, -1.5384e-01,\n         -1.7208e-01, -8.5349e-02, -1.0440e-01,  4.3879e-02,  5.0265e-02,\n          3.3199e-02, -9.4322e-02],\n        [-1.4490e-01, -5.3136e-02, -1.6066e-01, -7.7236e-02,  1.4688e-03,\n         -1.2220e-02,  9.7822e-02, -1.2144e-01, -9.6070e-03,  1.2488e-01,\n          2.1641e-03,  1.1651e-01, -1.2110e-01,  2.3824e-02,  3.5632e-02,\n          5.7502e-03, -2.2354e-02,  1.3590e-01, -1.3628e-01, -1.5510e-01,\n          9.8486e-03,  1.0219e-01,  1.2985e-01, -1.6359e-01, -1.3558e-01,\n         -8.5551e-02, -1.3648e-01, -1.6579e-01, -1.1025e-01, -1.1072e-01,\n         -7.0481e-02,  1.3963e-01],\n        [-1.5436e-01, -3.1946e-02,  3.9528e-02,  1.6378e-01,  1.8604e-02,\n         -1.5626e-02,  1.3926e-01, -2.5158e-02, -1.1278e-01,  3.0450e-02,\n         -3.1729e-02,  1.3615e-01,  1.2591e-01,  3.8193e-02, -8.1712e-02,\n         -2.8856e-02, -9.7828e-02, -5.2792e-02,  1.2460e-01, -5.3643e-03,\n          6.4122e-02, -1.5844e-01, -8.0775e-02,  9.6462e-02,  1.1585e-01,\n          1.7077e-01, -9.1753e-03, -2.4759e-03, -2.8886e-02,  3.8559e-02,\n          4.3754e-02,  1.7008e-01],\n        [ 1.7449e-01,  2.6509e-02,  2.8031e-02,  6.1539e-02,  1.3258e-01,\n         -1.6228e-01,  1.5989e-01,  1.0190e-01,  1.0916e-01, -1.2312e-01,\n          1.5856e-01,  1.3662e-02, -7.8713e-02, -1.3395e-01, -8.7752e-02,\n         -3.6917e-02,  8.5972e-02,  1.8113e-02,  9.2552e-02,  3.9073e-02,\n         -1.3914e-01,  1.5720e-01, -1.1804e-01,  5.3021e-02,  1.6067e-01,\n          5.1160e-02, -2.6592e-02, -6.9348e-02, -1.6183e-01, -7.7249e-02,\n          3.3396e-02, -5.7282e-02],\n        [ 1.3863e-01, -9.5178e-03,  9.1492e-02, -4.3900e-02,  9.9118e-02,\n          1.4893e-01,  1.1557e-01,  7.7275e-02,  1.5083e-01,  1.7062e-01,\n          1.5360e-01, -9.1154e-02, -1.6057e-01,  1.0449e-02, -1.7296e-01,\n          9.0110e-02, -4.2679e-02,  1.7167e-01,  1.3125e-01, -1.1445e-01,\n          8.8184e-02, -4.0645e-02,  3.4907e-02, -4.1953e-02,  7.5194e-02,\n         -9.4229e-02, -9.9683e-03, -1.6522e-02,  9.3176e-02, -1.6305e-01,\n          1.5253e-01,  1.1151e-02],\n        [ 3.4695e-02,  6.7044e-02,  1.5941e-01, -9.7369e-02, -8.7186e-02,\n          1.3662e-01, -2.5587e-02,  1.0881e-01, -2.8986e-03, -9.4102e-02,\n          4.2394e-02, -1.4143e-01,  1.7213e-01, -1.3663e-01,  5.3341e-02,\n          1.3508e-01, -1.5179e-01,  7.0173e-02,  4.0378e-02, -1.0361e-01,\n         -1.4623e-01,  1.5103e-01,  8.8067e-02, -1.5845e-01,  5.2659e-02,\n          1.3292e-02,  1.0195e-01,  4.9440e-02, -8.7791e-03,  8.0421e-02,\n          7.1490e-02,  2.7041e-02],\n        [-9.9841e-02,  1.2328e-01, -1.6198e-01, -1.0896e-01,  8.0383e-02,\n         -1.2755e-01,  5.1433e-02, -1.3539e-01,  9.9768e-02,  7.8071e-02,\n          1.7412e-01,  7.8243e-02, -1.2104e-01, -1.5379e-01,  9.2137e-02,\n         -1.6946e-01, -1.4148e-01, -1.5198e-01,  1.6881e-01, -9.5362e-02,\n         -9.3748e-02,  4.3403e-02, -8.7824e-02, -4.9672e-02,  1.3977e-01,\n         -1.2467e-02, -8.8441e-04, -1.5973e-01,  5.3127e-02,  1.6882e-01,\n         -3.2016e-02, -3.4026e-02],\n        [ 7.8435e-02, -1.6814e-01,  9.8955e-03,  6.1081e-02,  1.3178e-01,\n         -5.6417e-03,  1.1466e-01,  2.0362e-02,  2.2956e-03,  1.5791e-01,\n         -1.7206e-02,  1.2153e-02, -8.1878e-02, -1.5683e-01,  1.3850e-01,\n          7.3713e-02, -9.0716e-02, -1.0392e-01, -8.9968e-02, -7.3374e-02,\n         -1.4587e-01,  6.3743e-03,  3.7984e-02,  1.4947e-01, -1.1679e-02,\n         -1.0403e-01, -5.9837e-02, -1.0448e-01,  9.5830e-02,  9.0476e-02,\n         -9.8563e-02,  1.2367e-01],\n        [ 9.1095e-02, -1.5015e-02, -6.0378e-02,  1.2963e-01,  1.7358e-01,\n          7.1752e-02, -1.0373e-01,  2.3525e-02, -1.6658e-01,  4.1771e-02,\n          5.0764e-02, -1.3134e-01,  1.3284e-01, -3.3948e-02,  6.2755e-03,\n         -1.5079e-01,  6.7252e-02,  1.2751e-01, -1.1694e-01,  1.4731e-01,\n         -3.4226e-02,  5.7294e-02,  1.4377e-01, -1.2884e-02, -4.1519e-02,\n         -7.5462e-02, -2.7469e-02, -7.8669e-02, -5.8263e-02, -4.8364e-05,\n         -3.8848e-02,  7.8689e-02],\n        [ 9.4914e-02,  2.8891e-02,  6.9815e-02,  1.5062e-01, -4.8667e-02,\n         -1.5668e-01, -1.5302e-01, -1.6169e-01, -1.2777e-01,  7.1184e-02,\n          5.8239e-02,  1.3794e-01, -1.4777e-01, -1.7319e-01,  7.3800e-02,\n         -3.3717e-02, -7.1668e-03, -1.3165e-02, -5.0997e-02, -1.3538e-01,\n         -1.2831e-01, -1.2050e-01,  4.4147e-02,  1.3996e-01,  3.7132e-02,\n          4.0844e-02,  1.5788e-01,  1.1372e-01,  2.6260e-02, -8.8281e-02,\n         -6.4388e-02, -1.5860e-01],\n        [ 8.0737e-02, -3.1168e-02, -1.1539e-01, -7.3360e-02, -1.6368e-01,\n         -1.3037e-01,  1.7341e-01,  3.3365e-03,  1.4699e-01,  9.8497e-02,\n         -1.4614e-01, -6.3625e-02, -1.2331e-01,  8.0552e-02, -1.0003e-01,\n         -8.7328e-02, -4.1120e-02,  1.2893e-01,  5.2755e-02, -1.2063e-01,\n          1.4801e-01,  1.1545e-01,  7.3405e-02,  4.8035e-02, -1.3791e-01,\n         -1.1671e-01,  6.4933e-02, -1.2390e-01,  1.0913e-01,  9.4587e-02,\n          1.7206e-01, -7.4101e-02],\n        [-8.7147e-02, -1.4919e-03, -1.5115e-01, -9.5615e-02,  4.3767e-02,\n         -1.5772e-01,  1.1329e-01,  1.7423e-01,  4.7687e-02,  1.6534e-01,\n          3.0357e-02,  1.4373e-01,  5.2991e-02,  1.0164e-01,  1.2135e-01,\n          1.6628e-01,  1.1781e-01, -7.1302e-02, -4.8296e-02,  1.1456e-01,\n         -8.9152e-02, -1.7375e-01,  1.4579e-01, -1.5689e-01,  3.5061e-02,\n         -1.4168e-01,  3.8522e-02,  4.0479e-02, -7.8315e-02, -7.2896e-03,\n         -1.1146e-01,  1.3112e-01]], requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.0082,  0.0881, -0.1762, -0.0418, -0.0448,  0.1047,  0.0682, -0.1730,\n        -0.0637,  0.0507, -0.1500, -0.1511, -0.1699, -0.0254, -0.0504,  0.0111],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.2191,  0.1863, -0.2167, -0.1194,  0.1158,  0.1382,  0.1773,  0.0520,\n          0.2258, -0.2492,  0.2116,  0.0322, -0.0982, -0.0670, -0.2161, -0.0777],\n        [ 0.1356, -0.1698, -0.2238, -0.2160, -0.0367,  0.1367,  0.2080,  0.1240,\n         -0.0991, -0.2413,  0.0726,  0.0074, -0.1506, -0.2186, -0.1260, -0.1191],\n        [-0.0454,  0.0838,  0.1974, -0.0243, -0.1217, -0.0651, -0.0713,  0.0907,\n          0.1454,  0.0713, -0.0378,  0.1308, -0.2170, -0.1912, -0.2227, -0.1738],\n        [ 0.1012, -0.0257,  0.1428,  0.0657, -0.1809, -0.0755,  0.1676, -0.1214,\n          0.0169, -0.0878, -0.0068, -0.0018, -0.2053,  0.0761,  0.1633, -0.1674],\n        [ 0.0708, -0.0846,  0.1275,  0.1419,  0.0313, -0.1769,  0.0340, -0.1491,\n          0.2488, -0.0553, -0.0871,  0.0918,  0.2102,  0.0521, -0.1314,  0.1830],\n        [ 0.2301,  0.1938, -0.1670, -0.0151,  0.0578,  0.1494,  0.2339, -0.0470,\n          0.1064,  0.0589,  0.0118,  0.0210, -0.1229, -0.1698, -0.1957, -0.1114],\n        [ 0.0276, -0.1869,  0.0464,  0.1278, -0.1858,  0.2145, -0.0995, -0.1424,\n          0.0700, -0.0154,  0.1872, -0.0365, -0.0706, -0.0210, -0.0129,  0.2118],\n        [ 0.1968, -0.1576, -0.2261, -0.1183, -0.2023, -0.2289,  0.2058,  0.0986,\n          0.1082, -0.0332, -0.1916,  0.0837,  0.1580, -0.1723,  0.0441,  0.2394]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([ 0.1427,  0.1440,  0.1089, -0.2224, -0.1821,  0.1911, -0.0775, -0.2159],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([[-0.0172, -0.2877,  0.2396, -0.3276, -0.3151,  0.0512,  0.2990, -0.2753]],\n       requires_grad=True)",
                                "Parameter containing:\ntensor([0.0805], requires_grad=True)"
                            ],
                            "weight_decay":	0
                        }
                    ],
                    "state":	{}
                }
            },
            "logger":	{
                "<utils.logger.EpochLogger object at 0x75d46ba2b910>":	{
                    "epoch_dict":	{},
                    "exp_name":	"rl4sys-ppo-info",
                    "first_row":	true,
                    "log_current_row":	{},
                    "log_headers":	[],
                    "output_dir":	"/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s551360000",
                    "output_file":	{
                        "<_io.TextIOWrapper name='/home/girigiri-linux/Project/RL4Sys/examples/maze-game/./logs/rl4sys-ppo-info/rl4sys-ppo-info_s551360000/progress.txt' mode='w' encoding='UTF-8'>":	{
                            "mode":	"w"
                        }
                    }
                }
            }
        }
    },
    "target_kl":	0.01,
    "train_pi_iters":	40,
    "train_v_iters":	40,
    "traj_per_epoch":	5,
    "vf_lr":	0.0003
}