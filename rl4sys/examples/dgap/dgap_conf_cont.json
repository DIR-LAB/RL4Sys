{
  "client_id": "dgap",
  "algorithm_name": "PPO_Continuous",
  "algorithm_parameters": {
    "batch_size": 512,
    "act_dim": 1,
    "seed": 0,
    "traj_per_epoch": 512,
    "clip_ratio": 0.2,
    "gamma": 0.99,
    "lam": 0.95,
    "pi_lr": 3e-4,
    "vf_lr": 1e-3,
    "train_pi_iters": 40,
    "train_v_iters": 40,
    "target_kl": 0.02,
    "input_size": 6
  },
  "act_limit": 1.0,
  "max_traj_length": 1000,
  "type": "onpolicy",
  "train_server_address": "localhost:50051",
  "send_frequency": 1
}


